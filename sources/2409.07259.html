<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.07259] ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages</title><meta property="og:description" content="In this study, we introduce ManaTTS, the most extensive publicly accessible single-speaker Persian corpus, and a comprehensive framework for collecting transcribed speech datasets for the Persian language. ManaTTS, rel…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.07259">

<!--Generated on Sat Oct  5 23:23:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mahta Fetrat Qharabagh 
<br class="ltx_break">Department of Computer Engineering 
<br class="ltx_break">Sharif University of Technology 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">m.fetrat@sharif.edu</span> 
<br class="ltx_break">Zahra Dehghanian 
<br class="ltx_break">Department of Computer Engineering 
<br class="ltx_break">Sharif University of Technology 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">zahra.dehghanian97@sharif.edu</span> 
<br class="ltx_break">Hamid R. Rabiee 
<br class="ltx_break">Department of Computer Engineering 
<br class="ltx_break">Sharif University of Technology 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">rabiee@sharif.edu</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">In this study, we introduce ManaTTS, the most extensive publicly accessible single-speaker Persian corpus, and a comprehensive framework for collecting transcribed speech datasets for the Persian language. ManaTTS, released under the open CC-0 license, comprises approximately 86 hours of audio with a sampling rate of 44.1 kHz. Alongside ManaTTS, we also generated the VirgoolInformal dataset to evaluate Persian speech recognition models used for forced alignment, extending over 5 hours of audio. The datasets are supported by a fully transparent, MIT-licensed pipeline, a testament to innovation in the field. It includes unique tools for sentence tokenization, bounded audio segmentation, and a novel forced alignment method. This alignment technique is specifically designed for low-resource languages, addressing a crucial need in the field. With this dataset, we trained a Tacotron2-based TTS model, achieving a Mean Opinion Score (MOS) of 3.76, which is remarkably close to the MOS of 3.86 for the utterances generated by the same vocoder and natural spectrogram, and the MOS of 4.01 for the natural waveform, demonstrating the exceptional quality and effectiveness of the corpus.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Text-to-speech conversion has long been an essential task. It is integrated with everyday life, including navigation systems, e-learning, content providing, and much more <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. But one of the most vital applications of text-to-speech systems is providing accessibility for people with visual impairments, enabling written materials such as electronic device screens to be converted to speech that can be heard rather than read <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The reason to put an emphasis on the latter application is the lack of open-access high-quality systems. There are actually some Persian text-to-speech models embedded into applications like the Balad map <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and many commercial tools like Narakeet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. But there are not any high-quality freely available TTS models that can be used by the more limited audience including the visually impaired and speech domain researchers.
To address these challenges, it is crucial to develop open-access text-to-speech tools, which primarily requires a proper text-to-speech dataset.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">An ideal text-to-speech dataset must meet several criteria <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. First, it must
exhibit minimal to no
mismatches in transcripts. Second, it should have no background sound including noise or background music. Third, it should have a high sampling rate (at least 24 kHz) to be useful for modern TTS models. It is also beneficial if the transcripts include exact punctuation to help detect stops and intonations. Additionally, the dataset should be large in terms of both total time duration and word coverage. Therefore, it is important for the data source to be diverse and not limited to a specific domain.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Our investigations show that many existing text-to-speech datasets for the Persian language are not publicly available. On the other hand, there are serious challenges with the available data, the most important being non-open licenses, along with issues such as small size, low quality, and limited domain, which will be discussed in the related works review. Hence, the first step toward open-source and open-access text-to-speech models for the Persian language, and the main focus of the current study, is to prepare such a clean, large-scale and open-source dataset.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this work, we introduce a new dataset called "ManaTTS". The word Mana means "Enduring" and is derived from the name of a monthly magazine devoted to the blind community, called Nasl-e-Mana <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, which has been the source of our dataset. The magazine is publicly available, and the content providers were receptive to publishing the dataset with an open CC-0 license.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The dataset is available at https://huggingface.co/datasets/MahtaFetrat/Mana-TTS</span></span></span> The ManaTTS corpus has the following characteristics:</p>
</div>
<div id="S1.p6" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Sampling rate:</span> All the audio files have a sampling rate of 44.1 kHz.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Speakers:</span> The entire dataset is recorded by a single female speaker.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Duration:</span> It includes 86 hours and 24 minutes of processed and transcribed audio and is by far the largest single-speaker dataset in Persian.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">License:</span> It is distributed under the open CC-0 1.0 license, enabling educational and commercial use.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p"><span id="S1.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Environment:</span> The data is mostly recorded in a silent environment and processed to remove potential background music.</p>
</div>
</li>
<li id="S1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i6.p1" class="ltx_para">
<p id="S1.I1.i6.p1.1" class="ltx_p"><span id="S1.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Processing Method:</span> The entire processing pipeline of the dataset is available, making it fully reproducible. This pipeline introduces a set of open-source useful tools for speech dataset creation including a new sentence tokenization and forced alignment tool.</p>
</div>
</li>
<li id="S1.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i7.p1" class="ltx_para">
<p id="S1.I1.i7.p1.1" class="ltx_p"><span id="S1.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">Extendable:</span> The dataset can be easily extended thanks to the monthly growing Nasl-e-Mana magazine and the fully open pipeline.</p>
</div>
</li>
<li id="S1.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i8.p1" class="ltx_para">
<p id="S1.I1.i8.p1.1" class="ltx_p"><span id="S1.I1.i8.p1.1.1" class="ltx_text ltx_font_bold">Coverage:</span> The dataset includes 24113 unique words and encompasses a variety of different topic domains.</p>
</div>
</li>
<li id="S1.I1.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i9.p1" class="ltx_para">
<p id="S1.I1.i9.p1.1" class="ltx_p"><span id="S1.I1.i9.p1.1.1" class="ltx_text ltx_font_bold">Evaluation:</span> The dataset is used to train a TTS model and has demonstrated effectiveness and high-quality outputs.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">We have also collected and processed VirgoolInformal, a smaller dataset comprising 5.63 hours of transcribed speech. This dataset is suitable for evaluating ASR models based on Character Error Rate (CER) and is used to prioritize the ASR models in the alignment tool for this work. For more details, refer to Appendix <a href="#A2" title="Appendix B Evaluation of ASR Models ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">The rest of the paper is organized as follows. The next section provides a comprehensive review of the available Persian speech datasets. Section <a href="#S3" title="3 Dataset Preparation ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> includes a detailed explanation of the data collection and processing methods. Section <a href="#S4" title="4 Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> describes the statistics of the dataset. Section <a href="#S5" title="5 Experiments ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents the experimental results. The final sections <a href="#S6" title="6 Discussion ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> and <a href="#S7" title="7 Conclusion ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> summarize the achievements and limitations of this study.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Our analysis encompasses various Persian datasets, including text-to-speech (TTS) datasets (Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) and other collections featuring speech-text pairs (Table <a href="#A1.T3" title="Table 3 ‣ Appendix A Extended Discussion of Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). These include automatic speech recognition (ASR) datasets, audio-visual speech recognition (AVSR) datasets specific to Persian, a dataset for Persian phoneme recognition (PR), a Persian spoken digit recognition (DR) dataset, as well as multilingual datasets that incorporate Persian language components. While the primary focus of this study and the discussions in this section is on Persian speech corpora for text-to-speech systems, we have also included several well-known English TTS speech datasets for a more comprehensive comparison (Table <a href="#A1.T4" title="Table 4 ‣ Appendix A Extended Discussion of Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). To see an extended discussion of the related works, please refer to Appendix <a href="#A1" title="Appendix A Extended Discussion of Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a></p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.38.2.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">List of Persian text-to-speech corpora.<span id="S2.T1.2.1.2" class="ltx_text ltx_font_medium"> </span>Size<span id="S2.T1.2.1.1" class="ltx_text ltx_font_medium"> indicates the duration in hours, and 
<span id="S2.T1.2.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.0pt;height:6.1pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.5pt,0.0pt) scale(0.85,1.0) ;">
<span id="S2.T1.2.1.1.1.1" class="ltx_p"><math id="S2.T1.2.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.2.1.1.1.1.m1.1b"><mo id="S2.T1.2.1.1.1.1.m1.1.1" xref="S2.T1.2.1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.1.1.1.1.m1.1c"><times id="S2.T1.2.1.1.1.1.m1.1.1.cmml" xref="S2.T1.2.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.1.1.1.1.m1.1d">\times</annotation></semantics></math></span>
</span></span> in the </span>Natural Text<span id="S2.T1.2.1.3" class="ltx_text ltx_font_medium"> and </span>Natural Audio<span id="S2.T1.2.1.4" class="ltx_text ltx_font_medium"> columns signifies that the text/audio was synthesized.</span></span></figcaption>
<table id="S2.T1.32" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.32.31.1" class="ltx_tr">
<th id="S2.T1.32.31.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.32.31.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S2.T1.32.31.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.32.31.1.2.1" class="ltx_text ltx_font_bold">Size</span></th>
<th id="S2.T1.32.31.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.32.31.1.3.1" class="ltx_text ltx_font_bold">Speakers</span></th>
<th id="S2.T1.32.31.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S2.T1.32.31.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.32.31.1.4.1.1" class="ltx_tr">
<td id="S2.T1.32.31.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T1.32.31.1.4.1.1.1.1" class="ltx_text ltx_font_bold">Natural</span></td>
</tr>
<tr id="S2.T1.32.31.1.4.1.2" class="ltx_tr">
<td id="S2.T1.32.31.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T1.32.31.1.4.1.2.1.1" class="ltx_text ltx_font_bold">Text</span></td>
</tr>
</table>
</th>
<th id="S2.T1.32.31.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S2.T1.32.31.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.32.31.1.5.1.1" class="ltx_tr">
<td id="S2.T1.32.31.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T1.32.31.1.5.1.1.1.1" class="ltx_text ltx_font_bold">Natural</span></td>
</tr>
<tr id="S2.T1.32.31.1.5.1.2" class="ltx_tr">
<td id="S2.T1.32.31.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T1.32.31.1.5.1.2.1.1" class="ltx_text ltx_font_bold">Audio</span></td>
</tr>
</table>
</th>
<th id="S2.T1.32.31.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.32.31.1.6.1" class="ltx_text ltx_font_bold">Availability</span></th>
<th id="S2.T1.32.31.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.32.31.1.7.1" class="ltx_text ltx_font_bold">License</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.5.3" class="ltx_tr">
<td id="S2.T1.5.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.5.3.4.1" class="ltx_text ltx_font_bold">Mana TTS</span></td>
<td id="S2.T1.3.1.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="S2.T1.3.1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S2.T1.3.1.1.m1.1a"><mo id="S2.T1.3.1.1.m1.1.1" xref="S2.T1.3.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.3.1.1.m1.1.1.cmml" xref="S2.T1.3.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.1.1.m1.1c">\sim</annotation></semantics></math> <span id="S2.T1.3.1.1.1" class="ltx_text ltx_font_bold">86</span>
</td>
<td id="S2.T1.5.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.5.3.5.1" class="ltx_text ltx_font_bold">1</span></td>
<td id="S2.T1.4.2.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S2.T1.4.2.2.2" class="ltx_ERROR undefined">\textpdfrender</span>
TextRenderingMode=FillStroke,
LineWidth=.6pt, <span id="S2.T1.4.2.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.4.2.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.4.2.2.1.1.1" class="ltx_p"><math id="S2.T1.4.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.4.2.2.1.1.1.m1.1a"><msqrt id="S2.T1.4.2.2.1.1.1.m1.1.1" xref="S2.T1.4.2.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.4.2.2.1.1.1.m1.1.1.2" xref="S2.T1.4.2.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.4.2.2.1.1.1.m1.1b"><apply id="S2.T1.4.2.2.1.1.1.m1.1.1.cmml" xref="S2.T1.4.2.2.1.1.1.m1.1.1"><root id="S2.T1.4.2.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.4.2.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.4.2.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.4.2.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.2.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span>
</td>
<td id="S2.T1.5.3.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S2.T1.5.3.3.2" class="ltx_ERROR undefined">\textpdfrender</span>
TextRenderingMode=FillStroke,
LineWidth=.6pt, <span id="S2.T1.5.3.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.5.3.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.5.3.3.1.1.1" class="ltx_p"><math id="S2.T1.5.3.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.5.3.3.1.1.1.m1.1a"><msqrt id="S2.T1.5.3.3.1.1.1.m1.1.1" xref="S2.T1.5.3.3.1.1.1.m1.1.1.cmml"><mi id="S2.T1.5.3.3.1.1.1.m1.1.1.2" xref="S2.T1.5.3.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.5.3.3.1.1.1.m1.1b"><apply id="S2.T1.5.3.3.1.1.1.m1.1.1.cmml" xref="S2.T1.5.3.3.1.1.1.m1.1.1"><root id="S2.T1.5.3.3.1.1.1.m1.1.1a.cmml" xref="S2.T1.5.3.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.5.3.3.1.1.1.m1.1.1.2.cmml" xref="S2.T1.5.3.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.3.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span>
</td>
<td id="S2.T1.5.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.5.3.6.1" class="ltx_text ltx_font_bold">Avail.</span></td>
<td id="S2.T1.5.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.5.3.7.1" class="ltx_text ltx_font_bold">CC-0 1.0</span></td>
</tr>
<tr id="S2.T1.8.6" class="ltx_tr">
<td id="S2.T1.8.6.4" class="ltx_td ltx_align_center">Arman TTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S2.T1.6.4.1" class="ltx_td ltx_align_center">
<math id="S2.T1.6.4.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S2.T1.6.4.1.m1.1a"><mo id="S2.T1.6.4.1.m1.1.1" xref="S2.T1.6.4.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.4.1.m1.1b"><csymbol cd="latexml" id="S2.T1.6.4.1.m1.1.1.cmml" xref="S2.T1.6.4.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.4.1.m1.1c">\sim</annotation></semantics></math> 9</td>
<td id="S2.T1.8.6.5" class="ltx_td ltx_align_center">1</td>
<td id="S2.T1.7.5.2" class="ltx_td ltx_align_center"><span id="S2.T1.7.5.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.7.5.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.7.5.2.1.1.1" class="ltx_p"><math id="S2.T1.7.5.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.7.5.2.1.1.1.m1.1a"><msqrt id="S2.T1.7.5.2.1.1.1.m1.1.1" xref="S2.T1.7.5.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.7.5.2.1.1.1.m1.1.1.2" xref="S2.T1.7.5.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.7.5.2.1.1.1.m1.1b"><apply id="S2.T1.7.5.2.1.1.1.m1.1.1.cmml" xref="S2.T1.7.5.2.1.1.1.m1.1.1"><root id="S2.T1.7.5.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.7.5.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.7.5.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.7.5.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.5.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.8.6.3" class="ltx_td ltx_align_center"><span id="S2.T1.8.6.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.8.6.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.8.6.3.1.1.1" class="ltx_p"><math id="S2.T1.8.6.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.8.6.3.1.1.1.m1.1a"><msqrt id="S2.T1.8.6.3.1.1.1.m1.1.1" xref="S2.T1.8.6.3.1.1.1.m1.1.1.cmml"><mi id="S2.T1.8.6.3.1.1.1.m1.1.1.2" xref="S2.T1.8.6.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.8.6.3.1.1.1.m1.1b"><apply id="S2.T1.8.6.3.1.1.1.m1.1.1.cmml" xref="S2.T1.8.6.3.1.1.1.m1.1.1"><root id="S2.T1.8.6.3.1.1.1.m1.1.1a.cmml" xref="S2.T1.8.6.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.8.6.3.1.1.1.m1.1.1.2.cmml" xref="S2.T1.8.6.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.6.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.8.6.6" class="ltx_td ltx_align_center">Not Avail.</td>
<td id="S2.T1.8.6.7" class="ltx_td ltx_align_center">Unknown</td>
</tr>
<tr id="S2.T1.10.8" class="ltx_tr">
<td id="S2.T1.10.8.3" class="ltx_td ltx_align_center">AmerAndish <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S2.T1.10.8.4" class="ltx_td ltx_align_center">21</td>
<td id="S2.T1.10.8.5" class="ltx_td ltx_align_center">1</td>
<td id="S2.T1.9.7.1" class="ltx_td ltx_align_center"><span id="S2.T1.9.7.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.9.7.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.9.7.1.1.1.1" class="ltx_p"><math id="S2.T1.9.7.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.9.7.1.1.1.1.m1.1a"><msqrt id="S2.T1.9.7.1.1.1.1.m1.1.1" xref="S2.T1.9.7.1.1.1.1.m1.1.1.cmml"><mi id="S2.T1.9.7.1.1.1.1.m1.1.1.2" xref="S2.T1.9.7.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.9.7.1.1.1.1.m1.1b"><apply id="S2.T1.9.7.1.1.1.1.m1.1.1.cmml" xref="S2.T1.9.7.1.1.1.1.m1.1.1"><root id="S2.T1.9.7.1.1.1.1.m1.1.1a.cmml" xref="S2.T1.9.7.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.9.7.1.1.1.1.m1.1.1.2.cmml" xref="S2.T1.9.7.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.7.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.10.8.2" class="ltx_td ltx_align_center"><span id="S2.T1.10.8.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.10.8.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.10.8.2.1.1.1" class="ltx_p"><math id="S2.T1.10.8.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.10.8.2.1.1.1.m1.1a"><msqrt id="S2.T1.10.8.2.1.1.1.m1.1.1" xref="S2.T1.10.8.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.10.8.2.1.1.1.m1.1.1.2" xref="S2.T1.10.8.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.10.8.2.1.1.1.m1.1b"><apply id="S2.T1.10.8.2.1.1.1.m1.1.1.cmml" xref="S2.T1.10.8.2.1.1.1.m1.1.1"><root id="S2.T1.10.8.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.10.8.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.10.8.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.10.8.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.8.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.10.8.6" class="ltx_td ltx_align_center">Not Avail.</td>
<td id="S2.T1.10.8.7" class="ltx_td ltx_align_center">Unknown</td>
</tr>
<tr id="S2.T1.13.11" class="ltx_tr">
<td id="S2.T1.13.11.4" class="ltx_td ltx_align_center">tts dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S2.T1.11.9.1" class="ltx_td ltx_align_center">
<math id="S2.T1.11.9.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S2.T1.11.9.1.m1.1a"><mo id="S2.T1.11.9.1.m1.1.1" xref="S2.T1.11.9.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.T1.11.9.1.m1.1b"><csymbol cd="latexml" id="S2.T1.11.9.1.m1.1.1.cmml" xref="S2.T1.11.9.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.9.1.m1.1c">\sim</annotation></semantics></math> 16</td>
<td id="S2.T1.13.11.5" class="ltx_td ltx_align_center">1</td>
<td id="S2.T1.12.10.2" class="ltx_td ltx_align_center"><span id="S2.T1.12.10.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.12.10.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.12.10.2.1.1.1" class="ltx_p"><math id="S2.T1.12.10.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.12.10.2.1.1.1.m1.1a"><msqrt id="S2.T1.12.10.2.1.1.1.m1.1.1" xref="S2.T1.12.10.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.12.10.2.1.1.1.m1.1.1.2" xref="S2.T1.12.10.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.12.10.2.1.1.1.m1.1b"><apply id="S2.T1.12.10.2.1.1.1.m1.1.1.cmml" xref="S2.T1.12.10.2.1.1.1.m1.1.1"><root id="S2.T1.12.10.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.12.10.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.12.10.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.12.10.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.10.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.13.11.3" class="ltx_td ltx_align_center"><span id="S2.T1.13.11.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.13.11.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.13.11.3.1.1.1" class="ltx_p"><math id="S2.T1.13.11.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.13.11.3.1.1.1.m1.1a"><msqrt id="S2.T1.13.11.3.1.1.1.m1.1.1" xref="S2.T1.13.11.3.1.1.1.m1.1.1.cmml"><mi id="S2.T1.13.11.3.1.1.1.m1.1.1.2" xref="S2.T1.13.11.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.13.11.3.1.1.1.m1.1b"><apply id="S2.T1.13.11.3.1.1.1.m1.1.1.cmml" xref="S2.T1.13.11.3.1.1.1.m1.1.1"><root id="S2.T1.13.11.3.1.1.1.m1.1.1a.cmml" xref="S2.T1.13.11.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.13.11.3.1.1.1.m1.1.1.2.cmml" xref="S2.T1.13.11.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.11.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.13.11.6" class="ltx_td ltx_align_center">Avail.</td>
<td id="S2.T1.13.11.7" class="ltx_td ltx_align_center">Unknown</td>
</tr>
<tr id="S2.T1.16.14" class="ltx_tr">
<td id="S2.T1.16.14.4" class="ltx_td ltx_align_center">TTS audio <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>
</td>
<td id="S2.T1.14.12.1" class="ltx_td ltx_align_center">
<math id="S2.T1.14.12.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S2.T1.14.12.1.m1.1a"><mo id="S2.T1.14.12.1.m1.1.1" xref="S2.T1.14.12.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.T1.14.12.1.m1.1b"><csymbol cd="latexml" id="S2.T1.14.12.1.m1.1.1.cmml" xref="S2.T1.14.12.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.12.1.m1.1c">\sim</annotation></semantics></math>26</td>
<td id="S2.T1.16.14.5" class="ltx_td ltx_align_center">1</td>
<td id="S2.T1.15.13.2" class="ltx_td ltx_align_center"><span id="S2.T1.15.13.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.15.13.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.15.13.2.1.1.1" class="ltx_p"><math id="S2.T1.15.13.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.15.13.2.1.1.1.m1.1a"><msqrt id="S2.T1.15.13.2.1.1.1.m1.1.1" xref="S2.T1.15.13.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.15.13.2.1.1.1.m1.1.1.2" xref="S2.T1.15.13.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.15.13.2.1.1.1.m1.1b"><apply id="S2.T1.15.13.2.1.1.1.m1.1.1.cmml" xref="S2.T1.15.13.2.1.1.1.m1.1.1"><root id="S2.T1.15.13.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.15.13.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.15.13.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.15.13.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.13.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.16.14.3" class="ltx_td ltx_align_center"><span id="S2.T1.16.14.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.16.14.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.16.14.3.1.1.1" class="ltx_p"><math id="S2.T1.16.14.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.16.14.3.1.1.1.m1.1a"><msqrt id="S2.T1.16.14.3.1.1.1.m1.1.1" xref="S2.T1.16.14.3.1.1.1.m1.1.1.cmml"><mi id="S2.T1.16.14.3.1.1.1.m1.1.1.2" xref="S2.T1.16.14.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.16.14.3.1.1.1.m1.1b"><apply id="S2.T1.16.14.3.1.1.1.m1.1.1.cmml" xref="S2.T1.16.14.3.1.1.1.m1.1.1"><root id="S2.T1.16.14.3.1.1.1.m1.1.1a.cmml" xref="S2.T1.16.14.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.16.14.3.1.1.1.m1.1.1.2.cmml" xref="S2.T1.16.14.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.14.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.16.14.6" class="ltx_td ltx_align_center">Avail.</td>
<td id="S2.T1.16.14.7" class="ltx_td ltx_align_center">Proprietary</td>
</tr>
<tr id="S2.T1.18.16" class="ltx_tr">
<td id="S2.T1.18.16.3" class="ltx_td ltx_align_center">Persian TTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</td>
<td id="S2.T1.18.16.4" class="ltx_td ltx_align_center">+30</td>
<td id="S2.T1.18.16.5" class="ltx_td ltx_align_center">1</td>
<td id="S2.T1.17.15.1" class="ltx_td ltx_align_center"><span id="S2.T1.17.15.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.17.15.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.17.15.1.1.1.1" class="ltx_p"><math id="S2.T1.17.15.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.17.15.1.1.1.1.m1.1a"><msqrt id="S2.T1.17.15.1.1.1.1.m1.1.1" xref="S2.T1.17.15.1.1.1.1.m1.1.1.cmml"><mi id="S2.T1.17.15.1.1.1.1.m1.1.1.2" xref="S2.T1.17.15.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.17.15.1.1.1.1.m1.1b"><apply id="S2.T1.17.15.1.1.1.1.m1.1.1.cmml" xref="S2.T1.17.15.1.1.1.1.m1.1.1"><root id="S2.T1.17.15.1.1.1.1.m1.1.1a.cmml" xref="S2.T1.17.15.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.17.15.1.1.1.1.m1.1.1.2.cmml" xref="S2.T1.17.15.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.17.15.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.18.16.2" class="ltx_td ltx_align_center"><span id="S2.T1.18.16.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.18.16.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.18.16.2.1.1.1" class="ltx_p"><math id="S2.T1.18.16.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.18.16.2.1.1.1.m1.1a"><msqrt id="S2.T1.18.16.2.1.1.1.m1.1.1" xref="S2.T1.18.16.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.18.16.2.1.1.1.m1.1.1.2" xref="S2.T1.18.16.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.18.16.2.1.1.1.m1.1b"><apply id="S2.T1.18.16.2.1.1.1.m1.1.1.cmml" xref="S2.T1.18.16.2.1.1.1.m1.1.1"><root id="S2.T1.18.16.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.18.16.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.18.16.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.18.16.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.18.16.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.18.16.6" class="ltx_td ltx_align_center">Not Avail.</td>
<td id="S2.T1.18.16.7" class="ltx_td ltx_align_center">Unknown</td>
</tr>
<tr id="S2.T1.21.19" class="ltx_tr">
<td id="S2.T1.21.19.4" class="ltx_td ltx_align_center">tts-famale <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>
</td>
<td id="S2.T1.19.17.1" class="ltx_td ltx_align_center">
<math id="S2.T1.19.17.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S2.T1.19.17.1.m1.1a"><mo id="S2.T1.19.17.1.m1.1.1" xref="S2.T1.19.17.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.T1.19.17.1.m1.1b"><csymbol cd="latexml" id="S2.T1.19.17.1.m1.1.1.cmml" xref="S2.T1.19.17.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.19.17.1.m1.1c">\sim</annotation></semantics></math> 30</td>
<td id="S2.T1.21.19.5" class="ltx_td ltx_align_center">1</td>
<td id="S2.T1.20.18.2" class="ltx_td ltx_align_center"><span id="S2.T1.20.18.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.20.18.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.20.18.2.1.1.1" class="ltx_p"><math id="S2.T1.20.18.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.20.18.2.1.1.1.m1.1a"><msqrt id="S2.T1.20.18.2.1.1.1.m1.1.1" xref="S2.T1.20.18.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.20.18.2.1.1.1.m1.1.1.2" xref="S2.T1.20.18.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.20.18.2.1.1.1.m1.1b"><apply id="S2.T1.20.18.2.1.1.1.m1.1.1.cmml" xref="S2.T1.20.18.2.1.1.1.m1.1.1"><root id="S2.T1.20.18.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.20.18.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.20.18.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.20.18.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.20.18.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.21.19.3" class="ltx_td ltx_align_center">
<div id="S2.T1.21.19.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.6pt;height:6.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.6pt,0.0pt) scale(0.85,1.0) ;">
<p id="S2.T1.21.19.3.1.1" class="ltx_p"><math id="S2.T1.21.19.3.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.21.19.3.1.1.m1.1a"><mo id="S2.T1.21.19.3.1.1.m1.1.1" xref="S2.T1.21.19.3.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.21.19.3.1.1.m1.1b"><times id="S2.T1.21.19.3.1.1.m1.1.1.cmml" xref="S2.T1.21.19.3.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.21.19.3.1.1.m1.1c">\times</annotation></semantics></math></p>
</span></div>
</td>
<td id="S2.T1.21.19.6" class="ltx_td ltx_align_center">Avail.</td>
<td id="S2.T1.21.19.7" class="ltx_td ltx_align_center">CC-0 1.0</td>
</tr>
<tr id="S2.T1.24.22" class="ltx_tr">
<td id="S2.T1.24.22.4" class="ltx_td ltx_align_center">tts-male <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S2.T1.22.20.1" class="ltx_td ltx_align_center">
<math id="S2.T1.22.20.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S2.T1.22.20.1.m1.1a"><mo id="S2.T1.22.20.1.m1.1.1" xref="S2.T1.22.20.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.T1.22.20.1.m1.1b"><csymbol cd="latexml" id="S2.T1.22.20.1.m1.1.1.cmml" xref="S2.T1.22.20.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.22.20.1.m1.1c">\sim</annotation></semantics></math> 38</td>
<td id="S2.T1.24.22.5" class="ltx_td ltx_align_center">1</td>
<td id="S2.T1.23.21.2" class="ltx_td ltx_align_center"><span id="S2.T1.23.21.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.23.21.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.23.21.2.1.1.1" class="ltx_p"><math id="S2.T1.23.21.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.23.21.2.1.1.1.m1.1a"><msqrt id="S2.T1.23.21.2.1.1.1.m1.1.1" xref="S2.T1.23.21.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.23.21.2.1.1.1.m1.1.1.2" xref="S2.T1.23.21.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.23.21.2.1.1.1.m1.1b"><apply id="S2.T1.23.21.2.1.1.1.m1.1.1.cmml" xref="S2.T1.23.21.2.1.1.1.m1.1.1"><root id="S2.T1.23.21.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.23.21.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.23.21.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.23.21.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.23.21.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.24.22.3" class="ltx_td ltx_align_center">
<div id="S2.T1.24.22.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.6pt;height:6.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.6pt,0.0pt) scale(0.85,1.0) ;">
<p id="S2.T1.24.22.3.1.1" class="ltx_p"><math id="S2.T1.24.22.3.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.24.22.3.1.1.m1.1a"><mo id="S2.T1.24.22.3.1.1.m1.1.1" xref="S2.T1.24.22.3.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.24.22.3.1.1.m1.1b"><times id="S2.T1.24.22.3.1.1.m1.1.1.cmml" xref="S2.T1.24.22.3.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.24.22.3.1.1.m1.1c">\times</annotation></semantics></math></p>
</span></div>
</td>
<td id="S2.T1.24.22.6" class="ltx_td ltx_align_center">Avail.</td>
<td id="S2.T1.24.22.7" class="ltx_td ltx_align_center">CC-0 1.0</td>
</tr>
<tr id="S2.T1.27.25" class="ltx_tr">
<td id="S2.T1.27.25.4" class="ltx_td ltx_align_center">Persian Speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</td>
<td id="S2.T1.25.23.1" class="ltx_td ltx_align_center">
<math id="S2.T1.25.23.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S2.T1.25.23.1.m1.1a"><mo id="S2.T1.25.23.1.m1.1.1" xref="S2.T1.25.23.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.T1.25.23.1.m1.1b"><csymbol cd="latexml" id="S2.T1.25.23.1.m1.1.1.cmml" xref="S2.T1.25.23.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.25.23.1.m1.1c">\sim</annotation></semantics></math> 2.5</td>
<td id="S2.T1.27.25.5" class="ltx_td ltx_align_center">1</td>
<td id="S2.T1.26.24.2" class="ltx_td ltx_align_center"><span id="S2.T1.26.24.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.26.24.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.26.24.2.1.1.1" class="ltx_p"><math id="S2.T1.26.24.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.26.24.2.1.1.1.m1.1a"><msqrt id="S2.T1.26.24.2.1.1.1.m1.1.1" xref="S2.T1.26.24.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.26.24.2.1.1.1.m1.1.1.2" xref="S2.T1.26.24.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.26.24.2.1.1.1.m1.1b"><apply id="S2.T1.26.24.2.1.1.1.m1.1.1.cmml" xref="S2.T1.26.24.2.1.1.1.m1.1.1"><root id="S2.T1.26.24.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.26.24.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.26.24.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.26.24.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.26.24.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.27.25.3" class="ltx_td ltx_align_center"><span id="S2.T1.27.25.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.27.25.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.27.25.3.1.1.1" class="ltx_p"><math id="S2.T1.27.25.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.27.25.3.1.1.1.m1.1a"><msqrt id="S2.T1.27.25.3.1.1.1.m1.1.1" xref="S2.T1.27.25.3.1.1.1.m1.1.1.cmml"><mi id="S2.T1.27.25.3.1.1.1.m1.1.1.2" xref="S2.T1.27.25.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.27.25.3.1.1.1.m1.1b"><apply id="S2.T1.27.25.3.1.1.1.m1.1.1.cmml" xref="S2.T1.27.25.3.1.1.1.m1.1.1"><root id="S2.T1.27.25.3.1.1.1.m1.1.1a.cmml" xref="S2.T1.27.25.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.27.25.3.1.1.1.m1.1.1.2.cmml" xref="S2.T1.27.25.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.27.25.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.27.25.6" class="ltx_td ltx_align_center">Avail.</td>
<td id="S2.T1.27.25.7" class="ltx_td ltx_align_center">CC BY-NC-SA 4.0</td>
</tr>
<tr id="S2.T1.30.28" class="ltx_tr">
<td id="S2.T1.30.28.4" class="ltx_td ltx_align_center">ParsiGoo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</td>
<td id="S2.T1.28.26.1" class="ltx_td ltx_align_center">
<math id="S2.T1.28.26.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S2.T1.28.26.1.m1.1a"><mo id="S2.T1.28.26.1.m1.1.1" xref="S2.T1.28.26.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S2.T1.28.26.1.m1.1b"><csymbol cd="latexml" id="S2.T1.28.26.1.m1.1.1.cmml" xref="S2.T1.28.26.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.28.26.1.m1.1c">\sim</annotation></semantics></math> 5</td>
<td id="S2.T1.30.28.5" class="ltx_td ltx_align_center">6</td>
<td id="S2.T1.29.27.2" class="ltx_td ltx_align_center"><span id="S2.T1.29.27.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.29.27.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.29.27.2.1.1.1" class="ltx_p"><math id="S2.T1.29.27.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.29.27.2.1.1.1.m1.1a"><msqrt id="S2.T1.29.27.2.1.1.1.m1.1.1" xref="S2.T1.29.27.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.29.27.2.1.1.1.m1.1.1.2" xref="S2.T1.29.27.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.29.27.2.1.1.1.m1.1b"><apply id="S2.T1.29.27.2.1.1.1.m1.1.1.cmml" xref="S2.T1.29.27.2.1.1.1.m1.1.1"><root id="S2.T1.29.27.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.29.27.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.29.27.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.29.27.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.29.27.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.30.28.3" class="ltx_td ltx_align_center">
<div id="S2.T1.30.28.3.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.6pt;height:6.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.6pt,0.0pt) scale(0.85,1.0) ;">
<p id="S2.T1.30.28.3.1.1" class="ltx_p"><math id="S2.T1.30.28.3.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.30.28.3.1.1.m1.1a"><mo id="S2.T1.30.28.3.1.1.m1.1.1" xref="S2.T1.30.28.3.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.30.28.3.1.1.m1.1b"><times id="S2.T1.30.28.3.1.1.m1.1.1.cmml" xref="S2.T1.30.28.3.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.30.28.3.1.1.m1.1c">\times</annotation></semantics></math></p>
</span></div>
</td>
<td id="S2.T1.30.28.6" class="ltx_td ltx_align_center">Avail.</td>
<td id="S2.T1.30.28.7" class="ltx_td ltx_align_center">CC BY-SA 4.0</td>
</tr>
<tr id="S2.T1.32.30" class="ltx_tr">
<td id="S2.T1.32.30.3" class="ltx_td ltx_align_center ltx_border_bb">
<table id="S2.T1.32.30.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.32.30.3.1.1" class="ltx_tr">
<td id="S2.T1.32.30.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">DeepMine</td>
</tr>
<tr id="S2.T1.32.30.3.1.2" class="ltx_tr">
<td id="S2.T1.32.30.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Multi-TTS</td>
</tr>
</table> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>
</td>
<td id="S2.T1.32.30.4" class="ltx_td ltx_align_center ltx_border_bb">120</td>
<td id="S2.T1.32.30.5" class="ltx_td ltx_align_center ltx_border_bb">67</td>
<td id="S2.T1.31.29.1" class="ltx_td ltx_align_center ltx_border_bb">
<div id="S2.T1.31.29.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.6pt;height:6.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.6pt,0.0pt) scale(0.85,1.0) ;">
<p id="S2.T1.31.29.1.1.1" class="ltx_p"><math id="S2.T1.31.29.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.31.29.1.1.1.m1.1a"><mo id="S2.T1.31.29.1.1.1.m1.1.1" xref="S2.T1.31.29.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.31.29.1.1.1.m1.1b"><times id="S2.T1.31.29.1.1.1.m1.1.1.cmml" xref="S2.T1.31.29.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.31.29.1.1.1.m1.1c">\times</annotation></semantics></math></p>
</span></div>
</td>
<td id="S2.T1.32.30.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.32.30.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="S2.T1.32.30.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="S2.T1.32.30.2.1.1.1" class="ltx_p"><math id="S2.T1.32.30.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="S2.T1.32.30.2.1.1.1.m1.1a"><msqrt id="S2.T1.32.30.2.1.1.1.m1.1.1" xref="S2.T1.32.30.2.1.1.1.m1.1.1.cmml"><mi id="S2.T1.32.30.2.1.1.1.m1.1.1.2" xref="S2.T1.32.30.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="S2.T1.32.30.2.1.1.1.m1.1b"><apply id="S2.T1.32.30.2.1.1.1.m1.1.1.cmml" xref="S2.T1.32.30.2.1.1.1.m1.1.1"><root id="S2.T1.32.30.2.1.1.1.m1.1.1a.cmml" xref="S2.T1.32.30.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="S2.T1.32.30.2.1.1.1.m1.1.1.2.cmml" xref="S2.T1.32.30.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.32.30.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="S2.T1.32.30.6" class="ltx_td ltx_align_center ltx_border_bb">Avail. on req.</td>
<td id="S2.T1.32.30.7" class="ltx_td ltx_align_center ltx_border_bb">Unknown</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset Preparation</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">As mentioned earlier, the raw material of our dataset is crawled<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The crawling script and the entire processing source code is available at https://github.com/MahtaFetrat/ManaTTS-Persian-Speech-Dataset</span></span></span> from the website of the Nasl-e-Mana magazine <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and is published under the CC-0 1.0 license with the consent of its owners.
A female speaker recorded the majority of the audio files, and we manually removed any files not associated with her to ensure the dataset remained single-speaker.
This data was then processed through a pipeline to obtain pairs of speech and transcripts as output. An overview of the entire pipeline is provided in Figure <a href="#S3.F1.sf1" title="In Figure 1 ‣ 3.1 Preprocessing ‣ 3 Dataset Preparation ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The hardware utilized for the entire processing pipeline and model training consisted of a 12th Gen Intel Core i9-12900K CPU with 24 cores and an NVIDIA GeForce RTX 4090 GPU with 24,564 MiB of memory, supporting CUDA version 12.2.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Preprocessing</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Prior to processing speech-text pairs, we preprocess audio and text files separately. The audio files, initially in MP3 format, are converted to WAV files. WAV format offers lossless compression, preserving audio quality throughout processing. Additionally, the audio undergoes processing with a source separation tool, namely Spleeter <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, to eliminate any potential background music and retain only the vocals.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">There is a distinct pipeline for processing the text files, as summarized in Figure <a href="#S3.F1.sf2" title="In Figure 1 ‣ 3.1 Preprocessing ‣ 3 Dataset Preparation ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>. The text data undergoes normalization using Hazm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> normalizer. This step is crucial as it standardizes the words, ensuring consistency. This simplification reduces the unnecessary details that the TTS model must handle.</p>
</div>
<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.07259/assets/figs/data-processing-pipeline.png" id="S3.F1.sf1.g1" class="ltx_graphics ltx_img_square" width="598" height="484" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Processing pipeline for audio and text files.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.07259/assets/figs/text-processing-pipeline.png" id="S3.F1.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="460" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Processing pipeline for text files.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Dataset processing pipelines.</span></figcaption>
</figure>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">The subsequent three steps aim to remove links and references that are typically not meant to be read aloud. These encompass all inline references in the form [NUM], end-of-text references such as author names and book details, and end-of-text links, including entire lines containing URLs.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">In the next phase, we addressed the issue of numbers being written differently from how they’re spoken. To handle this, we used the parsi-io <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> tool to detect numbers in the text and convert them into spoken equivalents. Afterward, we trimmed non-essential symbols to streamline the text and decrease the input given to the model. Lastly, we eliminated any extra whitespace, including empty lines, to ready the text for alignment with audio components in later phases, as explained in more detail below.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Alignment</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Alignment involves matching audio to its transcript. We have divided this task into two phases. Firstly, we ensure that each audio file contains the same initial and final content as the corresponding text file, which we refer to as start-end alignment. Secondly, we segment the large audio and text files into smaller pieces, typically a few seconds and a few words, in a process known as forced alignment.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Manually performing alignment, especially on large datasets, is an arduous task. Therefore, we opted to automate this process. Our general approach for both alignment phases is rooted in automatic speech recognition (ASR) models. We developed a module that generates reliable hypothesis transcripts for each audio chunk. Subsequently, we attempt to match the hypothesis with the corresponding segment in the ground truth text.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Transcription Module</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">The transcription task can be as straightforward as utilizing a single reliable ASR model to obtain the transcript of a given audio chunk. However, this wasn’t our scenario because there is no openly accessible Persian ASR model that is sufficiently reliable to handle this task alone. One common issue with ASR models, for instance, was occasional generation of truncated transcripts for some input cases. Consequently, we chose to integrate multiple ASR models into a transcription module and implement a form of majority voting among them. This approach allows errors from one or two models to be concealed, significantly reducing the likelihood of such defects appearing in the output transcripts.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">We utilized five of the top open-access Persian ASR models.
We deliberately selected the ASR models and all tools in our pipeline from the open-source domain, enabling us to publish our work entirely under non-restrictive licenses. A list of the tools used, including the ASR models, can be found in Table <a href="#A6.T11" title="Table 11 ‣ Appendix F Supplementary Tables ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">Some ASR models were accompanied by a reported Word Error Rate (WER). However, they were assessed on different test sets, making them incomparable. To rank and compare the ASR models based on their error rates, we gathered and processed the CC-0 licensed VirgoolInformal dataset, evaluating the models accordingly.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>This dataset is available at https://huggingface.co/datasets/MahtaFetrat/GPTInformal-Persian</span></span></span> Further details regarding this dataset, including its collection method and evaluation results, are provided in the Appendix <a href="#A2" title="Appendix B Evaluation of ASR Models ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p id="S3.SS2.SSS1.p4.1" class="ltx_p">The input to the transcription module is a small audio chunk, typically less than 20 seconds in duration. The output comprises a list of eligible transcripts sorted by the reliability of their corresponding ASR models. Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2.1 Transcription Module ‣ 3.2 Alignment ‣ 3 Dataset Preparation ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> depicts an overview of this module.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2409.07259/assets/figs/transcription-module.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="109" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Transcription Module</span></figcaption>
</figure>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<p id="S3.SS2.SSS1.p5.1" class="ltx_p">The transcripts are generated as follows: initially, a given audio chunk is input into all ASR models. Subsequently, any transcripts shorter than 80% of the longest is discarded. This step helps address the issue of incomplete transcripts, which was mentioned before. The remaining transcripts that meet the length criteria are then sorted based on the performance of their respective ASR models and returned in a list. Some insightful statistics of this module can be found in Appendix <a href="#A3" title="Appendix C Transcript Module Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Start/End Alignment</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">In the raw dataset, each audio file is paired with a corresponding text file. However, certain factors can cause inconsistencies between the starting/ending points of the audio and its associated text, necessitating start-end alignment processes that may involve removing a few seconds or words from each. The primary factors include:</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">The title and author name read by the speaker, even though not included in the text.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Additional resources at the end of the text that are typically unread.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p">The general workflow of the start-end alignment is as follows: the audio is initially segmented based on silent moments, then a search iterates over these segments as potential starting (or ending) points for the audio. For each segment, the most reliable hypothesis transcript is obtained from the transcription module, and the text is searched to find the best matching interval. The pair of trimmed audio and text with the lowest Character Error Rate (CER) between the hypothesis transcript and reference text is selected to determine the start and end of the files.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Forced Alignment</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">The start-end alignment phase generates pairs of audio and text files that are perfectly matched at the beginning and end. However, this format isn’t suitable for feeding into a TTS model. The audio and text files must be divided into smaller chunks, typically a few to 15 seconds each. This process is commonly known as forced alignment.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p id="S3.SS2.SSS3.p2.1" class="ltx_p">In our search for a forced alignment tool for Persian, we considered Aeneas <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, which is known for its large community and high performance. However, as noted in their project limitations, "Audio should match the text: large portions of spurious text or audio might produce a wrong sync map." This limitation made Aeneas unsuitable for our needs, as the audio and text could have mismatches due to factors such as:</p>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para">
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">The speaker was provided with a slightly different version of the text to read.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">The speaker might censor some parts of the text.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p">The speaker might make a mistake and repeat herself to correct it.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS3.p4" class="ltx_para">
<p id="S3.SS2.SSS3.p4.1" class="ltx_p">As a result, we decided to develop our method for forced alignment. The primary workflow of our forced alignment algorithm is illustrated in Figure <a href="#A5.F11" title="Figure 11 ‣ Appendix E Supplementary Figures ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> in Appendix <a href="#A5" title="Appendix E Supplementary Figures ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<div id="S3.SS2.SSS3.p5" class="ltx_para">
<p id="S3.SS2.SSS3.p5.1" class="ltx_p">Initially, the audio is divided into smaller parts using silent intervals. We ensure these audio parts are between 2 and 12 seconds by combining smaller segments or changing the silence detection setting to create smaller parts. The last step is to find a matching section from the reference text. We use the hypothesis transcripts provided by the transcription module until we find a subsection of the text that meets the desired similarity criteria.</p>
</div>
<div id="S3.SS2.SSS3.p6" class="ltx_para">
<p id="S3.SS2.SSS3.p6.2" class="ltx_p">The algorithm employs two search methods to find matching text: Interval Search and Gapped Search. Interval Search seeks all sub-strings of the text in the form of <math id="S3.SS2.SSS3.p6.1.m1.1" class="ltx_math_unparsed" alttext="text[s:i]" display="inline"><semantics id="S3.SS2.SSS3.p6.1.m1.1a"><mrow id="S3.SS2.SSS3.p6.1.m1.1b"><mi id="S3.SS2.SSS3.p6.1.m1.1.1">t</mi><mi id="S3.SS2.SSS3.p6.1.m1.1.2">e</mi><mi id="S3.SS2.SSS3.p6.1.m1.1.3">x</mi><mi id="S3.SS2.SSS3.p6.1.m1.1.4">t</mi><mrow id="S3.SS2.SSS3.p6.1.m1.1.5"><mo stretchy="false" id="S3.SS2.SSS3.p6.1.m1.1.5.1">[</mo><mi id="S3.SS2.SSS3.p6.1.m1.1.5.2">s</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS2.SSS3.p6.1.m1.1.5.3">:</mo><mi id="S3.SS2.SSS3.p6.1.m1.1.5.4">i</mi><mo stretchy="false" id="S3.SS2.SSS3.p6.1.m1.1.5.5">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p6.1.m1.1c">text[s:i]</annotation></semantics></math> within a defined range. As the name suggests, the Gapped Search would let a missing gap in the text and look for sub-strings of the form <math id="S3.SS2.SSS3.p6.2.m2.1" class="ltx_math_unparsed" alttext="text[s:j]+text[k:i]" display="inline"><semantics id="S3.SS2.SSS3.p6.2.m2.1a"><mrow id="S3.SS2.SSS3.p6.2.m2.1b"><mi id="S3.SS2.SSS3.p6.2.m2.1.1">t</mi><mi id="S3.SS2.SSS3.p6.2.m2.1.2">e</mi><mi id="S3.SS2.SSS3.p6.2.m2.1.3">x</mi><mi id="S3.SS2.SSS3.p6.2.m2.1.4">t</mi><mrow id="S3.SS2.SSS3.p6.2.m2.1.5"><mo stretchy="false" id="S3.SS2.SSS3.p6.2.m2.1.5.1">[</mo><mi id="S3.SS2.SSS3.p6.2.m2.1.5.2">s</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS2.SSS3.p6.2.m2.1.5.3">:</mo><mi id="S3.SS2.SSS3.p6.2.m2.1.5.4">j</mi><mo stretchy="false" id="S3.SS2.SSS3.p6.2.m2.1.5.5">]</mo></mrow><mo id="S3.SS2.SSS3.p6.2.m2.1.6">+</mo><mi id="S3.SS2.SSS3.p6.2.m2.1.7">t</mi><mi id="S3.SS2.SSS3.p6.2.m2.1.8">e</mi><mi id="S3.SS2.SSS3.p6.2.m2.1.9">x</mi><mi id="S3.SS2.SSS3.p6.2.m2.1.10">t</mi><mrow id="S3.SS2.SSS3.p6.2.m2.1.11"><mo stretchy="false" id="S3.SS2.SSS3.p6.2.m2.1.11.1">[</mo><mi id="S3.SS2.SSS3.p6.2.m2.1.11.2">k</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS2.SSS3.p6.2.m2.1.11.3">:</mo><mi id="S3.SS2.SSS3.p6.2.m2.1.11.4">i</mi><mo stretchy="false" id="S3.SS2.SSS3.p6.2.m2.1.11.5">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p6.2.m2.1c">text[s:j]+text[k:i]</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS3.p7" class="ltx_para">
<p id="S3.SS2.SSS3.p7.3" class="ltx_p">The search process halts immediately upon finding a match with <math id="S3.SS2.SSS3.p7.1.m1.1" class="ltx_Math" alttext="CER\leq 0.05" display="inline"><semantics id="S3.SS2.SSS3.p7.1.m1.1a"><mrow id="S3.SS2.SSS3.p7.1.m1.1.1" xref="S3.SS2.SSS3.p7.1.m1.1.1.cmml"><mrow id="S3.SS2.SSS3.p7.1.m1.1.1.2" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS3.p7.1.m1.1.1.2.2" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p7.1.m1.1.1.2.1" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.1.cmml">​</mo><mi id="S3.SS2.SSS3.p7.1.m1.1.1.2.3" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p7.1.m1.1.1.2.1a" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.1.cmml">​</mo><mi id="S3.SS2.SSS3.p7.1.m1.1.1.2.4" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.4.cmml">R</mi></mrow><mo id="S3.SS2.SSS3.p7.1.m1.1.1.1" xref="S3.SS2.SSS3.p7.1.m1.1.1.1.cmml">≤</mo><mn id="S3.SS2.SSS3.p7.1.m1.1.1.3" xref="S3.SS2.SSS3.p7.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.1.m1.1b"><apply id="S3.SS2.SSS3.p7.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1"><leq id="S3.SS2.SSS3.p7.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.1"></leq><apply id="S3.SS2.SSS3.p7.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.2"><times id="S3.SS2.SSS3.p7.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.1"></times><ci id="S3.SS2.SSS3.p7.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.2">𝐶</ci><ci id="S3.SS2.SSS3.p7.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.3">𝐸</ci><ci id="S3.SS2.SSS3.p7.1.m1.1.1.2.4.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.2.4">𝑅</ci></apply><cn type="float" id="S3.SS2.SSS3.p7.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p7.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.1.m1.1c">CER\leq 0.05</annotation></semantics></math>. Moreover, due to the lower computational cost of Interval Search, matches with <math id="S3.SS2.SSS3.p7.2.m2.1" class="ltx_Math" alttext="0.05&lt;CER\leq 0.2" display="inline"><semantics id="S3.SS2.SSS3.p7.2.m2.1a"><mrow id="S3.SS2.SSS3.p7.2.m2.1.1" xref="S3.SS2.SSS3.p7.2.m2.1.1.cmml"><mn id="S3.SS2.SSS3.p7.2.m2.1.1.2" xref="S3.SS2.SSS3.p7.2.m2.1.1.2.cmml">0.05</mn><mo id="S3.SS2.SSS3.p7.2.m2.1.1.3" xref="S3.SS2.SSS3.p7.2.m2.1.1.3.cmml">&lt;</mo><mrow id="S3.SS2.SSS3.p7.2.m2.1.1.4" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.cmml"><mi id="S3.SS2.SSS3.p7.2.m2.1.1.4.2" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p7.2.m2.1.1.4.1" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.1.cmml">​</mo><mi id="S3.SS2.SSS3.p7.2.m2.1.1.4.3" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p7.2.m2.1.1.4.1a" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.1.cmml">​</mo><mi id="S3.SS2.SSS3.p7.2.m2.1.1.4.4" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.4.cmml">R</mi></mrow><mo id="S3.SS2.SSS3.p7.2.m2.1.1.5" xref="S3.SS2.SSS3.p7.2.m2.1.1.5.cmml">≤</mo><mn id="S3.SS2.SSS3.p7.2.m2.1.1.6" xref="S3.SS2.SSS3.p7.2.m2.1.1.6.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.2.m2.1b"><apply id="S3.SS2.SSS3.p7.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1"><and id="S3.SS2.SSS3.p7.2.m2.1.1a.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1"></and><apply id="S3.SS2.SSS3.p7.2.m2.1.1b.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1"><lt id="S3.SS2.SSS3.p7.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.3"></lt><cn type="float" id="S3.SS2.SSS3.p7.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.2">0.05</cn><apply id="S3.SS2.SSS3.p7.2.m2.1.1.4.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.4"><times id="S3.SS2.SSS3.p7.2.m2.1.1.4.1.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.1"></times><ci id="S3.SS2.SSS3.p7.2.m2.1.1.4.2.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.2">𝐶</ci><ci id="S3.SS2.SSS3.p7.2.m2.1.1.4.3.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.3">𝐸</ci><ci id="S3.SS2.SSS3.p7.2.m2.1.1.4.4.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.4.4">𝑅</ci></apply></apply><apply id="S3.SS2.SSS3.p7.2.m2.1.1c.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1"><leq id="S3.SS2.SSS3.p7.2.m2.1.1.5.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.5"></leq><share href="#S3.SS2.SSS3.p7.2.m2.1.1.4.cmml" id="S3.SS2.SSS3.p7.2.m2.1.1d.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1"></share><cn type="float" id="S3.SS2.SSS3.p7.2.m2.1.1.6.cmml" xref="S3.SS2.SSS3.p7.2.m2.1.1.6">0.2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.2.m2.1c">0.05&lt;CER\leq 0.2</annotation></semantics></math> at the end of this search are also accepted, avoiding the initiation of the Gapped Search. Suppose neither of the search methods can find a matching substring with <math id="S3.SS2.SSS3.p7.3.m3.1" class="ltx_Math" alttext="CER\leq 0.2" display="inline"><semantics id="S3.SS2.SSS3.p7.3.m3.1a"><mrow id="S3.SS2.SSS3.p7.3.m3.1.1" xref="S3.SS2.SSS3.p7.3.m3.1.1.cmml"><mrow id="S3.SS2.SSS3.p7.3.m3.1.1.2" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.cmml"><mi id="S3.SS2.SSS3.p7.3.m3.1.1.2.2" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p7.3.m3.1.1.2.1" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.1.cmml">​</mo><mi id="S3.SS2.SSS3.p7.3.m3.1.1.2.3" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p7.3.m3.1.1.2.1a" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.1.cmml">​</mo><mi id="S3.SS2.SSS3.p7.3.m3.1.1.2.4" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.4.cmml">R</mi></mrow><mo id="S3.SS2.SSS3.p7.3.m3.1.1.1" xref="S3.SS2.SSS3.p7.3.m3.1.1.1.cmml">≤</mo><mn id="S3.SS2.SSS3.p7.3.m3.1.1.3" xref="S3.SS2.SSS3.p7.3.m3.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p7.3.m3.1b"><apply id="S3.SS2.SSS3.p7.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1"><leq id="S3.SS2.SSS3.p7.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.1"></leq><apply id="S3.SS2.SSS3.p7.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.2"><times id="S3.SS2.SSS3.p7.3.m3.1.1.2.1.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.1"></times><ci id="S3.SS2.SSS3.p7.3.m3.1.1.2.2.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.2">𝐶</ci><ci id="S3.SS2.SSS3.p7.3.m3.1.1.2.3.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.3">𝐸</ci><ci id="S3.SS2.SSS3.p7.3.m3.1.1.2.4.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.2.4">𝑅</ci></apply><cn type="float" id="S3.SS2.SSS3.p7.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p7.3.m3.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p7.3.m3.1c">CER\leq 0.2</annotation></semantics></math>. In that case, the process iteratively tests the next hypothesis transcripts until all options are exhausted, resulting in the complete rejection of the chunk.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Post-Processing</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In this phase, the audio chunks undergo processing to eliminate any silent segments lasting more than 1 second. It’s worth noting that silence removal occurs after forced alignment because silent moments are utilized in segmenting the audio into smaller chunks and should not be removed beforehand. For this task, we utilize the Pydub <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> silence module, which is also used for segmenting the audio into chunks. The audio chunks are converted from stereo to mono as the final step.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Statistics</h2>

<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Raw Files:</h5>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">Nasl-e-Mana maintains an archive of 41 magazines spanning over three years. The archive comprises a total of 568 audio-text files. The audio files underwent manual inspection to ensure the dataset consisted of single-speaker recordings. Following this review, four files were excluded from the raw material, resulting in 564 files for automated processing. The duration of the audio files ranged from approximately 0.5 to 34 minutes, with an average duration of about 10 minutes. Similarly, the lengths of the text files varied, with word counts ranging from 44 to 3951 and an average length of 1234 words.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Processed Chunks Count:</h5>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">Executing the pipeline on the raw material yielded a minimum, maximum, and average of approximately 4, 398, and 118 chunks per file, respectively, totaling 66172 chunks overall. Roughly 97.98% of these chunks were automatically accepted as having good quality, while 1338 (about 2.02%) were rejected due to an unacceptable CER between the hypothesis transcript and the matching text. Consequently, the final dataset comprises 64834 accepted audio-text chunks.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Accepted Chunks Duration:</h5>

<div id="S4.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p1.1" class="ltx_p">As previously mentioned, our pipeline’s chunking method guarantees that audio chunks have durations ranging from a minimum of 2 seconds to a maximum of 12 seconds. The histogram depicting the duration distribution of the audio chunks is illustrated in Figure <a href="#S4.F4" title="Figure 4 ‣ Accepted Chunks Duration: ‣ 4 Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" style="width:223.3pt;"><img src="/html/2409.07259/assets/figs/chunk-duration-hist.png" id="S4.F4.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="390" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.1.1.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F4.1.2.2" class="ltx_text" style="font-size:90%;">Distribution of the duration of audio chunks.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" style="width:166.9pt;"><img src="/html/2409.07259/assets/figs/chunk-distr-purple.png" id="S4.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="480" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.2.2.2" class="ltx_text" style="font-size:90%;">Distribution of search type and match quality of accepted chunks.</span></figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S4.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Accepted chunks search type:</h5>

<div id="S4.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px4.p1.1" class="ltx_p">As outlined in previous sections, two search methods are employed to match a hypothesis transcript with the ground truth text: Interval Search and Gapped Search. It is important to note the preference for the Interval Search method due to its lower computational cost. Consequently, if a match meeting the acceptance criteria is found through Interval Search, further searching with the Gapped Search is unnecessary. Gapped Search is primarily utilized when the ground truth text does not perfectly align with the hypothesis. Analysis of chunk information reveals that approximately 99.39% of matching text chunks are identified through Interval Search, while the remaining 0.61% (397 chunks) are the result of Gapped Search.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Accepted chunks match quality:</h5>

<div id="S4.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px5.p1.1" class="ltx_p">As mentioned earlier, there are two threshold levels for CER of audio chunks. The first, labeled HIGH, signifies a perfect match between the hypothesis and ground truth text with a CER less than 0.05. The second, labeled MIDDLE, denotes an acceptable CER ranging from 0.05 to 0.2. Attaining the HIGH threshold during the search prompts an immediate acceptance of the chunk, whereas achieving the MIDDLE threshold would only accept the chunk at the end of each of the search types.</p>
</div>
<div id="S4.SS0.SSS0.Px5.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px5.p2.1" class="ltx_p">In total, approximately 71.46% of the chunks (46330 in total) have the HIGH and about 28.54% of the chunks (18504 in total) have the MIDDLE match quality. Figure <a href="#S4.F4" title="Figure 4 ‣ Accepted Chunks Duration: ‣ 4 Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the joint distribution of the search type and match quality of the audio-text chunks, as they are correlated.</p>
</div>
<div id="S4.SS0.SSS0.Px5.p3" class="ltx_para">
<p id="S4.SS0.SSS0.Px5.p3.1" class="ltx_p">It’s also intriguing to visualize the distribution of CER values for all the chunks that passed through the dataset creation pipeline. As illustrated in Figure <a href="#S4.F5" title="Figure 5 ‣ Accepted chunks match quality: ‣ 4 Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, there is only a small number of rejected chunks compared to the matched chunks in the other groups. Manual investigations indicate that these rejected chunks are mostly associated with an underlying discrepancy between the raw audio and text files. Other reasons for rejection include utterances that differ in their written and spoken forms, which will be further discussed in the section <a href="#S6.SS1" title="6.1 Limitations ‣ 6 Discussion ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2409.07259/assets/figs/cer-hist.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Distribution of CER values across all chunks.<span id="S4.F5.4.2.1" class="ltx_text ltx_font_medium"> The vertical lines denote the threshold values for the HIGH, MIDDLE, and REJECT match qualities as discussed in the section <a href="#S3.SS2.SSS3" title="3.2.3 Forced Alignment ‣ 3.2 Alignment ‣ 3 Dataset Preparation ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.3</span></a>.</span></span></figcaption>
</figure>
</section>
<section id="S4.SS0.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Word count:</h5>

<div id="S4.SS0.SSS0.Px6.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px6.p1.1" class="ltx_p">The accepted chunks exhibit a range of 1 to 38 words, with an average of approximately 11 words per chunk. The histogram illustrating the distribution of word counts can be found in Figure <a href="#S4.F6" title="Figure 6 ‣ Word count: ‣ 4 Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Overall, the dataset contains a total of approximately 24,113 unique words.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2409.07259/assets/figs/word-count-hist.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="151" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">Word count distribution of accepted text chunks.</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">To assess the quality and efficacy of the ManaTTS dataset, we embarked on training a Tacotron2-based TTS model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> from the ground up using this corpus. This model comprises three main components: First, a speaker encoder, trained on extensive untranscribed datasets, enabling extraction of speaker characteristics from mere seconds of speech. Second, a sequence-to-sequence Tacotron2-based model tasked with converting text into mel-spectrograms, and final component, a vocoder responsible for transforming the mel-spectrogram into the speech waveform.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We adopt a Persian language setup for the text-to-mel-spectrogram module <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. The input data undergo resampling to 24 kHz and preprocessing using an FFT size of 2048 and 80 mel-frequency filter banks. We then conduct six training sessions. The learning rate begins at 1e-3 and gradually reduces to 1e-5 in the final session, while the batch size is fixed at 16. With these parameters, the model undergoes training for 320,000 steps and is subsequently used for synthesizing samples for evaluation. <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>The full settings and scripts used for training are available at https://github.com/MahtaFetrat/Persian-MultiSpeaker-Tacotron2</span></span></span></p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">For the speaker encoder and vocoder components, we used the pre-trained encoder and HiFi-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> vocoder from the previously mentioned work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. HiFi-GAN is trained adversarially, where the generator synthesizes waveforms from spectrograms, and the discriminator distinguishes between synthetic and real waveforms. Due to its non-auto-regressive nature, HiFi-GAN operates faster than earlier vocoders while achieving superior speech quality.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">To evaluate the TTS model trained on ManaTTS, we selected five utterances from the latest issue of Nasl-e-Mana magazine that were not included in the training data and synthesized their corresponding speech waveforms using our TTS model. Additionally, we used two open-access Persian TTS models based on VITS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and Glow-TTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> as baseline models, generating waveforms for the same utterances for comparison.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">Furthermore, we compare the synthesized speech waveforms with the natural speech waveforms of the selected utterances. It is important to note that the vocoder used to generate waveforms from the TTS model’s spectrograms was not trained on our dataset. Therefore, to assess the model’s spectrogram generation ability fairly, we extracted the mel-spectrograms of the natural utterances and generated their waveforms using the pre-trained vocoder. We then compared these natural spectrogram-generated waveforms to the model’s outputs.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p">We used the subjective Mean Opinion Score (MOS) metric to evaluate our model.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>For other objective methods, please refer to Appendix <a href="#A4" title="Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</span></span></span> Scores were collected from 76 native Persian speakers, and the results are presented in Table <a href="#S5.T2" title="Table 2 ‣ 5 Experiments ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. For more details on the evaluation method, please refer to Appendix <a href="#A4" title="Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.10.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.11.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Subjective assessment of outcomes of the TTS models.<span id="S5.T2.11.2.1" class="ltx_text ltx_font_medium"> </span>GT Spec<span id="S5.T2.11.2.2" class="ltx_text ltx_font_medium"> refers to the utterances with ground truth spectrograms but HiFi-GAN-synthesized waveforms, and </span>GT Waveform<span id="S5.T2.11.2.3" class="ltx_text ltx_font_medium"> refers to the natural speech samples. The values are presented as mean opinion score (MOS) ± standard deviation (std).</span></span></figcaption>
<table id="S5.T2.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.5.6.1" class="ltx_tr">
<th id="S5.T2.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S5.T2.5.6.1.1.1" class="ltx_text ltx_font_bold">Source</span></th>
<th id="S5.T2.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">VITS</th>
<th id="S5.T2.5.6.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Glow</th>
<th id="S5.T2.5.6.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T2.5.6.1.4.1" class="ltx_text ltx_font_bold">Ours</span></th>
<th id="S5.T2.5.6.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">GT Spec</th>
<th id="S5.T2.5.6.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">GT Waveform</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.5.5" class="ltx_tr">
<th id="S5.T2.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S5.T2.5.5.6.1" class="ltx_text ltx_font_bold">MOS</span></th>
<td id="S5.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S5.T2.1.1.1.m1.1" class="ltx_Math" alttext="1.68\pm 0.80" display="inline"><semantics id="S5.T2.1.1.1.m1.1a"><mrow id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml"><mn id="S5.T2.1.1.1.m1.1.1.2" xref="S5.T2.1.1.1.m1.1.1.2.cmml">1.68</mn><mo id="S5.T2.1.1.1.m1.1.1.1" xref="S5.T2.1.1.1.m1.1.1.1.cmml">±</mo><mn id="S5.T2.1.1.1.m1.1.1.3" xref="S5.T2.1.1.1.m1.1.1.3.cmml">0.80</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><apply id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.1.1.1.m1.1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.1.1.1.m1.1.1.2.cmml" xref="S5.T2.1.1.1.m1.1.1.2">1.68</cn><cn type="float" id="S5.T2.1.1.1.m1.1.1.3.cmml" xref="S5.T2.1.1.1.m1.1.1.3">0.80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">1.68\pm 0.80</annotation></semantics></math></td>
<td id="S5.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S5.T2.2.2.2.m1.1" class="ltx_Math" alttext="1.34\pm 0.70" display="inline"><semantics id="S5.T2.2.2.2.m1.1a"><mrow id="S5.T2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.m1.1.1.cmml"><mn id="S5.T2.2.2.2.m1.1.1.2" xref="S5.T2.2.2.2.m1.1.1.2.cmml">1.34</mn><mo id="S5.T2.2.2.2.m1.1.1.1" xref="S5.T2.2.2.2.m1.1.1.1.cmml">±</mo><mn id="S5.T2.2.2.2.m1.1.1.3" xref="S5.T2.2.2.2.m1.1.1.3.cmml">0.70</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.m1.1b"><apply id="S5.T2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1"><csymbol cd="latexml" id="S5.T2.2.2.2.m1.1.1.1.cmml" xref="S5.T2.2.2.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.2.2.2.m1.1.1.2.cmml" xref="S5.T2.2.2.2.m1.1.1.2">1.34</cn><cn type="float" id="S5.T2.2.2.2.m1.1.1.3.cmml" xref="S5.T2.2.2.2.m1.1.1.3">0.70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.m1.1c">1.34\pm 0.70</annotation></semantics></math></td>
<td id="S5.T2.3.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S5.T2.3.3.3.m1.1" class="ltx_Math" alttext="\mathbf{3.76\pm 1.04}" display="inline"><semantics id="S5.T2.3.3.3.m1.1a"><mrow id="S5.T2.3.3.3.m1.1.1" xref="S5.T2.3.3.3.m1.1.1.cmml"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S5.T2.3.3.3.m1.1.1.2" xref="S5.T2.3.3.3.m1.1.1.2.cmml">3.76</mn><mo id="S5.T2.3.3.3.m1.1.1.1" xref="S5.T2.3.3.3.m1.1.1.1.cmml">±</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S5.T2.3.3.3.m1.1.1.3" xref="S5.T2.3.3.3.m1.1.1.3.cmml">1.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.m1.1b"><apply id="S5.T2.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1"><csymbol cd="latexml" id="S5.T2.3.3.3.m1.1.1.1.cmml" xref="S5.T2.3.3.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.3.3.3.m1.1.1.2.cmml" xref="S5.T2.3.3.3.m1.1.1.2">3.76</cn><cn type="float" id="S5.T2.3.3.3.m1.1.1.3.cmml" xref="S5.T2.3.3.3.m1.1.1.3">1.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.m1.1c">\mathbf{3.76\pm 1.04}</annotation></semantics></math></td>
<td id="S5.T2.4.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S5.T2.4.4.4.m1.1" class="ltx_Math" alttext="3.86\pm 1.04" display="inline"><semantics id="S5.T2.4.4.4.m1.1a"><mrow id="S5.T2.4.4.4.m1.1.1" xref="S5.T2.4.4.4.m1.1.1.cmml"><mn id="S5.T2.4.4.4.m1.1.1.2" xref="S5.T2.4.4.4.m1.1.1.2.cmml">3.86</mn><mo id="S5.T2.4.4.4.m1.1.1.1" xref="S5.T2.4.4.4.m1.1.1.1.cmml">±</mo><mn id="S5.T2.4.4.4.m1.1.1.3" xref="S5.T2.4.4.4.m1.1.1.3.cmml">1.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.m1.1b"><apply id="S5.T2.4.4.4.m1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1"><csymbol cd="latexml" id="S5.T2.4.4.4.m1.1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.4.4.4.m1.1.1.2.cmml" xref="S5.T2.4.4.4.m1.1.1.2">3.86</cn><cn type="float" id="S5.T2.4.4.4.m1.1.1.3.cmml" xref="S5.T2.4.4.4.m1.1.1.3">1.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.m1.1c">3.86\pm 1.04</annotation></semantics></math></td>
<td id="S5.T2.5.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S5.T2.5.5.5.m1.1" class="ltx_Math" alttext="4.01\pm 1.14" display="inline"><semantics id="S5.T2.5.5.5.m1.1a"><mrow id="S5.T2.5.5.5.m1.1.1" xref="S5.T2.5.5.5.m1.1.1.cmml"><mn id="S5.T2.5.5.5.m1.1.1.2" xref="S5.T2.5.5.5.m1.1.1.2.cmml">4.01</mn><mo id="S5.T2.5.5.5.m1.1.1.1" xref="S5.T2.5.5.5.m1.1.1.1.cmml">±</mo><mn id="S5.T2.5.5.5.m1.1.1.3" xref="S5.T2.5.5.5.m1.1.1.3.cmml">1.14</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.m1.1b"><apply id="S5.T2.5.5.5.m1.1.1.cmml" xref="S5.T2.5.5.5.m1.1.1"><csymbol cd="latexml" id="S5.T2.5.5.5.m1.1.1.1.cmml" xref="S5.T2.5.5.5.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S5.T2.5.5.5.m1.1.1.2.cmml" xref="S5.T2.5.5.5.m1.1.1.2">4.01</cn><cn type="float" id="S5.T2.5.5.5.m1.1.1.3.cmml" xref="S5.T2.5.5.5.m1.1.1.3">1.14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.m1.1c">4.01\pm 1.14</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The absence of high-quality, open-source/open-access text-to-speech models and datasets for the Persian language has been highlighted in section <a href="#A1" title="Appendix A Extended Discussion of Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. Below are some of the critical challenges associated with the available corpora.</p>
</div>
<div id="S6.p2" class="ltx_para">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">The dataset is either inaccessible, lacks a specified license, or is under a restrictive license.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">The dataset contains utterances from a limited domain, such as religious contexts exclusively.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">The speech is synthesized using a text-to-speech model.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p id="S6.I1.i4.p1.1" class="ltx_p">The text is synthesized using a speech-to-text model and has not been adequately verified.</p>
</div>
</li>
<li id="S6.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i5.p1" class="ltx_para">
<p id="S6.I1.i5.p1.1" class="ltx_p">The dataset is limited in size.</p>
</div>
</li>
</ul>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">The ManaTTS dataset introduced in this work is the first Persian language text-to-speech corpus that addresses all the above challenges. This dataset is publicly available under an open CC-0 1.0 license. It includes utterances from a monthly magazine over three years and covers various Persian language utterances. The speech and ground truth text in this dataset are collected by human agents, not synthesized. Most notably, it is the largest single-speaker text-to-speech dataset available to date.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">Another notable contribution of this work is that it represents the first fully open-source text-to-speech data collection project for the Persian language. Due to the open code base, all steps, including data crawling, processing, and model training, are reproducible. This approach helps develop additional Persian speech datasets and offers two fundamental benefits.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">First, in addition to the standard tools used in typical speech data processing, this project introduces a new sentence tokenization method and a new start-end alignment and forced alignment tool capable of aligning speech and text pairs that are not exact matches but are slightly different. Our work demonstrates that this tool can be effectively used with publicly available Persian ASR models of moderate accuracy, thus contributing yet another open-license tool to the community.</p>
</div>
<div id="S6.p6" class="ltx_para">
<p id="S6.p6.1" class="ltx_p">Second, the ever-growing monthly magazine of Nasl-e-Mana and the fully available data collection and processing pipeline make this dataset easily extendable. Future work can obtain an even larger dataset by executing a few scripts.</p>
</div>
<div id="S6.p7" class="ltx_para">
<p id="S6.p7.1" class="ltx_p">The experiments reveal that the TTS model, trained on the ManaTTS dataset, achieved a MOS of 3.76, slightly lower than natural spectrograms at 3.86 and natural speech at 4.01. It has even outperformed the ground truth spectrogram and waveform samples in some of the test utterances (refer to Appendix <a href="#A4" title="Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>). This implies that our dataset has acceptable quality and can be used effectively to train Persian text-to-speech models.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Limitations</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Despite the contributions of our work, there are some limitations to it. Firstly, although the transcripts are acquired using multiple ASR models and are used to find a match from the ground truth text only if they satisfy certain CER thresholds, this process is not entirely deterministic and is prone to minor errors that might not significantly affect the CER value. Thus, employing superior ASR systems with stricter CER thresholds might further reduce such errors.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">Secondly, owing to the pervasive nature of the English language, text in other languages may incorporate English words and phrases. However, our pipeline lacks an explicit mechanism to match these phrases between speech and text. Therefore, if the TTS model is expected to detect and vocalize English subtexts, the pipeline should be modified to include more of these examples in the dataset.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">Thirdly, while the pipeline incorporates a mechanism to match the spoken form of numbers, some specifically formatted numeric words remain challenging. For instance, a phone number might be pronounced in various ways, as could date or time. Therefore, a tool capable of converting between these differences in the spoken and written forms of specific numeric data and symbols for the Persian language would be highly beneficial.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p id="S6.SS1.p4.1" class="ltx_p">Finally, despite the public availability of the raw data, it’s important to recognize potential misuse concerns arising from our dataset or processing pipeline, such as voice impersonation. Anonymization emerges as a solution to mitigate these risks, ensuring responsible dataset usage in alignment with privacy and ethical considerations.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this work, we proposed a processing pipeline to create a TTS dataset from raw speech and text files. Applying the pipeline to the archive of the Nasl-e-Mana magazine, we published ManaTTS, the largest single-speaker Persian TTS dataset, under the open CC-0 1.0 license. Additionally, we released a smaller transcribed speech dataset, VirgoolInformal, which serves as a valuable test dataset for evaluating ASR models and is utilized in our novel forced alignment method. Evaluating ManaTTS involved training a Tacotron2-based TTS model. The samples synthesized by this model exhibited remarkable naturalness, comparing favorably to both the utterances generated from gold speech spectrograms and natural speech waveforms.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments and Disclosure of Funding</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We thank the Nasl-e-Mana magazine for their invaluable work and for being so generous with the published dataset license. We also extend our gratitude to the Iran Blind Non-governmental Organization for their support and guidance regarding the need for open access initiatives in this domain.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p"><span id="Sx1.p2.1.1" class="ltx_text ltx_font_bold">Funding Disclosure:</span> No funding was received for conducting this study.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Google maps.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.google.com/maps" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.google.com/maps</a>.

</span>
<span class="ltx_bibblock">Accessed: June 1, 2024.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Speechify for education.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://speechify.com/edu/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://speechify.com/edu/</a>.

</span>
<span class="ltx_bibblock">Accessed: June 1, 2024.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Murf ai.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://murf.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://murf.ai/</a>.

</span>
<span class="ltx_bibblock">Accessed: June 1, 2024.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Nv access.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.nvaccess.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nvaccess.org/</a>.

</span>
<span class="ltx_bibblock">Accessed: June 1, 2024.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Balad.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://balad.ir/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://balad.ir/</a>.

</span>
<span class="ltx_bibblock">Accessed: June 1, 2024.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Narakeet.

</span>
<span class="ltx_bibblock">Persian text to speech.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.narakeet.com/languages/persian-text-to-speech/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.narakeet.com/languages/persian-text-to-speech/</a>.

</span>
<span class="ltx_bibblock">Accessed: June 1, 2024.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Navid Naderi, Babak Nasersharif, and Amirhossein Nikoofard.

</span>
<span class="ltx_bibblock">Persian speech synthesis using enhanced tacotron based on multi-resolution convolution layers and a convex optimization method.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Multimedia Tools and Applications</span>, 81(3):3629–3645, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Heiga Zen, Viet Dang, Rob Clark, Yu Zhang, Ron J Weiss, Ye Jia, Zhifeng Chen, and Yonghui Wu.

</span>
<span class="ltx_bibblock">Libritts: A corpus derived from librispeech for text-to-speech.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1904.02882</span>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Nasl-e-mana magazine.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://naslemana.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://naslemana.com/</a>.

</span>
<span class="ltx_bibblock">Accessed: June 1, 2024.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Mohammd Hasan Shamgholi, Vahid Saeedi, Javad Peymanfard, Leila Alhabib, and Hossein Zeinali.

</span>
<span class="ltx_bibblock">Armantts single-speaker persian dataset.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.03585</span>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Magnoliasis.

</span>
<span class="ltx_bibblock">Persian TTS Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Moradi.

</span>
<span class="ltx_bibblock">Persian Text-to-Speech Audio Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.kaggle.com/datasets/moradi/persian-texttospeech-audio" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/moradi/persian-texttospeech-audio</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
AlisterTA.

</span>
<span class="ltx_bibblock">Persian Text-to-Speech Repository.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/AlisterTA/Persian-text-to-speech?tab=readme-ov-file" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/AlisterTA/Persian-text-to-speech?tab=readme-ov-file</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Magnoliasis.

</span>
<span class="ltx_bibblock">Persian TTS Dataset (Female).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-famale" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-famale</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Magnoliasis.

</span>
<span class="ltx_bibblock">Persian TTS Dataset (Male).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-male" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-male</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Persian speech corpus website.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://fa.persianspeechcorpus.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://fa.persianspeechcorpus.com/</a>, 2017.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Kamtera.

</span>
<span class="ltx_bibblock">ParsiGoo.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/datasets/Kamtera/ParsiGoo" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/Kamtera/ParsiGoo</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Majid Adibian, Hossein Zeinali, and Soroush Barmaki.

</span>
<span class="ltx_bibblock">Deepmine-multi-tts: A persian speech corpus for multi-speaker text-to-speech.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Available at SSRN 4673655</span>, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Romain Hennequin, Anis Khlif, Felix Voituret, and Manuel Moussallam.

</span>
<span class="ltx_bibblock">Spleeter: a fast and efficient music source separation tool with pre-trained models.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Journal of Open Source Software</span>, 5(50):2154, 2020.

</span>
<span class="ltx_bibblock">Deezer Research.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Roshan-AI.

</span>
<span class="ltx_bibblock">Hazm.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.roshan-ai.ir/hazm/docs/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.roshan-ai.ir/hazm/docs/index.html</a>.

</span>
<span class="ltx_bibblock">Accessed: May 3, 2024.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Parsi.io.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/language-ml/parsi.io" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/language-ml/parsi.io</a>.

</span>
<span class="ltx_bibblock">Accessed: May 3, 2024.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
ReadBeyond.

</span>
<span class="ltx_bibblock">Aeneas.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/readbeyond/aeneas" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/readbeyond/aeneas</a>.

</span>
<span class="ltx_bibblock">Accessed: May 3, 2024.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
James Robert.

</span>
<span class="ltx_bibblock">Pydub.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/jiaaro/pydub" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jiaaro/pydub</a>.

</span>
<span class="ltx_bibblock">Accessed: May 3, 2024.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Ye Jia, Yu Zhang, Ron Weiss, Quan Wang, Jonathan Shen, Fei Ren, Patrick Nguyen, Ruoming Pang, Ignacio Lopez Moreno, Yonghui Wu, et al.

</span>
<span class="ltx_bibblock">Transfer learning from speaker verification to multispeaker text-to-speech synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 31, 2018.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Majid Adibian.

</span>
<span class="ltx_bibblock">Persian-MultiSpeaker-Tacotron2.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/Adibian/Persian-MultiSpeaker-Tacotron2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Adibian/Persian-MultiSpeaker-Tacotron2</a>.

</span>
<span class="ltx_bibblock">Accessed on: May 4, 2024.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae.

</span>
<span class="ltx_bibblock">Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 33:17022–17033, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Jaehyeon Kim, Jungil Kong, and Juhee Son.

</span>
<span class="ltx_bibblock">Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 5530–5540. PMLR, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Kamtera.

</span>
<span class="ltx_bibblock">Persian tts female vits.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/Kamtera/persian-tts-female-vits" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/Kamtera/persian-tts-female-vits</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: May 31, 2024.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Jaehyeon Kim, Sungwon Kim, Jungil Kong, and Sungroh Yoon.

</span>
<span class="ltx_bibblock">Glow-tts: A generative flow for text-to-speech via monotonic alignment search.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 33:8067–8077, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Kamtera.

</span>
<span class="ltx_bibblock">Persian tts female glow_tts.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/Kamtera/persian-tts-female-glow_tts" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/Kamtera/persian-tts-female-glow_tts</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: May 31, 2024.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Hossein Zeinali, Lukáš Burget, and Jan Honza Černockỳ.

</span>
<span class="ltx_bibblock">A multi purpose and large scale speech corpus in persian and english for speaker and speech recognition: the deepmine database.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</span>, pages 397–402. IEEE, 2019.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Alan W Black.

</span>
<span class="ltx_bibblock">Cmu wilderness multilingual speech dataset.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 5971–5975. IEEE, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Mark Mazumder, Sharad Chitlangia, Colby Banbury, Yiping Kang, Juan Manuel Ciro, Keith Achorn, Daniel Galvez, Mark Sabini, Peter Mattson, David Kanter, et al.

</span>
<span class="ltx_bibblock">Multilingual spoken words corpus.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)</span>, 2021.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Rafael Mosquera Gómez, Julián Eusse, Juan Ciro, Daniel Galvez, Ryan Hileman, Kurt Bollacker, and David Kanter.

</span>
<span class="ltx_bibblock">Speech wikimedia: A 77 language multilingual speech dataset.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.15710</span>, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
PersianDataset.

</span>
<span class="ltx_bibblock">PersianSpeech: Persian Speech Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/persiandataset/PersianSpeech" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/persiandataset/PersianSpeech</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Elham Pourabbas and Kaveh Taghipour and Fatemeh Salehi.

</span>
<span class="ltx_bibblock">Persian speech emotion recognition dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://zenodo.org/records/7486182" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://zenodo.org/records/7486182</a>, 2022.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Farsdat (farsi speech database) corpus.

</span>
<span class="ltx_bibblock">ELRA Catalog, 2001.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Large farsdat corpus.

</span>
<span class="ltx_bibblock">ELRA Catalog, 2016.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Amir Pourmand.

</span>
<span class="ltx_bibblock">Automatic Speech Recognition Farsi YouTube.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.kaggle.com/datasets/amirpourmand/automatic-speech-recognition-farsi-youtube" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.kaggle.com/datasets/amirpourmand/automatic-speech-recognition-farsi-youtube</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Common Voice Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://commonvoice.mozilla.org/en/datasets" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://commonvoice.mozilla.org/en/datasets</a>.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Farsspon persian speech recognition system.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://asr-gooyesh.com/fa/shop/%D8%AF%D8%A7%D8%AF%DA%AF%D8%A7%D9%86-farsspon/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://asr-gooyesh.com/fa/shop/%D8%AF%D8%A7%D8%AF%DA%AF%D8%A7%D9%86-farsspon/</a>.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
shenasa-ai.

</span>
<span class="ltx_bibblock">Speech2Text Repository.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/shenasa-ai/speech2text" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/shenasa-ai/speech2text</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Seyed Saleh Hosseini.

</span>
<span class="ltx_bibblock">Persian Speech Recognition.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/seyedsaleh/persian-speech-recognition" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/seyedsaleh/persian-speech-recognition</a>, Year of last commit.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Javad Peymanfard, Samin Heydarian, Ali Lashini, Hossein Zeinali, Mohammad Reza Mohammadi, and Nasser Mozayani.

</span>
<span class="ltx_bibblock">A multi-purpose audio-visual corpus for multi-modal persian speech recognition: The arman-av dataset.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Expert Systems with Applications</span>, 238:121648, 2024.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Javad Peymanfard, Ali Lashini, Samin Heydarian, Hossein Zeinali, and Nasser Mozayani.

</span>
<span class="ltx_bibblock">Word-level persian lipreading dataset.

</span>
<span class="ltx_bibblock">In <span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">2022 12th International Conference on Computer and Knowledge Engineering (ICCKE)</span>, pages 225–230. IEEE, 2022.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Saber Malekzadeh, Mohammad Hossein Gholizadeh, and Seyed Naser Razavi.

</span>
<span class="ltx_bibblock">Persian vowel recognition with mfcc and ann on pcvc speech dataset.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1812.06953</span>, 2018.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Ralireza.

</span>
<span class="ltx_bibblock">PSDR: Persian Speech Dataset for Recognition.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/Ralireza/PSDR" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Ralireza/PSDR</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Evelina Bakhturina, Vitaly Lavrukhin, Boris Ginsburg, and Yang Zhang.

</span>
<span class="ltx_bibblock">Hi-fi multi-speaker english tts dataset.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2104.01497</span>, 2021.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Blizzard Challenge 2013 Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.synsig.org/index.php/Blizzard_Challenge_2013#Data_download" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.synsig.org/index.php/Blizzard_Challenge_2013#Data_download</a>.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Veaux, Christophe and Yamagishi, Junichi and MacDonald, Kirsten.

</span>
<span class="ltx_bibblock">CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://datashare.ed.ac.uk/handle/10283/2651" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://datashare.ed.ac.uk/handle/10283/2651</a>, 2017.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Librispeech: an asr corpus based on public domain audio books.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)</span>, pages 5206–5210. IEEE, 2015.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Daniel Galvez, Greg Diamos, Juan Ciro, Juan Felipe Cerón, Keith Achorn, Anjali Gopi, David Kanter, Maximilian Lam, Mark Mazumder, and Vijay Janapa Reddi.

</span>
<span class="ltx_bibblock">The people’s speech: A large-scale diverse english speech recognition dataset for commercial usage.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2111.09344</span>, 2021.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Rohola Zandie, Mohammad H Mahoor, Julia Madsen, and Eshrat S Emamian.

</span>
<span class="ltx_bibblock">Ryanspeech: A corpus for conversational text-to-speech synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.08468</span>, 2021.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Hugging Face.

</span>
<span class="ltx_bibblock">LJ Speech Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/datasets/lj_speech" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/lj_speech</a>.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Caito.

</span>
<span class="ltx_bibblock">M-AILABS Speech Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.caito.de/2019/01/03/the-m-ailabs-speech-dataset/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.caito.de/2019/01/03/the-m-ailabs-speech-dataset/</a>.

</span>
<span class="ltx_bibblock">Accessed: April 22, 2024.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Sadra Sabouri, Elnaz Rahmati, Soroush Gooran, and Hossein Sameti.

</span>
<span class="ltx_bibblock">naab: A ready-to-use plug-and-play corpus for farsi.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2208.13486</span>, 2022.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Virgool.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://virgool.io/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://virgool.io/</a>.

</span>
<span class="ltx_bibblock">Accessed: June 1, 2024.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Mohammad Hadi Bashari.

</span>
<span class="ltx_bibblock">Perpos: Cross platform persian pos tagger.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/mhbashari/perpos" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/mhbashari/perpos</a>, 2021.

</span>
<span class="ltx_bibblock">Accessed: May 23, 2024.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Antony W Rix, John G Beerends, Michael P Hollier, and Andries P Hekstra.

</span>
<span class="ltx_bibblock">Perceptual evaluation of speech quality (pesq)-a new method for speech quality assessment of telephone networks and codecs.

</span>
<span class="ltx_bibblock">In <span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">2001 IEEE international conference on acoustics, speech, and signal processing. Proceedings (Cat. No. 01CH37221)</span>, volume 2, pages 749–752. IEEE, 2001.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Robert Kubichek.

</span>
<span class="ltx_bibblock">Mel-cepstral distance measure for objective speech quality assessment.

</span>
<span class="ltx_bibblock">In <span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE pacific rim conference on communications computers and signal processing</span>, volume 1, pages 125–128. IEEE, 1993.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Anthony Zhang.

</span>
<span class="ltx_bibblock">Speech recognition (version 3.8).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/Uberi/speech_recognition#readme" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Uberi/speech_recognition#readme</a>, 2017.

</span>
<span class="ltx_bibblock">Software.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Alpha Cephei Inc.

</span>
<span class="ltx_bibblock">Vosk - offline speech recognition api.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://alphacephei.com/vosk/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://alphacephei.com/vosk/</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: May 23, 2024.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
SpeechBrain.

</span>
<span class="ltx_bibblock">Whisper large-v2 fine-tuned on commonvoice persian.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/speechbrain/asr-whisper-large-v2-commonvoice-fa" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/speechbrain/asr-whisper-large-v2-commonvoice-fa</a>, 2023.

</span>
<span class="ltx_bibblock">Accessed: June 4, 2024.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Mirco Ravanelli, Titouan Parcollet, Aku Rouhe, Peter Plantinga, Elena Rastorgueva, Loren Lugosch, Nauman Dawalatabad, Chou Ju-Chieh, Abdel Heba, Francois Grondin, William Aris, Chien-Feng Liao, Samuele Cornell, Sung-Lin Yeh, Hwidong Na, Yan Gao, Szu-Wei Fu, Cem Subakan, Renato De Mori, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Speechbrain.

</span>
<span class="ltx_bibblock">
<br class="ltx_break">
<br class="ltx_break">urlhttps://github.com/speechbrain/speechbrain, 2021.

</span>
<span class="ltx_bibblock">Accessed: May 23, 2024.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
M Mehdadfi.

</span>
<span class="ltx_bibblock">Wav2vec2-large-xlsr-persian-v3.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/m3hrdadfi/wav2vec2-large-xlsr-persian-v3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/m3hrdadfi/wav2vec2-large-xlsr-persian-v3</a>, 2021.

</span>
<span class="ltx_bibblock">Accessed: May 23, 2024.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Seyyed Mohammad Masoud Paparnchi.

</span>
<span class="ltx_bibblock">wav2vec2-xlsr-multilingual-53-fa.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/Hamtech-ai/wav2vec2-fa" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Hamtech-ai/wav2vec2-fa</a>, 2021.

</span>
<span class="ltx_bibblock">Accessed: May 23, 2024.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Aryan Shekarlaban and Pooya Mohammadi Kazaj.

</span>
<span class="ltx_bibblock">Hezar: The all-in-one ai library for persian.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/hezarai/hezar" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/hezarai/hezar</a>, 2023.

</span>
<span class="ltx_bibblock">Accessed: May 3, 2024.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
JiWER.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/jitsi/jiwer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jitsi/jiwer</a>.

</span>
<span class="ltx_bibblock">Accessed: May 3, 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">NeurIPS Paper Checklist</h2>

<div id="Sx2.p1" class="ltx_para">
<ol id="Sx2.I1" class="ltx_enumerate">
<li id="Sx2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="Sx2.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i1.p1.1" class="ltx_p"><span id="Sx2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Claims</span></p>
</div>
</li>
<li id="Sx2.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix1.p1" class="ltx_para">
<p id="Sx2.I1.ix1.p1.1" class="ltx_p">Question: Do the main claims made in the abstract and introduction accurately reflect the paper’s contributions and scope?</p>
</div>
</li>
<li id="Sx2.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix2.p1" class="ltx_para">
<p id="Sx2.I1.ix2.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix2.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix3.p1" class="ltx_para">
<p id="Sx2.I1.ix3.p1.1" class="ltx_p">Justification: The Abstract briefly introduces the key findings of our work. The Introduction section highlights the challenges associated with available resources and then enumerates the main characteristics and contributions of our work in nine points.</p>
</div>
</li>
<li id="Sx2.I1.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix4.p1" class="ltx_para">
<p id="Sx2.I1.ix4.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix4.I1" class="ltx_itemize">
<li id="Sx2.I1.ix4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix4.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix4.I1.i1.p1.1" class="ltx_p">The answer NA means that the abstract and introduction do not include the claims made in the paper.</p>
</div>
</li>
<li id="Sx2.I1.ix4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix4.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix4.I1.i2.p1.1" class="ltx_p">The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.</p>
</div>
</li>
<li id="Sx2.I1.ix4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix4.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix4.I1.i3.p1.1" class="ltx_p">The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.</p>
</div>
</li>
<li id="Sx2.I1.ix4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix4.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix4.I1.i4.p1.1" class="ltx_p">It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="Sx2.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i2.p1.1" class="ltx_p"><span id="Sx2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Limitations</span></p>
</div>
</li>
<li id="Sx2.I1.ix5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix5.p1" class="ltx_para">
<p id="Sx2.I1.ix5.p1.1" class="ltx_p">Question: Does the paper discuss the limitations of the work performed by the authors?</p>
</div>
</li>
<li id="Sx2.I1.ix6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix6.p1" class="ltx_para">
<p id="Sx2.I1.ix6.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix6.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix7.p1" class="ltx_para">
<p id="Sx2.I1.ix7.p1.1" class="ltx_p">Justification: There is a Limitations section in the paper introducing four main limitations of the current work and provide suggestions for addressing each.</p>
</div>
</li>
<li id="Sx2.I1.ix8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix8.p1" class="ltx_para">
<p id="Sx2.I1.ix8.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix8.I1" class="ltx_itemize">
<li id="Sx2.I1.ix8.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix8.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix8.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.</p>
</div>
</li>
<li id="Sx2.I1.ix8.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix8.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix8.I1.i2.p1.1" class="ltx_p">The authors are encouraged to create a separate "Limitations" section in their paper.</p>
</div>
</li>
<li id="Sx2.I1.ix8.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix8.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix8.I1.i3.p1.1" class="ltx_p">The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.</p>
</div>
</li>
<li id="Sx2.I1.ix8.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix8.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix8.I1.i4.p1.1" class="ltx_p">The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.</p>
</div>
</li>
<li id="Sx2.I1.ix8.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix8.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.ix8.I1.i5.p1.1" class="ltx_p">The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.</p>
</div>
</li>
<li id="Sx2.I1.ix8.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix8.I1.i6.p1" class="ltx_para">
<p id="Sx2.I1.ix8.I1.i6.p1.1" class="ltx_p">The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.</p>
</div>
</li>
<li id="Sx2.I1.ix8.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix8.I1.i7.p1" class="ltx_para">
<p id="Sx2.I1.ix8.I1.i7.p1.1" class="ltx_p">If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.</p>
</div>
</li>
<li id="Sx2.I1.ix8.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix8.I1.i8.p1" class="ltx_para">
<p id="Sx2.I1.ix8.I1.i8.p1.1" class="ltx_p">While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren’t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="Sx2.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i3.p1.1" class="ltx_p"><span id="Sx2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Theory Assumptions and Proofs</span></p>
</div>
</li>
<li id="Sx2.I1.ix9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix9.p1" class="ltx_para">
<p id="Sx2.I1.ix9.p1.1" class="ltx_p">Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?</p>
</div>
</li>
<li id="Sx2.I1.ix10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix10.p1" class="ltx_para">
<p id="Sx2.I1.ix10.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix10.p1.1.1" class="ltx_text" style="color:#808080;">[N/A] </span></p>
</div>
</li>
<li id="Sx2.I1.ix11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix11.p1" class="ltx_para">
<p id="Sx2.I1.ix11.p1.1" class="ltx_p">Justification: The paper does not include theoretical results.</p>
</div>
</li>
<li id="Sx2.I1.ix12" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix12.p1" class="ltx_para">
<p id="Sx2.I1.ix12.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix12.I1" class="ltx_itemize">
<li id="Sx2.I1.ix12.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix12.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix12.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not include theoretical results.</p>
</div>
</li>
<li id="Sx2.I1.ix12.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix12.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix12.I1.i2.p1.1" class="ltx_p">All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.</p>
</div>
</li>
<li id="Sx2.I1.ix12.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix12.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix12.I1.i3.p1.1" class="ltx_p">All assumptions should be clearly stated or referenced in the statement of any theorems.</p>
</div>
</li>
<li id="Sx2.I1.ix12.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix12.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix12.I1.i4.p1.1" class="ltx_p">The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.</p>
</div>
</li>
<li id="Sx2.I1.ix12.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix12.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.ix12.I1.i5.p1.1" class="ltx_p">Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.</p>
</div>
</li>
<li id="Sx2.I1.ix12.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix12.I1.i6.p1" class="ltx_para">
<p id="Sx2.I1.ix12.I1.i6.p1.1" class="ltx_p">Theorems and Lemmas that the proof relies upon should be properly referenced.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="Sx2.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.i4.p1.1" class="ltx_p"><span id="Sx2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Experimental Result Reproducibility</span></p>
</div>
</li>
<li id="Sx2.I1.ix13" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix13.p1" class="ltx_para">
<p id="Sx2.I1.ix13.p1.1" class="ltx_p">Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?</p>
</div>
</li>
<li id="Sx2.I1.ix14" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix14.p1" class="ltx_para">
<p id="Sx2.I1.ix14.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix14.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix15" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix15.p1" class="ltx_para">
<p id="Sx2.I1.ix15.p1.1" class="ltx_p">Justification: All steps of this study, from the very initial step of data collection scripts to the entire data processing pipeline and evaluation phase, are fully open-source and reproducible. We utilize tools from the open-source domain, and the processed data is also published with the most open license, with consent from its owner. Even the ASR evaluation dataset and processing codes are openly available and reproducible. Additionally, all the new processing tools proposed are also open.</p>
</div>
</li>
<li id="Sx2.I1.ix16" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix16.p1" class="ltx_para">
<p id="Sx2.I1.ix16.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix16.I1" class="ltx_itemize">
<li id="Sx2.I1.ix16.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix16.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not include experiments.</p>
</div>
</li>
<li id="Sx2.I1.ix16.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix16.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i2.p1.1" class="ltx_p">If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.</p>
</div>
</li>
<li id="Sx2.I1.ix16.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix16.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i3.p1.1" class="ltx_p">If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.</p>
</div>
</li>
<li id="Sx2.I1.ix16.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix16.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i4.p1.1" class="ltx_p">Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.</p>
</div>
</li>
<li id="Sx2.I1.ix16.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix16.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i5.p1.1" class="ltx_p">While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example</p>
<ol id="Sx2.I1.ix16.I1.i5.I1" class="ltx_enumerate">
<li id="Sx2.I1.ix16.I1.i5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(a)</span> 
<div id="Sx2.I1.ix16.I1.i5.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i5.I1.i1.p1.1" class="ltx_p">If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.</p>
</div>
</li>
<li id="Sx2.I1.ix16.I1.i5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(b)</span> 
<div id="Sx2.I1.ix16.I1.i5.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i5.I1.i2.p1.1" class="ltx_p">If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.</p>
</div>
</li>
<li id="Sx2.I1.ix16.I1.i5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(c)</span> 
<div id="Sx2.I1.ix16.I1.i5.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i5.I1.i3.p1.1" class="ltx_p">If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).</p>
</div>
</li>
<li id="Sx2.I1.ix16.I1.i5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(d)</span> 
<div id="Sx2.I1.ix16.I1.i5.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix16.I1.i5.I1.i4.p1.1" class="ltx_p">We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.</p>
</div>
</li>
</ol>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="Sx2.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.i5.p1.1" class="ltx_p"><span id="Sx2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Open access to data and code</span></p>
</div>
</li>
<li id="Sx2.I1.ix17" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix17.p1" class="ltx_para">
<p id="Sx2.I1.ix17.p1.1" class="ltx_p">Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?</p>
</div>
</li>
<li id="Sx2.I1.ix18" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix18.p1" class="ltx_para">
<p id="Sx2.I1.ix18.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix18.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix19" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix19.p1" class="ltx_para">
<p id="Sx2.I1.ix19.p1.1" class="ltx_p">Justification: As previously mentioned, all code and scripts are open-source. The raw data source is publicly accessible on the internet, and the processed dataset, suitable for TTS and other speech tasks, is also published under an open CC-0 license.</p>
</div>
</li>
<li id="Sx2.I1.ix20" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix20.p1" class="ltx_para">
<p id="Sx2.I1.ix20.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix20.I1" class="ltx_itemize">
<li id="Sx2.I1.ix20.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix20.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix20.I1.i1.p1.1" class="ltx_p">The answer NA means that paper does not include experiments requiring code.</p>
</div>
</li>
<li id="Sx2.I1.ix20.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix20.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix20.I1.i2.p1.1" class="ltx_p">Please see the NeurIPS code and data submission guidelines (<a target="_blank" href="https://nips.cc/public/guides/CodeSubmissionPolicy" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://nips.cc/public/guides/CodeSubmissionPolicy</a>) for more details.</p>
</div>
</li>
<li id="Sx2.I1.ix20.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix20.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix20.I1.i3.p1.1" class="ltx_p">While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).</p>
</div>
</li>
<li id="Sx2.I1.ix20.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix20.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix20.I1.i4.p1.1" class="ltx_p">The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (<a target="_blank" href="https://nips.cc/public/guides/CodeSubmissionPolicy" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://nips.cc/public/guides/CodeSubmissionPolicy</a>) for more details.</p>
</div>
</li>
<li id="Sx2.I1.ix20.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix20.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.ix20.I1.i5.p1.1" class="ltx_p">The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.</p>
</div>
</li>
<li id="Sx2.I1.ix20.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix20.I1.i6.p1" class="ltx_para">
<p id="Sx2.I1.ix20.I1.i6.p1.1" class="ltx_p">The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.</p>
</div>
</li>
<li id="Sx2.I1.ix20.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix20.I1.i7.p1" class="ltx_para">
<p id="Sx2.I1.ix20.I1.i7.p1.1" class="ltx_p">At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).</p>
</div>
</li>
<li id="Sx2.I1.ix20.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix20.I1.i8.p1" class="ltx_para">
<p id="Sx2.I1.ix20.I1.i8.p1.1" class="ltx_p">Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span> 
<div id="Sx2.I1.i6.p1" class="ltx_para">
<p id="Sx2.I1.i6.p1.1" class="ltx_p"><span id="Sx2.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Experimental Setting/Details</span></p>
</div>
</li>
<li id="Sx2.I1.ix21" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix21.p1" class="ltx_para">
<p id="Sx2.I1.ix21.p1.1" class="ltx_p">Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?</p>
</div>
</li>
<li id="Sx2.I1.ix22" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix22.p1" class="ltx_para">
<p id="Sx2.I1.ix22.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix22.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix23" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix23.p1" class="ltx_para">
<p id="Sx2.I1.ix23.p1.1" class="ltx_p">Justification: The Data Preparation section outlines the hardware used, while the Experiments section highlights key training parameters. Furthermore, comprehensive details and parameters of the trained model are accessible within the open-source code accompanying this work.</p>
</div>
</li>
<li id="Sx2.I1.ix24" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix24.p1" class="ltx_para">
<p id="Sx2.I1.ix24.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix24.I1" class="ltx_itemize">
<li id="Sx2.I1.ix24.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix24.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix24.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not include experiments.</p>
</div>
</li>
<li id="Sx2.I1.ix24.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix24.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix24.I1.i2.p1.1" class="ltx_p">The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.</p>
</div>
</li>
<li id="Sx2.I1.ix24.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix24.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix24.I1.i3.p1.1" class="ltx_p">The full details can be provided either with the code, in appendix, or as supplemental material.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span> 
<div id="Sx2.I1.i7.p1" class="ltx_para">
<p id="Sx2.I1.i7.p1.1" class="ltx_p"><span id="Sx2.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">Experiment Statistical Significance</span></p>
</div>
</li>
<li id="Sx2.I1.ix25" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix25.p1" class="ltx_para">
<p id="Sx2.I1.ix25.p1.1" class="ltx_p">Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?</p>
</div>
</li>
<li id="Sx2.I1.ix26" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix26.p1" class="ltx_para">
<p id="Sx2.I1.ix26.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix26.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix27" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix27.p1" class="ltx_para">
<p id="Sx2.I1.ix27.p1.1" class="ltx_p">Justification: The paper provides error bars (standard deviations) for the subjective assessment of outcomes across various sources in both tabular and graphical representations, offering transparent insights into the variability of the data, as presented in Appendix <a href="#A4" title="Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
</li>
<li id="Sx2.I1.ix28" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix28.p1" class="ltx_para">
<p id="Sx2.I1.ix28.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix28.I1" class="ltx_itemize">
<li id="Sx2.I1.ix28.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not include experiments.</p>
</div>
</li>
<li id="Sx2.I1.ix28.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i2.p1.1" class="ltx_p">The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.</p>
</div>
</li>
<li id="Sx2.I1.ix28.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i3.p1.1" class="ltx_p">The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).</p>
</div>
</li>
<li id="Sx2.I1.ix28.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i4.p1.1" class="ltx_p">The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)</p>
</div>
</li>
<li id="Sx2.I1.ix28.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i5.p1.1" class="ltx_p">The assumptions made should be given (e.g., Normally distributed errors).</p>
</div>
</li>
<li id="Sx2.I1.ix28.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i6.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i6.p1.1" class="ltx_p">It should be clear whether the error bar is the standard deviation or the standard error of the mean.</p>
</div>
</li>
<li id="Sx2.I1.ix28.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i7.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i7.p1.1" class="ltx_p">It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.</p>
</div>
</li>
<li id="Sx2.I1.ix28.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i8.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i8.p1.1" class="ltx_p">For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).</p>
</div>
</li>
<li id="Sx2.I1.ix28.I1.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix28.I1.i9.p1" class="ltx_para">
<p id="Sx2.I1.ix28.I1.i9.p1.1" class="ltx_p">If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">8.</span> 
<div id="Sx2.I1.i8.p1" class="ltx_para">
<p id="Sx2.I1.i8.p1.1" class="ltx_p"><span id="Sx2.I1.i8.p1.1.1" class="ltx_text ltx_font_bold">Experiments Compute Resources</span></p>
</div>
</li>
<li id="Sx2.I1.ix29" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix29.p1" class="ltx_para">
<p id="Sx2.I1.ix29.p1.1" class="ltx_p">Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?</p>
</div>
</li>
<li id="Sx2.I1.ix30" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix30.p1" class="ltx_para">
<p id="Sx2.I1.ix30.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix30.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix31" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix31.p1" class="ltx_para">
<p id="Sx2.I1.ix31.p1.1" class="ltx_p">Justification: The paper introduces the hardware specifications utilized for both data processing and experimental model training in the Data Preparation section.</p>
</div>
</li>
<li id="Sx2.I1.ix32" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix32.p1" class="ltx_para">
<p id="Sx2.I1.ix32.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix32.I1" class="ltx_itemize">
<li id="Sx2.I1.ix32.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix32.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix32.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not include experiments.</p>
</div>
</li>
<li id="Sx2.I1.ix32.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix32.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix32.I1.i2.p1.1" class="ltx_p">The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.</p>
</div>
</li>
<li id="Sx2.I1.ix32.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix32.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix32.I1.i3.p1.1" class="ltx_p">The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.</p>
</div>
</li>
<li id="Sx2.I1.ix32.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix32.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix32.I1.i4.p1.1" class="ltx_p">The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn’t make it into the paper).</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">9.</span> 
<div id="Sx2.I1.i9.p1" class="ltx_para">
<p id="Sx2.I1.i9.p1.1" class="ltx_p"><span id="Sx2.I1.i9.p1.1.1" class="ltx_text ltx_font_bold">Code Of Ethics</span></p>
</div>
</li>
<li id="Sx2.I1.ix33" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix33.p1" class="ltx_para">
<p id="Sx2.I1.ix33.p1.1" class="ltx_p">Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics <a target="_blank" href="https://neurips.cc/public/EthicsGuidelines" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://neurips.cc/public/EthicsGuidelines</a>?</p>
</div>
</li>
<li id="Sx2.I1.ix34" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix34.p1" class="ltx_para">
<p id="Sx2.I1.ix34.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix34.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix35" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix35.p1" class="ltx_para">
<p id="Sx2.I1.ix35.p1.1" class="ltx_p">Justification: The research aligns with the NeurIPS Code of Ethics, ensuring ethical standards are met throughout the study.</p>
</div>
</li>
<li id="Sx2.I1.ix36" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix36.p1" class="ltx_para">
<p id="Sx2.I1.ix36.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix36.I1" class="ltx_itemize">
<li id="Sx2.I1.ix36.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix36.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix36.I1.i1.p1.1" class="ltx_p">The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.</p>
</div>
</li>
<li id="Sx2.I1.ix36.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix36.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix36.I1.i2.p1.1" class="ltx_p">If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.</p>
</div>
</li>
<li id="Sx2.I1.ix36.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix36.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix36.I1.i3.p1.1" class="ltx_p">The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">10.</span> 
<div id="Sx2.I1.i10.p1" class="ltx_para">
<p id="Sx2.I1.i10.p1.1" class="ltx_p"><span id="Sx2.I1.i10.p1.1.1" class="ltx_text ltx_font_bold">Broader Impacts</span></p>
</div>
</li>
<li id="Sx2.I1.ix37" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix37.p1" class="ltx_para">
<p id="Sx2.I1.ix37.p1.1" class="ltx_p">Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?</p>
</div>
</li>
<li id="Sx2.I1.ix38" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix38.p1" class="ltx_para">
<p id="Sx2.I1.ix38.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix38.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix39" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix39.p1" class="ltx_para">
<p id="Sx2.I1.ix39.p1.1" class="ltx_p">Justification: The Introduction emphasizes the benefits of a large-scale TTS dataset, particularly its role in providing high-quality models for accessibility purposes. The Limitations section, on the other hand, discusses concerns about potential data misuse.</p>
</div>
</li>
<li id="Sx2.I1.ix40" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix40.p1" class="ltx_para">
<p id="Sx2.I1.ix40.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix40.I1" class="ltx_itemize">
<li id="Sx2.I1.ix40.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix40.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix40.I1.i1.p1.1" class="ltx_p">The answer NA means that there is no societal impact of the work performed.</p>
</div>
</li>
<li id="Sx2.I1.ix40.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix40.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix40.I1.i2.p1.1" class="ltx_p">If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.</p>
</div>
</li>
<li id="Sx2.I1.ix40.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix40.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix40.I1.i3.p1.1" class="ltx_p">Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.</p>
</div>
</li>
<li id="Sx2.I1.ix40.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix40.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix40.I1.i4.p1.1" class="ltx_p">The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.</p>
</div>
</li>
<li id="Sx2.I1.ix40.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix40.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.ix40.I1.i5.p1.1" class="ltx_p">The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.</p>
</div>
</li>
<li id="Sx2.I1.ix40.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix40.I1.i6.p1" class="ltx_para">
<p id="Sx2.I1.ix40.I1.i6.p1.1" class="ltx_p">If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">11.</span> 
<div id="Sx2.I1.i11.p1" class="ltx_para">
<p id="Sx2.I1.i11.p1.1" class="ltx_p"><span id="Sx2.I1.i11.p1.1.1" class="ltx_text ltx_font_bold">Safeguards</span></p>
</div>
</li>
<li id="Sx2.I1.ix41" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix41.p1" class="ltx_para">
<p id="Sx2.I1.ix41.p1.1" class="ltx_p">Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?</p>
</div>
</li>
<li id="Sx2.I1.ix42" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix42.p1" class="ltx_para">
<p id="Sx2.I1.ix42.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix42.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix43" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix43.p1" class="ltx_para">
<p id="Sx2.I1.ix43.p1.1" class="ltx_p">Justification: We have provided explicit guidance to users against misuse, such as voice impersonation, in dataset utilization. Moreover, the crawled data is sourced from a single reputable website and comprises only text data, reducing potential safety concerns.</p>
</div>
</li>
<li id="Sx2.I1.ix44" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix44.p1" class="ltx_para">
<p id="Sx2.I1.ix44.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix44.I1" class="ltx_itemize">
<li id="Sx2.I1.ix44.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix44.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix44.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper poses no such risks.</p>
</div>
</li>
<li id="Sx2.I1.ix44.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix44.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix44.I1.i2.p1.1" class="ltx_p">Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.</p>
</div>
</li>
<li id="Sx2.I1.ix44.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix44.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix44.I1.i3.p1.1" class="ltx_p">Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.</p>
</div>
</li>
<li id="Sx2.I1.ix44.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix44.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix44.I1.i4.p1.1" class="ltx_p">We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i12" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">12.</span> 
<div id="Sx2.I1.i12.p1" class="ltx_para">
<p id="Sx2.I1.i12.p1.1" class="ltx_p"><span id="Sx2.I1.i12.p1.1.1" class="ltx_text ltx_font_bold">Licenses for existing assets</span></p>
</div>
</li>
<li id="Sx2.I1.ix45" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix45.p1" class="ltx_para">
<p id="Sx2.I1.ix45.p1.1" class="ltx_p">Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?</p>
</div>
</li>
<li id="Sx2.I1.ix46" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix46.p1" class="ltx_para">
<p id="Sx2.I1.ix46.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix46.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix47" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix47.p1" class="ltx_para">
<p id="Sx2.I1.ix47.p1.1" class="ltx_p">Justification: The assets utilized in the paper are explicitly listed in the Supplementary Tables section along with their licenses, and all are sourced from the open-source domain.</p>
</div>
</li>
<li id="Sx2.I1.ix48" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix48.p1" class="ltx_para">
<p id="Sx2.I1.ix48.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix48.I1" class="ltx_itemize">
<li id="Sx2.I1.ix48.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix48.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix48.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not use existing assets.</p>
</div>
</li>
<li id="Sx2.I1.ix48.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix48.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix48.I1.i2.p1.1" class="ltx_p">The authors should cite the original paper that produced the code package or dataset.</p>
</div>
</li>
<li id="Sx2.I1.ix48.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix48.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix48.I1.i3.p1.1" class="ltx_p">The authors should state which version of the asset is used and, if possible, include a URL.</p>
</div>
</li>
<li id="Sx2.I1.ix48.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix48.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix48.I1.i4.p1.1" class="ltx_p">The name of the license (e.g., CC BY 4.0) should be included for each asset.</p>
</div>
</li>
<li id="Sx2.I1.ix48.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix48.I1.i5.p1" class="ltx_para">
<p id="Sx2.I1.ix48.I1.i5.p1.1" class="ltx_p">For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.</p>
</div>
</li>
<li id="Sx2.I1.ix48.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix48.I1.i6.p1" class="ltx_para">
<p id="Sx2.I1.ix48.I1.i6.p1.1" class="ltx_p">If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, <a href="paperswithcode.com/datasets" title="" class="ltx_ref ltx_url ltx_font_typewriter">paperswithcode.com/datasets</a> has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.</p>
</div>
</li>
<li id="Sx2.I1.ix48.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix48.I1.i7.p1" class="ltx_para">
<p id="Sx2.I1.ix48.I1.i7.p1.1" class="ltx_p">For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.</p>
</div>
</li>
<li id="Sx2.I1.ix48.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix48.I1.i8.p1" class="ltx_para">
<p id="Sx2.I1.ix48.I1.i8.p1.1" class="ltx_p">If this information is not Avail. online, the authors are encouraged to reach out to the asset’s creators.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i13" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">13.</span> 
<div id="Sx2.I1.i13.p1" class="ltx_para">
<p id="Sx2.I1.i13.p1.1" class="ltx_p"><span id="Sx2.I1.i13.p1.1.1" class="ltx_text ltx_font_bold">New Assets</span></p>
</div>
</li>
<li id="Sx2.I1.ix49" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix49.p1" class="ltx_para">
<p id="Sx2.I1.ix49.p1.1" class="ltx_p">Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?</p>
</div>
</li>
<li id="Sx2.I1.ix50" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix50.p1" class="ltx_para">
<p id="Sx2.I1.ix50.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix50.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span> </p>
</div>
</li>
<li id="Sx2.I1.ix51" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix51.p1" class="ltx_para">
<p id="Sx2.I1.ix51.p1.1" class="ltx_p">Justification: The code base and tools introduced in this work are thoroughly documented, accompanied by ReadMe files in a publicly accessible repository. All assets are appropriately licensed, with detailed license information provided, including external assets.</p>
</div>
</li>
<li id="Sx2.I1.ix52" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix52.p1" class="ltx_para">
<p id="Sx2.I1.ix52.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix52.I1" class="ltx_itemize">
<li id="Sx2.I1.ix52.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix52.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix52.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not release new assets.</p>
</div>
</li>
<li id="Sx2.I1.ix52.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix52.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix52.I1.i2.p1.1" class="ltx_p">Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.</p>
</div>
</li>
<li id="Sx2.I1.ix52.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix52.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix52.I1.i3.p1.1" class="ltx_p">The paper should discuss whether and how consent was obtained from people whose asset is used.</p>
</div>
</li>
<li id="Sx2.I1.ix52.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix52.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix52.I1.i4.p1.1" class="ltx_p">At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i14" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">14.</span> 
<div id="Sx2.I1.i14.p1" class="ltx_para">
<p id="Sx2.I1.i14.p1.1" class="ltx_p"><span id="Sx2.I1.i14.p1.1.1" class="ltx_text ltx_font_bold">Crowdsourcing and Research with Human Subjects</span></p>
</div>
</li>
<li id="Sx2.I1.ix53" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix53.p1" class="ltx_para">
<p id="Sx2.I1.ix53.p1.1" class="ltx_p">Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?</p>
</div>
</li>
<li id="Sx2.I1.ix54" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix54.p1" class="ltx_para">
<p id="Sx2.I1.ix54.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix54.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix55" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix55.p1" class="ltx_para">
<p id="Sx2.I1.ix55.p1.1" class="ltx_p">Justification: Section <a href="#A4" title="Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a> contains the instructions provided to human subjects, ensuring transparency in the experimental process. Notably, screenshots are not applicable, and there was no compensation involved.</p>
</div>
</li>
<li id="Sx2.I1.ix56" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix56.p1" class="ltx_para">
<p id="Sx2.I1.ix56.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix56.I1" class="ltx_itemize">
<li id="Sx2.I1.ix56.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix56.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix56.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.</p>
</div>
</li>
<li id="Sx2.I1.ix56.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix56.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix56.I1.i2.p1.1" class="ltx_p">Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.</p>
</div>
</li>
<li id="Sx2.I1.ix56.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix56.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix56.I1.i3.p1.1" class="ltx_p">According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="Sx2.I1.i15" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">15.</span> 
<div id="Sx2.I1.i15.p1" class="ltx_para">
<p id="Sx2.I1.i15.p1.1" class="ltx_p"><span id="Sx2.I1.i15.p1.1.1" class="ltx_text ltx_font_bold">Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects</span></p>
</div>
</li>
<li id="Sx2.I1.ix57" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix57.p1" class="ltx_para">
<p id="Sx2.I1.ix57.p1.1" class="ltx_p">Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?</p>
</div>
</li>
<li id="Sx2.I1.ix58" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix58.p1" class="ltx_para">
<p id="Sx2.I1.ix58.p1.1" class="ltx_p">Answer: <span id="Sx2.I1.ix58.p1.1.1" class="ltx_text" style="color:#0000FF;">[Yes] </span></p>
</div>
</li>
<li id="Sx2.I1.ix59" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix59.p1" class="ltx_para">
<p id="Sx2.I1.ix59.p1.1" class="ltx_p">Justification: As the study did not pose any risks to the subjects, there was no need for risk disclosure. Furthermore, Institutional Review Board (IRB) approvals or equivalent safeguards were not required for this research.</p>
</div>
</li>
<li id="Sx2.I1.ix60" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"></span>
<div id="Sx2.I1.ix60.p1" class="ltx_para">
<p id="Sx2.I1.ix60.p1.1" class="ltx_p">Guidelines:</p>
<ul id="Sx2.I1.ix60.I1" class="ltx_itemize">
<li id="Sx2.I1.ix60.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix60.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.ix60.I1.i1.p1.1" class="ltx_p">The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.</p>
</div>
</li>
<li id="Sx2.I1.ix60.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix60.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.ix60.I1.i2.p1.1" class="ltx_p">Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.</p>
</div>
</li>
<li id="Sx2.I1.ix60.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix60.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.ix60.I1.i3.p1.1" class="ltx_p">We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.</p>
</div>
</li>
<li id="Sx2.I1.ix60.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I1.ix60.I1.i4.p1" class="ltx_para">
<p id="Sx2.I1.ix60.I1.i4.p1.1" class="ltx_p">For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.</p>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Extended Discussion of Related Works</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Recent advancements in speech recognition and synthesis techniques have led to numerous projects developing systems for the Persian language. Each project comes with its own dataset, each having unique advantages and limitations. This section provides a comprehensive review of Persian speech datasets paired with their corresponding transcripts, detailing their respective merits and drawbacks.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p">Our analysis encompasses a diverse range of Persian datasets, including text-to-speech (TTS) datasets (Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), automatic speech recognition (ASR) datasets, audio-visual speech recognition (AVSR) datasets tailored for Persian, a dataset specifically designed for Persian phoneme recognition (PR), a Persian spoken digit recognition (DR) dataset, and multilingual datasets incorporating Persian language components (Table <a href="#A1.T3" title="Table 3 ‣ Appendix A Extended Discussion of Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). While our primary focus and discussions in this section center around Persian speech corpora for text-to-speech systems, we have also included notable English TTS speech datasets for a comprehensive comparison (Table <a href="#A1.T4" title="Table 4 ‣ Appendix A Extended Discussion of Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T3.48.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="A1.T3.49.2" class="ltx_text ltx_font_bold" style="font-size:90%;">List of other Persian datasets including speech and text.<span id="A1.T3.49.2.1" class="ltx_text ltx_font_medium"> The datasets indicated by a plus sign are multilingual, but only the information for the Persian part is shown. </span>Size<span id="A1.T3.49.2.2" class="ltx_text ltx_font_medium"> shows the duration in hours, </span>Spks.<span id="A1.T3.49.2.3" class="ltx_text ltx_font_medium"> stands for the number of speakers, and the columns </span>N.T.<span id="A1.T3.49.2.4" class="ltx_text ltx_font_medium"> and </span>N.A.<span id="A1.T3.49.2.5" class="ltx_text ltx_font_medium"> abbreviate Natural Text and Natural Audio as in Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. </span>Comm.<span id="A1.T3.49.2.6" class="ltx_text ltx_font_medium"> stands for a commercial license.</span></span></figcaption>
<table id="A1.T3.40" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T3.40.41.1" class="ltx_tr">
<td id="A1.T3.40.41.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T3.40.41.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="A1.T3.40.41.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T3.40.41.1.2.1" class="ltx_text ltx_font_bold">Usage</span></td>
<td id="A1.T3.40.41.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T3.40.41.1.3.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="A1.T3.40.41.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T3.40.41.1.4.1" class="ltx_text ltx_font_bold">Spks.</span></td>
<td id="A1.T3.40.41.1.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="A1.T3.40.41.1.5.1" class="ltx_text ltx_font_bold">N.T</span>.</td>
<td id="A1.T3.40.41.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T3.40.41.1.6.1" class="ltx_text ltx_font_bold">N.A.</span></td>
<td id="A1.T3.40.41.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T3.40.41.1.7.1" class="ltx_text ltx_font_bold">Availability</span></td>
<td id="A1.T3.40.41.1.8" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T3.40.41.1.8.1" class="ltx_text ltx_font_bold">License</span></td>
</tr>
<tr id="A1.T3.2.2" class="ltx_tr">
<td id="A1.T3.2.2.3" class="ltx_td ltx_align_center ltx_border_t">DeepMine+ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="A1.T3.2.2.4" class="ltx_td ltx_align_center ltx_border_t">ASR</td>
<td id="A1.T3.2.2.5" class="ltx_td ltx_align_center ltx_border_t">+480</td>
<td id="A1.T3.2.2.6" class="ltx_td ltx_align_center ltx_border_t">+1850</td>
<td id="A1.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.1.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.1.1.1.1.1.1" class="ltx_p"><math id="A1.T3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.1.1.1.1.1.1.m1.1a"><msqrt id="A1.T3.1.1.1.1.1.1.m1.1.1" xref="A1.T3.1.1.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.1.1.1.1.1.1.m1.1.1.2" xref="A1.T3.1.1.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.1.1.m1.1b"><apply id="A1.T3.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.1.1.m1.1.1"><root id="A1.T3.1.1.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.1.1.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.1.1.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.2.2.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.2.2.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.2.2.2.1.1.1" class="ltx_p"><math id="A1.T3.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.2.2.2.1.1.1.m1.1a"><msqrt id="A1.T3.2.2.2.1.1.1.m1.1.1" xref="A1.T3.2.2.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.2.2.2.1.1.1.m1.1.1.2" xref="A1.T3.2.2.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.1.1.1.m1.1b"><apply id="A1.T3.2.2.2.1.1.1.m1.1.1.cmml" xref="A1.T3.2.2.2.1.1.1.m1.1.1"><root id="A1.T3.2.2.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.2.2.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.2.2.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.2.2.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.2.2.7" class="ltx_td ltx_align_center ltx_border_t">Paid</td>
<td id="A1.T3.2.2.8" class="ltx_td ltx_align_center ltx_border_t">Proprietary</td>
</tr>
<tr id="A1.T3.4.4" class="ltx_tr">
<td id="A1.T3.4.4.3" class="ltx_td ltx_align_center">CMU Wilderness+ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</td>
<td id="A1.T3.4.4.4" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.4.4.5" class="ltx_td ltx_align_center">5</td>
<td id="A1.T3.4.4.6" class="ltx_td ltx_align_center">1</td>
<td id="A1.T3.3.3.1" class="ltx_td ltx_align_center"><span id="A1.T3.3.3.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.3.3.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.3.3.1.1.1.1" class="ltx_p"><math id="A1.T3.3.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.3.3.1.1.1.1.m1.1a"><msqrt id="A1.T3.3.3.1.1.1.1.m1.1.1" xref="A1.T3.3.3.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.3.3.1.1.1.1.m1.1.1.2" xref="A1.T3.3.3.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.1.1.1.1.m1.1b"><apply id="A1.T3.3.3.1.1.1.1.m1.1.1.cmml" xref="A1.T3.3.3.1.1.1.1.m1.1.1"><root id="A1.T3.3.3.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.3.3.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.3.3.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.3.3.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.4.4.2" class="ltx_td ltx_align_center"><span id="A1.T3.4.4.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.4.4.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.4.4.2.1.1.1" class="ltx_p"><math id="A1.T3.4.4.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.4.4.2.1.1.1.m1.1a"><msqrt id="A1.T3.4.4.2.1.1.1.m1.1.1" xref="A1.T3.4.4.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.4.4.2.1.1.1.m1.1.1.2" xref="A1.T3.4.4.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.4.4.2.1.1.1.m1.1b"><apply id="A1.T3.4.4.2.1.1.1.m1.1.1.cmml" xref="A1.T3.4.4.2.1.1.1.m1.1.1"><root id="A1.T3.4.4.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.4.4.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.4.4.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.4.4.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.4.4.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.4.4.7" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T3.4.4.8" class="ltx_td ltx_align_center">CC-0 1.0</td>
</tr>
<tr id="A1.T3.6.6" class="ltx_tr">
<td id="A1.T3.6.6.3" class="ltx_td ltx_align_center">MLCommons+ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>
</td>
<td id="A1.T3.6.6.4" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.6.6.5" class="ltx_td ltx_align_center">327</td>
<td id="A1.T3.6.6.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.5.5.1" class="ltx_td ltx_align_center"><span id="A1.T3.5.5.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.5.5.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.5.5.1.1.1.1" class="ltx_p"><math id="A1.T3.5.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.5.5.1.1.1.1.m1.1a"><msqrt id="A1.T3.5.5.1.1.1.1.m1.1.1" xref="A1.T3.5.5.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.5.5.1.1.1.1.m1.1.1.2" xref="A1.T3.5.5.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.5.5.1.1.1.1.m1.1b"><apply id="A1.T3.5.5.1.1.1.1.m1.1.1.cmml" xref="A1.T3.5.5.1.1.1.1.m1.1.1"><root id="A1.T3.5.5.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.5.5.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.5.5.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.5.5.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.5.5.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.6.6.2" class="ltx_td ltx_align_center"><span id="A1.T3.6.6.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.6.6.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.6.6.2.1.1.1" class="ltx_p"><math id="A1.T3.6.6.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.6.6.2.1.1.1.m1.1a"><msqrt id="A1.T3.6.6.2.1.1.1.m1.1.1" xref="A1.T3.6.6.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.6.6.2.1.1.1.m1.1.1.2" xref="A1.T3.6.6.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.6.6.2.1.1.1.m1.1b"><apply id="A1.T3.6.6.2.1.1.1.m1.1.1.cmml" xref="A1.T3.6.6.2.1.1.1.m1.1.1"><root id="A1.T3.6.6.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.6.6.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.6.6.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.6.6.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.6.6.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.6.6.7" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T3.6.6.8" class="ltx_td ltx_align_center">CC BY 4.0</td>
</tr>
<tr id="A1.T3.9.9" class="ltx_tr">
<td id="A1.T3.9.9.4" class="ltx_td ltx_align_center">
<table id="A1.T3.9.9.4.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T3.9.9.4.1.1" class="ltx_tr">
<td id="A1.T3.9.9.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Speech</td>
</tr>
<tr id="A1.T3.9.9.4.1.2" class="ltx_tr">
<td id="A1.T3.9.9.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Wikimedia</td>
</tr>
</table>+ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</td>
<td id="A1.T3.9.9.5" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.7.7.1" class="ltx_td ltx_align_center">
<math id="A1.T3.7.7.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T3.7.7.1.m1.1a"><mo id="A1.T3.7.7.1.m1.1.1" xref="A1.T3.7.7.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T3.7.7.1.m1.1b"><csymbol cd="latexml" id="A1.T3.7.7.1.m1.1.1.cmml" xref="A1.T3.7.7.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.7.7.1.m1.1c">\sim</annotation></semantics></math> 0.13</td>
<td id="A1.T3.9.9.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.8.8.2" class="ltx_td ltx_align_center"><span id="A1.T3.8.8.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.8.8.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.8.8.2.1.1.1" class="ltx_p"><math id="A1.T3.8.8.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.8.8.2.1.1.1.m1.1a"><msqrt id="A1.T3.8.8.2.1.1.1.m1.1.1" xref="A1.T3.8.8.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.8.8.2.1.1.1.m1.1.1.2" xref="A1.T3.8.8.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.8.8.2.1.1.1.m1.1b"><apply id="A1.T3.8.8.2.1.1.1.m1.1.1.cmml" xref="A1.T3.8.8.2.1.1.1.m1.1.1"><root id="A1.T3.8.8.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.8.8.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.8.8.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.8.8.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.8.8.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.9.9.3" class="ltx_td ltx_align_center"><span id="A1.T3.9.9.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.9.9.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.9.9.3.1.1.1" class="ltx_p"><math id="A1.T3.9.9.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.9.9.3.1.1.1.m1.1a"><msqrt id="A1.T3.9.9.3.1.1.1.m1.1.1" xref="A1.T3.9.9.3.1.1.1.m1.1.1.cmml"><mi id="A1.T3.9.9.3.1.1.1.m1.1.1.2" xref="A1.T3.9.9.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.9.9.3.1.1.1.m1.1b"><apply id="A1.T3.9.9.3.1.1.1.m1.1.1.cmml" xref="A1.T3.9.9.3.1.1.1.m1.1.1"><root id="A1.T3.9.9.3.1.1.1.m1.1.1a.cmml" xref="A1.T3.9.9.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.9.9.3.1.1.1.m1.1.1.2.cmml" xref="A1.T3.9.9.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.9.9.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.9.9.7" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T3.9.9.8" class="ltx_td ltx_align_center">CC BY-SA</td>
</tr>
<tr id="A1.T3.12.12" class="ltx_tr">
<td id="A1.T3.12.12.4" class="ltx_td ltx_align_center">PersianSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="A1.T3.12.12.5" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.10.10.1" class="ltx_td ltx_align_center">
<math id="A1.T3.10.10.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T3.10.10.1.m1.1a"><mo id="A1.T3.10.10.1.m1.1.1" xref="A1.T3.10.10.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T3.10.10.1.m1.1b"><csymbol cd="latexml" id="A1.T3.10.10.1.m1.1.1.cmml" xref="A1.T3.10.10.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.10.10.1.m1.1c">\sim</annotation></semantics></math> 3</td>
<td id="A1.T3.12.12.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.11.11.2" class="ltx_td ltx_align_center"><span id="A1.T3.11.11.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.11.11.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.11.11.2.1.1.1" class="ltx_p"><math id="A1.T3.11.11.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.11.11.2.1.1.1.m1.1a"><msqrt id="A1.T3.11.11.2.1.1.1.m1.1.1" xref="A1.T3.11.11.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.11.11.2.1.1.1.m1.1.1.2" xref="A1.T3.11.11.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.11.11.2.1.1.1.m1.1b"><apply id="A1.T3.11.11.2.1.1.1.m1.1.1.cmml" xref="A1.T3.11.11.2.1.1.1.m1.1.1"><root id="A1.T3.11.11.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.11.11.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.11.11.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.11.11.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.11.11.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.12.12.3" class="ltx_td ltx_align_center"><span id="A1.T3.12.12.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.12.12.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.12.12.3.1.1.1" class="ltx_p"><math id="A1.T3.12.12.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.12.12.3.1.1.1.m1.1a"><msqrt id="A1.T3.12.12.3.1.1.1.m1.1.1" xref="A1.T3.12.12.3.1.1.1.m1.1.1.cmml"><mi id="A1.T3.12.12.3.1.1.1.m1.1.1.2" xref="A1.T3.12.12.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.12.12.3.1.1.1.m1.1b"><apply id="A1.T3.12.12.3.1.1.1.m1.1.1.cmml" xref="A1.T3.12.12.3.1.1.1.m1.1.1"><root id="A1.T3.12.12.3.1.1.1.m1.1.1a.cmml" xref="A1.T3.12.12.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.12.12.3.1.1.1.m1.1.1.2.cmml" xref="A1.T3.12.12.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.12.12.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.12.12.7" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T3.12.12.8" class="ltx_td ltx_align_center">MIT</td>
</tr>
<tr id="A1.T3.13.13" class="ltx_tr">
<td id="A1.T3.13.13.2" class="ltx_td ltx_align_center">PersianSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="A1.T3.13.13.3" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.13.13.1" class="ltx_td ltx_align_center">
<math id="A1.T3.13.13.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T3.13.13.1.m1.1a"><mo id="A1.T3.13.13.1.m1.1.1" xref="A1.T3.13.13.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T3.13.13.1.m1.1b"><csymbol cd="latexml" id="A1.T3.13.13.1.m1.1.1.cmml" xref="A1.T3.13.13.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.13.13.1.m1.1c">\sim</annotation></semantics></math> 86</td>
<td id="A1.T3.13.13.4" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.13.13.5" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.13.13.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.13.13.7" class="ltx_td ltx_align_center">Avail. on req.</td>
<td id="A1.T3.13.13.8" class="ltx_td ltx_align_center">MIT</td>
</tr>
<tr id="A1.T3.15.15" class="ltx_tr">
<td id="A1.T3.15.15.3" class="ltx_td ltx_align_center">Persian STT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</td>
<td id="A1.T3.15.15.4" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.15.15.5" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.15.15.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.14.14.1" class="ltx_td ltx_align_center">
<div id="A1.T3.14.14.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.6pt;height:6.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.6pt,0.0pt) scale(0.85,1.0) ;">
<p id="A1.T3.14.14.1.1.1" class="ltx_p"><math id="A1.T3.14.14.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.14.14.1.1.1.m1.1a"><mo id="A1.T3.14.14.1.1.1.m1.1.1" xref="A1.T3.14.14.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.14.14.1.1.1.m1.1b"><times id="A1.T3.14.14.1.1.1.m1.1.1.cmml" xref="A1.T3.14.14.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.14.14.1.1.1.m1.1c">\times</annotation></semantics></math></p>
</span></div>
</td>
<td id="A1.T3.15.15.2" class="ltx_td ltx_align_center"><span id="A1.T3.15.15.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.15.15.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.15.15.2.1.1.1" class="ltx_p"><math id="A1.T3.15.15.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.15.15.2.1.1.1.m1.1a"><msqrt id="A1.T3.15.15.2.1.1.1.m1.1.1" xref="A1.T3.15.15.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.15.15.2.1.1.1.m1.1.1.2" xref="A1.T3.15.15.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.15.15.2.1.1.1.m1.1b"><apply id="A1.T3.15.15.2.1.1.1.m1.1.1.cmml" xref="A1.T3.15.15.2.1.1.1.m1.1.1"><root id="A1.T3.15.15.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.15.15.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.15.15.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.15.15.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.15.15.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.15.15.7" class="ltx_td ltx_align_center">Not Avail.</td>
<td id="A1.T3.15.15.8" class="ltx_td ltx_align_center">CC BY 4.0</td>
</tr>
<tr id="A1.T3.17.17" class="ltx_tr">
<td id="A1.T3.17.17.3" class="ltx_td ltx_align_center">Small Farsdat <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="A1.T3.17.17.4" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.17.17.5" class="ltx_td ltx_align_center">5</td>
<td id="A1.T3.17.17.6" class="ltx_td ltx_align_center">300</td>
<td id="A1.T3.16.16.1" class="ltx_td ltx_align_center"><span id="A1.T3.16.16.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.16.16.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.16.16.1.1.1.1" class="ltx_p"><math id="A1.T3.16.16.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.16.16.1.1.1.1.m1.1a"><msqrt id="A1.T3.16.16.1.1.1.1.m1.1.1" xref="A1.T3.16.16.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.16.16.1.1.1.1.m1.1.1.2" xref="A1.T3.16.16.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.16.16.1.1.1.1.m1.1b"><apply id="A1.T3.16.16.1.1.1.1.m1.1.1.cmml" xref="A1.T3.16.16.1.1.1.1.m1.1.1"><root id="A1.T3.16.16.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.16.16.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.16.16.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.16.16.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.16.16.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.17.17.2" class="ltx_td ltx_align_center"><span id="A1.T3.17.17.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.17.17.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.17.17.2.1.1.1" class="ltx_p"><math id="A1.T3.17.17.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.17.17.2.1.1.1.m1.1a"><msqrt id="A1.T3.17.17.2.1.1.1.m1.1.1" xref="A1.T3.17.17.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.17.17.2.1.1.1.m1.1.1.2" xref="A1.T3.17.17.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.17.17.2.1.1.1.m1.1b"><apply id="A1.T3.17.17.2.1.1.1.m1.1.1.cmml" xref="A1.T3.17.17.2.1.1.1.m1.1.1"><root id="A1.T3.17.17.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.17.17.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.17.17.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.17.17.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.17.17.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.17.17.7" class="ltx_td ltx_align_center">Paid</td>
<td id="A1.T3.17.17.8" class="ltx_td ltx_align_center">
<table id="A1.T3.17.17.8.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T3.17.17.8.1.1" class="ltx_tr">
<td id="A1.T3.17.17.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Non comm.</td>
</tr>
<tr id="A1.T3.17.17.8.1.2" class="ltx_tr">
<td id="A1.T3.17.17.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Comm.</td>
</tr>
</table>
</td>
</tr>
<tr id="A1.T3.20.20" class="ltx_tr">
<td id="A1.T3.20.20.4" class="ltx_td ltx_align_center">Large Farsdat <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>
</td>
<td id="A1.T3.20.20.5" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.18.18.1" class="ltx_td ltx_align_center">
<math id="A1.T3.18.18.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T3.18.18.1.m1.1a"><mo id="A1.T3.18.18.1.m1.1.1" xref="A1.T3.18.18.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T3.18.18.1.m1.1b"><csymbol cd="latexml" id="A1.T3.18.18.1.m1.1.1.cmml" xref="A1.T3.18.18.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.18.18.1.m1.1c">\sim</annotation></semantics></math> 73</td>
<td id="A1.T3.20.20.6" class="ltx_td ltx_align_center">100</td>
<td id="A1.T3.19.19.2" class="ltx_td ltx_align_center"><span id="A1.T3.19.19.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.19.19.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.19.19.2.1.1.1" class="ltx_p"><math id="A1.T3.19.19.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.19.19.2.1.1.1.m1.1a"><msqrt id="A1.T3.19.19.2.1.1.1.m1.1.1" xref="A1.T3.19.19.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.19.19.2.1.1.1.m1.1.1.2" xref="A1.T3.19.19.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.19.19.2.1.1.1.m1.1b"><apply id="A1.T3.19.19.2.1.1.1.m1.1.1.cmml" xref="A1.T3.19.19.2.1.1.1.m1.1.1"><root id="A1.T3.19.19.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.19.19.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.19.19.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.19.19.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.19.19.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.20.20.3" class="ltx_td ltx_align_center"><span id="A1.T3.20.20.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.20.20.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.20.20.3.1.1.1" class="ltx_p"><math id="A1.T3.20.20.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.20.20.3.1.1.1.m1.1a"><msqrt id="A1.T3.20.20.3.1.1.1.m1.1.1" xref="A1.T3.20.20.3.1.1.1.m1.1.1.cmml"><mi id="A1.T3.20.20.3.1.1.1.m1.1.1.2" xref="A1.T3.20.20.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.20.20.3.1.1.1.m1.1b"><apply id="A1.T3.20.20.3.1.1.1.m1.1.1.cmml" xref="A1.T3.20.20.3.1.1.1.m1.1.1"><root id="A1.T3.20.20.3.1.1.1.m1.1.1a.cmml" xref="A1.T3.20.20.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.20.20.3.1.1.1.m1.1.1.2.cmml" xref="A1.T3.20.20.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.20.20.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.20.20.7" class="ltx_td ltx_align_center">Paid</td>
<td id="A1.T3.20.20.8" class="ltx_td ltx_align_center">
<table id="A1.T3.20.20.8.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T3.20.20.8.1.1" class="ltx_tr">
<td id="A1.T3.20.20.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Non comm.</td>
</tr>
<tr id="A1.T3.20.20.8.1.2" class="ltx_tr">
<td id="A1.T3.20.20.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Comm.</td>
</tr>
</table>
</td>
</tr>
<tr id="A1.T3.22.22" class="ltx_tr">
<td id="A1.T3.22.22.3" class="ltx_td ltx_align_center">ASR Farsi <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="A1.T3.22.22.4" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.22.22.5" class="ltx_td ltx_align_center">+300</td>
<td id="A1.T3.22.22.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.21.21.1" class="ltx_td ltx_align_center"><span id="A1.T3.21.21.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.21.21.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.21.21.1.1.1.1" class="ltx_p"><math id="A1.T3.21.21.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.21.21.1.1.1.1.m1.1a"><msqrt id="A1.T3.21.21.1.1.1.1.m1.1.1" xref="A1.T3.21.21.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.21.21.1.1.1.1.m1.1.1.2" xref="A1.T3.21.21.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.21.21.1.1.1.1.m1.1b"><apply id="A1.T3.21.21.1.1.1.1.m1.1.1.cmml" xref="A1.T3.21.21.1.1.1.1.m1.1.1"><root id="A1.T3.21.21.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.21.21.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.21.21.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.21.21.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.21.21.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.22.22.2" class="ltx_td ltx_align_center"><span id="A1.T3.22.22.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.22.22.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.22.22.2.1.1.1" class="ltx_p"><math id="A1.T3.22.22.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.22.22.2.1.1.1.m1.1a"><msqrt id="A1.T3.22.22.2.1.1.1.m1.1.1" xref="A1.T3.22.22.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.22.22.2.1.1.1.m1.1.1.2" xref="A1.T3.22.22.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.22.22.2.1.1.1.m1.1b"><apply id="A1.T3.22.22.2.1.1.1.m1.1.1.cmml" xref="A1.T3.22.22.2.1.1.1.m1.1.1"><root id="A1.T3.22.22.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.22.22.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.22.22.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.22.22.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.22.22.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.22.22.7" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T3.22.22.8" class="ltx_td ltx_align_center">CC-0 1.0</td>
</tr>
<tr id="A1.T3.24.24" class="ltx_tr">
<td id="A1.T3.24.24.3" class="ltx_td ltx_align_center">CommonVoice+ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="A1.T3.24.24.4" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.24.24.5" class="ltx_td ltx_align_center">416</td>
<td id="A1.T3.24.24.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.23.23.1" class="ltx_td ltx_align_center"><span id="A1.T3.23.23.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.23.23.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.23.23.1.1.1.1" class="ltx_p"><math id="A1.T3.23.23.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.23.23.1.1.1.1.m1.1a"><msqrt id="A1.T3.23.23.1.1.1.1.m1.1.1" xref="A1.T3.23.23.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.23.23.1.1.1.1.m1.1.1.2" xref="A1.T3.23.23.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.23.23.1.1.1.1.m1.1b"><apply id="A1.T3.23.23.1.1.1.1.m1.1.1.cmml" xref="A1.T3.23.23.1.1.1.1.m1.1.1"><root id="A1.T3.23.23.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.23.23.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.23.23.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.23.23.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.23.23.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.24.24.2" class="ltx_td ltx_align_center"><span id="A1.T3.24.24.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.24.24.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.24.24.2.1.1.1" class="ltx_p"><math id="A1.T3.24.24.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.24.24.2.1.1.1.m1.1a"><msqrt id="A1.T3.24.24.2.1.1.1.m1.1.1" xref="A1.T3.24.24.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.24.24.2.1.1.1.m1.1.1.2" xref="A1.T3.24.24.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.24.24.2.1.1.1.m1.1b"><apply id="A1.T3.24.24.2.1.1.1.m1.1.1.cmml" xref="A1.T3.24.24.2.1.1.1.m1.1.1"><root id="A1.T3.24.24.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.24.24.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.24.24.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.24.24.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.24.24.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.24.24.7" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T3.24.24.8" class="ltx_td ltx_align_center">CC-0 1.0</td>
</tr>
<tr id="A1.T3.26.26" class="ltx_tr">
<td id="A1.T3.26.26.3" class="ltx_td ltx_align_center">FarsSpon <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>
</td>
<td id="A1.T3.26.26.4" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.26.26.5" class="ltx_td ltx_align_center">+530</td>
<td id="A1.T3.26.26.6" class="ltx_td ltx_align_center">+5300</td>
<td id="A1.T3.25.25.1" class="ltx_td ltx_align_center"><span id="A1.T3.25.25.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.25.25.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.25.25.1.1.1.1" class="ltx_p"><math id="A1.T3.25.25.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.25.25.1.1.1.1.m1.1a"><msqrt id="A1.T3.25.25.1.1.1.1.m1.1.1" xref="A1.T3.25.25.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.25.25.1.1.1.1.m1.1.1.2" xref="A1.T3.25.25.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.25.25.1.1.1.1.m1.1b"><apply id="A1.T3.25.25.1.1.1.1.m1.1.1.cmml" xref="A1.T3.25.25.1.1.1.1.m1.1.1"><root id="A1.T3.25.25.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.25.25.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.25.25.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.25.25.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.25.25.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.26.26.2" class="ltx_td ltx_align_center"><span id="A1.T3.26.26.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.26.26.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.26.26.2.1.1.1" class="ltx_p"><math id="A1.T3.26.26.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.26.26.2.1.1.1.m1.1a"><msqrt id="A1.T3.26.26.2.1.1.1.m1.1.1" xref="A1.T3.26.26.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.26.26.2.1.1.1.m1.1.1.2" xref="A1.T3.26.26.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.26.26.2.1.1.1.m1.1b"><apply id="A1.T3.26.26.2.1.1.1.m1.1.1.cmml" xref="A1.T3.26.26.2.1.1.1.m1.1.1"><root id="A1.T3.26.26.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.26.26.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.26.26.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.26.26.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.26.26.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.26.26.7" class="ltx_td ltx_align_center">Paid</td>
<td id="A1.T3.26.26.8" class="ltx_td ltx_align_center">Proprietary</td>
</tr>
<tr id="A1.T3.29.29" class="ltx_tr">
<td id="A1.T3.29.29.4" class="ltx_td ltx_align_center">Shenasa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>
</td>
<td id="A1.T3.29.29.5" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.27.27.1" class="ltx_td ltx_align_center">
<math id="A1.T3.27.27.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T3.27.27.1.m1.1a"><mo id="A1.T3.27.27.1.m1.1.1" xref="A1.T3.27.27.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T3.27.27.1.m1.1b"><csymbol cd="latexml" id="A1.T3.27.27.1.m1.1.1.cmml" xref="A1.T3.27.27.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.27.27.1.m1.1c">\sim</annotation></semantics></math>300</td>
<td id="A1.T3.29.29.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.28.28.2" class="ltx_td ltx_align_center"><span id="A1.T3.28.28.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.28.28.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.28.28.2.1.1.1" class="ltx_p"><math id="A1.T3.28.28.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.28.28.2.1.1.1.m1.1a"><msqrt id="A1.T3.28.28.2.1.1.1.m1.1.1" xref="A1.T3.28.28.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.28.28.2.1.1.1.m1.1.1.2" xref="A1.T3.28.28.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.28.28.2.1.1.1.m1.1b"><apply id="A1.T3.28.28.2.1.1.1.m1.1.1.cmml" xref="A1.T3.28.28.2.1.1.1.m1.1.1"><root id="A1.T3.28.28.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.28.28.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.28.28.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.28.28.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.28.28.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.29.29.3" class="ltx_td ltx_align_center"><span id="A1.T3.29.29.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.29.29.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.29.29.3.1.1.1" class="ltx_p"><math id="A1.T3.29.29.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.29.29.3.1.1.1.m1.1a"><msqrt id="A1.T3.29.29.3.1.1.1.m1.1.1" xref="A1.T3.29.29.3.1.1.1.m1.1.1.cmml"><mi id="A1.T3.29.29.3.1.1.1.m1.1.1.2" xref="A1.T3.29.29.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.29.29.3.1.1.1.m1.1b"><apply id="A1.T3.29.29.3.1.1.1.m1.1.1.cmml" xref="A1.T3.29.29.3.1.1.1.m1.1.1"><root id="A1.T3.29.29.3.1.1.1.m1.1.1a.cmml" xref="A1.T3.29.29.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.29.29.3.1.1.1.m1.1.1.2.cmml" xref="A1.T3.29.29.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.29.29.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.29.29.7" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T3.29.29.8" class="ltx_td ltx_align_center">GPL-3.0</td>
</tr>
<tr id="A1.T3.31.31" class="ltx_tr">
<td id="A1.T3.31.31.3" class="ltx_td ltx_align_center">Persian-SR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>
</td>
<td id="A1.T3.31.31.4" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T3.31.31.5" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.31.31.6" class="ltx_td ltx_align_center">-</td>
<td id="A1.T3.30.30.1" class="ltx_td ltx_align_center"><span id="A1.T3.30.30.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.30.30.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.30.30.1.1.1.1" class="ltx_p"><math id="A1.T3.30.30.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.30.30.1.1.1.1.m1.1a"><msqrt id="A1.T3.30.30.1.1.1.1.m1.1.1" xref="A1.T3.30.30.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.30.30.1.1.1.1.m1.1.1.2" xref="A1.T3.30.30.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.30.30.1.1.1.1.m1.1b"><apply id="A1.T3.30.30.1.1.1.1.m1.1.1.cmml" xref="A1.T3.30.30.1.1.1.1.m1.1.1"><root id="A1.T3.30.30.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.30.30.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.30.30.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.30.30.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.30.30.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.31.31.2" class="ltx_td ltx_align_center"><span id="A1.T3.31.31.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.31.31.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.31.31.2.1.1.1" class="ltx_p"><math id="A1.T3.31.31.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.31.31.2.1.1.1.m1.1a"><msqrt id="A1.T3.31.31.2.1.1.1.m1.1.1" xref="A1.T3.31.31.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.31.31.2.1.1.1.m1.1.1.2" xref="A1.T3.31.31.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.31.31.2.1.1.1.m1.1b"><apply id="A1.T3.31.31.2.1.1.1.m1.1.1.cmml" xref="A1.T3.31.31.2.1.1.1.m1.1.1"><root id="A1.T3.31.31.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.31.31.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.31.31.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.31.31.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.31.31.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.31.31.7" class="ltx_td ltx_align_center">Avail. on req.</td>
<td id="A1.T3.31.31.8" class="ltx_td ltx_align_center">MIT</td>
</tr>
<tr id="A1.T3.33.33" class="ltx_tr">
<td id="A1.T3.33.33.3" class="ltx_td ltx_align_center">Arman AV <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
<td id="A1.T3.33.33.4" class="ltx_td ltx_align_center">AVSR</td>
<td id="A1.T3.33.33.5" class="ltx_td ltx_align_center">220</td>
<td id="A1.T3.33.33.6" class="ltx_td ltx_align_center">1760</td>
<td id="A1.T3.32.32.1" class="ltx_td ltx_align_center"><span id="A1.T3.32.32.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.32.32.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.32.32.1.1.1.1" class="ltx_p"><math id="A1.T3.32.32.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.32.32.1.1.1.1.m1.1a"><msqrt id="A1.T3.32.32.1.1.1.1.m1.1.1" xref="A1.T3.32.32.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.32.32.1.1.1.1.m1.1.1.2" xref="A1.T3.32.32.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.32.32.1.1.1.1.m1.1b"><apply id="A1.T3.32.32.1.1.1.1.m1.1.1.cmml" xref="A1.T3.32.32.1.1.1.1.m1.1.1"><root id="A1.T3.32.32.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.32.32.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.32.32.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.32.32.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.32.32.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.33.33.2" class="ltx_td ltx_align_center"><span id="A1.T3.33.33.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.33.33.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.33.33.2.1.1.1" class="ltx_p"><math id="A1.T3.33.33.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.33.33.2.1.1.1.m1.1a"><msqrt id="A1.T3.33.33.2.1.1.1.m1.1.1" xref="A1.T3.33.33.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.33.33.2.1.1.1.m1.1.1.2" xref="A1.T3.33.33.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.33.33.2.1.1.1.m1.1b"><apply id="A1.T3.33.33.2.1.1.1.m1.1.1.cmml" xref="A1.T3.33.33.2.1.1.1.m1.1.1"><root id="A1.T3.33.33.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.33.33.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.33.33.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.33.33.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.33.33.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.33.33.7" class="ltx_td ltx_align_center">Avail. on req.</td>
<td id="A1.T3.33.33.8" class="ltx_td ltx_align_center">Proprietary</td>
</tr>
<tr id="A1.T3.35.35" class="ltx_tr">
<td id="A1.T3.35.35.3" class="ltx_td ltx_align_center">PLRW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>
</td>
<td id="A1.T3.35.35.4" class="ltx_td ltx_align_center">AVSR</td>
<td id="A1.T3.35.35.5" class="ltx_td ltx_align_center">30</td>
<td id="A1.T3.35.35.6" class="ltx_td ltx_align_center">1800</td>
<td id="A1.T3.34.34.1" class="ltx_td ltx_align_center">
<div id="A1.T3.34.34.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.6pt;height:6.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.6pt,0.0pt) scale(0.85,1.0) ;">
<p id="A1.T3.34.34.1.1.1" class="ltx_p"><math id="A1.T3.34.34.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.T3.34.34.1.1.1.m1.1a"><mo id="A1.T3.34.34.1.1.1.m1.1.1" xref="A1.T3.34.34.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.T3.34.34.1.1.1.m1.1b"><times id="A1.T3.34.34.1.1.1.m1.1.1.cmml" xref="A1.T3.34.34.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.34.34.1.1.1.m1.1c">\times</annotation></semantics></math></p>
</span></div>
</td>
<td id="A1.T3.35.35.2" class="ltx_td ltx_align_center"><span id="A1.T3.35.35.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.35.35.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.35.35.2.1.1.1" class="ltx_p"><math id="A1.T3.35.35.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.35.35.2.1.1.1.m1.1a"><msqrt id="A1.T3.35.35.2.1.1.1.m1.1.1" xref="A1.T3.35.35.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.35.35.2.1.1.1.m1.1.1.2" xref="A1.T3.35.35.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.35.35.2.1.1.1.m1.1b"><apply id="A1.T3.35.35.2.1.1.1.m1.1.1.cmml" xref="A1.T3.35.35.2.1.1.1.m1.1.1"><root id="A1.T3.35.35.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.35.35.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.35.35.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.35.35.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.35.35.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.35.35.7" class="ltx_td ltx_align_center">Not Avail.</td>
<td id="A1.T3.35.35.8" class="ltx_td ltx_align_center">CC BY 4.0</td>
</tr>
<tr id="A1.T3.38.38" class="ltx_tr">
<td id="A1.T3.38.38.4" class="ltx_td ltx_align_center">PCVC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="A1.T3.38.38.5" class="ltx_td ltx_align_center">PR</td>
<td id="A1.T3.36.36.1" class="ltx_td ltx_align_center">
<math id="A1.T3.36.36.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="A1.T3.36.36.1.m1.1a"><mo id="A1.T3.36.36.1.m1.1.1" xref="A1.T3.36.36.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A1.T3.36.36.1.m1.1b"><csymbol cd="latexml" id="A1.T3.36.36.1.m1.1.1.cmml" xref="A1.T3.36.36.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.36.36.1.m1.1c">\sim</annotation></semantics></math> 1</td>
<td id="A1.T3.38.38.6" class="ltx_td ltx_align_center">12</td>
<td id="A1.T3.37.37.2" class="ltx_td ltx_align_center"><span id="A1.T3.37.37.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.37.37.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.37.37.2.1.1.1" class="ltx_p"><math id="A1.T3.37.37.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.37.37.2.1.1.1.m1.1a"><msqrt id="A1.T3.37.37.2.1.1.1.m1.1.1" xref="A1.T3.37.37.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.37.37.2.1.1.1.m1.1.1.2" xref="A1.T3.37.37.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.37.37.2.1.1.1.m1.1b"><apply id="A1.T3.37.37.2.1.1.1.m1.1.1.cmml" xref="A1.T3.37.37.2.1.1.1.m1.1.1"><root id="A1.T3.37.37.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.37.37.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.37.37.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.37.37.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.37.37.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.38.38.3" class="ltx_td ltx_align_center"><span id="A1.T3.38.38.3.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.38.38.3.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.38.38.3.1.1.1" class="ltx_p"><math id="A1.T3.38.38.3.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.38.38.3.1.1.1.m1.1a"><msqrt id="A1.T3.38.38.3.1.1.1.m1.1.1" xref="A1.T3.38.38.3.1.1.1.m1.1.1.cmml"><mi id="A1.T3.38.38.3.1.1.1.m1.1.1.2" xref="A1.T3.38.38.3.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.38.38.3.1.1.1.m1.1b"><apply id="A1.T3.38.38.3.1.1.1.m1.1.1.cmml" xref="A1.T3.38.38.3.1.1.1.m1.1.1"><root id="A1.T3.38.38.3.1.1.1.m1.1.1a.cmml" xref="A1.T3.38.38.3.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.38.38.3.1.1.1.m1.1.1.2.cmml" xref="A1.T3.38.38.3.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.38.38.3.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.38.38.7" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T3.38.38.8" class="ltx_td ltx_align_center">GPL-3.0</td>
</tr>
<tr id="A1.T3.40.40" class="ltx_tr">
<td id="A1.T3.40.40.3" class="ltx_td ltx_align_center ltx_border_bb">PSDR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>
</td>
<td id="A1.T3.40.40.4" class="ltx_td ltx_align_center ltx_border_bb">DR</td>
<td id="A1.T3.40.40.5" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="A1.T3.40.40.6" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="A1.T3.39.39.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T3.39.39.1.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.39.39.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.39.39.1.1.1.1" class="ltx_p"><math id="A1.T3.39.39.1.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.39.39.1.1.1.1.m1.1a"><msqrt id="A1.T3.39.39.1.1.1.1.m1.1.1" xref="A1.T3.39.39.1.1.1.1.m1.1.1.cmml"><mi id="A1.T3.39.39.1.1.1.1.m1.1.1.2" xref="A1.T3.39.39.1.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.39.39.1.1.1.1.m1.1b"><apply id="A1.T3.39.39.1.1.1.1.m1.1.1.cmml" xref="A1.T3.39.39.1.1.1.1.m1.1.1"><root id="A1.T3.39.39.1.1.1.1.m1.1.1a.cmml" xref="A1.T3.39.39.1.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.39.39.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.39.39.1.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.39.39.1.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.40.40.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T3.40.40.2.1" class="ltx_text" style="position:relative; bottom:2.6pt;">
<span id="A1.T3.40.40.2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:0.0pt;height:0pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(0.7,0.7) ;">
<span id="A1.T3.40.40.2.1.1.1" class="ltx_p"><math id="A1.T3.40.40.2.1.1.1.m1.1" class="ltx_Math" alttext="\sqrt{}" display="inline"><semantics id="A1.T3.40.40.2.1.1.1.m1.1a"><msqrt id="A1.T3.40.40.2.1.1.1.m1.1.1" xref="A1.T3.40.40.2.1.1.1.m1.1.1.cmml"><mi id="A1.T3.40.40.2.1.1.1.m1.1.1.2" xref="A1.T3.40.40.2.1.1.1.m1.1.1.2.cmml"></mi></msqrt><annotation-xml encoding="MathML-Content" id="A1.T3.40.40.2.1.1.1.m1.1b"><apply id="A1.T3.40.40.2.1.1.1.m1.1.1.cmml" xref="A1.T3.40.40.2.1.1.1.m1.1.1"><root id="A1.T3.40.40.2.1.1.1.m1.1.1a.cmml" xref="A1.T3.40.40.2.1.1.1.m1.1.1"></root><csymbol cd="latexml" id="A1.T3.40.40.2.1.1.1.m1.1.1.2.cmml" xref="A1.T3.40.40.2.1.1.1.m1.1.1.2">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.40.40.2.1.1.1.m1.1c">\sqrt{}</annotation></semantics></math></span>
</span></span></span></td>
<td id="A1.T3.40.40.7" class="ltx_td ltx_align_center ltx_border_bb">Avail.</td>
<td id="A1.T3.40.40.8" class="ltx_td ltx_align_center ltx_border_bb">GPL-3.0</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T4.5.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="A1.T4.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">List of well-known English datasets including speech and text.<span id="A1.T4.6.2.1" class="ltx_text ltx_font_medium"> </span>Size<span id="A1.T4.6.2.2" class="ltx_text ltx_font_medium"> indicates the duration in hours, and </span>Non comm.<span id="A1.T4.6.2.3" class="ltx_text ltx_font_medium"> stands for a non-commercial license.</span></span></figcaption>
<table id="A1.T4.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T4.7.1.1" class="ltx_tr">
<th id="A1.T4.7.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.7.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="A1.T4.7.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.7.1.1.2.1" class="ltx_text ltx_font_bold">Usage</span></th>
<th id="A1.T4.7.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.7.1.1.3.1" class="ltx_text ltx_font_bold">Size</span></th>
<th id="A1.T4.7.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.7.1.1.4.1" class="ltx_text ltx_font_bold">Speakers</span></th>
<th id="A1.T4.7.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.7.1.1.5.1" class="ltx_text ltx_font_bold">Availability</span></th>
<th id="A1.T4.7.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A1.T4.7.1.1.6.1" class="ltx_text ltx_font_bold">License</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T4.7.2.1" class="ltx_tr">
<td id="A1.T4.7.2.1.1" class="ltx_td ltx_align_center ltx_border_t">Hi-Fi TTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>
</td>
<td id="A1.T4.7.2.1.2" class="ltx_td ltx_align_center ltx_border_t">TTS</td>
<td id="A1.T4.7.2.1.3" class="ltx_td ltx_align_center ltx_border_t">292</td>
<td id="A1.T4.7.2.1.4" class="ltx_td ltx_align_center ltx_border_t">10</td>
<td id="A1.T4.7.2.1.5" class="ltx_td ltx_align_center ltx_border_t">Avail.</td>
<td id="A1.T4.7.2.1.6" class="ltx_td ltx_align_center ltx_border_t">CC BY 4.0</td>
</tr>
<tr id="A1.T4.7.3.2" class="ltx_tr">
<td id="A1.T4.7.3.2.1" class="ltx_td ltx_align_center">Libri TTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="A1.T4.7.3.2.2" class="ltx_td ltx_align_center">TTS</td>
<td id="A1.T4.7.3.2.3" class="ltx_td ltx_align_center">585</td>
<td id="A1.T4.7.3.2.4" class="ltx_td ltx_align_center">2456</td>
<td id="A1.T4.7.3.2.5" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T4.7.3.2.6" class="ltx_td ltx_align_center">CC BY 4.0</td>
</tr>
<tr id="A1.T4.7.4.3" class="ltx_tr">
<td id="A1.T4.7.4.3.1" class="ltx_td ltx_align_center">BC2013 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="A1.T4.7.4.3.2" class="ltx_td ltx_align_center">TTS</td>
<td id="A1.T4.7.4.3.3" class="ltx_td ltx_align_center">300</td>
<td id="A1.T4.7.4.3.4" class="ltx_td ltx_align_center">1</td>
<td id="A1.T4.7.4.3.5" class="ltx_td ltx_align_center">Avail. on req.</td>
<td id="A1.T4.7.4.3.6" class="ltx_td ltx_align_center">Non comm.</td>
</tr>
<tr id="A1.T4.7.5.4" class="ltx_tr">
<td id="A1.T4.7.5.4.1" class="ltx_td ltx_align_center">VCTK <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>
</td>
<td id="A1.T4.7.5.4.2" class="ltx_td ltx_align_center">TTS</td>
<td id="A1.T4.7.5.4.3" class="ltx_td ltx_align_center">44</td>
<td id="A1.T4.7.5.4.4" class="ltx_td ltx_align_center">109</td>
<td id="A1.T4.7.5.4.5" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T4.7.5.4.6" class="ltx_td ltx_align_center">ODC-BY v1.0</td>
</tr>
<tr id="A1.T4.7.6.5" class="ltx_tr">
<td id="A1.T4.7.6.5.1" class="ltx_td ltx_align_center">LibriSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>
</td>
<td id="A1.T4.7.6.5.2" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T4.7.6.5.3" class="ltx_td ltx_align_center">982</td>
<td id="A1.T4.7.6.5.4" class="ltx_td ltx_align_center">2484</td>
<td id="A1.T4.7.6.5.5" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T4.7.6.5.6" class="ltx_td ltx_align_center">CC BY 4.0</td>
</tr>
<tr id="A1.T4.7.7.6" class="ltx_tr">
<td id="A1.T4.7.7.6.1" class="ltx_td ltx_align_center">People’s Speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>
</td>
<td id="A1.T4.7.7.6.2" class="ltx_td ltx_align_center">ASR</td>
<td id="A1.T4.7.7.6.3" class="ltx_td ltx_align_center">30k</td>
<td id="A1.T4.7.7.6.4" class="ltx_td ltx_align_center">-</td>
<td id="A1.T4.7.7.6.5" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T4.7.7.6.6" class="ltx_td ltx_align_center">CC BY-SA</td>
</tr>
<tr id="A1.T4.7.8.7" class="ltx_tr">
<td id="A1.T4.7.8.7.1" class="ltx_td ltx_align_center">RyanSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
<td id="A1.T4.7.8.7.2" class="ltx_td ltx_align_center">ASR/TTS</td>
<td id="A1.T4.7.8.7.3" class="ltx_td ltx_align_center">10</td>
<td id="A1.T4.7.8.7.4" class="ltx_td ltx_align_center">1</td>
<td id="A1.T4.7.8.7.5" class="ltx_td ltx_align_center">Avail. on req.</td>
<td id="A1.T4.7.8.7.6" class="ltx_td ltx_align_center">CC BY 4.0</td>
</tr>
<tr id="A1.T4.7.9.8" class="ltx_tr">
<td id="A1.T4.7.9.8.1" class="ltx_td ltx_align_center">LJSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>
</td>
<td id="A1.T4.7.9.8.2" class="ltx_td ltx_align_center">ASR/TTS</td>
<td id="A1.T4.7.9.8.3" class="ltx_td ltx_align_center">24</td>
<td id="A1.T4.7.9.8.4" class="ltx_td ltx_align_center">1</td>
<td id="A1.T4.7.9.8.5" class="ltx_td ltx_align_center">Avail.</td>
<td id="A1.T4.7.9.8.6" class="ltx_td ltx_align_center">CC-0 1.0</td>
</tr>
<tr id="A1.T4.7.10.9" class="ltx_tr">
<td id="A1.T4.7.10.9.1" class="ltx_td ltx_align_center ltx_border_bb">MAILABS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</td>
<td id="A1.T4.7.10.9.2" class="ltx_td ltx_align_center ltx_border_bb">ASR/TTS</td>
<td id="A1.T4.7.10.9.3" class="ltx_td ltx_align_center ltx_border_bb">75</td>
<td id="A1.T4.7.10.9.4" class="ltx_td ltx_align_center ltx_border_bb">2</td>
<td id="A1.T4.7.10.9.5" class="ltx_td ltx_align_center ltx_border_bb">Avail.</td>
<td id="A1.T4.7.10.9.6" class="ltx_td ltx_align_center ltx_border_bb">BSD</td>
</tr>
</tbody>
</table>
</figure>
<div id="A1.p3" class="ltx_para">
<p id="A1.p3.1" class="ltx_p">It is worth noting that the availability of single-speaker TTS datasets in Persian is notably limited compared to their English counterparts. Moreover, the average size of English TTS datasets significantly surpasses that of Persian datasets. This highlights a crucial gap and emphasizes the pressing need for comprehensive, single-speaker Persian datasets to drive progress in research and application development within this domain. In the subsequent part of this section, we will delve into the specifics of each Persian TTS dataset listed in Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Works ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="A1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ArmanTTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px1.p1.1" class="ltx_p">is a prominent single-speaker TTS dataset for the Persian language, comprising approximately 9 hours of audio recorded in a professional studio setting at a sampling rate of 22.05 kHz. The audio files are typically about 2.5 seconds long (with a maximum of 12.5 seconds), corresponding to approximately 5 words (and up to a maximum of 30 words), with an average signal-to-noise ratio of 25 dB. Unfortunately, this dataset has not been publicly available yet and the authors have not provided options for access upon request or specified any licensing terms for its use.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">AmerAndish <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px2.p1.1" class="ltx_p">introduced by Naderi et al., is derived from audio books read by a single female speaker. They used a set of automatic tools to read text of PDF files, remove audio noise, and remove audio clips with a different speaker. However, the task of splitting the audio to chunks and matching the chunks with some reference text was performed manually by human agents and later double checked with an ASR system to remove potential mismatches. The resulting dataset includes chunks of 1-12 seconds and summing up to 21 hours of audio and matching text. Unfortunately, the authors have not provided any means of accessing the dataset or issued a license for its use.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">persian tts dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px3.p1.1" class="ltx_p">represents another single-speaker Persian resource, featuring approximately 15.6 hours of audio. While the dataset owners have not provided a detailed description, it is evident that the audio is derived from a Persian translation of the Holy Quran. Regrettably, the owners have also not provided any licensing information for the dataset, and it remains unclear whether the audiobook and the corresponding text are free from copyright restrictions. Furthermore, the dataset’s exclusive focus on the Holy Quran means it lacks topical and lexical diversity, which is a substantial limitation for developing TTS systems that require a broad range of vocabulary and expressions to perform effectively in varied contexts.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Persian text-to-speech audio <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px4.p1.1" class="ltx_p">is a single-speaker corpus with 26 hours of content. This dataset, derived from a Persian translation of the Holy Quran, lacks a detailed description. Similarly to prior datasets, copyright details and licensing status are not provided by the dataset owners, leaving all rights reserved to the original authors.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Persian-text-to-speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px5.p1.1" class="ltx_p">details a Persian TTS model project. Researchers compiled a dataset from over 30 hours of audio sourced from commercially purchased audiobooks, narrated by a female speaker. They segmented the audio into chunks ranging from 3 to 14 seconds using silence detection, then manually aligned these chunks with their corresponding texts. Notably, the purchase of the audiobooks implies copyright restrictions, rendering the dataset non-public and unlicensed.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">persian tts dataset (female) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px6.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px6.p1.1" class="ltx_p">is a single-speaker Persian dataset under a CC-0 license, comprising 30 hours of audio synthesized from the Persian text corpus Naab <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. The dataset’s primary limitation is its fully synthesized audio content, which restricts the performance of TTS models trained on it, as they cannot reach the naturalness of human speech due to the inherent constraints of the used synthesizer.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">persian-tts-dataset-male <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px7.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px7.p1.1" class="ltx_p">unveils a CC-0 licensed, single-speaker Persian dataset, containing approximately 38 hours of audio. The dataset documentation lacks specifics regarding the source and data collection methodology. However, Initial manual analysis of several audio samples indicates that the content was synthesized using another TTS model.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px8" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Persian Speech Corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px8.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px8.p1.1" class="ltx_p">presents a Persian TTS dataset, licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Featuring recordings from a single male speaker, this corpus encompasses professionally produced studio-quality audio, but totals only 2.5 hours, which may be considered brief for extensive TTS research and development.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px9" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ParsiGoo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px9.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px9.p1.1" class="ltx_p">introduces a multi-speaker TTS dataset tailored for the Persian language, secured under the CC BY-SA 4.0 license. This collection comprises about 5 hours of audio, recorded at a sampling rate of 22.05 kHz. The dataset features four distinct speaking styles across six speakers, enhancing its diversity. However, detailed provenance of the audio sources remains unspecified. Manual examination reveals that audio from five speakers is synthesized, while recordings from the sixth speaker are authentically vocal. Regrettably, there is no information provided on the copyright status of these audio files.</p>
</div>
</section>
<section id="A1.SS0.SSS0.Px10" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">DeepMine Multi-TTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>
</h5>

<div id="A1.SS0.SSS0.Px10.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px10.p1.1" class="ltx_p">is the first large-scale multi-speaker Persian TTS dataset. It encompasses 120 hours of audio recordings sampled at a rate of 22.05 kHz, featuring contributions from 67 speakers. The dataset primarily consists of audio files obtained from a platform hosting public and freely accessible audio-books. The audio tracks have been processed manually to remove parts that included background music. The transcripts of this dataset were generated using a specific ASR system and then checked manually. The resulting chunks vary in length from 0 to 14 seconds but are mostly between 1 to 10 seconds long. Although this dataset has not been published publicly and lacks a specified license, the authors note that the data will be available on request for only research purposes.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Evaluation of ASR Models</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">As detailed in Section <a href="#S3.SS2" title="3.2 Alignment ‣ 3 Dataset Preparation ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, alignment tools necessitate the ASR models to be arranged based on their reliability. This section elucidates the process undertaken to conduct this assessment.</p>
</div>
<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>VirgoolInformal Dataset</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">To ensure a proper assessment of the ASR models, we required a dataset that had not been seen by these models during their training phase. However, many existing ASR corpora, such as CommonVoice, had been utilized in training these ASRs. Consequently, we opted to create a small, high-quality dataset sourced from a collection of text files for the evaluation process. We deliberately selected informal Persian text,<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Persian language is spoken with slight variations between formal contexts and everyday use.</span></span></span> as it likely contained fewer words familiar to the models. This approach served as a more rigorous test, evaluating the models’ ability to accurately transcribe phonemes in audio files from new domains and thus show a low CER.</p>
</div>
<div id="A2.SS1.p2" class="ltx_para">
<p id="A2.SS1.p2.1" class="ltx_p">To gather text for this dataset, we created a tool that distinguishes between formal and informal writing styles. Using this module, we then crawled the Persian blog post website, Virgool <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, and gathered a set of informal text.<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>The code for informal text detection is available at https://github.com/MahtaFetrat/Persian-Informal-Text-Detector</span></span></span> A subset of the collected text files was then recorded by a female speaker in a silent environment through different sessions.</p>
</div>
<div id="A2.SS1.p3" class="ltx_para">
<p id="A2.SS1.p3.1" class="ltx_p">The raw files of the dataset comprise 25 pairs of audio and text files from 25 informal-text posts. The total duration of the audio files is approximately 5.63 hours, with a vocabulary of 6840 unique words. The dataset is segmented into smaller audio and text chunks ranging from 2 to 12 seconds, encompassing up to about 24 words each. Similar to the entire study, this dataset is released under a CC-0 license and is accessible to the public.</p>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Dataset Processing</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">We utilized the pre-processing component as same as our ManaTTS dataset preparation pipeline to obtain clean pairs of audio and text files.
Given that the audio files in this dataset were meticulously recorded from the crawled text files without alteration, they remain an exact match. Consequently, there was no necessity for the start-end alignment process.</p>
</div>
<div id="A2.SS2.p2" class="ltx_para">
<p id="A2.SS2.p2.1" class="ltx_p">This precise correspondence also enables the use of the lighter forced alignment tool, Aeneas. The Aeneas forced alignment tool requires the text files to be split into sentences and then attempts to align the audio with the provided sentences. Therefore, we needed a sentence tokenization tool for the Persian language.</p>
</div>
<section id="A2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">B.2.1 </span>Sentence Tokenization Method</h4>

<div id="A2.SS2.SSS1.p1" class="ltx_para">
<p id="A2.SS2.SSS1.p1.1" class="ltx_p">The most widely recognized and commonly used tool for this purpose in Persian is the Hazm sentence tokenizer. However, this tool primarily tokenizes based on punctuation, which can result in some very long sentences if the original text is not well-punctuated, a common occurrence in informal text. To address this issue, we integrate a part-of-speech (POS) model into Hazm tokenizer to get a customized sentence tokenization module. This module considers multiple criteria to split the text into more coherent and independent sentences.</p>
</div>
<div id="A2.SS2.SSS1.p2" class="ltx_para">
<p id="A2.SS2.SSS1.p2.1" class="ltx_p">The sentence splitting module requires an input minimum and maximum sentence length, along with the input text string. It utilizes the Hazm sentence tokenizer to segment the text into sentences, primarily separated by punctuation marks. Subsequently, it iterates through these sentences, dividing any that exceed the specified maximum length. Conversely, the minimum parameter is employed to avoid excessively short sentence fragments.</p>
</div>
<div id="A2.SS2.SSS1.p3" class="ltx_para">
<p id="A2.SS2.SSS1.p3.1" class="ltx_p">To achieve a meaningful split, this module employs the Perpos <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> POS model to identify verbs within the text. Subsequently, it divides the string around these identified verb positions. Notably, it includes any adjacent symbols and the conjunction word ’<span id="A2.SS2.SSS1.p3.1.1" class="ltx_ERROR undefined">\tipaencoding</span>/v<span id="A2.SS2.SSS1.p3.1.2" class="ltx_ERROR undefined">\textscripta</span><span id="A2.SS2.SSS1.p3.1.3" class="ltx_ERROR undefined">\textlengthmark</span>/’ (meaning ’and’ in English) in the split with the verb. This is because symbols can influence the verb’s intonation, and the word ’<span id="A2.SS2.SSS1.p3.1.4" class="ltx_ERROR undefined">\tipaencoding</span>/v<span id="A2.SS2.SSS1.p3.1.5" class="ltx_ERROR undefined">\textscripta</span><span id="A2.SS2.SSS1.p3.1.6" class="ltx_ERROR undefined">\textlengthmark</span>/’ following the verb is typically phonetically integrated with it and pronounced as ’<span id="A2.SS2.SSS1.p3.1.7" class="ltx_ERROR undefined">\tipaencoding</span>/<span id="A2.SS2.SSS1.p3.1.8" class="ltx_ERROR undefined">\textschwa</span><span id="A2.SS2.SSS1.p3.1.9" class="ltx_ERROR undefined">\textupsilon</span>/’.</p>
</div>
<div id="A2.SS2.SSS1.p4" class="ltx_para">
<p id="A2.SS2.SSS1.p4.1" class="ltx_p">The Perpos model is also utilized to identify "Ezafe" tags. Words marked with this tag are pronounced in a manner that is linked to the preceding words. Therefore, it is not advisable to split sentences when encountering this tag, as it may result in the audio being interrupted in the middle of the vowel phoneme <span id="A2.SS2.SSS1.p4.1.1" class="ltx_ERROR undefined">\tipaencoding</span>/e/. To address this consideration during sentence splitting, the module treats a word and all its subsequent Ezafe-tagged words as a single word group while iterating over the text tokens. The complete code for the processing steps of this dataset, including the sentence tokenization module, is publicly available.<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>https://github.com/MahtaFetrat/VirgoolInformal-Speech-Dataset</span></span></span></p>
</div>
</section>
</section>
<section id="A2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Evaluation</h3>

<div id="A2.SS3.p1" class="ltx_para">
<p id="A2.SS3.p1.1" class="ltx_p">The audio-text chunks of VirgoolInformal dataset were employed to evaluate and compare the Persian ASR models. Each audio chunk underwent processing through all the ASR models, and the resulting transcripts were recorded. Following a lightweight text processing to eliminate irrelevant symbols and characters from both the hypothesis transcripts and the ground truth text, the CER between these two strings was computed. Subsequently, the average CER of each model on the dataset chunks was taken into account as the performance criterion (See the first column of Table <a href="#A2.T5" title="Table 5 ‣ B.3 Evaluation ‣ Appendix B Evaluation of ASR Models ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<figure id="A2.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Evaluation results of ASR models based on all output transcripts and transcripts after filtering out truncated instances.</figcaption>
<table id="A2.T5.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A2.T5.4.1.1" class="ltx_tr">
<th id="A2.T5.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="A2.T5.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">ASR Model</span></th>
<th id="A2.T5.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A2.T5.4.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Average CER (All Transcripts)</span></th>
<th id="A2.T5.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A2.T5.4.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Average CER (Filtered Transcripts)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A2.T5.4.2.1" class="ltx_tr">
<th id="A2.T5.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="A2.T5.4.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Vosk</span></th>
<td id="A2.T5.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T5.4.2.1.2.1" class="ltx_text" style="font-size:90%;">0.1128</span></td>
<td id="A2.T5.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T5.4.2.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.1005</span></td>
</tr>
<tr id="A2.T5.4.3.2" class="ltx_tr">
<th id="A2.T5.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A2.T5.4.3.2.1.1" class="ltx_text" style="font-size:90%;">Wav2vec-v3</span></th>
<td id="A2.T5.4.3.2.2" class="ltx_td ltx_align_center"><span id="A2.T5.4.3.2.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.1090</span></td>
<td id="A2.T5.4.3.2.3" class="ltx_td ltx_align_center"><span id="A2.T5.4.3.2.3.1" class="ltx_text" style="font-size:90%;">0.1053</span></td>
</tr>
<tr id="A2.T5.4.4.3" class="ltx_tr">
<th id="A2.T5.4.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A2.T5.4.4.3.1.1" class="ltx_text" style="font-size:90%;">Wav2vec-fa</span></th>
<td id="A2.T5.4.4.3.2" class="ltx_td ltx_align_center"><span id="A2.T5.4.4.3.2.1" class="ltx_text" style="font-size:90%;">0.1411</span></td>
<td id="A2.T5.4.4.3.3" class="ltx_td ltx_align_center"><span id="A2.T5.4.4.3.3.1" class="ltx_text" style="font-size:90%;">0.1147</span></td>
</tr>
<tr id="A2.T5.4.5.4" class="ltx_tr">
<th id="A2.T5.4.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A2.T5.4.5.4.1.1" class="ltx_text" style="font-size:90%;">Whisper-fa</span></th>
<td id="A2.T5.4.5.4.2" class="ltx_td ltx_align_center"><span id="A2.T5.4.5.4.2.1" class="ltx_text" style="font-size:90%;">0.1701</span></td>
<td id="A2.T5.4.5.4.3" class="ltx_td ltx_align_center"><span id="A2.T5.4.5.4.3.1" class="ltx_text" style="font-size:90%;">0.1616</span></td>
</tr>
<tr id="A2.T5.4.6.5" class="ltx_tr">
<th id="A2.T5.4.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="A2.T5.4.6.5.1.1" class="ltx_text" style="font-size:90%;">Hezar</span></th>
<td id="A2.T5.4.6.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="A2.T5.4.6.5.2.1" class="ltx_text" style="font-size:90%;">0.3703</span></td>
<td id="A2.T5.4.6.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A2.T5.4.6.5.3.1" class="ltx_text" style="font-size:90%;">0.3715</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="A2.SS3.p2" class="ltx_para">
<p id="A2.SS3.p2.1" class="ltx_p">It’s noteworthy that while some ASR models encountered issues with truncated transcripts, they exhibited high-quality transcripts in other instances. Additionally, the transcription module effectively filters out truncated transcripts, alleviating concerns in this regard. These observations led us to first filter out truncated transcripts by excluding those with less than 80% of the length of the ground truth text. Subsequently, we calculated the average CER of the ASR models based on the remaining outputs. This metric offers insights into the quality of output transcripts independent of truncation issues. The results of this evaluation approach are presented in the second column of Table <a href="#A2.T5" title="Table 5 ‣ B.3 Evaluation ‣ Appendix B Evaluation of ASR Models ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="A2.SS3.p3" class="ltx_para">
<p id="A2.SS3.p3.1" class="ltx_p">The first column of Table <a href="#A2.T5" title="Table 5 ‣ B.3 Evaluation ‣ Appendix B Evaluation of ASR Models ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> also illustrates the ranking of ASR models’ reliability utilized in the alignment tools, determined by evaluation results and initial experimental findings.</p>
</div>
<div id="A2.SS3.p4" class="ltx_para">
<p id="A2.SS3.p4.1" class="ltx_p">Considering metrics from the second column of Table <a href="#A2.T5" title="Table 5 ‣ B.3 Evaluation ‣ Appendix B Evaluation of ASR Models ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> as the criterion to sort ASR models based on their reliability yields surprising results. As mentioned in the main body of the paper, utilizing the Vosk model as the most reliable ASR resulted in 71.46% of the chunks being accepted with a HIGH-quality match to the ground truth text. In contrast, if we selected Wav2vec-v3 as the most reliable ASR because of its smaller CER across all the transcripts, this ratio would reduce to 55.23%. This observation shows that the non-truncated transcripts from the Vosk model were a better match to the ground truth texts, and the second metric reflects this superiority better.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Transcript Module Statistics</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">As detailed in the Transcription Module section, the typical process for aligning text with an audio chunk’s transcript unfolds as follows:</p>
</div>
<div id="A3.p2" class="ltx_para">
<ol id="A3.I1" class="ltx_enumerate">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p id="A3.I1.i1.p1.1" class="ltx_p">The audio chunk undergoes processing by all ASR models, yielding a list of transcripts.</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p id="A3.I1.i2.p1.1" class="ltx_p">Any flawed transcripts, such as those exhibiting repetitive patterns, are identified and eliminated using regular expressions.</p>
</div>
</li>
<li id="A3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I1.i3.p1" class="ltx_para">
<p id="A3.I1.i3.p1.1" class="ltx_p">The longest transcript is singled out, and any transcripts shorter than 80% of its length are discarded.</p>
</div>
</li>
<li id="A3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I1.i4.p1" class="ltx_para">
<p id="A3.I1.i4.p1.1" class="ltx_p">The remaining transcripts are arranged in order of the reliability rates assigned to the ASR models during evaluation.</p>
</div>
</li>
<li id="A3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="A3.I1.i5.p1" class="ltx_para">
<p id="A3.I1.i5.p1.1" class="ltx_p">Sequentially, the transcripts undergo search algorithms until the earliest one meets the designated CER thresholds, at which point the process halts.</p>
</div>
</li>
</ol>
</div>
<div id="A3.p3" class="ltx_para">
<p id="A3.p3.1" class="ltx_p">This method naturally leans towards utilizing the most reliable ASR for aligning audio chunks with text. As anticipated, the bulk of the chunks (96.46%, equating to 62542 chunks) are accepted by the Vosk transcript form. Figure <a href="#A3.F7" title="Figure 7 ‣ Appendix C Transcript Module Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> illustrates the acceptance ratios of the ASR models, with Vosk contributing the most and Whisper-fa the least.</p>
</div>
<figure id="A3.F7" class="ltx_figure"><img src="/html/2409.07259/assets/figs/acceptance-ratio-asr.png" id="A3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F7.3.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="A3.F7.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Acceptance Ratio by ASR Model.<span id="A3.F7.4.2.1" class="ltx_text ltx_font_medium"> The values in parentheses represent the exact number of chunks.</span></span></figcaption>
</figure>
<div id="A3.p4" class="ltx_para">
<p id="A3.p4.1" class="ltx_p">It’s intriguing to observe the effectiveness of the multiple ASR using scheme. This can be explored in two aspects, corresponding to the two strategies employed in the transcription module. Firstly, through majority voting on transcript length, and secondly, by attempting sequential transcript matching until a suitable fit is found.</p>
</div>
<div id="A3.p5" class="ltx_para">
<p id="A3.p5.1" class="ltx_p">Our primary focus lies in assessing the effectiveness of the length majority voting technique in recovering from truncated transcript errors. Upon analyzing our processed data chunks, we observed that transcripts generated by Vosk were excluded from analysis in 1646 audio segments due to their insufficient word count, possibly indicating an error in this particular ASR system. Notably, the truncation error was even more pronounced in less reliable ASRs like Whisper-fa; however, the majority voting technique effectively mitigated its impact. For a visual representation of the number and proportion of rejected transcripts due to the length filter, please refer to Figure <a href="#A3.F8" title="Figure 8 ‣ Appendix C Transcript Module Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<figure id="A3.F8" class="ltx_figure"><img src="/html/2409.07259/assets/figs/truncated-transcripts-bar-chart.png" id="A3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="236" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="A3.F8.3.2" class="ltx_text" style="font-size:90%;">Distribution of transcripts filtered out due to inadequate length.</span></figcaption>
</figure>
<div id="A3.p6" class="ltx_para">
<p id="A3.p6.1" class="ltx_p">Next, our aim is to assess whether alignment with alternative transcripts contributed to some audio chunks being successfully matched. Table <a href="#A3.T6" title="Table 6 ‣ Appendix C Transcript Module Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> presents the number of transcripts that underwent the matching process until an audio chunk was successfully matched with the ground truth text.
It’s also worth noting that in 646 of the audio chunks, the transcript from Vosk couldn’t be matched to the ground truth text, but it was matched by the transcript from subsequent ASRs.</p>
</div>
<figure id="A3.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A3.T6.3.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="A3.T6.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Distribution of transcripts processed to match individual audio chunks.<span id="A3.T6.4.2.1" class="ltx_text ltx_font_medium"> The table shows the number of chunks aligned using different numbers of transcripts. For example, 64119 chunks were aligned using the transcript from a single ASR, 592 chunks required processing into the second transcript, and so forth.</span></span></figcaption>
<table id="A3.T6.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.T6.5.1.1" class="ltx_tr">
<td id="A3.T6.5.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="A3.T6.5.1.1.1.1" class="ltx_text ltx_font_bold">Number of Chunks</span></td>
<td id="A3.T6.5.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="A3.T6.5.1.1.2.1" class="ltx_text ltx_font_bold">Number of Processed Transcripts</span></td>
</tr>
<tr id="A3.T6.5.2.2" class="ltx_tr">
<td id="A3.T6.5.2.2.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="A3.T6.5.2.2.2" class="ltx_td ltx_align_center ltx_border_t">64119</td>
</tr>
<tr id="A3.T6.5.3.3" class="ltx_tr">
<td id="A3.T6.5.3.3.1" class="ltx_td ltx_align_center">2</td>
<td id="A3.T6.5.3.3.2" class="ltx_td ltx_align_center">592</td>
</tr>
<tr id="A3.T6.5.4.4" class="ltx_tr">
<td id="A3.T6.5.4.4.1" class="ltx_td ltx_align_center">3</td>
<td id="A3.T6.5.4.4.2" class="ltx_td ltx_align_center">74</td>
</tr>
<tr id="A3.T6.5.5.5" class="ltx_tr">
<td id="A3.T6.5.5.5.1" class="ltx_td ltx_align_center">4</td>
<td id="A3.T6.5.5.5.2" class="ltx_td ltx_align_center">39</td>
</tr>
<tr id="A3.T6.5.6.6" class="ltx_tr">
<td id="A3.T6.5.6.6.1" class="ltx_td ltx_align_center ltx_border_bb">5</td>
<td id="A3.T6.5.6.6.2" class="ltx_td ltx_align_center ltx_border_bb">10</td>
</tr>
</tbody>
</table>
</figure>
<div id="A3.p7" class="ltx_para">
<p id="A3.p7.1" class="ltx_p">Our transcription module employs a Majority of Experts (MoE) technique for forced alignment using multiple non-perfect ASR models to mitigate their individual errors. In one experiment, we aimed to assess the robustness of this forced alignment tool by determining how much error of the ASRs it could tolerate.</p>
</div>
<div id="A3.p8" class="ltx_para">
<p id="A3.p8.1" class="ltx_p">Before discussing the experiment, it’s important to note that regardless of ASR weaknesses, the quality of audio-text chunks from the pipeline remains high. This is because chunks are only accepted if they meet strict CER thresholds, ensuring they uphold a high-quality standard. The primary impact of weaker ASRs is on the number of accepted chunks, not their quality. As ASR errors increase, their transcripts become less similar to the ground truth, resulting in fewer chunks passing the CER thresholds.</p>
</div>
<div id="A3.p9" class="ltx_para">
<p id="A3.p9.12" class="ltx_p">To evaluate this, we introduced artificial errors into the ASR outputs, randomly flipping characters in the transcripts. The error rates were uniformly chosen from the ranges <math id="A3.p9.1.m1.2" class="ltx_Math" alttext="[0,0.1]" display="inline"><semantics id="A3.p9.1.m1.2a"><mrow id="A3.p9.1.m1.2.3.2" xref="A3.p9.1.m1.2.3.1.cmml"><mo stretchy="false" id="A3.p9.1.m1.2.3.2.1" xref="A3.p9.1.m1.2.3.1.cmml">[</mo><mn id="A3.p9.1.m1.1.1" xref="A3.p9.1.m1.1.1.cmml">0</mn><mo id="A3.p9.1.m1.2.3.2.2" xref="A3.p9.1.m1.2.3.1.cmml">,</mo><mn id="A3.p9.1.m1.2.2" xref="A3.p9.1.m1.2.2.cmml">0.1</mn><mo stretchy="false" id="A3.p9.1.m1.2.3.2.3" xref="A3.p9.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.1.m1.2b"><interval closure="closed" id="A3.p9.1.m1.2.3.1.cmml" xref="A3.p9.1.m1.2.3.2"><cn type="integer" id="A3.p9.1.m1.1.1.cmml" xref="A3.p9.1.m1.1.1">0</cn><cn type="float" id="A3.p9.1.m1.2.2.cmml" xref="A3.p9.1.m1.2.2">0.1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.1.m1.2c">[0,0.1]</annotation></semantics></math>, <math id="A3.p9.2.m2.2" class="ltx_Math" alttext="[0,0.2]" display="inline"><semantics id="A3.p9.2.m2.2a"><mrow id="A3.p9.2.m2.2.3.2" xref="A3.p9.2.m2.2.3.1.cmml"><mo stretchy="false" id="A3.p9.2.m2.2.3.2.1" xref="A3.p9.2.m2.2.3.1.cmml">[</mo><mn id="A3.p9.2.m2.1.1" xref="A3.p9.2.m2.1.1.cmml">0</mn><mo id="A3.p9.2.m2.2.3.2.2" xref="A3.p9.2.m2.2.3.1.cmml">,</mo><mn id="A3.p9.2.m2.2.2" xref="A3.p9.2.m2.2.2.cmml">0.2</mn><mo stretchy="false" id="A3.p9.2.m2.2.3.2.3" xref="A3.p9.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.2.m2.2b"><interval closure="closed" id="A3.p9.2.m2.2.3.1.cmml" xref="A3.p9.2.m2.2.3.2"><cn type="integer" id="A3.p9.2.m2.1.1.cmml" xref="A3.p9.2.m2.1.1">0</cn><cn type="float" id="A3.p9.2.m2.2.2.cmml" xref="A3.p9.2.m2.2.2">0.2</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.2.m2.2c">[0,0.2]</annotation></semantics></math>, <math id="A3.p9.3.m3.2" class="ltx_Math" alttext="[0,0.3]" display="inline"><semantics id="A3.p9.3.m3.2a"><mrow id="A3.p9.3.m3.2.3.2" xref="A3.p9.3.m3.2.3.1.cmml"><mo stretchy="false" id="A3.p9.3.m3.2.3.2.1" xref="A3.p9.3.m3.2.3.1.cmml">[</mo><mn id="A3.p9.3.m3.1.1" xref="A3.p9.3.m3.1.1.cmml">0</mn><mo id="A3.p9.3.m3.2.3.2.2" xref="A3.p9.3.m3.2.3.1.cmml">,</mo><mn id="A3.p9.3.m3.2.2" xref="A3.p9.3.m3.2.2.cmml">0.3</mn><mo stretchy="false" id="A3.p9.3.m3.2.3.2.3" xref="A3.p9.3.m3.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.3.m3.2b"><interval closure="closed" id="A3.p9.3.m3.2.3.1.cmml" xref="A3.p9.3.m3.2.3.2"><cn type="integer" id="A3.p9.3.m3.1.1.cmml" xref="A3.p9.3.m3.1.1">0</cn><cn type="float" id="A3.p9.3.m3.2.2.cmml" xref="A3.p9.3.m3.2.2">0.3</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.3.m3.2c">[0,0.3]</annotation></semantics></math>, <math id="A3.p9.4.m4.2" class="ltx_Math" alttext="[0,0.4]" display="inline"><semantics id="A3.p9.4.m4.2a"><mrow id="A3.p9.4.m4.2.3.2" xref="A3.p9.4.m4.2.3.1.cmml"><mo stretchy="false" id="A3.p9.4.m4.2.3.2.1" xref="A3.p9.4.m4.2.3.1.cmml">[</mo><mn id="A3.p9.4.m4.1.1" xref="A3.p9.4.m4.1.1.cmml">0</mn><mo id="A3.p9.4.m4.2.3.2.2" xref="A3.p9.4.m4.2.3.1.cmml">,</mo><mn id="A3.p9.4.m4.2.2" xref="A3.p9.4.m4.2.2.cmml">0.4</mn><mo stretchy="false" id="A3.p9.4.m4.2.3.2.3" xref="A3.p9.4.m4.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.4.m4.2b"><interval closure="closed" id="A3.p9.4.m4.2.3.1.cmml" xref="A3.p9.4.m4.2.3.2"><cn type="integer" id="A3.p9.4.m4.1.1.cmml" xref="A3.p9.4.m4.1.1">0</cn><cn type="float" id="A3.p9.4.m4.2.2.cmml" xref="A3.p9.4.m4.2.2">0.4</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.4.m4.2c">[0,0.4]</annotation></semantics></math>, and <math id="A3.p9.5.m5.2" class="ltx_Math" alttext="[0,0.5]" display="inline"><semantics id="A3.p9.5.m5.2a"><mrow id="A3.p9.5.m5.2.3.2" xref="A3.p9.5.m5.2.3.1.cmml"><mo stretchy="false" id="A3.p9.5.m5.2.3.2.1" xref="A3.p9.5.m5.2.3.1.cmml">[</mo><mn id="A3.p9.5.m5.1.1" xref="A3.p9.5.m5.1.1.cmml">0</mn><mo id="A3.p9.5.m5.2.3.2.2" xref="A3.p9.5.m5.2.3.1.cmml">,</mo><mn id="A3.p9.5.m5.2.2" xref="A3.p9.5.m5.2.2.cmml">0.5</mn><mo stretchy="false" id="A3.p9.5.m5.2.3.2.3" xref="A3.p9.5.m5.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.5.m5.2b"><interval closure="closed" id="A3.p9.5.m5.2.3.1.cmml" xref="A3.p9.5.m5.2.3.2"><cn type="integer" id="A3.p9.5.m5.1.1.cmml" xref="A3.p9.5.m5.1.1">0</cn><cn type="float" id="A3.p9.5.m5.2.2.cmml" xref="A3.p9.5.m5.2.2">0.5</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.5.m5.2c">[0,0.5]</annotation></semantics></math>. This produced average CER increases of approximately
<math id="A3.p9.6.m6.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="A3.p9.6.m6.1a"><mrow id="A3.p9.6.m6.1.1" xref="A3.p9.6.m6.1.1.cmml"><mn id="A3.p9.6.m6.1.1.2" xref="A3.p9.6.m6.1.1.2.cmml">5</mn><mo id="A3.p9.6.m6.1.1.1" xref="A3.p9.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.6.m6.1b"><apply id="A3.p9.6.m6.1.1.cmml" xref="A3.p9.6.m6.1.1"><csymbol cd="latexml" id="A3.p9.6.m6.1.1.1.cmml" xref="A3.p9.6.m6.1.1.1">percent</csymbol><cn type="integer" id="A3.p9.6.m6.1.1.2.cmml" xref="A3.p9.6.m6.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.6.m6.1c">5\%</annotation></semantics></math>,
<math id="A3.p9.7.m7.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="A3.p9.7.m7.1a"><mrow id="A3.p9.7.m7.1.1" xref="A3.p9.7.m7.1.1.cmml"><mn id="A3.p9.7.m7.1.1.2" xref="A3.p9.7.m7.1.1.2.cmml">10</mn><mo id="A3.p9.7.m7.1.1.1" xref="A3.p9.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.7.m7.1b"><apply id="A3.p9.7.m7.1.1.cmml" xref="A3.p9.7.m7.1.1"><csymbol cd="latexml" id="A3.p9.7.m7.1.1.1.cmml" xref="A3.p9.7.m7.1.1.1">percent</csymbol><cn type="integer" id="A3.p9.7.m7.1.1.2.cmml" xref="A3.p9.7.m7.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.7.m7.1c">10\%</annotation></semantics></math>,
<math id="A3.p9.8.m8.1" class="ltx_Math" alttext="15\%" display="inline"><semantics id="A3.p9.8.m8.1a"><mrow id="A3.p9.8.m8.1.1" xref="A3.p9.8.m8.1.1.cmml"><mn id="A3.p9.8.m8.1.1.2" xref="A3.p9.8.m8.1.1.2.cmml">15</mn><mo id="A3.p9.8.m8.1.1.1" xref="A3.p9.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.8.m8.1b"><apply id="A3.p9.8.m8.1.1.cmml" xref="A3.p9.8.m8.1.1"><csymbol cd="latexml" id="A3.p9.8.m8.1.1.1.cmml" xref="A3.p9.8.m8.1.1.1">percent</csymbol><cn type="integer" id="A3.p9.8.m8.1.1.2.cmml" xref="A3.p9.8.m8.1.1.2">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.8.m8.1c">15\%</annotation></semantics></math>,
<math id="A3.p9.9.m9.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="A3.p9.9.m9.1a"><mrow id="A3.p9.9.m9.1.1" xref="A3.p9.9.m9.1.1.cmml"><mn id="A3.p9.9.m9.1.1.2" xref="A3.p9.9.m9.1.1.2.cmml">20</mn><mo id="A3.p9.9.m9.1.1.1" xref="A3.p9.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.9.m9.1b"><apply id="A3.p9.9.m9.1.1.cmml" xref="A3.p9.9.m9.1.1"><csymbol cd="latexml" id="A3.p9.9.m9.1.1.1.cmml" xref="A3.p9.9.m9.1.1.1">percent</csymbol><cn type="integer" id="A3.p9.9.m9.1.1.2.cmml" xref="A3.p9.9.m9.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.9.m9.1c">20\%</annotation></semantics></math>, and
<math id="A3.p9.10.m10.1" class="ltx_Math" alttext="25\%" display="inline"><semantics id="A3.p9.10.m10.1a"><mrow id="A3.p9.10.m10.1.1" xref="A3.p9.10.m10.1.1.cmml"><mn id="A3.p9.10.m10.1.1.2" xref="A3.p9.10.m10.1.1.2.cmml">25</mn><mo id="A3.p9.10.m10.1.1.1" xref="A3.p9.10.m10.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.10.m10.1b"><apply id="A3.p9.10.m10.1.1.cmml" xref="A3.p9.10.m10.1.1"><csymbol cd="latexml" id="A3.p9.10.m10.1.1.1.cmml" xref="A3.p9.10.m10.1.1.1">percent</csymbol><cn type="integer" id="A3.p9.10.m10.1.1.2.cmml" xref="A3.p9.10.m10.1.1.2">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.10.m10.1c">25\%</annotation></semantics></math>
respectively. These were substantial increases, especially considering the ASRs already had baseline CERs of <math id="A3.p9.11.m11.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A3.p9.11.m11.1a"><mn id="A3.p9.11.m11.1.1" xref="A3.p9.11.m11.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A3.p9.11.m11.1b"><cn type="integer" id="A3.p9.11.m11.1.1.cmml" xref="A3.p9.11.m11.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.11.m11.1c">10</annotation></semantics></math>-<math id="A3.p9.12.m12.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="A3.p9.12.m12.1a"><mrow id="A3.p9.12.m12.1.1" xref="A3.p9.12.m12.1.1.cmml"><mn id="A3.p9.12.m12.1.1.2" xref="A3.p9.12.m12.1.1.2.cmml">30</mn><mo id="A3.p9.12.m12.1.1.1" xref="A3.p9.12.m12.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.p9.12.m12.1b"><apply id="A3.p9.12.m12.1.1.cmml" xref="A3.p9.12.m12.1.1"><csymbol cd="latexml" id="A3.p9.12.m12.1.1.1.cmml" xref="A3.p9.12.m12.1.1.1">percent</csymbol><cn type="integer" id="A3.p9.12.m12.1.1.2.cmml" xref="A3.p9.12.m12.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p9.12.m12.1c">30\%</annotation></semantics></math> on the VirgoolInformal dataset.</p>
</div>
<div id="A3.p10" class="ltx_para">
<p id="A3.p10.1" class="ltx_p">Using these modified ASRs, we performed forced alignment on an audio file that had previously been segmented into 151 chunks without any rejections. The results were impressive, demonstrating the resilience of the MoE approach to ASR degradation. The number of rejected chunks for each error level, as shown in Table <a href="#A3.T7" title="Table 7 ‣ Appendix C Transcript Module Statistics ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, highlights this robustness.</p>
</div>
<figure id="A3.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A3.T7.8.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="A3.T7.9.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Number of rejected chunks at different ASR error levels.<span id="A3.T7.9.2.1" class="ltx_text ltx_font_medium"> The columns represent the range of additional error introduced into the ASR outputs, while the rows compare the performance of our method (which combines multiple ASRs) with that of using a single ASR. The numbers in the cells indicate how many out of 151 chunks were rejected, with lower values indicating greater robustness and effectiveness.</span></span></figcaption>
<table id="A3.T7.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T7.5.5" class="ltx_tr">
<th id="A3.T7.5.5.6" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="A3.T7.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="A3.T7.1.1.1.m1.2" class="ltx_Math" alttext="\mathbf{[0,0.1]}" display="inline"><semantics id="A3.T7.1.1.1.m1.2a"><mrow id="A3.T7.1.1.1.m1.2.3.2" xref="A3.T7.1.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="A3.T7.1.1.1.m1.2.3.2.1" xref="A3.T7.1.1.1.m1.2.3.1.cmml">[</mo><mn id="A3.T7.1.1.1.m1.1.1" xref="A3.T7.1.1.1.m1.1.1.cmml">𝟎</mn><mo id="A3.T7.1.1.1.m1.2.3.2.2" xref="A3.T7.1.1.1.m1.2.3.1.cmml">,</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A3.T7.1.1.1.m1.2.2" xref="A3.T7.1.1.1.m1.2.2.cmml">0.1</mn><mo stretchy="false" id="A3.T7.1.1.1.m1.2.3.2.3" xref="A3.T7.1.1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T7.1.1.1.m1.2b"><interval closure="closed" id="A3.T7.1.1.1.m1.2.3.1.cmml" xref="A3.T7.1.1.1.m1.2.3.2"><cn type="integer" id="A3.T7.1.1.1.m1.1.1.cmml" xref="A3.T7.1.1.1.m1.1.1">0</cn><cn type="float" id="A3.T7.1.1.1.m1.2.2.cmml" xref="A3.T7.1.1.1.m1.2.2">0.1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.1.1.1.m1.2c">\mathbf{[0,0.1]}</annotation></semantics></math></th>
<th id="A3.T7.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="A3.T7.2.2.2.m1.2" class="ltx_Math" alttext="\mathbf{[0,0.2]}" display="inline"><semantics id="A3.T7.2.2.2.m1.2a"><mrow id="A3.T7.2.2.2.m1.2.3.2" xref="A3.T7.2.2.2.m1.2.3.1.cmml"><mo stretchy="false" id="A3.T7.2.2.2.m1.2.3.2.1" xref="A3.T7.2.2.2.m1.2.3.1.cmml">[</mo><mn id="A3.T7.2.2.2.m1.1.1" xref="A3.T7.2.2.2.m1.1.1.cmml">𝟎</mn><mo id="A3.T7.2.2.2.m1.2.3.2.2" xref="A3.T7.2.2.2.m1.2.3.1.cmml">,</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A3.T7.2.2.2.m1.2.2" xref="A3.T7.2.2.2.m1.2.2.cmml">0.2</mn><mo stretchy="false" id="A3.T7.2.2.2.m1.2.3.2.3" xref="A3.T7.2.2.2.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T7.2.2.2.m1.2b"><interval closure="closed" id="A3.T7.2.2.2.m1.2.3.1.cmml" xref="A3.T7.2.2.2.m1.2.3.2"><cn type="integer" id="A3.T7.2.2.2.m1.1.1.cmml" xref="A3.T7.2.2.2.m1.1.1">0</cn><cn type="float" id="A3.T7.2.2.2.m1.2.2.cmml" xref="A3.T7.2.2.2.m1.2.2">0.2</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.2.2.2.m1.2c">\mathbf{[0,0.2]}</annotation></semantics></math></th>
<th id="A3.T7.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="A3.T7.3.3.3.m1.2" class="ltx_Math" alttext="\mathbf{[0,0.3]}" display="inline"><semantics id="A3.T7.3.3.3.m1.2a"><mrow id="A3.T7.3.3.3.m1.2.3.2" xref="A3.T7.3.3.3.m1.2.3.1.cmml"><mo stretchy="false" id="A3.T7.3.3.3.m1.2.3.2.1" xref="A3.T7.3.3.3.m1.2.3.1.cmml">[</mo><mn id="A3.T7.3.3.3.m1.1.1" xref="A3.T7.3.3.3.m1.1.1.cmml">𝟎</mn><mo id="A3.T7.3.3.3.m1.2.3.2.2" xref="A3.T7.3.3.3.m1.2.3.1.cmml">,</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A3.T7.3.3.3.m1.2.2" xref="A3.T7.3.3.3.m1.2.2.cmml">0.3</mn><mo stretchy="false" id="A3.T7.3.3.3.m1.2.3.2.3" xref="A3.T7.3.3.3.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T7.3.3.3.m1.2b"><interval closure="closed" id="A3.T7.3.3.3.m1.2.3.1.cmml" xref="A3.T7.3.3.3.m1.2.3.2"><cn type="integer" id="A3.T7.3.3.3.m1.1.1.cmml" xref="A3.T7.3.3.3.m1.1.1">0</cn><cn type="float" id="A3.T7.3.3.3.m1.2.2.cmml" xref="A3.T7.3.3.3.m1.2.2">0.3</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.3.3.3.m1.2c">\mathbf{[0,0.3]}</annotation></semantics></math></th>
<th id="A3.T7.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="A3.T7.4.4.4.m1.2" class="ltx_Math" alttext="\mathbf{[0,0.4]}" display="inline"><semantics id="A3.T7.4.4.4.m1.2a"><mrow id="A3.T7.4.4.4.m1.2.3.2" xref="A3.T7.4.4.4.m1.2.3.1.cmml"><mo stretchy="false" id="A3.T7.4.4.4.m1.2.3.2.1" xref="A3.T7.4.4.4.m1.2.3.1.cmml">[</mo><mn id="A3.T7.4.4.4.m1.1.1" xref="A3.T7.4.4.4.m1.1.1.cmml">𝟎</mn><mo id="A3.T7.4.4.4.m1.2.3.2.2" xref="A3.T7.4.4.4.m1.2.3.1.cmml">,</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A3.T7.4.4.4.m1.2.2" xref="A3.T7.4.4.4.m1.2.2.cmml">0.4</mn><mo stretchy="false" id="A3.T7.4.4.4.m1.2.3.2.3" xref="A3.T7.4.4.4.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T7.4.4.4.m1.2b"><interval closure="closed" id="A3.T7.4.4.4.m1.2.3.1.cmml" xref="A3.T7.4.4.4.m1.2.3.2"><cn type="integer" id="A3.T7.4.4.4.m1.1.1.cmml" xref="A3.T7.4.4.4.m1.1.1">0</cn><cn type="float" id="A3.T7.4.4.4.m1.2.2.cmml" xref="A3.T7.4.4.4.m1.2.2">0.4</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.4.4.4.m1.2c">\mathbf{[0,0.4]}</annotation></semantics></math></th>
<th id="A3.T7.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="A3.T7.5.5.5.m1.2" class="ltx_Math" alttext="\mathbf{[0,0.5]}" display="inline"><semantics id="A3.T7.5.5.5.m1.2a"><mrow id="A3.T7.5.5.5.m1.2.3.2" xref="A3.T7.5.5.5.m1.2.3.1.cmml"><mo stretchy="false" id="A3.T7.5.5.5.m1.2.3.2.1" xref="A3.T7.5.5.5.m1.2.3.1.cmml">[</mo><mn id="A3.T7.5.5.5.m1.1.1" xref="A3.T7.5.5.5.m1.1.1.cmml">𝟎</mn><mo id="A3.T7.5.5.5.m1.2.3.2.2" xref="A3.T7.5.5.5.m1.2.3.1.cmml">,</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A3.T7.5.5.5.m1.2.2" xref="A3.T7.5.5.5.m1.2.2.cmml">0.5</mn><mo stretchy="false" id="A3.T7.5.5.5.m1.2.3.2.3" xref="A3.T7.5.5.5.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T7.5.5.5.m1.2b"><interval closure="closed" id="A3.T7.5.5.5.m1.2.3.1.cmml" xref="A3.T7.5.5.5.m1.2.3.2"><cn type="integer" id="A3.T7.5.5.5.m1.1.1.cmml" xref="A3.T7.5.5.5.m1.1.1">0</cn><cn type="float" id="A3.T7.5.5.5.m1.2.2.cmml" xref="A3.T7.5.5.5.m1.2.2">0.5</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.5.5.5.m1.2c">\mathbf{[0,0.5]}</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T7.5.6.1" class="ltx_tr">
<th id="A3.T7.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="A3.T7.5.6.1.1.1" class="ltx_text ltx_font_bold">Our Method (Multiple ASRs)</span></th>
<td id="A3.T7.5.6.1.2" class="ltx_td ltx_align_center ltx_border_t">0</td>
<td id="A3.T7.5.6.1.3" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="A3.T7.5.6.1.4" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="A3.T7.5.6.1.5" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="A3.T7.5.6.1.6" class="ltx_td ltx_align_center ltx_border_t">9</td>
</tr>
<tr id="A3.T7.5.7.2" class="ltx_tr">
<th id="A3.T7.5.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="A3.T7.5.7.2.1.1" class="ltx_text ltx_font_bold">Single ASR</span></th>
<td id="A3.T7.5.7.2.2" class="ltx_td ltx_align_center ltx_border_bb">1</td>
<td id="A3.T7.5.7.2.3" class="ltx_td ltx_align_center ltx_border_bb">4</td>
<td id="A3.T7.5.7.2.4" class="ltx_td ltx_align_center ltx_border_bb">17</td>
<td id="A3.T7.5.7.2.5" class="ltx_td ltx_align_center ltx_border_bb">53</td>
<td id="A3.T7.5.7.2.6" class="ltx_td ltx_align_center ltx_border_bb">65</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>TTS Model Evaluation Details</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">In this section, we elaborate on the method used to evaluate the TTS model trained on the MansTTS dataset.</p>
</div>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>MOS Score</h3>

<div id="A4.SS1.p1" class="ltx_para">
<p id="A4.SS1.p1.1" class="ltx_p">As explained earlier, the model was trained on data from all issues of the Nasl-e-Mana magazine except the most recent one at the time of this study. Thus, the data used to assess the model was selected from this last exclusive issue. We passed the data from this issue through the dataset processing pipeline and obtained the audio-text chunks. We then selected five of these chunks as the evaluation samples.</p>
</div>
<div id="A4.SS1.p2" class="ltx_para">
<p id="A4.SS1.p2.1" class="ltx_p">We then generated the speech waveform of the selected utterances using the following sources:</p>
</div>
<div id="A4.SS1.p3" class="ltx_para">
<ol id="A4.I1" class="ltx_enumerate">
<li id="A4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A4.I1.i1.p1" class="ltx_para">
<p id="A4.I1.i1.p1.1" class="ltx_p">Baseline Model 1: A VITS-based TTS model trained for the Persian language with an open-access model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
</li>
<li id="A4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A4.I1.i2.p1" class="ltx_para">
<p id="A4.I1.i2.p1.1" class="ltx_p">Baseline Model 2: Another open-access model based on Glow-TTS trained for the Persian language <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.</p>
</div>
</li>
<li id="A4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A4.I1.i3.p1" class="ltx_para">
<p id="A4.I1.i3.p1.1" class="ltx_p">Ours: The model used in our study, which generates spectrograms for a given utterance, and the waveform is generated using a HiFi-GAN vocoder.</p>
</div>
</li>
<li id="A4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A4.I1.i4.p1" class="ltx_para">
<p id="A4.I1.i4.p1.1" class="ltx_p">GT Spec: Waveforms generated from the gold spectrogram of the natural speech using the same HiFi-GAN vocoder as our work.</p>
</div>
</li>
</ol>
</div>
<div id="A4.SS1.p4" class="ltx_para">
<p id="A4.SS1.p4.1" class="ltx_p">We accompanied these four classes of utterances with natural audio chunks of the five selected samples and conducted a MOS test using 76 native speakers.</p>
</div>
<div id="A4.SS1.p5" class="ltx_para">
<p id="A4.SS1.p5.1" class="ltx_p">The subjects were prompted as follows: "Rate the voices you hear based on how natural they sound and how likely they are to have been uttered by a human. If you think the voice is completely natural and has no problems, rate it 5. Otherwise, decrease the rating down to 1 based on how robotic it sounds and the problems or noises you notice."</p>
</div>
<div id="A4.SS1.p6" class="ltx_para">
<p id="A4.SS1.p6.1" class="ltx_p">The order of the models for each of the five utterances was shuffled to prevent bias towards consistently rating a specific model the same or being influenced by an increasing/decreasing naturalness trend. They were also not informed which utterances were related to our work or that there was a natural utterance for each sample. The resulting MOS scores can be seen in Table <a href="#A4.T8" title="Table 8 ‣ D.1 MOS Score ‣ Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> along with the position of the sources in the played samples.</p>
</div>
<figure id="A4.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A4.T8.5.1.1" class="ltx_text" style="font-size:90%;">Table 8</span>: </span><span id="A4.T8.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Subjective assessment of outcomes of the different speech sources per utterance.<span id="A4.T8.6.2.1" class="ltx_text ltx_font_medium"> </span>GT Spec<span id="A4.T8.6.2.2" class="ltx_text ltx_font_medium"> refers to the utterances with ground truth spectrograms but HiFi-GAN-synthesized waveforms, and </span>GT Waveform<span id="A4.T8.6.2.3" class="ltx_text ltx_font_medium"> refers to the natural speech samples.</span></span></figcaption>
<table id="A4.T8.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T8.7.1.1" class="ltx_tr">
<th id="A4.T8.7.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="A4.T8.7.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt"></th>
<th id="A4.T8.7.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T8.7.1.1.3.1" class="ltx_text ltx_font_bold">VITS</span></th>
<th id="A4.T8.7.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T8.7.1.1.4.1" class="ltx_text ltx_font_bold">Glow</span></th>
<th id="A4.T8.7.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T8.7.1.1.5.1" class="ltx_text ltx_font_bold">Ours</span></th>
<th id="A4.T8.7.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T8.7.1.1.6.1" class="ltx_text ltx_font_bold">GT Spec</span></th>
<th id="A4.T8.7.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T8.7.1.1.7.1" class="ltx_text ltx_font_bold">GT Waveform</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T8.7.2.1" class="ltx_tr">
<th id="A4.T8.7.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="2"><span id="A4.T8.7.2.1.1.1" class="ltx_text ltx_font_bold">utterance 1</span></th>
<th id="A4.T8.7.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="A4.T8.7.2.1.2.1" class="ltx_text ltx_font_bold">position</span></th>
<td id="A4.T8.7.2.1.3" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="A4.T8.7.2.1.4" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="A4.T8.7.2.1.5" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="A4.T8.7.2.1.6" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="A4.T8.7.2.1.7" class="ltx_td ltx_align_center ltx_border_t">5</td>
</tr>
<tr id="A4.T8.7.3.2" class="ltx_tr">
<th id="A4.T8.7.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="A4.T8.7.3.2.1.1" class="ltx_text ltx_font_bold">MOS</span></th>
<td id="A4.T8.7.3.2.2" class="ltx_td ltx_align_center">1.78</td>
<td id="A4.T8.7.3.2.3" class="ltx_td ltx_align_center">1.44</td>
<td id="A4.T8.7.3.2.4" class="ltx_td ltx_align_center">4.24</td>
<td id="A4.T8.7.3.2.5" class="ltx_td ltx_align_center">3.69</td>
<td id="A4.T8.7.3.2.6" class="ltx_td ltx_align_center"><span id="A4.T8.7.3.2.6.1" class="ltx_text ltx_font_bold">4.42</span></td>
</tr>
<tr id="A4.T8.7.4.3" class="ltx_tr">
<th id="A4.T8.7.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="2"><span id="A4.T8.7.4.3.1.1" class="ltx_text ltx_font_bold">utterance 2</span></th>
<th id="A4.T8.7.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="A4.T8.7.4.3.2.1" class="ltx_text ltx_font_bold">position</span></th>
<td id="A4.T8.7.4.3.3" class="ltx_td ltx_align_center ltx_border_t">5</td>
<td id="A4.T8.7.4.3.4" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="A4.T8.7.4.3.5" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="A4.T8.7.4.3.6" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="A4.T8.7.4.3.7" class="ltx_td ltx_align_center ltx_border_t">3</td>
</tr>
<tr id="A4.T8.7.5.4" class="ltx_tr">
<th id="A4.T8.7.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="A4.T8.7.5.4.1.1" class="ltx_text ltx_font_bold">MOS</span></th>
<td id="A4.T8.7.5.4.2" class="ltx_td ltx_align_center">1.65</td>
<td id="A4.T8.7.5.4.3" class="ltx_td ltx_align_center">1.26</td>
<td id="A4.T8.7.5.4.4" class="ltx_td ltx_align_center"><span id="A4.T8.7.5.4.4.1" class="ltx_text ltx_font_bold">3.10</span></td>
<td id="A4.T8.7.5.4.5" class="ltx_td ltx_align_center">2.96</td>
<td id="A4.T8.7.5.4.6" class="ltx_td ltx_align_center">3.03</td>
</tr>
<tr id="A4.T8.7.6.5" class="ltx_tr">
<th id="A4.T8.7.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="2"><span id="A4.T8.7.6.5.1.1" class="ltx_text ltx_font_bold">utterance 3</span></th>
<th id="A4.T8.7.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="A4.T8.7.6.5.2.1" class="ltx_text ltx_font_bold">position</span></th>
<td id="A4.T8.7.6.5.3" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="A4.T8.7.6.5.4" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="A4.T8.7.6.5.5" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="A4.T8.7.6.5.6" class="ltx_td ltx_align_center ltx_border_t">5</td>
<td id="A4.T8.7.6.5.7" class="ltx_td ltx_align_center ltx_border_t">1</td>
</tr>
<tr id="A4.T8.7.7.6" class="ltx_tr">
<th id="A4.T8.7.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="A4.T8.7.7.6.1.1" class="ltx_text ltx_font_bold">MOS</span></th>
<td id="A4.T8.7.7.6.2" class="ltx_td ltx_align_center">1.34</td>
<td id="A4.T8.7.7.6.3" class="ltx_td ltx_align_center">1.30</td>
<td id="A4.T8.7.7.6.4" class="ltx_td ltx_align_center">3.92</td>
<td id="A4.T8.7.7.6.5" class="ltx_td ltx_align_center"><span id="A4.T8.7.7.6.5.1" class="ltx_text ltx_font_bold">4.20</span></td>
<td id="A4.T8.7.7.6.6" class="ltx_td ltx_align_center">3.96</td>
</tr>
<tr id="A4.T8.7.8.7" class="ltx_tr">
<th id="A4.T8.7.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="2"><span id="A4.T8.7.8.7.1.1" class="ltx_text ltx_font_bold">utterance 4</span></th>
<th id="A4.T8.7.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="A4.T8.7.8.7.2.1" class="ltx_text ltx_font_bold">position</span></th>
<td id="A4.T8.7.8.7.3" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="A4.T8.7.8.7.4" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="A4.T8.7.8.7.5" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="A4.T8.7.8.7.6" class="ltx_td ltx_align_center ltx_border_t">5</td>
<td id="A4.T8.7.8.7.7" class="ltx_td ltx_align_center ltx_border_t">2</td>
</tr>
<tr id="A4.T8.7.9.8" class="ltx_tr">
<th id="A4.T8.7.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="A4.T8.7.9.8.1.1" class="ltx_text ltx_font_bold">MOS</span></th>
<td id="A4.T8.7.9.8.2" class="ltx_td ltx_align_center">2.03</td>
<td id="A4.T8.7.9.8.3" class="ltx_td ltx_align_center">1.39</td>
<td id="A4.T8.7.9.8.4" class="ltx_td ltx_align_center">3.48</td>
<td id="A4.T8.7.9.8.5" class="ltx_td ltx_align_center"><span id="A4.T8.7.9.8.5.1" class="ltx_text ltx_font_bold">4.16</span></td>
<td id="A4.T8.7.9.8.6" class="ltx_td ltx_align_center">4.05</td>
</tr>
<tr id="A4.T8.7.10.9" class="ltx_tr">
<th id="A4.T8.7.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" rowspan="2"><span id="A4.T8.7.10.9.1.1" class="ltx_text ltx_font_bold">utterance 5</span></th>
<th id="A4.T8.7.10.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="A4.T8.7.10.9.2.1" class="ltx_text ltx_font_bold">position</span></th>
<td id="A4.T8.7.10.9.3" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="A4.T8.7.10.9.4" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="A4.T8.7.10.9.5" class="ltx_td ltx_align_center ltx_border_t">5</td>
<td id="A4.T8.7.10.9.6" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="A4.T8.7.10.9.7" class="ltx_td ltx_align_center ltx_border_t">2</td>
</tr>
<tr id="A4.T8.7.11.10" class="ltx_tr">
<th id="A4.T8.7.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb"><span id="A4.T8.7.11.10.1.1" class="ltx_text ltx_font_bold">MOS</span></th>
<td id="A4.T8.7.11.10.2" class="ltx_td ltx_align_center ltx_border_bb">1.61</td>
<td id="A4.T8.7.11.10.3" class="ltx_td ltx_align_center ltx_border_bb">1.32</td>
<td id="A4.T8.7.11.10.4" class="ltx_td ltx_align_center ltx_border_bb">4.08</td>
<td id="A4.T8.7.11.10.5" class="ltx_td ltx_align_center ltx_border_bb">4.25</td>
<td id="A4.T8.7.11.10.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="A4.T8.7.11.10.6.1" class="ltx_text ltx_font_bold">4.57</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="A4.SS1.p7" class="ltx_para">
<p id="A4.SS1.p7.1" class="ltx_p">The MOS across all samples and utterances, along with their variability, are presented in Table <a href="#S5.T2" title="Table 2 ‣ 5 Experiments ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and visualized in Figure <a href="#A4.F9" title="Figure 9 ‣ D.1 MOS Score ‣ Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. The standard deviation of the scores was calculated using the numpy std function on the aggregated scores from all samples of the five utterances. The primary sources of variation in the scores are as follows:</p>
</div>
<div id="A4.SS1.p8" class="ltx_para">
<ul id="A4.I2" class="ltx_itemize">
<li id="A4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A4.I2.i1.p1" class="ltx_para">
<p id="A4.I2.i1.p1.1" class="ltx_p">Specific sources may appear more natural in some utterances and perform worse in others.</p>
</div>
</li>
<li id="A4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A4.I2.i2.p1" class="ltx_para">
<p id="A4.I2.i2.p1.1" class="ltx_p">Subjects have varying understandings and expectations regarding the naturalness of a speech sample.</p>
</div>
</li>
<li id="A4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A4.I2.i3.p1" class="ltx_para">
<p id="A4.I2.i3.p1.1" class="ltx_p">The random shuffling of the sources’ order in each utterance affects the scores given by subjects due to the relative naturalness of the different sources.</p>
</div>
</li>
</ul>
</div>
<figure id="A4.F9" class="ltx_figure"><img src="/html/2409.07259/assets/figs/mos-all.png" id="A4.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="274" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A4.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="A4.F9.3.2" class="ltx_text" style="font-size:90%;">MOS of different sources and their variability.</span></figcaption>
</figure>
<div id="A4.SS1.p9" class="ltx_para">
<p id="A4.SS1.p9.1" class="ltx_p">In addition to examining the model’s overall performance, it is insightful to analyze the distribution of Mean Opinion Score (MOS) ratings given to our model by individual subjects. This provides valuable insight into how opinions varied among respondents regarding our model. Figure <a href="#A4.F10" title="Figure 10 ‣ D.1 MOS Score ‣ Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> presents this distribution, shedding light on how the average scores assigned to our model are spread among respondents.</p>
</div>
<figure id="A4.F10" class="ltx_figure"><img src="/html/2409.07259/assets/figs/mos-per-subject.png" id="A4.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="212" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A4.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="A4.F10.3.2" class="ltx_text" style="font-size:90%;">Distribution of Mean Opinion Score (MOS) ratings given to our model by individual subjects.</span></figcaption>
</figure>
</section>
<section id="A4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Objective Scores</h3>

<div id="A4.SS2.p1" class="ltx_para">
<p id="A4.SS2.p1.1" class="ltx_p">In addition to the subjective MOS score, we conducted a more comprehensive evaluation of the trained TTS model using several objective methods. We selected a subset of 100 audio and text chunks, generating audio from these text chunks using our TTS model and two baseline models (VITS and Glow). Additionally, we regenerated the audio from their spectrograms using the vocoder employed by our TTS system. The evaluation metrics included PESQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, MCD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, and APTD (Average Predicted Time Difference in seconds). The results of these metrics are presented in Table <a href="#A4.T9" title="Table 9 ‣ D.2 Objective Scores ‣ Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure id="A4.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A4.T9.4.1.1" class="ltx_text" style="font-size:90%;">Table 9</span>: </span><span id="A4.T9.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Objective assessment of outcomes of the TTS models.<span id="A4.T9.5.2.1" class="ltx_text ltx_font_medium"> </span>GT Spec<span id="A4.T9.5.2.2" class="ltx_text ltx_font_medium"> refers to the utterances
with ground truth spectrograms but HiFi-GAN-synthesized waveforms.</span></span></figcaption>
<table id="A4.T9.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T9.6.1.1" class="ltx_tr">
<th id="A4.T9.6.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="A4.T9.6.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T9.6.1.1.2.1" class="ltx_text ltx_font_bold">Baseline 1 (Vits)</span></th>
<th id="A4.T9.6.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T9.6.1.1.3.1" class="ltx_text ltx_font_bold">Baseline 2 (Glow)</span></th>
<th id="A4.T9.6.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T9.6.1.1.4.1" class="ltx_text ltx_font_bold">Ours</span></th>
<th id="A4.T9.6.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T9.6.1.1.5.1" class="ltx_text ltx_font_bold">GT Spec</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T9.6.2.1" class="ltx_tr">
<th id="A4.T9.6.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="A4.T9.6.2.1.1.1" class="ltx_text ltx_font_bold">PESQ</span></th>
<td id="A4.T9.6.2.1.2" class="ltx_td ltx_align_center ltx_border_t">1.05</td>
<td id="A4.T9.6.2.1.3" class="ltx_td ltx_align_center ltx_border_t">1.06</td>
<td id="A4.T9.6.2.1.4" class="ltx_td ltx_align_center ltx_border_t">1.11</td>
<td id="A4.T9.6.2.1.5" class="ltx_td ltx_align_center ltx_border_t">2.89</td>
</tr>
<tr id="A4.T9.6.3.2" class="ltx_tr">
<th id="A4.T9.6.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="A4.T9.6.3.2.1.1" class="ltx_text ltx_font_bold">APTD</span></th>
<td id="A4.T9.6.3.2.2" class="ltx_td ltx_align_center">1.4185</td>
<td id="A4.T9.6.3.2.3" class="ltx_td ltx_align_center">0.2781</td>
<td id="A4.T9.6.3.2.4" class="ltx_td ltx_align_center">0.5783</td>
<td id="A4.T9.6.3.2.5" class="ltx_td ltx_align_center">0.0064</td>
</tr>
<tr id="A4.T9.6.4.3" class="ltx_tr">
<th id="A4.T9.6.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="A4.T9.6.4.3.1.1" class="ltx_text ltx_font_bold">MCD</span></th>
<td id="A4.T9.6.4.3.2" class="ltx_td ltx_align_center ltx_border_bb">15.1611</td>
<td id="A4.T9.6.4.3.3" class="ltx_td ltx_align_center ltx_border_bb">18.5218</td>
<td id="A4.T9.6.4.3.4" class="ltx_td ltx_align_center ltx_border_bb">18.5682</td>
<td id="A4.T9.6.4.3.5" class="ltx_td ltx_align_center ltx_border_bb">7.1069</td>
</tr>
</tbody>
</table>
</figure>
<div id="A4.SS2.p2" class="ltx_para">
<p id="A4.SS2.p2.1" class="ltx_p">We also evaluated intelligibility using two ASR models: 1) Google Speech Recognition API <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, and 2) Vosk. The same 100 randomly selected audio chunks generated by the TTS models and HiFi-GAN vocoder were transcribed by these ASR systems. We computed the Character Error Rate (CER) by comparing the ASR-generated transcripts with the ground truth transcripts. Additionally, we computed the CER for the ground truth audio to account for the inherent error rates of the ASR models. The results are summarized in Table <a href="#A4.T10" title="Table 10 ‣ D.2 Objective Scores ‣ Appendix D TTS Model Evaluation Details ‣ ManaTTS Persian: a recipe for creating TTS datasets for lower resource languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<figure id="A4.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A4.T10.5.1.1" class="ltx_text" style="font-size:90%;">Table 10</span>: </span><span id="A4.T10.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Average CER of outcomes of TTS models.<span id="A4.T10.6.2.1" class="ltx_text ltx_font_medium"> </span>GT Spec<span id="A4.T10.6.2.2" class="ltx_text ltx_font_medium"> refers to the utterances
with ground truth spectrograms but HiFi-GAN-synthesized waveforms, and </span>GT Waveform<span id="A4.T10.6.2.3" class="ltx_text ltx_font_medium"> refers to the natural speech samples.</span></span></figcaption>
<table id="A4.T10.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T10.7.1.1" class="ltx_tr">
<th id="A4.T10.7.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="A4.T10.7.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T10.7.1.1.2.1" class="ltx_text ltx_font_bold">Baseline 1 (Vits)</span></th>
<th id="A4.T10.7.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T10.7.1.1.3.1" class="ltx_text ltx_font_bold">Baseline 2 (Glow)</span></th>
<th id="A4.T10.7.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T10.7.1.1.4.1" class="ltx_text ltx_font_bold">Ours</span></th>
<th id="A4.T10.7.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T10.7.1.1.5.1" class="ltx_text ltx_font_bold">GT Spec</span></th>
<th id="A4.T10.7.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A4.T10.7.1.1.6.1" class="ltx_text ltx_font_bold">GT Waveform</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T10.7.2.1" class="ltx_tr">
<th id="A4.T10.7.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="A4.T10.7.2.1.1.1" class="ltx_text ltx_font_bold">Google API</span></th>
<td id="A4.T10.7.2.1.2" class="ltx_td ltx_align_center ltx_border_tt">0.1259</td>
<td id="A4.T10.7.2.1.3" class="ltx_td ltx_align_center ltx_border_tt">0.2325</td>
<td id="A4.T10.7.2.1.4" class="ltx_td ltx_align_center ltx_border_tt">0.0956</td>
<td id="A4.T10.7.2.1.5" class="ltx_td ltx_align_center ltx_border_tt">0.0533</td>
<td id="A4.T10.7.2.1.6" class="ltx_td ltx_align_center ltx_border_tt">0.0482</td>
</tr>
<tr id="A4.T10.7.3.2" class="ltx_tr">
<th id="A4.T10.7.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="A4.T10.7.3.2.1.1" class="ltx_text ltx_font_bold">Vosk</span></th>
<td id="A4.T10.7.3.2.2" class="ltx_td ltx_align_center ltx_border_bb">0.2095</td>
<td id="A4.T10.7.3.2.3" class="ltx_td ltx_align_center ltx_border_bb">0.2762</td>
<td id="A4.T10.7.3.2.4" class="ltx_td ltx_align_center ltx_border_bb">0.1506</td>
<td id="A4.T10.7.3.2.5" class="ltx_td ltx_align_center ltx_border_bb">0.1406</td>
<td id="A4.T10.7.3.2.6" class="ltx_td ltx_align_center ltx_border_bb">0.1372</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Supplementary Figures</h2>

<figure id="A5.F11" class="ltx_figure"><img src="/html/2409.07259/assets/figs/forced-alignment-flowchart.png" id="A5.F11.g1" class="ltx_graphics ltx_centering ltx_img_square" width="419" height="513" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A5.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="A5.F11.3.2" class="ltx_text" style="font-size:90%;">Flowchart of the forced alignment algorithm.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Supplementary Tables</h2>

<figure id="A6.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A6.T11.2.1.1" class="ltx_text" style="font-size:90%;">Table 11</span>: </span><span id="A6.T11.3.2" class="ltx_text" style="font-size:90%;">The list of tools used in the dataset preparation code; all with open source licenses.</span></figcaption>
<table id="A6.T11.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A6.T11.4.1.1" class="ltx_tr">
<th id="A6.T11.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A6.T11.4.1.1.1.1" class="ltx_text ltx_font_bold">Tool Name</span></th>
<th id="A6.T11.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A6.T11.4.1.1.2.1" class="ltx_text ltx_font_bold">Usage</span></th>
<th id="A6.T11.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A6.T11.4.1.1.3.1" class="ltx_text ltx_font_bold">Repository Page</span></th>
<th id="A6.T11.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="A6.T11.4.1.1.4.1" class="ltx_text ltx_font_bold">License</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A6.T11.4.2.1" class="ltx_tr">
<td id="A6.T11.4.2.1.1" class="ltx_td ltx_align_center ltx_border_t">Spleeter <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>
</td>
<td id="A6.T11.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t">
<table id="A6.T11.4.2.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T11.4.2.1.2.1.1" class="ltx_tr">
<td id="A6.T11.4.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Source separation</td>
</tr>
<tr id="A6.T11.4.2.1.2.1.2" class="ltx_tr">
<td id="A6.T11.4.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(remove background music)</td>
</tr>
</table>
</td>
<td id="A6.T11.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://github.com/deezer/spleeter" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t">MIT</td>
</tr>
<tr id="A6.T11.4.3.2" class="ltx_tr">
<td id="A6.T11.4.3.2.1" class="ltx_td ltx_align_center">Parsi.io <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="A6.T11.4.3.2.2" class="ltx_td ltx_align_center">
<table id="A6.T11.4.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T11.4.3.2.2.1.1" class="ltx_tr">
<td id="A6.T11.4.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Number extraction &amp;</td>
</tr>
<tr id="A6.T11.4.3.2.2.1.2" class="ltx_tr">
<td id="A6.T11.4.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">number to text conversion</td>
</tr>
</table>
</td>
<td id="A6.T11.4.3.2.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://github.com/language-ml/parsi.io" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.3.2.4" class="ltx_td ltx_align_center">Apache-2.0</td>
</tr>
<tr id="A6.T11.4.4.3" class="ltx_tr">
<td id="A6.T11.4.4.3.1" class="ltx_td ltx_align_center">Hazm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="A6.T11.4.4.3.2" class="ltx_td ltx_align_center">Text normalization</td>
<td id="A6.T11.4.4.3.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://github.com/roshan-research/hazm" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.4.3.4" class="ltx_td ltx_align_center">MIT</td>
</tr>
<tr id="A6.T11.4.5.4" class="ltx_tr">
<td id="A6.T11.4.5.4.1" class="ltx_td ltx_align_center">Pydub <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="A6.T11.4.5.4.2" class="ltx_td ltx_align_center">Silence detection/removal</td>
<td id="A6.T11.4.5.4.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://github.com/jiaaro/pydub" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.5.4.4" class="ltx_td ltx_align_center">MIT</td>
</tr>
<tr id="A6.T11.4.6.5" class="ltx_tr">
<td id="A6.T11.4.6.5.1" class="ltx_td ltx_align_center">Perpos <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>
</td>
<td id="A6.T11.4.6.5.2" class="ltx_td ltx_align_center">
<table id="A6.T11.4.6.5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="A6.T11.4.6.5.2.1.1" class="ltx_tr">
<td id="A6.T11.4.6.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Part of speech tagging</td>
</tr>
<tr id="A6.T11.4.6.5.2.1.2" class="ltx_tr">
<td id="A6.T11.4.6.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">for sentence tokenization</td>
</tr>
<tr id="A6.T11.4.6.5.2.1.3" class="ltx_tr">
<td id="A6.T11.4.6.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">See appendix.</td>
</tr>
</table>
</td>
<td id="A6.T11.4.6.5.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://github.com/mhbashari/perpos" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.6.5.4" class="ltx_td ltx_align_center">MIT</td>
</tr>
<tr id="A6.T11.4.7.6" class="ltx_tr">
<td id="A6.T11.4.7.6.1" class="ltx_td ltx_align_center">Vosk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>
</td>
<td id="A6.T11.4.7.6.2" class="ltx_td ltx_align_center">Forced alignment</td>
<td id="A6.T11.4.7.6.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://github.com/alphacep/vosk" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.7.6.4" class="ltx_td ltx_align_center">Apache-2.0</td>
</tr>
<tr id="A6.T11.4.8.7" class="ltx_tr">
<td id="A6.T11.4.8.7.1" class="ltx_td ltx_align_center">Whisper-fa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>
</td>
<td id="A6.T11.4.8.7.2" class="ltx_td ltx_align_center">Forced alignment</td>
<td id="A6.T11.4.8.7.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://huggingface.co/speechbrain/asr-whisper-large-v2-commonvoice-fa" title="" class="ltx_ref ltx_href">HuggingFace</a></td>
<td id="A6.T11.4.8.7.4" class="ltx_td ltx_align_center">Apache-2.0</td>
</tr>
<tr id="A6.T11.4.9.8" class="ltx_tr">
<td id="A6.T11.4.9.8.1" class="ltx_td ltx_align_center">Wav2vec2-v3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>
</td>
<td id="A6.T11.4.9.8.2" class="ltx_td ltx_align_center">Forced alignment</td>
<td id="A6.T11.4.9.8.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://huggingface.co/m3hrdadfi/wav2vec2-large-xlsr-persian-v3" title="" class="ltx_ref ltx_href">HuggingFace</a></td>
<td id="A6.T11.4.9.8.4" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A6.T11.4.10.9" class="ltx_tr">
<td id="A6.T11.4.10.9.1" class="ltx_td ltx_align_center">Wav2vec2-fa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>
</td>
<td id="A6.T11.4.10.9.2" class="ltx_td ltx_align_center">Forced alignment</td>
<td id="A6.T11.4.10.9.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://github.com/Hamtech-ai/wav2vec2-fa" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.10.9.4" class="ltx_td ltx_align_center">Apache-3.0</td>
</tr>
<tr id="A6.T11.4.11.10" class="ltx_tr">
<td id="A6.T11.4.11.10.1" class="ltx_td ltx_align_center">Hezar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>
</td>
<td id="A6.T11.4.11.10.2" class="ltx_td ltx_align_center">Forced alignment</td>
<td id="A6.T11.4.11.10.3" class="ltx_td ltx_align_center"><a target="_blank" href="https://github.com/hezarai/hezar" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.11.10.4" class="ltx_td ltx_align_center">Apache-2.0</td>
</tr>
<tr id="A6.T11.4.12.11" class="ltx_tr">
<td id="A6.T11.4.12.11.1" class="ltx_td ltx_align_center ltx_border_bb">JiWER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>
</td>
<td id="A6.T11.4.12.11.2" class="ltx_td ltx_align_center ltx_border_bb">CER calculation</td>
<td id="A6.T11.4.12.11.3" class="ltx_td ltx_align_center ltx_border_bb"><a target="_blank" href="https://github.com/jitsi/jiwer" title="" class="ltx_ref ltx_href">GitHub</a></td>
<td id="A6.T11.4.12.11.4" class="ltx_td ltx_align_center ltx_border_bb">Apache-2.0</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.07258" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.07259" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.07259">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.07259" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.07260" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 23:23:37 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
