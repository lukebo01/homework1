<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.14418] MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues</title><meta property="og:description" content="Automatic Speech Recognition (ASR) systems are used to transcribe speech into text, yet the errors they introduce can significantly degrade the performance of downstream tasks like summarization. This issue is particul…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.14418">

<!--Generated on Thu Sep  5 11:57:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MEDSAGE: Enhancing Robustness of <span id="id5.id1" class="ltx_text ltx_framed ltx_framed_underline">Me</span>dical <span id="id6.id2" class="ltx_text ltx_framed ltx_framed_underline">D</span>ialogue <span id="id7.id3" class="ltx_text ltx_framed ltx_framed_underline">S</span>ummarization to <span id="id8.id4" class="ltx_text ltx_framed ltx_framed_underline">A</span>SR Errors with LLM-<span id="id9.id5" class="ltx_text ltx_framed ltx_framed_underline">ge</span>nerated Synthetic Dialogues</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Kuluhan Binici<sup id="id1.1.1" class="ltx_sup">1,2<math id="id1.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="id1.1.1.m1.1a"><mo id="id1.1.1.m1.1.1" xref="id1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id1.1.1.m1.1b"><ci id="id1.1.1.m1.1.1.cmml" xref="id1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.m1.1c">\dagger</annotation></semantics></math></sup>,
Abhinav Ramesh Kashyap<sup id="id2.2.2" class="ltx_sup">3<math id="id2.2.2.m1.1" class="ltx_Math" alttext="\mathsection" display="inline"><semantics id="id2.2.2.m1.1a"><mi mathvariant="normal" id="id2.2.2.m1.1.1" xref="id2.2.2.m1.1.1.cmml">§</mi><annotation-xml encoding="MathML-Content" id="id2.2.2.m1.1b"><ci id="id2.2.2.m1.1.1.cmml" xref="id2.2.2.m1.1.1">§</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.2.2.m1.1c">\mathsection</annotation></semantics></math></sup>,
Viktor Schlegel<sup id="id3.3.3" class="ltx_sup">4,5<math id="id3.3.3.m1.1" class="ltx_Math" alttext="\mathsection" display="inline"><semantics id="id3.3.3.m1.1a"><mi mathvariant="normal" id="id3.3.3.m1.1.1" xref="id3.3.3.m1.1.1.cmml">§</mi><annotation-xml encoding="MathML-Content" id="id3.3.3.m1.1b"><ci id="id3.3.3.m1.1.1.cmml" xref="id3.3.3.m1.1.1">§</ci></annotation-xml><annotation encoding="application/x-tex" id="id3.3.3.m1.1c">\mathsection</annotation></semantics></math></sup>,
Andy T. Liu<sup id="id10.5.id1" class="ltx_sup">1</sup>,

<br class="ltx_break">Vijay Prakash Dwivedi<sup id="id11.6.id2" class="ltx_sup">1</sup>,
Thanh-Tung Nguyen<sup id="id4.4.4" class="ltx_sup">1<math id="id4.4.4.m1.1" class="ltx_Math" alttext="\mathsection" display="inline"><semantics id="id4.4.4.m1.1a"><mi mathvariant="normal" id="id4.4.4.m1.1.1" xref="id4.4.4.m1.1.1.cmml">§</mi><annotation-xml encoding="MathML-Content" id="id4.4.4.m1.1b"><ci id="id4.4.4.m1.1.1.cmml" xref="id4.4.4.m1.1.1">§</ci></annotation-xml><annotation encoding="application/x-tex" id="id4.4.4.m1.1c">\mathsection</annotation></semantics></math></sup>,
Xiaoxue Gao<sup id="id12.7.id3" class="ltx_sup">6</sup>,
Nancy F. Chen<sup id="id13.8.id4" class="ltx_sup">6</sup>,
Stefan Winkler<sup id="id14.9.id5" class="ltx_sup">1,2</sup>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id15.id1" class="ltx_p">Automatic Speech Recognition (ASR) systems are used to transcribe speech into text, yet the errors they introduce can significantly degrade the performance of downstream tasks like summarization. This issue is particularly pronounced in clinical dialogue summarization, a low-resource domain where supervised data for fine-tuning is scarce, necessitating the use of ASR models as black-box solutions. Employing conventional data augmentation for enhancing the noise robustness of summarization models is not feasible either due to the unavailability of sufficient medical dialogue audio recordings and corresponding ASR transcripts. To address this challenge, we propose <span id="id15.id1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>, an approach for generating synthetic samples for data augmentation using Large Language Models (LLMs). Specifically, we leverage the in-context learning capabilities of LLMs and instruct them to generate ASR-like errors based on a few available medical dialogue examples with audio recordings. Experimental results show that LLMs can effectively model ASR noise, and incorporating this noisy data into the training process significantly improves the robustness and accuracy of medical dialogue summarization systems. This approach addresses the challenges of noisy ASR outputs in critical applications, offering a robust solution to enhance the reliability of clinical dialogue summarization.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Automatic Speech Recognition (ASR) <cite class="ltx_cite ltx_citemacro_citep">(Yu and Deng <a href="#bib.bib37" title="" class="ltx_ref">2016</a>)</cite> is the task of transcribing speech signals into text, enabling a wide range of applications from voice-activated assistants to automated customer service systems. ASR systems significantly aid various downstream tasks such as dialogue summarization <cite class="ltx_cite ltx_citemacro_citep">(Zhong et al. <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>, where the goal is to distill key information from spoken interactions. However, errors introduced by ASR systems can degrade the performance of these summarization tasks <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a href="#bib.bib18" title="" class="ltx_ref">2014</a>; Guo et al. <a href="#bib.bib10" title="" class="ltx_ref">2024</a>)</cite>, which limits their application in high-stake domains where correctness of the summaries is important. The synthesis of Electronic Medical Records (EMRs) from doctor-patient dialogues <cite class="ltx_cite ltx_citemacro_citep">(Krishna et al. <a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> is among such summarization tasks where accuracy is critical. Here, ASR errors can lead to inaccuracies in transcribing clinical terms, medication, or procedure names, resulting in erroneous medical notes <cite class="ltx_cite ltx_citemacro_citep">(Hodgson and Coiera <a href="#bib.bib11" title="" class="ltx_ref">2016</a>)</cite>, which can lead to misdiagnosis, incorrect treatment plans, and potentially harmful patient outcomes.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">One way to improve dialogue summarization is to improve the ASR systems. However, this requires large amounts of supervised data <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite>, which is often unavailable in the healthcare domain due to privacy and ethical concerns surrounding the recording of doctor-patient conversations. Consequently, practical clinical summarization systems often treat ASR systems as black boxes, mandating that overall improvements must arise either from post-processing ASR outputs as a separate step, or making down-stream methods robust to ASR errors. Recent works propose post-processing ASR outputs using LLMs to correct erroneous ASR transcripts <cite class="ltx_cite ltx_citemacro_citep">(Radhakrishnan et al. <a href="#bib.bib28" title="" class="ltx_ref">2023</a>; Bai et al. <a href="#bib.bib2" title="" class="ltx_ref">2024</a>)</cite>. Nonetheless, based on prior studies, using prompting techniques to clear noise only proves effective only when using LLMs of large sizes, typically those that exceed 100B parameters <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib36" title="" class="ltx_ref">2023</a>)</cite>. Moreover, LLMs are prone to hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Maynez et al. <a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite>, which can introduce irrelevant symptoms or medication names into the dialogue transcript, potentially degrading summarization quality while attempting to clear ASR noise.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Alternatively, the summarization robustness to ASR errors can be improved through data augmentation techniques <cite class="ltx_cite ltx_citemacro_citep">(Fabbri et al. <a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>. However, the conventional augmentation approach of exposing the summarization model to erroneous ASR dialogues during the training phase is not feasible either, again due to the limited availability of medical dialogue audio preventing the generation of ASR dialogue transcripts <cite class="ltx_cite ltx_citemacro_citep">(Nanayakkara et al. <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite>. Heuristic approaches for augmentation, such as randomly applying a set of corruption operations, are not ideal either, as they fail to accurately mimic ASR errors both qualitatively and quantitatively, causing the augmented training data distribution to diverge from the real test distribution <cite class="ltx_cite ltx_citemacro_citep">(Wang et al. <a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Recognizing these limitations, we propose the use of LLMs to generate synthetic dialogues mimicking <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">real</em> ASR transcriptions with their characteristic errors, as a means for data augmentation. To circumvent hallucinations, we rely on the signal from downstream tasks during fine-tuning on these generated transcripts. As such, if new domain-specific entities are mistakenly hallucinated during the augmentation process, the fine-tuning phase ensures that the model learns to disregard these irrelevant entities, increasing the feasibility of this approach as a result. To accommodate for the scarcity of medical audio recordings, we leverage the in-context learning <cite class="ltx_cite ltx_citemacro_citep">(Brown et al. <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> capabilities to specialize LLMs for the task of ASR transcript generation based on a few descriptive examples. Specifically, using Primock57 dataset <cite class="ltx_cite ltx_citemacro_citep">(Papadopoulos Korfiatis et al. <a href="#bib.bib25" title="" class="ltx_ref">2022</a>)</cite>, which includes audio recordings of clinical visits alongside their corresponding human-transcribed text, we first produce noisy transcriptions using ASR models. These noisy ASR dialogue transcripts are then paired with their clean human-transcribed versions to form the few-shot examples needed for effective in-context learning.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">While in-context learning enables the qualitative approximation of ASR errors such as phonetic confusions, ensuring that synthetic errors are quantitatively similar remains a challenge <cite class="ltx_cite ltx_citemacro_citep">(Everson et al. <a href="#bib.bib8" title="" class="ltx_ref">2024</a>)</cite>. To address this, we first analyze the error profile of ASR models by measuring their word-error-rates and the distribution of error types, including insertions, deletions, and substitutions. Subsequently, we introduce a novel description syntax that instructs the LLMs on where to make realistic errors and what types of errors to introduce. By tagging the inputs with appropriate error tags based on the measured noise profiles of the target ASR models, we ensure that the synthetic errors generated are both qualitatively and quantitatively similar to real-world ASR errors. This methodology allows us to create synthetic noisy dialogues that accurately reflect ASR error patterns, which can be used for effective data augmentation in training robust summarization models.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Our experimental evaluation reveals that large language models (LLMs) are effective noise modelers, capable of producing errors similar to those found in transcripts produced by ASR. This is evident from the qunatitative and qualitative similarities between the word error profiles of the synthetic dialogues we generate and actual ASR dialogue transcripts. Such similarity also reflects on the downstream summarization performance, mirroring the performance drop caused by ASR errors. Lastly, when we utilize these synthetic noisy dialogues to augment the training set of the summarization models, the performance on the noisy test set improves by up to <math id="S1.p6.1.m1.1" class="ltx_Math" alttext="16\%" display="inline"><semantics id="S1.p6.1.m1.1a"><mrow id="S1.p6.1.m1.1.1" xref="S1.p6.1.m1.1.1.cmml"><mn id="S1.p6.1.m1.1.1.2" xref="S1.p6.1.m1.1.1.2.cmml">16</mn><mo id="S1.p6.1.m1.1.1.1" xref="S1.p6.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p6.1.m1.1b"><apply id="S1.p6.1.m1.1.1.cmml" xref="S1.p6.1.m1.1.1"><csymbol cd="latexml" id="S1.p6.1.m1.1.1.1.cmml" xref="S1.p6.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.p6.1.m1.1.1.2.cmml" xref="S1.p6.1.m1.1.1.2">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.1.m1.1c">16\%</annotation></semantics></math>, indicating enhanced robustness against ASR errors. In summary, our contributions leading to the robustness are:</p>
</div>
<div id="S1.p7" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We utilize the in-context learning ability of LLMs to create synthetic errors that closely resemble those present in ASR transcriptions. This method is used as a data augmentation strategy to improve the strength of dialogue summarization models in situations where audio recordings are limited.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We introduce an error tagging syntax designed to accurately match the error patterns of real ASR transcriptions in the generated synthetic dialogues. This syntax provides detailed control over the type and amount of errors added, ensuring that the synthetic data closely aligns with real-world ASR errors.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dialogue Summarization</h5>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">Summarizing human conversations or speech has been a longstanding challenge that has received significant attention over the years <cite class="ltx_cite ltx_citemacro_citep">(Hori and Furui <a href="#bib.bib12" title="" class="ltx_ref">2003</a>; Liu and Hakkani-Tür <a href="#bib.bib22" title="" class="ltx_ref">2011</a>)</cite>. An important subset of these endeavors involves ASR-based summarization, where automatic speech recognition systems are used to transcribe spoken dialogues before summarization <cite class="ltx_cite ltx_citemacro_citep">(Zhong et al. <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite>. Recently, this challenge has extended to clinical applications, including the summarization of patient-doctor conversations <cite class="ltx_cite ltx_citemacro_citep">(Krishna et al. <a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>, utilizing LLMs as tools for text comprehension <cite class="ltx_cite ltx_citemacro_citep">(Le-Duc et al. <a href="#bib.bib17" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
<figure id="S2.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.14418/assets/figures/fig_a.png" id="S2.F1.sf1.g1" class="ltx_graphics ltx_img_landscape" width="349" height="119" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">((a)) </span></figcaption>
<figure id="S2.F1.sf2" class="ltx_figure"><img src="/html/2408.14418/assets/figures/fig_b.png" id="S2.F1.sf2.g1" class="ltx_graphics ltx_img_landscape" width="314" height="114" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">((b)) </span></figcaption>
</figure>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of our <span id="S2.F1.sf1.2.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span> pipeline. First in-context examples are constructed and the error profile of the target ASR model is inferred. Later, the error profile, in-context examples and inputs dialogues are processed by the LLM model to generate noisy dialogues.</figcaption>
<br class="ltx_break ltx_break">
<p id="S2.F1.sf1.3" class="ltx_p ltx_figure_panel ltx_align_center"><span class="ltx_rule" style="background:black;display:inline-block;"> </span></p>
</figure>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ASR Error Correction</h5>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">ASR models are prone to producing erroneous dialogue transcripts, especially in challenging environments where the conversation is disrupted by noise. These errors can significantly degrade the quality of downstream tasks like summarization using ASR transcriptions. Recent advancements in LLMs have shown promise in addressing these ASR errors. For instance, <cite class="ltx_cite ltx_citemacro_citet">Yang et al. (<a href="#bib.bib36" title="" class="ltx_ref">2023</a>)</cite> investigated prompting techniques in correcting ASR errors. <cite class="ltx_cite ltx_citemacro_citet">Radhakrishnan et al. (<a href="#bib.bib28" title="" class="ltx_ref">2023</a>)</cite> introduced Whispering LLaMA, a cross-modal generative error correction framework that fuses acoustic information with linguistic representations. <cite class="ltx_cite ltx_citemacro_citet">Bai et al. (<a href="#bib.bib2" title="" class="ltx_ref">2024</a>)</cite> proposed a seed-based method that enhances ASR outputs by integrating linguistic context during correction, effectively reducing error propagation in downstream tasks. <cite class="ltx_cite ltx_citemacro_citet">Hu et al. (<a href="#bib.bib14" title="" class="ltx_ref">2024</a>)</cite> introduced a method that leverages the inherent noise in audio signals to generate robust language embeddings. To provide a standard benchmark for evaluating ASR error correction methods, <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a href="#bib.bib5" title="" class="ltx_ref">2024</a>)</cite> introduced the Hyporadise dataset. These techniques are unsuitable for the medical domain because fine-tuning denoising models is often impractical due to the lack of public medical dialogue audio recordings <cite class="ltx_cite ltx_citemacro_citep">(Nanayakkara et al. <a href="#bib.bib24" title="" class="ltx_ref">2022</a>)</cite>. Additionally, prompting without fine-tuning is only effective for large models <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib36" title="" class="ltx_ref">2023</a>)</cite>, which might be impractical, due to privacy concerns when using public APIs or resource constraints when hosting locally.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data Augmentation</h5>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">Data augmentation (DA) is crucial for enhancing model performance by diversifying training examples. Traditional DA methods in NLP, such as paraphrasing <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al. <a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>, back-translation <cite class="ltx_cite ltx_citemacro_citep">(Sugiyama and Yoshinaga <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite>, and noise injection <cite class="ltx_cite ltx_citemacro_citep">(Wang et al. <a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite>, have been effective in some scenarios, but may not fully capture the complexity of real-world variations. Recent LLM advancements have revolutionized DA by using models like GPT-3 and GPT-4 to generate high-quality synthetic data. For instance, <cite class="ltx_cite ltx_citemacro_citet">Chintagunta et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite> use in-context learning with LLMs to create synthetic medical dialogue summaries, while Dialogic <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite> employs LLMs to generate annotated dialogues with automatic verification and revision. DA is also used to improve robustness against adversarial examples, as used by<cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>, who apply adversarial training to make sentiment analysis models more resilient to noise and variations.
Our method differs by addressing the challenges of augmenting medical dialogue data where real ASR transcripts are scarce. Instead of relying on heuristic corruptions that don’t mimic ASR errors accurately, we use LLMs to generate synthetic dialogues that realistically replicate ASR errors, ensuring the augmented training data better aligns with real-world test conditions.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>MEDSAGE</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We use LLMs to generate realistic ASR noise. On a high level, we pair human-transcribed sentences with their ASR counterparts as in-context examples to an LLM, which we instruct to generate noisy sentences (Section <a href="#S3.SS1" title="3.1 Error Generation using In-context Learning ‣ 3 MEDSAGE ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>). These examples convey the qualitative aspects of the ASR errors such as phonetic confusions. To also ensure that the errors in the generated synthetic dialogues quantitatively match that of the ASR transcriptions, we propose a controlled generation strategy (Section <a href="#S3.SS2" title="3.2 Controlled Generation ‣ 3 MEDSAGE ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>). Our strategy involves introducing a tagging syntax that instructs the LLM on the specific word locations to corrupt with specific types of errors. This enables the generation of synthetic dialogues with any arbitrary error distribution that mirrors the characteristics observed in real ASR transcriptions. An overview of our <span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span> pipeline is given in Figure <a href="#S2.F1.sf1" title="Figure 1 ‣ Dialogue Summarization ‣ 2 Related Work ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Error Generation using In-context Learning</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To generate synthetic noisy dialogues, we first use a specialised system prompt to instruct the LLMs about the error generation task. Later we form the in-context examples by pairing sentences from human-transcribed clean dialogues with their ASR-generated counterparts. These examples are subsequently provided to the LLMs to convey the characteristics of ASR errors that we are trying to mimic. An example query that illustrates our structure when prompting the noise-generating LLMs is displayed in the following colored box. As seen from the example, the clean sentences are given as inputs and the responses are expected to contain erroneous versions as if they were obtained through ASR models. The curly braces surrounding certain substrings are a part of our error tagging system, which is detailed later in Section <a href="#S3.SS2" title="3.2 Controlled Generation ‣ 3 MEDSAGE ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, and they denote which words or substrings are transcribed wrongly by the ASR models and how. For instance, in the example provided, the word “Tylenol” is wrongly transcribed as “tie-and-all”, highlighting the common issue of ASR systems confusing tokens with similar pronunciation. Lastly, the input at the end contains the actual clean sentence that we aim to corrupt. The words to be corrupted are also indicated to the LLM through the use of curly braces.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<svg id="S3.SS1.p2.pic1" class="ltx_picture" height="319.16" overflow="visible" version="1.1" width="600"><g transform="translate(0,319.16) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#0000BF" fill-opacity="1.0"><path d="M 0 5.91 L 0 313.25 C 0 316.51 2.64 319.16 5.91 319.16 L 594.09 319.16 C 597.36 319.16 600 316.51 600 313.25 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 295.05 L 598.03 295.05 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 300.95)"><foreignObject width="556.69" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S3.SS1.p2.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="S3.SS1.p2.pic1.2.2.2.1.1.1" class="ltx_p">In-Context Learning for ASR Noise Generation</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 5.91)"><foreignObject width="556.69" height="277.33" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1" class="ltx_p"><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1" class="ltx_text ltx_font_bold">### System Prompt:</span> 
<br class="ltx_break">You are an AI assistant tasked with simulating errors similar to those made by Automated Speech Recognition (ASR) systems. You will be given sentences with the type of errors to be made indicated by tags. Corrupt the sentences based on <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2" class="ltx_text ltx_font_typewriter">[explanation of the tagging system]</span>.
<br class="ltx_break">
<br class="ltx_break"> <svg id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1" class="ltx_picture" height="130.81" overflow="visible" version="1.1" width="600"><g transform="translate(0,130.81) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#666666" fill-opacity="1.0"><path d="M 0 0 L 0 130.81 L 600 130.81 L 600 0 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 1.97 L 1.97 114.58 L 598.03 114.58 L 598.03 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 17.72 116.54)"><foreignObject width="564.57" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">
<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:408.0pt;">
<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.2.2.2.1.1.1" class="ltx_p">In-Context Examples</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 17.72 9.84)"><foreignObject width="564.57" height="96.86" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" style="width:408.0pt;">
<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1" class="ltx_p"><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1" class="ltx_text ltx_font_bold">### Input:</span> I <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2" class="ltx_text ltx_font_bold">{</span>took a Tylenol<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.3" class="ltx_text ltx_font_bold">}</span> <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.4" class="ltx_text ltx_font_typewriter">(human-</span> 
<br class="ltx_break"><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.5" class="ltx_text ltx_font_typewriter">transcribed)
<br class="ltx_break"></span><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.6" class="ltx_text ltx_font_bold">### Response:</span> I <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.7" class="ltx_text ltx_font_bold">{</span>shook tie-and-all<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.8" class="ltx_text ltx_font_bold">}</span> <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.9" class="ltx_text ltx_font_typewriter">(ASR)
<br class="ltx_break">
<br class="ltx_break"></span><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.10" class="ltx_text ltx_font_bold">### Input:</span> I just had some <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.11" class="ltx_text ltx_font_bold">{</span>diarrhea<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.12" class="ltx_text ltx_font_bold">}</span> for the last three days <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.13" class="ltx_text ltx_font_typewriter">(human-transcribed)
<br class="ltx_break"></span><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.14" class="ltx_text ltx_font_bold">### Response:</span> I just had some <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.15" class="ltx_text ltx_font_bold">{</span>diary<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.16" class="ltx_text ltx_font_bold">}</span> for the last three days <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.17" class="ltx_text ltx_font_typewriter">(ASR)
<br class="ltx_break"></span></span>
</span></span></foreignObject></g></g></svg>
<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.3" class="ltx_text ltx_font_bold">### Input:</span> yeah now i mean have you any have you noticed any kind of <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.4" class="ltx_text ltx_font_bold">{</span>white spots<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.5" class="ltx_text ltx_font_bold">}</span> on the back of your back of your <span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.6" class="ltx_text ltx_font_bold">{</span>throat<span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.7" class="ltx_text ltx_font_bold">}</span> or redness 
<br class="ltx_break"><span id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.8" class="ltx_text ltx_font_bold">### Response:</span> 
<br class="ltx_break"></span>
</span></span></foreignObject></g></g></svg>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Controlled Generation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">For data augmentation to be effective in improving performance on noisy test data, the generated synthetic data must closely follow the error patterns found in real-world ASR outputs. However, solely relying on in-context learning with a few examples often fails to capture the nuanced distribution of errors produced by ASR models. To overcome this limitation, we propose a controlled noise injection mechanism. This is to, ensuring the synthetic data aligns with the error profile of the target ASR model.
This approach relies on a detailed analysis of the types and frequencies of errors in ASR transcripts. Using these insights, we then guide the noise generation process by conditioning the LLM with an error tagging syntax.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ASR Error Profiling:</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">To quantitatively represent the error profile of ASR models, we focus on three primary error types: insertion, deletion, and substitution, which collectively contribute to the calculation of Word Error Rate (WER). To estimate the distribution of these errors, we first transcribe a set of medical conversation dialogues using the ASR models. The transcriptions are then aligned with human-annotated ground truth using the Wagner-Fisher algorithm <cite class="ltx_cite ltx_citemacro_citep">(Wagner and Fischer <a href="#bib.bib32" title="" class="ltx_ref">1974</a>)</cite>. This alignment allows us to and quantify the occurrences of each specific error type produced by the ASR model.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.7" class="ltx_p">We estimate the probability distribution of errors as follows. Let <math id="S3.SS2.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="c_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.1.m1.1a"><msub id="S3.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.1.m1.1b"><apply id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.2">𝑐</ci><ci id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.1.m1.1c">c_{i}</annotation></semantics></math> denote the event that the word at index <math id="S3.SS2.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.2.m2.1a"><mi id="S3.SS2.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.2.m2.1b"><ci id="S3.SS2.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.2.m2.1c">i</annotation></semantics></math> is corrupted. The probability <math id="S3.SS2.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="p(c_{i})" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.3.m3.1a"><mrow id="S3.SS2.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.3" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.2" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.2.cmml">​</mo><mrow id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.3.m3.1b"><apply id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1"><times id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.2"></times><ci id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.3">𝑝</ci><apply id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.2">𝑐</ci><ci id="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.3.m3.1c">p(c_{i})</annotation></semantics></math> of a word being corrupted is defined as the WER of the ASR model i.e., <math id="S3.SS2.SSS0.Px1.p2.4.m4.1" class="ltx_Math" alttext="p(c_{i})" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.4.m4.1a"><mrow id="S3.SS2.SSS0.Px1.p2.4.m4.1.1" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.3" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml">​</mo><mrow id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.2.cmml">c</mi><mi id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.4.m4.1b"><apply id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1"><times id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.2"></times><ci id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.3">𝑝</ci><apply id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.2">𝑐</ci><ci id="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.4.m4.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.4.m4.1c">p(c_{i})</annotation></semantics></math> = WER. Given that a word is corrupted, the probability of a specific error type <math id="S3.SS2.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="e_{t}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.5.m5.1a"><msub id="S3.SS2.SSS0.Px1.p2.5.m5.1.1" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.2" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.2.cmml">e</mi><mi id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.3" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.5.m5.1b"><apply id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.2">𝑒</ci><ci id="S3.SS2.SSS0.Px1.p2.5.m5.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.5.m5.1c">e_{t}</annotation></semantics></math> can be expressed as <math id="S3.SS2.SSS0.Px1.p2.6.m6.1" class="ltx_Math" alttext="p(e_{t}|c_{i})" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.6.m6.1a"><mrow id="S3.SS2.SSS0.Px1.p2.6.m6.1.1" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.3" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.2" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.2.cmml">​</mo><mrow id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.cmml"><msub id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.2" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.2.cmml">e</mi><mi id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.3" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.2" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.2.cmml">c</mi><mi id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.3" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.6.m6.1b"><apply id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1"><times id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.2"></times><ci id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.3">𝑝</ci><apply id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.2">𝑒</ci><ci id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.2">𝑐</ci><ci id="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px1.p2.6.m6.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.6.m6.1c">p(e_{t}|c_{i})</annotation></semantics></math>, where <math id="S3.SS2.SSS0.Px1.p2.7.m7.1" class="ltx_Math" alttext="e_{t}\in\{\textit{insertion, deletion, substitution}\}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.7.m7.1a"><mrow id="S3.SS2.SSS0.Px1.p2.7.m7.1.2" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.cmml"><msub id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.cmml"><mi id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.2" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.2.cmml">e</mi><mi id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.3" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.3.cmml">t</mi></msub><mo id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.1" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.1.cmml">∈</mo><mrow id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.3.2" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.3.2.1" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.3.1.cmml">{</mo><mtext class="ltx_mathvariant_italic" id="S3.SS2.SSS0.Px1.p2.7.m7.1.1" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.1a.cmml">insertion, deletion, substitution</mtext><mo stretchy="false" id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.3.2.2" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.7.m7.1b"><apply id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2"><in id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.1"></in><apply id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.2">𝑒</ci><ci id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.2.3">𝑡</ci></apply><set id="S3.SS2.SSS0.Px1.p2.7.m7.1.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.2.3.2"><ci id="S3.SS2.SSS0.Px1.p2.7.m7.1.1a.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.1"><mtext class="ltx_mathvariant_italic" id="S3.SS2.SSS0.Px1.p2.7.m7.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.7.m7.1.1">insertion, deletion, substitution</mtext></ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.7.m7.1c">e_{t}\in\{\textit{insertion, deletion, substitution}\}</annotation></semantics></math> . These conditional probabilities represent the distribution of different error types observed in the ASR model’s output (See Section <a href="#S5.SS2" title="5.2 Different ASR models exhibit different error profiles ‣ 5 Preliminary Experiments ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>). We use this error distribution to formulate our tagging system.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Tagging System</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">We develop a tagging system to instruct the LLM on the specific word-level corruptions to perform to be able to have more control on the WER of generated noise and the distribution of error types. Specifically, we employ the following tags to indicate the error-type that the model should simulate at the word level.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para ltx_noindent">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Words enclosed in curly brackets <span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">{}</span> should be replaced with phonetically similar words. For instance, <span id="S3.I1.i1.p1.1.2" class="ltx_text ltx_font_typewriter">{wheezy}</span> might be replaced with <span id="S3.I1.i1.p1.1.3" class="ltx_text ltx_font_typewriter">{weesy}</span>, and <span id="S3.I1.i1.p1.1.4" class="ltx_text ltx_font_typewriter">{Tylenol}</span> could be changed to <span id="S3.I1.i1.p1.1.5" class="ltx_text ltx_font_typewriter">{tie-and-all}</span>.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">The tag <span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">(INSERTION)</span> indicates where a new word should be inserted. These new words should be general in nature and should not introduce new domain-specific terminology such as drug names or symptoms.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">We do not specify any tags for deletion; instead, words that need to be deleted are simply removed from the text.</p>
</div>
</li>
</ul>
<p id="S3.SS2.SSS0.Px2.p2.1" class="ltx_p">This meaning of the tagging system is conveyed to the the model both through the system prompt and in-context examples. To decorate the in-context examples with error tags accordingly, we align the clean and noisy examples pairs using the Wagner-Fisher algorithm and determine the locations of word errors along with their types. During inference, these tags are randomly applied on the ground-truth transcripts based on the estimated error distribution of the target ASR model. The probability of tagging a word at index <math id="S3.SS2.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.1.m1.1c">i</annotation></semantics></math> with a specific error type is thus given by:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="p(e_{t}|c_{i})\cdot p(c_{i})" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.2.cmml">e</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.3.2.cmml">c</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">⋅</mo><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.3" xref="S3.E1.m1.2.2.3.cmml">​</mo><mrow id="S3.E1.m1.2.2.2.1" xref="S3.E1.m1.2.2.2.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.1.2" xref="S3.E1.m1.2.2.2.1.1.cmml">(</mo><msub id="S3.E1.m1.2.2.2.1.1" xref="S3.E1.m1.2.2.2.1.1.cmml"><mi id="S3.E1.m1.2.2.2.1.1.2" xref="S3.E1.m1.2.2.2.1.1.2.cmml">c</mi><mi id="S3.E1.m1.2.2.2.1.1.3" xref="S3.E1.m1.2.2.2.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.2.2.2.1.3" xref="S3.E1.m1.2.2.2.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><times id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.3"></times><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><ci id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2">⋅</ci><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3">𝑝</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.2">𝑒</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3.2">𝑐</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">𝑝</ci></apply><apply id="S3.E1.m1.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.2.1.1.2">𝑐</ci><ci id="S3.E1.m1.2.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.2.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">p(e_{t}|c_{i})\cdot p(c_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS0.Px2.p2.2" class="ltx_p">which is the joint probability of a word being corrupted and the occurrence of a specific error type.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Generating Synthetic Noisy Dialogues Using LLMs</figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1:</span><span id="alg1.l1.1" class="ltx_text ltx_font_bold">Input:</span> Clean transcripts <math id="alg1.l1.m1.1" class="ltx_Math" alttext="T_{\text{cln}}" display="inline"><semantics id="alg1.l1.m1.1a"><msub id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mi id="alg1.l1.m1.1.1.2" xref="alg1.l1.m1.1.1.2.cmml">T</mi><mtext id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3a.cmml">cln</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1">subscript</csymbol><ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">𝑇</ci><ci id="alg1.l1.m1.1.1.3a.cmml" xref="alg1.l1.m1.1.1.3"><mtext mathsize="70%" id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">cln</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">T_{\text{cln}}</annotation></semantics></math>, in-context example pairs <math id="alg1.l1.m2.1" class="ltx_Math" alttext="E_{\text{in}}" display="inline"><semantics id="alg1.l1.m2.1a"><msub id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml"><mi id="alg1.l1.m2.1.1.2" xref="alg1.l1.m2.1.1.2.cmml">E</mi><mtext id="alg1.l1.m2.1.1.3" xref="alg1.l1.m2.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><apply id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.1.1.1.cmml" xref="alg1.l1.m2.1.1">subscript</csymbol><ci id="alg1.l1.m2.1.1.2.cmml" xref="alg1.l1.m2.1.1.2">𝐸</ci><ci id="alg1.l1.m2.1.1.3a.cmml" xref="alg1.l1.m2.1.1.3"><mtext mathsize="70%" id="alg1.l1.m2.1.1.3.cmml" xref="alg1.l1.m2.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">E_{\text{in}}</annotation></semantics></math>, LLM

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2:</span><span id="alg1.l2.1" class="ltx_text ltx_font_bold">Output:</span> Synthetic noisy dialogues <math id="alg1.l2.m1.1" class="ltx_Math" alttext="T_{\text{syn}}" display="inline"><semantics id="alg1.l2.m1.1a"><msub id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">T</mi><mtext id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3a.cmml">syn</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">𝑇</ci><ci id="alg1.l2.m1.1.1.3a.cmml" xref="alg1.l2.m1.1.1.3"><mtext mathsize="70%" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">syn</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">T_{\text{syn}}</annotation></semantics></math>

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3:</span>
</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4:</span># Create in-context examples

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5:</span><span id="alg1.l5.1" class="ltx_text ltx_font_bold">for</span> each pair <math id="alg1.l5.m1.2" class="ltx_Math" alttext="(t_{\text{cln}},t_{\text{ASR}})" display="inline"><semantics id="alg1.l5.m1.2a"><mrow id="alg1.l5.m1.2.2.2" xref="alg1.l5.m1.2.2.3.cmml"><mo stretchy="false" id="alg1.l5.m1.2.2.2.3" xref="alg1.l5.m1.2.2.3.cmml">(</mo><msub id="alg1.l5.m1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.cmml"><mi id="alg1.l5.m1.1.1.1.1.2" xref="alg1.l5.m1.1.1.1.1.2.cmml">t</mi><mtext id="alg1.l5.m1.1.1.1.1.3" xref="alg1.l5.m1.1.1.1.1.3a.cmml">cln</mtext></msub><mo id="alg1.l5.m1.2.2.2.4" xref="alg1.l5.m1.2.2.3.cmml">,</mo><msub id="alg1.l5.m1.2.2.2.2" xref="alg1.l5.m1.2.2.2.2.cmml"><mi id="alg1.l5.m1.2.2.2.2.2" xref="alg1.l5.m1.2.2.2.2.2.cmml">t</mi><mtext id="alg1.l5.m1.2.2.2.2.3" xref="alg1.l5.m1.2.2.2.2.3a.cmml">ASR</mtext></msub><mo stretchy="false" id="alg1.l5.m1.2.2.2.5" xref="alg1.l5.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.2b"><interval closure="open" id="alg1.l5.m1.2.2.3.cmml" xref="alg1.l5.m1.2.2.2"><apply id="alg1.l5.m1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1">subscript</csymbol><ci id="alg1.l5.m1.1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.1.2">𝑡</ci><ci id="alg1.l5.m1.1.1.1.1.3a.cmml" xref="alg1.l5.m1.1.1.1.1.3"><mtext mathsize="70%" id="alg1.l5.m1.1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.1.3">cln</mtext></ci></apply><apply id="alg1.l5.m1.2.2.2.2.cmml" xref="alg1.l5.m1.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l5.m1.2.2.2.2.1.cmml" xref="alg1.l5.m1.2.2.2.2">subscript</csymbol><ci id="alg1.l5.m1.2.2.2.2.2.cmml" xref="alg1.l5.m1.2.2.2.2.2">𝑡</ci><ci id="alg1.l5.m1.2.2.2.2.3a.cmml" xref="alg1.l5.m1.2.2.2.2.3"><mtext mathsize="70%" id="alg1.l5.m1.2.2.2.2.3.cmml" xref="alg1.l5.m1.2.2.2.2.3">ASR</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.2c">(t_{\text{cln}},t_{\text{ASR}})</annotation></semantics></math> in <math id="alg1.l5.m2.1" class="ltx_Math" alttext="E_{\text{in}}" display="inline"><semantics id="alg1.l5.m2.1a"><msub id="alg1.l5.m2.1.1" xref="alg1.l5.m2.1.1.cmml"><mi id="alg1.l5.m2.1.1.2" xref="alg1.l5.m2.1.1.2.cmml">E</mi><mtext id="alg1.l5.m2.1.1.3" xref="alg1.l5.m2.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l5.m2.1b"><apply id="alg1.l5.m2.1.1.cmml" xref="alg1.l5.m2.1.1"><csymbol cd="ambiguous" id="alg1.l5.m2.1.1.1.cmml" xref="alg1.l5.m2.1.1">subscript</csymbol><ci id="alg1.l5.m2.1.1.2.cmml" xref="alg1.l5.m2.1.1.2">𝐸</ci><ci id="alg1.l5.m2.1.1.3a.cmml" xref="alg1.l5.m2.1.1.3"><mtext mathsize="70%" id="alg1.l5.m2.1.1.3.cmml" xref="alg1.l5.m2.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m2.1c">E_{\text{in}}</annotation></semantics></math> <span id="alg1.l5.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6:</span>     Compute word-locations and types of errors <math id="alg1.l6.m1.1" class="ltx_Math" alttext="e_{i}" display="inline"><semantics id="alg1.l6.m1.1a"><msub id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mi id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">e</mi><mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">𝑒</ci><ci id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">e_{i}</annotation></semantics></math>, <math id="alg1.l6.m2.1" class="ltx_Math" alttext="e_{t}" display="inline"><semantics id="alg1.l6.m2.1a"><msub id="alg1.l6.m2.1.1" xref="alg1.l6.m2.1.1.cmml"><mi id="alg1.l6.m2.1.1.2" xref="alg1.l6.m2.1.1.2.cmml">e</mi><mi id="alg1.l6.m2.1.1.3" xref="alg1.l6.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b"><apply id="alg1.l6.m2.1.1.cmml" xref="alg1.l6.m2.1.1"><csymbol cd="ambiguous" id="alg1.l6.m2.1.1.1.cmml" xref="alg1.l6.m2.1.1">subscript</csymbol><ci id="alg1.l6.m2.1.1.2.cmml" xref="alg1.l6.m2.1.1.2">𝑒</ci><ci id="alg1.l6.m2.1.1.3.cmml" xref="alg1.l6.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m2.1c">e_{t}</annotation></semantics></math>

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7:</span>     <math id="alg1.l7.m1.6" class="ltx_Math" alttext="(t_{\text{cln}},t_{\text{ASR}})^{\prime}\leftarrow\text{insert\_tags}(t_{\text{cln}},t_{\text{ASR}},e_{i},e_{t})" display="inline"><semantics id="alg1.l7.m1.6a"><mrow id="alg1.l7.m1.6.6" xref="alg1.l7.m1.6.6.cmml"><msup id="alg1.l7.m1.2.2.2" xref="alg1.l7.m1.2.2.2.cmml"><mrow id="alg1.l7.m1.2.2.2.2.2" xref="alg1.l7.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="alg1.l7.m1.2.2.2.2.2.3" xref="alg1.l7.m1.2.2.2.2.3.cmml">(</mo><msub id="alg1.l7.m1.1.1.1.1.1.1" xref="alg1.l7.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l7.m1.1.1.1.1.1.1.2" xref="alg1.l7.m1.1.1.1.1.1.1.2.cmml">t</mi><mtext id="alg1.l7.m1.1.1.1.1.1.1.3" xref="alg1.l7.m1.1.1.1.1.1.1.3a.cmml">cln</mtext></msub><mo id="alg1.l7.m1.2.2.2.2.2.4" xref="alg1.l7.m1.2.2.2.2.3.cmml">,</mo><msub id="alg1.l7.m1.2.2.2.2.2.2" xref="alg1.l7.m1.2.2.2.2.2.2.cmml"><mi id="alg1.l7.m1.2.2.2.2.2.2.2" xref="alg1.l7.m1.2.2.2.2.2.2.2.cmml">t</mi><mtext id="alg1.l7.m1.2.2.2.2.2.2.3" xref="alg1.l7.m1.2.2.2.2.2.2.3a.cmml">ASR</mtext></msub><mo stretchy="false" id="alg1.l7.m1.2.2.2.2.2.5" xref="alg1.l7.m1.2.2.2.2.3.cmml">)</mo></mrow><mo id="alg1.l7.m1.2.2.2.4" xref="alg1.l7.m1.2.2.2.4.cmml">′</mo></msup><mo stretchy="false" id="alg1.l7.m1.6.6.7" xref="alg1.l7.m1.6.6.7.cmml">←</mo><mrow id="alg1.l7.m1.6.6.6" xref="alg1.l7.m1.6.6.6.cmml"><mtext id="alg1.l7.m1.6.6.6.6" xref="alg1.l7.m1.6.6.6.6a.cmml">insert_tags</mtext><mo lspace="0em" rspace="0em" id="alg1.l7.m1.6.6.6.5" xref="alg1.l7.m1.6.6.6.5.cmml">​</mo><mrow id="alg1.l7.m1.6.6.6.4.4" xref="alg1.l7.m1.6.6.6.4.5.cmml"><mo stretchy="false" id="alg1.l7.m1.6.6.6.4.4.5" xref="alg1.l7.m1.6.6.6.4.5.cmml">(</mo><msub id="alg1.l7.m1.3.3.3.1.1.1" xref="alg1.l7.m1.3.3.3.1.1.1.cmml"><mi id="alg1.l7.m1.3.3.3.1.1.1.2" xref="alg1.l7.m1.3.3.3.1.1.1.2.cmml">t</mi><mtext id="alg1.l7.m1.3.3.3.1.1.1.3" xref="alg1.l7.m1.3.3.3.1.1.1.3a.cmml">cln</mtext></msub><mo id="alg1.l7.m1.6.6.6.4.4.6" xref="alg1.l7.m1.6.6.6.4.5.cmml">,</mo><msub id="alg1.l7.m1.4.4.4.2.2.2" xref="alg1.l7.m1.4.4.4.2.2.2.cmml"><mi id="alg1.l7.m1.4.4.4.2.2.2.2" xref="alg1.l7.m1.4.4.4.2.2.2.2.cmml">t</mi><mtext id="alg1.l7.m1.4.4.4.2.2.2.3" xref="alg1.l7.m1.4.4.4.2.2.2.3a.cmml">ASR</mtext></msub><mo id="alg1.l7.m1.6.6.6.4.4.7" xref="alg1.l7.m1.6.6.6.4.5.cmml">,</mo><msub id="alg1.l7.m1.5.5.5.3.3.3" xref="alg1.l7.m1.5.5.5.3.3.3.cmml"><mi id="alg1.l7.m1.5.5.5.3.3.3.2" xref="alg1.l7.m1.5.5.5.3.3.3.2.cmml">e</mi><mi id="alg1.l7.m1.5.5.5.3.3.3.3" xref="alg1.l7.m1.5.5.5.3.3.3.3.cmml">i</mi></msub><mo id="alg1.l7.m1.6.6.6.4.4.8" xref="alg1.l7.m1.6.6.6.4.5.cmml">,</mo><msub id="alg1.l7.m1.6.6.6.4.4.4" xref="alg1.l7.m1.6.6.6.4.4.4.cmml"><mi id="alg1.l7.m1.6.6.6.4.4.4.2" xref="alg1.l7.m1.6.6.6.4.4.4.2.cmml">e</mi><mi id="alg1.l7.m1.6.6.6.4.4.4.3" xref="alg1.l7.m1.6.6.6.4.4.4.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.l7.m1.6.6.6.4.4.9" xref="alg1.l7.m1.6.6.6.4.5.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.6b"><apply id="alg1.l7.m1.6.6.cmml" xref="alg1.l7.m1.6.6"><ci id="alg1.l7.m1.6.6.7.cmml" xref="alg1.l7.m1.6.6.7">←</ci><apply id="alg1.l7.m1.2.2.2.cmml" xref="alg1.l7.m1.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.m1.2.2.2.3.cmml" xref="alg1.l7.m1.2.2.2">superscript</csymbol><interval closure="open" id="alg1.l7.m1.2.2.2.2.3.cmml" xref="alg1.l7.m1.2.2.2.2.2"><apply id="alg1.l7.m1.1.1.1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l7.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l7.m1.1.1.1.1.1.1.2">𝑡</ci><ci id="alg1.l7.m1.1.1.1.1.1.1.3a.cmml" xref="alg1.l7.m1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="alg1.l7.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l7.m1.1.1.1.1.1.1.3">cln</mtext></ci></apply><apply id="alg1.l7.m1.2.2.2.2.2.2.cmml" xref="alg1.l7.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.m1.2.2.2.2.2.2.1.cmml" xref="alg1.l7.m1.2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l7.m1.2.2.2.2.2.2.2.cmml" xref="alg1.l7.m1.2.2.2.2.2.2.2">𝑡</ci><ci id="alg1.l7.m1.2.2.2.2.2.2.3a.cmml" xref="alg1.l7.m1.2.2.2.2.2.2.3"><mtext mathsize="70%" id="alg1.l7.m1.2.2.2.2.2.2.3.cmml" xref="alg1.l7.m1.2.2.2.2.2.2.3">ASR</mtext></ci></apply></interval><ci id="alg1.l7.m1.2.2.2.4.cmml" xref="alg1.l7.m1.2.2.2.4">′</ci></apply><apply id="alg1.l7.m1.6.6.6.cmml" xref="alg1.l7.m1.6.6.6"><times id="alg1.l7.m1.6.6.6.5.cmml" xref="alg1.l7.m1.6.6.6.5"></times><ci id="alg1.l7.m1.6.6.6.6a.cmml" xref="alg1.l7.m1.6.6.6.6"><mtext id="alg1.l7.m1.6.6.6.6.cmml" xref="alg1.l7.m1.6.6.6.6">insert_tags</mtext></ci><vector id="alg1.l7.m1.6.6.6.4.5.cmml" xref="alg1.l7.m1.6.6.6.4.4"><apply id="alg1.l7.m1.3.3.3.1.1.1.cmml" xref="alg1.l7.m1.3.3.3.1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.3.3.3.1.1.1.1.cmml" xref="alg1.l7.m1.3.3.3.1.1.1">subscript</csymbol><ci id="alg1.l7.m1.3.3.3.1.1.1.2.cmml" xref="alg1.l7.m1.3.3.3.1.1.1.2">𝑡</ci><ci id="alg1.l7.m1.3.3.3.1.1.1.3a.cmml" xref="alg1.l7.m1.3.3.3.1.1.1.3"><mtext mathsize="70%" id="alg1.l7.m1.3.3.3.1.1.1.3.cmml" xref="alg1.l7.m1.3.3.3.1.1.1.3">cln</mtext></ci></apply><apply id="alg1.l7.m1.4.4.4.2.2.2.cmml" xref="alg1.l7.m1.4.4.4.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.m1.4.4.4.2.2.2.1.cmml" xref="alg1.l7.m1.4.4.4.2.2.2">subscript</csymbol><ci id="alg1.l7.m1.4.4.4.2.2.2.2.cmml" xref="alg1.l7.m1.4.4.4.2.2.2.2">𝑡</ci><ci id="alg1.l7.m1.4.4.4.2.2.2.3a.cmml" xref="alg1.l7.m1.4.4.4.2.2.2.3"><mtext mathsize="70%" id="alg1.l7.m1.4.4.4.2.2.2.3.cmml" xref="alg1.l7.m1.4.4.4.2.2.2.3">ASR</mtext></ci></apply><apply id="alg1.l7.m1.5.5.5.3.3.3.cmml" xref="alg1.l7.m1.5.5.5.3.3.3"><csymbol cd="ambiguous" id="alg1.l7.m1.5.5.5.3.3.3.1.cmml" xref="alg1.l7.m1.5.5.5.3.3.3">subscript</csymbol><ci id="alg1.l7.m1.5.5.5.3.3.3.2.cmml" xref="alg1.l7.m1.5.5.5.3.3.3.2">𝑒</ci><ci id="alg1.l7.m1.5.5.5.3.3.3.3.cmml" xref="alg1.l7.m1.5.5.5.3.3.3.3">𝑖</ci></apply><apply id="alg1.l7.m1.6.6.6.4.4.4.cmml" xref="alg1.l7.m1.6.6.6.4.4.4"><csymbol cd="ambiguous" id="alg1.l7.m1.6.6.6.4.4.4.1.cmml" xref="alg1.l7.m1.6.6.6.4.4.4">subscript</csymbol><ci id="alg1.l7.m1.6.6.6.4.4.4.2.cmml" xref="alg1.l7.m1.6.6.6.4.4.4.2">𝑒</ci><ci id="alg1.l7.m1.6.6.6.4.4.4.3.cmml" xref="alg1.l7.m1.6.6.6.4.4.4.3">𝑡</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.6c">(t_{\text{cln}},t_{\text{ASR}})^{\prime}\leftarrow\text{insert\_tags}(t_{\text{cln}},t_{\text{ASR}},e_{i},e_{t})</annotation></semantics></math>

</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8:</span>     Replace <math id="alg1.l8.m1.2" class="ltx_Math" alttext="(t_{\text{cln}},t_{\text{ASR}})" display="inline"><semantics id="alg1.l8.m1.2a"><mrow id="alg1.l8.m1.2.2.2" xref="alg1.l8.m1.2.2.3.cmml"><mo stretchy="false" id="alg1.l8.m1.2.2.2.3" xref="alg1.l8.m1.2.2.3.cmml">(</mo><msub id="alg1.l8.m1.1.1.1.1" xref="alg1.l8.m1.1.1.1.1.cmml"><mi id="alg1.l8.m1.1.1.1.1.2" xref="alg1.l8.m1.1.1.1.1.2.cmml">t</mi><mtext id="alg1.l8.m1.1.1.1.1.3" xref="alg1.l8.m1.1.1.1.1.3a.cmml">cln</mtext></msub><mo id="alg1.l8.m1.2.2.2.4" xref="alg1.l8.m1.2.2.3.cmml">,</mo><msub id="alg1.l8.m1.2.2.2.2" xref="alg1.l8.m1.2.2.2.2.cmml"><mi id="alg1.l8.m1.2.2.2.2.2" xref="alg1.l8.m1.2.2.2.2.2.cmml">t</mi><mtext id="alg1.l8.m1.2.2.2.2.3" xref="alg1.l8.m1.2.2.2.2.3a.cmml">ASR</mtext></msub><mo stretchy="false" id="alg1.l8.m1.2.2.2.5" xref="alg1.l8.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.2b"><interval closure="open" id="alg1.l8.m1.2.2.3.cmml" xref="alg1.l8.m1.2.2.2"><apply id="alg1.l8.m1.1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1.1">subscript</csymbol><ci id="alg1.l8.m1.1.1.1.1.2.cmml" xref="alg1.l8.m1.1.1.1.1.2">𝑡</ci><ci id="alg1.l8.m1.1.1.1.1.3a.cmml" xref="alg1.l8.m1.1.1.1.1.3"><mtext mathsize="70%" id="alg1.l8.m1.1.1.1.1.3.cmml" xref="alg1.l8.m1.1.1.1.1.3">cln</mtext></ci></apply><apply id="alg1.l8.m1.2.2.2.2.cmml" xref="alg1.l8.m1.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l8.m1.2.2.2.2.1.cmml" xref="alg1.l8.m1.2.2.2.2">subscript</csymbol><ci id="alg1.l8.m1.2.2.2.2.2.cmml" xref="alg1.l8.m1.2.2.2.2.2">𝑡</ci><ci id="alg1.l8.m1.2.2.2.2.3a.cmml" xref="alg1.l8.m1.2.2.2.2.3"><mtext mathsize="70%" id="alg1.l8.m1.2.2.2.2.3.cmml" xref="alg1.l8.m1.2.2.2.2.3">ASR</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.2c">(t_{\text{cln}},t_{\text{ASR}})</annotation></semantics></math> with <math id="alg1.l8.m2.2" class="ltx_Math" alttext="(t_{\text{cln}},t_{\text{ASR}})^{\prime}" display="inline"><semantics id="alg1.l8.m2.2a"><msup id="alg1.l8.m2.2.2" xref="alg1.l8.m2.2.2.cmml"><mrow id="alg1.l8.m2.2.2.2.2" xref="alg1.l8.m2.2.2.2.3.cmml"><mo stretchy="false" id="alg1.l8.m2.2.2.2.2.3" xref="alg1.l8.m2.2.2.2.3.cmml">(</mo><msub id="alg1.l8.m2.1.1.1.1.1" xref="alg1.l8.m2.1.1.1.1.1.cmml"><mi id="alg1.l8.m2.1.1.1.1.1.2" xref="alg1.l8.m2.1.1.1.1.1.2.cmml">t</mi><mtext id="alg1.l8.m2.1.1.1.1.1.3" xref="alg1.l8.m2.1.1.1.1.1.3a.cmml">cln</mtext></msub><mo id="alg1.l8.m2.2.2.2.2.4" xref="alg1.l8.m2.2.2.2.3.cmml">,</mo><msub id="alg1.l8.m2.2.2.2.2.2" xref="alg1.l8.m2.2.2.2.2.2.cmml"><mi id="alg1.l8.m2.2.2.2.2.2.2" xref="alg1.l8.m2.2.2.2.2.2.2.cmml">t</mi><mtext id="alg1.l8.m2.2.2.2.2.2.3" xref="alg1.l8.m2.2.2.2.2.2.3a.cmml">ASR</mtext></msub><mo stretchy="false" id="alg1.l8.m2.2.2.2.2.5" xref="alg1.l8.m2.2.2.2.3.cmml">)</mo></mrow><mo id="alg1.l8.m2.2.2.4" xref="alg1.l8.m2.2.2.4.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="alg1.l8.m2.2b"><apply id="alg1.l8.m2.2.2.cmml" xref="alg1.l8.m2.2.2"><csymbol cd="ambiguous" id="alg1.l8.m2.2.2.3.cmml" xref="alg1.l8.m2.2.2">superscript</csymbol><interval closure="open" id="alg1.l8.m2.2.2.2.3.cmml" xref="alg1.l8.m2.2.2.2.2"><apply id="alg1.l8.m2.1.1.1.1.1.cmml" xref="alg1.l8.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l8.m2.1.1.1.1.1.1.cmml" xref="alg1.l8.m2.1.1.1.1.1">subscript</csymbol><ci id="alg1.l8.m2.1.1.1.1.1.2.cmml" xref="alg1.l8.m2.1.1.1.1.1.2">𝑡</ci><ci id="alg1.l8.m2.1.1.1.1.1.3a.cmml" xref="alg1.l8.m2.1.1.1.1.1.3"><mtext mathsize="70%" id="alg1.l8.m2.1.1.1.1.1.3.cmml" xref="alg1.l8.m2.1.1.1.1.1.3">cln</mtext></ci></apply><apply id="alg1.l8.m2.2.2.2.2.2.cmml" xref="alg1.l8.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l8.m2.2.2.2.2.2.1.cmml" xref="alg1.l8.m2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l8.m2.2.2.2.2.2.2.cmml" xref="alg1.l8.m2.2.2.2.2.2.2">𝑡</ci><ci id="alg1.l8.m2.2.2.2.2.2.3a.cmml" xref="alg1.l8.m2.2.2.2.2.2.3"><mtext mathsize="70%" id="alg1.l8.m2.2.2.2.2.2.3.cmml" xref="alg1.l8.m2.2.2.2.2.2.3">ASR</mtext></ci></apply></interval><ci id="alg1.l8.m2.2.2.4.cmml" xref="alg1.l8.m2.2.2.4">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m2.2c">(t_{\text{cln}},t_{\text{ASR}})^{\prime}</annotation></semantics></math> in <math id="alg1.l8.m3.1" class="ltx_Math" alttext="E_{\text{in}}" display="inline"><semantics id="alg1.l8.m3.1a"><msub id="alg1.l8.m3.1.1" xref="alg1.l8.m3.1.1.cmml"><mi id="alg1.l8.m3.1.1.2" xref="alg1.l8.m3.1.1.2.cmml">E</mi><mtext id="alg1.l8.m3.1.1.3" xref="alg1.l8.m3.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l8.m3.1b"><apply id="alg1.l8.m3.1.1.cmml" xref="alg1.l8.m3.1.1"><csymbol cd="ambiguous" id="alg1.l8.m3.1.1.1.cmml" xref="alg1.l8.m3.1.1">subscript</csymbol><ci id="alg1.l8.m3.1.1.2.cmml" xref="alg1.l8.m3.1.1.2">𝐸</ci><ci id="alg1.l8.m3.1.1.3a.cmml" xref="alg1.l8.m3.1.1.3"><mtext mathsize="70%" id="alg1.l8.m3.1.1.3.cmml" xref="alg1.l8.m3.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m3.1c">E_{\text{in}}</annotation></semantics></math>

</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9:</span><span id="alg1.l9.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l9.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10:</span>
</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11:</span>Initialize <math id="alg1.l11.m1.1" class="ltx_Math" alttext="T_{\text{syn}}\leftarrow\emptyset" display="inline"><semantics id="alg1.l11.m1.1a"><mrow id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml"><msub id="alg1.l11.m1.1.1.2" xref="alg1.l11.m1.1.1.2.cmml"><mi id="alg1.l11.m1.1.1.2.2" xref="alg1.l11.m1.1.1.2.2.cmml">T</mi><mtext id="alg1.l11.m1.1.1.2.3" xref="alg1.l11.m1.1.1.2.3a.cmml">syn</mtext></msub><mo stretchy="false" id="alg1.l11.m1.1.1.1" xref="alg1.l11.m1.1.1.1.cmml">←</mo><mi mathvariant="normal" id="alg1.l11.m1.1.1.3" xref="alg1.l11.m1.1.1.3.cmml">∅</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><apply id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1"><ci id="alg1.l11.m1.1.1.1.cmml" xref="alg1.l11.m1.1.1.1">←</ci><apply id="alg1.l11.m1.1.1.2.cmml" xref="alg1.l11.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.2.1.cmml" xref="alg1.l11.m1.1.1.2">subscript</csymbol><ci id="alg1.l11.m1.1.1.2.2.cmml" xref="alg1.l11.m1.1.1.2.2">𝑇</ci><ci id="alg1.l11.m1.1.1.2.3a.cmml" xref="alg1.l11.m1.1.1.2.3"><mtext mathsize="70%" id="alg1.l11.m1.1.1.2.3.cmml" xref="alg1.l11.m1.1.1.2.3">syn</mtext></ci></apply><emptyset id="alg1.l11.m1.1.1.3.cmml" xref="alg1.l11.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">T_{\text{syn}}\leftarrow\emptyset</annotation></semantics></math>

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12:</span>
</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13:</span># Prompt LLM with in-context examples

</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14:</span><span id="alg1.l14.1" class="ltx_text ltx_font_bold">for</span> each input dialogue <math id="alg1.l14.m1.1" class="ltx_Math" alttext="t_{\text{cln}}" display="inline"><semantics id="alg1.l14.m1.1a"><msub id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml"><mi id="alg1.l14.m1.1.1.2" xref="alg1.l14.m1.1.1.2.cmml">t</mi><mtext id="alg1.l14.m1.1.1.3" xref="alg1.l14.m1.1.1.3a.cmml">cln</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><apply id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1"><csymbol cd="ambiguous" id="alg1.l14.m1.1.1.1.cmml" xref="alg1.l14.m1.1.1">subscript</csymbol><ci id="alg1.l14.m1.1.1.2.cmml" xref="alg1.l14.m1.1.1.2">𝑡</ci><ci id="alg1.l14.m1.1.1.3a.cmml" xref="alg1.l14.m1.1.1.3"><mtext mathsize="70%" id="alg1.l14.m1.1.1.3.cmml" xref="alg1.l14.m1.1.1.3">cln</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">t_{\text{cln}}</annotation></semantics></math> in <math id="alg1.l14.m2.1" class="ltx_Math" alttext="T_{\text{cln}}" display="inline"><semantics id="alg1.l14.m2.1a"><msub id="alg1.l14.m2.1.1" xref="alg1.l14.m2.1.1.cmml"><mi id="alg1.l14.m2.1.1.2" xref="alg1.l14.m2.1.1.2.cmml">T</mi><mtext id="alg1.l14.m2.1.1.3" xref="alg1.l14.m2.1.1.3a.cmml">cln</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l14.m2.1b"><apply id="alg1.l14.m2.1.1.cmml" xref="alg1.l14.m2.1.1"><csymbol cd="ambiguous" id="alg1.l14.m2.1.1.1.cmml" xref="alg1.l14.m2.1.1">subscript</csymbol><ci id="alg1.l14.m2.1.1.2.cmml" xref="alg1.l14.m2.1.1.2">𝑇</ci><ci id="alg1.l14.m2.1.1.3a.cmml" xref="alg1.l14.m2.1.1.3"><mtext mathsize="70%" id="alg1.l14.m2.1.1.3.cmml" xref="alg1.l14.m2.1.1.3">cln</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m2.1c">T_{\text{cln}}</annotation></semantics></math> <span id="alg1.l14.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15:</span>     Sample error indexes <math id="alg1.l15.m1.1" class="ltx_Math" alttext="e_{i}\sim p(c_{i})" display="inline"><semantics id="alg1.l15.m1.1a"><mrow id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml"><msub id="alg1.l15.m1.1.1.3" xref="alg1.l15.m1.1.1.3.cmml"><mi id="alg1.l15.m1.1.1.3.2" xref="alg1.l15.m1.1.1.3.2.cmml">e</mi><mi id="alg1.l15.m1.1.1.3.3" xref="alg1.l15.m1.1.1.3.3.cmml">i</mi></msub><mo id="alg1.l15.m1.1.1.2" xref="alg1.l15.m1.1.1.2.cmml">∼</mo><mrow id="alg1.l15.m1.1.1.1" xref="alg1.l15.m1.1.1.1.cmml"><mi id="alg1.l15.m1.1.1.1.3" xref="alg1.l15.m1.1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l15.m1.1.1.1.2" xref="alg1.l15.m1.1.1.1.2.cmml">​</mo><mrow id="alg1.l15.m1.1.1.1.1.1" xref="alg1.l15.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="alg1.l15.m1.1.1.1.1.1.2" xref="alg1.l15.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l15.m1.1.1.1.1.1.1" xref="alg1.l15.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l15.m1.1.1.1.1.1.1.2" xref="alg1.l15.m1.1.1.1.1.1.1.2.cmml">c</mi><mi id="alg1.l15.m1.1.1.1.1.1.1.3" xref="alg1.l15.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="alg1.l15.m1.1.1.1.1.1.3" xref="alg1.l15.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><apply id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1"><csymbol cd="latexml" id="alg1.l15.m1.1.1.2.cmml" xref="alg1.l15.m1.1.1.2">similar-to</csymbol><apply id="alg1.l15.m1.1.1.3.cmml" xref="alg1.l15.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l15.m1.1.1.3.1.cmml" xref="alg1.l15.m1.1.1.3">subscript</csymbol><ci id="alg1.l15.m1.1.1.3.2.cmml" xref="alg1.l15.m1.1.1.3.2">𝑒</ci><ci id="alg1.l15.m1.1.1.3.3.cmml" xref="alg1.l15.m1.1.1.3.3">𝑖</ci></apply><apply id="alg1.l15.m1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1"><times id="alg1.l15.m1.1.1.1.2.cmml" xref="alg1.l15.m1.1.1.1.2"></times><ci id="alg1.l15.m1.1.1.1.3.cmml" xref="alg1.l15.m1.1.1.1.3">𝑝</ci><apply id="alg1.l15.m1.1.1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l15.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l15.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.2">𝑐</ci><ci id="alg1.l15.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l15.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">e_{i}\sim p(c_{i})</annotation></semantics></math>

</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16:</span>     Sample error types <math id="alg1.l16.m1.1" class="ltx_Math" alttext="e_{t}\sim p(e_{t}\mid c_{i}=e_{i})" display="inline"><semantics id="alg1.l16.m1.1a"><mrow id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml"><msub id="alg1.l16.m1.1.1.3" xref="alg1.l16.m1.1.1.3.cmml"><mi id="alg1.l16.m1.1.1.3.2" xref="alg1.l16.m1.1.1.3.2.cmml">e</mi><mi id="alg1.l16.m1.1.1.3.3" xref="alg1.l16.m1.1.1.3.3.cmml">t</mi></msub><mo id="alg1.l16.m1.1.1.2" xref="alg1.l16.m1.1.1.2.cmml">∼</mo><mrow id="alg1.l16.m1.1.1.1" xref="alg1.l16.m1.1.1.1.cmml"><mi id="alg1.l16.m1.1.1.1.3" xref="alg1.l16.m1.1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l16.m1.1.1.1.2" xref="alg1.l16.m1.1.1.1.2.cmml">​</mo><mrow id="alg1.l16.m1.1.1.1.1.1" xref="alg1.l16.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="alg1.l16.m1.1.1.1.1.1.2" xref="alg1.l16.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="alg1.l16.m1.1.1.1.1.1.1" xref="alg1.l16.m1.1.1.1.1.1.1.cmml"><mrow id="alg1.l16.m1.1.1.1.1.1.1.2" xref="alg1.l16.m1.1.1.1.1.1.1.2.cmml"><msub id="alg1.l16.m1.1.1.1.1.1.1.2.2" xref="alg1.l16.m1.1.1.1.1.1.1.2.2.cmml"><mi id="alg1.l16.m1.1.1.1.1.1.1.2.2.2" xref="alg1.l16.m1.1.1.1.1.1.1.2.2.2.cmml">e</mi><mi id="alg1.l16.m1.1.1.1.1.1.1.2.2.3" xref="alg1.l16.m1.1.1.1.1.1.1.2.2.3.cmml">t</mi></msub><mo id="alg1.l16.m1.1.1.1.1.1.1.2.1" xref="alg1.l16.m1.1.1.1.1.1.1.2.1.cmml">∣</mo><msub id="alg1.l16.m1.1.1.1.1.1.1.2.3" xref="alg1.l16.m1.1.1.1.1.1.1.2.3.cmml"><mi id="alg1.l16.m1.1.1.1.1.1.1.2.3.2" xref="alg1.l16.m1.1.1.1.1.1.1.2.3.2.cmml">c</mi><mi id="alg1.l16.m1.1.1.1.1.1.1.2.3.3" xref="alg1.l16.m1.1.1.1.1.1.1.2.3.3.cmml">i</mi></msub></mrow><mo id="alg1.l16.m1.1.1.1.1.1.1.1" xref="alg1.l16.m1.1.1.1.1.1.1.1.cmml">=</mo><msub id="alg1.l16.m1.1.1.1.1.1.1.3" xref="alg1.l16.m1.1.1.1.1.1.1.3.cmml"><mi id="alg1.l16.m1.1.1.1.1.1.1.3.2" xref="alg1.l16.m1.1.1.1.1.1.1.3.2.cmml">e</mi><mi id="alg1.l16.m1.1.1.1.1.1.1.3.3" xref="alg1.l16.m1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="alg1.l16.m1.1.1.1.1.1.3" xref="alg1.l16.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b"><apply id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1"><csymbol cd="latexml" id="alg1.l16.m1.1.1.2.cmml" xref="alg1.l16.m1.1.1.2">similar-to</csymbol><apply id="alg1.l16.m1.1.1.3.cmml" xref="alg1.l16.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l16.m1.1.1.3.1.cmml" xref="alg1.l16.m1.1.1.3">subscript</csymbol><ci id="alg1.l16.m1.1.1.3.2.cmml" xref="alg1.l16.m1.1.1.3.2">𝑒</ci><ci id="alg1.l16.m1.1.1.3.3.cmml" xref="alg1.l16.m1.1.1.3.3">𝑡</ci></apply><apply id="alg1.l16.m1.1.1.1.cmml" xref="alg1.l16.m1.1.1.1"><times id="alg1.l16.m1.1.1.1.2.cmml" xref="alg1.l16.m1.1.1.1.2"></times><ci id="alg1.l16.m1.1.1.1.3.cmml" xref="alg1.l16.m1.1.1.1.3">𝑝</ci><apply id="alg1.l16.m1.1.1.1.1.1.1.cmml" xref="alg1.l16.m1.1.1.1.1.1"><eq id="alg1.l16.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.1"></eq><apply id="alg1.l16.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2"><csymbol cd="latexml" id="alg1.l16.m1.1.1.1.1.1.1.2.1.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.1">conditional</csymbol><apply id="alg1.l16.m1.1.1.1.1.1.1.2.2.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="alg1.l16.m1.1.1.1.1.1.1.2.2.1.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="alg1.l16.m1.1.1.1.1.1.1.2.2.2.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.2.2">𝑒</ci><ci id="alg1.l16.m1.1.1.1.1.1.1.2.2.3.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.2.3">𝑡</ci></apply><apply id="alg1.l16.m1.1.1.1.1.1.1.2.3.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="alg1.l16.m1.1.1.1.1.1.1.2.3.1.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="alg1.l16.m1.1.1.1.1.1.1.2.3.2.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.3.2">𝑐</ci><ci id="alg1.l16.m1.1.1.1.1.1.1.2.3.3.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.2.3.3">𝑖</ci></apply></apply><apply id="alg1.l16.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l16.m1.1.1.1.1.1.1.3.1.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="alg1.l16.m1.1.1.1.1.1.1.3.2.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.3.2">𝑒</ci><ci id="alg1.l16.m1.1.1.1.1.1.1.3.3.cmml" xref="alg1.l16.m1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.1c">e_{t}\sim p(e_{t}\mid c_{i}=e_{i})</annotation></semantics></math>

</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17:</span>     <math id="alg1.l17.m1.3" class="ltx_Math" alttext="t_{\text{cln}}^{\prime}\leftarrow\text{insert\_tags}(t_{\text{cln}},e_{i},e_{t})" display="inline"><semantics id="alg1.l17.m1.3a"><mrow id="alg1.l17.m1.3.3" xref="alg1.l17.m1.3.3.cmml"><msubsup id="alg1.l17.m1.3.3.5" xref="alg1.l17.m1.3.3.5.cmml"><mi id="alg1.l17.m1.3.3.5.2.2" xref="alg1.l17.m1.3.3.5.2.2.cmml">t</mi><mtext id="alg1.l17.m1.3.3.5.2.3" xref="alg1.l17.m1.3.3.5.2.3a.cmml">cln</mtext><mo id="alg1.l17.m1.3.3.5.3" xref="alg1.l17.m1.3.3.5.3.cmml">′</mo></msubsup><mo stretchy="false" id="alg1.l17.m1.3.3.4" xref="alg1.l17.m1.3.3.4.cmml">←</mo><mrow id="alg1.l17.m1.3.3.3" xref="alg1.l17.m1.3.3.3.cmml"><mtext id="alg1.l17.m1.3.3.3.5" xref="alg1.l17.m1.3.3.3.5a.cmml">insert_tags</mtext><mo lspace="0em" rspace="0em" id="alg1.l17.m1.3.3.3.4" xref="alg1.l17.m1.3.3.3.4.cmml">​</mo><mrow id="alg1.l17.m1.3.3.3.3.3" xref="alg1.l17.m1.3.3.3.3.4.cmml"><mo stretchy="false" id="alg1.l17.m1.3.3.3.3.3.4" xref="alg1.l17.m1.3.3.3.3.4.cmml">(</mo><msub id="alg1.l17.m1.1.1.1.1.1.1" xref="alg1.l17.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l17.m1.1.1.1.1.1.1.2" xref="alg1.l17.m1.1.1.1.1.1.1.2.cmml">t</mi><mtext id="alg1.l17.m1.1.1.1.1.1.1.3" xref="alg1.l17.m1.1.1.1.1.1.1.3a.cmml">cln</mtext></msub><mo id="alg1.l17.m1.3.3.3.3.3.5" xref="alg1.l17.m1.3.3.3.3.4.cmml">,</mo><msub id="alg1.l17.m1.2.2.2.2.2.2" xref="alg1.l17.m1.2.2.2.2.2.2.cmml"><mi id="alg1.l17.m1.2.2.2.2.2.2.2" xref="alg1.l17.m1.2.2.2.2.2.2.2.cmml">e</mi><mi id="alg1.l17.m1.2.2.2.2.2.2.3" xref="alg1.l17.m1.2.2.2.2.2.2.3.cmml">i</mi></msub><mo id="alg1.l17.m1.3.3.3.3.3.6" xref="alg1.l17.m1.3.3.3.3.4.cmml">,</mo><msub id="alg1.l17.m1.3.3.3.3.3.3" xref="alg1.l17.m1.3.3.3.3.3.3.cmml"><mi id="alg1.l17.m1.3.3.3.3.3.3.2" xref="alg1.l17.m1.3.3.3.3.3.3.2.cmml">e</mi><mi id="alg1.l17.m1.3.3.3.3.3.3.3" xref="alg1.l17.m1.3.3.3.3.3.3.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.l17.m1.3.3.3.3.3.7" xref="alg1.l17.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.3b"><apply id="alg1.l17.m1.3.3.cmml" xref="alg1.l17.m1.3.3"><ci id="alg1.l17.m1.3.3.4.cmml" xref="alg1.l17.m1.3.3.4">←</ci><apply id="alg1.l17.m1.3.3.5.cmml" xref="alg1.l17.m1.3.3.5"><csymbol cd="ambiguous" id="alg1.l17.m1.3.3.5.1.cmml" xref="alg1.l17.m1.3.3.5">superscript</csymbol><apply id="alg1.l17.m1.3.3.5.2.cmml" xref="alg1.l17.m1.3.3.5"><csymbol cd="ambiguous" id="alg1.l17.m1.3.3.5.2.1.cmml" xref="alg1.l17.m1.3.3.5">subscript</csymbol><ci id="alg1.l17.m1.3.3.5.2.2.cmml" xref="alg1.l17.m1.3.3.5.2.2">𝑡</ci><ci id="alg1.l17.m1.3.3.5.2.3a.cmml" xref="alg1.l17.m1.3.3.5.2.3"><mtext mathsize="70%" id="alg1.l17.m1.3.3.5.2.3.cmml" xref="alg1.l17.m1.3.3.5.2.3">cln</mtext></ci></apply><ci id="alg1.l17.m1.3.3.5.3.cmml" xref="alg1.l17.m1.3.3.5.3">′</ci></apply><apply id="alg1.l17.m1.3.3.3.cmml" xref="alg1.l17.m1.3.3.3"><times id="alg1.l17.m1.3.3.3.4.cmml" xref="alg1.l17.m1.3.3.3.4"></times><ci id="alg1.l17.m1.3.3.3.5a.cmml" xref="alg1.l17.m1.3.3.3.5"><mtext id="alg1.l17.m1.3.3.3.5.cmml" xref="alg1.l17.m1.3.3.3.5">insert_tags</mtext></ci><vector id="alg1.l17.m1.3.3.3.3.4.cmml" xref="alg1.l17.m1.3.3.3.3.3"><apply id="alg1.l17.m1.1.1.1.1.1.1.cmml" xref="alg1.l17.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l17.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l17.m1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l17.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l17.m1.1.1.1.1.1.1.2">𝑡</ci><ci id="alg1.l17.m1.1.1.1.1.1.1.3a.cmml" xref="alg1.l17.m1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="alg1.l17.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l17.m1.1.1.1.1.1.1.3">cln</mtext></ci></apply><apply id="alg1.l17.m1.2.2.2.2.2.2.cmml" xref="alg1.l17.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l17.m1.2.2.2.2.2.2.1.cmml" xref="alg1.l17.m1.2.2.2.2.2.2">subscript</csymbol><ci id="alg1.l17.m1.2.2.2.2.2.2.2.cmml" xref="alg1.l17.m1.2.2.2.2.2.2.2">𝑒</ci><ci id="alg1.l17.m1.2.2.2.2.2.2.3.cmml" xref="alg1.l17.m1.2.2.2.2.2.2.3">𝑖</ci></apply><apply id="alg1.l17.m1.3.3.3.3.3.3.cmml" xref="alg1.l17.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="alg1.l17.m1.3.3.3.3.3.3.1.cmml" xref="alg1.l17.m1.3.3.3.3.3.3">subscript</csymbol><ci id="alg1.l17.m1.3.3.3.3.3.3.2.cmml" xref="alg1.l17.m1.3.3.3.3.3.3.2">𝑒</ci><ci id="alg1.l17.m1.3.3.3.3.3.3.3.cmml" xref="alg1.l17.m1.3.3.3.3.3.3.3">𝑡</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.3c">t_{\text{cln}}^{\prime}\leftarrow\text{insert\_tags}(t_{\text{cln}},e_{i},e_{t})</annotation></semantics></math>

</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18:</span>     <math id="alg1.l18.m1.2" class="ltx_Math" alttext="t_{\text{syn}}\leftarrow\text{LLM}(\text{prompt},t_{\text{cln}}^{\prime})" display="inline"><semantics id="alg1.l18.m1.2a"><mrow id="alg1.l18.m1.2.2" xref="alg1.l18.m1.2.2.cmml"><msub id="alg1.l18.m1.2.2.3" xref="alg1.l18.m1.2.2.3.cmml"><mi id="alg1.l18.m1.2.2.3.2" xref="alg1.l18.m1.2.2.3.2.cmml">t</mi><mtext id="alg1.l18.m1.2.2.3.3" xref="alg1.l18.m1.2.2.3.3a.cmml">syn</mtext></msub><mo stretchy="false" id="alg1.l18.m1.2.2.2" xref="alg1.l18.m1.2.2.2.cmml">←</mo><mrow id="alg1.l18.m1.2.2.1" xref="alg1.l18.m1.2.2.1.cmml"><mtext id="alg1.l18.m1.2.2.1.3" xref="alg1.l18.m1.2.2.1.3a.cmml">LLM</mtext><mo lspace="0em" rspace="0em" id="alg1.l18.m1.2.2.1.2" xref="alg1.l18.m1.2.2.1.2.cmml">​</mo><mrow id="alg1.l18.m1.2.2.1.1.1" xref="alg1.l18.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="alg1.l18.m1.2.2.1.1.1.2" xref="alg1.l18.m1.2.2.1.1.2.cmml">(</mo><mtext id="alg1.l18.m1.1.1" xref="alg1.l18.m1.1.1a.cmml">prompt</mtext><mo id="alg1.l18.m1.2.2.1.1.1.3" xref="alg1.l18.m1.2.2.1.1.2.cmml">,</mo><msubsup id="alg1.l18.m1.2.2.1.1.1.1" xref="alg1.l18.m1.2.2.1.1.1.1.cmml"><mi id="alg1.l18.m1.2.2.1.1.1.1.2.2" xref="alg1.l18.m1.2.2.1.1.1.1.2.2.cmml">t</mi><mtext id="alg1.l18.m1.2.2.1.1.1.1.2.3" xref="alg1.l18.m1.2.2.1.1.1.1.2.3a.cmml">cln</mtext><mo id="alg1.l18.m1.2.2.1.1.1.1.3" xref="alg1.l18.m1.2.2.1.1.1.1.3.cmml">′</mo></msubsup><mo stretchy="false" id="alg1.l18.m1.2.2.1.1.1.4" xref="alg1.l18.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l18.m1.2b"><apply id="alg1.l18.m1.2.2.cmml" xref="alg1.l18.m1.2.2"><ci id="alg1.l18.m1.2.2.2.cmml" xref="alg1.l18.m1.2.2.2">←</ci><apply id="alg1.l18.m1.2.2.3.cmml" xref="alg1.l18.m1.2.2.3"><csymbol cd="ambiguous" id="alg1.l18.m1.2.2.3.1.cmml" xref="alg1.l18.m1.2.2.3">subscript</csymbol><ci id="alg1.l18.m1.2.2.3.2.cmml" xref="alg1.l18.m1.2.2.3.2">𝑡</ci><ci id="alg1.l18.m1.2.2.3.3a.cmml" xref="alg1.l18.m1.2.2.3.3"><mtext mathsize="70%" id="alg1.l18.m1.2.2.3.3.cmml" xref="alg1.l18.m1.2.2.3.3">syn</mtext></ci></apply><apply id="alg1.l18.m1.2.2.1.cmml" xref="alg1.l18.m1.2.2.1"><times id="alg1.l18.m1.2.2.1.2.cmml" xref="alg1.l18.m1.2.2.1.2"></times><ci id="alg1.l18.m1.2.2.1.3a.cmml" xref="alg1.l18.m1.2.2.1.3"><mtext id="alg1.l18.m1.2.2.1.3.cmml" xref="alg1.l18.m1.2.2.1.3">LLM</mtext></ci><interval closure="open" id="alg1.l18.m1.2.2.1.1.2.cmml" xref="alg1.l18.m1.2.2.1.1.1"><ci id="alg1.l18.m1.1.1a.cmml" xref="alg1.l18.m1.1.1"><mtext id="alg1.l18.m1.1.1.cmml" xref="alg1.l18.m1.1.1">prompt</mtext></ci><apply id="alg1.l18.m1.2.2.1.1.1.1.cmml" xref="alg1.l18.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l18.m1.2.2.1.1.1.1.1.cmml" xref="alg1.l18.m1.2.2.1.1.1.1">superscript</csymbol><apply id="alg1.l18.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l18.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l18.m1.2.2.1.1.1.1.2.1.cmml" xref="alg1.l18.m1.2.2.1.1.1.1">subscript</csymbol><ci id="alg1.l18.m1.2.2.1.1.1.1.2.2.cmml" xref="alg1.l18.m1.2.2.1.1.1.1.2.2">𝑡</ci><ci id="alg1.l18.m1.2.2.1.1.1.1.2.3a.cmml" xref="alg1.l18.m1.2.2.1.1.1.1.2.3"><mtext mathsize="70%" id="alg1.l18.m1.2.2.1.1.1.1.2.3.cmml" xref="alg1.l18.m1.2.2.1.1.1.1.2.3">cln</mtext></ci></apply><ci id="alg1.l18.m1.2.2.1.1.1.1.3.cmml" xref="alg1.l18.m1.2.2.1.1.1.1.3">′</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m1.2c">t_{\text{syn}}\leftarrow\text{LLM}(\text{prompt},t_{\text{cln}}^{\prime})</annotation></semantics></math>

</div>
<div id="alg1.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19:</span>     <math id="alg1.l19.m1.1" class="ltx_Math" alttext="T_{\text{syn}}\leftarrow T_{\text{syn}}\cup t_{\text{syn}}" display="inline"><semantics id="alg1.l19.m1.1a"><mrow id="alg1.l19.m1.1.1" xref="alg1.l19.m1.1.1.cmml"><msub id="alg1.l19.m1.1.1.2" xref="alg1.l19.m1.1.1.2.cmml"><mi id="alg1.l19.m1.1.1.2.2" xref="alg1.l19.m1.1.1.2.2.cmml">T</mi><mtext id="alg1.l19.m1.1.1.2.3" xref="alg1.l19.m1.1.1.2.3a.cmml">syn</mtext></msub><mo stretchy="false" id="alg1.l19.m1.1.1.1" xref="alg1.l19.m1.1.1.1.cmml">←</mo><mrow id="alg1.l19.m1.1.1.3" xref="alg1.l19.m1.1.1.3.cmml"><msub id="alg1.l19.m1.1.1.3.2" xref="alg1.l19.m1.1.1.3.2.cmml"><mi id="alg1.l19.m1.1.1.3.2.2" xref="alg1.l19.m1.1.1.3.2.2.cmml">T</mi><mtext id="alg1.l19.m1.1.1.3.2.3" xref="alg1.l19.m1.1.1.3.2.3a.cmml">syn</mtext></msub><mo id="alg1.l19.m1.1.1.3.1" xref="alg1.l19.m1.1.1.3.1.cmml">∪</mo><msub id="alg1.l19.m1.1.1.3.3" xref="alg1.l19.m1.1.1.3.3.cmml"><mi id="alg1.l19.m1.1.1.3.3.2" xref="alg1.l19.m1.1.1.3.3.2.cmml">t</mi><mtext id="alg1.l19.m1.1.1.3.3.3" xref="alg1.l19.m1.1.1.3.3.3a.cmml">syn</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b"><apply id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1"><ci id="alg1.l19.m1.1.1.1.cmml" xref="alg1.l19.m1.1.1.1">←</ci><apply id="alg1.l19.m1.1.1.2.cmml" xref="alg1.l19.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.2.1.cmml" xref="alg1.l19.m1.1.1.2">subscript</csymbol><ci id="alg1.l19.m1.1.1.2.2.cmml" xref="alg1.l19.m1.1.1.2.2">𝑇</ci><ci id="alg1.l19.m1.1.1.2.3a.cmml" xref="alg1.l19.m1.1.1.2.3"><mtext mathsize="70%" id="alg1.l19.m1.1.1.2.3.cmml" xref="alg1.l19.m1.1.1.2.3">syn</mtext></ci></apply><apply id="alg1.l19.m1.1.1.3.cmml" xref="alg1.l19.m1.1.1.3"><union id="alg1.l19.m1.1.1.3.1.cmml" xref="alg1.l19.m1.1.1.3.1"></union><apply id="alg1.l19.m1.1.1.3.2.cmml" xref="alg1.l19.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.3.2.1.cmml" xref="alg1.l19.m1.1.1.3.2">subscript</csymbol><ci id="alg1.l19.m1.1.1.3.2.2.cmml" xref="alg1.l19.m1.1.1.3.2.2">𝑇</ci><ci id="alg1.l19.m1.1.1.3.2.3a.cmml" xref="alg1.l19.m1.1.1.3.2.3"><mtext mathsize="70%" id="alg1.l19.m1.1.1.3.2.3.cmml" xref="alg1.l19.m1.1.1.3.2.3">syn</mtext></ci></apply><apply id="alg1.l19.m1.1.1.3.3.cmml" xref="alg1.l19.m1.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.3.3.1.cmml" xref="alg1.l19.m1.1.1.3.3">subscript</csymbol><ci id="alg1.l19.m1.1.1.3.3.2.cmml" xref="alg1.l19.m1.1.1.3.3.2">𝑡</ci><ci id="alg1.l19.m1.1.1.3.3.3a.cmml" xref="alg1.l19.m1.1.1.3.3.3"><mtext mathsize="70%" id="alg1.l19.m1.1.1.3.3.3.cmml" xref="alg1.l19.m1.1.1.3.3.3">syn</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m1.1c">T_{\text{syn}}\leftarrow T_{\text{syn}}\cup t_{\text{syn}}</annotation></semantics></math>

</div>
<div id="alg1.l20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20:</span><span id="alg1.l20.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l20.2" class="ltx_text ltx_font_bold">for</span>
</div>
</div>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment Settings</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents our experimental evaluation of the proposed method for generating synthetic noisy dialogue transcripts to improve the robustness of summarization models against ASR errors.</p>
</div>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ASR models: </h5>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">We utilized the <span id="S4.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">Whisper tiny</span>, <span id="S4.SS0.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">Whisper large</span> <cite class="ltx_cite ltx_citemacro_citep">(Radford et al. <a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite>, and <span id="S4.SS0.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_italic">Wav2vec2-base</span> <cite class="ltx_cite ltx_citemacro_citep">(Baevski et al. <a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite> ASR models to generate transcriptions of medical dialogues.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Large Language Models: </h5>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">We use <span id="S4.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Llama-3-8B</span> <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al. <a href="#bib.bib7" title="" class="ltx_ref">2024</a>)</cite> and <span id="S4.SS0.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">Mistral-7B</span> <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al. <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> both for generating synthetic dialogues and summarization, while <span id="S4.SS0.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_italic">Gemma-7B</span> <cite class="ltx_cite ltx_citemacro_citep">(Team et al. <a href="#bib.bib31" title="" class="ltx_ref">2024</a>)</cite> is only used for summarization.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Datasets: </h5>

<div id="S4.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p1.1" class="ltx_p">For testing our approach, we use the <span id="S4.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">Primock57</span> dataset, which comprises audio recordings of 57 enacted doctor-patient dialogues and their text transcripts written by human annotators. For experiments involving fine-tuning we use the <span id="S4.SS0.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">NoteChat-1000</span> dataset <cite class="ltx_cite ltx_citemacro_citep">(Wang et al. <a href="#bib.bib33" title="" class="ltx_ref">2024</a>)</cite> for training, which includes 1000 synthetic doctor-patient dialogue transcripts generated by multiple LLMs in a cooperative roleplay setting, conditioned on clinical notes.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation Metrics:</h5>

<div id="S4.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px4.p1.1" class="ltx_p">We utilized three types of evaluation metrics to assess the performance of the summarization models. For lexical similarity, we used the ROUGE metrics <cite class="ltx_cite ltx_citemacro_citep">(Lin <a href="#bib.bib20" title="" class="ltx_ref">2004</a>)</cite>, specifically focusing on ROUGE-L, which measures the longest common subsequence overlap between generated and reference summaries. To capture the semantic similarity, we employed BERTScore <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a href="#bib.bib38" title="" class="ltx_ref">2020</a>)</cite>, which uses embeddings from pre-trained BERT models to compare the contextual meaning of the texts. Additionally, recognizing the importance of accurately identifying medical terminology in summaries, we assessed the overlap of domain-specific named entities (DSEs) using the F1 score, which combines both precision and recall, based on entities extracted through named entity recognition (NER).</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Preliminary Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this section, we present preliminary experiments that lay the foundation for our work. First, we conduct a motivating study that verifies how errors introduced by ASR systems negatively impact the performance of a downstream medical dialogue summarization task. Subsequently, we perform an analysis that suggests different ASR models exhibit distinct error profiles.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>ASR noise harms medical report quality</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.2" class="ltx_p">Our findings, as displayed in Table <a href="#S5.T1" title="Table 1 ‣ 5.1 ASR noise harms medical report quality ‣ 5 Preliminary Experiments ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, reveal that ASR noise can significantly degrade the quality of the generated summaries, especially when using small ASR models. Specifically, using Wav2vec2-base generated transcripts instead of human annotated ones lead to a noticeable reduction in the domain-specific entity F1 score of <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="23\%" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mrow id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mn id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">23</mn><mo id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">23</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">23\%</annotation></semantics></math> (<math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="22.11\rightarrow 16.99" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mrow id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mn id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">22.11</mn><mo stretchy="false" id="S5.SS1.p1.2.m2.1.1.1" xref="S5.SS1.p1.2.m2.1.1.1.cmml">→</mo><mn id="S5.SS1.p1.2.m2.1.1.3" xref="S5.SS1.p1.2.m2.1.1.3.cmml">16.99</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><ci id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1.1">→</ci><cn type="float" id="S5.SS1.p1.2.m2.1.1.2.cmml" xref="S5.SS1.p1.2.m2.1.1.2">22.11</cn><cn type="float" id="S5.SS1.p1.2.m2.1.1.3.cmml" xref="S5.SS1.p1.2.m2.1.1.3">16.99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">22.11\rightarrow 16.99</annotation></semantics></math>). While using larger models like Whisper-large exhibits comparable downstream task performance as using ground truth dialogues, deployment area of such large-scale models is limited due to the computational resource requirements they demand. Such a difference in the DSE overlap measure indicates a loss in accurately capturing critical medical entities. The ROUGE-L scores also decline, reflecting reduced textual overlap and coherence between the generated and reference summaries. Moreover, the BERT Scores drop, suggesting a decrease in the semantic similarity to the reference summaries. These results underscore the challenges of downstream tasks, such as dialogue summarisation, face, arising from erroneous ASR transcripts.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<div id="S5.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:201.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(42.8pt,-19.9pt) scale(1.24600332756057,1.24600332756057) ;">
<table id="S5.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.1.1.1.1" class="ltx_tr">
<th id="S5.T1.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S5.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3"><span id="S5.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Llama-3-8B</span></th>
<th id="S5.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3"><span id="S5.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Mistral-7B</span></th>
</tr>
<tr id="S5.T1.1.1.2.2" class="ltx_tr">
<th id="S5.T1.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S5.T1.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Transcription</span></th>
<th id="S5.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.1.1.2.2.2.1" class="ltx_text ltx_font_bold">F1</span></th>
<th id="S5.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.1.1.2.2.3.1" class="ltx_text ltx_font_bold">RougeL</span></th>
<th id="S5.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.1.1.2.2.4.1" class="ltx_text ltx_font_bold">Bert</span></th>
<th id="S5.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.1.1.2.2.5.1" class="ltx_text ltx_font_bold">F1</span></th>
<th id="S5.T1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.1.1.2.2.6.1" class="ltx_text ltx_font_bold">RougeL</span></th>
<th id="S5.T1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.1.1.2.2.7.1" class="ltx_text ltx_font_bold">Bert</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.1.1.3.1" class="ltx_tr">
<th id="S5.T1.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S5.T1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Wav2vec2-base (ASR)</span></th>
<td id="S5.T1.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">16.99</td>
<td id="S5.T1.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">11.52</td>
<td id="S5.T1.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">52.46</td>
<td id="S5.T1.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">17.06</td>
<td id="S5.T1.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">11.09</td>
<td id="S5.T1.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">50.40</td>
</tr>
<tr id="S5.T1.1.1.4.2" class="ltx_tr">
<th id="S5.T1.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T1.1.1.4.2.1.1" class="ltx_text ltx_font_bold">+ Denoising</span></th>
<td id="S5.T1.1.1.4.2.2" class="ltx_td ltx_align_center">15.20</td>
<td id="S5.T1.1.1.4.2.3" class="ltx_td ltx_align_center">10.19</td>
<td id="S5.T1.1.1.4.2.4" class="ltx_td ltx_align_center">51.49</td>
<td id="S5.T1.1.1.4.2.5" class="ltx_td ltx_align_center">20.62</td>
<td id="S5.T1.1.1.4.2.6" class="ltx_td ltx_align_center">11.03</td>
<td id="S5.T1.1.1.4.2.7" class="ltx_td ltx_align_center">51.51</td>
</tr>
<tr id="S5.T1.1.1.5.3" class="ltx_tr">
<th id="S5.T1.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T1.1.1.5.3.1.1" class="ltx_text ltx_font_bold">Whisper-tiny (ASR)</span></th>
<td id="S5.T1.1.1.5.3.2" class="ltx_td ltx_align_center">19.86</td>
<td id="S5.T1.1.1.5.3.3" class="ltx_td ltx_align_center">11.65</td>
<td id="S5.T1.1.1.5.3.4" class="ltx_td ltx_align_center">52.73</td>
<td id="S5.T1.1.1.5.3.5" class="ltx_td ltx_align_center">21.85</td>
<td id="S5.T1.1.1.5.3.6" class="ltx_td ltx_align_center">11.91</td>
<td id="S5.T1.1.1.5.3.7" class="ltx_td ltx_align_center">51.97</td>
</tr>
<tr id="S5.T1.1.1.6.4" class="ltx_tr">
<th id="S5.T1.1.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T1.1.1.6.4.1.1" class="ltx_text ltx_font_bold">+ Denoising</span></th>
<td id="S5.T1.1.1.6.4.2" class="ltx_td ltx_align_center">12.73</td>
<td id="S5.T1.1.1.6.4.3" class="ltx_td ltx_align_center">9.95</td>
<td id="S5.T1.1.1.6.4.4" class="ltx_td ltx_align_center">51.94</td>
<td id="S5.T1.1.1.6.4.5" class="ltx_td ltx_align_center">19.81</td>
<td id="S5.T1.1.1.6.4.6" class="ltx_td ltx_align_center">11.42</td>
<td id="S5.T1.1.1.6.4.7" class="ltx_td ltx_align_center">51.74</td>
</tr>
<tr id="S5.T1.1.1.7.5" class="ltx_tr">
<th id="S5.T1.1.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T1.1.1.7.5.1.1" class="ltx_text ltx_font_bold">Whisper-large (ASR)</span></th>
<td id="S5.T1.1.1.7.5.2" class="ltx_td ltx_align_center">21.42</td>
<td id="S5.T1.1.1.7.5.3" class="ltx_td ltx_align_center">13.67</td>
<td id="S5.T1.1.1.7.5.4" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.7.5.4.1" class="ltx_text ltx_font_bold">54.23</span></td>
<td id="S5.T1.1.1.7.5.5" class="ltx_td ltx_align_center">24.06</td>
<td id="S5.T1.1.1.7.5.6" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.7.5.6.1" class="ltx_text ltx_font_bold">13.27</span></td>
<td id="S5.T1.1.1.7.5.7" class="ltx_td ltx_align_center"><span id="S5.T1.1.1.7.5.7.1" class="ltx_text ltx_font_bold">53.29</span></td>
</tr>
<tr id="S5.T1.1.1.8.6" class="ltx_tr">
<th id="S5.T1.1.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T1.1.1.8.6.1.1" class="ltx_text ltx_font_bold">+ Denoising</span></th>
<td id="S5.T1.1.1.8.6.2" class="ltx_td ltx_align_center">18.64</td>
<td id="S5.T1.1.1.8.6.3" class="ltx_td ltx_align_center">12.57</td>
<td id="S5.T1.1.1.8.6.4" class="ltx_td ltx_align_center">53.15</td>
<td id="S5.T1.1.1.8.6.5" class="ltx_td ltx_align_center">23.12</td>
<td id="S5.T1.1.1.8.6.6" class="ltx_td ltx_align_center">12.67</td>
<td id="S5.T1.1.1.8.6.7" class="ltx_td ltx_align_center">52.50</td>
</tr>
<tr id="S5.T1.1.1.9.7" class="ltx_tr">
<th id="S5.T1.1.1.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S5.T1.1.1.9.7.1.1" class="ltx_text ltx_font_bold">Ground Truth</span></th>
<td id="S5.T1.1.1.9.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T1.1.1.9.7.2.1" class="ltx_text ltx_font_bold">22.11</span></td>
<td id="S5.T1.1.1.9.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T1.1.1.9.7.3.1" class="ltx_text ltx_font_bold">14.07</span></td>
<td id="S5.T1.1.1.9.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">53.80</td>
<td id="S5.T1.1.1.9.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T1.1.1.9.7.5.1" class="ltx_text ltx_font_bold">24.53</span></td>
<td id="S5.T1.1.1.9.7.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">13.25</td>
<td id="S5.T1.1.1.9.7.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">52.85</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Effect on Summarization quality due to ASR errors. <span id="S5.T1.4.1" class="ltx_text ltx_font_italic">“Ground Truth”</span> indicates using the ground-truth ASR transcripts as input for summarization for measuring upper-bound performance. <span id="S5.T1.5.2" class="ltx_text ltx_font_italic">+ Denoising</span> indicates that the ASR generated transcripts are passed through a denoising LLM to clean the errors if any and then summarized.</figcaption>
</figure>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">We also explored applying few-shot denoising on ASR transcribed dialogues, which is denoted as “+ Denoising”. However, the results show that this method does not recover the summarization performance, highlighting the limitations of traditional post-processing based noise reduction techniques in this context.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Different ASR models exhibit different error profiles</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.3" class="ltx_p">We analyzed the errors made by the ASR models on Primock57 audio samples. <span id="S5.SS2.p1.3.1" class="ltx_text ltx_font_italic">Whisper-large</span> transcription results in <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="25\%" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">25</mn><mo id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">25\%</annotation></semantics></math> WER. Both the <span id="S5.SS2.p1.3.2" class="ltx_text ltx_font_italic">Whisper-tiny</span> and <span id="S5.SS2.p1.3.3" class="ltx_text ltx_font_italic">Wav2vec2-base</span> models had similar WER scores, with the former achieving <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="44\%" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mrow id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mn id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">44</mn><mo id="S5.SS2.p1.2.m2.1.1.1" xref="S5.SS2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">44</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">44\%</annotation></semantics></math> and the latter <math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="45\%" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><mrow id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml"><mn id="S5.SS2.p1.3.m3.1.1.2" xref="S5.SS2.p1.3.m3.1.1.2.cmml">45</mn><mo id="S5.SS2.p1.3.m3.1.1.1" xref="S5.SS2.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><apply id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"><csymbol cd="latexml" id="S5.SS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2">45</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">45\%</annotation></semantics></math>. Moreover, the breakdown of error types associated with each ASR model is displayed in Figure <a href="#S5.F2" title="Figure 2 ‣ 5.2 Different ASR models exhibit different error profiles ‣ 5 Preliminary Experiments ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The differing noise profiles suggest that to accurately mimic the properties of ASR transcriptions, the synthetic dialogue generation process must be controllable and adjustable with respect to the error profile of the target ASR model.</p>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="/html/2408.14418/assets/x1.png" id="S5.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="191" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>ASR errors of different models. The breakdown shows the different types of errors made by the model.</figcaption>
</figure>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2408.14418/assets/x2.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="430" height="140" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Similarities between ASR-generated transcriptions (rows) and LLM-generated synthetic transcriptions (columns) with respect to F1, Rouge-L, and WER metrics. The highest similarities are observed on the diagonals indicating overlap between corresponding ASR- and LLM-generated transcriptions.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Main Experiments</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Building on the insights from our preliminary experiments, we present our main experimental findings in this section.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<div id="S6.T2.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:109.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-162.0pt,35.1pt) scale(0.609570112692123,0.609570112692123) ;">
<table id="S6.T2.5.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T2.5.1.1.1" class="ltx_tr">
<th id="S6.T2.5.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S6.T2.5.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S6.T2.5.1.1.1.2.1" class="ltx_text ltx_font_bold">Llama-3-8B</span></td>
<td id="S6.T2.5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S6.T2.5.1.1.1.3.1" class="ltx_text ltx_font_bold">Mistral-7B</span></td>
<td id="S6.T2.5.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S6.T2.5.1.1.1.4.1" class="ltx_text ltx_font_bold">Gemma-7B</span></td>
</tr>
<tr id="S6.T2.5.1.2.2" class="ltx_tr">
<th id="S6.T2.5.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T2.5.1.2.2.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="S6.T2.5.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.2.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="S6.T2.5.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.3.1" class="ltx_text ltx_font_bold">RougeL</span></td>
<td id="S6.T2.5.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.4.1" class="ltx_text ltx_font_bold">Bert</span></td>
<td id="S6.T2.5.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.5.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="S6.T2.5.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.6.1" class="ltx_text ltx_font_bold">RougeL</span></td>
<td id="S6.T2.5.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.7.1" class="ltx_text ltx_font_bold">Bert</span></td>
<td id="S6.T2.5.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.8.1" class="ltx_text ltx_font_bold">F1</span></td>
<td id="S6.T2.5.1.2.2.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.9.1" class="ltx_text ltx_font_bold">RougeL</span></td>
<td id="S6.T2.5.1.2.2.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.2.2.10.1" class="ltx_text ltx_font_bold">Bert</span></td>
</tr>
<tr id="S6.T2.5.1.3.3" class="ltx_tr">
<th id="S6.T2.5.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S6.T2.5.1.3.3.1.1" class="ltx_text ltx_font_bold">Zero-shot</span></th>
<td id="S6.T2.5.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">19.90</td>
<td id="S6.T2.5.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">11.84</td>
<td id="S6.T2.5.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.5.1.3.3.4.1" class="ltx_text ltx_font_bold">52.85</span></td>
<td id="S6.T2.5.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">20.77</td>
<td id="S6.T2.5.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">11.81</td>
<td id="S6.T2.5.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">52.36</td>
<td id="S6.T2.5.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">21.30</td>
<td id="S6.T2.5.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">12.73</td>
<td id="S6.T2.5.1.3.3.10" class="ltx_td ltx_align_center ltx_border_t">50.95</td>
</tr>
<tr id="S6.T2.5.1.4.4" class="ltx_tr">
<th id="S6.T2.5.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T2.5.1.4.4.1.1" class="ltx_text ltx_font_bold">+ Denoising</span></th>
<td id="S6.T2.5.1.4.4.2" class="ltx_td ltx_align_center">15.31 (-23.0%)</td>
<td id="S6.T2.5.1.4.4.3" class="ltx_td ltx_align_center">10.55 (-10.9%)</td>
<td id="S6.T2.5.1.4.4.4" class="ltx_td ltx_align_center">51.93 (-1.7%)</td>
<td id="S6.T2.5.1.4.4.5" class="ltx_td ltx_align_center">17.87 (-14.0%)</td>
<td id="S6.T2.5.1.4.4.6" class="ltx_td ltx_align_center">10.75 (-9.0%)</td>
<td id="S6.T2.5.1.4.4.7" class="ltx_td ltx_align_center">51.32 (-2.0%)</td>
<td id="S6.T2.5.1.4.4.8" class="ltx_td ltx_align_center">18.97 (-10.9%)</td>
<td id="S6.T2.5.1.4.4.9" class="ltx_td ltx_align_center">12.63 (-0.8%)</td>
<td id="S6.T2.5.1.4.4.10" class="ltx_td ltx_align_center">51.11 (+0.3%)</td>
</tr>
<tr id="S6.T2.5.1.5.5" class="ltx_tr">
<th id="S6.T2.5.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T2.5.1.5.5.1.1" class="ltx_text ltx_font_bold">FT on clean</span></th>
<td id="S6.T2.5.1.5.5.2" class="ltx_td ltx_align_center">20.42 (+2.6%)</td>
<td id="S6.T2.5.1.5.5.3" class="ltx_td ltx_align_center">12.74 (+7.6%)</td>
<td id="S6.T2.5.1.5.5.4" class="ltx_td ltx_align_center">52.35 (-1.0%)</td>
<td id="S6.T2.5.1.5.5.5" class="ltx_td ltx_align_center">16.76 (-19.3%)</td>
<td id="S6.T2.5.1.5.5.6" class="ltx_td ltx_align_center">8.06 (-31.7%)</td>
<td id="S6.T2.5.1.5.5.7" class="ltx_td ltx_align_center">49.46 (-5.5%)</td>
<td id="S6.T2.5.1.5.5.8" class="ltx_td ltx_align_center">21.21 (-0.4%)</td>
<td id="S6.T2.5.1.5.5.9" class="ltx_td ltx_align_center">13.19 (+3.6%)</td>
<td id="S6.T2.5.1.5.5.10" class="ltx_td ltx_align_center">51.31 (+0.7%)</td>
</tr>
<tr id="S6.T2.5.1.6.6" class="ltx_tr">
<th id="S6.T2.5.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T2.5.1.6.6.1.1" class="ltx_text ltx_font_bold">+ Denoising</span></th>
<td id="S6.T2.5.1.6.6.2" class="ltx_td ltx_align_center">19.34 (-2.8%)</td>
<td id="S6.T2.5.1.6.6.3" class="ltx_td ltx_align_center">11.49 (-3.0%)</td>
<td id="S6.T2.5.1.6.6.4" class="ltx_td ltx_align_center">51.35 (-2.8%)</td>
<td id="S6.T2.5.1.6.6.5" class="ltx_td ltx_align_center">14.88 (-28.3%)</td>
<td id="S6.T2.5.1.6.6.6" class="ltx_td ltx_align_center">7.49 (-36.6%)</td>
<td id="S6.T2.5.1.6.6.7" class="ltx_td ltx_align_center">48.73 (-6.9%)</td>
<td id="S6.T2.5.1.6.6.8" class="ltx_td ltx_align_center">19.09 (-10.4%)</td>
<td id="S6.T2.5.1.6.6.9" class="ltx_td ltx_align_center">12.49 (-1.9%)</td>
<td id="S6.T2.5.1.6.6.10" class="ltx_td ltx_align_center">50.57 (-0.7%)</td>
</tr>
<tr id="S6.T2.5.1.7.7" class="ltx_tr">
<th id="S6.T2.5.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S6.T2.5.1.7.7.1.1" class="ltx_text ltx_font_bold">FT-aug (1x, <span id="S6.T2.5.1.7.7.1.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>)</span></th>
<td id="S6.T2.5.1.7.7.2" class="ltx_td ltx_align_center ltx_border_t">20.93 (+5.2%)</td>
<td id="S6.T2.5.1.7.7.3" class="ltx_td ltx_align_center ltx_border_t">12.29 (+3.8%)</td>
<td id="S6.T2.5.1.7.7.4" class="ltx_td ltx_align_center ltx_border_t">52.00 (-1.6%)</td>
<td id="S6.T2.5.1.7.7.5" class="ltx_td ltx_align_center ltx_border_t">23.89 (+15.0%)</td>
<td id="S6.T2.5.1.7.7.6" class="ltx_td ltx_align_center ltx_border_t">12.34 (+4.5%)</td>
<td id="S6.T2.5.1.7.7.7" class="ltx_td ltx_align_center ltx_border_t">52.68 (+0.6%)</td>
<td id="S6.T2.5.1.7.7.8" class="ltx_td ltx_align_center ltx_border_t">22.84 (+7.2%)</td>
<td id="S6.T2.5.1.7.7.9" class="ltx_td ltx_align_center ltx_border_t">13.33 (+4.7%)</td>
<td id="S6.T2.5.1.7.7.10" class="ltx_td ltx_align_center ltx_border_t">51.42 (+0.9%)</td>
</tr>
<tr id="S6.T2.5.1.8.8" class="ltx_tr">
<th id="S6.T2.5.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T2.5.1.8.8.1.1" class="ltx_text ltx_font_bold">FT-aug (2x, <span id="S6.T2.5.1.8.8.1.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>)</span></th>
<td id="S6.T2.5.1.8.8.2" class="ltx_td ltx_align_center">22.84 (+14.8%)</td>
<td id="S6.T2.5.1.8.8.3" class="ltx_td ltx_align_center">13.08 (+10.5%)</td>
<td id="S6.T2.5.1.8.8.4" class="ltx_td ltx_align_center">51.36 (-2.8%)</td>
<td id="S6.T2.5.1.8.8.5" class="ltx_td ltx_align_center">24.17 (+16.4%)</td>
<td id="S6.T2.5.1.8.8.6" class="ltx_td ltx_align_center">13.27 (+12.4%)</td>
<td id="S6.T2.5.1.8.8.7" class="ltx_td ltx_align_center">53.10 (+1.4%)</td>
<td id="S6.T2.5.1.8.8.8" class="ltx_td ltx_align_center">22.48 (+5.5%)</td>
<td id="S6.T2.5.1.8.8.9" class="ltx_td ltx_align_center">12.73 (0.0%)</td>
<td id="S6.T2.5.1.8.8.10" class="ltx_td ltx_align_center">51.48 (+1.0%)</td>
</tr>
<tr id="S6.T2.5.1.9.9" class="ltx_tr">
<th id="S6.T2.5.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T2.5.1.9.9.1.1" class="ltx_text ltx_font_bold">FT-aug (3x, <span id="S6.T2.5.1.9.9.1.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>)</span></th>
<td id="S6.T2.5.1.9.9.2" class="ltx_td ltx_align_center">22.51 (+13.1%)</td>
<td id="S6.T2.5.1.9.9.3" class="ltx_td ltx_align_center">12.78 (+7.9%)</td>
<td id="S6.T2.5.1.9.9.4" class="ltx_td ltx_align_center">51.91 (-1.8%)</td>
<td id="S6.T2.5.1.9.9.5" class="ltx_td ltx_align_center">22.11 (+6.5%)</td>
<td id="S6.T2.5.1.9.9.6" class="ltx_td ltx_align_center">12.93 (+9.5%)</td>
<td id="S6.T2.5.1.9.9.7" class="ltx_td ltx_align_center">52.66 (+0.6%)</td>
<td id="S6.T2.5.1.9.9.8" class="ltx_td ltx_align_center">20.96 (-1.6%)</td>
<td id="S6.T2.5.1.9.9.9" class="ltx_td ltx_align_center">13.25 (+4.1%)</td>
<td id="S6.T2.5.1.9.9.10" class="ltx_td ltx_align_center">51.29 (+0.7%)</td>
</tr>
<tr id="S6.T2.5.1.10.10" class="ltx_tr">
<th id="S6.T2.5.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.1.1" class="ltx_text ltx_font_bold">FT-aug (Best, <span id="S6.T2.5.1.10.10.1.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>)</span></th>
<td id="S6.T2.5.1.10.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.2.1" class="ltx_text ltx_font_bold">22.84 (+14.8%)</span></td>
<td id="S6.T2.5.1.10.10.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.3.1" class="ltx_text ltx_font_bold">13.08 (+10.5%)</span></td>
<td id="S6.T2.5.1.10.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">52.00 (-1.6%)</td>
<td id="S6.T2.5.1.10.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.5.1" class="ltx_text ltx_font_bold">24.17 (+16.4%)</span></td>
<td id="S6.T2.5.1.10.10.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.6.1" class="ltx_text ltx_font_bold">13.27 (+12.4%)</span></td>
<td id="S6.T2.5.1.10.10.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.7.1" class="ltx_text ltx_font_bold">53.10 (+1.4%)</span></td>
<td id="S6.T2.5.1.10.10.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.8.1" class="ltx_text ltx_font_bold">22.84 (+7.2%)</span></td>
<td id="S6.T2.5.1.10.10.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.9.1" class="ltx_text ltx_font_bold">13.33 (+4.7%)</span></td>
<td id="S6.T2.5.1.10.10.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S6.T2.5.1.10.10.10.1" class="ltx_text ltx_font_bold">51.48 (+1.0%)</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Summarization qualities of Llama-3-8B, Mistral-7B, and Gemma-7B for different training settings. <span id="S6.T2.10.1" class="ltx_text ltx_font_italic">FT</span> and <span id="S6.T2.11.2" class="ltx_text ltx_font_italic">aug</span> stand for <span id="S6.T2.12.3" class="ltx_text ltx_font_italic">fine-tuning</span> and <span id="S6.T2.13.4" class="ltx_text ltx_font_italic">data augmentation</span> respectively. The number of synthetic dialogues per ground truth dialogue included in augmented training sets are indicated with <math id="S6.T2.3.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S6.T2.3.m1.1b"><mi id="S6.T2.3.m1.1.1" xref="S6.T2.3.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S6.T2.3.m1.1c"><ci id="S6.T2.3.m1.1.1.cmml" xref="S6.T2.3.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.3.m1.1d">x</annotation></semantics></math> multiples. Relative improvements compared to the Zero-shot method are displayed in parenthesis (<math id="S6.T2.4.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S6.T2.4.m2.1b"><mo id="S6.T2.4.m2.1.1" xref="S6.T2.4.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S6.T2.4.m2.1c"><csymbol cd="latexml" id="S6.T2.4.m2.1.1.cmml" xref="S6.T2.4.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.4.m2.1d">\%</annotation></semantics></math>).</figcaption>
</figure>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Data augmentation using synthetic dialogues improves robustness against ASR errors</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">To assess the impact of <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>, we first investigate the effectiveness of LLM-generated synthetic dialogues in building robustness against ASR errors through data augmentation. In this experiment, we begin by augmenting the training set of the note chat-1000 dataset using synthetic dialogues. Later, we fine-tune summarization models through LoRa (Low-Rank Adaptation) adapters <cite class="ltx_cite ltx_citemacro_citep">(Hu et al. <a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite> on augmented datasets that include a mix of clean ground-truth dialogues and our synthetic noisy dialogues. Then we compare the summarization performance of these fine-tuned models against three baselines on the ASR-transcribed Primock57 audio recordings, which comprise our test set. The three baselines we use for evaluation are:</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Zero-shot</span>: Pre-trained LLMs are prompted to replicate medical notes written by doctors based on input dialogues.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">FT on clean</span>: LLMs are fine-tuned only on clean transcripts.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Denoising</span>: The ASR transcripts are cleaned by LLama-3-8B model before summarization.</p>
</div>
</li>
</ul>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">As shown in Table <a href="#S6.T2" title="Table 2 ‣ 6 Main Experiments ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the results indicate that the inclusion of synthetic noisy dialogues in the training set considerably improves the robustness of the summarization models, resulting in up to <math id="S6.SS1.p2.1.m1.1" class="ltx_Math" alttext="16.4\%" display="inline"><semantics id="S6.SS1.p2.1.m1.1a"><mrow id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml"><mn id="S6.SS1.p2.1.m1.1.1.2" xref="S6.SS1.p2.1.m1.1.1.2.cmml">16.4</mn><mo id="S6.SS1.p2.1.m1.1.1.1" xref="S6.SS1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><apply id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S6.SS1.p2.1.m1.1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.SS1.p2.1.m1.1.1.2.cmml" xref="S6.SS1.p2.1.m1.1.1.2">16.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">16.4\%</annotation></semantics></math> improvement in F1. In contrast, <span id="S6.SS1.p2.1.1" class="ltx_text ltx_font_italic">FT on clean</span> baseline only marginally improves or even degrades performance depending on the summarization model architecture. This suggests that while fine-tuning on clean dialogues alone can benefit summarization models by adapting them to the medical domain, it does not consistently enhance their ability to handle ASR noise. Moreover, denoising consistently harmed summarization performance across all experiments. This can be attributed to the two aforementioned key factors: (1) denoising models below a certain parameter size (such as LLama-8B) are ineffective at cleaning noise, and (2) using prompting techniques without fine-tuning introduces a risk of hallucinations, potentially injecting irrelevant medical entities into the dialogue.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>LLM-produced synthetic errors are realistic</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">To ensure that the improvements observed indeed stem from the accurate simulation of ASR noise, we need to establish whether the synthetic dialogues generated by our <span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span> method exhibit error characteristics similar to those found in actual ASR transcriptions. This assessment involves two main comparisons.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<div id="S6.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:394.6pt;height:211.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-55.1pt,29.5pt) scale(0.78175901555517,0.78175901555517) ;">
<table id="S6.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.1.1.1.1" class="ltx_tr">
<th id="S6.T3.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S6.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Llama-3-8B Summarization</span></th>
<th id="S6.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S6.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Mistral-7B Summarization</span></th>
</tr>
<tr id="S6.T3.1.1.2.2" class="ltx_tr">
<th id="S6.T3.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S6.T3.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Source Transcripts</span></th>
<th id="S6.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.2.2.2.1" class="ltx_text ltx_font_bold" style="color:#0000FF;">ASR</span></th>
<th id="S6.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.2.2.3.1" class="ltx_text ltx_font_bold">Random</span></th>
<th id="S6.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2"><span id="S6.T3.1.1.2.2.4.1" class="ltx_text ltx_font_bold">LLM-generated (<span id="S6.T3.1.1.2.2.4.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>)</span></th>
<th id="S6.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.2.2.5.1" class="ltx_text ltx_font_bold" style="color:#0000FF;">ASR</span></th>
<th id="S6.T3.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.2.2.6.1" class="ltx_text ltx_font_bold">Random</span></th>
<th id="S6.T3.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2"><span id="S6.T3.1.1.2.2.7.1" class="ltx_text ltx_font_bold">LLM-generated (<span id="S6.T3.1.1.2.2.7.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>)</span></th>
</tr>
<tr id="S6.T3.1.1.3.3" class="ltx_tr">
<th id="S6.T3.1.1.3.3.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S6.T3.1.1.3.3.2" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S6.T3.1.1.3.3.3" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S6.T3.1.1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.3.3.4.1" class="ltx_text ltx_font_bold">Llama-3-8B</span></th>
<th id="S6.T3.1.1.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.3.3.5.1" class="ltx_text ltx_font_bold">Mistral-7B</span></th>
<th id="S6.T3.1.1.3.3.6" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S6.T3.1.1.3.3.7" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S6.T3.1.1.3.3.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.3.3.8.1" class="ltx_text ltx_font_bold">Llama-3-8B</span></th>
<th id="S6.T3.1.1.3.3.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S6.T3.1.1.3.3.9.1" class="ltx_text ltx_font_bold">Mistral-7B</span></th>
</tr>
<tr id="S6.T3.1.1.4.4" class="ltx_tr">
<th id="S6.T3.1.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="background-color:#C0C0C0;" colspan="9"><span id="S6.T3.1.1.4.4.1.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">F1</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.1.1.5.1" class="ltx_tr">
<th id="S6.T3.1.1.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T3.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Wav2vec2-base</span></th>
<td id="S6.T3.1.1.5.1.2" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.1.2.1" class="ltx_text" style="color:#0000FF;">16.99</span></td>
<td id="S6.T3.1.1.5.1.3" class="ltx_td ltx_align_center">11.24</td>
<td id="S6.T3.1.1.5.1.4" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.1.4.1" class="ltx_text ltx_font_bold">17.35</span></td>
<td id="S6.T3.1.1.5.1.5" class="ltx_td ltx_align_center">16.54</td>
<td id="S6.T3.1.1.5.1.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.1.6.1" class="ltx_text" style="color:#0000FF;">17.06</span></td>
<td id="S6.T3.1.1.5.1.7" class="ltx_td ltx_align_center">11.73</td>
<td id="S6.T3.1.1.5.1.8" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.5.1.8.1" class="ltx_text ltx_font_bold">15.95</span></td>
<td id="S6.T3.1.1.5.1.9" class="ltx_td ltx_align_center">15.05</td>
</tr>
<tr id="S6.T3.1.1.6.2" class="ltx_tr">
<th id="S6.T3.1.1.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T3.1.1.6.2.1.1" class="ltx_text ltx_font_bold">Whisper-tiny</span></th>
<td id="S6.T3.1.1.6.2.2" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.6.2.2.1" class="ltx_text" style="color:#0000FF;">19.86</span></td>
<td id="S6.T3.1.1.6.2.3" class="ltx_td ltx_align_center">12.83</td>
<td id="S6.T3.1.1.6.2.4" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.6.2.4.1" class="ltx_text ltx_font_bold">18.02</span></td>
<td id="S6.T3.1.1.6.2.5" class="ltx_td ltx_align_center">17.91</td>
<td id="S6.T3.1.1.6.2.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.6.2.6.1" class="ltx_text" style="color:#0000FF;">18.04</span></td>
<td id="S6.T3.1.1.6.2.7" class="ltx_td ltx_align_center">15.38</td>
<td id="S6.T3.1.1.6.2.8" class="ltx_td ltx_align_center">18.63</td>
<td id="S6.T3.1.1.6.2.9" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.6.2.9.1" class="ltx_text ltx_font_bold">18.10</span></td>
</tr>
<tr id="S6.T3.1.1.7.3" class="ltx_tr">
<th id="S6.T3.1.1.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T3.1.1.7.3.1.1" class="ltx_text ltx_font_bold">Whisper-large</span></th>
<td id="S6.T3.1.1.7.3.2" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.7.3.2.1" class="ltx_text" style="color:#0000FF;">21.42</span></td>
<td id="S6.T3.1.1.7.3.3" class="ltx_td ltx_align_center">18.84</td>
<td id="S6.T3.1.1.7.3.4" class="ltx_td ltx_align_center">20.35</td>
<td id="S6.T3.1.1.7.3.5" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.7.3.5.1" class="ltx_text ltx_font_bold">22.02</span></td>
<td id="S6.T3.1.1.7.3.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.7.3.6.1" class="ltx_text" style="color:#0000FF;">24.06</span></td>
<td id="S6.T3.1.1.7.3.7" class="ltx_td ltx_align_center">22.28</td>
<td id="S6.T3.1.1.7.3.8" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.7.3.8.1" class="ltx_text ltx_font_bold">23.82</span></td>
<td id="S6.T3.1.1.7.3.9" class="ltx_td ltx_align_center">21.40</td>
</tr>
<tr id="S6.T3.1.1.8.4" class="ltx_tr">
<th id="S6.T3.1.1.8.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="background-color:#C0C0C0;" colspan="9"><span id="S6.T3.1.1.8.4.1.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">RougeL</span></th>
</tr>
<tr id="S6.T3.1.1.9.5" class="ltx_tr">
<th id="S6.T3.1.1.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T3.1.1.9.5.1.1" class="ltx_text ltx_font_bold">Wav2vec2-base</span></th>
<td id="S6.T3.1.1.9.5.2" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.9.5.2.1" class="ltx_text" style="color:#0000FF;">11.52</span></td>
<td id="S6.T3.1.1.9.5.3" class="ltx_td ltx_align_center">8.50</td>
<td id="S6.T3.1.1.9.5.4" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.9.5.4.1" class="ltx_text ltx_font_bold">11.47</span></td>
<td id="S6.T3.1.1.9.5.5" class="ltx_td ltx_align_center">11.18</td>
<td id="S6.T3.1.1.9.5.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.9.5.6.1" class="ltx_text" style="color:#0000FF;">11.09</span></td>
<td id="S6.T3.1.1.9.5.7" class="ltx_td ltx_align_center">8.32</td>
<td id="S6.T3.1.1.9.5.8" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.9.5.8.1" class="ltx_text ltx_font_bold">11.70</span></td>
<td id="S6.T3.1.1.9.5.9" class="ltx_td ltx_align_center">10.34</td>
</tr>
<tr id="S6.T3.1.1.10.6" class="ltx_tr">
<th id="S6.T3.1.1.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T3.1.1.10.6.1.1" class="ltx_text ltx_font_bold">Whisper-tiny</span></th>
<td id="S6.T3.1.1.10.6.2" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.10.6.2.1" class="ltx_text" style="color:#0000FF;">11.65</span></td>
<td id="S6.T3.1.1.10.6.3" class="ltx_td ltx_align_center">9.88</td>
<td id="S6.T3.1.1.10.6.4" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.10.6.4.1" class="ltx_text ltx_font_bold">11.92</span></td>
<td id="S6.T3.1.1.10.6.5" class="ltx_td ltx_align_center">10.91</td>
<td id="S6.T3.1.1.10.6.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.10.6.6.1" class="ltx_text" style="color:#0000FF;">11.91</span></td>
<td id="S6.T3.1.1.10.6.7" class="ltx_td ltx_align_center">9.93</td>
<td id="S6.T3.1.1.10.6.8" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.10.6.8.1" class="ltx_text ltx_font_bold">12.60</span></td>
<td id="S6.T3.1.1.10.6.9" class="ltx_td ltx_align_center">10.51</td>
</tr>
<tr id="S6.T3.1.1.11.7" class="ltx_tr">
<th id="S6.T3.1.1.11.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T3.1.1.11.7.1.1" class="ltx_text ltx_font_bold">Whisper-large</span></th>
<td id="S6.T3.1.1.11.7.2" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.11.7.2.1" class="ltx_text" style="color:#0000FF;">13.67</span></td>
<td id="S6.T3.1.1.11.7.3" class="ltx_td ltx_align_center">11.98</td>
<td id="S6.T3.1.1.11.7.4" class="ltx_td ltx_align_center">12.52</td>
<td id="S6.T3.1.1.11.7.5" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.11.7.5.1" class="ltx_text ltx_font_bold">12.70</span></td>
<td id="S6.T3.1.1.11.7.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.11.7.6.1" class="ltx_text" style="color:#0000FF;">13.27</span></td>
<td id="S6.T3.1.1.11.7.7" class="ltx_td ltx_align_center">11.82</td>
<td id="S6.T3.1.1.11.7.8" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.11.7.8.1" class="ltx_text ltx_font_bold">13.47</span></td>
<td id="S6.T3.1.1.11.7.9" class="ltx_td ltx_align_center">11.39</td>
</tr>
<tr id="S6.T3.1.1.12.8" class="ltx_tr">
<th id="S6.T3.1.1.12.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="background-color:#C0C0C0;" colspan="9"><span id="S6.T3.1.1.12.8.1.1" class="ltx_text ltx_font_bold" style="background-color:#C0C0C0;">Bert</span></th>
</tr>
<tr id="S6.T3.1.1.13.9" class="ltx_tr">
<th id="S6.T3.1.1.13.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T3.1.1.13.9.1.1" class="ltx_text ltx_font_bold">Wav2vec2-base</span></th>
<td id="S6.T3.1.1.13.9.2" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.13.9.2.1" class="ltx_text" style="color:#0000FF;">52.46</span></td>
<td id="S6.T3.1.1.13.9.3" class="ltx_td ltx_align_center">49.59</td>
<td id="S6.T3.1.1.13.9.4" class="ltx_td ltx_align_center">52.87</td>
<td id="S6.T3.1.1.13.9.5" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.13.9.5.1" class="ltx_text ltx_font_bold">52.71</span></td>
<td id="S6.T3.1.1.13.9.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.13.9.6.1" class="ltx_text" style="color:#0000FF;">50.40</span></td>
<td id="S6.T3.1.1.13.9.7" class="ltx_td ltx_align_center">44.61</td>
<td id="S6.T3.1.1.13.9.8" class="ltx_td ltx_align_center">51.78</td>
<td id="S6.T3.1.1.13.9.9" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.13.9.9.1" class="ltx_text ltx_font_bold">49.56</span></td>
</tr>
<tr id="S6.T3.1.1.14.10" class="ltx_tr">
<th id="S6.T3.1.1.14.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S6.T3.1.1.14.10.1.1" class="ltx_text ltx_font_bold">Whisper-tiny</span></th>
<td id="S6.T3.1.1.14.10.2" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.14.10.2.1" class="ltx_text" style="color:#0000FF;">52.73</span></td>
<td id="S6.T3.1.1.14.10.3" class="ltx_td ltx_align_center">50.80</td>
<td id="S6.T3.1.1.14.10.4" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.14.10.4.1" class="ltx_text ltx_font_bold">53.48</span></td>
<td id="S6.T3.1.1.14.10.5" class="ltx_td ltx_align_center">51.57</td>
<td id="S6.T3.1.1.14.10.6" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.14.10.6.1" class="ltx_text" style="color:#0000FF;">51.97</span></td>
<td id="S6.T3.1.1.14.10.7" class="ltx_td ltx_align_center">48.17</td>
<td id="S6.T3.1.1.14.10.8" class="ltx_td ltx_align_center"><span id="S6.T3.1.1.14.10.8.1" class="ltx_text ltx_font_bold">52.47</span></td>
<td id="S6.T3.1.1.14.10.9" class="ltx_td ltx_align_center">48.67</td>
</tr>
<tr id="S6.T3.1.1.15.11" class="ltx_tr">
<th id="S6.T3.1.1.15.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S6.T3.1.1.15.11.1.1" class="ltx_text ltx_font_bold">Whisper-large</span></th>
<td id="S6.T3.1.1.15.11.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.1.1.15.11.2.1" class="ltx_text" style="color:#0000FF;">54.23</span></td>
<td id="S6.T3.1.1.15.11.3" class="ltx_td ltx_align_center ltx_border_bb">52.07</td>
<td id="S6.T3.1.1.15.11.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.1.1.15.11.4.1" class="ltx_text ltx_font_bold">53.70</span></td>
<td id="S6.T3.1.1.15.11.5" class="ltx_td ltx_align_center ltx_border_bb">53.59</td>
<td id="S6.T3.1.1.15.11.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.1.1.15.11.6.1" class="ltx_text" style="color:#0000FF;">53.29</span></td>
<td id="S6.T3.1.1.15.11.7" class="ltx_td ltx_align_center ltx_border_bb">50.09</td>
<td id="S6.T3.1.1.15.11.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.1.1.15.11.8.1" class="ltx_text ltx_font_bold">53.64</span></td>
<td id="S6.T3.1.1.15.11.9" class="ltx_td ltx_align_center ltx_border_bb">49.94</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Summarization qualities for ASR and LLM-generated dialogue transcripts. <span id="S6.T3.3.1" class="ltx_text ltx_font_italic">Random</span> stands for augmenting clean dialogues using random insertion, deletion and substitutions. The numbers in the ASR columns are colored blue to indicate reference values. The summarization qualities from synthetic dialogues closest to real ASR values are shown in bold.</figcaption>
</figure>
<section id="S6.SS2.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Qualitative Comparison</h4>

<div id="S6.SS2.SSSx1.p1" class="ltx_para">
<p id="S6.SS2.SSSx1.p1.1" class="ltx_p">To illustrate that synthetic dialogues produced by our <span id="S6.SS2.SSSx1.p1.1.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span> method properly mimics the errors caracteristics that real ASR transcriptions exhibit, we present randomly selected snippets from doctor-patient conversations in Figure <a href="#S6.F4" title="Figure 4 ‣ Qualitative Comparison ‣ 6.2 LLM-produced synthetic errors are realistic ‣ 6 Main Experiments ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S6.F4" class="ltx_figure">
<div id="S6.F4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.3pt;height:100.8pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-51.5pt,12.0pt) scale(0.806409461880864,0.806409461880864) ;">
<table id="S6.F4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.F4.1.1.1.1" class="ltx_tr">
<th id="S6.F4.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S6.F4.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.F4.1.1.1.1.1.1.1" class="ltx_p" style="width:520.3pt;"><span id="S6.F4.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Sentence</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.F4.1.1.2.1" class="ltx_tr">
<td id="S6.F4.1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.F4.1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.F4.1.1.2.1.1.1.1" class="ltx_p" style="width:520.3pt;"><span id="S6.F4.1.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">(Ground truth)</span> Doctor: yeah now i mean have you any <span id="S6.F4.1.1.2.1.1.1.1.2" class="ltx_text" style="background-color:#000000;">have</span> you <span id="S6.F4.1.1.2.1.1.1.1.3" class="ltx_text" style="background-color:#000000;">noticed</span> <span id="S6.F4.1.1.2.1.1.1.1.4" class="ltx_text" style="background-color:#000000;">any</span> <span id="S6.F4.1.1.2.1.1.1.1.5" class="ltx_text" style="background-color:#000000;">kind</span> <span id="S6.F4.1.1.2.1.1.1.1.6" class="ltx_text" style="background-color:#000000;">of</span> white spots on the back <span id="S6.F4.1.1.2.1.1.1.1.7" class="ltx_text" style="background-color:#000000;">of</span> <span id="S6.F4.1.1.2.1.1.1.1.8" class="ltx_text" style="background-color:#000000;">your</span> back of your <span id="S6.F4.1.1.2.1.1.1.1.9" class="ltx_text" style="background-color:#000000;">throat</span> or <span id="S6.F4.1.1.2.1.1.1.1.10" class="ltx_text" style="background-color:#000000;">redness</span></span>
</span>
</td>
</tr>
<tr id="S6.F4.1.1.3.2" class="ltx_tr">
<td id="S6.F4.1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S6.F4.1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.F4.1.1.3.2.1.1.1" class="ltx_p" style="width:520.3pt;"><span id="S6.F4.1.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold">(Whisper ASR)</span> Doctor: yeah now i mean have you any <span id="S6.F4.1.1.3.2.1.1.1.2" class="ltx_text" style="background-color:#000000;">if</span> you <span id="S6.F4.1.1.3.2.1.1.1.3" class="ltx_text" style="background-color:#000000;">know</span> <span id="S6.F4.1.1.3.2.1.1.1.4" class="ltx_text" style="background-color:#000000;">the</span> <span id="S6.F4.1.1.3.2.1.1.1.5" class="ltx_text" style="background-color:#000000;">new</span> <span id="S6.F4.1.1.3.2.1.1.1.6" class="ltx_text" style="background-color:#000000;">chrome</span> white spots on the back <span id="S6.F4.1.1.3.2.1.1.1.7" class="ltx_text" style="background-color:#000000;">ports</span> <span id="S6.F4.1.1.3.2.1.1.1.8" class="ltx_text" style="background-color:#000000;">youll</span> back of your <span id="S6.F4.1.1.3.2.1.1.1.9" class="ltx_text" style="background-color:#000000;">throws</span> or <span id="S6.F4.1.1.3.2.1.1.1.10" class="ltx_text" style="background-color:#000000;">readiness</span></span>
</span>
</td>
</tr>
<tr id="S6.F4.1.1.4.3" class="ltx_tr">
<td id="S6.F4.1.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.F4.1.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.F4.1.1.4.3.1.1.1" class="ltx_p" style="width:520.3pt;"><span id="S6.F4.1.1.4.3.1.1.1.1" class="ltx_text ltx_font_bold">(Ground truth)</span> Doctor: yeah now i mean have you any <span id="S6.F4.1.1.4.3.1.1.1.2" class="ltx_text" style="background-color:#000000;">have</span> <span id="S6.F4.1.1.4.3.1.1.1.3" class="ltx_text" style="background-color:#000000;">you</span> <span id="S6.F4.1.1.4.3.1.1.1.4" class="ltx_text" style="background-color:#000000;">noticed</span> any kind <span id="S6.F4.1.1.4.3.1.1.1.5" class="ltx_text" style="background-color:#000000;">of</span> <span id="S6.F4.1.1.4.3.1.1.1.6" class="ltx_text" style="background-color:#000000;">white</span> <span id="S6.F4.1.1.4.3.1.1.1.7" class="ltx_text" style="background-color:#000000;">spots</span> on the back of your <span id="S6.F4.1.1.4.3.1.1.1.8" class="ltx_text" style="background-color:#000000;">back</span> <span id="S6.F4.1.1.4.3.1.1.1.9" class="ltx_text" style="background-color:#000000;">of</span> <span id="S6.F4.1.1.4.3.1.1.1.10" class="ltx_text" style="background-color:#000000;">your</span> <span id="S6.F4.1.1.4.3.1.1.1.11" class="ltx_text" style="background-color:#000000;">throat</span> or <span id="S6.F4.1.1.4.3.1.1.1.12" class="ltx_text" style="background-color:#000000;">redness</span></span>
</span>
</td>
</tr>
<tr id="S6.F4.1.1.5.4" class="ltx_tr">
<td id="S6.F4.1.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="S6.F4.1.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.F4.1.1.5.4.1.1.1" class="ltx_p" style="width:520.3pt;"><span id="S6.F4.1.1.5.4.1.1.1.1" class="ltx_text ltx_font_typewriter ltx_font_bold">MEDSAGE</span> Doctor: yeah now i mean have you any <span id="S6.F4.1.1.5.4.1.1.1.2" class="ltx_text" style="background-color:#000000;">do</span> <span id="S6.F4.1.1.5.4.1.1.1.3" class="ltx_text" style="background-color:#000000;">ya</span> <span id="S6.F4.1.1.5.4.1.1.1.4" class="ltx_text" style="background-color:#000000;">notice</span> any kind <span id="S6.F4.1.1.5.4.1.1.1.5" class="ltx_text" style="background-color:#000000;">kinda</span> <span id="S6.F4.1.1.5.4.1.1.1.6" class="ltx_text" style="background-color:#000000;">whish</span> <span id="S6.F4.1.1.5.4.1.1.1.7" class="ltx_text" style="background-color:#000000;">spits</span> on the back of your <span id="S6.F4.1.1.5.4.1.1.1.8" class="ltx_text" style="background-color:#000000;">bak</span> <span id="S6.F4.1.1.5.4.1.1.1.9" class="ltx_text" style="background-color:#000000;">o</span> <span id="S6.F4.1.1.5.4.1.1.1.10" class="ltx_text" style="background-color:#000000;">yer</span> <span id="S6.F4.1.1.5.4.1.1.1.11" class="ltx_text" style="background-color:#000000;">throt</span> or <span id="S6.F4.1.1.5.4.1.1.1.12" class="ltx_text" style="background-color:#000000;">reddness</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Comparison of an ASR transcription and its LLM-generated counterpart produced by <span id="S6.F4.4.1" class="ltx_text ltx_font_typewriter">MEDSAGE</span>. The words highlighted in yellow are errors at common word indexes among both transcripts, while those that are highlighted in red and green indicate unique errors of ASR and <span id="S6.F4.5.2" class="ltx_text ltx_font_typewriter">MEDSAGE</span>, respectively.</figcaption>
</figure>
<div id="S6.SS2.SSSx1.p2" class="ltx_para">
<p id="S6.SS2.SSSx1.p2.1" class="ltx_p">The commonalities between the nature of errors present in both utterances, such as phonetic confusions underscore the accuracy of the noise injections. For instance, the words ”white spots” are confused with ”whish spits”. This qualitative evidence supports our quantitative findings, demonstrating that LLM-generated synthetic noise can replicate the nuanced flaws typically seen in ASR outputs.</p>
</div>
</section>
<section id="S6.SS2.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Quantitative Comparison</h4>

<div id="S6.SS2.SSSx2.p1" class="ltx_para">
<p id="S6.SS2.SSSx2.p1.1" class="ltx_p">To further substantiate the realism of LLM-generated synthetic noise, we conduct quantitative comparisons between the errors in synthetic dialogues and those in ASR-transcribed dialogues using the aforementioned metrics. First, we compute pairwise similarities, w.r.t. three evaluation metrics, among ASR transcripts and synthetic dialogues. As shown in the similarity matrices in Figure <a href="#S5.F3" title="Figure 3 ‣ 5.2 Different ASR models exhibit different error profiles ‣ 5 Preliminary Experiments ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the diagonal entries contain the highest similarity scores, indicating that the greatest overlap is between ASR transcripts and the corresponding synthetic dialogues generated to mimic them. This pattern suggests that the LLM-generated synthetic dialogues are successful in accurately replicating the specific error characteristics of the ASR transcripts they were designed to imitate.</p>
</div>
<div id="S6.SS2.SSSx2.p2" class="ltx_para">
<p id="S6.SS2.SSSx2.p2.1" class="ltx_p">Additionally, we provide an indirect comparison based on the summarization qualities each dialogue transcript yields. In this experiment, we also include dialogues corrupted with random deletions as well as insertions and substitutions from the NLTK words corpus <cite class="ltx_cite ltx_citemacro_citep">(Bird, Klein, and Loper <a href="#bib.bib3" title="" class="ltx_ref">2009</a>)</cite> and name this baseline as <span id="S6.SS2.SSSx2.p2.1.1" class="ltx_text ltx_font_italic">Random</span>. As shown in Table <a href="#S6.T3" title="Table 3 ‣ 6.2 LLM-produced synthetic errors are realistic ‣ 6 Main Experiments ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the summarization qualities of LLM-generated synthetic dialogues closely align with those of the ASR transcripts, which are indicated in blue as reference values. This further supports the effectiveness of our method in producing realistic synthetic data that mimics ASR errors.</p>
</div>
<figure id="S6.F5" class="ltx_figure"><img src="/html/2408.14418/assets/x3.png" id="S6.F5.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="322" height="497" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Change in the downstream summarization quality w.r.t. F1 and RougeL metrics as the rate of error tags used to generate synthetic dialogues increases. In-context examples were taken from Whisper-tiny transcribed dialogues. Green dots mark the scores of real ASR transcriptions.</figcaption>
</figure>
</section>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Error tagging system enables controllable generation</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">Lastly, we validate that our method is capable of adjusting the injected noise rate through the use of corruption tags, as detailed in the methodology section. To this end, we insert corruption tags at various rates to simulate increasing amounts of noise. We then record the resulting transcription quality and summarization performance for each noise level.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">As depicted in Figure <a href="#S6.F5" title="Figure 5 ‣ Quantitative Comparison ‣ 6.2 LLM-produced synthetic errors are realistic ‣ 6 Main Experiments ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we observe a clear trend: as the noise rate increases, the quality of the generated summaries decreases. This is evidenced by a gradual drop in the summarization quality quantified by the scores on various metrics. This analysis demonstrates the controllability of our noise generation method, which is essential for adapting the synthetic noise generation to errors made by various different ASR models with ease.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This study highlights the critical role of Automated Speech Recognition (ASR) technology in transcribing medical dialogues and the consequent impact of ASR errors on downstream summarization tasks. Recognizing the challenges posed by limited availability of supervised data, we explored a novel approach to improve summarization models through data augmentation. By leveraging large language models (LLMs) to generate synthetic noisy dialogues that accurately reflect real-world ASR errors, we developed a method for enhancing robustness in clinical dialogue summarization. Our findings demonstrate that LLMs can effectively model ASR noise, and the use of these noisy transcripts for data augmentation leads to significant improvements in the performance of summarization models.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski et al. (2020)</span>
<span class="ltx_bibblock">
Baevski, A.; Zhou, Y.; Mohamed, A.; and Auli, M. 2020.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33: 12449–12460.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2024)</span>
<span class="ltx_bibblock">
Bai, Y.; Chen, J.; Chen, J.; Chen, W.; Chen, Z.; Ding, C.; Dong, L.; Dong, Q.; Du, Y.; Gao, K.; et al. 2024.

</span>
<span class="ltx_bibblock">Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2407.04675</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bird, Klein, and Loper (2009)</span>
<span class="ltx_bibblock">
Bird, S.; Klein, E.; and Loper, E. 2009.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit</em>.

</span>
<span class="ltx_bibblock">O’Reilly Media, Inc.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; et al. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33: 1877–1901.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Chen, C.; et al. 2024.

</span>
<span class="ltx_bibblock">Hyporadise: An open baseline for generative speech recognition with large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 36.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chintagunta et al. (2021)</span>
<span class="ltx_bibblock">
Chintagunta, B.; Katariya, N.; Amatriain, X.; and Kannan, A. 2021.

</span>
<span class="ltx_bibblock">Medically Aware GPT-3 as a Data Generator for Medical Dialogue Summarization.

</span>
<span class="ltx_bibblock">In Shivade, C.; Gangadharaiah, R.; Gella, S.; Konam, S.; Yuan, S.; Zhang, Y.; Bhatia, P.; and Wallace, B., eds., <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Second Workshop on Natural Language Processing for Medical Conversations</em>, 66–76. Online: Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. (2024)</span>
<span class="ltx_bibblock">
Dubey, A.; Jauhri, A.; Pandey, A.; Kadian, A.; Al-Dahle, A.; Letman, A.; Mathur, A.; Schelten, A.; Yang, A.; Fan, A.; et al. 2024.

</span>
<span class="ltx_bibblock">The Llama 3 Herd of Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2407.21783</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Everson et al. (2024)</span>
<span class="ltx_bibblock">
Everson, K.; Gu, Y.; Yang, H.; Shivakumar, P. G.; Lin, G.-T.; Kolehmainen, J.; Bulyko, I.; Gandhe, A.; Ghosh, S.; Hamza, W.; et al. 2024.

</span>
<span class="ltx_bibblock">Towards ASR robust spoken language understanding through in-context learning with word confusion networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 12856–12860. IEEE.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fabbri et al. (2021)</span>
<span class="ltx_bibblock">
Fabbri, A. R.; Han, S.; Li, H.; Li, H.; Ghazvininejad, M.; Joty, S.; Radev, D.; and Mehdad, Y. 2021.

</span>
<span class="ltx_bibblock">Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine-tuning and Data Augmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, 704–717.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2024)</span>
<span class="ltx_bibblock">
Guo, J.; Wang, M.; Qiao, X.; Wei, D.; Shang, H.; Li, Z.; Yu, Z.; Li, Y.; Su, C.; Zhang, M.; et al. 2024.

</span>
<span class="ltx_bibblock">Ucorrect: An unsupervised framework for automatic speech recognition error correction.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.05689</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hodgson and Coiera (2016)</span>
<span class="ltx_bibblock">
Hodgson, T.; and Coiera, E. 2016.

</span>
<span class="ltx_bibblock">Risks and benefits of speech recognition for clinical documentation: a systematic review.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Journal of the american medical informatics association</em>, 23(e1): e169–e179.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hori and Furui (2003)</span>
<span class="ltx_bibblock">
Hori, C.; and Furui, S. 2003.

</span>
<span class="ltx_bibblock">A new approach to automatic speech summarization.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em>, 5(3): 368–378.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Hu, E. J.; Shen, Y.; Wallis, P.; Allen-Zhu, Z.; Li, Y.; Wang, S.; Wang, L.; and Chen, W. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.09685</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2024)</span>
<span class="ltx_bibblock">
Hu, Y.; et al. 2024.

</span>
<span class="ltx_bibblock">Large Language Models are Efficient Learners of Noise-Robust Speech Recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.10446</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Jiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.; Chaplot, D. S.; Casas, D. d. l.; Bressand, F.; Lengyel, G.; Lample, G.; Saulnier, L.; et al. 2023.

</span>
<span class="ltx_bibblock">Mistral 7B.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.06825</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna et al. (2021)</span>
<span class="ltx_bibblock">
Krishna, K.; Khosla, S.; Bigham, J.; and Lipton, Z. C. 2021.

</span>
<span class="ltx_bibblock">Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques.

</span>
<span class="ltx_bibblock">In Zong, C.; Xia, F.; Li, W.; and Navigli, R., eds., <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>, 4958–4972. Online: Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le-Duc et al. (2024)</span>
<span class="ltx_bibblock">
Le-Duc, K.; Nguyen, K.-N.; Vo-Dang, L.; and Hy, T.-S. 2024.

</span>
<span class="ltx_bibblock">Real-time Speech Summarization for Medical Conversations.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.15888</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2014)</span>
<span class="ltx_bibblock">
Li, J.; Deng, L.; Gong, Y.; and Haeb-Umbach, R. 2014.

</span>
<span class="ltx_bibblock">An overview of noise-robust automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 22(4): 745–777.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022)</span>
<span class="ltx_bibblock">
Li, Z.; Chen, W.; Li, S.; Wang, H.; Qian, J.; and Yan, X. 2022.

</span>
<span class="ltx_bibblock">Controllable Dialogue Simulation with In-context Learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, 4330–4347.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Lin, C.-Y. 2004.

</span>
<span class="ltx_bibblock">Rouge: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Text summarization branches out</em>, 74–81.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020)</span>
<span class="ltx_bibblock">
Liu, X.; Cheng, H.; He, P.; Chen, W.; Wang, Y.; Poon, H.; and Gao, J. 2020.

</span>
<span class="ltx_bibblock">Adversarial training for large neural language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.08994</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Hakkani-Tür (2011)</span>
<span class="ltx_bibblock">
Liu, Y.; and Hakkani-Tür, D. 2011.

</span>
<span class="ltx_bibblock">Speech summarization.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Spoken language understanding: Systems for extracting semantic information from speech</em>, 357–396.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maynez et al. (2020)</span>
<span class="ltx_bibblock">
Maynez, J.; Narayan, S.; Bohnet, B.; and McDonald, R. 2020.

</span>
<span class="ltx_bibblock">On Faithfulness and Factuality in Abstractive Summarization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, 1906–1919.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nanayakkara et al. (2022)</span>
<span class="ltx_bibblock">
Nanayakkara, G.; Wiratunga, N.; Corsar, D.; Martin, K.; and Wijekoon, A. 2022.

</span>
<span class="ltx_bibblock">Clinical dialogue transcription error correction using Seq2Seq models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Multimodal AI in healthcare: A paradigm shift in health intelligence</em>, 41–57. Springer.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papadopoulos Korfiatis et al. (2022)</span>
<span class="ltx_bibblock">
Papadopoulos Korfiatis, A.; Moramarco, F.; Sarac, R.; and Savkov, A. 2022.

</span>
<span class="ltx_bibblock">PriMock57: A Dataset Of Primary Care Mock Consultations.

</span>
<span class="ltx_bibblock">In Muresan, S.; Nakov, P.; and Villavicencio, A., eds., <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, 588–598. Dublin, Ireland: Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2022)</span>
<span class="ltx_bibblock">
Radford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey, C.; and Sutskever, I. 2022.

</span>
<span class="ltx_bibblock">Robust Speech Recognition via Large-Scale Weak Supervision.

</span>
<span class="ltx_bibblock">arXiv:2212.04356.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2023)</span>
<span class="ltx_bibblock">
Radford, A.; Kim, J. W.; Xu, T.; Brockman, G.; McLeavey, C.; and Sutskever, I. 2023.

</span>
<span class="ltx_bibblock">Robust speech recognition via large-scale weak supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, 28492–28518. PMLR.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radhakrishnan et al. (2023)</span>
<span class="ltx_bibblock">
Radhakrishnan, S.; Yang, C.-H.; Khan, S.; Kumar, R.; Kiani, N.; Gomez-Cabrero, D.; and Tegnér, J. 2023.

</span>
<span class="ltx_bibblock">Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, 10007–10016.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et al. (2023)</span>
<span class="ltx_bibblock">
Sharma, S.; Joshi, A.; Zhao, Y.; Mukhija, N.; Bhathena, H.; Singh, P.; and Santhanam, S. 2023.

</span>
<span class="ltx_bibblock">When and how to paraphrase for named entity recognition?

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 7052–7087.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sugiyama and Yoshinaga (2019)</span>
<span class="ltx_bibblock">
Sugiyama, A.; and Yoshinaga, N. 2019.

</span>
<span class="ltx_bibblock">Data augmentation using back-translation for context-aware neural machine translation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the fourth workshop on discourse in machine translation (DiscoMT 2019)</em>, 35–44.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2024)</span>
<span class="ltx_bibblock">
Team, G.; Mesnard, T.; Hardin, C.; Dadashi, R.; Bhupatiraju, S.; Pathak, S.; Sifre, L.; Rivière, M.; Kale, M. S.; Love, J.; et al. 2024.

</span>
<span class="ltx_bibblock">Gemma: Open models based on gemini research and technology.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2403.08295</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wagner and Fischer (1974)</span>
<span class="ltx_bibblock">
Wagner, R. A.; and Fischer, M. J. 1974.

</span>
<span class="ltx_bibblock">The string-to-string correction problem.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Journal of the ACM (JACM)</em>, 21(1): 168–173.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024)</span>
<span class="ltx_bibblock">
Wang, J.; Yao, Z.; Yang, Z.; Zhou, H.; Li, R.; Wang, X.; Xu, Y.; and Yu, H. 2024.

</span>
<span class="ltx_bibblock">NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned on Clinical Notes.

</span>
<span class="ltx_bibblock">arXiv:2310.15959.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2020)</span>
<span class="ltx_bibblock">
Wang, L.; Fazel-Zarandi, M.; Tiwari, A.; Matsoukas, S.; and Polymenakos, L. 2020.

</span>
<span class="ltx_bibblock">Data augmentation for training dialog models robust to speech recognition errors.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.05635</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2018)</span>
<span class="ltx_bibblock">
Wang, X.; Pham, H.; Dai, Z.; and Neubig, G. 2018.

</span>
<span class="ltx_bibblock">SwitchOut: an efficient data augmentation algorithm for neural machine translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1808.07512</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2023)</span>
<span class="ltx_bibblock">
Yang, C.-H. H.; et al. 2023.

</span>
<span class="ltx_bibblock">Generative speech recognition error correction with large language models and task-activating prompting.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>. IEEE.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu and Deng (2016)</span>
<span class="ltx_bibblock">
Yu, D.; and Deng, L. 2016.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Automatic speech recognition</em>, volume 1.

</span>
<span class="ltx_bibblock">Springer.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Zhang, T.; Kishore, V.; Wu, F.; Weinberger, K. Q.; and Artzi, Y. 2020.

</span>
<span class="ltx_bibblock">BERTScore: Evaluating Text Generation with BERT.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2022)</span>
<span class="ltx_bibblock">
Zhong, M.; Liu, Y.; Xu, Y.; Zhu, C.; and Zeng, M. 2022.

</span>
<span class="ltx_bibblock">Dialoglm: Pre-trained model for long dialogue understanding and summarization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume 36, 11765–11773.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Appendix A: Computing Infrastructure</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The specifications of the system used to run computational experiments are:</p>
<ul id="Sx1.I1" class="ltx_itemize">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.p1.1" class="ltx_p">Ubuntu 22.04.4 LTS</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.p1.1" class="ltx_p">NVIDIA A100 80GB GPUs</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.p1.1" class="ltx_p">Intel(R) Xeon(R) Silver 4314 CPU @ 2.40GHz</p>
</div>
</li>
</ul>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Appendix B: Additional Experiment Details &amp; Results</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">Here we present additional qualitative and quantitative experimental results that extend beyond those given in the main paper.</p>
</div>
<section id="Sx2.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Huggingface Models Used in Experiments</h3>

<div id="Sx2.SSx1.p1" class="ltx_para">
<p id="Sx2.SSx1.p1.1" class="ltx_p">For the experiments resulting in Table 2 of the main paper, we fine-tuned the following model checkpoints retrieved from Hugging Face:</p>
</div>
<div id="Sx2.SSx1.p2" class="ltx_para">
<ul id="Sx2.I2" class="ltx_itemize">
<li id="Sx2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I2.i1.p1" class="ltx_para">
<p id="Sx2.I2.i1.p1.1" class="ltx_p"><span id="Sx2.I2.i1.p1.1.1" class="ltx_text ltx_font_typewriter">meta-llama/Meta-Llama-3-8B-Instruct</span></p>
</div>
</li>
<li id="Sx2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I2.i2.p1" class="ltx_para">
<p id="Sx2.I2.i2.p1.1" class="ltx_p"><span id="Sx2.I2.i2.p1.1.1" class="ltx_text ltx_font_typewriter">mistralai/Mistral-7B-Instruct-v0.2</span></p>
</div>
</li>
<li id="Sx2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I2.i3.p1" class="ltx_para">
<p id="Sx2.I2.i3.p1.1" class="ltx_p"><span id="Sx2.I2.i3.p1.1.1" class="ltx_text ltx_font_typewriter">unsloth/gemma-7b-it</span></p>
</div>
</li>
</ul>
</div>
<div id="Sx2.SSx1.p3" class="ltx_para">
<p id="Sx2.SSx1.p3.1" class="ltx_p">For the remaining experiments, we used AWQ quantized checkpoints of the same models:</p>
</div>
<div id="Sx2.SSx1.p4" class="ltx_para">
<ul id="Sx2.I3" class="ltx_itemize">
<li id="Sx2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I3.i1.p1" class="ltx_para">
<p id="Sx2.I3.i1.p1.1" class="ltx_p"><span id="Sx2.I3.i1.p1.1.1" class="ltx_text ltx_font_typewriter">solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ</span></p>
</div>
</li>
<li id="Sx2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx2.I3.i2.p1" class="ltx_para">
<p id="Sx2.I3.i2.p1.1" class="ltx_p"><span id="Sx2.I3.i2.p1.1.1" class="ltx_text ltx_font_typewriter">TheBloke/Mistral-7B-Instruct-v0.2-AWQ</span></p>
</div>
</li>
</ul>
</div>
<div id="Sx2.SSx1.p5" class="ltx_para">
<p id="Sx2.SSx1.p5.1" class="ltx_p">For inference, we primarily used the Text Generation Inference (TGI) framework<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/huggingface/text-generation-inference</span></span></span>. For fine-tuning, we utilized Unsloth<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://github.com/Unsloth/unsloth</span></span></span>.</p>
</div>
</section>
<section id="Sx2.SSx2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Extended Evaluation Using Other Metrics</h3>

<div id="Sx2.SSx2.p1" class="ltx_para">
<p id="Sx2.SSx2.p1.1" class="ltx_p">The experimental evaluation in the main paper primarily reports F1 score over domain-specific entities, Rouge-L, and Bert score. Here, we extend this evaluation by presenting results using additional metrics such as Precision, Recall, Rouge-1, and Rouge-2.</p>
</div>
<figure id="Sx2.F6" class="ltx_figure"><img src="/html/2408.14418/assets/x4.png" id="Sx2.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="317" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Precision, Recall, and F1 score across different noise levels. The shaded regions represent the standard deviation (STD) across multiple runs.</figcaption>
</figure>
<figure id="Sx2.F7" class="ltx_figure"><img src="/html/2408.14418/assets/x5.png" id="Sx2.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="317" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Rouge-1, Rouge-2, Rouge-L, and Rouge-Lsum scores across different noise levels. The shaded regions represent the standard deviation (STD) across multiple runs.</figcaption>
</figure>
<div id="Sx2.SSx2.p2" class="ltx_para">
<p id="Sx2.SSx2.p2.1" class="ltx_p">Figures <a href="#Sx2.F6" title="Figure 6 ‣ Extended Evaluation Using Other Metrics ‣ Appendix B: Additional Experiment Details &amp; Results ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> and <a href="#Sx2.F7" title="Figure 7 ‣ Extended Evaluation Using Other Metrics ‣ Appendix B: Additional Experiment Details &amp; Results ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, also included in the attachment, illustrate how these additional metrics behave under varying noise levels. It is observed that these metrics, such as Precision, Recall, Rouge-1, and Rouge-2, closely correlate with the Rouge-L and F1 scores reported in the main paper. Specifically, as noise increases, a noticeable decline is observed across all metrics.</p>
</div>
<figure id="Sx2.F8" class="ltx_figure">
<div id="Sx2.F8.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:505.9pt;height:500.2pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-6.0pt,5.9pt) scale(0.976829056336013,0.976829056336013) ;">
<table id="Sx2.F8.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Sx2.F8.1.1.1.1" class="ltx_tr" style="background-color:#F7E1E6;">
<th id="Sx2.F8.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="Sx2.F8.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#F7E1E6;">
<span id="Sx2.F8.1.1.1.1.1.1.1" class="ltx_p" style="width:505.9pt;"><span id="Sx2.F8.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Snippet 1:</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Sx2.F8.1.1.2.1" class="ltx_tr">
<td id="Sx2.F8.1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx2.F8.1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.2.1.1.1.1" class="ltx_p" style="width:505.9pt;"><span id="Sx2.F8.1.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">(Whisper-tiny ASR + Denoising)</span></span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.3.2" class="ltx_tr">
<td id="Sx2.F8.1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.3.2.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: Comes and goes, yeah.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.4.3" class="ltx_tr">
<td id="Sx2.F8.1.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.4.3.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: Is there a pain, somewhere else, moving down between <span id="Sx2.F8.1.1.4.3.1.1.1.1" class="ltx_text" style="background-color:#000000;">your shoulders</span>?</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.5.4" class="ltx_tr">
<td id="Sx2.F8.1.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.5.4.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: Um, no, actually… just possibly my stomach.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.6.5" class="ltx_tr">
<td id="Sx2.F8.1.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.6.5.1.1.1" class="ltx_p" style="width:505.9pt;"><span id="Sx2.F8.1.1.6.5.1.1.1.1" class="ltx_text ltx_font_bold">(Whisper-tiny ASR)</span></span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.7.6" class="ltx_tr">
<td id="Sx2.F8.1.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.7.6.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: comes and goes.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.8.7" class="ltx_tr">
<td id="Sx2.F8.1.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.8.7.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: There’s a pain move anywhere else, with on-between <span id="Sx2.F8.1.1.8.7.1.1.1.1" class="ltx_text" style="background-color:#000000;">your back</span>.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.9.8" class="ltx_tr">
<td id="Sx2.F8.1.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.9.8.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: Um, no, just maybe my stomach.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.10.9" class="ltx_tr">
<td id="Sx2.F8.1.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.10.9.1.1.1" class="ltx_p" style="width:505.9pt;"><span id="Sx2.F8.1.1.10.9.1.1.1.1" class="ltx_text ltx_font_bold">(Ground truth)</span></span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.11.10" class="ltx_tr">
<td id="Sx2.F8.1.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.11.10.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: Uh, it comes and goes.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.12.11" class="ltx_tr">
<td id="Sx2.F8.1.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.12.11.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: Come and go. Does the pain move anywhere else, for example towards <span id="Sx2.F8.1.1.12.11.1.1.1.1" class="ltx_text" style="background-color:#000000;">your back</span>?</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.13.12" class="ltx_tr">
<td id="Sx2.F8.1.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.13.12.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: Uh…no, just maybe my stomach.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.14.13" class="ltx_tr" style="background-color:#F7E1E6;">
<td id="Sx2.F8.1.1.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx2.F8.1.1.14.13.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#F7E1E6;">
<span id="Sx2.F8.1.1.14.13.1.1.1" class="ltx_p" style="width:505.9pt;"><span id="Sx2.F8.1.1.14.13.1.1.1.1" class="ltx_text ltx_font_bold">Snippet 2:</span></span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.15.14" class="ltx_tr">
<td id="Sx2.F8.1.1.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="Sx2.F8.1.1.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.15.14.1.1.1" class="ltx_p" style="width:505.9pt;"><span id="Sx2.F8.1.1.15.14.1.1.1.1" class="ltx_text ltx_font_bold">(Whisper-tiny ASR + Denoising)</span></span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.16.15" class="ltx_tr">
<td id="Sx2.F8.1.1.16.15.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.16.15.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: OK, an’…an’ yep, you did mention having some pain in yer tummies too, didn’t ya? Whereabouts is the pain?</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.17.16" class="ltx_tr">
<td id="Sx2.F8.1.1.17.16.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.17.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.17.16.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: Ah, yes… <span id="Sx2.F8.1.1.17.16.1.1.1.1" class="ltx_text" style="background-color:#000000;">actually, I don’t think this has got anything to do with my elbow… I mean, aren’t we talking about something else?</span> Like, ah, in my lower abdomen… specifically, towards one side…?</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.18.17" class="ltx_tr">
<td id="Sx2.F8.1.1.18.17.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.18.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.18.17.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: One side…um, what did you mean by ”which” side?</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.19.18" class="ltx_tr">
<td id="Sx2.F8.1.1.19.18.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.19.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.19.18.1.1.1" class="ltx_p" style="width:505.9pt;"><span id="Sx2.F8.1.1.19.18.1.1.1.1" class="ltx_text ltx_font_bold">(Whisper-tiny ASR)</span></span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.20.19" class="ltx_tr">
<td id="Sx2.F8.1.1.20.19.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.20.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.20.19.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: Okay, and you mentioned you’ve had some pain in your tummy as well. Yep, where about as is the pain?</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.21.20" class="ltx_tr">
<td id="Sx2.F8.1.1.21.20.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.21.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.21.20.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: Yeah, we’re exactly in my lower abdomen, so like, yeah, just to one side.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.22.21" class="ltx_tr">
<td id="Sx2.F8.1.1.22.21.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.22.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.22.21.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: one side of what side is that?</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.23.22" class="ltx_tr">
<td id="Sx2.F8.1.1.23.22.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.23.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.23.22.1.1.1" class="ltx_p" style="width:505.9pt;"><span id="Sx2.F8.1.1.23.22.1.1.1.1" class="ltx_text ltx_font_bold">(Ground truth)</span></span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.24.23" class="ltx_tr">
<td id="Sx2.F8.1.1.24.23.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.24.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.24.23.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: Okay. And you mentioned you’ve had some pain in your tummy as well. Whereabouts is the pain, exactly?</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.25.24" class="ltx_tr">
<td id="Sx2.F8.1.1.25.24.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="Sx2.F8.1.1.25.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.25.24.1.1.1" class="ltx_p" style="width:505.9pt;">Patient: Yep. So in my lower abdomen, so, uh, like, um…yeah, just to one side.</span>
</span>
</td>
</tr>
<tr id="Sx2.F8.1.1.26.25" class="ltx_tr">
<td id="Sx2.F8.1.1.26.25.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b">
<span id="Sx2.F8.1.1.26.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="Sx2.F8.1.1.26.25.1.1.1" class="ltx_p" style="width:505.9pt;">Doctor: One side. And what side is that?</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Comparison of dialogue transcripts showing hallucinated words by the denoising model, highlighted in red. Yellow highlights indicate the correct words in the ASR and ground truth transcriptions corresponding to the hallucinated substrings in
the denoising output. </figcaption>
</figure>
</section>
<section id="Sx2.SSx3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Denoising Models can Hallucinate</h3>

<div id="Sx2.SSx3.p1" class="ltx_para">
<p id="Sx2.SSx3.p1.1" class="ltx_p">As outlined in the main paper, one significant challenge associated with using LLMs for ASR error correction, without fine-tuning, is their inclination to hallucinate, or generate content that is not present in the original input. This issue can severely degrade the quality of medical reports that are generated based on dialogues that are pre-processed by denoising models. Figure <a href="#Sx2.F8" title="Figure 8 ‣ Extended Evaluation Using Other Metrics ‣ Appendix B: Additional Experiment Details &amp; Results ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> provides qualitative examples that highlight this problem. These examples illustrate how a denoising model, designed to clean up noisy ASR transcriptions, introduces additional errors in the form of hallucinations.</p>
</div>
<div id="Sx2.SSx3.p2" class="ltx_para">
<p id="Sx2.SSx3.p2.1" class="ltx_p">In Snippet 1, for example, the denoising model generates the phrase ”your shoulders,” which is not present in either the ASR output or the ground truth transcript. Similarly, in Snippet 2, the denoising model introduces a segment that is non-existent in the actual converstaion: ”actually, I don’t think this has got anything to do with my elbow… I mean, aren’t we talking about something else?” These hallucinations can lead to inaccurate representations of the dialogue, which is particularly problematic when the text is later used for summarization or decision-making in clinical settings.</p>
</div>
</section>
<section id="Sx2.SSx4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Diversity of Error Styles Across ASR Models</h3>

<div id="Sx2.SSx4.p1" class="ltx_para">
<p id="Sx2.SSx4.p1.1" class="ltx_p">The analysis of ASR errors reveals that these errors are often rooted in phonetic confusions, where the model misinterprets similar-sounding words or phrases. However, the specific types of phonetic confusions are unique to the ASR model employed, as demonstrated in the examples provided in Figure <a href="#Sx2.F9" title="Figure 9 ‣ Diversity of Error Styles Across ASR Models ‣ Appendix B: Additional Experiment Details &amp; Results ‣ MEDSAGE: Enhancing Robustness of Medical Dialogue Summarization to ASR Errors with LLM-generated Synthetic Dialogues" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. For instance, the Whisper Tiny model shows errors such as ”diure” instead of ”diarrhea,” while the Wav2vec2 model struggles with more severe distortions like ”TWOLLE” instead of ”toilet.” This variability of error styles across ASR models underscores the challenge of employing a one-fits-all synthetic dialogue generation approach. To address this, our LLM-based synthetic data generation framework incorporates in-context examples that capture the distinctive error patterns of each ASR model. By providing the LLM with these targeted examples, we ensure that it qualitatively understands the specific types of ASR errors we aim to mimic.</p>
</div>
<figure id="Sx2.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_pagination ltx_centering ltx_figure_panel ltx_role_start_2_columns"></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="Sx2.F9.pic1" class="ltx_picture ltx_centering ltx_figure_panel" height="129.96" overflow="visible" version="1.1" width="600"><g transform="translate(0,129.96) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#0000BF" fill-opacity="1.0"><path d="M 0 5.91 L 0 124.05 C 0 127.31 2.64 129.96 5.91 129.96 L 594.09 129.96 C 597.36 129.96 600 127.31 600 124.05 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2FF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 104.31 L 598.03 104.31 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 110.21)"><foreignObject width="556.69" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="Sx2.F9.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="Sx2.F9.pic1.1.1.1.1.1.1" class="ltx_p">Whisper Tiny (ASR)</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="78.72" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="Sx2.F9.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="Sx2.F9.pic1.2.2.2.1.1.1" class="ltx_p"><span id="Sx2.F9.pic1.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Doctor:</span> Sorry to hear that. And when you say diure, what do you mean by diure? Do you mean you’re going to tell a more often or are your schools more loose? Yes.</span>
<span id="Sx2.F9.pic1.2.2.2.1.1.2" class="ltx_p"><span id="Sx2.F9.pic1.2.2.2.1.1.2.1" class="ltx_text ltx_font_bold">Patient:</span> Yeah, so it’s like loose and watery stall going to the toilet quite often and like some pain in my like lower stomach. Okay</span>
<span id="Sx2.F9.pic1.2.2.2.1.1.3" class="ltx_p"><span id="Sx2.F9.pic1.2.2.2.1.1.3.1" class="ltx_text ltx_font_bold">Doctor:</span> And how many times a day are you going? Let’s see, a lot of a couple of days.</span>
</span></foreignObject></g></g></svg></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="Sx2.F9.pic2" class="ltx_picture ltx_centering ltx_figure_panel" height="160.32" overflow="visible" version="1.1" width="600"><g transform="translate(0,160.32) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#00BF00" fill-opacity="1.0"><path d="M 0 5.91 L 0 154.41 C 0 157.68 2.64 160.32 5.91 160.32 L 594.09 160.32 C 597.36 160.32 600 157.68 600 154.41 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2FFF2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 134.67 L 598.03 134.67 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 140.58)"><foreignObject width="556.69" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="Sx2.F9.pic2.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="Sx2.F9.pic2.1.1.1.1.1.1" class="ltx_p">Wav2vec2 (ASR)</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="109.08" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="Sx2.F9.pic2.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="Sx2.F9.pic2.2.2.2.1.1.1" class="ltx_p"><span id="Sx2.F9.pic2.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Doctor:</span> SO YO HEAR BATS AND WE YOU SAID DIRE AR WHAT DO YOU MEAN BY DIRECT YOU MEAN YOU GAINST THE TWOLLE MORE OFTEN OR ARE YOUR STOOLS MORE LOOSE YE</span>
<span id="Sx2.F9.pic2.2.2.2.1.1.2" class="ltx_p"><span id="Sx2.F9.pic2.2.2.2.1.1.2.1" class="ltx_text ltx_font_bold">Patient:</span> YEA SO IT’S LIKE LOOSE AND MORDERY STOL GOING TO THE TOILET QUITE OFTEN LA AND LIKE SOME PAIN IN MY LIKE LOWER STOMACH LIK</span>
<span id="Sx2.F9.pic2.2.2.2.1.1.3" class="ltx_p"><span id="Sx2.F9.pic2.2.2.2.1.1.3.1" class="ltx_text ltx_font_bold">Doctor:</span> LA N E AND HAWMY TIMES A DAY ARE YOU GOING LETS SEE ER LOST COUPLE DAYS</span>
</span></foreignObject></g></g></svg></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_pagination ltx_centering ltx_figure_panel ltx_role_end_2_columns"></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_pagination ltx_centering ltx_figure_panel ltx_role_start_2_columns"></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="Sx2.F9.pic3" class="ltx_picture ltx_centering ltx_figure_panel" height="129.96" overflow="visible" version="1.1" width="600"><g transform="translate(0,129.96) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#BF0000" fill-opacity="1.0"><path d="M 0 5.91 L 0 124.05 C 0 127.31 2.64 129.96 5.91 129.96 L 594.09 129.96 C 597.36 129.96 600 127.31 600 124.05 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFF2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 104.31 L 598.03 104.31 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 110.21)"><foreignObject width="556.69" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="Sx2.F9.pic3.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="Sx2.F9.pic3.1.1.1.1.1.1" class="ltx_p">Whisper Large (ASR)</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="78.72" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="Sx2.F9.pic3.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="Sx2.F9.pic3.2.2.2.1.1.1" class="ltx_p"><span id="Sx2.F9.pic3.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Doctor:</span> Sorry to hear that. And when you say diarrhea, what do you mean by diarrhea? Do you mean you go into the toilet more often or are your stools more loose?</span>
<span id="Sx2.F9.pic3.2.2.2.1.1.2" class="ltx_p"><span id="Sx2.F9.pic3.2.2.2.1.1.2.1" class="ltx_text ltx_font_bold">Patient:</span> Yeah, so it’s like loose and watery stool going to the toilet quite often and like some pain in my like lower stomach. Okay</span>
<span id="Sx2.F9.pic3.2.2.2.1.1.3" class="ltx_p"><span id="Sx2.F9.pic3.2.2.2.1.1.3.1" class="ltx_text ltx_font_bold">Doctor:</span> How many times a day are you going?</span>
</span></foreignObject></g></g></svg></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="Sx2.F9.pic4" class="ltx_picture ltx_centering ltx_figure_panel" height="139.64" overflow="visible" version="1.1" width="600"><g transform="translate(0,139.64) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#BFBF00" fill-opacity="1.0"><path d="M 0 5.91 L 0 133.74 C 0 137 2.64 139.64 5.91 139.64 L 594.09 139.64 C 597.36 139.64 600 137 600 133.74 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFF2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 118.22 L 598.03 118.22 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 124.13)"><foreignObject width="556.69" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="Sx2.F9.pic4.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="Sx2.F9.pic4.1.1.1.1.1.1" class="ltx_p">Ground Truth</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="92.63" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="Sx2.F9.pic4.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="Sx2.F9.pic4.2.2.2.1.1.1" class="ltx_p"><span id="Sx2.F9.pic4.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Doctor:</span> Sorry to hear that. Um, and and when you say diarrhea, what’d you mean by diarrhea? Do you mean you’re going to the toilet more often? Or are your stools more loose?</span>
<span id="Sx2.F9.pic4.2.2.2.1.1.2" class="ltx_p"><span id="Sx2.F9.pic4.2.2.2.1.1.2.1" class="ltx_text ltx_font_bold">Patient:</span> Yeah, so it’s like loose and watery stool, going to the toilet quite often, uh and like some pain in my, like, lower stomach?</span>
<span id="Sx2.F9.pic4.2.2.2.1.1.3" class="ltx_p"><span id="Sx2.F9.pic4.2.2.2.1.1.3.1" class="ltx_text ltx_font_bold">Doctor:</span> Okay. And how many times a day are you going, let’s say, in the last couple of days?</span>
</span></foreignObject></g></g></svg></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_pagination ltx_centering ltx_figure_panel ltx_role_end_2_columns"></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Comparison of dialogue transcripts generated by different ASR models and the ground truth. The figure illustrates how phonetic confusions are common across ASR models, while each model exhibits a unique error style.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.14417" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.14418" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.14418">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.14418" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.14419" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 11:57:14 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
