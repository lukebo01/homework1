<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.17997] On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures</title><meta property="og:description" content="In this work we evaluate the utility of synthetic data for training automatic speech recognition (ASR).
We use the ASR training data to train a text-to-speech (TTS) system similar to FastSpeech-2.
With this TTS we repr‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.17997">

<!--Generated on Mon Aug  5 16:34:23 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.2" class="ltx_ERROR undefined">\name</span>
<p id="p1.3" class="ltx_p">[affiliation=1,2,*]BenediktHilmes
<span id="p1.3.1" class="ltx_ERROR undefined">\name</span>[affiliation=1,2,*]NickRossenbach
<span id="p1.3.2" class="ltx_ERROR undefined">\name</span>[affiliation=1,2]RalfSchl√ºter




















  















</p>
</div>
<h1 class="ltx_title ltx_title_document">On the Effect of Purely Synthetic Training Data
<br class="ltx_break">for Different Automatic Speech Recognition Architectures</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">In this work we evaluate the utility of synthetic data for training automatic speech recognition (ASR).
We use the ASR training data to train a text-to-speech (TTS) system similar to FastSpeech-2.
With this TTS we reproduce the original training data, training ASR systems solely on synthetic data.
For ASR, we use three different architectures, attention-based encoder-decoder, hybrid deep neural network hidden Markov model and a Gaussian mixture hidden Markov model, showing the different sensitivity of the models to synthetic data generation.
In order to extend previous work, we present a number of ablation studies on the effectiveness of synthetic vs. real training data for ASR.
In particular we focus on how the gap between training on synthetic and real data changes by varying the speaker embedding or by scaling the model size.
For the latter we show that the TTS models generalize well, even when training scores indicate overfitting.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>synthetic data generation, text-to-speech, speech recognition, semi-supervised training
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Current literature shows the capability of synthetic data to complement real data and thus improve <span title="" class="ltx_glossaryref">automatic speech recognition (ASR)</span> training through various ways and techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> .
Commonly end-to-end architectures are trained with a combination of real and synthetic data, where especially models like the <span title="" class="ltx_glossaryref">attention-based encoder-decoder (AED)</span> benefit from the additional synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
However, we still lack a good understanding of how well synthetic data is able to replace real data.
To this end, we suggest to use synthetic training data <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">only</span> to analyze and compare its <span title="" class="ltx_glossaryref">ASR</span> training utility against real data.
Such a study helps to gain further insight on the discrepancy between synthetic and real data.
Recent work has presented large TTS systems trained on much more data than typically available for academically defined tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, p. 5]</cite>.
But even with such an industrial scale system it was not possible to create synthetic data that is equally utilizable to real data.
In this work we explore the corresponding performance gap for three <span title="" class="ltx_glossaryref">ASR</span> architectures: A classic <span title="" class="ltx_glossaryref">Gaussian mixture based system using hidden Markov model (GMM-HMM)</span>, a <span title="" class="ltx_glossaryref">hybrid deep neural network HMM (Hybrid)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and an <span title="" class="ltx_glossaryref">AED</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> system.
A lot of previous work on synthetic data analysis was done on data generated by autoregressive <span title="" class="ltx_glossaryref">text-to-speech (TTS)</span> models, like Tacotron-2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, with the exception of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
In this work we focus on a simple non-autoregressive TTS model which is similar to FastSpeech, but with a BLSTM-decoder, and an encoder with mixed convolutions and BLSTM.
There are more recent architectures which exhibit strong performance on standard TTS tasks.
However, we consider a more simple and established TTS architecture that we know from previous experiments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> to work on ASR-specific training data and thus is expected to be better suited for our analysis.
The contributions of this work are as follows:</p>
</div>
<div id="S1.p2" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Investigating how robust traditional ASR approaches such as <span title="" class="ltx_glossaryref">GMM-HMM</span> react to synthetic data compared to a more modern <span title="" class="ltx_glossaryref">Hybrid</span> or AED system.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Quantifying the impact of low-quality Griffin &amp; Lim vocoding for the usability of audio data.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Showing how simply increasing the number of TTS model parameters already improves the usability of the synthetic data for ASR.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Showing that in the context of this work, more sophisticated speaker embedding systems greatly influence the performance.</p>
</div>
</li>
</ul>
<p id="S1.p2.1" class="ltx_p">Especially, the effect of hyper-parameter tuning rarely is covered in TTS-literature due to the expensive MOS evaluations this would ensue.
A large scale comparison of training various ASR architectures with both real and synthetic data has been done in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
We extend <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> through analyzing the effect of ASR performance by using synthetic data <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">only</span> for ASR training.
Our work and software is publicly accessible and will remain as such <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/rwth-i6/returnn-experiments/tree/master/2024-pure-synthetic-data" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/rwth-i6/returnn-experiments/tree/master/2024-pure-synthetic-data</a></span></span></span>.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Evaluation on LibriSpeech <span id="S1.T1.1.1" class="ltx_text ltx_font_italic">dev-clean</span> and <span id="S1.T1.2.2" class="ltx_text ltx_font_italic">dev-other</span> corpora. Only data from LibriSpeech train-clean-100 is used for TTS training. <span id="S1.T1.3.3" class="ltx_text ltx_font_italic">Vocoding only</span> used features extracted from the real data, vocoded by Griffin-Lim. <span title="" class="ltx_glossaryref">TTS</span>-Durations indicates whether the model predicts phoneme durations via the duration predictor or is fed the ground truth durations from the alignment.</figcaption>
<table id="S1.T1.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.T1.4.1" class="ltx_tr">
<td id="S1.T1.4.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S1.T1.4.1.1.1" class="ltx_text">Data</span></td>
<td id="S1.T1.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S1.T1.4.1.2.1" class="ltx_text">
<span id="S1.T1.4.1.2.1.1" class="ltx_inline-block ltx_align_center">
<span id="S1.T1.4.1.2.1.1.1" class="ltx_p">Silence</span>
<span id="S1.T1.4.1.2.1.1.2" class="ltx_p">Removal</span>
</span></span></td>
<td id="S1.T1.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S1.T1.4.1.3.1" class="ltx_text">
<span id="S1.T1.4.1.3.1.1" class="ltx_inline-block ltx_align_center">
<span id="S1.T1.4.1.3.1.1.1" class="ltx_p">TTS-</span>
<span id="S1.T1.4.1.3.1.1.2" class="ltx_p">Durations</span>
</span></span></td>
<td id="S1.T1.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S1.T1.4.1.4.1" class="ltx_text">
<span id="S1.T1.4.1.4.1.1" class="ltx_inline-block ltx_align_center">
<span id="S1.T1.4.1.4.1.1.1" class="ltx_p">Data</span>
<span id="S1.T1.4.1.4.1.1.2" class="ltx_p">Length</span>
</span></span></td>
<td id="S1.T1.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="5">WER [%]</td>
</tr>
<tr id="S1.T1.4.2" class="ltx_tr">
<td id="S1.T1.4.2.1" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span title="" class="ltx_glossaryref">GMM-HMM</span></td>
<td id="S1.T1.4.2.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2"><span title="" class="ltx_glossaryref">AED</span></td>
<td id="S1.T1.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span title="" class="ltx_glossaryref">Hybrid</span></td>
</tr>
<tr id="S1.T1.4.3" class="ltx_tr">
<td id="S1.T1.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">clean</td>
<td id="S1.T1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
<td id="S1.T1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">clean</td>
<td id="S1.T1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
<td id="S1.T1.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
</tr>
<tr id="S1.T1.4.4" class="ltx_tr">
<td id="S1.T1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="S1.T1.4.4.1.1" class="ltx_text">Real</span></td>
<td id="S1.T1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">No</td>
<td id="S1.T1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S1.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">100.6h</td>
<td id="S1.T1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S1.T1.4.4.5.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S1.T1.4.4.5.2" class="ltx_text ltx_font_bold">8.1</span>
</td>
<td id="S1.T1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T1.4.4.6.1" class="ltx_text ltx_font_bold">25.9</span></td>
<td id="S1.T1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S1.T1.4.4.7.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S1.T1.4.4.7.2" class="ltx_text ltx_font_bold">7.5</span>
</td>
<td id="S1.T1.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T1.4.4.8.1" class="ltx_text ltx_font_bold">18.9</span></td>
<td id="S1.T1.4.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S1.T1.4.4.9.1" class="ltx_text ltx_font_bold">15.0</span></td>
</tr>
<tr id="S1.T1.4.5" class="ltx_tr">
<td id="S1.T1.4.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Yes</td>
<td id="S1.T1.4.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S1.T1.4.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S1.T1.4.5.3.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>88.7h</td>
<td id="S1.T1.4.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S1.T1.4.5.4.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>8.7</td>
<td id="S1.T1.4.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.0</td>
<td id="S1.T1.4.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S1.T1.4.5.6.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>7.8</td>
<td id="S1.T1.4.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.3</td>
<td id="S1.T1.4.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.5</td>
</tr>
<tr id="S1.T1.4.6" class="ltx_tr">
<td id="S1.T1.4.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">Vocoding</td>
<td id="S1.T1.4.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">No</td>
<td id="S1.T1.4.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S1.T1.4.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">100.6h</td>
<td id="S1.T1.4.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S1.T1.4.6.5.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>8.7</td>
<td id="S1.T1.4.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">27.7</td>
<td id="S1.T1.4.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S1.T1.4.6.7.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>7.6</td>
<td id="S1.T1.4.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">19.4</td>
<td id="S1.T1.4.6.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">15.2</td>
</tr>
<tr id="S1.T1.4.7" class="ltx_tr">
<td id="S1.T1.4.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">Only</td>
<td id="S1.T1.4.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Yes</td>
<td id="S1.T1.4.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S1.T1.4.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S1.T1.4.7.4.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>88.7h</td>
<td id="S1.T1.4.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S1.T1.4.7.5.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.5</td>
<td id="S1.T1.4.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.8</td>
<td id="S1.T1.4.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S1.T1.4.7.7.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>8.0</td>
<td id="S1.T1.4.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.1</td>
<td id="S1.T1.4.7.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.1</td>
</tr>
<tr id="S1.T1.4.8" class="ltx_tr">
<td id="S1.T1.4.8.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" rowspan="2"><span id="S1.T1.4.8.1.1" class="ltx_text">Synthetic</span></td>
<td id="S1.T1.4.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt" rowspan="2"><span id="S1.T1.4.8.2.1" class="ltx_text">Yes</span></td>
<td id="S1.T1.4.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">pred.</td>
<td id="S1.T1.4.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S1.T1.4.8.4.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>81.1h</td>
<td id="S1.T1.4.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">10.0</td>
<td id="S1.T1.4.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">32.2</td>
<td id="S1.T1.4.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">14.1</td>
<td id="S1.T1.4.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">37.6</td>
<td id="S1.T1.4.8.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">26.2</td>
</tr>
<tr id="S1.T1.4.9" class="ltx_tr">
<td id="S1.T1.4.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">real</td>
<td id="S1.T1.4.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T1.4.9.2.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>88.3h</td>
<td id="S1.T1.4.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S1.T1.4.9.3.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.7</td>
<td id="S1.T1.4.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">32.2</td>
<td id="S1.T1.4.9.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">10.9</td>
<td id="S1.T1.4.9.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">31.8</td>
<td id="S1.T1.4.9.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">26.8</td>
</tr>
</table>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Speech Synthesis</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">As <span title="" class="ltx_glossaryref">TTS</span> system we use the <span title="" class="ltx_glossaryref">non-autoregressive (NAR)</span> model from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, which is closely related to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, extended with Gaussian Upsampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
It consists of a phoneme encoder, duration predictor and a feature decoder, which follow exactly the design as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
For both duration prediction and decoding we pass a speaker embedding to enable multi speaker capabilities.
In the simplest case this is generated by look-up table on the speaker ID which is learned during training, but we also investigate different more elaborate approaches, by generating fixed speaker embeddings through stronger pre-trained models.
Training is done on the reference durations, extracted from a given alignment.
As spectrogram targets we use globally normalized 80-dimensional log-mel features with frame shift 12.5 ms and window size of 50 ms.
The spectrogram predictions are transformed into 512-dimensional linear features for <span title="" class="ltx_glossaryref">Griffin &amp; Lim (G&amp;L)</span> vocoding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> via a pre-trained <span title="" class="ltx_glossaryref">bi-directional LSTM (BiLSTM)</span> network.
As validated in the baseline experiments of this paper, simple <span title="" class="ltx_glossaryref">G&amp;L</span> vocoding does not reduce the quality of the generated audio for <span title="" class="ltx_glossaryref">ASR</span> training.
Counting both neural models, our architecture consists of 63M parameters.
The phoneme set consists of ARPA-BET phoneme symbols without stress marker. We mark word boundaries and possible silence with a <span id="S2.p1.1.1" class="ltx_text ltx_font_typewriter">[space]</span> token between the last phoneme of a word and the first of the next respectively.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Speech Recognition</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our <span title="" class="ltx_glossaryref ltx_font_bold">GMM-HMM</span> model is implemented in RASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, which is functionally close to the <span title="" class="ltx_glossaryref">Montreal forced aligner (MFA)</span> commonly used for <span title="" class="ltx_glossaryref">TTS</span> works such as FastSpeech-2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Training parameters are optimized on LibriSpeech-100h with focus on <span title="" class="ltx_glossaryref">ASR</span> performance. The overall training consists of the several steps, which in more detail are explained in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
In this work we use the <span title="" class="ltx_glossaryref">GMM-HMM</span> twofold. First we use the alignments produced by the system as ground truth alignments for duration prediction in our <span title="" class="ltx_glossaryref">TTS</span>. For this we calculate the Viterbi path for our best alignment, setting a duration of zero for <span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">[space]</span> tokens where no silence was aligned. For recognition, we use the model together with a pre-trained 4-gram count-based <span title="" class="ltx_glossaryref">language model (LM)</span> from the LibriSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> dataset.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">On top of the <span title="" class="ltx_glossaryref">GMM-HMM</span> we use a <span title="" class="ltx_glossaryref ltx_font_bold">Hybrid</span> model which predicts the frame-label posterior probability by a neural network. We use the final alignment output from the <span title="" class="ltx_glossaryref">ASR</span> <span title="" class="ltx_glossaryref">GMM-HMM</span> as training targets.
The <span title="" class="ltx_glossaryref">neural network (NN)</span> consists of a stack of 8 1024-dimensional <span title="" class="ltx_glossaryref">BiLSTM</span> layers followed by a linear layer with softmax activation and output size 12001 to match the corresponding CART <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> labels. In total the model consists of 210M parameters. For recognition we again use the LibriSpeech 4-gram <span title="" class="ltx_glossaryref">LM</span>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Our last model is an <span title="" class="ltx_glossaryref ltx_font_bold">AED</span> model as used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> with 12 conformer blocks as encoder and single layer LSTM for the decoder, resulting in 98M parameters. We use BPE labels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> with 2k merge operations as the output units.
Different from the <span title="" class="ltx_glossaryref">TTS</span> model we use a frame shift to 10 ms and the window size to 25 ms for the feature extraction. The models uses a downsampling factor of 6.
To improve training stability we increase the number of encoder layers over time, starting with 2 layers which are increased by 2 every 5 sub-epochs beginning the first increase after 10 sub-epochs reaching full model size at 10 full epochs (30 sub-epochs).
For data augmentation we use SpecAgument <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and apply speed-pertubation via librosa.resample()<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://librosa.org/doc/latest/generated/librosa.resample.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://librosa.org/doc/latest/generated/librosa.resample.html</a></span></span></span> uniformly distributing scales 0.9/1.0/1.1 among the input.
Recognition results are without the use of an external language model.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Generalization Results. Evaluation of LibriSpeech <span id="S3.T2.12.1" class="ltx_text ltx_font_italic">dev-clean</span> and <span id="S3.T2.13.2" class="ltx_text ltx_font_italic">dev-other</span> corpora. Only data from LibriSpeech train-clean-100 is used for TTS training. The synthetic data is created by using either text from train-clean-100h (LS-100) or an equivalent subset of train-clean-360h (100h-LS-360). <math id="S3.T2.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.T2.1.m1.1b"><mi id="S3.T2.1.m1.1.1" xref="S3.T2.1.m1.1.1.cmml">Œ≥</mi><annotation-xml encoding="MathML-Content" id="S3.T2.1.m1.1c"><ci id="S3.T2.1.m1.1.1.cmml" xref="S3.T2.1.m1.1.1">ùõæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.m1.1d">\gamma</annotation></semantics></math> denotes scaling the hidden dimension of the TTS by this factor. <math id="S3.T2.2.m2.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S3.T2.2.m2.1b"><mi id="S3.T2.2.m2.1.1" xref="S3.T2.2.m2.1.1.cmml">œâ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.2.m2.1c"><ci id="S3.T2.2.m2.1.1.cmml" xref="S3.T2.2.m2.1.1">ùúî</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.m2.1d">\omega</annotation></semantics></math> denotes scaling the number of layers by this factor.</figcaption>
<table id="S3.T2.11.9" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.11.9.10" class="ltx_tr">
<td id="S3.T2.11.9.10.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S3.T2.11.9.10.1.1" class="ltx_text">Data</span></td>
<td id="S3.T2.11.9.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S3.T2.11.9.10.2.1" class="ltx_text">
<span id="S3.T2.11.9.10.2.1.1" class="ltx_inline-block ltx_align_center">
<span id="S3.T2.11.9.10.2.1.1.1" class="ltx_p">(synth.)</span>
<span id="S3.T2.11.9.10.2.1.1.2" class="ltx_p">Audio</span>
<span id="S3.T2.11.9.10.2.1.1.3" class="ltx_p">Data</span>
</span></span></td>
<td id="S3.T2.11.9.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S3.T2.11.9.10.3.1" class="ltx_text">
<span id="S3.T2.11.9.10.3.1.1" class="ltx_inline-block ltx_align_center">
<span id="S3.T2.11.9.10.3.1.1.1" class="ltx_p">TTS-</span>
<span id="S3.T2.11.9.10.3.1.1.2" class="ltx_p">Dur.</span>
</span></span></td>
<td id="S3.T2.11.9.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S3.T2.11.9.10.4.1" class="ltx_text">
<span id="S3.T2.11.9.10.4.1.1" class="ltx_inline-block ltx_align_center">
<span id="S3.T2.11.9.10.4.1.1.1" class="ltx_p">Scale</span>
<span id="S3.T2.11.9.10.4.1.1.2" class="ltx_p">Type</span>
</span></span></td>
<td id="S3.T2.11.9.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S3.T2.11.9.10.5.1" class="ltx_text">
<span id="S3.T2.11.9.10.5.1.1" class="ltx_inline-block ltx_align_center">
<span id="S3.T2.11.9.10.5.1.1.1" class="ltx_p">Model</span>
<span id="S3.T2.11.9.10.5.1.1.2" class="ltx_p">Scale</span>
</span></span></td>
<td id="S3.T2.11.9.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="5">WER [%]</td>
</tr>
<tr id="S3.T2.11.9.11" class="ltx_tr">
<td id="S3.T2.11.9.11.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span title="" class="ltx_glossaryref">GMM-HMM</span></td>
<td id="S3.T2.11.9.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span title="" class="ltx_glossaryref">AED</span></td>
<td id="S3.T2.11.9.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span title="" class="ltx_glossaryref">Hybrid</span></td>
</tr>
<tr id="S3.T2.11.9.12" class="ltx_tr">
<td id="S3.T2.11.9.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">clean</td>
<td id="S3.T2.11.9.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
<td id="S3.T2.11.9.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">clean</td>
<td id="S3.T2.11.9.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
<td id="S3.T2.11.9.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
</tr>
<tr id="S3.T2.11.9.13" class="ltx_tr">
<td id="S3.T2.11.9.13.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">Real</td>
<td id="S3.T2.11.9.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">LS-100</td>
<td id="S3.T2.11.9.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S3.T2.11.9.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S3.T2.11.9.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S3.T2.11.9.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S3.T2.11.9.13.6.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S3.T2.11.9.13.6.2" class="ltx_text ltx_font_bold">8.1</span>
</td>
<td id="S3.T2.11.9.13.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S3.T2.11.9.13.7.1" class="ltx_text ltx_font_bold">25.9</span></td>
<td id="S3.T2.11.9.13.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S3.T2.11.9.13.8.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S3.T2.11.9.13.8.2" class="ltx_text ltx_font_bold">7.5</span>
</td>
<td id="S3.T2.11.9.13.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S3.T2.11.9.13.9.1" class="ltx_text ltx_font_bold">18.9</span></td>
<td id="S3.T2.11.9.13.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S3.T2.11.9.13.10.1" class="ltx_text ltx_font_bold">15.0</span></td>
</tr>
<tr id="S3.T2.11.9.14" class="ltx_tr">
<td id="S3.T2.11.9.14.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" rowspan="12"><span id="S3.T2.11.9.14.1.1" class="ltx_text">Synth.</span></td>
<td id="S3.T2.11.9.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="8"><span id="S3.T2.11.9.14.2.1" class="ltx_text">LS-100</span></td>
<td id="S3.T2.11.9.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="4"><span id="S3.T2.11.9.14.3.1" class="ltx_text">pred.</span></td>
<td id="S3.T2.11.9.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S3.T2.11.9.14.4.1" class="ltx_text">-</span></td>
<td id="S3.T2.11.9.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S3.T2.11.9.14.5.1" class="ltx_text">-</span></td>
<td id="S3.T2.11.9.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">10.0</td>
<td id="S3.T2.11.9.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">32.2</td>
<td id="S3.T2.11.9.14.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">14.1</td>
<td id="S3.T2.11.9.14.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">37.6</td>
<td id="S3.T2.11.9.14.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">26.2</td>
</tr>
<tr id="S3.T2.3.1.1" class="ltx_tr">
<td id="S3.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T2.3.1.1.2.1" class="ltx_text">Dimension</span></td>
<td id="S3.T2.3.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.3.1.1.1.1" class="ltx_text"><math id="S3.T2.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\gamma=1.5" display="inline"><semantics id="S3.T2.3.1.1.1.1.m1.1a"><mrow id="S3.T2.3.1.1.1.1.m1.1.1" xref="S3.T2.3.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.3.1.1.1.1.m1.1.1.2" xref="S3.T2.3.1.1.1.1.m1.1.1.2.cmml">Œ≥</mi><mo id="S3.T2.3.1.1.1.1.m1.1.1.1" xref="S3.T2.3.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.3.1.1.1.1.m1.1.1.3" xref="S3.T2.3.1.1.1.1.m1.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.3.1.1.1.1.m1.1b"><apply id="S3.T2.3.1.1.1.1.m1.1.1.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1"><eq id="S3.T2.3.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1.1"></eq><ci id="S3.T2.3.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1.2">ùõæ</ci><cn type="float" id="S3.T2.3.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.3.1.1.1.1.m1.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.1.1.1.1.m1.1c">\gamma=1.5</annotation></semantics></math></span></td>
<td id="S3.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.3.1.1.3.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.8</td>
<td id="S3.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.3</td>
<td id="S3.T2.3.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.7</td>
<td id="S3.T2.3.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.4</td>
<td id="S3.T2.3.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">23.4</td>
</tr>
<tr id="S3.T2.4.2.2" class="ltx_tr">
<td id="S3.T2.4.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.4.2.2.1.1" class="ltx_text"><math id="S3.T2.4.2.2.1.1.m1.1" class="ltx_Math" alttext="\gamma=2.0" display="inline"><semantics id="S3.T2.4.2.2.1.1.m1.1a"><mrow id="S3.T2.4.2.2.1.1.m1.1.1" xref="S3.T2.4.2.2.1.1.m1.1.1.cmml"><mi id="S3.T2.4.2.2.1.1.m1.1.1.2" xref="S3.T2.4.2.2.1.1.m1.1.1.2.cmml">Œ≥</mi><mo id="S3.T2.4.2.2.1.1.m1.1.1.1" xref="S3.T2.4.2.2.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.4.2.2.1.1.m1.1.1.3" xref="S3.T2.4.2.2.1.1.m1.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.4.2.2.1.1.m1.1b"><apply id="S3.T2.4.2.2.1.1.m1.1.1.cmml" xref="S3.T2.4.2.2.1.1.m1.1.1"><eq id="S3.T2.4.2.2.1.1.m1.1.1.1.cmml" xref="S3.T2.4.2.2.1.1.m1.1.1.1"></eq><ci id="S3.T2.4.2.2.1.1.m1.1.1.2.cmml" xref="S3.T2.4.2.2.1.1.m1.1.1.2">ùõæ</ci><cn type="float" id="S3.T2.4.2.2.1.1.m1.1.1.3.cmml" xref="S3.T2.4.2.2.1.1.m1.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.2.2.1.1.m1.1c">\gamma=2.0</annotation></semantics></math></span></td>
<td id="S3.T2.4.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.4.2.2.2.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S3.T2.4.2.2.2.2" class="ltx_text ltx_font_bold">9.5</span>
</td>
<td id="S3.T2.4.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.4.2.2.3.1" class="ltx_text ltx_font_bold">31.0</span></td>
<td id="S3.T2.4.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.4.2.2.4.1" class="ltx_text ltx_font_bold">10.5</span></td>
<td id="S3.T2.4.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.4.2.2.5.1" class="ltx_text ltx_font_bold">30.5</span></td>
<td id="S3.T2.4.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.4.2.2.6.1" class="ltx_text ltx_font_bold">22.1</span></td>
</tr>
<tr id="S3.T2.5.3.3" class="ltx_tr">
<td id="S3.T2.5.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.5.3.3.2.1" class="ltx_text">Layers</span></td>
<td id="S3.T2.5.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.5.3.3.1.1" class="ltx_text"><math id="S3.T2.5.3.3.1.1.m1.1" class="ltx_Math" alttext="\omega=2\phantom{.0}" display="inline"><semantics id="S3.T2.5.3.3.1.1.m1.1a"><mrow id="S3.T2.5.3.3.1.1.m1.1.1" xref="S3.T2.5.3.3.1.1.m1.1.1.cmml"><mi id="S3.T2.5.3.3.1.1.m1.1.1.2" xref="S3.T2.5.3.3.1.1.m1.1.1.2.cmml">œâ</mi><mo id="S3.T2.5.3.3.1.1.m1.1.1.1" xref="S3.T2.5.3.3.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.5.3.3.1.1.m1.1.1.3" xref="S3.T2.5.3.3.1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.5.3.3.1.1.m1.1b"><apply id="S3.T2.5.3.3.1.1.m1.1.1.cmml" xref="S3.T2.5.3.3.1.1.m1.1.1"><eq id="S3.T2.5.3.3.1.1.m1.1.1.1.cmml" xref="S3.T2.5.3.3.1.1.m1.1.1.1"></eq><ci id="S3.T2.5.3.3.1.1.m1.1.1.2.cmml" xref="S3.T2.5.3.3.1.1.m1.1.1.2">ùúî</ci><cn type="integer" id="S3.T2.5.3.3.1.1.m1.1.1.3.cmml" xref="S3.T2.5.3.3.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.3.3.1.1.m1.1c">\omega=2\phantom{.0}</annotation></semantics></math></span></td>
<td id="S3.T2.5.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.5.3.3.3.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.7</td>
<td id="S3.T2.5.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.8</td>
<td id="S3.T2.5.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13.5</td>
<td id="S3.T2.5.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.1</td>
<td id="S3.T2.5.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">24.4</td>
</tr>
<tr id="S3.T2.11.9.15" class="ltx_tr">
<td id="S3.T2.11.9.15.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="4"><span id="S3.T2.11.9.15.1.1" class="ltx_text">real</span></td>
<td id="S3.T2.11.9.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.11.9.15.2.1" class="ltx_text">-</span></td>
<td id="S3.T2.11.9.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.11.9.15.3.1" class="ltx_text">-</span></td>
<td id="S3.T2.11.9.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.11.9.15.4.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.7</td>
<td id="S3.T2.11.9.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.2</td>
<td id="S3.T2.11.9.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.9</td>
<td id="S3.T2.11.9.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.8</td>
<td id="S3.T2.11.9.15.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.8</td>
</tr>
<tr id="S3.T2.6.4.4" class="ltx_tr">
<td id="S3.T2.6.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T2.6.4.4.2.1" class="ltx_text">Dimension</span></td>
<td id="S3.T2.6.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.6.4.4.1.1" class="ltx_text"><math id="S3.T2.6.4.4.1.1.m1.1" class="ltx_Math" alttext="\gamma=1.5" display="inline"><semantics id="S3.T2.6.4.4.1.1.m1.1a"><mrow id="S3.T2.6.4.4.1.1.m1.1.1" xref="S3.T2.6.4.4.1.1.m1.1.1.cmml"><mi id="S3.T2.6.4.4.1.1.m1.1.1.2" xref="S3.T2.6.4.4.1.1.m1.1.1.2.cmml">Œ≥</mi><mo id="S3.T2.6.4.4.1.1.m1.1.1.1" xref="S3.T2.6.4.4.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.6.4.4.1.1.m1.1.1.3" xref="S3.T2.6.4.4.1.1.m1.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.6.4.4.1.1.m1.1b"><apply id="S3.T2.6.4.4.1.1.m1.1.1.cmml" xref="S3.T2.6.4.4.1.1.m1.1.1"><eq id="S3.T2.6.4.4.1.1.m1.1.1.1.cmml" xref="S3.T2.6.4.4.1.1.m1.1.1.1"></eq><ci id="S3.T2.6.4.4.1.1.m1.1.1.2.cmml" xref="S3.T2.6.4.4.1.1.m1.1.1.2">ùõæ</ci><cn type="float" id="S3.T2.6.4.4.1.1.m1.1.1.3.cmml" xref="S3.T2.6.4.4.1.1.m1.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.4.4.1.1.m1.1c">\gamma=1.5</annotation></semantics></math></span></td>
<td id="S3.T2.6.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.6.4.4.3.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.6</td>
<td id="S3.T2.6.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30.7</td>
<td id="S3.T2.6.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.6.4.4.5.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.7</td>
<td id="S3.T2.6.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.9</td>
<td id="S3.T2.6.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">24.5</td>
</tr>
<tr id="S3.T2.7.5.5" class="ltx_tr">
<td id="S3.T2.7.5.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.7.5.5.1.1" class="ltx_text"><math id="S3.T2.7.5.5.1.1.m1.1" class="ltx_Math" alttext="\gamma=2.0" display="inline"><semantics id="S3.T2.7.5.5.1.1.m1.1a"><mrow id="S3.T2.7.5.5.1.1.m1.1.1" xref="S3.T2.7.5.5.1.1.m1.1.1.cmml"><mi id="S3.T2.7.5.5.1.1.m1.1.1.2" xref="S3.T2.7.5.5.1.1.m1.1.1.2.cmml">Œ≥</mi><mo id="S3.T2.7.5.5.1.1.m1.1.1.1" xref="S3.T2.7.5.5.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.7.5.5.1.1.m1.1.1.3" xref="S3.T2.7.5.5.1.1.m1.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.7.5.5.1.1.m1.1b"><apply id="S3.T2.7.5.5.1.1.m1.1.1.cmml" xref="S3.T2.7.5.5.1.1.m1.1.1"><eq id="S3.T2.7.5.5.1.1.m1.1.1.1.cmml" xref="S3.T2.7.5.5.1.1.m1.1.1.1"></eq><ci id="S3.T2.7.5.5.1.1.m1.1.1.2.cmml" xref="S3.T2.7.5.5.1.1.m1.1.1.2">ùõæ</ci><cn type="float" id="S3.T2.7.5.5.1.1.m1.1.1.3.cmml" xref="S3.T2.7.5.5.1.1.m1.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.5.5.1.1.m1.1c">\gamma=2.0</annotation></semantics></math></span></td>
<td id="S3.T2.7.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.7.5.5.2.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.4</td>
<td id="S3.T2.7.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.7.5.5.3.1" class="ltx_text ltx_font_bold">30.5</span></td>
<td id="S3.T2.7.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.7.5.5.4.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S3.T2.7.5.5.4.2" class="ltx_text ltx_font_bold">9.3</span>
</td>
<td id="S3.T2.7.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.7.5.5.5.1" class="ltx_text ltx_font_bold">27.6</span></td>
<td id="S3.T2.7.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.7.5.5.6.1" class="ltx_text ltx_font_bold">23.1</span></td>
</tr>
<tr id="S3.T2.8.6.6" class="ltx_tr">
<td id="S3.T2.8.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.8.6.6.2.1" class="ltx_text">Layers</span></td>
<td id="S3.T2.8.6.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.8.6.6.1.1" class="ltx_text"><math id="S3.T2.8.6.6.1.1.m1.1" class="ltx_Math" alttext="\omega=2\phantom{.0}" display="inline"><semantics id="S3.T2.8.6.6.1.1.m1.1a"><mrow id="S3.T2.8.6.6.1.1.m1.1.1" xref="S3.T2.8.6.6.1.1.m1.1.1.cmml"><mi id="S3.T2.8.6.6.1.1.m1.1.1.2" xref="S3.T2.8.6.6.1.1.m1.1.1.2.cmml">œâ</mi><mo id="S3.T2.8.6.6.1.1.m1.1.1.1" xref="S3.T2.8.6.6.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.8.6.6.1.1.m1.1.1.3" xref="S3.T2.8.6.6.1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.8.6.6.1.1.m1.1b"><apply id="S3.T2.8.6.6.1.1.m1.1.1.cmml" xref="S3.T2.8.6.6.1.1.m1.1.1"><eq id="S3.T2.8.6.6.1.1.m1.1.1.1.cmml" xref="S3.T2.8.6.6.1.1.m1.1.1.1"></eq><ci id="S3.T2.8.6.6.1.1.m1.1.1.2.cmml" xref="S3.T2.8.6.6.1.1.m1.1.1.2">ùúî</ci><cn type="integer" id="S3.T2.8.6.6.1.1.m1.1.1.3.cmml" xref="S3.T2.8.6.6.1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.6.6.1.1.m1.1c">\omega=2\phantom{.0}</annotation></semantics></math></span></td>
<td id="S3.T2.8.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.8.6.6.3.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S3.T2.8.6.6.3.2" class="ltx_text ltx_font_bold">9.2</span>
</td>
<td id="S3.T2.8.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30.9</td>
<td id="S3.T2.8.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.2</td>
<td id="S3.T2.8.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">29.9</td>
<td id="S3.T2.8.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">24.8</td>
</tr>
<tr id="S3.T2.11.9.16" class="ltx_tr">
<td id="S3.T2.11.9.16.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="4"><span id="S3.T2.11.9.16.1.1" class="ltx_text">
<span id="S3.T2.11.9.16.1.1.1" class="ltx_inline-block ltx_align_center">
<span id="S3.T2.11.9.16.1.1.1.1" class="ltx_p">100h-</span>
<span id="S3.T2.11.9.16.1.1.1.2" class="ltx_p">LS-360</span>
</span></span></td>
<td id="S3.T2.11.9.16.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="4"><span id="S3.T2.11.9.16.2.1" class="ltx_text">pred.</span></td>
<td id="S3.T2.11.9.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T2.11.9.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T2.11.9.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.3</td>
<td id="S3.T2.11.9.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.9</td>
<td id="S3.T2.11.9.16.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">19.1</td>
<td id="S3.T2.11.9.16.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.8</td>
<td id="S3.T2.11.9.16.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.9</td>
</tr>
<tr id="S3.T2.9.7.7" class="ltx_tr">
<td id="S3.T2.9.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T2.9.7.7.2.1" class="ltx_text">Dimension</span></td>
<td id="S3.T2.9.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T2.9.7.7.1.m1.1" class="ltx_Math" alttext="\gamma=1.5" display="inline"><semantics id="S3.T2.9.7.7.1.m1.1a"><mrow id="S3.T2.9.7.7.1.m1.1.1" xref="S3.T2.9.7.7.1.m1.1.1.cmml"><mi id="S3.T2.9.7.7.1.m1.1.1.2" xref="S3.T2.9.7.7.1.m1.1.1.2.cmml">Œ≥</mi><mo id="S3.T2.9.7.7.1.m1.1.1.1" xref="S3.T2.9.7.7.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.9.7.7.1.m1.1.1.3" xref="S3.T2.9.7.7.1.m1.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.9.7.7.1.m1.1b"><apply id="S3.T2.9.7.7.1.m1.1.1.cmml" xref="S3.T2.9.7.7.1.m1.1.1"><eq id="S3.T2.9.7.7.1.m1.1.1.1.cmml" xref="S3.T2.9.7.7.1.m1.1.1.1"></eq><ci id="S3.T2.9.7.7.1.m1.1.1.2.cmml" xref="S3.T2.9.7.7.1.m1.1.1.2">ùõæ</ci><cn type="float" id="S3.T2.9.7.7.1.m1.1.1.3.cmml" xref="S3.T2.9.7.7.1.m1.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.7.7.1.m1.1c">\gamma=1.5</annotation></semantics></math></td>
<td id="S3.T2.9.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.9.7.7.3.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.9</td>
<td id="S3.T2.9.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.9</td>
<td id="S3.T2.9.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.1</td>
<td id="S3.T2.9.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">38.0</td>
<td id="S3.T2.9.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">24.5</td>
</tr>
<tr id="S3.T2.10.8.8" class="ltx_tr">
<td id="S3.T2.10.8.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T2.10.8.8.1.m1.1" class="ltx_Math" alttext="\gamma=2.0" display="inline"><semantics id="S3.T2.10.8.8.1.m1.1a"><mrow id="S3.T2.10.8.8.1.m1.1.1" xref="S3.T2.10.8.8.1.m1.1.1.cmml"><mi id="S3.T2.10.8.8.1.m1.1.1.2" xref="S3.T2.10.8.8.1.m1.1.1.2.cmml">Œ≥</mi><mo id="S3.T2.10.8.8.1.m1.1.1.1" xref="S3.T2.10.8.8.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.10.8.8.1.m1.1.1.3" xref="S3.T2.10.8.8.1.m1.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.10.8.8.1.m1.1b"><apply id="S3.T2.10.8.8.1.m1.1.1.cmml" xref="S3.T2.10.8.8.1.m1.1.1"><eq id="S3.T2.10.8.8.1.m1.1.1.1.cmml" xref="S3.T2.10.8.8.1.m1.1.1.1"></eq><ci id="S3.T2.10.8.8.1.m1.1.1.2.cmml" xref="S3.T2.10.8.8.1.m1.1.1.2">ùõæ</ci><cn type="float" id="S3.T2.10.8.8.1.m1.1.1.3.cmml" xref="S3.T2.10.8.8.1.m1.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.8.8.1.m1.1c">\gamma=2.0</annotation></semantics></math></td>
<td id="S3.T2.10.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.10.8.8.2.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S3.T2.10.8.8.2.2" class="ltx_text ltx_font_bold">9.8</span>
</td>
<td id="S3.T2.10.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.10.8.8.3.1" class="ltx_text ltx_font_bold">31.3</span></td>
<td id="S3.T2.10.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.10.8.8.4.1" class="ltx_text ltx_font_bold">15.0</span></td>
<td id="S3.T2.10.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.10.8.8.5.1" class="ltx_text ltx_font_bold">35.7</span></td>
<td id="S3.T2.10.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.10.8.8.6.1" class="ltx_text ltx_font_bold">23.2</span></td>
</tr>
<tr id="S3.T2.11.9.9" class="ltx_tr">
<td id="S3.T2.11.9.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Layers</td>
<td id="S3.T2.11.9.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S3.T2.11.9.9.1.m1.1" class="ltx_Math" alttext="\omega=2\phantom{.0}" display="inline"><semantics id="S3.T2.11.9.9.1.m1.1a"><mrow id="S3.T2.11.9.9.1.m1.1.1" xref="S3.T2.11.9.9.1.m1.1.1.cmml"><mi id="S3.T2.11.9.9.1.m1.1.1.2" xref="S3.T2.11.9.9.1.m1.1.1.2.cmml">œâ</mi><mo id="S3.T2.11.9.9.1.m1.1.1.1" xref="S3.T2.11.9.9.1.m1.1.1.1.cmml">=</mo><mn id="S3.T2.11.9.9.1.m1.1.1.3" xref="S3.T2.11.9.9.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.11.9.9.1.m1.1b"><apply id="S3.T2.11.9.9.1.m1.1.1.cmml" xref="S3.T2.11.9.9.1.m1.1.1"><eq id="S3.T2.11.9.9.1.m1.1.1.1.cmml" xref="S3.T2.11.9.9.1.m1.1.1.1"></eq><ci id="S3.T2.11.9.9.1.m1.1.1.2.cmml" xref="S3.T2.11.9.9.1.m1.1.1.2">ùúî</ci><cn type="integer" id="S3.T2.11.9.9.1.m1.1.1.3.cmml" xref="S3.T2.11.9.9.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.9.9.1.m1.1c">\omega=2\phantom{.0}</annotation></semantics></math></td>
<td id="S3.T2.11.9.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">10.1</td>
<td id="S3.T2.11.9.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">32.2</td>
<td id="S3.T2.11.9.9.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">18.6</td>
<td id="S3.T2.11.9.9.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">41.7</td>
<td id="S3.T2.11.9.9.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">24.7</td>
</tr>
</table>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Pipeline</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In general our pipeline consists of 5 steps analogue to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, which is visualized <a href="#S4.F1" title="In 4 Pipeline ‚Ä£ On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a>.
First the aligner is trained on the pre-processed data and a forced alignment generated as duration reference for the <span title="" class="ltx_glossaryref">TTS</span> model.
With that the <span title="" class="ltx_glossaryref">TTS</span> is trained and used for generation of synthetic data.
Afterwards the <span title="" class="ltx_glossaryref">ASR</span> models are trained on the generated data for a final evaluation.
We remove unnatural long silence portions by using the silence filter from FFmpeg<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://ffmpeg.org/ffmpeg-filters.html#silenceremove" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ffmpeg.org/ffmpeg-filters.html#silenceremove</a></span></span></span> with a threshold of -50dB.
Synthesis is done on two portions of data, the TTS training data and a similar amount of unseen text data.
Synthesizing the data seen during <span title="" class="ltx_glossaryref">TTS</span> allows our analysis to be done with as little <span title="" class="ltx_glossaryref">TTS</span> errors as possible, while using unseen data helps verifying the validity of our results.
In the baseline case we randomize the speaker ID, using speaker IDs of train-clean-100.
The synthesized data is then used to train the different <span title="" class="ltx_glossaryref">ASR</span> systems <span id="S4.p1.1.1" class="ltx_text ltx_font_bold">without</span> any additional real data.
Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, we additionally let the <span title="" class="ltx_glossaryref">TTS</span> model synthesize the data with access to the target durations which were seen during training. We denote this in the tables by marking the durations as <span id="S4.p1.1.2" class="ltx_text ltx_font_italic">real</span> durations.</p>
</div>
<figure id="S4.F1" class="ltx_figure">
<div id="S4.F1.1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:85.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-71.6pt,28.4pt) scale(0.60228991959611,0.60228991959611) ;"><svg id="S4.F1.1.1.pic1" class="ltx_picture" height="197.38" overflow="visible" version="1.1" width="484.26"><g transform="translate(0,197.38) matrix(1 0 0 -1 0 0) translate(61.04,0) translate(0,115.95)" fill="#000000" stroke="#000000"><g stroke-width="0.4pt"><g fill="#BCE1ED"><path d="M -34.45 -34.45 h 68.9 v 68.9 h -68.9 Z"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -24.43 -12.12)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 18.265)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 12.3)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 6.15)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 9.61)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Aligner </text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 21.54)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0.58 0)"><text transform="matrix(1 0 0 -1 0 0)">training</text></g></g></g></g><g fill="#BCE1ED"><path d="M 62.68 -34.45 h 68.9 v 68.9 h -68.9 Z"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 74.72 -24.79)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 43.43)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 37.28)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 32.475)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 37.28)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Forced </text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 46.89)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 7.8 0)"><text transform="matrix(1 0 0 -1 0 0)">align</text></g></g></g></g><g fill="#FDBE80"><path d="M 159.8 -34.45 h 68.9 v 68.9 h -68.9 Z"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 170.4 -24.53)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 43.095)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 37.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 7.71 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 32.4)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 37.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">TTS </text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 46.37)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">training</text></g></g></g></g><g fill="#FDBE80"><path d="M 256.93 -34.45 h 68.9 v 68.9 h -68.9 Z"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 263.24 -19.99)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 33.82)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 37.28)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Synthesis</text></g></g></g></g><g fill="#E15255"><path d="M 354.05 -34.45 h 68.9 v 68.9 h -68.9 Z"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 364.65 -24.53)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 43.095)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 37.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 7.42 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 32.4)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 37.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">ASR </text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 46.37)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">training</text></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 256.92 -111.34)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 40.67)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 34.52)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 9.07 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 29.715)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 34.52)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">random </text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 44.13)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">speaker tag</text></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 -56.42 67.21)" fill="#000000" stroke="#000000"><foreignObject width="112.85" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.F1.1.1.pic1.1.1.1.1.1.1" class="ltx_text">pre-processed data</span></foreignObject></g></g><g stroke-width="1.42264pt"><path d="M 34.73 0 L 60.88 0" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 60.88 0)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.1381pt"><path d="M -2.93 3.91 C -2.69 2.44 0 0.24 0.73 0 C 0 -0.24 -2.69 -2.44 -2.93 -3.91" style="fill:none"></path></g><g stroke-width="1.42264pt"><path d="M 131.85 0 L 158 0" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 158 0)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.1381pt"><path d="M -2.93 3.91 C -2.69 2.44 0 0.24 0.73 0 C 0 -0.24 -2.69 -2.44 -2.93 -3.91" style="fill:none"></path></g><g stroke-width="1.42264pt"><path d="M 228.98 0 L 255.13 0" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 255.13 0)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.1381pt"><path d="M -2.93 3.91 C -2.69 2.44 0 0.24 0.73 0 C 0 -0.24 -2.69 -2.44 -2.93 -3.91" style="fill:none"></path></g><g stroke-width="1.42264pt"><path d="M 326.1 0 L 352.25 0" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 352.25 0)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.1381pt"><path d="M -2.93 3.91 C -2.69 2.44 0 0.24 0.73 0 C 0 -0.24 -2.69 -2.44 -2.93 -3.91" style="fill:none"></path></g><g stroke-width="1.42264pt" stroke-dasharray="3.0pt,3.0pt" stroke-dashoffset="0.0pt"><path d="M 131.85 -34.73 C 174 -59.06 214.5 -59.06 255.33 -35.49" style="fill:none"></path><g transform="matrix(0.86603 0.5 -0.5 0.86603 255.33 -35.49)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.1381pt"><path d="M -2.93 3.91 C -2.69 2.44 0 0.24 0.73 0 C 0 -0.24 -2.69 -2.44 -2.93 -3.91" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 165.75 -88.86)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 19.945)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 15.14)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 8.49 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 10.335)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 15.14)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">oracle </text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 24.75)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">durations</text></g></g></g></g></g><g stroke-dasharray="3.0pt,3.0pt" stroke-dashoffset="0.0pt" stroke-width="1.42264pt"><path d="M 291.38 -59.63 L 291.38 -36.25" style="fill:none"></path></g><g transform="matrix(0.0 1.0 -1.0 0.0 291.38 -36.25)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.1381pt"><path d="M -2.93 3.91 C -2.69 2.44 0 0.24 0.73 0 C 0 -0.24 -2.69 -2.44 -2.93 -3.91" style="fill:none"></path></g><g stroke-width="1.42264pt"><path d="M 0 59.63 L 0 36.25" style="fill:none"></path></g><g transform="matrix(0.0 -1.0 1.0 0.0 0 36.25)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.1381pt"><path d="M -2.93 3.91 C -2.69 2.44 0 0.24 0.73 0 C 0 -0.24 -2.69 -2.44 -2.93 -3.91" style="fill:none"></path></g><g stroke-width="0.85358pt"><path d="M 61.31 70.67 C 102.13 69.17 127.38 59.93 158.72 35.36" style="fill:none"></path></g><g transform="matrix(0.78691 -0.61707 0.61707 0.78691 158.72 35.36)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.68286pt"><path d="M -2.23 2.97 C -2.04 1.85 0 0.19 0.56 0 C 0 -0.19 -2.04 -1.85 -2.23 -2.97" style="fill:none"></path></g></g></svg>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Experiment pipeline for synthetic data training.</figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Data and Training</h3>

<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Train and cross-validation (CV) mean-average error (MAE) Scores of <span title="" class="ltx_glossaryref">TTS</span> models.</figcaption>
<div id="S5.T3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:247.1pt;height:108pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T3.3.3" class="ltx_p"><span id="S5.T3.3.3.3" class="ltx_text">

<span id="S5.T3.3.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.3.3.3.3.4" class="ltx_tr">
<span id="S5.T3.3.3.3.3.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Scale</span>
<span id="S5.T3.3.3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Model</span>
<span id="S5.T3.3.3.3.3.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">Spectrogram MAE</span>
<span id="S5.T3.3.3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">Duration MAE</span></span>
<span id="S5.T3.3.3.3.3.5" class="ltx_tr">
<span id="S5.T3.3.3.3.3.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">Type</span>
<span id="S5.T3.3.3.3.3.5.2" class="ltx_td ltx_align_center ltx_border_r">Scale</span>
<span id="S5.T3.3.3.3.3.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Train</span>
<span id="S5.T3.3.3.3.3.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CV</span>
<span id="S5.T3.3.3.3.3.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Train</span>
<span id="S5.T3.3.3.3.3.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CV</span></span>
<span id="S5.T3.3.3.3.3.6" class="ltx_tr">
<span id="S5.T3.3.3.3.3.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">-</span>
<span id="S5.T3.3.3.3.3.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</span>
<span id="S5.T3.3.3.3.3.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.305</span>
<span id="S5.T3.3.3.3.3.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0.376</span>
<span id="S5.T3.3.3.3.3.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.373</span>
<span id="S5.T3.3.3.3.3.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1.461</span></span>
<span id="S5.T3.1.1.1.1.1" class="ltx_tr">
<span id="S5.T3.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S5.T3.1.1.1.1.1.2.1" class="ltx_text">Dimension</span></span>
<span id="S5.T3.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\gamma=1.5" display="inline"><semantics id="S5.T3.1.1.1.1.1.1.m1.1a"><mrow id="S5.T3.1.1.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S5.T3.1.1.1.1.1.1.m1.1.1.2" xref="S5.T3.1.1.1.1.1.1.m1.1.1.2.cmml">Œ≥</mi><mo id="S5.T3.1.1.1.1.1.1.m1.1.1.1" xref="S5.T3.1.1.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S5.T3.1.1.1.1.1.1.m1.1.1.3" xref="S5.T3.1.1.1.1.1.1.m1.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.1.1.m1.1b"><apply id="S5.T3.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1"><eq id="S5.T3.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1.1"></eq><ci id="S5.T3.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1.2">ùõæ</ci><cn type="float" id="S5.T3.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.1.1.m1.1c">\gamma=1.5</annotation></semantics></math></span>
<span id="S5.T3.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.278</span>
<span id="S5.T3.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.375</span>
<span id="S5.T3.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.201</span>
<span id="S5.T3.1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.448</span></span>
<span id="S5.T3.2.2.2.2.2" class="ltx_tr">
<span id="S5.T3.2.2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T3.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\gamma=2.0" display="inline"><semantics id="S5.T3.2.2.2.2.2.1.m1.1a"><mrow id="S5.T3.2.2.2.2.2.1.m1.1.1" xref="S5.T3.2.2.2.2.2.1.m1.1.1.cmml"><mi id="S5.T3.2.2.2.2.2.1.m1.1.1.2" xref="S5.T3.2.2.2.2.2.1.m1.1.1.2.cmml">Œ≥</mi><mo id="S5.T3.2.2.2.2.2.1.m1.1.1.1" xref="S5.T3.2.2.2.2.2.1.m1.1.1.1.cmml">=</mo><mn id="S5.T3.2.2.2.2.2.1.m1.1.1.3" xref="S5.T3.2.2.2.2.2.1.m1.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.2.1.m1.1b"><apply id="S5.T3.2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.2.2.2.1.m1.1.1"><eq id="S5.T3.2.2.2.2.2.1.m1.1.1.1.cmml" xref="S5.T3.2.2.2.2.2.1.m1.1.1.1"></eq><ci id="S5.T3.2.2.2.2.2.1.m1.1.1.2.cmml" xref="S5.T3.2.2.2.2.2.1.m1.1.1.2">ùõæ</ci><cn type="float" id="S5.T3.2.2.2.2.2.1.m1.1.1.3.cmml" xref="S5.T3.2.2.2.2.2.1.m1.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.2.1.m1.1c">\gamma=2.0</annotation></semantics></math></span>
<span id="S5.T3.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.264</span>
<span id="S5.T3.2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.373</span>
<span id="S5.T3.2.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.090</span>
<span id="S5.T3.2.2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.453</span></span>
<span id="S5.T3.3.3.3.3.3" class="ltx_tr">
<span id="S5.T3.3.3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Layers</span>
<span id="S5.T3.3.3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T3.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\omega=2\phantom{.0}" display="inline"><semantics id="S5.T3.3.3.3.3.3.1.m1.1a"><mrow id="S5.T3.3.3.3.3.3.1.m1.1.1" xref="S5.T3.3.3.3.3.3.1.m1.1.1.cmml"><mi id="S5.T3.3.3.3.3.3.1.m1.1.1.2" xref="S5.T3.3.3.3.3.3.1.m1.1.1.2.cmml">œâ</mi><mo id="S5.T3.3.3.3.3.3.1.m1.1.1.1" xref="S5.T3.3.3.3.3.3.1.m1.1.1.1.cmml">=</mo><mn id="S5.T3.3.3.3.3.3.1.m1.1.1.3" xref="S5.T3.3.3.3.3.3.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.3.3.1.m1.1b"><apply id="S5.T3.3.3.3.3.3.1.m1.1.1.cmml" xref="S5.T3.3.3.3.3.3.1.m1.1.1"><eq id="S5.T3.3.3.3.3.3.1.m1.1.1.1.cmml" xref="S5.T3.3.3.3.3.3.1.m1.1.1.1"></eq><ci id="S5.T3.3.3.3.3.3.1.m1.1.1.2.cmml" xref="S5.T3.3.3.3.3.3.1.m1.1.1.2">ùúî</ci><cn type="integer" id="S5.T3.3.3.3.3.3.1.m1.1.1.3.cmml" xref="S5.T3.3.3.3.3.3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.3.3.1.m1.1c">\omega=2\phantom{.0}</annotation></semantics></math></span>
<span id="S5.T3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.296</span>
<span id="S5.T3.3.3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.369</span>
<span id="S5.T3.3.3.3.3.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.333</span>
<span id="S5.T3.3.3.3.3.3.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1.451</span></span>
</span></span></p>
</span></div>
</figure>
<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.2" class="ltx_p">For all our experiments we use the the train-clean-100 subset of LibriSpeech as supervised training data.
While common literature usually synthesizes an unseen part of train-clean-360 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, we also conduct experiments on the previously seen training data.
Comparing results to synthesizing unseen data, we can observe generalization effects of the TTS.
As <span title="" class="ltx_glossaryref">cross validation (CV)</span> set for <span title="" class="ltx_glossaryref">ASR</span> training we use a combination of dev-clean and dev-other. For <span title="" class="ltx_glossaryref">TTS</span> training we construct our own <span title="" class="ltx_glossaryref">CV</span> set where we split 4 sequences per speaker from the training data resulting in 1004 sequences.
To generate phoneme representations for words not contained in the LibriSpeech lexicon we use Sequitur <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
For the <span title="" class="ltx_glossaryref">AED</span> model we use byte-pair encoding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> with 2000 merge operations.
We evaluate all of our models on <span id="S5.SS1.p1.2.1" class="ltx_text ltx_font_italic">dev-clean</span> and <span id="S5.SS1.p1.2.2" class="ltx_text ltx_font_italic">dev-other</span> and do not apply silence removal.
The <span title="" class="ltx_glossaryref">NAR</span>-<span title="" class="ltx_glossaryref">TTS</span> is trained for 200 steps, the <span title="" class="ltx_glossaryref">GMM-HMM</span> for 100 EM-steps, the <span title="" class="ltx_glossaryref">Hybrid</span> for <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mo id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><csymbol cd="latexml" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\sim</annotation></semantics></math>13 full epochs and the <span title="" class="ltx_glossaryref">AED</span> model for <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mo id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><csymbol cd="latexml" id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">\sim</annotation></semantics></math>165 full epochs.
All experiments were done on a single consumer 11Gb GPU for easy reproducibility. As optimizer we use Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> with a learning rate decay factor of 0.9 based on the CV score.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Effect of Vocoding and Data Preprocessing</h3>

<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Speaker Embedding results. WER [%] evaluation of LibriSpeech <span id="S5.T4.1.1" class="ltx_text ltx_font_italic">dev-clean</span> and <span id="S5.T4.2.2" class="ltx_text ltx_font_italic">dev-other</span> corpora. Gaussian upsampling with SAT alignment used for <span title="" class="ltx_glossaryref">TTS</span>. No shuffling means <span title="" class="ltx_glossaryref">TTS</span> sees the same speaker embedding as during training.</figcaption>
<table id="S5.T4.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T4.3.1" class="ltx_tr">
<td id="S5.T4.3.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S5.T4.3.1.1.1" class="ltx_text">Data</span></td>
<td id="S5.T4.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S5.T4.3.1.2.1" class="ltx_text">
<span id="S5.T4.3.1.2.1.1" class="ltx_inline-block ltx_align_center">
<span id="S5.T4.3.1.2.1.1.1" class="ltx_p">TTS-</span>
<span id="S5.T4.3.1.2.1.1.2" class="ltx_p">Durations</span>
</span></span></td>
<td id="S5.T4.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S5.T4.3.1.3.1" class="ltx_text">
<span id="S5.T4.3.1.3.1.1" class="ltx_inline-block ltx_align_center">
<span id="S5.T4.3.1.3.1.1.1" class="ltx_p">Embedding</span>
<span id="S5.T4.3.1.3.1.1.2" class="ltx_p">Type</span>
</span></span></td>
<td id="S5.T4.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S5.T4.3.1.4.1" class="ltx_text">
<span id="S5.T4.3.1.4.1.1" class="ltx_inline-block ltx_align_center">
<span id="S5.T4.3.1.4.1.1.1" class="ltx_p">Shuffle</span>
<span id="S5.T4.3.1.4.1.1.2" class="ltx_p">Embedding</span>
</span></span></td>
<td id="S5.T4.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="5">WER [%]</td>
</tr>
<tr id="S5.T4.3.2" class="ltx_tr">
<td id="S5.T4.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span title="" class="ltx_glossaryref">GMM-HMM</span></td>
<td id="S5.T4.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span title="" class="ltx_glossaryref">AED</span></td>
<td id="S5.T4.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span title="" class="ltx_glossaryref">Hybrid</span></td>
</tr>
<tr id="S5.T4.3.3" class="ltx_tr">
<td id="S5.T4.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">clean</td>
<td id="S5.T4.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
<td id="S5.T4.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">clean</td>
<td id="S5.T4.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
<td id="S5.T4.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">other</td>
</tr>
<tr id="S5.T4.3.4" class="ltx_tr">
<td id="S5.T4.3.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">Real</td>
<td id="S5.T4.3.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S5.T4.3.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S5.T4.3.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S5.T4.3.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S5.T4.3.4.5.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S5.T4.3.4.5.2" class="ltx_text ltx_font_bold">8.1</span>
</td>
<td id="S5.T4.3.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T4.3.4.6.1" class="ltx_text ltx_font_bold">25.9</span></td>
<td id="S5.T4.3.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">
<span id="S5.T4.3.4.7.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S5.T4.3.4.7.2" class="ltx_text ltx_font_bold">7.5</span>
</td>
<td id="S5.T4.3.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T4.3.4.8.1" class="ltx_text ltx_font_bold">18.9</span></td>
<td id="S5.T4.3.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T4.3.4.9.1" class="ltx_text ltx_font_bold">15.0</span></td>
</tr>
<tr id="S5.T4.3.5" class="ltx_tr">
<td id="S5.T4.3.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" rowspan="12"><span id="S5.T4.3.5.1.1" class="ltx_text">Synthetic</span></td>
<td id="S5.T4.3.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="6"><span id="S5.T4.3.5.2.1" class="ltx_text">pred.</span></td>
<td id="S5.T4.3.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T4.3.5.3.1" class="ltx_text">Linear</span></td>
<td id="S5.T4.3.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T4.3.5.4.1" class="ltx_text">Yes</span></td>
<td id="S5.T4.3.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">10.0</td>
<td id="S5.T4.3.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T4.3.5.6.1" class="ltx_text ltx_font_bold">32.2</span></td>
<td id="S5.T4.3.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T4.3.5.7.1" class="ltx_text ltx_font_bold">14.1</span></td>
<td id="S5.T4.3.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">37.6</td>
<td id="S5.T4.3.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">26.2</td>
</tr>
<tr id="S5.T4.3.6" class="ltx_tr">
<td id="S5.T4.3.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">No</td>
<td id="S5.T4.3.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T4.3.6.2.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S5.T4.3.6.2.2" class="ltx_text ltx_font_bold">9.8</span>
</td>
<td id="S5.T4.3.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.0</td>
<td id="S5.T4.3.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14.7</td>
<td id="S5.T4.3.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">39.3</td>
<td id="S5.T4.3.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">25.5</td>
</tr>
<tr id="S5.T4.3.7" class="ltx_tr">
<td id="S5.T4.3.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T4.3.7.1.1" class="ltx_text">X-Vectors</span></td>
<td id="S5.T4.3.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Yes</td>
<td id="S5.T4.3.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.3</td>
<td id="S5.T4.3.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.3</td>
<td id="S5.T4.3.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.1</td>
<td id="S5.T4.3.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.7</td>
<td id="S5.T4.3.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.4</td>
</tr>
<tr id="S5.T4.3.8" class="ltx_tr">
<td id="S5.T4.3.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.8.1.1" class="ltx_text">No</span></td>
<td id="S5.T4.3.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.3</td>
<td id="S5.T4.3.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.5</td>
<td id="S5.T4.3.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.8.4.1" class="ltx_text ltx_font_bold">14.1</span></td>
<td id="S5.T4.3.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.5</td>
<td id="S5.T4.3.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">24.0</td>
</tr>
<tr id="S5.T4.3.9" class="ltx_tr">
<td id="S5.T4.3.9.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T4.3.9.1.1" class="ltx_text">Resemblyzer</span></td>
<td id="S5.T4.3.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.9.2.1" class="ltx_text">Yes</span></td>
<td id="S5.T4.3.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.1</td>
<td id="S5.T4.3.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.4</td>
<td id="S5.T4.3.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.5</td>
<td id="S5.T4.3.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">38.4</td>
<td id="S5.T4.3.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">25.2</td>
</tr>
<tr id="S5.T4.3.10" class="ltx_tr">
<td id="S5.T4.3.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.10.1.1" class="ltx_text">No</span></td>
<td id="S5.T4.3.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.1</td>
<td id="S5.T4.3.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.6</td>
<td id="S5.T4.3.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14.6</td>
<td id="S5.T4.3.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.10.5.1" class="ltx_text ltx_font_bold">36.2</span></td>
<td id="S5.T4.3.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.10.6.1" class="ltx_text ltx_font_bold">23.8</span></td>
</tr>
<tr id="S5.T4.3.11" class="ltx_tr">
<td id="S5.T4.3.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="6"><span id="S5.T4.3.11.1.1" class="ltx_text">real</span></td>
<td id="S5.T4.3.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T4.3.11.2.1" class="ltx_text">Linear</span></td>
<td id="S5.T4.3.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.11.3.1" class="ltx_text">Yes</span></td>
<td id="S5.T4.3.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T4.3.11.4.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.7</td>
<td id="S5.T4.3.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.2</td>
<td id="S5.T4.3.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.9</td>
<td id="S5.T4.3.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.8</td>
<td id="S5.T4.3.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.8</td>
</tr>
<tr id="S5.T4.3.12" class="ltx_tr">
<td id="S5.T4.3.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">No</td>
<td id="S5.T4.3.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T4.3.12.2.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.6</td>
<td id="S5.T4.3.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.1</td>
<td id="S5.T4.3.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.9</td>
<td id="S5.T4.3.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.6</td>
<td id="S5.T4.3.12.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.2</td>
</tr>
<tr id="S5.T4.3.13" class="ltx_tr">
<td id="S5.T4.3.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T4.3.13.1.1" class="ltx_text">X-Vectors</span></td>
<td id="S5.T4.3.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Yes</td>
<td id="S5.T4.3.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T4.3.13.3.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.8</td>
<td id="S5.T4.3.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.4</td>
<td id="S5.T4.3.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.9</td>
<td id="S5.T4.3.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.6</td>
<td id="S5.T4.3.13.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.6</td>
</tr>
<tr id="S5.T4.3.14" class="ltx_tr">
<td id="S5.T4.3.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.14.1.1" class="ltx_text">No</span></td>
<td id="S5.T4.3.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T4.3.14.2.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S5.T4.3.14.2.2" class="ltx_text ltx_font_bold">9.5</span>
</td>
<td id="S5.T4.3.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.14.3.1" class="ltx_text ltx_font_bold">31.2</span></td>
<td id="S5.T4.3.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.1</td>
<td id="S5.T4.3.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.3</td>
<td id="S5.T4.3.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">24.7</td>
</tr>
<tr id="S5.T4.3.15" class="ltx_tr">
<td id="S5.T4.3.15.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T4.3.15.1.1" class="ltx_text">Resemblyzer</span></td>
<td id="S5.T4.3.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.15.2.1" class="ltx_text">Yes</span></td>
<td id="S5.T4.3.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T4.3.15.3.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.8</td>
<td id="S5.T4.3.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.0</td>
<td id="S5.T4.3.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.0</td>
<td id="S5.T4.3.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">31.2</td>
<td id="S5.T4.3.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">25.7</td>
</tr>
<tr id="S5.T4.3.16" class="ltx_tr">
<td id="S5.T4.3.16.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T4.3.16.1.1" class="ltx_text">No</span></td>
<td id="S5.T4.3.16.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S5.T4.3.16.2.1" class="ltx_text ltx_phantom"><span style="visibility:hidden">0</span></span>9.8</td>
<td id="S5.T4.3.16.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T4.3.16.3.1" class="ltx_text ltx_font_bold">31.0</span></td>
<td id="S5.T4.3.16.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S5.T4.3.16.4.1" class="ltx_text ltx_phantom ltx_font_bold"><span style="visibility:hidden">0</span></span><span id="S5.T4.3.16.4.2" class="ltx_text ltx_font_bold">9.9</span>
</td>
<td id="S5.T4.3.16.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T4.3.16.5.1" class="ltx_text ltx_font_bold">27.8</span></td>
<td id="S5.T4.3.16.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T4.3.16.6.1" class="ltx_text ltx_font_bold">24.5</span></td>
</tr>
</table>
</figure>
<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p"><a href="#S1.T1" title="In 1 Introduction ‚Ä£ On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a> shows a comparison of our three baseline models.
For this we first train the models on train-clean-100, with and without the silence removal.
All three models degrade by a similar amount, which is to be expected, since silence portions of both training and test data differ.
In lines three and four of <a href="#S1.T1" title="In 1 Introduction ‚Ä£ On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">1</span></a>, the effect of vocoding is shown.
For this we extract mel features from the real data and convert them back to audio with our vocoder.
Here a first difference of the ASR models becomes visible. The degradation of <span title="" class="ltx_glossaryref">GMM-HMM</span> ranges from 0.8% to 1.8% absolute for dev-other, depending on the inclusion of silence removal.
For the two neural models this degradation is much less, ranging from an improvement of 0.2% to a degradation of 0.6 % <span title="" class="ltx_glossaryref">word error rate (WER)</span>.
When replacing the real data with <span title="" class="ltx_glossaryref">TTS</span> generated audio again the models behave differently.
For dev-clean <span title="" class="ltx_glossaryref">GMM-HMM</span> is able to keep the best performance of <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mo id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\sim</annotation></semantics></math>25% relative increase, while for <span title="" class="ltx_glossaryref">AED</span> with predicted phoneme durations the <span title="" class="ltx_glossaryref">WER</span> doubles.
When using the aligned durations the <span title="" class="ltx_glossaryref">WER</span> of the <span title="" class="ltx_glossaryref">AED</span> improves by 4% absolute while improvements for <span title="" class="ltx_glossaryref">GMM-HMM</span> are only marginal.
For dev-other this effect is similar, but in this case dominated by the fact that the <span title="" class="ltx_glossaryref">GMM-HMM</span> is already showing weak performance on the more noisy data.
For the <span title="" class="ltx_glossaryref">Hybrid</span> model the performance degrades by around two-thirds, with the special exception that <span title="" class="ltx_glossaryref">TTS</span> with oracle durations do not help the model.
While the <span title="" class="ltx_glossaryref">TTS</span> converges without silence removal, contrary to previous experiments for autoregressive models in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, results are significantly worse and thus omitted from the table.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Model sizes and Generalization</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.8" class="ltx_p">Next-up we investigate the influence of different model sizes on both the generalization capabilities of the <span title="" class="ltx_glossaryref">TTS</span> model and the influence on <span title="" class="ltx_glossaryref">ASR</span> training.
For this we chose two different model scaling approaches.
TTS literature usually reports on a single set of hyperparameters, but due to the possibility of automatic evaluation through ASR training and recognition, we can conduct a study on different choices.
In the first approach we scale <span title="" class="ltx_glossaryref">TTS</span> model dimensions by a factor <math id="S5.SS3.p1.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S5.SS3.p1.1.m1.1a"><mi id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">Œ≥</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><ci id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">ùõæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">\gamma</annotation></semantics></math>, meaning that e.g. for <math id="S5.SS3.p1.2.m2.1" class="ltx_Math" alttext="\gamma=1.5" display="inline"><semantics id="S5.SS3.p1.2.m2.1a"><mrow id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mi id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2.cmml">Œ≥</mi><mo id="S5.SS3.p1.2.m2.1.1.1" xref="S5.SS3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><eq id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1.1"></eq><ci id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2">ùõæ</ci><cn type="float" id="S5.SS3.p1.2.m2.1.1.3.cmml" xref="S5.SS3.p1.2.m2.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">\gamma=1.5</annotation></semantics></math> the 512-dimensional layers are increased to 768.
Analogue we indicate scaling the layer amount with <math id="S5.SS3.p1.3.m3.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S5.SS3.p1.3.m3.1a"><mi id="S5.SS3.p1.3.m3.1.1" xref="S5.SS3.p1.3.m3.1.1.cmml">œâ</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.1b"><ci id="S5.SS3.p1.3.m3.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1">ùúî</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.1c">\omega</annotation></semantics></math>, meaning that e.g. for <math id="S5.SS3.p1.4.m4.1" class="ltx_Math" alttext="\omega=2" display="inline"><semantics id="S5.SS3.p1.4.m4.1a"><mrow id="S5.SS3.p1.4.m4.1.1" xref="S5.SS3.p1.4.m4.1.1.cmml"><mi id="S5.SS3.p1.4.m4.1.1.2" xref="S5.SS3.p1.4.m4.1.1.2.cmml">œâ</mi><mo id="S5.SS3.p1.4.m4.1.1.1" xref="S5.SS3.p1.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.4.m4.1.1.3" xref="S5.SS3.p1.4.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m4.1b"><apply id="S5.SS3.p1.4.m4.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1"><eq id="S5.SS3.p1.4.m4.1.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1"></eq><ci id="S5.SS3.p1.4.m4.1.1.2.cmml" xref="S5.SS3.p1.4.m4.1.1.2">ùúî</ci><cn type="integer" id="S5.SS3.p1.4.m4.1.1.3.cmml" xref="S5.SS3.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.4.m4.1c">\omega=2</annotation></semantics></math> there are twice as many <span title="" class="ltx_glossaryref">BiLSTM</span> layers in the <span title="" class="ltx_glossaryref">TTS</span> models.
As seen in the upper part of <a href="#S3.T2" title="In 3 Speech Recognition ‚Ä£ On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">2</span></a> increasing the model size or the layer count for audio generation in both cases helps the <span title="" class="ltx_glossaryref">ASR</span> models.
Here the <span title="" class="ltx_glossaryref">AED</span> model benefits the most from the larger models, increasing relative performance on dev-clean by <math id="S5.SS3.p1.5.m5.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS3.p1.5.m5.1a"><mo id="S5.SS3.p1.5.m5.1.1" xref="S5.SS3.p1.5.m5.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.5.m5.1b"><csymbol cd="latexml" id="S5.SS3.p1.5.m5.1.1.cmml" xref="S5.SS3.p1.5.m5.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.5.m5.1c">\sim</annotation></semantics></math>30% and on dev-other by <math id="S5.SS3.p1.6.m6.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS3.p1.6.m6.1a"><mo id="S5.SS3.p1.6.m6.1.1" xref="S5.SS3.p1.6.m6.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.6.m6.1b"><csymbol cd="latexml" id="S5.SS3.p1.6.m6.1.1.cmml" xref="S5.SS3.p1.6.m6.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.6.m6.1c">\sim</annotation></semantics></math>20%.
While the <span title="" class="ltx_glossaryref">Hybrid</span> model shows improvements of <math id="S5.SS3.p1.7.m7.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS3.p1.7.m7.1a"><mo id="S5.SS3.p1.7.m7.1.1" xref="S5.SS3.p1.7.m7.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.7.m7.1b"><csymbol cd="latexml" id="S5.SS3.p1.7.m7.1.1.cmml" xref="S5.SS3.p1.7.m7.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.7.m7.1c">\sim</annotation></semantics></math>15% on dev-other, the <span title="" class="ltx_glossaryref">GMM-HMM</span> model only improves marginally with data generated by larger <span title="" class="ltx_glossaryref">TTS</span> models.
This also contradicts to the common idea that deeper models are able to hold even with larger models, while having a friction of the parameters.
In the case of generating synthetic data for <span title="" class="ltx_glossaryref">ASR</span> training this paradigm seems to be not trivially realizable.
We hypothesize that larger <span title="" class="ltx_glossaryref">TTS</span> systems are able to better replicate the acoustic structure of the training data, which then reflects in better synthesis of seen data.
In the lower section of <a href="#S3.T2" title="In 3 Speech Recognition ‚Ä£ On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">2</span></a> we show results on an unseen portion of train-clean-360.
Namely, we chose transcriptions that in the original corpus relates to 100h of data, hence the name 100h-LS-360.
As to be expected the general performance of the <span title="" class="ltx_glossaryref">TTS</span> on unseen data is worse than on the training data, still the larger <span title="" class="ltx_glossaryref">TTS</span> models are able to improve the performance of the <span title="" class="ltx_glossaryref">ASR</span> models, even though training scores indicated overfitting, as visible in <a href="#S5.T3" title="In 5.1 Data and Training ‚Ä£ 5 Experiments ‚Ä£ On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">3</span></a>.
This confirms our perception that for synthetic data generation <span title="" class="ltx_glossaryref">TTS</span> training loss scores are not meaningful as an indicator for generalisation and performance on a held-out dataset.
A notable difference is visible in the performance of the different <span title="" class="ltx_glossaryref">ASR</span> models on the unseen data.
The <span title="" class="ltx_glossaryref">GMM-HMM</span> is almost able to replicate the performance compared to the seen training data, with an absolute difference of 0.3% WER on dev-clean and dev-other for the best results.
A similar result is visible for the <span title="" class="ltx_glossaryref">Hybrid</span> model, where the degradation is only 1.1% WER absolute.
In the case of <span title="" class="ltx_glossaryref">AED</span> the performance is a lot worse, where the best performance with unseen data degrades by almost 50% relative on dev-clean and <math id="S5.SS3.p1.8.m8.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS3.p1.8.m8.1a"><mo id="S5.SS3.p1.8.m8.1.1" xref="S5.SS3.p1.8.m8.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.8.m8.1b"><csymbol cd="latexml" id="S5.SS3.p1.8.m8.1.1.cmml" xref="S5.SS3.p1.8.m8.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.8.m8.1c">\sim</annotation></semantics></math>15% relative on dev-clean.
This indicates that modelling errors done by the <span title="" class="ltx_glossaryref">TTS</span> model during synthesis of unseen data hurt the performance of the <span title="" class="ltx_glossaryref">AED</span> a lot more than for the other two models.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Speaker Representations</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">As a last study we investigate the influence of the speaker embedding on the performance of the synthetic data in <span title="" class="ltx_glossaryref">ASR</span> training.
In order to generate more expressive speaker embeddings we train an X-Vector model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> on train-clean-100, as well as taking embeddings directly from the pre-trained  <span id="S5.SS4.p1.1.1" class="ltx_text ltx_font_italic">Resemblyzer<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_upright">4</span></span><a target="_blank" href="https://github.com/resemble-ai/Resemblyzer" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://github.com/resemble-ai/Resemblyzer</a></span></span></span></span> model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
We train our TTS model by replacing the lookup table by the generated embeddings.
The results of this can be found in <a href="#S5.T4" title="In 5.2 Effect of Vocoding and Data Preprocessing ‚Ä£ 5 Experiments ‚Ä£ On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>¬†<span class="ltx_text ltx_ref_tag">4</span></a>.
For our baseline keeping the speaker tags random does not make the synthesized data worse for <span title="" class="ltx_glossaryref">ASR</span> training.
Adding the embeddings generated by both X-Vectors and Resemblyzer does not help improve over the initial baseline and rather the performance degrades, especially in the case of AED.
Only when not shuffling the embeddings during synthesis the pre-trained embeddings are able to keep up with the baseline, surpassing it together with real durations.
From this we conclude that overall the speaker embeddings generated by the TTS model generalize well.
Feeding embeddings from more elaborate models without changes to the model makes the TTS overfit instead of benefiting from richer embeddings.
Nevertheless, in the correct setting, they can provide meaningful information to the model, as seen in the results with real durations.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work we used a text-to-speech (TTS) model for the generation of synthetic data for automatic speech recognition (ASR) training.
We modified the <span title="" class="ltx_glossaryref">TTS</span> system in different aspects and investigated how this impacts the ASR training on the synthetically generated data.
Increasing the size of the <span title="" class="ltx_glossaryref">TTS</span> led to more overfitting according to the training and validation scores.
Still, when using the enlarged TTS for synthetic data generation, the <span title="" class="ltx_glossaryref">ASR</span> performance would improve.
This means hyperparameter tuning for <span title="" class="ltx_glossaryref">TTS</span> and proper evaluation is required before drawing conclusions from <span title="" class="ltx_glossaryref">ASR</span> training procedures involving synthetic data.
Basing model selection solely on loss scores does not suffice.
In a second set of experiments, we increased the <span title="" class="ltx_glossaryref">TTS</span> complexity by adding pre-trained networks for speaker modeling.
In contrast to enlarging the model, the results were less conclusive.
Only in some of the experimental settings the <span title="" class="ltx_glossaryref">ASR</span> performance would improve, and the improvements were not consistent among the different <span title="" class="ltx_glossaryref">ASR</span> architectures used.
It seems that the TTS tends to overfit on the given embeddings, which is reflected in the performance increase when using real durations and using the same speaker embedding as seen during training for synthesis.
We made the additional observation, that the vocoding of log-mel-features using a low-quality method such as Griffin &amp; Lim does not strongly degrade the utilization of the audio data for <span title="" class="ltx_glossaryref">ASR</span> training, while reducing the overhead for data generation significantly.
Overall we have seen that gap between real and synthetic data is smaller for traditional <span title="" class="ltx_glossaryref">ASR</span> systems.
Real phoneme variations and stronger speaker embeddings affected these systems much less than an attention-encoder-decoder <span title="" class="ltx_glossaryref">ASR</span> systems.
Future work should aim to find suitable aspects in synthetic data which correlate with the ASR performance across different model conditions.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgments</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This work was partially supported by NeuroSys, which as part of the initiative ‚ÄúClusters4Future‚Äù is funded by the Federal Ministry of Education and Research BMBF (03ZU1106DA), and by the project RESCALE within the program <span id="S7.p1.1.1" class="ltx_text ltx_font_italic">AI Lighthouse Projects for the Environment, Climate, Nature and Resources</span> funded by the Federal Ministry for the Environment, Nature Conservation, Nuclear Safety and Consumer Protection (BMUV), funding ID: 67KI32006A.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A.¬†Laptev, R.¬†Korostik, A.¬†Svischev, A.¬†Andrusenko, I.¬†Medennikov, and
S.¬†Rybin, ``You do not need more data: Improving end-to-end speech
recognition by text-to-speech data augmentation,'' <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">2020 13th
International Congress on Image and Signal Processing, BioMedical Engineering
and Informatics (CISP-BMEI)</em>, October 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
N.¬†Rossenbach, M.¬†Zeineldeen, B.¬†Hilmes, R.¬†Schl√ºter, and H.¬†Ney, ``Comparing
the benefit of synthetic training data for various automatic speech
recognition architectures,'' in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Automatic Speech Recognition
and Understanding Workshop (ASRU)</em>, 2021, pp. 788‚Äì795.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A.¬†Tjandra, S.¬†Sakti, and S.¬†Nakamura, ``End-to-end feedback loss in speech
chain framework via straight-through estimator,'' in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ICASSP 2019 - 2019
IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>, 2019, pp. 6281‚Äì6285.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M.¬†K. Baskar, L.¬†Burget, S.¬†Watanabe, R.¬†F. Astudillo, and J.¬†H. Cernocky,
``Eat: Enhanced ASR-TTS for self-supervised speech recognition,'' in
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ICASSP 2021 - 2021 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</em>.¬†¬†¬†IEEE, June 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
T.-Y. Hu, M.¬†Armandpour, A.¬†Shrivastava, J.-H.¬†R. Chang, H.¬†Koppula,
and O.¬†Tuzel, ``SYNT++: Utilizing Imperfect Synthetic Data to
Improve Speech Recognition,'' in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022 - 2022 IEEE
International Conference on Acoustics, Speech and Signal
Processing (ICASSP)</em>.¬†¬†¬†IEEE, May
2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Seed-Team and ByteDance, ``Seed-tts: A family of high-quality versatile speech
generation models,'' <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2406.02430, p.¬†5, 2024.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
H.¬†A. Bourlard and N.¬†Morgan, <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Connectionist speech recognition: a hybrid
approach</em>.¬†¬†¬†Springer Science &amp;
Business Media, 2012, vol. 247.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
W.¬†Chan, N.¬†Jaitly, Q.¬†Le, and O.¬†Vinyals, ``Listen, attend and spell: A neural
network for large vocabulary conversational speech recognition,'' in
<em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">2016 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP)</em>, 2016, pp. 4960‚Äì4964.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J.¬†Shen, R.¬†Pang, R.¬†J. Weiss, M.¬†Schuster, N.¬†Jaitly, Z.¬†Yang, Z.¬†Chen,
Y.¬†Zhang, Y.¬†Wang, R.¬†Skerrv-Ryan, R.¬†A. Saurous, Y.¬†Agiomvrgiannakis, and
Y.¬†Wu, ``Natural TTS synthesis by conditioning wavenet on MEL spectrogram
predictions,'' in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ICASSP 2018 - 2018 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP)</em>.¬†¬†¬†IEEE, April 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
S.¬†Ueno, M.¬†Mimura, S.¬†Sakai, and T.¬†Kawahara, ``Data augmentation for asr
using tts via a discrete representation,'' in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Automatic
Speech Recognition and Understanding Workshop (ASRU)</em>, December 2021, pp.
68‚Äì75.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
N.¬†Rossenbach, B.¬†Hilmes, and R.¬†Schl√ºter, ``On the relevance of phoneme
duration variability of synthesized training data for automatic speech
recognition,'' in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Automatic Speech Recognition and Understanding
Workshop (ASRU)</em>, 2023, pp. 1‚Äì8.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A.¬†P√©rez-Gonz√°lez-de Martos, A.¬†Sanchis, and A.¬†Juan,
``VRAIN-UPV MLLP's system for the Blizzard Challenge 2021,''
<em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Festvox Blizzard Challenge 2021</em>, October 2021. [Online].
Available: <a target="_blank" href="http://arxiv.org/abs/2110.15792v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2110.15792v1</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J.¬†Shen, Y.¬†Jia, M.¬†Chrzanowski, Y.¬†Zhang, I.¬†Elias, H.¬†Zen, and Y.¬†Wu,
``Non-attentive tacotron: Robust and controllable neural TTS synthesis
including unsupervised duration modeling,'' <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol.
abs/2010.04301v3, October 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
D.¬†W. Griffin, D.¬†S. Deadrick, and J.¬†S. Lim, ``Speech synthesis from
short-time fourier transform magnitude and its application to speech
processing,'' in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ICASSP '84, San Diego, California, USA, March 19-21,
1984</em>, pp. 61‚Äì64. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1109/ICASSP.1984.1172423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICASSP.1984.1172423</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M.¬†Bisani and H.¬†Ney, ``Joint-sequence models for grapheme-to-phoneme
conversion,'' <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Speech Communication</em>, vol.¬†50, no.¬†5, pp. 434‚Äì451,
May 2008.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
S.¬†Wiesler, A.¬†Richard, P.¬†Golik, R.¬†Schl√ºter, and H.¬†Ney, ``RASR/NN: The
RWTH neural network toolkit for speech recognition,'' in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ICASSP
2014 - 2014 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP)</em>.¬†¬†¬†IEEE, May
2014.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Y.¬†Ren, C.¬†Hu, X.¬†Tan, T.¬†Qin, S.¬†Zhao, Z.¬†Zhao, and T.-Y. Liu,
``FastSpeech 2: Fast and High-Quality End-to-End Text to
Speech,'' in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations (ICLR)</em>, December 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
V.¬†Panayotov, G.¬†Chen, D.¬†Povey, and S.¬†Khudanpur, ``Librispeech: An asr corpus
based on public domain audio books.'' in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>.¬†¬†¬†IEEE, 2015, pp. 5206‚Äì5210.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
K.¬†Beulen and H.¬†Ney, ``Automatic question generation for decision tree based
state tying,'' in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1998 IEEE International Conference
on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)</em>,
vol.¬†2, May 1998, pp. 805‚Äì808.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
D.¬†S. Park, W.¬†Chan, Y.¬†Zhang, C.-C. Chiu, B.¬†Zoph, E.¬†D. Cubuk, and Q.¬†V. Le,
``SpecAugment: A Simple Data Augmentation Method for Automatic Speech
Recognition,'' in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>, 2019, pp. 2613‚Äì2617.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
R.¬†Sennrich, B.¬†Haddow, and A.¬†Birch, ``Neural machine translation of rare
words with subword units,'' in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 54th Annual Meeting
of the Association for Computational Linguistics (Volume 1: Long
Papers)</em>.¬†¬†¬†Association for
Computational Linguistics, Aug. 2016, pp. 1715‚Äì1725.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
D.¬†P. Kingma and J.¬†Ba, ``Adam: A method for stochastic optimization,'' in
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">3rd International Conference on Learning Representations, ICLR 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings</em>, Y.¬†Bengio
and Y.¬†LeCun, Eds., 2015.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
D.¬†Snyder, D.¬†Garcia-Romero, G.¬†Sell, D.¬†Povey, and S.¬†Khudanpur, ``X-vectors:
Robust dnn embeddings for speaker recognition,'' in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2018 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP)</em>, April 2018, pp. 5329‚Äì5333.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Y.¬†Jia, Y.¬†Zhang, R.¬†Weiss, Q.¬†Wang, J.¬†Shen, F.¬†Ren, P.¬†Nguyen, R.¬†Pang,
I.¬†Lopez¬†Moreno, Y.¬†Wu <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ``Transfer learning from speaker
verification to multispeaker text-to-speech synthesis,'' <em id="bib.bib24.2.2" class="ltx_emph ltx_font_italic">Advances in
neural information processing systems</em>, vol.¬†31, 2018.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.17996" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.17997" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.17997">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.17997" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.17998" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 16:34:23 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
