<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.10207] A Comprehensive Survey on Diffusion Models and Their Applications</title><meta property="og:description" content="Diffusion Models are probabilistic models that create realistic samples by simulating the diffusion process, gradually adding and removing noise from data. These models have gained popularity in domains such as image p‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Comprehensive Survey on Diffusion Models and Their Applications">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Comprehensive Survey on Diffusion Models and Their Applications">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.10207">

<!--Generated on Thu Sep  5 16:23:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Comprehensive Survey on Diffusion Models and Their Applications</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Md Manjurul Ahsan 
<br class="ltx_break">Industrial and Systems Engineering
<br class="ltx_break">University of Oklahoma
<br class="ltx_break">Norman, Oklahoma-73071 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">ahsan@ou.edu</span> 
<br class="ltx_break">&amp;Shivakumar Raman 
<br class="ltx_break">Department of Industrial and Systems Engineering
<br class="ltx_break">University of Oklahoma
<br class="ltx_break">Norman, Oklahoma-73071
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">raman@ou.edu</span>
&amp;Yingtao Liu 
<br class="ltx_break">Department of Aerospace and Mechanical Engineering
<br class="ltx_break">University of Oklahoma
<br class="ltx_break">Norman, Oklahoma-73071
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">yingtao@ou.edu</span>
&amp;Zahed Siddique 
<br class="ltx_break">Department of Aerospace and Mechanical Engineering
<br class="ltx_break">University of Oklahoma
<br class="ltx_break">Norman, Oklahoma-73071
<br class="ltx_break"><span id="id4.4.id4" class="ltx_text ltx_font_typewriter">zsiddique@ou.edu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id5.id1" class="ltx_p"><span id="id5.id1.1" class="ltx_text ltx_font_bold">Diffusion Models</span> are probabilistic models that create realistic samples by simulating the diffusion process, gradually adding and removing noise from data. These models have gained popularity in domains such as image processing, speech synthesis, and natural language processing due to their ability to produce high-quality samples. As <span id="id5.id1.2" class="ltx_text ltx_font_bold">Diffusion Models</span> are being adopted in various domains, existing literature reviews that often focus on specific areas like computer vision or medical imaging may not serve a broader audience across multiple fields. Therefore, this review presents a comprehensive overview of <span id="id5.id1.3" class="ltx_text ltx_font_bold">Diffusion Models</span>, covering their theoretical foundations and algorithmic innovations. We highlight their applications in diverse areas such as media quality, authenticity, synthesis, image transformation, healthcare, and more. By consolidating current knowledge and identifying emerging trends, this review aims to facilitate a deeper understanding and broader adoption of <span id="id5.id1.4" class="ltx_text ltx_font_bold">Diffusion Models</span> and provide guidelines for future researchers and practitioners across diverse disciplines.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.18" class="ltx_p"><em id="p1.18.1" class="ltx_emph ltx_font_bold ltx_font_italic">K</em><span id="p1.18.2" class="ltx_text ltx_font_bold">eywords</span>‚ÄÇDiffusion Models¬†<math id="p1.1.m1.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.1.m1.1a"><mo id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.1.m1.1b"><ci id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.1.m1.1c">\cdot</annotation></semantics></math>
Generative Modeling¬†<math id="p1.2.m2.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.2.m2.1a"><mo id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.2.m2.1b"><ci id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.2.m2.1c">\cdot</annotation></semantics></math>
Synthetic Data Generation¬†<math id="p1.3.m3.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.3.m3.1a"><mo id="p1.3.m3.1.1" xref="p1.3.m3.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.3.m3.1b"><ci id="p1.3.m3.1.1.cmml" xref="p1.3.m3.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.3.m3.1c">\cdot</annotation></semantics></math>
Image Synthesis¬†<math id="p1.4.m4.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.4.m4.1a"><mo id="p1.4.m4.1.1" xref="p1.4.m4.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.4.m4.1b"><ci id="p1.4.m4.1.1.cmml" xref="p1.4.m4.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.4.m4.1c">\cdot</annotation></semantics></math>
Image-to-Image Translation¬†<math id="p1.5.m5.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.5.m5.1a"><mo id="p1.5.m5.1.1" xref="p1.5.m5.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.5.m5.1b"><ci id="p1.5.m5.1.1.cmml" xref="p1.5.m5.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.5.m5.1c">\cdot</annotation></semantics></math>
Text-to-Image Generation¬†<math id="p1.6.m6.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.6.m6.1a"><mo id="p1.6.m6.1.1" xref="p1.6.m6.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.6.m6.1b"><ci id="p1.6.m6.1.1.cmml" xref="p1.6.m6.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.6.m6.1c">\cdot</annotation></semantics></math>
Audio Synthesis¬†<math id="p1.7.m7.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.7.m7.1a"><mo id="p1.7.m7.1.1" xref="p1.7.m7.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.7.m7.1b"><ci id="p1.7.m7.1.1.cmml" xref="p1.7.m7.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.7.m7.1c">\cdot</annotation></semantics></math>
Time Series Forecasting¬†<math id="p1.8.m8.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.8.m8.1a"><mo id="p1.8.m8.1.1" xref="p1.8.m8.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.8.m8.1b"><ci id="p1.8.m8.1.1.cmml" xref="p1.8.m8.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.8.m8.1c">\cdot</annotation></semantics></math>
Anomaly Detection¬†<math id="p1.9.m9.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.9.m9.1a"><mo id="p1.9.m9.1.1" xref="p1.9.m9.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.9.m9.1b"><ci id="p1.9.m9.1.1.cmml" xref="p1.9.m9.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.9.m9.1c">\cdot</annotation></semantics></math>
Medical Imaging¬†<math id="p1.10.m10.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.10.m10.1a"><mo id="p1.10.m10.1.1" xref="p1.10.m10.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.10.m10.1b"><ci id="p1.10.m10.1.1.cmml" xref="p1.10.m10.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.10.m10.1c">\cdot</annotation></semantics></math>
Data Augmentation¬†<math id="p1.11.m11.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.11.m11.1a"><mo id="p1.11.m11.1.1" xref="p1.11.m11.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.11.m11.1b"><ci id="p1.11.m11.1.1.cmml" xref="p1.11.m11.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.11.m11.1c">\cdot</annotation></semantics></math>
Computational Efficiency¬†<math id="p1.12.m12.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.12.m12.1a"><mo id="p1.12.m12.1.1" xref="p1.12.m12.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.12.m12.1b"><ci id="p1.12.m12.1.1.cmml" xref="p1.12.m12.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.12.m12.1c">\cdot</annotation></semantics></math>
Uncertainty Quantification¬†<math id="p1.13.m13.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.13.m13.1a"><mo id="p1.13.m13.1.1" xref="p1.13.m13.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.13.m13.1b"><ci id="p1.13.m13.1.1.cmml" xref="p1.13.m13.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.13.m13.1c">\cdot</annotation></semantics></math>
Riemannian Manifolds¬†<math id="p1.14.m14.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.14.m14.1a"><mo id="p1.14.m14.1.1" xref="p1.14.m14.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.14.m14.1b"><ci id="p1.14.m14.1.1.cmml" xref="p1.14.m14.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.14.m14.1c">\cdot</annotation></semantics></math>
Molecular Dynamics¬†<math id="p1.15.m15.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.15.m15.1a"><mo id="p1.15.m15.1.1" xref="p1.15.m15.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.15.m15.1b"><ci id="p1.15.m15.1.1.cmml" xref="p1.15.m15.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.15.m15.1c">\cdot</annotation></semantics></math>
Super-Resolution¬†<math id="p1.16.m16.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.16.m16.1a"><mo id="p1.16.m16.1.1" xref="p1.16.m16.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.16.m16.1b"><ci id="p1.16.m16.1.1.cmml" xref="p1.16.m16.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.16.m16.1c">\cdot</annotation></semantics></math>
Semantic Image Synthesis¬†<math id="p1.17.m17.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.17.m17.1a"><mo id="p1.17.m17.1.1" xref="p1.17.m17.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.17.m17.1b"><ci id="p1.17.m17.1.1.cmml" xref="p1.17.m17.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.17.m17.1c">\cdot</annotation></semantics></math>
Zero-Shot Classification¬†<math id="p1.18.m18.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.18.m18.1a"><mo id="p1.18.m18.1.1" xref="p1.18.m18.1.1.cmml">‚ãÖ</mo><annotation-xml encoding="MathML-Content" id="p1.18.m18.1b"><ci id="p1.18.m18.1.1.cmml" xref="p1.18.m18.1.1">‚ãÖ</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.18.m18.1c">\cdot</annotation></semantics></math>
Atmospheric Turbulence Correction</p>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Abbreviations</h2>

<div class="ltx_pagination ltx_role_start_2_columns"></div>
<div id="Sx1.p1" class="ltx_para ltx_noindent">
<ul id="Sx1.I1" class="ltx_itemize">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p id="Sx1.I1.i1.p1.1" class="ltx_p"><span id="Sx1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">ACDM:</span> Autoregressive Cascade Multiscale Diffusion</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p id="Sx1.I1.i2.p1.1" class="ltx_p"><span id="Sx1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">ACDMSR:</span> Accelerated Conditional Diffusion Model for Image Super-Resolution</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p id="Sx1.I1.i3.p1.1" class="ltx_p"><span id="Sx1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">AIoT:</span> Artificial Intelligence of Things</p>
</div>
</li>
<li id="Sx1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i4.p1" class="ltx_para">
<p id="Sx1.I1.i4.p1.1" class="ltx_p"><span id="Sx1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">BerDiff:</span> Bernoulli Diffusion Model</p>
</div>
</li>
<li id="Sx1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i5.p1" class="ltx_para">
<p id="Sx1.I1.i5.p1.1" class="ltx_p"><span id="Sx1.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">BLIP:</span> Bootstrapped Language-Image Pretraining</p>
</div>
</li>
<li id="Sx1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i6.p1" class="ltx_para">
<p id="Sx1.I1.i6.p1.1" class="ltx_p"><span id="Sx1.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">BuilDiff:</span> Building Diffusion</p>
</div>
</li>
<li id="Sx1.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i7.p1" class="ltx_para">
<p id="Sx1.I1.i7.p1.1" class="ltx_p"><span id="Sx1.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">CDDM:</span> Conditional Denoising Diffusion Model</p>
</div>
</li>
<li id="Sx1.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i8.p1" class="ltx_para">
<p id="Sx1.I1.i8.p1.1" class="ltx_p"><span id="Sx1.I1.i8.p1.1.1" class="ltx_text ltx_font_bold">CDMs:</span> Classifier-guided Diffusion Models</p>
</div>
</li>
<li id="Sx1.I1.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i9.p1" class="ltx_para">
<p id="Sx1.I1.i9.p1.1" class="ltx_p"><span id="Sx1.I1.i9.p1.1.1" class="ltx_text ltx_font_bold">CIDEr:</span> Consensus-based Image Description Evaluation</p>
</div>
</li>
<li id="Sx1.I1.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i10.p1" class="ltx_para">
<p id="Sx1.I1.i10.p1.1" class="ltx_p"><span id="Sx1.I1.i10.p1.1.1" class="ltx_text ltx_font_bold">CLE:</span> Controllable Light Enhancement Diffusion</p>
</div>
</li>
<li id="Sx1.I1.i11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i11.p1" class="ltx_para">
<p id="Sx1.I1.i11.p1.1" class="ltx_p"><span id="Sx1.I1.i11.p1.1.1" class="ltx_text ltx_font_bold">CLIP:</span> Contrastive Language-Image Pre-training</p>
</div>
</li>
<li id="Sx1.I1.i12" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i12.p1" class="ltx_para">
<p id="Sx1.I1.i12.p1.1" class="ltx_p"><span id="Sx1.I1.i12.p1.1.1" class="ltx_text ltx_font_bold">CLIPSonic:</span> Controlled Language-Image Pretraining Sonic</p>
</div>
</li>
<li id="Sx1.I1.i13" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i13.p1" class="ltx_para">
<p id="Sx1.I1.i13.p1.1" class="ltx_p"><span id="Sx1.I1.i13.p1.1.1" class="ltx_text ltx_font_bold">CMD:</span> Conditional Diffusion Models</p>
</div>
</li>
<li id="Sx1.I1.i14" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i14.p1" class="ltx_para">
<p id="Sx1.I1.i14.p1.1" class="ltx_p"><span id="Sx1.I1.i14.p1.1.1" class="ltx_text ltx_font_bold">DDIM:</span> Denoising Diffusion Implicit Models</p>
</div>
</li>
<li id="Sx1.I1.i15" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i15.p1" class="ltx_para">
<p id="Sx1.I1.i15.p1.1" class="ltx_p"><span id="Sx1.I1.i15.p1.1.1" class="ltx_text ltx_font_bold">DDPMs:</span> Denoising Diffusion Probabilistic Models</p>
</div>
</li>
<li id="Sx1.I1.i16" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i16.p1" class="ltx_para">
<p id="Sx1.I1.i16.p1.1" class="ltx_p"><span id="Sx1.I1.i16.p1.1.1" class="ltx_text ltx_font_bold">DeScoD-ECG:</span> Denoising Score-based Diffusion for Electrocardiogram</p>
</div>
</li>
<li id="Sx1.I1.i17" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i17.p1" class="ltx_para">
<p id="Sx1.I1.i17.p1.1" class="ltx_p"><span id="Sx1.I1.i17.p1.1.1" class="ltx_text ltx_font_bold">DiffWave:</span> Diffusion Waveform</p>
</div>
</li>
<li id="Sx1.I1.i18" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i18.p1" class="ltx_para">
<p id="Sx1.I1.i18.p1.1" class="ltx_p"><span id="Sx1.I1.i18.p1.1.1" class="ltx_text ltx_font_bold">DiffDreamer:</span> Diffusion Dreamer</p>
</div>
</li>
<li id="Sx1.I1.i19" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i19.p1" class="ltx_para">
<p id="Sx1.I1.i19.p1.1" class="ltx_p"><span id="Sx1.I1.i19.p1.1.1" class="ltx_text ltx_font_bold">DiffLL:</span> Diffusion Model for Low-Light</p>
</div>
</li>
<li id="Sx1.I1.i20" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i20.p1" class="ltx_para">
<p id="Sx1.I1.i20.p1.1" class="ltx_p"><span id="Sx1.I1.i20.p1.1.1" class="ltx_text ltx_font_bold">DMs:</span> Diffusion Models</p>
</div>
</li>
<li id="Sx1.I1.i21" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i21.p1" class="ltx_para">
<p id="Sx1.I1.i21.p1.1" class="ltx_p"><span id="Sx1.I1.i21.p1.1.1" class="ltx_text ltx_font_bold">DMSEtext:</span> Diffusion Model for Speech Enhancement text</p>
</div>
</li>
<li id="Sx1.I1.i22" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i22.p1" class="ltx_para">
<p id="Sx1.I1.i22.p1.1" class="ltx_p"><span id="Sx1.I1.i22.p1.1.1" class="ltx_text ltx_font_bold">DisC-Diff:</span> Discriminator Consistency Diffusion</p>
</div>
</li>
<li id="Sx1.I1.i23" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i23.p1" class="ltx_para">
<p id="Sx1.I1.i23.p1.1" class="ltx_p"><span id="Sx1.I1.i23.p1.1.1" class="ltx_text ltx_font_bold">DSBID:</span> Diffusion-based Stochastic Blind Image Deblurring</p>
</div>
</li>
<li id="Sx1.I1.i24" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i24.p1" class="ltx_para">
<p id="Sx1.I1.i24.p1.1" class="ltx_p"><span id="Sx1.I1.i24.p1.1.1" class="ltx_text ltx_font_bold">DSC:</span> Dice Similarity Coefficient</p>
</div>
</li>
<li id="Sx1.I1.i25" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i25.p1" class="ltx_para">
<p id="Sx1.I1.i25.p1.1" class="ltx_p"><span id="Sx1.I1.i25.p1.1.1" class="ltx_text ltx_font_bold">DICDNet:</span> Deep Interpretable Convolutional Dictionary Networks</p>
</div>
</li>
<li id="Sx1.I1.i26" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i26.p1" class="ltx_para">
<p id="Sx1.I1.i26.p1.1" class="ltx_p"><span id="Sx1.I1.i26.p1.1.1" class="ltx_text ltx_font_bold">EquiDiff:</span> Equivariant Diffusion</p>
</div>
</li>
<li id="Sx1.I1.i27" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i27.p1" class="ltx_para">
<p id="Sx1.I1.i27.p1.1" class="ltx_p"><span id="Sx1.I1.i27.p1.1.1" class="ltx_text ltx_font_bold">FID:</span> Frechet Inception Distance</p>
</div>
</li>
<li id="Sx1.I1.i28" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i28.p1" class="ltx_para">
<p id="Sx1.I1.i28.p1.1" class="ltx_p"><span id="Sx1.I1.i28.p1.1.1" class="ltx_text ltx_font_bold">GED:</span> Generalized Energy Distance</p>
</div>
</li>
<li id="Sx1.I1.i29" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i29.p1" class="ltx_para">
<p id="Sx1.I1.i29.p1.1" class="ltx_p"><span id="Sx1.I1.i29.p1.1.1" class="ltx_text ltx_font_bold">GNNs:</span> Graph Neural Networks</p>
</div>
</li>
<li id="Sx1.I1.i30" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i30.p1" class="ltx_para">
<p id="Sx1.I1.i30.p1.1" class="ltx_p"><span id="Sx1.I1.i30.p1.1.1" class="ltx_text ltx_font_bold">HiFi-Diff:</span> Hierarchical Feature Conditional Diffusion</p>
</div>
</li>
<li id="Sx1.I1.i31" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i31.p1" class="ltx_para">
<p id="Sx1.I1.i31.p1.1" class="ltx_p"><span id="Sx1.I1.i31.p1.1.1" class="ltx_text ltx_font_bold">HQS:</span> Hybrid Quality Score</p>
</div>
</li>
<li id="Sx1.I1.i32" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i32.p1" class="ltx_para">
<p id="Sx1.I1.i32.p1.1" class="ltx_p"><span id="Sx1.I1.i32.p1.1.1" class="ltx_text ltx_font_bold">ID3PM:</span> Identity Denoising Diffusion Probabilistic Model</p>
</div>
</li>
<li id="Sx1.I1.i33" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i33.p1" class="ltx_para">
<p id="Sx1.I1.i33.p1.1" class="ltx_p"><span id="Sx1.I1.i33.p1.1.1" class="ltx_text ltx_font_bold">IS:</span> Inception Score</p>
</div>
</li>
<li id="Sx1.I1.i34" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i34.p1" class="ltx_para">
<p id="Sx1.I1.i34.p1.1" class="ltx_p"><span id="Sx1.I1.i34.p1.1.1" class="ltx_text ltx_font_bold">KID:</span> Kernel Inception Distance</p>
</div>
</li>
<li id="Sx1.I1.i35" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i35.p1" class="ltx_para">
<p id="Sx1.I1.i35.p1.1" class="ltx_p"><span id="Sx1.I1.i35.p1.1.1" class="ltx_text ltx_font_bold">LEs:</span> Learnable Unauthorized Examples</p>
</div>
</li>
<li id="Sx1.I1.i36" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i36.p1" class="ltx_para">
<p id="Sx1.I1.i36.p1.1" class="ltx_p"><span id="Sx1.I1.i36.p1.1.1" class="ltx_text ltx_font_bold">LDMs:</span> Latent Diffusion Models</p>
</div>
</li>
<li id="Sx1.I1.i37" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i37.p1" class="ltx_para">
<p id="Sx1.I1.i37.p1.1" class="ltx_p"><span id="Sx1.I1.i37.p1.1.1" class="ltx_text ltx_font_bold">LPIPS:</span> Learned Perceptual Image Patch Similarity</p>
</div>
</li>
<li id="Sx1.I1.i38" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i38.p1" class="ltx_para">
<p id="Sx1.I1.i38.p1.1" class="ltx_p"><span id="Sx1.I1.i38.p1.1.1" class="ltx_text ltx_font_bold">MAAT:</span> Metric Anomaly Anticipation</p>
</div>
</li>
<li id="Sx1.I1.i39" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i39.p1" class="ltx_para">
<p id="Sx1.I1.i39.p1.1" class="ltx_p"><span id="Sx1.I1.i39.p1.1.1" class="ltx_text ltx_font_bold">MAD:</span> Mean Absolute Deviation</p>
</div>
</li>
<li id="Sx1.I1.i40" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i40.p1" class="ltx_para">
<p id="Sx1.I1.i40.p1.1" class="ltx_p"><span id="Sx1.I1.i40.p1.1.1" class="ltx_text ltx_font_bold">MAE:</span> Mean Absolute Error</p>
</div>
</li>
<li id="Sx1.I1.i41" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i41.p1" class="ltx_para">
<p id="Sx1.I1.i41.p1.1" class="ltx_p"><span id="Sx1.I1.i41.p1.1.1" class="ltx_text ltx_font_bold">MatFusion:</span> Material Fusion</p>
</div>
</li>
<li id="Sx1.I1.i42" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i42.p1" class="ltx_para">
<p id="Sx1.I1.i42.p1.1" class="ltx_p"><span id="Sx1.I1.i42.p1.1.1" class="ltx_text ltx_font_bold">MOS:</span> Mean Opinion Score</p>
</div>
</li>
<li id="Sx1.I1.i43" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i43.p1" class="ltx_para">
<p id="Sx1.I1.i43.p1.1" class="ltx_p"><span id="Sx1.I1.i43.p1.1.1" class="ltx_text ltx_font_bold">MPJPE:</span> Mean Per-Joint Position Error</p>
</div>
</li>
<li id="Sx1.I1.i44" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i44.p1" class="ltx_para">
<p id="Sx1.I1.i44.p1.1" class="ltx_p"><span id="Sx1.I1.i44.p1.1.1" class="ltx_text ltx_font_bold">NILM:</span> Non-Intrusive Load Monitoring</p>
</div>
</li>
<li id="Sx1.I1.i45" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i45.p1" class="ltx_para">
<p id="Sx1.I1.i45.p1.1" class="ltx_p"><span id="Sx1.I1.i45.p1.1.1" class="ltx_text ltx_font_bold">NASDM:</span> Nuclei-Aware Semantic Diffusion Model</p>
</div>
</li>
<li id="Sx1.I1.i46" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i46.p1" class="ltx_para">
<p id="Sx1.I1.i46.p1.1" class="ltx_p"><span id="Sx1.I1.i46.p1.1.1" class="ltx_text ltx_font_bold">NIQE:</span> Naturalness Image Quality Evaluator</p>
</div>
</li>
<li id="Sx1.I1.i47" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i47.p1" class="ltx_para">
<p id="Sx1.I1.i47.p1.1" class="ltx_p"><span id="Sx1.I1.i47.p1.1.1" class="ltx_text ltx_font_bold">OMOMO:</span> Object Motion Guided Human Motion Synthesis</p>
</div>
</li>
<li id="Sx1.I1.i48" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i48.p1" class="ltx_para">
<p id="Sx1.I1.i48.p1.1" class="ltx_p"><span id="Sx1.I1.i48.p1.1.1" class="ltx_text ltx_font_bold">PatchDDM:</span> Patch-based Diffusion Denoising Model</p>
</div>
</li>
<li id="Sx1.I1.i49" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i49.p1" class="ltx_para">
<p id="Sx1.I1.i49.p1.1" class="ltx_p"><span id="Sx1.I1.i49.p1.1.1" class="ltx_text ltx_font_bold">PRD:</span> Percent Root Mean Square Difference</p>
</div>
</li>
<li id="Sx1.I1.i50" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i50.p1" class="ltx_para">
<p id="Sx1.I1.i50.p1.1" class="ltx_p"><span id="Sx1.I1.i50.p1.1.1" class="ltx_text ltx_font_bold">PSNR:</span> Peak Signal-to-Noise Ratio</p>
</div>
</li>
<li id="Sx1.I1.i51" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i51.p1" class="ltx_para">
<p id="Sx1.I1.i51.p1.1" class="ltx_p"><span id="Sx1.I1.i51.p1.1.1" class="ltx_text ltx_font_bold">RGB-D-Fusion:</span> Red-Green-Blue Depth Fusion</p>
</div>
</li>
<li id="Sx1.I1.i52" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i52.p1" class="ltx_para">
<p id="Sx1.I1.i52.p1.1" class="ltx_p"><span id="Sx1.I1.i52.p1.1.1" class="ltx_text ltx_font_bold">RNNs:</span> Recurrent Neural Networks</p>
</div>
</li>
<li id="Sx1.I1.i53" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i53.p1" class="ltx_para">
<p id="Sx1.I1.i53.p1.1" class="ltx_p"><span id="Sx1.I1.i53.p1.1.1" class="ltx_text ltx_font_bold">RMSE:</span> Root Mean Square Error</p>
</div>
</li>
<li id="Sx1.I1.i54" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i54.p1" class="ltx_para">
<p id="Sx1.I1.i54.p1.1" class="ltx_p"><span id="Sx1.I1.i54.p1.1.1" class="ltx_text ltx_font_bold">SAG:</span> Self-Attention Guidance</p>
</div>
</li>
<li id="Sx1.I1.i55" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i55.p1" class="ltx_para">
<p id="Sx1.I1.i55.p1.1" class="ltx_p"><span id="Sx1.I1.i55.p1.1.1" class="ltx_text ltx_font_bold">SBDMs:</span> Score-Based Diffusion Models</p>
</div>
</li>
<li id="Sx1.I1.i56" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i56.p1" class="ltx_para">
<p id="Sx1.I1.i56.p1.1" class="ltx_p"><span id="Sx1.I1.i56.p1.1.1" class="ltx_text ltx_font_bold">SDEs:</span> Stochastic Differential Equations</p>
</div>
</li>
<li id="Sx1.I1.i57" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i57.p1" class="ltx_para">
<p id="Sx1.I1.i57.p1.1" class="ltx_p"><span id="Sx1.I1.i57.p1.1.1" class="ltx_text ltx_font_bold">SDG:</span> Semantic Diffusion Guidance</p>
</div>
</li>
<li id="Sx1.I1.i58" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i58.p1" class="ltx_para">
<p id="Sx1.I1.i58.p1.1" class="ltx_p"><span id="Sx1.I1.i58.p1.1.1" class="ltx_text ltx_font_bold">SegDiff:</span> Segmentation Diffusion</p>
</div>
</li>
<li id="Sx1.I1.i59" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i59.p1" class="ltx_para">
<p id="Sx1.I1.i59.p1.1" class="ltx_p"><span id="Sx1.I1.i59.p1.1.1" class="ltx_text ltx_font_bold">SketchFFusion:</span> Sketch-Driven Fusion</p>
</div>
</li>
<li id="Sx1.I1.i60" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i60.p1" class="ltx_para">
<p id="Sx1.I1.i60.p1.1" class="ltx_p"><span id="Sx1.I1.i60.p1.1.1" class="ltx_text ltx_font_bold">SMOS:</span> Style Similarity MOS</p>
</div>
</li>
<li id="Sx1.I1.i61" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i61.p1" class="ltx_para">
<p id="Sx1.I1.i61.p1.1" class="ltx_p"><span id="Sx1.I1.i61.p1.1.1" class="ltx_text ltx_font_bold">SSIM:</span> Structural Similarity Index Measure</p>
</div>
</li>
<li id="Sx1.I1.i62" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i62.p1" class="ltx_para">
<p id="Sx1.I1.i62.p1.1" class="ltx_p"><span id="Sx1.I1.i62.p1.1.1" class="ltx_text ltx_font_bold">SDEs:</span> Stochastic Differential Equations</p>
</div>
</li>
<li id="Sx1.I1.i63" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i63.p1" class="ltx_para">
<p id="Sx1.I1.i63.p1.1" class="ltx_p"><span id="Sx1.I1.i63.p1.1.1" class="ltx_text ltx_font_bold">TFDPM:</span> Temporal and Feature Pattern-based Diffusion Probabilistic Model</p>
</div>
</li>
<li id="Sx1.I1.i64" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i64.p1" class="ltx_para">
<p id="Sx1.I1.i64.p1.1" class="ltx_p"><span id="Sx1.I1.i64.p1.1.1" class="ltx_text ltx_font_bold">VDMs:</span> Variational Diffusion Models</p>
</div>
</li>
<li id="Sx1.I1.i65" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="Sx1.I1.i65.p1" class="ltx_para ltx_noindent">
<p id="Sx1.I1.i65.p1.1" class="ltx_p"><span id="Sx1.I1.i65.p1.1.1" class="ltx_text ltx_font_bold">VTF-GAN:</span> Visible-to-Thermal Facial GAN</p>
</div>
</li>
</ul>
<div class="ltx_pagination ltx_role_end_2_columns"></div>
</div>
</section>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">A <span id="S1.p1.1.1" class="ltx_text ltx_font_bold">Diffusion Model</span> (DM) is a type of generative model that creates data by reversing a diffusion process, which incrementally adds noise to the data until it becomes a Gaussian distribution. First introduced by Sohl-Dickstein et al. (2015), these models have shown exceptional performance in producing high-quality samples across various fields, such as image, audio, and video synthesis¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. The process involves an iterative procedure where the model is trained to predict the noise that has been added to the sample at each step, effectively learning to denoise data. This approach has led to significant advancements in generating detailed and coherent outputs, making DM a powerful tool for tasks that require high fidelity generation, such as text-to-image synthesis and improving low-resolution images¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. <span id="S1.p1.1.2" class="ltx_text ltx_font_bold">Figure¬†<a href="#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a></span> illustrates a DM introduced for high-resolution image synthesis.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2408.10207/assets/adobe21.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="3285" height="2003" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S1.F1.2.1" class="ltx_text ltx_font_bold">An example of Diffusion-based models. From the figure, it can be observed that the model uses cross-attention mechanisms to enhance image synthesis. This approach allows the model to integrate different types of input information, such as text or semantic maps, to control the image generation process more effectively. The figure shows how these inputs are processed and incorporated into the model to produce high-quality images¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Diffusion Models (DMs) have become popular in several areas, particularly in image generation, where they create photorealistic images, art, and edits based on textual descriptions¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. They are also becoming popular in Natural Language Processing (NLP) for text generation and enhancement, demonstrating an ability to produce coherent and contextually relevant text¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. In audio synthesis, DMs are used to generate realistic soundscapes, music, and human-like speech, pushing the boundaries of creative and communicative Artificial Intelligence (AI) applications¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Moreover, their application extends to molecular and material science for designing new chemical compounds and materials, demonstrating their versatility. The popularity of DMs rises from their robustness, flexibility, and the high fidelity of the generated outputs, positioning them as a groundbreaking tool in AI-driven creative and scientific fields¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Figure¬†<a href="#S1.F2" title="Figure 2 ‚Ä£ 1 Introduction ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></span> provides a statistical overview of the last five years of published papers on DMs in various disciplines. From <span id="S1.p3.1.2" class="ltx_text ltx_font_bold">Figure¬†<a href="#S1.F2" title="Figure 2 ‚Ä£ 1 Introduction ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(a)</span>, it can be observed that the number of papers published since 2020 has been constantly growing. <span id="S1.p3.1.3" class="ltx_text ltx_font_bold">Figure¬†<a href="#S1.F2" title="Figure 2 ‚Ä£ 1 Introduction ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(b)</span> shows that medicine dominates with 29% of the publications, followed by computer science with 17% and engineering with 14%. Fields such as chemistry and materials science have fewer publications, comprising 4% and 6% of the total, respectively. These trends highlight the extensive use of DMs in medicine and computer science, while their potential in other areas remains less explored.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">This review aims to provide a comprehensive overview of DMs across various domains, helping the general audience understand their ability and versatility. By presenting diverse applications, this review encourages interdisciplinary collaboration and innovation, potentially addressing open challenges in less-explored fields beyond traditional applications like computer vision.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2408.10207/assets/pubyear.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="279" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S1.F2.2.1" class="ltx_text ltx_font_bold">Statistics on (a) the number of papers published over the last five years in DMs and (b) the percentage of published papers across various domains.</span></figcaption>
</figure>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Motivation and uniqueness of this survey</h3>

<div id="S1.SS1.p1" class="ltx_para ltx_noindent">
<p id="S1.SS1.p1.1" class="ltx_p">The rapid advancements in DMs across various domains show their potential and versatility. Despite the increasing number of publications, existing surveys often focus on specific applications or narrow fields, leaving a gap in reviews that cover the wide range of DM applications. Considering this opportunity, this survey aims to address the gap in the existing literature by providing a comprehensive overview of DMs.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para ltx_noindent">
<p id="S1.SS1.p2.1" class="ltx_p">Our <span id="S1.SS1.p2.1.1" class="ltx_text ltx_font_bold">contributions</span> are summarized below:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚ùë</span> 
<div id="S1.I1.ix1.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.ix1.p1.1" class="ltx_p">This survey considers several key aspects of DMs, including theory, algorithms, innovations, media quality, image transformation, healthcare applications, and more. We provide an overview of relevant literature up to March 2024, highlighting the latest techniques and advancements.</p>
</div>
</li>
<li id="S1.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚ùë</span> 
<div id="S1.I1.ix2.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.ix2.p1.1" class="ltx_p">We categorize DMs into three main types: Denoising Diffusion Probabilistic Models (DDPMs), Noise-Conditioned Score Networks (NCSNs), and Stochastic Differential Equations (SDEs), which aids in understanding their theoretical foundations and algorithmic variations.</p>
</div>
</li>
<li id="S1.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚ùë</span> 
<div id="S1.I1.ix3.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.ix3.p1.1" class="ltx_p">We highlight novel approaches and experimental methodologies relevant to the application of DMs, considering data types, algorithms, applications, datasets, evaluations, and limitations.</p>
</div>
</li>
<li id="S1.I1.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚ùë</span> 
<div id="S1.I1.ix4.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.ix4.p1.1" class="ltx_p">Finally, we discuss the findings, identify open issues, and raise questions about future research directions in DMs, aiming to guide researchers and practitioners.</p>
</div>
</li>
</ul>
</div>
<div id="S1.SS1.p3" class="ltx_para ltx_noindent">
<p id="S1.SS1.p3.1" class="ltx_p"><span id="S1.SS1.p3.1.1" class="ltx_text ltx_font_bold">Figure¬†<a href="#S1.F3" title="Figure 3 ‚Ä£ 1.1 Motivation and uniqueness of this survey ‚Ä£ 1 Introduction ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a></span> illustrates the framework of DMs based on the referenced literature used in this study, discussed in <span id="S1.SS1.p3.1.2" class="ltx_text ltx_font_bold">Sections¬†<a href="#S2" title="2 General Overview of DMs ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>-¬†<a href="#S8" title="8 Applications of Diffusion Models in Other Fields ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a></span>.</p>
</div>
<figure id="S1.F3" class="ltx_figure"><img src="/html/2408.10207/assets/frameworkado.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="678" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S1.F3.2.1" class="ltx_text ltx_font_bold">Comprehensive overview of DMs: This diagram categorizes various DMs and their applications across different fields. DMF ‚Äì Diffusion Models framework, TDM ‚Äì Types of Diffusion Models, IET ‚Äì Image Enhancement and Transformation, MQAS ‚Äì Media Quality, Authenticity, and Synthesis, DDPMs ‚Äì Denoising Diffusion Probabilistic Models, NCSNs ‚Äì Noise-Conditioned Score Networks, SDEs ‚Äì Stochastic Differential Equations.</span></figcaption>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Search strategy</h3>

<div id="S1.SS2.p1" class="ltx_para ltx_noindent">
<p id="S1.SS2.p1.1" class="ltx_p">Data were sourced from Scopus, initially identified 3,746 articles using the title, abstract, and keywords with the search terms ‚ÄòDiffusion Model‚Äô AND (‚Äòimage‚Äô OR ‚Äòaudio‚Äô OR ‚Äòtext‚Äô OR ‚Äòspeech‚Äô). Restricting the search to English-language, peer-reviewed, and open-access papers published between 2020 and 2024 reduced the number to 473. Further filtering excluded terms such as ‚Äòhuman,‚Äô ‚Äòcontrolled study,‚Äô ‚Äòjob analysis,‚Äô ‚Äòquantitative analysis,‚Äô ‚Äòcomparative study,‚Äô ‚Äòspecificity,‚Äô and other irrelevant keywords, resulting in 326 papers.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para ltx_noindent">
<p id="S1.SS2.p2.1" class="ltx_p">One researcher (Y.L.) imported these 326 journal articles into Excel CSV files for detailed analysis. Later, Excel‚Äôs duplication tools were used to identify and remove duplicates. The titles and abstracts of the remaining papers were assessed by two independent reviewers (M.A. and Z.S.), identifying 65 relevant documents. Additionally, 20 more relevant papers were included, resulting in a total of 85 papers across various fields.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>General Overview of DMs</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">DMs are a type of generative model that simulates the diffusion process to construct or reconstruct data distributions through stochastic processes. This involves a dual-phase operation where noise is incrementally added and subsequently reversed¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. The algorithmic backbone of DMs contains several key phases¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>:</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Initialization:</span> Start with data in its original form <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="x_{0}" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><msub id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.2" xref="S2.I1.i1.p1.1.m1.1.1.2.cmml">x</mi><mn id="S2.I1.i1.p1.1.m1.1.1.3" xref="S2.I1.i1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><apply id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.1.m1.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2">ùë•</ci><cn type="integer" id="S2.I1.i1.p1.1.m1.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">x_{0}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.4" class="ltx_p"><span id="S2.I1.i2.p1.4.1" class="ltx_text ltx_font_bold">Forward Process (Noise Addition):</span> Gradually add noise over <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">T</annotation></semantics></math> timesteps, transforming the data from <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="x_{0}" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><msub id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.2.cmml">x</mi><mn id="S2.I1.i2.p1.2.m2.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><apply id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2">ùë•</ci><cn type="integer" id="S2.I1.i2.p1.2.m2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">x_{0}</annotation></semantics></math> to <math id="S2.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="x_{T}" display="inline"><semantics id="S2.I1.i2.p1.3.m3.1a"><msub id="S2.I1.i2.p1.3.m3.1.1" xref="S2.I1.i2.p1.3.m3.1.1.cmml"><mi id="S2.I1.i2.p1.3.m3.1.1.2" xref="S2.I1.i2.p1.3.m3.1.1.2.cmml">x</mi><mi id="S2.I1.i2.p1.3.m3.1.1.3" xref="S2.I1.i2.p1.3.m3.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.3.m3.1b"><apply id="S2.I1.i2.p1.3.m3.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.3.m3.1.1.1.cmml" xref="S2.I1.i2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.3.m3.1.1.2.cmml" xref="S2.I1.i2.p1.3.m3.1.1.2">ùë•</ci><ci id="S2.I1.i2.p1.3.m3.1.1.3.cmml" xref="S2.I1.i2.p1.3.m3.1.1.3">ùëá</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.3.m3.1c">x_{T}</annotation></semantics></math> based on a predefined noise schedule <math id="S2.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.I1.i2.p1.4.m4.1a"><mi id="S2.I1.i2.p1.4.m4.1.1" xref="S2.I1.i2.p1.4.m4.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.4.m4.1b"><ci id="S2.I1.i2.p1.4.m4.1.1.cmml" xref="S2.I1.i2.p1.4.m4.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.4.m4.1c">\beta</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S2.I1.i3.p1.3" class="ltx_p"><span id="S2.I1.i3.p1.3.1" class="ltx_text ltx_font_bold">Reverse Process (Denoising):</span> Sequentially estimate <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="x_{t-1}" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><msub id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml"><mi id="S2.I1.i3.p1.1.m1.1.1.2" xref="S2.I1.i3.p1.1.m1.1.1.2.cmml">x</mi><mrow id="S2.I1.i3.p1.1.m1.1.1.3" xref="S2.I1.i3.p1.1.m1.1.1.3.cmml"><mi id="S2.I1.i3.p1.1.m1.1.1.3.2" xref="S2.I1.i3.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="S2.I1.i3.p1.1.m1.1.1.3.1" xref="S2.I1.i3.p1.1.m1.1.1.3.1.cmml">‚àí</mo><mn id="S2.I1.i3.p1.1.m1.1.1.3.3" xref="S2.I1.i3.p1.1.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><apply id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.1.m1.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.1.1.2">ùë•</ci><apply id="S2.I1.i3.p1.1.m1.1.1.3.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3"><minus id="S2.I1.i3.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3.1"></minus><ci id="S2.I1.i3.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3.2">ùë°</ci><cn type="integer" id="S2.I1.i3.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">x_{t-1}</annotation></semantics></math> from <math id="S2.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S2.I1.i3.p1.2.m2.1a"><msub id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml"><mi id="S2.I1.i3.p1.2.m2.1.1.2" xref="S2.I1.i3.p1.2.m2.1.1.2.cmml">x</mi><mi id="S2.I1.i3.p1.2.m2.1.1.3" xref="S2.I1.i3.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><apply id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2">ùë•</ci><ci id="S2.I1.i3.p1.2.m2.1.1.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">x_{t}</annotation></semantics></math> using the learned parameters <math id="S2.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.I1.i3.p1.3.m3.1a"><mi id="S2.I1.i3.p1.3.m3.1.1" xref="S2.I1.i3.p1.3.m3.1.1.cmml">Œ∏</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.3.m3.1b"><ci id="S2.I1.i3.p1.3.m3.1.1.cmml" xref="S2.I1.i3.p1.3.m3.1.1">ùúÉ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.3.m3.1c">\theta</annotation></semantics></math>, effectively reversing the noise addition to either reconstruct the original data or generate new data samples.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S2.I1.i4.p1.3" class="ltx_p"><span id="S2.I1.i4.p1.3.1" class="ltx_text ltx_font_bold">Input:</span> Original data <math id="S2.I1.i4.p1.1.m1.4" class="ltx_Math" alttext="X=\{x_{1},x_{2},\ldots,x_{n}\}" display="inline"><semantics id="S2.I1.i4.p1.1.m1.4a"><mrow id="S2.I1.i4.p1.1.m1.4.4" xref="S2.I1.i4.p1.1.m1.4.4.cmml"><mi id="S2.I1.i4.p1.1.m1.4.4.5" xref="S2.I1.i4.p1.1.m1.4.4.5.cmml">X</mi><mo id="S2.I1.i4.p1.1.m1.4.4.4" xref="S2.I1.i4.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S2.I1.i4.p1.1.m1.4.4.3.3" xref="S2.I1.i4.p1.1.m1.4.4.3.4.cmml"><mo stretchy="false" id="S2.I1.i4.p1.1.m1.4.4.3.3.4" xref="S2.I1.i4.p1.1.m1.4.4.3.4.cmml">{</mo><msub id="S2.I1.i4.p1.1.m1.2.2.1.1.1" xref="S2.I1.i4.p1.1.m1.2.2.1.1.1.cmml"><mi id="S2.I1.i4.p1.1.m1.2.2.1.1.1.2" xref="S2.I1.i4.p1.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S2.I1.i4.p1.1.m1.2.2.1.1.1.3" xref="S2.I1.i4.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.I1.i4.p1.1.m1.4.4.3.3.5" xref="S2.I1.i4.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.I1.i4.p1.1.m1.3.3.2.2.2" xref="S2.I1.i4.p1.1.m1.3.3.2.2.2.cmml"><mi id="S2.I1.i4.p1.1.m1.3.3.2.2.2.2" xref="S2.I1.i4.p1.1.m1.3.3.2.2.2.2.cmml">x</mi><mn id="S2.I1.i4.p1.1.m1.3.3.2.2.2.3" xref="S2.I1.i4.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.I1.i4.p1.1.m1.4.4.3.3.6" xref="S2.I1.i4.p1.1.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.I1.i4.p1.1.m1.1.1" xref="S2.I1.i4.p1.1.m1.1.1.cmml">‚Ä¶</mi><mo id="S2.I1.i4.p1.1.m1.4.4.3.3.7" xref="S2.I1.i4.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.I1.i4.p1.1.m1.4.4.3.3.3" xref="S2.I1.i4.p1.1.m1.4.4.3.3.3.cmml"><mi id="S2.I1.i4.p1.1.m1.4.4.3.3.3.2" xref="S2.I1.i4.p1.1.m1.4.4.3.3.3.2.cmml">x</mi><mi id="S2.I1.i4.p1.1.m1.4.4.3.3.3.3" xref="S2.I1.i4.p1.1.m1.4.4.3.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S2.I1.i4.p1.1.m1.4.4.3.3.8" xref="S2.I1.i4.p1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.1.m1.4b"><apply id="S2.I1.i4.p1.1.m1.4.4.cmml" xref="S2.I1.i4.p1.1.m1.4.4"><eq id="S2.I1.i4.p1.1.m1.4.4.4.cmml" xref="S2.I1.i4.p1.1.m1.4.4.4"></eq><ci id="S2.I1.i4.p1.1.m1.4.4.5.cmml" xref="S2.I1.i4.p1.1.m1.4.4.5">ùëã</ci><set id="S2.I1.i4.p1.1.m1.4.4.3.4.cmml" xref="S2.I1.i4.p1.1.m1.4.4.3.3"><apply id="S2.I1.i4.p1.1.m1.2.2.1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.2.2.1.1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S2.I1.i4.p1.1.m1.2.2.1.1.1.2">ùë•</ci><cn type="integer" id="S2.I1.i4.p1.1.m1.2.2.1.1.1.3.cmml" xref="S2.I1.i4.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S2.I1.i4.p1.1.m1.3.3.2.2.2.cmml" xref="S2.I1.i4.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.3.3.2.2.2.1.cmml" xref="S2.I1.i4.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.3.3.2.2.2.2.cmml" xref="S2.I1.i4.p1.1.m1.3.3.2.2.2.2">ùë•</ci><cn type="integer" id="S2.I1.i4.p1.1.m1.3.3.2.2.2.3.cmml" xref="S2.I1.i4.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S2.I1.i4.p1.1.m1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1">‚Ä¶</ci><apply id="S2.I1.i4.p1.1.m1.4.4.3.3.3.cmml" xref="S2.I1.i4.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.4.4.3.3.3.1.cmml" xref="S2.I1.i4.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.4.4.3.3.3.2.cmml" xref="S2.I1.i4.p1.1.m1.4.4.3.3.3.2">ùë•</ci><ci id="S2.I1.i4.p1.1.m1.4.4.3.3.3.3.cmml" xref="S2.I1.i4.p1.1.m1.4.4.3.3.3.3">ùëõ</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.1.m1.4c">X=\{x_{1},x_{2},\ldots,x_{n}\}</annotation></semantics></math>, Total timesteps <math id="S2.I1.i4.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.I1.i4.p1.2.m2.1a"><mi id="S2.I1.i4.p1.2.m2.1.1" xref="S2.I1.i4.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.2.m2.1b"><ci id="S2.I1.i4.p1.2.m2.1.1.cmml" xref="S2.I1.i4.p1.2.m2.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.2.m2.1c">T</annotation></semantics></math>, Noise schedule <math id="S2.I1.i4.p1.3.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.I1.i4.p1.3.m3.1a"><mi id="S2.I1.i4.p1.3.m3.1.1" xref="S2.I1.i4.p1.3.m3.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.3.m3.1b"><ci id="S2.I1.i4.p1.3.m3.1.1.cmml" xref="S2.I1.i4.p1.3.m3.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.3.m3.1c">\beta</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Output:</span> Denoised or synthesized data <math id="S2.I1.i5.p1.1.m1.1" class="ltx_Math" alttext="X^{\prime}" display="inline"><semantics id="S2.I1.i5.p1.1.m1.1a"><msup id="S2.I1.i5.p1.1.m1.1.1" xref="S2.I1.i5.p1.1.m1.1.1.cmml"><mi id="S2.I1.i5.p1.1.m1.1.1.2" xref="S2.I1.i5.p1.1.m1.1.1.2.cmml">X</mi><mo id="S2.I1.i5.p1.1.m1.1.1.3" xref="S2.I1.i5.p1.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S2.I1.i5.p1.1.m1.1b"><apply id="S2.I1.i5.p1.1.m1.1.1.cmml" xref="S2.I1.i5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i5.p1.1.m1.1.1.1.cmml" xref="S2.I1.i5.p1.1.m1.1.1">superscript</csymbol><ci id="S2.I1.i5.p1.1.m1.1.1.2.cmml" xref="S2.I1.i5.p1.1.m1.1.1.2">ùëã</ci><ci id="S2.I1.i5.p1.1.m1.1.1.3.cmml" xref="S2.I1.i5.p1.1.m1.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i5.p1.1.m1.1c">X^{\prime}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i6.p1" class="ltx_para">
<p id="S2.I1.i6.p1.3" class="ltx_p"><span id="S2.I1.i6.p1.3.1" class="ltx_text ltx_font_bold">Training:</span> Train the model to approximate the reverse noise addition process by learning the conditional distributions <math id="S2.I1.i6.p1.1.m1.1" class="ltx_Math" alttext="p_{\theta}(x_{t-1}|x_{t})" display="inline"><semantics id="S2.I1.i6.p1.1.m1.1a"><mrow id="S2.I1.i6.p1.1.m1.1.1" xref="S2.I1.i6.p1.1.m1.1.1.cmml"><msub id="S2.I1.i6.p1.1.m1.1.1.3" xref="S2.I1.i6.p1.1.m1.1.1.3.cmml"><mi id="S2.I1.i6.p1.1.m1.1.1.3.2" xref="S2.I1.i6.p1.1.m1.1.1.3.2.cmml">p</mi><mi id="S2.I1.i6.p1.1.m1.1.1.3.3" xref="S2.I1.i6.p1.1.m1.1.1.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.I1.i6.p1.1.m1.1.1.2" xref="S2.I1.i6.p1.1.m1.1.1.2.cmml">‚Äã</mo><mrow id="S2.I1.i6.p1.1.m1.1.1.1.1" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.I1.i6.p1.1.m1.1.1.1.1.2" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.I1.i6.p1.1.m1.1.1.1.1.1" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.cmml"><msub id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.cmml"><mi id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.2" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.2.cmml">x</mi><mrow id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.cmml"><mi id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.2" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.1" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.1.cmml">‚àí</mo><mn id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.3" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S2.I1.i6.p1.1.m1.1.1.1.1.1.1" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.I1.i6.p1.1.m1.1.1.1.1.1.3" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.cmml"><mi id="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.2" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.3" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S2.I1.i6.p1.1.m1.1.1.1.1.3" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i6.p1.1.m1.1b"><apply id="S2.I1.i6.p1.1.m1.1.1.cmml" xref="S2.I1.i6.p1.1.m1.1.1"><times id="S2.I1.i6.p1.1.m1.1.1.2.cmml" xref="S2.I1.i6.p1.1.m1.1.1.2"></times><apply id="S2.I1.i6.p1.1.m1.1.1.3.cmml" xref="S2.I1.i6.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i6.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i6.p1.1.m1.1.1.3">subscript</csymbol><ci id="S2.I1.i6.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i6.p1.1.m1.1.1.3.2">ùëù</ci><ci id="S2.I1.i6.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i6.p1.1.m1.1.1.3.3">ùúÉ</ci></apply><apply id="S2.I1.i6.p1.1.m1.1.1.1.1.1.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.I1.i6.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.1.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.2.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.2">ùë•</ci><apply id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3"><minus id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.1.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.1"></minus><ci id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.2.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.2">ùë°</ci><cn type="integer" id="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.3.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.1.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.2.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.2">ùë•</ci><ci id="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.3.cmml" xref="S2.I1.i6.p1.1.m1.1.1.1.1.1.3.3">ùë°</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i6.p1.1.m1.1c">p_{\theta}(x_{t-1}|x_{t})</annotation></semantics></math> for each timestep <math id="S2.I1.i6.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.I1.i6.p1.2.m2.1a"><mi id="S2.I1.i6.p1.2.m2.1.1" xref="S2.I1.i6.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i6.p1.2.m2.1b"><ci id="S2.I1.i6.p1.2.m2.1.1.cmml" xref="S2.I1.i6.p1.2.m2.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i6.p1.2.m2.1c">t</annotation></semantics></math>, from <math id="S2.I1.i6.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.I1.i6.p1.3.m3.1a"><mi id="S2.I1.i6.p1.3.m3.1.1" xref="S2.I1.i6.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i6.p1.3.m3.1b"><ci id="S2.I1.i6.p1.3.m3.1.1.cmml" xref="S2.I1.i6.p1.3.m3.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i6.p1.3.m3.1c">T</annotation></semantics></math> down to 1.</p>
</div>
</li>
<li id="S2.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S2.I1.i7.p1" class="ltx_para ltx_noindent">
<p id="S2.I1.i7.p1.1" class="ltx_p"><span id="S2.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">Data Synthesis:</span> Begin with a sample of random noise <math id="S2.I1.i7.p1.1.m1.1" class="ltx_Math" alttext="x_{T}" display="inline"><semantics id="S2.I1.i7.p1.1.m1.1a"><msub id="S2.I1.i7.p1.1.m1.1.1" xref="S2.I1.i7.p1.1.m1.1.1.cmml"><mi id="S2.I1.i7.p1.1.m1.1.1.2" xref="S2.I1.i7.p1.1.m1.1.1.2.cmml">x</mi><mi id="S2.I1.i7.p1.1.m1.1.1.3" xref="S2.I1.i7.p1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i7.p1.1.m1.1b"><apply id="S2.I1.i7.p1.1.m1.1.1.cmml" xref="S2.I1.i7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i7.p1.1.m1.1.1.1.cmml" xref="S2.I1.i7.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i7.p1.1.m1.1.1.2.cmml" xref="S2.I1.i7.p1.1.m1.1.1.2">ùë•</ci><ci id="S2.I1.i7.p1.1.m1.1.1.3.cmml" xref="S2.I1.i7.p1.1.m1.1.1.3">ùëá</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i7.p1.1.m1.1c">x_{T}</annotation></semantics></math> and iteratively apply the learned reverse process:</p>
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.1" class="ltx_Math" alttext="x^{\prime}_{t-1}=\text{Sample\ from\ }p_{\theta}(x_{t-1}|x_{t})" display="block"><semantics id="S2.Ex1.m1.1a"><mrow id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml"><msubsup id="S2.Ex1.m1.1.1.3" xref="S2.Ex1.m1.1.1.3.cmml"><mi id="S2.Ex1.m1.1.1.3.2.2" xref="S2.Ex1.m1.1.1.3.2.2.cmml">x</mi><mrow id="S2.Ex1.m1.1.1.3.3" xref="S2.Ex1.m1.1.1.3.3.cmml"><mi id="S2.Ex1.m1.1.1.3.3.2" xref="S2.Ex1.m1.1.1.3.3.2.cmml">t</mi><mo id="S2.Ex1.m1.1.1.3.3.1" xref="S2.Ex1.m1.1.1.3.3.1.cmml">‚àí</mo><mn id="S2.Ex1.m1.1.1.3.3.3" xref="S2.Ex1.m1.1.1.3.3.3.cmml">1</mn></mrow><mo id="S2.Ex1.m1.1.1.3.2.3" xref="S2.Ex1.m1.1.1.3.2.3.cmml">‚Ä≤</mo></msubsup><mo id="S2.Ex1.m1.1.1.2" xref="S2.Ex1.m1.1.1.2.cmml">=</mo><mrow id="S2.Ex1.m1.1.1.1" xref="S2.Ex1.m1.1.1.1.cmml"><mtext id="S2.Ex1.m1.1.1.1.3" xref="S2.Ex1.m1.1.1.1.3a.cmml">Sample¬†from¬†</mtext><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.1.1.1.2" xref="S2.Ex1.m1.1.1.1.2.cmml">‚Äã</mo><msub id="S2.Ex1.m1.1.1.1.4" xref="S2.Ex1.m1.1.1.1.4.cmml"><mi id="S2.Ex1.m1.1.1.1.4.2" xref="S2.Ex1.m1.1.1.1.4.2.cmml">p</mi><mi id="S2.Ex1.m1.1.1.1.4.3" xref="S2.Ex1.m1.1.1.1.4.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.1.1.1.2a" xref="S2.Ex1.m1.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.Ex1.m1.1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.1.1.1.1.1.2" xref="S2.Ex1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.1.1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.1.1.cmml"><msub id="S2.Ex1.m1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.1.1.1.1.1.1.2.cmml"><mi id="S2.Ex1.m1.1.1.1.1.1.1.2.2" xref="S2.Ex1.m1.1.1.1.1.1.1.2.2.cmml">x</mi><mrow id="S2.Ex1.m1.1.1.1.1.1.1.2.3" xref="S2.Ex1.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.Ex1.m1.1.1.1.1.1.1.2.3.2" xref="S2.Ex1.m1.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.Ex1.m1.1.1.1.1.1.1.2.3.1" xref="S2.Ex1.m1.1.1.1.1.1.1.2.3.1.cmml">‚àí</mo><mn id="S2.Ex1.m1.1.1.1.1.1.1.2.3.3" xref="S2.Ex1.m1.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S2.Ex1.m1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.Ex1.m1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex1.m1.1.1.1.1.1.1.3.2" xref="S2.Ex1.m1.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S2.Ex1.m1.1.1.1.1.1.1.3.3" xref="S2.Ex1.m1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S2.Ex1.m1.1.1.1.1.1.3" xref="S2.Ex1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.1b"><apply id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1"><eq id="S2.Ex1.m1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.2"></eq><apply id="S2.Ex1.m1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.3.1.cmml" xref="S2.Ex1.m1.1.1.3">subscript</csymbol><apply id="S2.Ex1.m1.1.1.3.2.cmml" xref="S2.Ex1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.3.2.1.cmml" xref="S2.Ex1.m1.1.1.3">superscript</csymbol><ci id="S2.Ex1.m1.1.1.3.2.2.cmml" xref="S2.Ex1.m1.1.1.3.2.2">ùë•</ci><ci id="S2.Ex1.m1.1.1.3.2.3.cmml" xref="S2.Ex1.m1.1.1.3.2.3">‚Ä≤</ci></apply><apply id="S2.Ex1.m1.1.1.3.3.cmml" xref="S2.Ex1.m1.1.1.3.3"><minus id="S2.Ex1.m1.1.1.3.3.1.cmml" xref="S2.Ex1.m1.1.1.3.3.1"></minus><ci id="S2.Ex1.m1.1.1.3.3.2.cmml" xref="S2.Ex1.m1.1.1.3.3.2">ùë°</ci><cn type="integer" id="S2.Ex1.m1.1.1.3.3.3.cmml" xref="S2.Ex1.m1.1.1.3.3.3">1</cn></apply></apply><apply id="S2.Ex1.m1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1"><times id="S2.Ex1.m1.1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.1.2"></times><ci id="S2.Ex1.m1.1.1.1.3a.cmml" xref="S2.Ex1.m1.1.1.1.3"><mtext id="S2.Ex1.m1.1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.1.3">Sample¬†from¬†</mtext></ci><apply id="S2.Ex1.m1.1.1.1.4.cmml" xref="S2.Ex1.m1.1.1.1.4"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.1.4.1.cmml" xref="S2.Ex1.m1.1.1.1.4">subscript</csymbol><ci id="S2.Ex1.m1.1.1.1.4.2.cmml" xref="S2.Ex1.m1.1.1.1.4.2">ùëù</ci><ci id="S2.Ex1.m1.1.1.1.4.3.cmml" xref="S2.Ex1.m1.1.1.1.4.3">ùúÉ</ci></apply><apply id="S2.Ex1.m1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.Ex1.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.2.2">ùë•</ci><apply id="S2.Ex1.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.2.3"><minus id="S2.Ex1.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.2.3.1"></minus><ci id="S2.Ex1.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.2.3.2">ùë°</ci><cn type="integer" id="S2.Ex1.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex1.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.3.2">ùë•</ci><ci id="S2.Ex1.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.Ex1.m1.1.1.1.1.1.1.3.3">ùë°</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.1c">x^{\prime}_{t-1}=\text{Sample\ from\ }p_{\theta}(x_{t-1}|x_{t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.I1.i7.p1.2" class="ltx_p">culminating in <math id="S2.I1.i7.p1.2.m1.1" class="ltx_Math" alttext="x^{\prime}_{0}" display="inline"><semantics id="S2.I1.i7.p1.2.m1.1a"><msubsup id="S2.I1.i7.p1.2.m1.1.1" xref="S2.I1.i7.p1.2.m1.1.1.cmml"><mi id="S2.I1.i7.p1.2.m1.1.1.2.2" xref="S2.I1.i7.p1.2.m1.1.1.2.2.cmml">x</mi><mn id="S2.I1.i7.p1.2.m1.1.1.3" xref="S2.I1.i7.p1.2.m1.1.1.3.cmml">0</mn><mo id="S2.I1.i7.p1.2.m1.1.1.2.3" xref="S2.I1.i7.p1.2.m1.1.1.2.3.cmml">‚Ä≤</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i7.p1.2.m1.1b"><apply id="S2.I1.i7.p1.2.m1.1.1.cmml" xref="S2.I1.i7.p1.2.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i7.p1.2.m1.1.1.1.cmml" xref="S2.I1.i7.p1.2.m1.1.1">subscript</csymbol><apply id="S2.I1.i7.p1.2.m1.1.1.2.cmml" xref="S2.I1.i7.p1.2.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i7.p1.2.m1.1.1.2.1.cmml" xref="S2.I1.i7.p1.2.m1.1.1">superscript</csymbol><ci id="S2.I1.i7.p1.2.m1.1.1.2.2.cmml" xref="S2.I1.i7.p1.2.m1.1.1.2.2">ùë•</ci><ci id="S2.I1.i7.p1.2.m1.1.1.2.3.cmml" xref="S2.I1.i7.p1.2.m1.1.1.2.3">‚Ä≤</ci></apply><cn type="integer" id="S2.I1.i7.p1.2.m1.1.1.3.cmml" xref="S2.I1.i7.p1.2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i7.p1.2.m1.1c">x^{\prime}_{0}</annotation></semantics></math>, the final synthesized or reconstructed data.</p>
</div>
</li>
</ul>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Types of DM.</span> Over the years, several diffusion-based models have been proposed, each contributing uniquely to the advancement of generative modeling. <span id="S2.p3.1.2" class="ltx_text ltx_font_bold">Figure¬†<a href="#S2.F4" title="Figure 4 ‚Ä£ 2 General Overview of DMs ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a></span> illustrates some of the important and influential DM along with their timeline. Among them, three DMs are very popular and widely adopted due to their impact on various applications: DDPMs, NCSNs, and SDEs.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2408.10207/assets/taxonomyfinal.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="401" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S2.F4.2.1" class="ltx_text ltx_font_bold">Timeline of different DMs from 2010 to 2023. The three main DMs, such as NCSNs, DDPMs, and SDEs, are highlighted with different colors.</span></figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>DDPMs</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.1" class="ltx_p">Introduced by Ho et al. (2020), DDPMs are generative models that transform noise into data through a series of gradual stochastic steps¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.3" class="ltx_p"><span id="S2.SS1.p2.3.1" class="ltx_text ltx_font_bold">Forward Diffusion Process.</span> The forward diffusion process incrementally adds Gaussian noise to the data, transforming it into a noise distribution. Given a data point <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{x}_{0}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><msub id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">ùê±</mi><mn id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">ùê±</ci><cn type="integer" id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\mathbf{x}_{0}</annotation></semantics></math>, the process is defined over <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">T</annotation></semantics></math> timesteps. At each timestep <math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><mi id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">t</annotation></semantics></math>, Gaussian noise is added to the data:</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="q(\mathbf{x}_{t}|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x}_{t};\sqrt{1-\beta_{t}}\mathbf{x}_{t-1},\beta_{t}\mathbf{I})," display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml">ùê±</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml">ùê±</mi><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.1.cmml">‚àí</mo><mn id="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.5" xref="S2.E1.m1.1.1.1.1.5.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.1.1.4.5" xref="S2.E1.m1.1.1.1.1.4.5.cmml">ùí©</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.4.4" xref="S2.E1.m1.1.1.1.1.4.4.cmml">‚Äã</mo><mrow id="S2.E1.m1.1.1.1.1.4.3.3" xref="S2.E1.m1.1.1.1.1.4.3.4.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.4.3.3.4" xref="S2.E1.m1.1.1.1.1.4.3.4.cmml">(</mo><msub id="S2.E1.m1.1.1.1.1.2.1.1.1" xref="S2.E1.m1.1.1.1.1.2.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.2.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.1.1.1.2.cmml">ùê±</mi><mi id="S2.E1.m1.1.1.1.1.2.1.1.1.3" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3.cmml">t</mi></msub><mo id="S2.E1.m1.1.1.1.1.4.3.3.5" xref="S2.E1.m1.1.1.1.1.4.3.4.cmml">;</mo><mrow id="S2.E1.m1.1.1.1.1.3.2.2.2" xref="S2.E1.m1.1.1.1.1.3.2.2.2.cmml"><msqrt id="S2.E1.m1.1.1.1.1.3.2.2.2.2" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.cmml"><mrow id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.cmml"><mn id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.2" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.2.cmml">1</mn><mo id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.1" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.1.cmml">‚àí</mo><msub id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.2" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.2.cmml">Œ≤</mi><mi id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.3" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.3.2.2.2.1" xref="S2.E1.m1.1.1.1.1.3.2.2.2.1.cmml">‚Äã</mo><msub id="S2.E1.m1.1.1.1.1.3.2.2.2.3" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.2.2.2.3.2" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.2.cmml">ùê±</mi><mrow id="S2.E1.m1.1.1.1.1.3.2.2.2.3.3" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.2" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.1" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.1.cmml">‚àí</mo><mn id="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.3" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S2.E1.m1.1.1.1.1.4.3.3.6" xref="S2.E1.m1.1.1.1.1.4.3.4.cmml">,</mo><mrow id="S2.E1.m1.1.1.1.1.4.3.3.3" xref="S2.E1.m1.1.1.1.1.4.3.3.3.cmml"><msub id="S2.E1.m1.1.1.1.1.4.3.3.3.2" xref="S2.E1.m1.1.1.1.1.4.3.3.3.2.cmml"><mi id="S2.E1.m1.1.1.1.1.4.3.3.3.2.2" xref="S2.E1.m1.1.1.1.1.4.3.3.3.2.2.cmml">Œ≤</mi><mi id="S2.E1.m1.1.1.1.1.4.3.3.3.2.3" xref="S2.E1.m1.1.1.1.1.4.3.3.3.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.4.3.3.3.1" xref="S2.E1.m1.1.1.1.1.4.3.3.3.1.cmml">‚Äã</mo><mi id="S2.E1.m1.1.1.1.1.4.3.3.3.3" xref="S2.E1.m1.1.1.1.1.4.3.3.3.3.cmml">ùêà</mi></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.4.3.3.7" xref="S2.E1.m1.1.1.1.1.4.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.1.5"></eq><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3">ùëû</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.2">ùê±</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.3">ùë°</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.2">ùê±</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.3"><minus id="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.1"></minus><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.2">ùë°</ci><cn type="integer" id="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.4"><times id="S2.E1.m1.1.1.1.1.4.4.cmml" xref="S2.E1.m1.1.1.1.1.4.4"></times><ci id="S2.E1.m1.1.1.1.1.4.5.cmml" xref="S2.E1.m1.1.1.1.1.4.5">ùí©</ci><list id="S2.E1.m1.1.1.1.1.4.3.4.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3"><apply id="S2.E1.m1.1.1.1.1.2.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.2">ùê±</ci><ci id="S2.E1.m1.1.1.1.1.2.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.3">ùë°</ci></apply><apply id="S2.E1.m1.1.1.1.1.3.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2"><times id="S2.E1.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.1"></times><apply id="S2.E1.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2"><root id="S2.E1.m1.1.1.1.1.3.2.2.2.2a.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2"></root><apply id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2"><minus id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.1"></minus><cn type="integer" id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.2">1</cn><apply id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.2">ùõΩ</ci><ci id="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.2.2.3.3">ùë°</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.3.2.2.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.3.2.2.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.2">ùê±</ci><apply id="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.3"><minus id="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.1"></minus><ci id="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.2">ùë°</ci><cn type="integer" id="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.2.2.2.3.3.3">1</cn></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.4.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3.3"><times id="S2.E1.m1.1.1.1.1.4.3.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3.3.1"></times><apply id="S2.E1.m1.1.1.1.1.4.3.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.4.3.3.3.2.1.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3.3.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.4.3.3.3.2.2.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3.3.2.2">ùõΩ</ci><ci id="S2.E1.m1.1.1.1.1.4.3.3.3.2.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3.3.2.3">ùë°</ci></apply><ci id="S2.E1.m1.1.1.1.1.4.3.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3.3.3">ùêà</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">q(\mathbf{x}_{t}|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x}_{t};\sqrt{1-\beta_{t}}\mathbf{x}_{t-1},\beta_{t}\mathbf{I}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.1" class="ltx_p">By the end of the diffusion process, the data is effectively transformed into pure Gaussian noise.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para ltx_noindent">
<p id="S2.SS1.p5.2" class="ltx_p"><span id="S2.SS1.p5.2.1" class="ltx_text ltx_font_bold">Reverse Denoising Process.</span> The reverse denoising process aims to recover the original data from the noisy observations. This is modeled using a parameterized reverse Markov chain, where the goal is to estimate the posterior distribution <math id="S2.SS1.p5.1.m1.1" class="ltx_Math" alttext="q(\mathbf{x}_{t-1}|\mathbf{x}_{t})" display="inline"><semantics id="S2.SS1.p5.1.m1.1a"><mrow id="S2.SS1.p5.1.m1.1.1" xref="S2.SS1.p5.1.m1.1.1.cmml"><mi id="S2.SS1.p5.1.m1.1.1.3" xref="S2.SS1.p5.1.m1.1.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p5.1.m1.1.1.2" xref="S2.SS1.p5.1.m1.1.1.2.cmml">‚Äã</mo><mrow id="S2.SS1.p5.1.m1.1.1.1.1" xref="S2.SS1.p5.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p5.1.m1.1.1.1.1.2" xref="S2.SS1.p5.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p5.1.m1.1.1.1.1.1" xref="S2.SS1.p5.1.m1.1.1.1.1.1.cmml"><msub id="S2.SS1.p5.1.m1.1.1.1.1.1.2" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.cmml"><mi id="S2.SS1.p5.1.m1.1.1.1.1.1.2.2" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.2.cmml">ùê±</mi><mrow id="S2.SS1.p5.1.m1.1.1.1.1.1.2.3" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.cmml"><mi id="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.2" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.1" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.1.cmml">‚àí</mo><mn id="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.3" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S2.SS1.p5.1.m1.1.1.1.1.1.1" xref="S2.SS1.p5.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.SS1.p5.1.m1.1.1.1.1.1.3" xref="S2.SS1.p5.1.m1.1.1.1.1.1.3.cmml"><mi id="S2.SS1.p5.1.m1.1.1.1.1.1.3.2" xref="S2.SS1.p5.1.m1.1.1.1.1.1.3.2.cmml">ùê±</mi><mi id="S2.SS1.p5.1.m1.1.1.1.1.1.3.3" xref="S2.SS1.p5.1.m1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S2.SS1.p5.1.m1.1.1.1.1.3" xref="S2.SS1.p5.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.1.m1.1b"><apply id="S2.SS1.p5.1.m1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1"><times id="S2.SS1.p5.1.m1.1.1.2.cmml" xref="S2.SS1.p5.1.m1.1.1.2"></times><ci id="S2.SS1.p5.1.m1.1.1.3.cmml" xref="S2.SS1.p5.1.m1.1.1.3">ùëû</ci><apply id="S2.SS1.p5.1.m1.1.1.1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p5.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS1.p5.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p5.1.m1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS1.p5.1.m1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.2">ùê±</ci><apply id="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.3"><minus id="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.1.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.1"></minus><ci id="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.2.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.2">ùë°</ci><cn type="integer" id="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.3.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.SS1.p5.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p5.1.m1.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p5.1.m1.1.1.1.1.1.3.2.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.3.2">ùê±</ci><ci id="S2.SS1.p5.1.m1.1.1.1.1.1.3.3.cmml" xref="S2.SS1.p5.1.m1.1.1.1.1.1.3.3">ùë°</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.1.m1.1c">q(\mathbf{x}_{t-1}|\mathbf{x}_{t})</annotation></semantics></math>. However, this posterior is not directly computable, so a Neural Network (NN) <math id="S2.SS1.p5.2.m2.1" class="ltx_Math" alttext="p_{\theta}" display="inline"><semantics id="S2.SS1.p5.2.m2.1a"><msub id="S2.SS1.p5.2.m2.1.1" xref="S2.SS1.p5.2.m2.1.1.cmml"><mi id="S2.SS1.p5.2.m2.1.1.2" xref="S2.SS1.p5.2.m2.1.1.2.cmml">p</mi><mi id="S2.SS1.p5.2.m2.1.1.3" xref="S2.SS1.p5.2.m2.1.1.3.cmml">Œ∏</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.2.m2.1b"><apply id="S2.SS1.p5.2.m2.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p5.2.m2.1.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p5.2.m2.1.1.2.cmml" xref="S2.SS1.p5.2.m2.1.1.2">ùëù</ci><ci id="S2.SS1.p5.2.m2.1.1.3.cmml" xref="S2.SS1.p5.2.m2.1.1.3">ùúÉ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.2.m2.1c">p_{\theta}</annotation></semantics></math> is employed to approximate it:</p>
</div>
<div id="S2.SS1.p6" class="ltx_para ltx_noindent">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.3" class="ltx_Math" alttext="p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})=\mathcal{N}(\mathbf{x}_{t-1};\mu_{\theta}(\mathbf{x}_{t},t),\Sigma_{\theta}(\mathbf{x}_{t},t))." display="block"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1.1" xref="S2.E2.m1.3.3.1.1.1.cmml"><msub id="S2.E2.m1.3.3.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.3.cmml"><mi id="S2.E2.m1.3.3.1.1.1.3.2" xref="S2.E2.m1.3.3.1.1.1.3.2.cmml">p</mi><mi id="S2.E2.m1.3.3.1.1.1.3.3" xref="S2.E2.m1.3.3.1.1.1.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S2.E2.m1.3.3.1.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.2.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.2.cmml">ùê±</mi><mrow id="S2.E2.m1.3.3.1.1.1.1.1.1.2.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.1.cmml">‚àí</mo><mn id="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S2.E2.m1.3.3.1.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.E2.m1.3.3.1.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml">ùê±</mi><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.3.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.3.3.1.1.5" xref="S2.E2.m1.3.3.1.1.5.cmml">=</mo><mrow id="S2.E2.m1.3.3.1.1.4" xref="S2.E2.m1.3.3.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3.1.1.4.5" xref="S2.E2.m1.3.3.1.1.4.5.cmml">ùí©</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.1.4.4" xref="S2.E2.m1.3.3.1.1.4.4.cmml">‚Äã</mo><mrow id="S2.E2.m1.3.3.1.1.4.3.3" xref="S2.E2.m1.3.3.1.1.4.3.4.cmml"><mo stretchy="false" id="S2.E2.m1.3.3.1.1.4.3.3.4" xref="S2.E2.m1.3.3.1.1.4.3.4.cmml">(</mo><msub id="S2.E2.m1.3.3.1.1.2.1.1.1" xref="S2.E2.m1.3.3.1.1.2.1.1.1.cmml"><mi id="S2.E2.m1.3.3.1.1.2.1.1.1.2" xref="S2.E2.m1.3.3.1.1.2.1.1.1.2.cmml">ùê±</mi><mrow id="S2.E2.m1.3.3.1.1.2.1.1.1.3" xref="S2.E2.m1.3.3.1.1.2.1.1.1.3.cmml"><mi id="S2.E2.m1.3.3.1.1.2.1.1.1.3.2" xref="S2.E2.m1.3.3.1.1.2.1.1.1.3.2.cmml">t</mi><mo id="S2.E2.m1.3.3.1.1.2.1.1.1.3.1" xref="S2.E2.m1.3.3.1.1.2.1.1.1.3.1.cmml">‚àí</mo><mn id="S2.E2.m1.3.3.1.1.2.1.1.1.3.3" xref="S2.E2.m1.3.3.1.1.2.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S2.E2.m1.3.3.1.1.4.3.3.5" xref="S2.E2.m1.3.3.1.1.4.3.4.cmml">;</mo><mrow id="S2.E2.m1.3.3.1.1.3.2.2.2" xref="S2.E2.m1.3.3.1.1.3.2.2.2.cmml"><msub id="S2.E2.m1.3.3.1.1.3.2.2.2.3" xref="S2.E2.m1.3.3.1.1.3.2.2.2.3.cmml"><mi id="S2.E2.m1.3.3.1.1.3.2.2.2.3.2" xref="S2.E2.m1.3.3.1.1.3.2.2.2.3.2.cmml">Œº</mi><mi id="S2.E2.m1.3.3.1.1.3.2.2.2.3.3" xref="S2.E2.m1.3.3.1.1.3.2.2.2.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.1.3.2.2.2.2" xref="S2.E2.m1.3.3.1.1.3.2.2.2.2.cmml">‚Äã</mo><mrow id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.2" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml">(</mo><msub id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.cmml"><mi id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.2" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.2.cmml">ùê±</mi><mi id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.3" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.3" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml">,</mo><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">t</mi><mo stretchy="false" id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.4" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.3.3.1.1.4.3.3.6" xref="S2.E2.m1.3.3.1.1.4.3.4.cmml">,</mo><mrow id="S2.E2.m1.3.3.1.1.4.3.3.3" xref="S2.E2.m1.3.3.1.1.4.3.3.3.cmml"><msub id="S2.E2.m1.3.3.1.1.4.3.3.3.3" xref="S2.E2.m1.3.3.1.1.4.3.3.3.3.cmml"><mi mathvariant="normal" id="S2.E2.m1.3.3.1.1.4.3.3.3.3.2" xref="S2.E2.m1.3.3.1.1.4.3.3.3.3.2.cmml">Œ£</mi><mi id="S2.E2.m1.3.3.1.1.4.3.3.3.3.3" xref="S2.E2.m1.3.3.1.1.4.3.3.3.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.1.4.3.3.3.2" xref="S2.E2.m1.3.3.1.1.4.3.3.3.2.cmml">‚Äã</mo><mrow id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.2" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml">(</mo><msub id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.cmml"><mi id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.2" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.2.cmml">ùê±</mi><mi id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.3" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.3.cmml">t</mi></msub><mo id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.3" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml">,</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">t</mi><mo stretchy="false" id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.4" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E2.m1.3.3.1.1.4.3.3.7" xref="S2.E2.m1.3.3.1.1.4.3.4.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S2.E2.m1.3.3.1.2" xref="S2.E2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1"><eq id="S2.E2.m1.3.3.1.1.5.cmml" xref="S2.E2.m1.3.3.1.1.5"></eq><apply id="S2.E2.m1.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1"><times id="S2.E2.m1.3.3.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.2"></times><apply id="S2.E2.m1.3.3.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.1.3.2">ùëù</ci><ci id="S2.E2.m1.3.3.1.1.1.3.3.cmml" xref="S2.E2.m1.3.3.1.1.1.3.3">ùúÉ</ci></apply><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.2">ùê±</ci><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.3"><minus id="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.1"></minus><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.2">ùë°</ci><cn type="integer" id="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2">ùê±</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.3">ùë°</ci></apply></apply></apply><apply id="S2.E2.m1.3.3.1.1.4.cmml" xref="S2.E2.m1.3.3.1.1.4"><times id="S2.E2.m1.3.3.1.1.4.4.cmml" xref="S2.E2.m1.3.3.1.1.4.4"></times><ci id="S2.E2.m1.3.3.1.1.4.5.cmml" xref="S2.E2.m1.3.3.1.1.4.5">ùí©</ci><list id="S2.E2.m1.3.3.1.1.4.3.4.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3"><apply id="S2.E2.m1.3.3.1.1.2.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.2.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.2.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1.2">ùê±</ci><apply id="S2.E2.m1.3.3.1.1.2.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1.3"><minus id="S2.E2.m1.3.3.1.1.2.1.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1.3.1"></minus><ci id="S2.E2.m1.3.3.1.1.2.1.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1.3.2">ùë°</ci><cn type="integer" id="S2.E2.m1.3.3.1.1.2.1.1.1.3.3.cmml" xref="S2.E2.m1.3.3.1.1.2.1.1.1.3.3">1</cn></apply></apply><apply id="S2.E2.m1.3.3.1.1.3.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2"><times id="S2.E2.m1.3.3.1.1.3.2.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.2"></times><apply id="S2.E2.m1.3.3.1.1.3.2.2.2.3.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.3.2.2.2.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.3">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.3.2.2.2.3.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.3.2">ùúá</ci><ci id="S2.E2.m1.3.3.1.1.3.2.2.2.3.3.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.3.3">ùúÉ</ci></apply><interval closure="open" id="S2.E2.m1.3.3.1.1.3.2.2.2.1.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.1"><apply id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.2">ùê±</ci><ci id="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.3.2.2.2.1.1.1.3">ùë°</ci></apply><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">ùë°</ci></interval></apply><apply id="S2.E2.m1.3.3.1.1.4.3.3.3.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3"><times id="S2.E2.m1.3.3.1.1.4.3.3.3.2.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.2"></times><apply id="S2.E2.m1.3.3.1.1.4.3.3.3.3.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.4.3.3.3.3.1.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.3">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.4.3.3.3.3.2.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.3.2">Œ£</ci><ci id="S2.E2.m1.3.3.1.1.4.3.3.3.3.3.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.3.3">ùúÉ</ci></apply><interval closure="open" id="S2.E2.m1.3.3.1.1.4.3.3.3.1.2.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.1"><apply id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.2">ùê±</ci><ci id="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.4.3.3.3.1.1.1.3">ùë°</ci></apply><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">ùë°</ci></interval></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})=\mathcal{N}(\mathbf{x}_{t-1};\mu_{\theta}(\mathbf{x}_{t},t),\Sigma_{\theta}(\mathbf{x}_{t},t)).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p7" class="ltx_para ltx_noindent">
<p id="S2.SS1.p7.1" class="ltx_p">The network is trained to minimize the following Variational Lower Bound (VLB) on the negative Log-likelihood:</p>
</div>
<div id="S2.SS1.p8" class="ltx_para ltx_noindent">
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.1" class="ltx_math_unparsed" alttext="L_{\text{vlb}}=\mathbb{E}_{q}\left[\sum_{t=1}^{T}D_{\text{KL}}\left(q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\,||\,p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\right)-\log p_{\theta}(\mathbf{x}_{0}|\mathbf{x}_{1})\right]," display="block"><semantics id="S2.E3.m1.1a"><mrow id="S2.E3.m1.1b"><msub id="S2.E3.m1.1.1"><mi id="S2.E3.m1.1.1.2">L</mi><mtext id="S2.E3.m1.1.1.3">vlb</mtext></msub><mo id="S2.E3.m1.1.2">=</mo><msub id="S2.E3.m1.1.3"><mi id="S2.E3.m1.1.3.2">ùîº</mi><mi id="S2.E3.m1.1.3.3">q</mi></msub><mrow id="S2.E3.m1.1.4"><mo id="S2.E3.m1.1.4.1">[</mo><munderover id="S2.E3.m1.1.4.2"><mo lspace="0em" movablelimits="false" id="S2.E3.m1.1.4.2.2.2">‚àë</mo><mrow id="S2.E3.m1.1.4.2.2.3"><mi id="S2.E3.m1.1.4.2.2.3.2">t</mi><mo id="S2.E3.m1.1.4.2.2.3.1">=</mo><mn id="S2.E3.m1.1.4.2.2.3.3">1</mn></mrow><mi id="S2.E3.m1.1.4.2.3">T</mi></munderover><msub id="S2.E3.m1.1.4.3"><mi id="S2.E3.m1.1.4.3.2">D</mi><mtext id="S2.E3.m1.1.4.3.3">KL</mtext></msub><mrow id="S2.E3.m1.1.4.4"><mo id="S2.E3.m1.1.4.4.1">(</mo><mi id="S2.E3.m1.1.4.4.2">q</mi><mrow id="S2.E3.m1.1.4.4.3"><mo stretchy="false" id="S2.E3.m1.1.4.4.3.1">(</mo><msub id="S2.E3.m1.1.4.4.3.2"><mi id="S2.E3.m1.1.4.4.3.2.2">ùê±</mi><mrow id="S2.E3.m1.1.4.4.3.2.3"><mi id="S2.E3.m1.1.4.4.3.2.3.2">t</mi><mo id="S2.E3.m1.1.4.4.3.2.3.1">‚àí</mo><mn id="S2.E3.m1.1.4.4.3.2.3.3">1</mn></mrow></msub><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E3.m1.1.4.4.3.3">|</mo><msub id="S2.E3.m1.1.4.4.3.4"><mi id="S2.E3.m1.1.4.4.3.4.2">ùê±</mi><mi id="S2.E3.m1.1.4.4.3.4.3">t</mi></msub><mo id="S2.E3.m1.1.4.4.3.5">,</mo><msub id="S2.E3.m1.1.4.4.3.6"><mi id="S2.E3.m1.1.4.4.3.6.2">ùê±</mi><mn id="S2.E3.m1.1.4.4.3.6.3">0</mn></msub><mo rspace="0.170em" stretchy="false" id="S2.E3.m1.1.4.4.3.7">)</mo></mrow><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E3.m1.1.4.4.4">|</mo><mo fence="false" rspace="0.337em" stretchy="false" id="S2.E3.m1.1.4.4.5">|</mo><msub id="S2.E3.m1.1.4.4.6"><mi id="S2.E3.m1.1.4.4.6.2">p</mi><mi id="S2.E3.m1.1.4.4.6.3">Œ∏</mi></msub><mrow id="S2.E3.m1.1.4.4.7"><mo stretchy="false" id="S2.E3.m1.1.4.4.7.1">(</mo><msub id="S2.E3.m1.1.4.4.7.2"><mi id="S2.E3.m1.1.4.4.7.2.2">ùê±</mi><mrow id="S2.E3.m1.1.4.4.7.2.3"><mi id="S2.E3.m1.1.4.4.7.2.3.2">t</mi><mo id="S2.E3.m1.1.4.4.7.2.3.1">‚àí</mo><mn id="S2.E3.m1.1.4.4.7.2.3.3">1</mn></mrow></msub><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E3.m1.1.4.4.7.3">|</mo><msub id="S2.E3.m1.1.4.4.7.4"><mi id="S2.E3.m1.1.4.4.7.4.2">ùê±</mi><mi id="S2.E3.m1.1.4.4.7.4.3">t</mi></msub><mo stretchy="false" id="S2.E3.m1.1.4.4.7.5">)</mo></mrow><mo id="S2.E3.m1.1.4.4.8">)</mo></mrow><mo id="S2.E3.m1.1.4.5">‚àí</mo><mi id="S2.E3.m1.1.4.6">log</mi><msub id="S2.E3.m1.1.4.7"><mi id="S2.E3.m1.1.4.7.2">p</mi><mi id="S2.E3.m1.1.4.7.3">Œ∏</mi></msub><mrow id="S2.E3.m1.1.4.8"><mo stretchy="false" id="S2.E3.m1.1.4.8.1">(</mo><msub id="S2.E3.m1.1.4.8.2"><mi id="S2.E3.m1.1.4.8.2.2">ùê±</mi><mn id="S2.E3.m1.1.4.8.2.3">0</mn></msub><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E3.m1.1.4.8.3">|</mo><msub id="S2.E3.m1.1.4.8.4"><mi id="S2.E3.m1.1.4.8.4.2">ùê±</mi><mn id="S2.E3.m1.1.4.8.4.3">1</mn></msub><mo stretchy="false" id="S2.E3.m1.1.4.8.5">)</mo></mrow><mo id="S2.E3.m1.1.4.9">]</mo></mrow><mo id="S2.E3.m1.1.5">,</mo></mrow><annotation encoding="application/x-tex" id="S2.E3.m1.1c">L_{\text{vlb}}=\mathbb{E}_{q}\left[\sum_{t=1}^{T}D_{\text{KL}}\left(q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\,||\,p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\right)-\log p_{\theta}(\mathbf{x}_{0}|\mathbf{x}_{1})\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p9" class="ltx_para ltx_noindent">
<p id="S2.SS1.p9.1" class="ltx_p"><span id="S2.SS1.p9.1.1" class="ltx_text ltx_font_bold">Training Objective.</span> To simplify the training process, Ho et al. (2020) proposed a reparameterization of the training objective that aligns closely with denoising score matching. The simplified objective can be expressed as¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>:</p>
</div>
<div id="S2.SS1.p10" class="ltx_para ltx_noindent">
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.5" class="ltx_Math" alttext="L_{\text{simple}}=\mathbb{E}_{t,\mathbf{x}_{0},\epsilon}\left[||\epsilon-\epsilon_{\theta}(\mathbf{x}_{t},t)||^{2}\right]," display="block"><semantics id="S2.E4.m1.5a"><mrow id="S2.E4.m1.5.5.1" xref="S2.E4.m1.5.5.1.1.cmml"><mrow id="S2.E4.m1.5.5.1.1" xref="S2.E4.m1.5.5.1.1.cmml"><msub id="S2.E4.m1.5.5.1.1.3" xref="S2.E4.m1.5.5.1.1.3.cmml"><mi id="S2.E4.m1.5.5.1.1.3.2" xref="S2.E4.m1.5.5.1.1.3.2.cmml">L</mi><mtext id="S2.E4.m1.5.5.1.1.3.3" xref="S2.E4.m1.5.5.1.1.3.3a.cmml">simple</mtext></msub><mo id="S2.E4.m1.5.5.1.1.2" xref="S2.E4.m1.5.5.1.1.2.cmml">=</mo><mrow id="S2.E4.m1.5.5.1.1.1" xref="S2.E4.m1.5.5.1.1.1.cmml"><msub id="S2.E4.m1.5.5.1.1.1.3" xref="S2.E4.m1.5.5.1.1.1.3.cmml"><mi id="S2.E4.m1.5.5.1.1.1.3.2" xref="S2.E4.m1.5.5.1.1.1.3.2.cmml">ùîº</mi><mrow id="S2.E4.m1.3.3.3.3" xref="S2.E4.m1.3.3.3.4.cmml"><mi id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml">t</mi><mo id="S2.E4.m1.3.3.3.3.2" xref="S2.E4.m1.3.3.3.4.cmml">,</mo><msub id="S2.E4.m1.3.3.3.3.1" xref="S2.E4.m1.3.3.3.3.1.cmml"><mi id="S2.E4.m1.3.3.3.3.1.2" xref="S2.E4.m1.3.3.3.3.1.2.cmml">ùê±</mi><mn id="S2.E4.m1.3.3.3.3.1.3" xref="S2.E4.m1.3.3.3.3.1.3.cmml">0</mn></msub><mo id="S2.E4.m1.3.3.3.3.3" xref="S2.E4.m1.3.3.3.4.cmml">,</mo><mi id="S2.E4.m1.2.2.2.2" xref="S2.E4.m1.2.2.2.2.cmml">œµ</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.5.5.1.1.1.2" xref="S2.E4.m1.5.5.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E4.m1.5.5.1.1.1.1.1" xref="S2.E4.m1.5.5.1.1.1.1.2.cmml"><mo id="S2.E4.m1.5.5.1.1.1.1.1.2" xref="S2.E4.m1.5.5.1.1.1.1.2.1.cmml">[</mo><msup id="S2.E4.m1.5.5.1.1.1.1.1.1" xref="S2.E4.m1.5.5.1.1.1.1.1.1.cmml"><mrow id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.2.1.cmml">‚Äñ</mo><mrow id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.3.cmml">œµ</mi><mo id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">‚àí</mo><mrow id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.2.cmml">œµ</mi><mi id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">ùê±</mi><mi id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E4.m1.4.4" xref="S2.E4.m1.4.4.cmml">t</mi><mo stretchy="false" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.4" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.2.1.cmml">‚Äñ</mo></mrow><mn id="S2.E4.m1.5.5.1.1.1.1.1.1.3" xref="S2.E4.m1.5.5.1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S2.E4.m1.5.5.1.1.1.1.1.3" xref="S2.E4.m1.5.5.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S2.E4.m1.5.5.1.2" xref="S2.E4.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.5b"><apply id="S2.E4.m1.5.5.1.1.cmml" xref="S2.E4.m1.5.5.1"><eq id="S2.E4.m1.5.5.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.2"></eq><apply id="S2.E4.m1.5.5.1.1.3.cmml" xref="S2.E4.m1.5.5.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.1.1.3.1.cmml" xref="S2.E4.m1.5.5.1.1.3">subscript</csymbol><ci id="S2.E4.m1.5.5.1.1.3.2.cmml" xref="S2.E4.m1.5.5.1.1.3.2">ùêø</ci><ci id="S2.E4.m1.5.5.1.1.3.3a.cmml" xref="S2.E4.m1.5.5.1.1.3.3"><mtext mathsize="70%" id="S2.E4.m1.5.5.1.1.3.3.cmml" xref="S2.E4.m1.5.5.1.1.3.3">simple</mtext></ci></apply><apply id="S2.E4.m1.5.5.1.1.1.cmml" xref="S2.E4.m1.5.5.1.1.1"><times id="S2.E4.m1.5.5.1.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.1.2"></times><apply id="S2.E4.m1.5.5.1.1.1.3.cmml" xref="S2.E4.m1.5.5.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.1.1.1.3.1.cmml" xref="S2.E4.m1.5.5.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.5.5.1.1.1.3.2.cmml" xref="S2.E4.m1.5.5.1.1.1.3.2">ùîº</ci><list id="S2.E4.m1.3.3.3.4.cmml" xref="S2.E4.m1.3.3.3.3"><ci id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1">ùë°</ci><apply id="S2.E4.m1.3.3.3.3.1.cmml" xref="S2.E4.m1.3.3.3.3.1"><csymbol cd="ambiguous" id="S2.E4.m1.3.3.3.3.1.1.cmml" xref="S2.E4.m1.3.3.3.3.1">subscript</csymbol><ci id="S2.E4.m1.3.3.3.3.1.2.cmml" xref="S2.E4.m1.3.3.3.3.1.2">ùê±</ci><cn type="integer" id="S2.E4.m1.3.3.3.3.1.3.cmml" xref="S2.E4.m1.3.3.3.3.1.3">0</cn></apply><ci id="S2.E4.m1.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2">italic-œµ</ci></list></apply><apply id="S2.E4.m1.5.5.1.1.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.5.5.1.1.1.1.2.1.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E4.m1.5.5.1.1.1.1.1.1.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E4.m1.5.5.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1"><minus id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.2"></minus><ci id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.3">italic-œµ</ci><apply id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1"><times id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.2">italic-œµ</ci><ci id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.3">ùúÉ</ci></apply><interval closure="open" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1"><apply id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ùê±</ci><ci id="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ùë°</ci></apply><ci id="S2.E4.m1.4.4.cmml" xref="S2.E4.m1.4.4">ùë°</ci></interval></apply></apply></apply><cn type="integer" id="S2.E4.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.5.5.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.5c">L_{\text{simple}}=\mathbb{E}_{t,\mathbf{x}_{0},\epsilon}\left[||\epsilon-\epsilon_{\theta}(\mathbf{x}_{t},t)||^{2}\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p11" class="ltx_para ltx_noindent">
<p id="S2.SS1.p11.1" class="ltx_p"><span id="S2.SS1.p11.1.1" class="ltx_text ltx_font_bold">Sampling from DDPMs.</span> Once trained, sampling from DDPMs involves running the reverse process starting from pure Gaussian noise <math id="S2.SS1.p11.1.m1.2" class="ltx_Math" alttext="\mathbf{x}_{T}\sim\mathcal{N}(0,\mathbf{I})" display="inline"><semantics id="S2.SS1.p11.1.m1.2a"><mrow id="S2.SS1.p11.1.m1.2.3" xref="S2.SS1.p11.1.m1.2.3.cmml"><msub id="S2.SS1.p11.1.m1.2.3.2" xref="S2.SS1.p11.1.m1.2.3.2.cmml"><mi id="S2.SS1.p11.1.m1.2.3.2.2" xref="S2.SS1.p11.1.m1.2.3.2.2.cmml">ùê±</mi><mi id="S2.SS1.p11.1.m1.2.3.2.3" xref="S2.SS1.p11.1.m1.2.3.2.3.cmml">T</mi></msub><mo id="S2.SS1.p11.1.m1.2.3.1" xref="S2.SS1.p11.1.m1.2.3.1.cmml">‚àº</mo><mrow id="S2.SS1.p11.1.m1.2.3.3" xref="S2.SS1.p11.1.m1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p11.1.m1.2.3.3.2" xref="S2.SS1.p11.1.m1.2.3.3.2.cmml">ùí©</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p11.1.m1.2.3.3.1" xref="S2.SS1.p11.1.m1.2.3.3.1.cmml">‚Äã</mo><mrow id="S2.SS1.p11.1.m1.2.3.3.3.2" xref="S2.SS1.p11.1.m1.2.3.3.3.1.cmml"><mo stretchy="false" id="S2.SS1.p11.1.m1.2.3.3.3.2.1" xref="S2.SS1.p11.1.m1.2.3.3.3.1.cmml">(</mo><mn id="S2.SS1.p11.1.m1.1.1" xref="S2.SS1.p11.1.m1.1.1.cmml">0</mn><mo id="S2.SS1.p11.1.m1.2.3.3.3.2.2" xref="S2.SS1.p11.1.m1.2.3.3.3.1.cmml">,</mo><mi id="S2.SS1.p11.1.m1.2.2" xref="S2.SS1.p11.1.m1.2.2.cmml">ùêà</mi><mo stretchy="false" id="S2.SS1.p11.1.m1.2.3.3.3.2.3" xref="S2.SS1.p11.1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p11.1.m1.2b"><apply id="S2.SS1.p11.1.m1.2.3.cmml" xref="S2.SS1.p11.1.m1.2.3"><csymbol cd="latexml" id="S2.SS1.p11.1.m1.2.3.1.cmml" xref="S2.SS1.p11.1.m1.2.3.1">similar-to</csymbol><apply id="S2.SS1.p11.1.m1.2.3.2.cmml" xref="S2.SS1.p11.1.m1.2.3.2"><csymbol cd="ambiguous" id="S2.SS1.p11.1.m1.2.3.2.1.cmml" xref="S2.SS1.p11.1.m1.2.3.2">subscript</csymbol><ci id="S2.SS1.p11.1.m1.2.3.2.2.cmml" xref="S2.SS1.p11.1.m1.2.3.2.2">ùê±</ci><ci id="S2.SS1.p11.1.m1.2.3.2.3.cmml" xref="S2.SS1.p11.1.m1.2.3.2.3">ùëá</ci></apply><apply id="S2.SS1.p11.1.m1.2.3.3.cmml" xref="S2.SS1.p11.1.m1.2.3.3"><times id="S2.SS1.p11.1.m1.2.3.3.1.cmml" xref="S2.SS1.p11.1.m1.2.3.3.1"></times><ci id="S2.SS1.p11.1.m1.2.3.3.2.cmml" xref="S2.SS1.p11.1.m1.2.3.3.2">ùí©</ci><interval closure="open" id="S2.SS1.p11.1.m1.2.3.3.3.1.cmml" xref="S2.SS1.p11.1.m1.2.3.3.3.2"><cn type="integer" id="S2.SS1.p11.1.m1.1.1.cmml" xref="S2.SS1.p11.1.m1.1.1">0</cn><ci id="S2.SS1.p11.1.m1.2.2.cmml" xref="S2.SS1.p11.1.m1.2.2">ùêà</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p11.1.m1.2c">\mathbf{x}_{T}\sim\mathcal{N}(0,\mathbf{I})</annotation></semantics></math> and iteratively applying the learned denoising steps:</p>
</div>
<div id="S2.SS1.p12" class="ltx_para ltx_noindent">
<table id="S2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E5.m1.3" class="ltx_Math" alttext="\mathbf{x}_{t-1}=\mu_{\theta}(\mathbf{x}_{t},t)+\Sigma_{\theta}(\mathbf{x}_{t},t)\cdot\mathbf{z}," display="block"><semantics id="S2.E5.m1.3a"><mrow id="S2.E5.m1.3.3.1" xref="S2.E5.m1.3.3.1.1.cmml"><mrow id="S2.E5.m1.3.3.1.1" xref="S2.E5.m1.3.3.1.1.cmml"><msub id="S2.E5.m1.3.3.1.1.4" xref="S2.E5.m1.3.3.1.1.4.cmml"><mi id="S2.E5.m1.3.3.1.1.4.2" xref="S2.E5.m1.3.3.1.1.4.2.cmml">ùê±</mi><mrow id="S2.E5.m1.3.3.1.1.4.3" xref="S2.E5.m1.3.3.1.1.4.3.cmml"><mi id="S2.E5.m1.3.3.1.1.4.3.2" xref="S2.E5.m1.3.3.1.1.4.3.2.cmml">t</mi><mo id="S2.E5.m1.3.3.1.1.4.3.1" xref="S2.E5.m1.3.3.1.1.4.3.1.cmml">‚àí</mo><mn id="S2.E5.m1.3.3.1.1.4.3.3" xref="S2.E5.m1.3.3.1.1.4.3.3.cmml">1</mn></mrow></msub><mo id="S2.E5.m1.3.3.1.1.3" xref="S2.E5.m1.3.3.1.1.3.cmml">=</mo><mrow id="S2.E5.m1.3.3.1.1.2" xref="S2.E5.m1.3.3.1.1.2.cmml"><mrow id="S2.E5.m1.3.3.1.1.1.1" xref="S2.E5.m1.3.3.1.1.1.1.cmml"><msub id="S2.E5.m1.3.3.1.1.1.1.3" xref="S2.E5.m1.3.3.1.1.1.1.3.cmml"><mi id="S2.E5.m1.3.3.1.1.1.1.3.2" xref="S2.E5.m1.3.3.1.1.1.1.3.2.cmml">Œº</mi><mi id="S2.E5.m1.3.3.1.1.1.1.3.3" xref="S2.E5.m1.3.3.1.1.1.1.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E5.m1.3.3.1.1.1.1.2" xref="S2.E5.m1.3.3.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E5.m1.3.3.1.1.1.1.1.1" xref="S2.E5.m1.3.3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E5.m1.3.3.1.1.1.1.1.1.2" xref="S2.E5.m1.3.3.1.1.1.1.1.2.cmml">(</mo><msub id="S2.E5.m1.3.3.1.1.1.1.1.1.1" xref="S2.E5.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S2.E5.m1.3.3.1.1.1.1.1.1.1.2" xref="S2.E5.m1.3.3.1.1.1.1.1.1.1.2.cmml">ùê±</mi><mi id="S2.E5.m1.3.3.1.1.1.1.1.1.1.3" xref="S2.E5.m1.3.3.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E5.m1.3.3.1.1.1.1.1.1.3" xref="S2.E5.m1.3.3.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E5.m1.1.1" xref="S2.E5.m1.1.1.cmml">t</mi><mo stretchy="false" id="S2.E5.m1.3.3.1.1.1.1.1.1.4" xref="S2.E5.m1.3.3.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E5.m1.3.3.1.1.2.3" xref="S2.E5.m1.3.3.1.1.2.3.cmml">+</mo><mrow id="S2.E5.m1.3.3.1.1.2.2" xref="S2.E5.m1.3.3.1.1.2.2.cmml"><mrow id="S2.E5.m1.3.3.1.1.2.2.1" xref="S2.E5.m1.3.3.1.1.2.2.1.cmml"><msub id="S2.E5.m1.3.3.1.1.2.2.1.3" xref="S2.E5.m1.3.3.1.1.2.2.1.3.cmml"><mi mathvariant="normal" id="S2.E5.m1.3.3.1.1.2.2.1.3.2" xref="S2.E5.m1.3.3.1.1.2.2.1.3.2.cmml">Œ£</mi><mi id="S2.E5.m1.3.3.1.1.2.2.1.3.3" xref="S2.E5.m1.3.3.1.1.2.2.1.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E5.m1.3.3.1.1.2.2.1.2" xref="S2.E5.m1.3.3.1.1.2.2.1.2.cmml">‚Äã</mo><mrow id="S2.E5.m1.3.3.1.1.2.2.1.1.1" xref="S2.E5.m1.3.3.1.1.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.E5.m1.3.3.1.1.2.2.1.1.1.2" xref="S2.E5.m1.3.3.1.1.2.2.1.1.2.cmml">(</mo><msub id="S2.E5.m1.3.3.1.1.2.2.1.1.1.1" xref="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.cmml"><mi id="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.2" xref="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.2.cmml">ùê±</mi><mi id="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.3" xref="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E5.m1.3.3.1.1.2.2.1.1.1.3" xref="S2.E5.m1.3.3.1.1.2.2.1.1.2.cmml">,</mo><mi id="S2.E5.m1.2.2" xref="S2.E5.m1.2.2.cmml">t</mi><mo rspace="0.055em" stretchy="false" id="S2.E5.m1.3.3.1.1.2.2.1.1.1.4" xref="S2.E5.m1.3.3.1.1.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S2.E5.m1.3.3.1.1.2.2.2" xref="S2.E5.m1.3.3.1.1.2.2.2.cmml">‚ãÖ</mo><mi id="S2.E5.m1.3.3.1.1.2.2.3" xref="S2.E5.m1.3.3.1.1.2.2.3.cmml">ùê≥</mi></mrow></mrow></mrow><mo id="S2.E5.m1.3.3.1.2" xref="S2.E5.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.3b"><apply id="S2.E5.m1.3.3.1.1.cmml" xref="S2.E5.m1.3.3.1"><eq id="S2.E5.m1.3.3.1.1.3.cmml" xref="S2.E5.m1.3.3.1.1.3"></eq><apply id="S2.E5.m1.3.3.1.1.4.cmml" xref="S2.E5.m1.3.3.1.1.4"><csymbol cd="ambiguous" id="S2.E5.m1.3.3.1.1.4.1.cmml" xref="S2.E5.m1.3.3.1.1.4">subscript</csymbol><ci id="S2.E5.m1.3.3.1.1.4.2.cmml" xref="S2.E5.m1.3.3.1.1.4.2">ùê±</ci><apply id="S2.E5.m1.3.3.1.1.4.3.cmml" xref="S2.E5.m1.3.3.1.1.4.3"><minus id="S2.E5.m1.3.3.1.1.4.3.1.cmml" xref="S2.E5.m1.3.3.1.1.4.3.1"></minus><ci id="S2.E5.m1.3.3.1.1.4.3.2.cmml" xref="S2.E5.m1.3.3.1.1.4.3.2">ùë°</ci><cn type="integer" id="S2.E5.m1.3.3.1.1.4.3.3.cmml" xref="S2.E5.m1.3.3.1.1.4.3.3">1</cn></apply></apply><apply id="S2.E5.m1.3.3.1.1.2.cmml" xref="S2.E5.m1.3.3.1.1.2"><plus id="S2.E5.m1.3.3.1.1.2.3.cmml" xref="S2.E5.m1.3.3.1.1.2.3"></plus><apply id="S2.E5.m1.3.3.1.1.1.1.cmml" xref="S2.E5.m1.3.3.1.1.1.1"><times id="S2.E5.m1.3.3.1.1.1.1.2.cmml" xref="S2.E5.m1.3.3.1.1.1.1.2"></times><apply id="S2.E5.m1.3.3.1.1.1.1.3.cmml" xref="S2.E5.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.3.3.1.1.1.1.3.1.cmml" xref="S2.E5.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S2.E5.m1.3.3.1.1.1.1.3.2.cmml" xref="S2.E5.m1.3.3.1.1.1.1.3.2">ùúá</ci><ci id="S2.E5.m1.3.3.1.1.1.1.3.3.cmml" xref="S2.E5.m1.3.3.1.1.1.1.3.3">ùúÉ</ci></apply><interval closure="open" id="S2.E5.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E5.m1.3.3.1.1.1.1.1.1"><apply id="S2.E5.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.E5.m1.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E5.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S2.E5.m1.3.3.1.1.1.1.1.1.1.2">ùê±</ci><ci id="S2.E5.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S2.E5.m1.3.3.1.1.1.1.1.1.1.3">ùë°</ci></apply><ci id="S2.E5.m1.1.1.cmml" xref="S2.E5.m1.1.1">ùë°</ci></interval></apply><apply id="S2.E5.m1.3.3.1.1.2.2.cmml" xref="S2.E5.m1.3.3.1.1.2.2"><ci id="S2.E5.m1.3.3.1.1.2.2.2.cmml" xref="S2.E5.m1.3.3.1.1.2.2.2">‚ãÖ</ci><apply id="S2.E5.m1.3.3.1.1.2.2.1.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1"><times id="S2.E5.m1.3.3.1.1.2.2.1.2.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.2"></times><apply id="S2.E5.m1.3.3.1.1.2.2.1.3.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.3"><csymbol cd="ambiguous" id="S2.E5.m1.3.3.1.1.2.2.1.3.1.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.3">subscript</csymbol><ci id="S2.E5.m1.3.3.1.1.2.2.1.3.2.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.3.2">Œ£</ci><ci id="S2.E5.m1.3.3.1.1.2.2.1.3.3.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.3.3">ùúÉ</ci></apply><interval closure="open" id="S2.E5.m1.3.3.1.1.2.2.1.1.2.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.1.1"><apply id="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.1.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.1.1.1">subscript</csymbol><ci id="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.2.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.2">ùê±</ci><ci id="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.3.cmml" xref="S2.E5.m1.3.3.1.1.2.2.1.1.1.1.3">ùë°</ci></apply><ci id="S2.E5.m1.2.2.cmml" xref="S2.E5.m1.2.2">ùë°</ci></interval></apply><ci id="S2.E5.m1.3.3.1.1.2.2.3.cmml" xref="S2.E5.m1.3.3.1.1.2.2.3">ùê≥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.3c">\mathbf{x}_{t-1}=\mu_{\theta}(\mathbf{x}_{t},t)+\Sigma_{\theta}(\mathbf{x}_{t},t)\cdot\mathbf{z},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>NCSNs</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p">Introduced by Song et al. (2019), NCSNs aim to generate data by estimating the gradients of the data distribution, known as Score Functions, at various noise levels¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.3" class="ltx_p"><span id="S2.SS2.p2.3.1" class="ltx_text ltx_font_bold">Forward Diffusion Process.</span> The forward diffusion process in NCSNs involves gradually perturbing the data with Gaussian noise of increasing intensity, similar to the procedure described for <a href="#S2.SS1" title="2.1 DDPMs ‚Ä£ 2 General Overview of DMs ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref ltx_font_bold">DDPMs</a>. Given an initial data point <math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{x}_{0}" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><msub id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><mi id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2.cmml">ùê±</mi><mn id="S2.SS2.p2.1.m1.1.1.3" xref="S2.SS2.p2.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.1.2">ùê±</ci><cn type="integer" id="S2.SS2.p2.1.m1.1.1.3.cmml" xref="S2.SS2.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">\mathbf{x}_{0}</annotation></semantics></math>, the data is progressively noised to generate a sequence of noisy data points <math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="\{\mathbf{x}_{t}\}" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mrow id="S2.SS2.p2.2.m2.1.1.1" xref="S2.SS2.p2.2.m2.1.1.2.cmml"><mo stretchy="false" id="S2.SS2.p2.2.m2.1.1.1.2" xref="S2.SS2.p2.2.m2.1.1.2.cmml">{</mo><msub id="S2.SS2.p2.2.m2.1.1.1.1" xref="S2.SS2.p2.2.m2.1.1.1.1.cmml"><mi id="S2.SS2.p2.2.m2.1.1.1.1.2" xref="S2.SS2.p2.2.m2.1.1.1.1.2.cmml">ùê±</mi><mi id="S2.SS2.p2.2.m2.1.1.1.1.3" xref="S2.SS2.p2.2.m2.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS2.p2.2.m2.1.1.1.3" xref="S2.SS2.p2.2.m2.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><set id="S2.SS2.p2.2.m2.1.1.2.cmml" xref="S2.SS2.p2.2.m2.1.1.1"><apply id="S2.SS2.p2.2.m2.1.1.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.2.m2.1.1.1.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p2.2.m2.1.1.1.1.2.cmml" xref="S2.SS2.p2.2.m2.1.1.1.1.2">ùê±</ci><ci id="S2.SS2.p2.2.m2.1.1.1.1.3.cmml" xref="S2.SS2.p2.2.m2.1.1.1.1.3">ùë°</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">\{\mathbf{x}_{t}\}</annotation></semantics></math> over <math id="S2.SS2.p2.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS2.p2.3.m3.1a"><mi id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><ci id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">T</annotation></semantics></math> timesteps.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.3" class="ltx_p"><span id="S2.SS2.p3.3.1" class="ltx_text ltx_font_bold">Learning the Score Function.</span> The core of NCSNs lies in learning the score function, which is the gradient of the log data density <math id="S2.SS2.p3.1.m1.1" class="ltx_Math" alttext="\nabla_{\mathbf{x}}\log p(\mathbf{x})" display="inline"><semantics id="S2.SS2.p3.1.m1.1a"><mrow id="S2.SS2.p3.1.m1.1.2" xref="S2.SS2.p3.1.m1.1.2.cmml"><mrow id="S2.SS2.p3.1.m1.1.2.2" xref="S2.SS2.p3.1.m1.1.2.2.cmml"><mrow id="S2.SS2.p3.1.m1.1.2.2.1" xref="S2.SS2.p3.1.m1.1.2.2.1.cmml"><msub id="S2.SS2.p3.1.m1.1.2.2.1.1" xref="S2.SS2.p3.1.m1.1.2.2.1.1.cmml"><mo id="S2.SS2.p3.1.m1.1.2.2.1.1.2" xref="S2.SS2.p3.1.m1.1.2.2.1.1.2.cmml">‚àá</mo><mi id="S2.SS2.p3.1.m1.1.2.2.1.1.3" xref="S2.SS2.p3.1.m1.1.2.2.1.1.3.cmml">ùê±</mi></msub><mi id="S2.SS2.p3.1.m1.1.2.2.1.2" xref="S2.SS2.p3.1.m1.1.2.2.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S2.SS2.p3.1.m1.1.2.2a" xref="S2.SS2.p3.1.m1.1.2.2.cmml">‚Å°</mo><mi id="S2.SS2.p3.1.m1.1.2.2.2" xref="S2.SS2.p3.1.m1.1.2.2.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S2.SS2.p3.1.m1.1.2.1" xref="S2.SS2.p3.1.m1.1.2.1.cmml">‚Äã</mo><mrow id="S2.SS2.p3.1.m1.1.2.3.2" xref="S2.SS2.p3.1.m1.1.2.cmml"><mo stretchy="false" id="S2.SS2.p3.1.m1.1.2.3.2.1" xref="S2.SS2.p3.1.m1.1.2.cmml">(</mo><mi id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">ùê±</mi><mo stretchy="false" id="S2.SS2.p3.1.m1.1.2.3.2.2" xref="S2.SS2.p3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.2"><times id="S2.SS2.p3.1.m1.1.2.1.cmml" xref="S2.SS2.p3.1.m1.1.2.1"></times><apply id="S2.SS2.p3.1.m1.1.2.2.cmml" xref="S2.SS2.p3.1.m1.1.2.2"><apply id="S2.SS2.p3.1.m1.1.2.2.1.cmml" xref="S2.SS2.p3.1.m1.1.2.2.1"><apply id="S2.SS2.p3.1.m1.1.2.2.1.1.cmml" xref="S2.SS2.p3.1.m1.1.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.1.m1.1.2.2.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.2.2.1.1">subscript</csymbol><ci id="S2.SS2.p3.1.m1.1.2.2.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.2.2.1.1.2">‚àá</ci><ci id="S2.SS2.p3.1.m1.1.2.2.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.2.2.1.1.3">ùê±</ci></apply><log id="S2.SS2.p3.1.m1.1.2.2.1.2.cmml" xref="S2.SS2.p3.1.m1.1.2.2.1.2"></log></apply><ci id="S2.SS2.p3.1.m1.1.2.2.2.cmml" xref="S2.SS2.p3.1.m1.1.2.2.2">ùëù</ci></apply><ci id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">ùê±</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">\nabla_{\mathbf{x}}\log p(\mathbf{x})</annotation></semantics></math>. However, instead of directly learning this for the original data distribution, NCSNs learn it for the perturbed data at various noise levels. An NN <math id="S2.SS2.p3.2.m2.2" class="ltx_Math" alttext="s_{\theta}(\mathbf{x},\sigma_{t})" display="inline"><semantics id="S2.SS2.p3.2.m2.2a"><mrow id="S2.SS2.p3.2.m2.2.2" xref="S2.SS2.p3.2.m2.2.2.cmml"><msub id="S2.SS2.p3.2.m2.2.2.3" xref="S2.SS2.p3.2.m2.2.2.3.cmml"><mi id="S2.SS2.p3.2.m2.2.2.3.2" xref="S2.SS2.p3.2.m2.2.2.3.2.cmml">s</mi><mi id="S2.SS2.p3.2.m2.2.2.3.3" xref="S2.SS2.p3.2.m2.2.2.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.p3.2.m2.2.2.2" xref="S2.SS2.p3.2.m2.2.2.2.cmml">‚Äã</mo><mrow id="S2.SS2.p3.2.m2.2.2.1.1" xref="S2.SS2.p3.2.m2.2.2.1.2.cmml"><mo stretchy="false" id="S2.SS2.p3.2.m2.2.2.1.1.2" xref="S2.SS2.p3.2.m2.2.2.1.2.cmml">(</mo><mi id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml">ùê±</mi><mo id="S2.SS2.p3.2.m2.2.2.1.1.3" xref="S2.SS2.p3.2.m2.2.2.1.2.cmml">,</mo><msub id="S2.SS2.p3.2.m2.2.2.1.1.1" xref="S2.SS2.p3.2.m2.2.2.1.1.1.cmml"><mi id="S2.SS2.p3.2.m2.2.2.1.1.1.2" xref="S2.SS2.p3.2.m2.2.2.1.1.1.2.cmml">œÉ</mi><mi id="S2.SS2.p3.2.m2.2.2.1.1.1.3" xref="S2.SS2.p3.2.m2.2.2.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS2.p3.2.m2.2.2.1.1.4" xref="S2.SS2.p3.2.m2.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.2b"><apply id="S2.SS2.p3.2.m2.2.2.cmml" xref="S2.SS2.p3.2.m2.2.2"><times id="S2.SS2.p3.2.m2.2.2.2.cmml" xref="S2.SS2.p3.2.m2.2.2.2"></times><apply id="S2.SS2.p3.2.m2.2.2.3.cmml" xref="S2.SS2.p3.2.m2.2.2.3"><csymbol cd="ambiguous" id="S2.SS2.p3.2.m2.2.2.3.1.cmml" xref="S2.SS2.p3.2.m2.2.2.3">subscript</csymbol><ci id="S2.SS2.p3.2.m2.2.2.3.2.cmml" xref="S2.SS2.p3.2.m2.2.2.3.2">ùë†</ci><ci id="S2.SS2.p3.2.m2.2.2.3.3.cmml" xref="S2.SS2.p3.2.m2.2.2.3.3">ùúÉ</ci></apply><interval closure="open" id="S2.SS2.p3.2.m2.2.2.1.2.cmml" xref="S2.SS2.p3.2.m2.2.2.1.1"><ci id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1">ùê±</ci><apply id="S2.SS2.p3.2.m2.2.2.1.1.1.cmml" xref="S2.SS2.p3.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS2.p3.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.p3.2.m2.2.2.1.1.1.2.cmml" xref="S2.SS2.p3.2.m2.2.2.1.1.1.2">ùúé</ci><ci id="S2.SS2.p3.2.m2.2.2.1.1.1.3.cmml" xref="S2.SS2.p3.2.m2.2.2.1.1.1.3">ùë°</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.2c">s_{\theta}(\mathbf{x},\sigma_{t})</annotation></semantics></math> is trained to approximate these score functions for different noise levels <math id="S2.SS2.p3.3.m3.1" class="ltx_Math" alttext="\sigma_{t}" display="inline"><semantics id="S2.SS2.p3.3.m3.1a"><msub id="S2.SS2.p3.3.m3.1.1" xref="S2.SS2.p3.3.m3.1.1.cmml"><mi id="S2.SS2.p3.3.m3.1.1.2" xref="S2.SS2.p3.3.m3.1.1.2.cmml">œÉ</mi><mi id="S2.SS2.p3.3.m3.1.1.3" xref="S2.SS2.p3.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.1b"><apply id="S2.SS2.p3.3.m3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m3.1.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p3.3.m3.1.1.2.cmml" xref="S2.SS2.p3.3.m3.1.1.2">ùúé</ci><ci id="S2.SS2.p3.3.m3.1.1.3.cmml" xref="S2.SS2.p3.3.m3.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.1c">\sigma_{t}</annotation></semantics></math>:</p>
</div>
<div id="S2.SS2.p4" class="ltx_para ltx_noindent">
<table id="S2.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E6.m1.3" class="ltx_Math" alttext="s_{\theta}(\mathbf{x},\sigma_{t})\approx\nabla_{\mathbf{x}}\log p_{\sigma}(\mathbf{x})," display="block"><semantics id="S2.E6.m1.3a"><mrow id="S2.E6.m1.3.3.1" xref="S2.E6.m1.3.3.1.1.cmml"><mrow id="S2.E6.m1.3.3.1.1" xref="S2.E6.m1.3.3.1.1.cmml"><mrow id="S2.E6.m1.3.3.1.1.1" xref="S2.E6.m1.3.3.1.1.1.cmml"><msub id="S2.E6.m1.3.3.1.1.1.3" xref="S2.E6.m1.3.3.1.1.1.3.cmml"><mi id="S2.E6.m1.3.3.1.1.1.3.2" xref="S2.E6.m1.3.3.1.1.1.3.2.cmml">s</mi><mi id="S2.E6.m1.3.3.1.1.1.3.3" xref="S2.E6.m1.3.3.1.1.1.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E6.m1.3.3.1.1.1.2" xref="S2.E6.m1.3.3.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E6.m1.3.3.1.1.1.1.1" xref="S2.E6.m1.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E6.m1.3.3.1.1.1.1.1.2" xref="S2.E6.m1.3.3.1.1.1.1.2.cmml">(</mo><mi id="S2.E6.m1.1.1" xref="S2.E6.m1.1.1.cmml">ùê±</mi><mo id="S2.E6.m1.3.3.1.1.1.1.1.3" xref="S2.E6.m1.3.3.1.1.1.1.2.cmml">,</mo><msub id="S2.E6.m1.3.3.1.1.1.1.1.1" xref="S2.E6.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S2.E6.m1.3.3.1.1.1.1.1.1.2" xref="S2.E6.m1.3.3.1.1.1.1.1.1.2.cmml">œÉ</mi><mi id="S2.E6.m1.3.3.1.1.1.1.1.1.3" xref="S2.E6.m1.3.3.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.E6.m1.3.3.1.1.1.1.1.4" xref="S2.E6.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E6.m1.3.3.1.1.2" xref="S2.E6.m1.3.3.1.1.2.cmml">‚âà</mo><mrow id="S2.E6.m1.3.3.1.1.3" xref="S2.E6.m1.3.3.1.1.3.cmml"><mrow id="S2.E6.m1.3.3.1.1.3.2" xref="S2.E6.m1.3.3.1.1.3.2.cmml"><mrow id="S2.E6.m1.3.3.1.1.3.2.1" xref="S2.E6.m1.3.3.1.1.3.2.1.cmml"><msub id="S2.E6.m1.3.3.1.1.3.2.1.1" xref="S2.E6.m1.3.3.1.1.3.2.1.1.cmml"><mo rspace="0.167em" id="S2.E6.m1.3.3.1.1.3.2.1.1.2" xref="S2.E6.m1.3.3.1.1.3.2.1.1.2.cmml">‚àá</mo><mi id="S2.E6.m1.3.3.1.1.3.2.1.1.3" xref="S2.E6.m1.3.3.1.1.3.2.1.1.3.cmml">ùê±</mi></msub><mi id="S2.E6.m1.3.3.1.1.3.2.1.2" xref="S2.E6.m1.3.3.1.1.3.2.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S2.E6.m1.3.3.1.1.3.2a" xref="S2.E6.m1.3.3.1.1.3.2.cmml">‚Å°</mo><msub id="S2.E6.m1.3.3.1.1.3.2.2" xref="S2.E6.m1.3.3.1.1.3.2.2.cmml"><mi id="S2.E6.m1.3.3.1.1.3.2.2.2" xref="S2.E6.m1.3.3.1.1.3.2.2.2.cmml">p</mi><mi id="S2.E6.m1.3.3.1.1.3.2.2.3" xref="S2.E6.m1.3.3.1.1.3.2.2.3.cmml">œÉ</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S2.E6.m1.3.3.1.1.3.1" xref="S2.E6.m1.3.3.1.1.3.1.cmml">‚Äã</mo><mrow id="S2.E6.m1.3.3.1.1.3.3.2" xref="S2.E6.m1.3.3.1.1.3.cmml"><mo stretchy="false" id="S2.E6.m1.3.3.1.1.3.3.2.1" xref="S2.E6.m1.3.3.1.1.3.cmml">(</mo><mi id="S2.E6.m1.2.2" xref="S2.E6.m1.2.2.cmml">ùê±</mi><mo stretchy="false" id="S2.E6.m1.3.3.1.1.3.3.2.2" xref="S2.E6.m1.3.3.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E6.m1.3.3.1.2" xref="S2.E6.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m1.3b"><apply id="S2.E6.m1.3.3.1.1.cmml" xref="S2.E6.m1.3.3.1"><approx id="S2.E6.m1.3.3.1.1.2.cmml" xref="S2.E6.m1.3.3.1.1.2"></approx><apply id="S2.E6.m1.3.3.1.1.1.cmml" xref="S2.E6.m1.3.3.1.1.1"><times id="S2.E6.m1.3.3.1.1.1.2.cmml" xref="S2.E6.m1.3.3.1.1.1.2"></times><apply id="S2.E6.m1.3.3.1.1.1.3.cmml" xref="S2.E6.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S2.E6.m1.3.3.1.1.1.3.1.cmml" xref="S2.E6.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S2.E6.m1.3.3.1.1.1.3.2.cmml" xref="S2.E6.m1.3.3.1.1.1.3.2">ùë†</ci><ci id="S2.E6.m1.3.3.1.1.1.3.3.cmml" xref="S2.E6.m1.3.3.1.1.1.3.3">ùúÉ</ci></apply><interval closure="open" id="S2.E6.m1.3.3.1.1.1.1.2.cmml" xref="S2.E6.m1.3.3.1.1.1.1.1"><ci id="S2.E6.m1.1.1.cmml" xref="S2.E6.m1.1.1">ùê±</ci><apply id="S2.E6.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E6.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E6.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S2.E6.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E6.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E6.m1.3.3.1.1.1.1.1.1.2">ùúé</ci><ci id="S2.E6.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S2.E6.m1.3.3.1.1.1.1.1.1.3">ùë°</ci></apply></interval></apply><apply id="S2.E6.m1.3.3.1.1.3.cmml" xref="S2.E6.m1.3.3.1.1.3"><times id="S2.E6.m1.3.3.1.1.3.1.cmml" xref="S2.E6.m1.3.3.1.1.3.1"></times><apply id="S2.E6.m1.3.3.1.1.3.2.cmml" xref="S2.E6.m1.3.3.1.1.3.2"><apply id="S2.E6.m1.3.3.1.1.3.2.1.cmml" xref="S2.E6.m1.3.3.1.1.3.2.1"><apply id="S2.E6.m1.3.3.1.1.3.2.1.1.cmml" xref="S2.E6.m1.3.3.1.1.3.2.1.1"><csymbol cd="ambiguous" id="S2.E6.m1.3.3.1.1.3.2.1.1.1.cmml" xref="S2.E6.m1.3.3.1.1.3.2.1.1">subscript</csymbol><ci id="S2.E6.m1.3.3.1.1.3.2.1.1.2.cmml" xref="S2.E6.m1.3.3.1.1.3.2.1.1.2">‚àá</ci><ci id="S2.E6.m1.3.3.1.1.3.2.1.1.3.cmml" xref="S2.E6.m1.3.3.1.1.3.2.1.1.3">ùê±</ci></apply><log id="S2.E6.m1.3.3.1.1.3.2.1.2.cmml" xref="S2.E6.m1.3.3.1.1.3.2.1.2"></log></apply><apply id="S2.E6.m1.3.3.1.1.3.2.2.cmml" xref="S2.E6.m1.3.3.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E6.m1.3.3.1.1.3.2.2.1.cmml" xref="S2.E6.m1.3.3.1.1.3.2.2">subscript</csymbol><ci id="S2.E6.m1.3.3.1.1.3.2.2.2.cmml" xref="S2.E6.m1.3.3.1.1.3.2.2.2">ùëù</ci><ci id="S2.E6.m1.3.3.1.1.3.2.2.3.cmml" xref="S2.E6.m1.3.3.1.1.3.2.2.3">ùúé</ci></apply></apply><ci id="S2.E6.m1.2.2.cmml" xref="S2.E6.m1.2.2">ùê±</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.3c">s_{\theta}(\mathbf{x},\sigma_{t})\approx\nabla_{\mathbf{x}}\log p_{\sigma}(\mathbf{x}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p5" class="ltx_para ltx_noindent">
<p id="S2.SS2.p5.1" class="ltx_p"><span id="S2.SS2.p5.1.1" class="ltx_text ltx_font_bold">Training Objective.</span> The training objective for NCSNs involves minimizing a denoising score matching objective, which encourages the NN to accurately predict the score function. This loss function can be expressed as:</p>
</div>
<div id="S2.SS2.p6" class="ltx_para ltx_noindent">
<table id="S2.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E7.m1.6" class="ltx_Math" alttext="L_{\text{ncsn}}=\mathbb{E}_{\mathbf{x}_{0},\mathbf{\epsilon},\sigma}\left[\lambda(\sigma)||s_{\theta}(\mathbf{x}_{0}+\sigma\mathbf{\epsilon},\sigma)-\frac{\mathbf{\epsilon}}{\sigma}||^{2}\right]," display="block"><semantics id="S2.E7.m1.6a"><mrow id="S2.E7.m1.6.6.1" xref="S2.E7.m1.6.6.1.1.cmml"><mrow id="S2.E7.m1.6.6.1.1" xref="S2.E7.m1.6.6.1.1.cmml"><msub id="S2.E7.m1.6.6.1.1.3" xref="S2.E7.m1.6.6.1.1.3.cmml"><mi id="S2.E7.m1.6.6.1.1.3.2" xref="S2.E7.m1.6.6.1.1.3.2.cmml">L</mi><mtext id="S2.E7.m1.6.6.1.1.3.3" xref="S2.E7.m1.6.6.1.1.3.3a.cmml">ncsn</mtext></msub><mo id="S2.E7.m1.6.6.1.1.2" xref="S2.E7.m1.6.6.1.1.2.cmml">=</mo><mrow id="S2.E7.m1.6.6.1.1.1" xref="S2.E7.m1.6.6.1.1.1.cmml"><msub id="S2.E7.m1.6.6.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.3.cmml"><mi id="S2.E7.m1.6.6.1.1.1.3.2" xref="S2.E7.m1.6.6.1.1.1.3.2.cmml">ùîº</mi><mrow id="S2.E7.m1.3.3.3.3" xref="S2.E7.m1.3.3.3.4.cmml"><msub id="S2.E7.m1.3.3.3.3.1" xref="S2.E7.m1.3.3.3.3.1.cmml"><mi id="S2.E7.m1.3.3.3.3.1.2" xref="S2.E7.m1.3.3.3.3.1.2.cmml">ùê±</mi><mn id="S2.E7.m1.3.3.3.3.1.3" xref="S2.E7.m1.3.3.3.3.1.3.cmml">0</mn></msub><mo id="S2.E7.m1.3.3.3.3.2" xref="S2.E7.m1.3.3.3.4.cmml">,</mo><mi id="S2.E7.m1.1.1.1.1" xref="S2.E7.m1.1.1.1.1.cmml">œµ</mi><mo id="S2.E7.m1.3.3.3.3.3" xref="S2.E7.m1.3.3.3.4.cmml">,</mo><mi id="S2.E7.m1.2.2.2.2" xref="S2.E7.m1.2.2.2.2.cmml">œÉ</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E7.m1.6.6.1.1.1.2" xref="S2.E7.m1.6.6.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E7.m1.6.6.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.2.cmml"><mo id="S2.E7.m1.6.6.1.1.1.1.1.2" xref="S2.E7.m1.6.6.1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E7.m1.6.6.1.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.cmml"><mi id="S2.E7.m1.6.6.1.1.1.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.3.cmml">Œª</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.6.6.1.1.1.1.1.1.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E7.m1.6.6.1.1.1.1.1.1.4.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E7.m1.6.6.1.1.1.1.1.1.4.2.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.cmml">(</mo><mi id="S2.E7.m1.4.4" xref="S2.E7.m1.4.4.cmml">œÉ</mi><mo stretchy="false" id="S2.E7.m1.6.6.1.1.1.1.1.1.4.2.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E7.m1.6.6.1.1.1.1.1.1.2a" xref="S2.E7.m1.6.6.1.1.1.1.1.1.2.cmml">‚Äã</mo><msup id="S2.E7.m1.6.6.1.1.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.cmml"><mrow id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml">‚Äñ</mo><mrow id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">s</mi><mi id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">ùê±</mi><mn id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">0</mn></msub><mo id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">œÉ</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">‚Äã</mo><mi id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">œµ</mi></mrow></mrow><mo id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E7.m1.5.5" xref="S2.E7.m1.5.5.cmml">œÉ</mi><mo stretchy="false" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.4" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.cmml">‚àí</mo><mfrac id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.2.cmml">œµ</mi><mi id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.3.cmml">œÉ</mi></mfrac></mrow><mo stretchy="false" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml">‚Äñ</mo></mrow><mn id="S2.E7.m1.6.6.1.1.1.1.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.3.cmml">2</mn></msup></mrow><mo id="S2.E7.m1.6.6.1.1.1.1.1.3" xref="S2.E7.m1.6.6.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S2.E7.m1.6.6.1.2" xref="S2.E7.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E7.m1.6b"><apply id="S2.E7.m1.6.6.1.1.cmml" xref="S2.E7.m1.6.6.1"><eq id="S2.E7.m1.6.6.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.2"></eq><apply id="S2.E7.m1.6.6.1.1.3.cmml" xref="S2.E7.m1.6.6.1.1.3"><csymbol cd="ambiguous" id="S2.E7.m1.6.6.1.1.3.1.cmml" xref="S2.E7.m1.6.6.1.1.3">subscript</csymbol><ci id="S2.E7.m1.6.6.1.1.3.2.cmml" xref="S2.E7.m1.6.6.1.1.3.2">ùêø</ci><ci id="S2.E7.m1.6.6.1.1.3.3a.cmml" xref="S2.E7.m1.6.6.1.1.3.3"><mtext mathsize="70%" id="S2.E7.m1.6.6.1.1.3.3.cmml" xref="S2.E7.m1.6.6.1.1.3.3">ncsn</mtext></ci></apply><apply id="S2.E7.m1.6.6.1.1.1.cmml" xref="S2.E7.m1.6.6.1.1.1"><times id="S2.E7.m1.6.6.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.2"></times><apply id="S2.E7.m1.6.6.1.1.1.3.cmml" xref="S2.E7.m1.6.6.1.1.1.3"><csymbol cd="ambiguous" id="S2.E7.m1.6.6.1.1.1.3.1.cmml" xref="S2.E7.m1.6.6.1.1.1.3">subscript</csymbol><ci id="S2.E7.m1.6.6.1.1.1.3.2.cmml" xref="S2.E7.m1.6.6.1.1.1.3.2">ùîº</ci><list id="S2.E7.m1.3.3.3.4.cmml" xref="S2.E7.m1.3.3.3.3"><apply id="S2.E7.m1.3.3.3.3.1.cmml" xref="S2.E7.m1.3.3.3.3.1"><csymbol cd="ambiguous" id="S2.E7.m1.3.3.3.3.1.1.cmml" xref="S2.E7.m1.3.3.3.3.1">subscript</csymbol><ci id="S2.E7.m1.3.3.3.3.1.2.cmml" xref="S2.E7.m1.3.3.3.3.1.2">ùê±</ci><cn type="integer" id="S2.E7.m1.3.3.3.3.1.3.cmml" xref="S2.E7.m1.3.3.3.3.1.3">0</cn></apply><ci id="S2.E7.m1.1.1.1.1.cmml" xref="S2.E7.m1.1.1.1.1">italic-œµ</ci><ci id="S2.E7.m1.2.2.2.2.cmml" xref="S2.E7.m1.2.2.2.2">ùúé</ci></list></apply><apply id="S2.E7.m1.6.6.1.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1"><csymbol cd="latexml" id="S2.E7.m1.6.6.1.1.1.1.2.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1"><times id="S2.E7.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.2"></times><ci id="S2.E7.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.3">ùúÜ</ci><ci id="S2.E7.m1.4.4.cmml" xref="S2.E7.m1.4.4">ùúé</ci><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1"><minus id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.2"></minus><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1"><times id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.2">ùë†</ci><ci id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.3">ùúÉ</ci></apply><interval closure="open" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1"><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><plus id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">ùê±</ci><cn type="integer" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">0</cn></apply><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><times id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">ùúé</ci><ci id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">italic-œµ</ci></apply></apply><ci id="S2.E7.m1.5.5.cmml" xref="S2.E7.m1.5.5">ùúé</ci></interval></apply><apply id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3"><divide id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3"></divide><ci id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.2">italic-œµ</ci><ci id="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.3">ùúé</ci></apply></apply></apply><cn type="integer" id="S2.E7.m1.6.6.1.1.1.1.1.1.1.3.cmml" xref="S2.E7.m1.6.6.1.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m1.6c">L_{\text{ncsn}}=\mathbb{E}_{\mathbf{x}_{0},\mathbf{\epsilon},\sigma}\left[\lambda(\sigma)||s_{\theta}(\mathbf{x}_{0}+\sigma\mathbf{\epsilon},\sigma)-\frac{\mathbf{\epsilon}}{\sigma}||^{2}\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p7" class="ltx_para ltx_noindent">
<p id="S2.SS2.p7.1" class="ltx_p"><span id="S2.SS2.p7.1.1" class="ltx_text ltx_font_bold">Sampling from NCSNs.</span> Sampling from NCSNs involves using the learned score function to iteratively denoise a sample of
pure Gaussian noise. This is typically done using Langevin dynamics, a method that iteratively refines the noisy sample by adding the score function and some additional noise:</p>
</div>
<div id="S2.SS2.p8" class="ltx_para ltx_noindent">
<table id="S2.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E8.m1.3" class="ltx_Math" alttext="\mathbf{x}_{t+1}=\mathbf{x}_{t}+\frac{\alpha}{2}s_{\theta}(\mathbf{x}_{t},\sigma_{t})+\sqrt{\alpha}\mathbf{z},\quad\mathbf{z}\sim\mathcal{N}(0,\mathbf{I})," display="block"><semantics id="S2.E8.m1.3a"><mrow id="S2.E8.m1.3.3.1"><mrow id="S2.E8.m1.3.3.1.1.2" xref="S2.E8.m1.3.3.1.1.3.cmml"><mrow id="S2.E8.m1.3.3.1.1.1.1" xref="S2.E8.m1.3.3.1.1.1.1.cmml"><msub id="S2.E8.m1.3.3.1.1.1.1.4" xref="S2.E8.m1.3.3.1.1.1.1.4.cmml"><mi id="S2.E8.m1.3.3.1.1.1.1.4.2" xref="S2.E8.m1.3.3.1.1.1.1.4.2.cmml">ùê±</mi><mrow id="S2.E8.m1.3.3.1.1.1.1.4.3" xref="S2.E8.m1.3.3.1.1.1.1.4.3.cmml"><mi id="S2.E8.m1.3.3.1.1.1.1.4.3.2" xref="S2.E8.m1.3.3.1.1.1.1.4.3.2.cmml">t</mi><mo id="S2.E8.m1.3.3.1.1.1.1.4.3.1" xref="S2.E8.m1.3.3.1.1.1.1.4.3.1.cmml">+</mo><mn id="S2.E8.m1.3.3.1.1.1.1.4.3.3" xref="S2.E8.m1.3.3.1.1.1.1.4.3.3.cmml">1</mn></mrow></msub><mo id="S2.E8.m1.3.3.1.1.1.1.3" xref="S2.E8.m1.3.3.1.1.1.1.3.cmml">=</mo><mrow id="S2.E8.m1.3.3.1.1.1.1.2" xref="S2.E8.m1.3.3.1.1.1.1.2.cmml"><msub id="S2.E8.m1.3.3.1.1.1.1.2.4" xref="S2.E8.m1.3.3.1.1.1.1.2.4.cmml"><mi id="S2.E8.m1.3.3.1.1.1.1.2.4.2" xref="S2.E8.m1.3.3.1.1.1.1.2.4.2.cmml">ùê±</mi><mi id="S2.E8.m1.3.3.1.1.1.1.2.4.3" xref="S2.E8.m1.3.3.1.1.1.1.2.4.3.cmml">t</mi></msub><mo id="S2.E8.m1.3.3.1.1.1.1.2.3" xref="S2.E8.m1.3.3.1.1.1.1.2.3.cmml">+</mo><mrow id="S2.E8.m1.3.3.1.1.1.1.2.2" xref="S2.E8.m1.3.3.1.1.1.1.2.2.cmml"><mfrac id="S2.E8.m1.3.3.1.1.1.1.2.2.4" xref="S2.E8.m1.3.3.1.1.1.1.2.2.4.cmml"><mi id="S2.E8.m1.3.3.1.1.1.1.2.2.4.2" xref="S2.E8.m1.3.3.1.1.1.1.2.2.4.2.cmml">Œ±</mi><mn id="S2.E8.m1.3.3.1.1.1.1.2.2.4.3" xref="S2.E8.m1.3.3.1.1.1.1.2.2.4.3.cmml">2</mn></mfrac><mo lspace="0em" rspace="0em" id="S2.E8.m1.3.3.1.1.1.1.2.2.3" xref="S2.E8.m1.3.3.1.1.1.1.2.2.3.cmml">‚Äã</mo><msub id="S2.E8.m1.3.3.1.1.1.1.2.2.5" xref="S2.E8.m1.3.3.1.1.1.1.2.2.5.cmml"><mi id="S2.E8.m1.3.3.1.1.1.1.2.2.5.2" xref="S2.E8.m1.3.3.1.1.1.1.2.2.5.2.cmml">s</mi><mi id="S2.E8.m1.3.3.1.1.1.1.2.2.5.3" xref="S2.E8.m1.3.3.1.1.1.1.2.2.5.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S2.E8.m1.3.3.1.1.1.1.2.2.3a" xref="S2.E8.m1.3.3.1.1.1.1.2.2.3.cmml">‚Äã</mo><mrow id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.3.cmml"><mo stretchy="false" id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.3" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.3.cmml">(</mo><msub id="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">ùê±</mi><mi id="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.4" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.3.cmml">,</mo><msub id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.cmml"><mi id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.2" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.2.cmml">œÉ</mi><mi id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.3" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.5" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E8.m1.3.3.1.1.1.1.2.3a" xref="S2.E8.m1.3.3.1.1.1.1.2.3.cmml">+</mo><mrow id="S2.E8.m1.3.3.1.1.1.1.2.5" xref="S2.E8.m1.3.3.1.1.1.1.2.5.cmml"><msqrt id="S2.E8.m1.3.3.1.1.1.1.2.5.2" xref="S2.E8.m1.3.3.1.1.1.1.2.5.2.cmml"><mi id="S2.E8.m1.3.3.1.1.1.1.2.5.2.2" xref="S2.E8.m1.3.3.1.1.1.1.2.5.2.2.cmml">Œ±</mi></msqrt><mo lspace="0em" rspace="0em" id="S2.E8.m1.3.3.1.1.1.1.2.5.1" xref="S2.E8.m1.3.3.1.1.1.1.2.5.1.cmml">‚Äã</mo><mi id="S2.E8.m1.3.3.1.1.1.1.2.5.3" xref="S2.E8.m1.3.3.1.1.1.1.2.5.3.cmml">ùê≥</mi></mrow></mrow></mrow><mo rspace="1.167em" id="S2.E8.m1.3.3.1.1.2.3" xref="S2.E8.m1.3.3.1.1.3a.cmml">,</mo><mrow id="S2.E8.m1.3.3.1.1.2.2" xref="S2.E8.m1.3.3.1.1.2.2.cmml"><mi id="S2.E8.m1.3.3.1.1.2.2.2" xref="S2.E8.m1.3.3.1.1.2.2.2.cmml">ùê≥</mi><mo id="S2.E8.m1.3.3.1.1.2.2.1" xref="S2.E8.m1.3.3.1.1.2.2.1.cmml">‚àº</mo><mrow id="S2.E8.m1.3.3.1.1.2.2.3" xref="S2.E8.m1.3.3.1.1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E8.m1.3.3.1.1.2.2.3.2" xref="S2.E8.m1.3.3.1.1.2.2.3.2.cmml">ùí©</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.3.3.1.1.2.2.3.1" xref="S2.E8.m1.3.3.1.1.2.2.3.1.cmml">‚Äã</mo><mrow id="S2.E8.m1.3.3.1.1.2.2.3.3.2" xref="S2.E8.m1.3.3.1.1.2.2.3.3.1.cmml"><mo stretchy="false" id="S2.E8.m1.3.3.1.1.2.2.3.3.2.1" xref="S2.E8.m1.3.3.1.1.2.2.3.3.1.cmml">(</mo><mn id="S2.E8.m1.1.1" xref="S2.E8.m1.1.1.cmml">0</mn><mo id="S2.E8.m1.3.3.1.1.2.2.3.3.2.2" xref="S2.E8.m1.3.3.1.1.2.2.3.3.1.cmml">,</mo><mi id="S2.E8.m1.2.2" xref="S2.E8.m1.2.2.cmml">ùêà</mi><mo stretchy="false" id="S2.E8.m1.3.3.1.1.2.2.3.3.2.3" xref="S2.E8.m1.3.3.1.1.2.2.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E8.m1.3.3.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E8.m1.3b"><apply id="S2.E8.m1.3.3.1.1.3.cmml" xref="S2.E8.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.E8.m1.3.3.1.1.3a.cmml" xref="S2.E8.m1.3.3.1.1.2.3">formulae-sequence</csymbol><apply id="S2.E8.m1.3.3.1.1.1.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1"><eq id="S2.E8.m1.3.3.1.1.1.1.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.3"></eq><apply id="S2.E8.m1.3.3.1.1.1.1.4.cmml" xref="S2.E8.m1.3.3.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E8.m1.3.3.1.1.1.1.4.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.4">subscript</csymbol><ci id="S2.E8.m1.3.3.1.1.1.1.4.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.4.2">ùê±</ci><apply id="S2.E8.m1.3.3.1.1.1.1.4.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.4.3"><plus id="S2.E8.m1.3.3.1.1.1.1.4.3.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.4.3.1"></plus><ci id="S2.E8.m1.3.3.1.1.1.1.4.3.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.4.3.2">ùë°</ci><cn type="integer" id="S2.E8.m1.3.3.1.1.1.1.4.3.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.4.3.3">1</cn></apply></apply><apply id="S2.E8.m1.3.3.1.1.1.1.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2"><plus id="S2.E8.m1.3.3.1.1.1.1.2.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.3"></plus><apply id="S2.E8.m1.3.3.1.1.1.1.2.4.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S2.E8.m1.3.3.1.1.1.1.2.4.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.4">subscript</csymbol><ci id="S2.E8.m1.3.3.1.1.1.1.2.4.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.4.2">ùê±</ci><ci id="S2.E8.m1.3.3.1.1.1.1.2.4.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.4.3">ùë°</ci></apply><apply id="S2.E8.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2"><times id="S2.E8.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.3"></times><apply id="S2.E8.m1.3.3.1.1.1.1.2.2.4.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.4"><divide id="S2.E8.m1.3.3.1.1.1.1.2.2.4.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.4"></divide><ci id="S2.E8.m1.3.3.1.1.1.1.2.2.4.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.4.2">ùõº</ci><cn type="integer" id="S2.E8.m1.3.3.1.1.1.1.2.2.4.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.4.3">2</cn></apply><apply id="S2.E8.m1.3.3.1.1.1.1.2.2.5.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.5"><csymbol cd="ambiguous" id="S2.E8.m1.3.3.1.1.1.1.2.2.5.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.5">subscript</csymbol><ci id="S2.E8.m1.3.3.1.1.1.1.2.2.5.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.5.2">ùë†</ci><ci id="S2.E8.m1.3.3.1.1.1.1.2.2.5.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.5.3">ùúÉ</ci></apply><interval closure="open" id="S2.E8.m1.3.3.1.1.1.1.2.2.2.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.2"><apply id="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.2">ùê±</ci><ci id="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.1.1.1.1.1.3">ùë°</ci></apply><apply id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2">subscript</csymbol><ci id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.2">ùúé</ci><ci id="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.2.2.2.2.3">ùë°</ci></apply></interval></apply><apply id="S2.E8.m1.3.3.1.1.1.1.2.5.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.5"><times id="S2.E8.m1.3.3.1.1.1.1.2.5.1.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.5.1"></times><apply id="S2.E8.m1.3.3.1.1.1.1.2.5.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.5.2"><root id="S2.E8.m1.3.3.1.1.1.1.2.5.2a.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.5.2"></root><ci id="S2.E8.m1.3.3.1.1.1.1.2.5.2.2.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.5.2.2">ùõº</ci></apply><ci id="S2.E8.m1.3.3.1.1.1.1.2.5.3.cmml" xref="S2.E8.m1.3.3.1.1.1.1.2.5.3">ùê≥</ci></apply></apply></apply><apply id="S2.E8.m1.3.3.1.1.2.2.cmml" xref="S2.E8.m1.3.3.1.1.2.2"><csymbol cd="latexml" id="S2.E8.m1.3.3.1.1.2.2.1.cmml" xref="S2.E8.m1.3.3.1.1.2.2.1">similar-to</csymbol><ci id="S2.E8.m1.3.3.1.1.2.2.2.cmml" xref="S2.E8.m1.3.3.1.1.2.2.2">ùê≥</ci><apply id="S2.E8.m1.3.3.1.1.2.2.3.cmml" xref="S2.E8.m1.3.3.1.1.2.2.3"><times id="S2.E8.m1.3.3.1.1.2.2.3.1.cmml" xref="S2.E8.m1.3.3.1.1.2.2.3.1"></times><ci id="S2.E8.m1.3.3.1.1.2.2.3.2.cmml" xref="S2.E8.m1.3.3.1.1.2.2.3.2">ùí©</ci><interval closure="open" id="S2.E8.m1.3.3.1.1.2.2.3.3.1.cmml" xref="S2.E8.m1.3.3.1.1.2.2.3.3.2"><cn type="integer" id="S2.E8.m1.1.1.cmml" xref="S2.E8.m1.1.1">0</cn><ci id="S2.E8.m1.2.2.cmml" xref="S2.E8.m1.2.2">ùêà</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E8.m1.3c">\mathbf{x}_{t+1}=\mathbf{x}_{t}+\frac{\alpha}{2}s_{\theta}(\mathbf{x}_{t},\sigma_{t})+\sqrt{\alpha}\mathbf{z},\quad\mathbf{z}\sim\mathcal{N}(0,\mathbf{I}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>SDEs</h3>

<div id="S2.SS3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS3.p1.1" class="ltx_p">Introduced by Song et al. (2020), SDEs leverage the mathematical framework of SDE to model the data generation process through continuous noise perturbations and denoising¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.p2.1" class="ltx_p"><span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold">Forward Diffusion Process.</span> In the SDE framework, the forward diffusion process involves transforming the data into a noise distribution through a continuous-time stochastic process, similar to the procedure described for <a href="#S2.SS1" title="2.1 DDPMs ‚Ä£ 2 General Overview of DMs ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref ltx_font_bold">DDPMs</a>. This is typically modeled by an It√¥ SDE:</p>
</div>
<div id="S2.SS3.p3" class="ltx_para ltx_noindent">
<table id="S2.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E9.m1.4" class="ltx_Math" alttext="d\mathbf{x}=f(\mathbf{x},t)dt+g(t)d\mathbf{w}," display="block"><semantics id="S2.E9.m1.4a"><mrow id="S2.E9.m1.4.4.1" xref="S2.E9.m1.4.4.1.1.cmml"><mrow id="S2.E9.m1.4.4.1.1" xref="S2.E9.m1.4.4.1.1.cmml"><mrow id="S2.E9.m1.4.4.1.1.2" xref="S2.E9.m1.4.4.1.1.2.cmml"><mi id="S2.E9.m1.4.4.1.1.2.2" xref="S2.E9.m1.4.4.1.1.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.1.1.2.1" xref="S2.E9.m1.4.4.1.1.2.1.cmml">‚Äã</mo><mi id="S2.E9.m1.4.4.1.1.2.3" xref="S2.E9.m1.4.4.1.1.2.3.cmml">ùê±</mi></mrow><mo id="S2.E9.m1.4.4.1.1.1" xref="S2.E9.m1.4.4.1.1.1.cmml">=</mo><mrow id="S2.E9.m1.4.4.1.1.3" xref="S2.E9.m1.4.4.1.1.3.cmml"><mrow id="S2.E9.m1.4.4.1.1.3.2" xref="S2.E9.m1.4.4.1.1.3.2.cmml"><mi id="S2.E9.m1.4.4.1.1.3.2.2" xref="S2.E9.m1.4.4.1.1.3.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.1.1.3.2.1" xref="S2.E9.m1.4.4.1.1.3.2.1.cmml">‚Äã</mo><mrow id="S2.E9.m1.4.4.1.1.3.2.3.2" xref="S2.E9.m1.4.4.1.1.3.2.3.1.cmml"><mo stretchy="false" id="S2.E9.m1.4.4.1.1.3.2.3.2.1" xref="S2.E9.m1.4.4.1.1.3.2.3.1.cmml">(</mo><mi id="S2.E9.m1.1.1" xref="S2.E9.m1.1.1.cmml">ùê±</mi><mo id="S2.E9.m1.4.4.1.1.3.2.3.2.2" xref="S2.E9.m1.4.4.1.1.3.2.3.1.cmml">,</mo><mi id="S2.E9.m1.2.2" xref="S2.E9.m1.2.2.cmml">t</mi><mo stretchy="false" id="S2.E9.m1.4.4.1.1.3.2.3.2.3" xref="S2.E9.m1.4.4.1.1.3.2.3.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.1.1.3.2.1a" xref="S2.E9.m1.4.4.1.1.3.2.1.cmml">‚Äã</mo><mi id="S2.E9.m1.4.4.1.1.3.2.4" xref="S2.E9.m1.4.4.1.1.3.2.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.1.1.3.2.1b" xref="S2.E9.m1.4.4.1.1.3.2.1.cmml">‚Äã</mo><mi id="S2.E9.m1.4.4.1.1.3.2.5" xref="S2.E9.m1.4.4.1.1.3.2.5.cmml">t</mi></mrow><mo id="S2.E9.m1.4.4.1.1.3.1" xref="S2.E9.m1.4.4.1.1.3.1.cmml">+</mo><mrow id="S2.E9.m1.4.4.1.1.3.3" xref="S2.E9.m1.4.4.1.1.3.3.cmml"><mi id="S2.E9.m1.4.4.1.1.3.3.2" xref="S2.E9.m1.4.4.1.1.3.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.1.1.3.3.1" xref="S2.E9.m1.4.4.1.1.3.3.1.cmml">‚Äã</mo><mrow id="S2.E9.m1.4.4.1.1.3.3.3.2" xref="S2.E9.m1.4.4.1.1.3.3.cmml"><mo stretchy="false" id="S2.E9.m1.4.4.1.1.3.3.3.2.1" xref="S2.E9.m1.4.4.1.1.3.3.cmml">(</mo><mi id="S2.E9.m1.3.3" xref="S2.E9.m1.3.3.cmml">t</mi><mo stretchy="false" id="S2.E9.m1.4.4.1.1.3.3.3.2.2" xref="S2.E9.m1.4.4.1.1.3.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.1.1.3.3.1a" xref="S2.E9.m1.4.4.1.1.3.3.1.cmml">‚Äã</mo><mi id="S2.E9.m1.4.4.1.1.3.3.4" xref="S2.E9.m1.4.4.1.1.3.3.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.1.1.3.3.1b" xref="S2.E9.m1.4.4.1.1.3.3.1.cmml">‚Äã</mo><mi id="S2.E9.m1.4.4.1.1.3.3.5" xref="S2.E9.m1.4.4.1.1.3.3.5.cmml">ùê∞</mi></mrow></mrow></mrow><mo id="S2.E9.m1.4.4.1.2" xref="S2.E9.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E9.m1.4b"><apply id="S2.E9.m1.4.4.1.1.cmml" xref="S2.E9.m1.4.4.1"><eq id="S2.E9.m1.4.4.1.1.1.cmml" xref="S2.E9.m1.4.4.1.1.1"></eq><apply id="S2.E9.m1.4.4.1.1.2.cmml" xref="S2.E9.m1.4.4.1.1.2"><times id="S2.E9.m1.4.4.1.1.2.1.cmml" xref="S2.E9.m1.4.4.1.1.2.1"></times><ci id="S2.E9.m1.4.4.1.1.2.2.cmml" xref="S2.E9.m1.4.4.1.1.2.2">ùëë</ci><ci id="S2.E9.m1.4.4.1.1.2.3.cmml" xref="S2.E9.m1.4.4.1.1.2.3">ùê±</ci></apply><apply id="S2.E9.m1.4.4.1.1.3.cmml" xref="S2.E9.m1.4.4.1.1.3"><plus id="S2.E9.m1.4.4.1.1.3.1.cmml" xref="S2.E9.m1.4.4.1.1.3.1"></plus><apply id="S2.E9.m1.4.4.1.1.3.2.cmml" xref="S2.E9.m1.4.4.1.1.3.2"><times id="S2.E9.m1.4.4.1.1.3.2.1.cmml" xref="S2.E9.m1.4.4.1.1.3.2.1"></times><ci id="S2.E9.m1.4.4.1.1.3.2.2.cmml" xref="S2.E9.m1.4.4.1.1.3.2.2">ùëì</ci><interval closure="open" id="S2.E9.m1.4.4.1.1.3.2.3.1.cmml" xref="S2.E9.m1.4.4.1.1.3.2.3.2"><ci id="S2.E9.m1.1.1.cmml" xref="S2.E9.m1.1.1">ùê±</ci><ci id="S2.E9.m1.2.2.cmml" xref="S2.E9.m1.2.2">ùë°</ci></interval><ci id="S2.E9.m1.4.4.1.1.3.2.4.cmml" xref="S2.E9.m1.4.4.1.1.3.2.4">ùëë</ci><ci id="S2.E9.m1.4.4.1.1.3.2.5.cmml" xref="S2.E9.m1.4.4.1.1.3.2.5">ùë°</ci></apply><apply id="S2.E9.m1.4.4.1.1.3.3.cmml" xref="S2.E9.m1.4.4.1.1.3.3"><times id="S2.E9.m1.4.4.1.1.3.3.1.cmml" xref="S2.E9.m1.4.4.1.1.3.3.1"></times><ci id="S2.E9.m1.4.4.1.1.3.3.2.cmml" xref="S2.E9.m1.4.4.1.1.3.3.2">ùëî</ci><ci id="S2.E9.m1.3.3.cmml" xref="S2.E9.m1.3.3">ùë°</ci><ci id="S2.E9.m1.4.4.1.1.3.3.4.cmml" xref="S2.E9.m1.4.4.1.1.3.3.4">ùëë</ci><ci id="S2.E9.m1.4.4.1.1.3.3.5.cmml" xref="S2.E9.m1.4.4.1.1.3.3.5">ùê∞</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E9.m1.4c">d\mathbf{x}=f(\mathbf{x},t)dt+g(t)d\mathbf{w},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p4" class="ltx_para ltx_noindent">
<p id="S2.SS3.p4.5" class="ltx_p">where <math id="S2.SS3.p4.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S2.SS3.p4.1.m1.1a"><mi id="S2.SS3.p4.1.m1.1.1" xref="S2.SS3.p4.1.m1.1.1.cmml">ùê±</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.1.m1.1b"><ci id="S2.SS3.p4.1.m1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1">ùê±</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.1.m1.1c">\mathbf{x}</annotation></semantics></math> represents the data, <math id="S2.SS3.p4.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS3.p4.2.m2.1a"><mi id="S2.SS3.p4.2.m2.1.1" xref="S2.SS3.p4.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.2.m2.1b"><ci id="S2.SS3.p4.2.m2.1.1.cmml" xref="S2.SS3.p4.2.m2.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.2.m2.1c">t</annotation></semantics></math> is the time variable, <math id="S2.SS3.p4.3.m3.2" class="ltx_Math" alttext="f(\mathbf{x},t)" display="inline"><semantics id="S2.SS3.p4.3.m3.2a"><mrow id="S2.SS3.p4.3.m3.2.3" xref="S2.SS3.p4.3.m3.2.3.cmml"><mi id="S2.SS3.p4.3.m3.2.3.2" xref="S2.SS3.p4.3.m3.2.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p4.3.m3.2.3.1" xref="S2.SS3.p4.3.m3.2.3.1.cmml">‚Äã</mo><mrow id="S2.SS3.p4.3.m3.2.3.3.2" xref="S2.SS3.p4.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS3.p4.3.m3.2.3.3.2.1" xref="S2.SS3.p4.3.m3.2.3.3.1.cmml">(</mo><mi id="S2.SS3.p4.3.m3.1.1" xref="S2.SS3.p4.3.m3.1.1.cmml">ùê±</mi><mo id="S2.SS3.p4.3.m3.2.3.3.2.2" xref="S2.SS3.p4.3.m3.2.3.3.1.cmml">,</mo><mi id="S2.SS3.p4.3.m3.2.2" xref="S2.SS3.p4.3.m3.2.2.cmml">t</mi><mo stretchy="false" id="S2.SS3.p4.3.m3.2.3.3.2.3" xref="S2.SS3.p4.3.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.3.m3.2b"><apply id="S2.SS3.p4.3.m3.2.3.cmml" xref="S2.SS3.p4.3.m3.2.3"><times id="S2.SS3.p4.3.m3.2.3.1.cmml" xref="S2.SS3.p4.3.m3.2.3.1"></times><ci id="S2.SS3.p4.3.m3.2.3.2.cmml" xref="S2.SS3.p4.3.m3.2.3.2">ùëì</ci><interval closure="open" id="S2.SS3.p4.3.m3.2.3.3.1.cmml" xref="S2.SS3.p4.3.m3.2.3.3.2"><ci id="S2.SS3.p4.3.m3.1.1.cmml" xref="S2.SS3.p4.3.m3.1.1">ùê±</ci><ci id="S2.SS3.p4.3.m3.2.2.cmml" xref="S2.SS3.p4.3.m3.2.2">ùë°</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.3.m3.2c">f(\mathbf{x},t)</annotation></semantics></math> is the drift coefficient, <math id="S2.SS3.p4.4.m4.1" class="ltx_Math" alttext="g(t)" display="inline"><semantics id="S2.SS3.p4.4.m4.1a"><mrow id="S2.SS3.p4.4.m4.1.2" xref="S2.SS3.p4.4.m4.1.2.cmml"><mi id="S2.SS3.p4.4.m4.1.2.2" xref="S2.SS3.p4.4.m4.1.2.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p4.4.m4.1.2.1" xref="S2.SS3.p4.4.m4.1.2.1.cmml">‚Äã</mo><mrow id="S2.SS3.p4.4.m4.1.2.3.2" xref="S2.SS3.p4.4.m4.1.2.cmml"><mo stretchy="false" id="S2.SS3.p4.4.m4.1.2.3.2.1" xref="S2.SS3.p4.4.m4.1.2.cmml">(</mo><mi id="S2.SS3.p4.4.m4.1.1" xref="S2.SS3.p4.4.m4.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS3.p4.4.m4.1.2.3.2.2" xref="S2.SS3.p4.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.4.m4.1b"><apply id="S2.SS3.p4.4.m4.1.2.cmml" xref="S2.SS3.p4.4.m4.1.2"><times id="S2.SS3.p4.4.m4.1.2.1.cmml" xref="S2.SS3.p4.4.m4.1.2.1"></times><ci id="S2.SS3.p4.4.m4.1.2.2.cmml" xref="S2.SS3.p4.4.m4.1.2.2">ùëî</ci><ci id="S2.SS3.p4.4.m4.1.1.cmml" xref="S2.SS3.p4.4.m4.1.1">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.4.m4.1c">g(t)</annotation></semantics></math> is the diffusion coefficient, and <math id="S2.SS3.p4.5.m5.1" class="ltx_Math" alttext="\mathbf{w}" display="inline"><semantics id="S2.SS3.p4.5.m5.1a"><mi id="S2.SS3.p4.5.m5.1.1" xref="S2.SS3.p4.5.m5.1.1.cmml">ùê∞</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.5.m5.1b"><ci id="S2.SS3.p4.5.m5.1.1.cmml" xref="S2.SS3.p4.5.m5.1.1">ùê∞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.5.m5.1c">\mathbf{w}</annotation></semantics></math> is a standard Wiener process¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para ltx_noindent">
<p id="S2.SS3.p5.1" class="ltx_p"><span id="S2.SS3.p5.1.1" class="ltx_text ltx_font_bold">Reverse SDE Process.</span> The reverse process aims to revert the noisy data back to its original form by solving the reverse-time SDE. This process is governed by:</p>
</div>
<div id="S2.SS3.p6" class="ltx_para ltx_noindent">
<table id="S2.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E10.m1.6" class="ltx_Math" alttext="d\mathbf{x}=[f(\mathbf{x},t)-g(t)^{2}\nabla_{\mathbf{x}}\log p_{t}(\mathbf{x})]dt+g(t)d\mathbf{\bar{w}}," display="block"><semantics id="S2.E10.m1.6a"><mrow id="S2.E10.m1.6.6.1" xref="S2.E10.m1.6.6.1.1.cmml"><mrow id="S2.E10.m1.6.6.1.1" xref="S2.E10.m1.6.6.1.1.cmml"><mrow id="S2.E10.m1.6.6.1.1.3" xref="S2.E10.m1.6.6.1.1.3.cmml"><mi id="S2.E10.m1.6.6.1.1.3.2" xref="S2.E10.m1.6.6.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.3.1" xref="S2.E10.m1.6.6.1.1.3.1.cmml">‚Äã</mo><mi id="S2.E10.m1.6.6.1.1.3.3" xref="S2.E10.m1.6.6.1.1.3.3.cmml">ùê±</mi></mrow><mo id="S2.E10.m1.6.6.1.1.2" xref="S2.E10.m1.6.6.1.1.2.cmml">=</mo><mrow id="S2.E10.m1.6.6.1.1.1" xref="S2.E10.m1.6.6.1.1.1.cmml"><mrow id="S2.E10.m1.6.6.1.1.1.1" xref="S2.E10.m1.6.6.1.1.1.1.cmml"><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1" xref="S2.E10.m1.6.6.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.1.1.1.2" xref="S2.E10.m1.6.6.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.cmml"><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.1.cmml">‚Äã</mo><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml"><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.2.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml">(</mo><mi id="S2.E10.m1.1.1" xref="S2.E10.m1.1.1.cmml">ùê±</mi><mo id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.2.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml">,</mo><mi id="S2.E10.m1.2.2" xref="S2.E10.m1.2.2.cmml">t</mi><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.2.3" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E10.m1.6.6.1.1.1.1.1.1.1.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.1.cmml">‚àí</mo><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.1.cmml">‚Äã</mo><msup id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.cmml"><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.2.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.cmml"><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.2.2.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.cmml">(</mo><mi id="S2.E10.m1.3.3" xref="S2.E10.m1.3.3.cmml">t</mi><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.2.2.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.cmml">)</mo></mrow><mn id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.3" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.3.cmml">2</mn></msup><mo lspace="0.167em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.1a" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.1.cmml">‚Äã</mo><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.cmml"><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.cmml"><msub id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.cmml"><mo rspace="0.167em" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.2.cmml">‚àá</mo><mi id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.3" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.3.cmml">ùê±</mi></msub><mi id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4a" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.cmml">‚Å°</mo><msub id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.cmml"><mi id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.2.cmml">p</mi><mi id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.3" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.3.cmml">t</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.1b" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.1.cmml">‚Äã</mo><mrow id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.5.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.5.2.1" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.cmml">(</mo><mi id="S2.E10.m1.4.4" xref="S2.E10.m1.4.4.cmml">ùê±</mi><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.5.2.2" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.1.1.1.3" xref="S2.E10.m1.6.6.1.1.1.1.1.2.1.cmml">]</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.1.2" xref="S2.E10.m1.6.6.1.1.1.1.2.cmml">‚Äã</mo><mi id="S2.E10.m1.6.6.1.1.1.1.3" xref="S2.E10.m1.6.6.1.1.1.1.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.1.2a" xref="S2.E10.m1.6.6.1.1.1.1.2.cmml">‚Äã</mo><mi id="S2.E10.m1.6.6.1.1.1.1.4" xref="S2.E10.m1.6.6.1.1.1.1.4.cmml">t</mi></mrow><mo id="S2.E10.m1.6.6.1.1.1.2" xref="S2.E10.m1.6.6.1.1.1.2.cmml">+</mo><mrow id="S2.E10.m1.6.6.1.1.1.3" xref="S2.E10.m1.6.6.1.1.1.3.cmml"><mi id="S2.E10.m1.6.6.1.1.1.3.2" xref="S2.E10.m1.6.6.1.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.3.1" xref="S2.E10.m1.6.6.1.1.1.3.1.cmml">‚Äã</mo><mrow id="S2.E10.m1.6.6.1.1.1.3.3.2" xref="S2.E10.m1.6.6.1.1.1.3.cmml"><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.3.3.2.1" xref="S2.E10.m1.6.6.1.1.1.3.cmml">(</mo><mi id="S2.E10.m1.5.5" xref="S2.E10.m1.5.5.cmml">t</mi><mo stretchy="false" id="S2.E10.m1.6.6.1.1.1.3.3.2.2" xref="S2.E10.m1.6.6.1.1.1.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.3.1a" xref="S2.E10.m1.6.6.1.1.1.3.1.cmml">‚Äã</mo><mi id="S2.E10.m1.6.6.1.1.1.3.4" xref="S2.E10.m1.6.6.1.1.1.3.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.6.6.1.1.1.3.1b" xref="S2.E10.m1.6.6.1.1.1.3.1.cmml">‚Äã</mo><mover accent="true" id="S2.E10.m1.6.6.1.1.1.3.5" xref="S2.E10.m1.6.6.1.1.1.3.5.cmml"><mi id="S2.E10.m1.6.6.1.1.1.3.5.2" xref="S2.E10.m1.6.6.1.1.1.3.5.2.cmml">ùê∞</mi><mo id="S2.E10.m1.6.6.1.1.1.3.5.1" xref="S2.E10.m1.6.6.1.1.1.3.5.1.cmml">¬Ø</mo></mover></mrow></mrow></mrow><mo id="S2.E10.m1.6.6.1.2" xref="S2.E10.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E10.m1.6b"><apply id="S2.E10.m1.6.6.1.1.cmml" xref="S2.E10.m1.6.6.1"><eq id="S2.E10.m1.6.6.1.1.2.cmml" xref="S2.E10.m1.6.6.1.1.2"></eq><apply id="S2.E10.m1.6.6.1.1.3.cmml" xref="S2.E10.m1.6.6.1.1.3"><times id="S2.E10.m1.6.6.1.1.3.1.cmml" xref="S2.E10.m1.6.6.1.1.3.1"></times><ci id="S2.E10.m1.6.6.1.1.3.2.cmml" xref="S2.E10.m1.6.6.1.1.3.2">ùëë</ci><ci id="S2.E10.m1.6.6.1.1.3.3.cmml" xref="S2.E10.m1.6.6.1.1.3.3">ùê±</ci></apply><apply id="S2.E10.m1.6.6.1.1.1.cmml" xref="S2.E10.m1.6.6.1.1.1"><plus id="S2.E10.m1.6.6.1.1.1.2.cmml" xref="S2.E10.m1.6.6.1.1.1.2"></plus><apply id="S2.E10.m1.6.6.1.1.1.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1"><times id="S2.E10.m1.6.6.1.1.1.1.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.2"></times><apply id="S2.E10.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E10.m1.6.6.1.1.1.1.1.2.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E10.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1"><minus id="S2.E10.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.1"></minus><apply id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2"><times id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.1"></times><ci id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.2">ùëì</ci><interval closure="open" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.2.3.2"><ci id="S2.E10.m1.1.1.cmml" xref="S2.E10.m1.1.1">ùê±</ci><ci id="S2.E10.m1.2.2.cmml" xref="S2.E10.m1.2.2">ùë°</ci></interval></apply><apply id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3"><times id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.1"></times><ci id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.2">ùëî</ci><apply id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3">superscript</csymbol><ci id="S2.E10.m1.3.3.cmml" xref="S2.E10.m1.3.3">ùë°</ci><cn type="integer" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.3.3">2</cn></apply><apply id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4"><apply id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1"><apply id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1"><csymbol cd="ambiguous" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1">subscript</csymbol><ci id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.2">‚àá</ci><ci id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.3.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.1.3">ùê±</ci></apply><log id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.1.2"></log></apply><apply id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2"><csymbol cd="ambiguous" id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.1.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2">subscript</csymbol><ci id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.2.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.2">ùëù</ci><ci id="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.3.cmml" xref="S2.E10.m1.6.6.1.1.1.1.1.1.1.3.4.2.3">ùë°</ci></apply></apply><ci id="S2.E10.m1.4.4.cmml" xref="S2.E10.m1.4.4">ùê±</ci></apply></apply></apply><ci id="S2.E10.m1.6.6.1.1.1.1.3.cmml" xref="S2.E10.m1.6.6.1.1.1.1.3">ùëë</ci><ci id="S2.E10.m1.6.6.1.1.1.1.4.cmml" xref="S2.E10.m1.6.6.1.1.1.1.4">ùë°</ci></apply><apply id="S2.E10.m1.6.6.1.1.1.3.cmml" xref="S2.E10.m1.6.6.1.1.1.3"><times id="S2.E10.m1.6.6.1.1.1.3.1.cmml" xref="S2.E10.m1.6.6.1.1.1.3.1"></times><ci id="S2.E10.m1.6.6.1.1.1.3.2.cmml" xref="S2.E10.m1.6.6.1.1.1.3.2">ùëî</ci><ci id="S2.E10.m1.5.5.cmml" xref="S2.E10.m1.5.5">ùë°</ci><ci id="S2.E10.m1.6.6.1.1.1.3.4.cmml" xref="S2.E10.m1.6.6.1.1.1.3.4">ùëë</ci><apply id="S2.E10.m1.6.6.1.1.1.3.5.cmml" xref="S2.E10.m1.6.6.1.1.1.3.5"><ci id="S2.E10.m1.6.6.1.1.1.3.5.1.cmml" xref="S2.E10.m1.6.6.1.1.1.3.5.1">¬Ø</ci><ci id="S2.E10.m1.6.6.1.1.1.3.5.2.cmml" xref="S2.E10.m1.6.6.1.1.1.3.5.2">ùê∞</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E10.m1.6c">d\mathbf{x}=[f(\mathbf{x},t)-g(t)^{2}\nabla_{\mathbf{x}}\log p_{t}(\mathbf{x})]dt+g(t)d\mathbf{\bar{w}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p7" class="ltx_para ltx_noindent">
<p id="S2.SS3.p7.3" class="ltx_p">where <math id="S2.SS3.p7.1.m1.1" class="ltx_Math" alttext="\nabla_{\mathbf{x}}\log p_{t}(\mathbf{x})" display="inline"><semantics id="S2.SS3.p7.1.m1.1a"><mrow id="S2.SS3.p7.1.m1.1.2" xref="S2.SS3.p7.1.m1.1.2.cmml"><mrow id="S2.SS3.p7.1.m1.1.2.2" xref="S2.SS3.p7.1.m1.1.2.2.cmml"><mrow id="S2.SS3.p7.1.m1.1.2.2.1" xref="S2.SS3.p7.1.m1.1.2.2.1.cmml"><msub id="S2.SS3.p7.1.m1.1.2.2.1.1" xref="S2.SS3.p7.1.m1.1.2.2.1.1.cmml"><mo id="S2.SS3.p7.1.m1.1.2.2.1.1.2" xref="S2.SS3.p7.1.m1.1.2.2.1.1.2.cmml">‚àá</mo><mi id="S2.SS3.p7.1.m1.1.2.2.1.1.3" xref="S2.SS3.p7.1.m1.1.2.2.1.1.3.cmml">ùê±</mi></msub><mi id="S2.SS3.p7.1.m1.1.2.2.1.2" xref="S2.SS3.p7.1.m1.1.2.2.1.2.cmml">log</mi></mrow><mo lspace="0.167em" id="S2.SS3.p7.1.m1.1.2.2a" xref="S2.SS3.p7.1.m1.1.2.2.cmml">‚Å°</mo><msub id="S2.SS3.p7.1.m1.1.2.2.2" xref="S2.SS3.p7.1.m1.1.2.2.2.cmml"><mi id="S2.SS3.p7.1.m1.1.2.2.2.2" xref="S2.SS3.p7.1.m1.1.2.2.2.2.cmml">p</mi><mi id="S2.SS3.p7.1.m1.1.2.2.2.3" xref="S2.SS3.p7.1.m1.1.2.2.2.3.cmml">t</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S2.SS3.p7.1.m1.1.2.1" xref="S2.SS3.p7.1.m1.1.2.1.cmml">‚Äã</mo><mrow id="S2.SS3.p7.1.m1.1.2.3.2" xref="S2.SS3.p7.1.m1.1.2.cmml"><mo stretchy="false" id="S2.SS3.p7.1.m1.1.2.3.2.1" xref="S2.SS3.p7.1.m1.1.2.cmml">(</mo><mi id="S2.SS3.p7.1.m1.1.1" xref="S2.SS3.p7.1.m1.1.1.cmml">ùê±</mi><mo stretchy="false" id="S2.SS3.p7.1.m1.1.2.3.2.2" xref="S2.SS3.p7.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.1.m1.1b"><apply id="S2.SS3.p7.1.m1.1.2.cmml" xref="S2.SS3.p7.1.m1.1.2"><times id="S2.SS3.p7.1.m1.1.2.1.cmml" xref="S2.SS3.p7.1.m1.1.2.1"></times><apply id="S2.SS3.p7.1.m1.1.2.2.cmml" xref="S2.SS3.p7.1.m1.1.2.2"><apply id="S2.SS3.p7.1.m1.1.2.2.1.cmml" xref="S2.SS3.p7.1.m1.1.2.2.1"><apply id="S2.SS3.p7.1.m1.1.2.2.1.1.cmml" xref="S2.SS3.p7.1.m1.1.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p7.1.m1.1.2.2.1.1.1.cmml" xref="S2.SS3.p7.1.m1.1.2.2.1.1">subscript</csymbol><ci id="S2.SS3.p7.1.m1.1.2.2.1.1.2.cmml" xref="S2.SS3.p7.1.m1.1.2.2.1.1.2">‚àá</ci><ci id="S2.SS3.p7.1.m1.1.2.2.1.1.3.cmml" xref="S2.SS3.p7.1.m1.1.2.2.1.1.3">ùê±</ci></apply><log id="S2.SS3.p7.1.m1.1.2.2.1.2.cmml" xref="S2.SS3.p7.1.m1.1.2.2.1.2"></log></apply><apply id="S2.SS3.p7.1.m1.1.2.2.2.cmml" xref="S2.SS3.p7.1.m1.1.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p7.1.m1.1.2.2.2.1.cmml" xref="S2.SS3.p7.1.m1.1.2.2.2">subscript</csymbol><ci id="S2.SS3.p7.1.m1.1.2.2.2.2.cmml" xref="S2.SS3.p7.1.m1.1.2.2.2.2">ùëù</ci><ci id="S2.SS3.p7.1.m1.1.2.2.2.3.cmml" xref="S2.SS3.p7.1.m1.1.2.2.2.3">ùë°</ci></apply></apply><ci id="S2.SS3.p7.1.m1.1.1.cmml" xref="S2.SS3.p7.1.m1.1.1">ùê±</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.1.m1.1c">\nabla_{\mathbf{x}}\log p_{t}(\mathbf{x})</annotation></semantics></math> is the score function, which represents the gradient of the log-density of the data at time <math id="S2.SS3.p7.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS3.p7.2.m2.1a"><mi id="S2.SS3.p7.2.m2.1.1" xref="S2.SS3.p7.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.2.m2.1b"><ci id="S2.SS3.p7.2.m2.1.1.cmml" xref="S2.SS3.p7.2.m2.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.2.m2.1c">t</annotation></semantics></math>, and <math id="S2.SS3.p7.3.m3.1" class="ltx_Math" alttext="\mathbf{\bar{w}}" display="inline"><semantics id="S2.SS3.p7.3.m3.1a"><mover accent="true" id="S2.SS3.p7.3.m3.1.1" xref="S2.SS3.p7.3.m3.1.1.cmml"><mi id="S2.SS3.p7.3.m3.1.1.2" xref="S2.SS3.p7.3.m3.1.1.2.cmml">ùê∞</mi><mo id="S2.SS3.p7.3.m3.1.1.1" xref="S2.SS3.p7.3.m3.1.1.1.cmml">¬Ø</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS3.p7.3.m3.1b"><apply id="S2.SS3.p7.3.m3.1.1.cmml" xref="S2.SS3.p7.3.m3.1.1"><ci id="S2.SS3.p7.3.m3.1.1.1.cmml" xref="S2.SS3.p7.3.m3.1.1.1">¬Ø</ci><ci id="S2.SS3.p7.3.m3.1.1.2.cmml" xref="S2.SS3.p7.3.m3.1.1.2">ùê∞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p7.3.m3.1c">\mathbf{\bar{w}}</annotation></semantics></math> is a standard Wiener process running backward in time¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. The score function is estimated using an NN trained on denoising score matching¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S2.SS3.p8" class="ltx_para ltx_noindent">
<p id="S2.SS3.p8.1" class="ltx_p"><span id="S2.SS3.p8.1.1" class="ltx_text ltx_font_bold">Training Objective.</span> The training of Score-based Generative models involves learning the score function at different noise levels. The objective function for training is typically the denoising score matching loss:</p>
</div>
<div id="S2.SS3.p9" class="ltx_para ltx_noindent">
<table id="S2.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E11.m1.6" class="ltx_math_unparsed" alttext="L_{\text{score}}=\mathbb{E}_{p_{0}(\mathbf{x}),\epsilon,t}\left[\lambda(t)||s_{\theta}(\mathbf{x}_{t},t)-\nabla_{\mathbf{x}_{t}}\log p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})||^{2}\right]," display="block"><semantics id="S2.E11.m1.6a"><mrow id="S2.E11.m1.6b"><msub id="S2.E11.m1.6.7"><mi id="S2.E11.m1.6.7.2">L</mi><mtext id="S2.E11.m1.6.7.3">score</mtext></msub><mo id="S2.E11.m1.6.8">=</mo><msub id="S2.E11.m1.6.9"><mi id="S2.E11.m1.6.9.2">ùîº</mi><mrow id="S2.E11.m1.4.4.4.4"><mrow id="S2.E11.m1.4.4.4.4.1"><msub id="S2.E11.m1.4.4.4.4.1.2"><mi id="S2.E11.m1.4.4.4.4.1.2.2">p</mi><mn id="S2.E11.m1.4.4.4.4.1.2.3">0</mn></msub><mo lspace="0em" rspace="0em" id="S2.E11.m1.4.4.4.4.1.1">‚Äã</mo><mrow id="S2.E11.m1.4.4.4.4.1.3.2"><mo stretchy="false" id="S2.E11.m1.4.4.4.4.1.3.2.1">(</mo><mi id="S2.E11.m1.1.1.1.1">ùê±</mi><mo stretchy="false" id="S2.E11.m1.4.4.4.4.1.3.2.2">)</mo></mrow></mrow><mo id="S2.E11.m1.4.4.4.4.2">,</mo><mi id="S2.E11.m1.2.2.2.2">œµ</mi><mo id="S2.E11.m1.4.4.4.4.3">,</mo><mi id="S2.E11.m1.3.3.3.3">t</mi></mrow></msub><mrow id="S2.E11.m1.6.10"><mo id="S2.E11.m1.6.10.1">[</mo><mi id="S2.E11.m1.6.10.2">Œª</mi><mrow id="S2.E11.m1.6.10.3"><mo stretchy="false" id="S2.E11.m1.6.10.3.1">(</mo><mi id="S2.E11.m1.5.5">t</mi><mo stretchy="false" id="S2.E11.m1.6.10.3.2">)</mo></mrow><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E11.m1.6.10.4">|</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E11.m1.6.10.5">|</mo><msub id="S2.E11.m1.6.10.6"><mi id="S2.E11.m1.6.10.6.2">s</mi><mi id="S2.E11.m1.6.10.6.3">Œ∏</mi></msub><mrow id="S2.E11.m1.6.10.7"><mo stretchy="false" id="S2.E11.m1.6.10.7.1">(</mo><msub id="S2.E11.m1.6.10.7.2"><mi id="S2.E11.m1.6.10.7.2.2">ùê±</mi><mi id="S2.E11.m1.6.10.7.2.3">t</mi></msub><mo id="S2.E11.m1.6.10.7.3">,</mo><mi id="S2.E11.m1.6.6">t</mi><mo stretchy="false" id="S2.E11.m1.6.10.7.4">)</mo></mrow><mo id="S2.E11.m1.6.10.8">‚àí</mo><msub id="S2.E11.m1.6.10.9"><mo rspace="0.167em" id="S2.E11.m1.6.10.9.2">‚àá</mo><msub id="S2.E11.m1.6.10.9.3"><mi id="S2.E11.m1.6.10.9.3.2">ùê±</mi><mi id="S2.E11.m1.6.10.9.3.3">t</mi></msub></msub><mi id="S2.E11.m1.6.10.10">log</mi><msub id="S2.E11.m1.6.10.11"><mi id="S2.E11.m1.6.10.11.2">p</mi><mi id="S2.E11.m1.6.10.11.3">t</mi></msub><mrow id="S2.E11.m1.6.10.12"><mo stretchy="false" id="S2.E11.m1.6.10.12.1">(</mo><msub id="S2.E11.m1.6.10.12.2"><mi id="S2.E11.m1.6.10.12.2.2">ùê±</mi><mi id="S2.E11.m1.6.10.12.2.3">t</mi></msub><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E11.m1.6.10.12.3">|</mo><msub id="S2.E11.m1.6.10.12.4"><mi id="S2.E11.m1.6.10.12.4.2">ùê±</mi><mn id="S2.E11.m1.6.10.12.4.3">0</mn></msub><mo stretchy="false" id="S2.E11.m1.6.10.12.5">)</mo></mrow><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E11.m1.6.10.13">|</mo><msup id="S2.E11.m1.6.10.14"><mo fence="false" rspace="0.167em" stretchy="false" id="S2.E11.m1.6.10.14.2">|</mo><mn id="S2.E11.m1.6.10.14.3">2</mn></msup><mo id="S2.E11.m1.6.10.15">]</mo></mrow><mo id="S2.E11.m1.6.11">,</mo></mrow><annotation encoding="application/x-tex" id="S2.E11.m1.6c">L_{\text{score}}=\mathbb{E}_{p_{0}(\mathbf{x}),\epsilon,t}\left[\lambda(t)||s_{\theta}(\mathbf{x}_{t},t)-\nabla_{\mathbf{x}_{t}}\log p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})||^{2}\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p10" class="ltx_para ltx_noindent">
<p id="S2.SS3.p10.1" class="ltx_p"><span id="S2.SS3.p10.1.1" class="ltx_text ltx_font_bold">Sampling from SDEs.</span> Sampling from the trained Score-based model involves solving the reverse-time SDE starting from a sample of Gaussian noise. Numerical solvers, such as Euler-Maruyama or Predictor-Corrector methods, are used to approximate the reverse SDE and generate data samples¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>General Applications of DMs</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">Over the years, interest in DMs has grown exceptionally due to their ability to generate high-quality, realistic, and diverse data samples, making them highly deployable in several cutting-edge applications. Some of the most popular areas where DMs are used extensively include:</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚ùë</span> 
<div id="S3.I1.ix1.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.ix1.p1.1" class="ltx_p"><span id="S3.I1.ix1.p1.1.1" class="ltx_text ltx_font_bold">Image Synthesis:</span> DMs are used to create detailed, high-resolution images from a distribution of noise. They can generate new images or improve existing ones by improving clarity and resolution, making them particularly useful in fields such as digital art and graphic design¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚ùë</span> 
<div id="S3.I1.ix2.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.ix2.p1.1" class="ltx_p"><span id="S3.I1.ix2.p1.1.1" class="ltx_text ltx_font_bold">Text Generation:</span> DMs are capable of producing coherent and contextually relevant text sequences. This makes them suitable for applications such as creating literary content, generating realistic dialogues in virtual assistants, and automating content generation for news articles or creative writing¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.ix3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚ùë</span> 
<div id="S3.I1.ix3.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.ix3.p1.1" class="ltx_p"><span id="S3.I1.ix3.p1.1.1" class="ltx_text ltx_font_bold">Audio Synthesis:</span> DMs can generate clear and realistic audio from noisy signals. This is valuable in music production, where it‚Äôs necessary to create new sounds or improve the clarity of recorded audio, as well as in speech synthesis technologies used in various assistive devices¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.ix4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚ùë</span> 
<div id="S3.I1.ix4.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.ix4.p1.1" class="ltx_p"><span id="S3.I1.ix4.p1.1.1" class="ltx_text ltx_font_bold">Healthcare Applications:</span> Although not limited to medical imaging, DMs assist in synthesizing medical data, including Magnetic Resonance Imaging (MRI), Computed Tomography (CT) scans, and other imaging modalities. This ability is vital for training medical professionals, improving diagnostic tools, and developing more precise therapeutic strategies without compromising patient privacy¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
</li>
</ul>
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:dif</span></span> summarizes some of the renowned papers in DMs from 2020 to 2023, their proposed algorithms, used datasets, and applications. Different colors are used to distinguish between various algorithms and application types. From <span id="S3.p2.1.2" class="ltx_text ltx_font_bold">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:dif</span></span>, it can be observed that most of the papers primarily focus on image-based applications, such as image generation, segmentation, and reconstruction.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S3.T1.1.1" class="ltx_text ltx_font_bold">Some of the important papers in DMs from 2020 to 2023, along with their proposed algorithms, used datasets, and applications. Different colors are used to distinguish between various algorithms and application types.</span></figcaption>
<table id="S3.T1.3" class="ltx_tabular">
<tr id="S3.T1.3.1" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T1.3.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.1.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S3.T1.3.1.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S3.T1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Year</span></span>
</span>
</td>
<td id="S3.T1.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.1.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S3.T1.3.1.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.1.2.1.1.1" class="ltx_text ltx_font_bold">Proposed Algorithm</span></span>
</span>
</td>
<td id="S3.T1.3.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.1.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S3.T1.3.1.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.1.3.1.1.1" class="ltx_text ltx_font_bold">Used Datasets</span></span>
</span>
</td>
<td id="S3.T1.3.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.1.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S3.T1.3.1.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.1.4.1.1.1" class="ltx_text ltx_font_bold">Applications</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.2" class="ltx_tr">
<td id="S3.T1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.2.1.1.1" class="ltx_p" style="width:28.5pt;">2020</span>
</span>
</td>
<td id="S3.T1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.2.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.2.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">DDPMs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.2.3.1.1" class="ltx_p" style="width:113.8pt;">CIFAR-10¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, LSUN¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, CelebA¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite></span>
</span>
</td>
<td id="S3.T1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.2.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.2.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.3" class="ltx_tr">
<td id="S3.T1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.3.1.1.1" class="ltx_p" style="width:28.5pt;">2020</span>
</span>
</td>
<td id="S3.T1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.3.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.3.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">Score-Based DMs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.3.3.1.1" class="ltx_p" style="width:113.8pt;">CIFAR-10, CelebA, LSUN</span>
</span>
</td>
<td id="S3.T1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.3.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.3.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.4" class="ltx_tr">
<td id="S3.T1.3.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.4.1.1.1" class="ltx_p" style="width:28.5pt;">2020</span>
</span>
</td>
<td id="S3.T1.3.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.4.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.4.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">SDEs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.4.3.1.1" class="ltx_p" style="width:113.8pt;">CIFAR-10, CelebA, LSUN, FFHQ</span>
</span>
</td>
<td id="S3.T1.3.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.4.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.4.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.5" class="ltx_tr">
<td id="S3.T1.3.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.5.1.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S3.T1.3.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.5.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.5.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">Classifier-guided DMs (CDMs)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.5.3.1.1" class="ltx_p" style="width:113.8pt;">ImageNet, LSUN, CIFAR-10</span>
</span>
</td>
<td id="S3.T1.3.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.5.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.5.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.6" class="ltx_tr">
<td id="S3.T1.3.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.6.1.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S3.T1.3.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.6.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.6.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">Variational Diffusion Models (VDMs)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.6.3.1.1" class="ltx_p" style="width:113.8pt;">CIFAR-10, CelebA, LSUN</span>
</span>
</td>
<td id="S3.T1.3.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.6.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.6.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.7" class="ltx_tr">
<td id="S3.T1.3.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.7.1.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S3.T1.3.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.7.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.7.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">Improved DDPMs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.7.3.1.1" class="ltx_p" style="width:113.8pt;">CIFAR-10, CelebA, LSUN</span>
</span>
</td>
<td id="S3.T1.3.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.7.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.7.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.8" class="ltx_tr">
<td id="S3.T1.3.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.8.1.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S3.T1.3.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCFFCC;">
<span id="S3.T1.3.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.8.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.8.2.1.1.1" class="ltx_text" style="background-color:#CCFFCC;">Diffusion Waveform (DiffWave)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.8.3.1.1" class="ltx_p" style="width:113.8pt;">LJSpeech, VCTK</span>
</span>
</td>
<td id="S3.T1.3.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFFFCC;">
<span id="S3.T1.3.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.8.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.8.4.1.1.1" class="ltx_text" style="background-color:#FFFFCC;">Audio generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.9" class="ltx_tr">
<td id="S3.T1.3.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.9.1.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S3.T1.3.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCFFCC;">
<span id="S3.T1.3.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.9.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.9.2.1.1.1" class="ltx_text" style="background-color:#CCFFCC;">Segmentation Diffusion (SegDiff)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.9.3.1.1" class="ltx_p" style="width:113.8pt;">Cityscapes, Pascal VOC</span>
</span>
</td>
<td id="S3.T1.3.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCFFFF;">
<span id="S3.T1.3.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.9.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.9.4.1.1.1" class="ltx_text" style="background-color:#CCFFFF;">Image segmentation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.10" class="ltx_tr">
<td id="S3.T1.3.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.10.1.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S3.T1.3.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCFFCC;">
<span id="S3.T1.3.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.10.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.10.2.1.1.1" class="ltx_text" style="background-color:#CCFFCC;">Generative LIkelihood-based DEcompression (GLIDE)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.10.3.1.1" class="ltx_p" style="width:113.8pt;">MS-COCO, ImageNet</span>
</span>
</td>
<td id="S3.T1.3.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#F2FFCC;">
<span id="S3.T1.3.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.10.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.10.4.1.1.1" class="ltx_text" style="background-color:#F2FFCC;">Image reconstruction</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.11" class="ltx_tr">
<td id="S3.T1.3.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.11.1.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S3.T1.3.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.11.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.11.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">Latent Diffusion Models (LDMs)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.11.3.1.1" class="ltx_p" style="width:113.8pt;">LAION-400M, CelebA-HQ</span>
</span>
</td>
<td id="S3.T1.3.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#F2CCD9;">
<span id="S3.T1.3.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.11.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.11.4.1.1.1" class="ltx_text" style="background-color:#F2CCD9;">Image generation, Text-to-image</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.12" class="ltx_tr">
<td id="S3.T1.3.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.12.1.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S3.T1.3.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.12.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.12.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">Image Transformers¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.12.3.1.1" class="ltx_p" style="width:113.8pt;">ImageNet, COCO</span>
</span>
</td>
<td id="S3.T1.3.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.12.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.12.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.13" class="ltx_tr">
<td id="S3.T1.3.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.13.1.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S3.T1.3.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.13.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.13.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">Multiscale Diffusion Models¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.13.3.1.1" class="ltx_p" style="width:113.8pt;">ImageNet, CIFAR-10, LSUN</span>
</span>
</td>
<td id="S3.T1.3.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.13.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.13.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.14" class="ltx_tr">
<td id="S3.T1.3.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.14.1.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S3.T1.3.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#CCFFCC;">
<span id="S3.T1.3.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.14.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.14.2.1.1.1" class="ltx_text" style="background-color:#CCFFCC;">Video-DDPM¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.3.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.14.3.1.1" class="ltx_p" style="width:113.8pt;">Kinetics-600, UCF-101</span>
</span>
</td>
<td id="S3.T1.3.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="background-color:#FFE6CC;">
<span id="S3.T1.3.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.14.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.14.4.1.1.1" class="ltx_text" style="background-color:#FFE6CC;">Video generation</span></span>
</span>
</td>
</tr>
<tr id="S3.T1.3.15" class="ltx_tr">
<td id="S3.T1.3.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T1.3.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.15.1.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S3.T1.3.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFCCCC;">
<span id="S3.T1.3.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.15.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S3.T1.3.15.2.1.1.1" class="ltx_text" style="background-color:#FFCCCC;">Adaptive Diffusion Models¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span></span>
</span>
</td>
<td id="S3.T1.3.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T1.3.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.15.3.1.1" class="ltx_p" style="width:113.8pt;">CIFAR-10, CelebA, FFHQ</span>
</span>
</td>
<td id="S3.T1.3.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="background-color:#CCCCFF;">
<span id="S3.T1.3.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.3.15.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S3.T1.3.15.4.1.1.1" class="ltx_text" style="background-color:#CCCCFF;">Image generation</span></span>
</span>
</td>
</tr>
</table>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Innovations and Experimental Techniques in DMs</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">Several studies have utilized DM-based approaches because of their flexibility and effectiveness in various applications. <span id="S4.p1.1.1" class="ltx_text ltx_font_bold">Figure¬†<a href="#S4.F5" title="Figure 5 ‚Ä£ 4 Innovations and Experimental Techniques in DMs ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a></span> illustrates a DM introduced for guided image synthesis through initial image editing.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2408.10207/assets/dfinaladobi1.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="167" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="S4.F5.2.1" class="ltx_text ltx_font_bold">Mao et al. (2023) explored how the initial image influenced the image generation process and proposed a new method to control it by altering the initial random noise. They demonstrated two applications: layout-to-image synthesis, which created objects in specified locations, and re-painting, which allowed users to change specific portions of an image while keeping the rest unchanged¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.</span></figcaption>
</figure>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.1" class="ltx_p">Whang et al. (2022) introduced a diffusion-based stochastic blind image deblurring technique. This approach leveraged DMs to produce multiple plausible reconstructions for blurred images, significantly improving perceptual quality. Evaluations on the GoPro dataset showed impressive results with metrics such as FID of 4.04, Kernel Inception Distance (KID) of 0.98, Learned Perceptual Image Patch Similarity (LPIPS) of 0.059, Peak Signal-to-Noise Ratio (PSNR) of 31.66, and Structural Similarity Index Measure (SSIM) of 0.948¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. However, high computational demands pose limitations for real-time applications, suggesting a need for optimized sampling or network architecture adjustments.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.1" class="ltx_p">Chung et al. (2022) introduced the <span id="S4.p3.1.1" class="ltx_text ltx_font_bold">Come-Closer-Diffuse-Faster (CCDF)</span> sampling strategy to address the slow sampling rate of DMs. CCDF started from a forward-diffused state, reducing required sampling steps using the contraction theory of stochastic difference equations. This method enhanced tasks like super-resolution, image inpainting, and MRI reconstruction, showing improved FID scores and PSNR across datasets¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. However, selecting the optimal starting point remains challenging and requires several trial-and-error approaches.</p>
</div>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.1" class="ltx_p">Wang et al. (2023) introduced <span id="S4.p4.1.1" class="ltx_text ltx_font_bold">Selective Diffusion Distillation (SDD)</span> for improved image manipulation using conditional DMs. SDD trained a feedforward network guided by a DM, addressing the fidelity-editability trade-off. The framework used a Hybrid Quality Score (HQS) to select the optimal semantic timestep, improving image quality and semantic accuracy. SDD outperformed other methods, achieving an FID of 6.066 and a Contrastive Language-Image Pre-training (CLIP) similarity of 0.2337¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. However, a significant limitation remains in the necessity of carefully selecting HQS thresholds to balance manipulation and quality.</p>
</div>
<div id="S4.p5" class="ltx_para ltx_noindent">
<p id="S4.p5.1" class="ltx_p">Li et al. (2023) introduced <span id="S4.p5.1.1" class="ltx_text ltx_font_bold">Object Motion Guided Human Motion Synthesis (OMOMO)</span>, a framework for synthesizing human motion based on object motion, specifically for large object manipulation. OMOMO used two denoising processes to predict hand positions from object motion and synthesize full-body poses, ensuring accurate contact and realistic motion. By capturing motion via visual-inertial odometry on a smartphone, OMOMO showed potential for applications in virtual reality, augmented reality, and robotics. Their comprehensive dataset demonstrated the framework‚Äôs ability to generalize to unseen objects. OMOMO achieved high accuracy with a Mean Per-Joint Position Error (MPJPE) of 12.42, a precision score of 0.70, and an F1 score of 0.72¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. However, the issue of intermittent object contacts remains unaddressed. Additionally, the predicted hand motions are less plausible, as indicated by lower F1 and precision scores.</p>
</div>
<div id="S4.p6" class="ltx_para ltx_noindent">
<p id="S4.p6.1" class="ltx_p">Ni et al. (2023) introduced <span id="S4.p6.1.1" class="ltx_text ltx_font_bold">Degeneration-Tuning (DT)</span> to control text-to-image DMs like Stable Diffusion. DT prevents the generation of unwanted content by detaching undesirable textual concepts from image outputs using a scrambled grid. Integrated with Control Network (ControlNet), DT maintains high-quality generation for general content with minimal metric impact (FID from 12.61 to 13.04, IS from 39.20 to 38.25)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. However, DT‚Äôs slow sampling speeds, reliance on predefined prompts, and risk of over-degeneration limit its effectiveness, requiring further refinement to balance control and generative abilities.</p>
</div>
<div id="S4.p7" class="ltx_para ltx_noindent">
<p id="S4.p7.1" class="ltx_p">Yan et al. (2022) introduced <span id="S4.p7.1.1" class="ltx_text ltx_font_bold">Temporal and Feature Pattern-based Diffusion Probabilistic Model (TFDPM)</span>, a model for detecting attacks in cyber-physical systems within Artificial Intelligence of Things (AIoT). TFDPM combined energy-based generative models and Graph Neural Networks to handle complex data and correlations. It extracted temporal and feature patterns to guide a diffusion probabilistic model, improving accuracy and sensitivity¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. Their proposed TFDPM outperformed many of the existing State-of-the-Art (SOTA) techniques on PUMP, SWAT, and WADI datasets in terms of attack detection accuracy and speed. However, challenges remained in modeling discrete signals and exploring more robust configurations. Additionally, the model faced difficulties in ensuring scalability and adaptability across diverse AIoT environments as well.</p>
</div>
<div id="S4.p8" class="ltx_para ltx_noindent">
<p id="S4.p8.1" class="ltx_p">Lee et al. (2023) introduced <span id="S4.p8.1.1" class="ltx_text ltx_font_bold">Metric Anomaly Anticipation (MAAT)</span>, a framework for faster-than-real-time anomaly detection in cloud services. MAAT uses a two-stage process: multi-step forecasting with a Conditional Denoising Diffusion Model, followed by anomaly detection with an isolation forest. Tested on AIOps18, Hades, and Yahoo!S5 datasets, MAAT outperformed existing methods in speed, precision, and reliability¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. However, its focus on cloud-service metrics and a static time horizon limits its applicability to other time-series data and dynamic conditions. Furthermore, its performance with ultra-high-frequency data remains untested, indicating a need for further research to extend its capabilities and validate its effectiveness in these areas.</p>
</div>
<div id="S4.p9" class="ltx_para ltx_noindent">
<p id="S4.p9.1" class="ltx_p">Chen et al. (2023) introduced <span id="S4.p9.1.1" class="ltx_text ltx_font_bold">Equivariant Diffusion (EquiDiff)</span>, a deep generative model designed to improve the security and efficiency of autonomous vehicles by predicting vehicle routes. EquiDiff uses conditional DMs with an SO(2)-equivariant transformer, integrating historical trajectory data and Gaussian noise to generate future paths while respecting geometric constraints. It also incorporates Recurrent Neural Networks and Graph Attention Networks to model social interactions among vehicles. Evaluated on the NGSIM dataset, EquiDiff outperformed baseline models in short-term prediction accuracy, achieving a Root Mean Square Error (RMSE) of 0.55 at 1 second and 4.01 at 5 seconds¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. However, it showed higher errors in long-term predictions, which highlights limitations in the model‚Äôs ability to maintain accuracy over extended periods. This suggests the need for further refinement to address these long-term prediction challenges.</p>
</div>
<div id="S4.p10" class="ltx_para ltx_noindent">
<p id="S4.p10.1" class="ltx_p"><span id="S4.p10.1.1" class="ltx_text ltx_font_bold">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:mss</span></span> summarizes some of the referenced literature that uses innovative and experimental techniques in developing DMs, including applications in content security, cyber-physical system attack detection, anomaly anticipation, image deblurring, acceleration for inverse problems, image manipulation, and human motion synthesis.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S4.T2.1.1" class="ltx_text ltx_font_bold">Innovations and experimental techniques introduced by the referenced literature in the domain of DMs. FID: Frechet Inception Distance, IS: Inception Score, P<sub id="S4.T2.1.1.1" class="ltx_sub">r</sub>: Precision, R<sub id="S4.T2.1.1.2" class="ltx_sub">e</sub>: Recall, LPIPS: Learned Perceptual Image Patch Similarity, PSNR: Peak Signal-to-Noise Ratio, SSIM: Structural Similarity Index Measure, KID: Kernel Inception Distance, MPJPE: Mean Per Joint Position Error. Best results are highlighted in bold.</span></figcaption>
<table id="S4.T2.3" class="ltx_tabular">
<thead class="ltx_thead">
<tr id="S4.T2.3.1.1" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S4.T2.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T2.3.1.1.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S4.T2.3.1.1.1.1.1" class="ltx_p" style="width:8.7pt;"><span id="S4.T2.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></span>
</span>
</th>
<th id="S4.T2.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T2.3.1.1.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S4.T2.3.1.1.2.1.1" class="ltx_p" style="width:78.0pt;"><span id="S4.T2.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Algorithms</span></span>
</span>
</th>
<th id="S4.T2.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T2.3.1.1.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S4.T2.3.1.1.3.1.1" class="ltx_p" style="width:78.0pt;"><span id="S4.T2.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Applications</span></span>
</span>
</th>
<th id="S4.T2.3.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T2.3.1.1.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S4.T2.3.1.1.4.1.1" class="ltx_p" style="width:43.4pt;"><span id="S4.T2.3.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</th>
<th id="S4.T2.3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T2.3.1.1.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S4.T2.3.1.1.5.1.1" class="ltx_p" style="width:65.0pt;"><span id="S4.T2.3.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Evaluations</span></span>
</span>
</th>
<th id="S4.T2.3.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T2.3.1.1.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S4.T2.3.1.1.6.1.1" class="ltx_p" style="width:86.7pt;"><span id="S4.T2.3.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Limitations</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.2.1" class="ltx_tr">
<td id="S4.T2.3.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.1.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.1.2.1.1" class="ltx_p" style="width:78.0pt;">DT for Content Shielding in Stable DMs</span>
</span>
</td>
<td id="S4.T2.3.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.1.3.1.1" class="ltx_p" style="width:78.0pt;">Content shielding in text-to-image Diffusion Models using DT to prevent generation of unwanted concepts</span>
</span>
</td>
<td id="S4.T2.3.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.1.4.1.1" class="ltx_p" style="width:43.4pt;">COCO 30K</span>
</span>
</td>
<td id="S4.T2.3.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.1.5.1.1" class="ltx_p" style="width:65.0pt;">FID post-DT: 13.04, IS post-DT: 38.25</span>
</span>
</td>
<td id="S4.T2.3.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.1.6.1.1" class="ltx_p" style="width:86.7pt;">DT may limit model‚Äôs flexibility for diverse contexts.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.3.2" class="ltx_tr">
<td id="S4.T2.3.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.2.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.2.2.1.1" class="ltx_p" style="width:78.0pt;">TFDPM</span>
</span>
</td>
<td id="S4.T2.3.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.2.3.1.1" class="ltx_p" style="width:78.0pt;">Detecting cyber-physical system attacks using TFDPM with Graph Attention Networks for channel data correlation</span>
</span>
</td>
<td id="S4.T2.3.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.2.4.1.1" class="ltx_p" style="width:43.4pt;">PUMP, SWAT, WADI</span>
</span>
</td>
<td id="S4.T2.3.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.2.5.1.1" class="ltx_p" style="width:65.0pt;">P<sub id="S4.T2.3.3.2.5.1.1.1" class="ltx_sub">r</sub>: 0.96, R<sub id="S4.T2.3.3.2.5.1.1.2" class="ltx_sub">e</sub>: 0.91, F1: 0.91</span>
</span>
</td>
<td id="S4.T2.3.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.2.6.1.1" class="ltx_p" style="width:86.7pt;">Struggles with discrete signal modeling, needs SDE frameworks for better generative capabilities.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.4.3" class="ltx_tr">
<td id="S4.T2.3.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.3.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.3.2.1.1" class="ltx_p" style="width:78.0pt;">Maat: Anomaly Anticipation for Cloud Services</span>
</span>
</td>
<td id="S4.T2.3.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.3.3.1.1" class="ltx_p" style="width:78.0pt;">Anomaly anticipation using a two-stage Diffusion Model for cloud services, integrating metric forecasting and anomaly detection</span>
</span>
</td>
<td id="S4.T2.3.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.3.4.1.1" class="ltx_p" style="width:43.4pt;">AIOps18, Hades, Yahoo!S5</span>
</span>
</td>
<td id="S4.T2.3.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.3.5.1.1" class="ltx_p" style="width:65.0pt;"><span id="S4.T2.3.4.3.5.1.1.1" class="ltx_text ltx_font_bold">P<sub id="S4.T2.3.4.3.5.1.1.1.1" class="ltx_sub">r</sub>: 0.97</span>, <span id="S4.T2.3.4.3.5.1.1.2" class="ltx_text ltx_font_bold">R<sub id="S4.T2.3.4.3.5.1.1.2.1" class="ltx_sub">e</sub>: 0.91</span>, <span id="S4.T2.3.4.3.5.1.1.3" class="ltx_text ltx_font_bold">F1: 0.91</span></span>
</span>
</td>
<td id="S4.T2.3.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.3.6.1.1" class="ltx_p" style="width:86.7pt;">Limited generalizability and adaptability post-training.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.5.4" class="ltx_tr">
<td id="S4.T2.3.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.4.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.4.2.1.1" class="ltx_p" style="width:78.0pt;">Diffusion-based Stochastic Blind Image Deblurring</span>
</span>
</td>
<td id="S4.T2.3.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.4.3.1.1" class="ltx_p" style="width:78.0pt;">Blind image deblurring using Diffusion Models for multiple reconstructions</span>
</span>
</td>
<td id="S4.T2.3.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.4.4.1.1" class="ltx_p" style="width:43.4pt;">GoPro</span>
</span>
</td>
<td id="S4.T2.3.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.4.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 4.04, KID: 0.98, LPIPS: 0.06, PSNR: 31.66, SSIM: 0.95</span>
</span>
</td>
<td id="S4.T2.3.5.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.5.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.4.6.1.1" class="ltx_p" style="width:86.7pt;">High computational demands, needs optimized sampling or network architecture.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.6.5" class="ltx_tr">
<td id="S4.T2.3.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.5.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.5.2.1.1" class="ltx_p" style="width:78.0pt;">Come-Closer-Diffuse-Faster</span>
</span>
</td>
<td id="S4.T2.3.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.5.3.1.1" class="ltx_p" style="width:78.0pt;">Accelerating CMDs for applications like super-resolution and MRI reconstruction</span>
</span>
</td>
<td id="S4.T2.3.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.5.4.1.1" class="ltx_p" style="width:43.4pt;">FFHQ, AFHQ, fastMRI</span>
</span>
</td>
<td id="S4.T2.3.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.5.5.1.1" class="ltx_p" style="width:65.0pt;">FID varies; <span id="S4.T2.3.6.5.5.1.1.1" class="ltx_text ltx_font_bold">PSNR: 33.41</span> (best MRI case)</span>
</span>
</td>
<td id="S4.T2.3.6.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.6.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.5.6.1.1" class="ltx_p" style="width:86.7pt;">Optimal starting values (t0) vary, needs automation for practical deployment.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.7.6" class="ltx_tr">
<td id="S4.T2.3.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.6.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.6.2.1.1" class="ltx_p" style="width:78.0pt;">Selective Diffusion Distillation</span>
</span>
</td>
<td id="S4.T2.3.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.6.3.1.1" class="ltx_p" style="width:78.0pt;">Image manipulation balancing fidelity and editability without excessive noise trade-offs</span>
</span>
</td>
<td id="S4.T2.3.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.6.4.1.1" class="ltx_p" style="width:43.4pt;">N/A</span>
</span>
</td>
<td id="S4.T2.3.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.6.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 6.07, CLIP Similarity: 0.23</span>
</span>
</td>
<td id="S4.T2.3.7.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.7.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.6.6.1.1" class="ltx_p" style="width:86.7pt;">Reliance on correct timestep selection for semantic guidance may limit flexibility.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.8.7" class="ltx_tr">
<td id="S4.T2.3.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.7.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.7.2.1.1" class="ltx_p" style="width:78.0pt;">Object Motion Guided Human Motion Synthesis (OMOMO)</span>
</span>
</td>
<td id="S4.T2.3.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.7.3.1.1" class="ltx_p" style="width:78.0pt;">Full-body human motion synthesis guided by object motion using a conditional Diffusion Model</span>
</span>
</td>
<td id="S4.T2.3.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.7.4.1.1" class="ltx_p" style="width:43.4pt;">Custom dataset</span>
</span>
</td>
<td id="S4.T2.3.8.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.7.5.1.1" class="ltx_p" style="width:65.0pt;">MPJPE: 12.42, Troot: 18.44, Cprec: 0.82, Crec: 0.70, F1: 0.72</span>
</span>
</td>
<td id="S4.T2.3.8.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.7.6.1.1" class="ltx_p" style="width:86.7pt;">Limited representation of dexterous hand movements and intermittent contact scenarios.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.9.8" class="ltx_tr">
<td id="S4.T2.3.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.8.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.8.2.1.1" class="ltx_p" style="width:78.0pt;">DDPMs</span>
</span>
</td>
<td id="S4.T2.3.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.8.3.1.1" class="ltx_p" style="width:78.0pt;">Image generation using DDPMs</span>
</span>
</td>
<td id="S4.T2.3.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.8.4.1.1" class="ltx_p" style="width:43.4pt;">CIFAR-10, LSUN, CelebA</span>
</span>
</td>
<td id="S4.T2.3.9.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.8.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 3.17, IS: 9.46</span>
</span>
</td>
<td id="S4.T2.3.9.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.9.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.8.6.1.1" class="ltx_p" style="width:86.7pt;">High computational cost and slow sampling speed.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.10.9" class="ltx_tr">
<td id="S4.T2.3.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.10.9.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.10.9.2.1.1" class="ltx_p" style="width:78.0pt;">Improved Techniques for Training Score-Based Generative Models</span>
</span>
</td>
<td id="S4.T2.3.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.10.9.3.1.1" class="ltx_p" style="width:78.0pt;">Improved image generation using score-based models</span>
</span>
</td>
<td id="S4.T2.3.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.10.9.4.1.1" class="ltx_p" style="width:43.4pt;">CIFAR-10, CelebA, LSUN</span>
</span>
</td>
<td id="S4.T2.3.10.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.10.9.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 2.87, IS: 9.68</span>
</span>
</td>
<td id="S4.T2.3.10.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.10.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.10.9.6.1.1" class="ltx_p" style="width:86.7pt;">Training complexity and large computational resources required.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.11.10" class="ltx_tr">
<td id="S4.T2.3.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.11.10.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.11.10.2.1.1" class="ltx_p" style="width:78.0pt;">Score-Based Generative Modeling through SDEs</span>
</span>
</td>
<td id="S4.T2.3.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.11.10.3.1.1" class="ltx_p" style="width:78.0pt;">Image generation using SDEs for better quality</span>
</span>
</td>
<td id="S4.T2.3.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.11.10.4.1.1" class="ltx_p" style="width:43.4pt;">CIFAR-10, CelebA, LSUN, FFHQ</span>
</span>
</td>
<td id="S4.T2.3.11.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.11.10.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 2.92, IS: 9.62</span>
</span>
</td>
<td id="S4.T2.3.11.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.11.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.11.10.6.1.1" class="ltx_p" style="width:86.7pt;">SDE-based models can be computationally expensive.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.12.11" class="ltx_tr">
<td id="S4.T2.3.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.12.11.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.12.11.2.1.1" class="ltx_p" style="width:78.0pt;">Diffusion Models Beat Generative Adversarial Networks (GANs) on Image Synthesis</span>
</span>
</td>
<td id="S4.T2.3.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.12.11.3.1.1" class="ltx_p" style="width:78.0pt;">Image synthesis outperforming GANs using Diffusion Models</span>
</span>
</td>
<td id="S4.T2.3.12.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.12.11.4.1.1" class="ltx_p" style="width:43.4pt;">ImageNet, LSUN, CIFAR-10</span>
</span>
</td>
<td id="S4.T2.3.12.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.12.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.12.11.5.1.1" class="ltx_p" style="width:65.0pt;"><span id="S4.T2.3.12.11.5.1.1.1" class="ltx_text ltx_font_bold">FID: 2.97</span>, IS: 9.57</span>
</span>
</td>
<td id="S4.T2.3.12.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.12.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.12.11.6.1.1" class="ltx_p" style="width:86.7pt;">Large model size and slow training times.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.13.12" class="ltx_tr">
<td id="S4.T2.3.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.13.12.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.13.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.13.12.2.1.1" class="ltx_p" style="width:78.0pt;">VDMs</span>
</span>
</td>
<td id="S4.T2.3.13.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.13.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.13.12.3.1.1" class="ltx_p" style="width:78.0pt;">Image generation using variational Diffusion Models</span>
</span>
</td>
<td id="S4.T2.3.13.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.13.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.13.12.4.1.1" class="ltx_p" style="width:43.4pt;">CIFAR-10, CelebA, LSUN</span>
</span>
</td>
<td id="S4.T2.3.13.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.13.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.13.12.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 3.12, IS: 9.53</span>
</span>
</td>
<td id="S4.T2.3.13.12.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.13.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.13.12.6.1.1" class="ltx_p" style="width:86.7pt;">Complex model design and high computational cost.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.14.13" class="ltx_tr">
<td id="S4.T2.3.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.14.13.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.14.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.14.13.2.1.1" class="ltx_p" style="width:78.0pt;">Improved Denoising Diffusion Probabilistic Models</span>
</span>
</td>
<td id="S4.T2.3.14.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.14.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.14.13.3.1.1" class="ltx_p" style="width:78.0pt;">Enhanced DDPMs for better image quality</span>
</span>
</td>
<td id="S4.T2.3.14.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.14.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.14.13.4.1.1" class="ltx_p" style="width:43.4pt;">CIFAR-10, CelebA, LSUN</span>
</span>
</td>
<td id="S4.T2.3.14.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.14.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.14.13.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 3.05, IS: 9.50</span>
</span>
</td>
<td id="S4.T2.3.14.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.14.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.14.13.6.1.1" class="ltx_p" style="width:86.7pt;">Requires extensive hyperparameter tuning.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.15.14" class="ltx_tr">
<td id="S4.T2.3.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.15.14.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.15.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.15.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.15.14.2.1.1" class="ltx_p" style="width:78.0pt;">High-Resolution Image Synthesis with Latent Diffusion Models (LDMs)</span>
</span>
</td>
<td id="S4.T2.3.15.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.15.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.15.14.3.1.1" class="ltx_p" style="width:78.0pt;">High-resolution image and text-to-image synthesis</span>
</span>
</td>
<td id="S4.T2.3.15.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.15.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.15.14.4.1.1" class="ltx_p" style="width:43.4pt;">LAION-400M, CelebA-HQ</span>
</span>
</td>
<td id="S4.T2.3.15.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.15.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.15.14.5.1.1" class="ltx_p" style="width:65.0pt;"><span id="S4.T2.3.15.14.5.1.1.1" class="ltx_text ltx_font_bold">FID: 1.97</span>, IS: 10.32</span>
</span>
</td>
<td id="S4.T2.3.15.14.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.15.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.15.14.6.1.1" class="ltx_p" style="width:86.7pt;">High memory usage and computational cost.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.16.15" class="ltx_tr">
<td id="S4.T2.3.16.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.16.15.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.16.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.16.15.2.1.1" class="ltx_p" style="width:78.0pt;">Image Transformers with Autoregressive Models for High-Fidelity Image Synthesis</span>
</span>
</td>
<td id="S4.T2.3.16.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.16.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.16.15.3.1.1" class="ltx_p" style="width:78.0pt;">High-fidelity image synthesis using transformers</span>
</span>
</td>
<td id="S4.T2.3.16.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.16.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.16.15.4.1.1" class="ltx_p" style="width:43.4pt;">ImageNet, COCO</span>
</span>
</td>
<td id="S4.T2.3.16.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.16.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.16.15.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 2.30, IS: 9.95</span>
</span>
</td>
<td id="S4.T2.3.16.15.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.16.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.16.15.6.1.1" class="ltx_p" style="width:86.7pt;">Transformer models are computationally intensive.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.17.16" class="ltx_tr">
<td id="S4.T2.3.17.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.17.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.17.16.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.17.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.17.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.17.16.2.1.1" class="ltx_p" style="width:78.0pt;">Cascaded Diffusion Models for High-Fidelity Image Generation</span>
</span>
</td>
<td id="S4.T2.3.17.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.17.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.17.16.3.1.1" class="ltx_p" style="width:78.0pt;">High-fidelity image generation using multiscale Diffusion Models</span>
</span>
</td>
<td id="S4.T2.3.17.16.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.17.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.17.16.4.1.1" class="ltx_p" style="width:43.4pt;">ImageNet, CIFAR-10, LSUN</span>
</span>
</td>
<td id="S4.T2.3.17.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.17.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.17.16.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 2.15, IS: 9.88</span>
</span>
</td>
<td id="S4.T2.3.17.16.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.17.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.17.16.6.1.1" class="ltx_p" style="width:86.7pt;">Cascaded models require extensive computational resources.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.18.17" class="ltx_tr">
<td id="S4.T2.3.18.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.18.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.18.17.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.18.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.18.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.18.17.2.1.1" class="ltx_p" style="width:78.0pt;">Optimizing Diffusion Models for Image Synthesis</span>
</span>
</td>
<td id="S4.T2.3.18.17.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.18.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.18.17.3.1.1" class="ltx_p" style="width:78.0pt;">Adaptive Diffusion Models for better image synthesis</span>
</span>
</td>
<td id="S4.T2.3.18.17.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.18.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.18.17.4.1.1" class="ltx_p" style="width:43.4pt;">CIFAR-10, CelebA, FFHQ</span>
</span>
</td>
<td id="S4.T2.3.18.17.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.18.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.18.17.5.1.1" class="ltx_p" style="width:65.0pt;"><span id="S4.T2.3.18.17.5.1.1.1" class="ltx_text ltx_font_bold">FID: 1.89</span>, IS: 10.45</span>
</span>
</td>
<td id="S4.T2.3.18.17.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.18.17.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.18.17.6.1.1" class="ltx_p" style="width:86.7pt;">Adaptive models can be complex and resource-intensive.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.19.18" class="ltx_tr">
<td id="S4.T2.3.19.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.19.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.19.18.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.19.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.19.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.19.18.2.1.1" class="ltx_p" style="width:78.0pt;">DiffWave</span>
</span>
</td>
<td id="S4.T2.3.19.18.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.19.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.19.18.3.1.1" class="ltx_p" style="width:78.0pt;">Audio generation using Diffusion Models</span>
</span>
</td>
<td id="S4.T2.3.19.18.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.19.18.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.19.18.4.1.1" class="ltx_p" style="width:43.4pt;">LJSpeech, VCTK</span>
</span>
</td>
<td id="S4.T2.3.19.18.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.19.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.19.18.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 3.67, PSNR: 34.10</span>
</span>
</td>
<td id="S4.T2.3.19.18.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.19.18.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.19.18.6.1.1" class="ltx_p" style="width:86.7pt;">High computational cost and slow sampling speed.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.20.19" class="ltx_tr">
<td id="S4.T2.3.20.19.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.20.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.20.19.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.20.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.20.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.20.19.2.1.1" class="ltx_p" style="width:78.0pt;">Video Diffusion Models (Video-DDPM)</span>
</span>
</td>
<td id="S4.T2.3.20.19.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.20.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.20.19.3.1.1" class="ltx_p" style="width:78.0pt;">Video generation using Diffusion Models</span>
</span>
</td>
<td id="S4.T2.3.20.19.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.20.19.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.20.19.4.1.1" class="ltx_p" style="width:43.4pt;">Kinetics-600, UCF-101</span>
</span>
</td>
<td id="S4.T2.3.20.19.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.20.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.20.19.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 3.85, SSIM: 0.92</span>
</span>
</td>
<td id="S4.T2.3.20.19.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.20.19.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.20.19.6.1.1" class="ltx_p" style="width:86.7pt;">High computational demands and slow training times.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.21.20" class="ltx_tr">
<td id="S4.T2.3.21.20.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.21.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.21.20.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.21.20.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.21.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.21.20.2.1.1" class="ltx_p" style="width:78.0pt;">SegDiff</span>
</span>
</td>
<td id="S4.T2.3.21.20.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.21.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.21.20.3.1.1" class="ltx_p" style="width:78.0pt;">Image segmentation using Diffusion Models</span>
</span>
</td>
<td id="S4.T2.3.21.20.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.21.20.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.21.20.4.1.1" class="ltx_p" style="width:43.4pt;">Cityscapes, Pascal VOC</span>
</span>
</td>
<td id="S4.T2.3.21.20.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.21.20.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.21.20.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 3.50, SSIM: 0.87</span>
</span>
</td>
<td id="S4.T2.3.21.20.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.21.20.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.21.20.6.1.1" class="ltx_p" style="width:86.7pt;">Limited scalability to larger datasets.</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.22.21" class="ltx_tr">
<td id="S4.T2.3.22.21.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T2.3.22.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.22.21.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite></span>
</span>
</td>
<td id="S4.T2.3.22.21.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T2.3.22.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.22.21.2.1.1" class="ltx_p" style="width:78.0pt;">GLIDE</span>
</span>
</td>
<td id="S4.T2.3.22.21.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T2.3.22.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.22.21.3.1.1" class="ltx_p" style="width:78.0pt;">Photorealistic image generation and editing with text guidance</span>
</span>
</td>
<td id="S4.T2.3.22.21.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T2.3.22.21.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.22.21.4.1.1" class="ltx_p" style="width:43.4pt;">MS-COCO, ImageNet</span>
</span>
</td>
<td id="S4.T2.3.22.21.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T2.3.22.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.22.21.5.1.1" class="ltx_p" style="width:65.0pt;">FID: 3.21, IS: 9.67</span>
</span>
</td>
<td id="S4.T2.3.22.21.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T2.3.22.21.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.22.21.6.1.1" class="ltx_p" style="width:86.7pt;">Text-guided models require extensive training data.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S4.T2.4.1" class="ltx_text ltx_font_bold">Innovations and experimental techniques introduced by the referenced literature in the domain of DMs (cont.).</span></figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Media Quality, Authenticity, and Synthesis</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Several studies propose DMs to improve media quality and create realistic samples. <span id="S5.p1.1.1" class="ltx_text ltx_font_bold">Figure¬†<a href="#S5.F6" title="Figure 6 ‚Ä£ 5 Media Quality, Authenticity, and Synthesis ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a></span> illustrates an orthogonal, semi-parametric DM, which includes a trainable Conditional Generative Model, an external database for visual examples, and a sampling strategy to retrieve subsets for conditioning the model¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2408.10207/assets/overviewdemo1.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="239" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="S5.F6.26.13" class="ltx_text ltx_font_bold">A semi-parametric generative model consists of a trainable Conditional Generative Model <math id="S5.F6.14.1.m1.1" class="ltx_Math" alttext="p_{\theta}(x|\cdot)" display="inline"><semantics id="S5.F6.14.1.m1.1b"><mrow id="S5.F6.14.1.m1.1.1" xref="S5.F6.14.1.m1.1.1.cmml"><msub id="S5.F6.14.1.m1.1.1.3" xref="S5.F6.14.1.m1.1.1.3.cmml"><mi id="S5.F6.14.1.m1.1.1.3.2" xref="S5.F6.14.1.m1.1.1.3.2.cmml">p</mi><mi id="S5.F6.14.1.m1.1.1.3.3" xref="S5.F6.14.1.m1.1.1.3.3.cmml">Œ∏</mi></msub><mo lspace="0em" rspace="0em" id="S5.F6.14.1.m1.1.1.2" xref="S5.F6.14.1.m1.1.1.2.cmml">‚Äã</mo><mrow id="S5.F6.14.1.m1.1.1.1.1" xref="S5.F6.14.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.F6.14.1.m1.1.1.1.1.2" xref="S5.F6.14.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.F6.14.1.m1.1.1.1.1.1" xref="S5.F6.14.1.m1.1.1.1.1.1.cmml"><mi id="S5.F6.14.1.m1.1.1.1.1.1.2" xref="S5.F6.14.1.m1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" rspace="0em" id="S5.F6.14.1.m1.1.1.1.1.1.1" xref="S5.F6.14.1.m1.1.1.1.1.1.1.cmml">|</mo><mo lspace="0em" rspace="0em" id="S5.F6.14.1.m1.1.1.1.1.1.3" xref="S5.F6.14.1.m1.1.1.1.1.1.3.cmml">‚ãÖ</mo></mrow><mo stretchy="false" id="S5.F6.14.1.m1.1.1.1.1.3" xref="S5.F6.14.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.14.1.m1.1c"><apply id="S5.F6.14.1.m1.1.1.cmml" xref="S5.F6.14.1.m1.1.1"><times id="S5.F6.14.1.m1.1.1.2.cmml" xref="S5.F6.14.1.m1.1.1.2"></times><apply id="S5.F6.14.1.m1.1.1.3.cmml" xref="S5.F6.14.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.F6.14.1.m1.1.1.3.1.cmml" xref="S5.F6.14.1.m1.1.1.3">subscript</csymbol><ci id="S5.F6.14.1.m1.1.1.3.2.cmml" xref="S5.F6.14.1.m1.1.1.3.2">ùëù</ci><ci id="S5.F6.14.1.m1.1.1.3.3.cmml" xref="S5.F6.14.1.m1.1.1.3.3">ùúÉ</ci></apply><apply id="S5.F6.14.1.m1.1.1.1.1.1.cmml" xref="S5.F6.14.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.F6.14.1.m1.1.1.1.1.1.1.cmml" xref="S5.F6.14.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S5.F6.14.1.m1.1.1.1.1.1.2.cmml" xref="S5.F6.14.1.m1.1.1.1.1.1.2">ùë•</ci><ci id="S5.F6.14.1.m1.1.1.1.1.1.3.cmml" xref="S5.F6.14.1.m1.1.1.1.1.1.3">‚ãÖ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.14.1.m1.1d">p_{\theta}(x|\cdot)</annotation></semantics></math>, an external database <math id="S5.F6.15.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S5.F6.15.2.m2.1b"><mi id="S5.F6.15.2.m2.1.1" xref="S5.F6.15.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S5.F6.15.2.m2.1c"><ci id="S5.F6.15.2.m2.1.1.cmml" xref="S5.F6.15.2.m2.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.15.2.m2.1d">D</annotation></semantics></math> with visual examples, and a sampling strategy <math id="S5.F6.16.3.m3.1" class="ltx_Math" alttext="\xi_{k}" display="inline"><semantics id="S5.F6.16.3.m3.1b"><msub id="S5.F6.16.3.m3.1.1" xref="S5.F6.16.3.m3.1.1.cmml"><mi id="S5.F6.16.3.m3.1.1.2" xref="S5.F6.16.3.m3.1.1.2.cmml">Œæ</mi><mi id="S5.F6.16.3.m3.1.1.3" xref="S5.F6.16.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.16.3.m3.1c"><apply id="S5.F6.16.3.m3.1.1.cmml" xref="S5.F6.16.3.m3.1.1"><csymbol cd="ambiguous" id="S5.F6.16.3.m3.1.1.1.cmml" xref="S5.F6.16.3.m3.1.1">subscript</csymbol><ci id="S5.F6.16.3.m3.1.1.2.cmml" xref="S5.F6.16.3.m3.1.1.2">ùúâ</ci><ci id="S5.F6.16.3.m3.1.1.3.cmml" xref="S5.F6.16.3.m3.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.16.3.m3.1d">\xi_{k}</annotation></semantics></math> that selects a subset <math id="S5.F6.17.4.m4.1" class="ltx_Math" alttext="M(k)_{D}\subseteq D" display="inline"><semantics id="S5.F6.17.4.m4.1b"><mrow id="S5.F6.17.4.m4.1.2" xref="S5.F6.17.4.m4.1.2.cmml"><mrow id="S5.F6.17.4.m4.1.2.2" xref="S5.F6.17.4.m4.1.2.2.cmml"><mi id="S5.F6.17.4.m4.1.2.2.2" xref="S5.F6.17.4.m4.1.2.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S5.F6.17.4.m4.1.2.2.1" xref="S5.F6.17.4.m4.1.2.2.1.cmml">‚Äã</mo><msub id="S5.F6.17.4.m4.1.2.2.3" xref="S5.F6.17.4.m4.1.2.2.3.cmml"><mrow id="S5.F6.17.4.m4.1.2.2.3.2.2" xref="S5.F6.17.4.m4.1.2.2.3.cmml"><mo stretchy="false" id="S5.F6.17.4.m4.1.2.2.3.2.2.1" xref="S5.F6.17.4.m4.1.2.2.3.cmml">(</mo><mi id="S5.F6.17.4.m4.1.1" xref="S5.F6.17.4.m4.1.1.cmml">k</mi><mo stretchy="false" id="S5.F6.17.4.m4.1.2.2.3.2.2.2" xref="S5.F6.17.4.m4.1.2.2.3.cmml">)</mo></mrow><mi id="S5.F6.17.4.m4.1.2.2.3.3" xref="S5.F6.17.4.m4.1.2.2.3.3.cmml">D</mi></msub></mrow><mo id="S5.F6.17.4.m4.1.2.1" xref="S5.F6.17.4.m4.1.2.1.cmml">‚äÜ</mo><mi id="S5.F6.17.4.m4.1.2.3" xref="S5.F6.17.4.m4.1.2.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.17.4.m4.1c"><apply id="S5.F6.17.4.m4.1.2.cmml" xref="S5.F6.17.4.m4.1.2"><subset id="S5.F6.17.4.m4.1.2.1.cmml" xref="S5.F6.17.4.m4.1.2.1"></subset><apply id="S5.F6.17.4.m4.1.2.2.cmml" xref="S5.F6.17.4.m4.1.2.2"><times id="S5.F6.17.4.m4.1.2.2.1.cmml" xref="S5.F6.17.4.m4.1.2.2.1"></times><ci id="S5.F6.17.4.m4.1.2.2.2.cmml" xref="S5.F6.17.4.m4.1.2.2.2">ùëÄ</ci><apply id="S5.F6.17.4.m4.1.2.2.3.cmml" xref="S5.F6.17.4.m4.1.2.2.3"><csymbol cd="ambiguous" id="S5.F6.17.4.m4.1.2.2.3.1.cmml" xref="S5.F6.17.4.m4.1.2.2.3">subscript</csymbol><ci id="S5.F6.17.4.m4.1.1.cmml" xref="S5.F6.17.4.m4.1.1">ùëò</ci><ci id="S5.F6.17.4.m4.1.2.2.3.3.cmml" xref="S5.F6.17.4.m4.1.2.2.3.3">ùê∑</ci></apply></apply><ci id="S5.F6.17.4.m4.1.2.3.cmml" xref="S5.F6.17.4.m4.1.2.3">ùê∑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.17.4.m4.1d">M(k)_{D}\subseteq D</annotation></semantics></math> for conditioning <math id="S5.F6.18.5.m5.1" class="ltx_Math" alttext="p_{\theta}" display="inline"><semantics id="S5.F6.18.5.m5.1b"><msub id="S5.F6.18.5.m5.1.1" xref="S5.F6.18.5.m5.1.1.cmml"><mi id="S5.F6.18.5.m5.1.1.2" xref="S5.F6.18.5.m5.1.1.2.cmml">p</mi><mi id="S5.F6.18.5.m5.1.1.3" xref="S5.F6.18.5.m5.1.1.3.cmml">Œ∏</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.18.5.m5.1c"><apply id="S5.F6.18.5.m5.1.1.cmml" xref="S5.F6.18.5.m5.1.1"><csymbol cd="ambiguous" id="S5.F6.18.5.m5.1.1.1.cmml" xref="S5.F6.18.5.m5.1.1">subscript</csymbol><ci id="S5.F6.18.5.m5.1.1.2.cmml" xref="S5.F6.18.5.m5.1.1.2">ùëù</ci><ci id="S5.F6.18.5.m5.1.1.3.cmml" xref="S5.F6.18.5.m5.1.1.3">ùúÉ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.18.5.m5.1d">p_{\theta}</annotation></semantics></math>. To train <math id="S5.F6.19.6.m6.1" class="ltx_Math" alttext="p_{\theta}" display="inline"><semantics id="S5.F6.19.6.m6.1b"><msub id="S5.F6.19.6.m6.1.1" xref="S5.F6.19.6.m6.1.1.cmml"><mi id="S5.F6.19.6.m6.1.1.2" xref="S5.F6.19.6.m6.1.1.2.cmml">p</mi><mi id="S5.F6.19.6.m6.1.1.3" xref="S5.F6.19.6.m6.1.1.3.cmml">Œ∏</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.19.6.m6.1c"><apply id="S5.F6.19.6.m6.1.1.cmml" xref="S5.F6.19.6.m6.1.1"><csymbol cd="ambiguous" id="S5.F6.19.6.m6.1.1.1.cmml" xref="S5.F6.19.6.m6.1.1">subscript</csymbol><ci id="S5.F6.19.6.m6.1.1.2.cmml" xref="S5.F6.19.6.m6.1.1.2">ùëù</ci><ci id="S5.F6.19.6.m6.1.1.3.cmml" xref="S5.F6.19.6.m6.1.1.3">ùúÉ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.19.6.m6.1d">p_{\theta}</annotation></semantics></math> to create consistent scenes using <math id="S5.F6.20.7.m7.1" class="ltx_Math" alttext="M(k)_{D}" display="inline"><semantics id="S5.F6.20.7.m7.1b"><mrow id="S5.F6.20.7.m7.1.2" xref="S5.F6.20.7.m7.1.2.cmml"><mi id="S5.F6.20.7.m7.1.2.2" xref="S5.F6.20.7.m7.1.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S5.F6.20.7.m7.1.2.1" xref="S5.F6.20.7.m7.1.2.1.cmml">‚Äã</mo><msub id="S5.F6.20.7.m7.1.2.3" xref="S5.F6.20.7.m7.1.2.3.cmml"><mrow id="S5.F6.20.7.m7.1.2.3.2.2" xref="S5.F6.20.7.m7.1.2.3.cmml"><mo stretchy="false" id="S5.F6.20.7.m7.1.2.3.2.2.1" xref="S5.F6.20.7.m7.1.2.3.cmml">(</mo><mi id="S5.F6.20.7.m7.1.1" xref="S5.F6.20.7.m7.1.1.cmml">k</mi><mo stretchy="false" id="S5.F6.20.7.m7.1.2.3.2.2.2" xref="S5.F6.20.7.m7.1.2.3.cmml">)</mo></mrow><mi id="S5.F6.20.7.m7.1.2.3.3" xref="S5.F6.20.7.m7.1.2.3.3.cmml">D</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.20.7.m7.1c"><apply id="S5.F6.20.7.m7.1.2.cmml" xref="S5.F6.20.7.m7.1.2"><times id="S5.F6.20.7.m7.1.2.1.cmml" xref="S5.F6.20.7.m7.1.2.1"></times><ci id="S5.F6.20.7.m7.1.2.2.cmml" xref="S5.F6.20.7.m7.1.2.2">ùëÄ</ci><apply id="S5.F6.20.7.m7.1.2.3.cmml" xref="S5.F6.20.7.m7.1.2.3"><csymbol cd="ambiguous" id="S5.F6.20.7.m7.1.2.3.1.cmml" xref="S5.F6.20.7.m7.1.2.3">subscript</csymbol><ci id="S5.F6.20.7.m7.1.1.cmml" xref="S5.F6.20.7.m7.1.1">ùëò</ci><ci id="S5.F6.20.7.m7.1.2.3.3.cmml" xref="S5.F6.20.7.m7.1.2.3.3">ùê∑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.20.7.m7.1d">M(k)_{D}</annotation></semantics></math>, <math id="S5.F6.21.8.m8.1" class="ltx_Math" alttext="\xi_{k}" display="inline"><semantics id="S5.F6.21.8.m8.1b"><msub id="S5.F6.21.8.m8.1.1" xref="S5.F6.21.8.m8.1.1.cmml"><mi id="S5.F6.21.8.m8.1.1.2" xref="S5.F6.21.8.m8.1.1.2.cmml">Œæ</mi><mi id="S5.F6.21.8.m8.1.1.3" xref="S5.F6.21.8.m8.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.21.8.m8.1c"><apply id="S5.F6.21.8.m8.1.1.cmml" xref="S5.F6.21.8.m8.1.1"><csymbol cd="ambiguous" id="S5.F6.21.8.m8.1.1.1.cmml" xref="S5.F6.21.8.m8.1.1">subscript</csymbol><ci id="S5.F6.21.8.m8.1.1.2.cmml" xref="S5.F6.21.8.m8.1.1.2">ùúâ</ci><ci id="S5.F6.21.8.m8.1.1.3.cmml" xref="S5.F6.21.8.m8.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.21.8.m8.1d">\xi_{k}</annotation></semantics></math> retrieves the nearest neighbors of each target example from <math id="S5.F6.22.9.m9.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S5.F6.22.9.m9.1b"><mi id="S5.F6.22.9.m9.1.1" xref="S5.F6.22.9.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S5.F6.22.9.m9.1c"><ci id="S5.F6.22.9.m9.1.1.cmml" xref="S5.F6.22.9.m9.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.22.9.m9.1d">D</annotation></semantics></math>. By adjusting <math id="S5.F6.23.10.m10.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S5.F6.23.10.m10.1b"><mi id="S5.F6.23.10.m10.1.1" xref="S5.F6.23.10.m10.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S5.F6.23.10.m10.1c"><ci id="S5.F6.23.10.m10.1.1.cmml" xref="S5.F6.23.10.m10.1.1">ùê∑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.23.10.m10.1d">D</annotation></semantics></math> and <math id="S5.F6.24.11.m11.1" class="ltx_Math" alttext="\xi_{k}" display="inline"><semantics id="S5.F6.24.11.m11.1b"><msub id="S5.F6.24.11.m11.1.1" xref="S5.F6.24.11.m11.1.1.cmml"><mi id="S5.F6.24.11.m11.1.1.2" xref="S5.F6.24.11.m11.1.1.2.cmml">Œæ</mi><mi id="S5.F6.24.11.m11.1.1.3" xref="S5.F6.24.11.m11.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.24.11.m11.1c"><apply id="S5.F6.24.11.m11.1.1.cmml" xref="S5.F6.24.11.m11.1.1"><csymbol cd="ambiguous" id="S5.F6.24.11.m11.1.1.1.cmml" xref="S5.F6.24.11.m11.1.1">subscript</csymbol><ci id="S5.F6.24.11.m11.1.1.2.cmml" xref="S5.F6.24.11.m11.1.1.2">ùúâ</ci><ci id="S5.F6.24.11.m11.1.1.3.cmml" xref="S5.F6.24.11.m11.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.24.11.m11.1d">\xi_{k}</annotation></semantics></math> during inference, the model can flexibly sample with post-hoc conditioning on class labels (<math id="S5.F6.25.12.m12.1" class="ltx_Math" alttext="\xi^{1}_{k}" display="inline"><semantics id="S5.F6.25.12.m12.1b"><msubsup id="S5.F6.25.12.m12.1.1" xref="S5.F6.25.12.m12.1.1.cmml"><mi id="S5.F6.25.12.m12.1.1.2.2" xref="S5.F6.25.12.m12.1.1.2.2.cmml">Œæ</mi><mi id="S5.F6.25.12.m12.1.1.3" xref="S5.F6.25.12.m12.1.1.3.cmml">k</mi><mn id="S5.F6.25.12.m12.1.1.2.3" xref="S5.F6.25.12.m12.1.1.2.3.cmml">1</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.F6.25.12.m12.1c"><apply id="S5.F6.25.12.m12.1.1.cmml" xref="S5.F6.25.12.m12.1.1"><csymbol cd="ambiguous" id="S5.F6.25.12.m12.1.1.1.cmml" xref="S5.F6.25.12.m12.1.1">subscript</csymbol><apply id="S5.F6.25.12.m12.1.1.2.cmml" xref="S5.F6.25.12.m12.1.1"><csymbol cd="ambiguous" id="S5.F6.25.12.m12.1.1.2.1.cmml" xref="S5.F6.25.12.m12.1.1">superscript</csymbol><ci id="S5.F6.25.12.m12.1.1.2.2.cmml" xref="S5.F6.25.12.m12.1.1.2.2">ùúâ</ci><cn type="integer" id="S5.F6.25.12.m12.1.1.2.3.cmml" xref="S5.F6.25.12.m12.1.1.2.3">1</cn></apply><ci id="S5.F6.25.12.m12.1.1.3.cmml" xref="S5.F6.25.12.m12.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.25.12.m12.1d">\xi^{1}_{k}</annotation></semantics></math>) or text prompts (<math id="S5.F6.26.13.m13.1" class="ltx_Math" alttext="\xi^{3}_{k}" display="inline"><semantics id="S5.F6.26.13.m13.1b"><msubsup id="S5.F6.26.13.m13.1.1" xref="S5.F6.26.13.m13.1.1.cmml"><mi id="S5.F6.26.13.m13.1.1.2.2" xref="S5.F6.26.13.m13.1.1.2.2.cmml">Œæ</mi><mi id="S5.F6.26.13.m13.1.1.3" xref="S5.F6.26.13.m13.1.1.3.cmml">k</mi><mn id="S5.F6.26.13.m13.1.1.2.3" xref="S5.F6.26.13.m13.1.1.2.3.cmml">3</mn></msubsup><annotation-xml encoding="MathML-Content" id="S5.F6.26.13.m13.1c"><apply id="S5.F6.26.13.m13.1.1.cmml" xref="S5.F6.26.13.m13.1.1"><csymbol cd="ambiguous" id="S5.F6.26.13.m13.1.1.1.cmml" xref="S5.F6.26.13.m13.1.1">subscript</csymbol><apply id="S5.F6.26.13.m13.1.1.2.cmml" xref="S5.F6.26.13.m13.1.1"><csymbol cd="ambiguous" id="S5.F6.26.13.m13.1.1.2.1.cmml" xref="S5.F6.26.13.m13.1.1">superscript</csymbol><ci id="S5.F6.26.13.m13.1.1.2.2.cmml" xref="S5.F6.26.13.m13.1.1.2.2">ùúâ</ci><cn type="integer" id="S5.F6.26.13.m13.1.1.2.3.cmml" xref="S5.F6.26.13.m13.1.1.2.3">3</cn></apply><ci id="S5.F6.26.13.m13.1.1.3.cmml" xref="S5.F6.26.13.m13.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.26.13.m13.1d">\xi^{3}_{k}</annotation></semantics></math>), and perform zero-shot stylization¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</span>
</figcaption>
</figure>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p">Hong et al. (2023) introduced <span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Self-Attention Guidance (SAG)</span> to improve image generation using Denoising Diffusion Models (DDMs). SAG leverages self-attention maps to focus on significant areas, reducing artifacts and improving image quality. Evaluation on various platforms revealed that SAG significantly improved both FID and IS compared to existing methods¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p">Ji et al. (2024) introduced a <span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Learnable State-Estimator-based DMs</span> for inverse imaging problems, restoring clean images from corrupted inputs with high fidelity. This method uses a state estimator to dynamically adjust the diffusion process within a latent space, achieving computational efficiency and avoiding extensive training. Evaluated on tasks like inpainting, deblurring, and JPEG compression restoration, it showed strong performance, particularly on the FFHQ dataset with a PSNR of 27.98, LPIPS of 0.0939, and FID of 25.453¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. However, the model relies on current generative abilities and needs domain-specific adaptations for broader applications.</p>
</div>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.1" class="ltx_p">Tian et al. (2023) introduced <span id="S5.p4.1.1" class="ltx_text ltx_font_bold">Diffusion Model for Speech Enhancement text (DMSEtext)</span>, a conditional DMs designed to enhance speech quality in Text-to-Speech (TTS) systems by addressing audio degradations. Operating in the log Mel-spectrogram domain, it uses text transcriptions to improve audio fidelity. DMSEtext achieved a Mean Opinion Score (MOS) of 4.32 for cleanliness and 4.17 overall, with a reduced Phoneme Error Rate (PER) of 17.6%, indicating improved clarity and authenticity¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. However, its performance depends on the quality of text transcription and varies under different audio types.</p>
</div>
<div id="S5.p5" class="ltx_para ltx_noindent">
<p id="S5.p5.1" class="ltx_p">Jiang et al. (2023) introduced <span id="S5.p5.1.1" class="ltx_text ltx_font_bold">Diffusion Model for Low-Light (DiffLL)</span>, a framework for improving low-light images using a Wavelet-based Conditional Diffusion Model. This model increases inference speed and reduces computational demands while maintaining high image quality. A High-Frequency Restoration Module improves image details. DiffLL outperformed current methods on benchmarks like LOL-v1, LOLv2-real, and LSRW in PSNR, SSIM, LPIPS, and FID metrics¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. However, it struggles with extremely low-light conditions and is not optimized for real-time video processing. Additionally, the study did not consider real-time video support and handling diverse lighting conditions, which remain areas for further investigation.</p>
</div>
<div id="S5.p6" class="ltx_para ltx_noindent">
<p id="S5.p6.1" class="ltx_p">Dong et al. (2023) proposed <span id="S5.p6.1.1" class="ltx_text ltx_font_bold">Controlled Language-Image Pretraining Sonic (CLIPSonic)</span>, a text-to-audio synthesis method using unlabeled videos and pretrained language-vision models. It employs a conditional DMs to generate audio by translating text embeddings into image embeddings, improving zero-shot modality transfer. CLIPSonic demonstrated competitive performance on VGGSound and MUSIC datasets¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. However, its effectiveness is limited by the quality of pretrained models, distribution mismatches, and training complexity, posing scalability challenges.</p>
</div>
<div id="S5.p7" class="ltx_para ltx_noindent">
<p id="S5.p7.1" class="ltx_p">Liu et al. (2023) proposed <span id="S5.p7.1.1" class="ltx_text ltx_font_bold">Semantic Diffusion Guidance (SDG)</span>, a framework that improves DDMs with fine-grained control using language, image, or both modalities. SDG integrates guidance into pretrained models via image-text or image matching score gradients which eliminates the need for retraining. It enables text-guided image synthesis on datasets without text annotations using CLIP-based guidance and demonstrates better accuracy over baseline models such as Iterative Latent Variable Refinement¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> and StyleGAN+CLIP. On the FFHQ dataset, the proposed SDG models achieved an FID score of 14.37 and a top-1% accuracy of 0.520. Additionally, the ablation studies on LSUN showed minor performance improvements with different scaling factors¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. However, SDG‚Äôs effectiveness depends on the accuracy of pretrained models and their ability to process guidance signals. Additionally, the framework poses potential risks of misuse which necessitates the requirement of ethical guidelines to ensure responsible deployment.</p>
</div>
<div id="S5.p8" class="ltx_para ltx_noindent">
<p id="S5.p8.1" class="ltx_p">Cai et al. (2023) introduced <span id="S5.p8.1.1" class="ltx_text ltx_font_bold">Diffusion Dreamer (DiffDreamer)</span>, an unsupervised framework for scene extrapolation using conditional DMs to generate novel views from given images. By training on internet-collected nature images, DiffDreamer refines projected RGBD images through guided denoising steps, conditioned on multiple past and future frames. It significantly outperforms previous GAN-based methods in quality and consistency. On the LHQ dataset, DiffDreamer achieved an FID score of 51.0 over 100 steps and 34.49 over 20 steps¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. However, DiffDreamer cannot synthesize novel views in real time due to the computational intensity of DMs and does not ensure content diversity in extended extrapolations.</p>
</div>
<div id="S5.p9" class="ltx_para ltx_noindent">
<p id="S5.p9.1" class="ltx_p">Carrillo et al. (2023) proposed an interactive approach for line art colorization using conditional Diffusion Probabilistic Models, allowing users to input initial color strokes. The system integrates these inputs via a dual conditioning strategy, producing diverse, high-quality images. Their model outperforms SOTA methods by achieving an SSIM of 0.81, LPIPS of 0.14, and FID of 6.15. However, the model‚Äôs accuracy depends on the quality of user input, and the complex conditioning strategy may cause computational inefficiencies, which could eventually affect scalability as well¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
<div id="S5.p10" class="ltx_para ltx_noindent">
<p id="S5.p10.1" class="ltx_p">Mao et al. (2023) introduced <span id="S5.p10.1.1" class="ltx_text ltx_font_bold">Sketch-Driven Fusion (SketchFFusion)</span>, a model for sketch-guided image editing using a conditional Diffusion Model. SketchFFusion maintains the integrity of sketches while editing, simulating human sketch styles and preserving structural details. On the CelebA-HQ dataset, it outperformed SOTA methods with an FID of 9.07, PSNR of 26.74, and SSIM of 0.8822. The model was also tested on the COCO-AIGC dataset, demonstrating adaptability across various scenes and objects¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. However, SketchFFusion currently only supports binary sketches, limiting its use to black-and-white inputs.</p>
</div>
<div id="S5.p11" class="ltx_para ltx_noindent">
<p id="S5.p11.1" class="ltx_p">Luo et al. (2023) introduced <span id="S5.p11.1.1" class="ltx_text ltx_font_bold">Semantic-Conditional Diffusion Networks</span> for image captioning, leveraging DMs to improve visual-language alignment and coherence. Unlike traditional transformer models, their approach uses semantic priors from cross-modal retrieval and refines captions through multiple Diffusion Transformer layers. This dynamic integration of image and text features enhances caption relevance and accuracy. On the Common Objects in Context dataset, it achieved a Consensus-based Image Description Evaluation score of 131.6 and a BLEU-4 score of 39.4, outperforming SOTA models¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.</p>
</div>
<div id="S5.p12" class="ltx_para">
<p id="S5.p12.1" class="ltx_p"><span id="S5.p12.1.1" class="ltx_text ltx_font_bold">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:medau</span></span> summarizes some of the referenced literature that proposes different diffusion-based approaches to improve media quality and increase authenticity.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S5.T3.1.1" class="ltx_text ltx_font_bold">Improving media quality using diffusion-based approaches as demonstrated in the existing literature. FID: Frechet Inception Distance, IS: Inception Score, P<sub id="S5.T3.1.1.1" class="ltx_sub">r</sub>: Precision, R<sub id="S5.T3.1.1.2" class="ltx_sub">e</sub>: Recall, LPIPS: Perceptual Image Patch Similarity, PSNR: Peak Signal-to-Noise Ratio, SSIM: Structural Similarity Index Measure, KID: Kernel Inception Distance, MPJPE: Mean Per Joint Position Error. Best results are highlighted in bold.</span></figcaption>
<table id="S5.T3.3" class="ltx_tabular">
<thead class="ltx_thead">
<tr id="S5.T3.3.1.1" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S5.T3.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S5.T3.3.1.1.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S5.T3.3.1.1.1.1.1" class="ltx_p" style="width:8.7pt;"><span id="S5.T3.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></span>
</span>
</th>
<th id="S5.T3.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S5.T3.3.1.1.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S5.T3.3.1.1.2.1.1" class="ltx_p" style="width:78.0pt;"><span id="S5.T3.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Algorithms</span></span>
</span>
</th>
<th id="S5.T3.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S5.T3.3.1.1.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S5.T3.3.1.1.3.1.1" class="ltx_p" style="width:78.0pt;"><span id="S5.T3.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Applications</span></span>
</span>
</th>
<th id="S5.T3.3.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S5.T3.3.1.1.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S5.T3.3.1.1.4.1.1" class="ltx_p" style="width:43.4pt;"><span id="S5.T3.3.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</th>
<th id="S5.T3.3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S5.T3.3.1.1.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S5.T3.3.1.1.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S5.T3.3.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Evaluations</span></span>
</span>
</th>
<th id="S5.T3.3.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S5.T3.3.1.1.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S5.T3.3.1.1.6.1.1" class="ltx_p" style="width:65.0pt;"><span id="S5.T3.3.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Limitations</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.3.2.1" class="ltx_tr">
<td id="S5.T3.3.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.2.1.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.2.1.2.1.1" class="ltx_p" style="width:78.0pt;">SAG in DDMs</span>
</span>
</td>
<td id="S5.T3.3.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.2.1.3.1.1" class="ltx_p" style="width:78.0pt;">Image generation improvement</span>
</span>
</td>
<td id="S5.T3.3.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.2.1.4.1.1" class="ltx_p" style="width:43.4pt;">ImageNet, LSUN</span>
</span>
</td>
<td id="S5.T3.3.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.2.1.5.1.1" class="ltx_p" style="width:86.7pt;">FID: <span id="S5.T3.3.2.1.5.1.1.1" class="ltx_text ltx_font_bold">2.58</span>, sFID: 4.35</span>
</span>
</td>
<td id="S5.T3.3.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.2.1.6.1.1" class="ltx_p" style="width:65.0pt;">Needs broader application integration.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.3.2" class="ltx_tr">
<td id="S5.T3.3.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.3.2.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.3.2.2.1.1" class="ltx_p" style="width:78.0pt;">Learnable State-Estimator-Based Diffusion Model</span>
</span>
</td>
<td id="S5.T3.3.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.3.2.3.1.1" class="ltx_p" style="width:78.0pt;">Inverse imaging problems (inpainting, deblurring, JPEG restoration)</span>
</span>
</td>
<td id="S5.T3.3.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.3.2.4.1.1" class="ltx_p" style="width:43.4pt;">FFHQ, LSUN-Bedroom</span>
</span>
</td>
<td id="S5.T3.3.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.3.2.5.1.1" class="ltx_p" style="width:86.7pt;">PSNR: 27.98, LPIPS: 0.09, FID: 25.45</span>
</span>
</td>
<td id="S5.T3.3.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.3.2.6.1.1" class="ltx_p" style="width:65.0pt;">Limited generative capabilities, needs domain adaptation.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.4.3" class="ltx_tr">
<td id="S5.T3.3.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.4.3.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.4.3.2.1.1" class="ltx_p" style="width:78.0pt;">Score Dynamics (SD)</span>
</span>
</td>
<td id="S5.T3.3.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.4.3.3.1.1" class="ltx_p" style="width:78.0pt;">Accelerating molecular dynamics simulations</span>
</span>
</td>
<td id="S5.T3.3.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.4.3.4.1.1" class="ltx_p" style="width:43.4pt;">Alanine dipeptide, short alkanes in aqueous solution</span>
</span>
</td>
<td id="S5.T3.3.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.4.3.5.1.1" class="ltx_p" style="width:86.7pt;">Wall-clock speedup up to 180X</span>
</span>
</td>
<td id="S5.T3.3.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.4.3.6.1.1" class="ltx_p" style="width:65.0pt;">Requires large datasets; generalization challenges.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.5.4" class="ltx_tr">
<td id="S5.T3.3.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.5.4.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.5.4.2.1.1" class="ltx_p" style="width:78.0pt;">CMDs for Speech Enhancement (DMSEtext)</span>
</span>
</td>
<td id="S5.T3.3.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.5.4.3.1.1" class="ltx_p" style="width:78.0pt;">Speech enhancement for TTS model training</span>
</span>
</td>
<td id="S5.T3.3.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.5.4.4.1.1" class="ltx_p" style="width:43.4pt;">Real-world recordings</span>
</span>
</td>
<td id="S5.T3.3.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.5.4.5.1.1" class="ltx_p" style="width:86.7pt;">MOS Cleanliness: <span id="S5.T3.3.5.4.5.1.1.1" class="ltx_text ltx_font_bold">4.32</span> ¬± 0.08, Overall Impression: <span id="S5.T3.3.5.4.5.1.1.2" class="ltx_text ltx_font_bold">4.17</span> ¬± 0.06, PER: 17.6%</span>
</span>
</td>
<td id="S5.T3.3.5.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.5.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.5.4.6.1.1" class="ltx_p" style="width:65.0pt;">Needs text conditions for best results.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.6.5" class="ltx_tr">
<td id="S5.T3.3.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.6.5.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.6.5.2.1.1" class="ltx_p" style="width:78.0pt;">Conditional Diffusion Model for HDR Reconstruction</span>
</span>
</td>
<td id="S5.T3.3.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.6.5.3.1.1" class="ltx_p" style="width:78.0pt;">HDR image reconstruction from LDR images</span>
</span>
</td>
<td id="S5.T3.3.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.6.5.4.1.1" class="ltx_p" style="width:43.4pt;">Benchmark datasets for HDR imaging</span>
</span>
</td>
<td id="S5.T3.3.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.6.5.5.1.1" class="ltx_p" style="width:86.7pt;">PSNR-¬µ: 44.11, PSNR-L: 41.73, SSIM-¬µ: <span id="S5.T3.3.6.5.5.1.1.1" class="ltx_text ltx_font_bold">0.99</span>, SSIM-L: <span id="S5.T3.3.6.5.5.1.1.2" class="ltx_text ltx_font_bold">0.99</span>, HDR-VDP-2: 65.52, LPIPS: 0.01, FID: 6.20</span>
</span>
</td>
<td id="S5.T3.3.6.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.6.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.6.5.6.1.1" class="ltx_p" style="width:65.0pt;">Slow inference speed; improve distortion metrics.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.7.6" class="ltx_tr">
<td id="S5.T3.3.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.7.6.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.7.6.2.1.1" class="ltx_p" style="width:78.0pt;">CLIPSonic</span>
</span>
</td>
<td id="S5.T3.3.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.7.6.3.1.1" class="ltx_p" style="width:78.0pt;">Text-to-audio synthesis using unlabeled videos</span>
</span>
</td>
<td id="S5.T3.3.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.7.6.4.1.1" class="ltx_p" style="width:43.4pt;">VGGSound, MUSIC</span>
</span>
</td>
<td id="S5.T3.3.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.7.6.5.1.1" class="ltx_p" style="width:86.7pt;">FAD: CLIPSonic-ZS on MUSIC 19.30, CLIPSonic-PD on MUSIC 13.51; CLAP score: CLIPSonic-ZS on MUSIC 0.28, CLIPSonic-PD on MUSIC 0.25</span>
</span>
</td>
<td id="S5.T3.3.7.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.7.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.7.6.6.1.1" class="ltx_p" style="width:65.0pt;">Performance drop in zero-shot modality transfer.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.8.7" class="ltx_tr">
<td id="S5.T3.3.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.8.7.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.8.7.2.1.1" class="ltx_p" style="width:78.0pt;">SDG</span>
</span>
</td>
<td id="S5.T3.3.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.8.7.3.1.1" class="ltx_p" style="width:78.0pt;">Fine-grained image synthesis with text and image guidance</span>
</span>
</td>
<td id="S5.T3.3.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.8.7.4.1.1" class="ltx_p" style="width:43.4pt;">FFHQ, LSUN</span>
</span>
</td>
<td id="S5.T3.3.8.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.8.7.5.1.1" class="ltx_p" style="width:86.7pt;">FID: 14.37 (image guidance on FFHQ), 28.38 (text guidance on FFHQ); Top-5 Retrieval Accuracy: 0.742 (image guidance), 0.878 (text guidance)</span>
</span>
</td>
<td id="S5.T3.3.8.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.8.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.8.7.6.1.1" class="ltx_p" style="width:65.0pt;">Potential misuse in image generation.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.9.8" class="ltx_tr">
<td id="S5.T3.3.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.9.8.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.9.8.2.1.1" class="ltx_p" style="width:78.0pt;">DiffDreamer: Conditional Diffusion Model for Scene Extrapolation</span>
</span>
</td>
<td id="S5.T3.3.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.9.8.3.1.1" class="ltx_p" style="width:78.0pt;">Unsupervised 3D scene extrapolation</span>
</span>
</td>
<td id="S5.T3.3.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.9.8.4.1.1" class="ltx_p" style="width:43.4pt;">LHQ, ACID</span>
</span>
</td>
<td id="S5.T3.3.9.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.9.8.5.1.1" class="ltx_p" style="width:86.7pt;">Achieves low FID scores across various step intervals, e.g., 20 steps: FID: 34.49; 100 steps: FID: 51.00 on LHQ</span>
</span>
</td>
<td id="S5.T3.3.9.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.9.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.9.8.6.1.1" class="ltx_p" style="width:65.0pt;">Real-time synthesis not feasible; limited content diversity.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.10.9" class="ltx_tr">
<td id="S5.T3.3.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.10.9.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.10.9.2.1.1" class="ltx_p" style="width:78.0pt;">Diffusart: Conditional Diffusion Probabilistic Models for Line Art Colorization</span>
</span>
</td>
<td id="S5.T3.3.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.10.9.3.1.1" class="ltx_p" style="width:78.0pt;">Interactive line art colorization with user guidance</span>
</span>
</td>
<td id="S5.T3.3.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.10.9.4.1.1" class="ltx_p" style="width:43.4pt;">Danbooru2021</span>
</span>
</td>
<td id="S5.T3.3.10.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.10.9.5.1.1" class="ltx_p" style="width:86.7pt;">SSIM: 0.81, LPIPS: 0.14, FID: <span id="S5.T3.3.10.9.5.1.1.1" class="ltx_text ltx_font_bold">6.15</span></span>
</span>
</td>
<td id="S5.T3.3.10.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.10.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.10.9.6.1.1" class="ltx_p" style="width:65.0pt;">Bias towards white; limits color diversity.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.11.10" class="ltx_tr">
<td id="S5.T3.3.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.11.10.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.11.10.2.1.1" class="ltx_p" style="width:78.0pt;">SketchFFusion: A Conditional Diffusion Model for Sketch-guided Image Editing</span>
</span>
</td>
<td id="S5.T3.3.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.11.10.3.1.1" class="ltx_p" style="width:78.0pt;">Sketch-guided image editing for local fine-tuning using generated sketches</span>
</span>
</td>
<td id="S5.T3.3.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.11.10.4.1.1" class="ltx_p" style="width:43.4pt;">CelebA-HQ, COCO-AIGC</span>
</span>
</td>
<td id="S5.T3.3.11.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.11.10.5.1.1" class="ltx_p" style="width:86.7pt;">FID: 9.07, PSNR: 26.74, SSIM: 0.88</span>
</span>
</td>
<td id="S5.T3.3.11.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.11.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.11.10.6.1.1" class="ltx_p" style="width:65.0pt;">Supports only binary sketches; limits color editing.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.12.11" class="ltx_tr">
<td id="S5.T3.3.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.12.11.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.12.11.2.1.1" class="ltx_p" style="width:78.0pt;">Semantic-Conditional Diffusion Networks for Image Captioning</span>
</span>
</td>
<td id="S5.T3.3.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.12.11.3.1.1" class="ltx_p" style="width:78.0pt;">Advanced text-to-image captioning using semantic-driven Diffusion Models</span>
</span>
</td>
<td id="S5.T3.3.12.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.12.11.4.1.1" class="ltx_p" style="width:43.4pt;">COCO</span>
</span>
</td>
<td id="S5.T3.3.12.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.12.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.12.11.5.1.1" class="ltx_p" style="width:86.7pt;">B@1: 79.0, B@2: 63.4, B@3: 49.1, B@4: 37.3, CIDEr: <span id="S5.T3.3.12.11.5.1.1.1" class="ltx_text ltx_font_bold">131.6</span></span>
</span>
</td>
<td id="S5.T3.3.12.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.12.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.12.11.6.1.1" class="ltx_p" style="width:65.0pt;">Lacks real-time processing; needs optimization.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.13.12" class="ltx_tr">
<td id="S5.T3.3.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.13.12.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.13.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.13.12.2.1.1" class="ltx_p" style="width:78.0pt;">EquiDiff: Deep Generative Model for Vehicle Trajectory Prediction</span>
</span>
</td>
<td id="S5.T3.3.13.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.13.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.13.12.3.1.1" class="ltx_p" style="width:78.0pt;">Trajectory prediction for autonomous vehicles using a deep generative model with SO(2)-equivariant transformer</span>
</span>
</td>
<td id="S5.T3.3.13.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.13.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.13.12.4.1.1" class="ltx_p" style="width:43.4pt;">NGSIM</span>
</span>
</td>
<td id="S5.T3.3.13.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.13.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.13.12.5.1.1" class="ltx_p" style="width:86.7pt;">RMSE for 5s trajectory prediction shows competitive results</span>
</span>
</td>
<td id="S5.T3.3.13.12.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T3.3.13.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.13.12.6.1.1" class="ltx_p" style="width:65.0pt;">Effective short-term; higher errors in long-term predictions.</span>
</span>
</td>
</tr>
<tr id="S5.T3.3.14.13" class="ltx_tr">
<td id="S5.T3.3.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T3.3.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.14.13.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite></span>
</span>
</td>
<td id="S5.T3.3.14.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T3.3.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.14.13.2.1.1" class="ltx_p" style="width:78.0pt;">Efficient MRI Synthesis with Conditional Diffusion Probabilistic Models</span>
</span>
</td>
<td id="S5.T3.3.14.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T3.3.14.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.14.13.3.1.1" class="ltx_p" style="width:78.0pt;">Efficient synthesis of 3D brain MRIs using a conditional Diffusion Model</span>
</span>
</td>
<td id="S5.T3.3.14.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T3.3.14.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.14.13.4.1.1" class="ltx_p" style="width:43.4pt;">ADNI-1, UCSF, SRI International</span>
</span>
</td>
<td id="S5.T3.3.14.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T3.3.14.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.14.13.5.1.1" class="ltx_p" style="width:86.7pt;">MS-SSIM: 78.6%</span>
</span>
</td>
<td id="S5.T3.3.14.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S5.T3.3.14.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T3.3.14.13.6.1.1" class="ltx_p" style="width:65.0pt;">Focused on T1-weighted MRIs; explore more types.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S5.T3.4.1" class="ltx_text ltx_font_bold">Improving media quality using diffusion-based approaches as demonstrated in the existing literature (cont.).</span></figcaption>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Image Transformation and Enhancement</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Image-to-image transformation</h3>

<div id="S6.SS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS1.p1.1" class="ltx_p">DMs have shown significant potential in various image-to-image transformation tasks. Existing studies demonstrate that the versatility of DMs helps in improving image quality and generating new images. For instance, Yu et al. (2023) presented an autoregressive <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_bold">Cascade Multiscale Diffusion (CMD) for Novel View Synthesis (NVS)</span> from a single image, ensuring photorealistic and geometrically consistent image sequences. They introduced the Thresholded Symmetric Epipolar Distance for evaluating geometric consistency. Their proposed model outperforms GeoGPT and LookOut models when tested on CLEVR, RealEstate10K, and Matterport3D datasets in terms of LPIPS and PSNR. For example, on RealEstate10K, it achieves an LPIPS of 0.333 and a PSNR of 15.51 compared to LookOut‚Äôs 0.378 and 14.43¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. However, the model faces limitations, including performance drops in certain conditions and challenging scenarios. For instance, it may struggle with images that have complex textures or dynamic elements, leading to less accurate geometric consistency and lower visual quality. Additionally, the model‚Äôs robustness in diverse real-world environments is not fully tested, indicating a need for further refinement and evaluation to ensure reliable performance across a wider range of situations.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para ltx_noindent">
<p id="S6.SS1.p2.1" class="ltx_p">Yin et al. (2023) introduced <span id="S6.SS1.p2.1.1" class="ltx_text ltx_font_bold">Controllable Light Enhancement (CLE)</span> Diffusion, a novel framework for low-light image enhancement that offers users dynamic control over brightness adjustments. Utilizing CMDs with an illumination embedding and integrating the Segment-Anything Model (SAM), CLE Diffusion allows precise, region-specific improvements. Their proposed approach outperformed existing models in terms of PSNR, SSIM, LPIPS, and LI-LPIPS on the LOL and MIT-Adobe FiveK datasets. For instance, on the LOL dataset, it achieved a PSNR of 25.51 and an SSIM of 0.89¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. However, the slow inference speeds hinder real-time application and usability in time-sensitive scenarios. Additionally, the model struggles to maintain high performance in environments with complex and varying lighting conditions, leading to inaccuracies and lower image quality in such settings.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para ltx_noindent">
<p id="S6.SS1.p3.1" class="ltx_p">Papantoniou et al. (2023) introduced <span id="S6.SS1.p3.1.1" class="ltx_text ltx_font_bold">‚ÄúRelightify,"</span> a method for 3D facial <span id="S6.SS1.p3.1.2" class="ltx_text ltx_font_bold">Bidirectional Reflectance Distribution Function (BRDF)</span> reconstruction from a single image using DMs (<span id="S6.SS1.p3.1.3" class="ltx_text ltx_font_bold">Figure¬†<a href="#S6.F7" title="Figure 7 ‚Ä£ 6.1 Image-to-image transformation ‚Ä£ 6 Image Transformation and Enhancement ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a></span>). Relightify is trained on a UV dataset of facial reflectance to understand facial features and lighting interactions. It fits a 3D model to an input image, unwraps the face into a UV texture, and uses the Diffusion Model to fill in occluded areas while keeping the original textures for realistic results. Relightify outperforms methods like CE, UV-GAN, and OSTeC, especially in handling different viewing angles, as measured by its higher PSNR and SSIM metrics¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.</p>
</div>
<figure id="S6.F7" class="ltx_figure"><img src="/html/2408.10207/assets/finalimgimgadobi1.png" id="S6.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="206" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span id="S6.F7.10.5" class="ltx_text ltx_font_bold">The Relightify method employs a latent Diffusion Model for inference, visualizing denoising in the original image space. It initiates with 3DMM fitting to generate a partial UV texture via image-to-UV rasterization. The process then uses random noise, guided by known texture, to complete missing pixels in the texture/reflectance diffusion model. Denoising steps (<math id="S6.F7.6.1.m1.1" class="ltx_Math" alttext="z_{t}" display="inline"><semantics id="S6.F7.6.1.m1.1b"><msub id="S6.F7.6.1.m1.1.1" xref="S6.F7.6.1.m1.1.1.cmml"><mi id="S6.F7.6.1.m1.1.1.2" xref="S6.F7.6.1.m1.1.1.2.cmml">z</mi><mi id="S6.F7.6.1.m1.1.1.3" xref="S6.F7.6.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S6.F7.6.1.m1.1c"><apply id="S6.F7.6.1.m1.1.1.cmml" xref="S6.F7.6.1.m1.1.1"><csymbol cd="ambiguous" id="S6.F7.6.1.m1.1.1.1.cmml" xref="S6.F7.6.1.m1.1.1">subscript</csymbol><ci id="S6.F7.6.1.m1.1.1.2.cmml" xref="S6.F7.6.1.m1.1.1.2">ùëß</ci><ci id="S6.F7.6.1.m1.1.1.3.cmml" xref="S6.F7.6.1.m1.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.6.1.m1.1d">z_{t}</annotation></semantics></math> to <math id="S6.F7.7.2.m2.1" class="ltx_Math" alttext="z_{t-1}" display="inline"><semantics id="S6.F7.7.2.m2.1b"><msub id="S6.F7.7.2.m2.1.1" xref="S6.F7.7.2.m2.1.1.cmml"><mi id="S6.F7.7.2.m2.1.1.2" xref="S6.F7.7.2.m2.1.1.2.cmml">z</mi><mrow id="S6.F7.7.2.m2.1.1.3" xref="S6.F7.7.2.m2.1.1.3.cmml"><mi id="S6.F7.7.2.m2.1.1.3.2" xref="S6.F7.7.2.m2.1.1.3.2.cmml">t</mi><mo id="S6.F7.7.2.m2.1.1.3.1" xref="S6.F7.7.2.m2.1.1.3.1.cmml">‚àí</mo><mn id="S6.F7.7.2.m2.1.1.3.3" xref="S6.F7.7.2.m2.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S6.F7.7.2.m2.1c"><apply id="S6.F7.7.2.m2.1.1.cmml" xref="S6.F7.7.2.m2.1.1"><csymbol cd="ambiguous" id="S6.F7.7.2.m2.1.1.1.cmml" xref="S6.F7.7.2.m2.1.1">subscript</csymbol><ci id="S6.F7.7.2.m2.1.1.2.cmml" xref="S6.F7.7.2.m2.1.1.2">ùëß</ci><apply id="S6.F7.7.2.m2.1.1.3.cmml" xref="S6.F7.7.2.m2.1.1.3"><minus id="S6.F7.7.2.m2.1.1.3.1.cmml" xref="S6.F7.7.2.m2.1.1.3.1"></minus><ci id="S6.F7.7.2.m2.1.1.3.2.cmml" xref="S6.F7.7.2.m2.1.1.3.2">ùë°</ci><cn type="integer" id="S6.F7.7.2.m2.1.1.3.3.cmml" xref="S6.F7.7.2.m2.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.7.2.m2.1d">z_{t-1}</annotation></semantics></math>, <math id="S6.F7.8.3.m3.3" class="ltx_Math" alttext="t\in\{1,\ldots,T\}" display="inline"><semantics id="S6.F7.8.3.m3.3b"><mrow id="S6.F7.8.3.m3.3.4" xref="S6.F7.8.3.m3.3.4.cmml"><mi id="S6.F7.8.3.m3.3.4.2" xref="S6.F7.8.3.m3.3.4.2.cmml">t</mi><mo id="S6.F7.8.3.m3.3.4.1" xref="S6.F7.8.3.m3.3.4.1.cmml">‚àà</mo><mrow id="S6.F7.8.3.m3.3.4.3.2" xref="S6.F7.8.3.m3.3.4.3.1.cmml"><mo stretchy="false" id="S6.F7.8.3.m3.3.4.3.2.1" xref="S6.F7.8.3.m3.3.4.3.1.cmml">{</mo><mn id="S6.F7.8.3.m3.1.1" xref="S6.F7.8.3.m3.1.1.cmml">1</mn><mo id="S6.F7.8.3.m3.3.4.3.2.2" xref="S6.F7.8.3.m3.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S6.F7.8.3.m3.2.2" xref="S6.F7.8.3.m3.2.2.cmml">‚Ä¶</mi><mo id="S6.F7.8.3.m3.3.4.3.2.3" xref="S6.F7.8.3.m3.3.4.3.1.cmml">,</mo><mi id="S6.F7.8.3.m3.3.3" xref="S6.F7.8.3.m3.3.3.cmml">T</mi><mo stretchy="false" id="S6.F7.8.3.m3.3.4.3.2.4" xref="S6.F7.8.3.m3.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.F7.8.3.m3.3c"><apply id="S6.F7.8.3.m3.3.4.cmml" xref="S6.F7.8.3.m3.3.4"><in id="S6.F7.8.3.m3.3.4.1.cmml" xref="S6.F7.8.3.m3.3.4.1"></in><ci id="S6.F7.8.3.m3.3.4.2.cmml" xref="S6.F7.8.3.m3.3.4.2">ùë°</ci><set id="S6.F7.8.3.m3.3.4.3.1.cmml" xref="S6.F7.8.3.m3.3.4.3.2"><cn type="integer" id="S6.F7.8.3.m3.1.1.cmml" xref="S6.F7.8.3.m3.1.1">1</cn><ci id="S6.F7.8.3.m3.2.2.cmml" xref="S6.F7.8.3.m3.2.2">‚Ä¶</ci><ci id="S6.F7.8.3.m3.3.3.cmml" xref="S6.F7.8.3.m3.3.3">ùëá</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.8.3.m3.3d">t\in\{1,\ldots,T\}</annotation></semantics></math>) follow an inpainting approach similar to MCG: 1) Updating reflectance maps and unobserved texture pixels using reverse diffusion sampling and manifold constraints, and 2) Directly sampling known pixels from the input texture through forward diffusion (<math id="S6.F7.9.4.m4.1" class="ltx_Math" alttext="\odot" display="inline"><semantics id="S6.F7.9.4.m4.1b"><mo id="S6.F7.9.4.m4.1.1" xref="S6.F7.9.4.m4.1.1.cmml">‚äô</mo><annotation-xml encoding="MathML-Content" id="S6.F7.9.4.m4.1c"><csymbol cd="latexml" id="S6.F7.9.4.m4.1.1.cmml" xref="S6.F7.9.4.m4.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.9.4.m4.1d">\odot</annotation></semantics></math> and <math id="S6.F7.10.5.m5.1" class="ltx_Math" alttext="\oplus" display="inline"><semantics id="S6.F7.10.5.m5.1b"><mo id="S6.F7.10.5.m5.1.1" xref="S6.F7.10.5.m5.1.1.cmml">‚äï</mo><annotation-xml encoding="MathML-Content" id="S6.F7.10.5.m5.1c"><csymbol cd="latexml" id="S6.F7.10.5.m5.1.1.cmml" xref="S6.F7.10.5.m5.1.1">direct-sum</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.F7.10.5.m5.1d">\oplus</annotation></semantics></math> denote the Hadamard product and addition). Masking is applied solely to the texture, while reflectance maps (diffuse/specular albedo, normals) are predicted entirely from random noise. This technique produces high-quality rendering assets for realistic 3D avatar creation¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.</span></figcaption>
</figure>
<div id="S6.SS1.p4" class="ltx_para ltx_noindent">
<p id="S6.SS1.p4.1" class="ltx_p">Kirch et al. (2023) presented <span id="S6.SS1.p4.1.1" class="ltx_text ltx_font_bold">Red-Green-Blue Depth Fusion (RGB-D-Fusion)</span>, a multi-modal conditional diffusion denoising model that enhanced depth map resolution from low-resolution RGB images of humanoid subjects. Unlike Variational Autoencoders or GANs, RGB-D-Fusion employed diffusion denoising models in two stages: creating and refining low-resolution depth maps with RGB-D images, incorporating depth noise augmentation for robustness. It effectively generated detailed depth maps represented as point clouds when tested on a dataset of 25k samples¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. However, it required substantial resources for sampling and training and relied on known projection matrices, limiting its scalability and flexibility.</p>
</div>
<div id="S6.SS1.p5" class="ltx_para ltx_noindent">
<p id="S6.SS1.p5.1" class="ltx_p">Mao et al. (2023) improved <span id="S6.SS1.p5.1.1" class="ltx_text ltx_font_bold">multi-contrast MRI using the Discriminator Consistency Diffusion (DisC-Diff)</span> model, which stabilizes and leverages multi-contrast data. DisC-Diff outperforms existing techniques in terms of PSNR and SSIM metrics when tested on normal and pathological brain datasets¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. Nonetheless, the study has limitations, such as the risk of mode collapse when processing multi-contrast MRI data, which can impact the reliability of the super-resolution process. Additionally, the proposed DMs may not adequately capture the complex interactions in multi-contrast MRI, limiting their effectiveness in clinical applications.</p>
</div>
<div id="S6.SS1.p6" class="ltx_para ltx_noindent">
<p id="S6.SS1.p6.1" class="ltx_p"><span id="S6.SS1.p6.1.1" class="ltx_text ltx_font_bold">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:imtim</span></span> summarizes some of the referenced literature that proposes different diffusion-based approaches for image-to-image transformation.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S6.T4.2.1" class="ltx_text ltx_font_bold">Image-to-image transformation using different DMs. FID: Frechet Inception Distance, LPIPS: Learned Perceptual Image Patch Similarity, PSNR: Peak Signal-to-Noise Ratio, SSIM: Structural Similarity Index Measure, MSE: Mean Squared Error, RMSE: Root Mean Squared Error, CD: Chamfer Distance, EMD: Earth Mover‚Äôs Distance, IoU: Intersection over Union, VLB: Visible Light Blocking. Best results are highlighted in bold.</span></figcaption>
<table id="S6.T4.1" class="ltx_tabular">
<thead class="ltx_thead">
<tr id="S6.T4.1.2.1" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S6.T4.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T4.1.2.1.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T4.1.2.1.1.1.1" class="ltx_p" style="width:8.7pt;"><span id="S6.T4.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></span>
</span>
</th>
<th id="S6.T4.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T4.1.2.1.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T4.1.2.1.2.1.1" class="ltx_p" style="width:56.4pt;"><span id="S6.T4.1.2.1.2.1.1.1" class="ltx_text ltx_font_bold">Algorithms</span></span>
</span>
</th>
<th id="S6.T4.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T4.1.2.1.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T4.1.2.1.3.1.1" class="ltx_p" style="width:52.0pt;"><span id="S6.T4.1.2.1.3.1.1.1" class="ltx_text ltx_font_bold">Applications</span></span>
</span>
</th>
<th id="S6.T4.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T4.1.2.1.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T4.1.2.1.4.1.1" class="ltx_p" style="width:60.7pt;"><span id="S6.T4.1.2.1.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</th>
<th id="S6.T4.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T4.1.2.1.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T4.1.2.1.5.1.1" class="ltx_p" style="width:86.7pt;"><span id="S6.T4.1.2.1.5.1.1.1" class="ltx_text ltx_font_bold">Evaluations</span></span>
</span>
</th>
<th id="S6.T4.1.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T4.1.2.1.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T4.1.2.1.6.1.1" class="ltx_p" style="width:86.7pt;"><span id="S6.T4.1.2.1.6.1.1.1" class="ltx_text ltx_font_bold">Limitations</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T4.1.3.1" class="ltx_tr">
<td id="S6.T4.1.3.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.3.1.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite></span>
</span>
</td>
<td id="S6.T4.1.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.3.1.2.1.1" class="ltx_p" style="width:56.4pt;">Autoregressive conditional Diffusion-based Models (ACDM)</span>
</span>
</td>
<td id="S6.T4.1.3.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.3.1.3.1.1" class="ltx_p" style="width:52.0pt;">NVS from a single image</span>
</span>
</td>
<td id="S6.T4.1.3.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.3.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.3.1.4.1.1" class="ltx_p" style="width:60.7pt;">RealEstate10K, MP3D, CLEVR</span>
</span>
</td>
<td id="S6.T4.1.3.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.3.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.3.1.5.1.1" class="ltx_p" style="width:86.7pt;">LPIPS: 0.33, PSNR: 15.51 on RealEstate10K; LPIPS: 0.50, PSNR: 14.83 on MP3D; FID: 26.76 on RealEstate10K; FID: 73.16 on MP3D</span>
</span>
</td>
<td id="S6.T4.1.3.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.3.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.3.1.6.1.1" class="ltx_p" style="width:86.7pt;">Requires complex geometric consistency and heavy computational resources for extrapolating views.</span>
</span>
</td>
</tr>
<tr id="S6.T4.1.4.2" class="ltx_tr">
<td id="S6.T4.1.4.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.4.2.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite></span>
</span>
</td>
<td id="S6.T4.1.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.4.2.2.1.1" class="ltx_p" style="width:56.4pt;">CLE Diffusion</span>
</span>
</td>
<td id="S6.T4.1.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.4.2.3.1.1" class="ltx_p" style="width:52.0pt;">Low light enhancement</span>
</span>
</td>
<td id="S6.T4.1.4.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.4.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.4.2.4.1.1" class="ltx_p" style="width:60.7pt;">LOL, MIT-Adobe FiveK</span>
</span>
</td>
<td id="S6.T4.1.4.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.4.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.4.2.5.1.1" class="ltx_p" style="width:86.7pt;">PSNR: 29.81, SSIM: <span id="S6.T4.1.4.2.5.1.1.1" class="ltx_text ltx_font_bold">0.97</span> on MIT-Adobe FiveK; PSNR: 25.51, SSIM: 0.89, LPIPS: 0.16, LI-LPIPS: 0.18 on LOL</span>
</span>
</td>
<td id="S6.T4.1.4.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.4.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.4.2.6.1.1" class="ltx_p" style="width:86.7pt;">Slow inference speed and limited capability in handling complex lighting and blurry scenes.</span>
</span>
</td>
</tr>
<tr id="S6.T4.1.5.3" class="ltx_tr">
<td id="S6.T4.1.5.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.5.3.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite></span>
</span>
</td>
<td id="S6.T4.1.5.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.5.3.2.1.1" class="ltx_p" style="width:56.4pt;">Diffusion-based inpainting model for 3D facial BRDF reconstruction</span>
</span>
</td>
<td id="S6.T4.1.5.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.5.3.3.1.1" class="ltx_p" style="width:52.0pt;">Facial texture completion and reflectance reconstruction from a single image</span>
</span>
</td>
<td id="S6.T4.1.5.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.5.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.5.3.4.1.1" class="ltx_p" style="width:60.7pt;">MultiPIE</span>
</span>
</td>
<td id="S6.T4.1.5.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.5.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.5.3.5.1.1" class="ltx_p" style="width:86.7pt;">PSNR: 26.00, SSIM: 0.93 at 0¬∞ angle on MultiPIE; Sampling time: 17 sec</span>
</span>
</td>
<td id="S6.T4.1.5.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.5.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.5.3.6.1.1" class="ltx_p" style="width:86.7pt;">Limited by input image quality and potential under-representation of ethnic diversity in training data.</span>
</span>
</td>
</tr>
<tr id="S6.T4.1.6.4" class="ltx_tr">
<td id="S6.T4.1.6.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.6.4.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite></span>
</span>
</td>
<td id="S6.T4.1.6.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.6.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.6.4.2.1.1" class="ltx_p" style="width:56.4pt;">CMDs</span>
</span>
</td>
<td id="S6.T4.1.6.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.6.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.6.4.3.1.1" class="ltx_p" style="width:52.0pt;">HDR reconstruction from multi-exposed LDR images</span>
</span>
</td>
<td id="S6.T4.1.6.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.6.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.6.4.4.1.1" class="ltx_p" style="width:60.7pt;">Benchmark datasets for HDR imaging</span>
</span>
</td>
<td id="S6.T4.1.6.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.6.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.6.4.5.1.1" class="ltx_p" style="width:86.7pt;">PSNR-¬µ: 22.25, SSIM-¬µ: 0.84, LPIPS: 0.03 on Hu‚Äôs dataset</span>
</span>
</td>
<td id="S6.T4.1.6.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.6.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.6.4.6.1.1" class="ltx_p" style="width:86.7pt;">Slow inference speed due to iterative denoising process.</span>
</span>
</td>
</tr>
<tr id="S6.T4.1.1" class="ltx_tr">
<td id="S6.T4.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.1.2.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite></span>
</span>
</td>
<td id="S6.T4.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.1.3.1.1" class="ltx_p" style="width:56.4pt;">RGB-D-Fusion diffusion probabilistic models</span>
</span>
</td>
<td id="S6.T4.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.1.4.1.1" class="ltx_p" style="width:52.0pt;">Depth map generation and super-resolution from monocular images</span>
</span>
</td>
<td id="S6.T4.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.1.1.1.1" class="ltx_p" style="width:60.7pt;">Custom dataset with <math id="S6.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S6.T4.1.1.1.1.1.m1.1a"><mo id="S6.T4.1.1.1.1.1.m1.1.1" xref="S6.T4.1.1.1.1.1.m1.1.1.cmml">‚âà</mo><annotation-xml encoding="MathML-Content" id="S6.T4.1.1.1.1.1.m1.1b"><approx id="S6.T4.1.1.1.1.1.m1.1.1.cmml" xref="S6.T4.1.1.1.1.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.1.1.1.1.1.m1.1c">\approx</annotation></semantics></math> 25,000 RGB-D images from 3D models of people</span>
</span>
</td>
<td id="S6.T4.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.1.5.1.1" class="ltx_p" style="width:86.7pt;">MSE: 1.48, IoU: <span id="S6.T4.1.1.5.1.1.1" class="ltx_text ltx_font_bold">0.99</span>, VLB: 16.95 with UNet3+ model</span>
</span>
</td>
<td id="S6.T4.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T4.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.1.6.1.1" class="ltx_p" style="width:86.7pt;">High computational resources required for training and sampling.</span>
</span>
</td>
</tr>
<tr id="S6.T4.1.7.5" class="ltx_tr">
<td id="S6.T4.1.7.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T4.1.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.7.5.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite></span>
</span>
</td>
<td id="S6.T4.1.7.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T4.1.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.7.5.2.1.1" class="ltx_p" style="width:56.4pt;">Disentangled CMDs (DisC-Diff)</span>
</span>
</td>
<td id="S6.T4.1.7.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T4.1.7.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.7.5.3.1.1" class="ltx_p" style="width:52.0pt;">Multi-contrast MRI super-resolution</span>
</span>
</td>
<td id="S6.T4.1.7.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T4.1.7.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.7.5.4.1.1" class="ltx_p" style="width:60.7pt;">IXI dataset and clinical brain MRI dataset</span>
</span>
</td>
<td id="S6.T4.1.7.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T4.1.7.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.7.5.5.1.1" class="ltx_p" style="width:86.7pt;">PSNR: <span id="S6.T4.1.7.5.5.1.1.1" class="ltx_text ltx_font_bold">37.77</span> dB, SSIM: <span id="S6.T4.1.7.5.5.1.1.2" class="ltx_text ltx_font_bold">0.99</span> on 2√ó scale in clinical dataset</span>
</span>
</td>
<td id="S6.T4.1.7.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T4.1.7.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T4.1.7.5.6.1.1" class="ltx_p" style="width:86.7pt;">Requires accurate condition sampling for model precision.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S6.T4.4.1" class="ltx_text ltx_font_bold">Image-to-image transformation using different DMs (cont.).</span></figcaption>
</figure>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Image quality enhancement and processing</h3>

<div id="S6.SS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.p1.1" class="ltx_p">DMs have been used effectively in various image quality improvement tasks, as shown in <span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_bold">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:imh</span></span>. These tasks include improving document images, generating thermal facial images, and creating identity-preserving face images. In each case, DMs significantly boost image quality. They make images clearer, remove noise and watermarks, and create realistic images in different conditions, showing their versatility in image processing¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.p2.1" class="ltx_p">Yang et al. (2023) introduced <span id="S6.SS2.p2.1.1" class="ltx_text ltx_font_bold">Document Diffusion (DocDiff)</span>, a diffusion-based framework for restoring degraded document images. This framework recovers low-frequency content using a Coarse Predictor and high-frequency details with a High-Frequency Residual Refinement (HRR) module. DocDiff‚Äôs efficient architecture achieves SOTA results on benchmarks, improving readability and text edge sharpness with only 4.17 million parameters in the HRR module¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. However, the study did not consider additional document improvement tasks such as document super-resolution or style transfer. The robustness of DocDiff in handling various types and levels of document degradation might be insufficient, requiring more diverse training data and improved network architectures. Furthermore, there is no user-centric evaluation to assess the impact on readability and user satisfaction.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para ltx_noindent">
<p id="S6.SS2.p3.1" class="ltx_p">Ordun et al. (2023) introduced <span id="S6.SS2.p3.1.1" class="ltx_text ltx_font_bold">Visible-to-Thermal Facial GAN (VTF-GAN)</span>, a generative adversarial network that created high-resolution thermal facial images from visible spectrum inputs, addressing the lack of thermal sensors in common RGB cameras for telemedicine¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. However, the study did not address the potential biases or ethical considerations that may arise when using generated thermal faces for applications such as telemedicine, which could be crucial in real-world implementations. There is a lack of analysis regarding the generalizability of the VTF-GAN model across different datasets or demographic groups, which could impact its applicability in diverse scenarios. Additionally, there is no comprehensive discussion on the interpretability of the generated images and how they align with the underlying physiological conditions they aim to represent.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para ltx_noindent">
<p id="S6.SS2.p4.1" class="ltx_p">Kansy et al. (2023) introduced the Identity <span id="S6.SS2.p4.1.1" class="ltx_text ltx_font_bold">Denoising Diffusion Probabilistic Model (ID3PM)</span>, which can reverse-engineer face recognition models without needing full access (i.e., using a black-box method) to the model. ID3PM uses denoising diffusion to generate high-quality, identity-preserving facial images without needing an identity-specific loss. It effectively samples from the inverse distribution, producing diverse images with varying backgrounds, lighting, poses, and expressions¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. Nonetheless, the method presented in this work generates images at a relatively low resolution of 64 x 64, which may limit the fine details captured. Additionally, the inference times for image generation are relatively long, and small artifacts in the output could affect the overall quality of the generated images.</p>
</div>
<div id="S6.SS2.p5" class="ltx_para">
<p id="S6.SS2.p5.1" class="ltx_p">Yu et al. (2023) presented <span id="S6.SS2.p5.1.1" class="ltx_text ltx_font_bold">Free-form Deformation Model (FreeDoM)</span>, a versatile training-free conditional Diffusion Model that adapts to various conditions without condition-specific training (<span id="S6.SS2.p5.1.2" class="ltx_text ltx_font_bold">Figure¬†<a href="#S6.F8" title="Figure 8 ‚Ä£ 6.2 Image quality enhancement and processing ‚Ä£ 6 Image Transformation and Enhancement ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a></span>). Unlike traditional models, FreeDoM uses pre-trained networks to create time-independent energy functions, reducing costs and improving transferability. Tested on different data domains, it outperforms training-required methods like Text- and Image-driven Generative Adversarial Network (TediGAN) in generating segmentation maps, sketches, and text-conditioned images, with better condition matching and FID scores¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. While FreeDoM is designed to be training-free and adaptable to various conditions, it may struggle in situations where the conditions significantly differ from the capabilities of the pre-trained networks. This limitation could affect the model‚Äôs effectiveness in diverse and complex scenarios.</p>
</div>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2408.10207/assets/freedomadobi1.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="S6.F8.2.1" class="ltx_text ltx_font_bold">Single-condition guided results based on FreeDoM models, where (a) are Unconditional DMs and (b) are Classifier-based DMs, generated output on the ImageNet dataset¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.</span></figcaption>
</figure>
<figure id="S6.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span><span id="S6.T5.1.1" class="ltx_text ltx_font_bold">Image Enhancement and Processing based on the referenced literature. FID: Frechet Inception Distance, LPIPS: Learned Perceptual Image Patch Similarity, PSNR: Peak Signal-to-Noise Ratio, SSIM: Structural Similarity Index Measure, MANIQA: Mean Opinion Score Quality Index, MUSIQ: Measurement Uncertainty Simulation Quality Index, DISTS: Deep Image Structure and Texture Similarity, MSE: Mean Squared Error. Best results are highlighted in bold.</span></figcaption>
<table id="S6.T5.3" class="ltx_tabular">
<thead class="ltx_thead">
<tr id="S6.T5.3.1.1" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S6.T5.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T5.3.1.1.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T5.3.1.1.1.1.1" class="ltx_p" style="width:8.7pt;"><span id="S6.T5.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></span>
</span>
</th>
<th id="S6.T5.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T5.3.1.1.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T5.3.1.1.2.1.1" class="ltx_p" style="width:56.4pt;"><span id="S6.T5.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Algorithms</span></span>
</span>
</th>
<th id="S6.T5.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T5.3.1.1.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T5.3.1.1.3.1.1" class="ltx_p" style="width:56.4pt;"><span id="S6.T5.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Applications</span></span>
</span>
</th>
<th id="S6.T5.3.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T5.3.1.1.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T5.3.1.1.4.1.1" class="ltx_p" style="width:47.7pt;"><span id="S6.T5.3.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</th>
<th id="S6.T5.3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T5.3.1.1.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T5.3.1.1.5.1.1" class="ltx_p" style="width:69.4pt;"><span id="S6.T5.3.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Evaluations</span></span>
</span>
</th>
<th id="S6.T5.3.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S6.T5.3.1.1.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S6.T5.3.1.1.6.1.1" class="ltx_p" style="width:95.4pt;"><span id="S6.T5.3.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Limitations</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T5.3.2.1" class="ltx_tr">
<td id="S6.T5.3.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.2.1.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite></span>
</span>
</td>
<td id="S6.T5.3.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.2.1.2.1.1" class="ltx_p" style="width:56.4pt;">DocDiff conditional Diffusion Model</span>
</span>
</td>
<td id="S6.T5.3.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.2.1.3.1.1" class="ltx_p" style="width:56.4pt;">Document image enhancement including deblurring, denoising, and watermark removal</span>
</span>
</td>
<td id="S6.T5.3.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.2.1.4.1.1" class="ltx_p" style="width:47.7pt;">Document Deblurring Dataset</span>
</span>
</td>
<td id="S6.T5.3.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.2.1.5.1.1" class="ltx_p" style="width:69.4pt;">MANIQA: 0.72, MUSIQ: 50.62, DISTS: 0.06, LPIPS: 0.03, PSNR: 23.28, SSIM: <span id="S6.T5.3.2.1.5.1.1.1" class="ltx_text ltx_font_bold">0.95</span></span>
</span>
</td>
<td id="S6.T5.3.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.2.1.6.1.1" class="ltx_p" style="width:95.4pt;">May lose high-frequency information, leading to distorted text edges. Relies on the quality of low-frequency content recovery by the Coarse Predictor module.</span>
</span>
</td>
</tr>
<tr id="S6.T5.3.3.2" class="ltx_tr">
<td id="S6.T5.3.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.3.2.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite></span>
</span>
</td>
<td id="S6.T5.3.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.3.2.2.1.1" class="ltx_p" style="width:56.4pt;">VTF-GAN</span>
</span>
</td>
<td id="S6.T5.3.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.3.2.3.1.1" class="ltx_p" style="width:56.4pt;">Thermal facial imagery generation for telemedicine</span>
</span>
</td>
<td id="S6.T5.3.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.3.2.4.1.1" class="ltx_p" style="width:47.7pt;">Eurecom and Devcom datasets</span>
</span>
</td>
<td id="S6.T5.3.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.3.2.5.1.1" class="ltx_p" style="width:69.4pt;">FID: 47.35, DBCNN: 34.34%, MSE: 0.88, SPEC: -1.1% for VTF-GAN with Fourier Transform-Guided (FFT-G)</span>
</span>
</td>
<td id="S6.T5.3.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.3.2.6.1.1" class="ltx_p" style="width:95.4pt;">Generation constrained to static environments; performance untested in dynamic, variable conditions affecting thermal emission.</span>
</span>
</td>
</tr>
<tr id="S6.T5.3.4.3" class="ltx_tr">
<td id="S6.T5.3.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.4.3.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite></span>
</span>
</td>
<td id="S6.T5.3.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.4.3.2.1.1" class="ltx_p" style="width:56.4pt;">ID3PM</span>
</span>
</td>
<td id="S6.T5.3.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.4.3.3.1.1" class="ltx_p" style="width:56.4pt;">Inversion of pre-trained face recognition models, generating identity-preserving face images</span>
</span>
</td>
<td id="S6.T5.3.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.4.3.4.1.1" class="ltx_p" style="width:47.7pt;">LFW, AgeDB-30, CFP-FP datasets</span>
</span>
</td>
<td id="S6.T5.3.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.4.3.5.1.1" class="ltx_p" style="width:69.4pt;">LFW: <span id="S6.T5.3.4.3.5.1.1.1" class="ltx_text ltx_font_bold">99.20</span>%, AgeDB-30: 94.53%, CFP-FP: 96.13% with ID3PM using InsightFace embeddings</span>
</span>
</td>
<td id="S6.T5.3.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S6.T5.3.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.4.3.6.1.1" class="ltx_p" style="width:95.4pt;">Generation quality may vary with the diversity of embeddings; control over the generation process might need fine-tuning for specific applications.</span>
</span>
</td>
</tr>
<tr id="S6.T5.3.5.4" class="ltx_tr">
<td id="S6.T5.3.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T5.3.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.5.4.1.1.1" class="ltx_p" style="width:8.7pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite></span>
</span>
</td>
<td id="S6.T5.3.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T5.3.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.5.4.2.1.1" class="ltx_p" style="width:56.4pt;">FreeDoM</span>
</span>
</td>
<td id="S6.T5.3.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T5.3.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.5.4.3.1.1" class="ltx_p" style="width:56.4pt;">Conditional image and latent code generation</span>
</span>
</td>
<td id="S6.T5.3.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T5.3.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.5.4.4.1.1" class="ltx_p" style="width:47.7pt;">Multiple datasets for segmentation maps, sketches, texts</span>
</span>
</td>
<td id="S6.T5.3.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T5.3.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.5.4.5.1.1" class="ltx_p" style="width:69.4pt;">Distance: 1696.1, FID: 53.08 for segmentation maps with FreeDoM</span>
</span>
</td>
<td id="S6.T5.3.5.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S6.T5.3.5.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S6.T5.3.5.4.6.1.1" class="ltx_p" style="width:95.4pt;">High sampling time cost; struggles with fine-grained control in large data domains; may produce poor results with conflicting conditions.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span><span id="S6.T5.4.1" class="ltx_text ltx_font_bold">Image Enhancement and Processing (cont.).</span></figcaption>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Healthcare and medical applications</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">DMs have made significant contributions to the field of healthcare and medical analysis by offering cutting-edge solutions for a variety of tasks. Models like PatchDDM, a memory-efficient patch-based DM, have been effectively utilized for applications such as tumor segmentation in medical imaging datasets like BraTS2020, showing their ability to generate precise three-dimensional segmentations¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. Furthermore, DMs are renowned for their extensive mode coverage and the quality of samples they generate. These models are employed in medical imaging to address challenges related to limited data availability, inconsistent data acquisition methods, and privacy issues. For example, the Med-DDPM, a DM-based approach, has demonstrated super stability and performance in comparison to GANs when it comes to generating high quality, realistic 3D medical images¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>.</p>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p id="S7.p2.1" class="ltx_p">Chen et al. (2023) introduced the <span id="S7.p2.1.1" class="ltx_text ltx_font_bold">Bernoulli Diffusion Model (BerDiff)</span> for medical image segmentation. BerDiff used Bernoulli noise instead of Gaussian noise, improving binary segmentation tasks essential in medical imaging. By sampling Bernoulli noise and intermediate latent variables, BerDiff generated diverse and accurate segmentation masks. This approach, tested on the LIDC-IDRI and BRATS 2021 datasets, outperformed SOTA methods in metrics such as Generalized Energy Distance (GED) and Dice score¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. However, the proposed BerDiff model mainly focused on binary image segmentation, which may limit its application to more complex segmentation scenarios such as multi-class tasks. The study did not extensively discuss whether additional post-processing steps were needed for specific clinical tasks.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">Shrivastava et al. (2023) presented <span id="S7.p3.1.1" class="ltx_text ltx_font_bold">Nuclei-Aware Semantic Diffusion Model (NASDM)</span>, a framework for generating high-quality histopathological images using conditional Diffusion Modeling (<span id="S7.p3.1.2" class="ltx_text ltx_font_bold">Figure¬†<a href="#S7.F9" title="Figure 9 ‚Ä£ 7 Healthcare and medical applications ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a></span>). NASDM creates realistic tissue samples from semantic instance masks of six nuclei types, aiding pathological analysis and addressing training data scarcity for nuclei segmentation. On a colon dataset, NASDM achieved an FID of 15.7 and an IS of 2.7, outperforming existing methods¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>. However, the proposed approaches required large amounts of annotated data for training Deep Learning models for nuclei segmentation, which can be expensive and time-consuming. Additionally, the current methods focused only on generating tissue patches conditioned on the semantic layouts of nuclei, which may have restricted the framework‚Äôs scope to specific types of histopathological images.</p>
</div>
<figure id="S7.F9" class="ltx_figure"><img src="/html/2408.10207/assets/medicalonetwoadobi1.png" id="S7.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="238" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span><span id="S7.F9.22.11" class="ltx_text ltx_font_bold">The NASDM training protocol initiates with an original image <math id="S7.F9.12.1.m1.1" class="ltx_Math" alttext="x_{0}" display="inline"><semantics id="S7.F9.12.1.m1.1b"><msub id="S7.F9.12.1.m1.1.1" xref="S7.F9.12.1.m1.1.1.cmml"><mi id="S7.F9.12.1.m1.1.1.2" xref="S7.F9.12.1.m1.1.1.2.cmml">x</mi><mn id="S7.F9.12.1.m1.1.1.3" xref="S7.F9.12.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S7.F9.12.1.m1.1c"><apply id="S7.F9.12.1.m1.1.1.cmml" xref="S7.F9.12.1.m1.1.1"><csymbol cd="ambiguous" id="S7.F9.12.1.m1.1.1.1.cmml" xref="S7.F9.12.1.m1.1.1">subscript</csymbol><ci id="S7.F9.12.1.m1.1.1.2.cmml" xref="S7.F9.12.1.m1.1.1.2">ùë•</ci><cn type="integer" id="S7.F9.12.1.m1.1.1.3.cmml" xref="S7.F9.12.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.12.1.m1.1d">x_{0}</annotation></semantics></math> and its corresponding semantic mask <math id="S7.F9.13.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S7.F9.13.2.m2.1b"><mi id="S7.F9.13.2.m2.1.1" xref="S7.F9.13.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S7.F9.13.2.m2.1c"><ci id="S7.F9.13.2.m2.1.1.cmml" xref="S7.F9.13.2.m2.1.1">ùë¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.13.2.m2.1d">y</annotation></semantics></math>. It then generates a conditioning signal by enhancing the mask and incorporating an adjacent edge map. Subsequently, a timestep <math id="S7.F9.14.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S7.F9.14.3.m3.1b"><mi id="S7.F9.14.3.m3.1.1" xref="S7.F9.14.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S7.F9.14.3.m3.1c"><ci id="S7.F9.14.3.m3.1.1.cmml" xref="S7.F9.14.3.m3.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.14.3.m3.1d">t</annotation></semantics></math> is selected, and noise is applied to <math id="S7.F9.15.4.m4.1" class="ltx_Math" alttext="x_{0}" display="inline"><semantics id="S7.F9.15.4.m4.1b"><msub id="S7.F9.15.4.m4.1.1" xref="S7.F9.15.4.m4.1.1.cmml"><mi id="S7.F9.15.4.m4.1.1.2" xref="S7.F9.15.4.m4.1.1.2.cmml">x</mi><mn id="S7.F9.15.4.m4.1.1.3" xref="S7.F9.15.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S7.F9.15.4.m4.1c"><apply id="S7.F9.15.4.m4.1.1.cmml" xref="S7.F9.15.4.m4.1.1"><csymbol cd="ambiguous" id="S7.F9.15.4.m4.1.1.1.cmml" xref="S7.F9.15.4.m4.1.1">subscript</csymbol><ci id="S7.F9.15.4.m4.1.1.2.cmml" xref="S7.F9.15.4.m4.1.1.2">ùë•</ci><cn type="integer" id="S7.F9.15.4.m4.1.1.3.cmml" xref="S7.F9.15.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.15.4.m4.1d">x_{0}</annotation></semantics></math> through forward diffusion, resulting in a perturbed input <math id="S7.F9.16.5.m5.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S7.F9.16.5.m5.1b"><msub id="S7.F9.16.5.m5.1.1" xref="S7.F9.16.5.m5.1.1.cmml"><mi id="S7.F9.16.5.m5.1.1.2" xref="S7.F9.16.5.m5.1.1.2.cmml">x</mi><mi id="S7.F9.16.5.m5.1.1.3" xref="S7.F9.16.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S7.F9.16.5.m5.1c"><apply id="S7.F9.16.5.m5.1.1.cmml" xref="S7.F9.16.5.m5.1.1"><csymbol cd="ambiguous" id="S7.F9.16.5.m5.1.1.1.cmml" xref="S7.F9.16.5.m5.1.1">subscript</csymbol><ci id="S7.F9.16.5.m5.1.1.2.cmml" xref="S7.F9.16.5.m5.1.1.2">ùë•</ci><ci id="S7.F9.16.5.m5.1.1.3.cmml" xref="S7.F9.16.5.m5.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.16.5.m5.1d">x_{t}</annotation></semantics></math>. The denoising model then processes this corrupted image <math id="S7.F9.17.6.m6.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S7.F9.17.6.m6.1b"><msub id="S7.F9.17.6.m6.1.1" xref="S7.F9.17.6.m6.1.1.cmml"><mi id="S7.F9.17.6.m6.1.1.2" xref="S7.F9.17.6.m6.1.1.2.cmml">x</mi><mi id="S7.F9.17.6.m6.1.1.3" xref="S7.F9.17.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S7.F9.17.6.m6.1c"><apply id="S7.F9.17.6.m6.1.1.cmml" xref="S7.F9.17.6.m6.1.1"><csymbol cd="ambiguous" id="S7.F9.17.6.m6.1.1.1.cmml" xref="S7.F9.17.6.m6.1.1">subscript</csymbol><ci id="S7.F9.17.6.m6.1.1.2.cmml" xref="S7.F9.17.6.m6.1.1.2">ùë•</ci><ci id="S7.F9.17.6.m6.1.1.3.cmml" xref="S7.F9.17.6.m6.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.17.6.m6.1d">x_{t}</annotation></semantics></math>, along with the timestep <math id="S7.F9.18.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S7.F9.18.7.m7.1b"><mi id="S7.F9.18.7.m7.1.1" xref="S7.F9.18.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S7.F9.18.7.m7.1c"><ci id="S7.F9.18.7.m7.1.1.cmml" xref="S7.F9.18.7.m7.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.18.7.m7.1d">t</annotation></semantics></math> and semantic condition <math id="S7.F9.19.8.m8.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S7.F9.19.8.m8.1b"><mi id="S7.F9.19.8.m8.1.1" xref="S7.F9.19.8.m8.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S7.F9.19.8.m8.1c"><ci id="S7.F9.19.8.m8.1.1.cmml" xref="S7.F9.19.8.m8.1.1">ùë¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.19.8.m8.1d">y</annotation></semantics></math>, to estimate <math id="S7.F9.20.9.m9.1" class="ltx_Math" alttext="\hat{\epsilon}" display="inline"><semantics id="S7.F9.20.9.m9.1b"><mover accent="true" id="S7.F9.20.9.m9.1.1" xref="S7.F9.20.9.m9.1.1.cmml"><mi id="S7.F9.20.9.m9.1.1.2" xref="S7.F9.20.9.m9.1.1.2.cmml">œµ</mi><mo id="S7.F9.20.9.m9.1.1.1" xref="S7.F9.20.9.m9.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S7.F9.20.9.m9.1c"><apply id="S7.F9.20.9.m9.1.1.cmml" xref="S7.F9.20.9.m9.1.1"><ci id="S7.F9.20.9.m9.1.1.1.cmml" xref="S7.F9.20.9.m9.1.1.1">^</ci><ci id="S7.F9.20.9.m9.1.1.2.cmml" xref="S7.F9.20.9.m9.1.1.2">italic-œµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.20.9.m9.1d">\hat{\epsilon}</annotation></semantics></math>, representing the model‚Äôs prediction of the total noise introduced. The loss is then computed by comparing this estimate <math id="S7.F9.21.10.m10.1" class="ltx_Math" alttext="\hat{\epsilon}" display="inline"><semantics id="S7.F9.21.10.m10.1b"><mover accent="true" id="S7.F9.21.10.m10.1.1" xref="S7.F9.21.10.m10.1.1.cmml"><mi id="S7.F9.21.10.m10.1.1.2" xref="S7.F9.21.10.m10.1.1.2.cmml">œµ</mi><mo id="S7.F9.21.10.m10.1.1.1" xref="S7.F9.21.10.m10.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S7.F9.21.10.m10.1c"><apply id="S7.F9.21.10.m10.1.1.cmml" xref="S7.F9.21.10.m10.1.1"><ci id="S7.F9.21.10.m10.1.1.1.cmml" xref="S7.F9.21.10.m10.1.1.1">^</ci><ci id="S7.F9.21.10.m10.1.1.2.cmml" xref="S7.F9.21.10.m10.1.1.2">italic-œµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.21.10.m10.1d">\hat{\epsilon}</annotation></semantics></math> with the actual noise <math id="S7.F9.22.11.m11.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S7.F9.22.11.m11.1b"><mi id="S7.F9.22.11.m11.1.1" xref="S7.F9.22.11.m11.1.1.cmml">œµ</mi><annotation-xml encoding="MathML-Content" id="S7.F9.22.11.m11.1c"><ci id="S7.F9.22.11.m11.1.1.cmml" xref="S7.F9.22.11.m11.1.1">italic-œµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.F9.22.11.m11.1d">\epsilon</annotation></semantics></math> applied during the forward diffusion process¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite></span></figcaption>
</figure>
<div id="S7.p4" class="ltx_para ltx_noindent">
<p id="S7.p4.1" class="ltx_p">Wang et al. (2023) proposed a novel model, <span id="S7.p4.1.1" class="ltx_text ltx_font_bold">Hierarchical Feature Conditional Diffusion (HiFi-Diff)</span>, a framework for MRI image super-resolution that adapts to varying inter-slice spacings in clinical settings. HiFi-Diff uses hierarchical feature extraction to iteratively convert Gaussian noise into high-resolution MR slices, achieving superior image quality. Tested on the HCP-1200 dataset, HiFi-Diff outperformed traditional methods in PSNR, SSIM, and Dice similarity coefficient across various scaling tasks (√ó4, √ó5, √ó6, √ó7). For instance, in a √ó4 task, it achieved a PSNR of 39.50 and an SSIM of 0.98¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. While the experimental results demonstrate the effectiveness of HiFi-Diff on the HCP-1200 dataset, the study did not provide any insights regarding the model‚Äôs performance compared to existing super-resolution methods on a wider range of MRI datasets with varying characteristics.</p>
</div>
<div id="S7.p5" class="ltx_para ltx_noindent">
<p id="S7.p5.1" class="ltx_p">Li et al. (2023) introduced <span id="S7.p5.1.1" class="ltx_text ltx_font_bold">Denoising Score-based Diffusion for Electrocardiogram (DeScoD-ECG)</span>, a conditional Score-based Diffusion Model for improving Electrocardiogram (ECG) signals, which are essential for diagnosing cardiovascular diseases but often suffer from noise. Unlike traditional Deep Learning methods, DeScoD-ECG iteratively reconstructs signals from Gaussian white noise using a Markov Chain, improving reconstruction quality with a multi-shot averaging strategy. Validated on the QT Database and MIT-BIH Noise Stress Test Database, DeScoD-ECG outperforms existing methods in metrics such as Sum of Squared Differences (SSD), Mean Absolute Deviation (MAD), Percent Root Mean Square Difference (PRD), and Cosine Similarity, showing over a 20% improvement¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>. However, the study did not address other types of noise interference that can affect ECG signals, such as muscle artifacts or electrode motion artifacts. While the study highlights the potential of the DeScoD-ECG model for biomedical applications, it does not discuss any specific real-world applications or case studies where the method has been successfully applied.</p>
</div>
<div id="S7.p6" class="ltx_para">
<p id="S7.p6.1" class="ltx_p"><span id="S7.p6.1.1" class="ltx_text ltx_font_bold">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:hlm</span></span> summarizes some of the existing reference literature that considers DM-based approaches for developing realistic samples in medical imaging and healthcare.</p>
</div>
<figure id="S7.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span><span id="S7.T6.1.1" class="ltx_text ltx_font_bold">Health and medical applications using diffusion-based approaches as demonstrated in the existing literature. FID: Frechet Inception Distance, IS: Inception Score, PSNR: Peak Signal-to-Noise Ratio, SSIM: Structural Similarity Index Measure, GED: Generalized Energy Distance, HM-IoU: Harmonic Mean Intersection over Union, LPIS: Learned Perceptual Image Similarity. Best results are highlighted in bold.</span></figcaption>
<table id="S7.T6.3" class="ltx_tabular">
<thead class="ltx_thead">
<tr id="S7.T6.3.1.1" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S7.T6.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S7.T6.3.1.1.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S7.T6.3.1.1.1.1.1" class="ltx_p" style="width:13.0pt;"><span id="S7.T6.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></span>
</span>
</th>
<th id="S7.T6.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S7.T6.3.1.1.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S7.T6.3.1.1.2.1.1" class="ltx_p" style="width:65.0pt;"><span id="S7.T6.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Algorithms</span></span>
</span>
</th>
<th id="S7.T6.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S7.T6.3.1.1.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S7.T6.3.1.1.3.1.1" class="ltx_p" style="width:69.4pt;"><span id="S7.T6.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Applications</span></span>
</span>
</th>
<th id="S7.T6.3.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S7.T6.3.1.1.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S7.T6.3.1.1.4.1.1" class="ltx_p" style="width:65.0pt;"><span id="S7.T6.3.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</th>
<th id="S7.T6.3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S7.T6.3.1.1.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S7.T6.3.1.1.5.1.1" class="ltx_p" style="width:69.4pt;"><span id="S7.T6.3.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Evaluations</span></span>
</span>
</th>
<th id="S7.T6.3.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S7.T6.3.1.1.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S7.T6.3.1.1.6.1.1" class="ltx_p" style="width:73.7pt;"><span id="S7.T6.3.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Limitations</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T6.3.2.1" class="ltx_tr">
<td id="S7.T6.3.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.2.1.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite></span>
</span>
</td>
<td id="S7.T6.3.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.2.1.2.1.1" class="ltx_p" style="width:65.0pt;">BerDiff: Conditional Bernoulli Diffusion for Medical Image Segmentation</span>
</span>
</td>
<td id="S7.T6.3.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.2.1.3.1.1" class="ltx_p" style="width:69.4pt;">Advanced medical image segmentation using Bernoulli diffusion to produce accurate and diverse segmentation masks</span>
</span>
</td>
<td id="S7.T6.3.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.2.1.4.1.1" class="ltx_p" style="width:65.0pt;">LIDC-IDRI, BRATS 2021</span>
</span>
</td>
<td id="S7.T6.3.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.2.1.5.1.1" class="ltx_p" style="width:69.4pt;">Achieves state-of-the-art performance with metrics on LIDC-IDRI - GED: 0.24, HM-IoU: 0.60, and on BRATS 2021 - Dice: <span id="S7.T6.3.2.1.5.1.1.1" class="ltx_text ltx_font_bold">89.7</span>.</span>
</span>
</td>
<td id="S7.T6.3.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.2.1.6.1.1" class="ltx_p" style="width:73.7pt;">Focuses only on binary segmentation and requires significant time for iterative sampling.</span>
</span>
</td>
</tr>
<tr id="S7.T6.3.3.2" class="ltx_tr">
<td id="S7.T6.3.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.3.2.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite></span>
</span>
</td>
<td id="S7.T6.3.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.3.2.2.1.1" class="ltx_p" style="width:65.0pt;">NASDM: Nuclei-Aware Semantic Tissue Generation Framework</span>
</span>
</td>
<td id="S7.T6.3.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.3.2.3.1.1" class="ltx_p" style="width:69.4pt;">Generative modeling of histopathological images conditioned on semantic instance masks</span>
</span>
</td>
<td id="S7.T6.3.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.3.2.4.1.1" class="ltx_p" style="width:65.0pt;">Colon dataset</span>
</span>
</td>
<td id="S7.T6.3.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.3.2.5.1.1" class="ltx_p" style="width:69.4pt;">FID: 15.7, IS: 2.7, indicating high-quality and semantically accurate synthetic image generation.</span>
</span>
</td>
<td id="S7.T6.3.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S7.T6.3.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.3.2.6.1.1" class="ltx_p" style="width:73.7pt;">Further development is required for varied histopathological settings and end-to-end tissue generation that includes mask synthesis.</span>
</span>
</td>
</tr>
<tr id="S7.T6.3.4.3" class="ltx_tr">
<td id="S7.T6.3.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S7.T6.3.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.4.3.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite></span>
</span>
</td>
<td id="S7.T6.3.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S7.T6.3.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.4.3.2.1.1" class="ltx_p" style="width:65.0pt;">Hierarchical Feature Conditional Diffusion (HiFi-Diff)</span>
</span>
</td>
<td id="S7.T6.3.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S7.T6.3.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.4.3.3.1.1" class="ltx_p" style="width:69.4pt;">MR image super-resolution with arbitrary reduction of inter-slice spacing</span>
</span>
</td>
<td id="S7.T6.3.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S7.T6.3.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.4.3.4.1.1" class="ltx_p" style="width:65.0pt;">HCP-1200 dataset</span>
</span>
</td>
<td id="S7.T6.3.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S7.T6.3.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.4.3.5.1.1" class="ltx_p" style="width:69.4pt;">PSNR: 39.50¬±2.29, SSIM: <span id="S7.T6.3.4.3.5.1.1.1" class="ltx_text ltx_font_bold">0.99</span> for √ó4 SR task</span>
</span>
</td>
<td id="S7.T6.3.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_b ltx_border_t">
<span id="S7.T6.3.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T6.3.4.3.6.1.1" class="ltx_p" style="width:73.7pt;">Slow sampling speed, suggesting potential improvements through faster algorithms or knowledge distillation.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span><span id="S7.T6.4.1" class="ltx_text ltx_font_bold">Health and medical applications (cont.).</span></figcaption>
</figure>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Applications of Diffusion Models in Other Fields</h2>

<div id="S8.p1" class="ltx_para ltx_noindent">
<p id="S8.p1.1" class="ltx_p">DMs are adopted in various domains beyond image analysis and are effectively used for time series forecasting, imputation, and generation, demonstrating their versatility in handling sequential data. Additionally, DMs have been adapted for predicting chaotic dynamical systems, offering uncertainty quantification and the ability to represent outliers and extreme events effectively. Furthermore, recent advancements have extended DMs to Riemannian manifolds, enabling applications in constrained conformational modeling of protein backbones and robotic arms, highlighting their relevance in scientific domains as well. The evolution of DMs beyond image analysis underscores their adaptability and effectiveness across a wide range of fields¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">Li et al. (2023) developed the <span id="S8.p2.1.1" class="ltx_text ltx_font_bold">Diffusion Classifier</span>, a novel method using large-scale text-to-image Diffusion Models for zero-shot classification (<span id="S8.p2.1.2" class="ltx_text ltx_font_bold">Figure¬†<a href="#S8.F10" title="Figure 10 ‚Ä£ 8 Applications of Diffusion Models in Other Fields ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a></span>). This approach leverages Diffusion Models‚Äô density estimates to classify images without additional training, outperforming existing methods. The Diffusion Classifier performs exceptionally well in benchmarks and multimodal compositional reasoning, showing notable improvements in zero-shot reasoning tasks. It also demonstrated robustness against distribution shifts when tested with ImageNet¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>. While the study focuses on Stable Diffusion, it does not explore the potential challenges or limitations that may arise when applying this approach to other types of classification problems beyond image data.</p>
</div>
<figure id="S8.F10" class="ltx_figure"><img src="/html/2408.10207/assets/dfotheradobi1.png" id="S8.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="349" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span><span id="S8.F10.2.1" class="ltx_text ltx_font_bold">Various texts and captions (BLIP, Human-modified BLIP, correct class names, incorrect class names) in zero-shot classification using text-based DMs is examined. The input image is inverted with the caption and reconstructed using deterministic DDIM sampling. Human-modified BLIP captions align best with the input image. Images reconstructed with correct class names (col. 4) match better than those with incorrect class names (col. 5 and 6). In Row 3 (col. 4 and 5), the base Stable DMs fails to distinguish between Birman and Ragdoll breeds, causing classifier failure. BLIP: Bootstrapped Language-Image Pretraining, DDIM: Denoising Diffusion Implicit Models¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite></span></figcaption>
</figure>
<div id="S8.p3" class="ltx_para ltx_noindent">
<p id="S8.p3.1" class="ltx_p">Zhuang et al. (2023) explored DMs for semantic image synthesis, focusing on abdominal CT images. They compared three models‚ÄîConditional DDPM, Mask-guided DDPM, and Edge-guided DDPM‚Äîagainst SOTA GAN-based approaches. By using semantic masks to guide synthesis, the proposed approaches surpassed GANs in terms of FID, PSNR, SSIM, and Dice Score, generating higher-quality and more clinically accurate images¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. Despite their advantages, the proposed DMs faced significant challenges due to high computational costs and long processing times.</p>
</div>
<div id="S8.p4" class="ltx_para ltx_noindent">
<p id="S8.p4.1" class="ltx_p">Jiang et al. (2023) addressed data protection against unauthorized uses such as adversarial attacks (<span id="S8.p4.1.1" class="ltx_text ltx_font_bold">Figure¬†<a href="#S8.F11" title="Figure 11 ‚Ä£ 8 Applications of Diffusion Models in Other Fields ‚Ä£ A Comprehensive Survey on Diffusion Models and Their Applications" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a></span>). The study proposed a novel purification process called <span id="S8.p4.1.2" class="ltx_text ltx_font_bold">Joint-Conditional Diffusion Purification (JCDP)</span>, which projects Uncertain Examples (UEs) onto the manifold of Learnable Unauthorized Examples (LEs). By leveraging DMs and image generation approaches, the study maps from UEs to their corresponding clean samples. However, the study did not consider whether it might perform well in situations where the adversarial attack might evolve over time. Apart from this, they did not consider the generalizability of their proposed methods in terms of various Machine Learning techniques as well¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>.</p>
</div>
<figure id="S8.F11" class="ltx_figure"><img src="/html/2408.10207/assets/unlearnableadobi1.png" id="S8.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="294" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span><span id="S8.F11.2.1" class="ltx_text ltx_font_bold">Joint-conditional diffusion purification (JCDP) demonstrates the concept of learnable examples. When applied to datasets, non-generalizable or unlearnable data points fail to achieve effective generalization, consequently impacting the quality and reliability of the samples employed in training classification models¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>.</span></figcaption>
</figure>
<div id="S8.p5" class="ltx_para ltx_noindent">
<p id="S8.p5.1" class="ltx_p">Hsu et al. (2023) proposed <span id="S8.p5.1.1" class="ltx_text ltx_font_bold">Score Dynamics (SD)</span>, a framework that uses Graph Neural Networks to accelerate Molecular Dynamics (MD) simulations. SD uses evolution operators for large timestep transitions, which greatly increase simulation speed. It simulates molecular dynamics with 10 picosecond timesteps, showing high accuracy in studies of alanine dipeptide and short alkanes in aqueous solutions. SD outperforms traditional MD in speed by up to two orders of magnitude¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. Despite these promising results, challenges include extending SD to larger molecules, refining assumptions, and improving the accuracy and efficiency of the score model.</p>
</div>
<div id="S8.p6" class="ltx_para ltx_noindent">
<p id="S8.p6.1" class="ltx_p">Wang et al. (2023) introduced <span id="S8.p6.1.1" class="ltx_text ltx_font_bold">Atmospheric Turbulence Variational Diffusion (AT-VarDiff)</span>, a deep conditional Diffusion Model designed to correct atmospheric turbulence in images using a variational inference framework. This approach addresses geometric distortion and spatially variant blur. When tested on a synthetic dataset, AT-VarDiff achieved an LPIPS of 0.1094, an FID of 32.69, and a Naturalness Image Quality Evaluator (NIQE) score of 6.46, outperforming existing models¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>.</p>
</div>
<div id="S8.p7" class="ltx_para ltx_noindent">
<p id="S8.p7.1" class="ltx_p">Sartor et al. (2023) proposed <span id="S8.p7.1.1" class="ltx_text ltx_font_bold">Material Fusion (MatFusion)</span>, a method for estimating Spatially Varying Bidirectional Reflectance Distribution Functions (SVBRDF) from photographs using Diffusion Models. MatFusion is trained on 312,165 synthetic material samples and refines a conditional model to estimate material properties, generating multiple SVBRDF estimates per photo for user selection. It achieves high accuracy with an LPIPS of 0.2056 and RMSE values of 0.041 for diffuse, 0.066 for specular, 0.126 for roughness, and 0.052 for normal maps¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>. However, its performance depends on the quality of the photos and the user‚Äôs selection, which may introduce variability in the results. Additionally, the method lacks automatic selection metrics and could benefit from optimal regularization to improve consistency.</p>
</div>
<div id="S8.p8" class="ltx_para ltx_noindent">
<p id="S8.p8.1" class="ltx_p">Wei et al. (2023) proposed <span id="S8.p8.1.1" class="ltx_text ltx_font_bold">Building Diffusion (BuilDiff)</span>, an innovative method for generating 3D building point clouds from single general-view images. BuilDiff uses two CMDs and a regularization strategy to synthesize building roofs while maintaining structural integrity. It extracts image embeddings through a Convolutional Neural Network-based auto-encoder and utilizes a conditional denoising diffusion network and a point cloud upsampler. Tested on BuildingNet-SVI and BuildingNL3D datasets, BuilDiff outperforms existing methods¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. Despite its superior performance, BuilDiff heavily relies on the quality and variety of training data, limiting its generalizability to unseen building styles. Additionally, it demands significant computational resources for both training and inference. Furthermore, the model struggles to capture fine-grained details of building structures due to the resolution limits of the point clouds used.</p>
</div>
<div id="S8.p9" class="ltx_para ltx_noindent">
<p id="S8.p9.1" class="ltx_p">Niu et al. (2024) developed the <span id="S8.p9.1.1" class="ltx_text ltx_font_bold">Accelerated Conditional Diffusion Model for Image Super-Resolution (ACDMSR)</span>. ACDMSR used pre-super-resolved images as conditional inputs, improving efficiency and quality over traditional Diffusion Models. It adapted Diffusion Models for super-resolution through a faster, iterative denoising process. Testing on benchmark datasets like Set5 and Urban100 showed ACDMSR outperformed existing methods¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. However, reliance on initial pre-super-resolution may have limited its flexibility in diverse applications.</p>
</div>
<div id="S8.p10" class="ltx_para">
<p id="S8.p10.1" class="ltx_p"><span id="S8.p10.1.1" class="ltx_text ltx_font_bold">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:other_fields</span></span> summarizes some of the referenced literature that introduces diffusion-based approaches in various fields.</p>
</div>
<figure id="S8.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span><span id="S8.T7.1.1" class="ltx_text ltx_font_bold">Applications of DMs in other fields based on the referenced literature. FID: Frechet Inception Distance, PSNR: Peak Signal-to-Noise Ratio, SSIM: Structural Similarity Index Measure, DSC: Dice Similarity Coefficient, MAE: Mean Absolute Error, MOS: Mean Opinion Score, SMOS: Style Similarity MOS. Best results are highlighted in bold.</span></figcaption>
<table id="S8.T7.3" class="ltx_tabular">
<thead class="ltx_thead">
<tr id="S8.T7.3.1.1" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S8.T7.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S8.T7.3.1.1.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S8.T7.3.1.1.1.1.1" class="ltx_p" style="width:13.0pt;"><span id="S8.T7.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></span>
</span>
</th>
<th id="S8.T7.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S8.T7.3.1.1.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S8.T7.3.1.1.2.1.1" class="ltx_p" style="width:65.0pt;"><span id="S8.T7.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Algorithms</span></span>
</span>
</th>
<th id="S8.T7.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S8.T7.3.1.1.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S8.T7.3.1.1.3.1.1" class="ltx_p" style="width:69.4pt;"><span id="S8.T7.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Applications</span></span>
</span>
</th>
<th id="S8.T7.3.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S8.T7.3.1.1.4.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S8.T7.3.1.1.4.1.1" class="ltx_p" style="width:65.0pt;"><span id="S8.T7.3.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</th>
<th id="S8.T7.3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S8.T7.3.1.1.5.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S8.T7.3.1.1.5.1.1" class="ltx_p" style="width:69.4pt;"><span id="S8.T7.3.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Evaluations</span></span>
</span>
</th>
<th id="S8.T7.3.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S8.T7.3.1.1.6.1" class="ltx_inline-block ltx_align_top" style="background-color:#E6E6E6;">
<span id="S8.T7.3.1.1.6.1.1" class="ltx_p" style="width:73.7pt;"><span id="S8.T7.3.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Limitations</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S8.T7.3.2.1" class="ltx_tr">
<td id="S8.T7.3.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.2.1.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.2.1.2.1.1" class="ltx_p" style="width:65.0pt;">Diffusion Classifier using text-to-image Diffusion Models</span>
</span>
</td>
<td id="S8.T7.3.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.2.1.3.1.1" class="ltx_p" style="width:69.4pt;">Zero-shot classification using generative models</span>
</span>
</td>
<td id="S8.T7.3.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.2.1.4.1.1" class="ltx_p" style="width:65.0pt;">Standard image classification benchmarks (e.g., ImageNet, CIFAR10)</span>
</span>
</td>
<td id="S8.T7.3.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.2.1.5.1.1" class="ltx_p" style="width:69.4pt;">Zero-shot classification accuracy on ImageNet using Diffusion Classifier: <span id="S8.T7.3.2.1.5.1.1.1" class="ltx_text ltx_font_bold">58.9%</span></span>
</span>
</td>
<td id="S8.T7.3.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.2.1.6.1.1" class="ltx_p" style="width:73.7pt;">Performance gap in zero-shot recognition compared to SOTA discriminative models</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.3.2" class="ltx_tr">
<td id="S8.T7.3.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.3.2.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.3.2.2.1.1" class="ltx_p" style="width:65.0pt;">CMDs for semantic image synthesis</span>
</span>
</td>
<td id="S8.T7.3.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.3.2.3.1.1" class="ltx_p" style="width:69.4pt;">Semantic synthesis for abdominal CT, used in data augmentation</span>
</span>
</td>
<td id="S8.T7.3.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.3.2.4.1.1" class="ltx_p" style="width:65.0pt;">Not specified</span>
</span>
</td>
<td id="S8.T7.3.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.3.2.5.1.1" class="ltx_p" style="width:69.4pt;">FID: 10.32, PSNR: 16.14, SSIM: 0.64, DSC: <span id="S8.T7.3.3.2.5.1.1.1" class="ltx_text ltx_font_bold">95.6%</span> for mask-guided DDPM at 100k iterations</span>
</span>
</td>
<td id="S8.T7.3.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.3.2.6.1.1" class="ltx_p" style="width:73.7pt;">High sampling time and computational cost</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.4.3" class="ltx_tr">
<td id="S8.T7.3.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.4.3.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.4.3.2.1.1" class="ltx_p" style="width:65.0pt;">Learnable Unauthorized Examples (LEs) using joint-CMDs</span>
</span>
</td>
<td id="S8.T7.3.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.4.3.3.1.1" class="ltx_p" style="width:69.4pt;">Countermeasure to unlearnable examples in Machine Learning models</span>
</span>
</td>
<td id="S8.T7.3.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.4.3.4.1.1" class="ltx_p" style="width:65.0pt;">CIFAR-10, CIFAR-100, SVHN</span>
</span>
</td>
<td id="S8.T7.3.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.4.3.5.1.1" class="ltx_p" style="width:69.4pt;">Test accuracy on CIFAR-10 using LE: <span id="S8.T7.3.4.3.5.1.1.1" class="ltx_text ltx_font_bold">94.0%</span>, CIFAR-100: 67.8%, SVHN: <span id="S8.T7.3.4.3.5.1.1.2" class="ltx_text ltx_font_bold">94.9%</span></span>
</span>
</td>
<td id="S8.T7.3.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.4.3.6.1.1" class="ltx_p" style="width:73.7pt;">Limited by distribution mismatches</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.5.4" class="ltx_tr">
<td id="S8.T7.3.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.5.4.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.5.4.2.1.1" class="ltx_p" style="width:65.0pt;">Diffusion-based Non-Intrusive Load Monitoring (DiffNILM) Diffusion Probabilistic Model</span>
</span>
</td>
<td id="S8.T7.3.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.5.4.3.1.1" class="ltx_p" style="width:69.4pt;">Non-intrusive Load Monitoring (NILM) for appliance power consumption pattern disaggregation</span>
</span>
</td>
<td id="S8.T7.3.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.5.4.4.1.1" class="ltx_p" style="width:65.0pt;">REDD and UKDALE datasets</span>
</span>
</td>
<td id="S8.T7.3.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.5.4.5.1.1" class="ltx_p" style="width:69.4pt;">F1-Score: <span id="S8.T7.3.5.4.5.1.1.1" class="ltx_text ltx_font_bold">0.79</span> for refrigerator on REDD, MAE: <span id="S8.T7.3.5.4.5.1.1.2" class="ltx_text ltx_font_bold">4.54</span> for microwave on UKDALE</span>
</span>
</td>
<td id="S8.T7.3.5.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.5.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.5.4.6.1.1" class="ltx_p" style="width:73.7pt;">Generation of power waveforms not always sufficiently smooth; computational efficiency not optimized</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.6.5" class="ltx_tr">
<td id="S8.T7.3.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.6.5.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.6.5.2.1.1" class="ltx_p" style="width:65.0pt;">Noise-Robust Expressive Text-to-Speech model (NoreSpeech)</span>
</span>
</td>
<td id="S8.T7.3.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.6.5.3.1.1" class="ltx_p" style="width:69.4pt;">Expressive TTS in noise environments</span>
</span>
</td>
<td id="S8.T7.3.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.6.5.4.1.1" class="ltx_p" style="width:65.0pt;">Not specified</span>
</span>
</td>
<td id="S8.T7.3.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.6.5.5.1.1" class="ltx_p" style="width:69.4pt;">MOS: <span id="S8.T7.3.6.5.5.1.1.1" class="ltx_text ltx_font_bold">4.11</span>, SMOS: <span id="S8.T7.3.6.5.5.1.1.2" class="ltx_text ltx_font_bold">4.14</span> for NoreSpeech with T-SSL in noisy conditions</span>
</span>
</td>
<td id="S8.T7.3.6.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.6.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.6.5.6.1.1" class="ltx_p" style="width:73.7pt;">Dependent on quality of style teacher model</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.7.6" class="ltx_tr">
<td id="S8.T7.3.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.7.6.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.7.6.2.1.1" class="ltx_p" style="width:65.0pt;">Diffusion-based data augmentation for nuclei segmentation</span>
</span>
</td>
<td id="S8.T7.3.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.7.6.3.1.1" class="ltx_p" style="width:69.4pt;">Nuclei segmentation in histopathology image analysis</span>
</span>
</td>
<td id="S8.T7.3.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.7.6.4.1.1" class="ltx_p" style="width:65.0pt;">MoNuSeg and Kumar datasets</span>
</span>
</td>
<td id="S8.T7.3.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.7.6.5.1.1" class="ltx_p" style="width:69.4pt;">Dice score: <span id="S8.T7.3.7.6.5.1.1.1" class="ltx_text ltx_font_bold">0.83</span>, AJI: <span id="S8.T7.3.7.6.5.1.1.2" class="ltx_text ltx_font_bold">0.68</span> with 100% augmented data on MoNuSeg dataset</span>
</span>
</td>
<td id="S8.T7.3.7.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S8.T7.3.7.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.7.6.6.1.1" class="ltx_p" style="width:73.7pt;">Dependent on the quality of synthetic data</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.8.7" class="ltx_tr">
<td id="S8.T7.3.8.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.8.7.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.8.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.8.7.2.1.1" class="ltx_p" style="width:65.0pt;">AT-VarDiff</span>
</span>
</td>
<td id="S8.T7.3.8.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.8.7.3.1.1" class="ltx_p" style="width:69.4pt;">Atmospheric turbulence (AT) correction</span>
</span>
</td>
<td id="S8.T7.3.8.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.8.7.4.1.1" class="ltx_p" style="width:65.0pt;">Comprehensive synthetic atmospheric turbulence dataset</span>
</span>
</td>
<td id="S8.T7.3.8.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.8.7.5.1.1" class="ltx_p" style="width:69.4pt;">LPIPS: 0.11, FID: 32.69, NIQE: 6.46</span>
</span>
</td>
<td id="S8.T7.3.8.7.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.8.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.8.7.6.1.1" class="ltx_p" style="width:73.7pt;">May not generalize well to real-life atmospheric turbulence images.</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.9.8" class="ltx_tr">
<td id="S8.T7.3.9.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.9.8.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.9.8.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.9.8.2.1.1" class="ltx_p" style="width:65.0pt;">MatFusion Diffusion Models (unconditional and conditional)</span>
</span>
</td>
<td id="S8.T7.3.9.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.9.8.3.1.1" class="ltx_p" style="width:69.4pt;">SVBRDF estimation from photographs</span>
</span>
</td>
<td id="S8.T7.3.9.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.9.8.4.1.1" class="ltx_p" style="width:65.0pt;">Large set of 312,165 synthetic spatially varying material exemplars</span>
</span>
</td>
<td id="S8.T7.3.9.8.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.9.8.5.1.1" class="ltx_p" style="width:69.4pt;">RMSE on property maps: 0.04, LPIPS error on renders: 0.21</span>
</span>
</td>
<td id="S8.T7.3.9.8.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.9.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.9.8.6.1.1" class="ltx_p" style="width:73.7pt;">Limited by the variation in lighting conditions.</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.10.9" class="ltx_tr">
<td id="S8.T7.3.10.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.10.9.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.10.9.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.10.9.2.1.1" class="ltx_p" style="width:65.0pt;">Point cloud Diffusion Models with image conditioning schemes</span>
</span>
</td>
<td id="S8.T7.3.10.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.10.9.3.1.1" class="ltx_p" style="width:69.4pt;">3D building generation from images</span>
</span>
</td>
<td id="S8.T7.3.10.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.10.9.4.1.1" class="ltx_p" style="width:65.0pt;">BuildingNet-SVI and BuildingNL3D datasets</span>
</span>
</td>
<td id="S8.T7.3.10.9.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.10.9.5.1.1" class="ltx_p" style="width:69.4pt;">CD: 3.14, EMD: 10.84, F1 score: 21.41 on BuildingNet-SVI</span>
</span>
</td>
<td id="S8.T7.3.10.9.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S8.T7.3.10.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.10.9.6.1.1" class="ltx_p" style="width:73.7pt;">Constrained by specific image viewing angles.</span>
</span>
</td>
</tr>
<tr id="S8.T7.3.11.10" class="ltx_tr">
<td id="S8.T7.3.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S8.T7.3.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.11.10.1.1.1" class="ltx_p" style="width:13.0pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite></span>
</span>
</td>
<td id="S8.T7.3.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S8.T7.3.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.11.10.2.1.1" class="ltx_p" style="width:65.0pt;">ACDMSR: Accelerated Conditional Diffusion Model for Image Super-Resolution</span>
</span>
</td>
<td id="S8.T7.3.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S8.T7.3.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.11.10.3.1.1" class="ltx_p" style="width:69.4pt;">Enhancing super-resolution using Diffusion Models conditioned on pre-super-resolved images</span>
</span>
</td>
<td id="S8.T7.3.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S8.T7.3.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.11.10.4.1.1" class="ltx_p" style="width:65.0pt;">DIV2K, Set5, Set14, Urban100, BSD100, Manga109</span>
</span>
</td>
<td id="S8.T7.3.11.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S8.T7.3.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.11.10.5.1.1" class="ltx_p" style="width:69.4pt;">LPIS: 0.08, PSNR: 25.95, SSIM: 0.67</span>
</span>
</td>
<td id="S8.T7.3.11.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S8.T7.3.11.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S8.T7.3.11.10.6.1.1" class="ltx_p" style="width:73.7pt;">Challenges remain in processing images with more complex degradation patterns.</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span><span id="S8.T7.4.1" class="ltx_text ltx_font_bold">Applications of Diffusion Models in other fields based on the referenced literature (cont.).</span></figcaption>
</figure>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Discussion</h2>

<section id="S9.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.1 </span>Ensuring the authenticity of synthesized media</h3>

<div id="S9.SS1.p1" class="ltx_para ltx_noindent">
<p id="S9.SS1.p1.1" class="ltx_p">DMs play an important role in improving media quality and generating high-fidelity samples. Techniques such as SAG advance image generation by concentrating on significant areas and minimizing artifacts¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. While SAG enhances image quality by leveraging self-attention maps, it still faces challenges in real-time applications due to high computational demands¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. On the other hand, Learnable State-Estimator-based models offer computational efficiency but require extensive domain-specific adaptations for broader applications¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.</p>
</div>
<div id="S9.SS1.p2" class="ltx_para ltx_noindent">
<p id="S9.SS1.p2.1" class="ltx_p">Contradictions arise when certain methods show better performance in specific cases but fall short in others. For example, while the state-estimator-based model performs well on tasks like inpainting and deblurring, it may not work in real-time as effectively as SAG. This discrepancy highlights the need for a balanced approach that combines the strengths of various techniques.</p>
</div>
<div id="S9.SS1.p3" class="ltx_para ltx_noindent">
<p id="S9.SS1.p3.1" class="ltx_p">To address these challenges, integrating different types of DMs, such as Stepwise Error for Diffusion-generated Image Detection (SeDID) and Unlearnable Diffusion Perturbation (EUDP), could be effective¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>. Additionally, strategies like sampling space truncation and robustness penalties can also be helpful in ensuring the authenticity of media quality¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>.</p>
</div>
</section>
<section id="S9.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.2 </span>Overcoming challenges in synthesizing high-quality images and audio</h3>

<div id="S9.SS2.p1" class="ltx_para ltx_noindent">
<p id="S9.SS2.p1.1" class="ltx_p">Diffusion-based models play a crucial role in synthesizing high-quality images and audio by refining noise into structured data. These models utilize DDPMs, involving a forward process that adds Gaussian noise to the data and a reverse process that removes this noise to reconstruct the original signal. For instance, text-to-audio synthesis methods like CLIPSonic use CDMs to translate text embeddings into audio. This method shows superior performance but faces limitations due to the quality of pretrained models, distribution mismatches, and training complexity¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. Similarly, SDG improves image synthesis by adding fine-grained control to pretrained models. Its effectiveness depends on the precision of these models and the accuracy of guidance signals, raising concerns about potential misuse¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.</p>
</div>
<div id="S9.SS2.p2" class="ltx_para ltx_noindent">
<p id="S9.SS2.p2.1" class="ltx_p">Other approaches, such as DiffDreamer, use CMDs (CMDs) for scene extrapolation. They often show better quality and consistency than GAN-based methods but struggle with real-time synthesis and variety in generated content¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. Interactive tools like Diffusion-based Art Generation (DiffusArt) use Conditional Diffusion Probabilistic Models for line art colorization, which produces high-quality images but requires precise user input and faces computational inefficiencies¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. SketchFusion focuses on sketch-guided image editing, maintains the integrity of sketches, and achieves high-performance metrics but is limited to binary sketches¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>. Semantic-Conditional Diffusion Networks improve image captioning by enhancing visual-language alignment and outperform traditional models, but they face high computational demands and complexity¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.</p>
</div>
<div id="S9.SS2.p3" class="ltx_para ltx_noindent">
<p id="S9.SS2.p3.1" class="ltx_p">To overcome these challenges, future research should improve the computational efficiency of DMs, improve the quality and robustness of pretrained models, and develop adaptive techniques to handle distribution mismatches. Additionally, integrating ethical guidelines and protective measures can help reduce the risks of misuse, ensuring that these advanced models are applied responsibly.</p>
</div>
</section>
<section id="S9.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.3 </span>Optimizing DMs to reduce artifacts and improve image quality</h3>

<div id="S9.SS3.p1" class="ltx_para ltx_noindent">
<p id="S9.SS3.p1.1" class="ltx_p">Optimizing DMs to minimize artifacts and improve image quality is crucial for their broader application. These models, which refine noise into structured data, can introduce artifacts that compromise image fidelity¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. To optimize DMs for reducing artifacts and enhancing image quality, various techniques have been proposed. These include using Deep Interpretable Convolutional Dictionary Networks (DICDNet) for metal artifact reduction in CT images, and automatic segmentation of 3D objects to minimize supports and cuts for 3D printing¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>. For fetal MRI, efforts focus on improving image quality by optimizing acquisition speed, spatial resolution, and signal-to-noise ratio while considering artifacts from motion, banding, and aliasing¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. Challenges persist, such as balancing the effects of supports and cuts in 3D printing segmentation, trade-offs between scan parameters in fetal MRI optimization, and addressing artifacts from beam hardening in X-ray imaging¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>. These limitations highlight the complexity of optimizing Diffusion Models to reduce artifacts and improve image quality across different imaging methods.</p>
</div>
<div id="S9.SS3.p2" class="ltx_para ltx_noindent">
<p id="S9.SS3.p2.1" class="ltx_p">Another strategy is SDG integrates fine-grained control into pretrained models via image-text matching score gradients, enhancing image synthesis quality without retraining models¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. The success of SDG, though, depends on the precision of pretrained models and guidance signal accuracy.</p>
</div>
<div id="S9.SS3.p3" class="ltx_para ltx_noindent">
<p id="S9.SS3.p3.1" class="ltx_p">Advanced noise estimation techniques further improve DMs. Pixel-level autoregressive processes, like those used in Image Transformer models, significantly reduce noise and artifacts, which improves image fidelity and consistency across datasets¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Apart from this, dynamic thresholding and adaptive noise schedules can also fine-tune denoising steps to improve image quality by handling complex structures and textures more effectively.</p>
</div>
<div id="S9.SS3.p4" class="ltx_para ltx_noindent">
<p id="S9.SS3.p4.1" class="ltx_p">To sum up, optimizing DMs to reduce artifacts and improve image quality requires a multi-faceted approach. Incorporating, semantic guidance, and advanced noise estimation techniques, along with optimizing the diffusion process, can significantly increase model performance. Future research should focus on improving computational efficiency, developing robust conditioning strategies, and integrating adaptive techniques to further reduce artifacts and enhance image quality.</p>
</div>
</section>
<section id="S9.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.4 </span>Addressing computational efficiency and scalability issues in DMs</h3>

<div id="S9.SS4.p1" class="ltx_para ltx_noindent">
<p id="S9.SS4.p1.1" class="ltx_p">Addressing computational efficiency and scalability in DMs is crucial for practical application and widespread adoption. Despite their ability in generating high-fidelity images and audio, DMs often struggle with high computational demands and scalability, particularly with large datasets or real-time applications.</p>
</div>
<div id="S9.SS4.p2" class="ltx_para ltx_noindent">
<p id="S9.SS4.p2.1" class="ltx_p">To optimize computational efficiency, it is essential to use more efficient network architectures. For instance, integrating guidance into pretrained models via image-text matching score gradients eliminate the need for extensive retraining, thereby improves computational efficiency¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Additionally, dynamic adaptation of the diffusion process is an effective strategy. Adjusting the diffusion process within a latent space can achieve significant computational efficiency¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, which allows the model to focus resources on the most relevant datasets. Furthermore, parallelization and hardware acceleration, such as using Graphics Processing Unit (GPUs) and ensor Processing Unit (TPUs), can address scalability issues. Therefore, distributing the computational load across multiple processors can significantly speed up the training and inference processes of DMs.</p>
</div>
<div id="S9.SS4.p3" class="ltx_para ltx_noindent">
<p id="S9.SS4.p3.1" class="ltx_p">Moreover, multi-shot averaging strategies can improve the quality of generated images while maintaining efficiency¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Averaging multiple generated images reduces noise and improves overall quality without significantly increasing computational costs.
In summary, addressing computational efficiency and scalability in DMs involves optimizing network architectures, dynamically adapting the diffusion process, leveraging hardware acceleration, refining algorithms, and deploying strategies like multi-shot averaging. Future research should explore these approaches to develop more efficient and scalable DMs for a broader range of tasks and datasets.</p>
</div>
</section>
<section id="S9.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.5 </span>Improving DMs for accurate and reliable medical imaging and diagnostics</h3>

<div id="S9.SS5.p1" class="ltx_para ltx_noindent">
<p id="S9.SS5.p1.1" class="ltx_p">DMs in medical imaging and diagnostics show significant promise due to their ability to create high-quality images. Critical areas of focus include reducing the model size to ensure efficient deployment, developing better training approaches for realistic samples, and leveraging advanced techniques to handle data augmentation and anonymization when considering DM-based approaches.</p>
</div>
<div id="S9.SS5.p2" class="ltx_para ltx_noindent">
<p id="S9.SS5.p2.1" class="ltx_p">Reducing the model size of DMs is crucial for practical applications in medical imaging, where computational resources are often limited. Therefore, techniques such as model pruning, knowledge distillation, and post-training quantization are commonly used to achieve this goal. For instance, model pruning involves removing redundant parameters from the model, which decreases the model size without significantly affecting performance. Similarly, knowledge distillation transfers the knowledge from a large model (teacher) to a smaller model (student), which helps in maintaining performance while reducing the model size¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>. Additionally, post-training quantization converts the model parameters from floating-point to lower-bit representations, which reduces model size and speeds up inference without requiring retraining¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>.</p>
</div>
<div id="S9.SS5.p3" class="ltx_para ltx_noindent">
<p id="S9.SS5.p3.1" class="ltx_p">In medical imaging, data augmentation and anonymization are critical for creating robust ML models and protecting patient privacy. Semantic-based DMs offer promising solutions for these challenges. For data augmentation, these models can generate diverse and realistic medical images by conditioning on specific semantic features, which enriches the training dataset and improves model generalization¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>. For anonymization, semantic-based approaches can mask identifiable features in medical images while preserving clinically relevant information, ensuring that patient privacy is maintained without compromising the utility of the data¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>, <a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>.</p>
</div>
<div id="S9.SS5.p4" class="ltx_para ltx_noindent">
<p id="S9.SS5.p4.1" class="ltx_p">Incorporating domain-specific knowledge into training processes can further improve DMs. For instance, integrating medical expertise and anatomical priors helps models better understand the structure and context of medical images, leading to more accurate diagnostics¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. Moreover, collaborations between artificial intelligence researchers and medical professionals can facilitate the integration of such knowledge, enhancing the overall effectiveness of the models.</p>
</div>
</section>
<section id="S9.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.6 </span>Expanding the applicability and effectiveness of DMs in diverse fields</h3>

<div id="S9.SS6.p1" class="ltx_para ltx_noindent">
<p id="S9.SS6.p1.1" class="ltx_p">DMs are gaining popularity across various fields beyond their initial use in image analysis. These models have shown effectiveness in time series forecasting, imputation, and generation, which demonstrates their versatility in handling sequential data. Additionally, DMs have been adapted for predicting chaotic dynamical systems, which offers uncertainty quantification and the ability to represent outliers and extreme events effectively¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>. Moreover, advancements have extended DMs to Riemannian manifolds, enabling applications in constrained conformational modeling of protein backbones and robotic arms, which underscores their relevance in scientific domains¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>.
Despite these advances, one significant concern is model collapse, where the model fails to generate diverse outputs over time, leading to reduced effectiveness in applications requiring high variability. This is particularly relevant in fields like finance and time series forecasting, where the accuracy of predictions is crucial. While DMs offer robust solutions for these tasks, their feasibility compared to existing, more computationally efficient approaches like autoregressive models or Long Short-Term Memory networks (LSTMs) remains questionable. It is essential for researchers to exercise caution when considering DM-based approaches for financial and time series data, as these models may not always offer the most practical or efficient solutions¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>.
DMs have been applied to generate synthetic data, but they often underperform compared to techniques such as GANs, oversampling, and Synthetic Minority Over-sampling Technique (SMOTE). These traditional methods are often easier to deploy and require less computational power, making them more accessible for many applications. For instance, GANs have been widely used in generating realistic images and synthetic data for training ML models, providing a simpler alternative to DMs. Similarly, techniques like SMOTE are effective for addressing class imbalances in datasets and can be implemented with relative ease compared to the complex training processes required for DMs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>.</p>
</div>
</section>
<section id="S9.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.7 </span>Mitigating ethical considerations and potential risks associated with the use of DMs</h3>

<div id="S9.SS7.p1" class="ltx_para ltx_noindent">
<p id="S9.SS7.p1.1" class="ltx_p">While DMs are surpassing GANs in generating realistic images, audio, and other types of data, they also raise questions regarding ethical use and practical concerns. For instance, one of the primary ethical concerns is the potential for misuse in creating deepfakes and synthetic media that can spread misinformation or violate privacy. To reduce this risk, it is essential to develop robust detection mechanisms that can differentiate between real and synthetic media. Implementing adversarial training techniques can improve the ability of models to identify and flag manipulated content¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>.</p>
</div>
<div id="S9.SS7.p2" class="ltx_para ltx_noindent">
<p id="S9.SS7.p2.1" class="ltx_p">Another major risk is bias in the generated outputs, which can perpetuate or even worsen existing social biases if not properly managed. Ensuring diversity in training data and incorporating fairness-aware algorithms can help reduce bias in Diffusion Models. Regular audits and updates to the models can also ensure they remain unbiased and fair in their outputs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>.</p>
</div>
<div id="S9.SS7.p3" class="ltx_para ltx_noindent">
<p id="S9.SS7.p3.1" class="ltx_p">Transparency and explainability of DMs are also critical to address ethical concerns. Users need to understand how these models make decisions and generate outputs. Developing methods to explain the black box of DMs might help make their operations more transparent and accountable. Techniques such as interpretability frameworks and model-agnostic tools like Local Interpretable Model-Agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) can provide insights into how models produce their results¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>.</p>
</div>
<div id="S9.SS7.p4" class="ltx_para ltx_noindent">
<p id="S9.SS7.p4.1" class="ltx_p">Data privacy is another major concern, especially when DMs are applied to sensitive areas such as healthcare systems and clinical diagnosis. Ensuring that models comply with data protection regulations, such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA), is essential. Techniques like differential privacy can protect individual data while still allowing models to learn effectively from large datasets¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>.</p>
</div>
<div id="S9.SS7.p5" class="ltx_para ltx_noindent">
<p id="S9.SS7.p5.1" class="ltx_p">Collaborative governance and the establishment of ethical guidelines for the development and deployment of DMs are also necessary. Engaging stakeholders from diverse fields, including ethicists, policymakers, and technologists, can help create comprehensive frameworks that address the ethical implications of these technologies. Such collaboration can lead to the development of standards and best practices that promote the responsible use of DMs¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span>Conclusion</h2>

<div id="S10.p1" class="ltx_para ltx_noindent">
<p id="S10.p1.1" class="ltx_p">Diffusion Models (DMs) promise to transform many fields by solving challenges in data generation and processing through the creation of realistic samples. Therefore, addressing current limitations and building on the strengths of DMs will enable wider adoption and more impactful applications across various domains in the future. Our findings show that DMs‚Äô ability to generate high-quality synthetic data improves performance in applications such as text-to-image generation, where models like Diffusion Transformers (DT) for stable diffusion demonstrate advancements in data privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. In cyber-physical system security, the Temporal and Feature TFDPM helps detect attacks by correlating channel data using Graph Attention Networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. Moreover, for cloud service anomaly detection, models like Maat combine metric forecasting with anomaly detection to achieve higher accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.</p>
</div>
<div id="S10.p2" class="ltx_para ltx_noindent">
<p id="S10.p2.1" class="ltx_p">In image processing, diffusion-based techniques have shown superior performance in tasks like image deblurring and super-resolution. For example, stochastic image deblurring using DMs achieves high perceptual image patch similarity and structural similarity index measures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Additionally, accelerated CMDs for applications like MRI reconstruction show potential by improving image quality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Furthermore, the selective diffusion distillation approach balances image fidelity and editability, making it suitable for various image manipulation tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</p>
</div>
<div id="S10.p3" class="ltx_para ltx_noindent">
<p id="S10.p3.1" class="ltx_p">However, while DMs generate realistic data, they also raise ethical concerns. One primary issue is the potential misuse in creating deepfakes and synthetic media that can spread misinformation or violate privacy. To mitigate this risk, robust detection mechanisms are essential. Ensuring models remain unbiased is also crucial, which can be achieved by incorporating fairness-aware algorithms and diverse training data. Furthermore, transparency and explainability of DMs are critical. Techniques like LIME and SHAP provide insights into how models generate their results. Apart from this, ensuring data compliance with regulations like the GDPR and the Health HIPAA is also necessary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>, <a href="#bib.bib100" title="" class="ltx_ref">100</a>, <a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>.</p>
</div>
<div id="S10.p4" class="ltx_para ltx_noindent">
<p id="S10.p4.1" class="ltx_p">High computational demands and the need for better sampling or network architectures are recurring issues in DMs. Models often require extensive hyperparameter tuning and may struggle with discrete signal modeling or generalizing to different contexts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Additionally, the reliance on correct timestep selection for semantic guidance in some models can limit flexibility <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. Slow inference speeds and high resource requirements hinder real-time deployment and scalability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
<div id="S10.p5" class="ltx_para ltx_noindent">
<p id="S10.p5.1" class="ltx_p">Therefore, future research should address these limitations by developing more efficient algorithms and leveraging advancements in computational technologies. Exploring semi-supervised or unsupervised learning approaches, along with transfer learning from pre-trained models, can help overcome data scarcity challenges. Improving the robustness of DMs to noise and their ability to handle different data types is essential. Moreover, continued interdisciplinary collaboration and clear ethical guidelines will be vital for the responsible and effective use of DMs across diverse fields.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Conflict of interest</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">The authors declare no conflict of interest.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Jascha Sohl-Dickstein, Eric¬†A Weiss, Niru Maheswaranathan, and Surya Ganguli.

</span>
<span class="ltx_bibblock">Deep unsupervised learning using nonequilibrium thermodynamics.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1503.03585</span>, 2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Chitwan Saharia, Jonathan Ho, William Chan, David¬†J Fleet, Mohammad Norouzi, and Tim Salimans.

</span>
<span class="ltx_bibblock">Image super-resolution via iterative refinement.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2104.07636</span>, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj√∂rn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span>, pages 10684‚Äì10695, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Zero-shot text-to-image generation.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.12092</span>, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Jacob Austin, Augustus Odena, Erik Nijkamp, Nal Ballas, and Ian Goodfellow.

</span>
<span class="ltx_bibblock">Structured denoising diffusion models in discrete state-spaces.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro.

</span>
<span class="ltx_bibblock">Diffwave: A versatile diffusion model for audio synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2009.09761</span>, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Emiel Hoogeboom, Taco Cohen, and Jakub¬†M Tomczak.

</span>
<span class="ltx_bibblock">Equivariant diffusion models for molecule generation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 8816‚Äì8831. PMLR, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Yang Song, Jascha Sohl-Dickstein, Diederik¬†P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.

</span>
<span class="ltx_bibblock">Score-based generative modeling through stochastic differential equations.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2011.13456</span>, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Yang Song and Stefano Ermon.

</span>
<span class="ltx_bibblock">Generative modeling by estimating gradients of the data distribution.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 32, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Brian¬†DO Anderson.

</span>
<span class="ltx_bibblock">Reverse-time diffusion equation models.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Stochastic Processes and their Applications</span>, 12(3):313‚Äì326, 1982.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Pascal Vincent.

</span>
<span class="ltx_bibblock">A connection between score matching and denoising autoencoders.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Neural computation</span>, 23(7):1661‚Äì1674, 2011.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Weilun Wang, Jianmin Bao, Wengang Zhou, Dongdong Chen, Dong Chen, Lu¬†Yuan, and Houqiang Li.

</span>
<span class="ltx_bibblock">Semantic image synthesis via diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2207.00050</span>, 2022.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, and LingPeng Kong.

</span>
<span class="ltx_bibblock">Diffuseq: Sequence to sequence text generation with diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2210.08933</span>, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Amirhossein Kazerouni, Ehsan¬†Khodapanah Aghdam, Moein Heidari, Reza Azad, Mohsen Fayyaz, Ilker Hacihaliloglu, and Dorit Merhof.

</span>
<span class="ltx_bibblock">Diffusion models in medical imaging: A comprehensive survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, page 102846, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Geoffrey Hinton, et¬†al.

</span>
<span class="ltx_bibblock">Learning multiple layers of features from tiny images.

</span>
<span class="ltx_bibblock">Technical report, University of Toronto, Toronto, ON, Canada, 2009.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xia.

</span>
<span class="ltx_bibblock">Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1506.03365</span>, 2015.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.

</span>
<span class="ltx_bibblock">Deep learning face attributes in the wild.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</span>, 2015.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Yang Song and Stefano Ermon.

</span>
<span class="ltx_bibblock">Improved techniques for training score-based generative models.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 33:12438‚Äì12448, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Prafulla Dhariwal and Alex Nichol.

</span>
<span class="ltx_bibblock">Diffusion models beat gans on image synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Diederik¬†P Kingma, Prafulla Dhariwal, Jonathan Ho, Tim Salimans, Xi¬†Chen, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Variational diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2107.00630</span>, 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Alex Nichol and Prafulla Dhariwal.

</span>
<span class="ltx_bibblock">Improved denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2102.09672</span>, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro.

</span>
<span class="ltx_bibblock">Diffwave: A versatile diffusion model for audio synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2009.09761</span>, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Roy Amit and Yogesh Balaji.

</span>
<span class="ltx_bibblock">Segdiff: Image segmentation with diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.02477</span>, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Girish Sastry, Amanda Askell, Pamela Chen, Mark Mishkin, and Chug.

</span>
<span class="ltx_bibblock">Glide: Towards photorealistic image generation and editing with text-guided diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2112.10741</span>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
et¬†al. Saharia.

</span>
<span class="ltx_bibblock">Image transformers with autoregressive models for high-fidelity image synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Journal of Advanced Image Processing</span>, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Cascaded diffusion models for high-fidelity image generation.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.15282</span>, 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Jonathan Ho, William Chan, Tim Salimans, Alexey Gritsenko, Kashyap¬†Chitta Kumar, and Phillip Isola.

</span>
<span class="ltx_bibblock">Video diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2204.03458</span>, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
et¬†al. Li.

</span>
<span class="ltx_bibblock">Optimizing diffusion models for image synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Journal of Computational Imaging</span>, 2023.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Jiafeng Mao, Xueting Wang, and Kiyoharu Aizawa.

</span>
<span class="ltx_bibblock">Guided image synthesis via initial image editing in diffusion model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Proceedings of the 31st ACM International Conference on Multimedia</span>, pages 5321‚Äì5329, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Jay Whang, Mauricio Delbracio, Hossein Talebi, Chitwan Saharia, Alexandros¬†G Dimakis, and Peyman Milanfar.

</span>
<span class="ltx_bibblock">Deblurring via stochastic refinement.

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, pages 16293‚Äì16303, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Hyungjin Chung, Byeongsu Sim, and Jong¬†Chul Ye.

</span>
<span class="ltx_bibblock">Come-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, pages 12413‚Äì12422, 2022.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Luozhou Wang, Shuai Yang, Shu Liu, and Ying-cong Chen.

</span>
<span class="ltx_bibblock">Not all steps are created equal: Selective diffusion distillation for image manipulation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 7472‚Äì7481, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Jiaman Li, Jiajun Wu, and C¬†Karen Liu.

</span>
<span class="ltx_bibblock">Object motion guided human motion synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Graphics (TOG)</span>, 42(6):1‚Äì11, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Zixuan Ni, Longhui Wei, Jiacheng Li, Siliang Tang, Yueting Zhuang, and Qi¬†Tian.

</span>
<span class="ltx_bibblock">Degeneration-tuning: Using scrambled grid shield unwanted concepts from stable diffusion.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Proceedings of the 31st ACM International Conference on Multimedia</span>, pages 8900‚Äì8909, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Tijin Yan, Tong Zhou, Yufeng Zhan, and Yuanqing Xia.

</span>
<span class="ltx_bibblock">Tfdpm: Attack detection for cyber‚Äìphysical systems with diffusion probabilistic models.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Knowledge-Based Systems</span>, 255:109743, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Cheryl Lee, Tianyi Yang, Zhuangbin Chen, Yuxin Su, and Michael¬†R Lyu.

</span>
<span class="ltx_bibblock">Maat: Performance metric anomaly anticipation for cloud services with conditional diffusion.

</span>
<span class="ltx_bibblock">In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)</span>, pages 116‚Äì128. IEEE, 2023.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Kehua Chen, Xianda Chen, Zihan Yu, Meixin Zhu, and Hai Yang.

</span>
<span class="ltx_bibblock">Equidiff: A conditional equivariant diffusion model for trajectory prediction.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)</span>, pages 746‚Äì751. IEEE, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Andreas Blattmann, Robin Rombach, Kaan Oktay, Jonas M√ºller, and Bj√∂rn Ommer.

</span>
<span class="ltx_bibblock">Retrieval-augmented diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, 35:15309‚Äì15324, 2022.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Susung Hong, Gyuseong Lee, Wooseok Jang, and Seungryong Kim.

</span>
<span class="ltx_bibblock">Improving sample quality of diffusion models using self-attention guidance.

</span>
<span class="ltx_bibblock">In <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 7462‚Äì7471, 2023.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Liya Ji, Zhefan Rao, Sinno¬†Jialin Pan, Chenyang Lei, and Qifeng Chen.

</span>
<span class="ltx_bibblock">A diffusion model with state estimation for degradation-blind inverse imaging.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</span>, volume¬†38, pages 2471‚Äì2479, 2024.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Yusheng Tian, Wei Liu, and Tan Lee.

</span>
<span class="ltx_bibblock">Diffusion-based mel-spectrogram enhancement for personalized speech synthesis with found data.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</span>, pages 1‚Äì7. IEEE, 2023.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Hai Jiang, Ao¬†Luo, Haoqiang Fan, Songchen Han, and Shuaicheng Liu.

</span>
<span class="ltx_bibblock">Low-light image enhancement with wavelet-based diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Graphics (TOG)</span>, 42(6):1‚Äì14, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Hao-Wen Dong, Xiaoyu Liu, Jordi Pons, Gautam Bhattacharya, Santiago Pascual, Joan Serr√†, Taylor Berg-Kirkpatrick, and Julian McAuley.

</span>
<span class="ltx_bibblock">Clipsonic: Text-to-audio synthesis with unlabeled videos and pretrained language-vision models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</span>, pages 1‚Äì5. IEEE, 2023.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.

</span>
<span class="ltx_bibblock">Ilvr: Conditioning method for denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2108.02938</span>, 2021.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
et¬†al. Liu.

</span>
<span class="ltx_bibblock">More control with semantic diffusion guidance for image synthesis.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Journal of Image and Audio Synthesis</span>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Shengqu Cai, Eric¬†Ryan Chan, Songyou Peng, Mohamad Shahbazi, Anton Obukhov, Luc Van¬†Gool, and Gordon Wetzstein.

</span>
<span class="ltx_bibblock">Diffdreamer: Towards consistent unsupervised single-view scene extrapolation with conditional diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 2139‚Äì2150, 2023.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
et¬†al. Carrillo.

</span>
<span class="ltx_bibblock">Interactive line art colorization with conditional diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Journal of Specialized Techniques and Innovations in Diffusion Models</span>, 2023.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Weihang Mao, Bo¬†Han, and Zihao Wang.

</span>
<span class="ltx_bibblock">Sketchffusion: Sketch-guided image editing with diffusion model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">2023 IEEE International Conference on Image Processing (ICIP)</span>, pages 790‚Äì794. IEEE, 2023.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Jianjie Luo, Yehao Li, Yingwei Pan, Ting Yao, Jianlin Feng, Hongyang Chao, and Tao Mei.

</span>
<span class="ltx_bibblock">Semantic-conditional diffusion networks for image captioning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span>, pages 23359‚Äì23368, 2023.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Tim Hsu, Babak Sadigh, Vasily Bulatov, and Fei Zhou.

</span>
<span class="ltx_bibblock">Score dynamics: scaling molecular dynamics with picosecond timesteps via conditional diffusion model.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.01678</span>, 2023.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Qingsen Yan, Tao Hu, Yuan Sun, Hao Tang, Yu¬†Zhu, Wei Dong, Luc Van¬†Gool, and Yanning Zhang.

</span>
<span class="ltx_bibblock">Towards high-quality hdr deghosting with conditional diffusion models.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Circuits and Systems for Video Technology</span>, 2023.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Wei Peng, Ehsan Adeli, Tomas Bosschieter, Sang¬†Hyun Park, Qingyu Zhao, and Kilian¬†M Pohl.

</span>
<span class="ltx_bibblock">Generating realistic brain mris via a conditional diffusion probabilistic model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>, pages 14‚Äì24. Springer, 2023.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Jason¬†J Yu, Fereshteh Forghani, Konstantinos¬†G Derpanis, and Marcus¬†A Brubaker.

</span>
<span class="ltx_bibblock">Long-term photometric consistent novel view synthesis with diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 7094‚Äì7104, 2023.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Yuyang Yin, Dejia Xu, Chuangchuang Tan, Ping Liu, Yao Zhao, and Yunchao Wei.

</span>
<span class="ltx_bibblock">Cle diffusion: Controllable light enhancement diffusion model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Proceedings of the 31st ACM International Conference on Multimedia</span>, pages 8145‚Äì8156, 2023.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Foivos¬†Paraperas Papantoniou, Alexandros Lattas, Stylianos Moschoglou, and Stefanos Zafeiriou.

</span>
<span class="ltx_bibblock">Relightify: Relightable 3d faces from a single image via diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 8806‚Äì8817, 2023.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Sascha Kirch, Valeria Olyunina, Jan Ond≈ôej, Rafael Pag√©s, Sergio Martin, and Clara P√©rez-Molina.

</span>
<span class="ltx_bibblock">Rgb-d-fusion: Image conditioned depth diffusion of humanoid subjects.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 2023.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Ye¬†Mao, Lan Jiang, Xi¬†Chen, and Chao Li.

</span>
<span class="ltx_bibblock">Disc-diff: Disentangled conditional diffusion model for multi-contrast mri super-resolution.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>, pages 387‚Äì397. Springer, 2023.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Zongyuan Yang, Baolin Liu, Yongping Xxiong, Lan Yi, Guibin Wu, Xiaojun Tang, Ziqi Liu, Junjie Zhou, and Xing Zhang.

</span>
<span class="ltx_bibblock">Docdiff: Document enhancement via residual diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">Proceedings of the 31st ACM International Conference on Multimedia</span>, pages 2795‚Äì2806, 2023.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Catherine Ordun, Edward Raff, and Sanjay Purushotham.

</span>
<span class="ltx_bibblock">When visible-to-thermal facial gan beats conditional diffusion.

</span>
<span class="ltx_bibblock">In <span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">2023 IEEE International Conference on Image Processing (ICIP)</span>, pages 181‚Äì185. IEEE, 2023.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Manuel Kansy, Anton Ra√´l, Graziana Mignone, Jacek Naruniec, Christopher Schroers, Markus Gross, and Romann¬†M Weber.

</span>
<span class="ltx_bibblock">Controllable inversion of black-box face recognition models via diffusion.

</span>
<span class="ltx_bibblock">In <span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 3167‚Äì3177, 2023.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Jiwen Yu, Yinhuai Wang, Chen Zhao, Bernard Ghanem, and Jian Zhang.

</span>
<span class="ltx_bibblock">Freedom: Training-free energy-guided conditional diffusion model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 23174‚Äì23184, 2023.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Florentin Bieder, Julia Wolleb, Alicia Durrer, Robin Sandk√ºhler, and Philippe¬†C Cattin.

</span>
<span class="ltx_bibblock">Diffusion models for memory-efficient processing of 3d medical images.

</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.15288</span>, 2023.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Kazerouni Amirhossein, Aghdam¬†Ehsan Khodapanah, Heidari Moein, Azad Reza, Fayyaz Mohsen, Hacihaliloglu Ilker, and Merhof Dorit.

</span>
<span class="ltx_bibblock">Diffusion models for medical image analysis: a comprehensive survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv</span>, 2211, 2022.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Tao Chen, Chenhui Wang, and Hongming Shan.

</span>
<span class="ltx_bibblock">Berdiff: Conditional bernoulli diffusion model for medical image segmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>, pages 491‚Äì501. Springer, 2023.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Aman Shrivastava and P¬†Thomas Fletcher.

</span>
<span class="ltx_bibblock">Nasdm: nuclei-aware semantic histopathology image generation using diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>, pages 786‚Äì796. Springer, 2023.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Xin Wang, Zhenrong Shen, Zhiyun Song, Sheng Wang, Mengjun Liu, Lichi Zhang, Kai Xuan, and Qian Wang.

</span>
<span class="ltx_bibblock">Arbitrary reduction of mri inter-slice spacing using hierarchical feature conditional diffusion.

</span>
<span class="ltx_bibblock">In <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">International Workshop on Machine Learning in Medical Imaging</span>, pages 23‚Äì32. Springer, 2023.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Huayu Li, Gregory Ditzler, Janet Roveda, and Ao¬†Li.

</span>
<span class="ltx_bibblock">Descod-ecg: Deep score-based diffusion model for ecg baseline wander and noise removal.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">IEEE Journal of Biomedical and Health Informatics</span>, 2023.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Marc¬†Anton Finzi, Anudhyan Boral, Andrew¬†Gordon Wilson, Fei Sha, and Leonardo Zepeda-N√∫√±ez.

</span>
<span class="ltx_bibblock">User-defined event sampling and uncertainty quantification in diffusion models for physical dynamical systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages 10136‚Äì10152. PMLR, 2023.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Xiaoyan Yang, Wei Li, and Ming Zhang.

</span>
<span class="ltx_bibblock">Directional diffusion models for chaotic dynamical systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">Chaos: An Interdisciplinary Journal of Nonlinear Science</span>, 2024.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Jie Li, Rui Zhang, and Hui Wang.

</span>
<span class="ltx_bibblock">Comparison of manifold learning techniques for conformational modeling.

</span>
<span class="ltx_bibblock"><span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">Journal of Computational Biology</span>, 2023.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Alexander¬†C Li, Mihir Prabhudesai, Shivam Duggal, Ellis Brown, and Deepak Pathak.

</span>
<span class="ltx_bibblock">Your diffusion model is secretly a zero-shot classifier.

</span>
<span class="ltx_bibblock">In <span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 2206‚Äì2217, 2023.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Yan Zhuang, Benjamin Hou, Tejas¬†Sudharshan Mathai, Pritam Mukherjee, Boah Kim, and Ronald¬†M Summers.

</span>
<span class="ltx_bibblock">Semantic image synthesis for abdominal ct.

</span>
<span class="ltx_bibblock">In <span id="bib.bib73.1.1" class="ltx_text ltx_font_italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>, pages 214‚Äì224. Springer, 2023.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Wan Jiang, Yunfeng Diao, He¬†Wang, Jianxin Sun, Meng Wang, and Richang Hong.

</span>
<span class="ltx_bibblock">Unlearnable examples give a false sense of security: Piercing through unexploitable data with learnable examples.

</span>
<span class="ltx_bibblock">In <span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">Proceedings of the 31st ACM International Conference on Multimedia</span>, pages 8910‚Äì8921, 2023.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Xijun Wang, Santiago L√≥pez-Tapia, and Aggelos¬†K Katsaggelos.

</span>
<span class="ltx_bibblock">Atmospheric turbulence correction via variational deep diffusion.

</span>
<span class="ltx_bibblock">In <span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">2023 IEEE 6th International Conference on Multimedia Information Processing and Retrieval (MIPR)</span>, pages 1‚Äì4. IEEE, 2023.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Sam Sartor and Pieter Peers.

</span>
<span class="ltx_bibblock">Matfusion: a generative diffusion model for svbrdf capture.

</span>
<span class="ltx_bibblock">In <span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">SIGGRAPH Asia 2023 Conference Papers</span>, pages 1‚Äì10, 2023.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Yao Wei, George Vosselman, and Michael¬†Ying Yang.

</span>
<span class="ltx_bibblock">Buildiff: 3d building shape generation using single-image conditional point cloud diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</span>, pages 2910‚Äì2919, 2023.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Axi Niu, Trung¬†X Pham, Kang Zhang, Jinqiu Sun, Yu¬†Zhu, Qingsen Yan, In¬†So Kweon, and Yanning Zhang.

</span>
<span class="ltx_bibblock">Acdmsr: Accelerated conditional diffusion models for single image super-resolution.

</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Broadcasting</span>, 2024.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Ruichen Sun, Kun Dong, and Jianfeng Zhao.

</span>
<span class="ltx_bibblock">Diffnilm: a novel framework for non-intrusive load monitoring based on the conditional diffusion model.

</span>
<span class="ltx_bibblock"><span id="bib.bib79.1.1" class="ltx_text ltx_font_italic">Sensors</span>, 23(7):3540, 2023.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Dongchao Yang, Songxiang Liu, Jianwei Yu, Helin Wang, Chao Weng, and Yuexian Zou.

</span>
<span class="ltx_bibblock">Norespeech: Knowledge distillation based conditional diffusion model for noise-robust expressive tts.

</span>
<span class="ltx_bibblock"><span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.02448</span>, 2022.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Xinyi Yu, Guanbin Li, Wei Lou, Siqi Liu, Xiang Wan, Yan Chen, and Haofeng Li.

</span>
<span class="ltx_bibblock">Diffusion-based data augmentation for nuclei image segmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>, pages 592‚Äì602. Springer, 2023.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Ruipeng Ma, Jinhao Duan, Fei Kong, Xiaoshuang Shi, and Kaidi Xu.

</span>
<span class="ltx_bibblock">Exposing the fake: Effective diffusion-generated images detection.

</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.06272</span>, 2023.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Zhengyue Zhao, Jinhao Duan, Xing Hu, Kaidi Xu, Chenan Wang, Rui Zhang, Zidong Du, Qi¬†Guo, and Yunji Chen.

</span>
<span class="ltx_bibblock">Unlearnable examples for diffusion models: Protect data from unauthorized exploitation.

</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.01902</span>, 2023.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Kangfu Mei and Vishal Patel.

</span>
<span class="ltx_bibblock">Vidm: Video implicit diffusion models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</span>, volume¬†37, pages 9117‚Äì9125, 2023.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
John Mao, Jane Liu, and Wei Zhang.

</span>
<span class="ltx_bibblock">Sketchfusion: A model for sketch-guided image editing using a conditional diffusion model.

</span>
<span class="ltx_bibblock"><span id="bib.bib85.1.1" class="ltx_text ltx_font_italic">Journal of Graphics and Image Processing</span>, 12(4):123‚Äì134, 2023.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Hong Wang, Yuexiang Li, Nanjun He, Kai Ma, Deyu Meng, and Yefeng Zheng.

</span>
<span class="ltx_bibblock">Dicdnet: deep interpretable convolutional dictionary network for metal artifact reduction in ct images.

</span>
<span class="ltx_bibblock"><span id="bib.bib86.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Medical Imaging</span>, 41(4):869‚Äì880, 2021.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Nicole Maass, Andreas Maier, and Tobias Wuerfl.

</span>
<span class="ltx_bibblock">Reducing image artifacts, 2018.

</span>
<span class="ltx_bibblock">United States Patent Application 20180192985.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Irene Filoscia, Thomas Alderighi, Daniela Giorgi, Luigi Malomo, Marco Callieri, and Paolo Cignoni.

</span>
<span class="ltx_bibblock">Optimizing object decomposition to reduce visual artifacts in 3d printing.

</span>
<span class="ltx_bibblock">In <span id="bib.bib88.1.1" class="ltx_text ltx_font_italic">Computer Graphics Forum</span>, volume¬†39, pages 423‚Äì434. Wiley Online Library, 2020.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Song Han, Huizi Mao, and William¬†J Dally.

</span>
<span class="ltx_bibblock">Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding.

</span>
<span class="ltx_bibblock"><span id="bib.bib89.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1510.00149</span>, 2015.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Benoit Jacob, Skirmantas Kligys, Bo¬†Chen, Menglong Zhu, Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko.

</span>
<span class="ltx_bibblock">Quantization and training of neural networks for efficient integer-arithmetic-only inference.

</span>
<span class="ltx_bibblock"><span id="bib.bib90.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1712.05877</span>, 2018.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Hongmin Shin, Hanul Park, Ki¬†Yun Cho, and Seong¬†Kyu Kim.

</span>
<span class="ltx_bibblock">Medical image synthesis for data augmentation and anonymization using generative adversarial networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib91.1.1" class="ltx_text ltx_font_italic">Proceedings of the Medical Imaging Technology Conference</span>, 2018.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Mu¬†Yan, Ying Liu, and Youngjune Park.

</span>
<span class="ltx_bibblock">Radia: Protecting patient privacy in radiology reports.

</span>
<span class="ltx_bibblock"><span id="bib.bib92.1.1" class="ltx_text ltx_font_italic">IEEE Journal of Biomedical and Health Informatics</span>, 2021.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
et¬†al. Yu.

</span>
<span class="ltx_bibblock">Transfer learning in medical imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib93.1.1" class="ltx_text ltx_font_italic">Journal of Biomedical Engineering</span>, 2022.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
et¬†al. Chen.

</span>
<span class="ltx_bibblock">Incorporating domain-specific knowledge in diffusion models for medical imaging.

</span>
<span class="ltx_bibblock"><span id="bib.bib94.1.1" class="ltx_text ltx_font_italic">Journal of Medical Imaging and Diagnostics</span>, 2023.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
John¬†W. Goodell and Cyril Goutte.

</span>
<span class="ltx_bibblock">Toward ai and data analytics for financial inclusion: A review.

</span>
<span class="ltx_bibblock"><span id="bib.bib95.1.1" class="ltx_text ltx_font_italic">Journal of Financial Stability</span>, 2021.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Nitesh¬†V Chawla, Kevin¬†W Bowyer, Lawrence¬†O Hall, and W¬†Philip Kegelmeyer.

</span>
<span class="ltx_bibblock">Smote: synthetic minority over-sampling technique.

</span>
<span class="ltx_bibblock"><span id="bib.bib96.1.1" class="ltx_text ltx_font_italic">Journal of artificial intelligence research</span>, 16:321‚Äì357, 2002.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Yuchen Wang, Xiaoguang Li, Li¬†Yang, Jianfeng Ma, and Hui Li.

</span>
<span class="ltx_bibblock">Addition: Detecting adversarial examples with image-dependent noise reduction.

</span>
<span class="ltx_bibblock"><span id="bib.bib97.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Dependable and Secure Computing</span>, 2023.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Joy Buolamwini and Timnit Gebru.

</span>
<span class="ltx_bibblock">Gender shades: Intersectional accuracy disparities in commercial gender classification.

</span>
<span class="ltx_bibblock">In <span id="bib.bib98.1.1" class="ltx_text ltx_font_italic">Conference on fairness, accountability and transparency</span>, pages 77‚Äì91. PMLR, 2018.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
Marco¬†Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.

</span>
<span class="ltx_bibblock">"why should i trust you?": Explaining the predictions of any classifier.

</span>
<span class="ltx_bibblock"><span id="bib.bib99.1.1" class="ltx_text ltx_font_italic">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</span>, 2016.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Aaron Roth, et¬†al.

</span>
<span class="ltx_bibblock">The algorithmic foundations of differential privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bib100.1.1" class="ltx_text ltx_font_italic">Foundations and Trends¬Æ in Theoretical Computer Science</span>, 9(3‚Äì4):211‚Äì407, 2014.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Floridi et¬†al.

</span>
<span class="ltx_bibblock">Ai4people‚Äîan ethical framework for a good ai society: Opportunities, risks, principles, and recommendations.

</span>
<span class="ltx_bibblock"><span id="bib.bib101.1.1" class="ltx_text ltx_font_italic">Minds and Machines</span>, 2018.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.10206" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.10207" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.10207">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.10207" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.10208" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 16:23:59 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
