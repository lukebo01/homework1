<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.11519] MSNER: A Multilingual Speech Dataset for Named Entity Recognition</title><meta property="og:description" content="While extensively explored in text-based tasks, Named Entity Recognition (NER) remains largely neglected in spoken language understanding. Existing resources are limited to a single, English-only dataset. This paper ad…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MSNER: A Multilingual Speech Dataset for Named Entity Recognition">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MSNER: A Multilingual Speech Dataset for Named Entity Recognition">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.11519">

<!--Generated on Wed Jun  5 18:41:57 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">MSNER: A Multilingual Speech Dataset for Named Entity Recognition</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">While extensively explored in text-based tasks, Named Entity Recognition (NER) remains largely neglected in spoken language understanding. Existing resources are limited to a single, English-only dataset. This paper addresses this gap by introducing MSNER, a freely available, multilingual speech corpus annotated with named entities. It provides annotations to the VoxPopuli dataset in four languages (Dutch, French, German, and Spanish). We have also releasing an efficient annotation tool that leverages automatic pre-annotations for faster manual refinement. This results in 590 and 15 hours of silver-annotated speech for training and validation, alongside a 17-hour, manually-annotated evaluation set. We further provide an analysis comparing silver and gold annotations. Finally, we present baseline NER models to stimulate further research on this newly available dataset.
<br class="ltx_break">
<br class="ltx_break">
<span id="id7.id1.1" class="ltx_text ltx_font_bold">Keywords: </span>Spoken Named Entity Recognition, Spoken Language Understanding, Speech Dataset</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\NAT@set@cites</span>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p"><span id="p2.1.1" class="ltx_text"></span></p>
</div>
<div id="id6" class="ltx_logical-block">
<div id="id6.p1" class="ltx_para">
<p id="id6.p1.1" class="ltx_p ltx_align_center"><span id="id6.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">MSNER: A Multilingual Speech Dataset for Named Entity Recognition</span></p>
<br class="ltx_break ltx_centering">
<table id="id5.5" class="ltx_tabular ltx_centering ltx_align_top">
<tbody class="ltx_tbody">
<tr id="id3.3.3" class="ltx_tr">
<td id="id3.3.3.3" class="ltx_td ltx_align_center"><span id="id3.3.3.3.3" class="ltx_text ltx_font_bold" style="font-size:120%;">Quentin Meeus<sup id="id3.3.3.3.3.1" class="ltx_sup"><span id="id3.3.3.3.3.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,2</span></sup>, Marie-Francine Moens<sup id="id3.3.3.3.3.2" class="ltx_sup"><span id="id3.3.3.3.3.2.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup>, Hugo Van hamme<sup id="id3.3.3.3.3.3" class="ltx_sup"><span id="id3.3.3.3.3.3.1" class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup></span></td>
</tr>
<tr id="id5.5.6.1" class="ltx_tr">
<td id="id5.5.6.1.1" class="ltx_td ltx_align_center">
20th Joint ACL-ISO Workshop on Interoperable Semantic Annotation</td>
</tr>
<tr id="id5.5.5" class="ltx_tr">
<td id="id5.5.5.2" class="ltx_td ltx_align_center">
<sup id="id5.5.5.2.1" class="ltx_sup"><span id="id5.5.5.2.1.1" class="ltx_text ltx_font_italic">1</span></sup> LIIR Lab, Computer Science Dpt., KU Leuven  <sup id="id5.5.5.2.2" class="ltx_sup"><span id="id5.5.5.2.2.1" class="ltx_text ltx_font_italic">2</span></sup> PSI, Electrical Engineering Dpt., KU Leuven</td>
</tr>
<tr id="id5.5.7.2" class="ltx_tr">
<td id="id5.5.7.2.1" class="ltx_td ltx_align_center">Quentin.Meeus@kuleuven.be</td>
</tr>
</tbody>
</table>
<p id="id6.p1.2" class="ltx_p ltx_align_center"><span id="id6.p1.2.1" class="ltx_text ltx_font_italic">Abstract content</span></p>
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">1.   Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">In an increasingly interconnected world where language knows no boundaries, the field of Speech Processing is undergoing a transformative shift towards multilingual applications. One such pivotal area is Spoken Named Entity Recognition (Spoken NER). Named Entity Recognition (NER) is a natural language processing (NLP) task that involves the identification and categorization of named entities within a text, typically into predefined categories such as names of persons, organizations, locations, dates, numerical values, and more. The primary objective of NER is to automatically recognize and extract specific pieces of information from unstructured text, making it easier to analyze and understand the content. NER plays a crucial role in various NLP applications, including information retrieval, question answering, sentiment analysis, and language understanding. In contrast, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">Spoken NER</span> extracts named entities from audio documents, a task that is considerably more challenging. Indeed, aside from the inherent difficulties associated with speech processing, Spoken NER requires not only to identify and classify the entities, but also to transcribe them correctly. Variability in pronunciation, accents, and dialects can make the detection and especially the spelling of named entities very challenging. On the other hand, prosody, intonation and emphasis are cues that may be crucial for NER but are not readily available in written text. Recognizing the pressing need to facilitate cross-lingual research and to provide comprehensive evaluation resources for Spoken NER models, we have undertaken the task of manually annotating the popular speech dataset VoxPopuli’s test sets in four languages: Dutch, French, German, and Spanish. Additionally, we also provide machine-made annotations on the training and validation sets.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">In the following sections, we provide a detailed overview of our efforts in the domain of Spoken NER. First, we give an overview of related works and datasets. Then, we introduce the newly annotated dataset and provide information about its size, multilingual coverage, and its potential significance in advancing Spoken NER technology. Additionally, we describe the methodology employed in the dataset’s creation, breaking down the annotation process and data preparation. We also introduce the user-friendly annotation interface we’ve developed for this purpose. Furthermore, we present the results of various experiments and benchmarks conducted using this dataset. These experiments demonstrate its utility in evaluating Spoken NER models across the chosen languages, highlighting its role in advancing research and development in this field.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">In summary, this article describes our contributions to the field of multilingual Spoken NER, including the dataset’s creation, annotation methodology, and its role in advancing research in this domain.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">2.   Literature Review</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">In the field of NLP, there is not one unified label set. Both generic and specialized datasets exist with their own label sets defined. Specialized datasets might cover large amounts of topics with specific vocabulary and entities. For example, a NER system for doctors would include medications, dosages, medical reasons, etc. <cite class="ltx_cite ltx_citemacro_cite">Uzuner et al. (<a href="#bib.bib20" title="" class="ltx_ref">2010</a>)</cite>, and biomedical entities include names of proteins, chemical, disease, or species <cite class="ltx_cite ltx_citemacro_cite">Crichton et al. (<a href="#bib.bib4" title="" class="ltx_ref">2017</a>)</cite>. Other datasets provide more generic entities that cover broader landscapes. One of the most widely used is CoNLL-2003 <cite class="ltx_cite ltx_citemacro_cite">Tjong Kim Sang and De Meulder (<a href="#bib.bib18" title="" class="ltx_ref">2003</a>)</cite>, although it comes with only four entity types (LOC, ORG, PER and MISC). OntoNotes v5 enriches this set with 14 more classes (Table <a href="#S2.T2" title="Table 2 ‣ 2. Literature Review ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), to include things such as numbers, dates, and laws. Its high quality makes it one of the most widely used NER datasets, although it only covers three languages: English, Arabic and Chinese. Another notable mention is <cite class="ltx_cite ltx_citemacro_citet">Tedeschi et al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>, which adds a few more generic classes to OntoNotes definitions to cover things such as animal names, diseases, food, and plants, and released a dataset derived from Wikipedia where named entities were annotated automatically with an annotation pipeline that effectively combined pretrained language models and knowledge-based approaches. A follow-up dataset was published covering more languages <cite class="ltx_cite ltx_citemacro_cite">Tedeschi and Navigli (<a href="#bib.bib17" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">Currently, we know of only one Spoken NER dataset that is openly distributed as SLUE <cite class="ltx_cite ltx_citemacro_cite">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>. This is an annotated subset of the larger VoxPopuli dataset <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite>, which comprises audio recordings and corresponding transcripts of sessions held in the European Parliament. The annotated portion of the dataset include approximately 25 hours of speech, divided into three subsets: 3/5 for training, 1/5 for validation, and 1/5 for testing purposes. While this initiative is a significant step forward, SLUE exclusively covers the English language. They used the same entities as OntoNotes <cite class="ltx_cite ltx_citemacro_citep">(Weischedel et al., <a href="#biba.bib1" title="" class="ltx_ref">2013</a>)</cite> although in practice, they combine some types and remove rare ones to produce a new label set (Table <a href="#S2.T2" title="Table 2 ‣ 2. Literature Review ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, Column 2).</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">Another task in spoken language understanding is similar to Spoken NER: slot filling. This is the identification of information relevant to specific applications, such as flight booking <cite class="ltx_cite ltx_citemacro_cite">Hemphill et al. (<a href="#bib.bib5" title="" class="ltx_ref">1990</a>)</cite>. Although they share many grounds, there is a major difference: slot filling relates to a specific application, and in this regard, covers a much narrower domain than NER, often consisting of short commands for a computer interface <cite class="ltx_cite ltx_citemacro_citep">(Lugosch et al., <a href="#bib.bib8" title="" class="ltx_ref">2019</a>; Saade et al., <a href="#bib.bib14" title="" class="ltx_ref">2018</a>; Bastianelli et al., <a href="#bib.bib1" title="" class="ltx_ref">2020</a>; Lugosch et al., <a href="#bib.bib7" title="" class="ltx_ref">2021</a>; Renkens and Van hamme, <a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite> or a booking system <cite class="ltx_cite ltx_citemacro_citep">(Hemphill et al., <a href="#bib.bib5" title="" class="ltx_ref">1990</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p">Since the vast majority of entity recognition datasets are text-based, the same goes for the applications. Consequently, NER is often framed as a token classification task, where each word or word piece must be assigned an entity type. Since an entity can cover many tokens, the entity classes are redefined in the BIO format, a widely used tagging scheme in NER tasks <cite class="ltx_cite ltx_citemacro_cite">Ramshaw and Marcus (<a href="#bib.bib12" title="" class="ltx_ref">1995</a>)</cite>. This format provides a structured way to label and distinguish the boundaries of named entities within the text. Each word or token is tagged with one of three labels: “B” marks the beginning, or first word of an entity, “I” indicates the continuation of the named entity and always follows the “B” tag, and “O” is used for words that are not part of an entity. This marker, together with the entity type, makes the target for the classification task. Other annotation schemes are extensions of this (e.g. IO, IOBES, IOE, etc.). The major drawback of the BIO format is its inability to represent nested entities.</p>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.1" class="ltx_p">The modern approach to NER is to add linear layers to a pretrained language model and fine-tune it on the chosen NER dataset. Sometimes, a conditional random field (CRF) <cite class="ltx_cite ltx_citemacro_cite">Lafferty et al. (<a href="#bib.bib6" title="" class="ltx_ref">2001</a>)</cite> is added to learn the transition probabilities between the label classes <cite class="ltx_cite ltx_citemacro_cite">Ushio and Camacho-Collados (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>. In Spoken NER, the two main approaches are pipeline and end-to-end models. As the name suggests, pipeline models first use automatic speech recognition to transcribe an audio recording, then use NER to predict the entities. In contrast, end-to-end models do not force the model to make hard decisions by choosing one token over another. Instead, it predicts entities directly from the hidden states. Finally, hybrid models or multitask models predict both the entities and the transcriptions simultaneously <cite class="ltx_cite ltx_citemacro_cite">Meeus et al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.2.1.1" class="ltx_tr">
<th id="S2.T1.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.2.1.1.1.1" class="ltx_text" style="font-size:90%;">subset</span></th>
<th id="S2.T1.2.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.2.1.1.2.1" class="ltx_text" style="font-size:90%;">language</span></th>
<th id="S2.T1.2.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.2.1.1.3.1" class="ltx_text" style="font-size:90%;">duration</span></th>
<th id="S2.T1.2.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.2.1.1.4.1" class="ltx_text" style="font-size:90%;">size</span></th>
<th id="S2.T1.2.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.2.1.1.5.1" class="ltx_text" style="font-size:90%;">entities</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.2.2.1" class="ltx_tr">
<td id="S2.T1.2.2.1.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S2.T1.2.2.1.1.1" class="ltx_text" style="font-size:90%;">train</span></td>
<td id="S2.T1.2.2.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.2.1.2.1" class="ltx_text" style="font-size:90%;">DE</span></td>
<td id="S2.T1.2.2.1.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.2.1.3.1" class="ltx_text" style="font-size:90%;">224.5 h</span></td>
<td id="S2.T1.2.2.1.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.2.1.4.1" class="ltx_text" style="font-size:90%;">86,410</span></td>
<td id="S2.T1.2.2.1.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.2.1.5.1" class="ltx_text" style="font-size:90%;">97,492</span></td>
</tr>
<tr id="S2.T1.2.3.2" class="ltx_tr">
<td id="S2.T1.2.3.2.1" class="ltx_td ltx_align_left"><span id="S2.T1.2.3.2.1.1" class="ltx_text" style="font-size:90%;">ES</span></td>
<td id="S2.T1.2.3.2.2" class="ltx_td ltx_align_left"><span id="S2.T1.2.3.2.2.1" class="ltx_text" style="font-size:90%;">141.5 h</span></td>
<td id="S2.T1.2.3.2.3" class="ltx_td ltx_align_left"><span id="S2.T1.2.3.2.3.1" class="ltx_text" style="font-size:90%;">47,611</span></td>
<td id="S2.T1.2.3.2.4" class="ltx_td ltx_align_left"><span id="S2.T1.2.3.2.4.1" class="ltx_text" style="font-size:90%;">66,482</span></td>
</tr>
<tr id="S2.T1.2.4.3" class="ltx_tr">
<td id="S2.T1.2.4.3.1" class="ltx_td ltx_align_left"><span id="S2.T1.2.4.3.1.1" class="ltx_text" style="font-size:90%;">FR</span></td>
<td id="S2.T1.2.4.3.2" class="ltx_td ltx_align_left"><span id="S2.T1.2.4.3.2.1" class="ltx_text" style="font-size:90%;">186h</span></td>
<td id="S2.T1.2.4.3.3" class="ltx_td ltx_align_left"><span id="S2.T1.2.4.3.3.1" class="ltx_text" style="font-size:90%;">65,952</span></td>
<td id="S2.T1.2.4.3.4" class="ltx_td ltx_align_left"><span id="S2.T1.2.4.3.4.1" class="ltx_text" style="font-size:90%;">80,255</span></td>
</tr>
<tr id="S2.T1.2.5.4" class="ltx_tr">
<td id="S2.T1.2.5.4.1" class="ltx_td ltx_align_left"><span id="S2.T1.2.5.4.1.1" class="ltx_text" style="font-size:90%;">NL</span></td>
<td id="S2.T1.2.5.4.2" class="ltx_td ltx_align_left"><span id="S2.T1.2.5.4.2.1" class="ltx_text" style="font-size:90%;">38.5 h</span></td>
<td id="S2.T1.2.5.4.3" class="ltx_td ltx_align_left"><span id="S2.T1.2.5.4.3.1" class="ltx_text" style="font-size:90%;">16,533</span></td>
<td id="S2.T1.2.5.4.4" class="ltx_td ltx_align_left"><span id="S2.T1.2.5.4.4.1" class="ltx_text" style="font-size:90%;">19,566</span></td>
</tr>
<tr id="S2.T1.2.6.5" class="ltx_tr">
<td id="S2.T1.2.6.5.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="4"><span id="S2.T1.2.6.5.1.1" class="ltx_text" style="font-size:90%;">dev</span></td>
<td id="S2.T1.2.6.5.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.6.5.2.1" class="ltx_text" style="font-size:90%;">DE</span></td>
<td id="S2.T1.2.6.5.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.6.5.3.1" class="ltx_text" style="font-size:90%;">4h</span></td>
<td id="S2.T1.2.6.5.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.6.5.4.1" class="ltx_text" style="font-size:90%;">1,610</span></td>
<td id="S2.T1.2.6.5.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.6.5.5.1" class="ltx_text" style="font-size:90%;">1,880</span></td>
</tr>
<tr id="S2.T1.2.7.6" class="ltx_tr">
<td id="S2.T1.2.7.6.1" class="ltx_td ltx_align_left"><span id="S2.T1.2.7.6.1.1" class="ltx_text" style="font-size:90%;">ES</span></td>
<td id="S2.T1.2.7.6.2" class="ltx_td ltx_align_left"><span id="S2.T1.2.7.6.2.1" class="ltx_text" style="font-size:90%;">4h48</span></td>
<td id="S2.T1.2.7.6.3" class="ltx_td ltx_align_left"><span id="S2.T1.2.7.6.3.1" class="ltx_text" style="font-size:90%;">1,529</span></td>
<td id="S2.T1.2.7.6.4" class="ltx_td ltx_align_left"><span id="S2.T1.2.7.6.4.1" class="ltx_text" style="font-size:90%;">2,094</span></td>
</tr>
<tr id="S2.T1.2.8.7" class="ltx_tr">
<td id="S2.T1.2.8.7.1" class="ltx_td ltx_align_left"><span id="S2.T1.2.8.7.1.1" class="ltx_text" style="font-size:90%;">FR</span></td>
<td id="S2.T1.2.8.7.2" class="ltx_td ltx_align_left"><span id="S2.T1.2.8.7.2.1" class="ltx_text" style="font-size:90%;">4h22</span></td>
<td id="S2.T1.2.8.7.3" class="ltx_td ltx_align_left"><span id="S2.T1.2.8.7.3.1" class="ltx_text" style="font-size:90%;">1,527</span></td>
<td id="S2.T1.2.8.7.4" class="ltx_td ltx_align_left"><span id="S2.T1.2.8.7.4.1" class="ltx_text" style="font-size:90%;">1,884</span></td>
</tr>
<tr id="S2.T1.2.9.8" class="ltx_tr">
<td id="S2.T1.2.9.8.1" class="ltx_td ltx_align_left"><span id="S2.T1.2.9.8.1.1" class="ltx_text" style="font-size:90%;">NL</span></td>
<td id="S2.T1.2.9.8.2" class="ltx_td ltx_align_left"><span id="S2.T1.2.9.8.2.1" class="ltx_text" style="font-size:90%;">2h16</span></td>
<td id="S2.T1.2.9.8.3" class="ltx_td ltx_align_left"><span id="S2.T1.2.9.8.3.1" class="ltx_text" style="font-size:90%;">963</span></td>
<td id="S2.T1.2.9.8.4" class="ltx_td ltx_align_left"><span id="S2.T1.2.9.8.4.1" class="ltx_text" style="font-size:90%;">1,074</span></td>
</tr>
<tr id="S2.T1.2.10.9" class="ltx_tr">
<td id="S2.T1.2.10.9.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="4"><span id="S2.T1.2.10.9.1.1" class="ltx_text" style="font-size:90%;">test</span></td>
<td id="S2.T1.2.10.9.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.10.9.2.1" class="ltx_text" style="font-size:90%;">DE</span></td>
<td id="S2.T1.2.10.9.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.10.9.3.1" class="ltx_text" style="font-size:90%;">5h</span></td>
<td id="S2.T1.2.10.9.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.10.9.4.1" class="ltx_text" style="font-size:90%;">1,966</span></td>
<td id="S2.T1.2.10.9.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.2.10.9.5.1" class="ltx_text" style="font-size:90%;">2,061</span></td>
</tr>
<tr id="S2.T1.2.11.10" class="ltx_tr">
<td id="S2.T1.2.11.10.1" class="ltx_td ltx_align_left"><span id="S2.T1.2.11.10.1.1" class="ltx_text" style="font-size:90%;">ES</span></td>
<td id="S2.T1.2.11.10.2" class="ltx_td ltx_align_left"><span id="S2.T1.2.11.10.2.1" class="ltx_text" style="font-size:90%;">5h</span></td>
<td id="S2.T1.2.11.10.3" class="ltx_td ltx_align_left"><span id="S2.T1.2.11.10.3.1" class="ltx_text" style="font-size:90%;">1,512</span></td>
<td id="S2.T1.2.11.10.4" class="ltx_td ltx_align_left"><span id="S2.T1.2.11.10.4.1" class="ltx_text" style="font-size:90%;">2,198</span></td>
</tr>
<tr id="S2.T1.2.12.11" class="ltx_tr">
<td id="S2.T1.2.12.11.1" class="ltx_td ltx_align_left"><span id="S2.T1.2.12.11.1.1" class="ltx_text" style="font-size:90%;">FR</span></td>
<td id="S2.T1.2.12.11.2" class="ltx_td ltx_align_left"><span id="S2.T1.2.12.11.2.1" class="ltx_text" style="font-size:90%;">4h30</span></td>
<td id="S2.T1.2.12.11.3" class="ltx_td ltx_align_left"><span id="S2.T1.2.12.11.3.1" class="ltx_text" style="font-size:90%;">1,656</span></td>
<td id="S2.T1.2.12.11.4" class="ltx_td ltx_align_left"><span id="S2.T1.2.12.11.4.1" class="ltx_text" style="font-size:90%;">2,004</span></td>
</tr>
<tr id="S2.T1.2.13.12" class="ltx_tr">
<td id="S2.T1.2.13.12.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T1.2.13.12.1.1" class="ltx_text" style="font-size:90%;">NL</span></td>
<td id="S2.T1.2.13.12.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T1.2.13.12.2.1" class="ltx_text" style="font-size:90%;">2h30</span></td>
<td id="S2.T1.2.13.12.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T1.2.13.12.3.1" class="ltx_text" style="font-size:90%;">1,120</span></td>
<td id="S2.T1.2.13.12.4" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T1.2.13.12.4.1" class="ltx_text" style="font-size:90%;">1,272</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>MSNER Dataset statistics</figcaption>
</figure>
<figure id="S2.T2" class="ltx_table">
<table id="S2.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T2.2.1.1" class="ltx_tr">
<td id="S2.T2.2.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T2.2.1.1.1.1" class="ltx_text" style="font-size:90%;">OntoNotes5</span></td>
<td id="S2.T2.2.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T2.2.1.1.2.1" class="ltx_text" style="font-size:90%;">SLUE</span></td>
<td id="S2.T2.2.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T2.2.1.1.3.1" class="ltx_text" style="font-size:90%;">DE</span></td>
<td id="S2.T2.2.1.1.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T2.2.1.1.4.1" class="ltx_text" style="font-size:90%;">ES</span></td>
<td id="S2.T2.2.1.1.5" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T2.2.1.1.5.1" class="ltx_text" style="font-size:90%;">FR</span></td>
<td id="S2.T2.2.1.1.6" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T2.2.1.1.6.1" class="ltx_text" style="font-size:90%;">NL</span></td>
<td id="S2.T2.2.1.1.7" class="ltx_td ltx_align_right ltx_border_tt"><span id="S2.T2.2.1.1.7.1" class="ltx_text" style="font-size:90%;">Examples</span></td>
</tr>
<tr id="S2.T2.2.2.2" class="ltx_tr">
<td id="S2.T2.2.2.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.2.2.1.1" class="ltx_text" style="font-size:90%;">date</span></td>
<td id="S2.T2.2.2.2.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S2.T2.2.2.2.2.1" class="ltx_text" style="font-size:90%;">WHEN</span></td>
<td id="S2.T2.2.2.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.2.2.3.1" class="ltx_text" style="font-size:90%;">307</span></td>
<td id="S2.T2.2.2.2.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.2.2.4.1" class="ltx_text" style="font-size:90%;">276</span></td>
<td id="S2.T2.2.2.2.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.2.2.5.1" class="ltx_text" style="font-size:90%;">243</span></td>
<td id="S2.T2.2.2.2.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.2.2.6.1" class="ltx_text" style="font-size:90%;">113</span></td>
<td id="S2.T2.2.2.2.7" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.2.2.7.1" class="ltx_text" style="font-size:90%;">125 years ago, 15 maart, 1815—1830, 1997</span></td>
</tr>
<tr id="S2.T2.2.3.3" class="ltx_tr">
<td id="S2.T2.2.3.3.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.3.3.1.1" class="ltx_text" style="font-size:90%;">time</span></td>
<td id="S2.T2.2.3.3.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.3.3.2.1" class="ltx_text" style="font-size:90%;">12</span></td>
<td id="S2.T2.2.3.3.3" class="ltx_td ltx_align_right"><span id="S2.T2.2.3.3.3.1" class="ltx_text" style="font-size:90%;">21</span></td>
<td id="S2.T2.2.3.3.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.3.3.4.1" class="ltx_text" style="font-size:90%;">10</span></td>
<td id="S2.T2.2.3.3.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.3.3.5.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S2.T2.2.3.3.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.3.3.6.1" class="ltx_text" style="font-size:90%;">24 hours, acht uur, de hele dag, mañana</span></td>
</tr>
<tr id="S2.T2.2.4.4" class="ltx_tr">
<td id="S2.T2.2.4.4.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.4.4.1.1" class="ltx_text" style="font-size:90%;">cardinal number</span></td>
<td id="S2.T2.2.4.4.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="5"><span id="S2.T2.2.4.4.2.1" class="ltx_text" style="font-size:90%;">QUANT</span></td>
<td id="S2.T2.2.4.4.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.4.4.3.1" class="ltx_text" style="font-size:90%;">136</span></td>
<td id="S2.T2.2.4.4.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.4.4.4.1" class="ltx_text" style="font-size:90%;">167</span></td>
<td id="S2.T2.2.4.4.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.4.4.5.1" class="ltx_text" style="font-size:90%;">123</span></td>
<td id="S2.T2.2.4.4.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.4.4.6.1" class="ltx_text" style="font-size:90%;">91</span></td>
<td id="S2.T2.2.4.4.7" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.4.4.7.1" class="ltx_text" style="font-size:90%;">1, 10, 10 miljoen, 11, 11 billion</span></td>
</tr>
<tr id="S2.T2.2.5.5" class="ltx_tr">
<td id="S2.T2.2.5.5.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.5.5.1.1" class="ltx_text" style="font-size:90%;">ordinal number</span></td>
<td id="S2.T2.2.5.5.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.5.5.2.1" class="ltx_text" style="font-size:90%;">82</span></td>
<td id="S2.T2.2.5.5.3" class="ltx_td ltx_align_right"><span id="S2.T2.2.5.5.3.1" class="ltx_text" style="font-size:90%;">100</span></td>
<td id="S2.T2.2.5.5.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.5.5.4.1" class="ltx_text" style="font-size:90%;">79</span></td>
<td id="S2.T2.2.5.5.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.5.5.5.1" class="ltx_text" style="font-size:90%;">45</span></td>
<td id="S2.T2.2.5.5.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.5.5.6.1" class="ltx_text" style="font-size:90%;">First, Ten derde, dritten</span></td>
</tr>
<tr id="S2.T2.2.6.6" class="ltx_tr">
<td id="S2.T2.2.6.6.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.6.6.1.1" class="ltx_text" style="font-size:90%;">quantity</span></td>
<td id="S2.T2.2.6.6.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.6.6.2.1" class="ltx_text" style="font-size:90%;">6</span></td>
<td id="S2.T2.2.6.6.3" class="ltx_td ltx_align_right"><span id="S2.T2.2.6.6.3.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="S2.T2.2.6.6.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.6.6.4.1" class="ltx_text" style="font-size:90%;">5</span></td>
<td id="S2.T2.2.6.6.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.6.6.5.1" class="ltx_text" style="font-size:90%;">1</span></td>
<td id="S2.T2.2.6.6.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.6.6.6.1" class="ltx_text" style="font-size:90%;">one and a half meter, two inches</span></td>
</tr>
<tr id="S2.T2.2.7.7" class="ltx_tr">
<td id="S2.T2.2.7.7.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.7.7.1.1" class="ltx_text" style="font-size:90%;">money</span></td>
<td id="S2.T2.2.7.7.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.7.7.2.1" class="ltx_text" style="font-size:90%;">26</span></td>
<td id="S2.T2.2.7.7.3" class="ltx_td ltx_align_right"><span id="S2.T2.2.7.7.3.1" class="ltx_text" style="font-size:90%;">16</span></td>
<td id="S2.T2.2.7.7.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.7.7.4.1" class="ltx_text" style="font-size:90%;">18</span></td>
<td id="S2.T2.2.7.7.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.7.7.5.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S2.T2.2.7.7.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.7.7.6.1" class="ltx_text" style="font-size:90%;">200 million EUR, Dertig miljoen euro</span></td>
</tr>
<tr id="S2.T2.2.8.8" class="ltx_tr">
<td id="S2.T2.2.8.8.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.8.8.1.1" class="ltx_text" style="font-size:90%;">percent</span></td>
<td id="S2.T2.2.8.8.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.8.8.2.1" class="ltx_text" style="font-size:90%;">21</span></td>
<td id="S2.T2.2.8.8.3" class="ltx_td ltx_align_right"><span id="S2.T2.2.8.8.3.1" class="ltx_text" style="font-size:90%;">28</span></td>
<td id="S2.T2.2.8.8.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.8.8.4.1" class="ltx_text" style="font-size:90%;">13</span></td>
<td id="S2.T2.2.8.8.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.8.8.5.1" class="ltx_text" style="font-size:90%;">22</span></td>
<td id="S2.T2.2.8.8.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.8.8.6.1" class="ltx_text" style="font-size:90%;">1 procent, 100%, 15 Prozent</span></td>
</tr>
<tr id="S2.T2.2.9.9" class="ltx_tr">
<td id="S2.T2.2.9.9.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.9.9.1.1" class="ltx_text" style="font-size:90%;">geopolitical area</span></td>
<td id="S2.T2.2.9.9.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S2.T2.2.9.9.2.1" class="ltx_text" style="font-size:90%;">PLACE</span></td>
<td id="S2.T2.2.9.9.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.9.9.3.1" class="ltx_text" style="font-size:90%;">259</span></td>
<td id="S2.T2.2.9.9.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.9.9.4.1" class="ltx_text" style="font-size:90%;">285</span></td>
<td id="S2.T2.2.9.9.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.9.9.5.1" class="ltx_text" style="font-size:90%;">283</span></td>
<td id="S2.T2.2.9.9.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.9.9.6.1" class="ltx_text" style="font-size:90%;">176</span></td>
<td id="S2.T2.2.9.9.7" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.9.9.7.1" class="ltx_text" style="font-size:90%;">Amsterdam, Australië, Barcelona, Belgium</span></td>
</tr>
<tr id="S2.T2.2.10.10" class="ltx_tr">
<td id="S2.T2.2.10.10.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.10.10.1.1" class="ltx_text" style="font-size:90%;">location</span></td>
<td id="S2.T2.2.10.10.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.10.10.2.1" class="ltx_text" style="font-size:90%;">128</span></td>
<td id="S2.T2.2.10.10.3" class="ltx_td ltx_align_right"><span id="S2.T2.2.10.10.3.1" class="ltx_text" style="font-size:90%;">139</span></td>
<td id="S2.T2.2.10.10.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.10.10.4.1" class="ltx_text" style="font-size:90%;">214</span></td>
<td id="S2.T2.2.10.10.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.10.10.5.1" class="ltx_text" style="font-size:90%;">110</span></td>
<td id="S2.T2.2.10.10.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.10.10.6.1" class="ltx_text" style="font-size:90%;">Afrika, Balkanlanden, Europe</span></td>
</tr>
<tr id="S2.T2.2.11.11" class="ltx_tr">
<td id="S2.T2.2.11.11.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.11.11.1.1" class="ltx_text" style="font-size:90%;">group</span></td>
<td id="S2.T2.2.11.11.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.11.11.2.1" class="ltx_text" style="font-size:90%;">NORP</span></td>
<td id="S2.T2.2.11.11.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.2.11.11.3.1" class="ltx_text" style="font-size:90%;">229</span></td>
<td id="S2.T2.2.11.11.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.11.11.4.1" class="ltx_text" style="font-size:90%;">244</span></td>
<td id="S2.T2.2.11.11.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.11.11.5.1" class="ltx_text" style="font-size:90%;">285</span></td>
<td id="S2.T2.2.11.11.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.11.11.6.1" class="ltx_text" style="font-size:90%;">213</span></td>
<td id="S2.T2.2.11.11.7" class="ltx_td ltx_align_right ltx_border_t"><span id="S2.T2.2.11.11.7.1" class="ltx_text" style="font-size:90%;">African, American, Christian</span></td>
</tr>
<tr id="S2.T2.2.12.12" class="ltx_tr">
<td id="S2.T2.2.12.12.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.12.12.1.1" class="ltx_text" style="font-size:90%;">organization</span></td>
<td id="S2.T2.2.12.12.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.12.12.2.1" class="ltx_text" style="font-size:90%;">ORG</span></td>
<td id="S2.T2.2.12.12.3" class="ltx_td ltx_align_left"><span id="S2.T2.2.12.12.3.1" class="ltx_text" style="font-size:90%;">621</span></td>
<td id="S2.T2.2.12.12.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.12.12.4.1" class="ltx_text" style="font-size:90%;">638</span></td>
<td id="S2.T2.2.12.12.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.12.12.5.1" class="ltx_text" style="font-size:90%;">527</span></td>
<td id="S2.T2.2.12.12.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.12.12.6.1" class="ltx_text" style="font-size:90%;">362</span></td>
<td id="S2.T2.2.12.12.7" class="ltx_td ltx_align_right"><span id="S2.T2.2.12.12.7.1" class="ltx_text" style="font-size:90%;">Amnesty International, Charlie Hebdo</span></td>
</tr>
<tr id="S2.T2.2.13.13" class="ltx_tr">
<td id="S2.T2.2.13.13.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.13.13.1.1" class="ltx_text" style="font-size:90%;">law</span></td>
<td id="S2.T2.2.13.13.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.13.13.2.1" class="ltx_text" style="font-size:90%;">LAW</span></td>
<td id="S2.T2.2.13.13.3" class="ltx_td ltx_align_left"><span id="S2.T2.2.13.13.3.1" class="ltx_text" style="font-size:90%;">64</span></td>
<td id="S2.T2.2.13.13.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.13.13.4.1" class="ltx_text" style="font-size:90%;">108</span></td>
<td id="S2.T2.2.13.13.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.13.13.5.1" class="ltx_text" style="font-size:90%;">33</span></td>
<td id="S2.T2.2.13.13.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.13.13.6.1" class="ltx_text" style="font-size:90%;">22</span></td>
<td id="S2.T2.2.13.13.7" class="ltx_td ltx_align_right"><span id="S2.T2.2.13.13.7.1" class="ltx_text" style="font-size:90%;">Paris Accords, US Constitution</span></td>
</tr>
<tr id="S2.T2.2.14.14" class="ltx_tr">
<td id="S2.T2.2.14.14.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.14.14.1.1" class="ltx_text" style="font-size:90%;">person</span></td>
<td id="S2.T2.2.14.14.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.14.14.2.1" class="ltx_text" style="font-size:90%;">PERSON</span></td>
<td id="S2.T2.2.14.14.3" class="ltx_td ltx_align_left"><span id="S2.T2.2.14.14.3.1" class="ltx_text" style="font-size:90%;">123</span></td>
<td id="S2.T2.2.14.14.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.14.14.4.1" class="ltx_text" style="font-size:90%;">131</span></td>
<td id="S2.T2.2.14.14.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.14.14.5.1" class="ltx_text" style="font-size:90%;">100</span></td>
<td id="S2.T2.2.14.14.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.14.14.6.1" class="ltx_text" style="font-size:90%;">67</span></td>
<td id="S2.T2.2.14.14.7" class="ltx_td ltx_align_right"><span id="S2.T2.2.14.14.7.1" class="ltx_text" style="font-size:90%;">Angela Merkel, Barroso, Beyoncé</span></td>
</tr>
<tr id="S2.T2.2.15.15" class="ltx_tr">
<td id="S2.T2.2.15.15.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.15.15.1.1" class="ltx_text" style="font-size:90%;">facility</span></td>
<td id="S2.T2.2.15.15.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.15.15.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S2.T2.2.15.15.3" class="ltx_td ltx_align_left"><span id="S2.T2.2.15.15.3.1" class="ltx_text" style="font-size:90%;">6</span></td>
<td id="S2.T2.2.15.15.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.15.15.4.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="S2.T2.2.15.15.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.15.15.5.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S2.T2.2.15.15.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.15.15.6.1" class="ltx_text" style="font-size:90%;">12</span></td>
<td id="S2.T2.2.15.15.7" class="ltx_td ltx_align_right"><span id="S2.T2.2.15.15.7.1" class="ltx_text" style="font-size:90%;">Guantánamo, White House</span></td>
</tr>
<tr id="S2.T2.2.16.16" class="ltx_tr">
<td id="S2.T2.2.16.16.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.16.16.1.1" class="ltx_text" style="font-size:90%;">event</span></td>
<td id="S2.T2.2.16.16.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.16.16.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S2.T2.2.16.16.3" class="ltx_td ltx_align_left"><span id="S2.T2.2.16.16.3.1" class="ltx_text" style="font-size:90%;">23</span></td>
<td id="S2.T2.2.16.16.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.16.16.4.1" class="ltx_text" style="font-size:90%;">25</span></td>
<td id="S2.T2.2.16.16.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.16.16.5.1" class="ltx_text" style="font-size:90%;">21</span></td>
<td id="S2.T2.2.16.16.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.16.16.6.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S2.T2.2.16.16.7" class="ltx_td ltx_align_right"><span id="S2.T2.2.16.16.7.1" class="ltx_text" style="font-size:90%;">Europees Semester, Rio conferentie</span></td>
</tr>
<tr id="S2.T2.2.17.17" class="ltx_tr">
<td id="S2.T2.2.17.17.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.17.17.1.1" class="ltx_text" style="font-size:90%;">work of art</span></td>
<td id="S2.T2.2.17.17.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.17.17.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S2.T2.2.17.17.3" class="ltx_td ltx_align_left"><span id="S2.T2.2.17.17.3.1" class="ltx_text" style="font-size:90%;">6</span></td>
<td id="S2.T2.2.17.17.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.17.17.4.1" class="ltx_text" style="font-size:90%;">3</span></td>
<td id="S2.T2.2.17.17.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.17.17.5.1" class="ltx_text" style="font-size:90%;">4</span></td>
<td id="S2.T2.2.17.17.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.17.17.6.1" class="ltx_text" style="font-size:90%;">4</span></td>
<td id="S2.T2.2.17.17.7" class="ltx_td ltx_align_right"><span id="S2.T2.2.17.17.7.1" class="ltx_text" style="font-size:90%;">Green Book, Koran</span></td>
</tr>
<tr id="S2.T2.2.18.18" class="ltx_tr">
<td id="S2.T2.2.18.18.1" class="ltx_td ltx_align_left"><span id="S2.T2.2.18.18.1.1" class="ltx_text" style="font-size:90%;">product</span></td>
<td id="S2.T2.2.18.18.2" class="ltx_td ltx_align_left"><span id="S2.T2.2.18.18.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S2.T2.2.18.18.3" class="ltx_td ltx_align_left"><span id="S2.T2.2.18.18.3.1" class="ltx_text" style="font-size:90%;">4</span></td>
<td id="S2.T2.2.18.18.4" class="ltx_td ltx_align_right"><span id="S2.T2.2.18.18.4.1" class="ltx_text" style="font-size:90%;">1</span></td>
<td id="S2.T2.2.18.18.5" class="ltx_td ltx_align_right"><span id="S2.T2.2.18.18.5.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="S2.T2.2.18.18.6" class="ltx_td ltx_align_right"><span id="S2.T2.2.18.18.6.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S2.T2.2.18.18.7" class="ltx_td ltx_align_right"><span id="S2.T2.2.18.18.7.1" class="ltx_text" style="font-size:90%;">2G, 4G, 5G, iPhone</span></td>
</tr>
<tr id="S2.T2.2.19.19" class="ltx_tr">
<td id="S2.T2.2.19.19.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T2.2.19.19.1.1" class="ltx_text" style="font-size:90%;">language</span></td>
<td id="S2.T2.2.19.19.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T2.2.19.19.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S2.T2.2.19.19.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T2.2.19.19.3.1" class="ltx_text" style="font-size:90%;">3</span></td>
<td id="S2.T2.2.19.19.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S2.T2.2.19.19.4.1" class="ltx_text" style="font-size:90%;">12</span></td>
<td id="S2.T2.2.19.19.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S2.T2.2.19.19.5.1" class="ltx_text" style="font-size:90%;">6</span></td>
<td id="S2.T2.2.19.19.6" class="ltx_td ltx_align_right ltx_border_bb"><span id="S2.T2.2.19.19.6.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="S2.T2.2.19.19.7" class="ltx_td ltx_align_right ltx_border_bb"><span id="S2.T2.2.19.19.7.1" class="ltx_text" style="font-size:90%;">Latin, Nederlands, Español</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Number of annotated entities per entity type in the test sets. Column SLUE correspond to the ‘combined’ entity set proposed by <cite class="ltx_cite ltx_citemacro_citet">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>.</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">3.   Dataset description</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">The MSNER dataset is an annotated version of the VoxPopuli dataset <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> in four languages – Dutch, French, German, and Spanish. VoxPopuli is a collection of recorded sessions from the European Parliament, segmented to contain one or more sentence by one speaker. For each language in scope, we provide three annotated subsets (Table <a href="#S2.T1" title="Table 1 ‣ 2. Literature Review ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>): a training and development set with machine-generated “silver” annotations, and a test set with manual “gold” annotations. The subsets of the four languages in scope were annotated according to OntoNotes’ 18 classes. The test sets were manually annotated by the authors following the methodology outlined in Section <a href="#S4" title="4. Methodology ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Each example in the annotated dataset contains the VoxPopuli ID to identify the relevant audio recording in the original dataset, the transcribed sentence and the annotated named entities, that is, the list of entities, each composed of a text and a label component (Figure <a href="#S3.F1" title="Figure 1 ‣ 3. Dataset description ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). For the silver label datasets, we also provide a probability score of each predicted entity. We discuss in Section <a href="#S6" title="6. Experiments ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> how this number is related to the uncertainty of the model.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p">We use the 18-classes OntoNotes label set <cite class="ltx_cite ltx_citemacro_citep">(Weischedel et al., <a href="#biba.bib1" title="" class="ltx_ref">2013</a>)</cite>. However, following the example from <cite class="ltx_cite ltx_citemacro_citet">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>, we provide annotations by using an alternative label set that combines entity types like places or numbers and discard the rarest classes like languages, events, and work of art (Table <a href="#S2.T2" title="Table 2 ‣ 2. Literature Review ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> Column 2).</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2405.11519/assets/figures/Spoken-NER_example.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="360" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Annotated example</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">4.   Methodology</h2>

<figure id="S4.F2" class="ltx_figure"><img src="/html/2405.11519/assets/figures/annotations_breakdown.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="175" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;">Evaluation of text-based pretrained NER model against our annotations. Bright colors correspond to the F1-score and faded colors correspond to the label-F1 score, a metric that ignores spelling mistakes and segmentation errors.</span></figcaption>
</figure>
<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">We provide two kinds of label quality: machine-generated “silver” labels and human-annotated “gold” labels. For obvious reasons, the silver labels are much cheaper and easier to produce. Therefore, we only provide human-made annotations for the test sets, and the training and validation sets annotations are entirely machine-generated. The methodology follows these four broad steps: (1) filtering out recordings without or with misaligned transcripts, (2) generate silver labels for all subsets, (3) manually annotate the test sets and (4) verify the human-made annotations to identify and rectify potential labelling errors. We detail each step in the following paragraphs.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.1.   Filtering</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">The VoxPopuli dataset contains a few alignment errors between the spoken content and its corresponding transcript. To address this issue, we employed an automatic speech recognition (ASR) system, initially transcribing the spoken utterances and subsequently calculating the word error rate by comparing the ASR-generated sentence to the provided transcript. For this task, we opted for the Whisper large v2 ASR model <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>, because it showed near state-of-the-art performance across the selected languages. Notably, this model has been meticulously trained on extensive, well-curated data to perform both audio translation and transcription tasks.
<br class="ltx_break">For the training and development sets, we filter out examples with a WER larger than 20%, without verifying that the excluded examples were indeed problematic. This discards about 20% of the German and Dutch utterances, 10% of the French examples and 6% of the Spanish utterances.
<br class="ltx_break">For the test sets, instances where the word error rate (WER) between the machine-generated transcription and the original transcript exceeded 20%, we conducted a meticulous review process. This involved listening to the audio recording and cross-referencing it with the existing transcript. When feasible, we made necessary corrections to the transcript. However, in cases where multiple speakers were heard in the recording or no speech is present, we removed the problematic utterance from the dataset.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.2.   Pseudo-annotations</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p">We employed an established text-based Named Entity Recognition (NER) model to predict entities within the gold transcript. We chose to use the XLM-RoBERTa large pretrained model <cite class="ltx_cite ltx_citemacro_citep">(Conneau et al., <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>, fine-tuned specifically on the OntoNotes v5 dataset <cite class="ltx_cite ltx_citemacro_citep">(Weischedel et al., <a href="#biba.bib1" title="" class="ltx_ref">2013</a>)</cite>. This model is readily accessible through the HuggingFace repository<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://huggingface.co/asahi417/tner-xlm-roberta-base-ontonotes5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/asahi417/tner-xlm-roberta-base-ontonotes5</a></span></span></span>.
<br class="ltx_break">While it’s important to note that this particular model’s fine-tuning was conducted solely on English data, its robustness and efficacy across multiple languages were remarkable. In our evaluation, we observed impressive performance, with most sentences annotated correctly.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.3.   Annotation Tool</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.1" class="ltx_p">For each of the 6,254 pre-annotated sentences in the test sets, we corrected the annotations predicted by the model. For this purpose, we have developed a command line tool to quickly add, edit, merge or remove annotations in a sentence. This utility displays the pre-annotated sentence with a summary of the annotations below. Annotations appear as colored XML tags both in the text and in the summary. An annotated English translation can be displayed. The annotator then has access to both the original sentence and the translation to make sure that the annotations are as accurate as possible. When presented with a sentence, the annotator has the choice to add a new annotation, delete an existing one, merge two annotations together or modify an annotation, either by changing the type or by adding or removing words. Once a sentence has been annotated, it is saved to a file in JSON format. Following this methodology and with the help of this tool, we were able to save a lot of time and effort without sacrificing accuracy. For this reason, we make the tool available online so that others will have the opportunity to contribute to this field of research by easily annotating more data in many more languages.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p">As mentioned in Section <a href="#S3" title="3. Dataset description ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we not only provide annotations according to OntoNotes 18 classes, but also the 7-classes combined set proposed in <cite class="ltx_cite ltx_citemacro_citet">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>. However, we chose to completely reannotate the examples where entities are removed, instead of simply removing all the annotations of the same type from the dataset. To illustrate this, consider the following example:</p>
<blockquote id="S4.SS3.p2.2" class="ltx_quote">
<p id="S4.SS3.p2.2.1" class="ltx_p"><code id="S4.SS3.p2.2.1.1" class="ltx_verbatim ltx_font_typewriter">&lt;event&gt;</code><span id="S4.SS3.p2.2.1.2" class="ltx_text"> 15th conference on speech of Toronto <code id="S4.SS3.p2.2.1.2.1" class="ltx_verbatim ltx_font_typewriter">&lt;/event&gt;</code></span></p>
</blockquote>
<p id="S4.SS3.p2.3" class="ltx_p">According to the combined set conversion rules (Table <a href="#S2.T2" title="Table 2 ‣ 2. Literature Review ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), all the entities of type <code id="S4.SS3.p2.3.1" class="ltx_verbatim ltx_font_typewriter">&lt;event&gt;</code> are to be discarded. Doing that would lead to two unannotated entities, ‘15th’ as a number and ‘Toronto’ as a place. Instead, we re-annotate the examples containing removed entities to make sure that we are not penalizing the models for correct assumptions.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2405.11519/assets/figures/conditional_mean.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Distribution of predicted probability score per class given the target class for the text-based model’s predictions</span></figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2405.11519/assets/figures/confusion_matrix_all.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">Confusion matrix, normalized to show the probability distribution of the tags predicted with the text-based model.</span></figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.4.   Verification</h3>

<div id="S4.SS4.p1" class="ltx_para ltx_noindent">
<p id="S4.SS4.p1.1" class="ltx_p">Finally, we verify the integrity of the test annotations by deriving a number of heuristics and rules that the annotations must abide. This involved grouping the annotations by category and verify each list one by one, comparing them to one another, searching in the text for frequent annotated terms to identify missing annotations, etc. In this last step, we also fix some remaining transcription issues. For example, we realized that VoxPopuli transcripts omitted the symbol “%”, and sometimes the word “thousands” (in all languages). Consequently, for all entities marked as cardinal number, we added the missing tokens when necessary, following the rules specific to the language<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In French and in Spanish, the symbol “%” is generally used, but in German and in Dutch, the word is more commonly spelled as Prozent or procent, respectively.</span></span></span>. Another error often made by the text-based NER model is to predict the article as being part of the entity. As multiple sources advocate against doing so, we abided by the main guidelines <cite class="ltx_cite ltx_citemacro_cite">Maekawa (<a href="#bib.bib9" title="" class="ltx_ref">2018</a>); Benikova et al. (<a href="#bib.bib2" title="" class="ltx_ref">2014</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.5.   Distribution</h3>

<div id="S4.SS5.p1" class="ltx_para ltx_noindent">
<p id="S4.SS5.p1.1" class="ltx_p">The annotated datasets are distributed in two formats: As JSON Lines files available on GitHub<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/qmeeus/MSNER" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/qmeeus/MSNER</a></span></span></span>, and on the HuggingFace repository <cite class="ltx_cite ltx_citemacro_cite">Wolf et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>. There is one file per subset and per language, where each line is an annotated example. The audio files can be obtained by downloading VoxPopuli and matching the audio ID. The dataset version hosted on HuggingFace contains the audio recordings and the preprocessed annotations in BIO format, so that a researcher can already use the dataset after only two lines of code.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">5.   Evaluation Metrics</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_citet">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>, we recommend evaluating model predictions with the micro-averaged F1-score. The F1-score is the harmonic mean of precision and recall, calculated from an unordered list of named entities predicted for each utterance. Precision is the proportion of correctly predicted entities among all predicted entities, and recall is the proportion of ground truth entities that were correctly detected. An entity is considered to be predicted correctly if both the type and spelling are identical to the ground truth. To allow multiple entities with the same spelling and type in a sentence, we add a unique identifier to each entity/type pair. We recommend using the micro-averaged F1-score because the dataset is unbalanced. The label F1-score only considers the predicted type of the entity for correctness, leaving the transcribed entity out of the computations. This metric ignores spelling mistakes and segmentation errors.
We provide an evaluation script<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://raw.githubusercontent.com/qmeeus/MSNER/main/src/evaluate.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://raw.githubusercontent.com/qmeeus/MSNER/main/src/evaluate.py</a></span></span></span> to compute these metrics and generate a breakdown of the prediction results per entity type.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">6.   Experiments</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.1.   Setup</h3>

<div id="S6.SS1.p1" class="ltx_para ltx_noindent">
<p id="S6.SS1.p1.1" class="ltx_p">The first analysis compares the annotated test sets to the pseudo-annotations generated by the text-based NER model. Since the silver-label training and validation sets were generated with this model, this analysis is valuable for anyone intending to use these datasets for training. Indeed, it gives insights into the entities that are often confused with one another or remain undetected. It also gives some insights on the reliability of the model’s confidence score in assessing whether a prediction is correct.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para ltx_noindent">
<p id="S6.SS1.p2.1" class="ltx_p">We also consider two methods to predict named entities from speech, with a pipeline and an end-to-end model. The end-to-end model is a transformer encoder-decoder trained to perform both ASR and NER with a multitask objective <cite class="ltx_cite ltx_citemacro_cite">Meeus et al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>. This model is initialized from Whisper Large V2 <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>, with an additional SLU module connected to the layers of the decoder with an adaptor. The end-to-end model was fine-tuned on English SLUE-VoxPopuli <cite class="ltx_cite ltx_citemacro_cite">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>. The pipeline model transcribes the audio files and subsequently annotates the transcriptions. For the ASR model, we use Whisper Large V2 <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>. For the pipeline model, we provide two options to allow for a better comparison. In Table <a href="#S6.T3" title="Table 3 ‣ 6.2. Results ‣ 6. Experiments ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we use XML-RoBERTa fine-tuned on OntoNotes v5 <cite class="ltx_cite ltx_citemacro_citep">(Weischedel et al., <a href="#biba.bib1" title="" class="ltx_ref">2013</a>)</cite> and compare it to the predictions generated by the text-based NER model from the gold transcripts. In Table <a href="#S6.T4" title="Table 4 ‣ 6.2. Results ‣ 6. Experiments ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we fine-tuned the same XML-RoBERTa on SLUE-VoxPopuli <cite class="ltx_cite ltx_citemacro_cite">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>, which provides a fair comparison to the end-to-end model.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para ltx_noindent">
<p id="S6.SS1.p3.1" class="ltx_p">Although both models rely on multilingual pretrained models, the fine-tuning dataset is entirely in English. Therefore, we evaluate the ability of these models to generalize from one language (English) to other languages (Dutch, French, German, and Spanish). Before computing the F1-scores, we normalize the text by putting it in lower case and removing symbols. It should be noted that the evaluation script does normalize the text further, which could have its importance depending on the model to be evaluated.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para ltx_noindent">
<p id="S6.SS1.p4.1" class="ltx_p">All results are presented on the human-annotated test sets proposed in this article.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">6.2.   Results</h3>

<div id="S6.SS2.p1" class="ltx_para ltx_noindent">
<p id="S6.SS2.p1.2" class="ltx_p">Figure <a href="#S4.F3" title="Figure 3 ‣ 4.3. Annotation Tool ‣ 4. Methodology ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the distribution of calculated probabilities for predicted ‘B’ and ‘O’ tags conditional to whether they were predicted correctly or not. For each token position <math id="S6.SS2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS2.p1.1.m1.1a"><mi id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><ci id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">k</annotation></semantics></math>, the probability of the most likely tag <math id="S6.SS2.p1.2.m2.1" class="ltx_Math" alttext="i^{*}" display="inline"><semantics id="S6.SS2.p1.2.m2.1a"><msup id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml"><mi id="S6.SS2.p1.2.m2.1.1.2" xref="S6.SS2.p1.2.m2.1.1.2.cmml">i</mi><mo id="S6.SS2.p1.2.m2.1.1.3" xref="S6.SS2.p1.2.m2.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><apply id="S6.SS2.p1.2.m2.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S6.SS2.p1.2.m2.1.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S6.SS2.p1.2.m2.1.1.2.cmml" xref="S6.SS2.p1.2.m2.1.1.2">𝑖</ci><times id="S6.SS2.p1.2.m2.1.1.3.cmml" xref="S6.SS2.p1.2.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">i^{*}</annotation></semantics></math> is computed as follows:</p>
<table id="S6.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.Ex1.m1.1" class="ltx_Math" alttext="P(y^{k}=i^{*})=\max_{i}{\frac{e^{z^{k}_{i}}}{\sum_{j}e^{z^{k}_{j}}}}" display="block"><semantics id="S6.Ex1.m1.1a"><mrow id="S6.Ex1.m1.1.1" xref="S6.Ex1.m1.1.1.cmml"><mrow id="S6.Ex1.m1.1.1.1" xref="S6.Ex1.m1.1.1.1.cmml"><mi id="S6.Ex1.m1.1.1.1.3" xref="S6.Ex1.m1.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S6.Ex1.m1.1.1.1.2" xref="S6.Ex1.m1.1.1.1.2.cmml">​</mo><mrow id="S6.Ex1.m1.1.1.1.1.1" xref="S6.Ex1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S6.Ex1.m1.1.1.1.1.1.2" xref="S6.Ex1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S6.Ex1.m1.1.1.1.1.1.1" xref="S6.Ex1.m1.1.1.1.1.1.1.cmml"><msup id="S6.Ex1.m1.1.1.1.1.1.1.2" xref="S6.Ex1.m1.1.1.1.1.1.1.2.cmml"><mi id="S6.Ex1.m1.1.1.1.1.1.1.2.2" xref="S6.Ex1.m1.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S6.Ex1.m1.1.1.1.1.1.1.2.3" xref="S6.Ex1.m1.1.1.1.1.1.1.2.3.cmml">k</mi></msup><mo id="S6.Ex1.m1.1.1.1.1.1.1.1" xref="S6.Ex1.m1.1.1.1.1.1.1.1.cmml">=</mo><msup id="S6.Ex1.m1.1.1.1.1.1.1.3" xref="S6.Ex1.m1.1.1.1.1.1.1.3.cmml"><mi id="S6.Ex1.m1.1.1.1.1.1.1.3.2" xref="S6.Ex1.m1.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="S6.Ex1.m1.1.1.1.1.1.1.3.3" xref="S6.Ex1.m1.1.1.1.1.1.1.3.3.cmml">∗</mo></msup></mrow><mo stretchy="false" id="S6.Ex1.m1.1.1.1.1.1.3" xref="S6.Ex1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S6.Ex1.m1.1.1.2" xref="S6.Ex1.m1.1.1.2.cmml">=</mo><mrow id="S6.Ex1.m1.1.1.3" xref="S6.Ex1.m1.1.1.3.cmml"><munder id="S6.Ex1.m1.1.1.3.1" xref="S6.Ex1.m1.1.1.3.1.cmml"><mi id="S6.Ex1.m1.1.1.3.1.2" xref="S6.Ex1.m1.1.1.3.1.2.cmml">max</mi><mi id="S6.Ex1.m1.1.1.3.1.3" xref="S6.Ex1.m1.1.1.3.1.3.cmml">i</mi></munder><mo lspace="0.167em" id="S6.Ex1.m1.1.1.3a" xref="S6.Ex1.m1.1.1.3.cmml">⁡</mo><mfrac id="S6.Ex1.m1.1.1.3.2" xref="S6.Ex1.m1.1.1.3.2.cmml"><msup id="S6.Ex1.m1.1.1.3.2.2" xref="S6.Ex1.m1.1.1.3.2.2.cmml"><mi id="S6.Ex1.m1.1.1.3.2.2.2" xref="S6.Ex1.m1.1.1.3.2.2.2.cmml">e</mi><msubsup id="S6.Ex1.m1.1.1.3.2.2.3" xref="S6.Ex1.m1.1.1.3.2.2.3.cmml"><mi id="S6.Ex1.m1.1.1.3.2.2.3.2.2" xref="S6.Ex1.m1.1.1.3.2.2.3.2.2.cmml">z</mi><mi id="S6.Ex1.m1.1.1.3.2.2.3.3" xref="S6.Ex1.m1.1.1.3.2.2.3.3.cmml">i</mi><mi id="S6.Ex1.m1.1.1.3.2.2.3.2.3" xref="S6.Ex1.m1.1.1.3.2.2.3.2.3.cmml">k</mi></msubsup></msup><mrow id="S6.Ex1.m1.1.1.3.2.3" xref="S6.Ex1.m1.1.1.3.2.3.cmml"><msub id="S6.Ex1.m1.1.1.3.2.3.1" xref="S6.Ex1.m1.1.1.3.2.3.1.cmml"><mo id="S6.Ex1.m1.1.1.3.2.3.1.2" xref="S6.Ex1.m1.1.1.3.2.3.1.2.cmml">∑</mo><mi id="S6.Ex1.m1.1.1.3.2.3.1.3" xref="S6.Ex1.m1.1.1.3.2.3.1.3.cmml">j</mi></msub><msup id="S6.Ex1.m1.1.1.3.2.3.2" xref="S6.Ex1.m1.1.1.3.2.3.2.cmml"><mi id="S6.Ex1.m1.1.1.3.2.3.2.2" xref="S6.Ex1.m1.1.1.3.2.3.2.2.cmml">e</mi><msubsup id="S6.Ex1.m1.1.1.3.2.3.2.3" xref="S6.Ex1.m1.1.1.3.2.3.2.3.cmml"><mi id="S6.Ex1.m1.1.1.3.2.3.2.3.2.2" xref="S6.Ex1.m1.1.1.3.2.3.2.3.2.2.cmml">z</mi><mi id="S6.Ex1.m1.1.1.3.2.3.2.3.3" xref="S6.Ex1.m1.1.1.3.2.3.2.3.3.cmml">j</mi><mi id="S6.Ex1.m1.1.1.3.2.3.2.3.2.3" xref="S6.Ex1.m1.1.1.3.2.3.2.3.2.3.cmml">k</mi></msubsup></msup></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.Ex1.m1.1b"><apply id="S6.Ex1.m1.1.1.cmml" xref="S6.Ex1.m1.1.1"><eq id="S6.Ex1.m1.1.1.2.cmml" xref="S6.Ex1.m1.1.1.2"></eq><apply id="S6.Ex1.m1.1.1.1.cmml" xref="S6.Ex1.m1.1.1.1"><times id="S6.Ex1.m1.1.1.1.2.cmml" xref="S6.Ex1.m1.1.1.1.2"></times><ci id="S6.Ex1.m1.1.1.1.3.cmml" xref="S6.Ex1.m1.1.1.1.3">𝑃</ci><apply id="S6.Ex1.m1.1.1.1.1.1.1.cmml" xref="S6.Ex1.m1.1.1.1.1.1"><eq id="S6.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.1"></eq><apply id="S6.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.1.1.1.1.2.1.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S6.Ex1.m1.1.1.1.1.1.1.2.2.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S6.Ex1.m1.1.1.1.1.1.1.2.3.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.2.3">𝑘</ci></apply><apply id="S6.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.1.1.1.1.3.1.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S6.Ex1.m1.1.1.1.1.1.1.3.2.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.3.2">𝑖</ci><times id="S6.Ex1.m1.1.1.1.1.1.1.3.3.cmml" xref="S6.Ex1.m1.1.1.1.1.1.1.3.3"></times></apply></apply></apply><apply id="S6.Ex1.m1.1.1.3.cmml" xref="S6.Ex1.m1.1.1.3"><apply id="S6.Ex1.m1.1.1.3.1.cmml" xref="S6.Ex1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.3.1.1.cmml" xref="S6.Ex1.m1.1.1.3.1">subscript</csymbol><max id="S6.Ex1.m1.1.1.3.1.2.cmml" xref="S6.Ex1.m1.1.1.3.1.2"></max><ci id="S6.Ex1.m1.1.1.3.1.3.cmml" xref="S6.Ex1.m1.1.1.3.1.3">𝑖</ci></apply><apply id="S6.Ex1.m1.1.1.3.2.cmml" xref="S6.Ex1.m1.1.1.3.2"><divide id="S6.Ex1.m1.1.1.3.2.1.cmml" xref="S6.Ex1.m1.1.1.3.2"></divide><apply id="S6.Ex1.m1.1.1.3.2.2.cmml" xref="S6.Ex1.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.3.2.2.1.cmml" xref="S6.Ex1.m1.1.1.3.2.2">superscript</csymbol><ci id="S6.Ex1.m1.1.1.3.2.2.2.cmml" xref="S6.Ex1.m1.1.1.3.2.2.2">𝑒</ci><apply id="S6.Ex1.m1.1.1.3.2.2.3.cmml" xref="S6.Ex1.m1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.3.2.2.3.1.cmml" xref="S6.Ex1.m1.1.1.3.2.2.3">subscript</csymbol><apply id="S6.Ex1.m1.1.1.3.2.2.3.2.cmml" xref="S6.Ex1.m1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.3.2.2.3.2.1.cmml" xref="S6.Ex1.m1.1.1.3.2.2.3">superscript</csymbol><ci id="S6.Ex1.m1.1.1.3.2.2.3.2.2.cmml" xref="S6.Ex1.m1.1.1.3.2.2.3.2.2">𝑧</ci><ci id="S6.Ex1.m1.1.1.3.2.2.3.2.3.cmml" xref="S6.Ex1.m1.1.1.3.2.2.3.2.3">𝑘</ci></apply><ci id="S6.Ex1.m1.1.1.3.2.2.3.3.cmml" xref="S6.Ex1.m1.1.1.3.2.2.3.3">𝑖</ci></apply></apply><apply id="S6.Ex1.m1.1.1.3.2.3.cmml" xref="S6.Ex1.m1.1.1.3.2.3"><apply id="S6.Ex1.m1.1.1.3.2.3.1.cmml" xref="S6.Ex1.m1.1.1.3.2.3.1"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.3.2.3.1.1.cmml" xref="S6.Ex1.m1.1.1.3.2.3.1">subscript</csymbol><sum id="S6.Ex1.m1.1.1.3.2.3.1.2.cmml" xref="S6.Ex1.m1.1.1.3.2.3.1.2"></sum><ci id="S6.Ex1.m1.1.1.3.2.3.1.3.cmml" xref="S6.Ex1.m1.1.1.3.2.3.1.3">𝑗</ci></apply><apply id="S6.Ex1.m1.1.1.3.2.3.2.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.3.2.3.2.1.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2">superscript</csymbol><ci id="S6.Ex1.m1.1.1.3.2.3.2.2.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2.2">𝑒</ci><apply id="S6.Ex1.m1.1.1.3.2.3.2.3.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2.3"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.3.2.3.2.3.1.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2.3">subscript</csymbol><apply id="S6.Ex1.m1.1.1.3.2.3.2.3.2.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2.3"><csymbol cd="ambiguous" id="S6.Ex1.m1.1.1.3.2.3.2.3.2.1.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2.3">superscript</csymbol><ci id="S6.Ex1.m1.1.1.3.2.3.2.3.2.2.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2.3.2.2">𝑧</ci><ci id="S6.Ex1.m1.1.1.3.2.3.2.3.2.3.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2.3.2.3">𝑘</ci></apply><ci id="S6.Ex1.m1.1.1.3.2.3.2.3.3.cmml" xref="S6.Ex1.m1.1.1.3.2.3.2.3.3">𝑗</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.Ex1.m1.1c">P(y^{k}=i^{*})=\max_{i}{\frac{e^{z^{k}_{i}}}{\sum_{j}e^{z^{k}_{j}}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S6.SS2.p1.4" class="ltx_p">where <math id="S6.SS2.p1.3.m1.1" class="ltx_math_unparsed" alttext="z^{k}_{1..N}" display="inline"><semantics id="S6.SS2.p1.3.m1.1a"><msubsup id="S6.SS2.p1.3.m1.1.2"><mi id="S6.SS2.p1.3.m1.1.2.2.2">z</mi><mrow id="S6.SS2.p1.3.m1.1.1.1"><mn id="S6.SS2.p1.3.m1.1.1.1.1">1</mn><mo lspace="0em" rspace="0.0835em" id="S6.SS2.p1.3.m1.1.1.1.2">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S6.SS2.p1.3.m1.1.1.1.3">.</mo><mi id="S6.SS2.p1.3.m1.1.1.1.4">N</mi></mrow><mi id="S6.SS2.p1.3.m1.1.2.2.3">k</mi></msubsup><annotation encoding="application/x-tex" id="S6.SS2.p1.3.m1.1b">z^{k}_{1..N}</annotation></semantics></math> are the logits predicted by the model for the token at position <math id="S6.SS2.p1.4.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS2.p1.4.m2.1a"><mi id="S6.SS2.p1.4.m2.1.1" xref="S6.SS2.p1.4.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.4.m2.1b"><ci id="S6.SS2.p1.4.m2.1.1.cmml" xref="S6.SS2.p1.4.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.4.m2.1c">k</annotation></semantics></math>. We observe that, on average, annotations for which there was no agreement between the annotator and the NER model were predicted with a lower probability than annotations that were correctly annotated from the start. However, we observe major differences between the class distributions. For the most frequent classes, like ‘O’, ‘organization’ or ‘date’, the probability distributions overlap considerably, and
one should be careful if using this score as a proxy for the model’s uncertainty. This is not surprising, as transformers are known to be overconfident <cite class="ltx_cite ltx_citemacro_cite">Ye et al. (<a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>. For rare quantitative classes like ‘percent’ and ‘quantity’, the model shows confidence when predictions are correct, and uncertain otherwise. This indicates that for those particular classes, the given probability could be relied upon when estimating the model’s uncertainty. The score breakdown by entity and language (Figure <a href="#S4.F2" title="Figure 2 ‣ 4. Methodology ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) indicates that in general, there are no major differences across languages, except for rare classes, where the variability increases significantly.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.p2.1" class="ltx_p">Figure <a href="#S4.F4" title="Figure 4 ‣ 4.3. Annotation Tool ‣ 4. Methodology ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the confusion matrix of the NER model predictions against the manual annotations. Most errors are undetected entities (bottom row in Figure <a href="#S4.F4" title="Figure 4 ‣ 4.3. Annotation Tool ‣ 4. Methodology ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) and segmentation errors (I-tags predicted instead of B-tags and inversely, are visible on the lighter diagonals above and below the main diagonal). Some entities remain undetected more often than not, e.g. “work of art” and “event”, which is a sign that predictions are less reliable for these rare classes. Some other types are often confused with one another, like “money” and “cardinal number”. However, all types seem to have at most two confused types. We notice that “geopolitical area” is most often confused with “location” and “law”. In the latter case, this is because many laws are named after cities (e.g. the Paris Agreement, the Warsaw Treaty).</p>
</div>
<div id="S6.SS2.p3" class="ltx_para ltx_noindent">
<p id="S6.SS2.p3.1" class="ltx_p">Table <a href="#S6.T3" title="Table 3 ‣ 6.2. Results ‣ 6. Experiments ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> compares the text-based NER predictions with the NER predictions obtained from the ASR transcript and generated by the same text-based NER model. The OntoNotes dataset, although in English, provides many well-curated annotations and the NER model trained on this dataset seem to generalize well to the other languages. However, this model was not trained to handle automatic transcripts and we observe a considerable drop in performance when it is asked to process ASR outputs. To make a fair comparison with the end-to-end model, we fine-tune XML-RoBERTa on SLUE-VoxPopuli and report the results in Table <a href="#S6.T4" title="Table 4 ‣ 6.2. Results ‣ 6. Experiments ‣ MSNER: A Multilingual Speech Dataset for Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The fine-tuning dataset being of much modest size (14.5 hours of training data), the models do not have many examples to learn from. The end-to-end model has a slight advantage because it learns simultaneously the ASR and NER tasks, and it is able to share part of its architecture between both tasks. For example, it seems well able to identify the presence of entities despite a lot of transcription and segmentation errors, as evidenced by the large label F1-score. In contrast, the pipeline suffers much more from the transcription errors because it was pretrained on curated texts and is not expecting noisy ASR transcriptions.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para ltx_noindent">
<p id="S6.SS2.p4.1" class="ltx_p">The text-based NER model performs best for Dutch, then German, French and finally Spanish. As the model was trained on English annotations, this ranking is not a surprise, although the ability of the model to transfer to other languages is impressive. However, for the speech processing models, the same conclusion cannot be drawn.
The entity F1-score seem to be correlated with the word error rate, which is influenced by the availability of the different languages in the pretraining set. In other words, for speech models, this is the model’s ability to transcribe foreign languages that will drive the quality of the predictions, rather than how similar the evaluation and the pretraining language are. The label-F1 indicates how accurate a model is at detecting the presence of entity types, disregarding of its ability to transcribe it correctly. Looking at those numbers, we observe again the same behavior as with the text-based entity predictions, namely that entities are more likely to be accurately detected when the evaluation language is more similar to the finetuning language.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<table id="S6.T3.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T3.5.6.1" class="ltx_tr">
<th id="S6.T3.5.6.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt"><span id="S6.T3.5.6.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S6.T3.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T3.5.6.1.2.1" class="ltx_text" style="font-size:90%;">Metric</span></th>
<td id="S6.T3.5.6.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T3.5.6.1.3.1" class="ltx_text" style="font-size:90%;">DE</span></td>
<td id="S6.T3.5.6.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T3.5.6.1.4.1" class="ltx_text" style="font-size:90%;">ES</span></td>
<td id="S6.T3.5.6.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T3.5.6.1.5.1" class="ltx_text" style="font-size:90%;">FR</span></td>
<td id="S6.T3.5.6.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T3.5.6.1.6.1" class="ltx_text" style="font-size:90%;">NL</span></td>
</tr>
<tr id="S6.T3.1.1" class="ltx_tr">
<th id="S6.T3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="S6.T3.1.1.2.1" class="ltx_text" style="font-size:90%;">Gold</span></th>
<th id="S6.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S6.T3.1.1.1.1" class="ltx_text" style="font-size:90%;">F1 (</span><math id="S6.T3.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T3.1.1.1.m1.1.1" xref="S6.T3.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T3.1.1.1.m1.1b"><ci id="S6.T3.1.1.1.m1.1.1.cmml" xref="S6.T3.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.1.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S6.T3.1.1.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.3.1" class="ltx_text" style="font-size:90%;">77.4</span></td>
<td id="S6.T3.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.4.1" class="ltx_text" style="font-size:90%;">70.1</span></td>
<td id="S6.T3.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.5.1" class="ltx_text" style="font-size:90%;">71.1</span></td>
<td id="S6.T3.1.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.1.1.6.1" class="ltx_text" style="font-size:90%;">79.9</span></td>
</tr>
<tr id="S6.T3.2.2" class="ltx_tr">
<th id="S6.T3.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S6.T3.2.2.1.1" class="ltx_text" style="font-size:90%;">Label-F1 (</span><math id="S6.T3.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.2.2.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T3.2.2.1.m1.1.1" xref="S6.T3.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T3.2.2.1.m1.1b"><ci id="S6.T3.2.2.1.m1.1.1.cmml" xref="S6.T3.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.2.1.m1.1c">\uparrow</annotation></semantics></math><span id="S6.T3.2.2.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T3.2.2.2" class="ltx_td ltx_align_center"><span id="S6.T3.2.2.2.1" class="ltx_text" style="font-size:90%;">89.7</span></td>
<td id="S6.T3.2.2.3" class="ltx_td ltx_align_center"><span id="S6.T3.2.2.3.1" class="ltx_text" style="font-size:90%;">90.3</span></td>
<td id="S6.T3.2.2.4" class="ltx_td ltx_align_center"><span id="S6.T3.2.2.4.1" class="ltx_text" style="font-size:90%;">89.1</span></td>
<td id="S6.T3.2.2.5" class="ltx_td ltx_align_center"><span id="S6.T3.2.2.5.1" class="ltx_text" style="font-size:90%;">94.4</span></td>
</tr>
<tr id="S6.T3.3.3" class="ltx_tr">
<th id="S6.T3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="3"><span id="S6.T3.3.3.2.1" class="ltx_text" style="font-size:90%;">ASR</span></th>
<th id="S6.T3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S6.T3.3.3.1.1" class="ltx_text" style="font-size:90%;">F1 (</span><math id="S6.T3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.3.3.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T3.3.3.1.m1.1.1" xref="S6.T3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T3.3.3.1.m1.1b"><ci id="S6.T3.3.3.1.m1.1.1.cmml" xref="S6.T3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.3.3.1.m1.1c">\uparrow</annotation></semantics></math><span id="S6.T3.3.3.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.3.3.3.1" class="ltx_text" style="font-size:90%;">52.4</span></td>
<td id="S6.T3.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.3.3.4.1" class="ltx_text" style="font-size:90%;">50.6</span></td>
<td id="S6.T3.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.3.3.5.1" class="ltx_text" style="font-size:90%;">44.7</span></td>
<td id="S6.T3.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T3.3.3.6.1" class="ltx_text" style="font-size:90%;">52.7</span></td>
</tr>
<tr id="S6.T3.4.4" class="ltx_tr">
<th id="S6.T3.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S6.T3.4.4.1.1" class="ltx_text" style="font-size:90%;">Label-F1 (</span><math id="S6.T3.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T3.4.4.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T3.4.4.1.m1.1.1" xref="S6.T3.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T3.4.4.1.m1.1b"><ci id="S6.T3.4.4.1.m1.1.1.cmml" xref="S6.T3.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.4.4.1.m1.1c">\uparrow</annotation></semantics></math><span id="S6.T3.4.4.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T3.4.4.2" class="ltx_td ltx_align_center"><span id="S6.T3.4.4.2.1" class="ltx_text" style="font-size:90%;">66.2</span></td>
<td id="S6.T3.4.4.3" class="ltx_td ltx_align_center"><span id="S6.T3.4.4.3.1" class="ltx_text" style="font-size:90%;">63.6</span></td>
<td id="S6.T3.4.4.4" class="ltx_td ltx_align_center"><span id="S6.T3.4.4.4.1" class="ltx_text" style="font-size:90%;">59.4</span></td>
<td id="S6.T3.4.4.5" class="ltx_td ltx_align_center"><span id="S6.T3.4.4.5.1" class="ltx_text" style="font-size:90%;">66.1</span></td>
</tr>
<tr id="S6.T3.5.5" class="ltx_tr">
<th id="S6.T3.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S6.T3.5.5.1.1" class="ltx_text" style="font-size:90%;">WER (</span><math id="S6.T3.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T3.5.5.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T3.5.5.1.m1.1.1" xref="S6.T3.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T3.5.5.1.m1.1b"><ci id="S6.T3.5.5.1.m1.1.1.cmml" xref="S6.T3.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.5.5.1.m1.1c">\downarrow</annotation></semantics></math><span id="S6.T3.5.5.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T3.5.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.5.5.2.1" class="ltx_text" style="font-size:90%;">12.0</span></td>
<td id="S6.T3.5.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.5.5.3.1" class="ltx_text" style="font-size:90%;">8.6</span></td>
<td id="S6.T3.5.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.5.5.4.1" class="ltx_text" style="font-size:90%;">11.1</span></td>
<td id="S6.T3.5.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T3.5.5.5.1" class="ltx_text" style="font-size:90%;">13.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance of text-based NER model trained on OntoNotes. Gold corresponds to the model’s predictions from the gold transcripts and ASR corresponds to the model’s predictions on the ASR transcripts.</figcaption>
</figure>
<figure id="S6.T4" class="ltx_table">
<table id="S6.T4.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T4.6.7.1" class="ltx_tr">
<th id="S6.T4.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S6.T4.6.7.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S6.T4.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T4.6.7.1.2.1" class="ltx_text" style="font-size:90%;">Metric</span></th>
<th id="S6.T4.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T4.6.7.1.3.1" class="ltx_text" style="font-size:90%;">DE</span></th>
<th id="S6.T4.6.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T4.6.7.1.4.1" class="ltx_text" style="font-size:90%;">ES</span></th>
<th id="S6.T4.6.7.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T4.6.7.1.5.1" class="ltx_text" style="font-size:90%;">FR</span></th>
<th id="S6.T4.6.7.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T4.6.7.1.6.1" class="ltx_text" style="font-size:90%;">NL</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T4.1.1" class="ltx_tr">
<th id="S6.T4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S6.T4.1.1.2.1" class="ltx_text" style="font-size:90%;">Pipeline</span></th>
<th id="S6.T4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S6.T4.1.1.1.1" class="ltx_text" style="font-size:90%;">F1 (</span><math id="S6.T4.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T4.1.1.1.m1.1.1" xref="S6.T4.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T4.1.1.1.m1.1b"><ci id="S6.T4.1.1.1.m1.1.1.cmml" xref="S6.T4.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.1.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S6.T4.1.1.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.1.1.3.1" class="ltx_text" style="font-size:90%;">30.8</span></td>
<td id="S6.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.1.1.4.1" class="ltx_text" style="font-size:90%;">36.3</span></td>
<td id="S6.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.1.1.5.1" class="ltx_text" style="font-size:90%;">37.2</span></td>
<td id="S6.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.1.1.6.1" class="ltx_text" style="font-size:90%;">36.3</span></td>
</tr>
<tr id="S6.T4.2.2" class="ltx_tr">
<th id="S6.T4.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S6.T4.2.2.1.1" class="ltx_text" style="font-size:90%;">Label-F1 (</span><math id="S6.T4.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.2.2.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T4.2.2.1.m1.1.1" xref="S6.T4.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T4.2.2.1.m1.1b"><ci id="S6.T4.2.2.1.m1.1.1.cmml" xref="S6.T4.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.2.2.1.m1.1c">\uparrow</annotation></semantics></math><span id="S6.T4.2.2.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T4.2.2.2" class="ltx_td ltx_align_center"><span id="S6.T4.2.2.2.1" class="ltx_text" style="font-size:90%;">42.7</span></td>
<td id="S6.T4.2.2.3" class="ltx_td ltx_align_center"><span id="S6.T4.2.2.3.1" class="ltx_text" style="font-size:90%;">51.6</span></td>
<td id="S6.T4.2.2.4" class="ltx_td ltx_align_center"><span id="S6.T4.2.2.4.1" class="ltx_text" style="font-size:90%;">49.5</span></td>
<td id="S6.T4.2.2.5" class="ltx_td ltx_align_center"><span id="S6.T4.2.2.5.1" class="ltx_text" style="font-size:90%;">45.9</span></td>
</tr>
<tr id="S6.T4.3.3" class="ltx_tr">
<th id="S6.T4.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S6.T4.3.3.1.1" class="ltx_text" style="font-size:90%;">WER (</span><math id="S6.T4.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T4.3.3.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T4.3.3.1.m1.1.1" xref="S6.T4.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T4.3.3.1.m1.1b"><ci id="S6.T4.3.3.1.m1.1.1.cmml" xref="S6.T4.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.3.3.1.m1.1c">\downarrow</annotation></semantics></math><span id="S6.T4.3.3.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T4.3.3.2" class="ltx_td ltx_align_center"><span id="S6.T4.3.3.2.1" class="ltx_text" style="font-size:90%;">12.0</span></td>
<td id="S6.T4.3.3.3" class="ltx_td ltx_align_center"><span id="S6.T4.3.3.3.1" class="ltx_text" style="font-size:90%;">8.6</span></td>
<td id="S6.T4.3.3.4" class="ltx_td ltx_align_center"><span id="S6.T4.3.3.4.1" class="ltx_text" style="font-size:90%;">11.1</span></td>
<td id="S6.T4.3.3.5" class="ltx_td ltx_align_center"><span id="S6.T4.3.3.5.1" class="ltx_text" style="font-size:90%;">13.1</span></td>
</tr>
<tr id="S6.T4.4.4" class="ltx_tr">
<th id="S6.T4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="3"><span id="S6.T4.4.4.2.1" class="ltx_text" style="font-size:90%;">End2End</span></th>
<th id="S6.T4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S6.T4.4.4.1.1" class="ltx_text" style="font-size:90%;">F1 (</span><math id="S6.T4.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.4.4.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T4.4.4.1.m1.1.1" xref="S6.T4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T4.4.4.1.m1.1b"><ci id="S6.T4.4.4.1.m1.1.1.cmml" xref="S6.T4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.4.4.1.m1.1c">\uparrow</annotation></semantics></math><span id="S6.T4.4.4.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T4.4.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.4.4.3.1" class="ltx_text" style="font-size:90%;">38.3</span></td>
<td id="S6.T4.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.4.4.4.1" class="ltx_text" style="font-size:90%;">41.3</span></td>
<td id="S6.T4.4.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.4.4.5.1" class="ltx_text" style="font-size:90%;">39.6</span></td>
<td id="S6.T4.4.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.4.4.6.1" class="ltx_text" style="font-size:90%;">31.2</span></td>
</tr>
<tr id="S6.T4.5.5" class="ltx_tr">
<th id="S6.T4.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S6.T4.5.5.1.1" class="ltx_text" style="font-size:90%;">Label-F1 (</span><math id="S6.T4.5.5.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T4.5.5.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T4.5.5.1.m1.1.1" xref="S6.T4.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T4.5.5.1.m1.1b"><ci id="S6.T4.5.5.1.m1.1.1.cmml" xref="S6.T4.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.5.5.1.m1.1c">\uparrow</annotation></semantics></math><span id="S6.T4.5.5.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T4.5.5.2" class="ltx_td ltx_align_center"><span id="S6.T4.5.5.2.1" class="ltx_text" style="font-size:90%;">76.8</span></td>
<td id="S6.T4.5.5.3" class="ltx_td ltx_align_center"><span id="S6.T4.5.5.3.1" class="ltx_text" style="font-size:90%;">77.1</span></td>
<td id="S6.T4.5.5.4" class="ltx_td ltx_align_center"><span id="S6.T4.5.5.4.1" class="ltx_text" style="font-size:90%;">78.3</span></td>
<td id="S6.T4.5.5.5" class="ltx_td ltx_align_center"><span id="S6.T4.5.5.5.1" class="ltx_text" style="font-size:90%;">78.4</span></td>
</tr>
<tr id="S6.T4.6.6" class="ltx_tr">
<th id="S6.T4.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S6.T4.6.6.1.1" class="ltx_text" style="font-size:90%;">WER (</span><math id="S6.T4.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T4.6.6.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S6.T4.6.6.1.m1.1.1" xref="S6.T4.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T4.6.6.1.m1.1b"><ci id="S6.T4.6.6.1.m1.1.1.cmml" xref="S6.T4.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.6.6.1.m1.1c">\downarrow</annotation></semantics></math><span id="S6.T4.6.6.1.2" class="ltx_text" style="font-size:90%;">)</span>
</th>
<td id="S6.T4.6.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T4.6.6.2.1" class="ltx_text" style="font-size:90%;">13.3</span></td>
<td id="S6.T4.6.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T4.6.6.3.1" class="ltx_text" style="font-size:90%;">10.5</span></td>
<td id="S6.T4.6.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T4.6.6.4.1" class="ltx_text" style="font-size:90%;">14.5</span></td>
<td id="S6.T4.6.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T4.6.6.5.1" class="ltx_text" style="font-size:90%;">18.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Provided baselines on the annotated test sets for a pipeline ASR/NER model and an end-to-end multitask model. Both models were fine-tuned on SLUE-VoxPopuli <cite class="ltx_cite ltx_citemacro_cite">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite></figcaption>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">7.   Conclusion</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">In this manuscript, we have presented MSNER, a new dataset for evaluating multilingual Spoken NER systems. Although NER is a popular topic in NLP, this task has remained mostly unexplored in speech processing and spoken language understanding. To address this issue, we have used a pretrained model to annotate the VoxPopuli training and validation subsets in Dutch, French, German, and Spanish. Additionally, to provide researcher with a gold standard dataset for evaluating their Spoken NER models, the authors have manually annotated the test sets for these subsets. By analyzing the predictions of a text-based NER model, and comparing them with our annotations, we were able to identify points of attentions for researchers who intend to train a model on silver annotations. For example, in some cases, the model confidence on the predictions can serve as a basis to estimate the correctness of the prediction, but this must be done carefully, since we have seen that transformers can be overconfident. Counter-intuitively, we have shown that most frequent classes are not always the ones where the model’s uncertainty is most reliable. We also looked at the classes that were often confused with one another, which gave us some ideas about which errors might be present in the training and validation sets.</p>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p id="S7.p2.1" class="ltx_p">We also provide baselines on the newly annotated evaluation subsets. We selected a pipeline and an end-to-end SLU model, both fine-tuned on English SLUE VoxPopuli <cite class="ltx_cite ltx_citemacro_cite">Shon et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>, and we evaluate them on the manually annotated test sets. We saw that in a low resource scenario, the end-to-end model seems to benefit from learning simultaneously to transcribe and to annotate, which allows a better generalization across languages than the pipeline model fine-tuned on the same dataset. Finally, we found that the performance of text-based models on unseen languages is correlated with the similarity of the evaluation language with English. However, for speech models, this is the multilingual transcription accuracy that is the main driver for NER performance. Interestingly, we have seen that the end-to-end model was able to identify the presence of entities much better than the pipeline model, despite a similar overall performance, which illustrate the advantage of sharing parameters across tasks.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">8.   Acknowledgements</h2>

<div id="S8.p1" class="ltx_para ltx_noindent">
<p id="S8.p1.1" class="ltx_p">This research received funding from the Flemish Government under the “Onderzoeksprogramma Artificiele Intelligentie (AI) Vlaanderen” programme.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">9.   Bibliographical References</h2>

<div id="S9.p1" class="ltx_para">
<span id="S9.p1.1" class="ltx_ERROR undefined">\c@NAT@ctr</span>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography"></h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bastianelli et al. (2020)</span>
<span class="ltx_bibblock">
Emanuele Bastianelli, Andrea Vanzo, Pawel Swietojanski, and Verena Rieser.
2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.588" title="" class="ltx_ref ltx_href">SLURP: A
spoken language understanding resource package</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benikova et al. (2014)</span>
<span class="ltx_bibblock">
Darina Benikova, Chris Biemann, and Marc Reznicek. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2014/pdf/276_Paper.pdf" title="" class="ltx_ref ltx_href">NoSta-D named entity annotation for German: Guidelines and dataset</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Ninth International Conference on
Language Resources and Evaluation (LREC’14)</em>, pages 2524–2531, Reykjavik,
Iceland. European Language Resources Association (ELRA).

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2019)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer,
and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1911.02116.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crichton et al. (2017)</span>
<span class="ltx_bibblock">
Gamal Crichton, Sampo Pyysalo, Billy Chiu, and Anna Korhonen. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1186/s12859-017-1776-8" title="" class="ltx_ref ltx_href">A neural network
multi-task learning approach to biomedical named entity recognition</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">BMC Bioinformatics</em>, 18.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hemphill et al. (1990)</span>
<span class="ltx_bibblock">
Charles T. Hemphill, John J. Godfrey, and George R. Doddington. 1990.

</span>
<span class="ltx_bibblock">The ATIS spoken language systems pilot corpus.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Speech and Natural Language: Proceedings of a Workshop Held
at Hidden Valley, Pennsylvania</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lafferty et al. (2001)</span>
<span class="ltx_bibblock">
John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001.

</span>
<span class="ltx_bibblock">Conditional random fields: Probabilistic models for segmenting and
labeling sequence data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighteenth International Conference on
Machine Learning</em>, ICML. Morgan Kaufmann Publishers Inc.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lugosch et al. (2021)</span>
<span class="ltx_bibblock">
Loren Lugosch, Piyush Papreja, Mirco Ravanelli, Abdelwahab Heba, and Titouan
Parcollet. 2021.

</span>
<span class="ltx_bibblock">Timers and such: A practical benchmark for spoken language
understanding with numbers.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2104.01604.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lugosch et al. (2019)</span>
<span class="ltx_bibblock">
Loren Lugosch, Mirco Ravanelli, Patrick Ignoto, Vikrant Singh Tomar, and Yoshua
Bengio. 2019.

</span>
<span class="ltx_bibblock">Speech Model Pre-Training for End-to-End Spoken Language
Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maekawa (2018)</span>
<span class="ltx_bibblock">
Emi Maekawa. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www2.nict.go.jp/astrec-att/member/mutiyama/ALT/AnotGuideEnNE.pdf" title="" class="ltx_ref ltx_href">Annotation guidelines for named entities</a>.

</span>
<span class="ltx_bibblock">online.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meeus et al. (2023)</span>
<span class="ltx_bibblock">
Quentin Meeus, Marie-Francine Moens, and Hugo Van Hamme. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/ASRU57964.2023.10389786" title="" class="ltx_ref ltx_href">Whisper-slu:
Extending a pretrained speech-to-text transformer for low resource spoken
language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">2023 IEEE Automatic Speech Recognition and Understanding
Workshop (ASRU)</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2022)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and
Ilya Sutskever. 2022.

</span>
<span class="ltx_bibblock">Robust speech recognition via large-scale weak supervision.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">CoRR</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramshaw and Marcus (1995)</span>
<span class="ltx_bibblock">
Lance Ramshaw and Mitch Marcus. 1995.

</span>
<span class="ltx_bibblock">Text chunking using transformation-based learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Third Workshop on Very Large Corpora</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Renkens and Van hamme (2018)</span>
<span class="ltx_bibblock">
Vincent Renkens and Hugo Van hamme. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2018-1013" title="" class="ltx_ref ltx_href">Capsule
networks for low resource spoken language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>. International Speech Communication
Association.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saade et al. (2018)</span>
<span class="ltx_bibblock">
Alaa Saade, Alice Coucke, Alexandre Caulier, Joseph Dureau, Adrien Ball,
Théodore Bluche, David Leroy, Clément Doumouro, Thibault Gisselbrecht,
Francesco Caltagirone, Thibaut Lavril, and Mael Primet. 2018.

</span>
<span class="ltx_bibblock">Spoken language understanding on the edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">CoRR</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shon et al. (2021)</span>
<span class="ltx_bibblock">
Suwon Shon, Ankita Pasad, Felix Wu, Pablo Brusco, Yoav Artzi, Karen Livescu,
and Kyu J. Han. 2021.

</span>
<span class="ltx_bibblock">SLUE: new benchmark tasks for spoken language understanding
evaluation on natural speech.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">CoRR</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tedeschi et al. (2021)</span>
<span class="ltx_bibblock">
Simone Tedeschi, Simone Conia, Francesco Cecconi, and Roberto Navigli. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.findings-emnlp.220" title="" class="ltx_ref ltx_href">Named
entity recognition for entity linking: What works and what’s next</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tedeschi and Navigli (2022)</span>
<span class="ltx_bibblock">
Simone Tedeschi and Roberto Navigli. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.findings-naacl.60" title="" class="ltx_ref ltx_href">MultiNERD: A multilingual, multi-genre and fine-grained dataset for
named entity recognition (and disambiguation)</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
NAACL 2022</em>, Seattle, United States. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tjong Kim Sang and De Meulder (2003)</span>
<span class="ltx_bibblock">
Erik F. Tjong Kim Sang and Fien De Meulder. 2003.

</span>
<span class="ltx_bibblock">Introduction to the CoNLL-2003 shared task: Language-independent
named entity recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Conference on Natural Language
Learning at HLT-NAACL 2003</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ushio and Camacho-Collados (2021)</span>
<span class="ltx_bibblock">
Asahi Ushio and Jose Camacho-Collados. 2021.

</span>
<span class="ltx_bibblock">T-NER: An all-round python library for transformer-based named
entity recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th Conference of the European Chapter
of the Association for Computational Linguistics: System Demonstrations</em>.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Uzuner et al. (2010)</span>
<span class="ltx_bibblock">
Özlem Uzuner, Imre Solti, Fei Xia, and Eithon Cadag. 2010.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1136/jamia.2010.004200" title="" class="ltx_ref ltx_href">Community
annotation experiment for ground truth generation for the i2b2 medication
challenge</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics Association</em>,
17(5).

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021)</span>
<span class="ltx_bibblock">
Changhan Wang, Morgane Riviere, Ann Lee, Anne Wu, Chaitanya Talnikar, Daniel
Haziza, Mary Williamson, Juan Pino, and Emmanuel Dupoux. 2021.

</span>
<span class="ltx_bibblock">VoxPopuli: A large-scale multilingual speech corpus for
representation learning, semi-supervised learning and interpretation.

</span>
<span class="ltx_bibblock">Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et al. (2020)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe
Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander Rush. 2020.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>. ACL.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2023)</span>
<span class="ltx_bibblock">
Wenqian Ye, Yunsheng Ma, Xu Cao, and Kun Tang. 2023.

</span>
<span class="ltx_bibblock">Mitigating transformer overconfidence via Lipschitz regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirty-Ninth Conference on Uncertainty in
Artificial Intelligence</em>, volume 216 of <em id="bib.bib23.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning
Research</em>, pages 2422–2432. PMLR.

</span>
</li>
</ul>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">10.   Language Resource References</h2>

<div id="S10.p1" class="ltx_para">
<span id="S10.p1.1" class="ltx_ERROR undefined">\c@NAT@ctr</span>
</div>
</section>
<section id="biba" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography"> </h2>

<ul class="ltx_biblist">
<li id="biba.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weischedel et al. (2013)</span>
<span class="ltx_bibblock">
Ralph Weischedel and Martha Palmer and Mitchell Marcus and Eduard Hovy and
Sameer Pradhan and Lance Ramshaw and Nianwen Xue and Ann Taylor and Jeff
Kaufman and Michelle Franchini and Mohammed El-Bachouti and Robert Belvin and
Ann Houston. 2013.

</span>
<span class="ltx_bibblock"><em id="biba.bib1.1.1" class="ltx_emph ltx_font_italic">OntoNotes Release 5.0</em>.

</span>
<span class="ltx_bibblock">Linguistic Data Consortium LDC2013T19, ISLRN 151-738-649-048-2.

</span>
</li>
</ul>
</section>
<div id="p3" class="ltx_para ltx_noindent">
<p id="p3.1" class="ltx_p"></p>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.11518" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.11519" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.11519">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.11519" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.11520" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 18:41:57 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
