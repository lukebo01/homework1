<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.08805] Exploring SSL Discrete Tokens for Multilingual ASR</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Exploring SSL Discrete Tokens for Multilingual ASR">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Exploring SSL Discrete Tokens for Multilingual ASR">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.08805">

<!--Generated on Sat Oct  5 18:12:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Self-supervised Learning,  Discrete Tokens,  Multilingual Speech Recognition
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Exploring SSL Discrete Tokens for Multilingual ASR
<br class="ltx_break">
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Mingyu Cui<sup id="13.13.1" class="ltx_sup"><span id="13.13.1.1" class="ltx_text ltx_font_italic">1†</span></sup>, Daxin Tan<sup id="14.14.2" class="ltx_sup"><span id="14.14.2.1" class="ltx_text ltx_font_italic">3</span></sup>, Yifan Yang<sup id="15.15.3" class="ltx_sup"><span id="15.15.3.1" class="ltx_text ltx_font_italic">2</span></sup>, Dingdong Wang<sup id="16.16.4" class="ltx_sup"><span id="16.16.4.1" class="ltx_text ltx_font_italic">1</span></sup>, Huimeng Wang<sup id="17.17.5" class="ltx_sup"><span id="17.17.5.1" class="ltx_text ltx_font_italic">1</span></sup>, 
<br class="ltx_break">Xiao Chen<sup id="18.18.6" class="ltx_sup"><span id="18.18.6.1" class="ltx_text ltx_font_italic">3</span></sup>, Xie Chen<sup id="19.19.7" class="ltx_sup"><span id="19.19.7.1" class="ltx_text ltx_font_italic">2</span></sup>, Xunying Liu<sup id="20.20.8" class="ltx_sup"><span id="20.20.8.1" class="ltx_text ltx_font_italic">1</span></sup>
</span><span class="ltx_author_notes"><sup id="21.21.1" class="ltx_sup"><span id="21.21.1.1" class="ltx_text ltx_font_italic">†</span></sup>Work done during an internship at Noah’s Ark Lab
<span class="ltx_contact ltx_role_affiliation"><sup id="22.22.3" class="ltx_sup"><span id="22.22.3.1" class="ltx_text ltx_font_italic">1</span></sup><span id="id12.12.2" class="ltx_text ltx_font_italic">System Engineering and Engineering Management, The Chinese University of Hong Kong, China
<br class="ltx_break"><sup id="id12.12.2.1" class="ltx_sup">2</sup>MoE Key Lab of Artificial Intelligence, X-LANCE Lab, Shanghai Jiao Tong University
<br class="ltx_break"><sup id="id12.12.2.2" class="ltx_sup">3</sup>Noah’s Ark Lab, Hong Kong SAR, China</span>
</span></span></span>
</div>

<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Self-supervised Learning, Discrete Tokens, Multilingual Speech Recognition

</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">With the advancement of Self-supervised Learning (SSL) in speech-related tasks, there has been growing interest in utilizing discrete tokens generated by SSL for automatic speech recognition (ASR), as they offer faster processing techniques. However, previous studies primarily focused on multilingual ASR with Fbank features or English ASR with discrete tokens, leaving a gap in adapting discrete tokens for multilingual ASR scenarios. This study presents a comprehensive comparison of discrete tokens generated by various leading SSL models across multiple language domains. We aim to explore the performance and efficiency of speech discrete tokens across multiple language domains for both monolingual and multilingual ASR scenarios. Experimental results demonstrate that discrete tokens achieve comparable results against systems trained on Fbank features in ASR tasks across seven language domains with an average word error rate (WER) reduction of 0.31% and 1.76% absolute (2.80% and 15.70% relative) on dev and test sets respectively, with particularly WER reduction of 6.82% absolute (41.48% relative) on the Polish test set.</p>
</div>
<figure id="S0.F1" class="ltx_figure">
<p id="S0.F1.1" class="ltx_p ltx_align_center"><span id="S0.F1.1.1" class="ltx_text"><img src="/html/2409.08805/assets/x1.png" id="S0.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="118" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of the pipeline for discrete speech tokenization, showcasing how a waveform is transformed into discrete tokens. This is achieved either through k-means clustering of XLSR-53/WavLM-Large representations or directly via EnCodec-24kHz quantization</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Self-supervised learning (SSL) based speech foundation models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, constructed using large quantities of unlabelled data, have emerged as a powerful paradigm for many downstream speech processing tasks, including automatic speech recognition (ASR). Moreover, discrete tokens generated by SSL models have demonstrated remarkable performance compared to traditional FBank-based models in ASR tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. These tokens can be broadly categorized into two main types: semantic tokens and acoustic tokens. Semantic tokens are typically generated by SSL models employing quantization techniques, including vq-wav2vec<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, wav2vec 2.0<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, HuBERT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, and WavLM<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. These models commonly utilize k-means clustering or Gumbel-Softmax vectorization for quantization and are trained using discrimination tasks or masked prediction objectives. On the other hand, acoustic tokens generated by audio neural codec models like Soundstream<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and EnCodec<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> focus on accurately reconstructing speech and encoding detailed acoustic information.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">SSL discrete speech representations extracted from these models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> are highly adaptable across different task domains including ASR and text-to-speech (TTS) tasks. However, the application of discrete tokens produced by SSL models has predominantly focused on English-related domains, with models such as HuBERT and WavLM demonstrating exceptional performance in English corpora <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. While these studies have laid the groundwork for the utilization of discrete tokens in ASR, their limitation lies in the insufficient exploration of their potential in multilingual scenarios.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In multilingual ASR scenarios, existing research has primarily concentrated on FBank features as input. These approaches, which employ mel-spectral features for direct acoustic modeling, have achieved notable results in multilingual ASR tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. The successful performance of FBank features can be attributed to their ability to capture the special characteristics of speech across diverse acoustic and linguistic environments. However, there has been limited exploration of the effectiveness and potential of discrete tokens in multilingual ASR tasks across a broader range of languages.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The under-exploration of discrete tokens in multilingual ASR presents new challenges and benefits. This situation raises questions about the generalizability of discrete token approaches beyond the English language domain. Simultaneously, the unique properties of discrete tokens, which allow them to capture acoustic and semantic information in a compact form, may offer advantages in modeling the diverse phonetic and prosodic features encountered in multilingual scenarios.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To address these challenges and explore the potential benefits, this study aims to investigate the universality and performance of speech discrete tokens across multiple language domains for both monolingual and multilingual ASR scenarios. As illustrated in Fig. <a href="#S0.F1" title="Figure 1 ‣ Exploring SSL Discrete Tokens for Multilingual ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we convert raw audio into speech discrete tokens using three leading speech foundation models: WavLM-Large, XLSR-53, and EnCodec. We then utilize these discrete tokens to train end-to-end (E2E) ASR models for monolingual and multilingual ASR tasks. To fully explore the properties of discrete tokens, we extensively evaluate the efficacy of replacing Fbank-based features with SSL discrete tokens across seven language domains (German (DE), French (FR), Spanish (ES), Dutch (NL), Italian (IT), Portuguese (PT), and Polish (PL)) using the 6000-hour Multilingual Librispeech corpus. Our experiments cover both monolingual and multilingual ASR tasks. Notably, the best-performing Zipformer-Transducer system using discrete tokens outperforms the Fbank-based baselines with an average word error rate (WER) reduction of 0.31% and 1.76% absolute (2.80% and 15.70% relative) on dev and test sets across the seven languages and shows a remarkable performance with a 6.82% absolute (41.68% relative) WER reduction on the Polish test set.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The main contributions of this paper are summarized as follows:</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">1) To the best of our knowledge, this work pioneers the use of SSL discrete speech tokens for both monolingual and multilingual non-English language scenarios, extending beyond the English-centric focus of prior research.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">2) We comprehensively demonstrate the effectiveness and efficiency of replacing Fbank features with SSL discrete tokens across seven diverse languages, totaling 6000 hours of speech data from the Multilingual Librispeech corpus.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">3) By exploring the properties of discrete tokens in various language contexts, we demonstrate their versatility and robustness, providing valuable insights for developing more inclusive and efficient multilingual ASR systems.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Zipformer-Transducer ASR Architecture</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.11" class="ltx_p">This paper utilizes the neural Transducer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> model to perform speech recognition, which is composed of three modules: audio <span id="S2.p1.11.1" class="ltx_text ltx_font_bold">Encoder</span>, text <span id="S2.p1.11.2" class="ltx_text ltx_font_bold">Predictor</span> and <span id="S2.p1.11.3" class="ltx_text ltx_font_bold">Joint Network</span> respectively, as depicted in Fig. 1. Here we denote <math id="S2.p1.1.m1.4" class="ltx_Math" alttext="\mathbf{{x}}_{1:T_{i}}^{i}=[x^{i}_{1},x^{i}_{2},\cdots,x^{i}_{T_{i}}]" display="inline"><semantics id="S2.p1.1.m1.4a"><mrow id="S2.p1.1.m1.4.4" xref="S2.p1.1.m1.4.4.cmml"><msubsup id="S2.p1.1.m1.4.4.5" xref="S2.p1.1.m1.4.4.5.cmml"><mi id="S2.p1.1.m1.4.4.5.2.2" xref="S2.p1.1.m1.4.4.5.2.2.cmml">𝐱</mi><mrow id="S2.p1.1.m1.4.4.5.2.3" xref="S2.p1.1.m1.4.4.5.2.3.cmml"><mn id="S2.p1.1.m1.4.4.5.2.3.2" xref="S2.p1.1.m1.4.4.5.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.p1.1.m1.4.4.5.2.3.1" xref="S2.p1.1.m1.4.4.5.2.3.1.cmml">:</mo><msub id="S2.p1.1.m1.4.4.5.2.3.3" xref="S2.p1.1.m1.4.4.5.2.3.3.cmml"><mi id="S2.p1.1.m1.4.4.5.2.3.3.2" xref="S2.p1.1.m1.4.4.5.2.3.3.2.cmml">T</mi><mi id="S2.p1.1.m1.4.4.5.2.3.3.3" xref="S2.p1.1.m1.4.4.5.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S2.p1.1.m1.4.4.5.3" xref="S2.p1.1.m1.4.4.5.3.cmml">i</mi></msubsup><mo id="S2.p1.1.m1.4.4.4" xref="S2.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S2.p1.1.m1.4.4.3.3" xref="S2.p1.1.m1.4.4.3.4.cmml"><mo stretchy="false" id="S2.p1.1.m1.4.4.3.3.4" xref="S2.p1.1.m1.4.4.3.4.cmml">[</mo><msubsup id="S2.p1.1.m1.2.2.1.1.1" xref="S2.p1.1.m1.2.2.1.1.1.cmml"><mi id="S2.p1.1.m1.2.2.1.1.1.2.2" xref="S2.p1.1.m1.2.2.1.1.1.2.2.cmml">x</mi><mn id="S2.p1.1.m1.2.2.1.1.1.3" xref="S2.p1.1.m1.2.2.1.1.1.3.cmml">1</mn><mi id="S2.p1.1.m1.2.2.1.1.1.2.3" xref="S2.p1.1.m1.2.2.1.1.1.2.3.cmml">i</mi></msubsup><mo id="S2.p1.1.m1.4.4.3.3.5" xref="S2.p1.1.m1.4.4.3.4.cmml">,</mo><msubsup id="S2.p1.1.m1.3.3.2.2.2" xref="S2.p1.1.m1.3.3.2.2.2.cmml"><mi id="S2.p1.1.m1.3.3.2.2.2.2.2" xref="S2.p1.1.m1.3.3.2.2.2.2.2.cmml">x</mi><mn id="S2.p1.1.m1.3.3.2.2.2.3" xref="S2.p1.1.m1.3.3.2.2.2.3.cmml">2</mn><mi id="S2.p1.1.m1.3.3.2.2.2.2.3" xref="S2.p1.1.m1.3.3.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S2.p1.1.m1.4.4.3.3.6" xref="S2.p1.1.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">⋯</mi><mo id="S2.p1.1.m1.4.4.3.3.7" xref="S2.p1.1.m1.4.4.3.4.cmml">,</mo><msubsup id="S2.p1.1.m1.4.4.3.3.3" xref="S2.p1.1.m1.4.4.3.3.3.cmml"><mi id="S2.p1.1.m1.4.4.3.3.3.2.2" xref="S2.p1.1.m1.4.4.3.3.3.2.2.cmml">x</mi><msub id="S2.p1.1.m1.4.4.3.3.3.3" xref="S2.p1.1.m1.4.4.3.3.3.3.cmml"><mi id="S2.p1.1.m1.4.4.3.3.3.3.2" xref="S2.p1.1.m1.4.4.3.3.3.3.2.cmml">T</mi><mi id="S2.p1.1.m1.4.4.3.3.3.3.3" xref="S2.p1.1.m1.4.4.3.3.3.3.3.cmml">i</mi></msub><mi id="S2.p1.1.m1.4.4.3.3.3.2.3" xref="S2.p1.1.m1.4.4.3.3.3.2.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.p1.1.m1.4.4.3.3.8" xref="S2.p1.1.m1.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.4b"><apply id="S2.p1.1.m1.4.4.cmml" xref="S2.p1.1.m1.4.4"><eq id="S2.p1.1.m1.4.4.4.cmml" xref="S2.p1.1.m1.4.4.4"></eq><apply id="S2.p1.1.m1.4.4.5.cmml" xref="S2.p1.1.m1.4.4.5"><csymbol cd="ambiguous" id="S2.p1.1.m1.4.4.5.1.cmml" xref="S2.p1.1.m1.4.4.5">superscript</csymbol><apply id="S2.p1.1.m1.4.4.5.2.cmml" xref="S2.p1.1.m1.4.4.5"><csymbol cd="ambiguous" id="S2.p1.1.m1.4.4.5.2.1.cmml" xref="S2.p1.1.m1.4.4.5">subscript</csymbol><ci id="S2.p1.1.m1.4.4.5.2.2.cmml" xref="S2.p1.1.m1.4.4.5.2.2">𝐱</ci><apply id="S2.p1.1.m1.4.4.5.2.3.cmml" xref="S2.p1.1.m1.4.4.5.2.3"><ci id="S2.p1.1.m1.4.4.5.2.3.1.cmml" xref="S2.p1.1.m1.4.4.5.2.3.1">:</ci><cn type="integer" id="S2.p1.1.m1.4.4.5.2.3.2.cmml" xref="S2.p1.1.m1.4.4.5.2.3.2">1</cn><apply id="S2.p1.1.m1.4.4.5.2.3.3.cmml" xref="S2.p1.1.m1.4.4.5.2.3.3"><csymbol cd="ambiguous" id="S2.p1.1.m1.4.4.5.2.3.3.1.cmml" xref="S2.p1.1.m1.4.4.5.2.3.3">subscript</csymbol><ci id="S2.p1.1.m1.4.4.5.2.3.3.2.cmml" xref="S2.p1.1.m1.4.4.5.2.3.3.2">𝑇</ci><ci id="S2.p1.1.m1.4.4.5.2.3.3.3.cmml" xref="S2.p1.1.m1.4.4.5.2.3.3.3">𝑖</ci></apply></apply></apply><ci id="S2.p1.1.m1.4.4.5.3.cmml" xref="S2.p1.1.m1.4.4.5.3">𝑖</ci></apply><list id="S2.p1.1.m1.4.4.3.4.cmml" xref="S2.p1.1.m1.4.4.3.3"><apply id="S2.p1.1.m1.2.2.1.1.1.cmml" xref="S2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S2.p1.1.m1.2.2.1.1.1">subscript</csymbol><apply id="S2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.2.2.1.1.1.2.1.cmml" xref="S2.p1.1.m1.2.2.1.1.1">superscript</csymbol><ci id="S2.p1.1.m1.2.2.1.1.1.2.2.cmml" xref="S2.p1.1.m1.2.2.1.1.1.2.2">𝑥</ci><ci id="S2.p1.1.m1.2.2.1.1.1.2.3.cmml" xref="S2.p1.1.m1.2.2.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S2.p1.1.m1.2.2.1.1.1.3.cmml" xref="S2.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S2.p1.1.m1.3.3.2.2.2.cmml" xref="S2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S2.p1.1.m1.3.3.2.2.2">subscript</csymbol><apply id="S2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.p1.1.m1.3.3.2.2.2.2.1.cmml" xref="S2.p1.1.m1.3.3.2.2.2">superscript</csymbol><ci id="S2.p1.1.m1.3.3.2.2.2.2.2.cmml" xref="S2.p1.1.m1.3.3.2.2.2.2.2">𝑥</ci><ci id="S2.p1.1.m1.3.3.2.2.2.2.3.cmml" xref="S2.p1.1.m1.3.3.2.2.2.2.3">𝑖</ci></apply><cn type="integer" id="S2.p1.1.m1.3.3.2.2.2.3.cmml" xref="S2.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">⋯</ci><apply id="S2.p1.1.m1.4.4.3.3.3.cmml" xref="S2.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.p1.1.m1.4.4.3.3.3.1.cmml" xref="S2.p1.1.m1.4.4.3.3.3">subscript</csymbol><apply id="S2.p1.1.m1.4.4.3.3.3.2.cmml" xref="S2.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.p1.1.m1.4.4.3.3.3.2.1.cmml" xref="S2.p1.1.m1.4.4.3.3.3">superscript</csymbol><ci id="S2.p1.1.m1.4.4.3.3.3.2.2.cmml" xref="S2.p1.1.m1.4.4.3.3.3.2.2">𝑥</ci><ci id="S2.p1.1.m1.4.4.3.3.3.2.3.cmml" xref="S2.p1.1.m1.4.4.3.3.3.2.3">𝑖</ci></apply><apply id="S2.p1.1.m1.4.4.3.3.3.3.cmml" xref="S2.p1.1.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S2.p1.1.m1.4.4.3.3.3.3.1.cmml" xref="S2.p1.1.m1.4.4.3.3.3.3">subscript</csymbol><ci id="S2.p1.1.m1.4.4.3.3.3.3.2.cmml" xref="S2.p1.1.m1.4.4.3.3.3.3.2">𝑇</ci><ci id="S2.p1.1.m1.4.4.3.3.3.3.3.cmml" xref="S2.p1.1.m1.4.4.3.3.3.3.3">𝑖</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.4c">\mathbf{{x}}_{1:T_{i}}^{i}=[x^{i}_{1},x^{i}_{2},\cdots,x^{i}_{T_{i}}]</annotation></semantics></math> of length <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="T_{i}" display="inline"><semantics id="S2.p1.2.m2.1a"><msub id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">T</mi><mi id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">𝑇</ci><ci id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">T_{i}</annotation></semantics></math> as discrete token sequence and <math id="S2.p1.3.m3.4" class="ltx_Math" alttext="\mathbf{y}_{1:U_{i}}^{i}=[\mathbf{y}_{1}^{i},\mathbf{y}_{2}^{i},\cdots,\mathbf{y}_{U_{i}}^{i}]" display="inline"><semantics id="S2.p1.3.m3.4a"><mrow id="S2.p1.3.m3.4.4" xref="S2.p1.3.m3.4.4.cmml"><msubsup id="S2.p1.3.m3.4.4.5" xref="S2.p1.3.m3.4.4.5.cmml"><mi id="S2.p1.3.m3.4.4.5.2.2" xref="S2.p1.3.m3.4.4.5.2.2.cmml">𝐲</mi><mrow id="S2.p1.3.m3.4.4.5.2.3" xref="S2.p1.3.m3.4.4.5.2.3.cmml"><mn id="S2.p1.3.m3.4.4.5.2.3.2" xref="S2.p1.3.m3.4.4.5.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.p1.3.m3.4.4.5.2.3.1" xref="S2.p1.3.m3.4.4.5.2.3.1.cmml">:</mo><msub id="S2.p1.3.m3.4.4.5.2.3.3" xref="S2.p1.3.m3.4.4.5.2.3.3.cmml"><mi id="S2.p1.3.m3.4.4.5.2.3.3.2" xref="S2.p1.3.m3.4.4.5.2.3.3.2.cmml">U</mi><mi id="S2.p1.3.m3.4.4.5.2.3.3.3" xref="S2.p1.3.m3.4.4.5.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S2.p1.3.m3.4.4.5.3" xref="S2.p1.3.m3.4.4.5.3.cmml">i</mi></msubsup><mo id="S2.p1.3.m3.4.4.4" xref="S2.p1.3.m3.4.4.4.cmml">=</mo><mrow id="S2.p1.3.m3.4.4.3.3" xref="S2.p1.3.m3.4.4.3.4.cmml"><mo stretchy="false" id="S2.p1.3.m3.4.4.3.3.4" xref="S2.p1.3.m3.4.4.3.4.cmml">[</mo><msubsup id="S2.p1.3.m3.2.2.1.1.1" xref="S2.p1.3.m3.2.2.1.1.1.cmml"><mi id="S2.p1.3.m3.2.2.1.1.1.2.2" xref="S2.p1.3.m3.2.2.1.1.1.2.2.cmml">𝐲</mi><mn id="S2.p1.3.m3.2.2.1.1.1.2.3" xref="S2.p1.3.m3.2.2.1.1.1.2.3.cmml">1</mn><mi id="S2.p1.3.m3.2.2.1.1.1.3" xref="S2.p1.3.m3.2.2.1.1.1.3.cmml">i</mi></msubsup><mo id="S2.p1.3.m3.4.4.3.3.5" xref="S2.p1.3.m3.4.4.3.4.cmml">,</mo><msubsup id="S2.p1.3.m3.3.3.2.2.2" xref="S2.p1.3.m3.3.3.2.2.2.cmml"><mi id="S2.p1.3.m3.3.3.2.2.2.2.2" xref="S2.p1.3.m3.3.3.2.2.2.2.2.cmml">𝐲</mi><mn id="S2.p1.3.m3.3.3.2.2.2.2.3" xref="S2.p1.3.m3.3.3.2.2.2.2.3.cmml">2</mn><mi id="S2.p1.3.m3.3.3.2.2.2.3" xref="S2.p1.3.m3.3.3.2.2.2.3.cmml">i</mi></msubsup><mo id="S2.p1.3.m3.4.4.3.3.6" xref="S2.p1.3.m3.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">⋯</mi><mo id="S2.p1.3.m3.4.4.3.3.7" xref="S2.p1.3.m3.4.4.3.4.cmml">,</mo><msubsup id="S2.p1.3.m3.4.4.3.3.3" xref="S2.p1.3.m3.4.4.3.3.3.cmml"><mi id="S2.p1.3.m3.4.4.3.3.3.2.2" xref="S2.p1.3.m3.4.4.3.3.3.2.2.cmml">𝐲</mi><msub id="S2.p1.3.m3.4.4.3.3.3.2.3" xref="S2.p1.3.m3.4.4.3.3.3.2.3.cmml"><mi id="S2.p1.3.m3.4.4.3.3.3.2.3.2" xref="S2.p1.3.m3.4.4.3.3.3.2.3.2.cmml">U</mi><mi id="S2.p1.3.m3.4.4.3.3.3.2.3.3" xref="S2.p1.3.m3.4.4.3.3.3.2.3.3.cmml">i</mi></msub><mi id="S2.p1.3.m3.4.4.3.3.3.3" xref="S2.p1.3.m3.4.4.3.3.3.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.p1.3.m3.4.4.3.3.8" xref="S2.p1.3.m3.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.4b"><apply id="S2.p1.3.m3.4.4.cmml" xref="S2.p1.3.m3.4.4"><eq id="S2.p1.3.m3.4.4.4.cmml" xref="S2.p1.3.m3.4.4.4"></eq><apply id="S2.p1.3.m3.4.4.5.cmml" xref="S2.p1.3.m3.4.4.5"><csymbol cd="ambiguous" id="S2.p1.3.m3.4.4.5.1.cmml" xref="S2.p1.3.m3.4.4.5">superscript</csymbol><apply id="S2.p1.3.m3.4.4.5.2.cmml" xref="S2.p1.3.m3.4.4.5"><csymbol cd="ambiguous" id="S2.p1.3.m3.4.4.5.2.1.cmml" xref="S2.p1.3.m3.4.4.5">subscript</csymbol><ci id="S2.p1.3.m3.4.4.5.2.2.cmml" xref="S2.p1.3.m3.4.4.5.2.2">𝐲</ci><apply id="S2.p1.3.m3.4.4.5.2.3.cmml" xref="S2.p1.3.m3.4.4.5.2.3"><ci id="S2.p1.3.m3.4.4.5.2.3.1.cmml" xref="S2.p1.3.m3.4.4.5.2.3.1">:</ci><cn type="integer" id="S2.p1.3.m3.4.4.5.2.3.2.cmml" xref="S2.p1.3.m3.4.4.5.2.3.2">1</cn><apply id="S2.p1.3.m3.4.4.5.2.3.3.cmml" xref="S2.p1.3.m3.4.4.5.2.3.3"><csymbol cd="ambiguous" id="S2.p1.3.m3.4.4.5.2.3.3.1.cmml" xref="S2.p1.3.m3.4.4.5.2.3.3">subscript</csymbol><ci id="S2.p1.3.m3.4.4.5.2.3.3.2.cmml" xref="S2.p1.3.m3.4.4.5.2.3.3.2">𝑈</ci><ci id="S2.p1.3.m3.4.4.5.2.3.3.3.cmml" xref="S2.p1.3.m3.4.4.5.2.3.3.3">𝑖</ci></apply></apply></apply><ci id="S2.p1.3.m3.4.4.5.3.cmml" xref="S2.p1.3.m3.4.4.5.3">𝑖</ci></apply><list id="S2.p1.3.m3.4.4.3.4.cmml" xref="S2.p1.3.m3.4.4.3.3"><apply id="S2.p1.3.m3.2.2.1.1.1.cmml" xref="S2.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p1.3.m3.2.2.1.1.1.1.cmml" xref="S2.p1.3.m3.2.2.1.1.1">superscript</csymbol><apply id="S2.p1.3.m3.2.2.1.1.1.2.cmml" xref="S2.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p1.3.m3.2.2.1.1.1.2.1.cmml" xref="S2.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S2.p1.3.m3.2.2.1.1.1.2.2.cmml" xref="S2.p1.3.m3.2.2.1.1.1.2.2">𝐲</ci><cn type="integer" id="S2.p1.3.m3.2.2.1.1.1.2.3.cmml" xref="S2.p1.3.m3.2.2.1.1.1.2.3">1</cn></apply><ci id="S2.p1.3.m3.2.2.1.1.1.3.cmml" xref="S2.p1.3.m3.2.2.1.1.1.3">𝑖</ci></apply><apply id="S2.p1.3.m3.3.3.2.2.2.cmml" xref="S2.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.p1.3.m3.3.3.2.2.2.1.cmml" xref="S2.p1.3.m3.3.3.2.2.2">superscript</csymbol><apply id="S2.p1.3.m3.3.3.2.2.2.2.cmml" xref="S2.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.p1.3.m3.3.3.2.2.2.2.1.cmml" xref="S2.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.p1.3.m3.3.3.2.2.2.2.2.cmml" xref="S2.p1.3.m3.3.3.2.2.2.2.2">𝐲</ci><cn type="integer" id="S2.p1.3.m3.3.3.2.2.2.2.3.cmml" xref="S2.p1.3.m3.3.3.2.2.2.2.3">2</cn></apply><ci id="S2.p1.3.m3.3.3.2.2.2.3.cmml" xref="S2.p1.3.m3.3.3.2.2.2.3">𝑖</ci></apply><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">⋯</ci><apply id="S2.p1.3.m3.4.4.3.3.3.cmml" xref="S2.p1.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.p1.3.m3.4.4.3.3.3.1.cmml" xref="S2.p1.3.m3.4.4.3.3.3">superscript</csymbol><apply id="S2.p1.3.m3.4.4.3.3.3.2.cmml" xref="S2.p1.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.p1.3.m3.4.4.3.3.3.2.1.cmml" xref="S2.p1.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S2.p1.3.m3.4.4.3.3.3.2.2.cmml" xref="S2.p1.3.m3.4.4.3.3.3.2.2">𝐲</ci><apply id="S2.p1.3.m3.4.4.3.3.3.2.3.cmml" xref="S2.p1.3.m3.4.4.3.3.3.2.3"><csymbol cd="ambiguous" id="S2.p1.3.m3.4.4.3.3.3.2.3.1.cmml" xref="S2.p1.3.m3.4.4.3.3.3.2.3">subscript</csymbol><ci id="S2.p1.3.m3.4.4.3.3.3.2.3.2.cmml" xref="S2.p1.3.m3.4.4.3.3.3.2.3.2">𝑈</ci><ci id="S2.p1.3.m3.4.4.3.3.3.2.3.3.cmml" xref="S2.p1.3.m3.4.4.3.3.3.2.3.3">𝑖</ci></apply></apply><ci id="S2.p1.3.m3.4.4.3.3.3.3.cmml" xref="S2.p1.3.m3.4.4.3.3.3.3">𝑖</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.4c">\mathbf{y}_{1:U_{i}}^{i}=[\mathbf{y}_{1}^{i},\mathbf{y}_{2}^{i},\cdots,\mathbf{y}_{U_{i}}^{i}]</annotation></semantics></math> as the corresponding label of length <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="U_{i}" display="inline"><semantics id="S2.p1.4.m4.1a"><msub id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">U</mi><mi id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">𝑈</ci><ci id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">U_{i}</annotation></semantics></math>. Note that each element in the discrete token sequence <math id="S2.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{{x}}_{1:T_{i}}^{i}" display="inline"><semantics id="S2.p1.5.m5.1a"><msubsup id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml"><mi id="S2.p1.5.m5.1.1.2.2" xref="S2.p1.5.m5.1.1.2.2.cmml">𝐱</mi><mrow id="S2.p1.5.m5.1.1.2.3" xref="S2.p1.5.m5.1.1.2.3.cmml"><mn id="S2.p1.5.m5.1.1.2.3.2" xref="S2.p1.5.m5.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.p1.5.m5.1.1.2.3.1" xref="S2.p1.5.m5.1.1.2.3.1.cmml">:</mo><msub id="S2.p1.5.m5.1.1.2.3.3" xref="S2.p1.5.m5.1.1.2.3.3.cmml"><mi id="S2.p1.5.m5.1.1.2.3.3.2" xref="S2.p1.5.m5.1.1.2.3.3.2.cmml">T</mi><mi id="S2.p1.5.m5.1.1.2.3.3.3" xref="S2.p1.5.m5.1.1.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.1.cmml" xref="S2.p1.5.m5.1.1">superscript</csymbol><apply id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.2.1.cmml" xref="S2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.p1.5.m5.1.1.2.2.cmml" xref="S2.p1.5.m5.1.1.2.2">𝐱</ci><apply id="S2.p1.5.m5.1.1.2.3.cmml" xref="S2.p1.5.m5.1.1.2.3"><ci id="S2.p1.5.m5.1.1.2.3.1.cmml" xref="S2.p1.5.m5.1.1.2.3.1">:</ci><cn type="integer" id="S2.p1.5.m5.1.1.2.3.2.cmml" xref="S2.p1.5.m5.1.1.2.3.2">1</cn><apply id="S2.p1.5.m5.1.1.2.3.3.cmml" xref="S2.p1.5.m5.1.1.2.3.3"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.2.3.3.1.cmml" xref="S2.p1.5.m5.1.1.2.3.3">subscript</csymbol><ci id="S2.p1.5.m5.1.1.2.3.3.2.cmml" xref="S2.p1.5.m5.1.1.2.3.3.2">𝑇</ci><ci id="S2.p1.5.m5.1.1.2.3.3.3.cmml" xref="S2.p1.5.m5.1.1.2.3.3.3">𝑖</ci></apply></apply></apply><ci id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">\mathbf{{x}}_{1:T_{i}}^{i}</annotation></semantics></math> is an integer (codebook index) rather than a vector. Then it is fed into the encoder to produce the acoustic representation <math id="S2.p1.6.m6.1" class="ltx_Math" alttext="\mathbf{{h}}_{1:{T_{i}}}^{i}" display="inline"><semantics id="S2.p1.6.m6.1a"><msubsup id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2.2" xref="S2.p1.6.m6.1.1.2.2.cmml">𝐡</mi><mrow id="S2.p1.6.m6.1.1.2.3" xref="S2.p1.6.m6.1.1.2.3.cmml"><mn id="S2.p1.6.m6.1.1.2.3.2" xref="S2.p1.6.m6.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.p1.6.m6.1.1.2.3.1" xref="S2.p1.6.m6.1.1.2.3.1.cmml">:</mo><msub id="S2.p1.6.m6.1.1.2.3.3" xref="S2.p1.6.m6.1.1.2.3.3.cmml"><mi id="S2.p1.6.m6.1.1.2.3.3.2" xref="S2.p1.6.m6.1.1.2.3.3.2.cmml">T</mi><mi id="S2.p1.6.m6.1.1.2.3.3.3" xref="S2.p1.6.m6.1.1.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">superscript</csymbol><apply id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.2.1.cmml" xref="S2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.p1.6.m6.1.1.2.2.cmml" xref="S2.p1.6.m6.1.1.2.2">𝐡</ci><apply id="S2.p1.6.m6.1.1.2.3.cmml" xref="S2.p1.6.m6.1.1.2.3"><ci id="S2.p1.6.m6.1.1.2.3.1.cmml" xref="S2.p1.6.m6.1.1.2.3.1">:</ci><cn type="integer" id="S2.p1.6.m6.1.1.2.3.2.cmml" xref="S2.p1.6.m6.1.1.2.3.2">1</cn><apply id="S2.p1.6.m6.1.1.2.3.3.cmml" xref="S2.p1.6.m6.1.1.2.3.3"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.2.3.3.1.cmml" xref="S2.p1.6.m6.1.1.2.3.3">subscript</csymbol><ci id="S2.p1.6.m6.1.1.2.3.3.2.cmml" xref="S2.p1.6.m6.1.1.2.3.3.2">𝑇</ci><ci id="S2.p1.6.m6.1.1.2.3.3.3.cmml" xref="S2.p1.6.m6.1.1.2.3.3.3">𝑖</ci></apply></apply></apply><ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">\mathbf{{h}}_{1:{T_{i}}}^{i}</annotation></semantics></math>. The history output labels <math id="S2.p1.7.m7.1" class="ltx_Math" alttext="\mathbf{{y}}_{1:u-1}^{i}" display="inline"><semantics id="S2.p1.7.m7.1a"><msubsup id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml"><mi id="S2.p1.7.m7.1.1.2.2" xref="S2.p1.7.m7.1.1.2.2.cmml">𝐲</mi><mrow id="S2.p1.7.m7.1.1.2.3" xref="S2.p1.7.m7.1.1.2.3.cmml"><mn id="S2.p1.7.m7.1.1.2.3.2" xref="S2.p1.7.m7.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.p1.7.m7.1.1.2.3.1" xref="S2.p1.7.m7.1.1.2.3.1.cmml">:</mo><mrow id="S2.p1.7.m7.1.1.2.3.3" xref="S2.p1.7.m7.1.1.2.3.3.cmml"><mi id="S2.p1.7.m7.1.1.2.3.3.2" xref="S2.p1.7.m7.1.1.2.3.3.2.cmml">u</mi><mo id="S2.p1.7.m7.1.1.2.3.3.1" xref="S2.p1.7.m7.1.1.2.3.3.1.cmml">−</mo><mn id="S2.p1.7.m7.1.1.2.3.3.3" xref="S2.p1.7.m7.1.1.2.3.3.3.cmml">1</mn></mrow></mrow><mi id="S2.p1.7.m7.1.1.3" xref="S2.p1.7.m7.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><apply id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.p1.7.m7.1.1.1.cmml" xref="S2.p1.7.m7.1.1">superscript</csymbol><apply id="S2.p1.7.m7.1.1.2.cmml" xref="S2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.p1.7.m7.1.1.2.1.cmml" xref="S2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.p1.7.m7.1.1.2.2.cmml" xref="S2.p1.7.m7.1.1.2.2">𝐲</ci><apply id="S2.p1.7.m7.1.1.2.3.cmml" xref="S2.p1.7.m7.1.1.2.3"><ci id="S2.p1.7.m7.1.1.2.3.1.cmml" xref="S2.p1.7.m7.1.1.2.3.1">:</ci><cn type="integer" id="S2.p1.7.m7.1.1.2.3.2.cmml" xref="S2.p1.7.m7.1.1.2.3.2">1</cn><apply id="S2.p1.7.m7.1.1.2.3.3.cmml" xref="S2.p1.7.m7.1.1.2.3.3"><minus id="S2.p1.7.m7.1.1.2.3.3.1.cmml" xref="S2.p1.7.m7.1.1.2.3.3.1"></minus><ci id="S2.p1.7.m7.1.1.2.3.3.2.cmml" xref="S2.p1.7.m7.1.1.2.3.3.2">𝑢</ci><cn type="integer" id="S2.p1.7.m7.1.1.2.3.3.3.cmml" xref="S2.p1.7.m7.1.1.2.3.3.3">1</cn></apply></apply></apply><ci id="S2.p1.7.m7.1.1.3.cmml" xref="S2.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">\mathbf{{y}}_{1:u-1}^{i}</annotation></semantics></math> are fed into the predictor module to generate the text representation <math id="S2.p1.8.m8.1" class="ltx_Math" alttext="\mathbf{f}_{u-1}^{i}" display="inline"><semantics id="S2.p1.8.m8.1a"><msubsup id="S2.p1.8.m8.1.1" xref="S2.p1.8.m8.1.1.cmml"><mi id="S2.p1.8.m8.1.1.2.2" xref="S2.p1.8.m8.1.1.2.2.cmml">𝐟</mi><mrow id="S2.p1.8.m8.1.1.2.3" xref="S2.p1.8.m8.1.1.2.3.cmml"><mi id="S2.p1.8.m8.1.1.2.3.2" xref="S2.p1.8.m8.1.1.2.3.2.cmml">u</mi><mo id="S2.p1.8.m8.1.1.2.3.1" xref="S2.p1.8.m8.1.1.2.3.1.cmml">−</mo><mn id="S2.p1.8.m8.1.1.2.3.3" xref="S2.p1.8.m8.1.1.2.3.3.cmml">1</mn></mrow><mi id="S2.p1.8.m8.1.1.3" xref="S2.p1.8.m8.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.1b"><apply id="S2.p1.8.m8.1.1.cmml" xref="S2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p1.8.m8.1.1.1.cmml" xref="S2.p1.8.m8.1.1">superscript</csymbol><apply id="S2.p1.8.m8.1.1.2.cmml" xref="S2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p1.8.m8.1.1.2.1.cmml" xref="S2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.p1.8.m8.1.1.2.2.cmml" xref="S2.p1.8.m8.1.1.2.2">𝐟</ci><apply id="S2.p1.8.m8.1.1.2.3.cmml" xref="S2.p1.8.m8.1.1.2.3"><minus id="S2.p1.8.m8.1.1.2.3.1.cmml" xref="S2.p1.8.m8.1.1.2.3.1"></minus><ci id="S2.p1.8.m8.1.1.2.3.2.cmml" xref="S2.p1.8.m8.1.1.2.3.2">𝑢</ci><cn type="integer" id="S2.p1.8.m8.1.1.2.3.3.cmml" xref="S2.p1.8.m8.1.1.2.3.3">1</cn></apply></apply><ci id="S2.p1.8.m8.1.1.3.cmml" xref="S2.p1.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.1c">\mathbf{f}_{u-1}^{i}</annotation></semantics></math>. The outputs of the encoder and predictor are then combined in the Joint Network via a non-linear function such as ReLU to obtain the hidden state <math id="S2.p1.9.m9.2" class="ltx_Math" alttext="\mathbf{g}_{t,u-1}^{i}" display="inline"><semantics id="S2.p1.9.m9.2a"><msubsup id="S2.p1.9.m9.2.3" xref="S2.p1.9.m9.2.3.cmml"><mi id="S2.p1.9.m9.2.3.2.2" xref="S2.p1.9.m9.2.3.2.2.cmml">𝐠</mi><mrow id="S2.p1.9.m9.2.2.2.2" xref="S2.p1.9.m9.2.2.2.3.cmml"><mi id="S2.p1.9.m9.1.1.1.1" xref="S2.p1.9.m9.1.1.1.1.cmml">t</mi><mo id="S2.p1.9.m9.2.2.2.2.2" xref="S2.p1.9.m9.2.2.2.3.cmml">,</mo><mrow id="S2.p1.9.m9.2.2.2.2.1" xref="S2.p1.9.m9.2.2.2.2.1.cmml"><mi id="S2.p1.9.m9.2.2.2.2.1.2" xref="S2.p1.9.m9.2.2.2.2.1.2.cmml">u</mi><mo id="S2.p1.9.m9.2.2.2.2.1.1" xref="S2.p1.9.m9.2.2.2.2.1.1.cmml">−</mo><mn id="S2.p1.9.m9.2.2.2.2.1.3" xref="S2.p1.9.m9.2.2.2.2.1.3.cmml">1</mn></mrow></mrow><mi id="S2.p1.9.m9.2.3.3" xref="S2.p1.9.m9.2.3.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.2b"><apply id="S2.p1.9.m9.2.3.cmml" xref="S2.p1.9.m9.2.3"><csymbol cd="ambiguous" id="S2.p1.9.m9.2.3.1.cmml" xref="S2.p1.9.m9.2.3">superscript</csymbol><apply id="S2.p1.9.m9.2.3.2.cmml" xref="S2.p1.9.m9.2.3"><csymbol cd="ambiguous" id="S2.p1.9.m9.2.3.2.1.cmml" xref="S2.p1.9.m9.2.3">subscript</csymbol><ci id="S2.p1.9.m9.2.3.2.2.cmml" xref="S2.p1.9.m9.2.3.2.2">𝐠</ci><list id="S2.p1.9.m9.2.2.2.3.cmml" xref="S2.p1.9.m9.2.2.2.2"><ci id="S2.p1.9.m9.1.1.1.1.cmml" xref="S2.p1.9.m9.1.1.1.1">𝑡</ci><apply id="S2.p1.9.m9.2.2.2.2.1.cmml" xref="S2.p1.9.m9.2.2.2.2.1"><minus id="S2.p1.9.m9.2.2.2.2.1.1.cmml" xref="S2.p1.9.m9.2.2.2.2.1.1"></minus><ci id="S2.p1.9.m9.2.2.2.2.1.2.cmml" xref="S2.p1.9.m9.2.2.2.2.1.2">𝑢</ci><cn type="integer" id="S2.p1.9.m9.2.2.2.2.1.3.cmml" xref="S2.p1.9.m9.2.2.2.2.1.3">1</cn></apply></list></apply><ci id="S2.p1.9.m9.2.3.3.cmml" xref="S2.p1.9.m9.2.3.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.2c">\mathbf{g}_{t,u-1}^{i}</annotation></semantics></math> at time step <math id="S2.p1.10.m10.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.p1.10.m10.1a"><mi id="S2.p1.10.m10.1.1" xref="S2.p1.10.m10.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.p1.10.m10.1b"><ci id="S2.p1.10.m10.1.1.cmml" xref="S2.p1.10.m10.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.10.m10.1c">t</annotation></semantics></math> with output history <math id="S2.p1.11.m11.1" class="ltx_Math" alttext="\mathbf{y}_{1:u-1}^{i}" display="inline"><semantics id="S2.p1.11.m11.1a"><msubsup id="S2.p1.11.m11.1.1" xref="S2.p1.11.m11.1.1.cmml"><mi id="S2.p1.11.m11.1.1.2.2" xref="S2.p1.11.m11.1.1.2.2.cmml">𝐲</mi><mrow id="S2.p1.11.m11.1.1.2.3" xref="S2.p1.11.m11.1.1.2.3.cmml"><mn id="S2.p1.11.m11.1.1.2.3.2" xref="S2.p1.11.m11.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.p1.11.m11.1.1.2.3.1" xref="S2.p1.11.m11.1.1.2.3.1.cmml">:</mo><mrow id="S2.p1.11.m11.1.1.2.3.3" xref="S2.p1.11.m11.1.1.2.3.3.cmml"><mi id="S2.p1.11.m11.1.1.2.3.3.2" xref="S2.p1.11.m11.1.1.2.3.3.2.cmml">u</mi><mo id="S2.p1.11.m11.1.1.2.3.3.1" xref="S2.p1.11.m11.1.1.2.3.3.1.cmml">−</mo><mn id="S2.p1.11.m11.1.1.2.3.3.3" xref="S2.p1.11.m11.1.1.2.3.3.3.cmml">1</mn></mrow></mrow><mi id="S2.p1.11.m11.1.1.3" xref="S2.p1.11.m11.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.p1.11.m11.1b"><apply id="S2.p1.11.m11.1.1.cmml" xref="S2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S2.p1.11.m11.1.1.1.cmml" xref="S2.p1.11.m11.1.1">superscript</csymbol><apply id="S2.p1.11.m11.1.1.2.cmml" xref="S2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S2.p1.11.m11.1.1.2.1.cmml" xref="S2.p1.11.m11.1.1">subscript</csymbol><ci id="S2.p1.11.m11.1.1.2.2.cmml" xref="S2.p1.11.m11.1.1.2.2">𝐲</ci><apply id="S2.p1.11.m11.1.1.2.3.cmml" xref="S2.p1.11.m11.1.1.2.3"><ci id="S2.p1.11.m11.1.1.2.3.1.cmml" xref="S2.p1.11.m11.1.1.2.3.1">:</ci><cn type="integer" id="S2.p1.11.m11.1.1.2.3.2.cmml" xref="S2.p1.11.m11.1.1.2.3.2">1</cn><apply id="S2.p1.11.m11.1.1.2.3.3.cmml" xref="S2.p1.11.m11.1.1.2.3.3"><minus id="S2.p1.11.m11.1.1.2.3.3.1.cmml" xref="S2.p1.11.m11.1.1.2.3.3.1"></minus><ci id="S2.p1.11.m11.1.1.2.3.3.2.cmml" xref="S2.p1.11.m11.1.1.2.3.3.2">𝑢</ci><cn type="integer" id="S2.p1.11.m11.1.1.2.3.3.3.cmml" xref="S2.p1.11.m11.1.1.2.3.3.3">1</cn></apply></apply></apply><ci id="S2.p1.11.m11.1.1.3.cmml" xref="S2.p1.11.m11.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.11.m11.1c">\mathbf{y}_{1:u-1}^{i}</annotation></semantics></math>. These operations are as follows,</p>
</div>
<div id="S2.p2" class="ltx_para">
<table id="S2.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{h}_{1:T_{i}}^{i}" display="inline"><semantics id="S2.E1X.2.1.1.m1.1a"><msubsup id="S2.E1X.2.1.1.m1.1.1" xref="S2.E1X.2.1.1.m1.1.1.cmml"><mi id="S2.E1X.2.1.1.m1.1.1.2.2" xref="S2.E1X.2.1.1.m1.1.1.2.2.cmml">𝐡</mi><mrow id="S2.E1X.2.1.1.m1.1.1.2.3" xref="S2.E1X.2.1.1.m1.1.1.2.3.cmml"><mn id="S2.E1X.2.1.1.m1.1.1.2.3.2" xref="S2.E1X.2.1.1.m1.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E1X.2.1.1.m1.1.1.2.3.1" xref="S2.E1X.2.1.1.m1.1.1.2.3.1.cmml">:</mo><msub id="S2.E1X.2.1.1.m1.1.1.2.3.3" xref="S2.E1X.2.1.1.m1.1.1.2.3.3.cmml"><mi id="S2.E1X.2.1.1.m1.1.1.2.3.3.2" xref="S2.E1X.2.1.1.m1.1.1.2.3.3.2.cmml">T</mi><mi id="S2.E1X.2.1.1.m1.1.1.2.3.3.3" xref="S2.E1X.2.1.1.m1.1.1.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S2.E1X.2.1.1.m1.1.1.3" xref="S2.E1X.2.1.1.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.E1X.2.1.1.m1.1b"><apply id="S2.E1X.2.1.1.m1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">superscript</csymbol><apply id="S2.E1X.2.1.1.m1.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.1.1.2.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">subscript</csymbol><ci id="S2.E1X.2.1.1.m1.1.1.2.2.cmml" xref="S2.E1X.2.1.1.m1.1.1.2.2">𝐡</ci><apply id="S2.E1X.2.1.1.m1.1.1.2.3.cmml" xref="S2.E1X.2.1.1.m1.1.1.2.3"><ci id="S2.E1X.2.1.1.m1.1.1.2.3.1.cmml" xref="S2.E1X.2.1.1.m1.1.1.2.3.1">:</ci><cn type="integer" id="S2.E1X.2.1.1.m1.1.1.2.3.2.cmml" xref="S2.E1X.2.1.1.m1.1.1.2.3.2">1</cn><apply id="S2.E1X.2.1.1.m1.1.1.2.3.3.cmml" xref="S2.E1X.2.1.1.m1.1.1.2.3.3"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.1.1.2.3.3.1.cmml" xref="S2.E1X.2.1.1.m1.1.1.2.3.3">subscript</csymbol><ci id="S2.E1X.2.1.1.m1.1.1.2.3.3.2.cmml" xref="S2.E1X.2.1.1.m1.1.1.2.3.3.2">𝑇</ci><ci id="S2.E1X.2.1.1.m1.1.1.2.3.3.3.cmml" xref="S2.E1X.2.1.1.m1.1.1.2.3.3.3">𝑖</ci></apply></apply></apply><ci id="S2.E1X.2.1.1.m1.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.2.1.1.m1.1c">\displaystyle\mathbf{h}_{1:T_{i}}^{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1X.3.2.2.m1.1" class="ltx_Math" alttext="\displaystyle=\mathrm{Encoder}(\mathbf{x}_{1:{T_{i}}}^{i})" display="inline"><semantics id="S2.E1X.3.2.2.m1.1a"><mrow id="S2.E1X.3.2.2.m1.1.1" xref="S2.E1X.3.2.2.m1.1.1.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.3" xref="S2.E1X.3.2.2.m1.1.1.3.cmml"></mi><mo id="S2.E1X.3.2.2.m1.1.1.2" xref="S2.E1X.3.2.2.m1.1.1.2.cmml">=</mo><mrow id="S2.E1X.3.2.2.m1.1.1.1" xref="S2.E1X.3.2.2.m1.1.1.1.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.1.3" xref="S2.E1X.3.2.2.m1.1.1.1.3.cmml">Encoder</mi><mo lspace="0em" rspace="0em" id="S2.E1X.3.2.2.m1.1.1.1.2" xref="S2.E1X.3.2.2.m1.1.1.1.2.cmml">​</mo><mrow id="S2.E1X.3.2.2.m1.1.1.1.1.1" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1X.3.2.2.m1.1.1.1.1.1.2" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S2.E1X.3.2.2.m1.1.1.1.1.1.1" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.2" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.2.cmml">𝐱</mi><mrow id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.cmml"><mn id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.2" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.1" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.1.cmml">:</mo><msub id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.2" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.2.cmml">T</mi><mi id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.3" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.3" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.E1X.3.2.2.m1.1.1.1.1.1.3" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1X.3.2.2.m1.1b"><apply id="S2.E1X.3.2.2.m1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1"><eq id="S2.E1X.3.2.2.m1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.2"></eq><csymbol cd="latexml" id="S2.E1X.3.2.2.m1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.3">absent</csymbol><apply id="S2.E1X.3.2.2.m1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1"><times id="S2.E1X.3.2.2.m1.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.2"></times><ci id="S2.E1X.3.2.2.m1.1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.3">Encoder</ci><apply id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1">superscript</csymbol><apply id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.2">𝐱</ci><apply id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3"><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.1">:</ci><cn type="integer" id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.2">1</cn><apply id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.2">𝑇</ci><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.2.3.3.3">𝑖</ci></apply></apply></apply><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.3.2.2.m1.1c">\displaystyle=\mathrm{Encoder}(\mathbf{x}_{1:{T_{i}}}^{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="4" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
<tr id="S2.E1Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1Xa.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{f}_{u-1}^{i}" display="inline"><semantics id="S2.E1Xa.2.1.1.m1.1a"><msubsup id="S2.E1Xa.2.1.1.m1.1.1" xref="S2.E1Xa.2.1.1.m1.1.1.cmml"><mi id="S2.E1Xa.2.1.1.m1.1.1.2.2" xref="S2.E1Xa.2.1.1.m1.1.1.2.2.cmml">𝐟</mi><mrow id="S2.E1Xa.2.1.1.m1.1.1.2.3" xref="S2.E1Xa.2.1.1.m1.1.1.2.3.cmml"><mi id="S2.E1Xa.2.1.1.m1.1.1.2.3.2" xref="S2.E1Xa.2.1.1.m1.1.1.2.3.2.cmml">u</mi><mo id="S2.E1Xa.2.1.1.m1.1.1.2.3.1" xref="S2.E1Xa.2.1.1.m1.1.1.2.3.1.cmml">−</mo><mn id="S2.E1Xa.2.1.1.m1.1.1.2.3.3" xref="S2.E1Xa.2.1.1.m1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1Xa.2.1.1.m1.1.1.3" xref="S2.E1Xa.2.1.1.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.E1Xa.2.1.1.m1.1b"><apply id="S2.E1Xa.2.1.1.m1.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.1.1.1.cmml" xref="S2.E1Xa.2.1.1.m1.1.1">superscript</csymbol><apply id="S2.E1Xa.2.1.1.m1.1.1.2.cmml" xref="S2.E1Xa.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1Xa.2.1.1.m1.1.1.2.1.cmml" xref="S2.E1Xa.2.1.1.m1.1.1">subscript</csymbol><ci id="S2.E1Xa.2.1.1.m1.1.1.2.2.cmml" xref="S2.E1Xa.2.1.1.m1.1.1.2.2">𝐟</ci><apply id="S2.E1Xa.2.1.1.m1.1.1.2.3.cmml" xref="S2.E1Xa.2.1.1.m1.1.1.2.3"><minus id="S2.E1Xa.2.1.1.m1.1.1.2.3.1.cmml" xref="S2.E1Xa.2.1.1.m1.1.1.2.3.1"></minus><ci id="S2.E1Xa.2.1.1.m1.1.1.2.3.2.cmml" xref="S2.E1Xa.2.1.1.m1.1.1.2.3.2">𝑢</ci><cn type="integer" id="S2.E1Xa.2.1.1.m1.1.1.2.3.3.cmml" xref="S2.E1Xa.2.1.1.m1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.E1Xa.2.1.1.m1.1.1.3.cmml" xref="S2.E1Xa.2.1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1Xa.2.1.1.m1.1c">\displaystyle\mathbf{f}_{u-1}^{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1Xa.3.2.2.m1.1" class="ltx_Math" alttext="\displaystyle=\mathrm{Predictor}(\mathbf{y}_{1:u-1}^{i})" display="inline"><semantics id="S2.E1Xa.3.2.2.m1.1a"><mrow id="S2.E1Xa.3.2.2.m1.1.1" xref="S2.E1Xa.3.2.2.m1.1.1.cmml"><mi id="S2.E1Xa.3.2.2.m1.1.1.3" xref="S2.E1Xa.3.2.2.m1.1.1.3.cmml"></mi><mo id="S2.E1Xa.3.2.2.m1.1.1.2" xref="S2.E1Xa.3.2.2.m1.1.1.2.cmml">=</mo><mrow id="S2.E1Xa.3.2.2.m1.1.1.1" xref="S2.E1Xa.3.2.2.m1.1.1.1.cmml"><mi id="S2.E1Xa.3.2.2.m1.1.1.1.3" xref="S2.E1Xa.3.2.2.m1.1.1.1.3.cmml">Predictor</mi><mo lspace="0em" rspace="0em" id="S2.E1Xa.3.2.2.m1.1.1.1.2" xref="S2.E1Xa.3.2.2.m1.1.1.1.2.cmml">​</mo><mrow id="S2.E1Xa.3.2.2.m1.1.1.1.1.1" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.2" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.cmml"><mi id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.2" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.2.cmml">𝐲</mi><mrow id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.cmml"><mn id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.2" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.1" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.1.cmml">:</mo><mrow id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.2" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.2.cmml">u</mi><mo id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.1" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.1.cmml">−</mo><mn id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.3" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.3.cmml">1</mn></mrow></mrow><mi id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.3" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.3" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1Xa.3.2.2.m1.1b"><apply id="S2.E1Xa.3.2.2.m1.1.1.cmml" xref="S2.E1Xa.3.2.2.m1.1.1"><eq id="S2.E1Xa.3.2.2.m1.1.1.2.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.2"></eq><csymbol cd="latexml" id="S2.E1Xa.3.2.2.m1.1.1.3.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.3">absent</csymbol><apply id="S2.E1Xa.3.2.2.m1.1.1.1.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1"><times id="S2.E1Xa.3.2.2.m1.1.1.1.2.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.2"></times><ci id="S2.E1Xa.3.2.2.m1.1.1.1.3.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.3">Predictor</ci><apply id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1">superscript</csymbol><apply id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.2">𝐲</ci><apply id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3"><ci id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.1">:</ci><cn type="integer" id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.2">1</cn><apply id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3"><minus id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.1"></minus><ci id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.2">𝑢</ci><cn type="integer" id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.2.3.3.3">1</cn></apply></apply></apply><ci id="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.3.cmml" xref="S2.E1Xa.3.2.2.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1Xa.3.2.2.m1.1c">\displaystyle=\mathrm{Predictor}(\mathbf{y}_{1:u-1}^{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="S2.E1Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1Xb.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\mathbf{g}_{t,u-1}^{i}" display="inline"><semantics id="S2.E1Xb.2.1.1.m1.2a"><msubsup id="S2.E1Xb.2.1.1.m1.2.3" xref="S2.E1Xb.2.1.1.m1.2.3.cmml"><mi id="S2.E1Xb.2.1.1.m1.2.3.2.2" xref="S2.E1Xb.2.1.1.m1.2.3.2.2.cmml">𝐠</mi><mrow id="S2.E1Xb.2.1.1.m1.2.2.2.2" xref="S2.E1Xb.2.1.1.m1.2.2.2.3.cmml"><mi id="S2.E1Xb.2.1.1.m1.1.1.1.1" xref="S2.E1Xb.2.1.1.m1.1.1.1.1.cmml">t</mi><mo id="S2.E1Xb.2.1.1.m1.2.2.2.2.2" xref="S2.E1Xb.2.1.1.m1.2.2.2.3.cmml">,</mo><mrow id="S2.E1Xb.2.1.1.m1.2.2.2.2.1" xref="S2.E1Xb.2.1.1.m1.2.2.2.2.1.cmml"><mi id="S2.E1Xb.2.1.1.m1.2.2.2.2.1.2" xref="S2.E1Xb.2.1.1.m1.2.2.2.2.1.2.cmml">u</mi><mo id="S2.E1Xb.2.1.1.m1.2.2.2.2.1.1" xref="S2.E1Xb.2.1.1.m1.2.2.2.2.1.1.cmml">−</mo><mn id="S2.E1Xb.2.1.1.m1.2.2.2.2.1.3" xref="S2.E1Xb.2.1.1.m1.2.2.2.2.1.3.cmml">1</mn></mrow></mrow><mi id="S2.E1Xb.2.1.1.m1.2.3.3" xref="S2.E1Xb.2.1.1.m1.2.3.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.E1Xb.2.1.1.m1.2b"><apply id="S2.E1Xb.2.1.1.m1.2.3.cmml" xref="S2.E1Xb.2.1.1.m1.2.3"><csymbol cd="ambiguous" id="S2.E1Xb.2.1.1.m1.2.3.1.cmml" xref="S2.E1Xb.2.1.1.m1.2.3">superscript</csymbol><apply id="S2.E1Xb.2.1.1.m1.2.3.2.cmml" xref="S2.E1Xb.2.1.1.m1.2.3"><csymbol cd="ambiguous" id="S2.E1Xb.2.1.1.m1.2.3.2.1.cmml" xref="S2.E1Xb.2.1.1.m1.2.3">subscript</csymbol><ci id="S2.E1Xb.2.1.1.m1.2.3.2.2.cmml" xref="S2.E1Xb.2.1.1.m1.2.3.2.2">𝐠</ci><list id="S2.E1Xb.2.1.1.m1.2.2.2.3.cmml" xref="S2.E1Xb.2.1.1.m1.2.2.2.2"><ci id="S2.E1Xb.2.1.1.m1.1.1.1.1.cmml" xref="S2.E1Xb.2.1.1.m1.1.1.1.1">𝑡</ci><apply id="S2.E1Xb.2.1.1.m1.2.2.2.2.1.cmml" xref="S2.E1Xb.2.1.1.m1.2.2.2.2.1"><minus id="S2.E1Xb.2.1.1.m1.2.2.2.2.1.1.cmml" xref="S2.E1Xb.2.1.1.m1.2.2.2.2.1.1"></minus><ci id="S2.E1Xb.2.1.1.m1.2.2.2.2.1.2.cmml" xref="S2.E1Xb.2.1.1.m1.2.2.2.2.1.2">𝑢</ci><cn type="integer" id="S2.E1Xb.2.1.1.m1.2.2.2.2.1.3.cmml" xref="S2.E1Xb.2.1.1.m1.2.2.2.2.1.3">1</cn></apply></list></apply><ci id="S2.E1Xb.2.1.1.m1.2.3.3.cmml" xref="S2.E1Xb.2.1.1.m1.2.3.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1Xb.2.1.1.m1.2c">\displaystyle\mathbf{g}_{t,u-1}^{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1Xb.3.2.2.m1.1" class="ltx_Math" alttext="\displaystyle=\mathrm{Relu}(\mathbf{h}_{1:T_{i}}^{i}+\mathbf{f}_{u-1}^{i})" display="inline"><semantics id="S2.E1Xb.3.2.2.m1.1a"><mrow id="S2.E1Xb.3.2.2.m1.1.1" xref="S2.E1Xb.3.2.2.m1.1.1.cmml"><mi id="S2.E1Xb.3.2.2.m1.1.1.3" xref="S2.E1Xb.3.2.2.m1.1.1.3.cmml"></mi><mo id="S2.E1Xb.3.2.2.m1.1.1.2" xref="S2.E1Xb.3.2.2.m1.1.1.2.cmml">=</mo><mrow id="S2.E1Xb.3.2.2.m1.1.1.1" xref="S2.E1Xb.3.2.2.m1.1.1.1.cmml"><mi id="S2.E1Xb.3.2.2.m1.1.1.1.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.3.cmml">Relu</mi><mo lspace="0em" rspace="0em" id="S2.E1Xb.3.2.2.m1.1.1.1.2" xref="S2.E1Xb.3.2.2.m1.1.1.1.2.cmml">​</mo><mrow id="S2.E1Xb.3.2.2.m1.1.1.1.1.1" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.2" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.cmml"><msubsup id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.cmml"><mi id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.2" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.2.cmml">𝐡</mi><mrow id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.cmml"><mn id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.2" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.1" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.1.cmml">:</mo><msub id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.cmml"><mi id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.2" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.2.cmml">T</mi><mi id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.3.cmml">i</mi></msubsup><mo id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.1" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.1.cmml">+</mo><msubsup id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.2" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.2.cmml">𝐟</mi><mrow id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.2" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.2.cmml">u</mi><mo id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.1" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.1.cmml">−</mo><mn id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.3.cmml">1</mn></mrow><mi id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.3.cmml">i</mi></msubsup></mrow><mo stretchy="false" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.3" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1Xb.3.2.2.m1.1b"><apply id="S2.E1Xb.3.2.2.m1.1.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1"><eq id="S2.E1Xb.3.2.2.m1.1.1.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.2"></eq><csymbol cd="latexml" id="S2.E1Xb.3.2.2.m1.1.1.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.3">absent</csymbol><apply id="S2.E1Xb.3.2.2.m1.1.1.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1"><times id="S2.E1Xb.3.2.2.m1.1.1.1.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.2"></times><ci id="S2.E1Xb.3.2.2.m1.1.1.1.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.3">Relu</ci><apply id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1"><plus id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.1"></plus><apply id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.2">𝐡</ci><apply id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3"><ci id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.1">:</ci><cn type="integer" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.2">1</cn><apply id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3">subscript</csymbol><ci id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.2">𝑇</ci><ci id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.2.3.3.3">𝑖</ci></apply></apply></apply><ci id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.2">𝐟</ci><apply id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3"><minus id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.1"></minus><ci id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.2">𝑢</ci><cn type="integer" id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.2.3.3">1</cn></apply></apply><ci id="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1Xb.3.2.2.m1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1Xb.3.2.2.m1.1c">\displaystyle=\mathrm{Relu}(\mathbf{h}_{1:T_{i}}^{i}+\mathbf{f}_{u-1}^{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="S2.E1Xc" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1Xc.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle P(\mathbf{y}_{t}^{i}|\mathbf{y}_{1:u-1}^{i},\mathbf{x}_{1:{T_{i}}}^{i})" display="inline"><semantics id="S2.E1Xc.2.1.1.m1.1a"><mrow id="S2.E1Xc.2.1.1.m1.1.1" xref="S2.E1Xc.2.1.1.m1.1.1.cmml"><mi id="S2.E1Xc.2.1.1.m1.1.1.3" xref="S2.E1Xc.2.1.1.m1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.E1Xc.2.1.1.m1.1.1.2" xref="S2.E1Xc.2.1.1.m1.1.1.2.cmml">​</mo><mrow id="S2.E1Xc.2.1.1.m1.1.1.1.1" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1Xc.2.1.1.m1.1.1.1.1.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1Xc.2.1.1.m1.1.1.1.1.1" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.cmml"><msubsup id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.cmml"><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.2.cmml">𝐲</mi><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.3.cmml">t</mi><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.3.cmml">i</mi></msubsup><mo fence="false" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.3.cmml">|</mo><mrow id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.3.cmml"><msubsup id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml">𝐲</mi><mrow id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mn id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">:</mo><mrow id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.2.cmml">u</mi><mo id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.1" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.1.cmml">−</mo><mn id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.3.cmml">1</mn></mrow></mrow><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.3.cmml">,</mo><msubsup id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.2.cmml">𝐱</mi><mrow id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.cmml"><mn id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.1" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.1.cmml">:</mo><msub id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.cmml"><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.2" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.2.cmml">T</mi><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.3.cmml">i</mi></msub></mrow><mi id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msubsup></mrow></mrow><mo stretchy="false" id="S2.E1Xc.2.1.1.m1.1.1.1.1.3" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1Xc.2.1.1.m1.1b"><apply id="S2.E1Xc.2.1.1.m1.1.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1"><times id="S2.E1Xc.2.1.1.m1.1.1.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.2"></times><ci id="S2.E1Xc.2.1.1.m1.1.1.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.3">𝑃</ci><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.3">conditional</csymbol><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4">superscript</csymbol><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4">subscript</csymbol><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.2">𝐲</ci><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.2.3">𝑡</ci></apply><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.4.3">𝑖</ci></apply><list id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2"><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2">𝐲</ci><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3"><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.1">:</ci><cn type="integer" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.2">1</cn><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3"><minus id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.1"></minus><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.2">𝑢</ci><cn type="integer" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.3.3">1</cn></apply></apply></apply><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.2">𝐱</ci><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3"><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.1">:</ci><cn type="integer" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.2">1</cn><apply id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.1.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3">subscript</csymbol><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.2.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.2">𝑇</ci><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.2.3.3.3">𝑖</ci></apply></apply></apply><ci id="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E1Xc.2.1.1.m1.1.1.1.1.1.2.2.2.3">𝑖</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1Xc.2.1.1.m1.1c">\displaystyle P(\mathbf{y}_{t}^{i}|\mathbf{y}_{1:u-1}^{i},\mathbf{x}_{1:{T_{i}}}^{i})</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1Xc.3.2.2.m1.3" class="ltx_Math" alttext="\displaystyle=\mathrm{Softmax}({\mathbf{W}}_{o}*\mathbf{g}_{t,u-1}^{i})" display="inline"><semantics id="S2.E1Xc.3.2.2.m1.3a"><mrow id="S2.E1Xc.3.2.2.m1.3.3" xref="S2.E1Xc.3.2.2.m1.3.3.cmml"><mi id="S2.E1Xc.3.2.2.m1.3.3.3" xref="S2.E1Xc.3.2.2.m1.3.3.3.cmml"></mi><mo id="S2.E1Xc.3.2.2.m1.3.3.2" xref="S2.E1Xc.3.2.2.m1.3.3.2.cmml">=</mo><mrow id="S2.E1Xc.3.2.2.m1.3.3.1" xref="S2.E1Xc.3.2.2.m1.3.3.1.cmml"><mi id="S2.E1Xc.3.2.2.m1.3.3.1.3" xref="S2.E1Xc.3.2.2.m1.3.3.1.3.cmml">Softmax</mi><mo lspace="0em" rspace="0em" id="S2.E1Xc.3.2.2.m1.3.3.1.2" xref="S2.E1Xc.3.2.2.m1.3.3.1.2.cmml">​</mo><mrow id="S2.E1Xc.3.2.2.m1.3.3.1.1.1" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.2" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.cmml"><msub id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.cmml"><mi id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.2" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.2.cmml">𝐖</mi><mi id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.3" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.3.cmml">o</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.1" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.1.cmml">∗</mo><msubsup id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.cmml"><mi id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.2.2" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.2.2.cmml">𝐠</mi><mrow id="S2.E1Xc.3.2.2.m1.2.2.2.2" xref="S2.E1Xc.3.2.2.m1.2.2.2.3.cmml"><mi id="S2.E1Xc.3.2.2.m1.1.1.1.1" xref="S2.E1Xc.3.2.2.m1.1.1.1.1.cmml">t</mi><mo id="S2.E1Xc.3.2.2.m1.2.2.2.2.2" xref="S2.E1Xc.3.2.2.m1.2.2.2.3.cmml">,</mo><mrow id="S2.E1Xc.3.2.2.m1.2.2.2.2.1" xref="S2.E1Xc.3.2.2.m1.2.2.2.2.1.cmml"><mi id="S2.E1Xc.3.2.2.m1.2.2.2.2.1.2" xref="S2.E1Xc.3.2.2.m1.2.2.2.2.1.2.cmml">u</mi><mo id="S2.E1Xc.3.2.2.m1.2.2.2.2.1.1" xref="S2.E1Xc.3.2.2.m1.2.2.2.2.1.1.cmml">−</mo><mn id="S2.E1Xc.3.2.2.m1.2.2.2.2.1.3" xref="S2.E1Xc.3.2.2.m1.2.2.2.2.1.3.cmml">1</mn></mrow></mrow><mi id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.3" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.3.cmml">i</mi></msubsup></mrow><mo stretchy="false" id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.3" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1Xc.3.2.2.m1.3b"><apply id="S2.E1Xc.3.2.2.m1.3.3.cmml" xref="S2.E1Xc.3.2.2.m1.3.3"><eq id="S2.E1Xc.3.2.2.m1.3.3.2.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.2"></eq><csymbol cd="latexml" id="S2.E1Xc.3.2.2.m1.3.3.3.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.3">absent</csymbol><apply id="S2.E1Xc.3.2.2.m1.3.3.1.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1"><times id="S2.E1Xc.3.2.2.m1.3.3.1.2.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.2"></times><ci id="S2.E1Xc.3.2.2.m1.3.3.1.3.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.3">Softmax</ci><apply id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1"><times id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.1"></times><apply id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2">subscript</csymbol><ci id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.2">𝐖</ci><ci id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.3.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.2.3">𝑜</ci></apply><apply id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.1.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3">superscript</csymbol><apply id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.2.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.2.1.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.2.2.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.2.2">𝐠</ci><list id="S2.E1Xc.3.2.2.m1.2.2.2.3.cmml" xref="S2.E1Xc.3.2.2.m1.2.2.2.2"><ci id="S2.E1Xc.3.2.2.m1.1.1.1.1.cmml" xref="S2.E1Xc.3.2.2.m1.1.1.1.1">𝑡</ci><apply id="S2.E1Xc.3.2.2.m1.2.2.2.2.1.cmml" xref="S2.E1Xc.3.2.2.m1.2.2.2.2.1"><minus id="S2.E1Xc.3.2.2.m1.2.2.2.2.1.1.cmml" xref="S2.E1Xc.3.2.2.m1.2.2.2.2.1.1"></minus><ci id="S2.E1Xc.3.2.2.m1.2.2.2.2.1.2.cmml" xref="S2.E1Xc.3.2.2.m1.2.2.2.2.1.2">𝑢</ci><cn type="integer" id="S2.E1Xc.3.2.2.m1.2.2.2.2.1.3.cmml" xref="S2.E1Xc.3.2.2.m1.2.2.2.2.1.3">1</cn></apply></list></apply><ci id="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.3.cmml" xref="S2.E1Xc.3.2.2.m1.3.3.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1Xc.3.2.2.m1.3c">\displaystyle=\mathrm{Softmax}({\mathbf{W}}_{o}*\mathbf{g}_{t,u-1}^{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S2.p2.1" class="ltx_p">where <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{W}_{o}" display="inline"><semantics id="S2.p2.1.m1.1a"><msub id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mi id="S2.p2.1.m1.1.1.2" xref="S2.p2.1.m1.1.1.2.cmml">𝐖</mi><mi id="S2.p2.1.m1.1.1.3" xref="S2.p2.1.m1.1.1.3.cmml">o</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.p2.1.m1.1.1.2.cmml" xref="S2.p2.1.m1.1.1.2">𝐖</ci><ci id="S2.p2.1.m1.1.1.3.cmml" xref="S2.p2.1.m1.1.1.3">𝑜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\mathbf{W}_{o}</annotation></semantics></math> is a linear transformation applied prior to the final Softmax output layer. Among existing neural Transducer systems, Recurrent Neural Network (RNN) or long short term memory (LSTM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> architectures have been used for the encoder, while the predictor module is commonly based on LSTM. In this paper, Zipformer-Transducer designed using Zipformer based encoder and Stateless <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> Prediction modules are used throughout this paper.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">In contrast to Conformer, the Zipformer<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> encoder works with the sequence at a steady frame rate. Zipformer adopts a structure akin to U-Net with multiple stacks that each downscale the sequence to various lower frame rates. Second, the block structure is redesigned with two Conformer blocks and additional modules, and the attention weights are reused for efficiency. Additionally, it also proposes BiasNorm as a simpler replacement for LayerNorm, which allows for retaining length information in normalization. To achieve better results, it also replaces Swish with its new activation functions SwooshR and SwooshL. Furthermore, it also develops ScaledAdam, a parameter-scale-invariant version of Adam. In particular, the Zipformer block consists of six modules: Feed-Forward Network (FFN), Non-Linear Attention (NLA), Multi-Head Self-Attention (MHSA), Multi-Head Attention Weights (MHAW), Convolution (CONV), and Forward Network (FFN).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Speech Recognition with discrete tokens</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">ASR with Discrete Tokens Input</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We explore the application of discrete tokens generated by three SSL models to train E2E ASR systems. Our primary approach employs the XLSR-53 model for speech discretization because it is trained across 53 languages. For comparison, we also examine the discrete token generated by WavLM-Large and EnCodec 24kHz models. An illustration of the pipeline for discrete speech tokenization is shown in Fig. <a href="#S0.F1" title="Figure 1 ‣ Exploring SSL Discrete Tokens for Multilingual ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Discretization methodology for XLSR-53 and WavLM-Large involves extracting hidden embeddings from the 21st Transformer encoder layer, followed by k-means clustering. The k-means clustering approach is selected for discretizing continuous speech embeddings into discrete token labels for ASR modeling. Moreover, we fine-tuned XLSR-53 for the seven language domains before extracting discrete tokens. In contrast, EnCodec employs 8 codebooks with 1024 entries to directly output quantized labels.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">For ASR model training, we employ the Zipformer-Transducer architecture, utilizing the discrete speech tokens and their corresponding transcriptions as input. The training process incorporates Recurrent Neural Network Transducer (RNN-T) loss. A linear embedding layer projects the discrete tokens to 80-dimensional vectors. In cases of multiple feature groups, these are embedded, concatenated, and projected to maintain consistent input dimensions. Next, these features are interpolated to a consistent rate of 100 Hz before being input into the ASR model.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Discrete Data Augmentation Techniques</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To enhance model robustness and generalization, we implement four data augmentation techniques:</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Time Warping</span>: adjusts the sequence using the <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_italic">interpolate</span> function to create variations in timing. A random center within a certain range is selected to warp different segments of the sequence.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Time Masking:</span> hides consecutive parts of the sequence to encourage the model to learn from other parts. The number of masked regions and the width of each mask are randomly determined, introducing randomness and promoting robustness in learning.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Embedding Masking:</span> obscures parts of the vertical embedding dimension, helping the model focus on different aspects of the data. By applying this masking technique twice independently, the model gains additional exposure to varied information.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p"><span id="S3.SS2.p5.1.1" class="ltx_text ltx_font_bold">Gaussian Noise:</span> sampled from a standard normal distribution, is added to the data with a certain probability.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p">These augmentation strategies play a crucial role in improving the model’s ability to handle varied speech inputs which can be found in more detail in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Monolingual ASR Performance Comparison of Using Fbank and Discrete Token Features as Inputs on Multilingual LibriSpeech</figcaption>
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:626.8pt;height:119.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-64.2pt,12.2pt) scale(0.83,0.83) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">ID</span></td>
<td id="S3.T1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.1.1.2.1.2.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S3.T1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.1.1.2.1.3.1" class="ltx_text ltx_font_bold">Feature</span></td>
<td id="S3.T1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.1.1.2.1.4.1" class="ltx_text ltx_font_bold">Units</span></td>
<td id="S3.T1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" colspan="8"><span id="S3.T1.1.1.2.1.5.1" class="ltx_text ltx_font_bold">WER (%) dev / test</span></td>
</tr>
<tr id="S3.T1.1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.2.1.1" class="ltx_text ltx_font_bold">DE</span></td>
<td id="S3.T1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.2.2.1" class="ltx_text ltx_font_bold">NL</span></td>
<td id="S3.T1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.2.3.1" class="ltx_text ltx_font_bold">FR</span></td>
<td id="S3.T1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.2.4.1" class="ltx_text ltx_font_bold">ES</span></td>
<td id="S3.T1.1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.2.5.1" class="ltx_text ltx_font_bold">IT</span></td>
<td id="S3.T1.1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.2.6.1" class="ltx_text ltx_font_bold">PT</span></td>
<td id="S3.T1.1.1.3.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.2.7.1" class="ltx_text ltx_font_bold">PL</span></td>
<td id="S3.T1.1.1.3.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.2.8.1" class="ltx_text ltx_font_bold">Avg.</span></td>
</tr>
<tr id="S3.T1.1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S3.T1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">Whisper-L</td>
<td id="S3.T1.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T1.1.1.4.3.3.1" class="ltx_text">Fbank</span></td>
<td id="S3.T1.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T1.1.1.4.3.4.1" class="ltx_text">-</span></td>
<td id="S3.T1.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t">8.39 / 8.58</td>
<td id="S3.T1.1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_t">16.73 / 11.83</td>
<td id="S3.T1.1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_t">10.65 / 8.95</td>
<td id="S3.T1.1.1.4.3.8" class="ltx_td ltx_align_center ltx_border_t">6.32 / 5.72</td>
<td id="S3.T1.1.1.4.3.9" class="ltx_td ltx_align_center ltx_border_t">12.85 / 12.36</td>
<td id="S3.T1.1.1.4.3.10" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.1.1.4.3.10.1" class="ltx_text ltx_font_bold">13.26</span> / <span id="S3.T1.1.1.4.3.10.2" class="ltx_text ltx_font_bold">12.29</span>
</td>
<td id="S3.T1.1.1.4.3.11" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.1.1.4.3.11.1" class="ltx_text ltx_font_bold">10.11</span> / <span id="S3.T1.1.1.4.3.11.2" class="ltx_text ltx_font_bold">7.38</span>
</td>
<td id="S3.T1.1.1.4.3.12" class="ltx_td ltx_align_center ltx_border_t">11.18 / 9.59</td>
</tr>
<tr id="S3.T1.1.1.5.4" class="ltx_tr">
<td id="S3.T1.1.1.5.4.1" class="ltx_td ltx_align_center">2</td>
<td id="S3.T1.1.1.5.4.2" class="ltx_td ltx_align_center">XLSR-53-CTC</td>
<td id="S3.T1.1.1.5.4.3" class="ltx_td ltx_align_center">7.59 / 8.90</td>
<td id="S3.T1.1.1.5.4.4" class="ltx_td ltx_align_center">16.10 / 12.46</td>
<td id="S3.T1.1.1.5.4.5" class="ltx_td ltx_align_center">12.38 / 10.55</td>
<td id="S3.T1.1.1.5.4.6" class="ltx_td ltx_align_center">6.64 / 6.73</td>
<td id="S3.T1.1.1.5.4.7" class="ltx_td ltx_align_center">13.98 / 12.25</td>
<td id="S3.T1.1.1.5.4.8" class="ltx_td ltx_align_center">19.60 / 18.42</td>
<td id="S3.T1.1.1.5.4.9" class="ltx_td ltx_align_center">10.20 / 8.82</td>
<td id="S3.T1.1.1.5.4.10" class="ltx_td ltx_align_center">12.36 / 11.16</td>
</tr>
<tr id="S3.T1.1.1.6.5" class="ltx_tr">
<td id="S3.T1.1.1.6.5.1" class="ltx_td ltx_align_center">3</td>
<td id="S3.T1.1.1.6.5.2" class="ltx_td ltx_align_center">Zipformer-Transducer</td>
<td id="S3.T1.1.1.6.5.3" class="ltx_td ltx_align_center">4.00 / 5.06</td>
<td id="S3.T1.1.1.6.5.4" class="ltx_td ltx_align_center">16.21 / 15.80</td>
<td id="S3.T1.1.1.6.5.5" class="ltx_td ltx_align_center">
<span id="S3.T1.1.1.6.5.5.1" class="ltx_text ltx_font_bold">7.00</span> / <span id="S3.T1.1.1.6.5.5.2" class="ltx_text ltx_font_bold">5.80</span>
</td>
<td id="S3.T1.1.1.6.5.6" class="ltx_td ltx_align_center">5.16 / 5.57</td>
<td id="S3.T1.1.1.6.5.7" class="ltx_td ltx_align_center">12.87 / 11.30</td>
<td id="S3.T1.1.1.6.5.8" class="ltx_td ltx_align_center">19.50 / 18.58</td>
<td id="S3.T1.1.1.6.5.9" class="ltx_td ltx_align_center">11.24 / 16.36</td>
<td id="S3.T1.1.1.6.5.10" class="ltx_td ltx_align_center">10.85 / 11.21</td>
</tr>
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" rowspan="3"><span id="S3.T1.1.1.1.3.1" class="ltx_text">Zipformer-Transducer</span></td>
<td id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">Encodec</td>
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">1024<sup id="S3.T1.1.1.1.1.1" class="ltx_sup"><span id="S3.T1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">8</span></sup>
</td>
<td id="S3.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">6.07 / 7.56</td>
<td id="S3.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">16.56 / 16.20</td>
<td id="S3.T1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">7.50 / 7.32</td>
<td id="S3.T1.1.1.1.8" class="ltx_td ltx_align_center ltx_border_t">6.27 / 6.89</td>
<td id="S3.T1.1.1.1.9" class="ltx_td ltx_align_center ltx_border_t">14.02 / 12.58</td>
<td id="S3.T1.1.1.1.10" class="ltx_td ltx_align_center ltx_border_t">19.90 / 18.80</td>
<td id="S3.T1.1.1.1.11" class="ltx_td ltx_align_center ltx_border_t">11.50 / 16.57</td>
<td id="S3.T1.1.1.1.12" class="ltx_td ltx_align_center ltx_border_t">11.69 / 12.27</td>
</tr>
<tr id="S3.T1.1.1.7.6" class="ltx_tr">
<td id="S3.T1.1.1.7.6.1" class="ltx_td ltx_align_center">5</td>
<td id="S3.T1.1.1.7.6.2" class="ltx_td ltx_align_center">Wavlm</td>
<td id="S3.T1.1.1.7.6.3" class="ltx_td ltx_align_center">2000</td>
<td id="S3.T1.1.1.7.6.4" class="ltx_td ltx_align_center">4.88 / 5.96</td>
<td id="S3.T1.1.1.7.6.5" class="ltx_td ltx_align_center">18.67 / 13.28</td>
<td id="S3.T1.1.1.7.6.6" class="ltx_td ltx_align_center">7.92 / 6.58</td>
<td id="S3.T1.1.1.7.6.7" class="ltx_td ltx_align_center">5.40 / 6.38</td>
<td id="S3.T1.1.1.7.6.8" class="ltx_td ltx_align_center">14.46 / 11.66</td>
<td id="S3.T1.1.1.7.6.9" class="ltx_td ltx_align_center">19.47 / 19.27</td>
<td id="S3.T1.1.1.7.6.10" class="ltx_td ltx_align_center">11.78 / 12.50</td>
<td id="S3.T1.1.1.7.6.11" class="ltx_td ltx_align_center">11.79 / 10.80</td>
</tr>
<tr id="S3.T1.1.1.8.7" class="ltx_tr">
<td id="S3.T1.1.1.8.7.1" class="ltx_td ltx_align_center ltx_border_b">6</td>
<td id="S3.T1.1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_b">XLSR-53</td>
<td id="S3.T1.1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_b">2000</td>
<td id="S3.T1.1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_b">
<span id="S3.T1.1.1.8.7.4.1" class="ltx_text ltx_font_bold">4.00</span> / <span id="S3.T1.1.1.8.7.4.2" class="ltx_text ltx_font_bold">5.03</span>
</td>
<td id="S3.T1.1.1.8.7.5" class="ltx_td ltx_align_center ltx_border_b">
<span id="S3.T1.1.1.8.7.5.1" class="ltx_text ltx_font_bold">15.06</span> / <span id="S3.T1.1.1.8.7.5.2" class="ltx_text ltx_font_bold">11.71</span>
</td>
<td id="S3.T1.1.1.8.7.6" class="ltx_td ltx_align_center ltx_border_b">7.20 / 6.06</td>
<td id="S3.T1.1.1.8.7.7" class="ltx_td ltx_align_center ltx_border_b">
<span id="S3.T1.1.1.8.7.7.1" class="ltx_text ltx_font_bold">4.34</span> / <span id="S3.T1.1.1.8.7.7.2" class="ltx_text ltx_font_bold">5.54</span>
</td>
<td id="S3.T1.1.1.8.7.8" class="ltx_td ltx_align_center ltx_border_b">
<span id="S3.T1.1.1.8.7.8.1" class="ltx_text ltx_font_bold">12.85</span> / <span id="S3.T1.1.1.8.7.8.2" class="ltx_text ltx_font_bold">11.10</span>
</td>
<td id="S3.T1.1.1.8.7.9" class="ltx_td ltx_align_center ltx_border_b">19.15 / 17.21</td>
<td id="S3.T1.1.1.8.7.10" class="ltx_td ltx_align_center ltx_border_b">11.21 / 9.54</td>
<td id="S3.T1.1.1.8.7.11" class="ltx_td ltx_align_center ltx_border_b">
<span id="S3.T1.1.1.8.7.11.1" class="ltx_text ltx_font_bold">10.54</span> / <span id="S3.T1.1.1.8.7.11.2" class="ltx_text ltx_font_bold">9.45</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Statistics of Train/Dev/Test partition of each language.</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Language</span></th>
<th id="S3.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3"><span id="S3.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Durations (hrs)</span></th>
</tr>
<tr id="S3.T2.1.2.2" class="ltx_tr">
<th id="S3.T2.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">train</th>
<th id="S3.T2.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">dev</th>
<th id="S3.T2.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">test</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.3.1" class="ltx_tr">
<th id="S3.T2.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">German</th>
<td id="S3.T2.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1966.51</td>
<td id="S3.T2.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14.28</td>
<td id="S3.T2.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">14.29</td>
</tr>
<tr id="S3.T2.1.4.2" class="ltx_tr">
<th id="S3.T2.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Dutch</th>
<td id="S3.T2.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">1544.24</td>
<td id="S3.T2.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r">12.76</td>
<td id="S3.T2.1.4.2.4" class="ltx_td ltx_align_center">12.76</td>
</tr>
<tr id="S3.T2.1.5.3" class="ltx_tr">
<th id="S3.T2.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">French</th>
<td id="S3.T2.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r">1076.58</td>
<td id="S3.T2.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r">10.07</td>
<td id="S3.T2.1.5.3.4" class="ltx_td ltx_align_center">10.07</td>
</tr>
<tr id="S3.T2.1.6.4" class="ltx_tr">
<th id="S3.T2.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Spanish</th>
<td id="S3.T2.1.6.4.2" class="ltx_td ltx_align_center ltx_border_r">917.68</td>
<td id="S3.T2.1.6.4.3" class="ltx_td ltx_align_center ltx_border_r">9.99</td>
<td id="S3.T2.1.6.4.4" class="ltx_td ltx_align_center">10.0</td>
</tr>
<tr id="S3.T2.1.7.5" class="ltx_tr">
<th id="S3.T2.1.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Italian</th>
<td id="S3.T2.1.7.5.2" class="ltx_td ltx_align_center ltx_border_r">247.38</td>
<td id="S3.T2.1.7.5.3" class="ltx_td ltx_align_center ltx_border_r">5.18</td>
<td id="S3.T2.1.7.5.4" class="ltx_td ltx_align_center">5.27</td>
</tr>
<tr id="S3.T2.1.8.6" class="ltx_tr">
<th id="S3.T2.1.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Portuguese</th>
<td id="S3.T2.1.8.6.2" class="ltx_td ltx_align_center ltx_border_r">160.96</td>
<td id="S3.T2.1.8.6.3" class="ltx_td ltx_align_center ltx_border_r">3.64</td>
<td id="S3.T2.1.8.6.4" class="ltx_td ltx_align_center">3.74</td>
</tr>
<tr id="S3.T2.1.9.7" class="ltx_tr">
<th id="S3.T2.1.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">Polish</th>
<td id="S3.T2.1.9.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">103.65</td>
<td id="S3.T2.1.9.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">2.08</td>
<td id="S3.T2.1.9.7.4" class="ltx_td ltx_align_center ltx_border_b">2.14</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">General Setup</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The efficacy of the proposed pipeline in ASR is assessed on Multilingual Librispeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> corpora, including Word Error Rate (WER) for German (DE), Dutch (NL), French (FR), Spanish (ES), Italian (IT), Portuguese (PT), and Polish (PL) on dev and test sets in Table I. Separate k-means models are trained for each language domain on a 100-hour, randomly selected subset of speech.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">In Fbank-based experiments, SpecAugment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> is applied during training for robustness. The input is 80-channel Fbank features extracted over windows size 25ms with a 10ms frame shift. 500-Byte Pair Encoding (BPE) is applied for the monolingual classification units while 3500-BPE is utilized for multilingual speech training. In discrete tokens experiments, data augmentation is utilized for training as described in Sec. III.B</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.2" class="ltx_p">The Zipformer Transducer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> architecture is adopted for ASR implemented with the k2 and icefall<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/k2-fsa/icefall/tree/master</span></span></span> framework. The encoder employs a 6-stack Zipformer with downsampling factors of (1,2,4,8,4,2). The label decoder employs a stateless decoder consisting of an embedding layer followed by a 512-dim Conv1D layer. The model has 65.5M parameters. For German, Dutch, French, and Spanish each totaling duration close to or bigger than 1000h, the models are trained for 40 epochs with a learning rate of <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="10000/\text{total dataset duration}" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mrow id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mn id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">10000</mn><mo id="S4.SS1.p3.1.m1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.cmml">/</mo><mtext id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3a.cmml">total dataset duration</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><divide id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1"></divide><cn type="integer" id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">10000</cn><ci id="S4.SS1.p3.1.m1.1.1.3a.cmml" xref="S4.SS1.p3.1.m1.1.1.3"><mtext id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3">total dataset duration</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">10000/\text{total dataset duration}</annotation></semantics></math>. For Italian, Portuguese, and Polish each duration less than 1000h, the models are trained for 150 epochs with a learning rate <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="10000/\text{total dataset duration}" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mrow id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mn id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">10000</mn><mo id="S4.SS1.p3.2.m2.1.1.1" xref="S4.SS1.p3.2.m2.1.1.1.cmml">/</mo><mtext id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3a.cmml">total dataset duration</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><divide id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1.1"></divide><cn type="integer" id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">10000</cn><ci id="S4.SS1.p3.2.m2.1.1.3a.cmml" xref="S4.SS1.p3.2.m2.1.1.3"><mtext id="S4.SS1.p3.2.m2.1.1.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3">total dataset duration</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">10000/\text{total dataset duration}</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">The Whisper-Large<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://huggingface.co/openai/whisper-large-v3</span></span></span><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> model and finetuned XLSR-53-CTC<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://huggingface.co/facebook/wav2vec2-large-xlsr-53</span></span></span> model<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> are utilized for ASR training with FBank input. Moreover, the discrete tokens are extracted from the 21-st layer of XLSR-53 with 2000 units, the 21-st layer of WavLM large<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://huggingface.co/microsoft/wavlm-large</span></span></span><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> with 2000 units, and EnCodec<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://huggingface.co/facebook/encodec_24khz</span></span></span><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> 24kHz with <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="1024^{8}" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><msup id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml"><mn id="S4.SS1.p4.1.m1.1.1.2" xref="S4.SS1.p4.1.m1.1.1.2.cmml">1024</mn><mn id="S4.SS1.p4.1.m1.1.1.3" xref="S4.SS1.p4.1.m1.1.1.3.cmml">8</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><apply id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.p4.1.m1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.1.1.2">1024</cn><cn type="integer" id="S4.SS1.p4.1.m1.1.1.3.cmml" xref="S4.SS1.p4.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">1024^{8}</annotation></semantics></math> units.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">WER Results on Multilingual LibriSpeech</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">TABLE I presents a WER performance comparison of models trained on individual languages from the Multilingual LibriSpeech corpus, totaling 6000 hours, using various discrete token inputs. Sys. 1-3 comprise Whisper-Large, fine-tuned XLSR-53-CTC on each monolingual language, and Zipformer-Transducer models with Fbank features as input. Sys. 4-6 are Zipformer-Transducer models utilizing different discrete tokens generated by EnCodec-24kHz, WavLM-Large, and fine-tuned XLSR-53-CTC. Several trends can be found:</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">1) Among the experiments with Fbank features as input (Sys. 1-3, TABLE I), Zipformer-Transducer achieves almost the best or near-best performance across all monolingual languages except Polish and Portuguese. Therefore, we utilize Zipformer-Transducer architecture in discrete token experiments, while three systems (Sys.1-3, TABLE I) with Fbank feature serve as baseline systems for comparison.
</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">2) The Zipformer-Transducer model utilizing XLSR-53 discrete tokens as input (Sys. 6) outperforms its counterpart using Fbank features (Sys. 3) across all monolingual languages, with the sole exception of French. This superior performance is evident in the substantial WER reduction observed: the best performance showed a remarkable performance with a 6.82% absolute (41.68% relative) WER reduction on the Polish test set and an average WER reduction of 0.31% and 1.76% absolute (2.80% and 15.70%) on the dev and test sets across seven domains.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">3) The Zipformer-Transducer model utilizing XLSR-53 discrete tokens as input (Sys 6) outperforms all models using Fbank features (Sys. 1-3) across most languages, with the exceptions of Portuguese and Polish. Especially, the best-performing systems demonstrate significant WER reduction 4.39% and 3.55% absolute (52.62% and 41.37% relative) on German dev and test sets (Sys.6 vs. Sys.1).</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">4) The Zipformer-Transducer utilizing EnCodec discrete tokens (Sys. 4) exhibits suboptimal performance, possibly attributed to the EnCodec’s encoding of all speech aspects without disentanglement. In contrast, XLSR-53 and WavLM prioritize speech semantics and effectively support the ASR task.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p">5) Additionally, the Zipformer-Transducer with WavLM-Large discrete token (Sys. 5) demonstrates inferior results, which can be attributed to the linguistic limitations of WavLM’s training data. While WavLM was primarily trained on English data, XLSR-53 benefited from exposure to 53 languages during its training process. Consequently, for non-English speech recognition tasks, WavLM struggles to generate precise and relevant discrete tokens, hindering its effectiveness in multilingual ASR applications. Thus, we can infer that the WavLM pretrained on the English domain may struggle to transfer its self-supervised learning capabilities effectively to low-resource languages that it has not encountered before.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Ablation Study: Comparison of Monolingual vs. Multilingual Training with Discrete Tokens on Multilingual LibriSpeech.</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:574.8pt;height:86.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-71.8pt,10.8pt) scale(0.8,0.8) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" rowspan="2"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">ID</span></th>
<th id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" rowspan="2"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Mix data</span></th>
<th id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" rowspan="2"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Shared Kmeans</span></th>
<th id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" rowspan="2"><span id="S4.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Units</span></th>
<th id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="7"><span id="S4.T3.1.1.1.1.5.1" class="ltx_text ltx_font_bold">WER (%) dev / test</span></th>
<td id="S4.T3.1.1.1.1.6" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S4.T3.1.1.2.2" class="ltx_tr">
<th id="S4.T3.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T3.1.1.2.2.1.1" class="ltx_text ltx_font_bold">DE</span></th>
<th id="S4.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.2.1" class="ltx_text ltx_font_bold">NL</span></th>
<th id="S4.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.3.1" class="ltx_text ltx_font_bold">FR</span></th>
<th id="S4.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.4.1" class="ltx_text ltx_font_bold">ES</span></th>
<th id="S4.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.5.1" class="ltx_text ltx_font_bold">IT</span></th>
<th id="S4.T3.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.6.1" class="ltx_text ltx_font_bold">PT</span></th>
<th id="S4.T3.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.7.1" class="ltx_text ltx_font_bold">PL</span></th>
<th id="S4.T3.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.8.1" class="ltx_text ltx_font_bold">Avg.</span></th>
</tr>
<tr id="S4.T3.1.1.3.3" class="ltx_tr">
<td id="S4.T3.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_tt">1</td>
<td id="S4.T3.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_tt">✗</td>
<td id="S4.T3.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_tt">✗</td>
<td id="S4.T3.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_tt">2000</td>
<td id="S4.T3.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S4.T3.1.1.3.3.5.1" class="ltx_text ltx_font_bold">4.00</span> / <span id="S4.T3.1.1.3.3.5.2" class="ltx_text ltx_font_bold">5.03</span>
</td>
<td id="S4.T3.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_tt">15.06 / <span id="S4.T3.1.1.3.3.6.1" class="ltx_text ltx_font_bold">11.71</span>
</td>
<td id="S4.T3.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S4.T3.1.1.3.3.7.1" class="ltx_text ltx_font_bold">7.20</span> / <span id="S4.T3.1.1.3.3.7.2" class="ltx_text ltx_font_bold">6.06</span>
</td>
<td id="S4.T3.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S4.T3.1.1.3.3.8.1" class="ltx_text ltx_font_bold">4.34</span> / 5.54</td>
<td id="S4.T3.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S4.T3.1.1.3.3.9.1" class="ltx_text ltx_font_bold">12.85</span> / <span id="S4.T3.1.1.3.3.9.2" class="ltx_text ltx_font_bold">11.10</span>
</td>
<td id="S4.T3.1.1.3.3.10" class="ltx_td ltx_align_center ltx_border_tt">19.15 / 17.21</td>
<td id="S4.T3.1.1.3.3.11" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S4.T3.1.1.3.3.11.1" class="ltx_text ltx_font_bold">11.21</span> / <span id="S4.T3.1.1.3.3.11.2" class="ltx_text ltx_font_bold">9.54</span>
</td>
<td id="S4.T3.1.1.3.3.12" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S4.T3.1.1.3.3.12.1" class="ltx_text ltx_font_bold">10.54</span> / <span id="S4.T3.1.1.3.3.12.2" class="ltx_text ltx_font_bold">9.45</span>
</td>
</tr>
<tr id="S4.T3.1.1.4.4" class="ltx_tr">
<td id="S4.T3.1.1.4.4.1" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.4.4.2" class="ltx_td ltx_align_center">✗</td>
<td id="S4.T3.1.1.4.4.3" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.4.4.4" class="ltx_td ltx_align_center">2000</td>
<td id="S4.T3.1.1.4.4.5" class="ltx_td ltx_align_center">4.35 / 5.41</td>
<td id="S4.T3.1.1.4.4.6" class="ltx_td ltx_align_center">14.96 / 11.82</td>
<td id="S4.T3.1.1.4.4.7" class="ltx_td ltx_align_center">8.41 / 6.88</td>
<td id="S4.T3.1.1.4.4.8" class="ltx_td ltx_align_center">5.11 / 6.35</td>
<td id="S4.T3.1.1.4.4.9" class="ltx_td ltx_align_center">13.30 / 11.70</td>
<td id="S4.T3.1.1.4.4.10" class="ltx_td ltx_align_center">20.28 / 19.27</td>
<td id="S4.T3.1.1.4.4.11" class="ltx_td ltx_align_center">17.03 / 16.59</td>
<td id="S4.T3.1.1.4.4.12" class="ltx_td ltx_align_center">11.92 / 11.14</td>
</tr>
<tr id="S4.T3.1.1.5.5" class="ltx_tr">
<td id="S4.T3.1.1.5.5.1" class="ltx_td ltx_align_center">3</td>
<td id="S4.T3.1.1.5.5.2" class="ltx_td ltx_align_center">✗</td>
<td id="S4.T3.1.1.5.5.3" class="ltx_td ltx_align_center">✓</td>
<td id="S4.T3.1.1.5.5.4" class="ltx_td ltx_align_center">4000</td>
<td id="S4.T3.1.1.5.5.5" class="ltx_td ltx_align_center">4.11 / 5.23</td>
<td id="S4.T3.1.1.5.5.6" class="ltx_td ltx_align_center">14.93 / 11.76</td>
<td id="S4.T3.1.1.5.5.7" class="ltx_td ltx_align_center">8.00 / 6.53</td>
<td id="S4.T3.1.1.5.5.8" class="ltx_td ltx_align_center">4.78 / 5.80</td>
<td id="S4.T3.1.1.5.5.9" class="ltx_td ltx_align_center">13.23 / 11.59</td>
<td id="S4.T3.1.1.5.5.10" class="ltx_td ltx_align_center">18.90 / 18.32</td>
<td id="S4.T3.1.1.5.5.11" class="ltx_td ltx_align_center">13.27 / 13.16</td>
<td id="S4.T3.1.1.5.5.12" class="ltx_td ltx_align_center">11.03 / 10.34</td>
</tr>
<tr id="S4.T3.1.1.6.6" class="ltx_tr">
<td id="S4.T3.1.1.6.6.1" class="ltx_td ltx_align_center ltx_border_b">4</td>
<td id="S4.T3.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S4.T3.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_b">✓</td>
<td id="S4.T3.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_b">4000</td>
<td id="S4.T3.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_b">4.00 / 5.04</td>
<td id="S4.T3.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_b">
<span id="S4.T3.1.1.6.6.6.1" class="ltx_text ltx_font_bold">14.79</span> / 12.03</td>
<td id="S4.T3.1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_b">7.94 / 6.35</td>
<td id="S4.T3.1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_b">4.40 / <span id="S4.T3.1.1.6.6.8.1" class="ltx_text ltx_font_bold">5.42</span>
</td>
<td id="S4.T3.1.1.6.6.9" class="ltx_td ltx_align_center ltx_border_b">12.74 / 11.01</td>
<td id="S4.T3.1.1.6.6.10" class="ltx_td ltx_align_center ltx_border_b">
<span id="S4.T3.1.1.6.6.10.1" class="ltx_text ltx_font_bold">18.69</span> / <span id="S4.T3.1.1.6.6.10.2" class="ltx_text ltx_font_bold">17.94</span>
</td>
<td id="S4.T3.1.1.6.6.11" class="ltx_td ltx_align_center ltx_border_b">12.78 / 11.90</td>
<td id="S4.T3.1.1.6.6.12" class="ltx_td ltx_align_center ltx_border_b">10.76 / 9.95</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Efficiency Analysis of Discrete Tokens</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Figure <a href="#S4.F2" title="Figure 2 ‣ IV-C Efficiency Analysis of Discrete Tokens ‣ IV Experiments ‣ Exploring SSL Discrete Tokens for Multilingual ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents a comparative analysis of training durations (minutes) for one epoch across diverse language domains, contrasting the use of FBank features and discrete tokens. To ensure a fair comparison of training efficiency between Fbank and discrete token approaches, both experiments were conducted with an equal number of epochs. The results demonstrate that training with discrete tokens yields significantly reduced training times across all languages examined. This efficiency gain is particularly pronounced in the Polish language domain, where the training time using discrete tokens is remarkably less than 35% of the time required when utilizing FBank as input features.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">This substantial reduction in training time can be attributed to the compact representation provided by discrete tokens, which effectively condense the rich acoustic information present in speech signals. Such compression not only accelerates the training process but also potentially reduces computational resource requirements. These findings suggest that the adoption of discrete tokens in multilingual speech recognition systems could lead to more efficient model development and deployment, especially in scenarios where computational resources are constrained or rapid iteration is imperative.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<p id="S4.F2.1" class="ltx_p ltx_align_center"><span id="S4.F2.1.1" class="ltx_text"><img src="/html/2409.08805/assets/x2.png" id="S4.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="207" height="141" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustration of training time (minutes) per epoch using Discrete tokens / Fbank features.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Ablation Study</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">To evaluate the multilingual capabilities of discrete tokens, we examine the data mixing, the effects of shared k-means, and k-means units across seven language domains. Data mixing is the process of combining seven language domains into a unified dataset. The shared k-means was utilized to extract discrete tokens across all seven languages, allowing us to assess the effectiveness of this unified tokenization method in a multilingual context. To better compare the performance of discrete tokens, we use the best setup from the monolingual experiment of XLSR-53 (Sys.6, TABLE I, also showing Sys.1 in TABLE III) to conduct an ablation study. From the TABLE III, several trends can be found:</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">1) When comparing multilingual ASR with monolingual ASR (Sys.2 and Sys.3 vs. Sys.1), we observe that the shared k-means approach (using 2000 or 4000 clusters shared across 7 languages) underperforms compared to the monolingual approach (where each language has its own 2000 clusters). This performance gap likely arises from the challenge of adequately representing the nuanced characteristics of all seven languages with a shared set of 2000 or 4000 clusters, whereas 2000 clusters appear sufficient for capturing the features of a single language. As a result, distinct phonetic or semantic elements from different languages may be incorrectly assigned to the same discrete token label in the multilingual model, leading to reduced accuracy.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">2) The performance comparison between the shared k-means models with 2000 and 4000 clusters (Sys.2 vs. Sys.3) reveals that a higher cluster count yields better results. This suggests that increasing the number of clusters enables the extraction of more refined discrete tokens, thus capturing subtler speech features. This enhanced granularity in token discretization allows for a more precise encoding of acoustic characteristics but doesn’t necessarily outperform the monolingual approach (Sys.1).</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">3) The Zipformer-Transducer with mixing data and employing a shared k-means model achieves comparable performance to its counterpart without these features (Sys.4 vs. Sys.1) while potentially offering better cross-lingual generalization through its multilingual training strategy. We also attempted to mix data and employ a shared k-means model with 2000 units. However, this system failed to converge, indicating that using a shared K-means model with 2000 units is insufficient for effective training.</p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.1" class="ltx_p">4) Across all seven languages, the performance of the multilingual systems (Sys.2-4) consistently underperforms the monolingual training approach (Sys.1). This uniform underperformance strongly indicates that the optimal strategy for multilingual model development is to train separate models for each individual language, rather than employing mixed-language training methods.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Exploring the universality of speech discrete tokens across multilingual and monolingual ASR for seven languages, this paper presents a comprehensive study yields significant insights into the universality and efficacy of these tokens. Through an extensive investigation of discrete tokens derived from three leading SSL models: WavLM, XLSR-53, and EnCodec, experimental results indicate that discrete tokens are competitive with FBank features in ASR tasks across seven language domains in both multilingual and monolingual scenarios. Notably, the best-performing Zipformer-Transducer system using discrete tokens outperforms the Fbank-based baselines with an average WER reduction of 0.31% and 1.76% absolute (2.80% and 15.70% relative) on the dev and test sets across the seven languages and shows a remarkable performance with a 6.82% absolute (41.68% relative) WER reduction on the Polish test set. In terms of training efficacy, training with discrete tokens consistently outperforms FBank features across all languages, with the Polish domain demonstrating a notable reduction in training time to less than 35% of that required when using FBank features. These empirical findings suggest that universal discrete tokens have considerable potential across diverse multilingual speech tasks.
We hope that this work serves as the foundation for multilingual ASR, paving the way for future research on discrete tokens in diverse language recognition.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Mohamed, H.-y. Lee <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Self-supervised speech representation learning: A review,” <em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic">IEEE JSTSP</em>, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S. Chen <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Wavlm: large-scale self-supervised pre-training for full stack speech processing,” <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">IEEE JSTSP</em>, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Baevski <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Wav2vec 2.0: a framework for self-supervised learning of speech representations,” <em id="bib.bib3.2.2" class="ltx_emph ltx_font_italic">NIPS</em>, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Baevski, S. Schneider, and M. Auli, “Vq-wav2vec: self-supervised learning of discrete speech representations,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.05453</em>, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. Graves <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,” in <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">ICML, 2006</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
M. Ghodsi, X. Liu <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Rnn-transducer with stateless prediction network,” in <em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic">IEEE ICASSP</em>, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Gulati, J. Qin, C.-C. Chiu, N. Parmar, Y. Zhang, J. Yu, W. Han, S. Wang, Z. Zhang, Y. Wu <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Conformer: Convolution-augmented transformer for speech recognition,” <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.08100</em>, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
E. Tsunoo, Y. Kashiwagi <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Transformer ASR with Contextual Block Processing,” in <em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">ASRU Workshop</em>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
X. Chen <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Developing real-time streaming transformer transducer for speech recognition on large-scale dataset,” in <em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic">IEEE ICASSP</em>, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
X. Liu, M. Gales <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Use of contexts in language model interpolation and adaptation,” <em id="bib.bib10.2.2" class="ltx_emph ltx_font_italic">CSL</em>, 2013.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
M. Cui <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards effective and compact contextual representation for conformer transducer speech recognition systems,” in <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. Deng <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Confidence score based conformer speaker adaptation for speech recognition,” <em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Z. Dai <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Transformer-xl: attentive language models beyond a fixed-length context,” <em id="bib.bib13.2.2" class="ltx_emph ltx_font_italic">ACL</em>, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
W.-N. Hsu, B. Bolte, Y.-H. H. Tsai, K. Lakhotia, R. Salakhutdinov, and A. Mohamed, “Hubert: Self-supervised speech representation learning by masked prediction of hidden units,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM transactions on audio, speech, and language processing</em>, vol. 29, pp. 3451–3460, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
N. Zeghidour, A. Luebs <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Soundstream: an end-to-end neural audio codec,” <em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic">IEEE TASLP</em>, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. Défossez, J. Copet, G. Synnaeve, and Y. Adi, “High fidelity neural audio compression,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.13438</em>, 2022.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
X. Chang <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Exploring speech recognition, translation, and understanding with discrete speech units: A comparative study,” <em id="bib.bib17.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.15800</em>, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. Baevski <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Effectiveness of self-supervised pre-training for speech recognition,” <em id="bib.bib18.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.03912</em>, 2019.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
X. Chang <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Exploration of efficient end-to-end asr using discretized input from self-supervised learning,” <em id="bib.bib19.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.18108</em>, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Y. Yang <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards universal speech discrete tokens: a case study for asr and tts,” <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.07377</em>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
X. Chang, J. Shi, J. Tian, Y. Wu, Y. Tang, Y. Wu, S. Watanabe, Y. Adi, X. Chen, and Q. Jin, “The interspeech 2024 challenge on speech processing using discrete units,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.07725</em>, 2024.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
S. Ueno, M. Mimura, S. Sakai, and T. Kawahara, “Data augmentation for asr using tts via a discrete representation,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
B. Li, R. Pang, T. N. Sainath, A. Gulati, Y. Zhang, J. Qin, P. Haghani, W. R. Huang, M. Ma, and J. Bai, “Scaling end-to-end models for large-scale multilingual asr,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
V. Pratap, A. Sriram, P. Tomasello, A. Hannun, V. Liptchinsky, G. Synnaeve, and R. Collobert, “Massively multilingual asr: 50 languages, 1 model, 1 billion parameters,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.03001</em>, 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
J. Bai, B. Li, Y. Zhang, A. Bapna, N. Siddhartha, K. C. Sim, and T. N. Sainath, “Joint unsupervised and supervised training for multilingual asr,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
J. Li <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Recent advances in end-to-end automatic speech recognition,” <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">APSIPA</em>, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
J. Shi, S.-H. Wang, W. Chen, M. Bartelds, V. B. Kumar, J. Tian, X. Chang, D. Jurafsky, K. Livescu, H.-y. Lee <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Ml-superb 2.0: Benchmarking multilingual speech models across modeling constraints, languages, and datasets,” <em id="bib.bib27.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.08641</em>, 2024.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
A. Graves, “Sequence transduction with recurrent neural networks,” <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1211.3711</em>, 2012.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
J. Hou <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Bring dialogue-context into RNN-T for streaming ASR,” <em id="bib.bib29.2.2" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2022.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Q. Zhang, H. Lu <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Transformer transducer: a streamable speech recognition model with transformer encoders and RNN-T loss,” in <em id="bib.bib30.2.2" class="ltx_emph ltx_font_italic">IEEE ICASSP</em>, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Z. Yao, L. Guo <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Zipformer: A faster and better encoder for automatic speech recognition,” <em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.11230</em>, 2023.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
V. Pratap, Q. Xu, A. Sriram, G. Synnaeve, and R. Collobert, “Mls: A large-scale multilingual dataset for speech research,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.03411</em>, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
D. S. Park <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Specaugment: A Simple Data Augmentation Method for Automatic Speech Recognition,” <em id="bib.bib33.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.08779</em>, 2019.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever, “Robust speech recognition via large-scale weak supervision,” in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   PMLR, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
A. Conneau, A. Baevski, R. Collobert, A. Mohamed, and M. Auli, “Unsupervised cross-lingual representation learning for speech recognition,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.13979</em>, 2020.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.08804" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.08805" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.08805">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.08805" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.08806" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 18:12:05 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
