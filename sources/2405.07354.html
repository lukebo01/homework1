<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.07354] SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset</title><meta property="og:description" content="The application of Automatic Speech Recognition (ASR) technology in soccer offers numerous opportunities for sports analytics. Specifically, extracting audio commentaries with ASR provides valuable insights into the ev…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.07354">

<!--Generated on Wed Jun  5 18:20:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sushant Gautam<sup id="id17.17.id1" class="ltx_sup"><span id="id17.17.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>
 Mehdi Houshmand Sarkhoosh<sup id="id18.18.id2" class="ltx_sup"><span id="id18.18.id2.1" class="ltx_text ltx_font_italic">2,3</span></sup>
 Jan Held<sup id="id19.19.id3" class="ltx_sup"><span id="id19.19.id3.1" class="ltx_text ltx_font_italic">5</span></sup>
 Cise Midoglu<sup id="id20.20.id4" class="ltx_sup"><span id="id20.20.id4.1" class="ltx_text ltx_font_italic">1,3</span></sup> 
<br class="ltx_break"><span id="id5.5.1" class="ltx_text ltx_font_bold">Anthony Cioppa<sup id="id5.5.1.1" class="ltx_sup"><span id="id5.5.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">5,6</span></sup></span>
 <span id="id6.6.2" class="ltx_text ltx_font_bold">Silvio Giancola<sup id="id6.6.2.1" class="ltx_sup"><span id="id6.6.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">6</span></sup></span>
 <span id="id7.7.3" class="ltx_text ltx_font_bold">Vajira Thambawita<sup id="id7.7.3.1" class="ltx_sup"><span id="id7.7.3.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span> 
<br class="ltx_break"> <span id="id8.8.4" class="ltx_text ltx_font_bold">Michael A. Riegler<sup id="id8.8.4.1" class="ltx_sup"><span id="id8.8.4.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>
 <span id="id9.9.5" class="ltx_text ltx_font_bold">Pål Halvorsen<sup id="id9.9.5.1" class="ltx_sup"><span id="id9.9.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,2,3</span></sup></span>
 <span id="id11.11.7" class="ltx_text ltx_font_bold">Mubarak Shah<sup id="id11.11.7.1" class="ltx_sup"><span id="id11.11.7.1.1" class="ltx_text ltx_font_medium ltx_font_italic">4</span></sup>
<br class="ltx_break"><sup id="id11.11.7.2" class="ltx_sup"><span id="id11.11.7.2.1" class="ltx_text ltx_font_medium">1</span></sup></span><span id="id21.21.id5" class="ltx_text ltx_font_italic">SimulaMet, Norway</span>  <sup id="id22.22.id6" class="ltx_sup">2</sup><span id="id23.23.id7" class="ltx_text ltx_font_italic">OsloMet, Norway</span>  <sup id="id24.24.id8" class="ltx_sup">3</sup><span id="id25.25.id9" class="ltx_text ltx_font_italic">Forzasys, Norway</span> 
<br class="ltx_break"><sup id="id26.26.id10" class="ltx_sup">4</sup><span id="id27.27.id11" class="ltx_text ltx_font_italic">University of Central Florida, USA</span>  <sup id="id28.28.id12" class="ltx_sup">5</sup><span id="id29.29.id13" class="ltx_text ltx_font_italic">University of Liège, Belgium</span>  <sup id="id30.30.id14" class="ltx_sup">6</sup><span id="id31.31.id15" class="ltx_text ltx_font_italic">KAUST, Saudi Arabia
<br class="ltx_break"><a target="_blank" href="https://github.com/SoccerNet/sn-echoes" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://github.com/SoccerNet/sn-echoes</a></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id32.id1" class="ltx_p"><span id="id32.id1.1" class="ltx_text" lang="en">The application of <span title="" class="ltx_glossaryref">Automatic Speech Recognition (ASR)</span> technology in soccer offers numerous opportunities for sports analytics. Specifically, extracting audio commentaries with <span title="" class="ltx_glossaryref">ASR</span> provides valuable insights into the events of the game, and opens the door to several downstream applications such as automatic highlight generation. This paper presents SoccerNet-Echoes, an augmentation of the SoccerNet dataset with automatically generated transcriptions of audio commentaries from soccer game broadcasts, enhancing video content with rich layers of textual information derived from the game audio using <span title="" class="ltx_glossaryref">ASR</span>. These textual commentaries, generated using the <em id="id32.id1.1.1" class="ltx_emph ltx_font_italic">Whisper</em> model and translated with <em id="id32.id1.1.2" class="ltx_emph ltx_font_italic">Google Translate</em>, extend the usefulness of the SoccerNet dataset in diverse applications such as enhanced action spotting, automatic caption generation, and game summarization. By incorporating textual data alongside visual and auditory content, SoccerNet-Echoes aims to serve as a comprehensive resource for the development of algorithms specialized in capturing the dynamics of soccer games. We detail the methods involved in the curation of this dataset and the integration of <span title="" class="ltx_glossaryref">ASR</span>. We also highlight the implications of a multimodal approach in sports analytics, and how the enriched dataset can support diverse applications, thus broadening the scope of research and development in the field of sports analytics.</span></p>
</div>
<section id="S1" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2405.07354/assets/figures/images/pipeline.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="172" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">The pipeline for generating a multilingual commentary dataset from soccer game videos, incorporating different Whisper versions, language detection and translation.</span></figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Sports analytics has progressively embraced technological innovations, to enrich the analysis and understanding of complex sports events. Historically, analysis of sports video footage relied primarily on visual cues: action spotting, player recognition and player tracking were based solely on videos and video frames as images. However, with the advancement in multimodal data integration, the scope of sports analytics has broadened, encompassing audio and textual data alongside traditional visual input. This integration facilitates a more holistic view of sports events, capturing the nuances of game dynamics that visual data alone might miss.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The SoccerNet dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, initially designed to support video-based analyses such as action spotting, player tracking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, camera calibration <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, dense video captioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, foul recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and game state reconstruction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, has emerged as a key resource in sports video analytics. Yet, the rapidly evolving field of sports analytics demands ever more sophisticated tools that can process and interpret the complex interplay of multiple data modalities, including video, audio, and text. In response to this need, we augment the SoccerNet dataset by incorporating state-of-the-art <span title="" class="ltx_glossaryref">ASR</span> technology to enrich the dataset with textual information derived from live game commentaries. This multimodal approach aims to refine the accuracy of existing tasks such as action spotting and dense video captioning, as well as extends the dataset’s usefulness in more complex applications such as sentiment analysis or tactical assessment.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">This paper details our augmentation of the SoccerNet dataset to include audio commentary transcriptions, generated with OpenAI’s Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> tool, and translated with Google Translate <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The resulting SoccerNet-Echoes dataset serves as a comprehensive toolkit for researchers and practitioners, allowing enhanced interpretation and narrative generation from sports footage. Through the integration of audio commentaries in textual format, SoccerNet-Echoes facilitates a deeper understanding of the contextual aspects of soccer games, thereby enhancing both the analytical capabilities and the viewer’s experience.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Contributions.</span> Our contributions are threefold: (i) We augment the SoccerNet dataset with automatically transcribed and translated audio commentaries from soccer game broadcasts in multiple languages, and present this new dataset (SoccerNet-Echoes) as an open-access resource. (ii) We evaluate SoccerNet-Echoes using human-verified <span title="" class="ltx_glossaryref">ASR</span> from literature and perform quantitative analysis. (iii) We explore the potential applications of SoccerNet-Echoes in various research areas, and highlight the broader implications of adopting a multimodal approach for sports research in general.</p>
</div>
</section>
<section id="S2" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The integration of <span title="" class="ltx_glossaryref">ASR</span> technology has significantly advanced the analysis and processing of video content, impacting sports research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Initially, video understanding focused primarily on computer vision tasks, such as action recognition and event spotting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Advancements in dense video captioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> began to explore the generation of captions for temporally localized activities within untrimmed videos, representing a significant departure from the traditional approach of generating a single caption for short clips. Further evolution in the field saw the incorporation of audio and speech modalities alongside visual data, enhancing video captioning capabilities.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Early Applications: Action Recognition and Event Detection</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Before the integration of <span title="" class="ltx_glossaryref">ASR</span>, the primary focus in sports video analysis was on visual cues for game action recognition and event detection (spotting) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Researchers began to explore the use of multimodal sports data, combining game audio and video streams to improve the accuracy of action spotting in soccer videos <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. These studies marked an early recognition of the potential benefits of incorporating audio data alongside traditional video processing, setting the stage for the subsequent integration of <span title="" class="ltx_glossaryref">ASR</span> technologies in sports game analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Transition to Speech and Language Processing</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">As the potential of multimodal analysis became evident, subsequent studies began to integrate more sophisticated speech and language processing technologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. Gao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> utilized <span title="" class="ltx_glossaryref">ASR</span> to segment and categorize commentary from soccer videos, thereby enhancing key moment extraction and highlight generation. This application of <span title="" class="ltx_glossaryref">ASR</span> for segmenting commentator speech represented a shift towards leveraging linguistic information to complement visual data. Gautam et al. used captions, text and commentaries extracted from <span title="" class="ltx_glossaryref">ASR</span> for game summarization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, and used audio intensity to capture the field excitement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Multimodal Dense Video Captioning</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The application of textual modality in sports video analysis reached a new level with the introduction of dense video captioning tasks, as exemplified by the SoccerNet Challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. The SoccerNet-Caption dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> leverages rich, timestamped textual commentaries that capture both factual and emotional aspects of the game. Aiming to bridge the gap for fans unable to watch soccer games live by providing engaging summaries that mimic the excitement of real-time commentary, this task demonstrated the growing importance of textual modality in creating immersive fan experiences.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Lashin et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> highlighted the transformative potential of integrating <span title="" class="ltx_glossaryref">ASR</span> alongside video and audio data in dense video captioning. Their multimodal approach significantly improved event description accuracy, emphasizing the vital contextual cues provided by <span title="" class="ltx_glossaryref">ASR</span> that often elude video-only analyses. By combining visual information with speech data, their method demonstrated substantial performance enhancements, showcasing the synergistic benefits of leveraging multimodal inputs for comprehensive video understanding. <span title="" class="ltx_glossaryref">Movie Audio Descriptions (MAD)</span> dataset offers a novel benchmark for video-language grounding tasks, by aligning audio descriptions of mainstream movies with video content <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. The multimodal approach has since been embraced <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, enriching the scope of video captioning and commentary generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, and illustrating the transformative impact of <span title="" class="ltx_glossaryref">ASR</span> technology in video content analysis and processing.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Advancements in ASR Technologies</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">The development of LLM-based <span title="" class="ltx_glossaryref">ASR</span> technologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> further accelerated the use of speech recognition in sports analytics. The GOAL dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, derived from SoccerNet videos, comprises 80 full-game videos transcribed into raw text using the Azure ASR toolkit, then meticulously curated by English-speaking, soccer-knowledgeable annotators. 20 games were selected after quality filtering, and annotation tasks included proofreading, aligning text with video timelines, and annotating knowledge entities, ensuring comprehensive linguistic and visual analysis. Ikeda et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> leveraged <span title="" class="ltx_glossaryref">ASR</span> alongside Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> and a speech recognition model trained on the extensive Japanese audio corpus ReazonSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> to transcribe commentary from 134 Japanese <span title="" class="ltx_glossaryref">Major League Baseball (MLB)</span> highlight videos. To address noise challenges, Whisper transcripts underwent manual labeling, while ReazonSpeech transcripts were labeled using keyword techniques, thereby improving dataset quality and reducing time overheads. These approaches underscore a growing trend in leveraging <span title="" class="ltx_glossaryref">ASR</span> technology to create rich datasets for detailed examination of both linguistic and visual elements in sports commentary.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Broader Applications and Future Directions</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">The integration of <span title="" class="ltx_glossaryref">ASR</span> technology into soccer video analysis has followed a trajectory from enhancing basic action recognition to enabling sophisticated, multimodal interpretations of complex events. The evolution of this technology has not only improved the analytical capabilities of researchers but has also significantly enhanced the viewing experience for fans worldwide. Beyond soccer, the integration of <span title="" class="ltx_glossaryref">ASR</span> has also influenced broader video analysis tasks. Hessel et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> explored combining <span title="" class="ltx_glossaryref">ASR</span> and visual features to generate captions for instructional videos, highlighting how <span title="" class="ltx_glossaryref">ASR</span> can aid in distinguishing between similar actions through linguistic cues. Sattar et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> focused on identifying events in cricket games by combining commentary text obtained from <span title="" class="ltx_glossaryref">ASR</span> with visual data and cues such as replays, bowler and umpire positions.</p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p">These applications suggest potential future directions where <span title="" class="ltx_glossaryref">ASR</span> could be integrated into various types of content beyond sports, enriching content accessibility and understanding across domains. As <span title="" class="ltx_glossaryref">ASR</span> technology continues to advance, its applications in video analysis are expected to expand, further revolutionizing the field and providing deeper insights into the intricate dynamics of media content. However, it is important to acknowledge that despite the advancements, <span title="" class="ltx_glossaryref">ASR</span> technology is not flawless. Automated capture introduces uncertainty and errors in the ground truth data. Nonetheless, its cost-effectiveness and scalability make <span title="" class="ltx_glossaryref">ASR</span> a promising candidate for widespread use.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset Curation</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our comprehensive approach to curating a multilingual soccer commentary dataset, which includes the automated transcription and translation of commentaries, is illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Below, we detail the curation of the SoccerNet-Echoes using the illustrated methodology.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Sources and Collection</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We used all 1100 game half videos from the SoccerNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> dataset. These correspond to 550 games from 6 different leagues and 4 different seasons, as depicted in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Sources and Collection ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The games were narrated live by commentators speaking one of 10 different languages. The distribution of the original language of the broadcast game audio is provided in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.1 Sources and Collection ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We automatically extracted commentaries in textual format following the procedure described below.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><svg id="S3.F2.pic1" class="ltx_picture ltx_centering" height="214.92" overflow="visible" version="1.1" width="580.45"><g transform="translate(0,214.92) matrix(1 0 0 -1 0 0) translate(42.45,0) translate(0,66.9) matrix(1.0 0.0 0.0 1.0 -42.45 -66.9)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0) translate(87.26,0) translate(0,79.21)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><clipPath id="pgfcp1"><path d="M -44.81 -209.16 L 492.92 -209.16 L 492.92 332.28 L -44.81 332.28"></path></clipPath><g clip-path="url(#pgfcp1)"><g stroke-width="0.2pt" fill="#808080" stroke="#808080" color="#808080"><path d="M 0 -18.22 L 0 -12.31 M 179.24 -18.22 L 179.24 -12.31 M 358.48 -18.22 L 358.48 -12.31 M 268.86 -18.22 L 268.86 -12.31 M 448.1 -18.22 L 448.1 -12.31 M 89.62 -18.22 L 89.62 -12.31" style="fill:none"></path></g><g></g></g><clipPath id="pgfcp2"><path d="M -241.66 -12.31 L -241.66 135.43 L 689.77 135.43 L 689.77 -12.31"></path></clipPath><g clip-path="url(#pgfcp2)"><g stroke-width="0.2pt" fill="#808080" stroke="#808080" color="#808080"><path d="M -44.81 -1.47 L -38.91 -1.47 M -44.81 27.85 L -38.91 27.85 M -44.81 57.16 L -38.91 57.16 M -44.81 86.48 L -38.91 86.48 M -44.81 115.79 L -38.91 115.79" style="fill:none"></path></g><g></g></g><path d="M -44.81 -12.31 L 492.92 -12.31" style="fill:none"></path><path d="M -44.81 -12.31 L -44.81 135.43" style="fill:none"></path><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 -19.55 -44.45)" fill="#000000" stroke="#000000"><foreignObject width="27.48" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.6.6.6.6.1.1" class="ltx_text">EPL</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 149.78 -52.47)" fill="#000000" stroke="#000000"><foreignObject width="40.17" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.7.7.7.7.1.1" class="ltx_text">Ligue1</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 330.35 -53.04)" fill="#000000" stroke="#000000"><foreignObject width="39.63" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.8.8.8.8.1.1" class="ltx_text">SerieA</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 221.19 -70.79)" fill="#000000" stroke="#000000"><foreignObject width="65.99" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.9.9.9.9.1.1" class="ltx_text">Bundesliga</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 417.41 -53.69)" fill="#000000" stroke="#000000"><foreignObject width="41.9" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.10.10.10.10.1.1" class="ltx_text">LaLiga</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 68.99 -45.54)" fill="#000000" stroke="#000000"><foreignObject width="29.02" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.11.11.11.11.1.1" class="ltx_text">UCL</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -56.62 -5.92)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -63.54 23.39)" fill="#000000" stroke="#000000"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1c">20</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -63.54 52.7)" fill="#000000" stroke="#000000"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="40" display="inline"><semantics id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1c">40</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -63.54 82.02)" fill="#000000" stroke="#000000"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="60" display="inline"><semantics id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1c">60</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -63.54 111.33)" fill="#000000" stroke="#000000"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1c">80</annotation></semantics></math></foreignObject></g><clipPath id="pgfcp3"><path d="M -44.81 -12.31 L 492.92 -12.31 L 492.92 135.43 L -44.81 135.43 Z"></path></clipPath><g clip-path="url(#pgfcp3)"><g stroke="#0000FF" fill="#B3B3FF" color="#0000FF"><path d="M -23.52 -1.47 h 13.84 v 8.79 h -13.84 Z M 155.72 -1.47 h 13.84 v 1.47 h -13.84 Z M 334.96 -1.47 h 13.84 v 16.12 h -13.84 Z M 245.34 -1.47 h 13.84 v 11.73 h -13.84 Z M 424.58 -1.47 h 13.84 v 26.38 h -13.84 Z M 66.1 -1.47 h 13.84 v 54.23 h -13.84 Z"></path></g><g></g><g stroke="#FF0000" fill="#FFB3B3" color="#FF0000"><path d="M -6.92 -1.47 h 13.84 v 71.82 h -13.84 Z M 82.7 -1.47 h 13.84 v 65.96 h -13.84 Z M 172.32 -1.47 h 13.84 v 4.4 h -13.84 Z M 261.94 -1.47 h 13.84 v 26.38 h -13.84 Z M 351.56 -1.47 h 13.84 v 13.19 h -13.84 Z M 441.19 -1.47 h 13.84 v 52.77 h -13.84 Z"></path></g><g></g><g stroke="#734D26" fill="#ECD9C6" color="#734D26"><path d="M 9.69 -1.47 h 13.84 v 71.82 h -13.84 Z M 99.31 -1.47 h 13.84 v 38.11 h -13.84 Z M 188.93 -1.47 h 13.84 v 63.03 h -13.84 Z M 278.55 -1.47 h 13.84 v 51.3 h -13.84 Z M 368.17 -1.47 h 13.84 v 124.58 h -13.84 Z M 457.79 -1.47 h 13.84 v 92.34 h -13.84 Z"></path></g><g></g><g stroke="#000000" fill="#808080" color="#000000"><path d="M 474.39 -1.47 h 13.84 v 11.73 h -13.84 Z"></path></g><g></g></g><g transform="matrix(0.0 1.0 -1.0 0.0 -73.04 6.49)" fill="#000000" stroke="#000000"><foreignObject width="110.52" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.12.12.12.12.1.1" class="ltx_text">Number of Games</span></foreignObject></g><g fill="#FFFFFF" stroke="#000000"><path d="M -28.41 57.82 h 86.8 v 72.91 h -86.8 Z"></path></g><g fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -24.25 60.58)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 58.95)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.58)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0) translate(2.35,0)" fill="#B3B3FF" stroke="#0000FF" color="#0000FF"><path d="M -2.08 -2.77 h 4.15 v 11.07 h -4.15 Z M 6.23 -2.77 h 4.15 v 8.3 h -4.15 Z"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 13.01 0) translate(32.75,0) matrix(1.0 0.0 0.0 1.0 -29.98 -3.42)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 4.46)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.92)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">2014-2015</text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 25.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0) translate(2.35,0)" fill="#FFB3B3" stroke="#FF0000" color="#FF0000"><path d="M -2.08 -2.77 h 4.15 v 11.07 h -4.15 Z M 6.23 -2.77 h 4.15 v 8.3 h -4.15 Z"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 13.01 0) translate(32.75,0) matrix(1.0 0.0 0.0 1.0 -29.98 -3.42)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 4.46)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.92)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">2015-2016</text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 42.27)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0) translate(2.35,0)" fill="#ECD9C6" stroke="#734D26" color="#734D26"><path d="M -2.08 -2.77 h 4.15 v 11.07 h -4.15 Z M 6.23 -2.77 h 4.15 v 8.3 h -4.15 Z"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 13.01 0) translate(32.75,0) matrix(1.0 0.0 0.0 1.0 -29.98 -3.42)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 4.46)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.92)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">2016-2017</text></g></g></g></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 59.11)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0) translate(2.35,0)" fill="#808080" stroke="#000000" color="#000000"><path d="M -2.08 -2.77 h 4.15 v 11.07 h -4.15 Z M 6.23 -2.77 h 4.15 v 8.3 h -4.15 Z"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 13.01 0) translate(32.75,0) matrix(1.0 0.0 0.0 1.0 -29.98 -3.42)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 4.46)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.92)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">2019-2020</text></g></g></g></g></g></g></g></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Number of games<span id="S3.F2.4.2.1" class="ltx_text ltx_font_medium"> per league and season in the SoccerNet dataset (550 in total).</span></span></figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure"><svg id="S3.F3.pic1" class="ltx_picture ltx_centering" height="230.98" overflow="visible" version="1.1" width="587.22"><g transform="translate(0,230.98) matrix(1 0 0 -1 0 0) translate(49.21,0) translate(0,78.26) matrix(1.0 0.0 0.0 1.0 -49.21 -78.26)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0) translate(94.03,0) translate(0,78.26)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><clipPath id="pgfcp4"><path d="M -44.81 -196.85 L 492.92 -196.85 L 492.92 344.58 L -44.81 344.58"></path></clipPath><g clip-path="url(#pgfcp4)"><g stroke-width="0.2pt" fill="#808080" stroke="#808080" color="#808080"><path d="M 0 -5.91 L 0 0 M 44.81 -5.91 L 44.81 0 M 89.62 -5.91 L 89.62 0 M 134.43 -5.91 L 134.43 0 M 179.24 -5.91 L 179.24 0 M 224.05 -5.91 L 224.05 0 M 268.86 -5.91 L 268.86 0 M 313.67 -5.91 L 313.67 0 M 358.49 -5.91 L 358.49 0 M 403.3 -5.91 L 403.3 0 M 448.11 -5.91 L 448.11 0" style="fill:none"></path></g><g></g></g><clipPath id="pgfcp5"><path d="M -241.67 0 L -241.67 147.73 L 689.77 147.73 L 689.77 0"></path></clipPath><g clip-path="url(#pgfcp5)"><g stroke-width="0.2pt" fill="#808080" stroke="#808080" color="#808080"><path d="M -44.81 0 L -38.91 0 M -44.81 45.22 L -38.91 45.22 M -44.81 90.44 L -38.91 90.44 M -44.81 135.66 L -38.91 135.66" style="fill:none"></path></g><g></g></g><path d="M -44.81 0 L 492.92 0" style="fill:none"></path><path d="M -44.81 0 L -44.81 147.73" style="fill:none"></path><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 -32.73 -43.53)" fill="#000000" stroke="#000000"><foreignObject width="44.86" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.16.16.16.16.1.1" class="ltx_text">English</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 10.59 -45.02)" fill="#000000" stroke="#000000"><foreignObject width="46.97" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.17.17.17.17.1.1" class="ltx_text">Spanish</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 56.11 -46.11)" fill="#000000" stroke="#000000"><foreignObject width="47.24" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.18.18.18.18.1.1" class="ltx_text">Russian</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 99.98 -47.05)" fill="#000000" stroke="#000000"><foreignObject width="48.56" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.19.19.19.19.1.1" class="ltx_text">German</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 150.48 -41.46)" fill="#000000" stroke="#000000"><foreignObject width="40.59" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.20.20.20.20.1.1" class="ltx_text">French</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 191.3 -45.46)" fill="#000000" stroke="#000000"><foreignObject width="46.24" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.21.21.21.21.1.1" class="ltx_text">Turkish</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 240.81 -40.75)" fill="#000000" stroke="#000000"><foreignObject width="39.59" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.22.22.22.22.1.1" class="ltx_text">Italian</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 287.61 -38.77)" fill="#000000" stroke="#000000"><foreignObject width="36.78" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.23.23.23.23.1.1" class="ltx_text">Polish</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 324.21 -46.87)" fill="#000000" stroke="#000000"><foreignObject width="48.31" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.24.24.24.24.1.1" class="ltx_text">Bosnian</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 357.36 -56.63)" fill="#000000" stroke="#000000"><foreignObject width="63.46" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.25.25.25.25.1.1" class="ltx_text">Hungarian</span></foreignObject></g><g transform="matrix(0.7071 0.7071 -0.7071 0.7071 389.07 -71.74)" fill="#000000" stroke="#000000"><foreignObject width="83.41" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.26.26.26.26.1.1" class="ltx_text">Not Available</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -56.62 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -70.46 40.76)" fill="#000000" stroke="#000000"><foreignObject width="20.76" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S3.F3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1c">100</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -70.46 85.98)" fill="#000000" stroke="#000000"><foreignObject width="20.76" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="S3.F3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1c">200</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -70.46 131.2)" fill="#000000" stroke="#000000"><foreignObject width="20.76" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S3.F3.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1c">300</annotation></semantics></math></foreignObject></g><clipPath id="pgfcp6"><path d="M -44.81 0 L 492.92 0 L 492.92 147.73 L -44.81 147.73 Z"></path></clipPath><g clip-path="url(#pgfcp6)"><g stroke="#0000FF" fill="#B3B3FF" color="#0000FF"><path d="M -6.92 0 h 13.84 v 134.3 h -13.84 Z M 37.89 0 h 13.84 v 119.38 h -13.84 Z M 82.7 0 h 13.84 v 98.58 h -13.84 Z M 127.51 0 h 13.84 v 61.05 h -13.84 Z M 172.32 0 h 13.84 v 46.12 h -13.84 Z M 217.13 0 h 13.84 v 1.81 h -13.84 Z M 261.95 0 h 13.84 v 1.81 h -13.84 Z M 306.76 0 h 13.84 v 0.9 h -13.84 Z M 351.57 0 h 13.84 v 0.9 h -13.84 Z M 396.38 0 h 13.84 v 0.9 h -13.84 Z M 441.19 0 h 13.84 v 31.65 h -13.84 Z"></path></g><g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 -10.38 139.19)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="20.76" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="297" display="inline"><semantics id="S3.F3.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">297</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">297</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">297</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 34.43 124.27)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="20.76" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="264" display="inline"><semantics id="S3.F3.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">264</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1">264</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1c">264</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 79.24 103.47)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="20.76" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="218" display="inline"><semantics id="S3.F3.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">218</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1">218</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1c">218</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 124.05 65.93)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="20.76" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="135" display="inline"><semantics id="S3.F3.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">135</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1.1">135</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.m1.1c">135</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 168.86 51.01)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="20.76" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="102" display="inline"><semantics id="S3.F3.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">102</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1.1">102</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.5.5.5.5.5.5.5.1.1.1.1.1.1.1.1.1.m1.1c">102</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 220.59 6.7)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.F3.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.6.6.6.6.6.6.6.1.1.1.1.1.1.1.1.1.m1.1c">4</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 265.4 6.7)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.F3.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.7.7.7.7.7.7.7.1.1.1.1.1.1.1.1.1.m1.1c">4</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 310.22 5.79)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.F3.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.8.8.8.8.8.8.8.1.1.1.1.1.1.1.1.1.m1.1c">2</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 355.03 5.79)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.F3.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.9.9.9.9.9.9.9.1.1.1.1.1.1.1.1.1.m1.1c">2</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 399.84 5.79)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.F3.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.10.10.10.10.10.10.10.1.1.1.1.1.1.1.1.1.m1.1c">2</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 441.19 36.54)" fill="#0000FF" stroke="#0000FF" color="#0000FF"><foreignObject width="13.84" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F3.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="70" display="inline"><semantics id="S3.F3.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F3.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">70</mn><annotation-xml encoding="MathML-Content" id="S3.F3.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F3.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.m1.1.1">70</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.11.11.11.11.11.11.11.1.1.1.1.1.1.1.1.1.m1.1c">70</annotation></semantics></math></foreignObject></g><g transform="matrix(0.0 1.0 -1.0 0.0 -79.96 55.22)" fill="#000000" stroke="#000000"><foreignObject width="37.28" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F3.pic1.27.27.27.27.1.1" class="ltx_text">Count</span></foreignObject></g></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Language distribution<span id="S3.F3.4.2.1" class="ltx_text ltx_font_medium"> of the original broadcast audio for each game half, identified using Google Translate and the Whisper language detection model (1100 in total).</span></span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Transcriptions</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We used OpenAI’s Whisper large-v1<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://huggingface.co/openai/whisper-large" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/openai/whisper-large</a></span></span></span>, large-v2<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://huggingface.co/openai/whisper-large-v2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/openai/whisper-large-v2</a></span></span></span>, and large-v3<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://huggingface.co/openai/whisper-large-v3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/openai/whisper-large-v3</a></span></span></span> <span title="" class="ltx_glossaryref">ASR</span> models to transcribe the commentator speech from the game audio into text, with the default parameters provided in the original GitHub implementation (commit: <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">ba3f3cd</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Initially, the <span title="" class="ltx_glossaryref">ASR</span> models were used to process all games regardless of the presence of audible human commentary. By default, Whisper models recognize the audio language from the first <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><cn type="integer" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">30</annotation></semantics></math> seconds of the input, and assume that the rest of the audio is in the same language. It should be noted that the model’s capability to accurately identify entity names (players, teams, stadiums, etc.) is limited. We performed explicit language detection for all games using Whisper-v2, the resulting language distribution is depicted in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.1 Sources and Collection ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Figure <a href="#S3.F4" title="Figure 4 ‣ 3.2 Transcriptions ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents an example transcription using Whisper from original game audio in English.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-en-1.png" id="S3.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-en-2.png" id="S3.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-en-3.png" id="S3.F4.sf3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-en-4.png" id="S3.F4.sf4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F4.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-en-5.png" id="S3.F4.sf5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="279" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S3.F4.pic1" class="ltx_picture ltx_centering ltx_figure_panel" height="90.78" overflow="visible" version="1.1" width="600"><g transform="translate(0,90.78) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#0000BF" fill-opacity="1.0"><path d="M 0 7.87 L 0 82.91 C 0 87.26 3.53 90.78 7.87 90.78 L 592.13 90.78 C 596.47 90.78 600 87.26 600 82.91 L 600 7.87 C 600 3.53 596.47 0 592.13 0 L 7.87 0 C 3.53 0 0 3.53 0 7.87 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 9.84 L 1.97 58.8 L 598.03 58.8 L 598.03 9.84 C 598.03 5.49 594.51 1.97 590.16 1.97 L 9.84 1.97 C 5.49 1.97 1.97 5.49 1.97 9.84 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 68.64)"><foreignObject width="572.44" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S3.F4.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:413.7pt;">
<span id="S3.F4.pic1.1.1.1.1.1.1" class="ltx_p">Automatic English Transcription</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 13.78)"><foreignObject width="572.44" height="33.21" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.F4.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:413.7pt;">
<span id="S3.F4.pic1.2.2.2.1.1.1" class="ltx_p"><span id="S3.F4.pic1.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Frame a to e:</span> "Here is Coman. I wonder if the referee’s going to book him for that because that looked like a blatant dive really."</span>
</span></foreignObject></g></g></svg></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">Example transcription using Whisper (original audio in English). Key frames are shown to represent the corresponding video segment.</span></figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Manual validation of videos without commentary.</span> As shown in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.1 Sources and Collection ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, 70 game half videos in the SoccerNet dataset lack audio commentary and therefore had empty <span title="" class="ltx_glossaryref">ASR</span> outputs. We manually inspected these assets to ensure that they do not in fact contain commentary. Overall, 56 videos were confirmed not to have game audio at all, and 14 videos were confirmed to have game audio but without commentary (only stadium). The detailed list of videos in the SoccerNet dataset without audio commentary is released along with the SoccerNet-Echoes dataset as a spreadsheet.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Translations</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We used the language detection output from Whisper to filter non-English commentaries, and translate the non-English transcriptions into English using Google Translate <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. This choice was made due to Google Translate’s accessibility, ease, and comprehensive language support. Google Translate generally provides reliable translations, particularly for common languages and everyday communication. However, its accuracy can vary depending on factors such as text complexity and linguistic nuances. Figures <a href="#S3.F5" title="Figure 5 ‣ 3.3 Translations ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S3.F6" title="Figure 6 ‣ 3.3 Translations ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> present example transcriptions using Whisper and translations to English using Google Translate (from original game audio in German and Russian, respectively).</p>
</div>
<figure id="S3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-de-1.png" id="S3.F5.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="309" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-de-2.png" id="S3.F5.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="309" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-de-3.png" id="S3.F5.sf3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="309" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-de-4.png" id="S3.F5.sf4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="309" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F5.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-de-5.png" id="S3.F5.sf5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="309" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S3.F5.pic1" class="ltx_picture ltx_centering ltx_figure_panel" height="123.99" overflow="visible" version="1.1" width="600"><g transform="translate(0,123.99) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#0000BF" fill-opacity="1.0"><path d="M 0 7.87 L 0 116.12 C 0 120.47 3.53 123.99 7.87 123.99 L 592.13 123.99 C 596.47 123.99 600 120.47 600 116.12 L 600 7.87 C 600 3.53 596.47 0 592.13 0 L 7.87 0 C 3.53 0 0 3.53 0 7.87 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 9.84 L 1.97 92.01 L 598.03 92.01 L 598.03 9.84 C 598.03 5.49 594.51 1.97 590.16 1.97 L 9.84 1.97 C 5.49 1.97 1.97 5.49 1.97 9.84 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 101.85)"><foreignObject width="572.44" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S3.F5.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:413.7pt;">
<span id="S3.F5.pic1.1.1.1.1.1.1" class="ltx_p">Automatic German Transcription and English Translation</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 13.78)"><foreignObject width="572.44" height="66.42" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.F5.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:413.7pt;">
<span id="S3.F5.pic1.2.2.2.1.1.1" class="ltx_p"><span id="S3.F5.pic1.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Frame a to e (Transcription):</span> "Spiel für RB Leipzig, die Mannschaft spielt in weiß und rot Borussia Dortmund im ersten"</span>
<span id="S3.F5.pic1.2.2.2.1.1.2" class="ltx_p"><span id="S3.F5.pic1.2.2.2.1.1.2.1" class="ltx_text ltx_font_bold">Frame a to e (Translation):</span> "Game for RB Leipzig, the team plays in white and red Borussia Dortmund in the first"</span>
</span></foreignObject></g></g></svg></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.3.2" class="ltx_text" style="font-size:90%;">Example transcription using Whisper and translation to English using Google Translate (original audio in German). Key frames are shown to represent the corresponding video segment.</span></figcaption>
</figure>
<figure id="S3.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-ru-1.png" id="S3.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="335" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-ru-2.png" id="S3.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="335" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-ru-3.png" id="S3.F6.sf3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="335" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F6.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-ru-4.png" id="S3.F6.sf4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="335" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S3.F6.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/asr-example-ru-5.png" id="S3.F6.sf5.g1" class="ltx_graphics ltx_img_landscape" width="598" height="335" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S3.F6.pic1" class="ltx_picture ltx_centering ltx_figure_panel" height="221.54" overflow="visible" version="1.1" width="600"><g transform="translate(0,221.54) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#0000BF" fill-opacity="1.0"><path d="M 0 7.87 L 0 213.67 C 0 218.02 3.53 221.54 7.87 221.54 L 592.13 221.54 C 596.47 221.54 600 218.02 600 213.67 L 600 7.87 C 600 3.53 596.47 0 592.13 0 L 7.87 0 C 3.53 0 0 3.53 0 7.87 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 9.84 L 1.97 189.56 L 598.03 189.56 L 598.03 9.84 C 598.03 5.49 594.51 1.97 590.16 1.97 L 9.84 1.97 C 5.49 1.97 1.97 5.49 1.97 9.84 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 199.4)"><foreignObject width="572.44" height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S3.F6.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:413.7pt;">
<span id="S3.F6.pic1.1.1.1.1.1.1" class="ltx_p">Automatic Russian Transcription and English Translation</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 13.78)"><foreignObject width="572.44" height="163.97" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.F6.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:413.7pt;">
<span id="S3.F6.pic1.2.2.2.1.1.1" class="ltx_p"><span id="S3.F6.pic1.2.2.2.1.1.1.1" class="ltx_text ltx_font_bold">Frame a to e (Transcription):</span> "Ну что, похоже будет прямой удар. Мурель попадает в Лоподулу, который, по его мнению, играл рукой. Но Лоподулу сразу подхватывает мяч. Все-таки, да, подумав, подумав, Масимилиану Арате назначает штрафной. Он послушал выгон помощника. Показывает Лоподулу желтую карточку."</span>
<span id="S3.F6.pic1.2.2.2.1.1.2" class="ltx_p"><span id="S3.F6.pic1.2.2.2.1.1.2.1" class="ltx_text ltx_font_bold">Frame a to e (Translation):</span> "Well, it looks like it’s going to be a direct hit. Murel ends up in Lopodula, who, in his opinion, played with his hand. But Lopodulu immediately picks up the ball. Still, yes, after thinking, after thinking, he appoints Masimiliana Arata penalty. He listened to the assistant’s drive. Shows Lopodul a yellow card."</span>
</span></foreignObject></g></g></svg></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S3.F6.3.2" class="ltx_text" style="font-size:90%;">Example transcription using Whisper and translation to English using Google Translate (original audio in Russian). Key frames are shown to represent the corresponding video segment.</span></figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Final Public Dataset</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The SoccerNet-Echoes dataset and relevant code are publicly released on GitHub under <a target="_blank" href="https://github.com/SoccerNet/sn-echoes" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/SoccerNet/sn-echoes</a>. The dataset is organized as multiple folders under the <em id="S3.SS4.p1.1.1" class="ltx_emph ltx_font_italic">Dataset</em> directory, grouped by league, season, and game. Figure <a href="#A1.F9" title="Figure 9 ‣ Appendix A APPENDIX ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> presents an overview of the directory structure. Each <span title="" class="ltx_glossaryref">ASR</span> JSON file contains the transcribed (and translated where applicable) commentary segments for each game half, organized under the "segments" key, with each segment identified by a unique index within the respective half. Every segment records the start and end time in seconds, which delineate the temporal boundaries of the commentary, along with the transcribed speech, which provides a textual representation of the commentary content. Figure <a href="#A1.F10" title="Figure 10 ‣ Appendix A APPENDIX ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> presents the structure of the <span title="" class="ltx_glossaryref">ASR</span> JSON files.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">For evaluating the transcription and translations in the SoccerNet-Echoes dataset, we conducted an analysis that uses <span title="" class="ltx_glossaryref">Word Error Rate (WER)</span>, <span title="" class="ltx_glossaryref">Character Error Rate (CER)</span>, BLEU score, and word count as metrics. These metrics are crucial for discerning linguistic richness and accuracy.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Comparison with Verified Transcriptions</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">To evaluate the transcription performance, we conducted a comparative analysis using manually verified transcriptions from the GOAL dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. This dataset comprises human-verified transcriptions from 40 game half videos across 20 games with original commentary in English from the SoccerNet dataset. We assessed the transcription performance of Whisper large-v1/v2/v3 on these 40 videos against ground truth transcriptions from the GOAL dataset using <span title="" class="ltx_glossaryref">WER</span>, <span title="" class="ltx_glossaryref">CER</span>, and BLEU score as metrics. The results are presented in Table <a href="#S4.T1" title="Table 1 ‣ 4.1 Comparison with Verified Transcriptions ‣ 4 Evaluation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.2.1.1" class="ltx_tr">
<th id="S4.T1.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.2.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.2.1.1.2.1" class="ltx_text ltx_font_bold">WER</span></th>
<th id="S4.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.2.1.1.3.1" class="ltx_text ltx_font_bold">CER</span></th>
<th id="S4.T1.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.2.1.1.4.1" class="ltx_text ltx_font_bold">BLEU</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.2.2.1" class="ltx_tr">
<td id="S4.T1.2.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Whisper large-v1</td>
<td id="S4.T1.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.443</td>
<td id="S4.T1.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.261</td>
<td id="S4.T1.2.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">54.50</td>
</tr>
<tr id="S4.T1.2.3.2" class="ltx_tr">
<td id="S4.T1.2.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Whisper large-v2</td>
<td id="S4.T1.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.458</td>
<td id="S4.T1.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.269</td>
<td id="S4.T1.2.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">52.59</td>
</tr>
<tr id="S4.T1.2.4.3" class="ltx_tr">
<td id="S4.T1.2.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Whisper large-v3</td>
<td id="S4.T1.2.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.551</td>
<td id="S4.T1.2.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.341</td>
<td id="S4.T1.2.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">47.97</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.4.2" class="ltx_text" style="font-size:90%;">Transcription performance for different Whisper models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> against ground truth information from the GOAL dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, averaged over the 20 games for which ground truth transcriptions are available.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model Selection</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We implemented a "Unique Word Count" heuristic as a criterion to identify the most effective <span title="" class="ltx_glossaryref">ASR</span> model among the different Whisper versions. This approach facilitated the selection of the best-performing model for each game half based on the diversity of vocabulary in the transcriptions, and proved particularly valuable as a heuristic for assessing model performance in scenarios prone to repeated content, often manifesting as hallucinations (erroneously repeated phrases in the transcription, which are not actually present in the audio). This metric effectively captures the ability of <span title="" class="ltx_glossaryref">ASR</span> models to generate diverse linguistic outputs, which is crucial for minimizing the impact of such repetitions.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">For each game half video, we selected the model with the highest unique word count as the "best" model for further analysis and application. This selection criterion is anchored on the premise that a higher diversity in word usage is indicative of reduced hallucinatory repetitions and, by extension, a more robust transcription performance in diverse acoustic environments. Table <a href="#S4.T2" title="Table 2 ‣ 4.2 Model Selection ‣ 4 Evaluation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the average unique word ratio (unique word count divided by the the number of total words) for different Whisper models, averaged over the videos for which the model was selected to be the "best". A pie chart depicting the distribution of selected Whisper models is given in Figure <a href="#S4.F7" title="Figure 7 ‣ 4.2 Model Selection ‣ 4 Evaluation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.2.1.1" class="ltx_tr">
<th id="S4.T2.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.2.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.2.1.1.2.1" class="ltx_text ltx_font_bold">Number of Videos</span></th>
<th id="S4.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.2.1.1.3.1" class="ltx_text ltx_font_bold">Average Unique Word Ratio</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.2.2.1" class="ltx_tr">
<td id="S4.T2.2.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Whisper large-v1</td>
<td id="S4.T2.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">316</td>
<td id="S4.T2.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.311</td>
</tr>
<tr id="S4.T2.2.3.2" class="ltx_tr">
<td id="S4.T2.2.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Whisper large-v2</td>
<td id="S4.T2.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">231</td>
<td id="S4.T2.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.316</td>
</tr>
<tr id="S4.T2.2.4.3" class="ltx_tr">
<td id="S4.T2.2.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Whisper large-v3</td>
<td id="S4.T2.2.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">483</td>
<td id="S4.T2.2.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.370</td>
</tr>
<tr id="S4.T2.2.5.4" class="ltx_tr">
<td id="S4.T2.2.5.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Mixed Selection</td>
<td id="S4.T2.2.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">1030</td>
<td id="S4.T2.2.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.340</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.4.2" class="ltx_text" style="font-size:90%;">Average unique word ratio (number of unique words / number of total words) for different Whisper models. "Mixed Selection" represents the overall weighted average across a total of 1030 game half videos with valid commentary, using the "best" model for each video.</span></figcaption>
</figure>
<figure id="S4.F7" class="ltx_figure"><svg id="S4.F7.pic1" class="ltx_picture ltx_centering" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><foreignObject width="0" height="0" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.F7.pic1.1.1.1.1" class="ltx_ERROR undefined">\pie</span></foreignObject></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Distribution of the selected Whisper models, for a total of 1030 game half videos with valid commentary.</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Vocabulary Analysis</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We conducted an in-depth examination of the linguistic patterns in the soccer game commentaries to identify prevalent verb-noun pairs, which are key to understanding the action dynamics that are described. Utilizing <span title="" class="ltx_glossaryref">Natural Language Processing (NLP)</span> techniques, we parsed the transcriptions to extract named entities and specific grammatical structures, focusing on the interactions between players and teams. We then applied dependency parsing models to determine the dominant actions by identifying root verbs and their direct objects, providing clarity on the primary activities depicted.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">We conducted a sunburst visualization to represent the frequency and distribution of verb-noun combinations, displaying verbs as primary segments with corresponding nouns as sub-segments. This visualization, exemplified for one game half in Figure <a href="#S4.F8" title="Figure 8 ‣ 4.3 Vocabulary Analysis ‣ 4 Evaluation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, not only highlights predominant actions but also showcases vocabulary diversity. Such analyses offer insights into sports broadcasting narrative styles and can guide improvements in automated commentary systems.</p>
</div>
<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/sunburst-goal.png" id="S4.F8.sf1.g1" class="ltx_graphics ltx_img_square" width="598" height="615" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F8.sf1.3.2" class="ltx_text" style="font-size:90%;">Ground truth transcription from GOAL dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/sunburst-whisperv1.png" id="S4.F8.sf2.g1" class="ltx_graphics ltx_img_square" width="598" height="615" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F8.sf2.3.2" class="ltx_text" style="font-size:90%;">Whisper large-v1</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2405.07354/assets/figures/images/sunburst-whisperv3.png" id="S4.F8.sf3.g1" class="ltx_graphics ltx_img_square" width="598" height="615" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F8.sf3.3.2" class="ltx_text" style="font-size:90%;">Whisper large-v3</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.3.2" class="ltx_text" style="font-size:90%;">Sunburst plots representing the frequency of verb-noun combinations in the audio commentary transcription for one game half.</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Dataset Applications</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The augmentation of the SoccerNet dataset to include <span title="" class="ltx_glossaryref">ASR</span> data significantly enriches the multimodal nature of the dataset, enabling a broad range of applications which can leverage the combined strengths of video, audio, and now textual data derived from spoken commentary. These applications are fundamentally enabled by <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_italic">enhanced content understanding</span>, i.e., the possibility to train automated systems which can more effectively understand, interpret, and generate soccer-related multimedia content, including an increased contextual awareness for actions, in-game events, highlights/statistics, and entities (e.g., teams, players, locations). Below, we discuss several potential applications of the SoccerNet-Echoes dataset.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Multi-modal event detection:</span> The integration of <span title="" class="ltx_glossaryref">ASR</span> data can enable more sophisticated and accurate event detection mechanisms. Combining audio cues (such as crowd noise and commentator excitement) and textual triggers from the transcription (such as specific phrases indicating goals or fouls) with visual data can improve the precision and recall of event detection. Such integration is pivotal for real-time analytics, automated highlight generation, and conducting more detailed statistical analysis. The transcription example depicted in Figure <a href="#S3.F5" title="Figure 5 ‣ 3.3 Translations ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> showcases the advantages of <span title="" class="ltx_glossaryref">ASR</span> in this context. In scenarios where the sole analysis of video frames (e.g., based on the zoomed-out shots of the soccer pitch as shown in Figures <a href="#S3.F5.sf1" title="In Figure 5 ‣ 3.3 Translations ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>-<a href="#S3.F5.sf5" title="In Figure 5 ‣ 3.3 Translations ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(e)</span></a>) might fail to yield detailed information, <span title="" class="ltx_glossaryref">ASR</span> can provide contextual information, and allow for the extraction of additional details (such as the identification of the teams, and whether they are wearing home or away jerseys), which might not be discernible from the visual data alone.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">Game summarization:</span> Automated systems can generate insightful and context-rich summaries of soccer games using the textual modality. This involves not just identifying key events, but also understanding their significance within the game’s narrative, as well as the entities involved. For example, the frequency with which a player’s name is mentioned during a crucial moment in the game can indicate the level of their influence, which can be used for assigning an appropriate amount of the overall word budget for the player in the description of the action.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p"><span id="S5.SS1.p4.1.1" class="ltx_text ltx_font_bold">Automated soccer commentator:</span> Commentary datasets such as SoccerNet-Echoes up exciting possibilities for the development of automated real-time soccer game commentator systems. With increasingly more datasets available for training, models can be trained to create more realistic and contextually relevant, but also dynamic and captivating commentary, potentially offering elevated levels of immersion and engagement for the fans.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para">
<p id="S5.SS1.p5.1" class="ltx_p"><span id="S5.SS1.p5.1.1" class="ltx_text ltx_font_bold">Tactical analysis:</span> In certain cases, the <span title="" class="ltx_glossaryref">ASR</span> data can also provide a context for tactical analysis, by enabling an understanding of the discussions made by commentators based on the tactical adjustments made by the coaches during soccer games. In this sense, spoken commentary provides a layer of strategic insight that is typically not captured by video and audio alone. These insights can then also be integrated with various audio cues (such as the audio intensity levels from the stadium) to pinpoint and map tactical highlights to important fan moments within the game.</p>
</div>
<div id="S5.SS1.p6" class="ltx_para">
<p id="S5.SS1.p6.1" class="ltx_p">These applications demonstrate the significant potential of the SoccerNet-Echoes dataset to contribute to sports research and broadcasting. Using the power of multimodal data, researchers and developers can create more sophisticated tools that address a wide range of needs within the sports community.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Limitations and Future Work</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Our use of deep learning models for <span title="" class="ltx_glossaryref">ASR</span> and batch translation for the curation of the SoccerNet-Echoes dataset have also introduced a number of limitations. We aim to address several of the following challenges in future work.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_bold">Transcription accuracy:</span> The inference capability and accuracy of the <span title="" class="ltx_glossaryref">ASR</span> models are inherently constrained by their design, occasionally leading to errors in transcription.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p"><span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_bold">Hallucinations:</span> Whisper models are known to be prone to hallucinations (unwarranted repetition of phrases and words). During the curation of the SoccerNet-Echoes dataset, we have observed hallucinations across all Whisper <span title="" class="ltx_glossaryref">ASR</span> models, especially under conditions where the audio inputs were devoid of human speech, were excessively noisy, or contained musical elements. Such conditions significantly challenge transcription accuracy of the models, leading to the anomalous generation of repeated phrases. These repetitions not only degrade the quality of the transcription, but also affect the usability of the transcribed text in downstream applications, such as subtitle generation or voice-driven gameplay interaction. By analyzing the occurrences of repeated words under various audio conditions, we aimed to understand the strengths and limitations of different models.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p"><span id="S5.SS2.p4.1.1" class="ltx_text ltx_font_bold">Audio quality:</span> As mentioned above, we have seen that the quality of the audio to be transcribed significantly impacts the reliability of the transcriptions. Implementing advanced audio pre-processing techniques to filter out background noise and music could enhance the clarity of the input signal for <span title="" class="ltx_glossaryref">ASR</span> systems. Combining Whisper with other technologies such as <span title="" class="ltx_glossaryref">Voice Activity Detection (VAD)</span> could also help reduce <span title="" class="ltx_glossaryref">ASR</span> errors and hallucinations.</p>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p"><span id="S5.SS2.p5.1.1" class="ltx_text ltx_font_bold">Human verification:</span> The absence of human-verified annotations to serve as ground truth poses a substantial challenge for all <span title="" class="ltx_glossaryref">ASR</span> datasets. Generating such annotations is prohibitively expensive, thus limiting the ability of researchers to comprehensively verify and refine <span title="" class="ltx_glossaryref">ASR</span> datasets. However, this limitation is also critical to address, in order to advance the reliability and applicability of our SoccerNet-Echoes dataset. We therefore plan to invest in the curation of human-verified annotations, for a subset of the assets in SoccerNet-Echoes, as future work. Despite being expensive, we believe that such a dataset could provide a valuable benchmark for assessing and improving <span title="" class="ltx_glossaryref">ASR</span> accuracy. Efforts could also involve collaborations with various academic institutions and community-sourcing the annotations.</p>
</div>
<div id="S5.SS2.p6" class="ltx_para">
<p id="S5.SS2.p6.1" class="ltx_p"><span id="S5.SS2.p6.1.1" class="ltx_text ltx_font_bold">Batch translations:</span>
Machine translation systems, such as Google Translate, are not infallible and their limitations must be acknowledged. When translations are performed on entire texts at once, they can produce different outputs compared to translations of specific, smaller segments.
For instance, as depicted in Figure <a href="#S3.F6" title="Figure 6 ‣ 3.3 Translations ‣ 3 Dataset Curation ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, the Russian term "штрафной" was erroneously translated as "penalty kick" when the entire game half was translated, contrasting with the accurate translation "free kick" when only the segment was translated. This discrepancy underscores the contextual challenges faced by machine translation.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The augmentation of the SoccerNet dataset using <span title="" class="ltx_glossaryref">ASR</span> technology marks a pivotal advance in the domain of sports analytics, providing a richer and more integrated approach to understanding soccer games. The inclusion of multimodal data not only aids in the accurate detection and description of in-game events but also enriches the dataset’s applicability across various analytical tasks such as sentiment analysis and tactical assessments. Despite the limitations associated with <span title="" class="ltx_glossaryref">ASR</span>, such as potential inaccuracies and hallucinations under challenging audio conditions, the benefits presented by the SoccerNet-Echoes dataset are substantial. Future work will focus on refining <span title="" class="ltx_glossaryref">ASR</span> accuracy through the curation of a human-verified annotation subset and the implementation of advanced audio pre-processing techniques. By continually improving the dataset’s quality and the methodologies used to analyze it, SoccerNet-Echoes is poised to significantly influence the development of automated systems for sports broadcasting and analytics, enhancing the consumption and comprehension of sports events globally. This work not only underscores the transformative impact of integrating <span title="" class="ltx_glossaryref">ASR</span> into sports video analysis but also sets a precedent for future research in the field, promising deeper insights and more effective tools for researchers, sports analytics professionals, and enthusiasts.</p>
</div>
</section>
<section id="Sx1" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was partly funded by the Research Council of Norway, project number 346671 (AI-Storyteller), and has benefited from the Experimental Infrastructure for Exploration of Exascale Computing (eX3), which is financially supported by the Research Council of Norway under contract 270053.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography" lang="en">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barnard et al. [2003]</span>
<span class="ltx_bibblock">
M. Barnard, J.-M. Odobez, and S. Bengio.

</span>
<span class="ltx_bibblock">Multi-modal audio-visual event recognition for football analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE XIII Workshop on Neural Networks for Signal Processing (IEEE Cat. No.03TH8718)</em>, pages 17–19. IEEE, 2003.

</span>
<span class="ltx_bibblock">ISBN 978-0-7803-8177.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/NNSP.2003.1318046</span>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cabado et al. [2024]</span>
<span class="ltx_bibblock">
Bruno Cabado, Anthony Cioppa, Silvio Giancola, Andrés Villa, Bertha Guijarro-Berdinas, Emilio J Padròn, Bernard Ghanem, and Marc Van Droogenbroeck.

</span>
<span class="ltx_bibblock">Beyond the premier: Assessing action spotting transfer capability across diverse domains.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), CVsports</em>, 2024.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al. [1996]</span>
<span class="ltx_bibblock">
Yuh-Lin Chang, Wenjun Zeng, I. Kamel, and R. Alonso.

</span>
<span class="ltx_bibblock">Integrated image and speech analysis for content-based video indexing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third IEEE International Conference on Multimedia Computing and Systems</em>, pages 17–23. IEEE, 1996.

</span>
<span class="ltx_bibblock">ISBN 978-0-8186-7438.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/MMCS.1996.534992</span>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cioppa et al. [2022a]</span>
<span class="ltx_bibblock">
Anthony Cioppa, Adrien Deliège, Silvio Giancola, Bernard Ghanem, and Marc Van Droogenbroeck.

</span>
<span class="ltx_bibblock">Scaling up SoccerNet with multi-view spatial localization and re-identification.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Sci. Data</em>, 9(1):1–9, Jun. 2022a.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/s41597-022-01469-1</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1038/s41597-022-01469-1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41597-022-01469-1</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cioppa et al. [2022b]</span>
<span class="ltx_bibblock">
Anthony Cioppa, Silvio Giancola, Adrien Deliege, Le Kang, Xin Zhou, Zhiyu Cheng, Bernard Ghanem, and Marc Van Droogenbroeck.

</span>
<span class="ltx_bibblock">SoccerNet-tracking: Multiple object tracking dataset and benchmark in soccer videos.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Int. Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW), CVsports</em>, pages 3490–3501, New Orleans, LA, USA, Jun. 2022b. Inst. Electr. Electron. Eng. (IEEE).

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/cvprw56347.2022.00393</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/CVPRW56347.2022.00393" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPRW56347.2022.00393</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cioppa et al. [2023]</span>
<span class="ltx_bibblock">
Anthony Cioppa, Silvio Giancola, Vladimir Somers, Floriane Magera, Xin Zhou, Hassan Mkhallati, et al.

</span>
<span class="ltx_bibblock">SoccerNet 2023 Challenges Results.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv</em>, Sept. 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2309.06006</span>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deliège et al. [2021]</span>
<span class="ltx_bibblock">
Adrien Deliège, Anthony Cioppa, Silvio Giancola, Meisam J. Seikavandi, Jacob V. Dueholm, Kamal Nasrollahi, et al.

</span>
<span class="ltx_bibblock">SoccerNet-v2: A Dataset and Benchmarks for Holistic Understanding of Broadcast Soccer Videos.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>, pages 19–25. IEEE, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPRW53098.2021.00508</span>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. [2020]</span>
<span class="ltx_bibblock">
Xin Gao, Xusheng Liu, Taotao Yang, Guilin Deng, Hao Peng, Qiaosong Zhang, et al.

</span>
<span class="ltx_bibblock">Automatic Key Moment Extraction and Highlights Generation Based on Comprehensive Soccer Video Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Conference on Multimedia &amp; Expo Workshops (ICMEW)</em>, pages 06–10. IEEE, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICMEW46912.2020.9106051</span>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gautam [2023]</span>
<span class="ltx_bibblock">
Sushant Gautam.

</span>
<span class="ltx_bibblock">Bridging Multimedia Modalities: Enhanced Multimodal AI Understanding and Intelligent Agents.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ICMI ’23: Proceedings of the 25th International Conference on Multimodal Interaction</em>, pages 695–699. Association for Computing Machinery, New York, NY, USA, Oct. 2023.

</span>
<span class="ltx_bibblock">ISBN 979-840070055-2.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3577190.3614225</span>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gautam et al. [2022a]</span>
<span class="ltx_bibblock">
Sushant Gautam, Cise Midoglu, Saeed Shafiee Sabet, Dinesh Baniya Kshatri, and Pl Halvorsen.

</span>
<span class="ltx_bibblock">Soccer Game Summarization using Audio Commentary, Metadata, and Captions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">NarSUM ’22: Proceedings of the 1st Workshop on User-centric Narrative Summarization of Long Videos</em>, pages 13–22. Association for Computing Machinery, New York, NY, USA, Oct. 2022a.

</span>
<span class="ltx_bibblock">ISBN 978-1-45039493-2.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3552463.3557019</span>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gautam et al. [2022b]</span>
<span class="ltx_bibblock">
Sushant Gautam, Cise Midoglu, Saeed Shafiee Sabet, Dinesh Baniya Kshatri, and Pl Halvorsen.

</span>
<span class="ltx_bibblock">Assisting soccer game summarization via audio intensity analysis of game highlights.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proc. 12th IOE Graduate Conference</em>, pages 25–32. Inst. of Eng. Tribhuvan University, Nepal, Oct. 2022b.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://conference.ioe.edu.np/publications/ioegc12/IOEGC-12-004-12009.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://conference.ioe.edu.np/publications/ioegc12/IOEGC-12-004-12009.pdf</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Giancola et al. [2018]</span>
<span class="ltx_bibblock">
Silvio Giancola, Mohieddine Amine, Tarek Dghaily, and Bernard Ghanem.

</span>
<span class="ltx_bibblock">SoccerNet: A Scalable Dataset for Action Spotting in Soccer Videos.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>, pages 18–22. IEEE, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPRW.2018.00223</span>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google [2024]</span>
<span class="ltx_bibblock">
Google.

</span>
<span class="ltx_bibblock">Google Translate, Apr. 2024.

</span>
<span class="ltx_bibblock">[Online; https://translate.google.com].

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Held et al. [2023]</span>
<span class="ltx_bibblock">
Jan Held, Anthony Cioppa, Silvio Giancola, Abdullah Hamdi, Bernard Ghanem, and Marc Van Droogenbroeck.

</span>
<span class="ltx_bibblock">VARS: Video assistant referee system for automated soccer decision making from multiple views.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW)</em>, pages 5086–5097, Vancouver, Can., Jun. 2023. Inst. Electr. Electron. Eng. (IEEE).

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/cvprw59228.2023.00537</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/CVPRW59228.2023.00537" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPRW59228.2023.00537</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Held et al. [2024]</span>
<span class="ltx_bibblock">
Jan Held, Hani Itani, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, and Marc Van Droogenbroeck.

</span>
<span class="ltx_bibblock">X-vars: Introducing explainability in football refereeing with multi-modal large language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Int. Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW), CVsports</em>, Seattle, WA, USA, Jun. 2024.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hessel et al. [2019]</span>
<span class="ltx_bibblock">
Jack Hessel, Bo Pang, Zhenhai Zhu, and Radu Soricut.

</span>
<span class="ltx_bibblock">A Case Study on Combining ASR and Visual Features for Generating Instructional Video Captions.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ACL Anthology</em>, pages 419–429, Nov. 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/K19-1039</span>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ikeda et al. [2024]</span>
<span class="ltx_bibblock">
Riku Ikeda, Kazuma Sakamoto, and Yoshihiro Ueda.

</span>
<span class="ltx_bibblock">Breaking News System of At-Bat Results From Sports Commentary via Speech Recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 12:27199–27209, Feb. 2024.

</span>
<span class="ltx_bibblock">ISSN 2169-3536.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ACCESS.2024.3365948</span>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishna et al. [2017]</span>
<span class="ltx_bibblock">
Ranjay Krishna, Kenji Hata, Frederic Ren, Li Fei-Fei, and Juan Carlos Niebles.

</span>
<span class="ltx_bibblock">Dense-Captioning Events in Videos.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Computer Vision (ICCV)</em>, pages 22–29. IEEE, 2017.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICCV.2017.83</span>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lashin and Rahtu [2020]</span>
<span class="ltx_bibblock">
Vladimir Lashin and Esa Rahtu.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Multi-modal Dense Video Captioning</em>.

</span>
<span class="ltx_bibblock">IEEE Computer Society, Jun. 2020.

</span>
<span class="ltx_bibblock">ISBN 978-1-7281-9360-1.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPRW50498.2020.00487</span>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li [2022]</span>
<span class="ltx_bibblock">
Jinyu Li.

</span>
<span class="ltx_bibblock">Recent Advances in End-to-End Automatic Speech Recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">SIP</em>, 11(1), Apr. 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1561/116.00000050</span>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu and An [2020]</span>
<span class="ltx_bibblock">
Yao Lu and Shuyang An.

</span>
<span class="ltx_bibblock">Research on sports video detection technology motion 3D reconstruction based on hidden Markov model.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Cluster Comput.</em>, 23(3):1899–1909, Sept. 2020.

</span>
<span class="ltx_bibblock">ISSN 1573-7543.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/s10586-020-03097-z</span>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malik et al. [2021]</span>
<span class="ltx_bibblock">
Mishaim Malik, Muhammad Kamran Malik, Khawar Mehmood, and Imran Makhdoom.

</span>
<span class="ltx_bibblock">Automatic speech recognition: a survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Multimed. Tools Appl.</em>, 80(6):9411–9457, Mar. 2021.

</span>
<span class="ltx_bibblock">ISSN 1573-7721.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/s11042-020-10073-7</span>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mkhallati et al. [2023a]</span>
<span class="ltx_bibblock">
Hassan Mkhallati, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, and Marc Van Droogenbroeck.

</span>
<span class="ltx_bibblock">SoccerNet-Caption: Dense Video Captioning for Soccer Broadcasts Commentaries.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>, pages 17–24. IEEE, 2023a.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPRW59228.2023.00536</span>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mkhallati et al. [2023b]</span>
<span class="ltx_bibblock">
Hassan Mkhallati, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, and Marc Van Droogenbroeck.

</span>
<span class="ltx_bibblock">SoccerNet-caption: Dense video captioning for soccer broadcasts commentaries.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW)</em>, pages 5074–5085, Vancouver, Can., Jun. 2023b. Inst. Electr. Electron. Eng. (IEEE).

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/cvprw59228.2023.00536</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/CVPRW59228.2023.00536" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CVPRW59228.2023.00536</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI [2024]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Whisper.

</span>
<span class="ltx_bibblock">GitHub, Apr. 2024.

</span>
<span class="ltx_bibblock">[Online; https://github.com/openai/whisper].

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et al. [2023]</span>
<span class="ltx_bibblock">
Ji Qi, Jifan Yu, Teng Tu, Kunyu Gao, Yifan Xu, Xinyu Guan, et al.

</span>
<span class="ltx_bibblock">GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for Real-time Soccer Commentary Generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">CIKM ’23: Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, pages 5391–5395. Association for Computing Machinery, New York, NY, USA, Oct. 2023.

</span>
<span class="ltx_bibblock">ISBN 979-840070124-5.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3583780.3615120</span>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattar et al. [2023]</span>
<span class="ltx_bibblock">
Husnain Sattar, Muhammad Shamil Umar, Eeman Ijaz, and Muhammad Umair Arshad.

</span>
<span class="ltx_bibblock">Multi-Modal Architecture for Cricket Highlights Generation: Using Computer Vision and Large Language Model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">2023 17th International Conference on Open Source Systems and Technologies (ICOSST)</em>, pages 20–21. IEEE, 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICOSST60641.2023.10414235</span>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seo et al. [2022]</span>
<span class="ltx_bibblock">
Paul Hongsuck Seo, Arsha Nagrani, Anurag Arnab, and Cordelia Schmid.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">End-to-end Generative Pretraining for Multimodal Video Captioning</em>.

</span>
<span class="ltx_bibblock">IEEE Computer Society, Jun. 2022.

</span>
<span class="ltx_bibblock">ISBN 978-1-6654-6946-3.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPR52688.2022.01743</span>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shih [2017]</span>
<span class="ltx_bibblock">
Huang-Chia Shih.

</span>
<span class="ltx_bibblock">A Survey of Content-Aware Video Analysis for Sports.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Circuits Syst. Video Technol.</em>, 28(5):1212–1231, Jan. 2017.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TCSVT.2017.2655624</span>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soldan et al. [2022]</span>
<span class="ltx_bibblock">
Mattia Soldan, Alejandro Pardo, Juan León Alcázar, Fabian Caba, Chen Zhao, Silvio Giancola, and Bernard Ghanem.

</span>
<span class="ltx_bibblock">Mad: A scalable dataset for language grounding in videos from movie audio descriptions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 5026–5035, June 2022.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Somers et al. [2024]</span>
<span class="ltx_bibblock">
Vladimir Somers, Victor Joos, Silvio Giancola, Anthony Cioppa, Seyed Abolfazl Ghasemzadeh, Floriane Magera, Baptiste Standaert, Amir Mohammad Mansourian, Xin Zhou, Shohreh Kasaei, Bernard Ghanem, Alexandre Alahi, Marc Van Droogenbroeck, and Christophe De Vleeschouwer.

</span>
<span class="ltx_bibblock">SoccerNet game state reconstruction: End-to-end athlete tracking and identification on a minimap.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">IEEE Int. Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW), CVsports</em>, Seattle, WA, USA, Jun. 2024.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soomro et al. [2012]</span>
<span class="ltx_bibblock">
Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah.

</span>
<span class="ltx_bibblock">UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv</em>, Dec. 2012.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.1212.0402</span>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szeliski [2022]</span>
<span class="ltx_bibblock">
Richard Szeliski.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Computer Vision</em>.

</span>
<span class="ltx_bibblock">Springer International Publishing, Cham, Switzerland, 2022.

</span>
<span class="ltx_bibblock">ISBN 978-3-030-34372-9.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://link.springer.com/book/10.1007/978-3-030-34372-9" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://link.springer.com/book/10.1007/978-3-030-34372-9</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vanderplaetse and Dupont [2020]</span>
<span class="ltx_bibblock">
Bastien Vanderplaetse and Stéphane Dupont.

</span>
<span class="ltx_bibblock">Improved Soccer Action Spotting using both Audio and Video Streams.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>, pages 14–19. IEEE, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPRW50498.2020.00456</span>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. [2023]</span>
<span class="ltx_bibblock">
Yue Yin, Daijiro Mori, and Seiji Fujimoto.

</span>
<span class="ltx_bibblock">Reazonspeech: A free and massive corpus for japanese asr.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th Annual Conference of the Language Processing Society (NLP 2023)</em>, March 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2018]</span>
<span class="ltx_bibblock">
Zixing Zhang, Jürgen Geiger, Jouni Pohjalainen, Amr El-Desoky Mousa, Wenyu Jin, and Björn Schuller.

</span>
<span class="ltx_bibblock">Deep Learning for Environmentally Robust Speech Recognition: An Overview of Recent Developments.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. Technol.</em>, 9(5):1–28, Apr. 2018.

</span>
<span class="ltx_bibblock">ISSN 2157-6904.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3178115</span>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>APPENDIX</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Figure <a href="#A1.F9" title="Figure 9 ‣ Appendix A APPENDIX ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> presents an overview of the SoccerNet-Echoes dataset directory under <a target="_blank" href="https://github.com/SoccerNet/sn-echoes" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/SoccerNet/sn-echoes</a>.</p>
</div>
<figure id="A1.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="A1.F9.2" class="ltx_ERROR ltx_align_left ltx_figure_panel undefined">\dirtree</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A1.F9.3" class="ltx_p ltx_figure_panel ltx_align_left">.1 <span id="A1.F9.3.1" class="ltx_ERROR undefined">\faDatabase</span> Dataset.
.2 <span id="A1.F9.3.2" class="ltx_ERROR undefined">\faFolder</span> whisper_v1.
.3 <span id="A1.F9.3.3" class="ltx_ERROR undefined">\faTrophy</span> england_epl.
.4 <span id="A1.F9.3.4" class="ltx_ERROR undefined">\faCalendar</span> 2014-2015.
.5 <span id="A1.F9.3.5" class="ltx_ERROR undefined">\faSoccerBallO</span> 2016-03-02-23-00 Liverpool 3-0 Manchester City.
.6 <span id="A1.F9.3.6" class="ltx_ERROR undefined">\faCloud</span> 1_asr.json.
.6 <span id="A1.F9.3.7" class="ltx_ERROR undefined">\faCloud</span> 2_asr.json.
.5 … .
.4 <span id="A1.F9.3.8" class="ltx_ERROR undefined">\faCalendar</span> 2015-2016.
.4 … .
.3 <span id="A1.F9.3.9" class="ltx_ERROR undefined">\faTrophy</span> europe_uefa-champions-league.
.4 … .
.3 <span id="A1.F9.3.10" class="ltx_ERROR undefined">\faTrophy</span> france_ligue-1.
.4 … .
.3 <span id="A1.F9.3.11" class="ltx_ERROR undefined">\faTrophy</span> germany_bundesliga.
.4 … .
.3 <span id="A1.F9.3.12" class="ltx_ERROR undefined">\faTrophy</span> italy_serie-a.
.4 … .
.3 <span id="A1.F9.3.13" class="ltx_ERROR undefined">\faTrophy</span> spain_laliga.
.4 … .
.2 <span id="A1.F9.3.14" class="ltx_ERROR undefined">\faFolder</span> whisper_v1_en.
.3 … .
.2 <span id="A1.F9.3.15" class="ltx_ERROR undefined">\faFolder</span> whisper_v2.
.3 … .
.2 <span id="A1.F9.3.16" class="ltx_ERROR undefined">\faFolder</span> whisper_v2_en.
.3 … .
.2 <span id="A1.F9.3.17" class="ltx_ERROR undefined">\faFolder</span> whisper_v3.
.3 … .
.2 <span id="A1.F9.3.18" class="ltx_ERROR undefined">\faFolder</span> whisper_v3_en.
.3 … .

</p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.4.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="A1.F9.5.2" class="ltx_text" style="font-size:90%;">SoccerNet-Echoes dataset directory structure.</span></figcaption>
</figure>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p">Figure <a href="#A1.F10" title="Figure 10 ‣ Appendix A APPENDIX ‣ SoccerNet-Echoes: A Soccer Game Audio Commentary Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> presents the structure of the <span title="" class="ltx_glossaryref">ASR</span> JSON files in the dataset.</p>
</div>
<figure id="A1.F10" class="ltx_figure">
<div id="A1.F10.2" class="ltx_listing ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ICAgIHsKICAgICAgInNlZ21lbnRzIjogewogICAgICAgIChpbnQpIDxzZWdtZW50IGluZGV4PjpbCiAgICAgICAgICAgIChmbG9hdCkgPHN0YXJ0IHRpbWUgaW4gc2Vjb25kcz4sCiAgICAgICAgICAgIChmbG9hdCkgPGVuZCB0aW1lIGluIHNlY29uZHM+LAogICAgICAgICAgICAoc3RyaW5nKSA8Y29tbWVudGFyeSB0ZXh0PgogICAgICAgIF0sCiAgICAgICAgLi4uLgogICAgICB9CiAgICB9" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span id="lstnumberx1.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx1.2" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx2.2" class="ltx_text ltx_font_typewriter">"</span><span id="lstnumberx2.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">segments</span><span id="lstnumberx2.4" class="ltx_text ltx_font_typewriter">":</span><span id="lstnumberx2.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx2.6" class="ltx_text ltx_font_typewriter">{</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx3.2" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx3.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">int</span><span id="lstnumberx3.4" class="ltx_text ltx_font_typewriter">)</span><span id="lstnumberx3.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.6" class="ltx_text ltx_font_typewriter">&lt;</span><span id="lstnumberx3.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">segment</span><span id="lstnumberx3.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">index</span><span id="lstnumberx3.10" class="ltx_text ltx_font_typewriter">&gt;:[</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span id="lstnumberx4.1" class="ltx_text ltx_lst_space ltx_font_typewriter">            </span><span id="lstnumberx4.2" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx4.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">float</span><span id="lstnumberx4.4" class="ltx_text ltx_font_typewriter">)</span><span id="lstnumberx4.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.6" class="ltx_text ltx_font_typewriter">&lt;</span><span id="lstnumberx4.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">start</span><span id="lstnumberx4.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx4.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx4.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">seconds</span><span id="lstnumberx4.14" class="ltx_text ltx_font_typewriter">&gt;,</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_space ltx_font_typewriter">            </span><span id="lstnumberx5.2" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx5.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">float</span><span id="lstnumberx5.4" class="ltx_text ltx_font_typewriter">)</span><span id="lstnumberx5.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.6" class="ltx_text ltx_font_typewriter">&lt;</span><span id="lstnumberx5.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">end</span><span id="lstnumberx5.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">time</span><span id="lstnumberx5.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">in</span><span id="lstnumberx5.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">seconds</span><span id="lstnumberx5.14" class="ltx_text ltx_font_typewriter">&gt;,</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span id="lstnumberx6.1" class="ltx_text ltx_lst_space ltx_font_typewriter">            </span><span id="lstnumberx6.2" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx6.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">string</span><span id="lstnumberx6.4" class="ltx_text ltx_font_typewriter">)</span><span id="lstnumberx6.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.6" class="ltx_text ltx_font_typewriter">&lt;</span><span id="lstnumberx6.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">commentary</span><span id="lstnumberx6.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">text</span><span id="lstnumberx6.10" class="ltx_text ltx_font_typewriter">&gt;</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span id="lstnumberx7.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx7.2" class="ltx_text ltx_font_typewriter">],</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx8.2" class="ltx_text ltx_font_typewriter">....</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span id="lstnumberx9.1" class="ltx_text ltx_lst_space ltx_font_typewriter">      </span><span id="lstnumberx9.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx10.2" class="ltx_text ltx_font_typewriter">}</span>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F10.3.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="A1.F10.4.2" class="ltx_text" style="font-size:90%;">Structure of the <span title="" class="ltx_glossaryref">ASR</span> JSON files in the SoccerNet-Echoes dataset.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.07353" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.07354" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.07354">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.07354" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.07355" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 18:20:48 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
