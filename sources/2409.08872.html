<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.08872] Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages</title><meta property="og:description" content="This study investigates the efficacy of data augmentation techniques for low-resource automatic speech recognition (ASR), focusing on two endangered Austronesian languages, Amis and Seediq. Recognizing the potential ofâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.08872">

<!--Generated on Sun Oct  6 01:28:35 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
self-supervised learning,  low-resource language,  automatic speech recognition
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">

Yao-Fei Cheng<span id="id1.1.id1" class="ltx_text" style="position:relative; bottom:0.0pt;"><sup id="id1.1.id1.1" class="ltx_sup"><span id="id1.1.id1.1.1" class="ltx_text" style="font-size:80%;">1</span></sup></span>,
Li-Wei Chen<span id="id2.2.id2" class="ltx_text" style="position:relative; bottom:0.0pt;"><sup id="id2.2.id2.1" class="ltx_sup"><span id="id2.2.id2.1.1" class="ltx_text" style="font-size:80%;">2,3</span></sup></span>,
Hung-Shin Lee<span id="id3.3.id3" class="ltx_text" style="position:relative; bottom:0.0pt;"><sup id="id3.3.id3.1" class="ltx_sup"><span id="id3.3.id3.1.1" class="ltx_text" style="font-size:80%;">3</span></sup></span>,
Hsin-Min Wang<span id="id4.4.id4" class="ltx_text" style="position:relative; bottom:0.0pt;"><sup id="id4.4.id4.1" class="ltx_sup"><span id="id4.4.id4.1.1" class="ltx_text" style="font-size:80%;">4</span></sup></span>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.5.id1" class="ltx_text" style="position:relative; bottom:0.0pt;"><sup id="id5.5.id1.1" class="ltx_sup"><span id="id5.5.id1.1.1" class="ltx_text" style="font-size:80%;">1</span></sup></span>University of Washington, <span id="id6.6.id2" class="ltx_text" style="position:relative; bottom:0.0pt;"><sup id="id6.6.id2.1" class="ltx_sup"><span id="id6.6.id2.1.1" class="ltx_text" style="font-size:80%;">2</span></sup></span>National Tsing Hua University,
<span id="id7.7.id3" class="ltx_text" style="position:relative; bottom:0.0pt;"><sup id="id7.7.id3.1" class="ltx_sup"><span id="id7.7.id3.1.1" class="ltx_text" style="font-size:80%;">3</span></sup></span>United Link Co., Ltd.,
<span id="id8.8.id4" class="ltx_text" style="position:relative; bottom:0.0pt;"><sup id="id8.8.id4.1" class="ltx_sup"><span id="id8.8.id4.1.1" class="ltx_text" style="font-size:80%;">4</span></sup></span>Academia Sinica

</span>
<span class="ltx_contact ltx_role_affiliation">nlp5566@uw.edu
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">This study investigates the efficacy of data augmentation techniques for low-resource automatic speech recognition (ASR), focusing on two endangered Austronesian languages, Amis and Seediq. Recognizing the potential of self-supervised learning (SSL) in low-resource settings, we explore the impact of data volume on the continued pre-training of SSL models. We propose a novel data-selection scheme leveraging a multilingual corpus to augment the limited target language data. This scheme utilizes a language classifier to extract utterance embeddings and employs one-class classifiers to identify utterances phonetically and phonologically proximate to the target languages. Utterances are ranked and selected based on their decision scores, ensuring the inclusion of highly relevant data in the SSL-ASR pipeline. Our experimental results demonstrate the effectiveness of this approach, yielding substantial improvements in ASR performance for both Amis and Seediq. These findings underscore the feasibility and promise of data augmentation through cross-lingual transfer learning for low-resource language ASR.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
self-supervised learning, low-resource language, automatic speech recognition

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The development of contemporary end-to-end automatic speech recognition (ASR) systems has achieved remarkable success in high-resource languages such as English, French, and Chinese <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">1</a>, <a href="#bib.bibx2" title="" class="ltx_ref">2</a>]</cite>. This progress is largely attributed to the availability of extensive speech-text paired training data. However, this data abundance does not extend to endangered languages like Amis and Seediq, where acquiring high-quality transcriptions is particularly challenging and resource-intensive. The scarcity of annotated data and factors like limited speaker populations and non-standardized writing systems pose significant obstacles to developing effective ASR systems for these languages.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Self-supervised learning (SSL) has emerged as a promising avenue for mitigating the data sparsity issue in low-resource ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">3</a>, <a href="#bib.bibx4" title="" class="ltx_ref">4</a>, <a href="#bib.bibx5" title="" class="ltx_ref">5</a>]</cite>. SSL models, pre-trained on vast amounts of unlabeled speech data, can be effectively fine-tuned with limited labeled data. However, the initial pre-training phase of these models typically necessitates substantially larger amounts of data than supervised approaches. For instance, the monolingual model <span id="S1.p2.1.1" class="ltx_text ltx_font_typewriter">wav2vec 2.0 base</span> requires 960 hours of speech data for effective pre-training, with larger models demanding even more, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">4</a>]</cite>. This data requirement presents a significant hurdle for endangered languages, where collecting such extensive datasets is often infeasible, thus limiting the practicality of training SSL models from scratch.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Addressing the pervasive issue of resource scarcity in natural language processing, researchers have explored various avenues, including language representation tools like <span id="S1.p3.1.1" class="ltx_text ltx_font_typewriter">lang2vec</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">6</a>]</cite> and data augmentation techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">7</a>, <a href="#bib.bibx8" title="" class="ltx_ref">8</a>]</cite>. However, these approaches face limitations when applied to low-resourced languages like Amis and Seediq. <span id="S1.p3.1.2" class="ltx_text ltx_font_typewriter">lang2vec</span> currently lacks support for these languages, while data augmentation often relies on textual data, which is scarce or unavailable for many spoken and low-resource languages.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.2" class="ltx_p">Consequently, recent research has shifted towards leveraging multilingual SSL models for low-resource ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">9</a>, <a href="#bib.bibx10" title="" class="ltx_ref">10</a>]</cite>. This approach capitalizes on phonetic similarities across languages, enabling knowledge transfer and improved transcription accuracy during fine-tuning. Notably, the ML-SUPERB benchmark, encompassing <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="143" display="inline"><semantics id="S1.p4.1.m1.1a"><mn id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">143</mn><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><cn type="integer" id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">143</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">143</annotation></semantics></math> languages, highlighted the superior performance of <span id="S1.p4.2.1" class="ltx_text ltx_font_typewriter">XLSR-128</span> in both monolingual and multilingual ASR tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">11</a>]</cite>. Further emphasizing the potential of this approach, Nowakowski et al. demonstrated the effectiveness of continuing pre-training with target language data, albeit with a significant data requirement exceeding <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="234" display="inline"><semantics id="S1.p4.2.m2.1a"><mn id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml">234</mn><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><cn type="integer" id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1">234</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">234</annotation></semantics></math> hours <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">12</a>]</cite>. Their work also explored leveraging phonetically similar languages for data augmentation, achieving promising results. Similarly, San et al. proposed utilizing donor speech data from related languages for fine-tuning, highlighting the potential of cross-lingual transfer learning in low-resource settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">This research diverges from previous studies by exploring the feasibility of achieving robust ASR performance with minimal paired and unpaired data for the target language. Unlike studies assuming access to large-scale similar-language speech data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">12</a>]</cite>, we address a more challenging scenario where such data is unavailable. Focusing on the severely low-resource Austronesian languages, Amis and Seediq, we aim to develop effective ASR systems using a modest multilingual corpus and limited paired data (less than one hour per language). Our approach centers on a novel data-selection strategy designed to identify and incorporate utterances from the multilingual corpus that exhibit close phonetic and phonological similarity to the target languages, thus refining the SSL-ASR pipeline. We achieve this by first employing a language classifier to extract language-specific embeddings for each utterance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">14</a>, <a href="#bib.bibx15" title="" class="ltx_ref">15</a>]</cite>. Then, leveraging a suite of one-class classifiers â€“ One-class SVM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">16</a>]</cite>, Isolation Forest <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">17</a>]</cite>, and Deep SVDD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">18</a>]</cite> â€“ we rank and select utterances based on their decision scores, prioritizing those most similar to the target languages. Our results demonstrate the effectiveness of this approach for both Amis and Seediq, yielding promising ASR performance despite the significant data constraints.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.08872/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="207" height="196" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Diagram for picking the top-<math id="S1.F1.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S1.F1.2.m1.1b"><mi id="S1.F1.2.m1.1.1" xref="S1.F1.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.F1.2.m1.1c"><ci id="S1.F1.2.m1.1.1.cmml" xref="S1.F1.2.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.2.m1.1d">k</annotation></semantics></math> hours data.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Data Description</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.3" class="ltx_p">Taiwan is home to 16 indigenous ethnic groups, encompassing 42 dialects. The Taiwan Council of Indigenous Peoples introduced Klokah<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://web.klokah.tw" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://web.klokah.tw</a></span></span></span>, an e-learning platform with abundant audio materials to foster native language use among the younger generation. These materials span nine subjects, from everyday conversations to textbook passages. For ASR system development, we curated a dataset from two subjects: reading-and-writing and contextual-language, chosen based on their suitable audio lengths. We selected Amis and Seediq for experimentation, allocating <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn type="integer" id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">1</annotation></semantics></math> hour or <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S2.p1.2.m2.1a"><mn id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><cn type="integer" id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">10</annotation></semantics></math> minutes of speech for training and <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S2.p1.3.m3.1a"><mn id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><cn type="integer" id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">10</annotation></semantics></math> minutes each for validation and testing.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.4" class="ltx_p">As of 2023, Amis has approximately <math id="S2.p2.1.m1.2" class="ltx_Math" alttext="218,500" display="inline"><semantics id="S2.p2.1.m1.2a"><mrow id="S2.p2.1.m1.2.3.2" xref="S2.p2.1.m1.2.3.1.cmml"><mn id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">218</mn><mo id="S2.p2.1.m1.2.3.2.1" xref="S2.p2.1.m1.2.3.1.cmml">,</mo><mn id="S2.p2.1.m1.2.2" xref="S2.p2.1.m1.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.2b"><list id="S2.p2.1.m1.2.3.1.cmml" xref="S2.p2.1.m1.2.3.2"><cn type="integer" id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">218</cn><cn type="integer" id="S2.p2.1.m1.2.2.cmml" xref="S2.p2.1.m1.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.2c">218,500</annotation></semantics></math> speakers in Taiwan. It is one of the endangered languages identified by the United Nations Educational, Scientific and Cultural Organization (UNESCO). Its writing system consists of <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="21" display="inline"><semantics id="S2.p2.2.m2.1a"><mn id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">21</mn><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><cn type="integer" id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">21</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">21</annotation></semantics></math> Latin letters and one digraph (ng). Another <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S2.p2.3.m3.1a"><mn id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><cn type="integer" id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">5</annotation></semantics></math> Latin letters (b, g, j, q, and v) are used only for loanwords. The epiglottal stop // and glottal stop // are marked as â€™ and ^, respectively. The vowel length // is marked as a colon symbol <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="\colon" display="inline"><semantics id="S2.p2.4.m4.1a"><mo id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">:</mo><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">:</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">\colon</annotation></semantics></math>, meaning semantic emphasis.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.2" class="ltx_p">Seediq is also an endangered language that has been identified by UNESCO. Its speaker population in Taiwan is about <math id="S2.p3.1.m1.2" class="ltx_Math" alttext="10,970" display="inline"><semantics id="S2.p3.1.m1.2a"><mrow id="S2.p3.1.m1.2.3.2" xref="S2.p3.1.m1.2.3.1.cmml"><mn id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">10</mn><mo id="S2.p3.1.m1.2.3.2.1" xref="S2.p3.1.m1.2.3.1.cmml">,</mo><mn id="S2.p3.1.m1.2.2" xref="S2.p3.1.m1.2.2.cmml">970</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.2b"><list id="S2.p3.1.m1.2.3.1.cmml" xref="S2.p3.1.m1.2.3.2"><cn type="integer" id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">10</cn><cn type="integer" id="S2.p3.1.m1.2.2.cmml" xref="S2.p3.1.m1.2.2">970</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.2c">10,970</annotation></semantics></math>. Seediq's writing system consists of <math id="S2.p3.2.m2.1" class="ltx_Math" alttext="23" display="inline"><semantics id="S2.p3.2.m2.1a"><mn id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">23</mn><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><cn type="integer" id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">23</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">23</annotation></semantics></math> Latin letters and seven digraphs (aw, ay, ey, ow, uy, ug, and ng).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Method</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Inspired by Nowakowski et al.'s work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">12</a>]</cite>, which demonstrated the benefit of utilizing a related language (Japanese) for improving ASR performance in a low-resource setting (Ainu) through continued pre-training<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Interestingly, the Ainu speech data utilized for continued pre-training of the SSL model exceeded 200 hours.</span></span></span>, we propose a novel data augmentation strategy. Recognizing that <span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">lang2vec</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">6</a>]</cite>, the tool used in their study, does not currently support our target languages, we present an alternative approach: leveraging multilingual fine-tuning of an SSL model with data from languages exhibiting phonetic and phonological similarities to the target languages. This approach aims to enhance speech recognition performance by enriching the training data with acoustically similar utterances.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Our methodology, illustrated in <a href="#S1.F1" title="In I Introduction â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>, employs a two-phase approach. In the first phase, a neural spoken language identification model analyzes utterances to extract language-specific embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">14</a>, <a href="#bib.bibx15" title="" class="ltx_ref">15</a>]</cite> (orange box in <a href="#S1.F1" title="In I Introduction â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>). These embeddings, derived from the penultimate layer of the classifier, encapsulate rich phonetic and phonological information. The second phase leverages these embeddings to train a suite of one-class classifiers (red box in <a href="#S1.F1" title="In I Introduction â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>). These classifiers are then employed to identify and select utterances from a larger multilingual dataset that exhibit high similarity to the target language, thereby enriching the training data for subsequent SSL model fine-tuning.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.08872/assets/x2.png" id="S3.F2.sf1.g1" class="ltx_graphics ltx_img_square" width="207" height="208" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.08872/assets/x3.png" id="S3.F2.sf2.g1" class="ltx_graphics ltx_img_square" width="207" height="207" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The effect of data amount and selection on continued pre-training XLSR-128 for Amis and Seediq. The x-axis represents the amount of sampled data (in hours), and `1' means 1 hour of non-target language data is used together with 1 hour of target language data in continued pre-training.</figcaption>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">We employed three distinct one-class classifiers, each selected for its ability to effectively address the novelty detection task without relying on assumptions about the underlying data distribution.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">First, One-class Support Vector Machine (OcSVM) aims to construct a hyperplane in a high-dimensional feature space that encloses the majority of data points while maximizing the distance between this hyperplane and the origin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">16</a>]</cite>. This approach effectively separates the data from regions with a sparse data density. Data points falling outside the hyperplane's boundary are then classified as anomalies.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">Second, Isolation Forest (IF) leverages an ensemble of isolation trees to detect anomalies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">19</a>]</cite>. Each tree is constructed by recursively partitioning the data based on randomly selected features and split points. The algorithm aggregates these path lengths to provide an anomaly score for each data point.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">Finally, Deep Support Vector Data Description (D-SVDD) utilizes a deep neural network to learn a hypersphere in the feature space that encapsulates the training data while minimizing the volume of this hypersphere <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p">Given the potential for variation in the rankings produced by each classifier, we introduce an ensemble algorithm to harmonize their predictions and enhance the reliability of the utterance selection process (see <a href="#alg1" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>). This algorithm prioritizes consistently flagged utterances similar to those of all three classifiers, ensuring a more robust and confident data selection for augmenting the SSL model's training set.</p>
</div>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.4" class="ltx_p">In detail, <a href="#alg1" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> aims to create a list of utterances (<math id="S3.p8.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.p8.1.m1.1a"><mi id="S3.p8.1.m1.1.1" xref="S3.p8.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.p8.1.m1.1b"><ci id="S3.p8.1.m1.1.1.cmml" xref="S3.p8.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.1.m1.1c">R</annotation></semantics></math>), given three pre-sorted lists (<math id="S3.p8.2.m2.1" class="ltx_Math" alttext="U_{1}" display="inline"><semantics id="S3.p8.2.m2.1a"><msub id="S3.p8.2.m2.1.1" xref="S3.p8.2.m2.1.1.cmml"><mi id="S3.p8.2.m2.1.1.2" xref="S3.p8.2.m2.1.1.2.cmml">U</mi><mn id="S3.p8.2.m2.1.1.3" xref="S3.p8.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p8.2.m2.1b"><apply id="S3.p8.2.m2.1.1.cmml" xref="S3.p8.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p8.2.m2.1.1.1.cmml" xref="S3.p8.2.m2.1.1">subscript</csymbol><ci id="S3.p8.2.m2.1.1.2.cmml" xref="S3.p8.2.m2.1.1.2">ğ‘ˆ</ci><cn type="integer" id="S3.p8.2.m2.1.1.3.cmml" xref="S3.p8.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.2.m2.1c">U_{1}</annotation></semantics></math>, <math id="S3.p8.3.m3.1" class="ltx_Math" alttext="U_{2}" display="inline"><semantics id="S3.p8.3.m3.1a"><msub id="S3.p8.3.m3.1.1" xref="S3.p8.3.m3.1.1.cmml"><mi id="S3.p8.3.m3.1.1.2" xref="S3.p8.3.m3.1.1.2.cmml">U</mi><mn id="S3.p8.3.m3.1.1.3" xref="S3.p8.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p8.3.m3.1b"><apply id="S3.p8.3.m3.1.1.cmml" xref="S3.p8.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p8.3.m3.1.1.1.cmml" xref="S3.p8.3.m3.1.1">subscript</csymbol><ci id="S3.p8.3.m3.1.1.2.cmml" xref="S3.p8.3.m3.1.1.2">ğ‘ˆ</ci><cn type="integer" id="S3.p8.3.m3.1.1.3.cmml" xref="S3.p8.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.3.m3.1c">U_{2}</annotation></semantics></math>, <math id="S3.p8.4.m4.1" class="ltx_Math" alttext="U_{3}" display="inline"><semantics id="S3.p8.4.m4.1a"><msub id="S3.p8.4.m4.1.1" xref="S3.p8.4.m4.1.1.cmml"><mi id="S3.p8.4.m4.1.1.2" xref="S3.p8.4.m4.1.1.2.cmml">U</mi><mn id="S3.p8.4.m4.1.1.3" xref="S3.p8.4.m4.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p8.4.m4.1b"><apply id="S3.p8.4.m4.1.1.cmml" xref="S3.p8.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p8.4.m4.1.1.1.cmml" xref="S3.p8.4.m4.1.1">subscript</csymbol><ci id="S3.p8.4.m4.1.1.2.cmml" xref="S3.p8.4.m4.1.1.2">ğ‘ˆ</ci><cn type="integer" id="S3.p8.4.m4.1.1.3.cmml" xref="S3.p8.4.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.4.m4.1c">U_{3}</annotation></semantics></math>) based on the decision scores of Deep SVDD, One-class SVM, and Isolation Forest. The algorithm prioritizes utterances appearing high in all three lists.</p>
</div>
<div id="S3.p9" class="ltx_para">
<p id="S3.p9.12" class="ltx_p">The process begins by initializing <math id="S3.p9.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.p9.1.m1.1a"><mi id="S3.p9.1.m1.1.1" xref="S3.p9.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.p9.1.m1.1b"><ci id="S3.p9.1.m1.1.1.cmml" xref="S3.p9.1.m1.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.1.m1.1c">L</annotation></semantics></math> with an initial ranking limit (<math id="S3.p9.2.m2.1" class="ltx_Math" alttext="L_{0}" display="inline"><semantics id="S3.p9.2.m2.1a"><msub id="S3.p9.2.m2.1.1" xref="S3.p9.2.m2.1.1.cmml"><mi id="S3.p9.2.m2.1.1.2" xref="S3.p9.2.m2.1.1.2.cmml">L</mi><mn id="S3.p9.2.m2.1.1.3" xref="S3.p9.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p9.2.m2.1b"><apply id="S3.p9.2.m2.1.1.cmml" xref="S3.p9.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p9.2.m2.1.1.1.cmml" xref="S3.p9.2.m2.1.1">subscript</csymbol><ci id="S3.p9.2.m2.1.1.2.cmml" xref="S3.p9.2.m2.1.1.2">ğ¿</ci><cn type="integer" id="S3.p9.2.m2.1.1.3.cmml" xref="S3.p9.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.2.m2.1c">L_{0}</annotation></semantics></math>). It iteratively expands <math id="S3.p9.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.p9.3.m3.1a"><mi id="S3.p9.3.m3.1.1" xref="S3.p9.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.p9.3.m3.1b"><ci id="S3.p9.3.m3.1.1.cmml" xref="S3.p9.3.m3.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.3.m3.1c">L</annotation></semantics></math> until the total duration of utterances in <math id="S3.p9.4.m4.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.p9.4.m4.1a"><mi id="S3.p9.4.m4.1.1" xref="S3.p9.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.p9.4.m4.1b"><ci id="S3.p9.4.m4.1.1.cmml" xref="S3.p9.4.m4.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.4.m4.1c">R</annotation></semantics></math> meets a predefined time limit (<math id="S3.p9.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p9.5.m5.1a"><mi id="S3.p9.5.m5.1.1" xref="S3.p9.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p9.5.m5.1b"><ci id="S3.p9.5.m5.1.1.cmml" xref="S3.p9.5.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.5.m5.1c">k</annotation></semantics></math> hours). Each iteration involves selecting top <math id="S3.p9.6.m6.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.p9.6.m6.1a"><mi id="S3.p9.6.m6.1.1" xref="S3.p9.6.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.p9.6.m6.1b"><ci id="S3.p9.6.m6.1.1.cmml" xref="S3.p9.6.m6.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.6.m6.1c">L</annotation></semantics></math> utterances from each list (<math id="S3.p9.7.m7.1" class="ltx_Math" alttext="U_{1}" display="inline"><semantics id="S3.p9.7.m7.1a"><msub id="S3.p9.7.m7.1.1" xref="S3.p9.7.m7.1.1.cmml"><mi id="S3.p9.7.m7.1.1.2" xref="S3.p9.7.m7.1.1.2.cmml">U</mi><mn id="S3.p9.7.m7.1.1.3" xref="S3.p9.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p9.7.m7.1b"><apply id="S3.p9.7.m7.1.1.cmml" xref="S3.p9.7.m7.1.1"><csymbol cd="ambiguous" id="S3.p9.7.m7.1.1.1.cmml" xref="S3.p9.7.m7.1.1">subscript</csymbol><ci id="S3.p9.7.m7.1.1.2.cmml" xref="S3.p9.7.m7.1.1.2">ğ‘ˆ</ci><cn type="integer" id="S3.p9.7.m7.1.1.3.cmml" xref="S3.p9.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.7.m7.1c">U_{1}</annotation></semantics></math>, <math id="S3.p9.8.m8.1" class="ltx_Math" alttext="U_{2}" display="inline"><semantics id="S3.p9.8.m8.1a"><msub id="S3.p9.8.m8.1.1" xref="S3.p9.8.m8.1.1.cmml"><mi id="S3.p9.8.m8.1.1.2" xref="S3.p9.8.m8.1.1.2.cmml">U</mi><mn id="S3.p9.8.m8.1.1.3" xref="S3.p9.8.m8.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p9.8.m8.1b"><apply id="S3.p9.8.m8.1.1.cmml" xref="S3.p9.8.m8.1.1"><csymbol cd="ambiguous" id="S3.p9.8.m8.1.1.1.cmml" xref="S3.p9.8.m8.1.1">subscript</csymbol><ci id="S3.p9.8.m8.1.1.2.cmml" xref="S3.p9.8.m8.1.1.2">ğ‘ˆ</ci><cn type="integer" id="S3.p9.8.m8.1.1.3.cmml" xref="S3.p9.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.8.m8.1c">U_{2}</annotation></semantics></math>, <math id="S3.p9.9.m9.1" class="ltx_Math" alttext="U_{3}" display="inline"><semantics id="S3.p9.9.m9.1a"><msub id="S3.p9.9.m9.1.1" xref="S3.p9.9.m9.1.1.cmml"><mi id="S3.p9.9.m9.1.1.2" xref="S3.p9.9.m9.1.1.2.cmml">U</mi><mn id="S3.p9.9.m9.1.1.3" xref="S3.p9.9.m9.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p9.9.m9.1b"><apply id="S3.p9.9.m9.1.1.cmml" xref="S3.p9.9.m9.1.1"><csymbol cd="ambiguous" id="S3.p9.9.m9.1.1.1.cmml" xref="S3.p9.9.m9.1.1">subscript</csymbol><ci id="S3.p9.9.m9.1.1.2.cmml" xref="S3.p9.9.m9.1.1.2">ğ‘ˆ</ci><cn type="integer" id="S3.p9.9.m9.1.1.3.cmml" xref="S3.p9.9.m9.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.9.m9.1c">U_{3}</annotation></semantics></math>), denoted as <math id="S3.p9.10.m10.1" class="ltx_Math" alttext="\widehat{U_{1}}" display="inline"><semantics id="S3.p9.10.m10.1a"><mover accent="true" id="S3.p9.10.m10.1.1" xref="S3.p9.10.m10.1.1.cmml"><msub id="S3.p9.10.m10.1.1.2" xref="S3.p9.10.m10.1.1.2.cmml"><mi id="S3.p9.10.m10.1.1.2.2" xref="S3.p9.10.m10.1.1.2.2.cmml">U</mi><mn id="S3.p9.10.m10.1.1.2.3" xref="S3.p9.10.m10.1.1.2.3.cmml">1</mn></msub><mo id="S3.p9.10.m10.1.1.1" xref="S3.p9.10.m10.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p9.10.m10.1b"><apply id="S3.p9.10.m10.1.1.cmml" xref="S3.p9.10.m10.1.1"><ci id="S3.p9.10.m10.1.1.1.cmml" xref="S3.p9.10.m10.1.1.1">^</ci><apply id="S3.p9.10.m10.1.1.2.cmml" xref="S3.p9.10.m10.1.1.2"><csymbol cd="ambiguous" id="S3.p9.10.m10.1.1.2.1.cmml" xref="S3.p9.10.m10.1.1.2">subscript</csymbol><ci id="S3.p9.10.m10.1.1.2.2.cmml" xref="S3.p9.10.m10.1.1.2.2">ğ‘ˆ</ci><cn type="integer" id="S3.p9.10.m10.1.1.2.3.cmml" xref="S3.p9.10.m10.1.1.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.10.m10.1c">\widehat{U_{1}}</annotation></semantics></math>, <math id="S3.p9.11.m11.1" class="ltx_Math" alttext="\widehat{U_{2}}" display="inline"><semantics id="S3.p9.11.m11.1a"><mover accent="true" id="S3.p9.11.m11.1.1" xref="S3.p9.11.m11.1.1.cmml"><msub id="S3.p9.11.m11.1.1.2" xref="S3.p9.11.m11.1.1.2.cmml"><mi id="S3.p9.11.m11.1.1.2.2" xref="S3.p9.11.m11.1.1.2.2.cmml">U</mi><mn id="S3.p9.11.m11.1.1.2.3" xref="S3.p9.11.m11.1.1.2.3.cmml">2</mn></msub><mo id="S3.p9.11.m11.1.1.1" xref="S3.p9.11.m11.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p9.11.m11.1b"><apply id="S3.p9.11.m11.1.1.cmml" xref="S3.p9.11.m11.1.1"><ci id="S3.p9.11.m11.1.1.1.cmml" xref="S3.p9.11.m11.1.1.1">^</ci><apply id="S3.p9.11.m11.1.1.2.cmml" xref="S3.p9.11.m11.1.1.2"><csymbol cd="ambiguous" id="S3.p9.11.m11.1.1.2.1.cmml" xref="S3.p9.11.m11.1.1.2">subscript</csymbol><ci id="S3.p9.11.m11.1.1.2.2.cmml" xref="S3.p9.11.m11.1.1.2.2">ğ‘ˆ</ci><cn type="integer" id="S3.p9.11.m11.1.1.2.3.cmml" xref="S3.p9.11.m11.1.1.2.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.11.m11.1c">\widehat{U_{2}}</annotation></semantics></math>, and <math id="S3.p9.12.m12.1" class="ltx_Math" alttext="\widehat{U_{3}}" display="inline"><semantics id="S3.p9.12.m12.1a"><mover accent="true" id="S3.p9.12.m12.1.1" xref="S3.p9.12.m12.1.1.cmml"><msub id="S3.p9.12.m12.1.1.2" xref="S3.p9.12.m12.1.1.2.cmml"><mi id="S3.p9.12.m12.1.1.2.2" xref="S3.p9.12.m12.1.1.2.2.cmml">U</mi><mn id="S3.p9.12.m12.1.1.2.3" xref="S3.p9.12.m12.1.1.2.3.cmml">3</mn></msub><mo id="S3.p9.12.m12.1.1.1" xref="S3.p9.12.m12.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p9.12.m12.1b"><apply id="S3.p9.12.m12.1.1.cmml" xref="S3.p9.12.m12.1.1"><ci id="S3.p9.12.m12.1.1.1.cmml" xref="S3.p9.12.m12.1.1.1">^</ci><apply id="S3.p9.12.m12.1.1.2.cmml" xref="S3.p9.12.m12.1.1.2"><csymbol cd="ambiguous" id="S3.p9.12.m12.1.1.2.1.cmml" xref="S3.p9.12.m12.1.1.2">subscript</csymbol><ci id="S3.p9.12.m12.1.1.2.2.cmml" xref="S3.p9.12.m12.1.1.2.2">ğ‘ˆ</ci><cn type="integer" id="S3.p9.12.m12.1.1.2.3.cmml" xref="S3.p9.12.m12.1.1.2.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.12.m12.1c">\widehat{U_{3}}</annotation></semantics></math>.</p>
</div>
<div id="S3.p10" class="ltx_para">
<p id="S3.p10.11" class="ltx_p">Subsequently, each utterance (<math id="S3.p10.1.m1.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S3.p10.1.m1.1a"><mi id="S3.p10.1.m1.1.1" xref="S3.p10.1.m1.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.p10.1.m1.1b"><ci id="S3.p10.1.m1.1.1.cmml" xref="S3.p10.1.m1.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.1.m1.1c">u</annotation></semantics></math>) in <math id="S3.p10.2.m2.1" class="ltx_Math" alttext="\widehat{U_{1}}" display="inline"><semantics id="S3.p10.2.m2.1a"><mover accent="true" id="S3.p10.2.m2.1.1" xref="S3.p10.2.m2.1.1.cmml"><msub id="S3.p10.2.m2.1.1.2" xref="S3.p10.2.m2.1.1.2.cmml"><mi id="S3.p10.2.m2.1.1.2.2" xref="S3.p10.2.m2.1.1.2.2.cmml">U</mi><mn id="S3.p10.2.m2.1.1.2.3" xref="S3.p10.2.m2.1.1.2.3.cmml">1</mn></msub><mo id="S3.p10.2.m2.1.1.1" xref="S3.p10.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p10.2.m2.1b"><apply id="S3.p10.2.m2.1.1.cmml" xref="S3.p10.2.m2.1.1"><ci id="S3.p10.2.m2.1.1.1.cmml" xref="S3.p10.2.m2.1.1.1">^</ci><apply id="S3.p10.2.m2.1.1.2.cmml" xref="S3.p10.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.p10.2.m2.1.1.2.1.cmml" xref="S3.p10.2.m2.1.1.2">subscript</csymbol><ci id="S3.p10.2.m2.1.1.2.2.cmml" xref="S3.p10.2.m2.1.1.2.2">ğ‘ˆ</ci><cn type="integer" id="S3.p10.2.m2.1.1.2.3.cmml" xref="S3.p10.2.m2.1.1.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.2.m2.1c">\widehat{U_{1}}</annotation></semantics></math> is evaluated. If <math id="S3.p10.3.m3.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S3.p10.3.m3.1a"><mi id="S3.p10.3.m3.1.1" xref="S3.p10.3.m3.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.p10.3.m3.1b"><ci id="S3.p10.3.m3.1.1.cmml" xref="S3.p10.3.m3.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.3.m3.1c">u</annotation></semantics></math> is not already in <math id="S3.p10.4.m4.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.p10.4.m4.1a"><mi id="S3.p10.4.m4.1.1" xref="S3.p10.4.m4.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.p10.4.m4.1b"><ci id="S3.p10.4.m4.1.1.cmml" xref="S3.p10.4.m4.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.4.m4.1c">R</annotation></semantics></math> and is present in both <math id="S3.p10.5.m5.1" class="ltx_Math" alttext="\widehat{U_{2}}" display="inline"><semantics id="S3.p10.5.m5.1a"><mover accent="true" id="S3.p10.5.m5.1.1" xref="S3.p10.5.m5.1.1.cmml"><msub id="S3.p10.5.m5.1.1.2" xref="S3.p10.5.m5.1.1.2.cmml"><mi id="S3.p10.5.m5.1.1.2.2" xref="S3.p10.5.m5.1.1.2.2.cmml">U</mi><mn id="S3.p10.5.m5.1.1.2.3" xref="S3.p10.5.m5.1.1.2.3.cmml">2</mn></msub><mo id="S3.p10.5.m5.1.1.1" xref="S3.p10.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p10.5.m5.1b"><apply id="S3.p10.5.m5.1.1.cmml" xref="S3.p10.5.m5.1.1"><ci id="S3.p10.5.m5.1.1.1.cmml" xref="S3.p10.5.m5.1.1.1">^</ci><apply id="S3.p10.5.m5.1.1.2.cmml" xref="S3.p10.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.p10.5.m5.1.1.2.1.cmml" xref="S3.p10.5.m5.1.1.2">subscript</csymbol><ci id="S3.p10.5.m5.1.1.2.2.cmml" xref="S3.p10.5.m5.1.1.2.2">ğ‘ˆ</ci><cn type="integer" id="S3.p10.5.m5.1.1.2.3.cmml" xref="S3.p10.5.m5.1.1.2.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.5.m5.1c">\widehat{U_{2}}</annotation></semantics></math> and <math id="S3.p10.6.m6.1" class="ltx_Math" alttext="\widehat{U_{3}}" display="inline"><semantics id="S3.p10.6.m6.1a"><mover accent="true" id="S3.p10.6.m6.1.1" xref="S3.p10.6.m6.1.1.cmml"><msub id="S3.p10.6.m6.1.1.2" xref="S3.p10.6.m6.1.1.2.cmml"><mi id="S3.p10.6.m6.1.1.2.2" xref="S3.p10.6.m6.1.1.2.2.cmml">U</mi><mn id="S3.p10.6.m6.1.1.2.3" xref="S3.p10.6.m6.1.1.2.3.cmml">3</mn></msub><mo id="S3.p10.6.m6.1.1.1" xref="S3.p10.6.m6.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p10.6.m6.1b"><apply id="S3.p10.6.m6.1.1.cmml" xref="S3.p10.6.m6.1.1"><ci id="S3.p10.6.m6.1.1.1.cmml" xref="S3.p10.6.m6.1.1.1">^</ci><apply id="S3.p10.6.m6.1.1.2.cmml" xref="S3.p10.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.p10.6.m6.1.1.2.1.cmml" xref="S3.p10.6.m6.1.1.2">subscript</csymbol><ci id="S3.p10.6.m6.1.1.2.2.cmml" xref="S3.p10.6.m6.1.1.2.2">ğ‘ˆ</ci><cn type="integer" id="S3.p10.6.m6.1.1.2.3.cmml" xref="S3.p10.6.m6.1.1.2.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.6.m6.1c">\widehat{U_{3}}</annotation></semantics></math>, it signifies high ranking across all three lists and is appended to <math id="S3.p10.7.m7.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.p10.7.m7.1a"><mi id="S3.p10.7.m7.1.1" xref="S3.p10.7.m7.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.p10.7.m7.1b"><ci id="S3.p10.7.m7.1.1.cmml" xref="S3.p10.7.m7.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.7.m7.1c">R</annotation></semantics></math>. After processing all utterances in <math id="S3.p10.8.m8.1" class="ltx_Math" alttext="\widehat{U_{1}}" display="inline"><semantics id="S3.p10.8.m8.1a"><mover accent="true" id="S3.p10.8.m8.1.1" xref="S3.p10.8.m8.1.1.cmml"><msub id="S3.p10.8.m8.1.1.2" xref="S3.p10.8.m8.1.1.2.cmml"><mi id="S3.p10.8.m8.1.1.2.2" xref="S3.p10.8.m8.1.1.2.2.cmml">U</mi><mn id="S3.p10.8.m8.1.1.2.3" xref="S3.p10.8.m8.1.1.2.3.cmml">1</mn></msub><mo id="S3.p10.8.m8.1.1.1" xref="S3.p10.8.m8.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p10.8.m8.1b"><apply id="S3.p10.8.m8.1.1.cmml" xref="S3.p10.8.m8.1.1"><ci id="S3.p10.8.m8.1.1.1.cmml" xref="S3.p10.8.m8.1.1.1">^</ci><apply id="S3.p10.8.m8.1.1.2.cmml" xref="S3.p10.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.p10.8.m8.1.1.2.1.cmml" xref="S3.p10.8.m8.1.1.2">subscript</csymbol><ci id="S3.p10.8.m8.1.1.2.2.cmml" xref="S3.p10.8.m8.1.1.2.2">ğ‘ˆ</ci><cn type="integer" id="S3.p10.8.m8.1.1.2.3.cmml" xref="S3.p10.8.m8.1.1.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.8.m8.1c">\widehat{U_{1}}</annotation></semantics></math>, <math id="S3.p10.9.m9.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.p10.9.m9.1a"><mi id="S3.p10.9.m9.1.1" xref="S3.p10.9.m9.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.p10.9.m9.1b"><ci id="S3.p10.9.m9.1.1.cmml" xref="S3.p10.9.m9.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.9.m9.1c">L</annotation></semantics></math> is incremented by <math id="S3.p10.10.m10.1" class="ltx_Math" alttext="L_{0}" display="inline"><semantics id="S3.p10.10.m10.1a"><msub id="S3.p10.10.m10.1.1" xref="S3.p10.10.m10.1.1.cmml"><mi id="S3.p10.10.m10.1.1.2" xref="S3.p10.10.m10.1.1.2.cmml">L</mi><mn id="S3.p10.10.m10.1.1.3" xref="S3.p10.10.m10.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.p10.10.m10.1b"><apply id="S3.p10.10.m10.1.1.cmml" xref="S3.p10.10.m10.1.1"><csymbol cd="ambiguous" id="S3.p10.10.m10.1.1.1.cmml" xref="S3.p10.10.m10.1.1">subscript</csymbol><ci id="S3.p10.10.m10.1.1.2.cmml" xref="S3.p10.10.m10.1.1.2">ğ¿</ci><cn type="integer" id="S3.p10.10.m10.1.1.3.cmml" xref="S3.p10.10.m10.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.10.m10.1c">L_{0}</annotation></semantics></math> for the next iteration. This cycle continues until the time constraint of <math id="S3.p10.11.m11.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.p10.11.m11.1a"><mi id="S3.p10.11.m11.1.1" xref="S3.p10.11.m11.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.p10.11.m11.1b"><ci id="S3.p10.11.m11.1.1.cmml" xref="S3.p10.11.m11.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p10.11.m11.1c">R</annotation></semantics></math> is met.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Multi-list Utterance Selection</figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span><span id="alg1.l1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Given</span><span id="alg1.l1.3" class="ltx_text" style="font-size:90%;"> three lists of utterances </span><math id="alg1.l1.m1.1" class="ltx_Math" alttext="U_{1}" display="inline"><semantics id="alg1.l1.m1.1a"><msub id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l1.m1.1.1.2" xref="alg1.l1.m1.1.1.2.cmml">U</mi><mn mathsize="90%" id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1">subscript</csymbol><ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">ğ‘ˆ</ci><cn type="integer" id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">U_{1}</annotation></semantics></math><span id="alg1.l1.4" class="ltx_text" style="font-size:90%;">, </span><math id="alg1.l1.m2.1" class="ltx_Math" alttext="U_{2}" display="inline"><semantics id="alg1.l1.m2.1a"><msub id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml"><mi mathsize="90%" id="alg1.l1.m2.1.1.2" xref="alg1.l1.m2.1.1.2.cmml">U</mi><mn mathsize="90%" id="alg1.l1.m2.1.1.3" xref="alg1.l1.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><apply id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.1.1.1.cmml" xref="alg1.l1.m2.1.1">subscript</csymbol><ci id="alg1.l1.m2.1.1.2.cmml" xref="alg1.l1.m2.1.1.2">ğ‘ˆ</ci><cn type="integer" id="alg1.l1.m2.1.1.3.cmml" xref="alg1.l1.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">U_{2}</annotation></semantics></math><span id="alg1.l1.5" class="ltx_text" style="font-size:90%;">, and </span><math id="alg1.l1.m3.1" class="ltx_Math" alttext="U_{3}" display="inline"><semantics id="alg1.l1.m3.1a"><msub id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml"><mi mathsize="90%" id="alg1.l1.m3.1.1.2" xref="alg1.l1.m3.1.1.2.cmml">U</mi><mn mathsize="90%" id="alg1.l1.m3.1.1.3" xref="alg1.l1.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><apply id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1"><csymbol cd="ambiguous" id="alg1.l1.m3.1.1.1.cmml" xref="alg1.l1.m3.1.1">subscript</csymbol><ci id="alg1.l1.m3.1.1.2.cmml" xref="alg1.l1.m3.1.1.2">ğ‘ˆ</ci><cn type="integer" id="alg1.l1.m3.1.1.3.cmml" xref="alg1.l1.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">U_{3}</annotation></semantics></math><span id="alg1.l1.6" class="ltx_text" style="font-size:90%;"> sorted by decision scores of Deep SVDD, One-class SVM, and Isolation Forest </span>
</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span><span id="alg1.l2.2" class="ltx_text" style="font-size:90%;">Initial ranking limit </span><math id="alg1.l2.m1.1" class="ltx_Math" alttext="L_{0}" display="inline"><semantics id="alg1.l2.m1.1a"><msub id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">L</mi><mn mathsize="90%" id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">ğ¿</ci><cn type="integer" id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">L_{0}</annotation></semantics></math><span id="alg1.l2.3" class="ltx_text" style="font-size:90%;">, final list </span><math id="alg1.l2.m2.1" class="ltx_Math" alttext="R" display="inline"><semantics id="alg1.l2.m2.1a"><mi mathsize="90%" id="alg1.l2.m2.1.1" xref="alg1.l2.m2.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m2.1b"><ci id="alg1.l2.m2.1.1.cmml" xref="alg1.l2.m2.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m2.1c">R</annotation></semantics></math><span id="alg1.l2.4" class="ltx_text" style="font-size:90%;">, and specified hours </span><math id="alg1.l2.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.l2.m3.1a"><mi mathsize="90%" id="alg1.l2.m3.1.1" xref="alg1.l2.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m3.1b"><ci id="alg1.l2.m3.1.1.cmml" xref="alg1.l2.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m3.1c">k</annotation></semantics></math><span id="alg1.l2.5" class="ltx_text" style="font-size:90%;">.
</span>
</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span><math id="alg1.l3.m1.1" class="ltx_Math" alttext="L\leftarrow L_{0}" display="inline"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml">L</mi><mo mathsize="90%" stretchy="false" id="alg1.l3.m1.1.1.1" xref="alg1.l3.m1.1.1.1.cmml">â†</mo><msub id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l3.m1.1.1.3.2" xref="alg1.l3.m1.1.1.3.2.cmml">L</mi><mn mathsize="90%" id="alg1.l3.m1.1.1.3.3" xref="alg1.l3.m1.1.1.3.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><ci id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1">â†</ci><ci id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2">ğ¿</ci><apply id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.3.1.cmml" xref="alg1.l3.m1.1.1.3">subscript</csymbol><ci id="alg1.l3.m1.1.1.3.2.cmml" xref="alg1.l3.m1.1.1.3.2">ğ¿</ci><cn type="integer" id="alg1.l3.m1.1.1.3.3.cmml" xref="alg1.l3.m1.1.1.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">L\leftarrow L_{0}</annotation></semantics></math><span id="alg1.l3.2" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span><span id="alg1.l4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">while</span><span id="alg1.l4.3" class="ltx_text" style="font-size:90%;">Â the total lengthÂ in </span><math id="alg1.l4.m1.1" class="ltx_Math" alttext="R&lt;k" display="inline"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml">R</mi><mo mathsize="90%" id="alg1.l4.m1.1.1.1" xref="alg1.l4.m1.1.1.1.cmml">&lt;</mo><mi mathsize="90%" id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><lt id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1"></lt><ci id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2">ğ‘…</ci><ci id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">R&lt;k</annotation></semantics></math><span id="alg1.l4.4" class="ltx_text" style="font-size:90%;"> hoursÂ </span><span id="alg1.l4.5" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="alg1.l4.6" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span><span id="alg1.l5.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><math id="alg1.l5.m1.1" class="ltx_math_unparsed" alttext="\widehat{U}_{1}\leftarrow U_{1}[:L]" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1b"><msub id="alg1.l5.m1.1.1"><mover accent="true" id="alg1.l5.m1.1.1.2"><mi mathsize="90%" id="alg1.l5.m1.1.1.2.2">U</mi><mo mathsize="90%" id="alg1.l5.m1.1.1.2.1">^</mo></mover><mn mathsize="90%" id="alg1.l5.m1.1.1.3">1</mn></msub><mo mathsize="90%" stretchy="false" id="alg1.l5.m1.1.2">â†</mo><msub id="alg1.l5.m1.1.3"><mi mathsize="90%" id="alg1.l5.m1.1.3.2">U</mi><mn mathsize="90%" id="alg1.l5.m1.1.3.3">1</mn></msub><mrow id="alg1.l5.m1.1.4"><mo maxsize="90%" minsize="90%" id="alg1.l5.m1.1.4.1">[</mo><mo mathsize="90%" rspace="0.278em" id="alg1.l5.m1.1.4.2">:</mo><mi mathsize="90%" id="alg1.l5.m1.1.4.3">L</mi><mo maxsize="90%" minsize="90%" id="alg1.l5.m1.1.4.4">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">\widehat{U}_{1}\leftarrow U_{1}[:L]</annotation></semantics></math><span id="alg1.l5.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span><span id="alg1.l6.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><math id="alg1.l6.m1.1" class="ltx_math_unparsed" alttext="\widehat{U}_{2}\leftarrow U_{2}[:L]" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1b"><msub id="alg1.l6.m1.1.1"><mover accent="true" id="alg1.l6.m1.1.1.2"><mi mathsize="90%" id="alg1.l6.m1.1.1.2.2">U</mi><mo mathsize="90%" id="alg1.l6.m1.1.1.2.1">^</mo></mover><mn mathsize="90%" id="alg1.l6.m1.1.1.3">2</mn></msub><mo mathsize="90%" stretchy="false" id="alg1.l6.m1.1.2">â†</mo><msub id="alg1.l6.m1.1.3"><mi mathsize="90%" id="alg1.l6.m1.1.3.2">U</mi><mn mathsize="90%" id="alg1.l6.m1.1.3.3">2</mn></msub><mrow id="alg1.l6.m1.1.4"><mo maxsize="90%" minsize="90%" id="alg1.l6.m1.1.4.1">[</mo><mo mathsize="90%" rspace="0.278em" id="alg1.l6.m1.1.4.2">:</mo><mi mathsize="90%" id="alg1.l6.m1.1.4.3">L</mi><mo maxsize="90%" minsize="90%" id="alg1.l6.m1.1.4.4">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\widehat{U}_{2}\leftarrow U_{2}[:L]</annotation></semantics></math><span id="alg1.l6.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span><span id="alg1.l7.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><math id="alg1.l7.m1.1" class="ltx_math_unparsed" alttext="\widehat{U}_{3}\leftarrow U_{3}[:L]" display="inline"><semantics id="alg1.l7.m1.1a"><mrow id="alg1.l7.m1.1b"><msub id="alg1.l7.m1.1.1"><mover accent="true" id="alg1.l7.m1.1.1.2"><mi mathsize="90%" id="alg1.l7.m1.1.1.2.2">U</mi><mo mathsize="90%" id="alg1.l7.m1.1.1.2.1">^</mo></mover><mn mathsize="90%" id="alg1.l7.m1.1.1.3">3</mn></msub><mo mathsize="90%" stretchy="false" id="alg1.l7.m1.1.2">â†</mo><msub id="alg1.l7.m1.1.3"><mi mathsize="90%" id="alg1.l7.m1.1.3.2">U</mi><mn mathsize="90%" id="alg1.l7.m1.1.3.3">3</mn></msub><mrow id="alg1.l7.m1.1.4"><mo maxsize="90%" minsize="90%" id="alg1.l7.m1.1.4.1">[</mo><mo mathsize="90%" rspace="0.278em" id="alg1.l7.m1.1.4.2">:</mo><mi mathsize="90%" id="alg1.l7.m1.1.4.3">L</mi><mo maxsize="90%" minsize="90%" id="alg1.l7.m1.1.4.4">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">\widehat{U}_{3}\leftarrow U_{3}[:L]</annotation></semantics></math><span id="alg1.l7.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.2.1.1" class="ltx_text" style="font-size:80%;">8:</span></span><span id="alg1.l8.3" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><span id="alg1.l8.4" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span><span id="alg1.l8.5" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l8.1" class="ltx_text" style="font-size:90%;"><math id="alg1.l8.1.m1.1" class="ltx_Math" alttext="u\in\widehat{U}_{1}" display="inline"><semantics id="alg1.l8.1.m1.1a"><mrow id="alg1.l8.1.m1.1.1" xref="alg1.l8.1.m1.1.1.cmml"><mi id="alg1.l8.1.m1.1.1.2" xref="alg1.l8.1.m1.1.1.2.cmml">u</mi><mo id="alg1.l8.1.m1.1.1.1" xref="alg1.l8.1.m1.1.1.1.cmml">âˆˆ</mo><msub id="alg1.l8.1.m1.1.1.3" xref="alg1.l8.1.m1.1.1.3.cmml"><mover accent="true" id="alg1.l8.1.m1.1.1.3.2" xref="alg1.l8.1.m1.1.1.3.2.cmml"><mi id="alg1.l8.1.m1.1.1.3.2.2" xref="alg1.l8.1.m1.1.1.3.2.2.cmml">U</mi><mo id="alg1.l8.1.m1.1.1.3.2.1" xref="alg1.l8.1.m1.1.1.3.2.1.cmml">^</mo></mover><mn id="alg1.l8.1.m1.1.1.3.3" xref="alg1.l8.1.m1.1.1.3.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.1.m1.1b"><apply id="alg1.l8.1.m1.1.1.cmml" xref="alg1.l8.1.m1.1.1"><in id="alg1.l8.1.m1.1.1.1.cmml" xref="alg1.l8.1.m1.1.1.1"></in><ci id="alg1.l8.1.m1.1.1.2.cmml" xref="alg1.l8.1.m1.1.1.2">ğ‘¢</ci><apply id="alg1.l8.1.m1.1.1.3.cmml" xref="alg1.l8.1.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l8.1.m1.1.1.3.1.cmml" xref="alg1.l8.1.m1.1.1.3">subscript</csymbol><apply id="alg1.l8.1.m1.1.1.3.2.cmml" xref="alg1.l8.1.m1.1.1.3.2"><ci id="alg1.l8.1.m1.1.1.3.2.1.cmml" xref="alg1.l8.1.m1.1.1.3.2.1">^</ci><ci id="alg1.l8.1.m1.1.1.3.2.2.cmml" xref="alg1.l8.1.m1.1.1.3.2.2">ğ‘ˆ</ci></apply><cn type="integer" id="alg1.l8.1.m1.1.1.3.3.cmml" xref="alg1.l8.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.1.m1.1c">u\in\widehat{U}_{1}</annotation></semantics></math></span><span id="alg1.l8.6" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l8.7" class="ltx_text ltx_font_bold" style="font-size:90%;">do</span><span id="alg1.l8.8" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span><span id="alg1.l9.2" class="ltx_text" style="font-size:90%;">Â Â Â Â Â Â Â Â Â </span><span id="alg1.l9.3" class="ltx_text ltx_font_bold" style="font-size:90%;">if</span><span id="alg1.l9.4" class="ltx_text" style="font-size:90%;">Â </span><math id="alg1.l9.m1.1" class="ltx_Math" alttext="u\notin R" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml">u</mi><mo mathsize="90%" id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml">âˆ‰</mo><mi mathsize="90%" id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml">R</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><notin id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1"></notin><ci id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2">ğ‘¢</ci><ci id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3">ğ‘…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">u\notin R</annotation></semantics></math><span id="alg1.l9.5" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l9.6" class="ltx_text ltx_font_bold" style="font-size:90%;">and</span><span id="alg1.l9.7" class="ltx_text" style="font-size:90%;"> </span><math id="alg1.l9.m2.1" class="ltx_Math" alttext="u\in\widehat{U}_{2}" display="inline"><semantics id="alg1.l9.m2.1a"><mrow id="alg1.l9.m2.1.1" xref="alg1.l9.m2.1.1.cmml"><mi mathsize="90%" id="alg1.l9.m2.1.1.2" xref="alg1.l9.m2.1.1.2.cmml">u</mi><mo mathsize="90%" id="alg1.l9.m2.1.1.1" xref="alg1.l9.m2.1.1.1.cmml">âˆˆ</mo><msub id="alg1.l9.m2.1.1.3" xref="alg1.l9.m2.1.1.3.cmml"><mover accent="true" id="alg1.l9.m2.1.1.3.2" xref="alg1.l9.m2.1.1.3.2.cmml"><mi mathsize="90%" id="alg1.l9.m2.1.1.3.2.2" xref="alg1.l9.m2.1.1.3.2.2.cmml">U</mi><mo mathsize="90%" id="alg1.l9.m2.1.1.3.2.1" xref="alg1.l9.m2.1.1.3.2.1.cmml">^</mo></mover><mn mathsize="90%" id="alg1.l9.m2.1.1.3.3" xref="alg1.l9.m2.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m2.1b"><apply id="alg1.l9.m2.1.1.cmml" xref="alg1.l9.m2.1.1"><in id="alg1.l9.m2.1.1.1.cmml" xref="alg1.l9.m2.1.1.1"></in><ci id="alg1.l9.m2.1.1.2.cmml" xref="alg1.l9.m2.1.1.2">ğ‘¢</ci><apply id="alg1.l9.m2.1.1.3.cmml" xref="alg1.l9.m2.1.1.3"><csymbol cd="ambiguous" id="alg1.l9.m2.1.1.3.1.cmml" xref="alg1.l9.m2.1.1.3">subscript</csymbol><apply id="alg1.l9.m2.1.1.3.2.cmml" xref="alg1.l9.m2.1.1.3.2"><ci id="alg1.l9.m2.1.1.3.2.1.cmml" xref="alg1.l9.m2.1.1.3.2.1">^</ci><ci id="alg1.l9.m2.1.1.3.2.2.cmml" xref="alg1.l9.m2.1.1.3.2.2">ğ‘ˆ</ci></apply><cn type="integer" id="alg1.l9.m2.1.1.3.3.cmml" xref="alg1.l9.m2.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m2.1c">u\in\widehat{U}_{2}</annotation></semantics></math><span id="alg1.l9.8" class="ltx_text" style="font-size:90%;"> </span><span id="alg1.l9.9" class="ltx_text ltx_font_bold" style="font-size:90%;">and</span><span id="alg1.l9.10" class="ltx_text" style="font-size:90%;"> </span><math id="alg1.l9.m3.1" class="ltx_Math" alttext="u\in\widehat{U}_{3}" display="inline"><semantics id="alg1.l9.m3.1a"><mrow id="alg1.l9.m3.1.1" xref="alg1.l9.m3.1.1.cmml"><mi mathsize="90%" id="alg1.l9.m3.1.1.2" xref="alg1.l9.m3.1.1.2.cmml">u</mi><mo mathsize="90%" id="alg1.l9.m3.1.1.1" xref="alg1.l9.m3.1.1.1.cmml">âˆˆ</mo><msub id="alg1.l9.m3.1.1.3" xref="alg1.l9.m3.1.1.3.cmml"><mover accent="true" id="alg1.l9.m3.1.1.3.2" xref="alg1.l9.m3.1.1.3.2.cmml"><mi mathsize="90%" id="alg1.l9.m3.1.1.3.2.2" xref="alg1.l9.m3.1.1.3.2.2.cmml">U</mi><mo mathsize="90%" id="alg1.l9.m3.1.1.3.2.1" xref="alg1.l9.m3.1.1.3.2.1.cmml">^</mo></mover><mn mathsize="90%" id="alg1.l9.m3.1.1.3.3" xref="alg1.l9.m3.1.1.3.3.cmml">3</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m3.1b"><apply id="alg1.l9.m3.1.1.cmml" xref="alg1.l9.m3.1.1"><in id="alg1.l9.m3.1.1.1.cmml" xref="alg1.l9.m3.1.1.1"></in><ci id="alg1.l9.m3.1.1.2.cmml" xref="alg1.l9.m3.1.1.2">ğ‘¢</ci><apply id="alg1.l9.m3.1.1.3.cmml" xref="alg1.l9.m3.1.1.3"><csymbol cd="ambiguous" id="alg1.l9.m3.1.1.3.1.cmml" xref="alg1.l9.m3.1.1.3">subscript</csymbol><apply id="alg1.l9.m3.1.1.3.2.cmml" xref="alg1.l9.m3.1.1.3.2"><ci id="alg1.l9.m3.1.1.3.2.1.cmml" xref="alg1.l9.m3.1.1.3.2.1">^</ci><ci id="alg1.l9.m3.1.1.3.2.2.cmml" xref="alg1.l9.m3.1.1.3.2.2">ğ‘ˆ</ci></apply><cn type="integer" id="alg1.l9.m3.1.1.3.3.cmml" xref="alg1.l9.m3.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m3.1c">u\in\widehat{U}_{3}</annotation></semantics></math><span id="alg1.l9.11" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l9.12" class="ltx_text ltx_font_bold" style="font-size:90%;">then</span><span id="alg1.l9.13" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span><span id="alg1.l10.2" class="ltx_text" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â </span><math id="alg1.l10.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="alg1.l10.m1.1a"><mi mathsize="90%" id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">R</annotation></semantics></math><span id="alg1.l10.3" class="ltx_text" style="font-size:90%;">.append(</span><math id="alg1.l10.m2.1" class="ltx_Math" alttext="u" display="inline"><semantics id="alg1.l10.m2.1a"><mi mathsize="90%" id="alg1.l10.m2.1.1" xref="alg1.l10.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.m2.1b"><ci id="alg1.l10.m2.1.1.cmml" xref="alg1.l10.m2.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m2.1c">u</annotation></semantics></math><span id="alg1.l10.4" class="ltx_text" style="font-size:90%;">)
</span>
</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span><span id="alg1.l11.2" class="ltx_text" style="font-size:90%;">Â Â Â Â Â Â Â Â Â </span><span id="alg1.l11.3" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l11.4" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l11.5" class="ltx_text ltx_font_bold" style="font-size:90%;">if</span>
</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span><span id="alg1.l12.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><span id="alg1.l12.3" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l12.4" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l12.5" class="ltx_text ltx_font_bold" style="font-size:90%;">for</span>
</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span><span id="alg1.l13.2" class="ltx_text" style="font-size:90%;">Â Â Â Â </span><math id="alg1.l13.m1.1" class="ltx_Math" alttext="L\leftarrow L+L_{0}" display="inline"><semantics id="alg1.l13.m1.1a"><mrow id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml"><mi mathsize="90%" id="alg1.l13.m1.1.1.2" xref="alg1.l13.m1.1.1.2.cmml">L</mi><mo mathsize="90%" stretchy="false" id="alg1.l13.m1.1.1.1" xref="alg1.l13.m1.1.1.1.cmml">â†</mo><mrow id="alg1.l13.m1.1.1.3" xref="alg1.l13.m1.1.1.3.cmml"><mi mathsize="90%" id="alg1.l13.m1.1.1.3.2" xref="alg1.l13.m1.1.1.3.2.cmml">L</mi><mo mathsize="90%" id="alg1.l13.m1.1.1.3.1" xref="alg1.l13.m1.1.1.3.1.cmml">+</mo><msub id="alg1.l13.m1.1.1.3.3" xref="alg1.l13.m1.1.1.3.3.cmml"><mi mathsize="90%" id="alg1.l13.m1.1.1.3.3.2" xref="alg1.l13.m1.1.1.3.3.2.cmml">L</mi><mn mathsize="90%" id="alg1.l13.m1.1.1.3.3.3" xref="alg1.l13.m1.1.1.3.3.3.cmml">0</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.1b"><apply id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1"><ci id="alg1.l13.m1.1.1.1.cmml" xref="alg1.l13.m1.1.1.1">â†</ci><ci id="alg1.l13.m1.1.1.2.cmml" xref="alg1.l13.m1.1.1.2">ğ¿</ci><apply id="alg1.l13.m1.1.1.3.cmml" xref="alg1.l13.m1.1.1.3"><plus id="alg1.l13.m1.1.1.3.1.cmml" xref="alg1.l13.m1.1.1.3.1"></plus><ci id="alg1.l13.m1.1.1.3.2.cmml" xref="alg1.l13.m1.1.1.3.2">ğ¿</ci><apply id="alg1.l13.m1.1.1.3.3.cmml" xref="alg1.l13.m1.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l13.m1.1.1.3.3.1.cmml" xref="alg1.l13.m1.1.1.3.3">subscript</csymbol><ci id="alg1.l13.m1.1.1.3.3.2.cmml" xref="alg1.l13.m1.1.1.3.3.2">ğ¿</ci><cn type="integer" id="alg1.l13.m1.1.1.3.3.3.cmml" xref="alg1.l13.m1.1.1.3.3.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.1c">L\leftarrow L+L_{0}</annotation></semantics></math><span id="alg1.l13.3" class="ltx_text" style="font-size:90%;">
</span>
</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.1.1.1" class="ltx_text" style="font-size:80%;">14:</span></span><span id="alg1.l14.2" class="ltx_text ltx_font_bold" style="font-size:90%;">end</span><span id="alg1.l14.3" class="ltx_text" style="font-size:90%;">Â </span><span id="alg1.l14.4" class="ltx_text ltx_font_bold" style="font-size:90%;">while</span>
</div>
</div>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Our experimental procedure unfolds as follows: In addition to leveraging the existing, limited volume of target language data, we employ the top-<math id="S4.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.p1.1.m1.1a"><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">k</annotation></semantics></math> hours of sampled data from the ML-SUPERB multilingual corpus. This selection is facilitated by a one-class classifier or <a href="#alg1" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>, intended for the continued pre-training of the SSL model (XLSR-128). The refined model is then utilized to generate SSL features, enabling fine-tuning the downstream ASR model using target language speech data accompanied by transcriptions. For our framework, Fairseq is used for pre-training, while both S3PRL and ESPnet are employed for downstream ASR tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">20</a>, <a href="#bib.bibx21" title="" class="ltx_ref">21</a>, <a href="#bib.bibx22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Continued Pre-training</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.4" class="ltx_p">Using one-class classifiers, we curated utterances from the ML-SUPERB benchmark, following the methodology outlined by Nowakowski et al. for continued pre-training of the <span id="S4.SS1.p1.4.1" class="ltx_text ltx_font_typewriter">XLSR-128</span> model. This process involved <math id="S4.SS1.p1.1.m1.2" class="ltx_Math" alttext="100,000" display="inline"><semantics id="S4.SS1.p1.1.m1.2a"><mrow id="S4.SS1.p1.1.m1.2.3.2" xref="S4.SS1.p1.1.m1.2.3.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">100</mn><mo id="S4.SS1.p1.1.m1.2.3.2.1" xref="S4.SS1.p1.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS1.p1.1.m1.2.2" xref="S4.SS1.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.2b"><list id="S4.SS1.p1.1.m1.2.3.1.cmml" xref="S4.SS1.p1.1.m1.2.3.2"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">100</cn><cn type="integer" id="S4.SS1.p1.1.m1.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.2c">100,000</annotation></semantics></math> updates, including <math id="S4.SS1.p1.2.m2.2" class="ltx_Math" alttext="10,000" display="inline"><semantics id="S4.SS1.p1.2.m2.2a"><mrow id="S4.SS1.p1.2.m2.2.3.2" xref="S4.SS1.p1.2.m2.2.3.1.cmml"><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">10</mn><mo id="S4.SS1.p1.2.m2.2.3.2.1" xref="S4.SS1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS1.p1.2.m2.2.2" xref="S4.SS1.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.2b"><list id="S4.SS1.p1.2.m2.2.3.1.cmml" xref="S4.SS1.p1.2.m2.2.3.2"><cn type="integer" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">10</cn><cn type="integer" id="S4.SS1.p1.2.m2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.2c">10,000</annotation></semantics></math> warmup steps, with a batch size of <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mn id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><cn type="integer" id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">256</annotation></semantics></math> and a learning rate set at <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><msup id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mn id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">10</mn><mrow id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml"><mo id="S4.SS1.p1.4.m4.1.1.3a" xref="S4.SS1.p1.4.m4.1.1.3.cmml">âˆ’</mo><mn id="S4.SS1.p1.4.m4.1.1.3.2" xref="S4.SS1.p1.4.m4.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">10</cn><apply id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3"><minus id="S4.SS1.p1.4.m4.1.1.3.1.cmml" xref="S4.SS1.p1.4.m4.1.1.3"></minus><cn type="integer" id="S4.SS1.p1.4.m4.1.1.3.2.cmml" xref="S4.SS1.p1.4.m4.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">10^{-4}</annotation></semantics></math>. All settings were aligned with those of the <span id="S4.SS1.p1.4.2" class="ltx_text ltx_font_typewriter">wav2vec 2.0 large</span> model. The optimal configuration was identified using validation data from the ML-SUPERB benchmark.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.7" class="ltx_p">For the downstream ASR task, we adopted ML-SUPERB's architectural framework. SSL representations were frozen, carefully weighted, and combined. Our ASR model featured a CNN layer to reduce the original sequence of SSL features by half, followed by two transformer encoders with an attention dimension of <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mn id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><cn type="integer" id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">256</annotation></semantics></math>, a feedforward scaling of <math id="S4.SS1.p2.2.m2.2" class="ltx_Math" alttext="1,024" display="inline"><semantics id="S4.SS1.p2.2.m2.2a"><mrow id="S4.SS1.p2.2.m2.2.3.2" xref="S4.SS1.p2.2.m2.2.3.1.cmml"><mn id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">1</mn><mo id="S4.SS1.p2.2.m2.2.3.2.1" xref="S4.SS1.p2.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS1.p2.2.m2.2.2" xref="S4.SS1.p2.2.m2.2.2.cmml">024</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.2b"><list id="S4.SS1.p2.2.m2.2.3.1.cmml" xref="S4.SS1.p2.2.m2.2.3.2"><cn type="integer" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">1</cn><cn type="integer" id="S4.SS1.p2.2.m2.2.2.cmml" xref="S4.SS1.p2.2.m2.2.2">024</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.2c">1,024</annotation></semantics></math>, and eight attention heads. Training employed the CTC technique and the Adam optimizer, with learning rates starting at <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><msup id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml"><mn id="S4.SS1.p2.3.m3.1.1.2" xref="S4.SS1.p2.3.m3.1.1.2.cmml">10</mn><mrow id="S4.SS1.p2.3.m3.1.1.3" xref="S4.SS1.p2.3.m3.1.1.3.cmml"><mo id="S4.SS1.p2.3.m3.1.1.3a" xref="S4.SS1.p2.3.m3.1.1.3.cmml">âˆ’</mo><mn id="S4.SS1.p2.3.m3.1.1.3.2" xref="S4.SS1.p2.3.m3.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><apply id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.1.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.p2.3.m3.1.1.2.cmml" xref="S4.SS1.p2.3.m3.1.1.2">10</cn><apply id="S4.SS1.p2.3.m3.1.1.3.cmml" xref="S4.SS1.p2.3.m3.1.1.3"><minus id="S4.SS1.p2.3.m3.1.1.3.1.cmml" xref="S4.SS1.p2.3.m3.1.1.3"></minus><cn type="integer" id="S4.SS1.p2.3.m3.1.1.3.2.cmml" xref="S4.SS1.p2.3.m3.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">10^{-4}</annotation></semantics></math> and a weight decay of <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="10^{-6}" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><msup id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mn id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">10</mn><mrow id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3.cmml"><mo id="S4.SS1.p2.4.m4.1.1.3a" xref="S4.SS1.p2.4.m4.1.1.3.cmml">âˆ’</mo><mn id="S4.SS1.p2.4.m4.1.1.3.2" xref="S4.SS1.p2.4.m4.1.1.3.2.cmml">6</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">superscript</csymbol><cn type="integer" id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">10</cn><apply id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3"><minus id="S4.SS1.p2.4.m4.1.1.3.1.cmml" xref="S4.SS1.p2.4.m4.1.1.3"></minus><cn type="integer" id="S4.SS1.p2.4.m4.1.1.3.2.cmml" xref="S4.SS1.p2.4.m4.1.1.3.2">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">10^{-6}</annotation></semantics></math>. Optimization strategies included a <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mn id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><cn type="float" id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">0.1</annotation></semantics></math> dropout rate, a batch size of <math id="S4.SS1.p2.6.m6.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.SS1.p2.6.m6.1a"><mn id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><cn type="integer" id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">8</annotation></semantics></math>, and a gradient accumulation strategy of <math id="S4.SS1.p2.7.m7.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S4.SS1.p2.7.m7.1a"><mn id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><cn type="integer" id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m7.1c">4</annotation></semantics></math>. Furthermore, SpecAugment was utilized to enhance SSL features further <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">23</a>]</cite>.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Positive and negative error rates (%) with respect to three kinds of one-class classifiers. The numbers of positive/negative utterances in Amis and Seediq are 111/429 and 107/429, respectively.</figcaption>
<div id="S4.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:218.0pt;height:57.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.3pt,7.2pt) scale(0.8,0.8) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3"><span id="S4.T1.1.1.1.1.2.1" class="ltx_text" style="font-size:90%;">Amis</span></th>
<th id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3"><span id="S4.T1.1.1.1.1.3.1" class="ltx_text" style="font-size:90%;">Seediq</span></th>
</tr>
<tr id="S4.T1.1.1.2.2" class="ltx_tr">
<th id="S4.T1.1.1.2.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.2.2.2.1" class="ltx_text" style="font-size:90%;">OcSVM</span></th>
<th id="S4.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.2.2.3.1" class="ltx_text" style="font-size:90%;">IF</span></th>
<th id="S4.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.2.2.4.1" class="ltx_text" style="font-size:90%;">D-SVDD</span></th>
<th id="S4.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.2.2.5.1" class="ltx_text" style="font-size:90%;">OcSVM</span></th>
<th id="S4.T1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.2.2.6.1" class="ltx_text" style="font-size:90%;">IF</span></th>
<th id="S4.T1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T1.1.1.2.2.7.1" class="ltx_text" style="font-size:90%;">D-SVDD</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.3.1" class="ltx_tr">
<th id="S4.T1.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S4.T1.1.1.3.1.1.1" class="ltx_text" style="font-size:90%;">Pos.</span></th>
<td id="S4.T1.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.1.1.3.1.2.1" class="ltx_text" style="font-size:90%;">18.0</span></td>
<td id="S4.T1.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.1.1.3.1.3.1" class="ltx_text" style="font-size:90%;">6.3</span></td>
<td id="S4.T1.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.1.1.3.1.4.1" class="ltx_text" style="font-size:90%;">16.2</span></td>
<td id="S4.T1.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.1.1.3.1.5.1" class="ltx_text" style="font-size:90%;">11.2</span></td>
<td id="S4.T1.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.1.1.3.1.6.1" class="ltx_text" style="font-size:90%;">1.8</span></td>
<td id="S4.T1.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.1.1.3.1.7.1" class="ltx_text" style="font-size:90%;">30.8</span></td>
</tr>
<tr id="S4.T1.1.1.4.2" class="ltx_tr">
<th id="S4.T1.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T1.1.1.4.2.1.1" class="ltx_text" style="font-size:90%;">Neg.</span></th>
<td id="S4.T1.1.1.4.2.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.1.4.2.2.1" class="ltx_text" style="font-size:90%;">1.8</span></td>
<td id="S4.T1.1.1.4.2.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.1.4.2.3.1" class="ltx_text" style="font-size:90%;">71.3</span></td>
<td id="S4.T1.1.1.4.2.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.1.4.2.4.1" class="ltx_text" style="font-size:90%;">12.8</span></td>
<td id="S4.T1.1.1.4.2.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.1.4.2.5.1" class="ltx_text" style="font-size:90%;">0.7</span></td>
<td id="S4.T1.1.1.4.2.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.1.4.2.6.1" class="ltx_text" style="font-size:90%;">48.7</span></td>
<td id="S4.T1.1.1.4.2.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.1.4.2.7.1" class="ltx_text" style="font-size:90%;">33.1</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">One-class Classification</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">Our process commenced using NVIDIA's pre-trained TitaNet-LID to derive language embeddings for each utterance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">15</a>]</cite>. This model attains a <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="7.0" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">7.0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="float" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">7.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">7.0</annotation></semantics></math>% error rate on the <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="103" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">103</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn type="integer" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">103</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">103</annotation></semantics></math> languages test set. The obtained embeddings are situated in a 512-dimensional space, originating from the penultimate layer.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.4" class="ltx_p">For the classifiers, we utilized scikit-learn to train the One-class SVM and Isolation Forest, largely sticking to the default parameters. In the case of Deep SVDD, we implemented a modification by substituting the original 2D convolution for a 1D variant. The autoencoder was pre-trained for <math id="S4.SS2.p2.1.m1.2" class="ltx_Math" alttext="2,500" display="inline"><semantics id="S4.SS2.p2.1.m1.2a"><mrow id="S4.SS2.p2.1.m1.2.3.2" xref="S4.SS2.p2.1.m1.2.3.1.cmml"><mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">2</mn><mo id="S4.SS2.p2.1.m1.2.3.2.1" xref="S4.SS2.p2.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS2.p2.1.m1.2.2" xref="S4.SS2.p2.1.m1.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.2b"><list id="S4.SS2.p2.1.m1.2.3.1.cmml" xref="S4.SS2.p2.1.m1.2.3.2"><cn type="integer" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">2</cn><cn type="integer" id="S4.SS2.p2.1.m1.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.2c">2,500</annotation></semantics></math> epochs with a learning rate of <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="10^{-2}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msup id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mn id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">10</mn><mrow id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml"><mo id="S4.SS2.p2.2.m2.1.1.3a" xref="S4.SS2.p2.2.m2.1.1.3.cmml">âˆ’</mo><mn id="S4.SS2.p2.2.m2.1.1.3.2" xref="S4.SS2.p2.2.m2.1.1.3.2.cmml">2</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">10</cn><apply id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3"><minus id="S4.SS2.p2.2.m2.1.1.3.1.cmml" xref="S4.SS2.p2.2.m2.1.1.3"></minus><cn type="integer" id="S4.SS2.p2.2.m2.1.1.3.2.cmml" xref="S4.SS2.p2.2.m2.1.1.3.2">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">10^{-2}</annotation></semantics></math>, and the encoder was further trained for <math id="S4.SS2.p2.3.m3.2" class="ltx_Math" alttext="1,000" display="inline"><semantics id="S4.SS2.p2.3.m3.2a"><mrow id="S4.SS2.p2.3.m3.2.3.2" xref="S4.SS2.p2.3.m3.2.3.1.cmml"><mn id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml">1</mn><mo id="S4.SS2.p2.3.m3.2.3.2.1" xref="S4.SS2.p2.3.m3.2.3.1.cmml">,</mo><mn id="S4.SS2.p2.3.m3.2.2" xref="S4.SS2.p2.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.2b"><list id="S4.SS2.p2.3.m3.2.3.1.cmml" xref="S4.SS2.p2.3.m3.2.3.2"><cn type="integer" id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">1</cn><cn type="integer" id="S4.SS2.p2.3.m3.2.2.cmml" xref="S4.SS2.p2.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.2c">1,000</annotation></semantics></math> epochs at a reduced learning rate of <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="10^{-3}" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><msup id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mn id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">10</mn><mrow id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml"><mo id="S4.SS2.p2.4.m4.1.1.3a" xref="S4.SS2.p2.4.m4.1.1.3.cmml">âˆ’</mo><mn id="S4.SS2.p2.4.m4.1.1.3.2" xref="S4.SS2.p2.4.m4.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2">10</cn><apply id="S4.SS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3"><minus id="S4.SS2.p2.4.m4.1.1.3.1.cmml" xref="S4.SS2.p2.4.m4.1.1.3"></minus><cn type="integer" id="S4.SS2.p2.4.m4.1.1.3.2.cmml" xref="S4.SS2.p2.4.m4.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">10^{-3}</annotation></semantics></math>. Negative samples were selected from the ML-SUPERB training data and combined with the original test utterances from Amis and Seediq as positive samples. Our experiments demonstrated the superior performance of Deep SVDD in this setup.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><a href="#S4.T1" title="In IV-A Continued Pre-training â€£ IV Experiments â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">I</span></a> shows positive and negative error rates with respect to three kinds of one-class classifiers. The positive utterances are composed of the Dev-10min and Test-10min datasets, and three utterances for each language are randomly singled out from the ML-SUPERB training data to form a total of <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="429" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mn id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">429</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><cn type="integer" id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">429</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">429</annotation></semantics></math> negative utterances. It also shows the average superiority of Deep SVDD.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Results</span>
</h2>

<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>CER (%) evaluated on Amis and Seediq using SSL models. <sup id="S5.T2.8.1" class="ltx_sup"><span id="S5.T2.8.1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup> indicates a smaller downstream ASR model. 10min and 1h mean the amount of training data used in downstream ASR models.</figcaption>
<div id="S5.T2.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:561.0pt;height:361pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S5.T2.6.4" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.6.4.5.1" class="ltx_tr">
<td id="S5.T2.6.4.5.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T2.6.4.5.1.1.1" class="ltx_text ltx_font_bold">SSL/Acoustic Features</span></td>
<td id="S5.T2.6.4.5.1.2" class="ltx_td ltx_align_center ltx_border_tt"># Params. (M)</td>
<td id="S5.T2.6.4.5.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.6.4.5.1.3.1" class="ltx_text ltx_font_bold"># Languages</span></td>
<td id="S5.T2.6.4.5.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.6.4.5.1.4.1" class="ltx_text ltx_font_bold">Amis-10min</span></td>
<td id="S5.T2.6.4.5.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.6.4.5.1.5.1" class="ltx_text ltx_font_bold">Amis-1h</span></td>
<td id="S5.T2.6.4.5.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.6.4.5.1.6.1" class="ltx_text ltx_font_bold">Seediq-10min</span></td>
<td id="S5.T2.6.4.5.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T2.6.4.5.1.7.1" class="ltx_text ltx_font_bold">Seediq-1h</span></td>
</tr>
<tr id="S5.T2.6.4.6.2" class="ltx_tr">
<td id="S5.T2.6.4.6.2.1" class="ltx_td ltx_align_left ltx_border_tt">Mel-filterbank</td>
<td id="S5.T2.6.4.6.2.2" class="ltx_td ltx_align_center ltx_border_tt">N/A</td>
<td id="S5.T2.6.4.6.2.3" class="ltx_td ltx_align_center ltx_border_tt">N/A</td>
<td id="S5.T2.6.4.6.2.4" class="ltx_td ltx_align_center ltx_border_tt">40.5</td>
<td id="S5.T2.6.4.6.2.5" class="ltx_td ltx_align_center ltx_border_tt">28.5</td>
<td id="S5.T2.6.4.6.2.6" class="ltx_td ltx_align_center ltx_border_tt">49.4</td>
<td id="S5.T2.6.4.6.2.7" class="ltx_td ltx_align_center ltx_border_tt">36.0</td>
</tr>
<tr id="S5.T2.6.4.7.3" class="ltx_tr">
<td id="S5.T2.6.4.7.3.1" class="ltx_td ltx_align_left ltx_border_t">wav2vec2-base <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">4</a>]</cite>
</td>
<td id="S5.T2.6.4.7.3.2" class="ltx_td ltx_align_center ltx_border_t">95</td>
<td id="S5.T2.6.4.7.3.3" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S5.T2.6.4.7.3.4" class="ltx_td ltx_align_center ltx_border_t">14.6</td>
<td id="S5.T2.6.4.7.3.5" class="ltx_td ltx_align_center ltx_border_t">9.8</td>
<td id="S5.T2.6.4.7.3.6" class="ltx_td ltx_align_center ltx_border_t">19.8</td>
<td id="S5.T2.6.4.7.3.7" class="ltx_td ltx_align_center ltx_border_t">11.9</td>
</tr>
<tr id="S5.T2.6.4.8.4" class="ltx_tr">
<td id="S5.T2.6.4.8.4.1" class="ltx_td ltx_align_left">wav2vec2-large <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">4</a>]</cite>
</td>
<td id="S5.T2.6.4.8.4.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.6.4.8.4.3" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.6.4.8.4.4" class="ltx_td ltx_align_center">13.4</td>
<td id="S5.T2.6.4.8.4.5" class="ltx_td ltx_align_center">9.5</td>
<td id="S5.T2.6.4.8.4.6" class="ltx_td ltx_align_center">18.5</td>
<td id="S5.T2.6.4.8.4.7" class="ltx_td ltx_align_center">11.4</td>
</tr>
<tr id="S5.T2.6.4.9.5" class="ltx_tr">
<td id="S5.T2.6.4.9.5.1" class="ltx_td ltx_align_left">robust-wav2vec2-large <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">24</a>]</cite>
</td>
<td id="S5.T2.6.4.9.5.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.6.4.9.5.3" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.6.4.9.5.4" class="ltx_td ltx_align_center">13.5</td>
<td id="S5.T2.6.4.9.5.5" class="ltx_td ltx_align_center">9.3</td>
<td id="S5.T2.6.4.9.5.6" class="ltx_td ltx_align_center">18.6</td>
<td id="S5.T2.6.4.9.5.7" class="ltx_td ltx_align_center">11.5</td>
</tr>
<tr id="S5.T2.6.4.10.6" class="ltx_tr">
<td id="S5.T2.6.4.10.6.1" class="ltx_td ltx_align_left ltx_border_t">wav2vec2-base-cmn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S5.T2.6.4.10.6.2" class="ltx_td ltx_align_center ltx_border_t">95</td>
<td id="S5.T2.6.4.10.6.3" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S5.T2.6.4.10.6.4" class="ltx_td ltx_align_center ltx_border_t">14.4</td>
<td id="S5.T2.6.4.10.6.5" class="ltx_td ltx_align_center ltx_border_t">9.4</td>
<td id="S5.T2.6.4.10.6.6" class="ltx_td ltx_align_center ltx_border_t">18.7</td>
<td id="S5.T2.6.4.10.6.7" class="ltx_td ltx_align_center ltx_border_t">11.2</td>
</tr>
<tr id="S5.T2.6.4.11.7" class="ltx_tr">
<td id="S5.T2.6.4.11.7.1" class="ltx_td ltx_align_left">wav2vec2-large-cmn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S5.T2.6.4.11.7.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.6.4.11.7.3" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.6.4.11.7.4" class="ltx_td ltx_align_center">89.4</td>
<td id="S5.T2.6.4.11.7.5" class="ltx_td ltx_align_center">10.0</td>
<td id="S5.T2.6.4.11.7.6" class="ltx_td ltx_align_center">22.2</td>
<td id="S5.T2.6.4.11.7.7" class="ltx_td ltx_align_center">12.5</td>
</tr>
<tr id="S5.T2.3.1.1" class="ltx_tr">
<td id="S5.T2.3.1.1.1" class="ltx_td ltx_align_left">wav2vec2-large-cmn<sup id="S5.T2.3.1.1.1.1" class="ltx_sup"><span id="S5.T2.3.1.1.1.1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S5.T2.3.1.1.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.3.1.1.3" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.3.1.1.4" class="ltx_td ltx_align_center">15.3</td>
<td id="S5.T2.3.1.1.5" class="ltx_td ltx_align_center">10.0</td>
<td id="S5.T2.3.1.1.6" class="ltx_td ltx_align_center">21.6</td>
<td id="S5.T2.3.1.1.7" class="ltx_td ltx_align_center">12.3</td>
</tr>
<tr id="S5.T2.6.4.12.8" class="ltx_tr">
<td id="S5.T2.6.4.12.8.1" class="ltx_td ltx_align_left ltx_border_t">wav2vec2-base-23 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S5.T2.6.4.12.8.2" class="ltx_td ltx_align_center ltx_border_t">95</td>
<td id="S5.T2.6.4.12.8.3" class="ltx_td ltx_align_center ltx_border_t">23</td>
<td id="S5.T2.6.4.12.8.4" class="ltx_td ltx_align_center ltx_border_t">14.5</td>
<td id="S5.T2.6.4.12.8.5" class="ltx_td ltx_align_center ltx_border_t">9.2</td>
<td id="S5.T2.6.4.12.8.6" class="ltx_td ltx_align_center ltx_border_t">19.6</td>
<td id="S5.T2.6.4.12.8.7" class="ltx_td ltx_align_center ltx_border_t">12.1</td>
</tr>
<tr id="S5.T2.6.4.13.9" class="ltx_tr">
<td id="S5.T2.6.4.13.9.1" class="ltx_td ltx_align_left">wav2vec2-large-23 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S5.T2.6.4.13.9.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.6.4.13.9.3" class="ltx_td ltx_align_center">23</td>
<td id="S5.T2.6.4.13.9.4" class="ltx_td ltx_align_center">103.4</td>
<td id="S5.T2.6.4.13.9.5" class="ltx_td ltx_align_center">9.6</td>
<td id="S5.T2.6.4.13.9.6" class="ltx_td ltx_align_center">19.2</td>
<td id="S5.T2.6.4.13.9.7" class="ltx_td ltx_align_center">11.3</td>
</tr>
<tr id="S5.T2.4.2.2" class="ltx_tr">
<td id="S5.T2.4.2.2.1" class="ltx_td ltx_align_left">wav2vec2-large-23<sup id="S5.T2.4.2.2.1.1" class="ltx_sup"><span id="S5.T2.4.2.2.1.1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S5.T2.4.2.2.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.4.2.2.3" class="ltx_td ltx_align_center">23</td>
<td id="S5.T2.4.2.2.4" class="ltx_td ltx_align_center">13.5</td>
<td id="S5.T2.4.2.2.5" class="ltx_td ltx_align_center">9.2</td>
<td id="S5.T2.4.2.2.6" class="ltx_td ltx_align_center">18.4</td>
<td id="S5.T2.4.2.2.7" class="ltx_td ltx_align_center">11.4</td>
</tr>
<tr id="S5.T2.6.4.14.10" class="ltx_tr">
<td id="S5.T2.6.4.14.10.1" class="ltx_td ltx_align_left ltx_border_t">XLSR-53 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S5.T2.6.4.14.10.2" class="ltx_td ltx_align_center ltx_border_t">317</td>
<td id="S5.T2.6.4.14.10.3" class="ltx_td ltx_align_center ltx_border_t">53</td>
<td id="S5.T2.6.4.14.10.4" class="ltx_td ltx_align_center ltx_border_t">81.4</td>
<td id="S5.T2.6.4.14.10.5" class="ltx_td ltx_align_center ltx_border_t">10.4</td>
<td id="S5.T2.6.4.14.10.6" class="ltx_td ltx_align_center ltx_border_t">18.6</td>
<td id="S5.T2.6.4.14.10.7" class="ltx_td ltx_align_center ltx_border_t">14.0</td>
</tr>
<tr id="S5.T2.6.4.15.11" class="ltx_tr">
<td id="S5.T2.6.4.15.11.1" class="ltx_td ltx_align_left">XLSR-128 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S5.T2.6.4.15.11.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.6.4.15.11.3" class="ltx_td ltx_align_center">128</td>
<td id="S5.T2.6.4.15.11.4" class="ltx_td ltx_align_center">90.8</td>
<td id="S5.T2.6.4.15.11.5" class="ltx_td ltx_align_center">7.7</td>
<td id="S5.T2.6.4.15.11.6" class="ltx_td ltx_align_center">14.0</td>
<td id="S5.T2.6.4.15.11.7" class="ltx_td ltx_align_center">8.4</td>
</tr>
<tr id="S5.T2.5.3.3" class="ltx_tr">
<td id="S5.T2.5.3.3.1" class="ltx_td ltx_align_left">XLSR-128<sup id="S5.T2.5.3.3.1.1" class="ltx_sup"><span id="S5.T2.5.3.3.1.1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S5.T2.5.3.3.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.5.3.3.3" class="ltx_td ltx_align_center">128</td>
<td id="S5.T2.5.3.3.4" class="ltx_td ltx_align_center">10.9</td>
<td id="S5.T2.5.3.3.5" class="ltx_td ltx_align_center">7.9</td>
<td id="S5.T2.5.3.3.6" class="ltx_td ltx_align_center">13.7</td>
<td id="S5.T2.5.3.3.7" class="ltx_td ltx_align_center">8.6</td>
</tr>
<tr id="S5.T2.6.4.16.12" class="ltx_tr">
<td id="S5.T2.6.4.16.12.1" class="ltx_td ltx_align_left ltx_border_t">HuBERT-base <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">5</a>]</cite>
</td>
<td id="S5.T2.6.4.16.12.2" class="ltx_td ltx_align_center ltx_border_t">95</td>
<td id="S5.T2.6.4.16.12.3" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S5.T2.6.4.16.12.4" class="ltx_td ltx_align_center ltx_border_t">12.6</td>
<td id="S5.T2.6.4.16.12.5" class="ltx_td ltx_align_center ltx_border_t">8.8</td>
<td id="S5.T2.6.4.16.12.6" class="ltx_td ltx_align_center ltx_border_t">18.2</td>
<td id="S5.T2.6.4.16.12.7" class="ltx_td ltx_align_center ltx_border_t">11.0</td>
</tr>
<tr id="S5.T2.6.4.17.13" class="ltx_tr">
<td id="S5.T2.6.4.17.13.1" class="ltx_td ltx_align_left">HuBERT-large <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">5</a>]</cite>
</td>
<td id="S5.T2.6.4.17.13.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.6.4.17.13.3" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.6.4.17.13.4" class="ltx_td ltx_align_center">80.6</td>
<td id="S5.T2.6.4.17.13.5" class="ltx_td ltx_align_center">7.4</td>
<td id="S5.T2.6.4.17.13.6" class="ltx_td ltx_align_center">84.1</td>
<td id="S5.T2.6.4.17.13.7" class="ltx_td ltx_align_center">8.9</td>
</tr>
<tr id="S5.T2.6.4.4" class="ltx_tr">
<td id="S5.T2.6.4.4.1" class="ltx_td ltx_align_left">HuBERT-large<sup id="S5.T2.6.4.4.1.1" class="ltx_sup"><span id="S5.T2.6.4.4.1.1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">5</a>]</cite>
</td>
<td id="S5.T2.6.4.4.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.6.4.4.3" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.6.4.4.4" class="ltx_td ltx_align_center">10.3</td>
<td id="S5.T2.6.4.4.5" class="ltx_td ltx_align_center">7.5</td>
<td id="S5.T2.6.4.4.6" class="ltx_td ltx_align_center">14.0</td>
<td id="S5.T2.6.4.4.7" class="ltx_td ltx_align_center">9.1</td>
</tr>
<tr id="S5.T2.6.4.18.14" class="ltx_tr">
<td id="S5.T2.6.4.18.14.1" class="ltx_td ltx_align_left ltx_border_t">HuBERT-base-cmn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S5.T2.6.4.18.14.2" class="ltx_td ltx_align_center ltx_border_t">317</td>
<td id="S5.T2.6.4.18.14.3" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S5.T2.6.4.18.14.4" class="ltx_td ltx_align_center ltx_border_t">13.2</td>
<td id="S5.T2.6.4.18.14.5" class="ltx_td ltx_align_center ltx_border_t">9.0</td>
<td id="S5.T2.6.4.18.14.6" class="ltx_td ltx_align_center ltx_border_t">18.4</td>
<td id="S5.T2.6.4.18.14.7" class="ltx_td ltx_align_center ltx_border_t">10.9</td>
</tr>
<tr id="S5.T2.6.4.19.15" class="ltx_tr">
<td id="S5.T2.6.4.19.15.1" class="ltx_td ltx_align_left">HuBERT-large-cmn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S5.T2.6.4.19.15.2" class="ltx_td ltx_align_center">317</td>
<td id="S5.T2.6.4.19.15.3" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.6.4.19.15.4" class="ltx_td ltx_align_center">11.0</td>
<td id="S5.T2.6.4.19.15.5" class="ltx_td ltx_align_center">7.3</td>
<td id="S5.T2.6.4.19.15.6" class="ltx_td ltx_align_center">14.7</td>
<td id="S5.T2.6.4.19.15.7" class="ltx_td ltx_align_center">8.1</td>
</tr>
<tr id="S5.T2.6.4.20.16" class="ltx_tr">
<td id="S5.T2.6.4.20.16.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">mHuBERT-base <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx27" title="" class="ltx_ref">27</a>]</cite>
</td>
<td id="S5.T2.6.4.20.16.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">95</td>
<td id="S5.T2.6.4.20.16.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">3</td>
<td id="S5.T2.6.4.20.16.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">12.9</td>
<td id="S5.T2.6.4.20.16.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">8.9</td>
<td id="S5.T2.6.4.20.16.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">17.3</td>
<td id="S5.T2.6.4.20.16.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">11.5</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">To evaluate the effectiveness of our proposed data augmentation strategy, we conducted experiments with various SSL models on both Amis and Seediq ASR tasks (<a href="#S5.T2" title="In V Results â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">II</span></a>). Interestingly, <span id="S5.p1.1.1" class="ltx_text ltx_font_typewriter">HuBERT-large-cmn</span> consistently outperformed other models across different training data volumes, except for the Seediq 10-minute task. This superior performance was observed despite using identical training data for <span id="S5.p1.1.2" class="ltx_text ltx_font_typewriter">wav2vec2</span>, suggesting potential advantages of the <span id="S5.p1.1.3" class="ltx_text ltx_font_typewriter">HuBERT</span> architecture for these low-resource scenarios. Furthermore, <span id="S5.p1.1.4" class="ltx_text ltx_font_typewriter">XLSR-128</span> demonstrated comparable effectiveness, achieving the lowest character error rate (CER) of 13.7% on the Seediq 10-minute task. These results highlight several noteworthy trends:</p>
</div>
<div id="S5.p2" class="ltx_para">
<ol id="S5.I1" class="ltx_enumerate">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">HuBERT generally outperform <span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">wav2vec2</span> when trained on the same data.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">Utilizing larger SSL models leads to marginal, yet consistent, performance gains, particularly in the 1-hour training scenario.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">Multilingual pre-training contributes positively to ASR performance in low-resource settings.</p>
</div>
</li>
</ol>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.4" class="ltx_p">As observed in <a href="#S5.T2" title="In V Results â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">II</span></a>, large SSL models, while generally outperforming their smaller counterparts, exhibit a tendency to overfit when trained on limited data. This overfitting was particularly evident for models like <span id="S5.p3.4.1" class="ltx_text ltx_font_typewriter">wav2vec2-large-23</span>, <span id="S5.p3.4.2" class="ltx_text ltx_font_typewriter">wav2vec2-large-cmn</span>, <span id="S5.p3.4.3" class="ltx_text ltx_font_typewriter">XLSR-53</span>, <span id="S5.p3.4.4" class="ltx_text ltx_font_typewriter">XLSR-128</span>, and <span id="S5.p3.4.5" class="ltx_text ltx_font_typewriter">HuBERT-large</span>. To mitigate this issue, we modified the downstream ASR model architecture by halving the number of attention heads to <math id="S5.p3.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.p3.1.m1.1a"><mn id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><cn type="integer" id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">4</annotation></semantics></math>, reducing the feedforward dimension to <math id="S5.p3.2.m2.1" class="ltx_Math" alttext="512" display="inline"><semantics id="S5.p3.2.m2.1a"><mn id="S5.p3.2.m2.1.1" xref="S5.p3.2.m2.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="S5.p3.2.m2.1b"><cn type="integer" id="S5.p3.2.m2.1.1.cmml" xref="S5.p3.2.m2.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.2.m2.1c">512</annotation></semantics></math>, and increasing the dropout rate to <math id="S5.p3.3.m3.1" class="ltx_Math" alttext="0.3" display="inline"><semantics id="S5.p3.3.m3.1a"><mn id="S5.p3.3.m3.1.1" xref="S5.p3.3.m3.1.1.cmml">0.3</mn><annotation-xml encoding="MathML-Content" id="S5.p3.3.m3.1b"><cn type="float" id="S5.p3.3.m3.1.1.cmml" xref="S5.p3.3.m3.1.1">0.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.3.m3.1c">0.3</annotation></semantics></math>. These adjustments, as demonstrated in <a href="#S5.T2" title="In V Results â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>Â <span class="ltx_text ltx_ref_tag">II</span></a> (models denoted by <sup id="S5.p3.4.6" class="ltx_sup"><span id="S5.p3.4.6.1" class="ltx_text ltx_font_italic">âˆ—</span></sup>), enabled the smaller ASR model to achieve comparable performance even when paired with larger SSL models, effectively addressing the overfitting problem.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">While <span id="S5.p4.1.1" class="ltx_text ltx_font_typewriter">XLSR-128</span> did not consistently achieve the highest performance across all experimental settings, we selected it as our primary benchmark model. This decision stems from the fact that <span id="S5.p4.1.2" class="ltx_text ltx_font_typewriter">XLSR-128</span> is a multilingual model not specifically pre-trained on languages closely related to Amis and Seediq, making it a more generalizable choice for broader low-resource language research where such closely related pre-trained models might not be readily available.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.2" class="ltx_p"><a href="#S3.F2" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> illustrates the impact of data volume and selection strategy on the performance of <span id="S5.p5.2.1" class="ltx_text ltx_font_typewriter">XLSR-128</span> after continued pre-training for both Amis and Seediq. We evaluated three data selection approaches: random sampling, Deep SVDD, and our proposed ensemble algorithm (<a href="#alg1" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>). As expected, increasing the amount of pre-training data generally leads to improved ASR performance, mitigating the risk of overfitting. Notably, using only <math id="S5.p5.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.p5.1.m1.1a"><mn id="S5.p5.1.m1.1.1" xref="S5.p5.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.p5.1.m1.1b"><cn type="integer" id="S5.p5.1.m1.1.1.cmml" xref="S5.p5.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.1.m1.1c">1</annotation></semantics></math> hour of data from ML-SUPERB resulted in suboptimal performance across all selection methods, underscoring the importance of sufficient training data volume. Expanding the pre-training data to <math id="S5.p5.2.m2.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S5.p5.2.m2.1a"><mn id="S5.p5.2.m2.1.1" xref="S5.p5.2.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S5.p5.2.m2.1b"><cn type="integer" id="S5.p5.2.m2.1.1.cmml" xref="S5.p5.2.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.2.m2.1c">64</annotation></semantics></math> hours significantly reduced CER for both languages, highlighting the consistent benefit of larger datasets across languages</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.4" class="ltx_p">Our proposed methods (SVDD and <a href="#alg1" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>) consistently outperform the random selection baseline across nearly all experiments. The only exception is noted in the Seediq 1-hour experiments, where our methods demonstrate their effectiveness after selecting <math id="S5.p6.1.m1.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S5.p6.1.m1.1a"><mn id="S5.p6.1.m1.1.1" xref="S5.p6.1.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S5.p6.1.m1.1b"><cn type="integer" id="S5.p6.1.m1.1.1.cmml" xref="S5.p6.1.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.1.m1.1c">128</annotation></semantics></math> hours of non-target language data. Specifically, in both the Seediq 10-minute and 1-hour scenarios with <math id="S5.p6.2.m2.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S5.p6.2.m2.1a"><mn id="S5.p6.2.m2.1.1" xref="S5.p6.2.m2.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S5.p6.2.m2.1b"><cn type="integer" id="S5.p6.2.m2.1.1.cmml" xref="S5.p6.2.m2.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.2.m2.1c">128</annotation></semantics></math> hours of data selection, <a href="#alg1" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> consistently yields superior results compared to both random selection and SVDD. In the contrast, SVDD performs the best in Amis 10-minute and 1-hour scenarios with <math id="S5.p6.3.m3.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S5.p6.3.m3.1a"><mn id="S5.p6.3.m3.1.1" xref="S5.p6.3.m3.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S5.p6.3.m3.1b"><cn type="integer" id="S5.p6.3.m3.1.1.cmml" xref="S5.p6.3.m3.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.3.m3.1c">128</annotation></semantics></math> hours of data selection. However, increasing the data size to <math id="S5.p6.4.m4.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S5.p6.4.m4.1a"><mn id="S5.p6.4.m4.1.1" xref="S5.p6.4.m4.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S5.p6.4.m4.1b"><cn type="integer" id="S5.p6.4.m4.1.1.cmml" xref="S5.p6.4.m4.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.4.m4.1c">128</annotation></semantics></math> hours yielded only marginal improvements, suggesting that the model might be approaching saturation given the limited representation of the target languages within the available multilingual speech data.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p">Our findings for Amis reveal that when pre-training data is limited (e.g., <math id="S5.p7.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S5.p7.1.m1.1a"><mn id="S5.p7.1.m1.1.1" xref="S5.p7.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S5.p7.1.m1.1b"><cn type="integer" id="S5.p7.1.m1.1.1.cmml" xref="S5.p7.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.1.m1.1c">16</annotation></semantics></math> hours), utilizing <a href="#alg1" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Algorithm</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>) for data selection significantly outperforms both random sampling and Deep SVDD, particularly in the 10-minute and 1-hour training scenarios. Moreover, <a href="#S3.F2" title="In III Method â€£ Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a> demonstrates that the SSL model pre-trained with data selected using our algorithm exhibits greater robustness across almost all experimental conditions than models trained with randomly selected or Deep SVDD-sampled data.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This study introduces speech corpora for two low-resource Austronesian languages, Amis and Seediq, and presents a data augmentation strategy for enhancing low-resource ASR. We propose leveraging a novel ensemble algorithm to select acoustically similar utterances from a multilingual corpus for continued pre-training of the <span id="S6.p1.1.1" class="ltx_text ltx_font_typewriter">XLSR-128</span> model. Our results demonstrate that while the performance improvements are currently modest, the positive correlation between pre-training data volume and ASR accuracy highlights the potential of this approach.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu and Ruoming Pang
</span>
<span class="ltx_bibblock">``Conformer: Convolution-augmented transformer for speech recognition''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx1.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2020
</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">Kwangyoun Kim, Felix Wu, Yifan Peng, Jing Pan, Prashant Sridhar, Kyu J. Han and Shinji Watanabe
</span>
<span class="ltx_bibblock">``E-Branchformer: Branchformer with Enhanced merging for speech recognition''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx2.1.1" class="ltx_emph ltx_font_italic">Proc. SLT</em>, 2022
</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">Steffen Schneider, Alexei Baevski, Ronan Collobert and Michael Auli
</span>
<span class="ltx_bibblock">``Wav2vec: Unsupervised pre-training for speech recognition''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx3.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2019
</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">Alexei Baevski, Henry Zhou, Abdelrahman Mohamed and Michael Auli
</span>
<span class="ltx_bibblock">``Wav2vec 2.0: A framework for self-supervised learning of speech representations''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx4.1.1" class="ltx_emph ltx_font_italic">Proc. NeurIPS</em>, 2020
</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov and Abdelrahman Mohamed
</span>
<span class="ltx_bibblock">``HuBERT: self-supervised speech representation learning by masked prediction of hidden units''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx5.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Trans. Audio Speech Lang. Process.</em> <span id="bib.bibx5.2.2" class="ltx_text ltx_font_bold">29</span>, 2021, pp. 3451â€“3460
</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">Patrick Littell, David R. Mortensen, Ke Lin, Katherine Kairis, Carlisle Turner and Lori Levin
</span>
<span class="ltx_bibblock">``URIEL and lang2vec: Representing languages as typological, geographical, and phylogenetic vectors''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx6.1.1" class="ltx_emph ltx_font_italic">Proc. EACL</em>, 2017
</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">Martijn Bartelds, Dan Jurafsky and Martijn Wieling
</span>
<span class="ltx_bibblock">``Making More of Little Data: Improving Low-Resource Automatic Speech Recognition Using Data Augmentation''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx7.1.1" class="ltx_emph ltx_font_italic">Proc. ACL</em>, 2023
</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">Johan Safri, Wawan Sahrozi, Ben Foley, Bradley McDonnell and Dan Jurafsky
</span>
<span class="ltx_bibblock">``Leveraging supplementary text data to kick-start automatic speech recognition system development with limited transcriptions''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx8.1.1" class="ltx_emph ltx_font_italic">Proc. the Sixth Workshop on the Use of Computational Methods in the Study of Endangered Languages</em>, 2023
</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed and Michael Auli
</span>
<span class="ltx_bibblock">``Unsupervised cross-lingual representation learning for speech recognition''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx9.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2021
</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">Changhan Wang, Morgane Riviere, Ann Lee, Anne Wu, Chaitanya Talnikar, Daniel Haziza, Mary Williamson, Juan Pino and Emmanuel Dupoux
</span>
<span class="ltx_bibblock">``VoxPopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx10.1.1" class="ltx_emph ltx_font_italic">Proc. ACL</em>, 2021
</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau and Michael Auli
</span>
<span class="ltx_bibblock">``XLS-R: Self-supervised cross-lingual speech representation learning at scale''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx11.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2022
</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">Karol Nowakowski, Michal Ptaszynski, Kyoko Murasaki and Jagna NieuwaÅ¼ny
</span>
<span class="ltx_bibblock">``Adapting multilingual speech representation model for a enw, underresourced language through multilingual fine-tuning and continued pretraining''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx12.1.1" class="ltx_emph ltx_font_italic">Inf. Process. Manag.</em> <span id="bib.bibx12.2.2" class="ltx_text ltx_font_bold">60.2</span>, 2023, pp. 103148
</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">Nay San, Georgios Paraskevopoulos, Aryaman Arora, Xiluo He, Prabhjot Kaur, Oliver Adams and Dan Jurafsky
</span>
<span class="ltx_bibblock">``Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx13.1.1" class="ltx_emph ltx_font_italic">Proc. SIGTYP</em>, 2024
</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">Fei Jia, Nithin Rao Koluguri, Jagadeesh Balam and Boris Ginsburg
</span>
<span class="ltx_bibblock">``AmberNet: A compact end-to-end model for spoken language identification''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx14.1.1" class="ltx_emph ltx_font_italic">Arxiv preprint arXiv:2210.15781</em>, 2022
</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">Fei Jia, Nithin Rao Koluguri, Jagadeesh Balam and Boris Ginsburg
</span>
<span class="ltx_bibblock">``A compact end-to-end model with local and global context for spoken language identification''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx15.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2023
</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">Bernhard SchÃ¶lkopf, John C. Platt, John Shawe-Taylor, Alex J. Smola and Robert C. Williamson
</span>
<span class="ltx_bibblock">``Estimating the support of a high-dimensional distribution''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx16.1.1" class="ltx_emph ltx_font_italic">Neural. Comput.</em> <span id="bib.bibx16.2.2" class="ltx_text ltx_font_bold">13.7</span>, 2001, pp. 1443â€“1471
</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">Fei Tony Liu, Kai Ming Ting and Zhi-Hua Zhou
</span>
<span class="ltx_bibblock">``Isolation forest''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx17.1.1" class="ltx_emph ltx_font_italic">Proc. ICDM</em>, 2008
</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Alexander Binder, Emmanuel MÃ¼ller and Marius Kloft
</span>
<span class="ltx_bibblock">``Deep one-class classification''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx18.1.1" class="ltx_emph ltx_font_italic">Proc. ICML</em>, 2018
</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">Fei Tony Liu, Kai Ming Ting and Zhi-Hua Zhou
</span>
<span class="ltx_bibblock">``Isolation-based anomaly detection''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx19.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Knowl. Discov. Data</em> <span id="bib.bibx19.2.2" class="ltx_text ltx_font_bold">6.1</span>, 2012, pp. 1â€“39
</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier and Michael Auli
</span>
<span class="ltx_bibblock">``fairseq: A fast, extensible toolkit for sequence modeling''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx20.1.1" class="ltx_emph ltx_font_italic">Proc. NAACL</em>, 2019
</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">Shinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro Nishitoba, Yuya Unno, Nelson Enrique Yalta Soplin, Jahn Heymann, Matthew Wiesner, Nanxin Chen, Adithya Renduchintala and Tsubasa Ochiai
</span>
<span class="ltx_bibblock">``ESPnet: End-to-end speech processing toolkit''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx21.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2018
</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">Shu-wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I. Lai, Kushal Lakhotia, Yist Y. Lin, Andy T. Liu, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, Tzu-Hsien Huang, Wei-Cheng Tseng, Ko-tik Lee, Da-Rong Liu, Zili Huang, Shuyan Dong, Shang-Wen Li, Shinji Watanabe, Abdelrahman Mohamed and Hung-yi Lee
</span>
<span class="ltx_bibblock">``SUPERB: Speech processing universal performance benchmark''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx22.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2021
</span>
</li>
<li id="bib.bibx23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D. Cubuk and Quoc V. Le
</span>
<span class="ltx_bibblock">``SpecAugment: A simple data augmentation method for automatic speech recognition''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx23.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2019
</span>
</li>
<li id="bib.bibx24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">Wei-Ning Hsu, Anuroop Sriram, Alexei Baevski, Tatiana Likhomanenko, Qiantong Xu, Vineel Pratap, Jacob Kahn, Ann Lee, Ronan Collobert, Gabriel Synnaeve and Michael Auli
</span>
<span class="ltx_bibblock">``Robust wav2vec 2.0: Analyzing domain shift in self-supervised pre-training''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx24.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2021
</span>
</li>
<li id="bib.bibx25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">Binbin Zhang, Hang Lv, Pengcheng Guo, Qijie Shao, Chao Yang, Lei Xie, Xin Xu, Hui Bu, Xiaoyu Chen, Chenchen Zeng, Di Wu and Zhendong Peng
</span>
<span class="ltx_bibblock">``WenetSpeech: A 10000+ hours multi-domain mandarin corpus for speech recognition''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx25.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP</em>, 2022
</span>
</li>
<li id="bib.bibx26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco GuzmÃ¡n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov
</span>
<span class="ltx_bibblock">``Unsupervised cross-lingual depresentation learning at scale''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx26.1.1" class="ltx_emph ltx_font_italic">Proc. ACL</em>, 2020
</span>
</li>
<li id="bib.bibx27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">Ann Lee, Hongyu Gong, Paul-Ambroise Duquenne, Holger Schwenk, Peng-Jen Chen, Changhan Wang, Sravya Popuri, Yossi Adi, Juan Pino, Jiatao Gu and Wei-Ning Hsu
</span>
<span class="ltx_bibblock">``Textless speech-to-speech translation on real data''
</span>
<span class="ltx_bibblock">In <em id="bib.bibx27.1.1" class="ltx_emph ltx_font_italic">Proc. NAACL</em>, 2022
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.08871" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.08872" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.08872">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.08872" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.08873" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 01:28:35 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
