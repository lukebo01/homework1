<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.03235] Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language</title><meta property="og:description" content="One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. Recent advances in spâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.03235">

<!--Generated on Fri Jul  5 18:08:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Janick Michot<sup id="id1.1.id1" class="ltx_sup">1</sup>, Manuela HÃ¼rlimann<sup id="id2.2.id2" class="ltx_sup">1</sup>, Jan Deriu<sup id="id3.3.id3" class="ltx_sup">1</sup>, Luzia Sauer<sup id="id4.4.id4" class="ltx_sup">2</sup>. 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_bold">Katsiaryna Mlynchyk <sup id="id5.5.id5.1" class="ltx_sup">1</sup>, Mark Cieliebak<sup id="id5.5.id5.2" class="ltx_sup">1</sup></span> 
<br class="ltx_break"><sup id="id6.6.id6" class="ltx_sup">1</sup> Zurich University of Applied Sciences, Winterthur 
<br class="ltx_break"><sup id="id7.7.id7" class="ltx_sup">2</sup> PÃ¤dagogische Hochschule Zurich, Zurich
<br class="ltx_break">mict@zhaw.ch, hueu@zhaw.ch, deri@zhaw.ch, luzia.sauer@phzh.ch, 
<br class="ltx_break">mlyn@zhaw.ch, ciel@zhaw.ch
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. Recent advances in speech technology and natural language processing allow for the creation of novel tools to practice their speaking skills. In this work, we tackle the first component of such a pipeline, namely, the automated speech recognition module (ASR), which faces a number of challenges: first, state-of-the-art ASR models are often trained on adult read-aloud data by native speakers and do not transfer well to young language learnersâ€™ speech. Second, most ASR systems contain a powerful language model, which smooths out errors made by the speakers. To give corrective feedback, which is a crucial part of language learning, the ASR systems in our setting need to preserve the errors made by the language learners. In this work, we build an ASR system that satisfies these requirements: it works on spontaneous speech by young language learners and preserves their errors. For this, we collected a corpus containing around 85 hours of English audio spoken by learners in Switzerland from grades 4 to 6 on different language learning tasks, which we used to train an ASR model. Our experiments show that our model benefits from direct fine-tuning on childrenâ€™s voices and has a much higher error preservation rate than other models.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.1" class="ltx_block ltx_align_bottom">
<p id="p1.1.1" class="ltx_p"><span id="p1.1.1.1" class="ltx_text ltx_font_bold">Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.1.2" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.1.2.1" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.1.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.1.1.1.1" class="ltx_tr">
<span id="p1.1.2.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">
Janick Michot<sup id="p1.1.2.1.1.1.1.1.1.1" class="ltx_sup">1</sup>, Manuela HÃ¼rlimann<sup id="p1.1.2.1.1.1.1.1.1.2" class="ltx_sup">1</sup>, Jan Deriu<sup id="p1.1.2.1.1.1.1.1.1.3" class="ltx_sup">1</sup>, Luzia Sauer<sup id="p1.1.2.1.1.1.1.1.1.4" class="ltx_sup">2</sup>.</span></span></span>
<span id="p1.1.2.1.1.2.2" class="ltx_tr">
<span id="p1.1.2.1.1.2.2.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Katsiaryna Mlynchyk <sup id="p1.1.2.1.1.2.2.1.1.1" class="ltx_sup">1</sup>, Mark Cieliebak<sup id="p1.1.2.1.1.2.2.1.1.2" class="ltx_sup">1</sup></span></span></span>
<span id="p1.1.2.1.1.3.3" class="ltx_tr">
<span id="p1.1.2.1.1.3.3.1" class="ltx_td ltx_align_center"><sup id="p1.1.2.1.1.3.3.1.1" class="ltx_sup">1</sup> Zurich University of Applied Sciences, Winterthur</span></span>
<span id="p1.1.2.1.1.4.4" class="ltx_tr">
<span id="p1.1.2.1.1.4.4.1" class="ltx_td ltx_align_center"><sup id="p1.1.2.1.1.4.4.1.1" class="ltx_sup">2</sup> PÃ¤dagogische Hochschule Zurich, Zurich</span></span>
<span id="p1.1.2.1.1.5.5" class="ltx_tr">
<span id="p1.1.2.1.1.5.5.1" class="ltx_td ltx_align_center">mict@zhaw.ch, hueu@zhaw.ch, deri@zhaw.ch, luzia.sauer@phzh.ch,</span></span>
<span id="p1.1.2.1.1.6.6" class="ltx_tr">
<span id="p1.1.2.1.1.6.6.1" class="ltx_td ltx_align_center">mlyn@zhaw.ch, ciel@zhaw.ch</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Speaking is one of the core competencies to be developed in foreign language classes and
the second most widely used skill in everyday-life communicationÂ <cite class="ltx_cite ltx_citemacro_cite">Hedge (<a href="#bib.bib17" title="" class="ltx_ref">2001</a>)</cite>. For students to successfully acquire speaking competencies, they must be trained from an early stage in the language learning process and in a systematic manner. However, speech production is a highly complex process that is often not addressed adequately in classrooms. The main issue is that students often do not get enough speaking opportunitiesÂ <cite class="ltx_cite ltx_citemacro_cite">Kleinschroth and Oldham (<a href="#bib.bib18" title="" class="ltx_ref">2014</a>); Grimm etÂ al. (<a href="#bib.bib13" title="" class="ltx_ref">2015</a>)</cite>, and lack extended conversational practiceÂ <cite class="ltx_cite ltx_citemacro_cite">Pfenninger and Lendl (<a href="#bib.bib26" title="" class="ltx_ref">2017</a>)</cite>. The recent advancements in both speech processingÂ <cite class="ltx_cite ltx_citemacro_cite">Malik etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, and conversational dialogue systemsÂ <cite class="ltx_cite ltx_citemacro_cite">Deriu etÂ al. (<a href="#bib.bib7" title="" class="ltx_ref">2021</a>); Ni etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite> provide an opportunity to increase the speaking practice of language learners using automated tools.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The work presented in this paper is part of a larger effort to develop an interactive, voice-driven chatbot with which learners can practice their interactive speaking skills. The bot is designed as a conversation partner that adjusts to the proficiency level and interests of the students and provides corrective feedback to support their language development.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">One key issue is the automated speech recognition (ASR) module, which transcribes the utterances of the language learners into text to be processed in downstream tasks (e.g., speaker-error analysis, dialogue systems, inter alia). The focus of this work is to adapt the ASR module to handle childrenâ€™s speech in a language learning environment. The core challenge for the ASR system in this setting is not only to transcribe the speech but to make sure that the errors made by the language learners are transcribed faithfully. This is needed to provide language learners with corrective feedback, which is a key component of foreign language development. It prompts learners to notice errors and is likely to lead to utterance repair, which, in turn, facilitates language development <cite class="ltx_cite ltx_citemacro_cite">Ellis (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>. Our investigations showed that current state-of-the-art ASR models tend to correct the speakersâ€™ errors, which renders giving corrective feedback impossible.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The second challenge for the ASR system is handling spontaneous childrenâ€™s speech since most of these systems are trained on adult read-aloud error-free corpora recorded by native speakersÂ <cite class="ltx_cite ltx_citemacro_cite">Panayotov etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2015</a>); Ardila etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>. Childrenâ€™s speech, especially spontaneous speech of language learners, differs significantly from read-aloud speech of native adult speakersÂ <cite class="ltx_cite ltx_citemacro_cite">Shivakumar and Georgiou (<a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>. Childrenâ€™sâ€™ speech has a different range of sound frequenciesÂ <cite class="ltx_cite ltx_citemacro_cite">Potamianos and Narayanan (<a href="#bib.bib28" title="" class="ltx_ref">2003</a>)</cite>, a high within-subjects variabilityÂ <cite class="ltx_cite ltx_citemacro_cite">Gerosa etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2006</a>)</cite> and a high inter-speaker variability in different age groupsÂ <cite class="ltx_cite ltx_citemacro_cite">Lee etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">1999</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">These challenges yield three research questions, which we address in this work:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">How can we measure error preservation, i.e. the "verbatimness" of an ASR transcript?</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">How well do current pre-trained ASR systems perform on learnersâ€™ spontaneous English productions, with respect to error preservation and in general?</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Does fine-tuning pre-trained systems with data from young learners lead to improved error preservation in the ASR transcripts?</p>
</div>
</li>
</ol>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Contributions</h5>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">In order to answer these questions, we first collected a dataset of young learners in Swiss public schools speaking English, consisting of 85 hours of recordings corresponding to 45â€™004 individual utterances by 327 distinct speakers. We subsequently created verbatim transcriptions of these recordings, in which learner errors are annotated using specific symbols. This dataset can be accessed on HuggingFace<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://huggingface.co/datasets/mict-zhaw/chall" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/mict-zhaw/chall</a></span></span></span>, but the dataset files must be downloaded manually as described in Section <a href="#S3.SS4.SSS2" title="3.4.2 Data Availability â€£ 3.4 Final Dataset â€£ 3 Dataset: Spontaneous Speech of Young Learners of English â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.2</span></a> below. We next developed a metric for error preservation, called <em id="S1.SS0.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">Word-Based Error Preservation Rate (WEPR)</em>, which takes into account only those reference words that contain an error annotation. Using WEPR and standard ASR metrics, we compared 7 pre-trained ASR systems with a custom fine-tuned model<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://huggingface.co/mict-zhaw/chall_wav2vec2_xlsr_300m" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/mict-zhaw/chall_wav2vec2_xlsr_300m</a></span></span></span>. Our results show that a) there are large differences between the pre-trained models both in terms of standard metrics and in terms of WEPR and b) fine-tuning significantly improves error preservation of learnersâ€™ speech. All related code can be accessed on GitHub<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/mict-zhaw/chall_e2e_stt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/mict-zhaw/chall_e2e_stt</a></span></span></span>.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Childrenâ€™s Speech Corpora.</span> Corpora of childrenâ€™s speech can be divided into two types: i) corpora for native speaking children intended for building virtual tutors for non-language subjects, ii) corpora for young language learners that support building virtual tutors for language learning.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The MyST Childrenâ€™s Speech CorpusÂ <cite class="ltx_cite ltx_citemacro_cite">Pradhan etÂ al. (<a href="#bib.bib29" title="" class="ltx_ref">2016</a>); Ward etÂ al. (<a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite> contains 499 hours of conversational speech (out of which 233 hours are manually transcribed) for a virtual tutor for science topics targeted at young English native speakers. The OGI Kidsâ€™ Speech CorpusÂ <cite class="ltx_cite ltx_citemacro_cite">Shobaki etÂ al. (<a href="#bib.bib34" title="" class="ltx_ref">2000</a>)</cite> contains spontaneous speech from 1100 American children from kindergarten through grade 10, mainly consisting of scripted speech in the form of words and utterances, and a small sample of spontaneous speech. The AusKidTalk corpusÂ <cite class="ltx_cite ltx_citemacro_cite">Ahmed etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite> contains speech from Australian children ages 3 to 12 consisting of single words, utterances, and narrative speech. Other, smaller, datasets of native speaking children are available for different purposes such as read-aloud supportÂ <cite class="ltx_cite ltx_citemacro_cite">Eskenazi (<a href="#bib.bib10" title="" class="ltx_ref">1996</a>)</cite> or general analysis of English childrenâ€™s speechÂ <cite class="ltx_cite ltx_citemacro_cite">Lee etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">1999</a>); Hagen etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2003</a>)</cite>. For German, the KidsTalk corpusÂ <cite class="ltx_cite ltx_citemacro_cite">Rumberg etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2022</a>)</cite> contains 25 hours of transcribed continuous speech from children aged 3 to 11. All these corpora are devised for settings with native speakers.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">For language learners, there are far fewer datasets of childrenâ€™s speech. The TLT-school collectionÂ <cite class="ltx_cite ltx_citemacro_cite">Gretter etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> aims at assessing the proficiency of 9- to 16-year old Italian native speakers in English and German. TLT was recorded with a pool of 3000 students, resulting in approximately 275h of English and 265h of German data, out of which 16h for English and 8h for German have been transcribed. The corpus closest to our dataset is the CALL corpusÂ <cite class="ltx_cite ltx_citemacro_cite">Baur etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite>, consisting of English utterances by Swiss German second and third year learners, where the task is to label the correctness of each utterance. In total, the corpus contains 38k utterances of students interacting with an online dialogue system, where they receive various prompts to produce speech. Across a series of shared tasks, subsets of around 6k annotated utterances have been released. The setting differs significantly from ours as we are interested in spontaneous speech with transcriptions to train an ASR system which can automatically transcribe learnersâ€™ speech verbatim. <cite class="ltx_cite ltx_citemacro_citet">Batliner etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2005</a>)</cite> introduce a childrenâ€™s speech corpus containing 60 hours of childrenâ€™s speech aged 4-13 in a variety of languages, such as English, German, and Swedish, as well as English speech from German, Italian, and Swedish children. In general, there is only a limited amount of work investigating the effects of fine-tuning models on speech data of language learners to retain the speakersâ€™ errors. Â <cite class="ltx_cite ltx_citemacro_citet">Ma etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2023</a>)</cite> fine-tune Whisper to investigate its ability to retain hesitations, numbers, abbreviations, disfluencies, and incomplete words. Instead, we aim to preserve speaker errors in grammar, lexical choice, and pronunciation.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">ASR for childrenâ€™s speech and language learners.</span>
The literature on ASR models for childrenâ€™s speech, especially for non-native language learners, is sparse. Most notably, <cite class="ltx_cite ltx_citemacro_citet">Lu etÂ al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite> investigated the performance of fine-tuning wav2vec 2.0Â <cite class="ltx_cite ltx_citemacro_cite">Baevski etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> on childrenâ€™s speech (both native MyST and OGI), as well as non-native speech (TLT) compared to fine-tuning on adult-only data. The results show that ASR models trained on childrenâ€™s speech significantly outperform those models trained on adult-speech only, even in the case of non-native speakers. Similarly, <cite class="ltx_cite ltx_citemacro_citet">Shivakumar and Narayanan (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> investigated the impact of using childrenâ€™s data for fine-tuning ASR models. The conclusion is similar to <cite class="ltx_cite ltx_citemacro_citet">Lu etÂ al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>: adding childrenâ€™s data yields better performance; however, the performance of an adult ASR model on adult data is higher than the performance of an ASR model trained and applied on childrenâ€™s data. While both <cite class="ltx_cite ltx_citemacro_citet">Lu etÂ al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Shivakumar and Narayanan (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> are interested in the overall performance in terms of WER, our work focuses on the preservation of errors made by non-native children.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset: Spontaneous Speech of Young Learners of English</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We now describe the dataset that we collected for the purpose of this research. It contains 85 hours of audio recordings of spontaneous speech by young young learners of English in Switzerland. Each recording is paired with a verbatim transcript that contains error annotations.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Audio Recording</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The recording setup was designed such that the collected speech resembled the kind of conversations intended for the learners to hold with the chatbot.
We used playful and engaging activities targeted to elicit extended authentic communication from young learners. Activities included role plays with problem-solving components (e.g. â€˜going shopping for a school tripâ€™), guessing games (e.g. riddles), TV interviews with imaginary characters and asking/answering personal questions (e.g. â€˜if you could go into space, what would you take with you?â€™). All activities were piloted with a grade 4 class and maintained, adjusted (to yield more data) or rejected (e.g. because the task led to students communicating non-verbally and/or with much noise) for the main data collection period. To support learners, each activity further included visual and language support (e.g. cartoon characters they could choose from, sample dialogues, language chunks) as well as a preparation phase during which the students could familiarise themselves with the tasks by use of example sentences and model dialogues.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>The descriptions of the speaking activities is provided in the repository.</span></span></span></p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Speaker recruitment and consent</span>
After receiving permission to collect audio data with minors from key government institutions that act as ethics review boards in Switzerland concerning research with schools and their learners, we recruited 20 primary school teachers interested in participating in our project with their classes (via personal and university networks, newsletters and direct contact with schools). Participation was entirely voluntary and could be withdrawn at any time. Participation further necessitated the approval of the school principal and the written consent of each studentâ€™s legal caretaker.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>We share the consent forms in our repository.</span></span></span></p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In the span of 9 months (March-November 2023), 337 primary school students aged 9 to 14 years (4th to 6th graders) enrolled in 8 different schools in German-speaking Switzerland performed our activities in pairs, trios or alone (if necessary) in three different settings: at school recorded by project members; on the university campus recorded by project members and student assistants; and at school recorded by teachers and sent to us via safe weblinks. For reasons of practicability/feasibility (i.e., to respect teachersâ€™ tight schedules, time, and finances), the corpus was not annotated for CEFR levels, but according to the Swiss curriculum LP21, it should reflect performance at the A1 and A2 levels (English Basic Users). Some participants, including native-speaking children, performed beyond these levels.
School principals, teachers, and students were not remunerated for their participation but received small tokens of appreciation, such as flowers and chocolates.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Metadata</span> Each recording is associated with the following metadata:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">School area code: an integer between 1 and 8 (inclusive)</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">School grade of the speakers: 4gr, 5gr, 6gr as well as combinations (4/5gr, 5/6gr, 4/6gr)</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Recording Device</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Recording Application</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p">Speaking activities</p>
</div>
</li>
<li id="S3.I1.i6" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i6.p1" class="ltx_para">
<p id="S3.I1.i6.p1.1" class="ltx_p">Background Noise: a boolean indicating whether background noise is audible in the recording (set manually by project members).</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Transcription and Error Annotation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The transcription of our voice data was outsourced to a transcription agency. Services included both the transcription of the voice data and the annotation of lexical, grammatical and pronunciation errors, as well as usage of German words. We developed a comprehensive data transcription guideline for the transcription agency which was first piloted on a small number of transcripts and then adjusted where necessary.
Transcription guidelines included information about spelling conventions (British English), the frequency and nature of timestamps (start and end time of each word, in milliseconds), error codes (@! for errors of any kind and @g for German words) and disfluency markers (e.g. a hyphen "â€“" for verbatim repetitions, such as â€˜heâ€™s â€“ heâ€™s really tallâ€™). The complete transcription guidelines are provided in the supplementary material of this paper.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Data Aggregation and Filtering</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The recording stage resulted in 1039 audio recordings. Of these, 23 were removed due to missing metadata or missing/retracted consent, so a total of 1016 recordings and their associated metadata and transcriptions were available for our experiments.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">These recordings were split into individual utterances by a single speaker using the word-level timestamps provided in the transcripts, resulting in 49â€™608 utterances.We removed utterances shorter than 0.5 seconds and utterances attributed to adults (e.g. short interventions by teachers), creating a final dataset of 45â€™004 utterances corresponding to 85 hours of audio. Each utterance was paired with its reference transcription and metadata.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Final Dataset</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The final dataset contains 45â€™004 utterances by 327 distinct speakers. Figure <a href="#S3.F1" title="Figure 1 â€£ 3.4 Final Dataset â€£ 3 Dataset: Spontaneous Speech of Young Learners of English â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the number of recordings and audio duration by school grades and school area codes. Almost half the data in terms of both utterances and hours comes from 6th graders, while the other half is split among the other grades.
The dataset contains 485,770 tokens and 10,203 distinct types. There are 14,396 error-annotated tokens with 2,004 underlying types. Thus, our data contains a large amount of tokens and a relatively large amount of token diversity.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2406.03235/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="173" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Number of utterances (outer ring) and audio hours (inner ring) by school grade (a) and school area code (b).</figcaption>
</figure>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">The length distribution is shown in Figure <a href="#S3.F2" title="Figure 2 â€£ 3.4 Final Dataset â€£ 3 Dataset: Spontaneous Speech of Young Learners of English â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. It can be seen that most utterances are between 0.5 and 20 seconds long.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2406.03235/assets/figures/3_3_1_length_distribution_of_utterances.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="281" height="141" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distribution of utterance lengths.</figcaption>
</figure>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Data Folds</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">For the experiments in this paper, we split the dataset into five distinct folds of similar duration (about 16h each), where each class (and therefore also each speaker) occurs in only one fold. To simulate the use case of the ASR system being confronted with a new class of learners, each fold contains data from a mix of grades. Figure <a href="#S3.F3" title="Figure 3 â€£ 3.4.1 Data Folds â€£ 3.4 Final Dataset â€£ 3 Dataset: Spontaneous Speech of Young Learners of English â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> visualises the duration and grade distribution of each fold.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2406.03235/assets/figures/3_4_data_folds_duration.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="269" height="201" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Duration and grade distribution of the data folds.</figcaption>
</figure>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>Data Availability</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">The dataset that we collected contains sensitive data of minors and thus cannot be shared publicly. The data can, however, be accessed as part of a joint project with one or several of the original project partners, subject to a collaboration agreement. Before sharing, all transcripts will undergo complete anonymisation so that any names and other personal information are removed.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Error-Preserving Automatic Speech Recognition</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents the metrics used for measuring error preservation and evaluating systems (Section <a href="#S4.SS1" title="4.1 Metrics â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>), as well as the approaches to comparing pre-trained ASR systems (Section <a href="#S4.SS2" title="4.2 Pre-trained ASR Systems â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>) and to fine-tuning existing systems using our learner dataset (Section <a href="#S4.SS3" title="4.3 Fine-tuning Pre-trained ASR Systems Using Learner Data â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>). The qualitative results are presented and discussed in Section <a href="#S4.SS4" title="4.4 Quantitative Results â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>, and a qualitative evaluation is shared in <a href="#S4.SS5" title="4.5 Qualitative Results â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.5</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Metrics</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.5" class="ltx_p">In order to measure error preservation, we use the error annotations that were manually added to each utterance (cp. Section <a href="#S3.SS2" title="3.2 Transcription and Error Annotation â€£ 3 Dataset: Spontaneous Speech of Young Learners of English â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>) and a custom phonetic word-level alignment algorithm. This algorithm aligns two or more sequences (e.g., a reference and one or multiple hypotheses), identifying matches, substitutions (S), insertions (I), and deletions (D) at the word level. Our metric, WEPR (Word-Based Error Preservation Rate), considers only those word pairs where the reference word contains an error annotation. WEPR is calculated according to equation <a href="#S4.E1" title="In 4.1 Metrics â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>:
<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\mathcal{A}</annotation></semantics></math> is the set of annotations that are considered (e.g. <math id="S4.SS1.p1.2.m2.2" class="ltx_Math" alttext="\mathcal{A=\{\mathtt{@!},\mathtt{@g}\}}" display="inline"><semantics id="S4.SS1.p1.2.m2.2a"><mrow id="S4.SS1.p1.2.m2.2.2" xref="S4.SS1.p1.2.m2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.2.m2.2.2.4" xref="S4.SS1.p1.2.m2.2.2.4.cmml">ğ’œ</mi><mo id="S4.SS1.p1.2.m2.2.2.3" xref="S4.SS1.p1.2.m2.2.2.3.cmml">=</mo><mrow id="S4.SS1.p1.2.m2.2.2.2.2" xref="S4.SS1.p1.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S4.SS1.p1.2.m2.2.2.2.2.3" xref="S4.SS1.p1.2.m2.2.2.2.3.cmml">{</mo><mrow id="S4.SS1.p1.2.m2.1.1.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S4.SS1.p1.2.m2.1.1.1.1.1.2" xref="S4.SS1.p1.2.m2.1.1.1.1.1.2.cmml">@</mi><mo id="S4.SS1.p1.2.m2.1.1.1.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.1.1.1.cmml">!</mo></mrow><mo id="S4.SS1.p1.2.m2.2.2.2.2.4" xref="S4.SS1.p1.2.m2.2.2.2.3.cmml">,</mo><mrow id="S4.SS1.p1.2.m2.2.2.2.2.2" xref="S4.SS1.p1.2.m2.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S4.SS1.p1.2.m2.2.2.2.2.2.2" xref="S4.SS1.p1.2.m2.2.2.2.2.2.2.cmml">@</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.2.2.2.2.2.1" xref="S4.SS1.p1.2.m2.2.2.2.2.2.1.cmml">â€‹</mo><mi id="S4.SS1.p1.2.m2.2.2.2.2.2.3" xref="S4.SS1.p1.2.m2.2.2.2.2.2.3.cmml">ğš</mi></mrow><mo stretchy="false" id="S4.SS1.p1.2.m2.2.2.2.2.5" xref="S4.SS1.p1.2.m2.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.2b"><apply id="S4.SS1.p1.2.m2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2"><eq id="S4.SS1.p1.2.m2.2.2.3.cmml" xref="S4.SS1.p1.2.m2.2.2.3"></eq><ci id="S4.SS1.p1.2.m2.2.2.4.cmml" xref="S4.SS1.p1.2.m2.2.2.4">ğ’œ</ci><set id="S4.SS1.p1.2.m2.2.2.2.3.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2"><apply id="S4.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.1"><factorial id="S4.SS1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.1.1"></factorial><ci id="S4.SS1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.1.2">@</ci></apply><apply id="S4.SS1.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2"><times id="S4.SS1.p1.2.m2.2.2.2.2.2.1.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2.1"></times><ci id="S4.SS1.p1.2.m2.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2.2">@</ci><ci id="S4.SS1.p1.2.m2.2.2.2.2.2.3.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2.3">ğš</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.2c">\mathcal{A=\{\mathtt{@!},\mathtt{@g}\}}</annotation></semantics></math>), <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">ğ’®</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">ğ’®</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\mathcal{S}</annotation></semantics></math> and <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><ci id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">\mathcal{D}</annotation></semantics></math> are the number of substitutions and deletions, respectively, where the reference word contains an error annotation, and <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">ğ’©</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">ğ’©</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">\mathcal{N}</annotation></semantics></math> is the total number of reference words that contain an error annotation.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span id="S4.E1.m1.1.1.1" class="ltx_text ltx_markedasmath"><math id="S4.E1.m1.1.1.1.m1.2" class="ltx_Math" alttext="WEPR(\mathcal{A})=\frac{(\mathcal{S+D})}{\mathcal{N}}" display="inline"><semantics id="S4.E1.m1.1.1.1.m1.2a"><mrow id="S4.E1.m1.1.1.1.m1.2.3" xref="S4.E1.m1.1.1.1.m1.2.3.cmml"><mrow id="S4.E1.m1.1.1.1.m1.2.3.2" xref="S4.E1.m1.1.1.1.m1.2.3.2.cmml"><mi id="S4.E1.m1.1.1.1.m1.2.3.2.2" xref="S4.E1.m1.1.1.1.m1.2.3.2.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.m1.2.3.2.1" xref="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml">â€‹</mo><mi id="S4.E1.m1.1.1.1.m1.2.3.2.3" xref="S4.E1.m1.1.1.1.m1.2.3.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.m1.2.3.2.1a" xref="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml">â€‹</mo><mi id="S4.E1.m1.1.1.1.m1.2.3.2.4" xref="S4.E1.m1.1.1.1.m1.2.3.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.m1.2.3.2.1b" xref="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml">â€‹</mo><mi id="S4.E1.m1.1.1.1.m1.2.3.2.5" xref="S4.E1.m1.1.1.1.m1.2.3.2.5.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.m1.2.3.2.1c" xref="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml">â€‹</mo><mrow id="S4.E1.m1.1.1.1.m1.2.3.2.6.2" xref="S4.E1.m1.1.1.1.m1.2.3.2.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.m1.2.3.2.6.2.1" xref="S4.E1.m1.1.1.1.m1.2.3.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.m1.2.2" xref="S4.E1.m1.1.1.1.m1.2.2.cmml">ğ’œ</mi><mo stretchy="false" id="S4.E1.m1.1.1.1.m1.2.3.2.6.2.2" xref="S4.E1.m1.1.1.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.1.1.1.m1.2.3.1" xref="S4.E1.m1.1.1.1.m1.2.3.1.cmml">=</mo><mfrac id="S4.E1.m1.1.1.1.m1.1.1" xref="S4.E1.m1.1.1.1.m1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.m1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.2.cmml">ğ’®</mi><mo id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.1.cmml">+</mo><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.3.cmml">ğ’Ÿ</mi></mrow><mo stretchy="false" id="S4.E1.m1.1.1.1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.m1.1.1.3" xref="S4.E1.m1.1.1.1.m1.1.1.3.cmml">ğ’©</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1.1.1.m1.2b"><apply id="S4.E1.m1.1.1.1.m1.2.3.cmml" xref="S4.E1.m1.1.1.1.m1.2.3"><eq id="S4.E1.m1.1.1.1.m1.2.3.1.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.1"></eq><apply id="S4.E1.m1.1.1.1.m1.2.3.2.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2"><times id="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.1"></times><ci id="S4.E1.m1.1.1.1.m1.2.3.2.2.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.2">ğ‘Š</ci><ci id="S4.E1.m1.1.1.1.m1.2.3.2.3.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.3">ğ¸</ci><ci id="S4.E1.m1.1.1.1.m1.2.3.2.4.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.4">ğ‘ƒ</ci><ci id="S4.E1.m1.1.1.1.m1.2.3.2.5.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.5">ğ‘…</ci><ci id="S4.E1.m1.1.1.1.m1.2.2.cmml" xref="S4.E1.m1.1.1.1.m1.2.2">ğ’œ</ci></apply><apply id="S4.E1.m1.1.1.1.m1.1.1.cmml" xref="S4.E1.m1.1.1.1.m1.1.1"><divide id="S4.E1.m1.1.1.1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.m1.1.1"></divide><apply id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.1.1"><plus id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.1"></plus><ci id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.2">ğ’®</ci><ci id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.3">ğ’Ÿ</ci></apply><ci id="S4.E1.m1.1.1.1.m1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.3">ğ’©</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1.1.1.m1.2c">WEPR(\mathcal{A})=\frac{(\mathcal{S+D})}{\mathcal{N}}</annotation></semantics></math></span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="0" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">In addition to WEPR, we also compute the following general ASR metrics using all words in the utterance: Word Error Rate (WER)<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://github.com/huggingface/evaluate/blob/main/metrics/wer/wer.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/evaluate/blob/main/metrics/wer/wer.py</a></span></span></span>, Character Error Rate (CER)<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/huggingface/evaluate/blob/main/metrics/cer/cer.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/evaluate/blob/main/metrics/cer/cer.py</a></span></span></span>, and character n-gram F-Score (chrF)<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://www.nltk.org/api/nltk.translate.chrf_score.html#nltk.translate.chrf_score.corpus_chrf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nltk.org/api/nltk.translate.chrf_score.html#nltk.translate.chrf_score.corpus_chrf</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">PopoviÄ‡ (<a href="#bib.bib27" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">We evaluate all models on our datasetâ€™s five folds (cp. Section <a href="#S3.SS4.SSS1" title="3.4.1 Data Folds â€£ 3.4 Final Dataset â€£ 3 Dataset: Spontaneous Speech of Young Learners of English â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.1</span></a>) and report for each model the mean and standard deviation across all folds.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">For evaluation, all texts are normalised using the Whisper normalizer for English <span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://github.com/openai/whisper/blob/main/whisper/normalizers/english.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/openai/whisper/blob/main/whisper/normalizers/english.py</a></span></span></span>. Normalizing texts can mitigate the impact of disfluencies and non-standard linguistic forms, common in non-native and childrenâ€™s speech. This allows for a more accurate comparison between different ASR models, as it aligns the hypothesis and reference texts more closely.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.1 Metrics â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrates text normalization and WEPR calculation using a Whisper Large model prediction and a modified normalizer. The adjustments to the Whisper normalizer maintain contractions in references, ensuring the integrity of annotated words (e.g., itâ€™s@!). For error preservation assessment, phonetic alignment is performed between the normalized prediction (NP) and a reference without error annotations (NR2). This removal is essential because the alignment algorithm would otherwise misidentify annotated words. The normalized reference with annotations (NR1) is then used to identify word pairs in the alignment results that are relevant for WEPR calculation. The Whisper Normalizerâ€™s tendency to increase the similarity between predictiosn and references helps in building and classifying these word-level pairs.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:128.7pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-112.5pt,35.0pt) scale(0.646845204996048,0.646845204996048) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_t"></td>
<td id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.2.1.1" class="ltx_p" style="width:142.3pt;">Category</span>
</span>
</td>
<td id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.3.1.1" class="ltx_p" style="width:426.8pt;">Content</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.2.2" class="ltx_tr">
<td id="S4.T1.1.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_t">
<span id="S4.T1.1.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.1.1.1" class="ltx_p" style="width:28.5pt;">R</span>
</span>
</td>
<td id="S4.T1.1.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.2.1.1" class="ltx_p" style="width:142.3pt;">Reference</span>
</span>
</td>
<td id="S4.T1.1.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.3.1.1" class="ltx_p" style="width:426.8pt;">The beach, because itâ€™s <span id="S4.T1.1.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">a@!</span> very nice <span id="S4.T1.1.1.2.2.3.1.1.2" class="ltx_text ltx_font_bold">of@!</span> the beach. Tell me about <span id="S4.T1.1.1.2.2.3.1.1.3" class="ltx_text ltx_font_bold">you@!</span> favorite TV-show.</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.3.3" class="ltx_tr">
<td id="S4.T1.1.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.1.1.1" class="ltx_p" style="width:28.5pt;">P</span>
</span>
</td>
<td id="S4.T1.1.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.2.1.1" class="ltx_p" style="width:142.3pt;">Prediction</span>
</span>
</td>
<td id="S4.T1.1.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.3.1.1" class="ltx_p" style="width:426.8pt;">the beach because itâ€™s a very nice beach tell me about your favorite TV show</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.4.4" class="ltx_tr">
<td id="S4.T1.1.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_t">
<span id="S4.T1.1.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.1.1.1" class="ltx_p" style="width:28.5pt;">NR1</span>
</span>
</td>
<td id="S4.T1.1.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.2.1.1" class="ltx_p" style="width:142.3pt;">Normalized Reference (with @!)</span>
</span>
</td>
<td id="S4.T1.1.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.3.1.1" class="ltx_p" style="width:426.8pt;">the beach because itâ€™s <span id="S4.T1.1.1.4.4.3.1.1.1" class="ltx_text ltx_font_bold">a@!</span> very nice <span id="S4.T1.1.1.4.4.3.1.1.2" class="ltx_text ltx_font_bold">of@!</span> the beach tell me about <span id="S4.T1.1.1.4.4.3.1.1.3" class="ltx_text ltx_font_bold">you@!</span> favorite tvshow</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.5.5" class="ltx_tr">
<td id="S4.T1.1.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.1.1.1" class="ltx_p" style="width:28.5pt;">NR2</span>
</span>
</td>
<td id="S4.T1.1.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.2.1.1" class="ltx_p" style="width:142.3pt;">Normalized Reference</span>
</span>
</td>
<td id="S4.T1.1.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.3.1.1" class="ltx_p" style="width:426.8pt;">the beach because itâ€™s a very nice of the beach tell me about you favorite tvshow</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.6.6" class="ltx_tr">
<td id="S4.T1.1.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.1.1.1" class="ltx_p" style="width:28.5pt;">NP</span>
</span>
</td>
<td id="S4.T1.1.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.2.1.1" class="ltx_p" style="width:142.3pt;">Normalized Prediction</span>
</span>
</td>
<td id="S4.T1.1.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.3.1.1" class="ltx_p" style="width:426.8pt;">the beach because itâ€™s a very nice beach tell me about your favorite tv show</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.7.7" class="ltx_tr">
<td id="S4.T1.1.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_t">
<span id="S4.T1.1.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.1.1.1" class="ltx_p" style="width:28.5pt;">S</span>
</span>
</td>
<td id="S4.T1.1.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.2.1.1" class="ltx_p" style="width:142.3pt;">Substitutions</span>
</span>
</td>
<td id="S4.T1.1.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.3.1.1" class="ltx_p" style="width:426.8pt;">[(<span id="S4.T1.1.1.7.7.3.1.1.1" class="ltx_text ltx_font_bold">â€™you@!â€™</span>, â€™yourâ€™)]</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.8.8" class="ltx_tr">
<td id="S4.T1.1.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.1.1.1" class="ltx_p" style="width:28.5pt;">D</span>
</span>
</td>
<td id="S4.T1.1.1.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.2.1.1" class="ltx_p" style="width:142.3pt;">Deletions</span>
</span>
</td>
<td id="S4.T1.1.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.3.1.1" class="ltx_p" style="width:426.8pt;">[<span id="S4.T1.1.1.8.8.3.1.1.1" class="ltx_text ltx_font_bold">â€™of@!â€™</span>]</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.9.9" class="ltx_tr">
<td id="S4.T1.1.1.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.1.1.1" class="ltx_p" style="width:28.5pt;">I</span>
</span>
</td>
<td id="S4.T1.1.1.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.2.1.1" class="ltx_p" style="width:142.3pt;">Insertions</span>
</span>
</td>
<td id="S4.T1.1.1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.3.1.1" class="ltx_p" style="width:426.8pt;">[]</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.10.10" class="ltx_tr">
<td id="S4.T1.1.1.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.1.1.1" class="ltx_p" style="width:28.5pt;">C</span>
</span>
</td>
<td id="S4.T1.1.1.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.2.1.1" class="ltx_p" style="width:142.3pt;">Correct</span>
</span>
</td>
<td id="S4.T1.1.1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.3.1.1" class="ltx_p" style="width:426.8pt;">[<span id="S4.T1.1.1.10.10.3.1.1.1" class="ltx_text ltx_font_bold">â€™a@!â€™</span>]</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.11.11" class="ltx_tr">
<td id="S4.T1.1.1.11.11.1" class="ltx_td ltx_align_top ltx_border_b ltx_border_l ltx_border_t"></td>
<td id="S4.T1.1.1.11.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.11.11.2.1.1" class="ltx_p" style="width:142.3pt;">WEPR</span>
</span>
</td>
<td id="S4.T1.1.1.11.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.11.11.3.1.1" class="ltx_p" style="width:426.8pt;"><span id="S4.T1.1.1.11.11.3.1.1.1" class="ltx_text ltx_font_bold">0.67</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>WEPR calculation example using Whisper Large modelâ€™s prediction with texts normalized by a customized version of Whisperâ€™s Text Normalizer retaining contractions. Substitutions, insertions, deletions, and correct words are derived from phonetic alignment between NR2 and NP, but only for words that are annotated in NR1.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.32" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:325.2pt;height:117.3pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-63.3pt,22.7pt) scale(0.719900160430876,0.719900160430876) ;">
<table id="S4.T2.32.32" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.32.32.33.1" class="ltx_tr">
<th id="S4.T2.32.32.33.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">System Name</th>
<th id="S4.T2.32.32.33.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">#Param.</th>
<th id="S4.T2.32.32.33.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">WER</th>
<th id="S4.T2.32.32.33.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">CER</th>
<th id="S4.T2.32.32.33.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">chrF</th>
<th id="S4.T2.32.32.33.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">WEPR</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.4.4.4" class="ltx_tr">
<th id="S4.T2.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Wav2Vec Base</th>
<th id="S4.T2.4.4.4.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">95M</th>
<td id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="0.55\pm 0.02" display="inline"><semantics id="S4.T2.1.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml"><mn id="S4.T2.1.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.1.m1.1.1.2.cmml">0.55</mn><mo id="S4.T2.1.1.1.1.m1.1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.1.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.1.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.1.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2">0.55</cn><cn type="float" id="S4.T2.1.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">0.55\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="0.34\pm 0.02" display="inline"><semantics id="S4.T2.2.2.2.2.m1.1a"><mrow id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml"><mn id="S4.T2.2.2.2.2.m1.1.1.2" xref="S4.T2.2.2.2.2.m1.1.1.2.cmml">0.34</mn><mo id="S4.T2.2.2.2.2.m1.1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.2.2.2.2.m1.1.1.3" xref="S4.T2.2.2.2.2.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2">0.34</cn><cn type="float" id="S4.T2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T2.2.2.2.2.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">0.34\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="0.35\pm 0.02" display="inline"><semantics id="S4.T2.3.3.3.3.m1.1a"><mrow id="S4.T2.3.3.3.3.m1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.cmml"><mn id="S4.T2.3.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.3.m1.1.1.2.cmml">0.35</mn><mo id="S4.T2.3.3.3.3.m1.1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.3.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.3.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.3.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.3.m1.1.1.2">0.35</cn><cn type="float" id="S4.T2.3.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">0.35\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T2.4.4.4.4.m1.1" class="ltx_Math" alttext="0.57\pm 0.02" display="inline"><semantics id="S4.T2.4.4.4.4.m1.1a"><mrow id="S4.T2.4.4.4.4.m1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.cmml"><mn id="S4.T2.4.4.4.4.m1.1.1.2" xref="S4.T2.4.4.4.4.m1.1.1.2.cmml">0.57</mn><mo id="S4.T2.4.4.4.4.m1.1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.4.4.4.4.m1.1.1.3" xref="S4.T2.4.4.4.4.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.4.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.4.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2">0.57</cn><cn type="float" id="S4.T2.4.4.4.4.m1.1.1.3.cmml" xref="S4.T2.4.4.4.4.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.m1.1c">0.57\pm 0.02</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.8.8.8" class="ltx_tr">
<th id="S4.T2.8.8.8.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Wav2Vec Large</th>
<th id="S4.T2.8.8.8.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">317M</th>
<td id="S4.T2.5.5.5.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="0.49\pm 0.02" display="inline"><semantics id="S4.T2.5.5.5.1.m1.1a"><mrow id="S4.T2.5.5.5.1.m1.1.1" xref="S4.T2.5.5.5.1.m1.1.1.cmml"><mn id="S4.T2.5.5.5.1.m1.1.1.2" xref="S4.T2.5.5.5.1.m1.1.1.2.cmml">0.49</mn><mo id="S4.T2.5.5.5.1.m1.1.1.1" xref="S4.T2.5.5.5.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.5.5.5.1.m1.1.1.3" xref="S4.T2.5.5.5.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.1.m1.1b"><apply id="S4.T2.5.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.5.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.5.5.5.1.m1.1.1.1.cmml" xref="S4.T2.5.5.5.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.5.5.5.1.m1.1.1.2.cmml" xref="S4.T2.5.5.5.1.m1.1.1.2">0.49</cn><cn type="float" id="S4.T2.5.5.5.1.m1.1.1.3.cmml" xref="S4.T2.5.5.5.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.1.m1.1c">0.49\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.6.6.6.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.6.6.6.2.m1.1" class="ltx_Math" alttext="0.29\pm 0.01" display="inline"><semantics id="S4.T2.6.6.6.2.m1.1a"><mrow id="S4.T2.6.6.6.2.m1.1.1" xref="S4.T2.6.6.6.2.m1.1.1.cmml"><mn id="S4.T2.6.6.6.2.m1.1.1.2" xref="S4.T2.6.6.6.2.m1.1.1.2.cmml">0.29</mn><mo id="S4.T2.6.6.6.2.m1.1.1.1" xref="S4.T2.6.6.6.2.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.6.6.6.2.m1.1.1.3" xref="S4.T2.6.6.6.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.2.m1.1b"><apply id="S4.T2.6.6.6.2.m1.1.1.cmml" xref="S4.T2.6.6.6.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.6.6.6.2.m1.1.1.1.cmml" xref="S4.T2.6.6.6.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.6.6.6.2.m1.1.1.2.cmml" xref="S4.T2.6.6.6.2.m1.1.1.2">0.29</cn><cn type="float" id="S4.T2.6.6.6.2.m1.1.1.3.cmml" xref="S4.T2.6.6.6.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.2.m1.1c">0.29\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.7.7.7.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.7.7.7.3.m1.1" class="ltx_Math" alttext="0.41\pm 0.02" display="inline"><semantics id="S4.T2.7.7.7.3.m1.1a"><mrow id="S4.T2.7.7.7.3.m1.1.1" xref="S4.T2.7.7.7.3.m1.1.1.cmml"><mn id="S4.T2.7.7.7.3.m1.1.1.2" xref="S4.T2.7.7.7.3.m1.1.1.2.cmml">0.41</mn><mo id="S4.T2.7.7.7.3.m1.1.1.1" xref="S4.T2.7.7.7.3.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.7.7.7.3.m1.1.1.3" xref="S4.T2.7.7.7.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.3.m1.1b"><apply id="S4.T2.7.7.7.3.m1.1.1.cmml" xref="S4.T2.7.7.7.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.7.7.7.3.m1.1.1.1.cmml" xref="S4.T2.7.7.7.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.7.7.7.3.m1.1.1.2.cmml" xref="S4.T2.7.7.7.3.m1.1.1.2">0.41</cn><cn type="float" id="S4.T2.7.7.7.3.m1.1.1.3.cmml" xref="S4.T2.7.7.7.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.3.m1.1c">0.41\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.8.8.8.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.8.8.8.4.m1.1" class="ltx_Math" alttext="0.50\pm 0.02" display="inline"><semantics id="S4.T2.8.8.8.4.m1.1a"><mrow id="S4.T2.8.8.8.4.m1.1.1" xref="S4.T2.8.8.8.4.m1.1.1.cmml"><mn id="S4.T2.8.8.8.4.m1.1.1.2" xref="S4.T2.8.8.8.4.m1.1.1.2.cmml">0.50</mn><mo id="S4.T2.8.8.8.4.m1.1.1.1" xref="S4.T2.8.8.8.4.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.8.8.8.4.m1.1.1.3" xref="S4.T2.8.8.8.4.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.8.4.m1.1b"><apply id="S4.T2.8.8.8.4.m1.1.1.cmml" xref="S4.T2.8.8.8.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.8.8.8.4.m1.1.1.1.cmml" xref="S4.T2.8.8.8.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.8.8.8.4.m1.1.1.2.cmml" xref="S4.T2.8.8.8.4.m1.1.1.2">0.50</cn><cn type="float" id="S4.T2.8.8.8.4.m1.1.1.3.cmml" xref="S4.T2.8.8.8.4.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.8.4.m1.1c">0.50\pm 0.02</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.12.12.12" class="ltx_tr">
<th id="S4.T2.12.12.12.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">XLSR-53 + CommonVoice 6.1</th>
<th id="S4.T2.12.12.12.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">317M</th>
<td id="S4.T2.9.9.9.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="0.38\pm 0.01" display="inline"><semantics id="S4.T2.9.9.9.1.m1.1a"><mrow id="S4.T2.9.9.9.1.m1.1.1" xref="S4.T2.9.9.9.1.m1.1.1.cmml"><mn id="S4.T2.9.9.9.1.m1.1.1.2" xref="S4.T2.9.9.9.1.m1.1.1.2.cmml">0.38</mn><mo id="S4.T2.9.9.9.1.m1.1.1.1" xref="S4.T2.9.9.9.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.9.9.9.1.m1.1.1.3" xref="S4.T2.9.9.9.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.9.1.m1.1b"><apply id="S4.T2.9.9.9.1.m1.1.1.cmml" xref="S4.T2.9.9.9.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.9.9.9.1.m1.1.1.1.cmml" xref="S4.T2.9.9.9.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.9.9.9.1.m1.1.1.2.cmml" xref="S4.T2.9.9.9.1.m1.1.1.2">0.38</cn><cn type="float" id="S4.T2.9.9.9.1.m1.1.1.3.cmml" xref="S4.T2.9.9.9.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.9.1.m1.1c">0.38\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.10.10.10.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.10.10.10.2.m1.1" class="ltx_Math" alttext="0.26\pm 0.01" display="inline"><semantics id="S4.T2.10.10.10.2.m1.1a"><mrow id="S4.T2.10.10.10.2.m1.1.1" xref="S4.T2.10.10.10.2.m1.1.1.cmml"><mn id="S4.T2.10.10.10.2.m1.1.1.2" xref="S4.T2.10.10.10.2.m1.1.1.2.cmml">0.26</mn><mo id="S4.T2.10.10.10.2.m1.1.1.1" xref="S4.T2.10.10.10.2.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.10.10.10.2.m1.1.1.3" xref="S4.T2.10.10.10.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.10.2.m1.1b"><apply id="S4.T2.10.10.10.2.m1.1.1.cmml" xref="S4.T2.10.10.10.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.10.10.10.2.m1.1.1.1.cmml" xref="S4.T2.10.10.10.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.10.10.10.2.m1.1.1.2.cmml" xref="S4.T2.10.10.10.2.m1.1.1.2">0.26</cn><cn type="float" id="S4.T2.10.10.10.2.m1.1.1.3.cmml" xref="S4.T2.10.10.10.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.10.2.m1.1c">0.26\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.11.11.11.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.11.11.11.3.m1.1" class="ltx_Math" alttext="0.59\pm 0.01" display="inline"><semantics id="S4.T2.11.11.11.3.m1.1a"><mrow id="S4.T2.11.11.11.3.m1.1.1" xref="S4.T2.11.11.11.3.m1.1.1.cmml"><mn id="S4.T2.11.11.11.3.m1.1.1.2" xref="S4.T2.11.11.11.3.m1.1.1.2.cmml">0.59</mn><mo id="S4.T2.11.11.11.3.m1.1.1.1" xref="S4.T2.11.11.11.3.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.11.11.11.3.m1.1.1.3" xref="S4.T2.11.11.11.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.11.3.m1.1b"><apply id="S4.T2.11.11.11.3.m1.1.1.cmml" xref="S4.T2.11.11.11.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.11.11.11.3.m1.1.1.1.cmml" xref="S4.T2.11.11.11.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.11.11.11.3.m1.1.1.2.cmml" xref="S4.T2.11.11.11.3.m1.1.1.2">0.59</cn><cn type="float" id="S4.T2.11.11.11.3.m1.1.1.3.cmml" xref="S4.T2.11.11.11.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.11.3.m1.1c">0.59\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.12.12.12.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.12.12.12.4.m1.1" class="ltx_Math" alttext="0.50\pm 0.03" display="inline"><semantics id="S4.T2.12.12.12.4.m1.1a"><mrow id="S4.T2.12.12.12.4.m1.1.1" xref="S4.T2.12.12.12.4.m1.1.1.cmml"><mn id="S4.T2.12.12.12.4.m1.1.1.2" xref="S4.T2.12.12.12.4.m1.1.1.2.cmml">0.50</mn><mo id="S4.T2.12.12.12.4.m1.1.1.1" xref="S4.T2.12.12.12.4.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.12.12.12.4.m1.1.1.3" xref="S4.T2.12.12.12.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.12.4.m1.1b"><apply id="S4.T2.12.12.12.4.m1.1.1.cmml" xref="S4.T2.12.12.12.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.12.12.12.4.m1.1.1.1.cmml" xref="S4.T2.12.12.12.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.12.12.12.4.m1.1.1.2.cmml" xref="S4.T2.12.12.12.4.m1.1.1.2">0.50</cn><cn type="float" id="S4.T2.12.12.12.4.m1.1.1.3.cmml" xref="S4.T2.12.12.12.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.12.4.m1.1c">0.50\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.16.16.16" class="ltx_tr">
<th id="S4.T2.16.16.16.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">XLSR-1B + CommonVoice 6.1</th>
<th id="S4.T2.16.16.16.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1B</th>
<td id="S4.T2.13.13.13.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.13.13.13.1.m1.1" class="ltx_Math" alttext="0.31\pm 0.01" display="inline"><semantics id="S4.T2.13.13.13.1.m1.1a"><mrow id="S4.T2.13.13.13.1.m1.1.1" xref="S4.T2.13.13.13.1.m1.1.1.cmml"><mn id="S4.T2.13.13.13.1.m1.1.1.2" xref="S4.T2.13.13.13.1.m1.1.1.2.cmml">0.31</mn><mo id="S4.T2.13.13.13.1.m1.1.1.1" xref="S4.T2.13.13.13.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.13.13.13.1.m1.1.1.3" xref="S4.T2.13.13.13.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.13.13.13.1.m1.1b"><apply id="S4.T2.13.13.13.1.m1.1.1.cmml" xref="S4.T2.13.13.13.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.13.13.13.1.m1.1.1.1.cmml" xref="S4.T2.13.13.13.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.13.13.13.1.m1.1.1.2.cmml" xref="S4.T2.13.13.13.1.m1.1.1.2">0.31</cn><cn type="float" id="S4.T2.13.13.13.1.m1.1.1.3.cmml" xref="S4.T2.13.13.13.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.13.13.1.m1.1c">0.31\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.14.14.14.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.14.14.14.2.m1.1" class="ltx_Math" alttext="0.21\pm 0.01" display="inline"><semantics id="S4.T2.14.14.14.2.m1.1a"><mrow id="S4.T2.14.14.14.2.m1.1.1" xref="S4.T2.14.14.14.2.m1.1.1.cmml"><mn id="S4.T2.14.14.14.2.m1.1.1.2" xref="S4.T2.14.14.14.2.m1.1.1.2.cmml">0.21</mn><mo id="S4.T2.14.14.14.2.m1.1.1.1" xref="S4.T2.14.14.14.2.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.14.14.14.2.m1.1.1.3" xref="S4.T2.14.14.14.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.14.2.m1.1b"><apply id="S4.T2.14.14.14.2.m1.1.1.cmml" xref="S4.T2.14.14.14.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.14.14.14.2.m1.1.1.1.cmml" xref="S4.T2.14.14.14.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.14.14.14.2.m1.1.1.2.cmml" xref="S4.T2.14.14.14.2.m1.1.1.2">0.21</cn><cn type="float" id="S4.T2.14.14.14.2.m1.1.1.3.cmml" xref="S4.T2.14.14.14.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.14.2.m1.1c">0.21\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.15.15.15.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.15.15.15.3.m1.1" class="ltx_Math" alttext="0.61\pm 0.01" display="inline"><semantics id="S4.T2.15.15.15.3.m1.1a"><mrow id="S4.T2.15.15.15.3.m1.1.1" xref="S4.T2.15.15.15.3.m1.1.1.cmml"><mn id="S4.T2.15.15.15.3.m1.1.1.2" xref="S4.T2.15.15.15.3.m1.1.1.2.cmml">0.61</mn><mo id="S4.T2.15.15.15.3.m1.1.1.1" xref="S4.T2.15.15.15.3.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.15.15.15.3.m1.1.1.3" xref="S4.T2.15.15.15.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.15.3.m1.1b"><apply id="S4.T2.15.15.15.3.m1.1.1.cmml" xref="S4.T2.15.15.15.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.15.15.15.3.m1.1.1.1.cmml" xref="S4.T2.15.15.15.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.15.15.15.3.m1.1.1.2.cmml" xref="S4.T2.15.15.15.3.m1.1.1.2">0.61</cn><cn type="float" id="S4.T2.15.15.15.3.m1.1.1.3.cmml" xref="S4.T2.15.15.15.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.15.3.m1.1c">0.61\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.16.16.16.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.16.16.16.4.m1.1" class="ltx_Math" alttext="0.44\pm 0.03" display="inline"><semantics id="S4.T2.16.16.16.4.m1.1a"><mrow id="S4.T2.16.16.16.4.m1.1.1" xref="S4.T2.16.16.16.4.m1.1.1.cmml"><mn id="S4.T2.16.16.16.4.m1.1.1.2" xref="S4.T2.16.16.16.4.m1.1.1.2.cmml">0.44</mn><mo id="S4.T2.16.16.16.4.m1.1.1.1" xref="S4.T2.16.16.16.4.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.16.16.16.4.m1.1.1.3" xref="S4.T2.16.16.16.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.16.16.16.4.m1.1b"><apply id="S4.T2.16.16.16.4.m1.1.1.cmml" xref="S4.T2.16.16.16.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.16.16.16.4.m1.1.1.1.cmml" xref="S4.T2.16.16.16.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.16.16.16.4.m1.1.1.2.cmml" xref="S4.T2.16.16.16.4.m1.1.1.2">0.44</cn><cn type="float" id="S4.T2.16.16.16.4.m1.1.1.3.cmml" xref="S4.T2.16.16.16.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.16.16.4.m1.1c">0.44\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.20.20.20" class="ltx_tr">
<th id="S4.T2.20.20.20.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Whisper Medium</th>
<th id="S4.T2.20.20.20.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">769M</th>
<td id="S4.T2.17.17.17.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.17.17.17.1.m1.1" class="ltx_Math" alttext="0.26\pm 0.02" display="inline"><semantics id="S4.T2.17.17.17.1.m1.1a"><mrow id="S4.T2.17.17.17.1.m1.1.1" xref="S4.T2.17.17.17.1.m1.1.1.cmml"><mn id="S4.T2.17.17.17.1.m1.1.1.2" xref="S4.T2.17.17.17.1.m1.1.1.2.cmml">0.26</mn><mo id="S4.T2.17.17.17.1.m1.1.1.1" xref="S4.T2.17.17.17.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.17.17.17.1.m1.1.1.3" xref="S4.T2.17.17.17.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.17.17.17.1.m1.1b"><apply id="S4.T2.17.17.17.1.m1.1.1.cmml" xref="S4.T2.17.17.17.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.17.17.17.1.m1.1.1.1.cmml" xref="S4.T2.17.17.17.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.17.17.17.1.m1.1.1.2.cmml" xref="S4.T2.17.17.17.1.m1.1.1.2">0.26</cn><cn type="float" id="S4.T2.17.17.17.1.m1.1.1.3.cmml" xref="S4.T2.17.17.17.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.17.17.17.1.m1.1c">0.26\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.18.18.18.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.18.18.18.2.m1.1" class="ltx_Math" alttext="0.20\pm 0.03" display="inline"><semantics id="S4.T2.18.18.18.2.m1.1a"><mrow id="S4.T2.18.18.18.2.m1.1.1" xref="S4.T2.18.18.18.2.m1.1.1.cmml"><mn id="S4.T2.18.18.18.2.m1.1.1.2" xref="S4.T2.18.18.18.2.m1.1.1.2.cmml">0.20</mn><mo id="S4.T2.18.18.18.2.m1.1.1.1" xref="S4.T2.18.18.18.2.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.18.18.18.2.m1.1.1.3" xref="S4.T2.18.18.18.2.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.18.18.18.2.m1.1b"><apply id="S4.T2.18.18.18.2.m1.1.1.cmml" xref="S4.T2.18.18.18.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.18.18.18.2.m1.1.1.1.cmml" xref="S4.T2.18.18.18.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.18.18.18.2.m1.1.1.2.cmml" xref="S4.T2.18.18.18.2.m1.1.1.2">0.20</cn><cn type="float" id="S4.T2.18.18.18.2.m1.1.1.3.cmml" xref="S4.T2.18.18.18.2.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.18.18.18.2.m1.1c">0.20\pm 0.03</annotation></semantics></math></td>
<td id="S4.T2.19.19.19.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.19.19.19.3.m1.1" class="ltx_Math" alttext="\textbf{0.70}\pm 0.02" display="inline"><semantics id="S4.T2.19.19.19.3.m1.1a"><mrow id="S4.T2.19.19.19.3.m1.1.1" xref="S4.T2.19.19.19.3.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.19.19.19.3.m1.1.1.2" xref="S4.T2.19.19.19.3.m1.1.1.2a.cmml">0.70</mtext><mo id="S4.T2.19.19.19.3.m1.1.1.1" xref="S4.T2.19.19.19.3.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.19.19.19.3.m1.1.1.3" xref="S4.T2.19.19.19.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.19.19.19.3.m1.1b"><apply id="S4.T2.19.19.19.3.m1.1.1.cmml" xref="S4.T2.19.19.19.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.19.19.19.3.m1.1.1.1.cmml" xref="S4.T2.19.19.19.3.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.19.19.19.3.m1.1.1.2a.cmml" xref="S4.T2.19.19.19.3.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.19.19.19.3.m1.1.1.2.cmml" xref="S4.T2.19.19.19.3.m1.1.1.2">0.70</mtext></ci><cn type="float" id="S4.T2.19.19.19.3.m1.1.1.3.cmml" xref="S4.T2.19.19.19.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.19.19.19.3.m1.1c">\textbf{0.70}\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.20.20.20.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.20.20.20.4.m1.1" class="ltx_Math" alttext="0.46\pm 0.04" display="inline"><semantics id="S4.T2.20.20.20.4.m1.1a"><mrow id="S4.T2.20.20.20.4.m1.1.1" xref="S4.T2.20.20.20.4.m1.1.1.cmml"><mn id="S4.T2.20.20.20.4.m1.1.1.2" xref="S4.T2.20.20.20.4.m1.1.1.2.cmml">0.46</mn><mo id="S4.T2.20.20.20.4.m1.1.1.1" xref="S4.T2.20.20.20.4.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.20.20.20.4.m1.1.1.3" xref="S4.T2.20.20.20.4.m1.1.1.3.cmml">0.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.20.20.20.4.m1.1b"><apply id="S4.T2.20.20.20.4.m1.1.1.cmml" xref="S4.T2.20.20.20.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.20.20.20.4.m1.1.1.1.cmml" xref="S4.T2.20.20.20.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.20.20.20.4.m1.1.1.2.cmml" xref="S4.T2.20.20.20.4.m1.1.1.2">0.46</cn><cn type="float" id="S4.T2.20.20.20.4.m1.1.1.3.cmml" xref="S4.T2.20.20.20.4.m1.1.1.3">0.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.20.20.20.4.m1.1c">0.46\pm 0.04</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.24.24.24" class="ltx_tr">
<th id="S4.T2.24.24.24.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Whisper Large</th>
<th id="S4.T2.24.24.24.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.5B</th>
<td id="S4.T2.21.21.21.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.21.21.21.1.m1.1" class="ltx_Math" alttext="\textbf{0.25}\pm 0.02" display="inline"><semantics id="S4.T2.21.21.21.1.m1.1a"><mrow id="S4.T2.21.21.21.1.m1.1.1" xref="S4.T2.21.21.21.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.21.21.21.1.m1.1.1.2" xref="S4.T2.21.21.21.1.m1.1.1.2a.cmml">0.25</mtext><mo id="S4.T2.21.21.21.1.m1.1.1.1" xref="S4.T2.21.21.21.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.21.21.21.1.m1.1.1.3" xref="S4.T2.21.21.21.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.21.21.21.1.m1.1b"><apply id="S4.T2.21.21.21.1.m1.1.1.cmml" xref="S4.T2.21.21.21.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.21.21.21.1.m1.1.1.1.cmml" xref="S4.T2.21.21.21.1.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.21.21.21.1.m1.1.1.2a.cmml" xref="S4.T2.21.21.21.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.21.21.21.1.m1.1.1.2.cmml" xref="S4.T2.21.21.21.1.m1.1.1.2">0.25</mtext></ci><cn type="float" id="S4.T2.21.21.21.1.m1.1.1.3.cmml" xref="S4.T2.21.21.21.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.21.21.21.1.m1.1c">\textbf{0.25}\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.22.22.22.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.22.22.22.2.m1.1" class="ltx_Math" alttext="0.19\pm 0.01" display="inline"><semantics id="S4.T2.22.22.22.2.m1.1a"><mrow id="S4.T2.22.22.22.2.m1.1.1" xref="S4.T2.22.22.22.2.m1.1.1.cmml"><mn id="S4.T2.22.22.22.2.m1.1.1.2" xref="S4.T2.22.22.22.2.m1.1.1.2.cmml">0.19</mn><mo id="S4.T2.22.22.22.2.m1.1.1.1" xref="S4.T2.22.22.22.2.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.22.22.22.2.m1.1.1.3" xref="S4.T2.22.22.22.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.22.22.22.2.m1.1b"><apply id="S4.T2.22.22.22.2.m1.1.1.cmml" xref="S4.T2.22.22.22.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.22.22.22.2.m1.1.1.1.cmml" xref="S4.T2.22.22.22.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.22.22.22.2.m1.1.1.2.cmml" xref="S4.T2.22.22.22.2.m1.1.1.2">0.19</cn><cn type="float" id="S4.T2.22.22.22.2.m1.1.1.3.cmml" xref="S4.T2.22.22.22.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.22.22.22.2.m1.1c">0.19\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.23.23.23.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.23.23.23.3.m1.1" class="ltx_Math" alttext="\textbf{0.70}\pm 0.01" display="inline"><semantics id="S4.T2.23.23.23.3.m1.1a"><mrow id="S4.T2.23.23.23.3.m1.1.1" xref="S4.T2.23.23.23.3.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.23.23.23.3.m1.1.1.2" xref="S4.T2.23.23.23.3.m1.1.1.2a.cmml">0.70</mtext><mo id="S4.T2.23.23.23.3.m1.1.1.1" xref="S4.T2.23.23.23.3.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.23.23.23.3.m1.1.1.3" xref="S4.T2.23.23.23.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.23.23.23.3.m1.1b"><apply id="S4.T2.23.23.23.3.m1.1.1.cmml" xref="S4.T2.23.23.23.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.23.23.23.3.m1.1.1.1.cmml" xref="S4.T2.23.23.23.3.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.23.23.23.3.m1.1.1.2a.cmml" xref="S4.T2.23.23.23.3.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.23.23.23.3.m1.1.1.2.cmml" xref="S4.T2.23.23.23.3.m1.1.1.2">0.70</mtext></ci><cn type="float" id="S4.T2.23.23.23.3.m1.1.1.3.cmml" xref="S4.T2.23.23.23.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.23.23.23.3.m1.1c">\textbf{0.70}\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.24.24.24.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.24.24.24.4.m1.1" class="ltx_Math" alttext="0.47\pm 0.03" display="inline"><semantics id="S4.T2.24.24.24.4.m1.1a"><mrow id="S4.T2.24.24.24.4.m1.1.1" xref="S4.T2.24.24.24.4.m1.1.1.cmml"><mn id="S4.T2.24.24.24.4.m1.1.1.2" xref="S4.T2.24.24.24.4.m1.1.1.2.cmml">0.47</mn><mo id="S4.T2.24.24.24.4.m1.1.1.1" xref="S4.T2.24.24.24.4.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.24.24.24.4.m1.1.1.3" xref="S4.T2.24.24.24.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.24.24.24.4.m1.1b"><apply id="S4.T2.24.24.24.4.m1.1.1.cmml" xref="S4.T2.24.24.24.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.24.24.24.4.m1.1.1.1.cmml" xref="S4.T2.24.24.24.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.24.24.24.4.m1.1.1.2.cmml" xref="S4.T2.24.24.24.4.m1.1.1.2">0.47</cn><cn type="float" id="S4.T2.24.24.24.4.m1.1.1.3.cmml" xref="S4.T2.24.24.24.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.24.24.24.4.m1.1c">0.47\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.28.28.28" class="ltx_tr">
<th id="S4.T2.28.28.28.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Whisper Large-v3</th>
<th id="S4.T2.28.28.28.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.5B</th>
<td id="S4.T2.25.25.25.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.25.25.25.1.m1.1" class="ltx_Math" alttext="0.30\pm 0.04" display="inline"><semantics id="S4.T2.25.25.25.1.m1.1a"><mrow id="S4.T2.25.25.25.1.m1.1.1" xref="S4.T2.25.25.25.1.m1.1.1.cmml"><mn id="S4.T2.25.25.25.1.m1.1.1.2" xref="S4.T2.25.25.25.1.m1.1.1.2.cmml">0.30</mn><mo id="S4.T2.25.25.25.1.m1.1.1.1" xref="S4.T2.25.25.25.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.25.25.25.1.m1.1.1.3" xref="S4.T2.25.25.25.1.m1.1.1.3.cmml">0.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.25.25.25.1.m1.1b"><apply id="S4.T2.25.25.25.1.m1.1.1.cmml" xref="S4.T2.25.25.25.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.25.25.25.1.m1.1.1.1.cmml" xref="S4.T2.25.25.25.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.25.25.25.1.m1.1.1.2.cmml" xref="S4.T2.25.25.25.1.m1.1.1.2">0.30</cn><cn type="float" id="S4.T2.25.25.25.1.m1.1.1.3.cmml" xref="S4.T2.25.25.25.1.m1.1.1.3">0.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.25.25.25.1.m1.1c">0.30\pm 0.04</annotation></semantics></math></td>
<td id="S4.T2.26.26.26.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.26.26.26.2.m1.1" class="ltx_Math" alttext="0.23\pm 0.03" display="inline"><semantics id="S4.T2.26.26.26.2.m1.1a"><mrow id="S4.T2.26.26.26.2.m1.1.1" xref="S4.T2.26.26.26.2.m1.1.1.cmml"><mn id="S4.T2.26.26.26.2.m1.1.1.2" xref="S4.T2.26.26.26.2.m1.1.1.2.cmml">0.23</mn><mo id="S4.T2.26.26.26.2.m1.1.1.1" xref="S4.T2.26.26.26.2.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.26.26.26.2.m1.1.1.3" xref="S4.T2.26.26.26.2.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.26.26.26.2.m1.1b"><apply id="S4.T2.26.26.26.2.m1.1.1.cmml" xref="S4.T2.26.26.26.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.26.26.26.2.m1.1.1.1.cmml" xref="S4.T2.26.26.26.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.26.26.26.2.m1.1.1.2.cmml" xref="S4.T2.26.26.26.2.m1.1.1.2">0.23</cn><cn type="float" id="S4.T2.26.26.26.2.m1.1.1.3.cmml" xref="S4.T2.26.26.26.2.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.26.26.26.2.m1.1c">0.23\pm 0.03</annotation></semantics></math></td>
<td id="S4.T2.27.27.27.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.27.27.27.3.m1.1" class="ltx_Math" alttext="\textbf{0.70}\pm 0.02" display="inline"><semantics id="S4.T2.27.27.27.3.m1.1a"><mrow id="S4.T2.27.27.27.3.m1.1.1" xref="S4.T2.27.27.27.3.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.27.27.27.3.m1.1.1.2" xref="S4.T2.27.27.27.3.m1.1.1.2a.cmml">0.70</mtext><mo id="S4.T2.27.27.27.3.m1.1.1.1" xref="S4.T2.27.27.27.3.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.27.27.27.3.m1.1.1.3" xref="S4.T2.27.27.27.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.27.27.27.3.m1.1b"><apply id="S4.T2.27.27.27.3.m1.1.1.cmml" xref="S4.T2.27.27.27.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.27.27.27.3.m1.1.1.1.cmml" xref="S4.T2.27.27.27.3.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.27.27.27.3.m1.1.1.2a.cmml" xref="S4.T2.27.27.27.3.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.27.27.27.3.m1.1.1.2.cmml" xref="S4.T2.27.27.27.3.m1.1.1.2">0.70</mtext></ci><cn type="float" id="S4.T2.27.27.27.3.m1.1.1.3.cmml" xref="S4.T2.27.27.27.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.27.27.27.3.m1.1c">\textbf{0.70}\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.28.28.28.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.28.28.28.4.m1.1" class="ltx_Math" alttext="0.45\pm 0.03" display="inline"><semantics id="S4.T2.28.28.28.4.m1.1a"><mrow id="S4.T2.28.28.28.4.m1.1.1" xref="S4.T2.28.28.28.4.m1.1.1.cmml"><mn id="S4.T2.28.28.28.4.m1.1.1.2" xref="S4.T2.28.28.28.4.m1.1.1.2.cmml">0.45</mn><mo id="S4.T2.28.28.28.4.m1.1.1.1" xref="S4.T2.28.28.28.4.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.28.28.28.4.m1.1.1.3" xref="S4.T2.28.28.28.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.28.28.28.4.m1.1b"><apply id="S4.T2.28.28.28.4.m1.1.1.cmml" xref="S4.T2.28.28.28.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.28.28.28.4.m1.1.1.1.cmml" xref="S4.T2.28.28.28.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.28.28.28.4.m1.1.1.2.cmml" xref="S4.T2.28.28.28.4.m1.1.1.2">0.45</cn><cn type="float" id="S4.T2.28.28.28.4.m1.1.1.3.cmml" xref="S4.T2.28.28.28.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.28.28.28.4.m1.1c">0.45\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.32.32.32" class="ltx_tr">
<th id="S4.T2.32.32.32.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">ChaLL-300M (ours)</th>
<th id="S4.T2.32.32.32.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">300M</th>
<td id="S4.T2.29.29.29.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T2.29.29.29.1.m1.1" class="ltx_Math" alttext="0.30\pm 0.01" display="inline"><semantics id="S4.T2.29.29.29.1.m1.1a"><mrow id="S4.T2.29.29.29.1.m1.1.1" xref="S4.T2.29.29.29.1.m1.1.1.cmml"><mn id="S4.T2.29.29.29.1.m1.1.1.2" xref="S4.T2.29.29.29.1.m1.1.1.2.cmml">0.30</mn><mo id="S4.T2.29.29.29.1.m1.1.1.1" xref="S4.T2.29.29.29.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.29.29.29.1.m1.1.1.3" xref="S4.T2.29.29.29.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.29.29.29.1.m1.1b"><apply id="S4.T2.29.29.29.1.m1.1.1.cmml" xref="S4.T2.29.29.29.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.29.29.29.1.m1.1.1.1.cmml" xref="S4.T2.29.29.29.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.29.29.29.1.m1.1.1.2.cmml" xref="S4.T2.29.29.29.1.m1.1.1.2">0.30</cn><cn type="float" id="S4.T2.29.29.29.1.m1.1.1.3.cmml" xref="S4.T2.29.29.29.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.29.29.29.1.m1.1c">0.30\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.30.30.30.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T2.30.30.30.2.m1.1" class="ltx_Math" alttext="\textbf{0.16}\pm 0.01" display="inline"><semantics id="S4.T2.30.30.30.2.m1.1a"><mrow id="S4.T2.30.30.30.2.m1.1.1" xref="S4.T2.30.30.30.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.30.30.30.2.m1.1.1.2" xref="S4.T2.30.30.30.2.m1.1.1.2a.cmml">0.16</mtext><mo id="S4.T2.30.30.30.2.m1.1.1.1" xref="S4.T2.30.30.30.2.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.30.30.30.2.m1.1.1.3" xref="S4.T2.30.30.30.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.30.30.30.2.m1.1b"><apply id="S4.T2.30.30.30.2.m1.1.1.cmml" xref="S4.T2.30.30.30.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.30.30.30.2.m1.1.1.1.cmml" xref="S4.T2.30.30.30.2.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.30.30.30.2.m1.1.1.2a.cmml" xref="S4.T2.30.30.30.2.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.30.30.30.2.m1.1.1.2.cmml" xref="S4.T2.30.30.30.2.m1.1.1.2">0.16</mtext></ci><cn type="float" id="S4.T2.30.30.30.2.m1.1.1.3.cmml" xref="S4.T2.30.30.30.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.30.30.30.2.m1.1c">\textbf{0.16}\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.31.31.31.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T2.31.31.31.3.m1.1" class="ltx_Math" alttext="0.68\pm 0.01" display="inline"><semantics id="S4.T2.31.31.31.3.m1.1a"><mrow id="S4.T2.31.31.31.3.m1.1.1" xref="S4.T2.31.31.31.3.m1.1.1.cmml"><mn id="S4.T2.31.31.31.3.m1.1.1.2" xref="S4.T2.31.31.31.3.m1.1.1.2.cmml">0.68</mn><mo id="S4.T2.31.31.31.3.m1.1.1.1" xref="S4.T2.31.31.31.3.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.31.31.31.3.m1.1.1.3" xref="S4.T2.31.31.31.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.31.31.31.3.m1.1b"><apply id="S4.T2.31.31.31.3.m1.1.1.cmml" xref="S4.T2.31.31.31.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.31.31.31.3.m1.1.1.1.cmml" xref="S4.T2.31.31.31.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.31.31.31.3.m1.1.1.2.cmml" xref="S4.T2.31.31.31.3.m1.1.1.2">0.68</cn><cn type="float" id="S4.T2.31.31.31.3.m1.1.1.3.cmml" xref="S4.T2.31.31.31.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.31.31.31.3.m1.1c">0.68\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.32.32.32.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T2.32.32.32.4.m1.1" class="ltx_Math" alttext="\textbf{0.38}\pm 0.03" display="inline"><semantics id="S4.T2.32.32.32.4.m1.1a"><mrow id="S4.T2.32.32.32.4.m1.1.1" xref="S4.T2.32.32.32.4.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.32.32.32.4.m1.1.1.2" xref="S4.T2.32.32.32.4.m1.1.1.2a.cmml">0.38</mtext><mo id="S4.T2.32.32.32.4.m1.1.1.1" xref="S4.T2.32.32.32.4.m1.1.1.1.cmml">Â±</mo><mn id="S4.T2.32.32.32.4.m1.1.1.3" xref="S4.T2.32.32.32.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.32.32.32.4.m1.1b"><apply id="S4.T2.32.32.32.4.m1.1.1.cmml" xref="S4.T2.32.32.32.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.32.32.32.4.m1.1.1.1.cmml" xref="S4.T2.32.32.32.4.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.32.32.32.4.m1.1.1.2a.cmml" xref="S4.T2.32.32.32.4.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.32.32.32.4.m1.1.1.2.cmml" xref="S4.T2.32.32.32.4.m1.1.1.2">0.38</mtext></ci><cn type="float" id="S4.T2.32.32.32.4.m1.1.1.3.cmml" xref="S4.T2.32.32.32.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.32.32.32.4.m1.1c">\textbf{0.38}\pm 0.03</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of the 5-fold evaluation. We report for each model the mean and standard deviation (mean<math id="S4.T2.34.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.34.m1.1b"><mo id="S4.T2.34.m1.1.1" xref="S4.T2.34.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.34.m1.1c"><csymbol cd="latexml" id="S4.T2.34.m1.1.1.cmml" xref="S4.T2.34.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.34.m1.1d">\pm</annotation></semantics></math>std) of the scores on each of the 5 folds. The bottom row shows the scores of our fine-tuned model. </figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Pre-trained ASR Systems</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We compare the performance of state-of-the-art ASR systems trained on datasets of adult English speakers. For this, we select seven different models, four based on a CTC decoding strategy, and three based on an encoder-decoder architecture. Our hypothesis is that CTC models are better at preserving speaker-errors as they do not rely on a language model, which potentially corrects such errors. Therefore, we do not use a n-gram language model during the CTC decoding phase, which is usually added for better WER performance. For the CTC-based models, we use the original Wav2VWec 2.0 large and base modelsÂ <cite class="ltx_cite ltx_citemacro_cite">Baevski etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> fine-tuned on 960h of LibrispeechÂ <cite class="ltx_cite ltx_citemacro_cite">Panayotov etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2015</a>)</cite> (English adult read-aloud data). We also use the fine-tuned Wav2Vec 2.0 models provided byÂ <cite class="ltx_cite ltx_citemacro_citet">Grosman (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>, <a href="#bib.bib15" title="" class="ltx_ref">2022</a>)</cite>, which are based on the XLSR pretrainingÂ <cite class="ltx_cite ltx_citemacro_cite">Babu etÂ al. (<a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>, and were fine-tuned on the CommonVoice 6.1 dataÂ <cite class="ltx_cite ltx_citemacro_cite">Ardila etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite> consisting of approximately 2100 hours of English adult read-aloud data. For the encoder-decoder architecture, we used the Whisper medium, large, and large-v3 models provided by OpenAIÂ <cite class="ltx_cite ltx_citemacro_cite">Radford etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:281.9pt;height:364.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.3pt,15.9pt) scale(0.919909043701365,0.919909043701365) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_smallcaps">Prediction</span></td>
<td id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_smallcaps">Chall-300M</span></td>
<td id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.4.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.5.1" class="ltx_text ltx_font_smallcaps">XLSR-1B</span></td>
</tr>
<tr id="S4.T3.1.1.2.2" class="ltx_tr">
<td id="S4.T3.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">de@!</td>
<td id="S4.T3.1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">the</td>
<td id="S4.T3.1.1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.946</td>
<td id="S4.T3.1.1.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.869</td>
<td id="S4.T3.1.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.2.2.5.1" class="ltx_text ltx_font_bold">0.805</span></td>
</tr>
<tr id="S4.T3.1.1.3.3" class="ltx_tr">
<td id="S4.T3.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">a@!</td>
<td id="S4.T3.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.3.3.3.1" class="ltx_text ltx_font_bold">0.114</span></td>
<td id="S4.T3.1.1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.327</td>
<td id="S4.T3.1.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.347</td>
</tr>
<tr id="S4.T3.1.1.4.4" class="ltx_tr">
<td id="S4.T3.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">a@!</td>
<td id="S4.T3.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">an</td>
<td id="S4.T3.1.1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.4.4.3.1" class="ltx_text ltx_font_bold">0.026</span></td>
<td id="S4.T3.1.1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.398</td>
<td id="S4.T3.1.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.257</td>
</tr>
<tr id="S4.T3.1.1.5.5" class="ltx_tr">
<td id="S4.T3.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">have@!</td>
<td id="S4.T3.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">has</td>
<td id="S4.T3.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.5.5.3.1" class="ltx_text ltx_font_bold">0.015</span></td>
<td id="S4.T3.1.1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.231</td>
<td id="S4.T3.1.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.052</td>
</tr>
<tr id="S4.T3.1.1.6.6" class="ltx_tr">
<td id="S4.T3.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">have@!</td>
<td id="S4.T3.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.6.6.3.1" class="ltx_text ltx_font_bold">0.034</span></td>
<td id="S4.T3.1.1.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.128</td>
<td id="S4.T3.1.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.129</td>
</tr>
<tr id="S4.T3.1.1.7.7" class="ltx_tr">
<td id="S4.T3.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">you@!</td>
<td id="S4.T3.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">your</td>
<td id="S4.T3.1.1.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.244</td>
<td id="S4.T3.1.1.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.306</td>
<td id="S4.T3.1.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.7.7.5.1" class="ltx_text ltx_font_bold">0.099</span></td>
</tr>
<tr id="S4.T3.1.1.8.8" class="ltx_tr">
<td id="S4.T3.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">itâ€™s@!</td>
<td id="S4.T3.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">it</td>
<td id="S4.T3.1.1.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.8.8.3.1" class="ltx_text ltx_font_bold">0.068</span></td>
<td id="S4.T3.1.1.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.116</td>
<td id="S4.T3.1.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.136</td>
</tr>
<tr id="S4.T3.1.1.9.9" class="ltx_tr">
<td id="S4.T3.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">itâ€™s@!</td>
<td id="S4.T3.1.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.9.9.3.1" class="ltx_text ltx_font_bold">0.043</span></td>
<td id="S4.T3.1.1.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.119</td>
<td id="S4.T3.1.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.146</td>
</tr>
<tr id="S4.T3.1.1.10.10" class="ltx_tr">
<td id="S4.T3.1.1.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">is@!</td>
<td id="S4.T3.1.1.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.10.10.3.1" class="ltx_text ltx_font_bold">0.05</span></td>
<td id="S4.T3.1.1.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.125</td>
<td id="S4.T3.1.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.136</td>
</tr>
<tr id="S4.T3.1.1.11.11" class="ltx_tr">
<td id="S4.T3.1.1.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">itâ€™s@!</td>
<td id="S4.T3.1.1.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">is</td>
<td id="S4.T3.1.1.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.11.11.3.1" class="ltx_text ltx_font_bold">0.055</span></td>
<td id="S4.T3.1.1.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.133</td>
<td id="S4.T3.1.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.103</td>
</tr>
<tr id="S4.T3.1.1.12.12" class="ltx_tr">
<td id="S4.T3.1.1.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">are@!</td>
<td id="S4.T3.1.1.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.12.12.3.1" class="ltx_text ltx_font_bold">0.072</span></td>
<td id="S4.T3.1.1.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.162</td>
<td id="S4.T3.1.1.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.144</td>
</tr>
<tr id="S4.T3.1.1.13.13" class="ltx_tr">
<td id="S4.T3.1.1.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">dis@!</td>
<td id="S4.T3.1.1.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">this</td>
<td id="S4.T3.1.1.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.854</td>
<td id="S4.T3.1.1.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.83</td>
<td id="S4.T3.1.1.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.13.13.5.1" class="ltx_text ltx_font_bold">0.717</span></td>
</tr>
<tr id="S4.T3.1.1.14.14" class="ltx_tr">
<td id="S4.T3.1.1.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">it@!</td>
<td id="S4.T3.1.1.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.14.14.3.1" class="ltx_text ltx_font_bold">0.094</span></td>
<td id="S4.T3.1.1.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.311</td>
<td id="S4.T3.1.1.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.193</td>
</tr>
<tr id="S4.T3.1.1.15.15" class="ltx_tr">
<td id="S4.T3.1.1.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">he@!</td>
<td id="S4.T3.1.1.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.15.15.3.1" class="ltx_text ltx_font_bold">0.175</span></td>
<td id="S4.T3.1.1.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.254</td>
<td id="S4.T3.1.1.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.356</td>
</tr>
<tr id="S4.T3.1.1.16.16" class="ltx_tr">
<td id="S4.T3.1.1.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">de@!</td>
<td id="S4.T3.1.1.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.16.16.3.1" class="ltx_text ltx_font_bold">0.029</span></td>
<td id="S4.T3.1.1.16.16.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.123</td>
<td id="S4.T3.1.1.16.16.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.143</td>
</tr>
<tr id="S4.T3.1.1.17.17" class="ltx_tr">
<td id="S4.T3.1.1.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">the@!</td>
<td id="S4.T3.1.1.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.17.17.3.1" class="ltx_text ltx_font_bold">0.046</span></td>
<td id="S4.T3.1.1.17.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.24</td>
<td id="S4.T3.1.1.17.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.183</td>
</tr>
<tr id="S4.T3.1.1.18.18" class="ltx_tr">
<td id="S4.T3.1.1.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">in@!</td>
<td id="S4.T3.1.1.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.18.18.3.1" class="ltx_text ltx_font_bold">0.027</span></td>
<td id="S4.T3.1.1.18.18.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.127</td>
<td id="S4.T3.1.1.18.18.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.107</td>
</tr>
<tr id="S4.T3.1.1.19.19" class="ltx_tr">
<td id="S4.T3.1.1.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">you@!</td>
<td id="S4.T3.1.1.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.19.19.3.1" class="ltx_text ltx_font_bold">0.077</span></td>
<td id="S4.T3.1.1.19.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.113</td>
<td id="S4.T3.1.1.19.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.117</td>
</tr>
<tr id="S4.T3.1.1.20.20" class="ltx_tr">
<td id="S4.T3.1.1.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">i@!</td>
<td id="S4.T3.1.1.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.20.20.3.1" class="ltx_text ltx_font_bold">0.133</span></td>
<td id="S4.T3.1.1.20.20.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.248</td>
<td id="S4.T3.1.1.20.20.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.294</td>
</tr>
<tr id="S4.T3.1.1.21.21" class="ltx_tr">
<td id="S4.T3.1.1.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">on@!</td>
<td id="S4.T3.1.1.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.21.21.3.1" class="ltx_text ltx_font_bold">0.019</span></td>
<td id="S4.T3.1.1.21.21.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.129</td>
<td id="S4.T3.1.1.21.21.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.105</td>
</tr>
<tr id="S4.T3.1.1.22.22" class="ltx_tr">
<td id="S4.T3.1.1.22.22.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" colspan="2">Mean (n=20)</td>
<td id="S4.T3.1.1.22.22.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt"><span id="S4.T3.1.1.22.22.2.1" class="ltx_text ltx_font_bold">0.156</span></td>
<td id="S4.T3.1.1.22.22.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">0.265</td>
<td id="S4.T3.1.1.22.22.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">0.229</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>System comparison on 20 most frequent incorrectly transcribed speaker-errors. For each system, the number indicates the fraction of cases in which the system incorrectly transcribes the error <span id="S4.T3.5.1" class="ltx_text ltx_font_smallcaps">Target</span> as <span id="S4.T3.6.2" class="ltx_text ltx_font_smallcaps">Prediction</span> (where "_" denotes deletion of <span id="S4.T3.7.3" class="ltx_text ltx_font_smallcaps">Target</span>). The lowest value of each row is set in boldface. The final row shows the mean across the 20 samples.</figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:281.9pt;height:360pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.1pt,18.0pt) scale(0.909193263638839,0.909193263638839) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.2.1" class="ltx_text ltx_font_smallcaps">Prediction</span></td>
<td id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.3.1" class="ltx_text ltx_font_smallcaps">Chall-300M</span></td>
<td id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.4.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T4.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.5.1" class="ltx_text ltx_font_smallcaps">XLSR-1B</span></td>
</tr>
<tr id="S4.T4.1.1.2.2" class="ltx_tr">
<td id="S4.T4.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">have@!</td>
<td id="S4.T4.1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">have</td>
<td id="S4.T4.1.1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.2.2.3.1" class="ltx_text ltx_font_bold">0.875</span></td>
<td id="S4.T4.1.1.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.587</td>
<td id="S4.T4.1.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.699</td>
</tr>
<tr id="S4.T4.1.1.3.3" class="ltx_tr">
<td id="S4.T4.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">a@!</td>
<td id="S4.T4.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">a</td>
<td id="S4.T4.1.1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.3.3.3.1" class="ltx_text ltx_font_bold">0.804</span></td>
<td id="S4.T4.1.1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.215</td>
<td id="S4.T4.1.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.325</td>
</tr>
<tr id="S4.T4.1.1.4.4" class="ltx_tr">
<td id="S4.T4.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">is@!</td>
<td id="S4.T4.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">is</td>
<td id="S4.T4.1.1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.4.4.3.1" class="ltx_text ltx_font_bold">0.79</span></td>
<td id="S4.T4.1.1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.667</td>
<td id="S4.T4.1.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.769</td>
</tr>
<tr id="S4.T4.1.1.5.5" class="ltx_tr">
<td id="S4.T4.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">in@!</td>
<td id="S4.T4.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">in</td>
<td id="S4.T4.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.5.5.3.1" class="ltx_text ltx_font_bold">0.897</span></td>
<td id="S4.T4.1.1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.773</td>
<td id="S4.T4.1.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.807</td>
</tr>
<tr id="S4.T4.1.1.6.6" class="ltx_tr">
<td id="S4.T4.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">itâ€™s@!</td>
<td id="S4.T4.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">itâ€™s</td>
<td id="S4.T4.1.1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.6.6.3.1" class="ltx_text ltx_font_bold">0.703</span></td>
<td id="S4.T4.1.1.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.568</td>
<td id="S4.T4.1.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.482</td>
</tr>
<tr id="S4.T4.1.1.7.7" class="ltx_tr">
<td id="S4.T4.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">are@!</td>
<td id="S4.T4.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">are</td>
<td id="S4.T4.1.1.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.7.7.3.1" class="ltx_text ltx_font_bold">0.739</span></td>
<td id="S4.T4.1.1.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.688</td>
<td id="S4.T4.1.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.699</td>
</tr>
<tr id="S4.T4.1.1.8.8" class="ltx_tr">
<td id="S4.T4.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">on@!</td>
<td id="S4.T4.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">on</td>
<td id="S4.T4.1.1.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.8.8.3.1" class="ltx_text ltx_font_bold">0.917</span></td>
<td id="S4.T4.1.1.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.749</td>
<td id="S4.T4.1.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.79</td>
</tr>
<tr id="S4.T4.1.1.9.9" class="ltx_tr">
<td id="S4.T4.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">of@!</td>
<td id="S4.T4.1.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">of</td>
<td id="S4.T4.1.1.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.9.9.3.1" class="ltx_text ltx_font_bold">0.922</span></td>
<td id="S4.T4.1.1.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.705</td>
<td id="S4.T4.1.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.848</td>
</tr>
<tr id="S4.T4.1.1.10.10" class="ltx_tr">
<td id="S4.T4.1.1.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">the@!</td>
<td id="S4.T4.1.1.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">the</td>
<td id="S4.T4.1.1.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.10.10.3.1" class="ltx_text ltx_font_bold">0.815</span></td>
<td id="S4.T4.1.1.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.632</td>
<td id="S4.T4.1.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.678</td>
</tr>
<tr id="S4.T4.1.1.11.11" class="ltx_tr">
<td id="S4.T4.1.1.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">you@!</td>
<td id="S4.T4.1.1.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">you</td>
<td id="S4.T4.1.1.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.606</td>
<td id="S4.T4.1.1.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.55</td>
<td id="S4.T4.1.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.11.11.5.1" class="ltx_text ltx_font_bold">0.735</span></td>
</tr>
<tr id="S4.T4.1.1.12.12" class="ltx_tr">
<td id="S4.T4.1.1.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">she@!</td>
<td id="S4.T4.1.1.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">she</td>
<td id="S4.T4.1.1.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.12.12.3.1" class="ltx_text ltx_font_bold">0.867</span></td>
<td id="S4.T4.1.1.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.713</td>
<td id="S4.T4.1.1.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.774</td>
</tr>
<tr id="S4.T4.1.1.13.13" class="ltx_tr">
<td id="S4.T4.1.1.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">it@!</td>
<td id="S4.T4.1.1.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">it</td>
<td id="S4.T4.1.1.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.13.13.3.1" class="ltx_text ltx_font_bold">0.772</span></td>
<td id="S4.T4.1.1.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.579</td>
<td id="S4.T4.1.1.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.659</td>
</tr>
<tr id="S4.T4.1.1.14.14" class="ltx_tr">
<td id="S4.T4.1.1.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">has@!</td>
<td id="S4.T4.1.1.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">has</td>
<td id="S4.T4.1.1.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.14.14.3.1" class="ltx_text ltx_font_bold">0.825</span></td>
<td id="S4.T4.1.1.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.775</td>
<td id="S4.T4.1.1.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.774</td>
</tr>
<tr id="S4.T4.1.1.15.15" class="ltx_tr">
<td id="S4.T4.1.1.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">make@!</td>
<td id="S4.T4.1.1.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">make</td>
<td id="S4.T4.1.1.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.15.15.3.1" class="ltx_text ltx_font_bold">0.95</span></td>
<td id="S4.T4.1.1.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.746</td>
<td id="S4.T4.1.1.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.808</td>
</tr>
<tr id="S4.T4.1.1.16.16" class="ltx_tr">
<td id="S4.T4.1.1.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">do@!</td>
<td id="S4.T4.1.1.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">do</td>
<td id="S4.T4.1.1.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.16.16.3.1" class="ltx_text ltx_font_bold">0.82</span></td>
<td id="S4.T4.1.1.16.16.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.744</td>
<td id="S4.T4.1.1.16.16.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.748</td>
</tr>
<tr id="S4.T4.1.1.17.17" class="ltx_tr">
<td id="S4.T4.1.1.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">much@!</td>
<td id="S4.T4.1.1.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">much</td>
<td id="S4.T4.1.1.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.17.17.3.1" class="ltx_text ltx_font_bold">0.98</span></td>
<td id="S4.T4.1.1.17.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.96</td>
<td id="S4.T4.1.1.17.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.96</td>
</tr>
<tr id="S4.T4.1.1.18.18" class="ltx_tr">
<td id="S4.T4.1.1.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">he@!</td>
<td id="S4.T4.1.1.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">he</td>
<td id="S4.T4.1.1.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.18.18.3.1" class="ltx_text ltx_font_bold">0.679</span></td>
<td id="S4.T4.1.1.18.18.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.627</td>
<td id="S4.T4.1.1.18.18.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.561</td>
</tr>
<tr id="S4.T4.1.1.19.19" class="ltx_tr">
<td id="S4.T4.1.1.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">not@!</td>
<td id="S4.T4.1.1.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">not</td>
<td id="S4.T4.1.1.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.19.19.3.1" class="ltx_text ltx_font_bold">0.89</span></td>
<td id="S4.T4.1.1.19.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.75</td>
<td id="S4.T4.1.1.19.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.777</td>
</tr>
<tr id="S4.T4.1.1.20.20" class="ltx_tr">
<td id="S4.T4.1.1.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">at@!</td>
<td id="S4.T4.1.1.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">at</td>
<td id="S4.T4.1.1.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.20.20.3.1" class="ltx_text ltx_font_bold">0.811</span></td>
<td id="S4.T4.1.1.20.20.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.612</td>
<td id="S4.T4.1.1.20.20.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.759</td>
</tr>
<tr id="S4.T4.1.1.21.21" class="ltx_tr">
<td id="S4.T4.1.1.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">donâ€™t@!</td>
<td id="S4.T4.1.1.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">donâ€™t</td>
<td id="S4.T4.1.1.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.21.21.3.1" class="ltx_text ltx_font_bold">0.885</span></td>
<td id="S4.T4.1.1.21.21.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.826</td>
<td id="S4.T4.1.1.21.21.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.811</td>
</tr>
<tr id="S4.T4.1.1.22.22" class="ltx_tr">
<td id="S4.T4.1.1.22.22.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" colspan="2">Mean (n=20)</td>
<td id="S4.T4.1.1.22.22.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt"><span id="S4.T4.1.1.22.22.2.1" class="ltx_text ltx_font_bold">0.827</span></td>
<td id="S4.T4.1.1.22.22.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">0.673</td>
<td id="S4.T4.1.1.22.22.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">0.723</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>System comparison on 20 most frequent correctly preserved speaker-errors. For each system, the number indicates the fraction of cases in which the system correctly transcribes the error <span id="S4.T4.4.1" class="ltx_text ltx_font_smallcaps">Target</span> as <span id="S4.T4.5.2" class="ltx_text ltx_font_smallcaps">Prediction</span>. The highest value of each row is set in boldface. The final row shows the mean across the 20 samples.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Fine-tuning Pre-trained ASR Systems Using Learner Data</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To evaluate the impact of fine-tuning, we fine-tune the Wav2Vec-XLSR-300M modelÂ <span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Due to the high computational cost, we decided to use the 300M model instead of the 1B model.</span></span></span>Â <cite class="ltx_cite ltx_citemacro_cite">Babu etÂ al. (<a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite> on our collected language learner data.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Data Preprocessing.</span>
For fine-tuning, we split longer utterances into chunks of a maximum of 12 seconds and removed trailing pauses. The transcripts were preprocessed as follows:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Remove error annotations and other transcript conventions</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">Convert to lowercase</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Standardise text (Remove text between brackets and parentheses. Standardise apostrophes by removing spaces before them. Remove commas between digits and periods not followed by numbers.)</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">Clean and standardise whitespace</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p">Normalise/remove special characters.</p>
</div>
</li>
<li id="S4.I1.i6" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i6.p1" class="ltx_para">
<p id="S4.I1.i6.p1.1" class="ltx_p">Transform numbers into words using <span id="S4.I1.i6.p1.1.1" class="ltx_text ltx_font_italic">num2words</span></p>
</div>
</li>
</ul>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Approach.</span> We apply 5-fold cross-validation (cf. <a href="#S3.SS4.SSS1" title="3.4.1 Data Folds â€£ 3.4 Final Dataset â€£ 3 Dataset: Spontaneous Speech of Young Learners of English â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.1</span></a>), that is, we train on four folds, and evaluate on the held-out fold. We trained each run on 6 nVidia Tesla V100 GPUs for 4000 steps using a learning rate of 3e-5, a per-device batch size of 14, and 15 gradient accumulation steps (for a total batch size of 1260, which corresponds to approx. 2 hours of audio per batch), and we used the 8-bit AdamW optimizerÂ <cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a href="#bib.bib20" title="" class="ltx_ref">2017</a>); Dettmers etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>.
Our fine-tuned model, called ChaLL-300M, is available on HuggingFace.<a href="#footnote2" title="footnote 2 â€£ Contributions â€£ 1 Introduction â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Quantitative Results</h3>

<div id="S4.SS4.p1" class="ltx_para ltx_noindent">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_bold">Performance Metrics.</span> The scores achieved by the different models are summarised in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.1 Metrics â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Among the pre-trained models, <em id="S4.SS4.p1.1.2" class="ltx_emph ltx_font_italic">Whisper-Large</em> achieves the best overall WER and chrF scores. However, the best CERand WEPR scores were achieved by the <em id="S4.SS4.p1.1.3" class="ltx_emph ltx_font_italic">XLSR-1B</em> models fine-tuned on CommonVoice 6.1. This aligns with our expectations, as Whisper models are currently the most powerful ASR models, and we expected them to perform best in terms of WER. However, for our use-case, we are more interested in error preservation, thus, CTC-based models without language models are best for preserving the errors. The fine-tuning step on our dataset consisting of learner data yielded a significant boost in performance. It achieves the best WEPR score, which measures the error retention capability. The most comparable model in terms of number of parameters is the XLSR-53 model trained on adult read-aloud data. In comparison to this model, <em id="S4.SS4.p1.1.4" class="ltx_emph ltx_font_italic">ChaLL-300M</em> achieves an improvement of 8 points in WER and a 12-point improvement in WEPR. It is generally the case that larger models perform better. Thus, the interpretation of the results needs to factor this in. As most models are larger than ours, it becomes evident that fine-tuning on learner data increases the performance on this data in general, and the CTC architecture yields a better out-of-the-box preservation of speaker-errors .</p>
</div>
<figure id="S4.T5" class="ltx_table">
<div id="S4.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:175.7pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-62.1pt,29.5pt) scale(0.747982973837417,0.747982973837417) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.1.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T5.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r">Utterance</td>
<td id="S4.T5.1.1.1.1.3" class="ltx_td ltx_align_left">Err. Type.</td>
</tr>
<tr id="S4.T5.1.1.2.2" class="ltx_tr">
<td id="S4.T5.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T5.1.1.2.2.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T5.1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Yeah. Uhm itâ€™s â€“ It <span id="S4.T5.1.1.2.2.2.1" class="ltx_text" style="color:#FF0000;">have</span> a <span id="S4.T5.1.1.2.2.2.2" class="ltx_text" style="color:#FF8000;">Lampe</span>. Uhm you can â€“</td>
<td id="S4.T5.1.1.2.2.3" class="ltx_td ltx_align_left ltx_border_t">has/have, German</td>
</tr>
<tr id="S4.T5.1.1.3.3" class="ltx_tr">
<td id="S4.T5.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.3.3.1.1" class="ltx_text ltx_font_smallcaps">Chall300M</span></td>
<td id="S4.T5.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r">e uhm itâ€™s itâ€™s <span id="S4.T5.1.1.3.3.2.1" class="ltx_text" style="color:#FF0000;">have</span> a <span id="S4.T5.1.1.3.3.2.2" class="ltx_text" style="color:#FF8000;">lampe</span> you can</td>
<td id="S4.T5.1.1.3.3.3" class="ltx_td ltx_align_left">has/have, German</td>
</tr>
<tr id="S4.T5.1.1.4.4" class="ltx_tr">
<td id="S4.T5.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.4.4.1.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T5.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r">it has a lamp</td>
<td id="S4.T5.1.1.4.4.3" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S4.T5.1.1.5.5" class="ltx_tr">
<td id="S4.T5.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S4.T5.1.1.5.5.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T5.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">(â€¦) What youâ€™re rather be a (â€¦)- able <span id="S4.T5.1.1.5.5.2.1" class="ltx_text" style="color:#FF0000;">for</span> fly or be invisible- invisible?</td>
<td id="S4.T5.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_tt">for/to</td>
</tr>
<tr id="S4.T5.1.1.6.6" class="ltx_tr">
<td id="S4.T5.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.6.6.1.1" class="ltx_text ltx_font_smallcaps">Chall300M</span></td>
<td id="S4.T5.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r">wuld your reader be be aabble <span id="S4.T5.1.1.6.6.2.1" class="ltx_text" style="color:#FF0000;">for</span> fly or be invisible invisible</td>
<td id="S4.T5.1.1.6.6.3" class="ltx_td ltx_align_left">for/to</td>
</tr>
<tr id="S4.T5.1.1.7.7" class="ltx_tr">
<td id="S4.T5.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.7.7.1.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T5.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r">would your reader be able to fly or be invisible</td>
<td id="S4.T5.1.1.7.7.3" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S4.T5.1.1.8.8" class="ltx_tr">
<td id="S4.T5.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S4.T5.1.1.8.8.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T5.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Do you have <span id="S4.T5.1.1.8.8.2.1" class="ltx_text" style="color:#FF0000;">a</span> enemy?</td>
<td id="S4.T5.1.1.8.8.3" class="ltx_td ltx_align_left ltx_border_tt">a/an</td>
</tr>
<tr id="S4.T5.1.1.9.9" class="ltx_tr">
<td id="S4.T5.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.9.9.1.1" class="ltx_text ltx_font_smallcaps">Chall300M</span></td>
<td id="S4.T5.1.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r">do you have <span id="S4.T5.1.1.9.9.2.1" class="ltx_text" style="color:#FF0000;">a</span> enemey</td>
<td id="S4.T5.1.1.9.9.3" class="ltx_td ltx_align_left">a/an</td>
</tr>
<tr id="S4.T5.1.1.10.10" class="ltx_tr">
<td id="S4.T5.1.1.10.10.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.10.10.1.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T5.1.1.10.10.2" class="ltx_td ltx_align_left ltx_border_r">do you have an enemy</td>
<td id="S4.T5.1.1.10.10.3" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S4.T5.1.1.11.11" class="ltx_tr">
<td id="S4.T5.1.1.11.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S4.T5.1.1.11.11.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T5.1.1.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">What <span id="S4.T5.1.1.11.11.2.1" class="ltx_text" style="color:#FF0000;">do</span> you favourite food?</td>
<td id="S4.T5.1.1.11.11.3" class="ltx_td ltx_align_left ltx_border_tt">do/is</td>
</tr>
<tr id="S4.T5.1.1.12.12" class="ltx_tr">
<td id="S4.T5.1.1.12.12.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.12.12.1.1" class="ltx_text ltx_font_smallcaps">Chall300M</span></td>
<td id="S4.T5.1.1.12.12.2" class="ltx_td ltx_align_left ltx_border_r">what <span id="S4.T5.1.1.12.12.2.1" class="ltx_text" style="color:#FF0000;">do</span> you favorite food</td>
<td id="S4.T5.1.1.12.12.3" class="ltx_td ltx_align_left">do/is</td>
</tr>
<tr id="S4.T5.1.1.13.13" class="ltx_tr">
<td id="S4.T5.1.1.13.13.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span id="S4.T5.1.1.13.13.1.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T5.1.1.13.13.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">whatâ€™s your favorite food</td>
<td id="S4.T5.1.1.13.13.3" class="ltx_td ltx_align_left ltx_border_b">-</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Manually selected examples.</figcaption>
</figure>
<div id="S4.SS4.p2" class="ltx_para ltx_noindent">
<p id="S4.SS4.p2.1" class="ltx_p"><span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_bold">WEPR Analysis.</span> To show in more detail the reduction in WEPR, we compare the handling of specific speaker errors. TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.2 Pre-trained ASR Systems â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the confusion for the 20 most frequent examples, that is, the cases where the ASR system corrects a error it should have preserved. For each type of confusion, we report the rate at which it occurs. For instance, when the speaker mistakenly said "have" (denoted "have@!"), <em id="S4.SS4.p2.1.2" class="ltx_emph ltx_font_italic">ChaLL-300M</em> corrected it to "has" in 1.5% of cases, Whisper-Large corrected it in 23.1% of cases, and XLSR-1B in 12.9% of cases. Thus, <em id="S4.SS4.p2.1.3" class="ltx_emph ltx_font_italic">ChaLL-300M</em> preserved this particular kind of error the best. In total, it mistakenly corrected 15% of the 20 most frequent speaker-errors, while <em id="S4.SS4.p2.1.4" class="ltx_emph ltx_font_italic">Whisper-Large</em> corrected 26%, and <em id="S4.SS4.p2.1.5" class="ltx_emph ltx_font_italic">XLSR-1B</em> corrected 22.9%. It is interesting to note that two out of total three cases where <em id="S4.SS4.p2.1.6" class="ltx_emph ltx_font_italic">XLSR-1B</em> has the lowest rate of mis-correction is for pronunciation errors ("de@!" and "dis@!"). We also note that a majority of the most frequent unwanted error-corrections are deletions.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">On the other hand, TableÂ <a href="#S4.T4" title="Table 4 â€£ 4.2 Pre-trained ASR Systems â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the frequency at which the ASR systems correctly preserved the errors made by the speakers. For instance, when the speaker mistakenly says "have" (denoted as "have@!"), then <em id="S4.SS4.p3.1.1" class="ltx_emph ltx_font_italic">ChaLL-300M</em> preserves this error in 87.5% of cases, while <em id="S4.SS4.p3.1.2" class="ltx_emph ltx_font_italic">Whisper-Large</em> preserves it in only 58.7% and <em id="S4.SS4.p3.1.3" class="ltx_emph ltx_font_italic">XLSR-1B</em> in only 69.9% of cases. In total, <em id="S4.SS4.p3.1.4" class="ltx_emph ltx_font_italic">ChaLL-300M</em> is able to preserve 82.7% of the of the 20 most frequent errors made by speakers, while <em id="S4.SS4.p3.1.5" class="ltx_emph ltx_font_italic">Whisper-Large</em> only preserved 67.3% of speaker errors and <em id="S4.SS4.p3.1.6" class="ltx_emph ltx_font_italic">XLSR-1B</em> preserved 72.3%.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">Thus, <em id="S4.SS4.p4.1.1" class="ltx_emph ltx_font_italic">ChaLL-300M</em> displays a strong ability to preserve the errors made by speakers, which is crucial for the downstream task of providing automated corrective feedback.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Qualitative Results</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">TableÂ <a href="#S4.T5" title="Table 5 â€£ 4.4 Quantitative Results â€£ 4 Error-Preserving Automatic Speech Recognition â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows four manually selected examples, highlighting some errors which the best-performing pre-trained model, <em id="S4.SS5.p1.1.1" class="ltx_emph ltx_font_italic">Whisper-Large</em>, corrects, and our model preserves. In the first example, it shows the error of using "have" instead of "has", as well as using the German pronunciation of the word "lamp" (i.e., "Lampe"). <em id="S4.SS5.p1.1.2" class="ltx_emph ltx_font_italic">Whisper-Large</em> corrects these errors, and creates a grammatically correct English utterance. The <em id="S4.SS5.p1.1.3" class="ltx_emph ltx_font_italic">ChaLL-300M</em> model preserves these errors as desired. The second error is a prepositional error, where the learner said "for fly" instead of "to fly". The <em id="S4.SS5.p1.1.4" class="ltx_emph ltx_font_italic">Chall-300M</em> model correctly preserved this error, while the language model used in <em id="S4.SS5.p1.1.5" class="ltx_emph ltx_font_italic">Whisper-Large</em> smoothed out the error. The third example is an error of the indefinite article: the learner used "a" instead of "an", which <em id="S4.SS5.p1.1.6" class="ltx_emph ltx_font_italic">ChaLL-300M</em> correctly preserved while <em id="S4.SS5.p1.1.7" class="ltx_emph ltx_font_italic">Whisper-Large</em> corrected the error. The final example contains the usage of the wrong verb "do" instead of "is", which again is correctly preserved by our model while Whisper corrects the error.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Outlook</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our work shows that state-of-the-art ASR systems have difficulties handling young learnersâ€™ speech; furthermore, they tend to correct the errors made by the speakers, which makes the downstream identification of speaker errors and provision of corrective feedback impossible. Thus, we collected around 85 hours of childrenâ€™s language learner speech data, which we used to fine-tune a custom model. Our model outperforms all the others (including Whisper-Large) in terms of error preservation (Word-Based Error Preservation Rate, WEPR) and surpasses the English models of comparable size (<math id="S5.p1.1.m1.1" class="ltx_Math" alttext="\approx 300M" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml"></mi><mo id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">â‰ˆ</mo><mrow id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml"><mn id="S5.p1.1.m1.1.1.3.2" xref="S5.p1.1.m1.1.1.3.2.cmml">300</mn><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.3.1" xref="S5.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.1.1.3.3" xref="S5.p1.1.m1.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><approx id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">absent</csymbol><apply id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3"><times id="S5.p1.1.m1.1.1.3.1.cmml" xref="S5.p1.1.m1.1.1.3.1"></times><cn type="integer" id="S5.p1.1.m1.1.1.3.2.cmml" xref="S5.p1.1.m1.1.1.3.2">300</cn><ci id="S5.p1.1.m1.1.1.3.3.cmml" xref="S5.p1.1.m1.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\approx 300M</annotation></semantics></math> parameters) by a large margin in terms of Word Error Rate. Thus, our research shows the necessity of using targeted data (in this case, children who learn a foreign language) to fine-tune an ASR module, which is useful in downstream tasks. The focus of this work lies in a) investigating the utility of existing systems and b) creating an adequate ASR system that can be used as part of a language learning support tool to increase the studentsâ€™ speaking opportunities.
As a next step, we will investigate how to enhance error preservation. For this, training larger models is the most straightforward approach. However, we also plan to train the ASR system jointly with error annotations. For this, we started the creation of more detailed error annotations. Initial results have shown that verbal errors are the largest error category for young learners of English in Switzerland (with about 22% of all errors) , and within these, wrong subject-verb agreement is most frequent.
Similarly, investigating how to handle frequent code-switching to German words or sentence fragments is an unsolved issue that needs to be addressed to improve downstream tasks. Even <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">Whisper-Large</em>, which can handle multiple languages in principle, did not perform well in detecting code-switching.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Finally, we aim to evaluate ASR models in the context of integrating them with a conversational agent and corrective feedback.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by the Swiss Innovation Agency (Innosuisse) within the project "Towards a Voice-Based Chatbot for Language Learners (ChaLL)" [102.580.1 IP-ICT]. We thank the teachers and students who were part of the data collection for their efforts.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">While offering a unique tool for error-preserving ASR of young language learners, this work presents itself with a few limitations.</p>
</div>
<section id="Sx2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Limited Demographic.</h5>

<div id="Sx2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px1.p1.1" class="ltx_p">The dataset stems from a specific demographic of Swiss school children learning English in grades 4 to 6. An extension of the work would include language learners from other countries/with an academic language other than German/with a different language of instruction, or a larger range of ages. Thus, the transferability of our results must be confirmed with a different dataset.</p>
</div>
</section>
<section id="Sx2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Outsourcing Error Annotation.</h5>

<div id="Sx2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px2.p1.1" class="ltx_p">The outsourcing of transcription and error annotations always poses a risk of yielding erroneous data, since most transcribers are not trained in error annotation. We mitigated this risk by providing comprehensive guidelines and a steady exchange with the transcription agency. However, we plan to enhance the error annotations with a more detailed label set and annotators trained in this task.</p>
</div>
</section>
<section id="Sx2.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Small Model.</h5>

<div id="Sx2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px3.p1.1" class="ltx_p">Due to the high computational cost of fine-tuning a 1B parameter model, we limited ourselves to fine-tuning the 300M parameter XLSR model. Most research indicates that the usage of larger models yields better results; thus, there is still potential in terms of increasing WER and WEPR. However, our results showed that even a small model can preserve errors better than state-of-the-art pre-trained models, which was the main scope of this work.</p>
</div>
</section>
<section id="Sx2.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">No Performance Tuning.</h5>

<div id="Sx2.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px4.p1.1" class="ltx_p">Since the scope of this work is to understand if the usage of young learnersâ€™ speech data is beneficial for our purposes, we did not tune the performance of our model. That is, we did not perform any hyper-parameter tuning or any other methods to increase performance (e.g., joint prediction of errors using a language model). Thus, there is still a large margin of improvement using our dataset.</p>
</div>
</section>
<section id="Sx2.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data Availability.</h5>

<div id="Sx2.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px5.p1.1" class="ltx_p">Since our data consists of childrenâ€™s spontaneous speech, we must ensure its protection. Thus, we cannot make it freely available. While we publicly release the models trained on the data, access to the transcripts and recordings can only be granted in the scope of a joint project, subject to a collaboration agreement.</p>
</div>
</section>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">The main risks in this project have to do with data protection: all speakers are minors between 9 and 14 years of age, so their personal data must be very well safeguarded. Therefore, key government institutions approved the data collection before speakers were recruited, and informed consent was obtained from each speakerâ€™s legal caretaker (cp. details in Section <a href="#S3.SS1" title="3.1 Audio Recording â€£ 3 Dataset: Spontaneous Speech of Young Learners of English â€£ Error-preserving Automatic Speech Recognition of Young English Learnersâ€™ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
Consent forms entailed information about the nature of the project and data collection procedures, as well as a comprehensive description of the legal principles we followed to collect, use, and store voice data, transcripts, and annotations. The data protection measures we implemented for security and confidentiality were fully disclosed (e.g. password-protected documents, pseudonymisation, firewalls etc.) and risks to participants (e.g. potential voice recognition by project members) were outlined. Voice data and transcripts were pseudonymised by those project members who act as data owners before sharing them with other research partners and third parties.
Third-party access to the collected data will be enabled in a closely controlled setting consisting of a joint project with a collaboration agreement.</p>
</div>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Use of AI Assistants</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.1" class="ltx_p">ChatGPT was used to support the creation of some figures. No AI assistants were used to write the text of this paper.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmed etÂ al. (2021)</span>
<span class="ltx_bibblock">
Beena Ahmed, KirrieÂ J. Ballard, Denis Burnham, Tharmakulasingam Sirojan, Hadi Mehmood, Dominique Estival, Elise Baker, Felicity Cox, Joanne Arciuli, Titia Benders, Katherine Demuth, Barbara Kelly, ChloÃ© Diskin-Holdaway, Mostafa Shahin, Vidhyasaharan Sethu, Julien Epps, ChweeÂ Beng Lee, and Eliathamby Ambikairajah. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2021-2000" title="" class="ltx_ref ltx_href">AusKidTalk: An Auditory-Visual Corpus of 3- to 12-Year-Old Australian Childrenâ€™s Speech</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2021</em>, pages 3680â€“3684.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ardila etÂ al. (2020)</span>
<span class="ltx_bibblock">
R.Â Ardila, M.Â Branson, K.Â Davis, M.Â Henretty, M.Â Kohler, J.Â Meyer, R.Â Morais, L.Â Saunders, F.Â M. Tyers, and G.Â Weber. 2020.

</span>
<span class="ltx_bibblock">Common voice: A massively-multilingual speech corpus.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)</em>, pages 4211â€“4215.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Babu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, etÂ al. 2021.

</span>
<span class="ltx_bibblock">Xls-r: Self-supervised cross-lingual speech representation learning at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.09296</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski etÂ al. (2020)</span>
<span class="ltx_bibblock">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:12449â€“12460.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Batliner etÂ al. (2005)</span>
<span class="ltx_bibblock">
Anton Batliner, Mats Blomberg, Shona Dâ€™Arcy, Daniel Elenius, Diego Giuliani, Matteo Gerosa, Christian Hacker, Martin Russell, Stefan Steidl, and Michael Wong. 2005.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2005-705" title="" class="ltx_ref ltx_href">The PF_STAR childrenâ€™s speech corpus</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2005</em>, pages 2761â€“2764.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baur etÂ al. (2018)</span>
<span class="ltx_bibblock">
Claudia Baur, Andrew Caines, Cathy Chua, Johanna Gerlach, Mengjie Qian, Manny Rayner, Martin Russell, Helmer Strik, and Xizi Wei. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2018-97" title="" class="ltx_ref ltx_href">Overview of the 2018 spoken call shared task</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of Interspeech 2018</em>, Interspeech, pages 2354â€“2358. ISCA.

</span>
<span class="ltx_bibblock">Interspeech 2018 ; Conference date: 02-09-2018 Through 06-09-2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deriu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie Rosset, Eneko Agirre, and Mark Cieliebak. 2021.

</span>
<span class="ltx_bibblock">Survey on evaluation methods for dialogue systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence Review</em>, 54:755â€“810.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers etÂ al. (2021)</span>
<span class="ltx_bibblock">
Tim Dettmers, Mike Lewis, Sam Shleifer, and Luke Zettlemoyer. 2021.

</span>
<span class="ltx_bibblock">8-bit optimizers via block-wise quantization.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.02861</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ellis (2021)</span>
<span class="ltx_bibblock">
Rod Ellis. 2021.

</span>
<span class="ltx_bibblock">Explicit and Implicit Oral Corrective Feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">The Cambridge Handbook of Corrective Feedback in Second Language Learning and Teaching</em>, pages 341â€“364.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eskenazi (1996)</span>
<span class="ltx_bibblock">
MaxineÂ S Eskenazi. 1996.

</span>
<span class="ltx_bibblock">Kids: a database of childrenâ€™s speech.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">The Journal of the Acoustical Society of America</em>, 100(4_Supplement):2759â€“2759.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gerosa etÂ al. (2006)</span>
<span class="ltx_bibblock">
Matteo Gerosa, Diego Giuliani, and Shrikanth Narayanan. 2006.

</span>
<span class="ltx_bibblock">Acoustic analysis and automatic recognition of spontaneous childrenâ€™s speech.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Ninth International Conference on Spoken Language Processing</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gretter etÂ al. (2020)</span>
<span class="ltx_bibblock">
Roberto Gretter, Marco Matassoni, Stefano BannÃ², and Falavigna Daniele. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2020.lrec-1.47" title="" class="ltx_ref ltx_href">TLT-school: a corpus of non native children speech</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pages 378â€“385, Marseille, France. European Language Resources Association.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grimm etÂ al. (2015)</span>
<span class="ltx_bibblock">
Nancy Grimm, Michael Meyer, and Laurenz Volkmann. 2015.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Teaching English</em>.

</span>
<span class="ltx_bibblock">Narr Francke Attempto Verlag.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grosman (2021)</span>
<span class="ltx_bibblock">
Jonatas Grosman. 2021.

</span>
<span class="ltx_bibblock">Fine-tuned XLSR-53 large model for speech recognition in English.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grosman (2022)</span>
<span class="ltx_bibblock">
Jonatas Grosman. 2022.

</span>
<span class="ltx_bibblock">Fine-tuned XLS-R 1B model for speech recognition in English.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/jonatasgrosman/wav2vec2-xls-r-1b-english" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/jonatasgrosman/wav2vec2-xls-r-1b-english</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hagen etÂ al. (2003)</span>
<span class="ltx_bibblock">
Andreas Hagen, Bryan Pellom, and Ronald Cole. 2003.

</span>
<span class="ltx_bibblock">Childrenâ€™s speech recognition with application to interactive books and tutors.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">2003 IEEE Workshop on Automatic Speech Recognition and Understanding (IEEE Cat. No. 03EX721)</em>, pages 186â€“191. IEEE.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hedge (2001)</span>
<span class="ltx_bibblock">
Tricia Hedge. 2001.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Teaching and learning in the language classroom</em>, volume 106.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kleinschroth and Oldham (2014)</span>
<span class="ltx_bibblock">
Robert Kleinschroth and Pete Oldham. 2014.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Sprechkompetenz-Training im Englischunterricht 7-8: Lebensnahe SprechanlÃ¤sse und vielfÃ¤ltige Aufgaben (7. und 8. Klasse)</em>.

</span>
<span class="ltx_bibblock">Auer Verlag.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (1999)</span>
<span class="ltx_bibblock">
Sungbok Lee, Alexandros Potamianos, and Shrikanth Narayanan. 1999.

</span>
<span class="ltx_bibblock">Acoustics of childrenâ€™s speech: Developmental changes of temporal and spectral parameters.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">The Journal of the Acoustical Society of America</em>, 105(3):1455â€“1468.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2017)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2017.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.05101</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Renee Lu, Mostafa Shahin, and Beena Ahmed. 2022.

</span>
<span class="ltx_bibblock">Improving childrenâ€™s speech recognition by fine-tuning self-supervised adult speech representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.07769</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al. (2023)</span>
<span class="ltx_bibblock">
Rao Ma, Mengjie Qian, Mark Gales, and KatherineÂ M Knill. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/SLaTE.2023-20" title="" class="ltx_ref ltx_href">Adapting an ASR Foundation Model for Spoken Language Assessment</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proc. 9th Workshop on Speech and Language Technology in Education (SLaTE)</em>, pages 104â€“108.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malik etÂ al. (2021)</span>
<span class="ltx_bibblock">
Mishaim Malik, MuhammadÂ Kamran Malik, Khawar Mehmood, and Imran Makhdoom. 2021.

</span>
<span class="ltx_bibblock">Automatic speech recognition: a survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Multimedia Tools and Applications</em>, 80:9411â€“9457.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, and Erik Cambria. 2023.

</span>
<span class="ltx_bibblock">Recent advances in deep learning based dialogue systems: A systematic survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence review</em>, 56(4):3055â€“3155.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panayotov etÂ al. (2015)</span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. 2015.

</span>
<span class="ltx_bibblock">Librispeech: an asr corpus based on public domain audio books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on</em>, pages 5206â€“5210. IEEE.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfenninger and Lendl (2017)</span>
<span class="ltx_bibblock">
SimoneÂ E. Pfenninger and Johanna Lendl. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.14746/ssllt.2017.7.3.5" title="" class="ltx_ref ltx_href">Transitional woes: On the impact of l2 input continuity from primary to secondary school</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Studies in Second Language Learning and Teaching</em>, 7(3):443â€“469.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">PopoviÄ‡ (2015)</span>
<span class="ltx_bibblock">
Maja PopoviÄ‡. 2015.

</span>
<span class="ltx_bibblock">chrf: character n-gram f-score for automatic mt evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the tenth workshop on statistical machine translation</em>, pages 392â€“395.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Potamianos and Narayanan (2003)</span>
<span class="ltx_bibblock">
A.Â Potamianos and S.Â Narayanan. 2003.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/TSA.2003.818026" title="" class="ltx_ref ltx_href">Robust recognition of childrenâ€™s speech</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Speech and Audio Processing</em>, 11(6):603â€“616.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pradhan etÂ al. (2016)</span>
<span class="ltx_bibblock">
Sameer Pradhan, Ron Cole, and Wayne Ward. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P16-4021" title="" class="ltx_ref ltx_href">My science Tutorâ€”Learning science with a conversational virtual tutor</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of ACL-2016 System Demonstrations</em>, pages 121â€“126, Berlin, Germany. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2022)</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2212.04356" title="" class="ltx_ref ltx_href">Robust Speech Recognition via Large-Scale Weak Supervision</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rumberg etÂ al. (2022)</span>
<span class="ltx_bibblock">
Lars Rumberg, Christopher Gebauer, Hanna Ehlert, Maren Wallbaum, Lena Bornholt, JÃ¶rn Ostermann, and Ulrike LÃ¼dtke. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2022-330" title="" class="ltx_ref ltx_href">kidsTALC: A Corpus of 3- to 11-year-old German Childrenâ€™s Connected Natural Speech</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2022</em>, pages 5160â€“5164.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shivakumar and Georgiou (2020)</span>
<span class="ltx_bibblock">
PrashanthÂ Gurunath Shivakumar and Panayiotis Georgiou. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.csl.2020.101077" title="" class="ltx_ref ltx_href">Transfer learning from adult to children for speech recognition: Evaluation, analysis and recommendations</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, 63:101077.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shivakumar and Narayanan (2022)</span>
<span class="ltx_bibblock">
PrashanthÂ Gurunath Shivakumar and Shrikanth Narayanan. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.csl.2021.101289" title="" class="ltx_ref ltx_href">End-to-end neural systems for automatic children speech recognition: An empirical study</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, 72:101289.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shobaki etÂ al. (2000)</span>
<span class="ltx_bibblock">
Khaldoun Shobaki, John-Paul Hosom, and RonaldÂ A. Cole. 2000.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/ICSLP.2000-800" title="" class="ltx_ref ltx_href">The OGI kidsÂ² speech corpus and recognizers</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proc. 6th International Conference on Spoken Language Processing (ICSLP 2000)</em>, pages vol. 4, 258â€“261.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ward etÂ al. (2019)</span>
<span class="ltx_bibblock">
Wayne Ward, Ron Cole, and Sameer Pradhan. 2019.

</span>
<span class="ltx_bibblock">My science tutor and the myst corpus.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Boulder Learn. Inc</em>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.03234" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.03235" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.03235">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.03235" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.03236" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 18:08:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
