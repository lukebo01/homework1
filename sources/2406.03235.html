<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.03235] Error-preserving Automatic Speech Recognition of Young English Learners’ Language</title><meta property="og:description" content="One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. Recent advances in sp…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Error-preserving Automatic Speech Recognition of Young English Learners’ Language">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Error-preserving Automatic Speech Recognition of Young English Learners’ Language">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.03235">

<!--Generated on Fri Jul  5 18:08:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Error-preserving Automatic Speech Recognition of Young English Learners’ Language</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Janick Michot<sup id="id1.1.id1" class="ltx_sup">1</sup>, Manuela Hürlimann<sup id="id2.2.id2" class="ltx_sup">1</sup>, Jan Deriu<sup id="id3.3.id3" class="ltx_sup">1</sup>, Luzia Sauer<sup id="id4.4.id4" class="ltx_sup">2</sup>. 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_bold">Katsiaryna Mlynchyk <sup id="id5.5.id5.1" class="ltx_sup">1</sup>, Mark Cieliebak<sup id="id5.5.id5.2" class="ltx_sup">1</sup></span> 
<br class="ltx_break"><sup id="id6.6.id6" class="ltx_sup">1</sup> Zurich University of Applied Sciences, Winterthur 
<br class="ltx_break"><sup id="id7.7.id7" class="ltx_sup">2</sup> Pädagogische Hochschule Zurich, Zurich
<br class="ltx_break">mict@zhaw.ch, hueu@zhaw.ch, deri@zhaw.ch, luzia.sauer@phzh.ch, 
<br class="ltx_break">mlyn@zhaw.ch, ciel@zhaw.ch
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">One of the central skills that language learners need to practice is speaking the language. Currently, students in school do not get enough speaking opportunities and lack conversational practice. Recent advances in speech technology and natural language processing allow for the creation of novel tools to practice their speaking skills. In this work, we tackle the first component of such a pipeline, namely, the automated speech recognition module (ASR), which faces a number of challenges: first, state-of-the-art ASR models are often trained on adult read-aloud data by native speakers and do not transfer well to young language learners’ speech. Second, most ASR systems contain a powerful language model, which smooths out errors made by the speakers. To give corrective feedback, which is a crucial part of language learning, the ASR systems in our setting need to preserve the errors made by the language learners. In this work, we build an ASR system that satisfies these requirements: it works on spontaneous speech by young language learners and preserves their errors. For this, we collected a corpus containing around 85 hours of English audio spoken by learners in Switzerland from grades 4 to 6 on different language learning tasks, which we used to train an ASR model. Our experiments show that our model benefits from direct fine-tuning on children’s voices and has a much higher error preservation rate than other models.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.1" class="ltx_block ltx_align_bottom">
<p id="p1.1.1" class="ltx_p"><span id="p1.1.1.1" class="ltx_text ltx_font_bold">Error-preserving Automatic Speech Recognition of Young English Learners’ Language</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.1.2" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.1.2.1" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.1.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.1.1.1.1" class="ltx_tr">
<span id="p1.1.2.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">
Janick Michot<sup id="p1.1.2.1.1.1.1.1.1.1" class="ltx_sup">1</sup>, Manuela Hürlimann<sup id="p1.1.2.1.1.1.1.1.1.2" class="ltx_sup">1</sup>, Jan Deriu<sup id="p1.1.2.1.1.1.1.1.1.3" class="ltx_sup">1</sup>, Luzia Sauer<sup id="p1.1.2.1.1.1.1.1.1.4" class="ltx_sup">2</sup>.</span></span></span>
<span id="p1.1.2.1.1.2.2" class="ltx_tr">
<span id="p1.1.2.1.1.2.2.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.2.2.1.1" class="ltx_text ltx_font_bold">Katsiaryna Mlynchyk <sup id="p1.1.2.1.1.2.2.1.1.1" class="ltx_sup">1</sup>, Mark Cieliebak<sup id="p1.1.2.1.1.2.2.1.1.2" class="ltx_sup">1</sup></span></span></span>
<span id="p1.1.2.1.1.3.3" class="ltx_tr">
<span id="p1.1.2.1.1.3.3.1" class="ltx_td ltx_align_center"><sup id="p1.1.2.1.1.3.3.1.1" class="ltx_sup">1</sup> Zurich University of Applied Sciences, Winterthur</span></span>
<span id="p1.1.2.1.1.4.4" class="ltx_tr">
<span id="p1.1.2.1.1.4.4.1" class="ltx_td ltx_align_center"><sup id="p1.1.2.1.1.4.4.1.1" class="ltx_sup">2</sup> Pädagogische Hochschule Zurich, Zurich</span></span>
<span id="p1.1.2.1.1.5.5" class="ltx_tr">
<span id="p1.1.2.1.1.5.5.1" class="ltx_td ltx_align_center">mict@zhaw.ch, hueu@zhaw.ch, deri@zhaw.ch, luzia.sauer@phzh.ch,</span></span>
<span id="p1.1.2.1.1.6.6" class="ltx_tr">
<span id="p1.1.2.1.1.6.6.1" class="ltx_td ltx_align_center">mlyn@zhaw.ch, ciel@zhaw.ch</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Speaking is one of the core competencies to be developed in foreign language classes and
the second most widely used skill in everyday-life communication <cite class="ltx_cite ltx_citemacro_cite">Hedge (<a href="#bib.bib17" title="" class="ltx_ref">2001</a>)</cite>. For students to successfully acquire speaking competencies, they must be trained from an early stage in the language learning process and in a systematic manner. However, speech production is a highly complex process that is often not addressed adequately in classrooms. The main issue is that students often do not get enough speaking opportunities <cite class="ltx_cite ltx_citemacro_cite">Kleinschroth and Oldham (<a href="#bib.bib18" title="" class="ltx_ref">2014</a>); Grimm et al. (<a href="#bib.bib13" title="" class="ltx_ref">2015</a>)</cite>, and lack extended conversational practice <cite class="ltx_cite ltx_citemacro_cite">Pfenninger and Lendl (<a href="#bib.bib26" title="" class="ltx_ref">2017</a>)</cite>. The recent advancements in both speech processing <cite class="ltx_cite ltx_citemacro_cite">Malik et al. (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, and conversational dialogue systems <cite class="ltx_cite ltx_citemacro_cite">Deriu et al. (<a href="#bib.bib7" title="" class="ltx_ref">2021</a>); Ni et al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite> provide an opportunity to increase the speaking practice of language learners using automated tools.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The work presented in this paper is part of a larger effort to develop an interactive, voice-driven chatbot with which learners can practice their interactive speaking skills. The bot is designed as a conversation partner that adjusts to the proficiency level and interests of the students and provides corrective feedback to support their language development.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">One key issue is the automated speech recognition (ASR) module, which transcribes the utterances of the language learners into text to be processed in downstream tasks (e.g., speaker-error analysis, dialogue systems, inter alia). The focus of this work is to adapt the ASR module to handle children’s speech in a language learning environment. The core challenge for the ASR system in this setting is not only to transcribe the speech but to make sure that the errors made by the language learners are transcribed faithfully. This is needed to provide language learners with corrective feedback, which is a key component of foreign language development. It prompts learners to notice errors and is likely to lead to utterance repair, which, in turn, facilitates language development <cite class="ltx_cite ltx_citemacro_cite">Ellis (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>. Our investigations showed that current state-of-the-art ASR models tend to correct the speakers’ errors, which renders giving corrective feedback impossible.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The second challenge for the ASR system is handling spontaneous children’s speech since most of these systems are trained on adult read-aloud error-free corpora recorded by native speakers <cite class="ltx_cite ltx_citemacro_cite">Panayotov et al. (<a href="#bib.bib25" title="" class="ltx_ref">2015</a>); Ardila et al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>. Children’s speech, especially spontaneous speech of language learners, differs significantly from read-aloud speech of native adult speakers <cite class="ltx_cite ltx_citemacro_cite">Shivakumar and Georgiou (<a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>. Children’s’ speech has a different range of sound frequencies <cite class="ltx_cite ltx_citemacro_cite">Potamianos and Narayanan (<a href="#bib.bib28" title="" class="ltx_ref">2003</a>)</cite>, a high within-subjects variability <cite class="ltx_cite ltx_citemacro_cite">Gerosa et al. (<a href="#bib.bib11" title="" class="ltx_ref">2006</a>)</cite> and a high inter-speaker variability in different age groups <cite class="ltx_cite ltx_citemacro_cite">Lee et al. (<a href="#bib.bib19" title="" class="ltx_ref">1999</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">These challenges yield three research questions, which we address in this work:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">How can we measure error preservation, i.e. the "verbatimness" of an ASR transcript?</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">How well do current pre-trained ASR systems perform on learners’ spontaneous English productions, with respect to error preservation and in general?</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Does fine-tuning pre-trained systems with data from young learners lead to improved error preservation in the ASR transcripts?</p>
</div>
</li>
</ol>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Contributions</h5>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">In order to answer these questions, we first collected a dataset of young learners in Swiss public schools speaking English, consisting of 85 hours of recordings corresponding to 45’004 individual utterances by 327 distinct speakers. We subsequently created verbatim transcriptions of these recordings, in which learner errors are annotated using specific symbols. This dataset can be accessed on HuggingFace<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://huggingface.co/datasets/mict-zhaw/chall" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/mict-zhaw/chall</a></span></span></span>, but the dataset files must be downloaded manually as described in Section <a href="#S3.SS4.SSS2" title="3.4.2 Data Availability ‣ 3.4 Final Dataset ‣ 3 Dataset: Spontaneous Speech of Young Learners of English ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.2</span></a> below. We next developed a metric for error preservation, called <em id="S1.SS0.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">Word-Based Error Preservation Rate (WEPR)</em>, which takes into account only those reference words that contain an error annotation. Using WEPR and standard ASR metrics, we compared 7 pre-trained ASR systems with a custom fine-tuned model<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://huggingface.co/mict-zhaw/chall_wav2vec2_xlsr_300m" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/mict-zhaw/chall_wav2vec2_xlsr_300m</a></span></span></span>. Our results show that a) there are large differences between the pre-trained models both in terms of standard metrics and in terms of WEPR and b) fine-tuning significantly improves error preservation of learners’ speech. All related code can be accessed on GitHub<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/mict-zhaw/chall_e2e_stt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/mict-zhaw/chall_e2e_stt</a></span></span></span>.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Children’s Speech Corpora.</span> Corpora of children’s speech can be divided into two types: i) corpora for native speaking children intended for building virtual tutors for non-language subjects, ii) corpora for young language learners that support building virtual tutors for language learning.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The MyST Children’s Speech Corpus <cite class="ltx_cite ltx_citemacro_cite">Pradhan et al. (<a href="#bib.bib29" title="" class="ltx_ref">2016</a>); Ward et al. (<a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite> contains 499 hours of conversational speech (out of which 233 hours are manually transcribed) for a virtual tutor for science topics targeted at young English native speakers. The OGI Kids’ Speech Corpus <cite class="ltx_cite ltx_citemacro_cite">Shobaki et al. (<a href="#bib.bib34" title="" class="ltx_ref">2000</a>)</cite> contains spontaneous speech from 1100 American children from kindergarten through grade 10, mainly consisting of scripted speech in the form of words and utterances, and a small sample of spontaneous speech. The AusKidTalk corpus <cite class="ltx_cite ltx_citemacro_cite">Ahmed et al. (<a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite> contains speech from Australian children ages 3 to 12 consisting of single words, utterances, and narrative speech. Other, smaller, datasets of native speaking children are available for different purposes such as read-aloud support <cite class="ltx_cite ltx_citemacro_cite">Eskenazi (<a href="#bib.bib10" title="" class="ltx_ref">1996</a>)</cite> or general analysis of English children’s speech <cite class="ltx_cite ltx_citemacro_cite">Lee et al. (<a href="#bib.bib19" title="" class="ltx_ref">1999</a>); Hagen et al. (<a href="#bib.bib16" title="" class="ltx_ref">2003</a>)</cite>. For German, the KidsTalk corpus <cite class="ltx_cite ltx_citemacro_cite">Rumberg et al. (<a href="#bib.bib31" title="" class="ltx_ref">2022</a>)</cite> contains 25 hours of transcribed continuous speech from children aged 3 to 11. All these corpora are devised for settings with native speakers.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">For language learners, there are far fewer datasets of children’s speech. The TLT-school collection <cite class="ltx_cite ltx_citemacro_cite">Gretter et al. (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> aims at assessing the proficiency of 9- to 16-year old Italian native speakers in English and German. TLT was recorded with a pool of 3000 students, resulting in approximately 275h of English and 265h of German data, out of which 16h for English and 8h for German have been transcribed. The corpus closest to our dataset is the CALL corpus <cite class="ltx_cite ltx_citemacro_cite">Baur et al. (<a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite>, consisting of English utterances by Swiss German second and third year learners, where the task is to label the correctness of each utterance. In total, the corpus contains 38k utterances of students interacting with an online dialogue system, where they receive various prompts to produce speech. Across a series of shared tasks, subsets of around 6k annotated utterances have been released. The setting differs significantly from ours as we are interested in spontaneous speech with transcriptions to train an ASR system which can automatically transcribe learners’ speech verbatim. <cite class="ltx_cite ltx_citemacro_citet">Batliner et al. (<a href="#bib.bib5" title="" class="ltx_ref">2005</a>)</cite> introduce a children’s speech corpus containing 60 hours of children’s speech aged 4-13 in a variety of languages, such as English, German, and Swedish, as well as English speech from German, Italian, and Swedish children. In general, there is only a limited amount of work investigating the effects of fine-tuning models on speech data of language learners to retain the speakers’ errors.  <cite class="ltx_cite ltx_citemacro_citet">Ma et al. (<a href="#bib.bib22" title="" class="ltx_ref">2023</a>)</cite> fine-tune Whisper to investigate its ability to retain hesitations, numbers, abbreviations, disfluencies, and incomplete words. Instead, we aim to preserve speaker errors in grammar, lexical choice, and pronunciation.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">ASR for children’s speech and language learners.</span>
The literature on ASR models for children’s speech, especially for non-native language learners, is sparse. Most notably, <cite class="ltx_cite ltx_citemacro_citet">Lu et al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite> investigated the performance of fine-tuning wav2vec 2.0 <cite class="ltx_cite ltx_citemacro_cite">Baevski et al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> on children’s speech (both native MyST and OGI), as well as non-native speech (TLT) compared to fine-tuning on adult-only data. The results show that ASR models trained on children’s speech significantly outperform those models trained on adult-speech only, even in the case of non-native speakers. Similarly, <cite class="ltx_cite ltx_citemacro_citet">Shivakumar and Narayanan (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> investigated the impact of using children’s data for fine-tuning ASR models. The conclusion is similar to <cite class="ltx_cite ltx_citemacro_citet">Lu et al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>: adding children’s data yields better performance; however, the performance of an adult ASR model on adult data is higher than the performance of an ASR model trained and applied on children’s data. While both <cite class="ltx_cite ltx_citemacro_citet">Lu et al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Shivakumar and Narayanan (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> are interested in the overall performance in terms of WER, our work focuses on the preservation of errors made by non-native children.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset: Spontaneous Speech of Young Learners of English</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We now describe the dataset that we collected for the purpose of this research. It contains 85 hours of audio recordings of spontaneous speech by young young learners of English in Switzerland. Each recording is paired with a verbatim transcript that contains error annotations.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Audio Recording</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The recording setup was designed such that the collected speech resembled the kind of conversations intended for the learners to hold with the chatbot.
We used playful and engaging activities targeted to elicit extended authentic communication from young learners. Activities included role plays with problem-solving components (e.g. ‘going shopping for a school trip’), guessing games (e.g. riddles), TV interviews with imaginary characters and asking/answering personal questions (e.g. ‘if you could go into space, what would you take with you?’). All activities were piloted with a grade 4 class and maintained, adjusted (to yield more data) or rejected (e.g. because the task led to students communicating non-verbally and/or with much noise) for the main data collection period. To support learners, each activity further included visual and language support (e.g. cartoon characters they could choose from, sample dialogues, language chunks) as well as a preparation phase during which the students could familiarise themselves with the tasks by use of example sentences and model dialogues.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>The descriptions of the speaking activities is provided in the repository.</span></span></span></p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Speaker recruitment and consent</span>
After receiving permission to collect audio data with minors from key government institutions that act as ethics review boards in Switzerland concerning research with schools and their learners, we recruited 20 primary school teachers interested in participating in our project with their classes (via personal and university networks, newsletters and direct contact with schools). Participation was entirely voluntary and could be withdrawn at any time. Participation further necessitated the approval of the school principal and the written consent of each student’s legal caretaker.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>We share the consent forms in our repository.</span></span></span></p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In the span of 9 months (March-November 2023), 337 primary school students aged 9 to 14 years (4th to 6th graders) enrolled in 8 different schools in German-speaking Switzerland performed our activities in pairs, trios or alone (if necessary) in three different settings: at school recorded by project members; on the university campus recorded by project members and student assistants; and at school recorded by teachers and sent to us via safe weblinks. For reasons of practicability/feasibility (i.e., to respect teachers’ tight schedules, time, and finances), the corpus was not annotated for CEFR levels, but according to the Swiss curriculum LP21, it should reflect performance at the A1 and A2 levels (English Basic Users). Some participants, including native-speaking children, performed beyond these levels.
School principals, teachers, and students were not remunerated for their participation but received small tokens of appreciation, such as flowers and chocolates.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Metadata</span> Each recording is associated with the following metadata:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">School area code: an integer between 1 and 8 (inclusive)</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">School grade of the speakers: 4gr, 5gr, 6gr as well as combinations (4/5gr, 5/6gr, 4/6gr)</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Recording Device</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Recording Application</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p">Speaking activities</p>
</div>
</li>
<li id="S3.I1.i6" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i6.p1" class="ltx_para">
<p id="S3.I1.i6.p1.1" class="ltx_p">Background Noise: a boolean indicating whether background noise is audible in the recording (set manually by project members).</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Transcription and Error Annotation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The transcription of our voice data was outsourced to a transcription agency. Services included both the transcription of the voice data and the annotation of lexical, grammatical and pronunciation errors, as well as usage of German words. We developed a comprehensive data transcription guideline for the transcription agency which was first piloted on a small number of transcripts and then adjusted where necessary.
Transcription guidelines included information about spelling conventions (British English), the frequency and nature of timestamps (start and end time of each word, in milliseconds), error codes (@! for errors of any kind and @g for German words) and disfluency markers (e.g. a hyphen "–" for verbatim repetitions, such as ‘he’s – he’s really tall’). The complete transcription guidelines are provided in the supplementary material of this paper.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Data Aggregation and Filtering</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The recording stage resulted in 1039 audio recordings. Of these, 23 were removed due to missing metadata or missing/retracted consent, so a total of 1016 recordings and their associated metadata and transcriptions were available for our experiments.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">These recordings were split into individual utterances by a single speaker using the word-level timestamps provided in the transcripts, resulting in 49’608 utterances.We removed utterances shorter than 0.5 seconds and utterances attributed to adults (e.g. short interventions by teachers), creating a final dataset of 45’004 utterances corresponding to 85 hours of audio. Each utterance was paired with its reference transcription and metadata.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Final Dataset</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The final dataset contains 45’004 utterances by 327 distinct speakers. Figure <a href="#S3.F1" title="Figure 1 ‣ 3.4 Final Dataset ‣ 3 Dataset: Spontaneous Speech of Young Learners of English ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the number of recordings and audio duration by school grades and school area codes. Almost half the data in terms of both utterances and hours comes from 6th graders, while the other half is split among the other grades.
The dataset contains 485,770 tokens and 10,203 distinct types. There are 14,396 error-annotated tokens with 2,004 underlying types. Thus, our data contains a large amount of tokens and a relatively large amount of token diversity.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2406.03235/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="173" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Number of utterances (outer ring) and audio hours (inner ring) by school grade (a) and school area code (b).</figcaption>
</figure>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">The length distribution is shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.4 Final Dataset ‣ 3 Dataset: Spontaneous Speech of Young Learners of English ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. It can be seen that most utterances are between 0.5 and 20 seconds long.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2406.03235/assets/figures/3_3_1_length_distribution_of_utterances.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="281" height="141" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Distribution of utterance lengths.</figcaption>
</figure>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Data Folds</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">For the experiments in this paper, we split the dataset into five distinct folds of similar duration (about 16h each), where each class (and therefore also each speaker) occurs in only one fold. To simulate the use case of the ASR system being confronted with a new class of learners, each fold contains data from a mix of grades. Figure <a href="#S3.F3" title="Figure 3 ‣ 3.4.1 Data Folds ‣ 3.4 Final Dataset ‣ 3 Dataset: Spontaneous Speech of Young Learners of English ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> visualises the duration and grade distribution of each fold.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2406.03235/assets/figures/3_4_data_folds_duration.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="269" height="201" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Duration and grade distribution of the data folds.</figcaption>
</figure>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>Data Availability</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">The dataset that we collected contains sensitive data of minors and thus cannot be shared publicly. The data can, however, be accessed as part of a joint project with one or several of the original project partners, subject to a collaboration agreement. Before sharing, all transcripts will undergo complete anonymisation so that any names and other personal information are removed.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Error-Preserving Automatic Speech Recognition</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents the metrics used for measuring error preservation and evaluating systems (Section <a href="#S4.SS1" title="4.1 Metrics ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>), as well as the approaches to comparing pre-trained ASR systems (Section <a href="#S4.SS2" title="4.2 Pre-trained ASR Systems ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>) and to fine-tuning existing systems using our learner dataset (Section <a href="#S4.SS3" title="4.3 Fine-tuning Pre-trained ASR Systems Using Learner Data ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>). The qualitative results are presented and discussed in Section <a href="#S4.SS4" title="4.4 Quantitative Results ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>, and a qualitative evaluation is shared in <a href="#S4.SS5" title="4.5 Qualitative Results ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.5</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Metrics</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.5" class="ltx_p">In order to measure error preservation, we use the error annotations that were manually added to each utterance (cp. Section <a href="#S3.SS2" title="3.2 Transcription and Error Annotation ‣ 3 Dataset: Spontaneous Speech of Young Learners of English ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>) and a custom phonetic word-level alignment algorithm. This algorithm aligns two or more sequences (e.g., a reference and one or multiple hypotheses), identifying matches, substitutions (S), insertions (I), and deletions (D) at the word level. Our metric, WEPR (Word-Based Error Preservation Rate), considers only those word pairs where the reference word contains an error annotation. WEPR is calculated according to equation <a href="#S4.E1" title="In 4.1 Metrics ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>:
<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\mathcal{A}</annotation></semantics></math> is the set of annotations that are considered (e.g. <math id="S4.SS1.p1.2.m2.2" class="ltx_Math" alttext="\mathcal{A=\{\mathtt{@!},\mathtt{@g}\}}" display="inline"><semantics id="S4.SS1.p1.2.m2.2a"><mrow id="S4.SS1.p1.2.m2.2.2" xref="S4.SS1.p1.2.m2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.2.m2.2.2.4" xref="S4.SS1.p1.2.m2.2.2.4.cmml">𝒜</mi><mo id="S4.SS1.p1.2.m2.2.2.3" xref="S4.SS1.p1.2.m2.2.2.3.cmml">=</mo><mrow id="S4.SS1.p1.2.m2.2.2.2.2" xref="S4.SS1.p1.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S4.SS1.p1.2.m2.2.2.2.2.3" xref="S4.SS1.p1.2.m2.2.2.2.3.cmml">{</mo><mrow id="S4.SS1.p1.2.m2.1.1.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S4.SS1.p1.2.m2.1.1.1.1.1.2" xref="S4.SS1.p1.2.m2.1.1.1.1.1.2.cmml">@</mi><mo id="S4.SS1.p1.2.m2.1.1.1.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.1.1.1.cmml">!</mo></mrow><mo id="S4.SS1.p1.2.m2.2.2.2.2.4" xref="S4.SS1.p1.2.m2.2.2.2.3.cmml">,</mo><mrow id="S4.SS1.p1.2.m2.2.2.2.2.2" xref="S4.SS1.p1.2.m2.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S4.SS1.p1.2.m2.2.2.2.2.2.2" xref="S4.SS1.p1.2.m2.2.2.2.2.2.2.cmml">@</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.2.2.2.2.2.1" xref="S4.SS1.p1.2.m2.2.2.2.2.2.1.cmml">​</mo><mi id="S4.SS1.p1.2.m2.2.2.2.2.2.3" xref="S4.SS1.p1.2.m2.2.2.2.2.2.3.cmml">𝚐</mi></mrow><mo stretchy="false" id="S4.SS1.p1.2.m2.2.2.2.2.5" xref="S4.SS1.p1.2.m2.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.2b"><apply id="S4.SS1.p1.2.m2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2"><eq id="S4.SS1.p1.2.m2.2.2.3.cmml" xref="S4.SS1.p1.2.m2.2.2.3"></eq><ci id="S4.SS1.p1.2.m2.2.2.4.cmml" xref="S4.SS1.p1.2.m2.2.2.4">𝒜</ci><set id="S4.SS1.p1.2.m2.2.2.2.3.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2"><apply id="S4.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.1"><factorial id="S4.SS1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.1.1"></factorial><ci id="S4.SS1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.1.2">@</ci></apply><apply id="S4.SS1.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2"><times id="S4.SS1.p1.2.m2.2.2.2.2.2.1.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2.1"></times><ci id="S4.SS1.p1.2.m2.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2.2">@</ci><ci id="S4.SS1.p1.2.m2.2.2.2.2.2.3.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2.3">𝚐</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.2c">\mathcal{A=\{\mathtt{@!},\mathtt{@g}\}}</annotation></semantics></math>), <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\mathcal{S}</annotation></semantics></math> and <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><ci id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">\mathcal{D}</annotation></semantics></math> are the number of substitutions and deletions, respectively, where the reference word contains an error annotation, and <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">𝒩</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">𝒩</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">\mathcal{N}</annotation></semantics></math> is the total number of reference words that contain an error annotation.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span id="S4.E1.m1.1.1.1" class="ltx_text ltx_markedasmath"><math id="S4.E1.m1.1.1.1.m1.2" class="ltx_Math" alttext="WEPR(\mathcal{A})=\frac{(\mathcal{S+D})}{\mathcal{N}}" display="inline"><semantics id="S4.E1.m1.1.1.1.m1.2a"><mrow id="S4.E1.m1.1.1.1.m1.2.3" xref="S4.E1.m1.1.1.1.m1.2.3.cmml"><mrow id="S4.E1.m1.1.1.1.m1.2.3.2" xref="S4.E1.m1.1.1.1.m1.2.3.2.cmml"><mi id="S4.E1.m1.1.1.1.m1.2.3.2.2" xref="S4.E1.m1.1.1.1.m1.2.3.2.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.m1.2.3.2.1" xref="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml">​</mo><mi id="S4.E1.m1.1.1.1.m1.2.3.2.3" xref="S4.E1.m1.1.1.1.m1.2.3.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.m1.2.3.2.1a" xref="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml">​</mo><mi id="S4.E1.m1.1.1.1.m1.2.3.2.4" xref="S4.E1.m1.1.1.1.m1.2.3.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.m1.2.3.2.1b" xref="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml">​</mo><mi id="S4.E1.m1.1.1.1.m1.2.3.2.5" xref="S4.E1.m1.1.1.1.m1.2.3.2.5.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.m1.2.3.2.1c" xref="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml">​</mo><mrow id="S4.E1.m1.1.1.1.m1.2.3.2.6.2" xref="S4.E1.m1.1.1.1.m1.2.3.2.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.m1.2.3.2.6.2.1" xref="S4.E1.m1.1.1.1.m1.2.3.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.m1.2.2" xref="S4.E1.m1.1.1.1.m1.2.2.cmml">𝒜</mi><mo stretchy="false" id="S4.E1.m1.1.1.1.m1.2.3.2.6.2.2" xref="S4.E1.m1.1.1.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.1.1.1.m1.2.3.1" xref="S4.E1.m1.1.1.1.m1.2.3.1.cmml">=</mo><mfrac id="S4.E1.m1.1.1.1.m1.1.1" xref="S4.E1.m1.1.1.1.m1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.m1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.2.cmml">𝒮</mi><mo id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.1.cmml">+</mo><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.3.cmml">𝒟</mi></mrow><mo stretchy="false" id="S4.E1.m1.1.1.1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.m1.1.1.3" xref="S4.E1.m1.1.1.1.m1.1.1.3.cmml">𝒩</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1.1.1.m1.2b"><apply id="S4.E1.m1.1.1.1.m1.2.3.cmml" xref="S4.E1.m1.1.1.1.m1.2.3"><eq id="S4.E1.m1.1.1.1.m1.2.3.1.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.1"></eq><apply id="S4.E1.m1.1.1.1.m1.2.3.2.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2"><times id="S4.E1.m1.1.1.1.m1.2.3.2.1.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.1"></times><ci id="S4.E1.m1.1.1.1.m1.2.3.2.2.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.2">𝑊</ci><ci id="S4.E1.m1.1.1.1.m1.2.3.2.3.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.3">𝐸</ci><ci id="S4.E1.m1.1.1.1.m1.2.3.2.4.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.4">𝑃</ci><ci id="S4.E1.m1.1.1.1.m1.2.3.2.5.cmml" xref="S4.E1.m1.1.1.1.m1.2.3.2.5">𝑅</ci><ci id="S4.E1.m1.1.1.1.m1.2.2.cmml" xref="S4.E1.m1.1.1.1.m1.2.2">𝒜</ci></apply><apply id="S4.E1.m1.1.1.1.m1.1.1.cmml" xref="S4.E1.m1.1.1.1.m1.1.1"><divide id="S4.E1.m1.1.1.1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.m1.1.1"></divide><apply id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.1.1"><plus id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.1"></plus><ci id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.2">𝒮</ci><ci id="S4.E1.m1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.1.1.1.3">𝒟</ci></apply><ci id="S4.E1.m1.1.1.1.m1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.m1.1.1.3">𝒩</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1.1.1.m1.2c">WEPR(\mathcal{A})=\frac{(\mathcal{S+D})}{\mathcal{N}}</annotation></semantics></math></span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="0" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">In addition to WEPR, we also compute the following general ASR metrics using all words in the utterance: Word Error Rate (WER)<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://github.com/huggingface/evaluate/blob/main/metrics/wer/wer.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/evaluate/blob/main/metrics/wer/wer.py</a></span></span></span>, Character Error Rate (CER)<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/huggingface/evaluate/blob/main/metrics/cer/cer.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/evaluate/blob/main/metrics/cer/cer.py</a></span></span></span>, and character n-gram F-Score (chrF)<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://www.nltk.org/api/nltk.translate.chrf_score.html#nltk.translate.chrf_score.corpus_chrf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nltk.org/api/nltk.translate.chrf_score.html#nltk.translate.chrf_score.corpus_chrf</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Popović (<a href="#bib.bib27" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">We evaluate all models on our dataset’s five folds (cp. Section <a href="#S3.SS4.SSS1" title="3.4.1 Data Folds ‣ 3.4 Final Dataset ‣ 3 Dataset: Spontaneous Speech of Young Learners of English ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.1</span></a>) and report for each model the mean and standard deviation across all folds.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">For evaluation, all texts are normalised using the Whisper normalizer for English <span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://github.com/openai/whisper/blob/main/whisper/normalizers/english.py" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/openai/whisper/blob/main/whisper/normalizers/english.py</a></span></span></span>. Normalizing texts can mitigate the impact of disfluencies and non-standard linguistic forms, common in non-native and children’s speech. This allows for a more accurate comparison between different ASR models, as it aligns the hypothesis and reference texts more closely.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">Table <a href="#S4.T1" title="Table 1 ‣ 4.1 Metrics ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrates text normalization and WEPR calculation using a Whisper Large model prediction and a modified normalizer. The adjustments to the Whisper normalizer maintain contractions in references, ensuring the integrity of annotated words (e.g., it’s@!). For error preservation assessment, phonetic alignment is performed between the normalized prediction (NP) and a reference without error annotations (NR2). This removal is essential because the alignment algorithm would otherwise misidentify annotated words. The normalized reference with annotations (NR1) is then used to identify word pairs in the alignment results that are relevant for WEPR calculation. The Whisper Normalizer’s tendency to increase the similarity between predictiosn and references helps in building and classifying these word-level pairs.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:411.9pt;height:128.7pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-112.5pt,35.0pt) scale(0.646845204996048,0.646845204996048) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_top ltx_border_l ltx_border_t"></td>
<td id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.2.1.1" class="ltx_p" style="width:142.3pt;">Category</span>
</span>
</td>
<td id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.3.1.1" class="ltx_p" style="width:426.8pt;">Content</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.2.2" class="ltx_tr">
<td id="S4.T1.1.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_t">
<span id="S4.T1.1.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.1.1.1" class="ltx_p" style="width:28.5pt;">R</span>
</span>
</td>
<td id="S4.T1.1.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.2.1.1" class="ltx_p" style="width:142.3pt;">Reference</span>
</span>
</td>
<td id="S4.T1.1.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.3.1.1" class="ltx_p" style="width:426.8pt;">The beach, because it’s <span id="S4.T1.1.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">a@!</span> very nice <span id="S4.T1.1.1.2.2.3.1.1.2" class="ltx_text ltx_font_bold">of@!</span> the beach. Tell me about <span id="S4.T1.1.1.2.2.3.1.1.3" class="ltx_text ltx_font_bold">you@!</span> favorite TV-show.</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.3.3" class="ltx_tr">
<td id="S4.T1.1.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.1.1.1" class="ltx_p" style="width:28.5pt;">P</span>
</span>
</td>
<td id="S4.T1.1.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.2.1.1" class="ltx_p" style="width:142.3pt;">Prediction</span>
</span>
</td>
<td id="S4.T1.1.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.3.1.1" class="ltx_p" style="width:426.8pt;">the beach because it’s a very nice beach tell me about your favorite TV show</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.4.4" class="ltx_tr">
<td id="S4.T1.1.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_t">
<span id="S4.T1.1.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.1.1.1" class="ltx_p" style="width:28.5pt;">NR1</span>
</span>
</td>
<td id="S4.T1.1.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.2.1.1" class="ltx_p" style="width:142.3pt;">Normalized Reference (with @!)</span>
</span>
</td>
<td id="S4.T1.1.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.3.1.1" class="ltx_p" style="width:426.8pt;">the beach because it’s <span id="S4.T1.1.1.4.4.3.1.1.1" class="ltx_text ltx_font_bold">a@!</span> very nice <span id="S4.T1.1.1.4.4.3.1.1.2" class="ltx_text ltx_font_bold">of@!</span> the beach tell me about <span id="S4.T1.1.1.4.4.3.1.1.3" class="ltx_text ltx_font_bold">you@!</span> favorite tvshow</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.5.5" class="ltx_tr">
<td id="S4.T1.1.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.1.1.1" class="ltx_p" style="width:28.5pt;">NR2</span>
</span>
</td>
<td id="S4.T1.1.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.2.1.1" class="ltx_p" style="width:142.3pt;">Normalized Reference</span>
</span>
</td>
<td id="S4.T1.1.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.3.1.1" class="ltx_p" style="width:426.8pt;">the beach because it’s a very nice of the beach tell me about you favorite tvshow</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.6.6" class="ltx_tr">
<td id="S4.T1.1.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.1.1.1" class="ltx_p" style="width:28.5pt;">NP</span>
</span>
</td>
<td id="S4.T1.1.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.2.1.1" class="ltx_p" style="width:142.3pt;">Normalized Prediction</span>
</span>
</td>
<td id="S4.T1.1.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.3.1.1" class="ltx_p" style="width:426.8pt;">the beach because it’s a very nice beach tell me about your favorite tv show</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.7.7" class="ltx_tr">
<td id="S4.T1.1.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_t">
<span id="S4.T1.1.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.1.1.1" class="ltx_p" style="width:28.5pt;">S</span>
</span>
</td>
<td id="S4.T1.1.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.2.1.1" class="ltx_p" style="width:142.3pt;">Substitutions</span>
</span>
</td>
<td id="S4.T1.1.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.3.1.1" class="ltx_p" style="width:426.8pt;">[(<span id="S4.T1.1.1.7.7.3.1.1.1" class="ltx_text ltx_font_bold">’you@!’</span>, ’your’)]</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.8.8" class="ltx_tr">
<td id="S4.T1.1.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.1.1.1" class="ltx_p" style="width:28.5pt;">D</span>
</span>
</td>
<td id="S4.T1.1.1.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.2.1.1" class="ltx_p" style="width:142.3pt;">Deletions</span>
</span>
</td>
<td id="S4.T1.1.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.3.1.1" class="ltx_p" style="width:426.8pt;">[<span id="S4.T1.1.1.8.8.3.1.1.1" class="ltx_text ltx_font_bold">’of@!’</span>]</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.9.9" class="ltx_tr">
<td id="S4.T1.1.1.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.1.1.1" class="ltx_p" style="width:28.5pt;">I</span>
</span>
</td>
<td id="S4.T1.1.1.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.2.1.1" class="ltx_p" style="width:142.3pt;">Insertions</span>
</span>
</td>
<td id="S4.T1.1.1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.3.1.1" class="ltx_p" style="width:426.8pt;">[]</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.10.10" class="ltx_tr">
<td id="S4.T1.1.1.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l">
<span id="S4.T1.1.1.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.1.1.1" class="ltx_p" style="width:28.5pt;">C</span>
</span>
</td>
<td id="S4.T1.1.1.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.2.1.1" class="ltx_p" style="width:142.3pt;">Correct</span>
</span>
</td>
<td id="S4.T1.1.1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.3.1.1" class="ltx_p" style="width:426.8pt;">[<span id="S4.T1.1.1.10.10.3.1.1.1" class="ltx_text ltx_font_bold">’a@!’</span>]</span>
</span>
</td>
</tr>
<tr id="S4.T1.1.1.11.11" class="ltx_tr">
<td id="S4.T1.1.1.11.11.1" class="ltx_td ltx_align_top ltx_border_b ltx_border_l ltx_border_t"></td>
<td id="S4.T1.1.1.11.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.11.11.2.1.1" class="ltx_p" style="width:142.3pt;">WEPR</span>
</span>
</td>
<td id="S4.T1.1.1.11.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.11.11.3.1.1" class="ltx_p" style="width:426.8pt;"><span id="S4.T1.1.1.11.11.3.1.1.1" class="ltx_text ltx_font_bold">0.67</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>WEPR calculation example using Whisper Large model’s prediction with texts normalized by a customized version of Whisper’s Text Normalizer retaining contractions. Substitutions, insertions, deletions, and correct words are derived from phonetic alignment between NR2 and NP, but only for words that are annotated in NR1.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.32" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:325.2pt;height:117.3pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-63.3pt,22.7pt) scale(0.719900160430876,0.719900160430876) ;">
<table id="S4.T2.32.32" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.32.32.33.1" class="ltx_tr">
<th id="S4.T2.32.32.33.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">System Name</th>
<th id="S4.T2.32.32.33.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">#Param.</th>
<th id="S4.T2.32.32.33.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">WER</th>
<th id="S4.T2.32.32.33.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">CER</th>
<th id="S4.T2.32.32.33.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">chrF</th>
<th id="S4.T2.32.32.33.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">WEPR</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.4.4.4" class="ltx_tr">
<th id="S4.T2.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Wav2Vec Base</th>
<th id="S4.T2.4.4.4.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">95M</th>
<td id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="0.55\pm 0.02" display="inline"><semantics id="S4.T2.1.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml"><mn id="S4.T2.1.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.1.m1.1.1.2.cmml">0.55</mn><mo id="S4.T2.1.1.1.1.m1.1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.1.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.1.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.1.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2">0.55</cn><cn type="float" id="S4.T2.1.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">0.55\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="0.34\pm 0.02" display="inline"><semantics id="S4.T2.2.2.2.2.m1.1a"><mrow id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml"><mn id="S4.T2.2.2.2.2.m1.1.1.2" xref="S4.T2.2.2.2.2.m1.1.1.2.cmml">0.34</mn><mo id="S4.T2.2.2.2.2.m1.1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.1.cmml">±</mo><mn id="S4.T2.2.2.2.2.m1.1.1.3" xref="S4.T2.2.2.2.2.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2">0.34</cn><cn type="float" id="S4.T2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T2.2.2.2.2.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">0.34\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="0.35\pm 0.02" display="inline"><semantics id="S4.T2.3.3.3.3.m1.1a"><mrow id="S4.T2.3.3.3.3.m1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.cmml"><mn id="S4.T2.3.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.3.m1.1.1.2.cmml">0.35</mn><mo id="S4.T2.3.3.3.3.m1.1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.1.cmml">±</mo><mn id="S4.T2.3.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.3.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.3.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.3.m1.1.1.2">0.35</cn><cn type="float" id="S4.T2.3.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">0.35\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T2.4.4.4.4.m1.1" class="ltx_Math" alttext="0.57\pm 0.02" display="inline"><semantics id="S4.T2.4.4.4.4.m1.1a"><mrow id="S4.T2.4.4.4.4.m1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.cmml"><mn id="S4.T2.4.4.4.4.m1.1.1.2" xref="S4.T2.4.4.4.4.m1.1.1.2.cmml">0.57</mn><mo id="S4.T2.4.4.4.4.m1.1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.1.cmml">±</mo><mn id="S4.T2.4.4.4.4.m1.1.1.3" xref="S4.T2.4.4.4.4.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.4.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.4.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2">0.57</cn><cn type="float" id="S4.T2.4.4.4.4.m1.1.1.3.cmml" xref="S4.T2.4.4.4.4.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.m1.1c">0.57\pm 0.02</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.8.8.8" class="ltx_tr">
<th id="S4.T2.8.8.8.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Wav2Vec Large</th>
<th id="S4.T2.8.8.8.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">317M</th>
<td id="S4.T2.5.5.5.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="0.49\pm 0.02" display="inline"><semantics id="S4.T2.5.5.5.1.m1.1a"><mrow id="S4.T2.5.5.5.1.m1.1.1" xref="S4.T2.5.5.5.1.m1.1.1.cmml"><mn id="S4.T2.5.5.5.1.m1.1.1.2" xref="S4.T2.5.5.5.1.m1.1.1.2.cmml">0.49</mn><mo id="S4.T2.5.5.5.1.m1.1.1.1" xref="S4.T2.5.5.5.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.5.5.5.1.m1.1.1.3" xref="S4.T2.5.5.5.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.1.m1.1b"><apply id="S4.T2.5.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.5.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.5.5.5.1.m1.1.1.1.cmml" xref="S4.T2.5.5.5.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.5.5.5.1.m1.1.1.2.cmml" xref="S4.T2.5.5.5.1.m1.1.1.2">0.49</cn><cn type="float" id="S4.T2.5.5.5.1.m1.1.1.3.cmml" xref="S4.T2.5.5.5.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.1.m1.1c">0.49\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.6.6.6.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.6.6.6.2.m1.1" class="ltx_Math" alttext="0.29\pm 0.01" display="inline"><semantics id="S4.T2.6.6.6.2.m1.1a"><mrow id="S4.T2.6.6.6.2.m1.1.1" xref="S4.T2.6.6.6.2.m1.1.1.cmml"><mn id="S4.T2.6.6.6.2.m1.1.1.2" xref="S4.T2.6.6.6.2.m1.1.1.2.cmml">0.29</mn><mo id="S4.T2.6.6.6.2.m1.1.1.1" xref="S4.T2.6.6.6.2.m1.1.1.1.cmml">±</mo><mn id="S4.T2.6.6.6.2.m1.1.1.3" xref="S4.T2.6.6.6.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.2.m1.1b"><apply id="S4.T2.6.6.6.2.m1.1.1.cmml" xref="S4.T2.6.6.6.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.6.6.6.2.m1.1.1.1.cmml" xref="S4.T2.6.6.6.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.6.6.6.2.m1.1.1.2.cmml" xref="S4.T2.6.6.6.2.m1.1.1.2">0.29</cn><cn type="float" id="S4.T2.6.6.6.2.m1.1.1.3.cmml" xref="S4.T2.6.6.6.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.2.m1.1c">0.29\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.7.7.7.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.7.7.7.3.m1.1" class="ltx_Math" alttext="0.41\pm 0.02" display="inline"><semantics id="S4.T2.7.7.7.3.m1.1a"><mrow id="S4.T2.7.7.7.3.m1.1.1" xref="S4.T2.7.7.7.3.m1.1.1.cmml"><mn id="S4.T2.7.7.7.3.m1.1.1.2" xref="S4.T2.7.7.7.3.m1.1.1.2.cmml">0.41</mn><mo id="S4.T2.7.7.7.3.m1.1.1.1" xref="S4.T2.7.7.7.3.m1.1.1.1.cmml">±</mo><mn id="S4.T2.7.7.7.3.m1.1.1.3" xref="S4.T2.7.7.7.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.3.m1.1b"><apply id="S4.T2.7.7.7.3.m1.1.1.cmml" xref="S4.T2.7.7.7.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.7.7.7.3.m1.1.1.1.cmml" xref="S4.T2.7.7.7.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.7.7.7.3.m1.1.1.2.cmml" xref="S4.T2.7.7.7.3.m1.1.1.2">0.41</cn><cn type="float" id="S4.T2.7.7.7.3.m1.1.1.3.cmml" xref="S4.T2.7.7.7.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.3.m1.1c">0.41\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.8.8.8.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.8.8.8.4.m1.1" class="ltx_Math" alttext="0.50\pm 0.02" display="inline"><semantics id="S4.T2.8.8.8.4.m1.1a"><mrow id="S4.T2.8.8.8.4.m1.1.1" xref="S4.T2.8.8.8.4.m1.1.1.cmml"><mn id="S4.T2.8.8.8.4.m1.1.1.2" xref="S4.T2.8.8.8.4.m1.1.1.2.cmml">0.50</mn><mo id="S4.T2.8.8.8.4.m1.1.1.1" xref="S4.T2.8.8.8.4.m1.1.1.1.cmml">±</mo><mn id="S4.T2.8.8.8.4.m1.1.1.3" xref="S4.T2.8.8.8.4.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.8.4.m1.1b"><apply id="S4.T2.8.8.8.4.m1.1.1.cmml" xref="S4.T2.8.8.8.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.8.8.8.4.m1.1.1.1.cmml" xref="S4.T2.8.8.8.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.8.8.8.4.m1.1.1.2.cmml" xref="S4.T2.8.8.8.4.m1.1.1.2">0.50</cn><cn type="float" id="S4.T2.8.8.8.4.m1.1.1.3.cmml" xref="S4.T2.8.8.8.4.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.8.4.m1.1c">0.50\pm 0.02</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.12.12.12" class="ltx_tr">
<th id="S4.T2.12.12.12.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">XLSR-53 + CommonVoice 6.1</th>
<th id="S4.T2.12.12.12.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">317M</th>
<td id="S4.T2.9.9.9.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="0.38\pm 0.01" display="inline"><semantics id="S4.T2.9.9.9.1.m1.1a"><mrow id="S4.T2.9.9.9.1.m1.1.1" xref="S4.T2.9.9.9.1.m1.1.1.cmml"><mn id="S4.T2.9.9.9.1.m1.1.1.2" xref="S4.T2.9.9.9.1.m1.1.1.2.cmml">0.38</mn><mo id="S4.T2.9.9.9.1.m1.1.1.1" xref="S4.T2.9.9.9.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.9.9.9.1.m1.1.1.3" xref="S4.T2.9.9.9.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.9.1.m1.1b"><apply id="S4.T2.9.9.9.1.m1.1.1.cmml" xref="S4.T2.9.9.9.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.9.9.9.1.m1.1.1.1.cmml" xref="S4.T2.9.9.9.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.9.9.9.1.m1.1.1.2.cmml" xref="S4.T2.9.9.9.1.m1.1.1.2">0.38</cn><cn type="float" id="S4.T2.9.9.9.1.m1.1.1.3.cmml" xref="S4.T2.9.9.9.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.9.1.m1.1c">0.38\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.10.10.10.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.10.10.10.2.m1.1" class="ltx_Math" alttext="0.26\pm 0.01" display="inline"><semantics id="S4.T2.10.10.10.2.m1.1a"><mrow id="S4.T2.10.10.10.2.m1.1.1" xref="S4.T2.10.10.10.2.m1.1.1.cmml"><mn id="S4.T2.10.10.10.2.m1.1.1.2" xref="S4.T2.10.10.10.2.m1.1.1.2.cmml">0.26</mn><mo id="S4.T2.10.10.10.2.m1.1.1.1" xref="S4.T2.10.10.10.2.m1.1.1.1.cmml">±</mo><mn id="S4.T2.10.10.10.2.m1.1.1.3" xref="S4.T2.10.10.10.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.10.2.m1.1b"><apply id="S4.T2.10.10.10.2.m1.1.1.cmml" xref="S4.T2.10.10.10.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.10.10.10.2.m1.1.1.1.cmml" xref="S4.T2.10.10.10.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.10.10.10.2.m1.1.1.2.cmml" xref="S4.T2.10.10.10.2.m1.1.1.2">0.26</cn><cn type="float" id="S4.T2.10.10.10.2.m1.1.1.3.cmml" xref="S4.T2.10.10.10.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.10.2.m1.1c">0.26\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.11.11.11.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.11.11.11.3.m1.1" class="ltx_Math" alttext="0.59\pm 0.01" display="inline"><semantics id="S4.T2.11.11.11.3.m1.1a"><mrow id="S4.T2.11.11.11.3.m1.1.1" xref="S4.T2.11.11.11.3.m1.1.1.cmml"><mn id="S4.T2.11.11.11.3.m1.1.1.2" xref="S4.T2.11.11.11.3.m1.1.1.2.cmml">0.59</mn><mo id="S4.T2.11.11.11.3.m1.1.1.1" xref="S4.T2.11.11.11.3.m1.1.1.1.cmml">±</mo><mn id="S4.T2.11.11.11.3.m1.1.1.3" xref="S4.T2.11.11.11.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.11.3.m1.1b"><apply id="S4.T2.11.11.11.3.m1.1.1.cmml" xref="S4.T2.11.11.11.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.11.11.11.3.m1.1.1.1.cmml" xref="S4.T2.11.11.11.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.11.11.11.3.m1.1.1.2.cmml" xref="S4.T2.11.11.11.3.m1.1.1.2">0.59</cn><cn type="float" id="S4.T2.11.11.11.3.m1.1.1.3.cmml" xref="S4.T2.11.11.11.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.11.3.m1.1c">0.59\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.12.12.12.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.12.12.12.4.m1.1" class="ltx_Math" alttext="0.50\pm 0.03" display="inline"><semantics id="S4.T2.12.12.12.4.m1.1a"><mrow id="S4.T2.12.12.12.4.m1.1.1" xref="S4.T2.12.12.12.4.m1.1.1.cmml"><mn id="S4.T2.12.12.12.4.m1.1.1.2" xref="S4.T2.12.12.12.4.m1.1.1.2.cmml">0.50</mn><mo id="S4.T2.12.12.12.4.m1.1.1.1" xref="S4.T2.12.12.12.4.m1.1.1.1.cmml">±</mo><mn id="S4.T2.12.12.12.4.m1.1.1.3" xref="S4.T2.12.12.12.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.12.4.m1.1b"><apply id="S4.T2.12.12.12.4.m1.1.1.cmml" xref="S4.T2.12.12.12.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.12.12.12.4.m1.1.1.1.cmml" xref="S4.T2.12.12.12.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.12.12.12.4.m1.1.1.2.cmml" xref="S4.T2.12.12.12.4.m1.1.1.2">0.50</cn><cn type="float" id="S4.T2.12.12.12.4.m1.1.1.3.cmml" xref="S4.T2.12.12.12.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.12.4.m1.1c">0.50\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.16.16.16" class="ltx_tr">
<th id="S4.T2.16.16.16.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">XLSR-1B + CommonVoice 6.1</th>
<th id="S4.T2.16.16.16.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1B</th>
<td id="S4.T2.13.13.13.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.13.13.13.1.m1.1" class="ltx_Math" alttext="0.31\pm 0.01" display="inline"><semantics id="S4.T2.13.13.13.1.m1.1a"><mrow id="S4.T2.13.13.13.1.m1.1.1" xref="S4.T2.13.13.13.1.m1.1.1.cmml"><mn id="S4.T2.13.13.13.1.m1.1.1.2" xref="S4.T2.13.13.13.1.m1.1.1.2.cmml">0.31</mn><mo id="S4.T2.13.13.13.1.m1.1.1.1" xref="S4.T2.13.13.13.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.13.13.13.1.m1.1.1.3" xref="S4.T2.13.13.13.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.13.13.13.1.m1.1b"><apply id="S4.T2.13.13.13.1.m1.1.1.cmml" xref="S4.T2.13.13.13.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.13.13.13.1.m1.1.1.1.cmml" xref="S4.T2.13.13.13.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.13.13.13.1.m1.1.1.2.cmml" xref="S4.T2.13.13.13.1.m1.1.1.2">0.31</cn><cn type="float" id="S4.T2.13.13.13.1.m1.1.1.3.cmml" xref="S4.T2.13.13.13.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.13.13.1.m1.1c">0.31\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.14.14.14.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.14.14.14.2.m1.1" class="ltx_Math" alttext="0.21\pm 0.01" display="inline"><semantics id="S4.T2.14.14.14.2.m1.1a"><mrow id="S4.T2.14.14.14.2.m1.1.1" xref="S4.T2.14.14.14.2.m1.1.1.cmml"><mn id="S4.T2.14.14.14.2.m1.1.1.2" xref="S4.T2.14.14.14.2.m1.1.1.2.cmml">0.21</mn><mo id="S4.T2.14.14.14.2.m1.1.1.1" xref="S4.T2.14.14.14.2.m1.1.1.1.cmml">±</mo><mn id="S4.T2.14.14.14.2.m1.1.1.3" xref="S4.T2.14.14.14.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.14.2.m1.1b"><apply id="S4.T2.14.14.14.2.m1.1.1.cmml" xref="S4.T2.14.14.14.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.14.14.14.2.m1.1.1.1.cmml" xref="S4.T2.14.14.14.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.14.14.14.2.m1.1.1.2.cmml" xref="S4.T2.14.14.14.2.m1.1.1.2">0.21</cn><cn type="float" id="S4.T2.14.14.14.2.m1.1.1.3.cmml" xref="S4.T2.14.14.14.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.14.2.m1.1c">0.21\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.15.15.15.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.15.15.15.3.m1.1" class="ltx_Math" alttext="0.61\pm 0.01" display="inline"><semantics id="S4.T2.15.15.15.3.m1.1a"><mrow id="S4.T2.15.15.15.3.m1.1.1" xref="S4.T2.15.15.15.3.m1.1.1.cmml"><mn id="S4.T2.15.15.15.3.m1.1.1.2" xref="S4.T2.15.15.15.3.m1.1.1.2.cmml">0.61</mn><mo id="S4.T2.15.15.15.3.m1.1.1.1" xref="S4.T2.15.15.15.3.m1.1.1.1.cmml">±</mo><mn id="S4.T2.15.15.15.3.m1.1.1.3" xref="S4.T2.15.15.15.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.15.3.m1.1b"><apply id="S4.T2.15.15.15.3.m1.1.1.cmml" xref="S4.T2.15.15.15.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.15.15.15.3.m1.1.1.1.cmml" xref="S4.T2.15.15.15.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.15.15.15.3.m1.1.1.2.cmml" xref="S4.T2.15.15.15.3.m1.1.1.2">0.61</cn><cn type="float" id="S4.T2.15.15.15.3.m1.1.1.3.cmml" xref="S4.T2.15.15.15.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.15.3.m1.1c">0.61\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.16.16.16.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.16.16.16.4.m1.1" class="ltx_Math" alttext="0.44\pm 0.03" display="inline"><semantics id="S4.T2.16.16.16.4.m1.1a"><mrow id="S4.T2.16.16.16.4.m1.1.1" xref="S4.T2.16.16.16.4.m1.1.1.cmml"><mn id="S4.T2.16.16.16.4.m1.1.1.2" xref="S4.T2.16.16.16.4.m1.1.1.2.cmml">0.44</mn><mo id="S4.T2.16.16.16.4.m1.1.1.1" xref="S4.T2.16.16.16.4.m1.1.1.1.cmml">±</mo><mn id="S4.T2.16.16.16.4.m1.1.1.3" xref="S4.T2.16.16.16.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.16.16.16.4.m1.1b"><apply id="S4.T2.16.16.16.4.m1.1.1.cmml" xref="S4.T2.16.16.16.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.16.16.16.4.m1.1.1.1.cmml" xref="S4.T2.16.16.16.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.16.16.16.4.m1.1.1.2.cmml" xref="S4.T2.16.16.16.4.m1.1.1.2">0.44</cn><cn type="float" id="S4.T2.16.16.16.4.m1.1.1.3.cmml" xref="S4.T2.16.16.16.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.16.16.4.m1.1c">0.44\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.20.20.20" class="ltx_tr">
<th id="S4.T2.20.20.20.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Whisper Medium</th>
<th id="S4.T2.20.20.20.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">769M</th>
<td id="S4.T2.17.17.17.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.17.17.17.1.m1.1" class="ltx_Math" alttext="0.26\pm 0.02" display="inline"><semantics id="S4.T2.17.17.17.1.m1.1a"><mrow id="S4.T2.17.17.17.1.m1.1.1" xref="S4.T2.17.17.17.1.m1.1.1.cmml"><mn id="S4.T2.17.17.17.1.m1.1.1.2" xref="S4.T2.17.17.17.1.m1.1.1.2.cmml">0.26</mn><mo id="S4.T2.17.17.17.1.m1.1.1.1" xref="S4.T2.17.17.17.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.17.17.17.1.m1.1.1.3" xref="S4.T2.17.17.17.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.17.17.17.1.m1.1b"><apply id="S4.T2.17.17.17.1.m1.1.1.cmml" xref="S4.T2.17.17.17.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.17.17.17.1.m1.1.1.1.cmml" xref="S4.T2.17.17.17.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.17.17.17.1.m1.1.1.2.cmml" xref="S4.T2.17.17.17.1.m1.1.1.2">0.26</cn><cn type="float" id="S4.T2.17.17.17.1.m1.1.1.3.cmml" xref="S4.T2.17.17.17.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.17.17.17.1.m1.1c">0.26\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.18.18.18.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.18.18.18.2.m1.1" class="ltx_Math" alttext="0.20\pm 0.03" display="inline"><semantics id="S4.T2.18.18.18.2.m1.1a"><mrow id="S4.T2.18.18.18.2.m1.1.1" xref="S4.T2.18.18.18.2.m1.1.1.cmml"><mn id="S4.T2.18.18.18.2.m1.1.1.2" xref="S4.T2.18.18.18.2.m1.1.1.2.cmml">0.20</mn><mo id="S4.T2.18.18.18.2.m1.1.1.1" xref="S4.T2.18.18.18.2.m1.1.1.1.cmml">±</mo><mn id="S4.T2.18.18.18.2.m1.1.1.3" xref="S4.T2.18.18.18.2.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.18.18.18.2.m1.1b"><apply id="S4.T2.18.18.18.2.m1.1.1.cmml" xref="S4.T2.18.18.18.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.18.18.18.2.m1.1.1.1.cmml" xref="S4.T2.18.18.18.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.18.18.18.2.m1.1.1.2.cmml" xref="S4.T2.18.18.18.2.m1.1.1.2">0.20</cn><cn type="float" id="S4.T2.18.18.18.2.m1.1.1.3.cmml" xref="S4.T2.18.18.18.2.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.18.18.18.2.m1.1c">0.20\pm 0.03</annotation></semantics></math></td>
<td id="S4.T2.19.19.19.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.19.19.19.3.m1.1" class="ltx_Math" alttext="\textbf{0.70}\pm 0.02" display="inline"><semantics id="S4.T2.19.19.19.3.m1.1a"><mrow id="S4.T2.19.19.19.3.m1.1.1" xref="S4.T2.19.19.19.3.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.19.19.19.3.m1.1.1.2" xref="S4.T2.19.19.19.3.m1.1.1.2a.cmml">0.70</mtext><mo id="S4.T2.19.19.19.3.m1.1.1.1" xref="S4.T2.19.19.19.3.m1.1.1.1.cmml">±</mo><mn id="S4.T2.19.19.19.3.m1.1.1.3" xref="S4.T2.19.19.19.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.19.19.19.3.m1.1b"><apply id="S4.T2.19.19.19.3.m1.1.1.cmml" xref="S4.T2.19.19.19.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.19.19.19.3.m1.1.1.1.cmml" xref="S4.T2.19.19.19.3.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.19.19.19.3.m1.1.1.2a.cmml" xref="S4.T2.19.19.19.3.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.19.19.19.3.m1.1.1.2.cmml" xref="S4.T2.19.19.19.3.m1.1.1.2">0.70</mtext></ci><cn type="float" id="S4.T2.19.19.19.3.m1.1.1.3.cmml" xref="S4.T2.19.19.19.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.19.19.19.3.m1.1c">\textbf{0.70}\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.20.20.20.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.20.20.20.4.m1.1" class="ltx_Math" alttext="0.46\pm 0.04" display="inline"><semantics id="S4.T2.20.20.20.4.m1.1a"><mrow id="S4.T2.20.20.20.4.m1.1.1" xref="S4.T2.20.20.20.4.m1.1.1.cmml"><mn id="S4.T2.20.20.20.4.m1.1.1.2" xref="S4.T2.20.20.20.4.m1.1.1.2.cmml">0.46</mn><mo id="S4.T2.20.20.20.4.m1.1.1.1" xref="S4.T2.20.20.20.4.m1.1.1.1.cmml">±</mo><mn id="S4.T2.20.20.20.4.m1.1.1.3" xref="S4.T2.20.20.20.4.m1.1.1.3.cmml">0.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.20.20.20.4.m1.1b"><apply id="S4.T2.20.20.20.4.m1.1.1.cmml" xref="S4.T2.20.20.20.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.20.20.20.4.m1.1.1.1.cmml" xref="S4.T2.20.20.20.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.20.20.20.4.m1.1.1.2.cmml" xref="S4.T2.20.20.20.4.m1.1.1.2">0.46</cn><cn type="float" id="S4.T2.20.20.20.4.m1.1.1.3.cmml" xref="S4.T2.20.20.20.4.m1.1.1.3">0.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.20.20.20.4.m1.1c">0.46\pm 0.04</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.24.24.24" class="ltx_tr">
<th id="S4.T2.24.24.24.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Whisper Large</th>
<th id="S4.T2.24.24.24.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.5B</th>
<td id="S4.T2.21.21.21.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.21.21.21.1.m1.1" class="ltx_Math" alttext="\textbf{0.25}\pm 0.02" display="inline"><semantics id="S4.T2.21.21.21.1.m1.1a"><mrow id="S4.T2.21.21.21.1.m1.1.1" xref="S4.T2.21.21.21.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.21.21.21.1.m1.1.1.2" xref="S4.T2.21.21.21.1.m1.1.1.2a.cmml">0.25</mtext><mo id="S4.T2.21.21.21.1.m1.1.1.1" xref="S4.T2.21.21.21.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.21.21.21.1.m1.1.1.3" xref="S4.T2.21.21.21.1.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.21.21.21.1.m1.1b"><apply id="S4.T2.21.21.21.1.m1.1.1.cmml" xref="S4.T2.21.21.21.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.21.21.21.1.m1.1.1.1.cmml" xref="S4.T2.21.21.21.1.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.21.21.21.1.m1.1.1.2a.cmml" xref="S4.T2.21.21.21.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.21.21.21.1.m1.1.1.2.cmml" xref="S4.T2.21.21.21.1.m1.1.1.2">0.25</mtext></ci><cn type="float" id="S4.T2.21.21.21.1.m1.1.1.3.cmml" xref="S4.T2.21.21.21.1.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.21.21.21.1.m1.1c">\textbf{0.25}\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.22.22.22.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.22.22.22.2.m1.1" class="ltx_Math" alttext="0.19\pm 0.01" display="inline"><semantics id="S4.T2.22.22.22.2.m1.1a"><mrow id="S4.T2.22.22.22.2.m1.1.1" xref="S4.T2.22.22.22.2.m1.1.1.cmml"><mn id="S4.T2.22.22.22.2.m1.1.1.2" xref="S4.T2.22.22.22.2.m1.1.1.2.cmml">0.19</mn><mo id="S4.T2.22.22.22.2.m1.1.1.1" xref="S4.T2.22.22.22.2.m1.1.1.1.cmml">±</mo><mn id="S4.T2.22.22.22.2.m1.1.1.3" xref="S4.T2.22.22.22.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.22.22.22.2.m1.1b"><apply id="S4.T2.22.22.22.2.m1.1.1.cmml" xref="S4.T2.22.22.22.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.22.22.22.2.m1.1.1.1.cmml" xref="S4.T2.22.22.22.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.22.22.22.2.m1.1.1.2.cmml" xref="S4.T2.22.22.22.2.m1.1.1.2">0.19</cn><cn type="float" id="S4.T2.22.22.22.2.m1.1.1.3.cmml" xref="S4.T2.22.22.22.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.22.22.22.2.m1.1c">0.19\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.23.23.23.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.23.23.23.3.m1.1" class="ltx_Math" alttext="\textbf{0.70}\pm 0.01" display="inline"><semantics id="S4.T2.23.23.23.3.m1.1a"><mrow id="S4.T2.23.23.23.3.m1.1.1" xref="S4.T2.23.23.23.3.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.23.23.23.3.m1.1.1.2" xref="S4.T2.23.23.23.3.m1.1.1.2a.cmml">0.70</mtext><mo id="S4.T2.23.23.23.3.m1.1.1.1" xref="S4.T2.23.23.23.3.m1.1.1.1.cmml">±</mo><mn id="S4.T2.23.23.23.3.m1.1.1.3" xref="S4.T2.23.23.23.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.23.23.23.3.m1.1b"><apply id="S4.T2.23.23.23.3.m1.1.1.cmml" xref="S4.T2.23.23.23.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.23.23.23.3.m1.1.1.1.cmml" xref="S4.T2.23.23.23.3.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.23.23.23.3.m1.1.1.2a.cmml" xref="S4.T2.23.23.23.3.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.23.23.23.3.m1.1.1.2.cmml" xref="S4.T2.23.23.23.3.m1.1.1.2">0.70</mtext></ci><cn type="float" id="S4.T2.23.23.23.3.m1.1.1.3.cmml" xref="S4.T2.23.23.23.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.23.23.23.3.m1.1c">\textbf{0.70}\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.24.24.24.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.24.24.24.4.m1.1" class="ltx_Math" alttext="0.47\pm 0.03" display="inline"><semantics id="S4.T2.24.24.24.4.m1.1a"><mrow id="S4.T2.24.24.24.4.m1.1.1" xref="S4.T2.24.24.24.4.m1.1.1.cmml"><mn id="S4.T2.24.24.24.4.m1.1.1.2" xref="S4.T2.24.24.24.4.m1.1.1.2.cmml">0.47</mn><mo id="S4.T2.24.24.24.4.m1.1.1.1" xref="S4.T2.24.24.24.4.m1.1.1.1.cmml">±</mo><mn id="S4.T2.24.24.24.4.m1.1.1.3" xref="S4.T2.24.24.24.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.24.24.24.4.m1.1b"><apply id="S4.T2.24.24.24.4.m1.1.1.cmml" xref="S4.T2.24.24.24.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.24.24.24.4.m1.1.1.1.cmml" xref="S4.T2.24.24.24.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.24.24.24.4.m1.1.1.2.cmml" xref="S4.T2.24.24.24.4.m1.1.1.2">0.47</cn><cn type="float" id="S4.T2.24.24.24.4.m1.1.1.3.cmml" xref="S4.T2.24.24.24.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.24.24.24.4.m1.1c">0.47\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.28.28.28" class="ltx_tr">
<th id="S4.T2.28.28.28.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Whisper Large-v3</th>
<th id="S4.T2.28.28.28.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.5B</th>
<td id="S4.T2.25.25.25.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.25.25.25.1.m1.1" class="ltx_Math" alttext="0.30\pm 0.04" display="inline"><semantics id="S4.T2.25.25.25.1.m1.1a"><mrow id="S4.T2.25.25.25.1.m1.1.1" xref="S4.T2.25.25.25.1.m1.1.1.cmml"><mn id="S4.T2.25.25.25.1.m1.1.1.2" xref="S4.T2.25.25.25.1.m1.1.1.2.cmml">0.30</mn><mo id="S4.T2.25.25.25.1.m1.1.1.1" xref="S4.T2.25.25.25.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.25.25.25.1.m1.1.1.3" xref="S4.T2.25.25.25.1.m1.1.1.3.cmml">0.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.25.25.25.1.m1.1b"><apply id="S4.T2.25.25.25.1.m1.1.1.cmml" xref="S4.T2.25.25.25.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.25.25.25.1.m1.1.1.1.cmml" xref="S4.T2.25.25.25.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.25.25.25.1.m1.1.1.2.cmml" xref="S4.T2.25.25.25.1.m1.1.1.2">0.30</cn><cn type="float" id="S4.T2.25.25.25.1.m1.1.1.3.cmml" xref="S4.T2.25.25.25.1.m1.1.1.3">0.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.25.25.25.1.m1.1c">0.30\pm 0.04</annotation></semantics></math></td>
<td id="S4.T2.26.26.26.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.26.26.26.2.m1.1" class="ltx_Math" alttext="0.23\pm 0.03" display="inline"><semantics id="S4.T2.26.26.26.2.m1.1a"><mrow id="S4.T2.26.26.26.2.m1.1.1" xref="S4.T2.26.26.26.2.m1.1.1.cmml"><mn id="S4.T2.26.26.26.2.m1.1.1.2" xref="S4.T2.26.26.26.2.m1.1.1.2.cmml">0.23</mn><mo id="S4.T2.26.26.26.2.m1.1.1.1" xref="S4.T2.26.26.26.2.m1.1.1.1.cmml">±</mo><mn id="S4.T2.26.26.26.2.m1.1.1.3" xref="S4.T2.26.26.26.2.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.26.26.26.2.m1.1b"><apply id="S4.T2.26.26.26.2.m1.1.1.cmml" xref="S4.T2.26.26.26.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.26.26.26.2.m1.1.1.1.cmml" xref="S4.T2.26.26.26.2.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.26.26.26.2.m1.1.1.2.cmml" xref="S4.T2.26.26.26.2.m1.1.1.2">0.23</cn><cn type="float" id="S4.T2.26.26.26.2.m1.1.1.3.cmml" xref="S4.T2.26.26.26.2.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.26.26.26.2.m1.1c">0.23\pm 0.03</annotation></semantics></math></td>
<td id="S4.T2.27.27.27.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.27.27.27.3.m1.1" class="ltx_Math" alttext="\textbf{0.70}\pm 0.02" display="inline"><semantics id="S4.T2.27.27.27.3.m1.1a"><mrow id="S4.T2.27.27.27.3.m1.1.1" xref="S4.T2.27.27.27.3.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.27.27.27.3.m1.1.1.2" xref="S4.T2.27.27.27.3.m1.1.1.2a.cmml">0.70</mtext><mo id="S4.T2.27.27.27.3.m1.1.1.1" xref="S4.T2.27.27.27.3.m1.1.1.1.cmml">±</mo><mn id="S4.T2.27.27.27.3.m1.1.1.3" xref="S4.T2.27.27.27.3.m1.1.1.3.cmml">0.02</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.27.27.27.3.m1.1b"><apply id="S4.T2.27.27.27.3.m1.1.1.cmml" xref="S4.T2.27.27.27.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.27.27.27.3.m1.1.1.1.cmml" xref="S4.T2.27.27.27.3.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.27.27.27.3.m1.1.1.2a.cmml" xref="S4.T2.27.27.27.3.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.27.27.27.3.m1.1.1.2.cmml" xref="S4.T2.27.27.27.3.m1.1.1.2">0.70</mtext></ci><cn type="float" id="S4.T2.27.27.27.3.m1.1.1.3.cmml" xref="S4.T2.27.27.27.3.m1.1.1.3">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.27.27.27.3.m1.1c">\textbf{0.70}\pm 0.02</annotation></semantics></math></td>
<td id="S4.T2.28.28.28.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T2.28.28.28.4.m1.1" class="ltx_Math" alttext="0.45\pm 0.03" display="inline"><semantics id="S4.T2.28.28.28.4.m1.1a"><mrow id="S4.T2.28.28.28.4.m1.1.1" xref="S4.T2.28.28.28.4.m1.1.1.cmml"><mn id="S4.T2.28.28.28.4.m1.1.1.2" xref="S4.T2.28.28.28.4.m1.1.1.2.cmml">0.45</mn><mo id="S4.T2.28.28.28.4.m1.1.1.1" xref="S4.T2.28.28.28.4.m1.1.1.1.cmml">±</mo><mn id="S4.T2.28.28.28.4.m1.1.1.3" xref="S4.T2.28.28.28.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.28.28.28.4.m1.1b"><apply id="S4.T2.28.28.28.4.m1.1.1.cmml" xref="S4.T2.28.28.28.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.28.28.28.4.m1.1.1.1.cmml" xref="S4.T2.28.28.28.4.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.28.28.28.4.m1.1.1.2.cmml" xref="S4.T2.28.28.28.4.m1.1.1.2">0.45</cn><cn type="float" id="S4.T2.28.28.28.4.m1.1.1.3.cmml" xref="S4.T2.28.28.28.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.28.28.28.4.m1.1c">0.45\pm 0.03</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.32.32.32" class="ltx_tr">
<th id="S4.T2.32.32.32.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">ChaLL-300M (ours)</th>
<th id="S4.T2.32.32.32.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">300M</th>
<td id="S4.T2.29.29.29.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T2.29.29.29.1.m1.1" class="ltx_Math" alttext="0.30\pm 0.01" display="inline"><semantics id="S4.T2.29.29.29.1.m1.1a"><mrow id="S4.T2.29.29.29.1.m1.1.1" xref="S4.T2.29.29.29.1.m1.1.1.cmml"><mn id="S4.T2.29.29.29.1.m1.1.1.2" xref="S4.T2.29.29.29.1.m1.1.1.2.cmml">0.30</mn><mo id="S4.T2.29.29.29.1.m1.1.1.1" xref="S4.T2.29.29.29.1.m1.1.1.1.cmml">±</mo><mn id="S4.T2.29.29.29.1.m1.1.1.3" xref="S4.T2.29.29.29.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.29.29.29.1.m1.1b"><apply id="S4.T2.29.29.29.1.m1.1.1.cmml" xref="S4.T2.29.29.29.1.m1.1.1"><csymbol cd="latexml" id="S4.T2.29.29.29.1.m1.1.1.1.cmml" xref="S4.T2.29.29.29.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.29.29.29.1.m1.1.1.2.cmml" xref="S4.T2.29.29.29.1.m1.1.1.2">0.30</cn><cn type="float" id="S4.T2.29.29.29.1.m1.1.1.3.cmml" xref="S4.T2.29.29.29.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.29.29.29.1.m1.1c">0.30\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.30.30.30.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T2.30.30.30.2.m1.1" class="ltx_Math" alttext="\textbf{0.16}\pm 0.01" display="inline"><semantics id="S4.T2.30.30.30.2.m1.1a"><mrow id="S4.T2.30.30.30.2.m1.1.1" xref="S4.T2.30.30.30.2.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.30.30.30.2.m1.1.1.2" xref="S4.T2.30.30.30.2.m1.1.1.2a.cmml">0.16</mtext><mo id="S4.T2.30.30.30.2.m1.1.1.1" xref="S4.T2.30.30.30.2.m1.1.1.1.cmml">±</mo><mn id="S4.T2.30.30.30.2.m1.1.1.3" xref="S4.T2.30.30.30.2.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.30.30.30.2.m1.1b"><apply id="S4.T2.30.30.30.2.m1.1.1.cmml" xref="S4.T2.30.30.30.2.m1.1.1"><csymbol cd="latexml" id="S4.T2.30.30.30.2.m1.1.1.1.cmml" xref="S4.T2.30.30.30.2.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.30.30.30.2.m1.1.1.2a.cmml" xref="S4.T2.30.30.30.2.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.30.30.30.2.m1.1.1.2.cmml" xref="S4.T2.30.30.30.2.m1.1.1.2">0.16</mtext></ci><cn type="float" id="S4.T2.30.30.30.2.m1.1.1.3.cmml" xref="S4.T2.30.30.30.2.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.30.30.30.2.m1.1c">\textbf{0.16}\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.31.31.31.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T2.31.31.31.3.m1.1" class="ltx_Math" alttext="0.68\pm 0.01" display="inline"><semantics id="S4.T2.31.31.31.3.m1.1a"><mrow id="S4.T2.31.31.31.3.m1.1.1" xref="S4.T2.31.31.31.3.m1.1.1.cmml"><mn id="S4.T2.31.31.31.3.m1.1.1.2" xref="S4.T2.31.31.31.3.m1.1.1.2.cmml">0.68</mn><mo id="S4.T2.31.31.31.3.m1.1.1.1" xref="S4.T2.31.31.31.3.m1.1.1.1.cmml">±</mo><mn id="S4.T2.31.31.31.3.m1.1.1.3" xref="S4.T2.31.31.31.3.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.31.31.31.3.m1.1b"><apply id="S4.T2.31.31.31.3.m1.1.1.cmml" xref="S4.T2.31.31.31.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.31.31.31.3.m1.1.1.1.cmml" xref="S4.T2.31.31.31.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.31.31.31.3.m1.1.1.2.cmml" xref="S4.T2.31.31.31.3.m1.1.1.2">0.68</cn><cn type="float" id="S4.T2.31.31.31.3.m1.1.1.3.cmml" xref="S4.T2.31.31.31.3.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.31.31.31.3.m1.1c">0.68\pm 0.01</annotation></semantics></math></td>
<td id="S4.T2.32.32.32.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S4.T2.32.32.32.4.m1.1" class="ltx_Math" alttext="\textbf{0.38}\pm 0.03" display="inline"><semantics id="S4.T2.32.32.32.4.m1.1a"><mrow id="S4.T2.32.32.32.4.m1.1.1" xref="S4.T2.32.32.32.4.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T2.32.32.32.4.m1.1.1.2" xref="S4.T2.32.32.32.4.m1.1.1.2a.cmml">0.38</mtext><mo id="S4.T2.32.32.32.4.m1.1.1.1" xref="S4.T2.32.32.32.4.m1.1.1.1.cmml">±</mo><mn id="S4.T2.32.32.32.4.m1.1.1.3" xref="S4.T2.32.32.32.4.m1.1.1.3.cmml">0.03</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.32.32.32.4.m1.1b"><apply id="S4.T2.32.32.32.4.m1.1.1.cmml" xref="S4.T2.32.32.32.4.m1.1.1"><csymbol cd="latexml" id="S4.T2.32.32.32.4.m1.1.1.1.cmml" xref="S4.T2.32.32.32.4.m1.1.1.1">plus-or-minus</csymbol><ci id="S4.T2.32.32.32.4.m1.1.1.2a.cmml" xref="S4.T2.32.32.32.4.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T2.32.32.32.4.m1.1.1.2.cmml" xref="S4.T2.32.32.32.4.m1.1.1.2">0.38</mtext></ci><cn type="float" id="S4.T2.32.32.32.4.m1.1.1.3.cmml" xref="S4.T2.32.32.32.4.m1.1.1.3">0.03</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.32.32.32.4.m1.1c">\textbf{0.38}\pm 0.03</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of the 5-fold evaluation. We report for each model the mean and standard deviation (mean<math id="S4.T2.34.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T2.34.m1.1b"><mo id="S4.T2.34.m1.1.1" xref="S4.T2.34.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T2.34.m1.1c"><csymbol cd="latexml" id="S4.T2.34.m1.1.1.cmml" xref="S4.T2.34.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.34.m1.1d">\pm</annotation></semantics></math>std) of the scores on each of the 5 folds. The bottom row shows the scores of our fine-tuned model. </figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Pre-trained ASR Systems</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We compare the performance of state-of-the-art ASR systems trained on datasets of adult English speakers. For this, we select seven different models, four based on a CTC decoding strategy, and three based on an encoder-decoder architecture. Our hypothesis is that CTC models are better at preserving speaker-errors as they do not rely on a language model, which potentially corrects such errors. Therefore, we do not use a n-gram language model during the CTC decoding phase, which is usually added for better WER performance. For the CTC-based models, we use the original Wav2VWec 2.0 large and base models <cite class="ltx_cite ltx_citemacro_cite">Baevski et al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> fine-tuned on 960h of Librispeech <cite class="ltx_cite ltx_citemacro_cite">Panayotov et al. (<a href="#bib.bib25" title="" class="ltx_ref">2015</a>)</cite> (English adult read-aloud data). We also use the fine-tuned Wav2Vec 2.0 models provided by <cite class="ltx_cite ltx_citemacro_citet">Grosman (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>, <a href="#bib.bib15" title="" class="ltx_ref">2022</a>)</cite>, which are based on the XLSR pretraining <cite class="ltx_cite ltx_citemacro_cite">Babu et al. (<a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>, and were fine-tuned on the CommonVoice 6.1 data <cite class="ltx_cite ltx_citemacro_cite">Ardila et al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite> consisting of approximately 2100 hours of English adult read-aloud data. For the encoder-decoder architecture, we used the Whisper medium, large, and large-v3 models provided by OpenAI <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:281.9pt;height:364.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.3pt,15.9pt) scale(0.919909043701365,0.919909043701365) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_smallcaps">Prediction</span></td>
<td id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_smallcaps">Chall-300M</span></td>
<td id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.4.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.5.1" class="ltx_text ltx_font_smallcaps">XLSR-1B</span></td>
</tr>
<tr id="S4.T3.1.1.2.2" class="ltx_tr">
<td id="S4.T3.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">de@!</td>
<td id="S4.T3.1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">the</td>
<td id="S4.T3.1.1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.946</td>
<td id="S4.T3.1.1.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.869</td>
<td id="S4.T3.1.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.2.2.5.1" class="ltx_text ltx_font_bold">0.805</span></td>
</tr>
<tr id="S4.T3.1.1.3.3" class="ltx_tr">
<td id="S4.T3.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">a@!</td>
<td id="S4.T3.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.3.3.3.1" class="ltx_text ltx_font_bold">0.114</span></td>
<td id="S4.T3.1.1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.327</td>
<td id="S4.T3.1.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.347</td>
</tr>
<tr id="S4.T3.1.1.4.4" class="ltx_tr">
<td id="S4.T3.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">a@!</td>
<td id="S4.T3.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">an</td>
<td id="S4.T3.1.1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.4.4.3.1" class="ltx_text ltx_font_bold">0.026</span></td>
<td id="S4.T3.1.1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.398</td>
<td id="S4.T3.1.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.257</td>
</tr>
<tr id="S4.T3.1.1.5.5" class="ltx_tr">
<td id="S4.T3.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">have@!</td>
<td id="S4.T3.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">has</td>
<td id="S4.T3.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.5.5.3.1" class="ltx_text ltx_font_bold">0.015</span></td>
<td id="S4.T3.1.1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.231</td>
<td id="S4.T3.1.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.052</td>
</tr>
<tr id="S4.T3.1.1.6.6" class="ltx_tr">
<td id="S4.T3.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">have@!</td>
<td id="S4.T3.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.6.6.3.1" class="ltx_text ltx_font_bold">0.034</span></td>
<td id="S4.T3.1.1.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.128</td>
<td id="S4.T3.1.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.129</td>
</tr>
<tr id="S4.T3.1.1.7.7" class="ltx_tr">
<td id="S4.T3.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">you@!</td>
<td id="S4.T3.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">your</td>
<td id="S4.T3.1.1.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.244</td>
<td id="S4.T3.1.1.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.306</td>
<td id="S4.T3.1.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.7.7.5.1" class="ltx_text ltx_font_bold">0.099</span></td>
</tr>
<tr id="S4.T3.1.1.8.8" class="ltx_tr">
<td id="S4.T3.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">it’s@!</td>
<td id="S4.T3.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">it</td>
<td id="S4.T3.1.1.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.8.8.3.1" class="ltx_text ltx_font_bold">0.068</span></td>
<td id="S4.T3.1.1.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.116</td>
<td id="S4.T3.1.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.136</td>
</tr>
<tr id="S4.T3.1.1.9.9" class="ltx_tr">
<td id="S4.T3.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">it’s@!</td>
<td id="S4.T3.1.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.9.9.3.1" class="ltx_text ltx_font_bold">0.043</span></td>
<td id="S4.T3.1.1.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.119</td>
<td id="S4.T3.1.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.146</td>
</tr>
<tr id="S4.T3.1.1.10.10" class="ltx_tr">
<td id="S4.T3.1.1.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">is@!</td>
<td id="S4.T3.1.1.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.10.10.3.1" class="ltx_text ltx_font_bold">0.05</span></td>
<td id="S4.T3.1.1.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.125</td>
<td id="S4.T3.1.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.136</td>
</tr>
<tr id="S4.T3.1.1.11.11" class="ltx_tr">
<td id="S4.T3.1.1.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">it’s@!</td>
<td id="S4.T3.1.1.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">is</td>
<td id="S4.T3.1.1.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.11.11.3.1" class="ltx_text ltx_font_bold">0.055</span></td>
<td id="S4.T3.1.1.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.133</td>
<td id="S4.T3.1.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.103</td>
</tr>
<tr id="S4.T3.1.1.12.12" class="ltx_tr">
<td id="S4.T3.1.1.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">are@!</td>
<td id="S4.T3.1.1.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.12.12.3.1" class="ltx_text ltx_font_bold">0.072</span></td>
<td id="S4.T3.1.1.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.162</td>
<td id="S4.T3.1.1.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.144</td>
</tr>
<tr id="S4.T3.1.1.13.13" class="ltx_tr">
<td id="S4.T3.1.1.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">dis@!</td>
<td id="S4.T3.1.1.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">this</td>
<td id="S4.T3.1.1.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.854</td>
<td id="S4.T3.1.1.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.83</td>
<td id="S4.T3.1.1.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.13.13.5.1" class="ltx_text ltx_font_bold">0.717</span></td>
</tr>
<tr id="S4.T3.1.1.14.14" class="ltx_tr">
<td id="S4.T3.1.1.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">it@!</td>
<td id="S4.T3.1.1.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.14.14.3.1" class="ltx_text ltx_font_bold">0.094</span></td>
<td id="S4.T3.1.1.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.311</td>
<td id="S4.T3.1.1.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.193</td>
</tr>
<tr id="S4.T3.1.1.15.15" class="ltx_tr">
<td id="S4.T3.1.1.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">he@!</td>
<td id="S4.T3.1.1.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.15.15.3.1" class="ltx_text ltx_font_bold">0.175</span></td>
<td id="S4.T3.1.1.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.254</td>
<td id="S4.T3.1.1.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.356</td>
</tr>
<tr id="S4.T3.1.1.16.16" class="ltx_tr">
<td id="S4.T3.1.1.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">de@!</td>
<td id="S4.T3.1.1.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.16.16.3.1" class="ltx_text ltx_font_bold">0.029</span></td>
<td id="S4.T3.1.1.16.16.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.123</td>
<td id="S4.T3.1.1.16.16.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.143</td>
</tr>
<tr id="S4.T3.1.1.17.17" class="ltx_tr">
<td id="S4.T3.1.1.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">the@!</td>
<td id="S4.T3.1.1.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.17.17.3.1" class="ltx_text ltx_font_bold">0.046</span></td>
<td id="S4.T3.1.1.17.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.24</td>
<td id="S4.T3.1.1.17.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.183</td>
</tr>
<tr id="S4.T3.1.1.18.18" class="ltx_tr">
<td id="S4.T3.1.1.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">in@!</td>
<td id="S4.T3.1.1.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.18.18.3.1" class="ltx_text ltx_font_bold">0.027</span></td>
<td id="S4.T3.1.1.18.18.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.127</td>
<td id="S4.T3.1.1.18.18.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.107</td>
</tr>
<tr id="S4.T3.1.1.19.19" class="ltx_tr">
<td id="S4.T3.1.1.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">you@!</td>
<td id="S4.T3.1.1.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.19.19.3.1" class="ltx_text ltx_font_bold">0.077</span></td>
<td id="S4.T3.1.1.19.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.113</td>
<td id="S4.T3.1.1.19.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.117</td>
</tr>
<tr id="S4.T3.1.1.20.20" class="ltx_tr">
<td id="S4.T3.1.1.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">i@!</td>
<td id="S4.T3.1.1.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.20.20.3.1" class="ltx_text ltx_font_bold">0.133</span></td>
<td id="S4.T3.1.1.20.20.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.248</td>
<td id="S4.T3.1.1.20.20.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.294</td>
</tr>
<tr id="S4.T3.1.1.21.21" class="ltx_tr">
<td id="S4.T3.1.1.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">on@!</td>
<td id="S4.T3.1.1.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">_</td>
<td id="S4.T3.1.1.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T3.1.1.21.21.3.1" class="ltx_text ltx_font_bold">0.019</span></td>
<td id="S4.T3.1.1.21.21.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.129</td>
<td id="S4.T3.1.1.21.21.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.105</td>
</tr>
<tr id="S4.T3.1.1.22.22" class="ltx_tr">
<td id="S4.T3.1.1.22.22.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" colspan="2">Mean (n=20)</td>
<td id="S4.T3.1.1.22.22.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt"><span id="S4.T3.1.1.22.22.2.1" class="ltx_text ltx_font_bold">0.156</span></td>
<td id="S4.T3.1.1.22.22.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">0.265</td>
<td id="S4.T3.1.1.22.22.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">0.229</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>System comparison on 20 most frequent incorrectly transcribed speaker-errors. For each system, the number indicates the fraction of cases in which the system incorrectly transcribes the error <span id="S4.T3.5.1" class="ltx_text ltx_font_smallcaps">Target</span> as <span id="S4.T3.6.2" class="ltx_text ltx_font_smallcaps">Prediction</span> (where "_" denotes deletion of <span id="S4.T3.7.3" class="ltx_text ltx_font_smallcaps">Target</span>). The lowest value of each row is set in boldface. The final row shows the mean across the 20 samples.</figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:281.9pt;height:360pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.1pt,18.0pt) scale(0.909193263638839,0.909193263638839) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.2.1" class="ltx_text ltx_font_smallcaps">Prediction</span></td>
<td id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.3.1" class="ltx_text ltx_font_smallcaps">Chall-300M</span></td>
<td id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.4.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T4.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1.5.1" class="ltx_text ltx_font_smallcaps">XLSR-1B</span></td>
</tr>
<tr id="S4.T4.1.1.2.2" class="ltx_tr">
<td id="S4.T4.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">have@!</td>
<td id="S4.T4.1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">have</td>
<td id="S4.T4.1.1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.2.2.3.1" class="ltx_text ltx_font_bold">0.875</span></td>
<td id="S4.T4.1.1.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.587</td>
<td id="S4.T4.1.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.699</td>
</tr>
<tr id="S4.T4.1.1.3.3" class="ltx_tr">
<td id="S4.T4.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">a@!</td>
<td id="S4.T4.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">a</td>
<td id="S4.T4.1.1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.3.3.3.1" class="ltx_text ltx_font_bold">0.804</span></td>
<td id="S4.T4.1.1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.215</td>
<td id="S4.T4.1.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.325</td>
</tr>
<tr id="S4.T4.1.1.4.4" class="ltx_tr">
<td id="S4.T4.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">is@!</td>
<td id="S4.T4.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">is</td>
<td id="S4.T4.1.1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.4.4.3.1" class="ltx_text ltx_font_bold">0.79</span></td>
<td id="S4.T4.1.1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.667</td>
<td id="S4.T4.1.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.769</td>
</tr>
<tr id="S4.T4.1.1.5.5" class="ltx_tr">
<td id="S4.T4.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">in@!</td>
<td id="S4.T4.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">in</td>
<td id="S4.T4.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.5.5.3.1" class="ltx_text ltx_font_bold">0.897</span></td>
<td id="S4.T4.1.1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.773</td>
<td id="S4.T4.1.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.807</td>
</tr>
<tr id="S4.T4.1.1.6.6" class="ltx_tr">
<td id="S4.T4.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">it’s@!</td>
<td id="S4.T4.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">it’s</td>
<td id="S4.T4.1.1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.6.6.3.1" class="ltx_text ltx_font_bold">0.703</span></td>
<td id="S4.T4.1.1.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.568</td>
<td id="S4.T4.1.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.482</td>
</tr>
<tr id="S4.T4.1.1.7.7" class="ltx_tr">
<td id="S4.T4.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">are@!</td>
<td id="S4.T4.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">are</td>
<td id="S4.T4.1.1.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.7.7.3.1" class="ltx_text ltx_font_bold">0.739</span></td>
<td id="S4.T4.1.1.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.688</td>
<td id="S4.T4.1.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.699</td>
</tr>
<tr id="S4.T4.1.1.8.8" class="ltx_tr">
<td id="S4.T4.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">on@!</td>
<td id="S4.T4.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">on</td>
<td id="S4.T4.1.1.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.8.8.3.1" class="ltx_text ltx_font_bold">0.917</span></td>
<td id="S4.T4.1.1.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.749</td>
<td id="S4.T4.1.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.79</td>
</tr>
<tr id="S4.T4.1.1.9.9" class="ltx_tr">
<td id="S4.T4.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">of@!</td>
<td id="S4.T4.1.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">of</td>
<td id="S4.T4.1.1.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.9.9.3.1" class="ltx_text ltx_font_bold">0.922</span></td>
<td id="S4.T4.1.1.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.705</td>
<td id="S4.T4.1.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.848</td>
</tr>
<tr id="S4.T4.1.1.10.10" class="ltx_tr">
<td id="S4.T4.1.1.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">the@!</td>
<td id="S4.T4.1.1.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">the</td>
<td id="S4.T4.1.1.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.10.10.3.1" class="ltx_text ltx_font_bold">0.815</span></td>
<td id="S4.T4.1.1.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.632</td>
<td id="S4.T4.1.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.678</td>
</tr>
<tr id="S4.T4.1.1.11.11" class="ltx_tr">
<td id="S4.T4.1.1.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">you@!</td>
<td id="S4.T4.1.1.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">you</td>
<td id="S4.T4.1.1.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.606</td>
<td id="S4.T4.1.1.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.55</td>
<td id="S4.T4.1.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.11.11.5.1" class="ltx_text ltx_font_bold">0.735</span></td>
</tr>
<tr id="S4.T4.1.1.12.12" class="ltx_tr">
<td id="S4.T4.1.1.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">she@!</td>
<td id="S4.T4.1.1.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">she</td>
<td id="S4.T4.1.1.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.12.12.3.1" class="ltx_text ltx_font_bold">0.867</span></td>
<td id="S4.T4.1.1.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.713</td>
<td id="S4.T4.1.1.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.774</td>
</tr>
<tr id="S4.T4.1.1.13.13" class="ltx_tr">
<td id="S4.T4.1.1.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">it@!</td>
<td id="S4.T4.1.1.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">it</td>
<td id="S4.T4.1.1.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.13.13.3.1" class="ltx_text ltx_font_bold">0.772</span></td>
<td id="S4.T4.1.1.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.579</td>
<td id="S4.T4.1.1.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.659</td>
</tr>
<tr id="S4.T4.1.1.14.14" class="ltx_tr">
<td id="S4.T4.1.1.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">has@!</td>
<td id="S4.T4.1.1.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">has</td>
<td id="S4.T4.1.1.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.14.14.3.1" class="ltx_text ltx_font_bold">0.825</span></td>
<td id="S4.T4.1.1.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.775</td>
<td id="S4.T4.1.1.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.774</td>
</tr>
<tr id="S4.T4.1.1.15.15" class="ltx_tr">
<td id="S4.T4.1.1.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">make@!</td>
<td id="S4.T4.1.1.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">make</td>
<td id="S4.T4.1.1.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.15.15.3.1" class="ltx_text ltx_font_bold">0.95</span></td>
<td id="S4.T4.1.1.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.746</td>
<td id="S4.T4.1.1.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.808</td>
</tr>
<tr id="S4.T4.1.1.16.16" class="ltx_tr">
<td id="S4.T4.1.1.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">do@!</td>
<td id="S4.T4.1.1.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">do</td>
<td id="S4.T4.1.1.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.16.16.3.1" class="ltx_text ltx_font_bold">0.82</span></td>
<td id="S4.T4.1.1.16.16.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.744</td>
<td id="S4.T4.1.1.16.16.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.748</td>
</tr>
<tr id="S4.T4.1.1.17.17" class="ltx_tr">
<td id="S4.T4.1.1.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">much@!</td>
<td id="S4.T4.1.1.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">much</td>
<td id="S4.T4.1.1.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.17.17.3.1" class="ltx_text ltx_font_bold">0.98</span></td>
<td id="S4.T4.1.1.17.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.96</td>
<td id="S4.T4.1.1.17.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.96</td>
</tr>
<tr id="S4.T4.1.1.18.18" class="ltx_tr">
<td id="S4.T4.1.1.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">he@!</td>
<td id="S4.T4.1.1.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">he</td>
<td id="S4.T4.1.1.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.18.18.3.1" class="ltx_text ltx_font_bold">0.679</span></td>
<td id="S4.T4.1.1.18.18.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.627</td>
<td id="S4.T4.1.1.18.18.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.561</td>
</tr>
<tr id="S4.T4.1.1.19.19" class="ltx_tr">
<td id="S4.T4.1.1.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">not@!</td>
<td id="S4.T4.1.1.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">not</td>
<td id="S4.T4.1.1.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.19.19.3.1" class="ltx_text ltx_font_bold">0.89</span></td>
<td id="S4.T4.1.1.19.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.75</td>
<td id="S4.T4.1.1.19.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.777</td>
</tr>
<tr id="S4.T4.1.1.20.20" class="ltx_tr">
<td id="S4.T4.1.1.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">at@!</td>
<td id="S4.T4.1.1.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">at</td>
<td id="S4.T4.1.1.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.20.20.3.1" class="ltx_text ltx_font_bold">0.811</span></td>
<td id="S4.T4.1.1.20.20.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.612</td>
<td id="S4.T4.1.1.20.20.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.759</td>
</tr>
<tr id="S4.T4.1.1.21.21" class="ltx_tr">
<td id="S4.T4.1.1.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">don’t@!</td>
<td id="S4.T4.1.1.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">don’t</td>
<td id="S4.T4.1.1.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T4.1.1.21.21.3.1" class="ltx_text ltx_font_bold">0.885</span></td>
<td id="S4.T4.1.1.21.21.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.826</td>
<td id="S4.T4.1.1.21.21.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.811</td>
</tr>
<tr id="S4.T4.1.1.22.22" class="ltx_tr">
<td id="S4.T4.1.1.22.22.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" colspan="2">Mean (n=20)</td>
<td id="S4.T4.1.1.22.22.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt"><span id="S4.T4.1.1.22.22.2.1" class="ltx_text ltx_font_bold">0.827</span></td>
<td id="S4.T4.1.1.22.22.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">0.673</td>
<td id="S4.T4.1.1.22.22.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">0.723</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>System comparison on 20 most frequent correctly preserved speaker-errors. For each system, the number indicates the fraction of cases in which the system correctly transcribes the error <span id="S4.T4.4.1" class="ltx_text ltx_font_smallcaps">Target</span> as <span id="S4.T4.5.2" class="ltx_text ltx_font_smallcaps">Prediction</span>. The highest value of each row is set in boldface. The final row shows the mean across the 20 samples.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Fine-tuning Pre-trained ASR Systems Using Learner Data</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">To evaluate the impact of fine-tuning, we fine-tune the Wav2Vec-XLSR-300M model <span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Due to the high computational cost, we decided to use the 300M model instead of the 1B model.</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Babu et al. (<a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite> on our collected language learner data.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Data Preprocessing.</span>
For fine-tuning, we split longer utterances into chunks of a maximum of 12 seconds and removed trailing pauses. The transcripts were preprocessed as follows:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Remove error annotations and other transcript conventions</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">Convert to lowercase</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Standardise text (Remove text between brackets and parentheses. Standardise apostrophes by removing spaces before them. Remove commas between digits and periods not followed by numbers.)</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">Clean and standardise whitespace</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p">Normalise/remove special characters.</p>
</div>
</li>
<li id="S4.I1.i6" class="ltx_item" style="list-style-type:none;padding-top:1.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i6.p1" class="ltx_para">
<p id="S4.I1.i6.p1.1" class="ltx_p">Transform numbers into words using <span id="S4.I1.i6.p1.1.1" class="ltx_text ltx_font_italic">num2words</span></p>
</div>
</li>
</ul>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Approach.</span> We apply 5-fold cross-validation (cf. <a href="#S3.SS4.SSS1" title="3.4.1 Data Folds ‣ 3.4 Final Dataset ‣ 3 Dataset: Spontaneous Speech of Young Learners of English ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4.1</span></a>), that is, we train on four folds, and evaluate on the held-out fold. We trained each run on 6 nVidia Tesla V100 GPUs for 4000 steps using a learning rate of 3e-5, a per-device batch size of 14, and 15 gradient accumulation steps (for a total batch size of 1260, which corresponds to approx. 2 hours of audio per batch), and we used the 8-bit AdamW optimizer <cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a href="#bib.bib20" title="" class="ltx_ref">2017</a>); Dettmers et al. (<a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>.
Our fine-tuned model, called ChaLL-300M, is available on HuggingFace.<a href="#footnote2" title="footnote 2 ‣ Contributions ‣ 1 Introduction ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Quantitative Results</h3>

<div id="S4.SS4.p1" class="ltx_para ltx_noindent">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_bold">Performance Metrics.</span> The scores achieved by the different models are summarised in Table <a href="#S4.T2" title="Table 2 ‣ 4.1 Metrics ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Among the pre-trained models, <em id="S4.SS4.p1.1.2" class="ltx_emph ltx_font_italic">Whisper-Large</em> achieves the best overall WER and chrF scores. However, the best CERand WEPR scores were achieved by the <em id="S4.SS4.p1.1.3" class="ltx_emph ltx_font_italic">XLSR-1B</em> models fine-tuned on CommonVoice 6.1. This aligns with our expectations, as Whisper models are currently the most powerful ASR models, and we expected them to perform best in terms of WER. However, for our use-case, we are more interested in error preservation, thus, CTC-based models without language models are best for preserving the errors. The fine-tuning step on our dataset consisting of learner data yielded a significant boost in performance. It achieves the best WEPR score, which measures the error retention capability. The most comparable model in terms of number of parameters is the XLSR-53 model trained on adult read-aloud data. In comparison to this model, <em id="S4.SS4.p1.1.4" class="ltx_emph ltx_font_italic">ChaLL-300M</em> achieves an improvement of 8 points in WER and a 12-point improvement in WEPR. It is generally the case that larger models perform better. Thus, the interpretation of the results needs to factor this in. As most models are larger than ours, it becomes evident that fine-tuning on learner data increases the performance on this data in general, and the CTC architecture yields a better out-of-the-box preservation of speaker-errors .</p>
</div>
<figure id="S4.T5" class="ltx_table">
<div id="S4.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:175.7pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-62.1pt,29.5pt) scale(0.747982973837417,0.747982973837417) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.1.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T5.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r">Utterance</td>
<td id="S4.T5.1.1.1.1.3" class="ltx_td ltx_align_left">Err. Type.</td>
</tr>
<tr id="S4.T5.1.1.2.2" class="ltx_tr">
<td id="S4.T5.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T5.1.1.2.2.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T5.1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Yeah. Uhm it’s – It <span id="S4.T5.1.1.2.2.2.1" class="ltx_text" style="color:#FF0000;">have</span> a <span id="S4.T5.1.1.2.2.2.2" class="ltx_text" style="color:#FF8000;">Lampe</span>. Uhm you can –</td>
<td id="S4.T5.1.1.2.2.3" class="ltx_td ltx_align_left ltx_border_t">has/have, German</td>
</tr>
<tr id="S4.T5.1.1.3.3" class="ltx_tr">
<td id="S4.T5.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.3.3.1.1" class="ltx_text ltx_font_smallcaps">Chall300M</span></td>
<td id="S4.T5.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r">e uhm it’s it’s <span id="S4.T5.1.1.3.3.2.1" class="ltx_text" style="color:#FF0000;">have</span> a <span id="S4.T5.1.1.3.3.2.2" class="ltx_text" style="color:#FF8000;">lampe</span> you can</td>
<td id="S4.T5.1.1.3.3.3" class="ltx_td ltx_align_left">has/have, German</td>
</tr>
<tr id="S4.T5.1.1.4.4" class="ltx_tr">
<td id="S4.T5.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.4.4.1.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T5.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r">it has a lamp</td>
<td id="S4.T5.1.1.4.4.3" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S4.T5.1.1.5.5" class="ltx_tr">
<td id="S4.T5.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S4.T5.1.1.5.5.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T5.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">(…) What you’re rather be a (…)- able <span id="S4.T5.1.1.5.5.2.1" class="ltx_text" style="color:#FF0000;">for</span> fly or be invisible- invisible?</td>
<td id="S4.T5.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_tt">for/to</td>
</tr>
<tr id="S4.T5.1.1.6.6" class="ltx_tr">
<td id="S4.T5.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.6.6.1.1" class="ltx_text ltx_font_smallcaps">Chall300M</span></td>
<td id="S4.T5.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r">wuld your reader be be aabble <span id="S4.T5.1.1.6.6.2.1" class="ltx_text" style="color:#FF0000;">for</span> fly or be invisible invisible</td>
<td id="S4.T5.1.1.6.6.3" class="ltx_td ltx_align_left">for/to</td>
</tr>
<tr id="S4.T5.1.1.7.7" class="ltx_tr">
<td id="S4.T5.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.7.7.1.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T5.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r">would your reader be able to fly or be invisible</td>
<td id="S4.T5.1.1.7.7.3" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S4.T5.1.1.8.8" class="ltx_tr">
<td id="S4.T5.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S4.T5.1.1.8.8.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T5.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Do you have <span id="S4.T5.1.1.8.8.2.1" class="ltx_text" style="color:#FF0000;">a</span> enemy?</td>
<td id="S4.T5.1.1.8.8.3" class="ltx_td ltx_align_left ltx_border_tt">a/an</td>
</tr>
<tr id="S4.T5.1.1.9.9" class="ltx_tr">
<td id="S4.T5.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.9.9.1.1" class="ltx_text ltx_font_smallcaps">Chall300M</span></td>
<td id="S4.T5.1.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r">do you have <span id="S4.T5.1.1.9.9.2.1" class="ltx_text" style="color:#FF0000;">a</span> enemey</td>
<td id="S4.T5.1.1.9.9.3" class="ltx_td ltx_align_left">a/an</td>
</tr>
<tr id="S4.T5.1.1.10.10" class="ltx_tr">
<td id="S4.T5.1.1.10.10.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.10.10.1.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T5.1.1.10.10.2" class="ltx_td ltx_align_left ltx_border_r">do you have an enemy</td>
<td id="S4.T5.1.1.10.10.3" class="ltx_td ltx_align_left">-</td>
</tr>
<tr id="S4.T5.1.1.11.11" class="ltx_tr">
<td id="S4.T5.1.1.11.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S4.T5.1.1.11.11.1.1" class="ltx_text ltx_font_smallcaps">Target</span></td>
<td id="S4.T5.1.1.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">What <span id="S4.T5.1.1.11.11.2.1" class="ltx_text" style="color:#FF0000;">do</span> you favourite food?</td>
<td id="S4.T5.1.1.11.11.3" class="ltx_td ltx_align_left ltx_border_tt">do/is</td>
</tr>
<tr id="S4.T5.1.1.12.12" class="ltx_tr">
<td id="S4.T5.1.1.12.12.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T5.1.1.12.12.1.1" class="ltx_text ltx_font_smallcaps">Chall300M</span></td>
<td id="S4.T5.1.1.12.12.2" class="ltx_td ltx_align_left ltx_border_r">what <span id="S4.T5.1.1.12.12.2.1" class="ltx_text" style="color:#FF0000;">do</span> you favorite food</td>
<td id="S4.T5.1.1.12.12.3" class="ltx_td ltx_align_left">do/is</td>
</tr>
<tr id="S4.T5.1.1.13.13" class="ltx_tr">
<td id="S4.T5.1.1.13.13.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span id="S4.T5.1.1.13.13.1.1" class="ltx_text ltx_font_smallcaps">Whisper-Large</span></td>
<td id="S4.T5.1.1.13.13.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">what’s your favorite food</td>
<td id="S4.T5.1.1.13.13.3" class="ltx_td ltx_align_left ltx_border_b">-</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Manually selected examples.</figcaption>
</figure>
<div id="S4.SS4.p2" class="ltx_para ltx_noindent">
<p id="S4.SS4.p2.1" class="ltx_p"><span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_bold">WEPR Analysis.</span> To show in more detail the reduction in WEPR, we compare the handling of specific speaker errors. Table <a href="#S4.T3" title="Table 3 ‣ 4.2 Pre-trained ASR Systems ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the confusion for the 20 most frequent examples, that is, the cases where the ASR system corrects a error it should have preserved. For each type of confusion, we report the rate at which it occurs. For instance, when the speaker mistakenly said "have" (denoted "have@!"), <em id="S4.SS4.p2.1.2" class="ltx_emph ltx_font_italic">ChaLL-300M</em> corrected it to "has" in 1.5% of cases, Whisper-Large corrected it in 23.1% of cases, and XLSR-1B in 12.9% of cases. Thus, <em id="S4.SS4.p2.1.3" class="ltx_emph ltx_font_italic">ChaLL-300M</em> preserved this particular kind of error the best. In total, it mistakenly corrected 15% of the 20 most frequent speaker-errors, while <em id="S4.SS4.p2.1.4" class="ltx_emph ltx_font_italic">Whisper-Large</em> corrected 26%, and <em id="S4.SS4.p2.1.5" class="ltx_emph ltx_font_italic">XLSR-1B</em> corrected 22.9%. It is interesting to note that two out of total three cases where <em id="S4.SS4.p2.1.6" class="ltx_emph ltx_font_italic">XLSR-1B</em> has the lowest rate of mis-correction is for pronunciation errors ("de@!" and "dis@!"). We also note that a majority of the most frequent unwanted error-corrections are deletions.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">On the other hand, Table <a href="#S4.T4" title="Table 4 ‣ 4.2 Pre-trained ASR Systems ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the frequency at which the ASR systems correctly preserved the errors made by the speakers. For instance, when the speaker mistakenly says "have" (denoted as "have@!"), then <em id="S4.SS4.p3.1.1" class="ltx_emph ltx_font_italic">ChaLL-300M</em> preserves this error in 87.5% of cases, while <em id="S4.SS4.p3.1.2" class="ltx_emph ltx_font_italic">Whisper-Large</em> preserves it in only 58.7% and <em id="S4.SS4.p3.1.3" class="ltx_emph ltx_font_italic">XLSR-1B</em> in only 69.9% of cases. In total, <em id="S4.SS4.p3.1.4" class="ltx_emph ltx_font_italic">ChaLL-300M</em> is able to preserve 82.7% of the of the 20 most frequent errors made by speakers, while <em id="S4.SS4.p3.1.5" class="ltx_emph ltx_font_italic">Whisper-Large</em> only preserved 67.3% of speaker errors and <em id="S4.SS4.p3.1.6" class="ltx_emph ltx_font_italic">XLSR-1B</em> preserved 72.3%.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">Thus, <em id="S4.SS4.p4.1.1" class="ltx_emph ltx_font_italic">ChaLL-300M</em> displays a strong ability to preserve the errors made by speakers, which is crucial for the downstream task of providing automated corrective feedback.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Qualitative Results</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Table <a href="#S4.T5" title="Table 5 ‣ 4.4 Quantitative Results ‣ 4 Error-Preserving Automatic Speech Recognition ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows four manually selected examples, highlighting some errors which the best-performing pre-trained model, <em id="S4.SS5.p1.1.1" class="ltx_emph ltx_font_italic">Whisper-Large</em>, corrects, and our model preserves. In the first example, it shows the error of using "have" instead of "has", as well as using the German pronunciation of the word "lamp" (i.e., "Lampe"). <em id="S4.SS5.p1.1.2" class="ltx_emph ltx_font_italic">Whisper-Large</em> corrects these errors, and creates a grammatically correct English utterance. The <em id="S4.SS5.p1.1.3" class="ltx_emph ltx_font_italic">ChaLL-300M</em> model preserves these errors as desired. The second error is a prepositional error, where the learner said "for fly" instead of "to fly". The <em id="S4.SS5.p1.1.4" class="ltx_emph ltx_font_italic">Chall-300M</em> model correctly preserved this error, while the language model used in <em id="S4.SS5.p1.1.5" class="ltx_emph ltx_font_italic">Whisper-Large</em> smoothed out the error. The third example is an error of the indefinite article: the learner used "a" instead of "an", which <em id="S4.SS5.p1.1.6" class="ltx_emph ltx_font_italic">ChaLL-300M</em> correctly preserved while <em id="S4.SS5.p1.1.7" class="ltx_emph ltx_font_italic">Whisper-Large</em> corrected the error. The final example contains the usage of the wrong verb "do" instead of "is", which again is correctly preserved by our model while Whisper corrects the error.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Outlook</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our work shows that state-of-the-art ASR systems have difficulties handling young learners’ speech; furthermore, they tend to correct the errors made by the speakers, which makes the downstream identification of speaker errors and provision of corrective feedback impossible. Thus, we collected around 85 hours of children’s language learner speech data, which we used to fine-tune a custom model. Our model outperforms all the others (including Whisper-Large) in terms of error preservation (Word-Based Error Preservation Rate, WEPR) and surpasses the English models of comparable size (<math id="S5.p1.1.m1.1" class="ltx_Math" alttext="\approx 300M" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml"></mi><mo id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">≈</mo><mrow id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml"><mn id="S5.p1.1.m1.1.1.3.2" xref="S5.p1.1.m1.1.1.3.2.cmml">300</mn><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.1.1.3.1" xref="S5.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S5.p1.1.m1.1.1.3.3" xref="S5.p1.1.m1.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><approx id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></approx><csymbol cd="latexml" id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">absent</csymbol><apply id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3"><times id="S5.p1.1.m1.1.1.3.1.cmml" xref="S5.p1.1.m1.1.1.3.1"></times><cn type="integer" id="S5.p1.1.m1.1.1.3.2.cmml" xref="S5.p1.1.m1.1.1.3.2">300</cn><ci id="S5.p1.1.m1.1.1.3.3.cmml" xref="S5.p1.1.m1.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\approx 300M</annotation></semantics></math> parameters) by a large margin in terms of Word Error Rate. Thus, our research shows the necessity of using targeted data (in this case, children who learn a foreign language) to fine-tune an ASR module, which is useful in downstream tasks. The focus of this work lies in a) investigating the utility of existing systems and b) creating an adequate ASR system that can be used as part of a language learning support tool to increase the students’ speaking opportunities.
As a next step, we will investigate how to enhance error preservation. For this, training larger models is the most straightforward approach. However, we also plan to train the ASR system jointly with error annotations. For this, we started the creation of more detailed error annotations. Initial results have shown that verbal errors are the largest error category for young learners of English in Switzerland (with about 22% of all errors) , and within these, wrong subject-verb agreement is most frequent.
Similarly, investigating how to handle frequent code-switching to German words or sentence fragments is an unsolved issue that needs to be addressed to improve downstream tasks. Even <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">Whisper-Large</em>, which can handle multiple languages in principle, did not perform well in detecting code-switching.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Finally, we aim to evaluate ASR models in the context of integrating them with a conversational agent and corrective feedback.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by the Swiss Innovation Agency (Innosuisse) within the project "Towards a Voice-Based Chatbot for Language Learners (ChaLL)" [102.580.1 IP-ICT]. We thank the teachers and students who were part of the data collection for their efforts.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">While offering a unique tool for error-preserving ASR of young language learners, this work presents itself with a few limitations.</p>
</div>
<section id="Sx2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Limited Demographic.</h5>

<div id="Sx2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px1.p1.1" class="ltx_p">The dataset stems from a specific demographic of Swiss school children learning English in grades 4 to 6. An extension of the work would include language learners from other countries/with an academic language other than German/with a different language of instruction, or a larger range of ages. Thus, the transferability of our results must be confirmed with a different dataset.</p>
</div>
</section>
<section id="Sx2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Outsourcing Error Annotation.</h5>

<div id="Sx2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px2.p1.1" class="ltx_p">The outsourcing of transcription and error annotations always poses a risk of yielding erroneous data, since most transcribers are not trained in error annotation. We mitigated this risk by providing comprehensive guidelines and a steady exchange with the transcription agency. However, we plan to enhance the error annotations with a more detailed label set and annotators trained in this task.</p>
</div>
</section>
<section id="Sx2.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Small Model.</h5>

<div id="Sx2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px3.p1.1" class="ltx_p">Due to the high computational cost of fine-tuning a 1B parameter model, we limited ourselves to fine-tuning the 300M parameter XLSR model. Most research indicates that the usage of larger models yields better results; thus, there is still potential in terms of increasing WER and WEPR. However, our results showed that even a small model can preserve errors better than state-of-the-art pre-trained models, which was the main scope of this work.</p>
</div>
</section>
<section id="Sx2.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">No Performance Tuning.</h5>

<div id="Sx2.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px4.p1.1" class="ltx_p">Since the scope of this work is to understand if the usage of young learners’ speech data is beneficial for our purposes, we did not tune the performance of our model. That is, we did not perform any hyper-parameter tuning or any other methods to increase performance (e.g., joint prediction of errors using a language model). Thus, there is still a large margin of improvement using our dataset.</p>
</div>
</section>
<section id="Sx2.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data Availability.</h5>

<div id="Sx2.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="Sx2.SS0.SSS0.Px5.p1.1" class="ltx_p">Since our data consists of children’s spontaneous speech, we must ensure its protection. Thus, we cannot make it freely available. While we publicly release the models trained on the data, access to the transcripts and recordings can only be granted in the scope of a joint project, subject to a collaboration agreement.</p>
</div>
</section>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethical Considerations</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">The main risks in this project have to do with data protection: all speakers are minors between 9 and 14 years of age, so their personal data must be very well safeguarded. Therefore, key government institutions approved the data collection before speakers were recruited, and informed consent was obtained from each speaker’s legal caretaker (cp. details in Section <a href="#S3.SS1" title="3.1 Audio Recording ‣ 3 Dataset: Spontaneous Speech of Young Learners of English ‣ Error-preserving Automatic Speech Recognition of Young English Learners’ Language" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
Consent forms entailed information about the nature of the project and data collection procedures, as well as a comprehensive description of the legal principles we followed to collect, use, and store voice data, transcripts, and annotations. The data protection measures we implemented for security and confidentiality were fully disclosed (e.g. password-protected documents, pseudonymisation, firewalls etc.) and risks to participants (e.g. potential voice recognition by project members) were outlined. Voice data and transcripts were pseudonymised by those project members who act as data owners before sharing them with other research partners and third parties.
Third-party access to the collected data will be enabled in a closely controlled setting consisting of a joint project with a collaboration agreement.</p>
</div>
</section>
<section id="Sx4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Use of AI Assistants</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.1" class="ltx_p">ChatGPT was used to support the creation of some figures. No AI assistants were used to write the text of this paper.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmed et al. (2021)</span>
<span class="ltx_bibblock">
Beena Ahmed, Kirrie J. Ballard, Denis Burnham, Tharmakulasingam Sirojan, Hadi Mehmood, Dominique Estival, Elise Baker, Felicity Cox, Joanne Arciuli, Titia Benders, Katherine Demuth, Barbara Kelly, Chloé Diskin-Holdaway, Mostafa Shahin, Vidhyasaharan Sethu, Julien Epps, Chwee Beng Lee, and Eliathamby Ambikairajah. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2021-2000" title="" class="ltx_ref ltx_href">AusKidTalk: An Auditory-Visual Corpus of 3- to 12-Year-Old Australian Children’s Speech</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2021</em>, pages 3680–3684.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ardila et al. (2020)</span>
<span class="ltx_bibblock">
R. Ardila, M. Branson, K. Davis, M. Henretty, M. Kohler, J. Meyer, R. Morais, L. Saunders, F. M. Tyers, and G. Weber. 2020.

</span>
<span class="ltx_bibblock">Common voice: A massively-multilingual speech corpus.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Conference on Language Resources and Evaluation (LREC 2020)</em>, pages 4211–4215.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Babu et al. (2021)</span>
<span class="ltx_bibblock">
Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et al. 2021.

</span>
<span class="ltx_bibblock">Xls-r: Self-supervised cross-lingual speech representation learning at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.09296</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski et al. (2020)</span>
<span class="ltx_bibblock">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli. 2020.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:12449–12460.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Batliner et al. (2005)</span>
<span class="ltx_bibblock">
Anton Batliner, Mats Blomberg, Shona D’Arcy, Daniel Elenius, Diego Giuliani, Matteo Gerosa, Christian Hacker, Martin Russell, Stefan Steidl, and Michael Wong. 2005.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2005-705" title="" class="ltx_ref ltx_href">The PF_STAR children’s speech corpus</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2005</em>, pages 2761–2764.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baur et al. (2018)</span>
<span class="ltx_bibblock">
Claudia Baur, Andrew Caines, Cathy Chua, Johanna Gerlach, Mengjie Qian, Manny Rayner, Martin Russell, Helmer Strik, and Xizi Wei. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2018-97" title="" class="ltx_ref ltx_href">Overview of the 2018 spoken call shared task</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of Interspeech 2018</em>, Interspeech, pages 2354–2358. ISCA.

</span>
<span class="ltx_bibblock">Interspeech 2018 ; Conference date: 02-09-2018 Through 06-09-2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deriu et al. (2021)</span>
<span class="ltx_bibblock">
Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie Rosset, Eneko Agirre, and Mark Cieliebak. 2021.

</span>
<span class="ltx_bibblock">Survey on evaluation methods for dialogue systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence Review</em>, 54:755–810.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al. (2021)</span>
<span class="ltx_bibblock">
Tim Dettmers, Mike Lewis, Sam Shleifer, and Luke Zettlemoyer. 2021.

</span>
<span class="ltx_bibblock">8-bit optimizers via block-wise quantization.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.02861</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ellis (2021)</span>
<span class="ltx_bibblock">
Rod Ellis. 2021.

</span>
<span class="ltx_bibblock">Explicit and Implicit Oral Corrective Feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">The Cambridge Handbook of Corrective Feedback in Second Language Learning and Teaching</em>, pages 341–364.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eskenazi (1996)</span>
<span class="ltx_bibblock">
Maxine S Eskenazi. 1996.

</span>
<span class="ltx_bibblock">Kids: a database of children’s speech.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">The Journal of the Acoustical Society of America</em>, 100(4_Supplement):2759–2759.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gerosa et al. (2006)</span>
<span class="ltx_bibblock">
Matteo Gerosa, Diego Giuliani, and Shrikanth Narayanan. 2006.

</span>
<span class="ltx_bibblock">Acoustic analysis and automatic recognition of spontaneous children’s speech.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Ninth International Conference on Spoken Language Processing</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gretter et al. (2020)</span>
<span class="ltx_bibblock">
Roberto Gretter, Marco Matassoni, Stefano Bannò, and Falavigna Daniele. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2020.lrec-1.47" title="" class="ltx_ref ltx_href">TLT-school: a corpus of non native children speech</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pages 378–385, Marseille, France. European Language Resources Association.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grimm et al. (2015)</span>
<span class="ltx_bibblock">
Nancy Grimm, Michael Meyer, and Laurenz Volkmann. 2015.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Teaching English</em>.

</span>
<span class="ltx_bibblock">Narr Francke Attempto Verlag.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grosman (2021)</span>
<span class="ltx_bibblock">
Jonatas Grosman. 2021.

</span>
<span class="ltx_bibblock">Fine-tuned XLSR-53 large model for speech recognition in English.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grosman (2022)</span>
<span class="ltx_bibblock">
Jonatas Grosman. 2022.

</span>
<span class="ltx_bibblock">Fine-tuned XLS-R 1B model for speech recognition in English.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/jonatasgrosman/wav2vec2-xls-r-1b-english" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/jonatasgrosman/wav2vec2-xls-r-1b-english</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hagen et al. (2003)</span>
<span class="ltx_bibblock">
Andreas Hagen, Bryan Pellom, and Ronald Cole. 2003.

</span>
<span class="ltx_bibblock">Children’s speech recognition with application to interactive books and tutors.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">2003 IEEE Workshop on Automatic Speech Recognition and Understanding (IEEE Cat. No. 03EX721)</em>, pages 186–191. IEEE.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hedge (2001)</span>
<span class="ltx_bibblock">
Tricia Hedge. 2001.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Teaching and learning in the language classroom</em>, volume 106.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kleinschroth and Oldham (2014)</span>
<span class="ltx_bibblock">
Robert Kleinschroth and Pete Oldham. 2014.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Sprechkompetenz-Training im Englischunterricht 7-8: Lebensnahe Sprechanlässe und vielfältige Aufgaben (7. und 8. Klasse)</em>.

</span>
<span class="ltx_bibblock">Auer Verlag.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (1999)</span>
<span class="ltx_bibblock">
Sungbok Lee, Alexandros Potamianos, and Shrikanth Narayanan. 1999.

</span>
<span class="ltx_bibblock">Acoustics of children’s speech: Developmental changes of temporal and spectral parameters.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">The Journal of the Acoustical Society of America</em>, 105(3):1455–1468.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2017)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2017.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.05101</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2022)</span>
<span class="ltx_bibblock">
Renee Lu, Mostafa Shahin, and Beena Ahmed. 2022.

</span>
<span class="ltx_bibblock">Improving children’s speech recognition by fine-tuning self-supervised adult speech representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.07769</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2023)</span>
<span class="ltx_bibblock">
Rao Ma, Mengjie Qian, Mark Gales, and Katherine M Knill. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/SLaTE.2023-20" title="" class="ltx_ref ltx_href">Adapting an ASR Foundation Model for Spoken Language Assessment</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proc. 9th Workshop on Speech and Language Technology in Education (SLaTE)</em>, pages 104–108.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malik et al. (2021)</span>
<span class="ltx_bibblock">
Mishaim Malik, Muhammad Kamran Malik, Khawar Mehmood, and Imran Makhdoom. 2021.

</span>
<span class="ltx_bibblock">Automatic speech recognition: a survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Multimedia Tools and Applications</em>, 80:9411–9457.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ni et al. (2023)</span>
<span class="ltx_bibblock">
Jinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, and Erik Cambria. 2023.

</span>
<span class="ltx_bibblock">Recent advances in deep learning based dialogue systems: A systematic survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence review</em>, 56(4):3055–3155.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panayotov et al. (2015)</span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. 2015.

</span>
<span class="ltx_bibblock">Librispeech: an asr corpus based on public domain audio books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on</em>, pages 5206–5210. IEEE.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfenninger and Lendl (2017)</span>
<span class="ltx_bibblock">
Simone E. Pfenninger and Johanna Lendl. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.14746/ssllt.2017.7.3.5" title="" class="ltx_ref ltx_href">Transitional woes: On the impact of l2 input continuity from primary to secondary school</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Studies in Second Language Learning and Teaching</em>, 7(3):443–469.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Popović (2015)</span>
<span class="ltx_bibblock">
Maja Popović. 2015.

</span>
<span class="ltx_bibblock">chrf: character n-gram f-score for automatic mt evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the tenth workshop on statistical machine translation</em>, pages 392–395.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Potamianos and Narayanan (2003)</span>
<span class="ltx_bibblock">
A. Potamianos and S. Narayanan. 2003.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/TSA.2003.818026" title="" class="ltx_ref ltx_href">Robust recognition of children’s speech</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Speech and Audio Processing</em>, 11(6):603–616.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pradhan et al. (2016)</span>
<span class="ltx_bibblock">
Sameer Pradhan, Ron Cole, and Wayne Ward. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P16-4021" title="" class="ltx_ref ltx_href">My science Tutor—Learning science with a conversational virtual tutor</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of ACL-2016 System Demonstrations</em>, pages 121–126, Berlin, Germany. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2022)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2212.04356" title="" class="ltx_ref ltx_href">Robust Speech Recognition via Large-Scale Weak Supervision</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rumberg et al. (2022)</span>
<span class="ltx_bibblock">
Lars Rumberg, Christopher Gebauer, Hanna Ehlert, Maren Wallbaum, Lena Bornholt, Jörn Ostermann, and Ulrike Lüdtke. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2022-330" title="" class="ltx_ref ltx_href">kidsTALC: A Corpus of 3- to 11-year-old German Children’s Connected Natural Speech</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2022</em>, pages 5160–5164.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shivakumar and Georgiou (2020)</span>
<span class="ltx_bibblock">
Prashanth Gurunath Shivakumar and Panayiotis Georgiou. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.csl.2020.101077" title="" class="ltx_ref ltx_href">Transfer learning from adult to children for speech recognition: Evaluation, analysis and recommendations</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, 63:101077.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shivakumar and Narayanan (2022)</span>
<span class="ltx_bibblock">
Prashanth Gurunath Shivakumar and Shrikanth Narayanan. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.csl.2021.101289" title="" class="ltx_ref ltx_href">End-to-end neural systems for automatic children speech recognition: An empirical study</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, 72:101289.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shobaki et al. (2000)</span>
<span class="ltx_bibblock">
Khaldoun Shobaki, John-Paul Hosom, and Ronald A. Cole. 2000.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/ICSLP.2000-800" title="" class="ltx_ref ltx_href">The OGI kids² speech corpus and recognizers</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proc. 6th International Conference on Spoken Language Processing (ICSLP 2000)</em>, pages vol. 4, 258–261.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ward et al. (2019)</span>
<span class="ltx_bibblock">
Wayne Ward, Ron Cole, and Sameer Pradhan. 2019.

</span>
<span class="ltx_bibblock">My science tutor and the myst corpus.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Boulder Learn. Inc</em>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.03234" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.03235" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.03235">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.03235" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.03236" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 18:08:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
