<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.02562] Gated Low-rank Adaptation for personalized Code-Switching Automatic Speech Recognition on the low-spec devices</title><meta property="og:description" content="In recent times, there has been a growing interest in utilizing personalized large models on low-spec devices, such as mobile and CPU-only devices. However, utilizing a personalized large model in the on-device is inef‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Gated Low-rank Adaptation for personalized Code-Switching Automatic Speech Recognition on the low-spec devices">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Gated Low-rank Adaptation for personalized Code-Switching Automatic Speech Recognition on the low-spec devices">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.02562">

<!--Generated on Fri Jul  5 21:16:18 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Gated Low-rank Adaptation for personalized Code-Switching Automatic Speech Recognition on the low-spec devices</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text" style="font-size:90%;">In recent times, there has been a growing interest in utilizing personalized large models on low-spec devices, such as mobile and CPU-only devices. However, utilizing a personalized large model in the on-device is inefficient, and sometimes limited due to computational cost. To tackle the problem, this paper presents the weights separation method to minimize on-device model weights using parameter-efficient fine-tuning methods.
Moreover, some people speak multiple languages in an utterance, as known as code-switching, the personalized ASR model is necessary to address such cases. However, current multilingual speech recognition models are limited to recognizing a single language within each utterance. To tackle this problem, we propose code-switching speech recognition models that incorporate fine-tuned monolingual and multilingual speech recognition models. Additionally, we introduce a gated low-rank adaptation(GLoRA) for parameter-efficient fine-tuning with minimal performance degradation. Our experiments, conducted on Korean-English code-switching datasets, demonstrate that fine-tuning speech recognition models for code-switching surpasses the performance of traditional code-switching speech recognition models trained from scratch. Furthermore, GLoRA enhances parameter-efficient fine-tuning performance compared to conventional LoRA.</span></p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:90%;">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">‚Äî‚Äâ<span id="p1.1.1.1.1" class="ltx_text ltx_font_medium">
automatic speech recognition, code-switching, parameter-efficient fine-tuning, personalized, on-device</span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">footnotetext: </span><span id="footnotex1.1" class="ltx_text" style="font-size:90%;">This work was supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (NRF-2023R1A2C2005916). The authors were supported by Brand Engagement Networks. Corresponding Author: Hanseok Ko.</span></span></span></span>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text" style="font-size:90%;">In recent times, there has been a growing interest in utilizing personalized large models on low-spec devices, such as mobile and CPU-only devices. To inject personal information into large models, fine-tuning using individual data is crucial. However, there are some challenges to using fine-tuned large models on small devices: 1. too much computational cost during the training phase. 2. one fine-tuned large model should exist per one personalized device. 3. too many memory resources for saving and processing whole fine-tuned large models on low-spec devices. Since full fine-tuning large models is hard even in high-spec devices, some parameter-efficient fine-tuning(PEFT) methods, such as Adapter</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib1" title="" class="ltx_ref">1</a><span id="S1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.4" class="ltx_text" style="font-size:90%;">, Prefix</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S1.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.7" class="ltx_text" style="font-size:90%;">, and LoRA</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S1.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.10" class="ltx_text" style="font-size:90%;">, have been proposed to address the problem. These methods give the effect of fine-tuning with a small amount of additional weights, and without changing the weights of the original large model. In personalized, on-device environments, these properties have the advantage of low computational cost during the training phase and separating large model weights and personalized model weights. In this case, the large model weights are stored in high-spec servers and the personalized weights are stored in low-spec devices, as described in Fig. 1.</span></p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.02562/assets/Fig1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="337" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.5.1.1" class="ltx_text ltx_font_bold">Fig.¬†1</span>: </span>Schema of the separating personalized weights and large model weights.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text" style="font-size:90%;">Automatic speech recognition(ASR) is one of the most frequently used AI modules on mobile devices. Monolingual ASR performs well in ideal recording environments</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S1.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.4" class="ltx_text" style="font-size:90%;"> and has already found applications</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a><span id="S1.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.7" class="ltx_text" style="font-size:90%;"> in various domains, including smartphones, human-computer interaction, robots, and more. As shown in Fig. 2, the attention to multilingual ASR is gradually increased by well-formulated data sets and models. The large speech corpora, such as Commonvoice</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib13" title="" class="ltx_ref">13</a><span id="S1.p2.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.10" class="ltx_text" style="font-size:90%;"> and MLS</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S1.p2.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.13" class="ltx_text" style="font-size:90%;">, are collected and distributed in public. Moreover, large-scale speech models, such as Wav2Vec2</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S1.p2.1.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.16" class="ltx_text" style="font-size:90%;"> and Whisper</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.17.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S1.p2.1.18.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.19" class="ltx_text" style="font-size:90%;">, have enough capacity to address such large corpora. However, most previous multilingual ASR models recognize only one language per utterance. Since some people speak multiple languages in an utterance, as known as code-switching, the personalized ASR model is necessary to address such cases.</span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text" style="font-size:90%;">Moreover, the code-switching ASR assists in combining with multilingual LLMs. The multilingual ASR results can be used to the input of multilingual large language models(LLMs) when designing the speech-driven interaction agent. Since the tokenizer size of the LLMs is limited, unnecessary tokens should not be included in the tokenizer. However, the tokenizer should have the words with the same meaning not only in English but also in other languages if ASR cannot code-switch. For example, the multilingual utterance ‚ÄùI go to Í≤ΩÎ≥µÍ∂Å‚Äù is recognized by ASR as ‚ÄùI go to Gyeongboggung‚Äù in English and ‚ÄùÏïÑÏù¥ Í≥†Ïö∞ Ìà¨ Í≤ΩÎ≥µÍ∂Å‚Äù in Korean without code-switching. Despite only one token ‚ÄùÍ≤ΩÎ≥µÍ∂Å‚Äù is needed to understand ‚ÄùÍ≤ΩÎ≥µÍ∂Å‚Äù in the multilingual LLMs, the token of English pronunciation ‚ÄùGyeongboggung‚Äù should be added to the tokenizer without code-switching. Since ‚ÄùÍ≤ΩÎ≥µÍ∂Å‚Äù and ‚ÄùGyeongboggung‚Äù have the same meaning, adding both tokens to the tokenizer is inefficient. Therefore, code-switching ASR assists in reducing the tokenizer size of the LLMs.</span></p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2406.02562/assets/Fig2.jpg" id="S1.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="276" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.5.1.1" class="ltx_text ltx_font_bold">Fig.¬†2</span>: </span>Difference of the monolingual, multilingual, and code-switching ASR models.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text" style="font-size:90%;">Code-switching for multilingual ASR has a challenge that occurs with the same pronunciation between different languages. To tackle the problem, multilingual ASR methods</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S1.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.4" class="ltx_text" style="font-size:90%;"> first select or classify a language and recognize the transcription of the selected language only. Although this method can reduce confusion by pronunciation, the result is in one language, as mentioned above. Another approach</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S1.p4.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.7" class="ltx_text" style="font-size:90%;"> used the International Phonetic Alphabet (IPA) to address phonemes with similar pronunciation. Since this approach needs an additional IPA-to-language process, it may increase memory usage and latency. We tackle this problem by fine-tuning monolingual and multilingual ASR models using code-switching ASR data. The model is not limited to certain languages and can select any tokens in a dictionary.</span></p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text" style="font-size:90%;">In this paper, we propose a personalized code-switching ASR model with parameter-efficient fine-tuning large monolingual and multilingual ASR models to isolate personalized weights on the low-spec device and overcome the limitations of multilingual ASR models. We introduce a LoRA-style parameter-efficient fine-tuning method, named gated low-rank adaptation(GLoRA). GLoRA, which adopts gated linear units, improves the code-switching ASR performance with minimal parameter increase. We evaluate the code-switching ability of ASR models in three error rates that reflect linguistic features. With a series of experiments using a large Korean-English code-switching dataset, the fine-tuned code-switching ASR models outperform traditional code-switching speech recognition models and monolingual and multilingual ASR models in code-switching ASR. Especially, the fine-tuned models with GLoRA achieve competitive results to the full fine-tuning model with a small number of on-device weights.</span></p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text" style="font-size:90%;">Our contributions can be summarized as follows:</span></p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text" style="font-size:90%;">We propose a weight separation schema, which utilizes large model weights on the server with remaining minimal on-device model weights.</span></p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text" style="font-size:90%;">We present Korean-English code-switching ASR models with parameter-efficient fine-tuning methods to address the personalized code-switching behaviors of the users.</span></p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text" style="font-size:90%;">We propose gated low-rank adaptation(GLoRA) to improve parameter-efficient fine-tuning performance without a large number of parameter increases.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Code-switching ASR</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Recently, code-switching ASR models address One-to-English code-switching, and one can be other languages, such as Korean</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S2.SS1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.4" class="ltx_text" style="font-size:90%;">, Chinese</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S2.SS1.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.7" class="ltx_text" style="font-size:90%;">, and Arabic</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S2.SS1.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.10" class="ltx_text" style="font-size:90%;">. Lee et al.</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S2.SS1.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.13" class="ltx_text" style="font-size:90%;"> proposed phonetic variation modeling and language model adaptation for Korean-English code-switching. Wang et al.</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S2.SS1.p1.1.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.16" class="ltx_text" style="font-size:90%;"> analyze the Korean language system for improving Korean-English Code-switching ASR. Shan et al.</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.17.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S2.SS1.p1.1.18.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.19" class="ltx_text" style="font-size:90%;"> and Li et al.</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.20.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S2.SS1.p1.1.21.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.22" class="ltx_text" style="font-size:90%;"> address model structure aspects of the code-switching ASR, such as LAS</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.23.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S2.SS1.p1.1.24.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.25" class="ltx_text" style="font-size:90%;"> and CTC</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.26.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a><span id="S2.SS1.p1.1.27.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.28" class="ltx_text" style="font-size:90%;">. Hussein et al.</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.29.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S2.SS1.p1.1.30.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.31" class="ltx_text" style="font-size:90%;"> propose a pipeline structure for generating code-switching sentences. In this paper, the backbone models of the code-switching ASR model structures are updated to new large ASR models, including Wav2Vec2</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.32.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S2.SS1.p1.1.33.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.34" class="ltx_text" style="font-size:90%;"> and Whisper</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.35.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S2.SS1.p1.1.36.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.37" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Fine-tuning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p"><span id="S2.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">There are many fine-tuning methods, also known as transfer learning, such as full fine-tuning, Adapter</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib1" title="" class="ltx_ref">1</a><span id="S2.SS2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.4" class="ltx_text" style="font-size:90%;">, prefix tuning</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S2.SS2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.7" class="ltx_text" style="font-size:90%;">, and LoRA</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S2.SS2.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.10" class="ltx_text" style="font-size:90%;">. The full fine-tuning method trains all pre-trained weights. Although it often yields good performance, it is computing-inefficient. As the backbone model size grows larger, the computing-inefficient problem becomes a critical issue. To address the problem, Adapter</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib1" title="" class="ltx_ref">1</a><span id="S2.SS2.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.13" class="ltx_text" style="font-size:90%;">, prefix</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S2.SS2.p1.1.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.16" class="ltx_text" style="font-size:90%;">, or LoRA</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.17.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S2.SS2.p1.1.18.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.19" class="ltx_text" style="font-size:90%;"> layers are added to the backbone model. The weights of additional layers are only updated and the weights of the backbone model are frozen in the training stage. In this paper, the full fine-tuning and LoRA are used to comparison, and a new LoRA style model, named GLoRA, is proposed.</span></p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed method</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Weight Separation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">The proposed weight separation method is summarized as storing PEFT weights on the low-spec device and sending them to the high-spec device with the user speech. Since the weights of the PEFT demand small computation resources, they can be stored in low-spec devices. To avoid the model initialization time consumption, the pre-trained ASR model should be initialized with a PEFT structure placeholder, and plug the PEFT weights during inference. For the training, the PEFT weights are fine-tuned using the transmitted speech and sent to the low-spec device.</span></p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text" style="font-size:90%;">Although the proposed weight separation method has a limitation in that the low-spec device should be connected to a network server, it has the advantage of efficiency. Moreover, the proposed method has privacy advantages because the speech and personalized weights are not stored on the server. Furthermore, the proposed method has personalized ASR performance advantages compared to utilizing pre-trained ASR models, because personalized weights address the dialects or habits of the individual users.</span></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Architecture</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Whisper</span><span id="S3.SS2.p1.1.2" class="ltx_text" style="font-size:90%;">
Whisper</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S3.SS2.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p1.1.5" class="ltx_text" style="font-size:90%;"> is the transformer-based multilingual automatic speech recognition model, which is trained by weak supervision with large-scale speech recognition data. We use Whisper-tiny(39M parameters) and Whisper-small(244M parameters) as the backbone model in the Whisper model family.
The Whisper predicts subword-level tokens from the log-mel spectrogram. To preserve the token numbering of the backbone model, the existing tokenizer of the backbone model remains and adds unseen tokens to the tokenizer using a code-switching dataset. The settings to extract the log-mel spectrogram are the same as Whisper: sampling rate=16000Hz, window length=25ms, hop length=10ms, and the number of mel coefficients=80. The cross-entropy loss is used to fine-tune the Whisper-based code-switching ASR model.</span></p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Wav2Vec2</span><span id="S3.SS2.p2.1.2" class="ltx_text" style="font-size:90%;">
Wav2Vec2</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p2.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S3.SS2.p2.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p2.1.5" class="ltx_text" style="font-size:90%;"> is the speech representation model that contains CNN and transformer layers. Wav2Vec2 is composed of a multi-layer convolutional feature encoder, which finds latent speech representations, and a Transformer to build representations capturing information from the entire sequence. Unlike the Whisper, Wav2Vec2 predicts character-level tokens from the raw audio. Since the base language of the dataset used in this paper is Korean, we use models and tokenizers of the Wav2Vec2-large-xlsr-Korean</span><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://huggingface.co/kresnik/wav2vec2-large-xlsr-korean</span></span></span></span><span id="S3.SS2.p2.1.6" class="ltx_text" style="font-size:90%;"> as backbone models and tokenizers. We also add unseen tokens to the tokenizer using a code-switching dataset. All raw audio is re-sampled to a 16000Hz sampling rate. The CTC loss</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p2.1.7.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a><span id="S3.SS2.p2.1.8.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p2.1.9" class="ltx_text" style="font-size:90%;"> is used to fine-tune the Wav2Vec2-based code-switching ASR model.</span></p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Low Rank Adaptation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.4" class="ltx_p"><span id="S3.SS3.p1.4.1" class="ltx_text" style="font-size:90%;">Low-rank adaptation is an efficient fine-tuning method for updating weight matrices without changing the original backbone model. A pre-trained weight matrix </span><math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="W_{0}\in\mathbb{R}^{d\times k}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><msub id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.2.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.1.m1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">‚àà</mo><msup id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.1.1.3.3.2" xref="S3.SS3.p1.1.m1.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.SS3.p1.1.m1.1.1.3.3.1" xref="S3.SS3.p1.1.m1.1.1.3.3.1.cmml">√ó</mo><mi mathsize="90%" id="S3.SS3.p1.1.m1.1.1.3.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><in id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></in><apply id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.2.3">0</cn></apply><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">‚Ñù</ci><apply id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3"><times id="S3.SS3.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.1"></times><ci id="S3.SS3.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.2">ùëë</ci><ci id="S3.SS3.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3.3">ùëò</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">W_{0}\in\mathbb{R}^{d\times k}</annotation></semantics></math><span id="S3.SS3.p1.4.2" class="ltx_text" style="font-size:90%;"> is updated by gradients </span><math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\Delta W" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><times id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1"></times><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">Œî</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">ùëä</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\Delta W</annotation></semantics></math><span id="S3.SS3.p1.4.3" class="ltx_text" style="font-size:90%;"> during full fine-tuning. In the inference stage, the hidden features </span><math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi mathsize="90%" id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">ùë¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">y</annotation></semantics></math><span id="S3.SS3.p1.4.4" class="ltx_text" style="font-size:90%;"> are calculated from input features </span><math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi mathsize="90%" id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">x</annotation></semantics></math><span id="S3.SS3.p1.4.5" class="ltx_text" style="font-size:90%;"> as</span></p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="h=(W_{0}+\Delta W)x." display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">h</mi><mo mathsize="90%" id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mn mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml">W</mi></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">x</mi></mrow></mrow><mo lspace="0em" mathsize="90%" id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></eq><ci id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3">‚Ñé</ci><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></times><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><plus id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2">ùëä</ci><cn type="integer" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3">0</cn></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2">Œî</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3">ùëä</ci></apply></apply><ci id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3">ùë•</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">h=(W_{0}+\Delta W)x.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.20" class="ltx_p"><span id="S3.SS3.p1.20.1" class="ltx_text" style="font-size:90%;">After full fine-tuning, pre-trained weights </span><math id="S3.SS3.p1.5.m1.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S3.SS3.p1.5.m1.1a"><msub id="S3.SS3.p1.5.m1.1.1" xref="S3.SS3.p1.5.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.5.m1.1.1.2" xref="S3.SS3.p1.5.m1.1.1.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.5.m1.1.1.3" xref="S3.SS3.p1.5.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m1.1b"><apply id="S3.SS3.p1.5.m1.1.1.cmml" xref="S3.SS3.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m1.1.1.1.cmml" xref="S3.SS3.p1.5.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.5.m1.1.1.2.cmml" xref="S3.SS3.p1.5.m1.1.1.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.5.m1.1.1.3.cmml" xref="S3.SS3.p1.5.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m1.1c">W_{0}</annotation></semantics></math><span id="S3.SS3.p1.20.2" class="ltx_text" style="font-size:90%;"> are not saved anymore, and they are changed into </span><math id="S3.SS3.p1.6.m2.1" class="ltx_Math" alttext="W_{0}+\Delta W" display="inline"><semantics id="S3.SS3.p1.6.m2.1a"><mrow id="S3.SS3.p1.6.m2.1.1" xref="S3.SS3.p1.6.m2.1.1.cmml"><msub id="S3.SS3.p1.6.m2.1.1.2" xref="S3.SS3.p1.6.m2.1.1.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.6.m2.1.1.2.2" xref="S3.SS3.p1.6.m2.1.1.2.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.6.m2.1.1.2.3" xref="S3.SS3.p1.6.m2.1.1.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.SS3.p1.6.m2.1.1.1" xref="S3.SS3.p1.6.m2.1.1.1.cmml">+</mo><mrow id="S3.SS3.p1.6.m2.1.1.3" xref="S3.SS3.p1.6.m2.1.1.3.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.SS3.p1.6.m2.1.1.3.2" xref="S3.SS3.p1.6.m2.1.1.3.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.6.m2.1.1.3.1" xref="S3.SS3.p1.6.m2.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.6.m2.1.1.3.3" xref="S3.SS3.p1.6.m2.1.1.3.3.cmml">W</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m2.1b"><apply id="S3.SS3.p1.6.m2.1.1.cmml" xref="S3.SS3.p1.6.m2.1.1"><plus id="S3.SS3.p1.6.m2.1.1.1.cmml" xref="S3.SS3.p1.6.m2.1.1.1"></plus><apply id="S3.SS3.p1.6.m2.1.1.2.cmml" xref="S3.SS3.p1.6.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m2.1.1.2.1.cmml" xref="S3.SS3.p1.6.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.6.m2.1.1.2.2.cmml" xref="S3.SS3.p1.6.m2.1.1.2.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.6.m2.1.1.2.3.cmml" xref="S3.SS3.p1.6.m2.1.1.2.3">0</cn></apply><apply id="S3.SS3.p1.6.m2.1.1.3.cmml" xref="S3.SS3.p1.6.m2.1.1.3"><times id="S3.SS3.p1.6.m2.1.1.3.1.cmml" xref="S3.SS3.p1.6.m2.1.1.3.1"></times><ci id="S3.SS3.p1.6.m2.1.1.3.2.cmml" xref="S3.SS3.p1.6.m2.1.1.3.2">Œî</ci><ci id="S3.SS3.p1.6.m2.1.1.3.3.cmml" xref="S3.SS3.p1.6.m2.1.1.3.3">ùëä</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m2.1c">W_{0}+\Delta W</annotation></semantics></math><span id="S3.SS3.p1.20.3" class="ltx_text" style="font-size:90%;">. This induces excessive memory usage. Since gradients for all </span><math id="S3.SS3.p1.7.m3.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S3.SS3.p1.7.m3.1a"><msub id="S3.SS3.p1.7.m3.1.1" xref="S3.SS3.p1.7.m3.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.7.m3.1.1.2" xref="S3.SS3.p1.7.m3.1.1.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.7.m3.1.1.3" xref="S3.SS3.p1.7.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m3.1b"><apply id="S3.SS3.p1.7.m3.1.1.cmml" xref="S3.SS3.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m3.1.1.1.cmml" xref="S3.SS3.p1.7.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m3.1.1.2.cmml" xref="S3.SS3.p1.7.m3.1.1.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.7.m3.1.1.3.cmml" xref="S3.SS3.p1.7.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m3.1c">W_{0}</annotation></semantics></math><span id="S3.SS3.p1.20.4" class="ltx_text" style="font-size:90%;"> should be calculated during the full fine-tuning stage, much more GPU memory is necessary. Moreover, all of the weights </span><math id="S3.SS3.p1.8.m4.1" class="ltx_Math" alttext="W_{0}+\Delta W" display="inline"><semantics id="S3.SS3.p1.8.m4.1a"><mrow id="S3.SS3.p1.8.m4.1.1" xref="S3.SS3.p1.8.m4.1.1.cmml"><msub id="S3.SS3.p1.8.m4.1.1.2" xref="S3.SS3.p1.8.m4.1.1.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.8.m4.1.1.2.2" xref="S3.SS3.p1.8.m4.1.1.2.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.8.m4.1.1.2.3" xref="S3.SS3.p1.8.m4.1.1.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.SS3.p1.8.m4.1.1.1" xref="S3.SS3.p1.8.m4.1.1.1.cmml">+</mo><mrow id="S3.SS3.p1.8.m4.1.1.3" xref="S3.SS3.p1.8.m4.1.1.3.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.SS3.p1.8.m4.1.1.3.2" xref="S3.SS3.p1.8.m4.1.1.3.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.8.m4.1.1.3.1" xref="S3.SS3.p1.8.m4.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.8.m4.1.1.3.3" xref="S3.SS3.p1.8.m4.1.1.3.3.cmml">W</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m4.1b"><apply id="S3.SS3.p1.8.m4.1.1.cmml" xref="S3.SS3.p1.8.m4.1.1"><plus id="S3.SS3.p1.8.m4.1.1.1.cmml" xref="S3.SS3.p1.8.m4.1.1.1"></plus><apply id="S3.SS3.p1.8.m4.1.1.2.cmml" xref="S3.SS3.p1.8.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.8.m4.1.1.2.1.cmml" xref="S3.SS3.p1.8.m4.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.8.m4.1.1.2.2.cmml" xref="S3.SS3.p1.8.m4.1.1.2.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.8.m4.1.1.2.3.cmml" xref="S3.SS3.p1.8.m4.1.1.2.3">0</cn></apply><apply id="S3.SS3.p1.8.m4.1.1.3.cmml" xref="S3.SS3.p1.8.m4.1.1.3"><times id="S3.SS3.p1.8.m4.1.1.3.1.cmml" xref="S3.SS3.p1.8.m4.1.1.3.1"></times><ci id="S3.SS3.p1.8.m4.1.1.3.2.cmml" xref="S3.SS3.p1.8.m4.1.1.3.2">Œî</ci><ci id="S3.SS3.p1.8.m4.1.1.3.3.cmml" xref="S3.SS3.p1.8.m4.1.1.3.3">ùëä</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m4.1c">W_{0}+\Delta W</annotation></semantics></math><span id="S3.SS3.p1.20.5" class="ltx_text" style="font-size:90%;"> are saved for only one downstream task. If the task is changed, new weights </span><math id="S3.SS3.p1.9.m5.1" class="ltx_Math" alttext="W_{0}+\Delta W_{2}" display="inline"><semantics id="S3.SS3.p1.9.m5.1a"><mrow id="S3.SS3.p1.9.m5.1.1" xref="S3.SS3.p1.9.m5.1.1.cmml"><msub id="S3.SS3.p1.9.m5.1.1.2" xref="S3.SS3.p1.9.m5.1.1.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.9.m5.1.1.2.2" xref="S3.SS3.p1.9.m5.1.1.2.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.9.m5.1.1.2.3" xref="S3.SS3.p1.9.m5.1.1.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.SS3.p1.9.m5.1.1.1" xref="S3.SS3.p1.9.m5.1.1.1.cmml">+</mo><mrow id="S3.SS3.p1.9.m5.1.1.3" xref="S3.SS3.p1.9.m5.1.1.3.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.SS3.p1.9.m5.1.1.3.2" xref="S3.SS3.p1.9.m5.1.1.3.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.9.m5.1.1.3.1" xref="S3.SS3.p1.9.m5.1.1.3.1.cmml">‚Äã</mo><msub id="S3.SS3.p1.9.m5.1.1.3.3" xref="S3.SS3.p1.9.m5.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.9.m5.1.1.3.3.2" xref="S3.SS3.p1.9.m5.1.1.3.3.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.9.m5.1.1.3.3.3" xref="S3.SS3.p1.9.m5.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m5.1b"><apply id="S3.SS3.p1.9.m5.1.1.cmml" xref="S3.SS3.p1.9.m5.1.1"><plus id="S3.SS3.p1.9.m5.1.1.1.cmml" xref="S3.SS3.p1.9.m5.1.1.1"></plus><apply id="S3.SS3.p1.9.m5.1.1.2.cmml" xref="S3.SS3.p1.9.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m5.1.1.2.1.cmml" xref="S3.SS3.p1.9.m5.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.9.m5.1.1.2.2.cmml" xref="S3.SS3.p1.9.m5.1.1.2.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.9.m5.1.1.2.3.cmml" xref="S3.SS3.p1.9.m5.1.1.2.3">0</cn></apply><apply id="S3.SS3.p1.9.m5.1.1.3.cmml" xref="S3.SS3.p1.9.m5.1.1.3"><times id="S3.SS3.p1.9.m5.1.1.3.1.cmml" xref="S3.SS3.p1.9.m5.1.1.3.1"></times><ci id="S3.SS3.p1.9.m5.1.1.3.2.cmml" xref="S3.SS3.p1.9.m5.1.1.3.2">Œî</ci><apply id="S3.SS3.p1.9.m5.1.1.3.3.cmml" xref="S3.SS3.p1.9.m5.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m5.1.1.3.3.1.cmml" xref="S3.SS3.p1.9.m5.1.1.3.3">subscript</csymbol><ci id="S3.SS3.p1.9.m5.1.1.3.3.2.cmml" xref="S3.SS3.p1.9.m5.1.1.3.3.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.9.m5.1.1.3.3.3.cmml" xref="S3.SS3.p1.9.m5.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m5.1c">W_{0}+\Delta W_{2}</annotation></semantics></math><span id="S3.SS3.p1.20.6" class="ltx_text" style="font-size:90%;"> should be trained and stored. It is over-consumption and memory inefficient. To address the problem, LoRA constrains updating </span><math id="S3.SS3.p1.10.m6.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S3.SS3.p1.10.m6.1a"><msub id="S3.SS3.p1.10.m6.1.1" xref="S3.SS3.p1.10.m6.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.10.m6.1.1.2" xref="S3.SS3.p1.10.m6.1.1.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.10.m6.1.1.3" xref="S3.SS3.p1.10.m6.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.m6.1b"><apply id="S3.SS3.p1.10.m6.1.1.cmml" xref="S3.SS3.p1.10.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.10.m6.1.1.1.cmml" xref="S3.SS3.p1.10.m6.1.1">subscript</csymbol><ci id="S3.SS3.p1.10.m6.1.1.2.cmml" xref="S3.SS3.p1.10.m6.1.1.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.10.m6.1.1.3.cmml" xref="S3.SS3.p1.10.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.m6.1c">W_{0}</annotation></semantics></math><span id="S3.SS3.p1.20.7" class="ltx_text" style="font-size:90%;"> by representing the latter with a low-rank decomposition </span><math id="S3.SS3.p1.11.m7.1" class="ltx_Math" alttext="W_{0}+\Delta W=W_{0}+BA" display="inline"><semantics id="S3.SS3.p1.11.m7.1a"><mrow id="S3.SS3.p1.11.m7.1.1" xref="S3.SS3.p1.11.m7.1.1.cmml"><mrow id="S3.SS3.p1.11.m7.1.1.2" xref="S3.SS3.p1.11.m7.1.1.2.cmml"><msub id="S3.SS3.p1.11.m7.1.1.2.2" xref="S3.SS3.p1.11.m7.1.1.2.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.11.m7.1.1.2.2.2" xref="S3.SS3.p1.11.m7.1.1.2.2.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.11.m7.1.1.2.2.3" xref="S3.SS3.p1.11.m7.1.1.2.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.SS3.p1.11.m7.1.1.2.1" xref="S3.SS3.p1.11.m7.1.1.2.1.cmml">+</mo><mrow id="S3.SS3.p1.11.m7.1.1.2.3" xref="S3.SS3.p1.11.m7.1.1.2.3.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.SS3.p1.11.m7.1.1.2.3.2" xref="S3.SS3.p1.11.m7.1.1.2.3.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.11.m7.1.1.2.3.1" xref="S3.SS3.p1.11.m7.1.1.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.11.m7.1.1.2.3.3" xref="S3.SS3.p1.11.m7.1.1.2.3.3.cmml">W</mi></mrow></mrow><mo mathsize="90%" id="S3.SS3.p1.11.m7.1.1.1" xref="S3.SS3.p1.11.m7.1.1.1.cmml">=</mo><mrow id="S3.SS3.p1.11.m7.1.1.3" xref="S3.SS3.p1.11.m7.1.1.3.cmml"><msub id="S3.SS3.p1.11.m7.1.1.3.2" xref="S3.SS3.p1.11.m7.1.1.3.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.11.m7.1.1.3.2.2" xref="S3.SS3.p1.11.m7.1.1.3.2.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.11.m7.1.1.3.2.3" xref="S3.SS3.p1.11.m7.1.1.3.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.SS3.p1.11.m7.1.1.3.1" xref="S3.SS3.p1.11.m7.1.1.3.1.cmml">+</mo><mrow id="S3.SS3.p1.11.m7.1.1.3.3" xref="S3.SS3.p1.11.m7.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.11.m7.1.1.3.3.2" xref="S3.SS3.p1.11.m7.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.11.m7.1.1.3.3.1" xref="S3.SS3.p1.11.m7.1.1.3.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.11.m7.1.1.3.3.3" xref="S3.SS3.p1.11.m7.1.1.3.3.3.cmml">A</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.11.m7.1b"><apply id="S3.SS3.p1.11.m7.1.1.cmml" xref="S3.SS3.p1.11.m7.1.1"><eq id="S3.SS3.p1.11.m7.1.1.1.cmml" xref="S3.SS3.p1.11.m7.1.1.1"></eq><apply id="S3.SS3.p1.11.m7.1.1.2.cmml" xref="S3.SS3.p1.11.m7.1.1.2"><plus id="S3.SS3.p1.11.m7.1.1.2.1.cmml" xref="S3.SS3.p1.11.m7.1.1.2.1"></plus><apply id="S3.SS3.p1.11.m7.1.1.2.2.cmml" xref="S3.SS3.p1.11.m7.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.11.m7.1.1.2.2.1.cmml" xref="S3.SS3.p1.11.m7.1.1.2.2">subscript</csymbol><ci id="S3.SS3.p1.11.m7.1.1.2.2.2.cmml" xref="S3.SS3.p1.11.m7.1.1.2.2.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.11.m7.1.1.2.2.3.cmml" xref="S3.SS3.p1.11.m7.1.1.2.2.3">0</cn></apply><apply id="S3.SS3.p1.11.m7.1.1.2.3.cmml" xref="S3.SS3.p1.11.m7.1.1.2.3"><times id="S3.SS3.p1.11.m7.1.1.2.3.1.cmml" xref="S3.SS3.p1.11.m7.1.1.2.3.1"></times><ci id="S3.SS3.p1.11.m7.1.1.2.3.2.cmml" xref="S3.SS3.p1.11.m7.1.1.2.3.2">Œî</ci><ci id="S3.SS3.p1.11.m7.1.1.2.3.3.cmml" xref="S3.SS3.p1.11.m7.1.1.2.3.3">ùëä</ci></apply></apply><apply id="S3.SS3.p1.11.m7.1.1.3.cmml" xref="S3.SS3.p1.11.m7.1.1.3"><plus id="S3.SS3.p1.11.m7.1.1.3.1.cmml" xref="S3.SS3.p1.11.m7.1.1.3.1"></plus><apply id="S3.SS3.p1.11.m7.1.1.3.2.cmml" xref="S3.SS3.p1.11.m7.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p1.11.m7.1.1.3.2.1.cmml" xref="S3.SS3.p1.11.m7.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p1.11.m7.1.1.3.2.2.cmml" xref="S3.SS3.p1.11.m7.1.1.3.2.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.11.m7.1.1.3.2.3.cmml" xref="S3.SS3.p1.11.m7.1.1.3.2.3">0</cn></apply><apply id="S3.SS3.p1.11.m7.1.1.3.3.cmml" xref="S3.SS3.p1.11.m7.1.1.3.3"><times id="S3.SS3.p1.11.m7.1.1.3.3.1.cmml" xref="S3.SS3.p1.11.m7.1.1.3.3.1"></times><ci id="S3.SS3.p1.11.m7.1.1.3.3.2.cmml" xref="S3.SS3.p1.11.m7.1.1.3.3.2">ùêµ</ci><ci id="S3.SS3.p1.11.m7.1.1.3.3.3.cmml" xref="S3.SS3.p1.11.m7.1.1.3.3.3">ùê¥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.11.m7.1c">W_{0}+\Delta W=W_{0}+BA</annotation></semantics></math><span id="S3.SS3.p1.20.8" class="ltx_text" style="font-size:90%;">, where </span><math id="S3.SS3.p1.12.m8.1" class="ltx_Math" alttext="A\in\mathbb{R}^{d\times r}" display="inline"><semantics id="S3.SS3.p1.12.m8.1a"><mrow id="S3.SS3.p1.12.m8.1.1" xref="S3.SS3.p1.12.m8.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.12.m8.1.1.2" xref="S3.SS3.p1.12.m8.1.1.2.cmml">A</mi><mo mathsize="90%" id="S3.SS3.p1.12.m8.1.1.1" xref="S3.SS3.p1.12.m8.1.1.1.cmml">‚àà</mo><msup id="S3.SS3.p1.12.m8.1.1.3" xref="S3.SS3.p1.12.m8.1.1.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.12.m8.1.1.3.2" xref="S3.SS3.p1.12.m8.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS3.p1.12.m8.1.1.3.3" xref="S3.SS3.p1.12.m8.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.12.m8.1.1.3.3.2" xref="S3.SS3.p1.12.m8.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.SS3.p1.12.m8.1.1.3.3.1" xref="S3.SS3.p1.12.m8.1.1.3.3.1.cmml">√ó</mo><mi mathsize="90%" id="S3.SS3.p1.12.m8.1.1.3.3.3" xref="S3.SS3.p1.12.m8.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.12.m8.1b"><apply id="S3.SS3.p1.12.m8.1.1.cmml" xref="S3.SS3.p1.12.m8.1.1"><in id="S3.SS3.p1.12.m8.1.1.1.cmml" xref="S3.SS3.p1.12.m8.1.1.1"></in><ci id="S3.SS3.p1.12.m8.1.1.2.cmml" xref="S3.SS3.p1.12.m8.1.1.2">ùê¥</ci><apply id="S3.SS3.p1.12.m8.1.1.3.cmml" xref="S3.SS3.p1.12.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.12.m8.1.1.3.1.cmml" xref="S3.SS3.p1.12.m8.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.12.m8.1.1.3.2.cmml" xref="S3.SS3.p1.12.m8.1.1.3.2">‚Ñù</ci><apply id="S3.SS3.p1.12.m8.1.1.3.3.cmml" xref="S3.SS3.p1.12.m8.1.1.3.3"><times id="S3.SS3.p1.12.m8.1.1.3.3.1.cmml" xref="S3.SS3.p1.12.m8.1.1.3.3.1"></times><ci id="S3.SS3.p1.12.m8.1.1.3.3.2.cmml" xref="S3.SS3.p1.12.m8.1.1.3.3.2">ùëë</ci><ci id="S3.SS3.p1.12.m8.1.1.3.3.3.cmml" xref="S3.SS3.p1.12.m8.1.1.3.3.3">ùëü</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.12.m8.1c">A\in\mathbb{R}^{d\times r}</annotation></semantics></math><span id="S3.SS3.p1.20.9" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS3.p1.13.m9.1" class="ltx_Math" alttext="B\in\mathbb{R}^{r\times k}" display="inline"><semantics id="S3.SS3.p1.13.m9.1a"><mrow id="S3.SS3.p1.13.m9.1.1" xref="S3.SS3.p1.13.m9.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.13.m9.1.1.2" xref="S3.SS3.p1.13.m9.1.1.2.cmml">B</mi><mo mathsize="90%" id="S3.SS3.p1.13.m9.1.1.1" xref="S3.SS3.p1.13.m9.1.1.1.cmml">‚àà</mo><msup id="S3.SS3.p1.13.m9.1.1.3" xref="S3.SS3.p1.13.m9.1.1.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.13.m9.1.1.3.2" xref="S3.SS3.p1.13.m9.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS3.p1.13.m9.1.1.3.3" xref="S3.SS3.p1.13.m9.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.13.m9.1.1.3.3.2" xref="S3.SS3.p1.13.m9.1.1.3.3.2.cmml">r</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.SS3.p1.13.m9.1.1.3.3.1" xref="S3.SS3.p1.13.m9.1.1.3.3.1.cmml">√ó</mo><mi mathsize="90%" id="S3.SS3.p1.13.m9.1.1.3.3.3" xref="S3.SS3.p1.13.m9.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.13.m9.1b"><apply id="S3.SS3.p1.13.m9.1.1.cmml" xref="S3.SS3.p1.13.m9.1.1"><in id="S3.SS3.p1.13.m9.1.1.1.cmml" xref="S3.SS3.p1.13.m9.1.1.1"></in><ci id="S3.SS3.p1.13.m9.1.1.2.cmml" xref="S3.SS3.p1.13.m9.1.1.2">ùêµ</ci><apply id="S3.SS3.p1.13.m9.1.1.3.cmml" xref="S3.SS3.p1.13.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.13.m9.1.1.3.1.cmml" xref="S3.SS3.p1.13.m9.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.13.m9.1.1.3.2.cmml" xref="S3.SS3.p1.13.m9.1.1.3.2">‚Ñù</ci><apply id="S3.SS3.p1.13.m9.1.1.3.3.cmml" xref="S3.SS3.p1.13.m9.1.1.3.3"><times id="S3.SS3.p1.13.m9.1.1.3.3.1.cmml" xref="S3.SS3.p1.13.m9.1.1.3.3.1"></times><ci id="S3.SS3.p1.13.m9.1.1.3.3.2.cmml" xref="S3.SS3.p1.13.m9.1.1.3.3.2">ùëü</ci><ci id="S3.SS3.p1.13.m9.1.1.3.3.3.cmml" xref="S3.SS3.p1.13.m9.1.1.3.3.3">ùëò</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.13.m9.1c">B\in\mathbb{R}^{r\times k}</annotation></semantics></math><span id="S3.SS3.p1.20.10" class="ltx_text" style="font-size:90%;">, and rank </span><math id="S3.SS3.p1.14.m10.2" class="ltx_Math" alttext="r&lt;min(d,k)" display="inline"><semantics id="S3.SS3.p1.14.m10.2a"><mrow id="S3.SS3.p1.14.m10.2.3" xref="S3.SS3.p1.14.m10.2.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.14.m10.2.3.2" xref="S3.SS3.p1.14.m10.2.3.2.cmml">r</mi><mo mathsize="90%" id="S3.SS3.p1.14.m10.2.3.1" xref="S3.SS3.p1.14.m10.2.3.1.cmml">&lt;</mo><mrow id="S3.SS3.p1.14.m10.2.3.3" xref="S3.SS3.p1.14.m10.2.3.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.14.m10.2.3.3.2" xref="S3.SS3.p1.14.m10.2.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.14.m10.2.3.3.1" xref="S3.SS3.p1.14.m10.2.3.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.14.m10.2.3.3.3" xref="S3.SS3.p1.14.m10.2.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.14.m10.2.3.3.1a" xref="S3.SS3.p1.14.m10.2.3.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.14.m10.2.3.3.4" xref="S3.SS3.p1.14.m10.2.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.14.m10.2.3.3.1b" xref="S3.SS3.p1.14.m10.2.3.3.1.cmml">‚Äã</mo><mrow id="S3.SS3.p1.14.m10.2.3.3.5.2" xref="S3.SS3.p1.14.m10.2.3.3.5.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.14.m10.2.3.3.5.2.1" xref="S3.SS3.p1.14.m10.2.3.3.5.1.cmml">(</mo><mi mathsize="90%" id="S3.SS3.p1.14.m10.1.1" xref="S3.SS3.p1.14.m10.1.1.cmml">d</mi><mo mathsize="90%" id="S3.SS3.p1.14.m10.2.3.3.5.2.2" xref="S3.SS3.p1.14.m10.2.3.3.5.1.cmml">,</mo><mi mathsize="90%" id="S3.SS3.p1.14.m10.2.2" xref="S3.SS3.p1.14.m10.2.2.cmml">k</mi><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.14.m10.2.3.3.5.2.3" xref="S3.SS3.p1.14.m10.2.3.3.5.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.14.m10.2b"><apply id="S3.SS3.p1.14.m10.2.3.cmml" xref="S3.SS3.p1.14.m10.2.3"><lt id="S3.SS3.p1.14.m10.2.3.1.cmml" xref="S3.SS3.p1.14.m10.2.3.1"></lt><ci id="S3.SS3.p1.14.m10.2.3.2.cmml" xref="S3.SS3.p1.14.m10.2.3.2">ùëü</ci><apply id="S3.SS3.p1.14.m10.2.3.3.cmml" xref="S3.SS3.p1.14.m10.2.3.3"><times id="S3.SS3.p1.14.m10.2.3.3.1.cmml" xref="S3.SS3.p1.14.m10.2.3.3.1"></times><ci id="S3.SS3.p1.14.m10.2.3.3.2.cmml" xref="S3.SS3.p1.14.m10.2.3.3.2">ùëö</ci><ci id="S3.SS3.p1.14.m10.2.3.3.3.cmml" xref="S3.SS3.p1.14.m10.2.3.3.3">ùëñ</ci><ci id="S3.SS3.p1.14.m10.2.3.3.4.cmml" xref="S3.SS3.p1.14.m10.2.3.3.4">ùëõ</ci><interval closure="open" id="S3.SS3.p1.14.m10.2.3.3.5.1.cmml" xref="S3.SS3.p1.14.m10.2.3.3.5.2"><ci id="S3.SS3.p1.14.m10.1.1.cmml" xref="S3.SS3.p1.14.m10.1.1">ùëë</ci><ci id="S3.SS3.p1.14.m10.2.2.cmml" xref="S3.SS3.p1.14.m10.2.2">ùëò</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.14.m10.2c">r&lt;min(d,k)</annotation></semantics></math><span id="S3.SS3.p1.20.11" class="ltx_text" style="font-size:90%;">. During training, </span><math id="S3.SS3.p1.15.m11.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S3.SS3.p1.15.m11.1a"><msub id="S3.SS3.p1.15.m11.1.1" xref="S3.SS3.p1.15.m11.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.15.m11.1.1.2" xref="S3.SS3.p1.15.m11.1.1.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.15.m11.1.1.3" xref="S3.SS3.p1.15.m11.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.15.m11.1b"><apply id="S3.SS3.p1.15.m11.1.1.cmml" xref="S3.SS3.p1.15.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.15.m11.1.1.1.cmml" xref="S3.SS3.p1.15.m11.1.1">subscript</csymbol><ci id="S3.SS3.p1.15.m11.1.1.2.cmml" xref="S3.SS3.p1.15.m11.1.1.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.15.m11.1.1.3.cmml" xref="S3.SS3.p1.15.m11.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.15.m11.1c">W_{0}</annotation></semantics></math><span id="S3.SS3.p1.20.12" class="ltx_text" style="font-size:90%;"> is frozen and does not receive gradient updates, while </span><math id="S3.SS3.p1.16.m12.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS3.p1.16.m12.1a"><mi mathsize="90%" id="S3.SS3.p1.16.m12.1.1" xref="S3.SS3.p1.16.m12.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.16.m12.1b"><ci id="S3.SS3.p1.16.m12.1.1.cmml" xref="S3.SS3.p1.16.m12.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.16.m12.1c">A</annotation></semantics></math><span id="S3.SS3.p1.20.13" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS3.p1.17.m13.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS3.p1.17.m13.1a"><mi mathsize="90%" id="S3.SS3.p1.17.m13.1.1" xref="S3.SS3.p1.17.m13.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.17.m13.1b"><ci id="S3.SS3.p1.17.m13.1.1.cmml" xref="S3.SS3.p1.17.m13.1.1">ùêµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.17.m13.1c">B</annotation></semantics></math><span id="S3.SS3.p1.20.14" class="ltx_text" style="font-size:90%;"> contain trainable parameters. Note both </span><math id="S3.SS3.p1.18.m14.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S3.SS3.p1.18.m14.1a"><msub id="S3.SS3.p1.18.m14.1.1" xref="S3.SS3.p1.18.m14.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.18.m14.1.1.2" xref="S3.SS3.p1.18.m14.1.1.2.cmml">W</mi><mn mathsize="90%" id="S3.SS3.p1.18.m14.1.1.3" xref="S3.SS3.p1.18.m14.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.18.m14.1b"><apply id="S3.SS3.p1.18.m14.1.1.cmml" xref="S3.SS3.p1.18.m14.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.18.m14.1.1.1.cmml" xref="S3.SS3.p1.18.m14.1.1">subscript</csymbol><ci id="S3.SS3.p1.18.m14.1.1.2.cmml" xref="S3.SS3.p1.18.m14.1.1.2">ùëä</ci><cn type="integer" id="S3.SS3.p1.18.m14.1.1.3.cmml" xref="S3.SS3.p1.18.m14.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.18.m14.1c">W_{0}</annotation></semantics></math><span id="S3.SS3.p1.20.15" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS3.p1.19.m15.1" class="ltx_Math" alttext="\Delta W=BA" display="inline"><semantics id="S3.SS3.p1.19.m15.1a"><mrow id="S3.SS3.p1.19.m15.1.1" xref="S3.SS3.p1.19.m15.1.1.cmml"><mrow id="S3.SS3.p1.19.m15.1.1.2" xref="S3.SS3.p1.19.m15.1.1.2.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.SS3.p1.19.m15.1.1.2.2" xref="S3.SS3.p1.19.m15.1.1.2.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.19.m15.1.1.2.1" xref="S3.SS3.p1.19.m15.1.1.2.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.19.m15.1.1.2.3" xref="S3.SS3.p1.19.m15.1.1.2.3.cmml">W</mi></mrow><mo mathsize="90%" id="S3.SS3.p1.19.m15.1.1.1" xref="S3.SS3.p1.19.m15.1.1.1.cmml">=</mo><mrow id="S3.SS3.p1.19.m15.1.1.3" xref="S3.SS3.p1.19.m15.1.1.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.19.m15.1.1.3.2" xref="S3.SS3.p1.19.m15.1.1.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.19.m15.1.1.3.1" xref="S3.SS3.p1.19.m15.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.19.m15.1.1.3.3" xref="S3.SS3.p1.19.m15.1.1.3.3.cmml">A</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.19.m15.1b"><apply id="S3.SS3.p1.19.m15.1.1.cmml" xref="S3.SS3.p1.19.m15.1.1"><eq id="S3.SS3.p1.19.m15.1.1.1.cmml" xref="S3.SS3.p1.19.m15.1.1.1"></eq><apply id="S3.SS3.p1.19.m15.1.1.2.cmml" xref="S3.SS3.p1.19.m15.1.1.2"><times id="S3.SS3.p1.19.m15.1.1.2.1.cmml" xref="S3.SS3.p1.19.m15.1.1.2.1"></times><ci id="S3.SS3.p1.19.m15.1.1.2.2.cmml" xref="S3.SS3.p1.19.m15.1.1.2.2">Œî</ci><ci id="S3.SS3.p1.19.m15.1.1.2.3.cmml" xref="S3.SS3.p1.19.m15.1.1.2.3">ùëä</ci></apply><apply id="S3.SS3.p1.19.m15.1.1.3.cmml" xref="S3.SS3.p1.19.m15.1.1.3"><times id="S3.SS3.p1.19.m15.1.1.3.1.cmml" xref="S3.SS3.p1.19.m15.1.1.3.1"></times><ci id="S3.SS3.p1.19.m15.1.1.3.2.cmml" xref="S3.SS3.p1.19.m15.1.1.3.2">ùêµ</ci><ci id="S3.SS3.p1.19.m15.1.1.3.3.cmml" xref="S3.SS3.p1.19.m15.1.1.3.3">ùê¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.19.m15.1c">\Delta W=BA</annotation></semantics></math><span id="S3.SS3.p1.20.16" class="ltx_text" style="font-size:90%;"> are multiplied with the input features </span><math id="S3.SS3.p1.20.m16.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p1.20.m16.1a"><mi mathsize="90%" id="S3.SS3.p1.20.m16.1.1" xref="S3.SS3.p1.20.m16.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.20.m16.1b"><ci id="S3.SS3.p1.20.m16.1.1.cmml" xref="S3.SS3.p1.20.m16.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.20.m16.1c">x</annotation></semantics></math><span id="S3.SS3.p1.20.17" class="ltx_text" style="font-size:90%;">, and their respective output vectors are summed coordinate-wise. The LoRA-modified forward pass yields:</span></p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="h=(W_{0}+\Delta W)x=W_{0}x+BAx." display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml">h</mi><mo mathsize="90%" id="S3.E2.m1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.4.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mn mathsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.3.cmml">W</mi></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.2.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo mathsize="90%" id="S3.E2.m1.1.1.1.1.5" xref="S3.E2.m1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.6" xref="S3.E2.m1.1.1.1.1.6.cmml"><mrow id="S3.E2.m1.1.1.1.1.6.2" xref="S3.E2.m1.1.1.1.1.6.2.cmml"><msub id="S3.E2.m1.1.1.1.1.6.2.2" xref="S3.E2.m1.1.1.1.1.6.2.2.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.6.2.2.2" xref="S3.E2.m1.1.1.1.1.6.2.2.2.cmml">W</mi><mn mathsize="90%" id="S3.E2.m1.1.1.1.1.6.2.2.3" xref="S3.E2.m1.1.1.1.1.6.2.2.3.cmml">0</mn></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.6.2.1" xref="S3.E2.m1.1.1.1.1.6.2.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.6.2.3" xref="S3.E2.m1.1.1.1.1.6.2.3.cmml">x</mi></mrow><mo mathsize="90%" id="S3.E2.m1.1.1.1.1.6.1" xref="S3.E2.m1.1.1.1.1.6.1.cmml">+</mo><mrow id="S3.E2.m1.1.1.1.1.6.3" xref="S3.E2.m1.1.1.1.1.6.3.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.6.3.2" xref="S3.E2.m1.1.1.1.1.6.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.6.3.1" xref="S3.E2.m1.1.1.1.1.6.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.6.3.3" xref="S3.E2.m1.1.1.1.1.6.3.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.6.3.1a" xref="S3.E2.m1.1.1.1.1.6.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.6.3.4" xref="S3.E2.m1.1.1.1.1.6.3.4.cmml">x</mi></mrow></mrow></mrow><mo lspace="0em" mathsize="90%" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><and id="S3.E2.m1.1.1.1.1a.cmml" xref="S3.E2.m1.1.1.1"></and><apply id="S3.E2.m1.1.1.1.1b.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.4"></eq><ci id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3">‚Ñé</ci><apply id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.2"></times><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"><plus id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.2">ùëä</ci><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.3">0</cn></apply><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2">Œî</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.3">ùëä</ci></apply></apply><ci id="S3.E2.m1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.3">ùë•</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1c.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.5.cmml" xref="S3.E2.m1.1.1.1.1.5"></eq><share href="#S3.E2.m1.1.1.1.1.1.cmml" id="S3.E2.m1.1.1.1.1d.cmml" xref="S3.E2.m1.1.1.1"></share><apply id="S3.E2.m1.1.1.1.1.6.cmml" xref="S3.E2.m1.1.1.1.1.6"><plus id="S3.E2.m1.1.1.1.1.6.1.cmml" xref="S3.E2.m1.1.1.1.1.6.1"></plus><apply id="S3.E2.m1.1.1.1.1.6.2.cmml" xref="S3.E2.m1.1.1.1.1.6.2"><times id="S3.E2.m1.1.1.1.1.6.2.1.cmml" xref="S3.E2.m1.1.1.1.1.6.2.1"></times><apply id="S3.E2.m1.1.1.1.1.6.2.2.cmml" xref="S3.E2.m1.1.1.1.1.6.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.6.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.6.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.6.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.6.2.2.2">ùëä</ci><cn type="integer" id="S3.E2.m1.1.1.1.1.6.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.6.2.2.3">0</cn></apply><ci id="S3.E2.m1.1.1.1.1.6.2.3.cmml" xref="S3.E2.m1.1.1.1.1.6.2.3">ùë•</ci></apply><apply id="S3.E2.m1.1.1.1.1.6.3.cmml" xref="S3.E2.m1.1.1.1.1.6.3"><times id="S3.E2.m1.1.1.1.1.6.3.1.cmml" xref="S3.E2.m1.1.1.1.1.6.3.1"></times><ci id="S3.E2.m1.1.1.1.1.6.3.2.cmml" xref="S3.E2.m1.1.1.1.1.6.3.2">ùêµ</ci><ci id="S3.E2.m1.1.1.1.1.6.3.3.cmml" xref="S3.E2.m1.1.1.1.1.6.3.3">ùê¥</ci><ci id="S3.E2.m1.1.1.1.1.6.3.4.cmml" xref="S3.E2.m1.1.1.1.1.6.3.4">ùë•</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">h=(W_{0}+\Delta W)x=W_{0}x+BAx.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.21" class="ltx_p"><span id="S3.SS3.p1.21.1" class="ltx_text" style="font-size:90%;">The LoRA is memory-efficient and promises competitive results for fine-tuning.</span></p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Gated Low Rank Adaptation</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.4" class="ltx_p"><span id="S3.SS4.p1.4.1" class="ltx_text" style="font-size:90%;">The key idea of LoRA is estimating </span><math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="\Delta W" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mrow id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.1.m1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><times id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1"></times><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">Œî</ci><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">ùëä</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\Delta W</annotation></semantics></math><span id="S3.SS4.p1.4.2" class="ltx_text" style="font-size:90%;"> using </span><math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mi mathsize="90%" id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">A</annotation></semantics></math><span id="S3.SS4.p1.4.3" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mi mathsize="90%" id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">ùêµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">B</annotation></semantics></math><span id="S3.SS4.p1.4.4" class="ltx_text" style="font-size:90%;"> of minimal parameters, without changing </span><math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><msub id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS4.p1.4.m4.1.1.2" xref="S3.SS4.p1.4.m4.1.1.2.cmml">W</mi><mn mathsize="90%" id="S3.SS4.p1.4.m4.1.1.3" xref="S3.SS4.p1.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><apply id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.4.m4.1.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p1.4.m4.1.1.2.cmml" xref="S3.SS4.p1.4.m4.1.1.2">ùëä</ci><cn type="integer" id="S3.SS4.p1.4.m4.1.1.3.cmml" xref="S3.SS4.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">W_{0}</annotation></semantics></math><span id="S3.SS4.p1.4.5" class="ltx_text" style="font-size:90%;">. We aim to apply some tricks for performance improvement without hurting the original LoRA structure like:</span></p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="h=(W_{0}+\Delta W)x=W_{0}x+f(BA)x." display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.4" xref="S3.E3.m1.1.1.1.1.4.cmml">h</mi><mo mathsize="90%" id="S3.E3.m1.1.1.1.1.5" xref="S3.E3.m1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mn mathsize="90%" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml">0</mn></msub><mo mathsize="90%" id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.3.cmml">W</mi></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo mathsize="90%" id="S3.E3.m1.1.1.1.1.6" xref="S3.E3.m1.1.1.1.1.6.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><mrow id="S3.E3.m1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.2.3.cmml"><msub id="S3.E3.m1.1.1.1.1.2.3.2" xref="S3.E3.m1.1.1.1.1.2.3.2.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.3.2.2" xref="S3.E3.m1.1.1.1.1.2.3.2.2.cmml">W</mi><mn mathsize="90%" id="S3.E3.m1.1.1.1.1.2.3.2.3" xref="S3.E3.m1.1.1.1.1.2.3.2.3.cmml">0</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.3.1" xref="S3.E3.m1.1.1.1.1.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.3.3" xref="S3.E3.m1.1.1.1.1.2.3.3.cmml">x</mi></mrow><mo mathsize="90%" id="S3.E3.m1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.2.2.cmml">+</mo><mrow id="S3.E3.m1.1.1.1.1.2.1" xref="S3.E3.m1.1.1.1.1.2.1.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.1.3" xref="S3.E3.m1.1.1.1.1.2.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.1.2" xref="S3.E3.m1.1.1.1.1.2.1.2.cmml">‚Äã</mo><mrow id="S3.E3.m1.1.1.1.1.2.1.1.1" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E3.m1.1.1.1.1.2.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.2.1.1.1.1" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.3.cmml">A</mi></mrow><mo maxsize="90%" minsize="90%" id="S3.E3.m1.1.1.1.1.2.1.1.1.3" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.1.2a" xref="S3.E3.m1.1.1.1.1.2.1.2.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.1.4" xref="S3.E3.m1.1.1.1.1.2.1.4.cmml">x</mi></mrow></mrow></mrow><mo lspace="0em" mathsize="90%" id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><and id="S3.E3.m1.1.1.1.1a.cmml" xref="S3.E3.m1.1.1.1"></and><apply id="S3.E3.m1.1.1.1.1b.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.5.cmml" xref="S3.E3.m1.1.1.1.1.5"></eq><ci id="S3.E3.m1.1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.1.4">‚Ñé</ci><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><plus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2">ùëä</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3">0</cn></apply><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3"><times id="S3.E3.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.2">Œî</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.3">ùëä</ci></apply></apply><ci id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3">ùë•</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1c.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.6.cmml" xref="S3.E3.m1.1.1.1.1.6"></eq><share href="#S3.E3.m1.1.1.1.1.1.cmml" id="S3.E3.m1.1.1.1.1d.cmml" xref="S3.E3.m1.1.1.1"></share><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><plus id="S3.E3.m1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2"></plus><apply id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3"><times id="S3.E3.m1.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.3.1"></times><apply id="S3.E3.m1.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.3.2.2">ùëä</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.2.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3.2.3">0</cn></apply><ci id="S3.E3.m1.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3.3">ùë•</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.1"><times id="S3.E3.m1.1.1.1.1.2.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2.1.2"></times><ci id="S3.E3.m1.1.1.1.1.2.1.3.cmml" xref="S3.E3.m1.1.1.1.1.2.1.3">ùëì</ci><apply id="S3.E3.m1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1.1"><times id="S3.E3.m1.1.1.1.1.2.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.1"></times><ci id="S3.E3.m1.1.1.1.1.2.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.2">ùêµ</ci><ci id="S3.E3.m1.1.1.1.1.2.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.2.1.1.1.1.3">ùê¥</ci></apply><ci id="S3.E3.m1.1.1.1.1.2.1.4.cmml" xref="S3.E3.m1.1.1.1.1.2.1.4">ùë•</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">h=(W_{0}+\Delta W)x=W_{0}x+f(BA)x.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p1.10" class="ltx_p"><span id="S3.SS4.p1.10.1" class="ltx_text" style="font-size:90%;">where </span><math id="S3.SS4.p1.5.m1.1" class="ltx_Math" alttext="f(*)" display="inline"><semantics id="S3.SS4.p1.5.m1.1a"><mrow id="S3.SS4.p1.5.m1.1.2" xref="S3.SS4.p1.5.m1.1.2.cmml"><mi mathsize="90%" id="S3.SS4.p1.5.m1.1.2.2" xref="S3.SS4.p1.5.m1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.5.m1.1.2.1" xref="S3.SS4.p1.5.m1.1.2.1.cmml">‚Äã</mo><mrow id="S3.SS4.p1.5.m1.1.2.3.2" xref="S3.SS4.p1.5.m1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS4.p1.5.m1.1.2.3.2.1" xref="S3.SS4.p1.5.m1.1.2.cmml">(</mo><mo lspace="0em" mathsize="90%" rspace="0em" id="S3.SS4.p1.5.m1.1.1" xref="S3.SS4.p1.5.m1.1.1.cmml">‚àó</mo><mo maxsize="90%" minsize="90%" id="S3.SS4.p1.5.m1.1.2.3.2.2" xref="S3.SS4.p1.5.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m1.1b"><apply id="S3.SS4.p1.5.m1.1.2.cmml" xref="S3.SS4.p1.5.m1.1.2"><times id="S3.SS4.p1.5.m1.1.2.1.cmml" xref="S3.SS4.p1.5.m1.1.2.1"></times><ci id="S3.SS4.p1.5.m1.1.2.2.cmml" xref="S3.SS4.p1.5.m1.1.2.2">ùëì</ci><times id="S3.SS4.p1.5.m1.1.1.cmml" xref="S3.SS4.p1.5.m1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m1.1c">f(*)</annotation></semantics></math><span id="S3.SS4.p1.10.2" class="ltx_text" style="font-size:90%;"> denotes any performance-improving functions.
We added the gated linear units(GLU) into LoRA with various parameter paths to design the tricks, as shown in Fig. 3. In type 1, input features </span><math id="S3.SS4.p1.6.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS4.p1.6.m2.1a"><mi mathsize="90%" id="S3.SS4.p1.6.m2.1.1" xref="S3.SS4.p1.6.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m2.1b"><ci id="S3.SS4.p1.6.m2.1.1.cmml" xref="S3.SS4.p1.6.m2.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m2.1c">x</annotation></semantics></math><span id="S3.SS4.p1.10.3" class="ltx_text" style="font-size:90%;"> and pre-trained output features </span><math id="S3.SS4.p1.7.m3.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.SS4.p1.7.m3.1a"><mi mathsize="90%" id="S3.SS4.p1.7.m3.1.1" xref="S3.SS4.p1.7.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m3.1b"><ci id="S3.SS4.p1.7.m3.1.1.cmml" xref="S3.SS4.p1.7.m3.1.1">‚Ñé</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m3.1c">h</annotation></semantics></math><span id="S3.SS4.p1.10.4" class="ltx_text" style="font-size:90%;"> are refined by GLU, concatenated, and passed through LoRA layer. In type 2, the GLU layers are injected into the input and output features of the LoRA. In type 3, the mid-level features of the LoRA are refined by GLU. Type 1, 2 GLoRA apply GLU to </span><math id="S3.SS4.p1.8.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS4.p1.8.m4.1a"><mi mathsize="90%" id="S3.SS4.p1.8.m4.1.1" xref="S3.SS4.p1.8.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.8.m4.1b"><ci id="S3.SS4.p1.8.m4.1.1.cmml" xref="S3.SS4.p1.8.m4.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.8.m4.1c">x</annotation></semantics></math><span id="S3.SS4.p1.10.5" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS4.p1.9.m5.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.SS4.p1.9.m5.1a"><mi mathsize="90%" id="S3.SS4.p1.9.m5.1.1" xref="S3.SS4.p1.9.m5.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.9.m5.1b"><ci id="S3.SS4.p1.9.m5.1.1.cmml" xref="S3.SS4.p1.9.m5.1.1">‚Ñé</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.9.m5.1c">h</annotation></semantics></math><span id="S3.SS4.p1.10.6" class="ltx_text" style="font-size:90%;"> in order to refine frozen features before extracting LoRA features </span><math id="S3.SS4.p1.10.m6.1" class="ltx_Math" alttext="\Delta W" display="inline"><semantics id="S3.SS4.p1.10.m6.1a"><mrow id="S3.SS4.p1.10.m6.1.1" xref="S3.SS4.p1.10.m6.1.1.cmml"><mi mathsize="90%" mathvariant="normal" id="S3.SS4.p1.10.m6.1.1.2" xref="S3.SS4.p1.10.m6.1.1.2.cmml">Œî</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.10.m6.1.1.1" xref="S3.SS4.p1.10.m6.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS4.p1.10.m6.1.1.3" xref="S3.SS4.p1.10.m6.1.1.3.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.10.m6.1b"><apply id="S3.SS4.p1.10.m6.1.1.cmml" xref="S3.SS4.p1.10.m6.1.1"><times id="S3.SS4.p1.10.m6.1.1.1.cmml" xref="S3.SS4.p1.10.m6.1.1.1"></times><ci id="S3.SS4.p1.10.m6.1.1.2.cmml" xref="S3.SS4.p1.10.m6.1.1.2">Œî</ci><ci id="S3.SS4.p1.10.m6.1.1.3.cmml" xref="S3.SS4.p1.10.m6.1.1.3">ùëä</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.10.m6.1c">\Delta W</annotation></semantics></math><span id="S3.SS4.p1.10.7" class="ltx_text" style="font-size:90%;">. Type 1 uses both pre-features and post-features, and Type 2 uses pre-features Type 3 GLoRA applies GLU to middle-level features of the LoRA. In this case, GLU is performed like an activation function.</span></p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2406.02562/assets/Fig3.png" id="S3.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="209" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.5.1.1" class="ltx_text ltx_font_bold">Fig.¬†3</span>: </span>Illustration of AuLoRA structures. Type 1: cross-attention. Type 2: self-attention. Type 3:GLU for hidden features. Type 4:GLU for low-rank features.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Experiments were performed on a Korean-English code-switching data set. The Korean-English code-switching data set, named KECS, is available in AI Hub</span><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://aihub.or.kr/</span></span></span></span><span id="S4.SS1.p1.1.2" class="ltx_text" style="font-size:90%;">. The data set has 3502911 training utterances and 439607 test utterances with a 48kHz sampling rate. The waveform is resampled to follow the settings of the ASR models.
To evaluate Korean-English code-switching ASR models, we use word error rate(WER). Moreover, we adopt some additional measurements to consider linguistic differences. For the Korean-English case, character error rate(CER) and jamo error rate(JER) are calculated. In Korean, one character consists of many Jamos, and one word consists of many characters. As described in Fig 4, the Korean word ‚ÄùÍ≤ΩÎ≥µÍ∂Å‚Äù, which is pronounced ‚ÄùGyeongboggung‚Äù in English, can be separated into characters or Jamos. Since Jamos and characters are related to pronunciation and words are related to meaning, CER and JER measure the phonetic recognition performance and WER measures the linguistic information recognition performance of the ASR model.</span></p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2406.02562/assets/Fig4.jpg" id="S4.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="289" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.5.1.1" class="ltx_text ltx_font_bold">Fig.¬†4</span>: </span>Illustration of the Korean linguistic features. A Korean word can be separated into word, character, and Jamo.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evaluation Results and Discussion</h3>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.7.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>The evaluation results of the proposed weight separation method using Korean-English code-switching ASR models.</figcaption>
<table id="S4.T1.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.3.3" class="ltx_tr">
<td id="S4.T1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.3.4.1" class="ltx_text" style="font-size:90%;">Model</span></td>
<td id="S4.T1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.3.5.1" class="ltx_text" style="font-size:90%;">Fine-tuning</span></td>
<td id="S4.T1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.3.6.1" class="ltx_text" style="font-size:90%;">LoRA</span></td>
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.1.1" class="ltx_text" style="font-size:90%;">WER</span><math id="S4.T1.1.1.1.m1.1" class="ltx_math_unparsed" alttext="(\%)" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mrow id="S4.T1.1.1.1.m1.1b"><mo maxsize="90%" minsize="90%" id="S4.T1.1.1.1.m1.1.1">(</mo><mo mathsize="90%" id="S4.T1.1.1.1.m1.1.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T1.1.1.1.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">(\%)</annotation></semantics></math>
</td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.2.2.2.1" class="ltx_text" style="font-size:90%;">CER</span><math id="S4.T1.2.2.2.m1.1" class="ltx_math_unparsed" alttext="(\%)" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><mrow id="S4.T1.2.2.2.m1.1b"><mo maxsize="90%" minsize="90%" id="S4.T1.2.2.2.m1.1.1">(</mo><mo mathsize="90%" id="S4.T1.2.2.2.m1.1.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T1.2.2.2.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">(\%)</annotation></semantics></math>
</td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T1.3.3.3.1" class="ltx_text" style="font-size:90%;">JER</span><math id="S4.T1.3.3.3.m1.1" class="ltx_math_unparsed" alttext="(\%)" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><mrow id="S4.T1.3.3.3.m1.1b"><mo maxsize="90%" minsize="90%" id="S4.T1.3.3.3.m1.1.1">(</mo><mo mathsize="90%" id="S4.T1.3.3.3.m1.1.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T1.3.3.3.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">(\%)</annotation></semantics></math>
</td>
<td id="S4.T1.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.3.7.1" class="ltx_text" style="font-size:90%;">trainable params.</span></td>
</tr>
<tr id="S4.T1.3.4.1" class="ltx_tr">
<td id="S4.T1.3.4.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.1.1.1" class="ltx_text" style="font-size:90%;">Conformer</span></td>
<td id="S4.T1.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.1.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T1.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.1.3.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.1.4.1" class="ltx_text" style="font-size:90%;">82.098</span></td>
<td id="S4.T1.3.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.1.5.1" class="ltx_text" style="font-size:90%;">75.151</span></td>
<td id="S4.T1.3.4.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.1.6.1" class="ltx_text" style="font-size:90%;">63.582</span></td>
<td id="S4.T1.3.4.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.4.1.7.1" class="ltx_text" style="font-size:90%;">118.8M</span></td>
</tr>
<tr id="S4.T1.3.5.2" class="ltx_tr">
<td id="S4.T1.3.5.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.2.1.1" class="ltx_text" style="font-size:90%;">Whisper-tiny</span></td>
<td id="S4.T1.3.5.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.2.2.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.5.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.2.3.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.5.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.2.4.1" class="ltx_text" style="font-size:90%;">59.791</span></td>
<td id="S4.T1.3.5.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.2.5.1" class="ltx_text" style="font-size:90%;">50.447</span></td>
<td id="S4.T1.3.5.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.2.6.1" class="ltx_text" style="font-size:90%;">34.647</span></td>
<td id="S4.T1.3.5.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.5.2.7.1" class="ltx_text" style="font-size:90%;">39M</span></td>
</tr>
<tr id="S4.T1.3.6.3" class="ltx_tr">
<td id="S4.T1.3.6.3.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.6.3.1.1" class="ltx_text" style="font-size:90%;">Whisper-tiny</span></td>
<td id="S4.T1.3.6.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.6.3.2.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.6.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.6.3.3.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.6.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.6.3.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">42.843</span></td>
<td id="S4.T1.3.6.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.6.3.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">21.309</span></td>
<td id="S4.T1.3.6.3.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.6.3.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">15.845</span></td>
<td id="S4.T1.3.6.3.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.3.7.1" class="ltx_text" style="font-size:90%;">39M</span></td>
</tr>
<tr id="S4.T1.3.7.4" class="ltx_tr">
<td id="S4.T1.3.7.4.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.7.4.1.1" class="ltx_text" style="font-size:90%;">Whisper-tiny</span></td>
<td id="S4.T1.3.7.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.7.4.2.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.7.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.7.4.3.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.7.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.7.4.4.1" class="ltx_text" style="font-size:90%;">44.829</span></td>
<td id="S4.T1.3.7.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.7.4.5.1" class="ltx_text" style="font-size:90%;">25.925</span></td>
<td id="S4.T1.3.7.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.7.4.6.1" class="ltx_text" style="font-size:90%;">18.935</span></td>
<td id="S4.T1.3.7.4.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.7.4.7.1" class="ltx_text" style="font-size:90%;">1.9M</span></td>
</tr>
<tr id="S4.T1.3.8.5" class="ltx_tr">
<td id="S4.T1.3.8.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.8.5.1.1" class="ltx_text" style="font-size:90%;">Whisper-small</span></td>
<td id="S4.T1.3.8.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.8.5.2.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.8.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.8.5.3.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.8.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.8.5.4.1" class="ltx_text" style="font-size:90%;">45.140</span></td>
<td id="S4.T1.3.8.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.8.5.5.1" class="ltx_text" style="font-size:90%;">35.760</span></td>
<td id="S4.T1.3.8.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.8.5.6.1" class="ltx_text" style="font-size:90%;">23.941</span></td>
<td id="S4.T1.3.8.5.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.8.5.7.1" class="ltx_text" style="font-size:90%;">74M</span></td>
</tr>
<tr id="S4.T1.3.9.6" class="ltx_tr">
<td id="S4.T1.3.9.6.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.9.6.1.1" class="ltx_text" style="font-size:90%;">Whisper-small</span></td>
<td id="S4.T1.3.9.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.9.6.2.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.9.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.9.6.3.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.9.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.9.6.4.1" class="ltx_text" style="font-size:90%;">29.951</span></td>
<td id="S4.T1.3.9.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.9.6.5.1" class="ltx_text" style="font-size:90%;">15.277</span></td>
<td id="S4.T1.3.9.6.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.9.6.6.1" class="ltx_text" style="font-size:90%;">12.097</span></td>
<td id="S4.T1.3.9.6.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.6.7.1" class="ltx_text" style="font-size:90%;">74M</span></td>
</tr>
<tr id="S4.T1.3.10.7" class="ltx_tr">
<td id="S4.T1.3.10.7.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.10.7.1.1" class="ltx_text" style="font-size:90%;">Whisper-small</span></td>
<td id="S4.T1.3.10.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.10.7.2.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.10.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.10.7.3.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.10.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.10.7.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">33.575</span></td>
<td id="S4.T1.3.10.7.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.10.7.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">17.598</span></td>
<td id="S4.T1.3.10.7.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.10.7.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">13.671</span></td>
<td id="S4.T1.3.10.7.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.10.7.7.1" class="ltx_text" style="font-size:90%;">7.3M</span></td>
</tr>
<tr id="S4.T1.3.11.8" class="ltx_tr">
<td id="S4.T1.3.11.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.11.8.1.1" class="ltx_text" style="font-size:90%;">Wav2Vec2-large(ko)</span></td>
<td id="S4.T1.3.11.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.11.8.2.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.11.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.11.8.3.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.11.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.11.8.4.1" class="ltx_text" style="font-size:90%;">72.360</span></td>
<td id="S4.T1.3.11.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.11.8.5.1" class="ltx_text" style="font-size:90%;">55.965</span></td>
<td id="S4.T1.3.11.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.11.8.6.1" class="ltx_text" style="font-size:90%;">38.371</span></td>
<td id="S4.T1.3.11.8.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.11.8.7.1" class="ltx_text" style="font-size:90%;">313M</span></td>
</tr>
<tr id="S4.T1.3.12.9" class="ltx_tr">
<td id="S4.T1.3.12.9.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.12.9.1.1" class="ltx_text" style="font-size:90%;">Wav2Vec2-large(ko)</span></td>
<td id="S4.T1.3.12.9.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.12.9.2.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.12.9.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.12.9.3.1" class="ltx_text" style="font-size:90%;">‚úó</span></td>
<td id="S4.T1.3.12.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.12.9.4.1" class="ltx_text" style="font-size:90%;">42.371</span></td>
<td id="S4.T1.3.12.9.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.12.9.5.1" class="ltx_text" style="font-size:90%;">21.952</span></td>
<td id="S4.T1.3.12.9.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.3.12.9.6.1" class="ltx_text" style="font-size:90%;">18.068</span></td>
<td id="S4.T1.3.12.9.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.12.9.7.1" class="ltx_text" style="font-size:90%;">313M</span></td>
</tr>
<tr id="S4.T1.3.13.10" class="ltx_tr">
<td id="S4.T1.3.13.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.3.13.10.1.1" class="ltx_text" style="font-size:90%;">Wav2Vec2-large(ko)</span></td>
<td id="S4.T1.3.13.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.3.13.10.2.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.13.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.3.13.10.3.1" class="ltx_text" style="font-size:90%;">‚úì</span></td>
<td id="S4.T1.3.13.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.3.13.10.4.1" class="ltx_text" style="font-size:90%;">55.141</span></td>
<td id="S4.T1.3.13.10.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.3.13.10.5.1" class="ltx_text" style="font-size:90%;">55.394</span></td>
<td id="S4.T1.3.13.10.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.3.13.10.6.1" class="ltx_text" style="font-size:90%;">38.235</span></td>
<td id="S4.T1.3.13.10.7" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T1.3.13.10.7.1" class="ltx_text" style="font-size:90%;">7.1M</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.7.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>The evaluation results of the proposed GLoRA using Korean-English code-switching ASR models.</figcaption>
<table id="S4.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.3.3" class="ltx_tr">
<th id="S4.T2.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.3.3.4.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S4.T2.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.3.3.5.1" class="ltx_text" style="font-size:90%;">GLoRA</span></th>
<th id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T2.1.1.1.1" class="ltx_text" style="font-size:90%;">WER</span><math id="S4.T2.1.1.1.m1.1" class="ltx_math_unparsed" alttext="(\%)" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.m1.1b"><mo maxsize="90%" minsize="90%" id="S4.T2.1.1.1.m1.1.1">(</mo><mo mathsize="90%" id="S4.T2.1.1.1.m1.1.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T2.1.1.1.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">(\%)</annotation></semantics></math>
</th>
<th id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T2.2.2.2.1" class="ltx_text" style="font-size:90%;">CER</span><math id="S4.T2.2.2.2.m1.1" class="ltx_math_unparsed" alttext="(\%)" display="inline"><semantics id="S4.T2.2.2.2.m1.1a"><mrow id="S4.T2.2.2.2.m1.1b"><mo maxsize="90%" minsize="90%" id="S4.T2.2.2.2.m1.1.1">(</mo><mo mathsize="90%" id="S4.T2.2.2.2.m1.1.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T2.2.2.2.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">(\%)</annotation></semantics></math>
</th>
<th id="S4.T2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="S4.T2.3.3.3.1" class="ltx_text" style="font-size:90%;">JER</span><math id="S4.T2.3.3.3.m1.1" class="ltx_math_unparsed" alttext="(\%)" display="inline"><semantics id="S4.T2.3.3.3.m1.1a"><mrow id="S4.T2.3.3.3.m1.1b"><mo maxsize="90%" minsize="90%" id="S4.T2.3.3.3.m1.1.1">(</mo><mo mathsize="90%" id="S4.T2.3.3.3.m1.1.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T2.3.3.3.m1.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">(\%)</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.4.1" class="ltx_tr">
<td id="S4.T2.3.4.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.4.1.1.1" class="ltx_text" style="font-size:90%;">Whisper-tiny</span></td>
<td id="S4.T2.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.4.1.2.1" class="ltx_text" style="font-size:90%;">ori.</span></td>
<td id="S4.T2.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.4.1.3.1" class="ltx_text" style="font-size:90%;">44.829</span></td>
<td id="S4.T2.3.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.4.1.4.1" class="ltx_text" style="font-size:90%;">25.925</span></td>
<td id="S4.T2.3.4.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.4.1.5.1" class="ltx_text" style="font-size:90%;">18.935</span></td>
</tr>
<tr id="S4.T2.3.5.2" class="ltx_tr">
<td id="S4.T2.3.5.2.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.5.2.1.1" class="ltx_text" style="font-size:90%;">Whisper-tiny</span></td>
<td id="S4.T2.3.5.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.5.2.2.1" class="ltx_text" style="font-size:90%;">Type1</span></td>
<td id="S4.T2.3.5.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.5.2.3.1" class="ltx_text" style="font-size:90%;">41.740</span></td>
<td id="S4.T2.3.5.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.5.2.4.1" class="ltx_text" style="font-size:90%;">23.721</span></td>
<td id="S4.T2.3.5.2.5" class="ltx_td ltx_align_center"><span id="S4.T2.3.5.2.5.1" class="ltx_text" style="font-size:90%;">17.651</span></td>
</tr>
<tr id="S4.T2.3.6.3" class="ltx_tr">
<td id="S4.T2.3.6.3.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.6.3.1.1" class="ltx_text" style="font-size:90%;">Whisper-tiny</span></td>
<td id="S4.T2.3.6.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.6.3.2.1" class="ltx_text" style="font-size:90%;">Type2</span></td>
<td id="S4.T2.3.6.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.6.3.3.1" class="ltx_text" style="font-size:90%;">45.428</span></td>
<td id="S4.T2.3.6.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.6.3.4.1" class="ltx_text" style="font-size:90%;">26.375</span></td>
<td id="S4.T2.3.6.3.5" class="ltx_td ltx_align_center"><span id="S4.T2.3.6.3.5.1" class="ltx_text" style="font-size:90%;">19.225</span></td>
</tr>
<tr id="S4.T2.3.7.4" class="ltx_tr">
<td id="S4.T2.3.7.4.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.7.4.1.1" class="ltx_text" style="font-size:90%;">Whisper-tiny</span></td>
<td id="S4.T2.3.7.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.7.4.2.1" class="ltx_text" style="font-size:90%;">Type3</span></td>
<td id="S4.T2.3.7.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.7.4.3.1" class="ltx_text" style="font-size:90%;">44.919</span></td>
<td id="S4.T2.3.7.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.7.4.4.1" class="ltx_text" style="font-size:90%;">25.925</span></td>
<td id="S4.T2.3.7.4.5" class="ltx_td ltx_align_center"><span id="S4.T2.3.7.4.5.1" class="ltx_text" style="font-size:90%;">18.935</span></td>
</tr>
<tr id="S4.T2.3.8.5" class="ltx_tr">
<td id="S4.T2.3.8.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.8.5.1.1" class="ltx_text" style="font-size:90%;">Wav2Vec2</span></td>
<td id="S4.T2.3.8.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.8.5.2.1" class="ltx_text" style="font-size:90%;">ori.</span></td>
<td id="S4.T2.3.8.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.8.5.3.1" class="ltx_text" style="font-size:90%;">55.141</span></td>
<td id="S4.T2.3.8.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.3.8.5.4.1" class="ltx_text" style="font-size:90%;">55.394</span></td>
<td id="S4.T2.3.8.5.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.3.8.5.5.1" class="ltx_text" style="font-size:90%;">38.235</span></td>
</tr>
<tr id="S4.T2.3.9.6" class="ltx_tr">
<td id="S4.T2.3.9.6.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.9.6.1.1" class="ltx_text" style="font-size:90%;">Wav2Vec2</span></td>
<td id="S4.T2.3.9.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.9.6.2.1" class="ltx_text" style="font-size:90%;">Type1</span></td>
<td id="S4.T2.3.9.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.9.6.3.1" class="ltx_text" style="font-size:90%;">53.468</span></td>
<td id="S4.T2.3.9.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.9.6.4.1" class="ltx_text" style="font-size:90%;">54.208</span></td>
<td id="S4.T2.3.9.6.5" class="ltx_td ltx_align_center"><span id="S4.T2.3.9.6.5.1" class="ltx_text" style="font-size:90%;">36.646</span></td>
</tr>
<tr id="S4.T2.3.10.7" class="ltx_tr">
<td id="S4.T2.3.10.7.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.10.7.1.1" class="ltx_text" style="font-size:90%;">Wav2Vec2</span></td>
<td id="S4.T2.3.10.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.10.7.2.1" class="ltx_text" style="font-size:90%;">Type2</span></td>
<td id="S4.T2.3.10.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.10.7.3.1" class="ltx_text" style="font-size:90%;">54.663</span></td>
<td id="S4.T2.3.10.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.3.10.7.4.1" class="ltx_text" style="font-size:90%;">54.802</span></td>
<td id="S4.T2.3.10.7.5" class="ltx_td ltx_align_center"><span id="S4.T2.3.10.7.5.1" class="ltx_text" style="font-size:90%;">37.980</span></td>
</tr>
<tr id="S4.T2.3.11.8" class="ltx_tr">
<td id="S4.T2.3.11.8.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.3.11.8.1.1" class="ltx_text" style="font-size:90%;">Wav2Vec2</span></td>
<td id="S4.T2.3.11.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.3.11.8.2.1" class="ltx_text" style="font-size:90%;">Type3</span></td>
<td id="S4.T2.3.11.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.3.11.8.3.1" class="ltx_text" style="font-size:90%;">54.757</span></td>
<td id="S4.T2.3.11.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.3.11.8.4.1" class="ltx_text" style="font-size:90%;">54.813</span></td>
<td id="S4.T2.3.11.8.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.3.11.8.5.1" class="ltx_text" style="font-size:90%;">38.136</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">The evaluation results of the Korean-English code-switching are summarized in Table 1. To evaluate the conventional on-device code-switching ASR model, the Conformer</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S4.SS2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p1.1.4" class="ltx_text" style="font-size:90%;"> model is trained from scratch using Espnet2</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S4.SS2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p1.1.7" class="ltx_text" style="font-size:90%;"> first. The original and fine-tuned Whisper-tiny, Whisper-small, and Wav2Vec2-large models outperform the Conformer model by a large margin because the Conformer model is not pre-trained by other large corpora for ASR.</span></p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">To evaluate performance improvement of the weight separation process, the fine-tuned whisper-tiny model (small on-device ASR model) and LoRA fine-tuned whisper-small model (proposed weight separation method with large ASR) are compared, which are marked bold in Table 1. Although the Whisper-small LoRA fine-tuned model has lower parameters, which is 7.3M on-device parameters, it outperforms the Whisper-tiny full fine-tuned model which has 39M on-device parameters. Therefore, the efficiency and ASR performance gap is promised between the on-device code-switching ASR and the proposed weight separation method. The results of the Wav2Vec2-large(Korean) model are also summarized in Table 1. Since the pre-trained model is trained with Korean corpora only, the results are worse than the multilingual pre-trained ASR model. Still, it shows a similar tendency.</span></p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text" style="font-size:90%;">On the same model size and server-connected network setting, a large fully fine-tuned model achieves better performance than the pre-trained model and LoRA fine-tuned model. However, training and saving fully fine-tuned large models for each user need too much memory. Furthermore, the performance gap between a fully fine-tuned model and a LoRA fine-tuned model is not significant. Therefore, storing LoRA parameters for each user, especially saving them on the user‚Äôs device, is an efficient and secure way.</span></p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text" style="font-size:90%;">The evaluation results of the proposed GLoRA on Whisper-tiny and Wav2Vec2-large(ko) models are summarized in Table 2. The GLoRA-type1, which used not only pre-trained input features but also output features to extract LoRA features, outperforms the original and other types of GLoRA. The GLoRA-type2 and GLoRA-type3 achieve better performance on Wav2Vec2, but worse performance on Whisper-tiny, though the performance gap is not large.</span></p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.1" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Token normalization</span><span id="S4.SS2.p5.1.2" class="ltx_text" style="font-size:90%;"> There are two types of Unicode representation for Korean Jamo tokens. The unnormalized tokenizer uses the U+11xx lineup and the normalized tokenizer uses the U+31xx lineup. The comparison is described in Table 3. The fine-tuned model trained by a normalized tokenizer is 0.8% better than the unnormalized tokenizer in WER. We found that the tokenizer of the Whisper-small model has both types of tokens and the inference results of the original Whisper-small model always consist of normalized tokens. These results may infer that the Whisper-small model is trained by normalized tokens. Thus, the result that the fine-tuned model with normalized tokens is better than unnormalized tokens is reasonable.</span></p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.7.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>The effect of language token normalization on Korean-English code-switching task. Backbone model: Whisper-small</figcaption>
<table id="S4.T3.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.3.3" class="ltx_tr">
<th id="S4.T3.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.3.3.4.1" class="ltx_text" style="font-size:90%;">Lang. Tokenizer</span></th>
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S4.T3.1.1.1.m1.1" class="ltx_math_unparsed" alttext="WER(\%)" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.m1.1b"><mi mathsize="90%" id="S4.T3.1.1.1.m1.1.1">W</mi><mi mathsize="90%" id="S4.T3.1.1.1.m1.1.2">E</mi><mi mathsize="90%" id="S4.T3.1.1.1.m1.1.3">R</mi><mrow id="S4.T3.1.1.1.m1.1.4"><mo maxsize="90%" minsize="90%" id="S4.T3.1.1.1.m1.1.4.1">(</mo><mo mathsize="90%" id="S4.T3.1.1.1.m1.1.4.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T3.1.1.1.m1.1.4.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">WER(\%)</annotation></semantics></math></th>
<th id="S4.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S4.T3.2.2.2.m1.1" class="ltx_math_unparsed" alttext="CER(\%)" display="inline"><semantics id="S4.T3.2.2.2.m1.1a"><mrow id="S4.T3.2.2.2.m1.1b"><mi mathsize="90%" id="S4.T3.2.2.2.m1.1.1">C</mi><mi mathsize="90%" id="S4.T3.2.2.2.m1.1.2">E</mi><mi mathsize="90%" id="S4.T3.2.2.2.m1.1.3">R</mi><mrow id="S4.T3.2.2.2.m1.1.4"><mo maxsize="90%" minsize="90%" id="S4.T3.2.2.2.m1.1.4.1">(</mo><mo mathsize="90%" id="S4.T3.2.2.2.m1.1.4.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T3.2.2.2.m1.1.4.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">CER(\%)</annotation></semantics></math></th>
<th id="S4.T3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S4.T3.3.3.3.m1.1" class="ltx_math_unparsed" alttext="JER(\%)" display="inline"><semantics id="S4.T3.3.3.3.m1.1a"><mrow id="S4.T3.3.3.3.m1.1b"><mi mathsize="90%" id="S4.T3.3.3.3.m1.1.1">J</mi><mi mathsize="90%" id="S4.T3.3.3.3.m1.1.2">E</mi><mi mathsize="90%" id="S4.T3.3.3.3.m1.1.3">R</mi><mrow id="S4.T3.3.3.3.m1.1.4"><mo maxsize="90%" minsize="90%" id="S4.T3.3.3.3.m1.1.4.1">(</mo><mo mathsize="90%" id="S4.T3.3.3.3.m1.1.4.2">%</mo><mo maxsize="90%" minsize="90%" id="S4.T3.3.3.3.m1.1.4.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">JER(\%)</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.3.4.1" class="ltx_tr">
<th id="S4.T3.3.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.3.4.1.1.1" class="ltx_text" style="font-size:90%;">Unnormalized</span></th>
<td id="S4.T3.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.3.4.1.2.1" class="ltx_text" style="font-size:90%;">30.757</span></td>
<td id="S4.T3.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.3.4.1.3.1" class="ltx_text" style="font-size:90%;">15.702</span></td>
<td id="S4.T3.3.4.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.3.4.1.4.1" class="ltx_text" style="font-size:90%;">12.437</span></td>
</tr>
<tr id="S4.T3.3.5.2" class="ltx_tr">
<th id="S4.T3.3.5.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T3.3.5.2.1.1" class="ltx_text" style="font-size:90%;">Normalized</span></th>
<td id="S4.T3.3.5.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.3.5.2.2.1" class="ltx_text" style="font-size:90%;">29.951</span></td>
<td id="S4.T3.3.5.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.3.5.2.3.1" class="ltx_text" style="font-size:90%;">15.277</span></td>
<td id="S4.T3.3.5.2.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.3.5.2.4.1" class="ltx_text" style="font-size:90%;">12.097</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text" style="font-size:90%;">In this study, we proposed a weight separation method for personalized code-switching ASR on low-spec devices. We also presented the gated linear unit-based LoRA structure, named GLoRA. The proposed weight separation method has the advantages of efficiency, privacy, and personalized ASR performance. The GLoRA, which used gated linear units and pre-trained output features to extract LoRA features, outperforms the original LoRA. Through the series of experiments, the proposed methods are validated on personalized code-switching ASR. In the future, the weight separation method will be applied to customer service-level applications and the GLoRA will be employed for other tasks that use large neural network models.</span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:80%;">
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De¬†Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:80%;">‚ÄúParameter-efficient transfer learning for nlp,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">International Conference on Machine Learning</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:80%;">. PMLR, 2019, pp. 2790‚Äì2799.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:80%;">
Xiang¬†Lisa Li and Percy Liang,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:80%;">‚ÄúPrefix-tuning: Optimizing continuous prompts for generation,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2101.00190</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:80%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:80%;">
Edward¬†J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu¬†Wang, and Weizhu Chen,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:80%;">‚ÄúLoRA: Low-rank adaptation of large language models,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">International Conference on Learning Representations</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:80%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:80%;">
Chao-Yuan Kao, Sangwook Park, Alzahra Badi, David¬†K Han, and Hanseok Ko,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:80%;">‚ÄúOrthogonal gradient penalty for fast training of wasserstein gan based multi-task autoencoder toward robust speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">IEICE TRANSACTIONS on Information and Systems</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:80%;">, vol. 103, no. 5, pp. 1195‚Äì1198, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:80%;">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:80%;">‚ÄúLibrispeech: an asr corpus based on public domain audio books,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2015, pp. 5206‚Äì5210.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:80%;">
Junho Park and Hanseok Ko,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:80%;">‚ÄúAchieving a reliable compact acoustic model for embedded speech recognition system with high confusion frequency model handling,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Speech Communication</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:80%;">, vol. 48, no. 6, pp. 737‚Äì745, 2006.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:80%;">
Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu¬†Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:80%;">‚ÄúConformer: Convolution-augmented transformer for speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2005.08100</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:80%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:80%;">
Tae-Yoon Kim and Hanseok Ko,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:80%;">‚ÄúBayesian fusion of confidence measures for speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Signal Processing Letters</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:80%;">, vol. 12, no. 12, pp. 871‚Äì874, 2005.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:80%;">
Alex Graves,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:80%;">‚ÄúSequence transduction with recurrent neural networks,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1211.3711</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:80%;">, 2012.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:80%;">
BaeYoung Park, JunHo Park, JongSeong Yoon, and Hanseok Ko,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:80%;">‚ÄúRelationship between send characteristics of voip phone and speech recognition performance,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">2011 IEEE International Conference on Consumer Electronics (ICCE)</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2011, pp. 25‚Äì26.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:80%;">
Yoonjae Lee and Hanseok Ko,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:80%;">‚ÄúEffective energy feature compensation using modified log-energy dynamic range normalization for robust speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">IEICE transactions on communications</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:80%;">, vol. 90, no. 6, pp. 1508‚Äì1511, 2007.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:80%;">
Jounghoon Beh, Robert¬†H Baran, and Hanseok Ko,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:80%;">‚ÄúDual channel based speech enhancement using novelty filter for robust speech recognition in automobile environment,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">IEEE Transactions on Consumer Electronics</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:80%;">, vol. 52, no. 2, pp. 583‚Äì589, 2006.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:80%;">
Rosana Ardila, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael Henretty, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:80%;">‚ÄúCommon voice: A massively-multilingual speech corpus,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the Twelfth Language Resources and Evaluation Conference</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:80%;">, 2020, pp. 4218‚Äì4222.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:80%;">
Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, and Ronan Collobert,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:80%;">‚ÄúMls: A large-scale multilingual dataset for speech research,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Proc. Interspeech 2020</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:80%;">, pp. 2757‚Äì2761, 2020.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:80%;">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:80%;">‚Äúwav2vec 2.0: A framework for self-supervised learning of speech representations,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Advances in neural information processing systems</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:80%;">, vol. 33, pp. 12449‚Äì12460, 2020.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:80%;">
Alec Radford, Jong¬†Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:80%;">‚ÄúRobust speech recognition via large-scale weak supervision,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">International Conference on Machine Learning</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:80%;">. PMLR, 2023, pp. 28492‚Äì28518.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:80%;">
Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:80%;">‚ÄúXls-r: Self-supervised cross-lingual speech representation learning at scale,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2111.09296</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:80%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:80%;">
Ove Anderson, Paul Dalsgaard, and William Barry,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:80%;">‚ÄúOn the use of data-driven clustering technique for identification of poly-and mono-phonemes for four european languages,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of ICASSP‚Äô94. IEEE International Conference on Acoustics, Speech and Signal Processing</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 1994, vol.¬†1, pp. I‚Äì121.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:80%;">
Cheng Yi, Jianzong Wang, Ning Cheng, Shiyu Zhou, and Bo¬†Xu,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:80%;">‚ÄúTransfer ability of monolingual wav2vec2. 0 for low-resource speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">2021 international joint conference on neural networks (IJCNN)</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2021, pp. 1‚Äì6.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:80%;">
Damheo Lee, Donghyun Kim, Seung Yun, and Sanghun Kim,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:80%;">‚ÄúPhonetic variation modeling and a language model adaptation for korean english code-switching speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Applied Sciences</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:80%;">, vol. 11, no. 6, pp. 2866, 2021.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:80%;">
Jisung Wang, Jihwan Kim, Sangki Kim, and Yeha Lee,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:80%;">‚ÄúExploring lexicon-free modeling units for end-to-end korean and korean-english code-switching speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1910.11590</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:80%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:80%;">
Changhao Shan, Chao Weng, Guangsen Wang, Dan Su, Min Luo, Dong Yu, and Lei Xie,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:80%;">‚ÄúInvestigating end-to-end speech recognition for mandarin-english code-switching,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2019, pp. 6056‚Äì6060.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:80%;">
Ke¬†Li, Jinyu Li, Guoli Ye, Rui Zhao, and Yifan Gong,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:80%;">‚ÄúTowards code-switching asr for end-to-end ctc models,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2019, pp. 6076‚Äì6080.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:80%;">
Holy Lovenia, Samuel Cahyawijaya, Genta Winata, Peng Xu, Yan Xu, Zihan Liu, Rita Frieske, Tiezheng Yu, Wenliang Dai, Elham¬†J Barezi, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:80%;">‚ÄúAscend: A spontaneous chinese-english dataset for code-switching in multi-turn conversation,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the Thirteenth Language Resources and Evaluation Conference</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:80%;">, 2022, pp. 7259‚Äì7268.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:80%;">
Amir Hussein, Shammur¬†Absar Chowdhury, Ahmed Abdelali, Najim Dehak, Ahmed Ali, and Sanjeev Khudanpur,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:80%;">‚ÄúTextual data augmentation for arabic-english code-switching speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">2022 IEEE Spoken Language Technology Workshop (SLT)</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2023, pp. 777‚Äì784.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:80%;">
William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:80%;">‚ÄúListen, attend and spell: A neural network for large vocabulary conversational speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">2016 IEEE international conference on acoustics, speech and signal processing (ICASSP)</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:80%;">. IEEE, 2016, pp. 4960‚Äì4964.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:80%;">
Alex Graves, Santiago Fern√°ndez, Faustino Gomez, and J√ºrgen Schmidhuber,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:80%;">‚ÄúConnectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:80%;">in </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the 23rd international conference on Machine learning</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:80%;">, 2006, pp. 369‚Äì376.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:80%;">
Shinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro Nishitoba, Yuya Unno, Nelson Enrique¬†Yalta Soplin, Jahn Heymann, Matthew Wiesner, Nanxin Chen, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:80%;">‚ÄúEspnet: End-to-end speech processing toolkit,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1804.00015</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:80%;">, 2018.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.02560" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.02562" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.02562">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.02562" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.02563" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 21:16:18 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
