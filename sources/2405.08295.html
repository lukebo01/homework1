<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.08295] SpeechVerse: A Large-scale Generalizable Audio Language Model</title><meta property="og:description" content="Large language models (LLMs) have shown incredible proficiency in performing tasks that require semantic understanding of natural language instructions. Recently, many works have further expanded this capability to per…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SpeechVerse: A Large-scale Generalizable Audio Language Model">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SpeechVerse: A Large-scale Generalizable Audio Language Model">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.08295">

<!--Generated on Wed Jun  5 14:48:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SpeechVerse: A Large-scale Generalizable Audio Language Model</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Nilaksh Das <sup id="id2.2.id1" class="ltx_sup">∗</sup> &amp;Saket Dingliwal     &amp;Srikanth Ronanki &amp;Rohit Paturi &amp;Zhaocheng Huang &amp;Prashant Mathur &amp;Jie Yuan &amp;Dhanush Bekal &amp;Xing Niu &amp;Sai Muralidhar Jayanthi &amp;Xilai Li &amp;Karel Mundnich &amp;Monica Sunkara &amp;Sundararajan Srinivasan &amp;Daniel Garcia-Romero &amp;Kyu J. Han &amp;Katrin Kirchhoff &amp;
<br class="ltx_break"><span id="id3.3.id2" class="ltx_text ltx_font_bold" style="font-size:120%;">AWS AI Labs, Amazon</span>
</span><span class="ltx_author_notes">Equal ContributionsCorresponding author: skdin@amazon.com</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Large language models (LLMs) have shown incredible proficiency in performing tasks that require semantic understanding of natural language instructions. Recently, many works have further expanded this capability to perceive multimodal audio and text inputs, but their capabilities are often limited to specific fine-tuned tasks such as automatic speech recognition and translation. We therefore develop SpeechVerse, a robust multi-task training and curriculum learning framework that combines pre-trained speech and text foundation models via a small set of learnable parameters, while keeping the pre-trained models frozen during training. The models are instruction finetuned using continuous latent representations extracted from the speech foundation model to achieve optimal zero-shot performance on a diverse range of speech processing tasks using natural language instructions. We perform extensive benchmarking that includes comparing our model performance against traditional baselines across several datasets and tasks. Furthermore, we evaluate the model’s capability for generalized instruction following by testing on out-of-domain datasets, novel prompts, and unseen tasks. Our empirical experiments reveal that our multi-task SpeechVerse model is even superior to conventional task-specific baselines on 9 out of the 11 tasks.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Large language models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">3</a>, <a href="#bib.bibx1" title="" class="ltx_ref">1</a>, <a href="#bib.bibx2" title="" class="ltx_ref">2</a>]</cite> have achieved remarkable performance on a variety of natural language tasks through self-supervised pre-training on massive text corpora. They have also shown a striking ability to follow open-ended instructions from users through further instruction tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">5</a>, <a href="#bib.bibx6" title="" class="ltx_ref">6</a>, <a href="#bib.bibx4" title="" class="ltx_ref">4</a>, <a href="#bib.bibx7" title="" class="ltx_ref">7</a>]</cite>, enabling strong generalization capabilities. Despite the success, a significant limitation lies in the inability of language models to perceive non-textual modalities such as images and audio.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Speech in particular represents the most natural mode of human communication. Empowering LLMs to deeply understand speech could significantly enhance human-computer interaction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">8</a>]</cite> and multimodal dialog agents <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">9</a>, <a href="#bib.bibx10" title="" class="ltx_ref">10</a>]</cite>. As such, enabling LLMs to comprehend speech has received substantial attention recently. Some approaches first transcribe speech via an automated speech recognition (ASR) system and then process the text with an LLM for improved transcription <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">12</a>, <a href="#bib.bibx13" title="" class="ltx_ref">13</a>, <a href="#bib.bibx11" title="" class="ltx_ref">11</a>]</cite>. However, such pipelines cannot capture non-textual paralinguistic and prosodic features like speaker tone, intonation, emotion, valence, etc.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2405.08295/assets/figures/multi_task_figure.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="300" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Schematic diagram of the SpeechVerse framework.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">A promising new paradigm directly fuses textual LLMs with speech encoders within an end-to-end training framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">15</a>, <a href="#bib.bibx14" title="" class="ltx_ref">14</a>]</cite>. Enabling joint modeling of speech and text holds promise for richer speech and audio comprehension versus text-only methods. Particularly, instruction-following multimodal audio-language models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">18</a>, <a href="#bib.bibx17" title="" class="ltx_ref">17</a>, <a href="#bib.bibx16" title="" class="ltx_ref">16</a>]</cite> are increasingly receiving more attention due to their generalization capability. Despite some success, existing works in multi-task audio-language models such as SpeechT5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">19</a>]</cite>, Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">20</a>]</cite>, VIOLA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">15</a>]</cite>, SpeechGPT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">18</a>]</cite>, and SLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">17</a>]</cite> are limited to processing a small number of speech tasks.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We therefore propose SpeechVerse, a robust multi-task framework that leverages supervised instruction finetuning to incorporate various speech tasks (see Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). In contrast to SpeechGPT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">18</a>]</cite>, we propose using continuous representations extracted from a self-supervised pre-trained speech foundation model, focusing on tasks that generate text-only output. More recently, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">16</a>]</cite> proposed Qwen-Audio, a multi-task audio-language model capable of perceiving human speech and sound signals and is trained on 30 tasks from diverse audio types including music and songs. However, this requires carefully designed hierarchical tagging and a large-scale supervised audio encoder for fusion making it sub-optimal for unseen speech tasks. In contrast, our training paradigm incorporates multi-task learning and supervised instruction finetuning in a unified curriculum, without the need for task-specific tagging, allowing for generalization to unseen tasks using natural language instructions.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">We summarize our contributions below:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Scalable multimodal instruction finetuning for diverse speech tasks.</span>
SpeechVerse is a novel LLM-based audio-language framework to scalably exhibit strong performance on as many as 11 diverse tasks. We
extensively benchmark our models on public datasets spanning ASR, spoken language understanding and paralinguistic speech tasks.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Versatile instruction following capability for novel open-ended tasks.</span>
We demonstrate the SpeechVerse model’s capability to leverage
the robust language understanding of the LLM backbone in order to adapt to
open-ended tasks that were unseen during multimodal finetuning.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Strategies for improving generalization to unseen tasks.</span>
We further study prompting and decoding strategies including constrained and joint decoding,
that can enhance the model’s ability to generalize to completely unseen tasks,
improving absolute metrics by up to 21%.
</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Approach</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Architecture</h3>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2405.08295/assets/figures/AudioLLM.001.v2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="206" height="165" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Block diagram of the SpeechVerse architecture.</figcaption>
</figure>
<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">As shown in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1 Architecture ‣ 2 Approach ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, our multimodal model architecture consists of three main components:
(1) a pre-trained audio encoder to encode an audio signal into a feature sequence,
(2) a 1-D convolution module that operates over the audio feature sequence to abbreviate the sequence length,
and (3) a pre-trained LLM to use these audio features and textual instructions to perform the required task.
Details of each of these sub-systems are described below.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.6" class="ltx_p"><span id="S2.SS1.p2.6.1" class="ltx_text ltx_font_bold">Audio encoder:</span>
To extract semantic features from a given audio,
we use a large pre-trained self-supervised speech foundation model
as an audio encoder.
We can represent the audio encoder as a cascading collection
of <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">L</annotation></semantics></math> layers, where each intermediate layer <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">l</annotation></semantics></math>
returns a feature sequence
<math id="S2.SS1.p2.3.m3.5" class="ltx_Math" alttext="\mathbf{h}^{(l)}=f_{AE}(\mathbf{h}^{(l-1)};\theta^{(l)}_{AE})" display="inline"><semantics id="S2.SS1.p2.3.m3.5a"><mrow id="S2.SS1.p2.3.m3.5.5" xref="S2.SS1.p2.3.m3.5.5.cmml"><msup id="S2.SS1.p2.3.m3.5.5.4" xref="S2.SS1.p2.3.m3.5.5.4.cmml"><mi id="S2.SS1.p2.3.m3.5.5.4.2" xref="S2.SS1.p2.3.m3.5.5.4.2.cmml">𝐡</mi><mrow id="S2.SS1.p2.3.m3.1.1.1.3" xref="S2.SS1.p2.3.m3.5.5.4.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.1.1.1.3.1" xref="S2.SS1.p2.3.m3.5.5.4.cmml">(</mo><mi id="S2.SS1.p2.3.m3.1.1.1.1" xref="S2.SS1.p2.3.m3.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.SS1.p2.3.m3.1.1.1.3.2" xref="S2.SS1.p2.3.m3.5.5.4.cmml">)</mo></mrow></msup><mo id="S2.SS1.p2.3.m3.5.5.3" xref="S2.SS1.p2.3.m3.5.5.3.cmml">=</mo><mrow id="S2.SS1.p2.3.m3.5.5.2" xref="S2.SS1.p2.3.m3.5.5.2.cmml"><msub id="S2.SS1.p2.3.m3.5.5.2.4" xref="S2.SS1.p2.3.m3.5.5.2.4.cmml"><mi id="S2.SS1.p2.3.m3.5.5.2.4.2" xref="S2.SS1.p2.3.m3.5.5.2.4.2.cmml">f</mi><mrow id="S2.SS1.p2.3.m3.5.5.2.4.3" xref="S2.SS1.p2.3.m3.5.5.2.4.3.cmml"><mi id="S2.SS1.p2.3.m3.5.5.2.4.3.2" xref="S2.SS1.p2.3.m3.5.5.2.4.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.3.m3.5.5.2.4.3.1" xref="S2.SS1.p2.3.m3.5.5.2.4.3.1.cmml">​</mo><mi id="S2.SS1.p2.3.m3.5.5.2.4.3.3" xref="S2.SS1.p2.3.m3.5.5.2.4.3.3.cmml">E</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p2.3.m3.5.5.2.3" xref="S2.SS1.p2.3.m3.5.5.2.3.cmml">​</mo><mrow id="S2.SS1.p2.3.m3.5.5.2.2.2" xref="S2.SS1.p2.3.m3.5.5.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.5.5.2.2.2.3" xref="S2.SS1.p2.3.m3.5.5.2.2.3.cmml">(</mo><msup id="S2.SS1.p2.3.m3.4.4.1.1.1.1" xref="S2.SS1.p2.3.m3.4.4.1.1.1.1.cmml"><mi id="S2.SS1.p2.3.m3.4.4.1.1.1.1.2" xref="S2.SS1.p2.3.m3.4.4.1.1.1.1.2.cmml">𝐡</mi><mrow id="S2.SS1.p2.3.m3.2.2.1.1" xref="S2.SS1.p2.3.m3.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.2.2.1.1.2" xref="S2.SS1.p2.3.m3.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS1.p2.3.m3.2.2.1.1.1" xref="S2.SS1.p2.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS1.p2.3.m3.2.2.1.1.1.2" xref="S2.SS1.p2.3.m3.2.2.1.1.1.2.cmml">l</mi><mo id="S2.SS1.p2.3.m3.2.2.1.1.1.1" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.cmml">−</mo><mn id="S2.SS1.p2.3.m3.2.2.1.1.1.3" xref="S2.SS1.p2.3.m3.2.2.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S2.SS1.p2.3.m3.2.2.1.1.3" xref="S2.SS1.p2.3.m3.2.2.1.1.1.cmml">)</mo></mrow></msup><mo id="S2.SS1.p2.3.m3.5.5.2.2.2.4" xref="S2.SS1.p2.3.m3.5.5.2.2.3.cmml">;</mo><msubsup id="S2.SS1.p2.3.m3.5.5.2.2.2.2" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.cmml"><mi id="S2.SS1.p2.3.m3.5.5.2.2.2.2.2.2" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.2.2.cmml">θ</mi><mrow id="S2.SS1.p2.3.m3.5.5.2.2.2.2.3" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.cmml"><mi id="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.2" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.1" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.1.cmml">​</mo><mi id="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.3" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.3.cmml">E</mi></mrow><mrow id="S2.SS1.p2.3.m3.3.3.1.3" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.3.3.1.3.1" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.cmml">(</mo><mi id="S2.SS1.p2.3.m3.3.3.1.1" xref="S2.SS1.p2.3.m3.3.3.1.1.cmml">l</mi><mo stretchy="false" id="S2.SS1.p2.3.m3.3.3.1.3.2" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.cmml">)</mo></mrow></msubsup><mo stretchy="false" id="S2.SS1.p2.3.m3.5.5.2.2.2.5" xref="S2.SS1.p2.3.m3.5.5.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.5b"><apply id="S2.SS1.p2.3.m3.5.5.cmml" xref="S2.SS1.p2.3.m3.5.5"><eq id="S2.SS1.p2.3.m3.5.5.3.cmml" xref="S2.SS1.p2.3.m3.5.5.3"></eq><apply id="S2.SS1.p2.3.m3.5.5.4.cmml" xref="S2.SS1.p2.3.m3.5.5.4"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.5.5.4.1.cmml" xref="S2.SS1.p2.3.m3.5.5.4">superscript</csymbol><ci id="S2.SS1.p2.3.m3.5.5.4.2.cmml" xref="S2.SS1.p2.3.m3.5.5.4.2">𝐡</ci><ci id="S2.SS1.p2.3.m3.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1.1.1">𝑙</ci></apply><apply id="S2.SS1.p2.3.m3.5.5.2.cmml" xref="S2.SS1.p2.3.m3.5.5.2"><times id="S2.SS1.p2.3.m3.5.5.2.3.cmml" xref="S2.SS1.p2.3.m3.5.5.2.3"></times><apply id="S2.SS1.p2.3.m3.5.5.2.4.cmml" xref="S2.SS1.p2.3.m3.5.5.2.4"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.5.5.2.4.1.cmml" xref="S2.SS1.p2.3.m3.5.5.2.4">subscript</csymbol><ci id="S2.SS1.p2.3.m3.5.5.2.4.2.cmml" xref="S2.SS1.p2.3.m3.5.5.2.4.2">𝑓</ci><apply id="S2.SS1.p2.3.m3.5.5.2.4.3.cmml" xref="S2.SS1.p2.3.m3.5.5.2.4.3"><times id="S2.SS1.p2.3.m3.5.5.2.4.3.1.cmml" xref="S2.SS1.p2.3.m3.5.5.2.4.3.1"></times><ci id="S2.SS1.p2.3.m3.5.5.2.4.3.2.cmml" xref="S2.SS1.p2.3.m3.5.5.2.4.3.2">𝐴</ci><ci id="S2.SS1.p2.3.m3.5.5.2.4.3.3.cmml" xref="S2.SS1.p2.3.m3.5.5.2.4.3.3">𝐸</ci></apply></apply><list id="S2.SS1.p2.3.m3.5.5.2.2.3.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2"><apply id="S2.SS1.p2.3.m3.4.4.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.4.4.1.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.4.4.1.1.1.1">superscript</csymbol><ci id="S2.SS1.p2.3.m3.4.4.1.1.1.1.2.cmml" xref="S2.SS1.p2.3.m3.4.4.1.1.1.1.2">𝐡</ci><apply id="S2.SS1.p2.3.m3.2.2.1.1.1.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1"><minus id="S2.SS1.p2.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1"></minus><ci id="S2.SS1.p2.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.2">𝑙</ci><cn type="integer" id="S2.SS1.p2.3.m3.2.2.1.1.1.3.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.3">1</cn></apply></apply><apply id="S2.SS1.p2.3.m3.5.5.2.2.2.2.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.5.5.2.2.2.2.1.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2">subscript</csymbol><apply id="S2.SS1.p2.3.m3.5.5.2.2.2.2.2.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.5.5.2.2.2.2.2.1.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2">superscript</csymbol><ci id="S2.SS1.p2.3.m3.5.5.2.2.2.2.2.2.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.2.2">𝜃</ci><ci id="S2.SS1.p2.3.m3.3.3.1.1.cmml" xref="S2.SS1.p2.3.m3.3.3.1.1">𝑙</ci></apply><apply id="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.3"><times id="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.1.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.1"></times><ci id="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.2.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.2">𝐴</ci><ci id="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.3.cmml" xref="S2.SS1.p2.3.m3.5.5.2.2.2.2.3.3">𝐸</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.5c">\mathbf{h}^{(l)}=f_{AE}(\mathbf{h}^{(l-1)};\theta^{(l)}_{AE})</annotation></semantics></math>,
where <math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{h}^{(0)}=\mathbf{x}" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mrow id="S2.SS1.p2.4.m4.1.2" xref="S2.SS1.p2.4.m4.1.2.cmml"><msup id="S2.SS1.p2.4.m4.1.2.2" xref="S2.SS1.p2.4.m4.1.2.2.cmml"><mi id="S2.SS1.p2.4.m4.1.2.2.2" xref="S2.SS1.p2.4.m4.1.2.2.2.cmml">𝐡</mi><mrow id="S2.SS1.p2.4.m4.1.1.1.3" xref="S2.SS1.p2.4.m4.1.2.2.cmml"><mo stretchy="false" id="S2.SS1.p2.4.m4.1.1.1.3.1" xref="S2.SS1.p2.4.m4.1.2.2.cmml">(</mo><mn id="S2.SS1.p2.4.m4.1.1.1.1" xref="S2.SS1.p2.4.m4.1.1.1.1.cmml">0</mn><mo stretchy="false" id="S2.SS1.p2.4.m4.1.1.1.3.2" xref="S2.SS1.p2.4.m4.1.2.2.cmml">)</mo></mrow></msup><mo id="S2.SS1.p2.4.m4.1.2.1" xref="S2.SS1.p2.4.m4.1.2.1.cmml">=</mo><mi id="S2.SS1.p2.4.m4.1.2.3" xref="S2.SS1.p2.4.m4.1.2.3.cmml">𝐱</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><apply id="S2.SS1.p2.4.m4.1.2.cmml" xref="S2.SS1.p2.4.m4.1.2"><eq id="S2.SS1.p2.4.m4.1.2.1.cmml" xref="S2.SS1.p2.4.m4.1.2.1"></eq><apply id="S2.SS1.p2.4.m4.1.2.2.cmml" xref="S2.SS1.p2.4.m4.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.2.2.1.cmml" xref="S2.SS1.p2.4.m4.1.2.2">superscript</csymbol><ci id="S2.SS1.p2.4.m4.1.2.2.2.cmml" xref="S2.SS1.p2.4.m4.1.2.2.2">𝐡</ci><cn type="integer" id="S2.SS1.p2.4.m4.1.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1">0</cn></apply><ci id="S2.SS1.p2.4.m4.1.2.3.cmml" xref="S2.SS1.p2.4.m4.1.2.3">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">\mathbf{h}^{(0)}=\mathbf{x}</annotation></semantics></math> is the input audio.
Here, <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="\theta^{(l)}_{AE}" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><msubsup id="S2.SS1.p2.5.m5.1.2" xref="S2.SS1.p2.5.m5.1.2.cmml"><mi id="S2.SS1.p2.5.m5.1.2.2.2" xref="S2.SS1.p2.5.m5.1.2.2.2.cmml">θ</mi><mrow id="S2.SS1.p2.5.m5.1.2.3" xref="S2.SS1.p2.5.m5.1.2.3.cmml"><mi id="S2.SS1.p2.5.m5.1.2.3.2" xref="S2.SS1.p2.5.m5.1.2.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.5.m5.1.2.3.1" xref="S2.SS1.p2.5.m5.1.2.3.1.cmml">​</mo><mi id="S2.SS1.p2.5.m5.1.2.3.3" xref="S2.SS1.p2.5.m5.1.2.3.3.cmml">E</mi></mrow><mrow id="S2.SS1.p2.5.m5.1.1.1.3" xref="S2.SS1.p2.5.m5.1.2.cmml"><mo stretchy="false" id="S2.SS1.p2.5.m5.1.1.1.3.1" xref="S2.SS1.p2.5.m5.1.2.cmml">(</mo><mi id="S2.SS1.p2.5.m5.1.1.1.1" xref="S2.SS1.p2.5.m5.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.SS1.p2.5.m5.1.1.1.3.2" xref="S2.SS1.p2.5.m5.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.2.cmml" xref="S2.SS1.p2.5.m5.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.2.1.cmml" xref="S2.SS1.p2.5.m5.1.2">subscript</csymbol><apply id="S2.SS1.p2.5.m5.1.2.2.cmml" xref="S2.SS1.p2.5.m5.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.2.2.1.cmml" xref="S2.SS1.p2.5.m5.1.2">superscript</csymbol><ci id="S2.SS1.p2.5.m5.1.2.2.2.cmml" xref="S2.SS1.p2.5.m5.1.2.2.2">𝜃</ci><ci id="S2.SS1.p2.5.m5.1.1.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1.1.1">𝑙</ci></apply><apply id="S2.SS1.p2.5.m5.1.2.3.cmml" xref="S2.SS1.p2.5.m5.1.2.3"><times id="S2.SS1.p2.5.m5.1.2.3.1.cmml" xref="S2.SS1.p2.5.m5.1.2.3.1"></times><ci id="S2.SS1.p2.5.m5.1.2.3.2.cmml" xref="S2.SS1.p2.5.m5.1.2.3.2">𝐴</ci><ci id="S2.SS1.p2.5.m5.1.2.3.3.cmml" xref="S2.SS1.p2.5.m5.1.2.3.3">𝐸</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">\theta^{(l)}_{AE}</annotation></semantics></math> represents the learned weights
for layer <math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><mi id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">l</annotation></semantics></math> of the pre-trained speech model.
To capture a unified representation for
multi-faceted forms of feature semantics,
we compute the output of the audio encoder as:</p>
<table id="A1.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1.m1.3" class="ltx_Math" alttext="\displaystyle AE(\mathbf{x})=\frac{1}{L}\sum_{l=1}^{L}w^{(l)}\mathbf{h}^{(l)}\vspace{-0.2cm}" display="inline"><semantics id="S2.E1.m1.3a"><mrow id="S2.E1.m1.3.4" xref="S2.E1.m1.3.4.cmml"><mrow id="S2.E1.m1.3.4.2" xref="S2.E1.m1.3.4.2.cmml"><mi id="S2.E1.m1.3.4.2.2" xref="S2.E1.m1.3.4.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.4.2.1" xref="S2.E1.m1.3.4.2.1.cmml">​</mo><mi id="S2.E1.m1.3.4.2.3" xref="S2.E1.m1.3.4.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.4.2.1a" xref="S2.E1.m1.3.4.2.1.cmml">​</mo><mrow id="S2.E1.m1.3.4.2.4.2" xref="S2.E1.m1.3.4.2.cmml"><mo stretchy="false" id="S2.E1.m1.3.4.2.4.2.1" xref="S2.E1.m1.3.4.2.cmml">(</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">𝐱</mi><mo stretchy="false" id="S2.E1.m1.3.4.2.4.2.2" xref="S2.E1.m1.3.4.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.3.4.1" xref="S2.E1.m1.3.4.1.cmml">=</mo><mrow id="S2.E1.m1.3.4.3" xref="S2.E1.m1.3.4.3.cmml"><mstyle displaystyle="true" id="S2.E1.m1.3.4.3.2" xref="S2.E1.m1.3.4.3.2.cmml"><mfrac id="S2.E1.m1.3.4.3.2a" xref="S2.E1.m1.3.4.3.2.cmml"><mn id="S2.E1.m1.3.4.3.2.2" xref="S2.E1.m1.3.4.3.2.2.cmml">1</mn><mi id="S2.E1.m1.3.4.3.2.3" xref="S2.E1.m1.3.4.3.2.3.cmml">L</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.4.3.1" xref="S2.E1.m1.3.4.3.1.cmml">​</mo><mrow id="S2.E1.m1.3.4.3.3" xref="S2.E1.m1.3.4.3.3.cmml"><mstyle displaystyle="true" id="S2.E1.m1.3.4.3.3.1" xref="S2.E1.m1.3.4.3.3.1.cmml"><munderover id="S2.E1.m1.3.4.3.3.1a" xref="S2.E1.m1.3.4.3.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.3.4.3.3.1.2.2" xref="S2.E1.m1.3.4.3.3.1.2.2.cmml">∑</mo><mrow id="S2.E1.m1.3.4.3.3.1.2.3" xref="S2.E1.m1.3.4.3.3.1.2.3.cmml"><mi id="S2.E1.m1.3.4.3.3.1.2.3.2" xref="S2.E1.m1.3.4.3.3.1.2.3.2.cmml">l</mi><mo id="S2.E1.m1.3.4.3.3.1.2.3.1" xref="S2.E1.m1.3.4.3.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m1.3.4.3.3.1.2.3.3" xref="S2.E1.m1.3.4.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.3.4.3.3.1.3" xref="S2.E1.m1.3.4.3.3.1.3.cmml">L</mi></munderover></mstyle><mrow id="S2.E1.m1.3.4.3.3.2" xref="S2.E1.m1.3.4.3.3.2.cmml"><msup id="S2.E1.m1.3.4.3.3.2.2" xref="S2.E1.m1.3.4.3.3.2.2.cmml"><mi id="S2.E1.m1.3.4.3.3.2.2.2" xref="S2.E1.m1.3.4.3.3.2.2.2.cmml">w</mi><mrow id="S2.E1.m1.1.1.1.3" xref="S2.E1.m1.3.4.3.3.2.2.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.3.1" xref="S2.E1.m1.3.4.3.3.2.2.cmml">(</mo><mi id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">l</mi><mo stretchy="false" id="S2.E1.m1.1.1.1.3.2" xref="S2.E1.m1.3.4.3.3.2.2.cmml">)</mo></mrow></msup><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.4.3.3.2.1" xref="S2.E1.m1.3.4.3.3.2.1.cmml">​</mo><msup id="S2.E1.m1.3.4.3.3.2.3" xref="S2.E1.m1.3.4.3.3.2.3.cmml"><mi id="S2.E1.m1.3.4.3.3.2.3.2" xref="S2.E1.m1.3.4.3.3.2.3.2.cmml">𝐡</mi><mrow id="S2.E1.m1.2.2.1.3" xref="S2.E1.m1.3.4.3.3.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.3.1" xref="S2.E1.m1.3.4.3.3.2.3.cmml">(</mo><mi id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml">l</mi><mo stretchy="false" id="S2.E1.m1.2.2.1.3.2" xref="S2.E1.m1.3.4.3.3.2.3.cmml">)</mo></mrow></msup></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.3b"><apply id="S2.E1.m1.3.4.cmml" xref="S2.E1.m1.3.4"><eq id="S2.E1.m1.3.4.1.cmml" xref="S2.E1.m1.3.4.1"></eq><apply id="S2.E1.m1.3.4.2.cmml" xref="S2.E1.m1.3.4.2"><times id="S2.E1.m1.3.4.2.1.cmml" xref="S2.E1.m1.3.4.2.1"></times><ci id="S2.E1.m1.3.4.2.2.cmml" xref="S2.E1.m1.3.4.2.2">𝐴</ci><ci id="S2.E1.m1.3.4.2.3.cmml" xref="S2.E1.m1.3.4.2.3">𝐸</ci><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">𝐱</ci></apply><apply id="S2.E1.m1.3.4.3.cmml" xref="S2.E1.m1.3.4.3"><times id="S2.E1.m1.3.4.3.1.cmml" xref="S2.E1.m1.3.4.3.1"></times><apply id="S2.E1.m1.3.4.3.2.cmml" xref="S2.E1.m1.3.4.3.2"><divide id="S2.E1.m1.3.4.3.2.1.cmml" xref="S2.E1.m1.3.4.3.2"></divide><cn type="integer" id="S2.E1.m1.3.4.3.2.2.cmml" xref="S2.E1.m1.3.4.3.2.2">1</cn><ci id="S2.E1.m1.3.4.3.2.3.cmml" xref="S2.E1.m1.3.4.3.2.3">𝐿</ci></apply><apply id="S2.E1.m1.3.4.3.3.cmml" xref="S2.E1.m1.3.4.3.3"><apply id="S2.E1.m1.3.4.3.3.1.cmml" xref="S2.E1.m1.3.4.3.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.4.3.3.1.1.cmml" xref="S2.E1.m1.3.4.3.3.1">superscript</csymbol><apply id="S2.E1.m1.3.4.3.3.1.2.cmml" xref="S2.E1.m1.3.4.3.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.4.3.3.1.2.1.cmml" xref="S2.E1.m1.3.4.3.3.1">subscript</csymbol><sum id="S2.E1.m1.3.4.3.3.1.2.2.cmml" xref="S2.E1.m1.3.4.3.3.1.2.2"></sum><apply id="S2.E1.m1.3.4.3.3.1.2.3.cmml" xref="S2.E1.m1.3.4.3.3.1.2.3"><eq id="S2.E1.m1.3.4.3.3.1.2.3.1.cmml" xref="S2.E1.m1.3.4.3.3.1.2.3.1"></eq><ci id="S2.E1.m1.3.4.3.3.1.2.3.2.cmml" xref="S2.E1.m1.3.4.3.3.1.2.3.2">𝑙</ci><cn type="integer" id="S2.E1.m1.3.4.3.3.1.2.3.3.cmml" xref="S2.E1.m1.3.4.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.3.4.3.3.1.3.cmml" xref="S2.E1.m1.3.4.3.3.1.3">𝐿</ci></apply><apply id="S2.E1.m1.3.4.3.3.2.cmml" xref="S2.E1.m1.3.4.3.3.2"><times id="S2.E1.m1.3.4.3.3.2.1.cmml" xref="S2.E1.m1.3.4.3.3.2.1"></times><apply id="S2.E1.m1.3.4.3.3.2.2.cmml" xref="S2.E1.m1.3.4.3.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.4.3.3.2.2.1.cmml" xref="S2.E1.m1.3.4.3.3.2.2">superscript</csymbol><ci id="S2.E1.m1.3.4.3.3.2.2.2.cmml" xref="S2.E1.m1.3.4.3.3.2.2.2">𝑤</ci><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">𝑙</ci></apply><apply id="S2.E1.m1.3.4.3.3.2.3.cmml" xref="S2.E1.m1.3.4.3.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.3.4.3.3.2.3.1.cmml" xref="S2.E1.m1.3.4.3.3.2.3">superscript</csymbol><ci id="S2.E1.m1.3.4.3.3.2.3.2.cmml" xref="S2.E1.m1.3.4.3.3.2.3.2">𝐡</ci><ci id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1.1">𝑙</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.3c">\displaystyle AE(\mathbf{x})=\frac{1}{L}\sum_{l=1}^{L}w^{(l)}\mathbf{h}^{(l)}\vspace{-0.2cm}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p2.8" class="ltx_p">where, the scalars <math id="S2.SS1.p2.7.m1.4" class="ltx_Math" alttext="\{w^{(1)},\dots w^{(L)}\}" display="inline"><semantics id="S2.SS1.p2.7.m1.4a"><mrow id="S2.SS1.p2.7.m1.4.4.2" xref="S2.SS1.p2.7.m1.4.4.3.cmml"><mo stretchy="false" id="S2.SS1.p2.7.m1.4.4.2.3" xref="S2.SS1.p2.7.m1.4.4.3.cmml">{</mo><msup id="S2.SS1.p2.7.m1.3.3.1.1" xref="S2.SS1.p2.7.m1.3.3.1.1.cmml"><mi id="S2.SS1.p2.7.m1.3.3.1.1.2" xref="S2.SS1.p2.7.m1.3.3.1.1.2.cmml">w</mi><mrow id="S2.SS1.p2.7.m1.1.1.1.3" xref="S2.SS1.p2.7.m1.3.3.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.7.m1.1.1.1.3.1" xref="S2.SS1.p2.7.m1.3.3.1.1.cmml">(</mo><mn id="S2.SS1.p2.7.m1.1.1.1.1" xref="S2.SS1.p2.7.m1.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S2.SS1.p2.7.m1.1.1.1.3.2" xref="S2.SS1.p2.7.m1.3.3.1.1.cmml">)</mo></mrow></msup><mo id="S2.SS1.p2.7.m1.4.4.2.4" xref="S2.SS1.p2.7.m1.4.4.3.cmml">,</mo><mrow id="S2.SS1.p2.7.m1.4.4.2.2" xref="S2.SS1.p2.7.m1.4.4.2.2.cmml"><mi mathvariant="normal" id="S2.SS1.p2.7.m1.4.4.2.2.2" xref="S2.SS1.p2.7.m1.4.4.2.2.2.cmml">…</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.7.m1.4.4.2.2.1" xref="S2.SS1.p2.7.m1.4.4.2.2.1.cmml">​</mo><msup id="S2.SS1.p2.7.m1.4.4.2.2.3" xref="S2.SS1.p2.7.m1.4.4.2.2.3.cmml"><mi id="S2.SS1.p2.7.m1.4.4.2.2.3.2" xref="S2.SS1.p2.7.m1.4.4.2.2.3.2.cmml">w</mi><mrow id="S2.SS1.p2.7.m1.2.2.1.3" xref="S2.SS1.p2.7.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p2.7.m1.2.2.1.3.1" xref="S2.SS1.p2.7.m1.4.4.2.2.3.cmml">(</mo><mi id="S2.SS1.p2.7.m1.2.2.1.1" xref="S2.SS1.p2.7.m1.2.2.1.1.cmml">L</mi><mo stretchy="false" id="S2.SS1.p2.7.m1.2.2.1.3.2" xref="S2.SS1.p2.7.m1.4.4.2.2.3.cmml">)</mo></mrow></msup></mrow><mo stretchy="false" id="S2.SS1.p2.7.m1.4.4.2.5" xref="S2.SS1.p2.7.m1.4.4.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m1.4b"><set id="S2.SS1.p2.7.m1.4.4.3.cmml" xref="S2.SS1.p2.7.m1.4.4.2"><apply id="S2.SS1.p2.7.m1.3.3.1.1.cmml" xref="S2.SS1.p2.7.m1.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m1.3.3.1.1.1.cmml" xref="S2.SS1.p2.7.m1.3.3.1.1">superscript</csymbol><ci id="S2.SS1.p2.7.m1.3.3.1.1.2.cmml" xref="S2.SS1.p2.7.m1.3.3.1.1.2">𝑤</ci><cn type="integer" id="S2.SS1.p2.7.m1.1.1.1.1.cmml" xref="S2.SS1.p2.7.m1.1.1.1.1">1</cn></apply><apply id="S2.SS1.p2.7.m1.4.4.2.2.cmml" xref="S2.SS1.p2.7.m1.4.4.2.2"><times id="S2.SS1.p2.7.m1.4.4.2.2.1.cmml" xref="S2.SS1.p2.7.m1.4.4.2.2.1"></times><ci id="S2.SS1.p2.7.m1.4.4.2.2.2.cmml" xref="S2.SS1.p2.7.m1.4.4.2.2.2">…</ci><apply id="S2.SS1.p2.7.m1.4.4.2.2.3.cmml" xref="S2.SS1.p2.7.m1.4.4.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m1.4.4.2.2.3.1.cmml" xref="S2.SS1.p2.7.m1.4.4.2.2.3">superscript</csymbol><ci id="S2.SS1.p2.7.m1.4.4.2.2.3.2.cmml" xref="S2.SS1.p2.7.m1.4.4.2.2.3.2">𝑤</ci><ci id="S2.SS1.p2.7.m1.2.2.1.1.cmml" xref="S2.SS1.p2.7.m1.2.2.1.1">𝐿</ci></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m1.4c">\{w^{(1)},\dots w^{(L)}\}</annotation></semantics></math>
are a set of learnable parameters.
As this approach concurrently encodes features
from multiple intermediate layers of the speech foundation model,
it can simultaneously capture different forms of semantics
(higher-order as well as lower-order features),
leading to better generalization across a diverse set of tasks.
We also perform experiments by only taking the output
from the last layer of the audio encoder, i.e.,
<math id="S2.SS1.p2.8.m2.2" class="ltx_Math" alttext="AE(\mathbf{x})=\mathbf{h}^{(L)}" display="inline"><semantics id="S2.SS1.p2.8.m2.2a"><mrow id="S2.SS1.p2.8.m2.2.3" xref="S2.SS1.p2.8.m2.2.3.cmml"><mrow id="S2.SS1.p2.8.m2.2.3.2" xref="S2.SS1.p2.8.m2.2.3.2.cmml"><mi id="S2.SS1.p2.8.m2.2.3.2.2" xref="S2.SS1.p2.8.m2.2.3.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.8.m2.2.3.2.1" xref="S2.SS1.p2.8.m2.2.3.2.1.cmml">​</mo><mi id="S2.SS1.p2.8.m2.2.3.2.3" xref="S2.SS1.p2.8.m2.2.3.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.8.m2.2.3.2.1a" xref="S2.SS1.p2.8.m2.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.p2.8.m2.2.3.2.4.2" xref="S2.SS1.p2.8.m2.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.p2.8.m2.2.3.2.4.2.1" xref="S2.SS1.p2.8.m2.2.3.2.cmml">(</mo><mi id="S2.SS1.p2.8.m2.2.2" xref="S2.SS1.p2.8.m2.2.2.cmml">𝐱</mi><mo stretchy="false" id="S2.SS1.p2.8.m2.2.3.2.4.2.2" xref="S2.SS1.p2.8.m2.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p2.8.m2.2.3.1" xref="S2.SS1.p2.8.m2.2.3.1.cmml">=</mo><msup id="S2.SS1.p2.8.m2.2.3.3" xref="S2.SS1.p2.8.m2.2.3.3.cmml"><mi id="S2.SS1.p2.8.m2.2.3.3.2" xref="S2.SS1.p2.8.m2.2.3.3.2.cmml">𝐡</mi><mrow id="S2.SS1.p2.8.m2.1.1.1.3" xref="S2.SS1.p2.8.m2.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.p2.8.m2.1.1.1.3.1" xref="S2.SS1.p2.8.m2.2.3.3.cmml">(</mo><mi id="S2.SS1.p2.8.m2.1.1.1.1" xref="S2.SS1.p2.8.m2.1.1.1.1.cmml">L</mi><mo stretchy="false" id="S2.SS1.p2.8.m2.1.1.1.3.2" xref="S2.SS1.p2.8.m2.2.3.3.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m2.2b"><apply id="S2.SS1.p2.8.m2.2.3.cmml" xref="S2.SS1.p2.8.m2.2.3"><eq id="S2.SS1.p2.8.m2.2.3.1.cmml" xref="S2.SS1.p2.8.m2.2.3.1"></eq><apply id="S2.SS1.p2.8.m2.2.3.2.cmml" xref="S2.SS1.p2.8.m2.2.3.2"><times id="S2.SS1.p2.8.m2.2.3.2.1.cmml" xref="S2.SS1.p2.8.m2.2.3.2.1"></times><ci id="S2.SS1.p2.8.m2.2.3.2.2.cmml" xref="S2.SS1.p2.8.m2.2.3.2.2">𝐴</ci><ci id="S2.SS1.p2.8.m2.2.3.2.3.cmml" xref="S2.SS1.p2.8.m2.2.3.2.3">𝐸</ci><ci id="S2.SS1.p2.8.m2.2.2.cmml" xref="S2.SS1.p2.8.m2.2.2">𝐱</ci></apply><apply id="S2.SS1.p2.8.m2.2.3.3.cmml" xref="S2.SS1.p2.8.m2.2.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.8.m2.2.3.3.1.cmml" xref="S2.SS1.p2.8.m2.2.3.3">superscript</csymbol><ci id="S2.SS1.p2.8.m2.2.3.3.2.cmml" xref="S2.SS1.p2.8.m2.2.3.3.2">𝐡</ci><ci id="S2.SS1.p2.8.m2.1.1.1.1.cmml" xref="S2.SS1.p2.8.m2.1.1.1.1">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m2.2c">AE(\mathbf{x})=\mathbf{h}^{(L)}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.2" class="ltx_p"><span id="S2.SS1.p3.2.1" class="ltx_text ltx_font_bold">Convolution downsampling module:</span>
LLMs trained on text-only input
encode token sequences
which are typically of a considerably shorter length
compared to the feature sequences encoded by
speech foundation models.
To mitigate this large discrepancy in length distribution
between audio features and text tokens,
we downsample the encoded audio features through
a learnable convolution module.
This module consists of successive blocks,
each having a 1-D convolution layer
followed by layer normalization.
For the 1-D convolution,
we use a kernel size of 3,
which ensures that each output frame
has both left and right context from the input frames.
In our experiments, we use as many number of these downsampling blocks
as necessary such that the resulting
sampling rate for the audio comes out to be 12.5 Hz, i.e.,
each output frame corresponds to 80ms of audio.
By fine-tuning the convolution downsampling module,
the audio encoder output can be transformed
from an audio-only feature space
to a joint audio-text semantic space.
Hence, we set the number of output channels for the 1-D convolution
to be equal to the feature dimension of the token embeddings
for the downstream LLM.
We can represent the output of the convolution downsampling module as
<math id="S2.SS1.p3.1.m1.4" class="ltx_Math" alttext="CNN(\mathbf{x})=f_{CNN}(AE(\mathbf{x});\theta_{CNN})" display="inline"><semantics id="S2.SS1.p3.1.m1.4a"><mrow id="S2.SS1.p3.1.m1.4.4" xref="S2.SS1.p3.1.m1.4.4.cmml"><mrow id="S2.SS1.p3.1.m1.4.4.4" xref="S2.SS1.p3.1.m1.4.4.4.cmml"><mi id="S2.SS1.p3.1.m1.4.4.4.2" xref="S2.SS1.p3.1.m1.4.4.4.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.4.4.4.1" xref="S2.SS1.p3.1.m1.4.4.4.1.cmml">​</mo><mi id="S2.SS1.p3.1.m1.4.4.4.3" xref="S2.SS1.p3.1.m1.4.4.4.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.4.4.4.1a" xref="S2.SS1.p3.1.m1.4.4.4.1.cmml">​</mo><mi id="S2.SS1.p3.1.m1.4.4.4.4" xref="S2.SS1.p3.1.m1.4.4.4.4.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.4.4.4.1b" xref="S2.SS1.p3.1.m1.4.4.4.1.cmml">​</mo><mrow id="S2.SS1.p3.1.m1.4.4.4.5.2" xref="S2.SS1.p3.1.m1.4.4.4.cmml"><mo stretchy="false" id="S2.SS1.p3.1.m1.4.4.4.5.2.1" xref="S2.SS1.p3.1.m1.4.4.4.cmml">(</mo><mi id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S2.SS1.p3.1.m1.4.4.4.5.2.2" xref="S2.SS1.p3.1.m1.4.4.4.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p3.1.m1.4.4.3" xref="S2.SS1.p3.1.m1.4.4.3.cmml">=</mo><mrow id="S2.SS1.p3.1.m1.4.4.2" xref="S2.SS1.p3.1.m1.4.4.2.cmml"><msub id="S2.SS1.p3.1.m1.4.4.2.4" xref="S2.SS1.p3.1.m1.4.4.2.4.cmml"><mi id="S2.SS1.p3.1.m1.4.4.2.4.2" xref="S2.SS1.p3.1.m1.4.4.2.4.2.cmml">f</mi><mrow id="S2.SS1.p3.1.m1.4.4.2.4.3" xref="S2.SS1.p3.1.m1.4.4.2.4.3.cmml"><mi id="S2.SS1.p3.1.m1.4.4.2.4.3.2" xref="S2.SS1.p3.1.m1.4.4.2.4.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.4.4.2.4.3.1" xref="S2.SS1.p3.1.m1.4.4.2.4.3.1.cmml">​</mo><mi id="S2.SS1.p3.1.m1.4.4.2.4.3.3" xref="S2.SS1.p3.1.m1.4.4.2.4.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.4.4.2.4.3.1a" xref="S2.SS1.p3.1.m1.4.4.2.4.3.1.cmml">​</mo><mi id="S2.SS1.p3.1.m1.4.4.2.4.3.4" xref="S2.SS1.p3.1.m1.4.4.2.4.3.4.cmml">N</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.4.4.2.3" xref="S2.SS1.p3.1.m1.4.4.2.3.cmml">​</mo><mrow id="S2.SS1.p3.1.m1.4.4.2.2.2" xref="S2.SS1.p3.1.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p3.1.m1.4.4.2.2.2.3" xref="S2.SS1.p3.1.m1.4.4.2.2.3.cmml">(</mo><mrow id="S2.SS1.p3.1.m1.3.3.1.1.1.1" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.cmml"><mi id="S2.SS1.p3.1.m1.3.3.1.1.1.1.2" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.3.3.1.1.1.1.1" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.1.cmml">​</mo><mi id="S2.SS1.p3.1.m1.3.3.1.1.1.1.3" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.3.3.1.1.1.1.1a" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.1.cmml">​</mo><mrow id="S2.SS1.p3.1.m1.3.3.1.1.1.1.4.2" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.1.m1.3.3.1.1.1.1.4.2.1" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.cmml">(</mo><mi id="S2.SS1.p3.1.m1.2.2" xref="S2.SS1.p3.1.m1.2.2.cmml">𝐱</mi><mo stretchy="false" id="S2.SS1.p3.1.m1.3.3.1.1.1.1.4.2.2" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p3.1.m1.4.4.2.2.2.4" xref="S2.SS1.p3.1.m1.4.4.2.2.3.cmml">;</mo><msub id="S2.SS1.p3.1.m1.4.4.2.2.2.2" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.cmml"><mi id="S2.SS1.p3.1.m1.4.4.2.2.2.2.2" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.2.cmml">θ</mi><mrow id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.cmml"><mi id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.2" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.1" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.1.cmml">​</mo><mi id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.3" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.1a" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.1.cmml">​</mo><mi id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.4" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.4.cmml">N</mi></mrow></msub><mo stretchy="false" id="S2.SS1.p3.1.m1.4.4.2.2.2.5" xref="S2.SS1.p3.1.m1.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.4b"><apply id="S2.SS1.p3.1.m1.4.4.cmml" xref="S2.SS1.p3.1.m1.4.4"><eq id="S2.SS1.p3.1.m1.4.4.3.cmml" xref="S2.SS1.p3.1.m1.4.4.3"></eq><apply id="S2.SS1.p3.1.m1.4.4.4.cmml" xref="S2.SS1.p3.1.m1.4.4.4"><times id="S2.SS1.p3.1.m1.4.4.4.1.cmml" xref="S2.SS1.p3.1.m1.4.4.4.1"></times><ci id="S2.SS1.p3.1.m1.4.4.4.2.cmml" xref="S2.SS1.p3.1.m1.4.4.4.2">𝐶</ci><ci id="S2.SS1.p3.1.m1.4.4.4.3.cmml" xref="S2.SS1.p3.1.m1.4.4.4.3">𝑁</ci><ci id="S2.SS1.p3.1.m1.4.4.4.4.cmml" xref="S2.SS1.p3.1.m1.4.4.4.4">𝑁</ci><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">𝐱</ci></apply><apply id="S2.SS1.p3.1.m1.4.4.2.cmml" xref="S2.SS1.p3.1.m1.4.4.2"><times id="S2.SS1.p3.1.m1.4.4.2.3.cmml" xref="S2.SS1.p3.1.m1.4.4.2.3"></times><apply id="S2.SS1.p3.1.m1.4.4.2.4.cmml" xref="S2.SS1.p3.1.m1.4.4.2.4"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.4.4.2.4.1.cmml" xref="S2.SS1.p3.1.m1.4.4.2.4">subscript</csymbol><ci id="S2.SS1.p3.1.m1.4.4.2.4.2.cmml" xref="S2.SS1.p3.1.m1.4.4.2.4.2">𝑓</ci><apply id="S2.SS1.p3.1.m1.4.4.2.4.3.cmml" xref="S2.SS1.p3.1.m1.4.4.2.4.3"><times id="S2.SS1.p3.1.m1.4.4.2.4.3.1.cmml" xref="S2.SS1.p3.1.m1.4.4.2.4.3.1"></times><ci id="S2.SS1.p3.1.m1.4.4.2.4.3.2.cmml" xref="S2.SS1.p3.1.m1.4.4.2.4.3.2">𝐶</ci><ci id="S2.SS1.p3.1.m1.4.4.2.4.3.3.cmml" xref="S2.SS1.p3.1.m1.4.4.2.4.3.3">𝑁</ci><ci id="S2.SS1.p3.1.m1.4.4.2.4.3.4.cmml" xref="S2.SS1.p3.1.m1.4.4.2.4.3.4">𝑁</ci></apply></apply><list id="S2.SS1.p3.1.m1.4.4.2.2.3.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2"><apply id="S2.SS1.p3.1.m1.3.3.1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1"><times id="S2.SS1.p3.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.1"></times><ci id="S2.SS1.p3.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.2">𝐴</ci><ci id="S2.SS1.p3.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.3.3.1.1.1.1.3">𝐸</ci><ci id="S2.SS1.p3.1.m1.2.2.cmml" xref="S2.SS1.p3.1.m1.2.2">𝐱</ci></apply><apply id="S2.SS1.p3.1.m1.4.4.2.2.2.2.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.4.4.2.2.2.2.1.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p3.1.m1.4.4.2.2.2.2.2.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.2">𝜃</ci><apply id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3"><times id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.1.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.1"></times><ci id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.2.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.2">𝐶</ci><ci id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.3.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.3">𝑁</ci><ci id="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.4.cmml" xref="S2.SS1.p3.1.m1.4.4.2.2.2.2.3.4">𝑁</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.4c">CNN(\mathbf{x})=f_{CNN}(AE(\mathbf{x});\theta_{CNN})</annotation></semantics></math>,
where <math id="S2.SS1.p3.2.m2.1" class="ltx_Math" alttext="\theta_{CNN}" display="inline"><semantics id="S2.SS1.p3.2.m2.1a"><msub id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml"><mi id="S2.SS1.p3.2.m2.1.1.2" xref="S2.SS1.p3.2.m2.1.1.2.cmml">θ</mi><mrow id="S2.SS1.p3.2.m2.1.1.3" xref="S2.SS1.p3.2.m2.1.1.3.cmml"><mi id="S2.SS1.p3.2.m2.1.1.3.2" xref="S2.SS1.p3.2.m2.1.1.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.2.m2.1.1.3.1" xref="S2.SS1.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p3.2.m2.1.1.3.3" xref="S2.SS1.p3.2.m2.1.1.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.2.m2.1.1.3.1a" xref="S2.SS1.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p3.2.m2.1.1.3.4" xref="S2.SS1.p3.2.m2.1.1.3.4.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><apply id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.1.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p3.2.m2.1.1.2.cmml" xref="S2.SS1.p3.2.m2.1.1.2">𝜃</ci><apply id="S2.SS1.p3.2.m2.1.1.3.cmml" xref="S2.SS1.p3.2.m2.1.1.3"><times id="S2.SS1.p3.2.m2.1.1.3.1.cmml" xref="S2.SS1.p3.2.m2.1.1.3.1"></times><ci id="S2.SS1.p3.2.m2.1.1.3.2.cmml" xref="S2.SS1.p3.2.m2.1.1.3.2">𝐶</ci><ci id="S2.SS1.p3.2.m2.1.1.3.3.cmml" xref="S2.SS1.p3.2.m2.1.1.3.3">𝑁</ci><ci id="S2.SS1.p3.2.m2.1.1.3.4.cmml" xref="S2.SS1.p3.2.m2.1.1.3.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">\theta_{CNN}</annotation></semantics></math> represents learnable parameters of the 1-D convolution blocks.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.9" class="ltx_p"><span id="S2.SS1.p4.9.1" class="ltx_text ltx_font_bold">Large Language Model:</span>
An LLM typically takes in a sequence of input text tokens <math id="S2.SS1.p4.1.m1.1" class="ltx_Math" alttext="\mathbf{z}" display="inline"><semantics id="S2.SS1.p4.1.m1.1a"><mi id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.1b"><ci id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.1c">\mathbf{z}</annotation></semantics></math>
and models the probability of observing an output text sequence <math id="S2.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mathbf{y}" display="inline"><semantics id="S2.SS1.p4.2.m2.1a"><mi id="S2.SS1.p4.2.m2.1.1" xref="S2.SS1.p4.2.m2.1.1.cmml">𝐲</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.2.m2.1b"><ci id="S2.SS1.p4.2.m2.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1">𝐲</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.2.m2.1c">\mathbf{y}</annotation></semantics></math>
as the possible next tokens for the input text.
The text tokens are converted to vectorized embeddings <math id="S2.SS1.p4.3.m3.1" class="ltx_Math" alttext="EMB(\mathbf{z})" display="inline"><semantics id="S2.SS1.p4.3.m3.1a"><mrow id="S2.SS1.p4.3.m3.1.2" xref="S2.SS1.p4.3.m3.1.2.cmml"><mi id="S2.SS1.p4.3.m3.1.2.2" xref="S2.SS1.p4.3.m3.1.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.3.m3.1.2.1" xref="S2.SS1.p4.3.m3.1.2.1.cmml">​</mo><mi id="S2.SS1.p4.3.m3.1.2.3" xref="S2.SS1.p4.3.m3.1.2.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.3.m3.1.2.1a" xref="S2.SS1.p4.3.m3.1.2.1.cmml">​</mo><mi id="S2.SS1.p4.3.m3.1.2.4" xref="S2.SS1.p4.3.m3.1.2.4.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.3.m3.1.2.1b" xref="S2.SS1.p4.3.m3.1.2.1.cmml">​</mo><mrow id="S2.SS1.p4.3.m3.1.2.5.2" xref="S2.SS1.p4.3.m3.1.2.cmml"><mo stretchy="false" id="S2.SS1.p4.3.m3.1.2.5.2.1" xref="S2.SS1.p4.3.m3.1.2.cmml">(</mo><mi id="S2.SS1.p4.3.m3.1.1" xref="S2.SS1.p4.3.m3.1.1.cmml">𝐳</mi><mo stretchy="false" id="S2.SS1.p4.3.m3.1.2.5.2.2" xref="S2.SS1.p4.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.3.m3.1b"><apply id="S2.SS1.p4.3.m3.1.2.cmml" xref="S2.SS1.p4.3.m3.1.2"><times id="S2.SS1.p4.3.m3.1.2.1.cmml" xref="S2.SS1.p4.3.m3.1.2.1"></times><ci id="S2.SS1.p4.3.m3.1.2.2.cmml" xref="S2.SS1.p4.3.m3.1.2.2">𝐸</ci><ci id="S2.SS1.p4.3.m3.1.2.3.cmml" xref="S2.SS1.p4.3.m3.1.2.3">𝑀</ci><ci id="S2.SS1.p4.3.m3.1.2.4.cmml" xref="S2.SS1.p4.3.m3.1.2.4">𝐵</ci><ci id="S2.SS1.p4.3.m3.1.1.cmml" xref="S2.SS1.p4.3.m3.1.1">𝐳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.3.m3.1c">EMB(\mathbf{z})</annotation></semantics></math>
using a lookup matrix that is learned during training.
The output of the LLM can be represented as
<math id="S2.SS1.p4.4.m4.4" class="ltx_Math" alttext="LLM(\mathbf{z})=f_{LLM}(EMB(\mathbf{z});\theta_{LLM})" display="inline"><semantics id="S2.SS1.p4.4.m4.4a"><mrow id="S2.SS1.p4.4.m4.4.4" xref="S2.SS1.p4.4.m4.4.4.cmml"><mrow id="S2.SS1.p4.4.m4.4.4.4" xref="S2.SS1.p4.4.m4.4.4.4.cmml"><mi id="S2.SS1.p4.4.m4.4.4.4.2" xref="S2.SS1.p4.4.m4.4.4.4.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.4.4.4.1" xref="S2.SS1.p4.4.m4.4.4.4.1.cmml">​</mo><mi id="S2.SS1.p4.4.m4.4.4.4.3" xref="S2.SS1.p4.4.m4.4.4.4.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.4.4.4.1a" xref="S2.SS1.p4.4.m4.4.4.4.1.cmml">​</mo><mi id="S2.SS1.p4.4.m4.4.4.4.4" xref="S2.SS1.p4.4.m4.4.4.4.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.4.4.4.1b" xref="S2.SS1.p4.4.m4.4.4.4.1.cmml">​</mo><mrow id="S2.SS1.p4.4.m4.4.4.4.5.2" xref="S2.SS1.p4.4.m4.4.4.4.cmml"><mo stretchy="false" id="S2.SS1.p4.4.m4.4.4.4.5.2.1" xref="S2.SS1.p4.4.m4.4.4.4.cmml">(</mo><mi id="S2.SS1.p4.4.m4.1.1" xref="S2.SS1.p4.4.m4.1.1.cmml">𝐳</mi><mo stretchy="false" id="S2.SS1.p4.4.m4.4.4.4.5.2.2" xref="S2.SS1.p4.4.m4.4.4.4.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p4.4.m4.4.4.3" xref="S2.SS1.p4.4.m4.4.4.3.cmml">=</mo><mrow id="S2.SS1.p4.4.m4.4.4.2" xref="S2.SS1.p4.4.m4.4.4.2.cmml"><msub id="S2.SS1.p4.4.m4.4.4.2.4" xref="S2.SS1.p4.4.m4.4.4.2.4.cmml"><mi id="S2.SS1.p4.4.m4.4.4.2.4.2" xref="S2.SS1.p4.4.m4.4.4.2.4.2.cmml">f</mi><mrow id="S2.SS1.p4.4.m4.4.4.2.4.3" xref="S2.SS1.p4.4.m4.4.4.2.4.3.cmml"><mi id="S2.SS1.p4.4.m4.4.4.2.4.3.2" xref="S2.SS1.p4.4.m4.4.4.2.4.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.4.4.2.4.3.1" xref="S2.SS1.p4.4.m4.4.4.2.4.3.1.cmml">​</mo><mi id="S2.SS1.p4.4.m4.4.4.2.4.3.3" xref="S2.SS1.p4.4.m4.4.4.2.4.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.4.4.2.4.3.1a" xref="S2.SS1.p4.4.m4.4.4.2.4.3.1.cmml">​</mo><mi id="S2.SS1.p4.4.m4.4.4.2.4.3.4" xref="S2.SS1.p4.4.m4.4.4.2.4.3.4.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.4.4.2.3" xref="S2.SS1.p4.4.m4.4.4.2.3.cmml">​</mo><mrow id="S2.SS1.p4.4.m4.4.4.2.2.2" xref="S2.SS1.p4.4.m4.4.4.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p4.4.m4.4.4.2.2.2.3" xref="S2.SS1.p4.4.m4.4.4.2.2.3.cmml">(</mo><mrow id="S2.SS1.p4.4.m4.3.3.1.1.1.1" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.cmml"><mi id="S2.SS1.p4.4.m4.3.3.1.1.1.1.2" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.3.3.1.1.1.1.1" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.1.cmml">​</mo><mi id="S2.SS1.p4.4.m4.3.3.1.1.1.1.3" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.3.3.1.1.1.1.1a" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.1.cmml">​</mo><mi id="S2.SS1.p4.4.m4.3.3.1.1.1.1.4" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.4.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.3.3.1.1.1.1.1b" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.1.cmml">​</mo><mrow id="S2.SS1.p4.4.m4.3.3.1.1.1.1.5.2" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p4.4.m4.3.3.1.1.1.1.5.2.1" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.cmml">(</mo><mi id="S2.SS1.p4.4.m4.2.2" xref="S2.SS1.p4.4.m4.2.2.cmml">𝐳</mi><mo stretchy="false" id="S2.SS1.p4.4.m4.3.3.1.1.1.1.5.2.2" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p4.4.m4.4.4.2.2.2.4" xref="S2.SS1.p4.4.m4.4.4.2.2.3.cmml">;</mo><msub id="S2.SS1.p4.4.m4.4.4.2.2.2.2" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.cmml"><mi id="S2.SS1.p4.4.m4.4.4.2.2.2.2.2" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.2.cmml">θ</mi><mrow id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.cmml"><mi id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.2" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.1" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.1.cmml">​</mo><mi id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.3" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.1a" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.1.cmml">​</mo><mi id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.4" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.4.cmml">M</mi></mrow></msub><mo stretchy="false" id="S2.SS1.p4.4.m4.4.4.2.2.2.5" xref="S2.SS1.p4.4.m4.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.4.m4.4b"><apply id="S2.SS1.p4.4.m4.4.4.cmml" xref="S2.SS1.p4.4.m4.4.4"><eq id="S2.SS1.p4.4.m4.4.4.3.cmml" xref="S2.SS1.p4.4.m4.4.4.3"></eq><apply id="S2.SS1.p4.4.m4.4.4.4.cmml" xref="S2.SS1.p4.4.m4.4.4.4"><times id="S2.SS1.p4.4.m4.4.4.4.1.cmml" xref="S2.SS1.p4.4.m4.4.4.4.1"></times><ci id="S2.SS1.p4.4.m4.4.4.4.2.cmml" xref="S2.SS1.p4.4.m4.4.4.4.2">𝐿</ci><ci id="S2.SS1.p4.4.m4.4.4.4.3.cmml" xref="S2.SS1.p4.4.m4.4.4.4.3">𝐿</ci><ci id="S2.SS1.p4.4.m4.4.4.4.4.cmml" xref="S2.SS1.p4.4.m4.4.4.4.4">𝑀</ci><ci id="S2.SS1.p4.4.m4.1.1.cmml" xref="S2.SS1.p4.4.m4.1.1">𝐳</ci></apply><apply id="S2.SS1.p4.4.m4.4.4.2.cmml" xref="S2.SS1.p4.4.m4.4.4.2"><times id="S2.SS1.p4.4.m4.4.4.2.3.cmml" xref="S2.SS1.p4.4.m4.4.4.2.3"></times><apply id="S2.SS1.p4.4.m4.4.4.2.4.cmml" xref="S2.SS1.p4.4.m4.4.4.2.4"><csymbol cd="ambiguous" id="S2.SS1.p4.4.m4.4.4.2.4.1.cmml" xref="S2.SS1.p4.4.m4.4.4.2.4">subscript</csymbol><ci id="S2.SS1.p4.4.m4.4.4.2.4.2.cmml" xref="S2.SS1.p4.4.m4.4.4.2.4.2">𝑓</ci><apply id="S2.SS1.p4.4.m4.4.4.2.4.3.cmml" xref="S2.SS1.p4.4.m4.4.4.2.4.3"><times id="S2.SS1.p4.4.m4.4.4.2.4.3.1.cmml" xref="S2.SS1.p4.4.m4.4.4.2.4.3.1"></times><ci id="S2.SS1.p4.4.m4.4.4.2.4.3.2.cmml" xref="S2.SS1.p4.4.m4.4.4.2.4.3.2">𝐿</ci><ci id="S2.SS1.p4.4.m4.4.4.2.4.3.3.cmml" xref="S2.SS1.p4.4.m4.4.4.2.4.3.3">𝐿</ci><ci id="S2.SS1.p4.4.m4.4.4.2.4.3.4.cmml" xref="S2.SS1.p4.4.m4.4.4.2.4.3.4">𝑀</ci></apply></apply><list id="S2.SS1.p4.4.m4.4.4.2.2.3.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2"><apply id="S2.SS1.p4.4.m4.3.3.1.1.1.1.cmml" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1"><times id="S2.SS1.p4.4.m4.3.3.1.1.1.1.1.cmml" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.1"></times><ci id="S2.SS1.p4.4.m4.3.3.1.1.1.1.2.cmml" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.2">𝐸</ci><ci id="S2.SS1.p4.4.m4.3.3.1.1.1.1.3.cmml" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.3">𝑀</ci><ci id="S2.SS1.p4.4.m4.3.3.1.1.1.1.4.cmml" xref="S2.SS1.p4.4.m4.3.3.1.1.1.1.4">𝐵</ci><ci id="S2.SS1.p4.4.m4.2.2.cmml" xref="S2.SS1.p4.4.m4.2.2">𝐳</ci></apply><apply id="S2.SS1.p4.4.m4.4.4.2.2.2.2.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p4.4.m4.4.4.2.2.2.2.1.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p4.4.m4.4.4.2.2.2.2.2.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.2">𝜃</ci><apply id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3"><times id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.1.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.1"></times><ci id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.2.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.2">𝐿</ci><ci id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.3.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.3">𝐿</ci><ci id="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.4.cmml" xref="S2.SS1.p4.4.m4.4.4.2.2.2.2.3.4">𝑀</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.4.m4.4c">LLM(\mathbf{z})=f_{LLM}(EMB(\mathbf{z});\theta_{LLM})</annotation></semantics></math>,
where <math id="S2.SS1.p4.5.m5.1" class="ltx_Math" alttext="\theta_{LLM}" display="inline"><semantics id="S2.SS1.p4.5.m5.1a"><msub id="S2.SS1.p4.5.m5.1.1" xref="S2.SS1.p4.5.m5.1.1.cmml"><mi id="S2.SS1.p4.5.m5.1.1.2" xref="S2.SS1.p4.5.m5.1.1.2.cmml">θ</mi><mrow id="S2.SS1.p4.5.m5.1.1.3" xref="S2.SS1.p4.5.m5.1.1.3.cmml"><mi id="S2.SS1.p4.5.m5.1.1.3.2" xref="S2.SS1.p4.5.m5.1.1.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.5.m5.1.1.3.1" xref="S2.SS1.p4.5.m5.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p4.5.m5.1.1.3.3" xref="S2.SS1.p4.5.m5.1.1.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.5.m5.1.1.3.1a" xref="S2.SS1.p4.5.m5.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p4.5.m5.1.1.3.4" xref="S2.SS1.p4.5.m5.1.1.3.4.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.5.m5.1b"><apply id="S2.SS1.p4.5.m5.1.1.cmml" xref="S2.SS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.5.m5.1.1.1.cmml" xref="S2.SS1.p4.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p4.5.m5.1.1.2.cmml" xref="S2.SS1.p4.5.m5.1.1.2">𝜃</ci><apply id="S2.SS1.p4.5.m5.1.1.3.cmml" xref="S2.SS1.p4.5.m5.1.1.3"><times id="S2.SS1.p4.5.m5.1.1.3.1.cmml" xref="S2.SS1.p4.5.m5.1.1.3.1"></times><ci id="S2.SS1.p4.5.m5.1.1.3.2.cmml" xref="S2.SS1.p4.5.m5.1.1.3.2">𝐿</ci><ci id="S2.SS1.p4.5.m5.1.1.3.3.cmml" xref="S2.SS1.p4.5.m5.1.1.3.3">𝐿</ci><ci id="S2.SS1.p4.5.m5.1.1.3.4.cmml" xref="S2.SS1.p4.5.m5.1.1.3.4">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.5.m5.1c">\theta_{LLM}</annotation></semantics></math> are the weights of the LLM.
In this work, we leverage a pre-trained LLM for multimodal tasks.
For formulating the multimodal input with audio <math id="S2.SS1.p4.6.m6.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S2.SS1.p4.6.m6.1a"><mi id="S2.SS1.p4.6.m6.1.1" xref="S2.SS1.p4.6.m6.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.6.m6.1b"><ci id="S2.SS1.p4.6.m6.1.1.cmml" xref="S2.SS1.p4.6.m6.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.6.m6.1c">\mathbf{x}</annotation></semantics></math> and text sequence <math id="S2.SS1.p4.7.m7.1" class="ltx_Math" alttext="\mathbf{z}" display="inline"><semantics id="S2.SS1.p4.7.m7.1a"><mi id="S2.SS1.p4.7.m7.1.1" xref="S2.SS1.p4.7.m7.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.7.m7.1b"><ci id="S2.SS1.p4.7.m7.1.1.cmml" xref="S2.SS1.p4.7.m7.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.7.m7.1c">\mathbf{z}</annotation></semantics></math>, we simply concatenate
the downsampled audio features (<math id="S2.SS1.p4.8.m8.1" class="ltx_Math" alttext="CNN(\mathbf{x})" display="inline"><semantics id="S2.SS1.p4.8.m8.1a"><mrow id="S2.SS1.p4.8.m8.1.2" xref="S2.SS1.p4.8.m8.1.2.cmml"><mi id="S2.SS1.p4.8.m8.1.2.2" xref="S2.SS1.p4.8.m8.1.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.8.m8.1.2.1" xref="S2.SS1.p4.8.m8.1.2.1.cmml">​</mo><mi id="S2.SS1.p4.8.m8.1.2.3" xref="S2.SS1.p4.8.m8.1.2.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.8.m8.1.2.1a" xref="S2.SS1.p4.8.m8.1.2.1.cmml">​</mo><mi id="S2.SS1.p4.8.m8.1.2.4" xref="S2.SS1.p4.8.m8.1.2.4.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.8.m8.1.2.1b" xref="S2.SS1.p4.8.m8.1.2.1.cmml">​</mo><mrow id="S2.SS1.p4.8.m8.1.2.5.2" xref="S2.SS1.p4.8.m8.1.2.cmml"><mo stretchy="false" id="S2.SS1.p4.8.m8.1.2.5.2.1" xref="S2.SS1.p4.8.m8.1.2.cmml">(</mo><mi id="S2.SS1.p4.8.m8.1.1" xref="S2.SS1.p4.8.m8.1.1.cmml">𝐱</mi><mo stretchy="false" id="S2.SS1.p4.8.m8.1.2.5.2.2" xref="S2.SS1.p4.8.m8.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.8.m8.1b"><apply id="S2.SS1.p4.8.m8.1.2.cmml" xref="S2.SS1.p4.8.m8.1.2"><times id="S2.SS1.p4.8.m8.1.2.1.cmml" xref="S2.SS1.p4.8.m8.1.2.1"></times><ci id="S2.SS1.p4.8.m8.1.2.2.cmml" xref="S2.SS1.p4.8.m8.1.2.2">𝐶</ci><ci id="S2.SS1.p4.8.m8.1.2.3.cmml" xref="S2.SS1.p4.8.m8.1.2.3">𝑁</ci><ci id="S2.SS1.p4.8.m8.1.2.4.cmml" xref="S2.SS1.p4.8.m8.1.2.4">𝑁</ci><ci id="S2.SS1.p4.8.m8.1.1.cmml" xref="S2.SS1.p4.8.m8.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.8.m8.1c">CNN(\mathbf{x})</annotation></semantics></math>) with the token embeddings (<math id="S2.SS1.p4.9.m9.1" class="ltx_math_unparsed" alttext="(EMB(\mathbf{z})" display="inline"><semantics id="S2.SS1.p4.9.m9.1a"><mrow id="S2.SS1.p4.9.m9.1b"><mo stretchy="false" id="S2.SS1.p4.9.m9.1.2">(</mo><mi id="S2.SS1.p4.9.m9.1.3">E</mi><mi id="S2.SS1.p4.9.m9.1.4">M</mi><mi id="S2.SS1.p4.9.m9.1.5">B</mi><mrow id="S2.SS1.p4.9.m9.1.6"><mo stretchy="false" id="S2.SS1.p4.9.m9.1.6.1">(</mo><mi id="S2.SS1.p4.9.m9.1.1">𝐳</mi><mo stretchy="false" id="S2.SS1.p4.9.m9.1.6.2">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.SS1.p4.9.m9.1c">(EMB(\mathbf{z})</annotation></semantics></math>)
in the sequence dimension as shown in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1 Architecture ‣ 2 Approach ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Hence, we can represent the probability distribution over the output from our multi-modal Spoken Language Model (SLM) as:</p>
<table id="A1.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E2.m1.6" class="ltx_Math" alttext="\displaystyle SLM(\mathbf{x},\mathbf{z})=f_{LLM}\Big{(}\big{[}CNN(\mathbf{x}),EMB(\mathbf{z})\big{]};\theta_{LLM}\Big{)}" display="inline"><semantics id="S2.E2.m1.6a"><mrow id="S2.E2.m1.6.6" xref="S2.E2.m1.6.6.cmml"><mrow id="S2.E2.m1.6.6.4" xref="S2.E2.m1.6.6.4.cmml"><mi id="S2.E2.m1.6.6.4.2" xref="S2.E2.m1.6.6.4.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.4.1" xref="S2.E2.m1.6.6.4.1.cmml">​</mo><mi id="S2.E2.m1.6.6.4.3" xref="S2.E2.m1.6.6.4.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.4.1a" xref="S2.E2.m1.6.6.4.1.cmml">​</mo><mi id="S2.E2.m1.6.6.4.4" xref="S2.E2.m1.6.6.4.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.4.1b" xref="S2.E2.m1.6.6.4.1.cmml">​</mo><mrow id="S2.E2.m1.6.6.4.5.2" xref="S2.E2.m1.6.6.4.5.1.cmml"><mo stretchy="false" id="S2.E2.m1.6.6.4.5.2.1" xref="S2.E2.m1.6.6.4.5.1.cmml">(</mo><mi id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">𝐱</mi><mo id="S2.E2.m1.6.6.4.5.2.2" xref="S2.E2.m1.6.6.4.5.1.cmml">,</mo><mi id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">𝐳</mi><mo stretchy="false" id="S2.E2.m1.6.6.4.5.2.3" xref="S2.E2.m1.6.6.4.5.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.6.6.3" xref="S2.E2.m1.6.6.3.cmml">=</mo><mrow id="S2.E2.m1.6.6.2" xref="S2.E2.m1.6.6.2.cmml"><msub id="S2.E2.m1.6.6.2.4" xref="S2.E2.m1.6.6.2.4.cmml"><mi id="S2.E2.m1.6.6.2.4.2" xref="S2.E2.m1.6.6.2.4.2.cmml">f</mi><mrow id="S2.E2.m1.6.6.2.4.3" xref="S2.E2.m1.6.6.2.4.3.cmml"><mi id="S2.E2.m1.6.6.2.4.3.2" xref="S2.E2.m1.6.6.2.4.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.2.4.3.1" xref="S2.E2.m1.6.6.2.4.3.1.cmml">​</mo><mi id="S2.E2.m1.6.6.2.4.3.3" xref="S2.E2.m1.6.6.2.4.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.2.4.3.1a" xref="S2.E2.m1.6.6.2.4.3.1.cmml">​</mo><mi id="S2.E2.m1.6.6.2.4.3.4" xref="S2.E2.m1.6.6.2.4.3.4.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.2.3" xref="S2.E2.m1.6.6.2.3.cmml">​</mo><mrow id="S2.E2.m1.6.6.2.2.2" xref="S2.E2.m1.6.6.2.2.3.cmml"><mo maxsize="160%" minsize="160%" id="S2.E2.m1.6.6.2.2.2.3" xref="S2.E2.m1.6.6.2.2.3.cmml">(</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.3.cmml"><mo maxsize="120%" minsize="120%" id="S2.E2.m1.5.5.1.1.1.1.2.3" xref="S2.E2.m1.5.5.1.1.1.1.3.cmml">[</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.5.5.1.1.1.1.1.1.2" xref="S2.E2.m1.5.5.1.1.1.1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.1.1.1" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.cmml">​</mo><mi id="S2.E2.m1.5.5.1.1.1.1.1.1.3" xref="S2.E2.m1.5.5.1.1.1.1.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.1.1.1a" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.cmml">​</mo><mi id="S2.E2.m1.5.5.1.1.1.1.1.1.4" xref="S2.E2.m1.5.5.1.1.1.1.1.1.4.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.1.1.1b" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.1.1.5.2" xref="S2.E2.m1.5.5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.1.1.5.2.1" xref="S2.E2.m1.5.5.1.1.1.1.1.1.cmml">(</mo><mi id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">𝐱</mi><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.1.1.5.2.2" xref="S2.E2.m1.5.5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.5.5.1.1.1.1.2.4" xref="S2.E2.m1.5.5.1.1.1.1.3.cmml">,</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.2.2" xref="S2.E2.m1.5.5.1.1.1.1.2.2.cmml"><mi id="S2.E2.m1.5.5.1.1.1.1.2.2.2" xref="S2.E2.m1.5.5.1.1.1.1.2.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.2.2.1" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.cmml">​</mo><mi id="S2.E2.m1.5.5.1.1.1.1.2.2.3" xref="S2.E2.m1.5.5.1.1.1.1.2.2.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.2.2.1a" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.cmml">​</mo><mi id="S2.E2.m1.5.5.1.1.1.1.2.2.4" xref="S2.E2.m1.5.5.1.1.1.1.2.2.4.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.5.5.1.1.1.1.2.2.1b" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1.cmml">​</mo><mrow id="S2.E2.m1.5.5.1.1.1.1.2.2.5.2" xref="S2.E2.m1.5.5.1.1.1.1.2.2.cmml"><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.2.2.5.2.1" xref="S2.E2.m1.5.5.1.1.1.1.2.2.cmml">(</mo><mi id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml">𝐳</mi><mo stretchy="false" id="S2.E2.m1.5.5.1.1.1.1.2.2.5.2.2" xref="S2.E2.m1.5.5.1.1.1.1.2.2.cmml">)</mo></mrow></mrow><mo maxsize="120%" minsize="120%" id="S2.E2.m1.5.5.1.1.1.1.2.5" xref="S2.E2.m1.5.5.1.1.1.1.3.cmml">]</mo></mrow><mo id="S2.E2.m1.6.6.2.2.2.4" xref="S2.E2.m1.6.6.2.2.3.cmml">;</mo><msub id="S2.E2.m1.6.6.2.2.2.2" xref="S2.E2.m1.6.6.2.2.2.2.cmml"><mi id="S2.E2.m1.6.6.2.2.2.2.2" xref="S2.E2.m1.6.6.2.2.2.2.2.cmml">θ</mi><mrow id="S2.E2.m1.6.6.2.2.2.2.3" xref="S2.E2.m1.6.6.2.2.2.2.3.cmml"><mi id="S2.E2.m1.6.6.2.2.2.2.3.2" xref="S2.E2.m1.6.6.2.2.2.2.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.2.2.2.2.3.1" xref="S2.E2.m1.6.6.2.2.2.2.3.1.cmml">​</mo><mi id="S2.E2.m1.6.6.2.2.2.2.3.3" xref="S2.E2.m1.6.6.2.2.2.2.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.2.2.2.2.3.1a" xref="S2.E2.m1.6.6.2.2.2.2.3.1.cmml">​</mo><mi id="S2.E2.m1.6.6.2.2.2.2.3.4" xref="S2.E2.m1.6.6.2.2.2.2.3.4.cmml">M</mi></mrow></msub><mo maxsize="160%" minsize="160%" id="S2.E2.m1.6.6.2.2.2.5" xref="S2.E2.m1.6.6.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.6b"><apply id="S2.E2.m1.6.6.cmml" xref="S2.E2.m1.6.6"><eq id="S2.E2.m1.6.6.3.cmml" xref="S2.E2.m1.6.6.3"></eq><apply id="S2.E2.m1.6.6.4.cmml" xref="S2.E2.m1.6.6.4"><times id="S2.E2.m1.6.6.4.1.cmml" xref="S2.E2.m1.6.6.4.1"></times><ci id="S2.E2.m1.6.6.4.2.cmml" xref="S2.E2.m1.6.6.4.2">𝑆</ci><ci id="S2.E2.m1.6.6.4.3.cmml" xref="S2.E2.m1.6.6.4.3">𝐿</ci><ci id="S2.E2.m1.6.6.4.4.cmml" xref="S2.E2.m1.6.6.4.4">𝑀</ci><interval closure="open" id="S2.E2.m1.6.6.4.5.1.cmml" xref="S2.E2.m1.6.6.4.5.2"><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">𝐱</ci><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">𝐳</ci></interval></apply><apply id="S2.E2.m1.6.6.2.cmml" xref="S2.E2.m1.6.6.2"><times id="S2.E2.m1.6.6.2.3.cmml" xref="S2.E2.m1.6.6.2.3"></times><apply id="S2.E2.m1.6.6.2.4.cmml" xref="S2.E2.m1.6.6.2.4"><csymbol cd="ambiguous" id="S2.E2.m1.6.6.2.4.1.cmml" xref="S2.E2.m1.6.6.2.4">subscript</csymbol><ci id="S2.E2.m1.6.6.2.4.2.cmml" xref="S2.E2.m1.6.6.2.4.2">𝑓</ci><apply id="S2.E2.m1.6.6.2.4.3.cmml" xref="S2.E2.m1.6.6.2.4.3"><times id="S2.E2.m1.6.6.2.4.3.1.cmml" xref="S2.E2.m1.6.6.2.4.3.1"></times><ci id="S2.E2.m1.6.6.2.4.3.2.cmml" xref="S2.E2.m1.6.6.2.4.3.2">𝐿</ci><ci id="S2.E2.m1.6.6.2.4.3.3.cmml" xref="S2.E2.m1.6.6.2.4.3.3">𝐿</ci><ci id="S2.E2.m1.6.6.2.4.3.4.cmml" xref="S2.E2.m1.6.6.2.4.3.4">𝑀</ci></apply></apply><list id="S2.E2.m1.6.6.2.2.3.cmml" xref="S2.E2.m1.6.6.2.2.2"><interval closure="closed" id="S2.E2.m1.5.5.1.1.1.1.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2"><apply id="S2.E2.m1.5.5.1.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1"><times id="S2.E2.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.1"></times><ci id="S2.E2.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.2">𝐶</ci><ci id="S2.E2.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.3">𝑁</ci><ci id="S2.E2.m1.5.5.1.1.1.1.1.1.4.cmml" xref="S2.E2.m1.5.5.1.1.1.1.1.1.4">𝑁</ci><ci id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">𝐱</ci></apply><apply id="S2.E2.m1.5.5.1.1.1.1.2.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2"><times id="S2.E2.m1.5.5.1.1.1.1.2.2.1.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.1"></times><ci id="S2.E2.m1.5.5.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.2">𝐸</ci><ci id="S2.E2.m1.5.5.1.1.1.1.2.2.3.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.3">𝑀</ci><ci id="S2.E2.m1.5.5.1.1.1.1.2.2.4.cmml" xref="S2.E2.m1.5.5.1.1.1.1.2.2.4">𝐵</ci><ci id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4">𝐳</ci></apply></interval><apply id="S2.E2.m1.6.6.2.2.2.2.cmml" xref="S2.E2.m1.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.6.6.2.2.2.2.1.cmml" xref="S2.E2.m1.6.6.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.6.6.2.2.2.2.2.cmml" xref="S2.E2.m1.6.6.2.2.2.2.2">𝜃</ci><apply id="S2.E2.m1.6.6.2.2.2.2.3.cmml" xref="S2.E2.m1.6.6.2.2.2.2.3"><times id="S2.E2.m1.6.6.2.2.2.2.3.1.cmml" xref="S2.E2.m1.6.6.2.2.2.2.3.1"></times><ci id="S2.E2.m1.6.6.2.2.2.2.3.2.cmml" xref="S2.E2.m1.6.6.2.2.2.2.3.2">𝐿</ci><ci id="S2.E2.m1.6.6.2.2.2.2.3.3.cmml" xref="S2.E2.m1.6.6.2.2.2.2.3.3">𝐿</ci><ci id="S2.E2.m1.6.6.2.2.2.2.3.4.cmml" xref="S2.E2.m1.6.6.2.2.2.2.3.4">𝑀</ci></apply></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.6c">\displaystyle SLM(\mathbf{x},\mathbf{z})=f_{LLM}\Big{(}\big{[}CNN(\mathbf{x}),EMB(\mathbf{z})\big{]};\theta_{LLM}\Big{)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Multimodal Instruction Finetuning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.18" class="ltx_p">Let <math id="S2.SS2.p1.1.m1.2" class="ltx_Math" alttext="\mathcal{D}^{\tau}=\{\mathbf{x}^{\tau},\mathbf{y}^{\tau}\}_{1}^{n^{\tau}}" display="inline"><semantics id="S2.SS2.p1.1.m1.2a"><mrow id="S2.SS2.p1.1.m1.2.2" xref="S2.SS2.p1.1.m1.2.2.cmml"><msup id="S2.SS2.p1.1.m1.2.2.4" xref="S2.SS2.p1.1.m1.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.1.m1.2.2.4.2" xref="S2.SS2.p1.1.m1.2.2.4.2.cmml">𝒟</mi><mi id="S2.SS2.p1.1.m1.2.2.4.3" xref="S2.SS2.p1.1.m1.2.2.4.3.cmml">τ</mi></msup><mo id="S2.SS2.p1.1.m1.2.2.3" xref="S2.SS2.p1.1.m1.2.2.3.cmml">=</mo><msubsup id="S2.SS2.p1.1.m1.2.2.2" xref="S2.SS2.p1.1.m1.2.2.2.cmml"><mrow id="S2.SS2.p1.1.m1.2.2.2.2.2.2" xref="S2.SS2.p1.1.m1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS2.p1.1.m1.2.2.2.2.2.2.3" xref="S2.SS2.p1.1.m1.2.2.2.2.2.3.cmml">{</mo><msup id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml">τ</mi></msup><mo id="S2.SS2.p1.1.m1.2.2.2.2.2.2.4" xref="S2.SS2.p1.1.m1.2.2.2.2.2.3.cmml">,</mo><msup id="S2.SS2.p1.1.m1.2.2.2.2.2.2.2" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.cmml"><mi id="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.2" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.2.cmml">𝐲</mi><mi id="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.3" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.3.cmml">τ</mi></msup><mo stretchy="false" id="S2.SS2.p1.1.m1.2.2.2.2.2.2.5" xref="S2.SS2.p1.1.m1.2.2.2.2.2.3.cmml">}</mo></mrow><mn id="S2.SS2.p1.1.m1.2.2.2.2.4" xref="S2.SS2.p1.1.m1.2.2.2.2.4.cmml">1</mn><msup id="S2.SS2.p1.1.m1.2.2.2.4" xref="S2.SS2.p1.1.m1.2.2.2.4.cmml"><mi id="S2.SS2.p1.1.m1.2.2.2.4.2" xref="S2.SS2.p1.1.m1.2.2.2.4.2.cmml">n</mi><mi id="S2.SS2.p1.1.m1.2.2.2.4.3" xref="S2.SS2.p1.1.m1.2.2.2.4.3.cmml">τ</mi></msup></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.2b"><apply id="S2.SS2.p1.1.m1.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2"><eq id="S2.SS2.p1.1.m1.2.2.3.cmml" xref="S2.SS2.p1.1.m1.2.2.3"></eq><apply id="S2.SS2.p1.1.m1.2.2.4.cmml" xref="S2.SS2.p1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.2.2.4.1.cmml" xref="S2.SS2.p1.1.m1.2.2.4">superscript</csymbol><ci id="S2.SS2.p1.1.m1.2.2.4.2.cmml" xref="S2.SS2.p1.1.m1.2.2.4.2">𝒟</ci><ci id="S2.SS2.p1.1.m1.2.2.4.3.cmml" xref="S2.SS2.p1.1.m1.2.2.4.3">𝜏</ci></apply><apply id="S2.SS2.p1.1.m1.2.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.2.2.2.3.cmml" xref="S2.SS2.p1.1.m1.2.2.2">superscript</csymbol><apply id="S2.SS2.p1.1.m1.2.2.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="S2.SS2.p1.1.m1.2.2.2">subscript</csymbol><set id="S2.SS2.p1.1.m1.2.2.2.2.2.3.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2"><apply id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.3">𝜏</ci></apply><apply id="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.1.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2.2">superscript</csymbol><ci id="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.2">𝐲</ci><ci id="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.3.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.2.2.2.3">𝜏</ci></apply></set><cn type="integer" id="S2.SS2.p1.1.m1.2.2.2.2.4.cmml" xref="S2.SS2.p1.1.m1.2.2.2.2.4">1</cn></apply><apply id="S2.SS2.p1.1.m1.2.2.2.4.cmml" xref="S2.SS2.p1.1.m1.2.2.2.4"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.2.2.2.4.1.cmml" xref="S2.SS2.p1.1.m1.2.2.2.4">superscript</csymbol><ci id="S2.SS2.p1.1.m1.2.2.2.4.2.cmml" xref="S2.SS2.p1.1.m1.2.2.2.4.2">𝑛</ci><ci id="S2.SS2.p1.1.m1.2.2.2.4.3.cmml" xref="S2.SS2.p1.1.m1.2.2.2.4.3">𝜏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.2c">\mathcal{D}^{\tau}=\{\mathbf{x}^{\tau},\mathbf{y}^{\tau}\}_{1}^{n^{\tau}}</annotation></semantics></math> represent a labelled dataset for a task <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mi id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\tau</annotation></semantics></math> with <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="n^{\tau}" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><msup id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">n</mi><mi id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">superscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">𝑛</ci><ci id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">n^{\tau}</annotation></semantics></math> samples where each sample consists of audio sequence <math id="S2.SS2.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{x}^{\tau}" display="inline"><semantics id="S2.SS2.p1.4.m4.1a"><msup id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">superscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">𝐱</ci><ci id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">\mathbf{x}^{\tau}</annotation></semantics></math> and a corresponding text label sequence <math id="S2.SS2.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{y}^{\tau}" display="inline"><semantics id="S2.SS2.p1.5.m5.1a"><msup id="S2.SS2.p1.5.m5.1.1" xref="S2.SS2.p1.5.m5.1.1.cmml"><mi id="S2.SS2.p1.5.m5.1.1.2" xref="S2.SS2.p1.5.m5.1.1.2.cmml">𝐲</mi><mi id="S2.SS2.p1.5.m5.1.1.3" xref="S2.SS2.p1.5.m5.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.5.m5.1b"><apply id="S2.SS2.p1.5.m5.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.5.m5.1.1.1.cmml" xref="S2.SS2.p1.5.m5.1.1">superscript</csymbol><ci id="S2.SS2.p1.5.m5.1.1.2.cmml" xref="S2.SS2.p1.5.m5.1.1.2">𝐲</ci><ci id="S2.SS2.p1.5.m5.1.1.3.cmml" xref="S2.SS2.p1.5.m5.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.5.m5.1c">\mathbf{y}^{\tau}</annotation></semantics></math>.
Let <math id="S2.SS2.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{P}^{\tau}=\{\mathbf{p}^{\tau}\}_{1}^{m^{\tau}}" display="inline"><semantics id="S2.SS2.p1.6.m6.1a"><mrow id="S2.SS2.p1.6.m6.1.1" xref="S2.SS2.p1.6.m6.1.1.cmml"><msup id="S2.SS2.p1.6.m6.1.1.3" xref="S2.SS2.p1.6.m6.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.6.m6.1.1.3.2" xref="S2.SS2.p1.6.m6.1.1.3.2.cmml">𝒫</mi><mi id="S2.SS2.p1.6.m6.1.1.3.3" xref="S2.SS2.p1.6.m6.1.1.3.3.cmml">τ</mi></msup><mo id="S2.SS2.p1.6.m6.1.1.2" xref="S2.SS2.p1.6.m6.1.1.2.cmml">=</mo><msubsup id="S2.SS2.p1.6.m6.1.1.1" xref="S2.SS2.p1.6.m6.1.1.1.cmml"><mrow id="S2.SS2.p1.6.m6.1.1.1.1.1.1" xref="S2.SS2.p1.6.m6.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.SS2.p1.6.m6.1.1.1.1.1.1.2" xref="S2.SS2.p1.6.m6.1.1.1.1.1.2.cmml">{</mo><msup id="S2.SS2.p1.6.m6.1.1.1.1.1.1.1" xref="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.2" xref="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.2.cmml">𝐩</mi><mi id="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.3" xref="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.3.cmml">τ</mi></msup><mo stretchy="false" id="S2.SS2.p1.6.m6.1.1.1.1.1.1.3" xref="S2.SS2.p1.6.m6.1.1.1.1.1.2.cmml">}</mo></mrow><mn id="S2.SS2.p1.6.m6.1.1.1.1.3" xref="S2.SS2.p1.6.m6.1.1.1.1.3.cmml">1</mn><msup id="S2.SS2.p1.6.m6.1.1.1.3" xref="S2.SS2.p1.6.m6.1.1.1.3.cmml"><mi id="S2.SS2.p1.6.m6.1.1.1.3.2" xref="S2.SS2.p1.6.m6.1.1.1.3.2.cmml">m</mi><mi id="S2.SS2.p1.6.m6.1.1.1.3.3" xref="S2.SS2.p1.6.m6.1.1.1.3.3.cmml">τ</mi></msup></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.6.m6.1b"><apply id="S2.SS2.p1.6.m6.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1"><eq id="S2.SS2.p1.6.m6.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.2"></eq><apply id="S2.SS2.p1.6.m6.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.3.1.cmml" xref="S2.SS2.p1.6.m6.1.1.3">superscript</csymbol><ci id="S2.SS2.p1.6.m6.1.1.3.2.cmml" xref="S2.SS2.p1.6.m6.1.1.3.2">𝒫</ci><ci id="S2.SS2.p1.6.m6.1.1.3.3.cmml" xref="S2.SS2.p1.6.m6.1.1.3.3">𝜏</ci></apply><apply id="S2.SS2.p1.6.m6.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.1">superscript</csymbol><apply id="S2.SS2.p1.6.m6.1.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.1">subscript</csymbol><set id="S2.SS2.p1.6.m6.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.1.1.1.1"><apply id="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.6.m6.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.2">𝐩</ci><ci id="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.1.1.1.1.1.3">𝜏</ci></apply></set><cn type="integer" id="S2.SS2.p1.6.m6.1.1.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.1.1.3">1</cn></apply><apply id="S2.SS2.p1.6.m6.1.1.1.3.cmml" xref="S2.SS2.p1.6.m6.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.6.m6.1.1.1.3.1.cmml" xref="S2.SS2.p1.6.m6.1.1.1.3">superscript</csymbol><ci id="S2.SS2.p1.6.m6.1.1.1.3.2.cmml" xref="S2.SS2.p1.6.m6.1.1.1.3.2">𝑚</ci><ci id="S2.SS2.p1.6.m6.1.1.1.3.3.cmml" xref="S2.SS2.p1.6.m6.1.1.1.3.3">𝜏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.6.m6.1c">\mathcal{P}^{\tau}=\{\mathbf{p}^{\tau}\}_{1}^{m^{\tau}}</annotation></semantics></math> be a set of <math id="S2.SS2.p1.7.m7.1" class="ltx_Math" alttext="m^{\tau}" display="inline"><semantics id="S2.SS2.p1.7.m7.1a"><msup id="S2.SS2.p1.7.m7.1.1" xref="S2.SS2.p1.7.m7.1.1.cmml"><mi id="S2.SS2.p1.7.m7.1.1.2" xref="S2.SS2.p1.7.m7.1.1.2.cmml">m</mi><mi id="S2.SS2.p1.7.m7.1.1.3" xref="S2.SS2.p1.7.m7.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.7.m7.1b"><apply id="S2.SS2.p1.7.m7.1.1.cmml" xref="S2.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.7.m7.1.1.1.cmml" xref="S2.SS2.p1.7.m7.1.1">superscript</csymbol><ci id="S2.SS2.p1.7.m7.1.1.2.cmml" xref="S2.SS2.p1.7.m7.1.1.2">𝑚</ci><ci id="S2.SS2.p1.7.m7.1.1.3.cmml" xref="S2.SS2.p1.7.m7.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.7.m7.1c">m^{\tau}</annotation></semantics></math> textual prompts/instructions sequences <math id="S2.SS2.p1.8.m8.1" class="ltx_Math" alttext="\mathbf{p}^{\tau}" display="inline"><semantics id="S2.SS2.p1.8.m8.1a"><msup id="S2.SS2.p1.8.m8.1.1" xref="S2.SS2.p1.8.m8.1.1.cmml"><mi id="S2.SS2.p1.8.m8.1.1.2" xref="S2.SS2.p1.8.m8.1.1.2.cmml">𝐩</mi><mi id="S2.SS2.p1.8.m8.1.1.3" xref="S2.SS2.p1.8.m8.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.8.m8.1b"><apply id="S2.SS2.p1.8.m8.1.1.cmml" xref="S2.SS2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.8.m8.1.1.1.cmml" xref="S2.SS2.p1.8.m8.1.1">superscript</csymbol><ci id="S2.SS2.p1.8.m8.1.1.2.cmml" xref="S2.SS2.p1.8.m8.1.1.2">𝐩</ci><ci id="S2.SS2.p1.8.m8.1.1.3.cmml" xref="S2.SS2.p1.8.m8.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.8.m8.1c">\mathbf{p}^{\tau}</annotation></semantics></math> describing the task.
In our experiments, we do a weighted combination of datasets from each of the <math id="S2.SS2.p1.9.m9.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS2.p1.9.m9.1a"><mi id="S2.SS2.p1.9.m9.1.1" xref="S2.SS2.p1.9.m9.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.9.m9.1b"><ci id="S2.SS2.p1.9.m9.1.1.cmml" xref="S2.SS2.p1.9.m9.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.9.m9.1c">M</annotation></semantics></math> training tasks <math id="S2.SS2.p1.10.m10.2" class="ltx_Math" alttext="\{w^{\tau},\mathcal{D}^{\tau}\}_{1}^{M}" display="inline"><semantics id="S2.SS2.p1.10.m10.2a"><msubsup id="S2.SS2.p1.10.m10.2.2" xref="S2.SS2.p1.10.m10.2.2.cmml"><mrow id="S2.SS2.p1.10.m10.2.2.2.2.2" xref="S2.SS2.p1.10.m10.2.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS2.p1.10.m10.2.2.2.2.2.3" xref="S2.SS2.p1.10.m10.2.2.2.2.3.cmml">{</mo><msup id="S2.SS2.p1.10.m10.1.1.1.1.1.1" xref="S2.SS2.p1.10.m10.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.10.m10.1.1.1.1.1.1.2" xref="S2.SS2.p1.10.m10.1.1.1.1.1.1.2.cmml">w</mi><mi id="S2.SS2.p1.10.m10.1.1.1.1.1.1.3" xref="S2.SS2.p1.10.m10.1.1.1.1.1.1.3.cmml">τ</mi></msup><mo id="S2.SS2.p1.10.m10.2.2.2.2.2.4" xref="S2.SS2.p1.10.m10.2.2.2.2.3.cmml">,</mo><msup id="S2.SS2.p1.10.m10.2.2.2.2.2.2" xref="S2.SS2.p1.10.m10.2.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.10.m10.2.2.2.2.2.2.2" xref="S2.SS2.p1.10.m10.2.2.2.2.2.2.2.cmml">𝒟</mi><mi id="S2.SS2.p1.10.m10.2.2.2.2.2.2.3" xref="S2.SS2.p1.10.m10.2.2.2.2.2.2.3.cmml">τ</mi></msup><mo stretchy="false" id="S2.SS2.p1.10.m10.2.2.2.2.2.5" xref="S2.SS2.p1.10.m10.2.2.2.2.3.cmml">}</mo></mrow><mn id="S2.SS2.p1.10.m10.2.2.2.4" xref="S2.SS2.p1.10.m10.2.2.2.4.cmml">1</mn><mi id="S2.SS2.p1.10.m10.2.2.4" xref="S2.SS2.p1.10.m10.2.2.4.cmml">M</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.10.m10.2b"><apply id="S2.SS2.p1.10.m10.2.2.cmml" xref="S2.SS2.p1.10.m10.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.10.m10.2.2.3.cmml" xref="S2.SS2.p1.10.m10.2.2">superscript</csymbol><apply id="S2.SS2.p1.10.m10.2.2.2.cmml" xref="S2.SS2.p1.10.m10.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.10.m10.2.2.2.3.cmml" xref="S2.SS2.p1.10.m10.2.2">subscript</csymbol><set id="S2.SS2.p1.10.m10.2.2.2.2.3.cmml" xref="S2.SS2.p1.10.m10.2.2.2.2.2"><apply id="S2.SS2.p1.10.m10.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.10.m10.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.10.m10.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.10.m10.1.1.1.1.1.1">superscript</csymbol><ci id="S2.SS2.p1.10.m10.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.10.m10.1.1.1.1.1.1.2">𝑤</ci><ci id="S2.SS2.p1.10.m10.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.10.m10.1.1.1.1.1.1.3">𝜏</ci></apply><apply id="S2.SS2.p1.10.m10.2.2.2.2.2.2.cmml" xref="S2.SS2.p1.10.m10.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.10.m10.2.2.2.2.2.2.1.cmml" xref="S2.SS2.p1.10.m10.2.2.2.2.2.2">superscript</csymbol><ci id="S2.SS2.p1.10.m10.2.2.2.2.2.2.2.cmml" xref="S2.SS2.p1.10.m10.2.2.2.2.2.2.2">𝒟</ci><ci id="S2.SS2.p1.10.m10.2.2.2.2.2.2.3.cmml" xref="S2.SS2.p1.10.m10.2.2.2.2.2.2.3">𝜏</ci></apply></set><cn type="integer" id="S2.SS2.p1.10.m10.2.2.2.4.cmml" xref="S2.SS2.p1.10.m10.2.2.2.4">1</cn></apply><ci id="S2.SS2.p1.10.m10.2.2.4.cmml" xref="S2.SS2.p1.10.m10.2.2.4">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.10.m10.2c">\{w^{\tau},\mathcal{D}^{\tau}\}_{1}^{M}</annotation></semantics></math> where <math id="S2.SS2.p1.11.m11.1" class="ltx_Math" alttext="w^{\tau}" display="inline"><semantics id="S2.SS2.p1.11.m11.1a"><msup id="S2.SS2.p1.11.m11.1.1" xref="S2.SS2.p1.11.m11.1.1.cmml"><mi id="S2.SS2.p1.11.m11.1.1.2" xref="S2.SS2.p1.11.m11.1.1.2.cmml">w</mi><mi id="S2.SS2.p1.11.m11.1.1.3" xref="S2.SS2.p1.11.m11.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.11.m11.1b"><apply id="S2.SS2.p1.11.m11.1.1.cmml" xref="S2.SS2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.11.m11.1.1.1.cmml" xref="S2.SS2.p1.11.m11.1.1">superscript</csymbol><ci id="S2.SS2.p1.11.m11.1.1.2.cmml" xref="S2.SS2.p1.11.m11.1.1.2">𝑤</ci><ci id="S2.SS2.p1.11.m11.1.1.3.cmml" xref="S2.SS2.p1.11.m11.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.11.m11.1c">w^{\tau}</annotation></semantics></math> is the weight given to each sample of task <math id="S2.SS2.p1.12.m12.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S2.SS2.p1.12.m12.1a"><mi id="S2.SS2.p1.12.m12.1.1" xref="S2.SS2.p1.12.m12.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.12.m12.1b"><ci id="S2.SS2.p1.12.m12.1.1.cmml" xref="S2.SS2.p1.12.m12.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.12.m12.1c">\tau</annotation></semantics></math>. This is done to ensure balance between tasks with different complexities and training data sizes. Thus, each sample can be represented as a tuple <math id="S2.SS2.p1.13.m13.3" class="ltx_Math" alttext="(\mathbf{x}^{\tau},\mathbf{p}^{\tau},\mathbf{y}^{\tau})" display="inline"><semantics id="S2.SS2.p1.13.m13.3a"><mrow id="S2.SS2.p1.13.m13.3.3.3" xref="S2.SS2.p1.13.m13.3.3.4.cmml"><mo stretchy="false" id="S2.SS2.p1.13.m13.3.3.3.4" xref="S2.SS2.p1.13.m13.3.3.4.cmml">(</mo><msup id="S2.SS2.p1.13.m13.1.1.1.1" xref="S2.SS2.p1.13.m13.1.1.1.1.cmml"><mi id="S2.SS2.p1.13.m13.1.1.1.1.2" xref="S2.SS2.p1.13.m13.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.p1.13.m13.1.1.1.1.3" xref="S2.SS2.p1.13.m13.1.1.1.1.3.cmml">τ</mi></msup><mo id="S2.SS2.p1.13.m13.3.3.3.5" xref="S2.SS2.p1.13.m13.3.3.4.cmml">,</mo><msup id="S2.SS2.p1.13.m13.2.2.2.2" xref="S2.SS2.p1.13.m13.2.2.2.2.cmml"><mi id="S2.SS2.p1.13.m13.2.2.2.2.2" xref="S2.SS2.p1.13.m13.2.2.2.2.2.cmml">𝐩</mi><mi id="S2.SS2.p1.13.m13.2.2.2.2.3" xref="S2.SS2.p1.13.m13.2.2.2.2.3.cmml">τ</mi></msup><mo id="S2.SS2.p1.13.m13.3.3.3.6" xref="S2.SS2.p1.13.m13.3.3.4.cmml">,</mo><msup id="S2.SS2.p1.13.m13.3.3.3.3" xref="S2.SS2.p1.13.m13.3.3.3.3.cmml"><mi id="S2.SS2.p1.13.m13.3.3.3.3.2" xref="S2.SS2.p1.13.m13.3.3.3.3.2.cmml">𝐲</mi><mi id="S2.SS2.p1.13.m13.3.3.3.3.3" xref="S2.SS2.p1.13.m13.3.3.3.3.3.cmml">τ</mi></msup><mo stretchy="false" id="S2.SS2.p1.13.m13.3.3.3.7" xref="S2.SS2.p1.13.m13.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.13.m13.3b"><vector id="S2.SS2.p1.13.m13.3.3.4.cmml" xref="S2.SS2.p1.13.m13.3.3.3"><apply id="S2.SS2.p1.13.m13.1.1.1.1.cmml" xref="S2.SS2.p1.13.m13.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.13.m13.1.1.1.1.1.cmml" xref="S2.SS2.p1.13.m13.1.1.1.1">superscript</csymbol><ci id="S2.SS2.p1.13.m13.1.1.1.1.2.cmml" xref="S2.SS2.p1.13.m13.1.1.1.1.2">𝐱</ci><ci id="S2.SS2.p1.13.m13.1.1.1.1.3.cmml" xref="S2.SS2.p1.13.m13.1.1.1.1.3">𝜏</ci></apply><apply id="S2.SS2.p1.13.m13.2.2.2.2.cmml" xref="S2.SS2.p1.13.m13.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.13.m13.2.2.2.2.1.cmml" xref="S2.SS2.p1.13.m13.2.2.2.2">superscript</csymbol><ci id="S2.SS2.p1.13.m13.2.2.2.2.2.cmml" xref="S2.SS2.p1.13.m13.2.2.2.2.2">𝐩</ci><ci id="S2.SS2.p1.13.m13.2.2.2.2.3.cmml" xref="S2.SS2.p1.13.m13.2.2.2.2.3">𝜏</ci></apply><apply id="S2.SS2.p1.13.m13.3.3.3.3.cmml" xref="S2.SS2.p1.13.m13.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p1.13.m13.3.3.3.3.1.cmml" xref="S2.SS2.p1.13.m13.3.3.3.3">superscript</csymbol><ci id="S2.SS2.p1.13.m13.3.3.3.3.2.cmml" xref="S2.SS2.p1.13.m13.3.3.3.3.2">𝐲</ci><ci id="S2.SS2.p1.13.m13.3.3.3.3.3.cmml" xref="S2.SS2.p1.13.m13.3.3.3.3.3">𝜏</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.13.m13.3c">(\mathbf{x}^{\tau},\mathbf{p}^{\tau},\mathbf{y}^{\tau})</annotation></semantics></math> where <math id="S2.SS2.p1.14.m14.1" class="ltx_Math" alttext="\mathbf{x}^{\tau}" display="inline"><semantics id="S2.SS2.p1.14.m14.1a"><msup id="S2.SS2.p1.14.m14.1.1" xref="S2.SS2.p1.14.m14.1.1.cmml"><mi id="S2.SS2.p1.14.m14.1.1.2" xref="S2.SS2.p1.14.m14.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.p1.14.m14.1.1.3" xref="S2.SS2.p1.14.m14.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.14.m14.1b"><apply id="S2.SS2.p1.14.m14.1.1.cmml" xref="S2.SS2.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.14.m14.1.1.1.cmml" xref="S2.SS2.p1.14.m14.1.1">superscript</csymbol><ci id="S2.SS2.p1.14.m14.1.1.2.cmml" xref="S2.SS2.p1.14.m14.1.1.2">𝐱</ci><ci id="S2.SS2.p1.14.m14.1.1.3.cmml" xref="S2.SS2.p1.14.m14.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.14.m14.1c">\mathbf{x}^{\tau}</annotation></semantics></math> is the audio sample, <math id="S2.SS2.p1.15.m15.1" class="ltx_Math" alttext="\mathbf{p}^{\tau}" display="inline"><semantics id="S2.SS2.p1.15.m15.1a"><msup id="S2.SS2.p1.15.m15.1.1" xref="S2.SS2.p1.15.m15.1.1.cmml"><mi id="S2.SS2.p1.15.m15.1.1.2" xref="S2.SS2.p1.15.m15.1.1.2.cmml">𝐩</mi><mi id="S2.SS2.p1.15.m15.1.1.3" xref="S2.SS2.p1.15.m15.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.15.m15.1b"><apply id="S2.SS2.p1.15.m15.1.1.cmml" xref="S2.SS2.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.15.m15.1.1.1.cmml" xref="S2.SS2.p1.15.m15.1.1">superscript</csymbol><ci id="S2.SS2.p1.15.m15.1.1.2.cmml" xref="S2.SS2.p1.15.m15.1.1.2">𝐩</ci><ci id="S2.SS2.p1.15.m15.1.1.3.cmml" xref="S2.SS2.p1.15.m15.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.15.m15.1c">\mathbf{p}^{\tau}</annotation></semantics></math> is a prompt/instruction sampled uniformly from <math id="S2.SS2.p1.16.m16.1" class="ltx_Math" alttext="\mathcal{P}^{\tau}" display="inline"><semantics id="S2.SS2.p1.16.m16.1a"><msup id="S2.SS2.p1.16.m16.1.1" xref="S2.SS2.p1.16.m16.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.16.m16.1.1.2" xref="S2.SS2.p1.16.m16.1.1.2.cmml">𝒫</mi><mi id="S2.SS2.p1.16.m16.1.1.3" xref="S2.SS2.p1.16.m16.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.16.m16.1b"><apply id="S2.SS2.p1.16.m16.1.1.cmml" xref="S2.SS2.p1.16.m16.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.16.m16.1.1.1.cmml" xref="S2.SS2.p1.16.m16.1.1">superscript</csymbol><ci id="S2.SS2.p1.16.m16.1.1.2.cmml" xref="S2.SS2.p1.16.m16.1.1.2">𝒫</ci><ci id="S2.SS2.p1.16.m16.1.1.3.cmml" xref="S2.SS2.p1.16.m16.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.16.m16.1c">\mathcal{P}^{\tau}</annotation></semantics></math> and <math id="S2.SS2.p1.17.m17.1" class="ltx_Math" alttext="\mathbf{y}^{\tau}" display="inline"><semantics id="S2.SS2.p1.17.m17.1a"><msup id="S2.SS2.p1.17.m17.1.1" xref="S2.SS2.p1.17.m17.1.1.cmml"><mi id="S2.SS2.p1.17.m17.1.1.2" xref="S2.SS2.p1.17.m17.1.1.2.cmml">𝐲</mi><mi id="S2.SS2.p1.17.m17.1.1.3" xref="S2.SS2.p1.17.m17.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.17.m17.1b"><apply id="S2.SS2.p1.17.m17.1.1.cmml" xref="S2.SS2.p1.17.m17.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.17.m17.1.1.1.cmml" xref="S2.SS2.p1.17.m17.1.1">superscript</csymbol><ci id="S2.SS2.p1.17.m17.1.1.2.cmml" xref="S2.SS2.p1.17.m17.1.1.2">𝐲</ci><ci id="S2.SS2.p1.17.m17.1.1.3.cmml" xref="S2.SS2.p1.17.m17.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.17.m17.1c">\mathbf{y}^{\tau}</annotation></semantics></math> is the label.
Then the probability for predicting the labels <math id="S2.SS2.p1.18.m18.1" class="ltx_Math" alttext="\mathbf{y}^{\tau}" display="inline"><semantics id="S2.SS2.p1.18.m18.1a"><msup id="S2.SS2.p1.18.m18.1.1" xref="S2.SS2.p1.18.m18.1.1.cmml"><mi id="S2.SS2.p1.18.m18.1.1.2" xref="S2.SS2.p1.18.m18.1.1.2.cmml">𝐲</mi><mi id="S2.SS2.p1.18.m18.1.1.3" xref="S2.SS2.p1.18.m18.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.18.m18.1b"><apply id="S2.SS2.p1.18.m18.1.1.cmml" xref="S2.SS2.p1.18.m18.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.18.m18.1.1.1.cmml" xref="S2.SS2.p1.18.m18.1.1">superscript</csymbol><ci id="S2.SS2.p1.18.m18.1.1.2.cmml" xref="S2.SS2.p1.18.m18.1.1.2">𝐲</ci><ci id="S2.SS2.p1.18.m18.1.1.3.cmml" xref="S2.SS2.p1.18.m18.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.18.m18.1c">\mathbf{y}^{\tau}</annotation></semantics></math> can be defined as:
</p>
<table id="A1.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E3.m1.4" class="ltx_Math" alttext="\displaystyle p(\mathbf{y}^{\tau}|\mathbf{x}^{\tau},\mathbf{p}^{\tau};\Theta)=SLM(\mathbf{x}^{\tau},\mathbf{p}^{\tau})" display="inline"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml"><mrow id="S2.E3.m1.2.2.1" xref="S2.E3.m1.2.2.1.cmml"><mi id="S2.E3.m1.2.2.1.3" xref="S2.E3.m1.2.2.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.2" xref="S2.E3.m1.2.2.1.2.cmml">​</mo><mrow id="S2.E3.m1.2.2.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.2.2.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.cmml"><msup id="S2.E3.m1.2.2.1.1.1.1.4" xref="S2.E3.m1.2.2.1.1.1.1.4.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.4.2" xref="S2.E3.m1.2.2.1.1.1.1.4.2.cmml">𝐲</mi><mi id="S2.E3.m1.2.2.1.1.1.1.4.3" xref="S2.E3.m1.2.2.1.1.1.1.4.3.cmml">τ</mi></msup><mo fence="false" id="S2.E3.m1.2.2.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.3.cmml">|</mo><mrow id="S2.E3.m1.2.2.1.1.1.1.2.2" xref="S2.E3.m1.2.2.1.1.1.1.2.3.cmml"><msup id="S2.E3.m1.2.2.1.1.1.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.2" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.E3.m1.2.2.1.1.1.1.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml">τ</mi></msup><mo id="S2.E3.m1.2.2.1.1.1.1.2.2.3" xref="S2.E3.m1.2.2.1.1.1.1.2.3.cmml">,</mo><msup id="S2.E3.m1.2.2.1.1.1.1.2.2.2" xref="S2.E3.m1.2.2.1.1.1.1.2.2.2.cmml"><mi id="S2.E3.m1.2.2.1.1.1.1.2.2.2.2" xref="S2.E3.m1.2.2.1.1.1.1.2.2.2.2.cmml">𝐩</mi><mi id="S2.E3.m1.2.2.1.1.1.1.2.2.2.3" xref="S2.E3.m1.2.2.1.1.1.1.2.2.2.3.cmml">τ</mi></msup><mo id="S2.E3.m1.2.2.1.1.1.1.2.2.4" xref="S2.E3.m1.2.2.1.1.1.1.2.3.cmml">;</mo><mi mathvariant="normal" id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">Θ</mi></mrow></mrow><mo stretchy="false" id="S2.E3.m1.2.2.1.1.1.3" xref="S2.E3.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.4.4" xref="S2.E3.m1.4.4.4.cmml">=</mo><mrow id="S2.E3.m1.4.4.3" xref="S2.E3.m1.4.4.3.cmml"><mi id="S2.E3.m1.4.4.3.4" xref="S2.E3.m1.4.4.3.4.cmml">S</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.3.3" xref="S2.E3.m1.4.4.3.3.cmml">​</mo><mi id="S2.E3.m1.4.4.3.5" xref="S2.E3.m1.4.4.3.5.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.3.3a" xref="S2.E3.m1.4.4.3.3.cmml">​</mo><mi id="S2.E3.m1.4.4.3.6" xref="S2.E3.m1.4.4.3.6.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.3.3b" xref="S2.E3.m1.4.4.3.3.cmml">​</mo><mrow id="S2.E3.m1.4.4.3.2.2" xref="S2.E3.m1.4.4.3.2.3.cmml"><mo stretchy="false" id="S2.E3.m1.4.4.3.2.2.3" xref="S2.E3.m1.4.4.3.2.3.cmml">(</mo><msup id="S2.E3.m1.3.3.2.1.1.1" xref="S2.E3.m1.3.3.2.1.1.1.cmml"><mi id="S2.E3.m1.3.3.2.1.1.1.2" xref="S2.E3.m1.3.3.2.1.1.1.2.cmml">𝐱</mi><mi id="S2.E3.m1.3.3.2.1.1.1.3" xref="S2.E3.m1.3.3.2.1.1.1.3.cmml">τ</mi></msup><mo id="S2.E3.m1.4.4.3.2.2.4" xref="S2.E3.m1.4.4.3.2.3.cmml">,</mo><msup id="S2.E3.m1.4.4.3.2.2.2" xref="S2.E3.m1.4.4.3.2.2.2.cmml"><mi id="S2.E3.m1.4.4.3.2.2.2.2" xref="S2.E3.m1.4.4.3.2.2.2.2.cmml">𝐩</mi><mi id="S2.E3.m1.4.4.3.2.2.2.3" xref="S2.E3.m1.4.4.3.2.2.2.3.cmml">τ</mi></msup><mo stretchy="false" id="S2.E3.m1.4.4.3.2.2.5" xref="S2.E3.m1.4.4.3.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4"><eq id="S2.E3.m1.4.4.4.cmml" xref="S2.E3.m1.4.4.4"></eq><apply id="S2.E3.m1.2.2.1.cmml" xref="S2.E3.m1.2.2.1"><times id="S2.E3.m1.2.2.1.2.cmml" xref="S2.E3.m1.2.2.1.2"></times><ci id="S2.E3.m1.2.2.1.3.cmml" xref="S2.E3.m1.2.2.1.3">𝑝</ci><apply id="S2.E3.m1.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.2.2.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.3">conditional</csymbol><apply id="S2.E3.m1.2.2.1.1.1.1.4.cmml" xref="S2.E3.m1.2.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.1.1.4.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.4">superscript</csymbol><ci id="S2.E3.m1.2.2.1.1.1.1.4.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.4.2">𝐲</ci><ci id="S2.E3.m1.2.2.1.1.1.1.4.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.4.3">𝜏</ci></apply><list id="S2.E3.m1.2.2.1.1.1.1.2.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.2.2"><apply id="S2.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.E3.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.1.1.1.3">𝜏</ci></apply><apply id="S2.E3.m1.2.2.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.1.1.2.2.2.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1.2.2.2">superscript</csymbol><ci id="S2.E3.m1.2.2.1.1.1.1.2.2.2.2.cmml" xref="S2.E3.m1.2.2.1.1.1.1.2.2.2.2">𝐩</ci><ci id="S2.E3.m1.2.2.1.1.1.1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.1.1.1.1.2.2.2.3">𝜏</ci></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">Θ</ci></list></apply></apply><apply id="S2.E3.m1.4.4.3.cmml" xref="S2.E3.m1.4.4.3"><times id="S2.E3.m1.4.4.3.3.cmml" xref="S2.E3.m1.4.4.3.3"></times><ci id="S2.E3.m1.4.4.3.4.cmml" xref="S2.E3.m1.4.4.3.4">𝑆</ci><ci id="S2.E3.m1.4.4.3.5.cmml" xref="S2.E3.m1.4.4.3.5">𝐿</ci><ci id="S2.E3.m1.4.4.3.6.cmml" xref="S2.E3.m1.4.4.3.6">𝑀</ci><interval closure="open" id="S2.E3.m1.4.4.3.2.3.cmml" xref="S2.E3.m1.4.4.3.2.2"><apply id="S2.E3.m1.3.3.2.1.1.1.cmml" xref="S2.E3.m1.3.3.2.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.2.1.1.1.1.cmml" xref="S2.E3.m1.3.3.2.1.1.1">superscript</csymbol><ci id="S2.E3.m1.3.3.2.1.1.1.2.cmml" xref="S2.E3.m1.3.3.2.1.1.1.2">𝐱</ci><ci id="S2.E3.m1.3.3.2.1.1.1.3.cmml" xref="S2.E3.m1.3.3.2.1.1.1.3">𝜏</ci></apply><apply id="S2.E3.m1.4.4.3.2.2.2.cmml" xref="S2.E3.m1.4.4.3.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.3.2.2.2.1.cmml" xref="S2.E3.m1.4.4.3.2.2.2">superscript</csymbol><ci id="S2.E3.m1.4.4.3.2.2.2.2.cmml" xref="S2.E3.m1.4.4.3.2.2.2.2">𝐩</ci><ci id="S2.E3.m1.4.4.3.2.2.2.3.cmml" xref="S2.E3.m1.4.4.3.2.2.2.3">𝜏</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">\displaystyle p(\mathbf{y}^{\tau}|\mathbf{x}^{\tau},\mathbf{p}^{\tau};\Theta)=SLM(\mathbf{x}^{\tau},\mathbf{p}^{\tau})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p1.20" class="ltx_p">where <math id="S2.SS2.p1.19.m1.3" class="ltx_Math" alttext="\Theta=\{\theta_{AE},\theta_{CNN},\theta_{LLM}\}" display="inline"><semantics id="S2.SS2.p1.19.m1.3a"><mrow id="S2.SS2.p1.19.m1.3.3" xref="S2.SS2.p1.19.m1.3.3.cmml"><mi mathvariant="normal" id="S2.SS2.p1.19.m1.3.3.5" xref="S2.SS2.p1.19.m1.3.3.5.cmml">Θ</mi><mo id="S2.SS2.p1.19.m1.3.3.4" xref="S2.SS2.p1.19.m1.3.3.4.cmml">=</mo><mrow id="S2.SS2.p1.19.m1.3.3.3.3" xref="S2.SS2.p1.19.m1.3.3.3.4.cmml"><mo stretchy="false" id="S2.SS2.p1.19.m1.3.3.3.3.4" xref="S2.SS2.p1.19.m1.3.3.3.4.cmml">{</mo><msub id="S2.SS2.p1.19.m1.1.1.1.1.1" xref="S2.SS2.p1.19.m1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.19.m1.1.1.1.1.1.2" xref="S2.SS2.p1.19.m1.1.1.1.1.1.2.cmml">θ</mi><mrow id="S2.SS2.p1.19.m1.1.1.1.1.1.3" xref="S2.SS2.p1.19.m1.1.1.1.1.1.3.cmml"><mi id="S2.SS2.p1.19.m1.1.1.1.1.1.3.2" xref="S2.SS2.p1.19.m1.1.1.1.1.1.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.19.m1.1.1.1.1.1.3.1" xref="S2.SS2.p1.19.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.SS2.p1.19.m1.1.1.1.1.1.3.3" xref="S2.SS2.p1.19.m1.1.1.1.1.1.3.3.cmml">E</mi></mrow></msub><mo id="S2.SS2.p1.19.m1.3.3.3.3.5" xref="S2.SS2.p1.19.m1.3.3.3.4.cmml">,</mo><msub id="S2.SS2.p1.19.m1.2.2.2.2.2" xref="S2.SS2.p1.19.m1.2.2.2.2.2.cmml"><mi id="S2.SS2.p1.19.m1.2.2.2.2.2.2" xref="S2.SS2.p1.19.m1.2.2.2.2.2.2.cmml">θ</mi><mrow id="S2.SS2.p1.19.m1.2.2.2.2.2.3" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.cmml"><mi id="S2.SS2.p1.19.m1.2.2.2.2.2.3.2" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.19.m1.2.2.2.2.2.3.1" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.1.cmml">​</mo><mi id="S2.SS2.p1.19.m1.2.2.2.2.2.3.3" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.19.m1.2.2.2.2.2.3.1a" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.1.cmml">​</mo><mi id="S2.SS2.p1.19.m1.2.2.2.2.2.3.4" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.4.cmml">N</mi></mrow></msub><mo id="S2.SS2.p1.19.m1.3.3.3.3.6" xref="S2.SS2.p1.19.m1.3.3.3.4.cmml">,</mo><msub id="S2.SS2.p1.19.m1.3.3.3.3.3" xref="S2.SS2.p1.19.m1.3.3.3.3.3.cmml"><mi id="S2.SS2.p1.19.m1.3.3.3.3.3.2" xref="S2.SS2.p1.19.m1.3.3.3.3.3.2.cmml">θ</mi><mrow id="S2.SS2.p1.19.m1.3.3.3.3.3.3" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.cmml"><mi id="S2.SS2.p1.19.m1.3.3.3.3.3.3.2" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.19.m1.3.3.3.3.3.3.1" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.1.cmml">​</mo><mi id="S2.SS2.p1.19.m1.3.3.3.3.3.3.3" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p1.19.m1.3.3.3.3.3.3.1a" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.1.cmml">​</mo><mi id="S2.SS2.p1.19.m1.3.3.3.3.3.3.4" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.4.cmml">M</mi></mrow></msub><mo stretchy="false" id="S2.SS2.p1.19.m1.3.3.3.3.7" xref="S2.SS2.p1.19.m1.3.3.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.19.m1.3b"><apply id="S2.SS2.p1.19.m1.3.3.cmml" xref="S2.SS2.p1.19.m1.3.3"><eq id="S2.SS2.p1.19.m1.3.3.4.cmml" xref="S2.SS2.p1.19.m1.3.3.4"></eq><ci id="S2.SS2.p1.19.m1.3.3.5.cmml" xref="S2.SS2.p1.19.m1.3.3.5">Θ</ci><set id="S2.SS2.p1.19.m1.3.3.3.4.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3"><apply id="S2.SS2.p1.19.m1.1.1.1.1.1.cmml" xref="S2.SS2.p1.19.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.19.m1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.19.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p1.19.m1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.19.m1.1.1.1.1.1.2">𝜃</ci><apply id="S2.SS2.p1.19.m1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.19.m1.1.1.1.1.1.3"><times id="S2.SS2.p1.19.m1.1.1.1.1.1.3.1.cmml" xref="S2.SS2.p1.19.m1.1.1.1.1.1.3.1"></times><ci id="S2.SS2.p1.19.m1.1.1.1.1.1.3.2.cmml" xref="S2.SS2.p1.19.m1.1.1.1.1.1.3.2">𝐴</ci><ci id="S2.SS2.p1.19.m1.1.1.1.1.1.3.3.cmml" xref="S2.SS2.p1.19.m1.1.1.1.1.1.3.3">𝐸</ci></apply></apply><apply id="S2.SS2.p1.19.m1.2.2.2.2.2.cmml" xref="S2.SS2.p1.19.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.19.m1.2.2.2.2.2.1.cmml" xref="S2.SS2.p1.19.m1.2.2.2.2.2">subscript</csymbol><ci id="S2.SS2.p1.19.m1.2.2.2.2.2.2.cmml" xref="S2.SS2.p1.19.m1.2.2.2.2.2.2">𝜃</ci><apply id="S2.SS2.p1.19.m1.2.2.2.2.2.3.cmml" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3"><times id="S2.SS2.p1.19.m1.2.2.2.2.2.3.1.cmml" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.1"></times><ci id="S2.SS2.p1.19.m1.2.2.2.2.2.3.2.cmml" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.2">𝐶</ci><ci id="S2.SS2.p1.19.m1.2.2.2.2.2.3.3.cmml" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.3">𝑁</ci><ci id="S2.SS2.p1.19.m1.2.2.2.2.2.3.4.cmml" xref="S2.SS2.p1.19.m1.2.2.2.2.2.3.4">𝑁</ci></apply></apply><apply id="S2.SS2.p1.19.m1.3.3.3.3.3.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p1.19.m1.3.3.3.3.3.1.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3.3">subscript</csymbol><ci id="S2.SS2.p1.19.m1.3.3.3.3.3.2.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3.3.2">𝜃</ci><apply id="S2.SS2.p1.19.m1.3.3.3.3.3.3.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3"><times id="S2.SS2.p1.19.m1.3.3.3.3.3.3.1.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.1"></times><ci id="S2.SS2.p1.19.m1.3.3.3.3.3.3.2.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.2">𝐿</ci><ci id="S2.SS2.p1.19.m1.3.3.3.3.3.3.3.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.3">𝐿</ci><ci id="S2.SS2.p1.19.m1.3.3.3.3.3.3.4.cmml" xref="S2.SS2.p1.19.m1.3.3.3.3.3.3.4">𝑀</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.19.m1.3c">\Theta=\{\theta_{AE},\theta_{CNN},\theta_{LLM}\}</annotation></semantics></math> are all the parameters of our audio language model.
The self-attention layers in the LLM attend to both the audio and the textual instruction to generate the required output on any audio-related task.
We use the standard gradient descent method to maximise the likelihood of producing the target label <math id="S2.SS2.p1.20.m2.1" class="ltx_Math" alttext="\mathbf{y}^{\tau}" display="inline"><semantics id="S2.SS2.p1.20.m2.1a"><msup id="S2.SS2.p1.20.m2.1.1" xref="S2.SS2.p1.20.m2.1.1.cmml"><mi id="S2.SS2.p1.20.m2.1.1.2" xref="S2.SS2.p1.20.m2.1.1.2.cmml">𝐲</mi><mi id="S2.SS2.p1.20.m2.1.1.3" xref="S2.SS2.p1.20.m2.1.1.3.cmml">τ</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.20.m2.1b"><apply id="S2.SS2.p1.20.m2.1.1.cmml" xref="S2.SS2.p1.20.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.20.m2.1.1.1.cmml" xref="S2.SS2.p1.20.m2.1.1">superscript</csymbol><ci id="S2.SS2.p1.20.m2.1.1.2.cmml" xref="S2.SS2.p1.20.m2.1.1.2">𝐲</ci><ci id="S2.SS2.p1.20.m2.1.1.3.cmml" xref="S2.SS2.p1.20.m2.1.1.3">𝜏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.20.m2.1c">\mathbf{y}^{\tau}</annotation></semantics></math> for each sample in the training dataset as defined below:</p>
<table id="A1.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E4.m1.7" class="ltx_Math" alttext="\displaystyle\mathcal{L}(\Theta)=-\log p_{(\mathbf{x}^{\tau},\mathbf{p}^{\tau},\mathbf{y}^{\tau})\sim\{\mathcal{D}^{\tau}\}_{1}^{M}}(\mathbf{y}^{\tau}|\mathbf{x}^{\tau},\mathbf{p}^{\tau};\Theta)" display="inline"><semantics id="S2.E4.m1.7a"><mrow id="S2.E4.m1.7.7" xref="S2.E4.m1.7.7.cmml"><mrow id="S2.E4.m1.7.7.3" xref="S2.E4.m1.7.7.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.7.7.3.2" xref="S2.E4.m1.7.7.3.2.cmml">ℒ</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.3.1" xref="S2.E4.m1.7.7.3.1.cmml">​</mo><mrow id="S2.E4.m1.7.7.3.3.2" xref="S2.E4.m1.7.7.3.cmml"><mo stretchy="false" id="S2.E4.m1.7.7.3.3.2.1" xref="S2.E4.m1.7.7.3.cmml">(</mo><mi mathvariant="normal" id="S2.E4.m1.5.5" xref="S2.E4.m1.5.5.cmml">Θ</mi><mo stretchy="false" id="S2.E4.m1.7.7.3.3.2.2" xref="S2.E4.m1.7.7.3.cmml">)</mo></mrow></mrow><mo id="S2.E4.m1.7.7.2" xref="S2.E4.m1.7.7.2.cmml">=</mo><mrow id="S2.E4.m1.7.7.1" xref="S2.E4.m1.7.7.1.cmml"><mo rspace="0.167em" id="S2.E4.m1.7.7.1a" xref="S2.E4.m1.7.7.1.cmml">−</mo><mrow id="S2.E4.m1.7.7.1.1" xref="S2.E4.m1.7.7.1.1.cmml"><mrow id="S2.E4.m1.7.7.1.1.3" xref="S2.E4.m1.7.7.1.1.3.cmml"><mi id="S2.E4.m1.7.7.1.1.3.1" xref="S2.E4.m1.7.7.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.E4.m1.7.7.1.1.3a" xref="S2.E4.m1.7.7.1.1.3.cmml">⁡</mo><msub id="S2.E4.m1.7.7.1.1.3.2" xref="S2.E4.m1.7.7.1.1.3.2.cmml"><mi id="S2.E4.m1.7.7.1.1.3.2.2" xref="S2.E4.m1.7.7.1.1.3.2.2.cmml">p</mi><mrow id="S2.E4.m1.4.4.4" xref="S2.E4.m1.4.4.4.cmml"><mrow id="S2.E4.m1.3.3.3.3.3" xref="S2.E4.m1.3.3.3.3.4.cmml"><mo stretchy="false" id="S2.E4.m1.3.3.3.3.3.4" xref="S2.E4.m1.3.3.3.3.4.cmml">(</mo><msup id="S2.E4.m1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.E4.m1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.3.cmml">τ</mi></msup><mo id="S2.E4.m1.3.3.3.3.3.5" xref="S2.E4.m1.3.3.3.3.4.cmml">,</mo><msup id="S2.E4.m1.2.2.2.2.2.2" xref="S2.E4.m1.2.2.2.2.2.2.cmml"><mi id="S2.E4.m1.2.2.2.2.2.2.2" xref="S2.E4.m1.2.2.2.2.2.2.2.cmml">𝐩</mi><mi id="S2.E4.m1.2.2.2.2.2.2.3" xref="S2.E4.m1.2.2.2.2.2.2.3.cmml">τ</mi></msup><mo id="S2.E4.m1.3.3.3.3.3.6" xref="S2.E4.m1.3.3.3.3.4.cmml">,</mo><msup id="S2.E4.m1.3.3.3.3.3.3" xref="S2.E4.m1.3.3.3.3.3.3.cmml"><mi id="S2.E4.m1.3.3.3.3.3.3.2" xref="S2.E4.m1.3.3.3.3.3.3.2.cmml">𝐲</mi><mi id="S2.E4.m1.3.3.3.3.3.3.3" xref="S2.E4.m1.3.3.3.3.3.3.3.cmml">τ</mi></msup><mo stretchy="false" id="S2.E4.m1.3.3.3.3.3.7" xref="S2.E4.m1.3.3.3.3.4.cmml">)</mo></mrow><mo id="S2.E4.m1.4.4.4.5" xref="S2.E4.m1.4.4.4.5.cmml">∼</mo><msubsup id="S2.E4.m1.4.4.4.4" xref="S2.E4.m1.4.4.4.4.cmml"><mrow id="S2.E4.m1.4.4.4.4.1.1.1" xref="S2.E4.m1.4.4.4.4.1.1.2.cmml"><mo stretchy="false" id="S2.E4.m1.4.4.4.4.1.1.1.2" xref="S2.E4.m1.4.4.4.4.1.1.2.cmml">{</mo><msup id="S2.E4.m1.4.4.4.4.1.1.1.1" xref="S2.E4.m1.4.4.4.4.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E4.m1.4.4.4.4.1.1.1.1.2" xref="S2.E4.m1.4.4.4.4.1.1.1.1.2.cmml">𝒟</mi><mi id="S2.E4.m1.4.4.4.4.1.1.1.1.3" xref="S2.E4.m1.4.4.4.4.1.1.1.1.3.cmml">τ</mi></msup><mo stretchy="false" id="S2.E4.m1.4.4.4.4.1.1.1.3" xref="S2.E4.m1.4.4.4.4.1.1.2.cmml">}</mo></mrow><mn id="S2.E4.m1.4.4.4.4.1.3" xref="S2.E4.m1.4.4.4.4.1.3.cmml">1</mn><mi id="S2.E4.m1.4.4.4.4.3" xref="S2.E4.m1.4.4.4.4.3.cmml">M</mi></msubsup></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S2.E4.m1.7.7.1.1.2" xref="S2.E4.m1.7.7.1.1.2.cmml">​</mo><mrow id="S2.E4.m1.7.7.1.1.1.1" xref="S2.E4.m1.7.7.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E4.m1.7.7.1.1.1.1.2" xref="S2.E4.m1.7.7.1.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1" xref="S2.E4.m1.7.7.1.1.1.1.1.cmml"><msup id="S2.E4.m1.7.7.1.1.1.1.1.4" xref="S2.E4.m1.7.7.1.1.1.1.1.4.cmml"><mi id="S2.E4.m1.7.7.1.1.1.1.1.4.2" xref="S2.E4.m1.7.7.1.1.1.1.1.4.2.cmml">𝐲</mi><mi id="S2.E4.m1.7.7.1.1.1.1.1.4.3" xref="S2.E4.m1.7.7.1.1.1.1.1.4.3.cmml">τ</mi></msup><mo fence="false" id="S2.E4.m1.7.7.1.1.1.1.1.3" xref="S2.E4.m1.7.7.1.1.1.1.1.3.cmml">|</mo><mrow id="S2.E4.m1.7.7.1.1.1.1.1.2.2" xref="S2.E4.m1.7.7.1.1.1.1.1.2.3.cmml"><msup id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.3.cmml">τ</mi></msup><mo id="S2.E4.m1.7.7.1.1.1.1.1.2.2.3" xref="S2.E4.m1.7.7.1.1.1.1.1.2.3.cmml">,</mo><msup id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.cmml">𝐩</mi><mi id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.3" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.3.cmml">τ</mi></msup><mo id="S2.E4.m1.7.7.1.1.1.1.1.2.2.4" xref="S2.E4.m1.7.7.1.1.1.1.1.2.3.cmml">;</mo><mi mathvariant="normal" id="S2.E4.m1.6.6" xref="S2.E4.m1.6.6.cmml">Θ</mi></mrow></mrow><mo stretchy="false" id="S2.E4.m1.7.7.1.1.1.1.3" xref="S2.E4.m1.7.7.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.7b"><apply id="S2.E4.m1.7.7.cmml" xref="S2.E4.m1.7.7"><eq id="S2.E4.m1.7.7.2.cmml" xref="S2.E4.m1.7.7.2"></eq><apply id="S2.E4.m1.7.7.3.cmml" xref="S2.E4.m1.7.7.3"><times id="S2.E4.m1.7.7.3.1.cmml" xref="S2.E4.m1.7.7.3.1"></times><ci id="S2.E4.m1.7.7.3.2.cmml" xref="S2.E4.m1.7.7.3.2">ℒ</ci><ci id="S2.E4.m1.5.5.cmml" xref="S2.E4.m1.5.5">Θ</ci></apply><apply id="S2.E4.m1.7.7.1.cmml" xref="S2.E4.m1.7.7.1"><minus id="S2.E4.m1.7.7.1.2.cmml" xref="S2.E4.m1.7.7.1"></minus><apply id="S2.E4.m1.7.7.1.1.cmml" xref="S2.E4.m1.7.7.1.1"><times id="S2.E4.m1.7.7.1.1.2.cmml" xref="S2.E4.m1.7.7.1.1.2"></times><apply id="S2.E4.m1.7.7.1.1.3.cmml" xref="S2.E4.m1.7.7.1.1.3"><log id="S2.E4.m1.7.7.1.1.3.1.cmml" xref="S2.E4.m1.7.7.1.1.3.1"></log><apply id="S2.E4.m1.7.7.1.1.3.2.cmml" xref="S2.E4.m1.7.7.1.1.3.2"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.1.1.3.2.1.cmml" xref="S2.E4.m1.7.7.1.1.3.2">subscript</csymbol><ci id="S2.E4.m1.7.7.1.1.3.2.2.cmml" xref="S2.E4.m1.7.7.1.1.3.2.2">𝑝</ci><apply id="S2.E4.m1.4.4.4.cmml" xref="S2.E4.m1.4.4.4"><csymbol cd="latexml" id="S2.E4.m1.4.4.4.5.cmml" xref="S2.E4.m1.4.4.4.5">similar-to</csymbol><vector id="S2.E4.m1.3.3.3.3.4.cmml" xref="S2.E4.m1.3.3.3.3.3"><apply id="S2.E4.m1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.E4.m1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.3">𝜏</ci></apply><apply id="S2.E4.m1.2.2.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.2.2.2.2.1.cmml" xref="S2.E4.m1.2.2.2.2.2.2">superscript</csymbol><ci id="S2.E4.m1.2.2.2.2.2.2.2.cmml" xref="S2.E4.m1.2.2.2.2.2.2.2">𝐩</ci><ci id="S2.E4.m1.2.2.2.2.2.2.3.cmml" xref="S2.E4.m1.2.2.2.2.2.2.3">𝜏</ci></apply><apply id="S2.E4.m1.3.3.3.3.3.3.cmml" xref="S2.E4.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.E4.m1.3.3.3.3.3.3.1.cmml" xref="S2.E4.m1.3.3.3.3.3.3">superscript</csymbol><ci id="S2.E4.m1.3.3.3.3.3.3.2.cmml" xref="S2.E4.m1.3.3.3.3.3.3.2">𝐲</ci><ci id="S2.E4.m1.3.3.3.3.3.3.3.cmml" xref="S2.E4.m1.3.3.3.3.3.3.3">𝜏</ci></apply></vector><apply id="S2.E4.m1.4.4.4.4.cmml" xref="S2.E4.m1.4.4.4.4"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.4.4.2.cmml" xref="S2.E4.m1.4.4.4.4">superscript</csymbol><apply id="S2.E4.m1.4.4.4.4.1.cmml" xref="S2.E4.m1.4.4.4.4"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.4.4.1.2.cmml" xref="S2.E4.m1.4.4.4.4">subscript</csymbol><set id="S2.E4.m1.4.4.4.4.1.1.2.cmml" xref="S2.E4.m1.4.4.4.4.1.1.1"><apply id="S2.E4.m1.4.4.4.4.1.1.1.1.cmml" xref="S2.E4.m1.4.4.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.4.4.4.4.1.1.1.1.1.cmml" xref="S2.E4.m1.4.4.4.4.1.1.1.1">superscript</csymbol><ci id="S2.E4.m1.4.4.4.4.1.1.1.1.2.cmml" xref="S2.E4.m1.4.4.4.4.1.1.1.1.2">𝒟</ci><ci id="S2.E4.m1.4.4.4.4.1.1.1.1.3.cmml" xref="S2.E4.m1.4.4.4.4.1.1.1.1.3">𝜏</ci></apply></set><cn type="integer" id="S2.E4.m1.4.4.4.4.1.3.cmml" xref="S2.E4.m1.4.4.4.4.1.3">1</cn></apply><ci id="S2.E4.m1.4.4.4.4.3.cmml" xref="S2.E4.m1.4.4.4.4.3">𝑀</ci></apply></apply></apply></apply><apply id="S2.E4.m1.7.7.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.7.7.1.1.1.1.1.3.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.3">conditional</csymbol><apply id="S2.E4.m1.7.7.1.1.1.1.1.4.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.1.1.1.1.1.4.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.4">superscript</csymbol><ci id="S2.E4.m1.7.7.1.1.1.1.1.4.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.4.2">𝐲</ci><ci id="S2.E4.m1.7.7.1.1.1.1.1.4.3.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.4.3">𝜏</ci></apply><list id="S2.E4.m1.7.7.1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2"><apply id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.1.1.1.3">𝜏</ci></apply><apply id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2">superscript</csymbol><ci id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.2">𝐩</ci><ci id="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E4.m1.7.7.1.1.1.1.1.2.2.2.3">𝜏</ci></apply><ci id="S2.E4.m1.6.6.cmml" xref="S2.E4.m1.6.6">Θ</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.7c">\displaystyle\mathcal{L}(\Theta)=-\log p_{(\mathbf{x}^{\tau},\mathbf{p}^{\tau},\mathbf{y}^{\tau})\sim\{\mathcal{D}^{\tau}\}_{1}^{M}}(\mathbf{y}^{\tau}|\mathbf{x}^{\tau},\mathbf{p}^{\tau};\Theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Curriculum Learning with Parameter Efficient Finetuning</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.2" class="ltx_p">To ensure faster convergence and avoid catastrophic forgetting and overfitting
by the pre-trained LLM,
we adopt a parameter efficient approach
based on low-rank adaptation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">21</a>]</cite>, or LoRA,
for training our multimodal models.
In this work, we freeze the pre-trained audio encoder and LLM,
and only train the convolution downsampling module and the LoRA adapter.
Since the bulk of the parameters (<math id="S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="\theta_{AE}" display="inline"><semantics id="S2.SS3.p1.1.m1.1a"><msub id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml"><mi id="S2.SS3.p1.1.m1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.2.cmml">θ</mi><mrow id="S2.SS3.p1.1.m1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.3.cmml"><mi id="S2.SS3.p1.1.m1.1.1.3.2" xref="S2.SS3.p1.1.m1.1.1.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.1.m1.1.1.3.1" xref="S2.SS3.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S2.SS3.p1.1.m1.1.1.3.3" xref="S2.SS3.p1.1.m1.1.1.3.3.cmml">E</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2">𝜃</ci><apply id="S2.SS3.p1.1.m1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3"><times id="S2.SS3.p1.1.m1.1.1.3.1.cmml" xref="S2.SS3.p1.1.m1.1.1.3.1"></times><ci id="S2.SS3.p1.1.m1.1.1.3.2.cmml" xref="S2.SS3.p1.1.m1.1.1.3.2">𝐴</ci><ci id="S2.SS3.p1.1.m1.1.1.3.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3.3">𝐸</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">\theta_{AE}</annotation></semantics></math> and <math id="S2.SS3.p1.2.m2.1" class="ltx_Math" alttext="\theta_{LLM}" display="inline"><semantics id="S2.SS3.p1.2.m2.1a"><msub id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml"><mi id="S2.SS3.p1.2.m2.1.1.2" xref="S2.SS3.p1.2.m2.1.1.2.cmml">θ</mi><mrow id="S2.SS3.p1.2.m2.1.1.3" xref="S2.SS3.p1.2.m2.1.1.3.cmml"><mi id="S2.SS3.p1.2.m2.1.1.3.2" xref="S2.SS3.p1.2.m2.1.1.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.2.m2.1.1.3.1" xref="S2.SS3.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S2.SS3.p1.2.m2.1.1.3.3" xref="S2.SS3.p1.2.m2.1.1.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p1.2.m2.1.1.3.1a" xref="S2.SS3.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S2.SS3.p1.2.m2.1.1.3.4" xref="S2.SS3.p1.2.m2.1.1.3.4.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><apply id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.2.m2.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.p1.2.m2.1.1.2.cmml" xref="S2.SS3.p1.2.m2.1.1.2">𝜃</ci><apply id="S2.SS3.p1.2.m2.1.1.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3"><times id="S2.SS3.p1.2.m2.1.1.3.1.cmml" xref="S2.SS3.p1.2.m2.1.1.3.1"></times><ci id="S2.SS3.p1.2.m2.1.1.3.2.cmml" xref="S2.SS3.p1.2.m2.1.1.3.2">𝐿</ci><ci id="S2.SS3.p1.2.m2.1.1.3.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3.3">𝐿</ci><ci id="S2.SS3.p1.2.m2.1.1.3.4.cmml" xref="S2.SS3.p1.2.m2.1.1.3.4">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">\theta_{LLM}</annotation></semantics></math>) are never updated throughout the training process, it makes our framework compute efficient and allows us to scale to a large number of diverse datasets and tasks with limited compute resources. Moreover, it enables leveraging the existing capabilities of both pre-trained audio and language models without catastrophic forgetting.
However, when training both
the downsampling module and the LoRA adapter from scratch
on a diverse set of speech tasks,
we observe frequent gradient explosion,
leading to suboptimal convergence.
Hence, we carefully design a curriculum of two stages for training.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">In the first stage, we only train the convolution downsampling module
and the intermediate layer weights
without introducing the LoRA adapters.
Further, only the samples from the automatic speech recognition (ASR) task
are used in this stage.
Since the encoded speech feature vectors can be very different from the token embeddings of the text input,
this stage can help align them more easily in a common embedding space by only learning the
parameters for the convolution downsampling module in the confined task space of ASR.
This enables a pre-trained text-based LLM to attend to the content of the audio sequence
and generate the speech transcription.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">In the second stage, we now introduce the LoRA adapters
for training the model.
In this stage,
the intermediate layer weights,
the downsampling module
as well as the LoRA adapters
are unfrozen.
Since the LoRA adapters are training from scratch,
we first allow the adapter weights to warmup
by training only on the ASR task,
so as to get aligned to the common embedding space
learned by the convolution downsampling module in the first stage.
Finally, we introduce additional tasks on top of the ASR task
and continue training
while keeping the pre-trained audio encoder and LLM weights frozen.
Since the warmup using only the ASR task enables the model
to understand the contents of the audio,
our curriculum learning approach leads to
faster convergence on a variety of speech-based tasks
that rely on the spoken contents of the audio.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Tasks</h3>

<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Details of our tasks, training datasets and evaluation metrics. ST, IC, SF, KWE and KWS tasks are referred as spoken language understanding (SLU) tasks, while ER, ASC, SC, AC and SNS represents paralinguistic speech processing (PSP) tasks</figcaption>
<div id="S3.T1.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.3pt;height:308.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-49.0pt,35.1pt) scale(0.814205270662489,0.814205270662489) ;">
<table id="S3.T1.7.7" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.7.7.8" class="ltx_tr">
<td id="S3.T1.7.7.8.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T1.7.7.8.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></td>
<td id="S3.T1.7.7.8.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T1.7.7.8.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Description</span></td>
<td id="S3.T1.7.7.8.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T1.7.7.8.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Metric</span></td>
<td id="S3.T1.7.7.8.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T1.7.7.8.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dataset</span></td>
<td id="S3.T1.7.7.8.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T1.7.7.8.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Training</span></td>
</tr>
<tr id="S3.T1.7.7.9" class="ltx_tr">
<td id="S3.T1.7.7.9.1" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.9.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">#Hours</span></td>
<td id="S3.T1.7.7.9.2" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.9.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">#Samples</span></td>
</tr>
<tr id="S3.T1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="5"><span id="S3.T1.1.1.1.2.1" class="ltx_text" style="font-size:80%;">ASR</span></td>
<td id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="5">
<span id="S3.T1.1.1.1.3.1" class="ltx_text"></span><span id="S3.T1.1.1.1.3.2" class="ltx_text" style="font-size:80%;"> </span><span id="S3.T1.1.1.1.3.3" class="ltx_text" style="font-size:80%;">
<span id="S3.T1.1.1.1.3.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.1.1.1.3.3.1.1" class="ltx_tr">
<span id="S3.T1.1.1.1.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Automatic Speech</span></span>
<span id="S3.T1.1.1.1.3.3.1.2" class="ltx_tr">
<span id="S3.T1.1.1.1.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Recognition</span></span>
</span></span><span id="S3.T1.1.1.1.3.4" class="ltx_text"></span><span id="S3.T1.1.1.1.3.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="5">
<span id="S3.T1.1.1.1.1.2" class="ltx_text"></span><span id="S3.T1.1.1.1.1.3" class="ltx_text" style="font-size:80%;"> </span><span id="S3.T1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T1.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.1.1.1.1.1.1.1.2" class="ltx_tr">
<span id="S3.T1.1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Word Error</span></span>
<span id="S3.T1.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S3.T1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Rate (WER)<math id="S3.T1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.1.1.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span></span><span id="S3.T1.1.1.1.1.4" class="ltx_text"></span><span id="S3.T1.1.1.1.1.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.1.1.1.4.1" class="ltx_text" style="font-size:80%;">Librispeech </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.1.1.1.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx22" title="" class="ltx_ref">22</a><span id="S3.T1.1.1.1.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.1.1.1.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.1.1.1.5.1" class="ltx_text" style="font-size:80%;">960</span></td>
<td id="S3.T1.1.1.1.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.1.1.1.6.1" class="ltx_text" style="font-size:80%;">281K</span></td>
</tr>
<tr id="S3.T1.7.7.10" class="ltx_tr">
<td id="S3.T1.7.7.10.1" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.10.1.1" class="ltx_text" style="font-size:80%;">Mozilla Common Voice 5.1 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.10.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx23" title="" class="ltx_ref">23</a><span id="S3.T1.7.7.10.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.10.2" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.10.2.1" class="ltx_text" style="font-size:80%;">1.4K</span></td>
<td id="S3.T1.7.7.10.3" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.10.3.1" class="ltx_text" style="font-size:80%;">1.1M</span></td>
</tr>
<tr id="S3.T1.7.7.11" class="ltx_tr">
<td id="S3.T1.7.7.11.1" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.11.1.1" class="ltx_text" style="font-size:80%;">VoxPopuli </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.11.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx24" title="" class="ltx_ref">24</a><span id="S3.T1.7.7.11.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.11.2" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.11.2.1" class="ltx_text" style="font-size:80%;">385</span></td>
<td id="S3.T1.7.7.11.3" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.11.3.1" class="ltx_text" style="font-size:80%;">160K</span></td>
</tr>
<tr id="S3.T1.7.7.12" class="ltx_tr">
<td id="S3.T1.7.7.12.1" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.12.1.1" class="ltx_text" style="font-size:80%;">SLURP </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.12.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx25" title="" class="ltx_ref">25</a><span id="S3.T1.7.7.12.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.12.2" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.12.2.1" class="ltx_text" style="font-size:80%;">84</span></td>
<td id="S3.T1.7.7.12.3" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.12.3.1" class="ltx_text" style="font-size:80%;">119K</span></td>
</tr>
<tr id="S3.T1.7.7.13" class="ltx_tr">
<td id="S3.T1.7.7.13.1" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.13.1.1" class="ltx_text" style="font-size:80%;">EuroParl </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.13.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx26" title="" class="ltx_ref">26</a><span id="S3.T1.7.7.13.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.13.2" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.13.2.1" class="ltx_text" style="font-size:80%;">92</span></td>
<td id="S3.T1.7.7.13.3" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.13.3.1" class="ltx_text" style="font-size:80%;">39K</span></td>
</tr>
<tr id="S3.T1.7.7.14" class="ltx_tr">
<td id="S3.T1.7.7.14.1" class="ltx_td"></td>
<td id="S3.T1.7.7.14.2" class="ltx_td"></td>
<td id="S3.T1.7.7.14.3" class="ltx_td"></td>
<td id="S3.T1.7.7.14.4" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.14.4.1" class="ltx_text" style="font-size:80%;">MSP-Podcast 1.11 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.14.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx27" title="" class="ltx_ref">27</a><span id="S3.T1.7.7.14.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.14.5" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.14.5.1" class="ltx_text" style="font-size:80%;">135</span></td>
<td id="S3.T1.7.7.14.6" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.14.6.1" class="ltx_text" style="font-size:80%;">83K</span></td>
</tr>
<tr id="S3.T1.2.2.2" class="ltx_tr">
<td id="S3.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.2.2.2.2.1" class="ltx_text" style="font-size:80%;">ST</span></td>
<td id="S3.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.2.2.2.3.1" class="ltx_text" style="font-size:80%;">Speech Translation</span></td>
<td id="S3.T1.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">BLEU <math id="S3.T1.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.2.2.2.1.1.m1.1a"><mo stretchy="false" id="S3.T1.2.2.2.1.1.m1.1.1" xref="S3.T1.2.2.2.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.1.1.m1.1b"><ci id="S3.T1.2.2.2.1.1.m1.1.1.cmml" xref="S3.T1.2.2.2.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S3.T1.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.2.2.2.4.1" class="ltx_text" style="font-size:80%;">CoVost2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.2.2.2.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx28" title="" class="ltx_ref">28</a><span id="S3.T1.2.2.2.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.2.2.2.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.2.2.2.5.1" class="ltx_text" style="font-size:80%;">426</span></td>
<td id="S3.T1.2.2.2.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.2.2.2.6.1" class="ltx_text" style="font-size:80%;">576K</span></td>
</tr>
<tr id="S3.T1.7.7.15" class="ltx_tr">
<td id="S3.T1.7.7.15.1" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.15.1.1" class="ltx_text" style="font-size:80%;">EuroParl </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.15.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx26" title="" class="ltx_ref">26</a><span id="S3.T1.7.7.15.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.15.2" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.15.2.1" class="ltx_text" style="font-size:80%;">73</span></td>
<td id="S3.T1.7.7.15.3" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.15.3.1" class="ltx_text" style="font-size:80%;">90K</span></td>
</tr>
<tr id="S3.T1.3.3.3" class="ltx_tr">
<td id="S3.T1.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.3.3.3.2.1" class="ltx_text" style="font-size:80%;">IC</span></td>
<td id="S3.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.3.3.3.3.1" class="ltx_text" style="font-size:80%;">Intent Classification</span></td>
<td id="S3.T1.3.3.3.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.3.3.3.1.1" class="ltx_text" style="font-size:80%;">Accuracy (ACC)</span><math id="S3.T1.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.3.3.3.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S3.T1.3.3.3.1.m1.1.1" xref="S3.T1.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.1.m1.1b"><ci id="S3.T1.3.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S3.T1.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.3.3.3.4.1" class="ltx_text" style="font-size:80%;">SLURP </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.3.3.3.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx25" title="" class="ltx_ref">25</a><span id="S3.T1.3.3.3.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.3.3.3.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.3.3.3.5.1" class="ltx_text" style="font-size:80%;">35</span></td>
<td id="S3.T1.3.3.3.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.3.3.3.6.1" class="ltx_text" style="font-size:80%;">47K</span></td>
</tr>
<tr id="S3.T1.4.4.4" class="ltx_tr">
<td id="S3.T1.4.4.4.2" class="ltx_td ltx_align_center"><span id="S3.T1.4.4.4.2.1" class="ltx_text" style="font-size:80%;">SF</span></td>
<td id="S3.T1.4.4.4.3" class="ltx_td ltx_align_center"><span id="S3.T1.4.4.4.3.1" class="ltx_text" style="font-size:80%;">Slot Filling</span></td>
<td id="S3.T1.4.4.4.1" class="ltx_td ltx_align_center">
<span id="S3.T1.4.4.4.1.1" class="ltx_text" style="font-size:80%;">SLU-F1 </span><math id="S3.T1.4.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.4.4.4.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S3.T1.4.4.4.1.m1.1.1" xref="S3.T1.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.1.m1.1b"><ci id="S3.T1.4.4.4.1.m1.1.1.cmml" xref="S3.T1.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S3.T1.4.4.4.4" class="ltx_td ltx_align_center">
<span id="S3.T1.4.4.4.4.1" class="ltx_text" style="font-size:80%;">SLURP </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.4.4.4.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx25" title="" class="ltx_ref">25</a><span id="S3.T1.4.4.4.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.4.4.4.5" class="ltx_td ltx_align_right"><span id="S3.T1.4.4.4.5.1" class="ltx_text" style="font-size:80%;">25</span></td>
<td id="S3.T1.4.4.4.6" class="ltx_td ltx_align_right"><span id="S3.T1.4.4.4.6.1" class="ltx_text" style="font-size:80%;">30K</span></td>
</tr>
<tr id="S3.T1.5.5.5" class="ltx_tr">
<td id="S3.T1.5.5.5.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.5.5.5.2.1" class="ltx_text" style="font-size:80%;">KWE</span></td>
<td id="S3.T1.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.5.5.5.3.1" class="ltx_text" style="font-size:80%;">Keyword Extraction</span></td>
<td id="S3.T1.5.5.5.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.5.5.5.1.1" class="ltx_text" style="font-size:80%;">Macro F1<math id="S3.T1.5.5.5.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.5.5.5.1.1.m1.1a"><mo stretchy="false" id="S3.T1.5.5.5.1.1.m1.1.1" xref="S3.T1.5.5.5.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.1.1.m1.1b"><ci id="S3.T1.5.5.5.1.1.m1.1.1.cmml" xref="S3.T1.5.5.5.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S3.T1.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.5.5.5.4.1" class="ltx_text" style="font-size:80%;">Librispeech </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.5.5.5.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx22" title="" class="ltx_ref">22</a><span id="S3.T1.5.5.5.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.5.5.5.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.5.5.5.5.1" class="ltx_text" style="font-size:80%;">960</span></td>
<td id="S3.T1.5.5.5.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.5.5.5.6.1" class="ltx_text" style="font-size:80%;">281K</span></td>
</tr>
<tr id="S3.T1.7.7.16" class="ltx_tr">
<td id="S3.T1.7.7.16.1" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.16.1.1" class="ltx_text" style="font-size:80%;">Mozilla Common Voice 5.1 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.16.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx23" title="" class="ltx_ref">23</a><span id="S3.T1.7.7.16.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.16.2" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.16.2.1" class="ltx_text" style="font-size:80%;">426</span></td>
<td id="S3.T1.7.7.16.3" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.16.3.1" class="ltx_text" style="font-size:80%;">288K</span></td>
</tr>
<tr id="S3.T1.6.6.6" class="ltx_tr">
<td id="S3.T1.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.6.6.6.2.1" class="ltx_text" style="font-size:80%;">KWS</span></td>
<td id="S3.T1.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T1.6.6.6.3.1" class="ltx_text" style="font-size:80%;">Keyword Search</span></td>
<td id="S3.T1.6.6.6.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="S3.T1.6.6.6.1.2" class="ltx_text"></span><span id="S3.T1.6.6.6.1.3" class="ltx_text" style="font-size:80%;"> </span><span id="S3.T1.6.6.6.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T1.6.6.6.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.6.6.6.1.1.1.1.1" class="ltx_tr">
<span id="S3.T1.6.6.6.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Accuracy (ACC) <math id="S3.T1.6.6.6.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.6.6.6.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T1.6.6.6.1.1.1.1.1.1.m1.1.1" xref="S3.T1.6.6.6.1.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.1.1.1.1.1.1.m1.1b"><ci id="S3.T1.6.6.6.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.6.6.6.1.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.1.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></span>
</span></span><span id="S3.T1.6.6.6.1.4" class="ltx_text"></span><span id="S3.T1.6.6.6.1.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S3.T1.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.6.6.6.4.1" class="ltx_text" style="font-size:80%;">Librispeech </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.6.6.6.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx22" title="" class="ltx_ref">22</a><span id="S3.T1.6.6.6.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.6.6.6.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.6.6.6.5.1" class="ltx_text" style="font-size:80%;">960</span></td>
<td id="S3.T1.6.6.6.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.6.6.6.6.1" class="ltx_text" style="font-size:80%;">281K</span></td>
</tr>
<tr id="S3.T1.7.7.17" class="ltx_tr">
<td id="S3.T1.7.7.17.1" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.17.1.1" class="ltx_text" style="font-size:80%;">Mozilla Common Voice 5.1 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.17.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx23" title="" class="ltx_ref">23</a><span id="S3.T1.7.7.17.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.17.2" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.17.2.1" class="ltx_text" style="font-size:80%;">426</span></td>
<td id="S3.T1.7.7.17.3" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.17.3.1" class="ltx_text" style="font-size:80%;">288K</span></td>
</tr>
<tr id="S3.T1.7.7.7" class="ltx_tr">
<td id="S3.T1.7.7.7.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.7.7.7.2.1" class="ltx_text" style="font-size:80%;">ER</span></td>
<td id="S3.T1.7.7.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.7.7.7.3.1" class="ltx_text" style="font-size:80%;">Emotion Recognition</span></td>
<td id="S3.T1.7.7.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="5">
<span id="S3.T1.7.7.7.1.2" class="ltx_text"></span><span id="S3.T1.7.7.7.1.3" class="ltx_text" style="font-size:80%;"> </span><span id="S3.T1.7.7.7.1.1" class="ltx_text" style="font-size:80%;">
<span id="S3.T1.7.7.7.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T1.7.7.7.1.1.1.1.2" class="ltx_tr">
<span id="S3.T1.7.7.7.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Unweighted Average</span></span>
<span id="S3.T1.7.7.7.1.1.1.1.1" class="ltx_tr">
<span id="S3.T1.7.7.7.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Recall (UAR) <math id="S3.T1.7.7.7.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.7.7.7.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T1.7.7.7.1.1.1.1.1.1.m1.1.1" xref="S3.T1.7.7.7.1.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.7.1.1.1.1.1.1.m1.1b"><ci id="S3.T1.7.7.7.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.7.7.7.1.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.7.1.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></span>
</span></span><span id="S3.T1.7.7.7.1.4" class="ltx_text"></span><span id="S3.T1.7.7.7.1.5" class="ltx_text" style="font-size:80%;"></span>
</td>
<td id="S3.T1.7.7.7.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T1.7.7.7.4.1" class="ltx_text" style="font-size:80%;">MSP-Podcast 1.11 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.7.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx27" title="" class="ltx_ref">27</a><span id="S3.T1.7.7.7.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.7.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.7.7.7.5.1" class="ltx_text" style="font-size:80%;">91</span></td>
<td id="S3.T1.7.7.7.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S3.T1.7.7.7.6.1" class="ltx_text" style="font-size:80%;">57K</span></td>
</tr>
<tr id="S3.T1.7.7.18" class="ltx_tr">
<td id="S3.T1.7.7.18.1" class="ltx_td ltx_align_center"><span id="S3.T1.7.7.18.1.1" class="ltx_text" style="font-size:80%;">ASC</span></td>
<td id="S3.T1.7.7.18.2" class="ltx_td ltx_align_center"><span id="S3.T1.7.7.18.2.1" class="ltx_text" style="font-size:80%;">Audio Sentiment Classification</span></td>
<td id="S3.T1.7.7.18.3" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.18.3.1" class="ltx_text" style="font-size:80%;">MSP-Podcast 1.11 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.18.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx27" title="" class="ltx_ref">27</a><span id="S3.T1.7.7.18.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.18.4" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.18.4.1" class="ltx_text" style="font-size:80%;">135</span></td>
<td id="S3.T1.7.7.18.5" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.18.5.1" class="ltx_text" style="font-size:80%;">84K</span></td>
</tr>
<tr id="S3.T1.7.7.19" class="ltx_tr">
<td id="S3.T1.7.7.19.1" class="ltx_td ltx_align_center"><span id="S3.T1.7.7.19.1.1" class="ltx_text" style="font-size:80%;">SC</span></td>
<td id="S3.T1.7.7.19.2" class="ltx_td ltx_align_center"><span id="S3.T1.7.7.19.2.1" class="ltx_text" style="font-size:80%;">Speaker Counting</span></td>
<td id="S3.T1.7.7.19.3" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.19.3.1" class="ltx_text" style="font-size:80%;">Fisher </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.19.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx29" title="" class="ltx_ref">29</a>, <a href="#bib.bibx30" title="" class="ltx_ref">30</a><span id="S3.T1.7.7.19.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.19.4" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.19.4.1" class="ltx_text" style="font-size:80%;">690</span></td>
<td id="S3.T1.7.7.19.5" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.19.5.1" class="ltx_text" style="font-size:80%;">755K</span></td>
</tr>
<tr id="S3.T1.7.7.20" class="ltx_tr">
<td id="S3.T1.7.7.20.1" class="ltx_td ltx_align_center"><span id="S3.T1.7.7.20.1.1" class="ltx_text" style="font-size:80%;">AC</span></td>
<td id="S3.T1.7.7.20.2" class="ltx_td ltx_align_center"><span id="S3.T1.7.7.20.2.1" class="ltx_text" style="font-size:80%;">Accent Classification</span></td>
<td id="S3.T1.7.7.20.3" class="ltx_td ltx_align_center">
<span id="S3.T1.7.7.20.3.1" class="ltx_text" style="font-size:80%;">Mozilla Common Voice 5.1 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.7.7.20.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx23" title="" class="ltx_ref">23</a><span id="S3.T1.7.7.20.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.7.7.20.4" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.20.4.1" class="ltx_text" style="font-size:80%;">190</span></td>
<td id="S3.T1.7.7.20.5" class="ltx_td ltx_align_right"><span id="S3.T1.7.7.20.5.1" class="ltx_text" style="font-size:80%;">123K</span></td>
</tr>
<tr id="S3.T1.7.7.21" class="ltx_tr">
<td id="S3.T1.7.7.21.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.7.7.21.1.1" class="ltx_text" style="font-size:80%;">SNS</span></td>
<td id="S3.T1.7.7.21.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.7.7.21.2.1" class="ltx_text" style="font-size:80%;">Speech/Non-Speech Detection</span></td>
<td id="S3.T1.7.7.21.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.7.7.21.3.1" class="ltx_text" style="font-size:80%;">In-house VAD</span></td>
<td id="S3.T1.7.7.21.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T1.7.7.21.4.1" class="ltx_text" style="font-size:80%;">269</span></td>
<td id="S3.T1.7.7.21.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S3.T1.7.7.21.5.1" class="ltx_text" style="font-size:80%;">149K</span></td>
</tr>
</table>
</span></div>
</figure>
<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In this work, we use a large collection of publicly available speech datasets from a diverse set of tasks. A summary of the datasets and evaluation metrics for these tasks is provided in the Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Tasks ‣ 3 Experiments ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, while examples and prompts are covered in the Table <a href="#S4.T10" title="Table 10 ‣ 4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. Our training tasks include automatic speech recognition (ASR), five spoken language understanding (SLU) tasks, and five paralinguistic speech processing (PSP) tasks. The SLU tasks include those tasks which can be solved by a cascaded system of a ASR model and an LLM, while PSP tasks are classification tasks based on the audio, typically used in audio analytics.
For the IC/SL tasks, we split the SLURP dataset into seen and unseen intent/slot label classes and study them separately to understand the generalization capabilities of the model. The KWE task is about finding important keywords from the audio, while in the KWS task, we learn to classify whether a particular keyword was present in the audio or not. The target labels were synthetically created for both these tasks using an LLM. All other tasks are standard and an interested reader can refer to the Appendix <a href="#A1.SS3" title="A.3 Tasks ‣ Appendix A Appendix ‣ Ethics Statement ‣ Limitations ‣ 6 Conclusion ‣ 5 Related Work ‣ 4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a> for more details.
We create a list of at least 15 prompts per task describing the goal of the task. To further add diversity to the set of tasks, we use a text-to-speech (TTS) version of the Alpaca dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">31</a>]</cite>. This dataset contains a diverse collection of prompt, input, output tuples, where the prompt describes the task, input is the input for the task, and the output contains the target labels. However, there are no corresponding audios associated with the dataset. As in the existing work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">17</a>]</cite>, we use a TTS system (AWS Polly in our case) to generate synthetic audios for the input text using a pool of 10 different speakers.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Models</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">We train three different variants of multimodal models using our SpeechVerse framework, namely,
(1) <span id="S3.SS2.p1.4.1" class="ltx_text ltx_font_bold">Task-FT</span>: These represent a set of models where each model is trained individually for a particular task <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\tau</annotation></semantics></math>.
While most tasks have separate model, datasets from certain related tasks like IC/SF, KWE/KWS, and ER/ASC are trained together.
(2) <span id="S3.SS2.p1.4.2" class="ltx_text ltx_font_bold">Multitask-WLM</span>: This represents a single multi-task model trained by pooling datasets for all the tasks together. Both (1) and (2) uses a pretrained WavLM Large <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx32" title="" class="ltx_ref">32</a>]</cite> as the backbone audio encoder and only uses the last encoder layer output <math id="S3.SS2.p1.2.m2.2" class="ltx_Math" alttext="AE(\mathbf{x})=\mathbf{h}^{(L)}" display="inline"><semantics id="S3.SS2.p1.2.m2.2a"><mrow id="S3.SS2.p1.2.m2.2.3" xref="S3.SS2.p1.2.m2.2.3.cmml"><mrow id="S3.SS2.p1.2.m2.2.3.2" xref="S3.SS2.p1.2.m2.2.3.2.cmml"><mi id="S3.SS2.p1.2.m2.2.3.2.2" xref="S3.SS2.p1.2.m2.2.3.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.2.m2.2.3.2.1" xref="S3.SS2.p1.2.m2.2.3.2.1.cmml">​</mo><mi id="S3.SS2.p1.2.m2.2.3.2.3" xref="S3.SS2.p1.2.m2.2.3.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.2.m2.2.3.2.1a" xref="S3.SS2.p1.2.m2.2.3.2.1.cmml">​</mo><mrow id="S3.SS2.p1.2.m2.2.3.2.4.2" xref="S3.SS2.p1.2.m2.2.3.2.cmml"><mo stretchy="false" id="S3.SS2.p1.2.m2.2.3.2.4.2.1" xref="S3.SS2.p1.2.m2.2.3.2.cmml">(</mo><mi id="S3.SS2.p1.2.m2.2.2" xref="S3.SS2.p1.2.m2.2.2.cmml">𝐱</mi><mo stretchy="false" id="S3.SS2.p1.2.m2.2.3.2.4.2.2" xref="S3.SS2.p1.2.m2.2.3.2.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p1.2.m2.2.3.1" xref="S3.SS2.p1.2.m2.2.3.1.cmml">=</mo><msup id="S3.SS2.p1.2.m2.2.3.3" xref="S3.SS2.p1.2.m2.2.3.3.cmml"><mi id="S3.SS2.p1.2.m2.2.3.3.2" xref="S3.SS2.p1.2.m2.2.3.3.2.cmml">𝐡</mi><mrow id="S3.SS2.p1.2.m2.1.1.1.3" xref="S3.SS2.p1.2.m2.2.3.3.cmml"><mo stretchy="false" id="S3.SS2.p1.2.m2.1.1.1.3.1" xref="S3.SS2.p1.2.m2.2.3.3.cmml">(</mo><mi id="S3.SS2.p1.2.m2.1.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.1.cmml">L</mi><mo stretchy="false" id="S3.SS2.p1.2.m2.1.1.1.3.2" xref="S3.SS2.p1.2.m2.2.3.3.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.2b"><apply id="S3.SS2.p1.2.m2.2.3.cmml" xref="S3.SS2.p1.2.m2.2.3"><eq id="S3.SS2.p1.2.m2.2.3.1.cmml" xref="S3.SS2.p1.2.m2.2.3.1"></eq><apply id="S3.SS2.p1.2.m2.2.3.2.cmml" xref="S3.SS2.p1.2.m2.2.3.2"><times id="S3.SS2.p1.2.m2.2.3.2.1.cmml" xref="S3.SS2.p1.2.m2.2.3.2.1"></times><ci id="S3.SS2.p1.2.m2.2.3.2.2.cmml" xref="S3.SS2.p1.2.m2.2.3.2.2">𝐴</ci><ci id="S3.SS2.p1.2.m2.2.3.2.3.cmml" xref="S3.SS2.p1.2.m2.2.3.2.3">𝐸</ci><ci id="S3.SS2.p1.2.m2.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2">𝐱</ci></apply><apply id="S3.SS2.p1.2.m2.2.3.3.cmml" xref="S3.SS2.p1.2.m2.2.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.2.3.3.1.cmml" xref="S3.SS2.p1.2.m2.2.3.3">superscript</csymbol><ci id="S3.SS2.p1.2.m2.2.3.3.2.cmml" xref="S3.SS2.p1.2.m2.2.3.3.2">𝐡</ci><ci id="S3.SS2.p1.2.m2.1.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1.1">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.2c">AE(\mathbf{x})=\mathbf{h}^{(L)}</annotation></semantics></math> as the representation of the audio.
(3) <span id="S3.SS2.p1.4.3" class="ltx_text ltx_font_bold">Multitask-BRQ</span>: This model is similar to (2), but it uses the Best-RQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">33</a>]</cite> architecture for the audio encoder. Because the Best-RQ encoder is trained using a random projection quantizer, the middle layer weights are more suited for downstream tasks if the encoder is frozen during fine-tuning. We therefore used a unified representation that combines representations from all layers via learnable weights for the multitask model trained with the BEST-RQ encoder. The details about the pretraining of this audio encoder are described in the Appendix <a href="#A1.SS1" title="A.1 Audio Encoder Pre-training ‣ Appendix A Appendix ‣ Ethics Statement ‣ Limitations ‣ 6 Conclusion ‣ 5 Related Work ‣ 4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a>. All the three variants of our models are trained using curriculum learning as highlighted in the Section <a href="#S2.SS3" title="2.3 Curriculum Learning with Parameter Efficient Finetuning ‣ 2 Approach ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>. All the models use Flan-T5-XL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">5</a>]</cite> as the backbone LLM. The LoRA adapters introduced in Task-FT models have rank <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="(r)=8" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.2" xref="S3.SS2.p1.3.m3.1.2.cmml"><mrow id="S3.SS2.p1.3.m3.1.2.2.2" xref="S3.SS2.p1.3.m3.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.3.m3.1.2.2.2.1" xref="S3.SS2.p1.3.m3.1.2.cmml">(</mo><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">r</mi><mo stretchy="false" id="S3.SS2.p1.3.m3.1.2.2.2.2" xref="S3.SS2.p1.3.m3.1.2.cmml">)</mo></mrow><mo id="S3.SS2.p1.3.m3.1.2.1" xref="S3.SS2.p1.3.m3.1.2.1.cmml">=</mo><mn id="S3.SS2.p1.3.m3.1.2.3" xref="S3.SS2.p1.3.m3.1.2.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.2.cmml" xref="S3.SS2.p1.3.m3.1.2"><eq id="S3.SS2.p1.3.m3.1.2.1.cmml" xref="S3.SS2.p1.3.m3.1.2.1"></eq><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑟</ci><cn type="integer" id="S3.SS2.p1.3.m3.1.2.3.cmml" xref="S3.SS2.p1.3.m3.1.2.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">(r)=8</annotation></semantics></math>, while multitask models use <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="r=16" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mrow id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">r</mi><mo id="S3.SS2.p1.4.m4.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><eq id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1"></eq><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">𝑟</ci><cn type="integer" id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">r=16</annotation></semantics></math>, allowing more learnable parameters for solving a diverse collection of tasks. The complete list of hyper-parameters and training setting is provided in the Appendix <a href="#A1.SS2" title="A.2 Hyper-parameters ‣ Appendix A Appendix ‣ Ethics Statement ‣ Limitations ‣ 6 Conclusion ‣ 5 Related Work ‣ 4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.2" class="ltx_p"><span id="S3.SS2.p2.2.1" class="ltx_text ltx_font_bold">Baselines</span>: For the SLU tasks, we compare our models with a cascaded baseline that uses an LLM on ASR hypotheses (ASR <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mo stretchy="false" id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\rightarrow</annotation></semantics></math> LLM). For a fair comparison, we use a parameter-efficient fine-tuned version of Flan-T5-XL as the LLM for the baseline. The multi-task fine-tuning data is exactly the same between our models and the baseline except that the latter uses ground truth text in place of the audios. We benchmark the cascaded approach with ASR hypotheses from (1) a strong publicly available Whisper-large-v2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">20</a>]</cite> ASR model and (2) our ASR Task-FT SpeechVerse model, enabling a true comparison between a multimodal model vs cascaded approach.
Finally, we also benchmark the performance of the oracle ASR system by passing the ground truth transcripts to the baseline LLM (GT <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mo stretchy="false" id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\rightarrow</annotation></semantics></math> LLM). For the KWS task, we use substring search of the keyword in ASR hypotheses as the baseline. For PSP tasks, we train task-specific classifiers that use the last layer representations from WavLM Large. The classifier contains a feed-forward layer, followed by a 2-layer Gated Recurrent Unit (GRU) with mean pooling over frames, followed by another 2 layers of feed-forward network and finally a softmax operator. These models are trained on the same task-specific data thereby allowing for direct comparison with our WavLM-based multimodal models.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of ASR and spoken language understanding
(SLU) tasks. Datasets are defined as: LTC: Librispeech test-clean; LTO: Librispeech test-other; Vox: Voxpopuli; MCV: Mozilla Common Voice; EN: English; DE: German; FR: French;</figcaption>
<div id="S3.T2.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:128.5pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-67.3pt,19.8pt) scale(0.763115666171389,0.763115666171389) ;">
<table id="S3.T2.11.11" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.6.6.6" class="ltx_tr">
<td id="S3.T2.6.6.6.7" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T2.6.6.6.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></td>
<td id="S3.T2.6.6.6.8" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T2.6.6.6.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Training</span></td>
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" colspan="4">
<span id="S3.T2.1.1.1.1.2" class="ltx_text"></span><span id="S3.T2.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;"> <span id="S3.T2.1.1.1.1.1.1" class="ltx_text">
<span id="S3.T2.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.1.1.1.1.1.1.1.2" class="ltx_tr">
<span id="S3.T2.1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">ASR</span></span>
<span id="S3.T2.1.1.1.1.1.1.1.1" class="ltx_tr">
<span id="S3.T2.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">(WER<math id="S3.T2.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.1.1.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></span>
</span></span><span id="S3.T2.1.1.1.1.1.2" class="ltx_text"></span></span>
</td>
<td id="S3.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S3.T2.2.2.2.2.2" class="ltx_text"></span><span id="S3.T2.2.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;"> <span id="S3.T2.2.2.2.2.1.1" class="ltx_text">
<span id="S3.T2.2.2.2.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.2.2.2.2.1.1.1.2" class="ltx_tr">
<span id="S3.T2.2.2.2.2.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">IC</span></span>
<span id="S3.T2.2.2.2.2.1.1.1.1" class="ltx_tr">
<span id="S3.T2.2.2.2.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">(ACC<math id="S3.T2.2.2.2.2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.2.2.2.2.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.2.2.2.2.1.1.1.1.1.m1.1.1" xref="S3.T2.2.2.2.2.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.2.1.1.1.1.1.m1.1b"><ci id="S3.T2.2.2.2.2.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.2.2.2.2.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.2.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></span>
</span></span><span id="S3.T2.2.2.2.2.1.2" class="ltx_text"></span></span>
</td>
<td id="S3.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S3.T2.3.3.3.3.2" class="ltx_text"></span><span id="S3.T2.3.3.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;"> <span id="S3.T2.3.3.3.3.1.1" class="ltx_text">
<span id="S3.T2.3.3.3.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.3.3.3.3.1.1.1.2" class="ltx_tr">
<span id="S3.T2.3.3.3.3.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">SF</span></span>
<span id="S3.T2.3.3.3.3.1.1.1.1" class="ltx_tr">
<span id="S3.T2.3.3.3.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">(SLU-F1<math id="S3.T2.3.3.3.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.3.3.3.3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.3.3.3.3.1.1.1.1.1.m1.1.1" xref="S3.T2.3.3.3.3.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.3.1.1.1.1.1.m1.1b"><ci id="S3.T2.3.3.3.3.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.3.3.3.3.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.3.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></span>
</span></span><span id="S3.T2.3.3.3.3.1.2" class="ltx_text"></span></span>
</td>
<td id="S3.T2.4.4.4.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2">
<span id="S3.T2.4.4.4.4.2" class="ltx_text"></span><span id="S3.T2.4.4.4.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;"> <span id="S3.T2.4.4.4.4.1.1" class="ltx_text">
<span id="S3.T2.4.4.4.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.4.4.4.4.1.1.1.2" class="ltx_tr">
<span id="S3.T2.4.4.4.4.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">ST</span></span>
<span id="S3.T2.4.4.4.4.1.1.1.1" class="ltx_tr">
<span id="S3.T2.4.4.4.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">(BLEU<math id="S3.T2.4.4.4.4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.4.4.4.4.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.4.4.4.4.1.1.1.1.1.m1.1.1" xref="S3.T2.4.4.4.4.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.4.1.1.1.1.1.m1.1b"><ci id="S3.T2.4.4.4.4.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.4.4.4.4.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.4.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></span>
</span></span><span id="S3.T2.4.4.4.4.1.2" class="ltx_text"></span></span>
</td>
<td id="S3.T2.5.5.5.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S3.T2.5.5.5.5.2" class="ltx_text"></span><span id="S3.T2.5.5.5.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;"> <span id="S3.T2.5.5.5.5.1.1" class="ltx_text">
<span id="S3.T2.5.5.5.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.5.5.5.5.1.1.1.2" class="ltx_tr">
<span id="S3.T2.5.5.5.5.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">KWE</span></span>
<span id="S3.T2.5.5.5.5.1.1.1.1" class="ltx_tr">
<span id="S3.T2.5.5.5.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">(F1<math id="S3.T2.5.5.5.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.5.5.5.5.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.5.5.5.5.1.1.1.1.1.m1.1.1" xref="S3.T2.5.5.5.5.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.5.1.1.1.1.1.m1.1b"><ci id="S3.T2.5.5.5.5.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.5.5.5.5.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.5.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></span>
</span></span><span id="S3.T2.5.5.5.5.1.2" class="ltx_text"></span></span>
</td>
<td id="S3.T2.6.6.6.6" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S3.T2.6.6.6.6.2" class="ltx_text"></span><span id="S3.T2.6.6.6.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;"> <span id="S3.T2.6.6.6.6.1.1" class="ltx_text">
<span id="S3.T2.6.6.6.6.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.6.6.6.6.1.1.1.2" class="ltx_tr">
<span id="S3.T2.6.6.6.6.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">KWS</span></span>
<span id="S3.T2.6.6.6.6.1.1.1.1" class="ltx_tr">
<span id="S3.T2.6.6.6.6.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">(ACC<math id="S3.T2.6.6.6.6.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.6.6.6.6.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.6.6.6.6.1.1.1.1.1.m1.1.1" xref="S3.T2.6.6.6.6.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.6.6.1.1.1.1.1.m1.1b"><ci id="S3.T2.6.6.6.6.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.6.6.6.6.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.6.6.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></span>
</span></span><span id="S3.T2.6.6.6.6.1.2" class="ltx_text"></span></span>
</td>
</tr>
<tr id="S3.T2.8.8.8" class="ltx_tr">
<td id="S3.T2.8.8.8.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">LTC</span></td>
<td id="S3.T2.8.8.8.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">LTO</span></td>
<td id="S3.T2.8.8.8.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Vox</span></td>
<td id="S3.T2.8.8.8.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">MCV</span></td>
<td id="S3.T2.8.8.8.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SLURP</span></td>
<td id="S3.T2.8.8.8.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SLURP</span></td>
<td id="S3.T2.7.7.7.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.7.7.7.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">EN<math id="S3.T2.7.7.7.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.T2.7.7.7.1.1.m1.1a"><mo stretchy="false" id="S3.T2.7.7.7.1.1.m1.1.1" xref="S3.T2.7.7.7.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.7.1.1.m1.1b"><ci id="S3.T2.7.7.7.1.1.m1.1.1.cmml" xref="S3.T2.7.7.7.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.7.1.1.m1.1c">\rightarrow</annotation></semantics></math>DE</span></td>
<td id="S3.T2.8.8.8.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">EN<math id="S3.T2.8.8.8.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.T2.8.8.8.2.1.m1.1a"><mo stretchy="false" id="S3.T2.8.8.8.2.1.m1.1.1" xref="S3.T2.8.8.8.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.8.2.1.m1.1b"><ci id="S3.T2.8.8.8.2.1.m1.1.1.cmml" xref="S3.T2.8.8.8.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.8.2.1.m1.1c">\rightarrow</annotation></semantics></math>FR</span></td>
<td id="S3.T2.8.8.8.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">MCV</span></td>
<td id="S3.T2.8.8.8.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.8.8.8.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">MCV</span></td>
</tr>
<tr id="S3.T2.9.9.9" class="ltx_tr">
<td id="S3.T2.9.9.9.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S3.T2.9.9.9.1.1" class="ltx_text" style="font-size:80%;">Whisper ASR </span><math id="S3.T2.9.9.9.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.T2.9.9.9.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S3.T2.9.9.9.1.m1.1.1" xref="S3.T2.9.9.9.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.9.1.m1.1b"><ci id="S3.T2.9.9.9.1.m1.1.1.cmml" xref="S3.T2.9.9.9.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.9.1.m1.1c">\rightarrow</annotation></semantics></math><span id="S3.T2.9.9.9.1.2" class="ltx_text" style="font-size:80%;"> LLM</span>
</td>
<td id="S3.T2.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T2.9.9.9.2.1" class="ltx_text" style="font-size:80%;"><span id="S3.T2.9.9.9.2.1.1" class="ltx_text"></span> <span id="S3.T2.9.9.9.2.1.2" class="ltx_text">
<span id="S3.T2.9.9.9.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.9.9.9.2.1.2.1.1" class="ltx_tr">
<span id="S3.T2.9.9.9.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">LLM-FT</span></span>
</span></span> <span id="S3.T2.9.9.9.2.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.3.1" class="ltx_text" style="font-size:80%;">2.5</span></td>
<td id="S3.T2.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.4.1" class="ltx_text" style="font-size:80%;">4.9</span></td>
<td id="S3.T2.9.9.9.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.5.1" class="ltx_text" style="font-size:80%;">7.0</span></td>
<td id="S3.T2.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.6.1" class="ltx_text" style="font-size:80%;">8.2</span></td>
<td id="S3.T2.9.9.9.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.7.1" class="ltx_text" style="font-size:80%;">86.6</span></td>
<td id="S3.T2.9.9.9.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.8.1" class="ltx_text" style="font-size:80%;">72.3</span></td>
<td id="S3.T2.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.9.1" class="ltx_text" style="font-size:80%;">23.5</span></td>
<td id="S3.T2.9.9.9.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.10.1" class="ltx_text" style="font-size:80%;">30.6</span></td>
<td id="S3.T2.9.9.9.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.11.1" class="ltx_text" style="font-size:80%;">45.1</span></td>
<td id="S3.T2.9.9.9.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.9.9.12.1" class="ltx_text" style="font-size:80%;">87.7</span></td>
</tr>
<tr id="S3.T2.10.10.10" class="ltx_tr">
<td id="S3.T2.10.10.10.1" class="ltx_td ltx_align_center">
<span id="S3.T2.10.10.10.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse ASR </span><math id="S3.T2.10.10.10.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.T2.10.10.10.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S3.T2.10.10.10.1.m1.1.1" xref="S3.T2.10.10.10.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.T2.10.10.10.1.m1.1b"><ci id="S3.T2.10.10.10.1.m1.1.1.cmml" xref="S3.T2.10.10.10.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.10.10.1.m1.1c">\rightarrow</annotation></semantics></math><span id="S3.T2.10.10.10.1.2" class="ltx_text" style="font-size:80%;"> LLM</span>
</td>
<td id="S3.T2.10.10.10.2" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.2.1" class="ltx_text" style="font-size:80%;">2.1</span></td>
<td id="S3.T2.10.10.10.3" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.3.1" class="ltx_text" style="font-size:80%;">4.4</span></td>
<td id="S3.T2.10.10.10.4" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.4.1" class="ltx_text" style="font-size:80%;">6.5</span></td>
<td id="S3.T2.10.10.10.5" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.5.1" class="ltx_text" style="font-size:80%;">10.5</span></td>
<td id="S3.T2.10.10.10.6" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.6.1" class="ltx_text" style="font-size:80%;">88.8</span></td>
<td id="S3.T2.10.10.10.7" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.7.1" class="ltx_text" style="font-size:80%;">80.5</span></td>
<td id="S3.T2.10.10.10.8" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.8.1" class="ltx_text" style="font-size:80%;">24.4</span></td>
<td id="S3.T2.10.10.10.9" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.9.1" class="ltx_text" style="font-size:80%;">30.9</span></td>
<td id="S3.T2.10.10.10.10" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.10.1" class="ltx_text" style="font-size:80%;">54.3</span></td>
<td id="S3.T2.10.10.10.11" class="ltx_td ltx_align_center"><span id="S3.T2.10.10.10.11.1" class="ltx_text" style="font-size:80%;">87.3</span></td>
</tr>
<tr id="S3.T2.11.11.12" class="ltx_tr">
<td id="S3.T2.11.11.12.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T2.11.11.12.1.1" class="ltx_text" style="font-size:80%;"><span id="S3.T2.11.11.12.1.1.1" class="ltx_text"></span> <span id="S3.T2.11.11.12.1.1.2" class="ltx_text">
<span id="S3.T2.11.11.12.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.11.11.12.1.1.2.1.1" class="ltx_tr">
<span id="S3.T2.11.11.12.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">SpeechVerse</span></span>
<span id="S3.T2.11.11.12.1.1.2.1.2" class="ltx_tr">
<span id="S3.T2.11.11.12.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(E2E–SLM)</span></span>
</span></span> <span id="S3.T2.11.11.12.1.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.11.11.12.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.2.1" class="ltx_text" style="font-size:80%;">Task-FT</span></td>
<td id="S3.T2.11.11.12.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.3.1" class="ltx_text" style="font-size:80%;">2.1</span></td>
<td id="S3.T2.11.11.12.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.4.1" class="ltx_text" style="font-size:80%;">4.4</span></td>
<td id="S3.T2.11.11.12.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.5.1" class="ltx_text" style="font-size:80%;">6.5</span></td>
<td id="S3.T2.11.11.12.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.6.1" class="ltx_text" style="font-size:80%;">10.5</span></td>
<td id="S3.T2.11.11.12.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.7.1" class="ltx_text" style="font-size:80%;">90.4</span></td>
<td id="S3.T2.11.11.12.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.8.1" class="ltx_text" style="font-size:80%;">82.4</span></td>
<td id="S3.T2.11.11.12.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.9.1" class="ltx_text" style="font-size:80%;">27.8</span></td>
<td id="S3.T2.11.11.12.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.10.1" class="ltx_text" style="font-size:80%;">35.7</span></td>
<td id="S3.T2.11.11.12.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.11.1" class="ltx_text" style="font-size:80%;">46.9</span></td>
<td id="S3.T2.11.11.12.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.11.11.12.12.1" class="ltx_text" style="font-size:80%;">98.7</span></td>
</tr>
<tr id="S3.T2.11.11.13" class="ltx_tr">
<td id="S3.T2.11.11.13.1" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.1.1" class="ltx_text" style="font-size:80%;">Multitask-WLM</span></td>
<td id="S3.T2.11.11.13.2" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.2.1" class="ltx_text" style="font-size:80%;">2.5</span></td>
<td id="S3.T2.11.11.13.3" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.3.1" class="ltx_text" style="font-size:80%;">4.7</span></td>
<td id="S3.T2.11.11.13.4" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.4.1" class="ltx_text" style="font-size:80%;">6.8</span></td>
<td id="S3.T2.11.11.13.5" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.5.1" class="ltx_text" style="font-size:80%;">12.0</span></td>
<td id="S3.T2.11.11.13.6" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.6.1" class="ltx_text" style="font-size:80%;">90.3</span></td>
<td id="S3.T2.11.11.13.7" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.7.1" class="ltx_text" style="font-size:80%;">82.2</span></td>
<td id="S3.T2.11.11.13.8" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.8.1" class="ltx_text" style="font-size:80%;">25.9</span></td>
<td id="S3.T2.11.11.13.9" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.9.1" class="ltx_text" style="font-size:80%;">33.7</span></td>
<td id="S3.T2.11.11.13.10" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.10.1" class="ltx_text" style="font-size:80%;">46.6</span></td>
<td id="S3.T2.11.11.13.11" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.13.11.1" class="ltx_text" style="font-size:80%;">98.5</span></td>
</tr>
<tr id="S3.T2.11.11.14" class="ltx_tr">
<td id="S3.T2.11.11.14.1" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.1.1" class="ltx_text" style="font-size:80%;">Multitask-BRQ</span></td>
<td id="S3.T2.11.11.14.2" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.2.1" class="ltx_text" style="font-size:80%;">3.0</span></td>
<td id="S3.T2.11.11.14.3" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.3.1" class="ltx_text" style="font-size:80%;">6.7</span></td>
<td id="S3.T2.11.11.14.4" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.4.1" class="ltx_text" style="font-size:80%;">7.1</span></td>
<td id="S3.T2.11.11.14.5" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.5.1" class="ltx_text" style="font-size:80%;">11.8</span></td>
<td id="S3.T2.11.11.14.6" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.6.1" class="ltx_text" style="font-size:80%;">90.0</span></td>
<td id="S3.T2.11.11.14.7" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.7.1" class="ltx_text" style="font-size:80%;">83.4</span></td>
<td id="S3.T2.11.11.14.8" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.8.1" class="ltx_text" style="font-size:80%;">25.2</span></td>
<td id="S3.T2.11.11.14.9" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.9.1" class="ltx_text" style="font-size:80%;">32.5</span></td>
<td id="S3.T2.11.11.14.10" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.10.1" class="ltx_text" style="font-size:80%;">44.2</span></td>
<td id="S3.T2.11.11.14.11" class="ltx_td ltx_align_center"><span id="S3.T2.11.11.14.11.1" class="ltx_text" style="font-size:80%;">98.4</span></td>
</tr>
<tr id="S3.T2.11.11.11" class="ltx_tr">
<td id="S3.T2.11.11.11.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<span id="S3.T2.11.11.11.1.1" class="ltx_text" style="font-size:80%;">GT </span><math id="S3.T2.11.11.11.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S3.T2.11.11.11.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S3.T2.11.11.11.1.m1.1.1" xref="S3.T2.11.11.11.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.11.1.m1.1b"><ci id="S3.T2.11.11.11.1.m1.1.1.cmml" xref="S3.T2.11.11.11.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.11.1.m1.1c">\rightarrow</annotation></semantics></math><span id="S3.T2.11.11.11.1.2" class="ltx_text" style="font-size:80%;"> LLM</span>
</td>
<td id="S3.T2.11.11.11.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.2.1" class="ltx_text" style="font-size:80%;">LLM-FT</span></td>
<td id="S3.T2.11.11.11.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.3.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S3.T2.11.11.11.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.4.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S3.T2.11.11.11.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S3.T2.11.11.11.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S3.T2.11.11.11.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.7.1" class="ltx_text" style="font-size:80%;">94.2</span></td>
<td id="S3.T2.11.11.11.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.8.1" class="ltx_text" style="font-size:80%;">84.3</span></td>
<td id="S3.T2.11.11.11.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.9.1" class="ltx_text" style="font-size:80%;">27.2</span></td>
<td id="S3.T2.11.11.11.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.10.1" class="ltx_text" style="font-size:80%;">34.8</span></td>
<td id="S3.T2.11.11.11.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.11.1" class="ltx_text" style="font-size:80%;">70.3</span></td>
<td id="S3.T2.11.11.11.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.11.11.11.12.1" class="ltx_text" style="font-size:80%;">100</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Results of paralinguistic speech processing (PSP) tasks. All reported numbers are the value of the UAR metric.</figcaption>
<div id="S3.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:260.2pt;height:95.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.6pt,6.1pt) scale(0.886621676944146,0.886621676944146) ;">
<table id="S3.T3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T3.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></td>
<td id="S3.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T3.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Training</span></td>
<td id="S3.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ER</span></td>
<td id="S3.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ASC</span></td>
<td id="S3.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SC</span></td>
<td id="S3.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">AC</span></td>
<td id="S3.T3.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SNS</span></td>
</tr>
<tr id="S3.T3.1.1.2" class="ltx_tr">
<td id="S3.T3.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">MSP</span></td>
<td id="S3.T3.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">MSP</span></td>
<td id="S3.T3.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Fisher</span></td>
<td id="S3.T3.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">MCV</span></td>
<td id="S3.T3.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.2.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">VAD</span></td>
</tr>
<tr id="S3.T3.1.1.3" class="ltx_tr">
<td id="S3.T3.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.3.1.1" class="ltx_text" style="font-size:80%;">WavLM</span></td>
<td id="S3.T3.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.3.2.1" class="ltx_text" style="font-size:80%;">Task-FT</span></td>
<td id="S3.T3.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.3.3.1" class="ltx_text" style="font-size:80%;">60.3</span></td>
<td id="S3.T3.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.3.4.1" class="ltx_text" style="font-size:80%;">57.5</span></td>
<td id="S3.T3.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.3.5.1" class="ltx_text" style="font-size:80%;">98.5</span></td>
<td id="S3.T3.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.3.6.1" class="ltx_text" style="font-size:80%;">57.9</span></td>
<td id="S3.T3.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.3.7.1" class="ltx_text" style="font-size:80%;">96.3</span></td>
</tr>
<tr id="S3.T3.1.1.4" class="ltx_tr">
<td id="S3.T3.1.1.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="3"><span id="S3.T3.1.1.4.1.1" class="ltx_text" style="font-size:80%;"><span id="S3.T3.1.1.4.1.1.1" class="ltx_text"></span> <span id="S3.T3.1.1.4.1.1.2" class="ltx_text">
<span id="S3.T3.1.1.4.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.1.4.1.1.2.1.1" class="ltx_tr">
<span id="S3.T3.1.1.4.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">SpeechVerse</span></span>
<span id="S3.T3.1.1.4.1.1.2.1.2" class="ltx_tr">
<span id="S3.T3.1.1.4.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(E2E–SLM)</span></span>
</span></span> <span id="S3.T3.1.1.4.1.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.1.1.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.4.2.1" class="ltx_text" style="font-size:80%;">Task-FT</span></td>
<td id="S3.T3.1.1.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.4.3.1" class="ltx_text" style="font-size:80%;">64.6</span></td>
<td id="S3.T3.1.1.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.4.4.1" class="ltx_text" style="font-size:80%;">61.3</span></td>
<td id="S3.T3.1.1.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.4.5.1" class="ltx_text" style="font-size:80%;">99.6</span></td>
<td id="S3.T3.1.1.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.4.6.1" class="ltx_text" style="font-size:80%;">60.1</span></td>
<td id="S3.T3.1.1.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.4.7.1" class="ltx_text" style="font-size:80%;">96.9</span></td>
</tr>
<tr id="S3.T3.1.1.5" class="ltx_tr">
<td id="S3.T3.1.1.5.1" class="ltx_td ltx_align_center"><span id="S3.T3.1.1.5.1.1" class="ltx_text" style="font-size:80%;">Multitask-WLM</span></td>
<td id="S3.T3.1.1.5.2" class="ltx_td ltx_align_center"><span id="S3.T3.1.1.5.2.1" class="ltx_text" style="font-size:80%;">62.0</span></td>
<td id="S3.T3.1.1.5.3" class="ltx_td ltx_align_center"><span id="S3.T3.1.1.5.3.1" class="ltx_text" style="font-size:80%;">60.1</span></td>
<td id="S3.T3.1.1.5.4" class="ltx_td ltx_align_center"><span id="S3.T3.1.1.5.4.1" class="ltx_text" style="font-size:80%;">98.9</span></td>
<td id="S3.T3.1.1.5.5" class="ltx_td ltx_align_center"><span id="S3.T3.1.1.5.5.1" class="ltx_text" style="font-size:80%;">60.0</span></td>
<td id="S3.T3.1.1.5.6" class="ltx_td ltx_align_center"><span id="S3.T3.1.1.5.6.1" class="ltx_text" style="font-size:80%;">97.6</span></td>
</tr>
<tr id="S3.T3.1.1.6" class="ltx_tr">
<td id="S3.T3.1.1.6.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.1.1.6.1.1" class="ltx_text" style="font-size:80%;">Multitask-BRQ</span></td>
<td id="S3.T3.1.1.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.1.1.6.2.1" class="ltx_text" style="font-size:80%;">65.1</span></td>
<td id="S3.T3.1.1.6.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.1.1.6.3.1" class="ltx_text" style="font-size:80%;">64.1</span></td>
<td id="S3.T3.1.1.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.1.1.6.4.1" class="ltx_text" style="font-size:80%;">99.3</span></td>
<td id="S3.T3.1.1.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.1.1.6.5.1" class="ltx_text" style="font-size:80%;">60.4</span></td>
<td id="S3.T3.1.1.6.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.1.1.6.6.1" class="ltx_text" style="font-size:80%;">97.5</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Evaluation of SpeechVerse models</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluate end-to-end trained joint speech and language models (E2E-SLM) leveraging the SpeechVerse framework on 11 unique tasks across multiple domains and datasets. We first evaluate SpeechVerse’s core speech understanding capability through ASR benchmarks. We then evaluate more complex SLU tasks and paralinguistic speech tasks in Tables <a href="#S3.T2" title="Table 2 ‣ 3.2 Models ‣ 3 Experiments ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S3.T3" title="Table 3 ‣ 3.2 Models ‣ 3 Experiments ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> respectively.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Performance on ASR and SLU tasks</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">First, we evaluate the performance of SpeechVerse models on four public ASR benchmark datasets namely <span id="S4.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_italic">libri-test-clean</span>, <span id="S4.SS1.SSS1.p1.1.2" class="ltx_text ltx_font_italic">libri-test-other</span>, <span id="S4.SS1.SSS1.p1.1.3" class="ltx_text ltx_font_italic">Voxpopuli</span> and <span id="S4.SS1.SSS1.p1.1.4" class="ltx_text ltx_font_italic">CommonVoice</span>. The WER numbers for each of these datasets are reported in Table <a href="#S3.T2" title="Table 2 ‣ 3.2 Models ‣ 3 Experiments ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
SpeechVerse ASR in row 2 uses same model as task-specific pretrained ASR model (<span id="S4.SS1.SSS1.p1.1.5" class="ltx_text ltx_font_italic">Task-FT</span>) in row 3.
When comparing our task-specific pretrained ASR model, which also serves as the initialization for multi-task finetuning, to Whisper ASR, our model achieves slightly better performance on average. However, the WER increases in both multitask models with <span id="S4.SS1.SSS1.p1.1.6" class="ltx_text ltx_font_italic">Multitask-WLM</span> performing similarly to Whisper across three out of the four test sets. The lower performance of the multi-task SpeechVerse model compared to the task-specialized model is likely due to giving lower weight to ASR datasets when constructing batches during multi-task training. This was done to balance the performance across all tasks, since the data distribution is imbalanced between the different tasks.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.1" class="ltx_p">When it comes to SLU tasks, a frequent question posed is if an end-to-end model can outperform a cascaded pipeline that transcribes speech via ASR and then feeds it to a language model. To investigate this, we conducted experiments on five semantic understanding tasks using the same foundation models as SpeechVerse. The text foundation model was further fine-tuned on data from the five SLU tasks separately, as we found the zero-shot performance of Flan-T5 on these benchmark test sets to be quite poor. We also report performance when feeding ground-truth transcripts into the fine-tuned LLM, to provide upper bound results. On 4 of the 5 tasks, excluding Keyword Extraction, the end-to-end trained models outperform the cascaded pipeline. In particular, the more commonly used tasks like intent classification, slot labeling, and speech translation are performing better than the cascaded system, demonstrating the efficacy of our models trained using SpeechVerse. We also observed that SpeechVerse models on KWS task are outperforming cascaded pipeline by an absolute 10% in accuracy, while performing significantly behind on KWE task. Since the keyword search task requires an attention span focused on a specific word of interest, joint modeling helps improve accuracy by overcoming error propagation present in a cascaded pipeline. We also conducted an ablation study to determine if the KWE task benefits further from joint decoding of ASR transcription and keywords. We noticed an improvement in performance, closing the gap to the cascaded pipeline. The results from this study are detailed further in the sub-section <a href="#S4.SS3.SSS2" title="4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.2</span></a>. When comparing the multi-task models to the task-specific SpeechVerse models, there is a minor degradation in performance, but the difference is not substantial. Overall, the multitask model trained with either WavLM encoder or Best-RQ encoder outperformed cascaded systems in majority tasks.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Performance on paralinguistic tasks</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">The results in Table <a href="#S3.T3" title="Table 3 ‣ 3.2 Models ‣ 3 Experiments ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrate clear improvements in performance on various paralinguistic speech processing tasks when using multi-task learning compared to fine-tuning the WavLM model independently for each task. Specifically, the SpeechVerse model trained with multitask learning using Best-RQ audio encoder (Multitask-BRQ) achieves gains over the baseline WavLM model of 4.8% absolute on emotion recognition, 6.6% on audio sentiment classification, and 2.5% on accent classification. More modest gains are seen with the SpeechVerse model trained using multitask learning with WavLM encoder (Multitask-WLM). The unified representation’s adaptive combination of all encoder layers helps multitask BEST-RQ model improve diverse paralinguistic task performance. Overall, multi-task learning provides noticeable improvements in model generalization and effectiveness across a diverse set of speech tasks compared to task-specific fine-tuning of the baseline WavLM model. The results highlight the advantages of learning shared representations across related tasks using multi-task learning techniques.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Comparison against SOTA models</h4>

<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Comparison of SpeechVerse models to prior specialized SOTA models on five diverse tasks: automatic speech recognition (ASR), speech translation (ST), intent classification (IC), slot filling (SF), and emotion recognition (ER).</figcaption>
<div id="S4.T4.13" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:460.7pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-43.2pt,50.9pt) scale(0.818834761840593,0.818834761840593) ;">
<table id="S4.T4.13.13" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.13.13.14" class="ltx_tr">
<td id="S4.T4.13.13.14.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T4.13.13.14.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></td>
<td id="S4.T4.13.13.14.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T4.13.13.14.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dataset</span></td>
<td id="S4.T4.13.13.14.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T4.13.13.14.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></td>
<td id="S4.T4.13.13.14.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T4.13.13.14.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Performance</span></td>
</tr>
<tr id="S4.T4.13.13.15" class="ltx_tr">
<td id="S4.T4.13.13.15.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.13.13.15.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Metrics</span></td>
<td id="S4.T4.13.13.15.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.13.13.15.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Results</span></td>
</tr>
<tr id="S4.T4.1.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="12"><span id="S4.T4.1.1.1.2.1" class="ltx_text" style="font-size:80%;">ASR</span></td>
<td id="S4.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.1.1.1.3.1" class="ltx_text" style="font-size:80%;"><span id="S4.T4.1.1.1.3.1.1" class="ltx_text"></span> <span id="S4.T4.1.1.1.3.1.2" class="ltx_text">
<span id="S4.T4.1.1.1.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.1.1.3.1.2.1.1" class="ltx_tr">
<span id="S4.T4.1.1.1.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Librispeech</span></span>
<span id="S4.T4.1.1.1.3.1.2.1.2" class="ltx_tr">
<span id="S4.T4.1.1.1.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.1.3.1.2.1.2.1.1" class="ltx_text ltx_font_italic">test-clean</span> | <span id="S4.T4.1.1.1.3.1.2.1.2.1.2" class="ltx_text ltx_font_italic">test-other</span></span></span>
</span></span> <span id="S4.T4.1.1.1.3.1.3" class="ltx_text"></span></span></td>
<td id="S4.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.1.1.1.4.1" class="ltx_text" style="font-size:80%;">Whisper large-v2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.1.1.1.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx20" title="" class="ltx_ref">20</a><span id="S4.T4.1.1.1.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">WER <math id="S4.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T4.1.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.1.1.1.5.1" class="ltx_text"></span><span id="S4.T4.1.1.1.5.2" class="ltx_text" style="font-size:80%;"> </span><span id="S4.T4.1.1.1.5.3" class="ltx_text" style="font-size:80%;">
<span id="S4.T4.1.1.1.5.3.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.1.1.1.5.3.1.1" class="ltx_tr">
<span id="S4.T4.1.1.1.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">2.5 | 4.9</span></span>
</span></span><span id="S4.T4.1.1.1.5.4" class="ltx_text"></span><span id="S4.T4.1.1.1.5.5" class="ltx_text" style="font-size:80%;"></span>
</td>
</tr>
<tr id="S4.T4.13.13.16" class="ltx_tr">
<td id="S4.T4.13.13.16.1" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.16.1.1" class="ltx_text" style="font-size:80%;">SLM-FT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.13.13.16.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx17" title="" class="ltx_ref">17</a><span id="S4.T4.13.13.16.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.13.13.16.2" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.16.2.1" class="ltx_text"></span><span id="S4.T4.13.13.16.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="S4.T4.13.13.16.2.3" class="ltx_text" style="font-size:80%;">
<span id="S4.T4.13.13.16.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.13.13.16.2.3.1.1" class="ltx_tr">
<span id="S4.T4.13.13.16.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">2.6 | 5.0</span></span>
</span></span><span id="S4.T4.13.13.16.2.4" class="ltx_text"></span><span id="S4.T4.13.13.16.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
</tr>
<tr id="S4.T4.13.13.17" class="ltx_tr">
<td id="S4.T4.13.13.17.1" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.17.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Task-FT</span></td>
<td id="S4.T4.13.13.17.2" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.17.2.1" class="ltx_text"></span><span id="S4.T4.13.13.17.2.2" class="ltx_text" style="font-size:80%;"> </span><span id="S4.T4.13.13.17.2.3" class="ltx_text" style="font-size:80%;">
<span id="S4.T4.13.13.17.2.3.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.13.13.17.2.3.1.1" class="ltx_tr">
<span id="S4.T4.13.13.17.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.13.13.17.2.3.1.1.1.1" class="ltx_text ltx_font_bold">2.1</span> | <span id="S4.T4.13.13.17.2.3.1.1.1.2" class="ltx_text ltx_font_bold">4.4</span></span></span>
</span></span><span id="S4.T4.13.13.17.2.4" class="ltx_text"></span><span id="S4.T4.13.13.17.2.5" class="ltx_text" style="font-size:80%;"></span>
</td>
</tr>
<tr id="S4.T4.13.13.18" class="ltx_tr">
<td id="S4.T4.13.13.18.1" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.18.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Multitask-WLM</span></td>
<td id="S4.T4.13.13.18.2" class="ltx_td"></td>
<td id="S4.T4.13.13.18.3" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.18.3.1" class="ltx_text"></span><span id="S4.T4.13.13.18.3.2" class="ltx_text" style="font-size:80%;"> </span><span id="S4.T4.13.13.18.3.3" class="ltx_text" style="font-size:80%;">
<span id="S4.T4.13.13.18.3.3.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.13.13.18.3.3.1.1" class="ltx_tr">
<span id="S4.T4.13.13.18.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">2.5 | 4.7</span></span>
</span></span><span id="S4.T4.13.13.18.3.4" class="ltx_text"></span><span id="S4.T4.13.13.18.3.5" class="ltx_text" style="font-size:80%;"></span>
</td>
</tr>
<tr id="S4.T4.2.2.2" class="ltx_tr">
<td id="S4.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.2.2.2.2.1" class="ltx_text" style="font-size:80%;">VoxPopuli</span></td>
<td id="S4.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.2.2.2.3.1" class="ltx_text" style="font-size:80%;">Whisper large-v2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.2.2.2.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx20" title="" class="ltx_ref">20</a><span id="S4.T4.2.2.2.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.2.2.2.1.1" class="ltx_text" style="font-size:80%;">WER <math id="S4.T4.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.2.2.2.1.1.m1.1a"><mo stretchy="false" id="S4.T4.2.2.2.1.1.m1.1.1" xref="S4.T4.2.2.2.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.1.1.m1.1b"><ci id="S4.T4.2.2.2.1.1.m1.1.1.cmml" xref="S4.T4.2.2.2.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T4.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.2.2.2.4.1" class="ltx_text" style="font-size:80%;">7.0</span></td>
</tr>
<tr id="S4.T4.13.13.19" class="ltx_tr">
<td id="S4.T4.13.13.19.1" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.19.1.1" class="ltx_text" style="font-size:80%;">mSLAM-CTC </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.13.13.19.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx34" title="" class="ltx_ref">34</a><span id="S4.T4.13.13.19.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.13.13.19.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.19.2.1" class="ltx_text" style="font-size:80%;">7.0</span></td>
</tr>
<tr id="S4.T4.13.13.20" class="ltx_tr">
<td id="S4.T4.13.13.20.1" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.20.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Task-FT</span></td>
<td id="S4.T4.13.13.20.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.20.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">6.5</span></td>
</tr>
<tr id="S4.T4.13.13.21" class="ltx_tr">
<td id="S4.T4.13.13.21.1" class="ltx_td"></td>
<td id="S4.T4.13.13.21.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.21.2.1" class="ltx_text" style="font-size:80%;">SpeechVerse Multitask-WLM</span></td>
<td id="S4.T4.13.13.21.3" class="ltx_td"></td>
<td id="S4.T4.13.13.21.4" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.21.4.1" class="ltx_text" style="font-size:80%;">6.8</span></td>
</tr>
<tr id="S4.T4.3.3.3" class="ltx_tr">
<td id="S4.T4.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.3.3.3.2.1" class="ltx_text" style="font-size:80%;">CommonVoice 5.1</span></td>
<td id="S4.T4.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.3.3.3.3.1" class="ltx_text" style="font-size:80%;">Whisper large-v2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.3.3.3.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx20" title="" class="ltx_ref">20</a><span id="S4.T4.3.3.3.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.3.3.3.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.3.3.3.1.1" class="ltx_text" style="font-size:80%;">WER <math id="S4.T4.3.3.3.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.3.3.3.1.1.m1.1a"><mo stretchy="false" id="S4.T4.3.3.3.1.1.m1.1.1" xref="S4.T4.3.3.3.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.1.1.m1.1b"><ci id="S4.T4.3.3.3.1.1.m1.1.1.cmml" xref="S4.T4.3.3.3.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T4.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.3.3.3.4.1" class="ltx_text" style="font-size:80%;">8.2</span></td>
</tr>
<tr id="S4.T4.13.13.22" class="ltx_tr">
<td id="S4.T4.13.13.22.1" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.22.1.1" class="ltx_text" style="font-size:80%;">SLM-FT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.13.13.22.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx17" title="" class="ltx_ref">17</a><span id="S4.T4.13.13.22.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.13.13.22.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.22.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">7.5</span></td>
</tr>
<tr id="S4.T4.13.13.23" class="ltx_tr">
<td id="S4.T4.13.13.23.1" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.23.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Task-FT</span></td>
<td id="S4.T4.13.13.23.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.23.2.1" class="ltx_text" style="font-size:80%;">10.5</span></td>
</tr>
<tr id="S4.T4.13.13.24" class="ltx_tr">
<td id="S4.T4.13.13.24.1" class="ltx_td"></td>
<td id="S4.T4.13.13.24.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.24.2.1" class="ltx_text" style="font-size:80%;">SpeechVerse Multitask-WLM</span></td>
<td id="S4.T4.13.13.24.3" class="ltx_td"></td>
<td id="S4.T4.13.13.24.4" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.24.4.1" class="ltx_text" style="font-size:80%;">12.0</span></td>
</tr>
<tr id="S4.T4.7.7.7" class="ltx_tr">
<td id="S4.T4.7.7.7.5" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.7.7.7.5.1" class="ltx_text" style="font-size:80%;">ST</span></td>
<td id="S4.T4.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.6.6.6.3.3" class="ltx_text" style="font-size:80%;"><span id="S4.T4.6.6.6.3.3.4" class="ltx_text"></span> <span id="S4.T4.6.6.6.3.3.3" class="ltx_text">
<span id="S4.T4.6.6.6.3.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S4.T4.6.6.6.3.3.3.3.4" class="ltx_tr">
<span id="S4.T4.6.6.6.3.3.3.3.4.1" class="ltx_td ltx_nopad_r ltx_align_center">EuroParl</span></span>
<span id="S4.T4.6.6.6.3.3.3.3.3" class="ltx_tr">
<span id="S4.T4.6.6.6.3.3.3.3.3.3" class="ltx_td ltx_nopad_r ltx_align_center">EN<math id="S4.T4.4.4.4.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T4.4.4.4.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T4.4.4.4.1.1.1.1.1.1.m1.1.1" xref="S4.T4.4.4.4.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.1.1.1.1.1.1.m1.1b"><ci id="S4.T4.4.4.4.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.4.4.4.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>DE | EN<math id="S4.T4.5.5.5.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T4.5.5.5.2.2.2.2.2.2.m2.1a"><mo stretchy="false" id="S4.T4.5.5.5.2.2.2.2.2.2.m2.1.1" xref="S4.T4.5.5.5.2.2.2.2.2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.2.2.2.2.2.2.m2.1b"><ci id="S4.T4.5.5.5.2.2.2.2.2.2.m2.1.1.cmml" xref="S4.T4.5.5.5.2.2.2.2.2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.2.2.2.2.2.2.m2.1c">\rightarrow</annotation></semantics></math>FR | EN<math id="S4.T4.6.6.6.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T4.6.6.6.3.3.3.3.3.3.m3.1a"><mo stretchy="false" id="S4.T4.6.6.6.3.3.3.3.3.3.m3.1.1" xref="S4.T4.6.6.6.3.3.3.3.3.3.m3.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.6.3.3.3.3.3.3.m3.1b"><ci id="S4.T4.6.6.6.3.3.3.3.3.3.m3.1.1.cmml" xref="S4.T4.6.6.6.3.3.3.3.3.3.m3.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.6.3.3.3.3.3.3.m3.1c">\rightarrow</annotation></semantics></math>RO</span></span>
</span></span> <span id="S4.T4.6.6.6.3.3.5" class="ltx_text"></span></span></td>
<td id="S4.T4.7.7.7.6" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.7.7.7.6.1" class="ltx_text" style="font-size:80%;">SeamlessM4T 1.2B </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.7.7.7.6.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx35" title="" class="ltx_ref">35</a><span id="S4.T4.7.7.7.6.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.7.7.7.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.7.7.7.4.1" class="ltx_text" style="font-size:80%;">BLEU <math id="S4.T4.7.7.7.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.7.7.7.4.1.m1.1a"><mo stretchy="false" id="S4.T4.7.7.7.4.1.m1.1.1" xref="S4.T4.7.7.7.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.7.4.1.m1.1b"><ci id="S4.T4.7.7.7.4.1.m1.1.1.cmml" xref="S4.T4.7.7.7.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.7.4.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T4.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.7.7.7.7.1" class="ltx_text" style="font-size:80%;">27.8 | 30.3 | </span><span id="S4.T4.7.7.7.7.2" class="ltx_text ltx_font_bold" style="font-size:80%;">38.7</span>
</td>
</tr>
<tr id="S4.T4.13.13.25" class="ltx_tr">
<td id="S4.T4.13.13.25.1" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.25.1.1" class="ltx_text" style="font-size:80%;">XMEF </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.13.13.25.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx36" title="" class="ltx_ref">36</a><span id="S4.T4.13.13.25.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.13.13.25.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.25.2.1" class="ltx_text" style="font-size:80%;">22.5 | 30.0 | 32.3</span></td>
</tr>
<tr id="S4.T4.13.13.26" class="ltx_tr">
<td id="S4.T4.13.13.26.1" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.26.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Task-FT</span></td>
<td id="S4.T4.13.13.26.2" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.26.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">27.8</span><span id="S4.T4.13.13.26.2.2" class="ltx_text" style="font-size:80%;"> | </span><span id="S4.T4.13.13.26.2.3" class="ltx_text ltx_font_bold" style="font-size:80%;">35.7</span><span id="S4.T4.13.13.26.2.4" class="ltx_text" style="font-size:80%;"> | 32.2</span>
</td>
</tr>
<tr id="S4.T4.13.13.27" class="ltx_tr">
<td id="S4.T4.13.13.27.1" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.27.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Multitask-WLM</span></td>
<td id="S4.T4.13.13.27.2" class="ltx_td"></td>
<td id="S4.T4.13.13.27.3" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.27.3.1" class="ltx_text" style="font-size:80%;">25.9 | 33.7 | 30.1</span></td>
</tr>
<tr id="S4.T4.8.8.8" class="ltx_tr">
<td id="S4.T4.8.8.8.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.8.8.8.2.1" class="ltx_text" style="font-size:80%;">IC</span></td>
<td id="S4.T4.8.8.8.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.8.8.8.3.1" class="ltx_text" style="font-size:80%;">SLURP</span></td>
<td id="S4.T4.8.8.8.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.8.8.8.4.1" class="ltx_text" style="font-size:80%;">E2E-SLU CTI </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.8.8.8.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx37" title="" class="ltx_ref">37</a><span id="S4.T4.8.8.8.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.8.8.8.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.8.8.8.1.1" class="ltx_text" style="font-size:80%;">ACC <math id="S4.T4.8.8.8.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.8.8.8.1.1.m1.1a"><mo stretchy="false" id="S4.T4.8.8.8.1.1.m1.1.1" xref="S4.T4.8.8.8.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.8.1.1.m1.1b"><ci id="S4.T4.8.8.8.1.1.m1.1.1.cmml" xref="S4.T4.8.8.8.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.8.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T4.8.8.8.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.8.8.8.5.1" class="ltx_text" style="font-size:80%;">86.9</span></td>
</tr>
<tr id="S4.T4.13.13.28" class="ltx_tr">
<td id="S4.T4.13.13.28.1" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.28.1.1" class="ltx_text" style="font-size:80%;">Frozen-hbt-large </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.13.13.28.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx38" title="" class="ltx_ref">38</a><span id="S4.T4.13.13.28.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.13.13.28.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.28.2.1" class="ltx_text" style="font-size:80%;">74.4</span></td>
</tr>
<tr id="S4.T4.13.13.29" class="ltx_tr">
<td id="S4.T4.13.13.29.1" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.29.1.1" class="ltx_text" style="font-size:80%;">PF-hbt-large </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.13.13.29.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx38" title="" class="ltx_ref">38</a><span id="S4.T4.13.13.29.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.13.13.29.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.29.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">89.2</span></td>
</tr>
<tr id="S4.T4.9.9.9" class="ltx_tr">
<td id="S4.T4.9.9.9.1" class="ltx_td ltx_align_center">
<span id="S4.T4.9.9.9.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Task-FT</span><sup id="S4.T4.9.9.9.1.2" class="ltx_sup"><span id="S4.T4.9.9.9.1.2.1" class="ltx_text" style="font-size:80%;">∗</span></sup>
</td>
<td id="S4.T4.9.9.9.2" class="ltx_td ltx_align_center"><span id="S4.T4.9.9.9.2.1" class="ltx_text" style="font-size:80%;">84.6</span></td>
</tr>
<tr id="S4.T4.10.10.10" class="ltx_tr">
<td id="S4.T4.10.10.10.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.10.10.10.2.1" class="ltx_text" style="font-size:80%;">SF</span></td>
<td id="S4.T4.10.10.10.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.10.10.10.3.1" class="ltx_text" style="font-size:80%;">SLURP</span></td>
<td id="S4.T4.10.10.10.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.10.10.10.4.1" class="ltx_text" style="font-size:80%;">E2E-SLU CTI </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.10.10.10.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx37" title="" class="ltx_ref">37</a><span id="S4.T4.10.10.10.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.10.10.10.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S4.T4.10.10.10.1.1" class="ltx_text" style="font-size:80%;">SLU-F1 <math id="S4.T4.10.10.10.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.10.10.10.1.1.m1.1a"><mo stretchy="false" id="S4.T4.10.10.10.1.1.m1.1.1" xref="S4.T4.10.10.10.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.10.10.10.1.1.m1.1b"><ci id="S4.T4.10.10.10.1.1.m1.1.1.cmml" xref="S4.T4.10.10.10.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.10.10.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T4.10.10.10.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.10.10.10.5.1" class="ltx_text" style="font-size:80%;">74.7</span></td>
</tr>
<tr id="S4.T4.13.13.30" class="ltx_tr">
<td id="S4.T4.13.13.30.1" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.30.1.1" class="ltx_text" style="font-size:80%;">Frozen-hbt-large </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.13.13.30.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx38" title="" class="ltx_ref">38</a><span id="S4.T4.13.13.30.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.13.13.30.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.30.2.1" class="ltx_text" style="font-size:80%;">60.1</span></td>
</tr>
<tr id="S4.T4.13.13.31" class="ltx_tr">
<td id="S4.T4.13.13.31.1" class="ltx_td ltx_align_center">
<span id="S4.T4.13.13.31.1.1" class="ltx_text" style="font-size:80%;">PF-hbt-large </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.13.13.31.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx38" title="" class="ltx_ref">38</a><span id="S4.T4.13.13.31.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.13.13.31.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.31.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">78.9</span></td>
</tr>
<tr id="S4.T4.11.11.11" class="ltx_tr">
<td id="S4.T4.11.11.11.1" class="ltx_td ltx_align_center">
<span id="S4.T4.11.11.11.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Task-FT</span><sup id="S4.T4.11.11.11.1.2" class="ltx_sup"><span id="S4.T4.11.11.11.1.2.1" class="ltx_text" style="font-size:80%;">∗</span></sup>
</td>
<td id="S4.T4.11.11.11.2" class="ltx_td ltx_align_center"><span id="S4.T4.11.11.11.2.1" class="ltx_text" style="font-size:80%;">76.7</span></td>
</tr>
<tr id="S4.T4.12.12.12" class="ltx_tr">
<td id="S4.T4.12.12.12.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.12.12.12.2.1" class="ltx_text" style="font-size:80%;">ER</span></td>
<td id="S4.T4.12.12.12.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.12.12.12.3.1" class="ltx_text" style="font-size:80%;">MSP-Podcast 1.7</span></td>
<td id="S4.T4.12.12.12.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T4.12.12.12.4.1" class="ltx_text" style="font-size:80%;">w2v2-L-robust</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.12.12.12.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx39" title="" class="ltx_ref">39</a><span id="S4.T4.12.12.12.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T4.12.12.12.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T4.12.12.12.1.1" class="ltx_text" style="font-size:80%;">UAR <math id="S4.T4.12.12.12.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.12.12.12.1.1.m1.1a"><mo stretchy="false" id="S4.T4.12.12.12.1.1.m1.1.1" xref="S4.T4.12.12.12.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.12.12.12.1.1.m1.1b"><ci id="S4.T4.12.12.12.1.1.m1.1.1.cmml" xref="S4.T4.12.12.12.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.12.12.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T4.12.12.12.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.12.12.12.5.1" class="ltx_text" style="font-size:80%;">58</span></td>
</tr>
<tr id="S4.T4.13.13.32" class="ltx_tr">
<td id="S4.T4.13.13.32.1" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.32.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Task-FT</span></td>
<td id="S4.T4.13.13.32.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.32.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">66.7</span></td>
</tr>
<tr id="S4.T4.13.13.33" class="ltx_tr">
<td id="S4.T4.13.13.33.1" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.33.1.1" class="ltx_text" style="font-size:80%;">SpeechVerse Multitask-WLM</span></td>
<td id="S4.T4.13.13.33.2" class="ltx_td ltx_align_center"><span id="S4.T4.13.13.33.2.1" class="ltx_text" style="font-size:80%;">61.2</span></td>
</tr>
<tr id="S4.T4.13.13.13" class="ltx_tr">
<td id="S4.T4.13.13.13.1" class="ltx_td ltx_align_right ltx_border_tt" colspan="5">
<sup id="S4.T4.13.13.13.1.1" class="ltx_sup"><span id="S4.T4.13.13.13.1.1.1" class="ltx_text" style="font-size:50%;">∗</span></sup><span id="S4.T4.13.13.13.1.2" class="ltx_text" style="font-size:50%;">SpeechVerse Task-FT model was re-trained for SLURP by including <span id="S4.T4.13.13.13.1.2.1" class="ltx_text ltx_font_italic">all</span> intents and slots for comparison with other models.</span>
</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">Table <a href="#S4.T4" title="Table 4 ‣ 4.1.3 Comparison against SOTA models ‣ 4.1 Evaluation of SpeechVerse models ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> benchmarks SpeechVerse models against state-of-the-art (SOTA) models on five diverse tasks: automatic speech recognition (ASR), speech translation (ST), intent classification (IC), slot filling (SF), and emotion recognition (ER). Across these tasks, SpeechVerse demonstrates competitive or superior performance compared to prior specialized models. When comparing our task-specific pretrained ASR model, which also serves as the initialization for multi-task finetuning, to Whisper ASR, our model achieves slightly better performance on average. However, the multitask model (<span id="S4.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_italic">Multitask-WLM</span>) performed similarly to Whisper across three out of the four test sets. When evaluating on speech translation across three language pairs, the task-specialized SpeechVerse model surpassed SeamlessM4T on two pairs, while the multi-task SpeechVerse model achieved competitive performance compared to prior work on average. Both models did not perform well on English to Romanian pair. The overall performance of the SpeechVerse models on speech translation is heavily limited by the capabilities of the underlying language model FlanT5. The speech translation capabilities cannot exceed the translation quality provided by FlanT5 as the base language model. To evaluate SpeechVerse on spoken language understanding tasks like intent classification (IC) and slot filling (SF), we retrained the task-specialized SpeechVerse model by incorporating all 69 intents (both seen and unseen) as well as all slots. This allowed us to compare SpeechVerse to prior work on the complete intent and slot sets. Our SpeechVerse model achieved competitive performance to the previous SOTA (<span id="S4.SS1.SSS3.p1.1.2" class="ltx_text ltx_font_italic">PF-hbt-large</span>) on slot filling, but was significantly behind on intent classification with 5% lower absolute accuracy. However, SpeechVerse outperformed the same SOTA model (<span id="S4.SS1.SSS3.p1.1.3" class="ltx_text ltx_font_italic">Frozen-hbt-large</span>) by 10% when the encoder weights were frozen during fine-tuning. To further analyze the gap to prior state-of-the-art, we conducted an experiment allowing the audio encoder weights to be tunable during fine-tuning. This achieved 89.5% accuracy, matching the prior SOTA. This suggests the intent classification performance can overfit to the specific acoustic conditions of the SLURP dataset when full fine-tuning is performed. The SpeechVerse model that was trained end-to-end specifically for the task of emotion recognition achieved an 8% absolute improvement in unweighted average recall over the previous state-of-the-art model (<span id="S4.SS1.SSS3.p1.1.4" class="ltx_text ltx_font_italic">w2v2-L-robust</span>). In contrast, the multitask SpeechVerse model performed 3% better than the prior state-of-the-art. However, one key difference is that the previous SOTA work trained on the MSP-Podcast 1.7 dataset, while we used version 1.11 for training. The test set version remained the same between the two approaches. Overall, the SpeechVerse model demonstrated competitive performance compared to prior specialized models in some cases when evaluated across the various tasks.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Generalization Across Instructions</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We comprehensively study our Multitask-WLM model’s ability to generalize to diverse forms of unseen instructions. As a first, we try to accomplish seen tasks with differently worded instructions than those used for training. We create novel prompts for some of the training tasks and evaluate the robustness of the model to variations in the prompt. Next, we demonstrate the model’s potential to leverage the robust language understanding of the underlying LLM to generalize to completely new tasks that the model has not seen at all during multimodal finetuning.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Measuring robustness to prompt variations</h4>

<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Generalization to unseen prompts: The performance of each task is assessed on three different prompts, out of which, two are unseen during training.</figcaption>
<table id="S4.T5.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T5.4.5" class="ltx_tr">
<td id="S4.T5.4.5.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T5.4.5.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></td>
<td id="S4.T5.4.5.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T5.4.5.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dataset</span></td>
<td id="S4.T5.4.5.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T5.4.5.3.1" class="ltx_text" style="font-size:80%;"><span id="S4.T5.4.5.3.1.1" class="ltx_text"></span> <span id="S4.T5.4.5.3.1.2" class="ltx_text">
<span id="S4.T5.4.5.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T5.4.5.3.1.2.1.1" class="ltx_tr">
<span id="S4.T5.4.5.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.5.3.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Prompt</span></span></span>
<span id="S4.T5.4.5.3.1.2.1.2" class="ltx_tr">
<span id="S4.T5.4.5.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.5.3.1.2.1.2.1.1" class="ltx_text ltx_font_bold">(Unseen)</span></span></span>
</span></span> <span id="S4.T5.4.5.3.1.3" class="ltx_text"></span></span></td>
<td id="S4.T5.4.5.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T5.4.5.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Performance</span></td>
</tr>
<tr id="S4.T5.4.6" class="ltx_tr">
<td id="S4.T5.4.6.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.6.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Metric</span></td>
<td id="S4.T5.4.6.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.6.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Results</span></td>
</tr>
<tr id="S4.T5.1.1" class="ltx_tr">
<td id="S4.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T5.1.1.2.1" class="ltx_text" style="font-size:80%;">ASR</span></td>
<td id="S4.T5.1.1.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T5.1.1.3.1" class="ltx_text" style="font-size:80%;">Voxpopuli</span></td>
<td id="S4.T5.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.1.1.4.1" class="ltx_text" style="font-size:80%;">P1 (✗)</span></td>
<td id="S4.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T5.1.1.1.1" class="ltx_text" style="font-size:80%;">WER<math id="S4.T5.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T5.1.1.1.1.m1.1.1" xref="S4.T5.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.m1.1b"><ci id="S4.T5.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T5.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.1.1.5.1" class="ltx_text" style="font-size:80%;">6.8</span></td>
</tr>
<tr id="S4.T5.4.7" class="ltx_tr">
<td id="S4.T5.4.7.1" class="ltx_td ltx_align_center"><span id="S4.T5.4.7.1.1" class="ltx_text" style="font-size:80%;">P2 (✓)</span></td>
<td id="S4.T5.4.7.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.7.2.1" class="ltx_text" style="font-size:80%;">7.1</span></td>
</tr>
<tr id="S4.T5.4.8" class="ltx_tr">
<td id="S4.T5.4.8.1" class="ltx_td ltx_align_center"><span id="S4.T5.4.8.1.1" class="ltx_text" style="font-size:80%;">P3 (✓)</span></td>
<td id="S4.T5.4.8.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.8.2.1" class="ltx_text" style="font-size:80%;">6.8</span></td>
</tr>
<tr id="S4.T5.3.3" class="ltx_tr">
<td id="S4.T5.3.3.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T5.3.3.3.1" class="ltx_text" style="font-size:80%;">ST</span></td>
<td id="S4.T5.2.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T5.2.2.1.1" class="ltx_text" style="font-size:80%;"><span id="S4.T5.2.2.1.1.2" class="ltx_text"></span> <span id="S4.T5.2.2.1.1.1" class="ltx_text">
<span id="S4.T5.2.2.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T5.2.2.1.1.1.1.2" class="ltx_tr">
<span id="S4.T5.2.2.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">EuroParl</span></span>
<span id="S4.T5.2.2.1.1.1.1.1" class="ltx_tr">
<span id="S4.T5.2.2.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">EN<math id="S4.T5.2.2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T5.2.2.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T5.2.2.1.1.1.1.1.1.m1.1.1" xref="S4.T5.2.2.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.1.1.1.1.1.1.m1.1b"><ci id="S4.T5.2.2.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T5.2.2.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>FR</span></span>
</span></span> <span id="S4.T5.2.2.1.1.3" class="ltx_text"></span></span></td>
<td id="S4.T5.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.3.3.4.1" class="ltx_text" style="font-size:80%;">P1 (✗)</span></td>
<td id="S4.T5.3.3.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S4.T5.3.3.2.1" class="ltx_text" style="font-size:80%;">BLEU<math id="S4.T5.3.3.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.3.3.2.1.m1.1a"><mo stretchy="false" id="S4.T5.3.3.2.1.m1.1.1" xref="S4.T5.3.3.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.2.1.m1.1b"><ci id="S4.T5.3.3.2.1.m1.1.1.cmml" xref="S4.T5.3.3.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.2.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T5.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.3.3.5.1" class="ltx_text" style="font-size:80%;">33.7</span></td>
</tr>
<tr id="S4.T5.4.9" class="ltx_tr">
<td id="S4.T5.4.9.1" class="ltx_td ltx_align_center"><span id="S4.T5.4.9.1.1" class="ltx_text" style="font-size:80%;">P2 (✓)</span></td>
<td id="S4.T5.4.9.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.9.2.1" class="ltx_text" style="font-size:80%;">33.8</span></td>
</tr>
<tr id="S4.T5.4.10" class="ltx_tr">
<td id="S4.T5.4.10.1" class="ltx_td ltx_align_center"><span id="S4.T5.4.10.1.1" class="ltx_text" style="font-size:80%;">P3 (✓)</span></td>
<td id="S4.T5.4.10.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.10.2.1" class="ltx_text" style="font-size:80%;">33.5</span></td>
</tr>
<tr id="S4.T5.4.4" class="ltx_tr">
<td id="S4.T5.4.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="3"><span id="S4.T5.4.4.2.1" class="ltx_text" style="font-size:80%;">AC</span></td>
<td id="S4.T5.4.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="3"><span id="S4.T5.4.4.3.1" class="ltx_text" style="font-size:80%;">MCV</span></td>
<td id="S4.T5.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.4.4.1" class="ltx_text" style="font-size:80%;">P1 (✗)</span></td>
<td id="S4.T5.4.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="3"><span id="S4.T5.4.4.1.1" class="ltx_text" style="font-size:80%;">UAR<math id="S4.T5.4.4.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.4.4.1.1.m1.1a"><mo stretchy="false" id="S4.T5.4.4.1.1.m1.1.1" xref="S4.T5.4.4.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.1.1.m1.1b"><ci id="S4.T5.4.4.1.1.m1.1.1.cmml" xref="S4.T5.4.4.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T5.4.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.4.5.1" class="ltx_text" style="font-size:80%;">60.0</span></td>
</tr>
<tr id="S4.T5.4.11" class="ltx_tr">
<td id="S4.T5.4.11.1" class="ltx_td ltx_align_center"><span id="S4.T5.4.11.1.1" class="ltx_text" style="font-size:80%;">P2 (✓)</span></td>
<td id="S4.T5.4.11.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.11.2.1" class="ltx_text" style="font-size:80%;">60.7</span></td>
</tr>
<tr id="S4.T5.4.12" class="ltx_tr">
<td id="S4.T5.4.12.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.4.12.1.1" class="ltx_text" style="font-size:80%;">P3 (✓)</span></td>
<td id="S4.T5.4.12.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T5.4.12.2.1" class="ltx_text" style="font-size:80%;">60.6</span></td>
</tr>
</table>
</figure>
<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">To evaluate the effect of different prompts on the training task performance, we tested our MultiTask-WLM model with additional prompts for 3 different tasks: ASR, ST and AC. We test with three prompts per task, where one is directly taken from the set of prompts used during training, while two additional novel prompts are created by using a different wording and context. As showcased in the Table <a href="#S4.T5" title="Table 5 ‣ 4.2.1 Measuring robustness to prompt variations ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, the model showecased similar performance across prompts for each task. For the ASR task, we only see a minor variation of 0.3 in WER between seen and unseen prompts. Similarly for the ST and the AC task, the metric values deviates very little with the change in prompt. These small differences indicate that our model has generalized its core capabilities well and is not strongly dependent on the specific wording or context of the prompts. While prompt engineering remains important for optimal performance, these results suggest that the model has learned robust task-specific skills that transfer across the choice of prompts, at least for the tasks seen during training. For the tasks beyond those seen during training, we study the prompt design separately in a later subsection <a href="#S4.SS3.SSS1" title="4.3.1 Constrained Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3.1</span></a>.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Open-ended Instruction Following</h4>

<figure id="S4.SS2.SSS2.7" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Qualitative examples on open-ended tasks showcasing instruction-following ability of the model. DC: Domain Classification; QA: Question Answering; ST: Speech Translation</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.SS2.SSS2.7.7" class="ltx_inline-block ltx_align_left ltx_figure_panel ltx_transformed_outer" style="width:433.6pt;height:48648.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(140.5pt,-15762.8pt) scale(2.84112678010824,2.84112678010824) ;">
<table id="S4.SS2.SSS2.7.7.7" class="ltx_tabular ltx_align_middle">
<tr id="S4.SS2.SSS2.7.7.7.8" class="ltx_tr">
<td id="S4.SS2.SSS2.7.7.7.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.8.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.8.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.8.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.8.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Instruction</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.8.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.8.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Prediction</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.1.1.1.1" class="ltx_tr">
<td id="S4.SS2.SSS2.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;" colspan="2">
<img src="/html/2405.08295/assets/figures/audio-icon.png" id="S4.SS2.SSS2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"><span id="S4.SS2.SSS2.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;"> [Transcription: are you able to update the personal details on my account]</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.9" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.SS2.SSS2.7.7.7.9.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.9.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.9.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.9.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">Post Processing</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.9.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.9.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.9.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.9.2.1.1.1" class="ltx_text" style="font-size:80%;">Transcribe the preceding audio</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.9.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.9.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.9.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">are you able to update the personal details on my account</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.10" class="ltx_tr">
<td id="S4.SS2.SSS2.7.7.7.10.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.7.7.7.10.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.10.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.10.2.1.1.1" class="ltx_text" style="font-size:80%;">Transcribe the preceding audio with punctuations</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.10.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.10.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.10.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">are you able to update the personal details on my account?</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.11" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.SS2.SSS2.7.7.7.11.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.11.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.11.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.11.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">Response Generation</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.11.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.11.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.11.2.1.1.1" class="ltx_text" style="font-size:80%;">Generate a response to the user query in the preceding audio</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.11.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.11.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.11.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Sure, I can update the personal details on your account. Can you please tell me which account you are referring to and the specific details you would like me to update?</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.12" class="ltx_tr">
<td id="S4.SS2.SSS2.7.7.7.12.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.12.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.12.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">ST       <span id="S4.SS2.SSS2.7.7.7.12.1.1.1.1.1" class="ltx_text" style="font-size:63%;">unseen language</span></span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.12.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.12.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.12.2.1.1.1" class="ltx_text" style="font-size:80%;">Translate the preceding audio from english into spanish</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.12.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.12.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Puedes actualizar los datos personales de mi cuenta?</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.2.2.2.2" class="ltx_tr">
<td id="S4.SS2.SSS2.2.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.2.2.2.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;" colspan="2">
<img src="/html/2405.08295/assets/figures/audio-icon.png" id="S4.SS2.SSS2.2.2.2.2.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"><span id="S4.SS2.SSS2.2.2.2.2.1.1" class="ltx_text" style="font-size:80%;"> [Transcription: i need synthroid supply that will last me a month]</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.13" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.SS2.SSS2.7.7.7.13.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.13.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.13.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.13.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">Contextual Biasing</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.13.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.13.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.13.2.1.1.1" class="ltx_text" style="font-size:80%;">What is being said in the preceding audio?</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.13.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.13.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.13.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">i need <span id="S4.SS2.SSS2.7.7.7.13.3.1.1.1.1" class="ltx_text ltx_font_bold" style="color:#B31A1A;background-color:#ECECEC;">cynthroid</span> supply that will last me a month</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.14" class="ltx_tr">
<td id="S4.SS2.SSS2.7.7.7.14.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.7.7.7.14.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.14.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.14.2.1.1.1" class="ltx_text" style="font-size:80%;">What is being said in the preceding audio? Hints: thyroxine, synthroid, thyroid, hormones</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.14.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.14.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.14.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">i need synthroid supply that will last me a month</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.15" class="ltx_tr">
<td id="S4.SS2.SSS2.7.7.7.15.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.7.7.7.15.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:199.5pt;background-color:#ECECEC;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.15.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.15.2.1.1.1" class="ltx_text" style="font-size:80%;background-color:#ECECEC;">You are an AI assistant for a pharmaceutical company that specializes in thyroid treatment. Based on this context, what is being said in the preceding audio?</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.15.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:199.5pt;background-color:#ECECEC;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.15.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.15.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;background-color:#ECECEC;">i need synthroid supply that will last me a month</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.16" class="ltx_tr">
<td id="S4.SS2.SSS2.7.7.7.16.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.16.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.16.1.1.1.1" class="ltx_text" style="font-size:80%;">DC</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.16.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.16.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.16.2.1.1.1" class="ltx_text" style="font-size:80%;">Classify the domain of the user audio input into finance, healthcare, travel, internet or food</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.16.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.16.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.16.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">healthcare</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.17" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.SS2.SSS2.7.7.7.17.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.17.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.17.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.17.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">QA</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.17.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.17.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.17.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.17.2.1.1.1" class="ltx_text" style="font-size:80%;">What is the name of the medicine in the preceding audio?</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.17.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.17.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.17.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Synthroid</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.4.4.4.4" class="ltx_tr">
<td id="S4.SS2.SSS2.4.4.4.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.4.4.4.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;" colspan="2">
<img src="/html/2405.08295/assets/figures/audio-icon.png" id="S4.SS2.SSS2.3.3.3.3.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"><span id="S4.SS2.SSS2.4.4.4.4.2.1" class="ltx_text" style="font-size:80%;"> A 30-second audio generated using a text-to-speech system with contents of a news article</span><sup id="S4.SS2.SSS2.4.4.4.4.2.2" class="ltx_sup"><span id="S4.SS2.SSS2.4.4.4.4.2.2.1" class="ltx_text" style="font-size:80%;">∗</span></sup>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.18" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.SS2.SSS2.7.7.7.18.1" class="ltx_td ltx_nopad_r ltx_align_justify ltx_align_middle" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.18.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.18.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.18.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">Summar-</span></span>
<span id="S4.SS2.SSS2.7.7.7.18.1.1.2" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.18.1.1.2.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">ization</span><span id="S4.SS2.SSS2.7.7.7.18.1.1.2.2" class="ltx_text" style="font-size:80%;"></span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.18.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.18.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.18.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.18.2.1.1.1" class="ltx_text" style="font-size:80%;">Generate an abstractive summary for the content of the preceding audio in a single line</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.18.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.18.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.18.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.18.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Special counsel jack smith urges us supreme court to let former president donald trump’s election interference case proceed to trial without further delay.</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.19" class="ltx_tr">
<td id="S4.SS2.SSS2.7.7.7.19.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.7.7.7.19.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.19.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.19.2.1.1.1" class="ltx_text" style="font-size:80%;">Create a very crisp newspaper headline for the preceding audio</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.19.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.SS2.SSS2.7.7.7.19.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.19.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Former President Donald Trump Faces Election Interference Charges in Court</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.5.5.5.5" class="ltx_tr">
<td id="S4.SS2.SSS2.5.5.5.5.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.5.5.5.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;" colspan="2">
<img src="/html/2405.08295/assets/figures/audio-icon.png" id="S4.SS2.SSS2.5.5.5.5.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"><span id="S4.SS2.SSS2.5.5.5.5.1.1" class="ltx_text" style="font-size:80%;"> [Transcription: Can you explain the process of composting?]</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.20" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.SS2.SSS2.7.7.7.20.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.20.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.20.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.20.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">Factual QA</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.20.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.20.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.20.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.20.2.1.1.1" class="ltx_text" style="font-size:80%;">Generate a short factual answer to the question in the preceding audio</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.20.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.20.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.20.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.20.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">The process of composting is a gradual decomposition of organic matter into soil, with the goal being to decompose the organic matter into nutrients and water.</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.6.6.6.6" class="ltx_tr">
<td id="S4.SS2.SSS2.6.6.6.6.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.SS2.SSS2.6.6.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;" colspan="2">
<img src="/html/2405.08295/assets/figures/audio-icon.png" id="S4.SS2.SSS2.6.6.6.6.1.g1" class="ltx_graphics ltx_img_square" width="21" height="21" alt="[Uncaptioned image]"><span id="S4.SS2.SSS2.6.6.6.6.1.1" class="ltx_text" style="font-size:80%;"> [Transcription: Compose a descriptive paragraph about a childhood memory.]</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.21" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.SS2.SSS2.7.7.7.21.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.21.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.21.1.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.21.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">Creative QA</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.21.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.21.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.21.2.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.21.2.1.1.1" class="ltx_text" style="font-size:80%;">Generate a short creative answer to the question in the preceding audio</span></span>
</span>
</td>
<td id="S4.SS2.SSS2.7.7.7.21.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:199.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.SS2.SSS2.7.7.7.21.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.SS2.SSS2.7.7.7.21.3.1.1" class="ltx_p"><span id="S4.SS2.SSS2.7.7.7.21.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">A child’s imagination is a powerful tool for creating memorable images, and one of my favorite memories is the creation of a dollhouse complete with all the pieces.</span></span>
</span>
</td>
</tr>
<tr id="S4.SS2.SSS2.7.7.7.7" class="ltx_tr">
<td id="S4.SS2.SSS2.7.7.7.7.1" class="ltx_td ltx_align_right ltx_align_middle ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" colspan="3">
<sup id="S4.SS2.SSS2.7.7.7.7.1.1" class="ltx_sup"><span id="S4.SS2.SSS2.7.7.7.7.1.1.1" class="ltx_text" style="font-size:50%;">∗</span></sup><a target="_blank" href="https://apnews.com/article/trump-special-counsel-election-interference-january-6-c2dcc83e56a541804d4785f6bb6cd45c" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:50%;">https://apnews.com/article/trump-special-counsel-election-interference-january-6-c2dcc83e56a541804d4785f6bb6cd45c</a>
</td>
</tr>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.SS2.SSS2.7.8" class="ltx_p ltx_figure_panel"><span id="S4.SS2.SSS2.7.8.1" class="ltx_text" style="font-size:80%;">To study the model’s ability to understand open-ended text-based as well as speech-based instructions, we prompted the model with several unrestricted creative requests that were not a part of our training curriculum.
We enumerate several such examples in the Table <a href="#S4.SS2.SSS2" title="4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2.2</span></a>. In many of these examples, the model is required to exhibit
profound comprehension of both the spoken and written directives to successfully execute the task.
For example, in the Creative QA task, the model has to understand the spoken request as well as the instruction prompt
in order to generate a related response.
In the Summarization task, the model has to correctly surmise the spoken content to generate a summary.
In the Contextual Biasing task, we observe that the model is even able to correct its own output when provided with hints.
The robust responses of the multi-task model with such a distributional shift in the input from the training data
demonstrates the adaptability of its core instruction following skills. Rather than overfitting to the training domain, the multi-task learning approach enables the model to learn more versatile capabilities in instruction comprehension and execution that better transfer to new contexts. We provide some quantitative results on unseen tasks and labels in the next section.</span></p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<section id="S4.SS3" class="ltx_subsection ltx_figure_panel">
<h3 class="ltx_title ltx_title_subsection" style="font-size:80%;">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Strategies for Improving Performance</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text" style="font-size:80%;">We further evaluate strategies to improve the multi-task model’s performance specially for unseen tasks and class labels. First, we leverage contrained decoding </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS3.p1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx40" title="" class="ltx_ref">40</a><span id="S4.SS3.p1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S4.SS3.p1.1.4" class="ltx_text" style="font-size:80%;"> for tasks that have a pre-defined set of finite outcomes. Next, we also study joint decoding of the output of the task with the ASR hypotheses of the audio for certain complex spoken language understanding tasks.</span></p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 7: </span>Results on three unseen tasks with and without constrained decoding (CD). We compare the settings wherein the instruction prompt only contained the class labels v/s when descriptions were provided for each class label in the prompt.</figcaption>
<div id="S4.T7.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:159.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(16.4pt,-7.5pt) scale(1.10470423942738,1.10470423942738) ;">
<table id="S4.T7.3.3" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.3.3.4" class="ltx_tr">
<td id="S4.T7.3.3.4.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" rowspan="3"><span id="S4.T7.3.3.4.1.1" class="ltx_text" style="font-size:80%;">
<span id="S4.T7.3.3.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T7.3.3.4.1.1.1.1" class="ltx_tr">
<span id="S4.T7.3.3.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;">Class Label</span></span>
<span id="S4.T7.3.3.4.1.1.1.2" class="ltx_tr">
<span id="S4.T7.3.3.4.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;">Description</span></span>
</span></span></td>
<td id="S4.T7.3.3.4.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" rowspan="3"><span id="S4.T7.3.3.4.2.1" class="ltx_text" style="font-size:80%;">
<span id="S4.T7.3.3.4.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T7.3.3.4.2.1.1.1" class="ltx_tr">
<span id="S4.T7.3.3.4.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;">CD</span></span>
</span></span></td>
<td id="S4.T7.3.3.4.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" colspan="2"><span id="S4.T7.3.3.4.3.1" class="ltx_text" style="font-size:80%;">IC</span></td>
<td id="S4.T7.3.3.4.4" class="ltx_td ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.4.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" colspan="2"><span id="S4.T7.3.3.4.5.1" class="ltx_text" style="font-size:80%;">SL</span></td>
<td id="S4.T7.3.3.4.6" class="ltx_td ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.4.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.4.7.1" class="ltx_text" style="font-size:80%;">DC</span></td>
</tr>
<tr id="S4.T7.2.2.2" class="ltx_tr">
<td id="S4.T7.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T7.1.1.1.1.1" class="ltx_text" style="font-size:80%;">SLURP</span><sup id="S4.T7.1.1.1.1.2" class="ltx_sup"><span id="S4.T7.1.1.1.1.2.1" class="ltx_text" style="font-size:80%;">∗</span></sup>
</td>
<td id="S4.T7.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.2.2.2.3.1" class="ltx_text" style="font-size:80%;">SNIPS</span></td>
<td id="S4.T7.2.2.2.4" class="ltx_td" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" colspan="2">
<span id="S4.T7.2.2.2.2.1" class="ltx_text" style="font-size:80%;">SLURP</span><sup id="S4.T7.2.2.2.2.2" class="ltx_sup"><span id="S4.T7.2.2.2.2.2.1" class="ltx_text" style="font-size:80%;">∗</span></sup>
</td>
<td id="S4.T7.2.2.2.5" class="ltx_td" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.2.2.2.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.2.2.2.6.1" class="ltx_text" style="font-size:80%;">Internal</span></td>
</tr>
<tr id="S4.T7.3.3.5" class="ltx_tr">
<td id="S4.T7.3.3.5.1" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.5.1.1" class="ltx_text" style="font-size:80%;">(ACC)</span></td>
<td id="S4.T7.3.3.5.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.5.2.1" class="ltx_text" style="font-size:80%;">(ACC)</span></td>
<td id="S4.T7.3.3.5.3" class="ltx_td" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.5.4" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.5.4.1" class="ltx_text" style="font-size:80%;">(SD-F1)</span></td>
<td id="S4.T7.3.3.5.5" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.5.5.1" class="ltx_text" style="font-size:80%;">(SLU-F1)</span></td>
<td id="S4.T7.3.3.5.6" class="ltx_td" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.5.7" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.5.7.1" class="ltx_text" style="font-size:80%;">(ACC)</span></td>
</tr>
<tr id="S4.T7.3.3.6" class="ltx_tr">
<td id="S4.T7.3.3.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T7.3.3.6.1.1" class="ltx_text" style="font-size:80%;">No</span></td>
<td id="S4.T7.3.3.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.6.2.1" class="ltx_text" style="font-size:80%;">No</span></td>
<td id="S4.T7.3.3.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.6.3.1" class="ltx_text" style="font-size:80%;">51.7</span></td>
<td id="S4.T7.3.3.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.6.4.1" class="ltx_text" style="font-size:80%;">54.9</span></td>
<td id="S4.T7.3.3.6.5" class="ltx_td ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.6.6.1" class="ltx_text" style="font-size:80%;">73.12</span></td>
<td id="S4.T7.3.3.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.6.7.1" class="ltx_text" style="font-size:80%;">46.45</span></td>
<td id="S4.T7.3.3.6.8" class="ltx_td ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.6.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.6.9.1" class="ltx_text" style="font-size:80%;">56.9</span></td>
</tr>
<tr id="S4.T7.3.3.7" class="ltx_tr">
<td id="S4.T7.3.3.7.1" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.7.1.1" class="ltx_text" style="font-size:80%;">Yes</span></td>
<td id="S4.T7.3.3.7.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.7.2.1" class="ltx_text" style="font-size:80%;">68.8</span></td>
<td id="S4.T7.3.3.7.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.7.3.1" class="ltx_text" style="font-size:80%;">68.9</span></td>
<td id="S4.T7.3.3.7.4" class="ltx_td" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.7.5" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.7.5.1" class="ltx_text" style="font-size:80%;">73.38</span></td>
<td id="S4.T7.3.3.7.6" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.7.6.1" class="ltx_text" style="font-size:80%;">46.49</span></td>
<td id="S4.T7.3.3.7.7" class="ltx_td" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.7.8" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.7.8.1" class="ltx_text" style="font-size:80%;">59.0</span></td>
</tr>
<tr id="S4.T7.3.3.8" class="ltx_tr">
<td id="S4.T7.3.3.8.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T7.3.3.8.1.1" class="ltx_text" style="font-size:80%;">Yes</span></td>
<td id="S4.T7.3.3.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.8.2.1" class="ltx_text" style="font-size:80%;">No</span></td>
<td id="S4.T7.3.3.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.8.3.1" class="ltx_text" style="font-size:80%;">47.7</span></td>
<td id="S4.T7.3.3.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.8.4.1" class="ltx_text" style="font-size:80%;">61.0</span></td>
<td id="S4.T7.3.3.8.5" class="ltx_td ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.8.6.1" class="ltx_text" style="font-size:80%;">69.79</span></td>
<td id="S4.T7.3.3.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.8.7.1" class="ltx_text" style="font-size:80%;">47.34</span></td>
<td id="S4.T7.3.3.8.8" class="ltx_td ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.8.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.8.9.1" class="ltx_text" style="font-size:80%;">44.0</span></td>
</tr>
<tr id="S4.T7.3.3.9" class="ltx_tr">
<td id="S4.T7.3.3.9.1" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.9.1.1" class="ltx_text" style="font-size:80%;">Yes</span></td>
<td id="S4.T7.3.3.9.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.9.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.2</span></td>
<td id="S4.T7.3.3.9.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.9.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">75.9</span></td>
<td id="S4.T7.3.3.9.4" class="ltx_td" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.9.5" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.9.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">77.47</span></td>
<td id="S4.T7.3.3.9.6" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.9.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">48.45</span></td>
<td id="S4.T7.3.3.9.7" class="ltx_td" style="padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T7.3.3.9.8" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T7.3.3.9.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">62.0</span></td>
</tr>
<tr id="S4.T7.3.3.3" class="ltx_tr">
<td id="S4.T7.3.3.3.1" class="ltx_td ltx_align_right ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" colspan="9">
<sup id="S4.T7.3.3.3.1.1" class="ltx_sup"><span id="S4.T7.3.3.3.1.1.1" class="ltx_text" style="font-size:70%;">∗</span></sup><span id="S4.T7.3.3.3.1.2" class="ltx_text" style="font-size:70%;">This is a subset of SLURP labels not seen during training</span>
</td>
</tr>
</table>
</span></div>
</figure>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:80%;">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Constrained Decoding</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p"><span id="S4.SS3.SSS1.p1.1.1" class="ltx_text" style="font-size:80%;">The work in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS3.SSS1.p1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx40" title="" class="ltx_ref">40</a><span id="S4.SS3.SSS1.p1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S4.SS3.SSS1.p1.1.4" class="ltx_text" style="font-size:80%;"> introduced a model-agnostic technique to enforce domain-specific knowledge and constraints during text generation. Building on this prior approach, we have explored applying decoding constraints to the SpeechVerse model to improve generalization to unseen speech classification tasks. Rather than allowing the model to generate freely in response to a prompt, the decoding is restricted to output from a predefined vocabulary of class names. For example, in an intent classification task, the model would be constrained to only generate intent labels such as “</span><span id="S4.SS3.SSS1.p1.1.5" class="ltx_text ltx_font_italic" style="font-size:80%;">play_radio</span><span id="S4.SS3.SSS1.p1.1.6" class="ltx_text" style="font-size:80%;">”, “</span><span id="S4.SS3.SSS1.p1.1.7" class="ltx_text ltx_font_italic" style="font-size:80%;">datetime_query</span><span id="S4.SS3.SSS1.p1.1.8" class="ltx_text" style="font-size:80%;">” or “</span><span id="S4.SS3.SSS1.p1.1.9" class="ltx_text ltx_font_italic" style="font-size:80%;">cooking_recipe</span><span id="S4.SS3.SSS1.p1.1.10" class="ltx_text" style="font-size:80%;">”. By limiting the output space, the model is more likely to produce the desired class label rather than unrelated text.</span></p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p id="S4.SS3.SSS1.p2.1" class="ltx_p"><span id="S4.SS3.SSS1.p2.1.1" class="ltx_text" style="font-size:80%;">We meticulously benchmark the model’s performance on
close-ended tasks, such as a diverse set of classification tasks,
that have a pre-defined set of finite class labels.
To understand the influence of the instruction prompts,
we divide this study into two parts:
(1) where we only provide the class labels in the prompt,
and (2) where we provide an accompanying description of each class label in the prompt.
We ensure that none of these class labels were seen during training,
and hence these are all novel tasks for the model.
Further, we evaluate the efficacy of employing constrained decoding
in each of these two parts,
as the class labels are known to us beforehand.
Note here that the SL task can be considered a harder task
as the model has to correctly classify a slot label
as well as identify the corresponding slot value from the speech.
Hence, we report both, the SLU-F1 metric as well as the SD-F1 (Slot label Detection) metric for SL.
The results of this study are presented in Table </span><a href="#S4.T7" title="Table 7 ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref" style="font-size:80%;"><span class="ltx_text ltx_ref_tag">7</span></a><span id="S4.SS3.SSS1.p2.1.2" class="ltx_text" style="font-size:80%;">.</span></p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p id="S4.SS3.SSS1.p3.1" class="ltx_p"><span id="S4.SS3.SSS1.p3.1.1" class="ltx_text" style="font-size:80%;">We observe that including descriptions in the prompt has inconsistent results,
which can be attributed to the quality and subjectivity of the descriptions provided in the prompt,
especially as these descriptions were not seen during training.
However, we see that constrained decoding improves upon the results in all cases,
and most significant gains are observed only when descriptions are provided
with constrained decoding.
This indicates that providing descriptions
indeed steers the model towards
better comprehension of the task semantics,
but only constrained decoding is able
to objectively prune the noise introduced
by any prompt bias.
This phenomena is further revealed in the SL task,
where the SLU-F1 has a lower absolute value compared to SD-F1, as
the SLU-F1 metric incorporates both slot label and slot value,
whereas constrained decoding can only be applied to the slot label
(hence the higher SD-F1). Similarly, for a completely unseen task of Domain Classification (DC), where the goal is to classify the content of the audio into five domains like healthcare, technology etc, we observe a strong performance of 62% accuracy with constrained decoding.</span></p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:80%;">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Joint Decoding</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p"><span id="S4.SS3.SSS2.p1.1.1" class="ltx_text" style="font-size:80%;">Certain SLU tasks require the model to understand the semantics of the audio or perform a operation on the content of the audio. For example, KWE task is about extracting important keywords from the ASR hypothesis of the audio.
Since this is a multi-step reasoning process for the model, we take inspiration from the existing work </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS3.SSS2.p1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx41" title="" class="ltx_ref">41</a><span id="S4.SS3.SSS2.p1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S4.SS3.SSS2.p1.1.4" class="ltx_text" style="font-size:80%;"> on Chain-of-Thought (CoT) prompting. We train our model to first decode the ASR hypothesis of the audio, followed by the output of the task. The prompts used for the joint elicitation of ASR hypothesis and the task output are described in the Table </span><a href="#S4.T8" title="Table 8 ‣ 4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref" style="font-size:80%;"><span class="ltx_text ltx_ref_tag">8</span></a><span id="S4.SS3.SSS2.p1.1.5" class="ltx_text" style="font-size:80%;">. For a representative set of SLU tasks including IC, KWE and ER, we re-train the Task-FT models by adding a small portion of such multi-step examples along with single-task examples. We compare the results with and without joint decoding with ASR hypothesis in the Table </span><a href="#S4.T9" title="Table 9 ‣ 4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref" style="font-size:80%;"><span class="ltx_text ltx_ref_tag">9</span></a><span id="S4.SS3.SSS2.p1.1.6" class="ltx_text" style="font-size:80%;">.</span></p>
</div>
<figure id="S4.T8" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 8: </span>Example prompt for elicitation of compound goals for KWE and ER task</figcaption>
<table id="S4.T8.3" class="ltx_tabular ltx_align_middle">
<tr id="S4.T8.3.1" class="ltx_tr">
<td id="S4.T8.3.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.1.1.1.1" class="ltx_p"><span id="S4.T8.3.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></span>
</span>
</td>
<td id="S4.T8.3.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.1.2.1.1" class="ltx_p"><span id="S4.T8.3.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Instruction</span></span>
</span>
</td>
<td id="S4.T8.3.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.1.3.1.1" class="ltx_p"><span id="S4.T8.3.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Prediction</span></span>
</span>
</td>
</tr>
<tr id="S4.T8.3.2" class="ltx_tr">
<td id="S4.T8.3.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.2.1.1.1" class="ltx_p"><span id="S4.T8.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">KWE</span></span>
</span>
</td>
<td id="S4.T8.3.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.2.2.1.1" class="ltx_p"><span id="S4.T8.3.2.2.1.1.1" class="ltx_text" style="font-size:80%;">Perform the following audio-based tasks in the order as described.</span></span>
</span>
</td>
<td id="S4.T8.3.2.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.3" class="ltx_tr">
<td id="S4.T8.3.3.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.3.1.1.1" class="ltx_p"><span id="S4.T8.3.3.1.1.1.1" class="ltx_text" style="font-size:80%;">=== Task: ASR ===</span></span>
</span>
</td>
<td id="S4.T8.3.3.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T8.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.4" class="ltx_tr">
<td id="S4.T8.3.4.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.4.1.1.1" class="ltx_p"><span id="S4.T8.3.4.1.1.1.1" class="ltx_text" style="font-size:80%;">Perform speech recognition using the preceding audio.</span></span>
</span>
</td>
<td id="S4.T8.3.4.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T8.3.4.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.5" class="ltx_tr">
<td id="S4.T8.3.5.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.5.1.1.1" class="ltx_p"><span id="S4.T8.3.5.1.1.1.1" class="ltx_text" style="font-size:80%;">=== Task: KWE ===</span></span>
</span>
</td>
<td id="S4.T8.3.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T8.3.5.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.6" class="ltx_tr">
<td id="S4.T8.3.6.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.6.1.1.1" class="ltx_p"><span id="S4.T8.3.6.1.1.1.1" class="ltx_text" style="font-size:80%;">Identify significant keywords in the provided audio.</span></span>
</span>
</td>
<td id="S4.T8.3.6.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T8.3.6.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.7" class="ltx_tr">
<td id="S4.T8.3.7.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.7.1.1.1" class="ltx_p"><span id="S4.T8.3.7.1.1.1.1" class="ltx_text" style="font-size:80%;">Make sure to format the output as "ASR: … | KWE: … |"</span></span>
</span>
</td>
<td id="S4.T8.3.7.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.7.2.1.1" class="ltx_p"><span id="S4.T8.3.7.2.1.1.1" class="ltx_text" style="font-size:80%;">ASR: paris is the capital of france | KWE: paris, france |</span></span>
</span>
</td>
<td id="S4.T8.3.7.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.8" class="ltx_tr">
<td id="S4.T8.3.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.8.1.1.1" class="ltx_p"><span id="S4.T8.3.8.1.1.1.1" class="ltx_text" style="font-size:80%;">ER</span></span>
</span>
</td>
<td id="S4.T8.3.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.8.2.1.1" class="ltx_p"><span id="S4.T8.3.8.2.1.1.1" class="ltx_text" style="font-size:80%;">Perform the following audio-based tasks in the order as described.</span></span>
</span>
</td>
<td id="S4.T8.3.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.9" class="ltx_tr">
<td id="S4.T8.3.9.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.9.1.1.1" class="ltx_p"><span id="S4.T8.3.9.1.1.1.1" class="ltx_text" style="font-size:80%;">=== Task: ASR ===</span></span>
</span>
</td>
<td id="S4.T8.3.9.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T8.3.9.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.10" class="ltx_tr">
<td id="S4.T8.3.10.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.10.1.1.1" class="ltx_p"><span id="S4.T8.3.10.1.1.1.1" class="ltx_text" style="font-size:80%;">What is being said in the audio?</span></span>
</span>
</td>
<td id="S4.T8.3.10.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T8.3.10.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.11" class="ltx_tr">
<td id="S4.T8.3.11.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.11.1.1.1" class="ltx_p"><span id="S4.T8.3.11.1.1.1.1" class="ltx_text" style="font-size:80%;">=== Task: Emotion ===</span></span>
</span>
</td>
<td id="S4.T8.3.11.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T8.3.11.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.12" class="ltx_tr">
<td id="S4.T8.3.12.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.12.1.1.1" class="ltx_p"><span id="S4.T8.3.12.1.1.1.1" class="ltx_text" style="font-size:80%;">Classify the tone of the speaker as happy, sad, angry or neutral</span></span>
</span>
</td>
<td id="S4.T8.3.12.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T8.3.12.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T8.3.13" class="ltx_tr">
<td id="S4.T8.3.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:17.3pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.13.1.1.1" class="ltx_p"><span id="S4.T8.3.13.1.1.1.1" class="ltx_text" style="font-size:80%;">Make sure to format the output as "ASR: … | Emotion: … |"</span></span>
</span>
</td>
<td id="S4.T8.3.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:255.8pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T8.3.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.13.2.1.1" class="ltx_p"><span id="S4.T8.3.13.2.1.1.1" class="ltx_text" style="font-size:80%;">ASR: can you shut up for a while | Emotion: angry |</span></span>
</span>
</td>
<td id="S4.T8.3.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:121.4pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
</table>
</figure>
<figure id="S4.T9" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 9: </span>Results on compound goal experiments when decoding 
performed with (w/) and without (w/o) ASR.</figcaption>
<table id="S4.T9.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T9.3.4" class="ltx_tr">
<td id="S4.T9.3.4.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T9.3.4.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></td>
<td id="S4.T9.3.4.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T9.3.4.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dataset</span></td>
<td id="S4.T9.3.4.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T9.3.4.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Metric</span></td>
<td id="S4.T9.3.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;" colspan="2">
<span id="S4.T9.3.4.4.1" class="ltx_text"></span><span id="S4.T9.3.4.4.2" class="ltx_text" style="font-size:80%;"> </span><span id="S4.T9.3.4.4.3" class="ltx_text" style="font-size:80%;">
<span id="S4.T9.3.4.4.3.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T9.3.4.4.3.1.1" class="ltx_tr">
<span id="S4.T9.3.4.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.4.4.3.1.1.1.1" class="ltx_text ltx_font_bold">Joint Decoding</span></span></span>
</span></span><span id="S4.T9.3.4.4.4" class="ltx_text"></span><span id="S4.T9.3.4.4.5" class="ltx_text" style="font-size:80%;"></span>
</td>
</tr>
<tr id="S4.T9.3.5" class="ltx_tr">
<td id="S4.T9.3.5.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.5.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">w/o</span></td>
<td id="S4.T9.3.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.5.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">w/</span></td>
</tr>
<tr id="S4.T9.1.1" class="ltx_tr">
<td id="S4.T9.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.1.1.2.1" class="ltx_text" style="font-size:80%;">IC</span></td>
<td id="S4.T9.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.1.1.3.1" class="ltx_text" style="font-size:80%;">SLURP</span></td>
<td id="S4.T9.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.1.1.1.1" class="ltx_text" style="font-size:80%;">ACC<math id="S4.T9.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T9.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T9.1.1.1.1.m1.1.1" xref="S4.T9.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T9.1.1.1.1.m1.1b"><ci id="S4.T9.1.1.1.1.m1.1.1.cmml" xref="S4.T9.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T9.1.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.1.1.4.1" class="ltx_text" style="font-size:80%;">90.4</span></td>
<td id="S4.T9.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.1.1.5.1" class="ltx_text" style="font-size:80%;">92.2</span></td>
</tr>
<tr id="S4.T9.2.2" class="ltx_tr">
<td id="S4.T9.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T9.2.2.2.1" class="ltx_text" style="font-size:80%;">KWE</span></td>
<td id="S4.T9.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.2.2.3.1" class="ltx_text" style="font-size:80%;">MCV</span></td>
<td id="S4.T9.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;" rowspan="2"><span id="S4.T9.2.2.1.1" class="ltx_text" style="font-size:80%;">F1<math id="S4.T9.2.2.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T9.2.2.1.1.m1.1a"><mo stretchy="false" id="S4.T9.2.2.1.1.m1.1.1" xref="S4.T9.2.2.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T9.2.2.1.1.m1.1b"><ci id="S4.T9.2.2.1.1.m1.1.1.cmml" xref="S4.T9.2.2.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.2.2.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T9.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.2.2.4.1" class="ltx_text" style="font-size:80%;">46.9</span></td>
<td id="S4.T9.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.2.2.5.1" class="ltx_text" style="font-size:80%;">49.5</span></td>
</tr>
<tr id="S4.T9.3.6" class="ltx_tr">
<td id="S4.T9.3.6.1" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.6.1.1" class="ltx_text" style="font-size:80%;">Vox</span></td>
<td id="S4.T9.3.6.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.6.2.1" class="ltx_text" style="font-size:80%;">53.1</span></td>
<td id="S4.T9.3.6.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.6.3.1" class="ltx_text" style="font-size:80%;">56.7</span></td>
</tr>
<tr id="S4.T9.3.3" class="ltx_tr">
<td id="S4.T9.3.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.3.2.1" class="ltx_text" style="font-size:80%;">ER</span></td>
<td id="S4.T9.3.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.3.3.1" class="ltx_text" style="font-size:80%;">MSP</span></td>
<td id="S4.T9.3.3.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T9.3.3.1.1" class="ltx_text" style="font-size:80%;">UAR</span><math id="S4.T9.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T9.3.3.1.m1.1a"><mo mathsize="80%" stretchy="false" id="S4.T9.3.3.1.m1.1.1" xref="S4.T9.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T9.3.3.1.m1.1b"><ci id="S4.T9.3.3.1.m1.1.1.cmml" xref="S4.T9.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.3.3.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T9.3.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.3.4.1" class="ltx_text" style="font-size:80%;">64.5</span></td>
<td id="S4.T9.3.3.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="S4.T9.3.3.5.1" class="ltx_text" style="font-size:80%;">64.7</span></td>
</tr>
</table>
</figure>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.1" class="ltx_p"><span id="S4.SS3.SSS2.p2.1.1" class="ltx_text" style="font-size:80%;">The results in the table showcase that augmenting the training data with compound goals helps to improve the performance for all three tasks. The improved performance can be attributed to the possibility of self-attention on the already decoded ASR hypothesis in the decoder of our multimodal model. Further, such multi-step training examples brings out the true multimodal capabilities of the model to successfully complete the combination of tasks. Further, such a paradigm can help save crucial inference latency by using a single call of the large multi-modal model for obtaining both the transcript and the task output. A more detailed analysis on understanding the benefits of joint decoding will be conducted in future work.</span></p>
</div>
<figure id="S4.T10" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 10: </span>Qualitative examples of output from all the training tasks on a audio file with transcription "turn on the radio now"</figcaption>
<div id="S4.T10.3" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:93952.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(177.4pt,-38441.8pt) scale(5.5043360292927,5.5043360292927) ;">
<table id="S4.T10.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T10.3.1.1" class="ltx_tr">
<td id="S4.T10.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.1.1.1.1" class="ltx_p"><span id="S4.T10.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></span>
</span>
</td>
<td id="S4.T10.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.1.2.1.1" class="ltx_p"><span id="S4.T10.3.1.1.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Instruction</span></span>
</span>
</td>
<td id="S4.T10.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.1.3.1.1" class="ltx_p"><span id="S4.T10.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Prediction</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.2" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T10.3.1.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.2.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.2.1.1.1" class="ltx_p"><span id="S4.T10.3.1.2.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">ASR</span></span>
</span>
</td>
<td id="S4.T10.3.1.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.2.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.2.2.1.1" class="ltx_p"><span id="S4.T10.3.1.2.2.1.1.1" class="ltx_text" style="font-size:80%;">Transcribe the preceding audio</span></span>
</span>
</td>
<td id="S4.T10.3.1.2.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.2.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.2.3.1.1" class="ltx_p"><span id="S4.T10.3.1.2.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">turn on the radio now</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.3" class="ltx_tr">
<td id="S4.T10.3.1.3.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.3.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.3.2.1.1" class="ltx_p"><span id="S4.T10.3.1.3.2.1.1.1" class="ltx_text" style="font-size:80%;">What is being said in the preceding audio?</span></span>
</span>
</td>
<td id="S4.T10.3.1.3.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.3.3.1.1" class="ltx_p"><span id="S4.T10.3.1.3.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">turn on the radio now</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.4" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T10.3.1.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.4.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.4.1.1.1" class="ltx_p"><span id="S4.T10.3.1.4.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">ST</span></span>
</span>
</td>
<td id="S4.T10.3.1.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.4.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.4.2.1.1" class="ltx_p"><span id="S4.T10.3.1.4.2.1.1.1" class="ltx_text" style="font-size:80%;">Translate the english audio to german</span></span>
</span>
</td>
<td id="S4.T10.3.1.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.4.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.4.3.1.1" class="ltx_p"><span id="S4.T10.3.1.4.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">schalten sie jetzt den radio auf</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.5" class="ltx_tr">
<td id="S4.T10.3.1.5.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.5.2.1.1" class="ltx_p"><span id="S4.T10.3.1.5.2.1.1.1" class="ltx_text" style="font-size:80%;">Generate french translation for the english audio</span></span>
</span>
</td>
<td id="S4.T10.3.1.5.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.5.3.1.1" class="ltx_p"><span id="S4.T10.3.1.5.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">mettez le radio à l’onder maintenant</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.6" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T10.3.1.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.6.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.6.1.1.1" class="ltx_p"><span id="S4.T10.3.1.6.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">IC</span></span>
</span>
</td>
<td id="S4.T10.3.1.6.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.6.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.6.2.1.1" class="ltx_p"><span id="S4.T10.3.1.6.2.1.1.1" class="ltx_text" style="font-size:80%;">The previous audio needs to be mapped to exactly one of the following intents:</span></span>
</span>
</td>
<td id="S4.T10.3.1.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.7" class="ltx_tr">
<td id="S4.T10.3.1.7.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.7.1.1.1" class="ltx_p"><span id="S4.T10.3.1.7.1.1.1.1" class="ltx_text" style="font-size:80%;">- datetime_query: user asks about date, time, schedules, etc;</span></span>
</span>
</td>
<td id="S4.T10.3.1.7.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.7.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.8" class="ltx_tr">
<td id="S4.T10.3.1.8.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.8.1.1.1" class="ltx_p"><span id="S4.T10.3.1.8.1.1.1.1" class="ltx_text" style="font-size:80%;">- qa_definition: user wants to ask for general fact-based questions to receive definitions, explanations, descriptions, etc;</span></span>
</span>
</td>
<td id="S4.T10.3.1.8.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.8.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.9" class="ltx_tr">
<td id="S4.T10.3.1.9.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.9.1.1.1" class="ltx_p"><span id="S4.T10.3.1.9.1.1.1.1" class="ltx_text" style="font-size:80%;">- calendar_remove: user wants to remove calendar events by voice;</span></span>
</span>
</td>
<td id="S4.T10.3.1.9.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.9.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.10" class="ltx_tr">
<td id="S4.T10.3.1.10.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.10.1.1.1" class="ltx_p"><span id="S4.T10.3.1.10.1.1.1.1" class="ltx_text" style="font-size:80%;">…</span></span>
</span>
</td>
<td id="S4.T10.3.1.10.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.10.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.11" class="ltx_tr">
<td id="S4.T10.3.1.11.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.11.1.1.1" class="ltx_p"><span id="S4.T10.3.1.11.1.1.1.1" class="ltx_text" style="font-size:80%;">- play_radio: user wants to request playback of radio, stations, etc;</span></span>
</span>
</td>
<td id="S4.T10.3.1.11.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.11.2.1.1" class="ltx_p"><span id="S4.T10.3.1.11.2.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">play_radio</span></span>
</span>
</td>
<td id="S4.T10.3.1.11.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.12" class="ltx_tr">
<td id="S4.T10.3.1.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.12.1.1.1" class="ltx_p"><span id="S4.T10.3.1.12.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">SF</span></span>
</span>
</td>
<td id="S4.T10.3.1.12.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.12.2.1.1" class="ltx_p"><span id="S4.T10.3.1.12.2.1.1.1" class="ltx_text" style="font-size:80%;">Identify any of the following slots present in the speech:</span></span>
</span>
</td>
<td id="S4.T10.3.1.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.13" class="ltx_tr">
<td id="S4.T10.3.1.13.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.13.1.1.1" class="ltx_p"><span id="S4.T10.3.1.13.1.1.1.1" class="ltx_text" style="font-size:80%;">- date: any reference to a date, month or day of the week;</span></span>
</span>
</td>
<td id="S4.T10.3.1.13.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.13.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.14" class="ltx_tr">
<td id="S4.T10.3.1.14.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.14.1.1.1" class="ltx_p"><span id="S4.T10.3.1.14.1.1.1.1" class="ltx_text" style="font-size:80%;">- place_name: any reference of a place e.g., berlin, new york etc.;</span></span>
</span>
</td>
<td id="S4.T10.3.1.14.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.14.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.15" class="ltx_tr">
<td id="S4.T10.3.1.15.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.15.1.1.1" class="ltx_p"><span id="S4.T10.3.1.15.1.1.1.1" class="ltx_text" style="font-size:80%;">- person: any reference of a person;</span></span>
</span>
</td>
<td id="S4.T10.3.1.15.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;"></td>
<td id="S4.T10.3.1.15.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.16" class="ltx_tr">
<td id="S4.T10.3.1.16.1" class="ltx_td ltx_align_justify ltx_align_middle" style="width:39.0pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.16.1.1.1" class="ltx_p"><span id="S4.T10.3.1.16.1.1.1.1" class="ltx_text" style="font-size:80%;">- time: any reference to time e.g., three am, two thirty etc.;</span></span>
</span>
</td>
<td id="S4.T10.3.1.16.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.16.2.1.1" class="ltx_p"><span id="S4.T10.3.1.16.2.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">time = now;</span></span>
</span>
</td>
<td id="S4.T10.3.1.16.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;"></td>
</tr>
<tr id="S4.T10.3.1.17" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T10.3.1.17.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.17.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.17.1.1.1" class="ltx_p"><span id="S4.T10.3.1.17.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">KWE</span></span>
</span>
</td>
<td id="S4.T10.3.1.17.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.17.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.17.2.1.1" class="ltx_p"><span id="S4.T10.3.1.17.2.1.1.1" class="ltx_text" style="font-size:80%;">Identify important keywords in the preceding recording</span></span>
</span>
</td>
<td id="S4.T10.3.1.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.17.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.17.3.1.1" class="ltx_p"><span id="S4.T10.3.1.17.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">radio</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.18" class="ltx_tr">
<td id="S4.T10.3.1.18.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.18.1.1.1" class="ltx_p"><span id="S4.T10.3.1.18.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">KWS</span></span>
</span>
</td>
<td id="S4.T10.3.1.18.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.18.2.1.1" class="ltx_p"><span id="S4.T10.3.1.18.2.1.1.1" class="ltx_text" style="font-size:80%;">Is the word ’radio’ used in the audio?</span></span>
</span>
</td>
<td id="S4.T10.3.1.18.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.18.3.1.1" class="ltx_p"><span id="S4.T10.3.1.18.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">yes</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.19" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T10.3.1.19.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.19.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.19.1.1.1" class="ltx_p"><span id="S4.T10.3.1.19.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">ER</span></span>
</span>
</td>
<td id="S4.T10.3.1.19.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.19.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.19.2.1.1" class="ltx_p"><span id="S4.T10.3.1.19.2.1.1.1" class="ltx_text" style="font-size:80%;">Detect the primary emotion conveyed in this audio by the speaker’s tone - is it happiness, sadness, anger, or neutral?</span></span>
</span>
</td>
<td id="S4.T10.3.1.19.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.19.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.19.3.1.1" class="ltx_p"><span id="S4.T10.3.1.19.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">neutral</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.20" class="ltx_tr">
<td id="S4.T10.3.1.20.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.20.1.1.1" class="ltx_p"><span id="S4.T10.3.1.20.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">ASC</span></span>
</span>
</td>
<td id="S4.T10.3.1.20.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.20.2.1.1" class="ltx_p"><span id="S4.T10.3.1.20.2.1.1.1" class="ltx_text" style="font-size:80%;">Classify the sentiment of the speaker into one of the following - positivity, negativity, or neutrality</span></span>
</span>
</td>
<td id="S4.T10.3.1.20.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.20.3.1.1" class="ltx_p"><span id="S4.T10.3.1.20.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">neutral</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.21" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T10.3.1.21.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.21.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.21.1.1.1" class="ltx_p"><span id="S4.T10.3.1.21.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">AC</span></span>
</span>
</td>
<td id="S4.T10.3.1.21.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.21.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.21.2.1.1" class="ltx_p"><span id="S4.T10.3.1.21.2.1.1.1" class="ltx_text" style="font-size:80%;">Analyze the speaker voice and figure out their accent from one of American, Indian, Australian, Canadian or British.</span></span>
</span>
</td>
<td id="S4.T10.3.1.21.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.21.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.21.3.1.1" class="ltx_p"><span id="S4.T10.3.1.21.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">American</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.22" class="ltx_tr">
<td id="S4.T10.3.1.22.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.22.1.1.1" class="ltx_p"><span id="S4.T10.3.1.22.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">SC</span></span>
</span>
</td>
<td id="S4.T10.3.1.22.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.22.2.1.1" class="ltx_p"><span id="S4.T10.3.1.22.2.1.1.1" class="ltx_text" style="font-size:80%;">How many distinct speakers are there in this audio clip.</span></span>
</span>
</td>
<td id="S4.T10.3.1.22.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T10.3.1.22.3.1.1" class="ltx_p"><span id="S4.T10.3.1.22.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">one</span></span>
</span>
</td>
</tr>
<tr id="S4.T10.3.1.23" class="ltx_tr" style="background-color:#ECECEC;">
<td id="S4.T10.3.1.23.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t" style="width:39.0pt;background-color:#FFFFFF;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.23.1.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.23.1.1.1" class="ltx_p"><span id="S4.T10.3.1.23.1.1.1.1" class="ltx_text" style="font-size:80%;background-color:#FFFFFF;">SNS</span></span>
</span>
</td>
<td id="S4.T10.3.1.23.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t" style="width:303.5pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.23.2.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.23.2.1.1" class="ltx_p"><span id="S4.T10.3.1.23.2.1.1.1" class="ltx_text" style="font-size:80%;">Is their speech in the preceding audio or not?</span></span>
</span>
</td>
<td id="S4.T10.3.1.23.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb ltx_border_t" style="width:156.1pt;padding-top:2pt;padding-bottom:2pt;">
<span id="S4.T10.3.1.23.3.1" class="ltx_inline-block ltx_align_top" style="background-color:#ECECEC;">
<span id="S4.T10.3.1.23.3.1.1" class="ltx_p"><span id="S4.T10.3.1.23.3.1.1.1" class="ltx_text ltx_font_italic" style="font-size:80%;">speech</span></span>
</span>
</td>
</tr>
</table>
</span></div>
</figure>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:80%;">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Multi-task learning.</span><span id="S5.p1.1.2" class="ltx_text" style="font-size:80%;"> Prior studies have shown that a single deep learning model is capable of jointly learning multiple large-scale tasks across different domains </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p1.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx42" title="" class="ltx_ref">42</a><span id="S5.p1.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p1.1.5" class="ltx_text" style="font-size:80%;">. The key idea in multi-task learning is to leverage shared representations across related tasks to improve overall generalization and efficiency. Following this approach, the T5 model </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p1.1.6.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx43" title="" class="ltx_ref">43</a><span id="S5.p1.1.7.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p1.1.8" class="ltx_text" style="font-size:80%;"> frames all text tasks as text-in to text-out, using a unified text-based framework that facilitates shared representations across textual tasks. Similarly, SpeechNet </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p1.1.9.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx44" title="" class="ltx_ref">44</a><span id="S5.p1.1.10.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p1.1.11" class="ltx_text" style="font-size:80%;"> and SpeechT5 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p1.1.12.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx19" title="" class="ltx_ref">19</a><span id="S5.p1.1.13.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p1.1.14" class="ltx_text" style="font-size:80%;"> leverage a shared encoder-decoder framework to jointly model speech and text modalities spanning 5 to 6 tasks like TTS, ASR, and Voice Conversion (VC). VIOLA </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p1.1.15.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx15" title="" class="ltx_ref">15</a><span id="S5.p1.1.16.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p1.1.17" class="ltx_text" style="font-size:80%;">, a single auto-regressive Transformer decoder-only network, unifies various cross-modal speech and text tasks as a conditional codec language model via multi-task learning. Whisper </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p1.1.18.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx20" title="" class="ltx_ref">20</a><span id="S5.p1.1.19.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p1.1.20" class="ltx_text" style="font-size:80%;"> also employs large-scale multi-task learning, training on related speech tasks including language identification, speech recognition, and translation. In this work, SpeechVerse utilizes multi-task training to transfer knowledge between several related tasks while using natural language instructions to perform each task. Unlike prior work that generated text, speech, or both, our method focuses solely on producing textual output, while taking in audio and text instructions.</span></p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Multimodal Large Language Models.</span><span id="S5.p2.1.2" class="ltx_text" style="font-size:80%;"> Prior work on multimodal LLMs has focused primarily on tasks involving images, such as image generation, visual question answering, and image captioning </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p2.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx4" title="" class="ltx_ref">4</a>, <a href="#bib.bibx45" title="" class="ltx_ref">45</a>, <a href="#bib.bibx46" title="" class="ltx_ref">46</a>, <a href="#bib.bibx9" title="" class="ltx_ref">9</a><span id="S5.p2.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p2.1.5" class="ltx_text" style="font-size:80%;">. Multimodal models incorporating modalities like audio and speech have received relatively less attention compared to vision-and-language models </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p2.1.6.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx49" title="" class="ltx_ref">49</a>, <a href="#bib.bibx47" title="" class="ltx_ref">47</a>, <a href="#bib.bibx48" title="" class="ltx_ref">48</a><span id="S5.p2.1.7.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p2.1.8" class="ltx_text" style="font-size:80%;">. However, there has been growing interest in augmenting large language models with audio data, leading to several proposed approaches </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p2.1.9.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx8" title="" class="ltx_ref">8</a>, <a href="#bib.bibx18" title="" class="ltx_ref">18</a>, <a href="#bib.bibx51" title="" class="ltx_ref">51</a>, <a href="#bib.bibx14" title="" class="ltx_ref">14</a>, <a href="#bib.bibx52" title="" class="ltx_ref">52</a>, <a href="#bib.bibx50" title="" class="ltx_ref">50</a>, <a href="#bib.bibx17" title="" class="ltx_ref">17</a><span id="S5.p2.1.10.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p2.1.11" class="ltx_text" style="font-size:80%;">. SpeechGPT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p2.1.12.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx18" title="" class="ltx_ref">18</a><span id="S5.p2.1.13.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p2.1.14" class="ltx_text" style="font-size:80%;"> proposed a multimodal LLM combining discrete units of HuBERT with an LLM to solve few understanding tasks like ASR, Spoken QA as well as generation tasks like TTS. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p2.1.15.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx17" title="" class="ltx_ref">17</a><span id="S5.p2.1.16.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p2.1.17" class="ltx_text" style="font-size:80%;"> introduces the novel capability of zero-shot instruction-following for more diverse tasks such as dialog generation, speech continuation and Question Answering. Most recently, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p2.1.18.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx16" title="" class="ltx_ref">16</a><span id="S5.p2.1.19.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p2.1.20" class="ltx_text" style="font-size:80%;"> proposed Qwen-Audio, a large-scale audio-language model trained using a multi-task learning approach to handle a diverse range of tasks across various audio types including human speech, natural sounds, music, and songs. Qwen-Audio employs a single audio encoder to process various types of audio whose initialization is based on the Whisper-large-v2 model </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p2.1.21.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx20" title="" class="ltx_ref">20</a><span id="S5.p2.1.22.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p2.1.23" class="ltx_text" style="font-size:80%;"> and performs full finetuning. In contrast, our work utilizes two frozen pretrained models, one each for speech encoder and text decoder to retain their intrinsic strengths. Also, we utilize 30+ instructions for each task during training for improved generalization whereas </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.p2.1.24.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx17" title="" class="ltx_ref">17</a><span id="S5.p2.1.25.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S5.p2.1.26" class="ltx_text" style="font-size:80%;"> uses a single fixed instruction. Additionally, SpeechVerse incorporates multi-task learning and instruction finetuning in a single training stage.</span></p>
</div>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:80%;">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text" style="font-size:80%;">In this work, we propose SpeechVerse, a multimodal framework that enables LLMs to follow natural language instructions for performing diverse speech processing tasks.
Through supervised instruction finetuning and combining representations from frozen pre-trained speech and text foundation models, SpeechVerse achieves strong zero-shot generalization on unseen tasks. Extensive benchmarking against conventional baselines show SpeechVerse’s superiority on 9 out of 11 tasks, demonstrating its formidable instruction following capability.
Crucially, SpeechVerse maintains robust performance on out-of-domain datasets, unseen prompts, and even unseen tasks.
This highlights the efficacy of our proposed training methodology in imbuing the model with a generalizable skill for mapping text-based instructions to speech processing outputs. Moving forward, we aim to expand SpeechVerse’s capabilities to follow even more complex instructions and generalize to new domains.
By separating task specification from model design, SpeechVerse represents a versatile framework that can dynamically adapt to new tasks through natural language without retraining.</span></p>
</div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:80%;">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text" style="font-size:80%;">While this work demonstrated strong instruction following capabilities for the multitask SpeechVerse model across a variety of tasks, some limitations remain. The study relied on a single underlying LLM architecture (FlanT5) rather than exploring more recent models tailored for instruction following. Additionally, there is a trade-off between generalized capabilities on unseen tasks versus specialized performance on original training tasks that poses challenges for a single multitask model. While the model showed promise in handling diverse unseen tasks, its limitations were not fully characterized across the wide scope of possible instructions and the performance on these unseen tasks is not quantitatively measured.</span></p>
</div>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:80%;">Ethics Statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p"><span id="Sx2.p1.1.1" class="ltx_text" style="font-size:80%;">All speech datasets we use have anonymous speakers. We do not have any access to nor try to create any PII (Personal Identifiable Information) of speakers, and our model neither identifies speakers nor uses speaker embeddings. Most of the work used public open-source datasets for both training and testing. The in-house datasets used for pre-training Best-RQ encoder and SNS task are collected via third-party speech data vendors. No additional data collections made concerning to the work carried in this paper.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bibx1.1.1" class="ltx_text" style="font-size:80%;">Tom Brown et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx1.2.1" class="ltx_text" style="font-size:80%;">“Language models are few-shot learners”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx1.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx1.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Advances in neural information processing systems</em><span id="bib.bibx1.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx1.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">33</span><span id="bib.bibx1.7.5" class="ltx_text" style="font-size:80%;">, 2020, pp. 1877–1901</span>
</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bibx2.1.1" class="ltx_text" style="font-size:80%;">Aakanksha Chowdhery et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx2.2.1" class="ltx_text" style="font-size:80%;">“Palm: Scaling language modeling with pathways”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx2.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx2.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Journal of Machine Learning Research</em><span id="bib.bibx2.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx2.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">24.240</span><span id="bib.bibx2.7.5" class="ltx_text" style="font-size:80%;">, 2023, pp. 1–113</span>
</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bibx3.1.1" class="ltx_text" style="font-size:80%;">Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx3.2.1" class="ltx_text" style="font-size:80%;">“Improving language understanding by generative pre-training”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx3.3.1" class="ltx_text" style="font-size:80%;">OpenAI, 2018</span>
</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bibx4.1.1" class="ltx_text" style="font-size:80%;">Josh Achiam et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx4.2.1" class="ltx_text" style="font-size:80%;">“Gpt-4 technical report”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx4.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx4.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2303.08774</em><span id="bib.bibx4.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bibx5.1.1" class="ltx_text" style="font-size:80%;">Hyung Won Chung et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx5.2.1" class="ltx_text" style="font-size:80%;">“Scaling instruction-finetuned language models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx5.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx5.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2210.11416</em><span id="bib.bibx5.5.3" class="ltx_text" style="font-size:80%;">, 2022</span>
</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bibx6.1.1" class="ltx_text" style="font-size:80%;">Long Ouyang et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx6.2.1" class="ltx_text" style="font-size:80%;">“Training language models to follow instructions with human feedback”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx6.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx6.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Advances in Neural Information Processing Systems</em><span id="bib.bibx6.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx6.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">35</span><span id="bib.bibx6.7.5" class="ltx_text" style="font-size:80%;">, 2022, pp. 27730–27744</span>
</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bibx7.1.1" class="ltx_text" style="font-size:80%;">Hugo Touvron et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx7.2.1" class="ltx_text" style="font-size:80%;">“Llama: Open and efficient foundation language models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx7.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx7.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2302.13971</em><span id="bib.bibx7.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bibx8.1.1" class="ltx_text" style="font-size:80%;">Rongjie Huang et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx8.2.1" class="ltx_text" style="font-size:80%;">“AudioGPT: Understanding and generating speech, music, sound, and talking head”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx8.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx8.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2304.12995</em><span id="bib.bibx8.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bibx9.1.1" class="ltx_text" style="font-size:80%;">Team Gemini et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx9.2.1" class="ltx_text" style="font-size:80%;">“Gemini: a family of highly capable multimodal models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx9.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx9.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2312.11805</em><span id="bib.bibx9.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bibx10.1.1" class="ltx_text" style="font-size:80%;">Taicheng Guo et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx10.2.1" class="ltx_text" style="font-size:80%;">“Large Language Model based Multi-Agents: A Survey of Progress and Challenges”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx10.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx10.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2402.01680</em><span id="bib.bibx10.5.3" class="ltx_text" style="font-size:80%;">, 2024</span>
</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bibx11.1.1" class="ltx_text" style="font-size:80%;">W Ronny Huang et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx11.2.1" class="ltx_text" style="font-size:80%;">“Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx11.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx11.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2401.12789</em><span id="bib.bibx11.5.3" class="ltx_text" style="font-size:80%;">, 2024</span>
</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bibx12.1.1" class="ltx_text" style="font-size:80%;">Yuang Li, Yu Wu, Jinyu Li and Shujie Liu</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx12.2.1" class="ltx_text" style="font-size:80%;">“Prompting large language models for zero-shot domain adaptation in speech recognition”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx12.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx12.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proc. Automatic Speech Recognition and Understanding Workshop (ASRU)</em><span id="bib.bibx12.5.3" class="ltx_text" style="font-size:80%;">, 2023, pp. 1–8</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx12.6.1" class="ltx_text" style="font-size:80%;">IEEE</span>
</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bibx13.1.1" class="ltx_text" style="font-size:80%;">Rao Ma et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx13.2.1" class="ltx_text" style="font-size:80%;">“Can generative large language models perform asr error correction?”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx13.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx13.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2307.04172</em><span id="bib.bibx13.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bibx14.1.1" class="ltx_text" style="font-size:80%;">Paul K Rubenstein et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx14.2.1" class="ltx_text" style="font-size:80%;">“AudioPaLM: A Large Language Model That Can Speak and Listen”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx14.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx14.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2306.12925</em><span id="bib.bibx14.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bibx15.1.1" class="ltx_text" style="font-size:80%;">Tianrui Wang et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx15.2.1" class="ltx_text" style="font-size:80%;">“VioLA: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx15.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx15.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2305.16107</em><span id="bib.bibx15.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bibx16.1.1" class="ltx_text" style="font-size:80%;">Yunfei Chu et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx16.2.1" class="ltx_text" style="font-size:80%;">“Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx16.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx16.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2311.07919</em><span id="bib.bibx16.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bibx17.1.1" class="ltx_text" style="font-size:80%;">Mingqiu Wang et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx17.2.1" class="ltx_text" style="font-size:80%;">“SLM: Bridge the thin gap between speech and text foundation models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx17.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx17.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proc. Automatic Speech Recognition and Understanding Workshop (ASRU)</em><span id="bib.bibx17.5.3" class="ltx_text" style="font-size:80%;">, 2023, pp. 1–8</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx17.6.1" class="ltx_text" style="font-size:80%;">IEEE</span>
</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bibx18.1.1" class="ltx_text" style="font-size:80%;">Dong Zhang et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx18.2.1" class="ltx_text" style="font-size:80%;">“Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx18.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx18.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2305.11000</em><span id="bib.bibx18.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bibx19.1.1" class="ltx_text" style="font-size:80%;">Junyi Ao et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx19.2.1" class="ltx_text" style="font-size:80%;">“SpeechT5: Unified-modal encoder-decoder pre-training for spoken language processing”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx19.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx19.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2110.07205</em><span id="bib.bibx19.5.3" class="ltx_text" style="font-size:80%;">, 2021</span>
</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bibx20.1.1" class="ltx_text" style="font-size:80%;">Alec Radford et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx20.2.1" class="ltx_text" style="font-size:80%;">“Robust speech recognition via large-scale weak supervision”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx20.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx20.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proc. ICML</em><span id="bib.bibx20.5.3" class="ltx_text" style="font-size:80%;">, 2023, pp. 28492–28518</span>
</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bibx21.1.1" class="ltx_text" style="font-size:80%;">Edward J. Hu et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx21.2.1" class="ltx_text" style="font-size:80%;">“LoRA: Low-Rank Adaptation of Large Language Models”, 2021</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx21.3.1" class="ltx_text" style="font-size:80%;">arXiv:</span><a target="_blank" href="https://arxiv.org/abs/2106.09685" title="" class="ltx_ref ltx_href" style="font-size:80%;">2106.09685 [cs.CL]</a>
</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bibx22.1.1" class="ltx_text" style="font-size:80%;">Vassil Panayotov, Guoguo Chen, Daniel Povey and Sanjeev Khudanpur</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx22.2.1" class="ltx_text" style="font-size:80%;">“Librispeech: an asr corpus based on public domain audio books”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx22.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx22.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em><span id="bib.bibx22.5.3" class="ltx_text" style="font-size:80%;">, 2015, pp. 5206–5210</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx22.6.1" class="ltx_text" style="font-size:80%;">IEEE</span>
</span>
</li>
<li id="bib.bibx23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bibx23.1.1" class="ltx_text" style="font-size:80%;">Rosana Ardila et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx23.2.1" class="ltx_text" style="font-size:80%;">“Common voice: A massively-multilingual speech corpus”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx23.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx23.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1912.06670</em><span id="bib.bibx23.5.3" class="ltx_text" style="font-size:80%;">, 2019</span>
</span>
</li>
<li id="bib.bibx24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bibx24.1.1" class="ltx_text" style="font-size:80%;">Ofer Dekel and Ohad Shamir</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx24.2.1" class="ltx_text" style="font-size:80%;">“Vox Populi: Collecting High-Quality Labels from a Crowd.”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx24.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx24.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">COLT</em><span id="bib.bibx24.5.3" class="ltx_text" style="font-size:80%;">, 2009</span>
</span>
</li>
<li id="bib.bibx25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bibx25.1.1" class="ltx_text" style="font-size:80%;">Emanuele Bastianelli, Andrea Vanzo, Pawel Swietojanski and Verena Rieser</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx25.2.1" class="ltx_text" style="font-size:80%;">“SLURP: A spoken language understanding resource package”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx25.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx25.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2011.13205</em><span id="bib.bibx25.5.3" class="ltx_text" style="font-size:80%;">, 2020</span>
</span>
</li>
<li id="bib.bibx26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bibx26.1.1" class="ltx_text" style="font-size:80%;">Philipp Koehn</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx26.2.1" class="ltx_text" style="font-size:80%;">“Europarl: A parallel corpus for statistical machine translation”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx26.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx26.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proceedings of machine translation summit x: papers</em><span id="bib.bibx26.5.3" class="ltx_text" style="font-size:80%;">, 2005, pp. 79–86</span>
</span>
</li>
<li id="bib.bibx27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bibx27.1.1" class="ltx_text" style="font-size:80%;">Reza Lotfian and Carlos Busso</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx27.2.1" class="ltx_text" style="font-size:80%;">“Building naturalistic emotionally balanced speech corpus by retrieving emotional speech from existing podcast recordings”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx27.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx27.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE Transactions on Affective Computing</em><span id="bib.bibx27.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx27.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">10.4</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx27.7.1" class="ltx_text" style="font-size:80%;">IEEE, 2017, pp. 471–483</span>
</span>
</li>
<li id="bib.bibx28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bibx28.1.1" class="ltx_text" style="font-size:80%;">Changhan Wang, Anne Wu and Juan Pino</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx28.2.1" class="ltx_text" style="font-size:80%;">“Covost 2 and massively multilingual speech-to-text translation”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx28.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx28.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2007.10310</em><span id="bib.bibx28.5.3" class="ltx_text" style="font-size:80%;">, 2020</span>
</span>
</li>
<li id="bib.bibx29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bibx29.1.1" class="ltx_text" style="font-size:80%;">et al Cieri</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx29.2.1" class="ltx_text" style="font-size:80%;">“Fisher English Training Speech Part 1 Speech LDC2004S13”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx29.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx29.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Web Download. Philadelphia: Linguistic Data Consortium</em><span id="bib.bibx29.5.3" class="ltx_text" style="font-size:80%;">, 2004</span>
</span>
</li>
<li id="bib.bibx30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bibx30.1.1" class="ltx_text" style="font-size:80%;">et al Cieri</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx30.2.1" class="ltx_text" style="font-size:80%;">“Fisher English Training Part 2, Speech LDC2005S13”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx30.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx30.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Web Download. Philadelphia: Linguistic Data Consortium</em><span id="bib.bibx30.5.3" class="ltx_text" style="font-size:80%;">, 2005</span>
</span>
</li>
<li id="bib.bibx31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bibx31.1.1" class="ltx_text" style="font-size:80%;">Rohan Taori et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx31.2.1" class="ltx_text" style="font-size:80%;">“Stanford alpaca: An instruction-following llama model”, 2023</span>
</span>
</li>
<li id="bib.bibx32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bibx32.1.1" class="ltx_text" style="font-size:80%;">Sanyuan Chen et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx32.2.1" class="ltx_text" style="font-size:80%;">“WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx32.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx32.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE Journal of Selected Topics in Signal Processing</em><span id="bib.bibx32.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx32.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">16</span><span id="bib.bibx32.7.5" class="ltx_text" style="font-size:80%;">, 2021, pp. 1505–1518</span>
</span>
</li>
<li id="bib.bibx33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bibx33.1.1" class="ltx_text" style="font-size:80%;">Chung-Cheng Chiu et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx33.2.1" class="ltx_text" style="font-size:80%;">“Self-supervised learning with random-projection quantizer for speech recognition”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx33.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx33.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">International Conference on Machine Learning</em><span id="bib.bibx33.5.3" class="ltx_text" style="font-size:80%;">, 2022, pp. 3915–3924</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx33.6.1" class="ltx_text" style="font-size:80%;">PMLR</span>
</span>
</li>
<li id="bib.bibx34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bibx34.1.1" class="ltx_text" style="font-size:80%;">Ankur Bapna et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx34.2.1" class="ltx_text" style="font-size:80%;">“mslam: Massively multilingual joint pre-training for speech and text”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx34.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx34.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2202.01374</em><span id="bib.bibx34.5.3" class="ltx_text" style="font-size:80%;">, 2022</span>
</span>
</li>
<li id="bib.bibx35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bibx35.1.1" class="ltx_text" style="font-size:80%;"> Seamless Communication et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx35.2.1" class="ltx_text" style="font-size:80%;">“SeamlessM4T: Massively Multilingual &amp; Multimodal Machine Translation”, 2023</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx35.3.1" class="ltx_text" style="font-size:80%;">arXiv:</span><a target="_blank" href="https://arxiv.org/abs/2308.11596" title="" class="ltx_ref ltx_href" style="font-size:80%;">2308.11596 [cs.CL]</a>
</span>
</li>
<li id="bib.bibx36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bibx36.1.1" class="ltx_text" style="font-size:80%;">Xian Li et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx36.2.1" class="ltx_text" style="font-size:80%;">“Multilingual Speech Translation from Efficient Finetuning of Pretrained Models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx36.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx36.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em>
</span>
<span class="ltx_bibblock"><span id="bib.bibx36.5.1" class="ltx_text" style="font-size:80%;">Online: Association for Computational Linguistics, 2021, pp. 827–838</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx36.6.1" class="ltx_text" style="font-size:80%;">DOI: </span><a target="_blank" href="https://dx.doi.org/10.18653/v1/2021.acl-long.68" title="" class="ltx_ref ltx_href" style="font-size:80%;">10.18653/v1/2021.acl-long.68</a>
</span>
</li>
<li id="bib.bibx37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bibx37.1.1" class="ltx_text" style="font-size:80%;">Seunghyun Seo, Donghyun Kwak and Bowon Lee</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx37.2.1" class="ltx_text" style="font-size:80%;">“Integration of pre-trained networks with continuous token interface for end-to-end spoken language understanding”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx37.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx37.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proc. ICASSP</em><span id="bib.bibx37.5.3" class="ltx_text" style="font-size:80%;">, 2022, pp. 7152–7156</span>
</span>
</li>
<li id="bib.bibx38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bibx38.1.1" class="ltx_text" style="font-size:80%;">Yingzhi Wang, Abdelmoumene Boumadane and Abdelwahab Heba</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx38.2.1" class="ltx_text" style="font-size:80%;">“A fine-tuned wav2vec 2.0/hubert benchmark for speech emotion recognition, speaker verification and spoken language understanding”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx38.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx38.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2111.02735</em><span id="bib.bibx38.5.3" class="ltx_text" style="font-size:80%;">, 2022</span>
</span>
</li>
<li id="bib.bibx39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bibx39.1.1" class="ltx_text" style="font-size:80%;">Anna Derington et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx39.2.1" class="ltx_text" style="font-size:80%;">“Testing Speech Emotion Recognition Machine Learning Models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx39.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx39.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2312.06270</em><span id="bib.bibx39.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bibx40.1.1" class="ltx_text" style="font-size:80%;">Brandon T Willard and Rémi Louf</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx40.2.1" class="ltx_text" style="font-size:80%;">“Efficient Guided Generation for LLMs”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx40.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx40.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2307.09702</em><span id="bib.bibx40.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bibx41.1.1" class="ltx_text" style="font-size:80%;">Jason Wei et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx41.2.1" class="ltx_text" style="font-size:80%;">“Chain-of-thought prompting elicits reasoning in large language models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx41.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx41.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Advances in Neural Information Processing Systems</em><span id="bib.bibx41.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx41.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">35</span><span id="bib.bibx41.7.5" class="ltx_text" style="font-size:80%;">, 2022, pp. 24824–24837</span>
</span>
</li>
<li id="bib.bibx42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bibx42.1.1" class="ltx_text" style="font-size:80%;">Lukasz Kaiser et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx42.2.1" class="ltx_text" style="font-size:80%;">“One model to learn them all”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx42.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx42.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:1706.05137</em><span id="bib.bibx42.5.3" class="ltx_text" style="font-size:80%;">, 2017</span>
</span>
</li>
<li id="bib.bibx43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bibx43.1.1" class="ltx_text" style="font-size:80%;">Colin Raffel et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx43.2.1" class="ltx_text" style="font-size:80%;">“Exploring the limits of transfer learning with a unified text-to-text transformer”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx43.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx43.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">The Journal of Machine Learning Research</em><span id="bib.bibx43.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx43.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">21.1</span><span id="bib.bibx43.7.5" class="ltx_text" style="font-size:80%;">, 2020, pp. 5485–5551</span>
</span>
</li>
<li id="bib.bibx44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bibx44.1.1" class="ltx_text" style="font-size:80%;">Yi-Chen Chen et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx44.2.1" class="ltx_text" style="font-size:80%;">“Speechnet: A universal modularized model for speech processing tasks”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx44.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx44.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2105.03070</em><span id="bib.bibx44.5.3" class="ltx_text" style="font-size:80%;">, 2021</span>
</span>
</li>
<li id="bib.bibx45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bibx45.1.1" class="ltx_text" style="font-size:80%;">Jean-Baptiste Alayrac et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx45.2.1" class="ltx_text" style="font-size:80%;">“Flamingo: a visual language model for few-shot learning”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx45.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx45.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Advances in Neural Information Processing Systems</em><span id="bib.bibx45.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx45.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">35</span><span id="bib.bibx45.7.5" class="ltx_text" style="font-size:80%;">, 2022, pp. 23716–23736</span>
</span>
</li>
<li id="bib.bibx46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bibx46.1.1" class="ltx_text" style="font-size:80%;">Junnan Li, Dongxu Li, Caiming Xiong and Steven Hoi</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx46.2.1" class="ltx_text" style="font-size:80%;">“Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx46.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx46.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">International Conference on Machine Learning</em><span id="bib.bibx46.5.3" class="ltx_text" style="font-size:80%;">, 2022, pp. 12888–12900</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx46.6.1" class="ltx_text" style="font-size:80%;">PMLR</span>
</span>
</li>
<li id="bib.bibx47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bibx47.1.1" class="ltx_text" style="font-size:80%;">Jing Yu Koh, Ruslan Salakhutdinov and Daniel Fried</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx47.2.1" class="ltx_text" style="font-size:80%;">“Grounding language models to images for multimodal inputs and outputs”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx47.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx47.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">International Conference on Machine Learning</em><span id="bib.bibx47.5.3" class="ltx_text" style="font-size:80%;">, 2023, pp. 17283–17300</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx47.6.1" class="ltx_text" style="font-size:80%;">PMLR</span>
</span>
</li>
<li id="bib.bibx48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bibx48.1.1" class="ltx_text" style="font-size:80%;">Zhiliang Peng et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx48.2.1" class="ltx_text" style="font-size:80%;">“Kosmos-2: Grounding Multimodal Large Language Models to the World”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx48.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx48.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2306.14824</em><span id="bib.bibx48.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bibx49.1.1" class="ltx_text" style="font-size:80%;">Kaiyang Zhou, Jingkang Yang, Chen Change Loy and Ziwei Liu</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx49.2.1" class="ltx_text" style="font-size:80%;">“Learning to prompt for vision-language models”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx49.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx49.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">International Journal of Computer Vision</em><span id="bib.bibx49.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx49.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">130.9</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx49.7.1" class="ltx_text" style="font-size:80%;">Springer, 2022, pp. 2337–2348</span>
</span>
</li>
<li id="bib.bibx50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bibx50.1.1" class="ltx_text" style="font-size:80%;">Soham Deshmukh, Benjamin Elizalde, Rita Singh and Huaming Wang</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx50.2.1" class="ltx_text" style="font-size:80%;">“Pengi: An Audio Language Model for Audio Tasks”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx50.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx50.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2305.11834</em><span id="bib.bibx50.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bibx51.1.1" class="ltx_text" style="font-size:80%;">Yuan Gong et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx51.2.1" class="ltx_text" style="font-size:80%;">“Listen, Think, and Understand”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx51.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx51.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2305.10790</em><span id="bib.bibx51.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bibx52.1.1" class="ltx_text" style="font-size:80%;">Yu Shu et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx52.2.1" class="ltx_text" style="font-size:80%;">“Llasm: Large language and speech model”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx52.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx52.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv preprint arXiv:2308.15930</em><span id="bib.bibx52.5.3" class="ltx_text" style="font-size:80%;">, 2023</span>
</span>
</li>
<li id="bib.bibx53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bibx53.1.1" class="ltx_text" style="font-size:80%;">J. Iranzo-Sánchez et al.</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx53.2.1" class="ltx_text" style="font-size:80%;">“Europarl-ST: A Multilingual Corpus for Speech Translation of Parliamentary Debates”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx53.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx53.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em><span id="bib.bibx53.5.3" class="ltx_text" style="font-size:80%;">, 2020, pp. 8229–8233</span>
</span>
</li>
<li id="bib.bibx54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bibx54.1.1" class="ltx_text" style="font-size:80%;">R. Lotfian and C. Busso</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx54.2.1" class="ltx_text" style="font-size:80%;">“Building Naturalistic Emotionally Balanced Speech Corpus by Retrieving Emotional Speech From Existing Podcast Recordings”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx54.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx54.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE Transactions on Affective Computing</em><span id="bib.bibx54.5.3" class="ltx_text" style="font-size:80%;"> </span><span id="bib.bibx54.6.4" class="ltx_text ltx_font_bold" style="font-size:80%;">10.4</span><span id="bib.bibx54.7.5" class="ltx_text" style="font-size:80%;">, 2019, pp. 471–483</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx54.8.1" class="ltx_text" style="font-size:80%;">DOI: </span><a target="_blank" href="https://dx.doi.org/10.1109/TAFFC.2017.2736999" title="" class="ltx_ref ltx_href" style="font-size:80%;">10.1109/TAFFC.2017.2736999</a>
</span>
</li>
<li id="bib.bibx55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bibx55.1.1" class="ltx_text" style="font-size:80%;">Rohit Paturi, Sundararajan Srinivasan and Xiang Li</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx55.2.1" class="ltx_text" style="font-size:80%;">“Lexical Speaker Error Correction: Leveraging Language Models for Speaker Diarization Error Correction”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx55.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx55.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proc. INTERSPEECH 2023</em><span id="bib.bibx55.5.3" class="ltx_text" style="font-size:80%;">, 2023, pp. 3567–3571</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx55.6.1" class="ltx_text" style="font-size:80%;">DOI: </span><a target="_blank" href="https://dx.doi.org/10.21437/Interspeech.2023-1982" title="" class="ltx_ref ltx_href" style="font-size:80%;">10.21437/Interspeech.2023-1982</a>
</span>
</li>
<li id="bib.bibx56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bibx56.1.1" class="ltx_text" style="font-size:80%;">et al Cieri</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx56.2.1" class="ltx_text" style="font-size:80%;">“2000 HUB5 English Evaluation Speech LDC2002S09”</span>
</span>
<span class="ltx_bibblock"><span id="bib.bibx56.3.1" class="ltx_text" style="font-size:80%;">In </span><em id="bib.bibx56.4.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Web Download. Philadelphia: Linguistic Data Consortium</em><span id="bib.bibx56.5.3" class="ltx_text" style="font-size:80%;">, 2002</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:80%;">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:80%;">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Audio Encoder Pre-training</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p"><span id="A1.SS1.p1.1.1" class="ltx_text" style="font-size:80%;">Our audio encoder is a 24-layer Conformer model with feature dimension of 768 and attention head of 8. The total number of parameters of this encoder model is 300M. We adopt the BEST-RQ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A1.SS1.p1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx33" title="" class="ltx_ref">33</a><span id="A1.SS1.p1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="A1.SS1.p1.1.4" class="ltx_text" style="font-size:80%;"> method, which pre-trains the model to predict the masked speech signals with labels generated from a random-projection quantizer. The quantizer projects the speech inputs with a randomly initialized matrix, and performs a nearest-neighbor lookup in a randomly-initialized codebook. Neither the projection matrix nor the codebook is updated during pre-training. We build an internal pre-training dataset containing 300K hours English audios. The pre-training uses mask span of 10 with total effective masking ratio about 40%. The learning rate schedule follows the transformer learning rate schedule with peak value of 0.0005 and warm-up of 50K steps. AdamW optimizer is adopted with weight decay of 0.01. Since the encoder has 4 times temporal-dimension reduction, the quantization with random projections stacks every 4 frames for projections. We use 16 individual codeboooks, where the vocab size of each codebook is 8192 and the dimension is 16. The model is pre-trained for 500K steps in total.</span></p>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:80%;">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Hyper-parameters</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p"><span id="A1.SS2.p1.1.1" class="ltx_text" style="font-size:80%;">We train all our models on a cluster of machines with 8 A100 GPUs, each having 40GB of memory. Pytorch Lightning framework</span><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.pytorchlightning.ai" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:50%;">https://www.pytorchlightning.ai</a></span></span></span><span id="A1.SS2.p1.1.2" class="ltx_text" style="font-size:80%;"> is used for our implementation. A 5% subset of the complete training dataset for a model is used as a validation set to choose the important hyper-parameters. For the multi-task models, the sample weights for each dataset are also chosen using this validation set. Further, all models are trained till the validation loss converges and it does not improve for 5 consecutive epochs. The details of the learning rate, warmup steps, batch size for the Multitask-WLM and Multitask-BRQ are summarized in the Table </span><a href="#A1.T11" title="Table 11 ‣ A.2 Hyper-parameters ‣ Appendix A Appendix ‣ Ethics Statement ‣ Limitations ‣ 6 Conclusion ‣ 5 Related Work ‣ 4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref" style="font-size:80%;"><span class="ltx_text ltx_ref_tag">11</span></a><span id="A1.SS2.p1.1.3" class="ltx_text" style="font-size:80%;">. To adhere to memory constraints of the GPUs, we filter out any training sample where the sequence length of the audio is greater than 900 or the target label is greater than 600. Since, the WavLM Large samples audio features at 50Hz rate, we use two successive 1-D convolution blocks (kernel size=3, stride=2) for the Task-FT and Multitask-WLM model to downsample the audio four times and achieve the desired sampling rate of 12.5Hz. For BestRQ-based audio encoder, the sampling rate is 25Hz and hence the stride of the second convolution block is set to 1 to ensure the output sampling rate is 12.5Hz.</span></p>
</div>
<figure id="A1.T11" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">Table 11: </span>Various hyper-parameters for our models</figcaption>
<div id="A1.T11.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:212.5pt;height:214pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.9pt,19.0pt) scale(0.849072536760086,0.849072536760086) ;">
<table id="A1.T11.3.1" class="ltx_tabular ltx_align_middle">
<tr id="A1.T11.3.1.1" class="ltx_tr">
<td id="A1.T11.3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Parameter</span></td>
<td id="A1.T11.3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Multitask-WLM</span></td>
<td id="A1.T11.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Multitask-BRQ</span></td>
</tr>
<tr id="A1.T11.3.1.2" class="ltx_tr">
<td id="A1.T11.3.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.2.1.1" class="ltx_text" style="font-size:80%;">Audio encoder</span></td>
<td id="A1.T11.3.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.2.2.1" class="ltx_text" style="font-size:80%;">WavLM-Large</span></td>
<td id="A1.T11.3.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.2.3.1" class="ltx_text" style="font-size:80%;">Best-RQ</span></td>
</tr>
<tr id="A1.T11.3.1.3" class="ltx_tr">
<td id="A1.T11.3.1.3.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.3.1.1" class="ltx_text" style="font-size:80%;">LLM</span></td>
<td id="A1.T11.3.1.3.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.3.2.1" class="ltx_text" style="font-size:80%;">Flan-T5-XL</span></td>
<td id="A1.T11.3.1.3.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.3.3.1" class="ltx_text" style="font-size:80%;">Flan-T5-XL</span></td>
</tr>
<tr id="A1.T11.3.1.4" class="ltx_tr">
<td id="A1.T11.3.1.4.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.4.1.1" class="ltx_text" style="font-size:80%;">Convolution blocks</span></td>
<td id="A1.T11.3.1.4.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.4.2.1" class="ltx_text" style="font-size:80%;">2</span></td>
<td id="A1.T11.3.1.4.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.4.3.1" class="ltx_text" style="font-size:80%;">2</span></td>
</tr>
<tr id="A1.T11.3.1.5" class="ltx_tr">
<td id="A1.T11.3.1.5.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.5.1.1" class="ltx_text" style="font-size:80%;">Kernel sizes</span></td>
<td id="A1.T11.3.1.5.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.5.2.1" class="ltx_text" style="font-size:80%;">[3, 3]</span></td>
<td id="A1.T11.3.1.5.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.5.3.1" class="ltx_text" style="font-size:80%;">[3, 3]</span></td>
</tr>
<tr id="A1.T11.3.1.6" class="ltx_tr">
<td id="A1.T11.3.1.6.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.6.1.1" class="ltx_text" style="font-size:80%;">Strides</span></td>
<td id="A1.T11.3.1.6.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.6.2.1" class="ltx_text" style="font-size:80%;">[2, 2]</span></td>
<td id="A1.T11.3.1.6.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.6.3.1" class="ltx_text" style="font-size:80%;">[2, 1]</span></td>
</tr>
<tr id="A1.T11.3.1.7" class="ltx_tr">
<td id="A1.T11.3.1.7.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.7.1.1" class="ltx_text" style="font-size:80%;">Audio encoder ampling rate</span></td>
<td id="A1.T11.3.1.7.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.7.2.1" class="ltx_text" style="font-size:80%;">50Hz</span></td>
<td id="A1.T11.3.1.7.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.7.3.1" class="ltx_text" style="font-size:80%;">25Hz</span></td>
</tr>
<tr id="A1.T11.3.1.8" class="ltx_tr">
<td id="A1.T11.3.1.8.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.8.1.1" class="ltx_text" style="font-size:80%;">Down-sampling factor</span></td>
<td id="A1.T11.3.1.8.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.8.2.1" class="ltx_text" style="font-size:80%;">4x</span></td>
<td id="A1.T11.3.1.8.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.8.3.1" class="ltx_text" style="font-size:80%;">2x</span></td>
</tr>
<tr id="A1.T11.3.1.9" class="ltx_tr">
<td id="A1.T11.3.1.9.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.9.1.1" class="ltx_text" style="font-size:80%;"># parameters</span></td>
<td id="A1.T11.3.1.9.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.9.2.1" class="ltx_text" style="font-size:80%;">2.9B</span></td>
<td id="A1.T11.3.1.9.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.9.3.1" class="ltx_text" style="font-size:80%;">3.2B</span></td>
</tr>
<tr id="A1.T11.3.1.10" class="ltx_tr">
<td id="A1.T11.3.1.10.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.10.1.1" class="ltx_text" style="font-size:80%;"># trainable parameters</span></td>
<td id="A1.T11.3.1.10.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.10.2.1" class="ltx_text" style="font-size:80%;">28.3M</span></td>
<td id="A1.T11.3.1.10.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.10.3.1" class="ltx_text" style="font-size:80%;">26.8M</span></td>
</tr>
<tr id="A1.T11.3.1.11" class="ltx_tr">
<td id="A1.T11.3.1.11.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.11.1.1" class="ltx_text" style="font-size:80%;">LoRA rank(r)</span></td>
<td id="A1.T11.3.1.11.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.11.2.1" class="ltx_text" style="font-size:80%;">16</span></td>
<td id="A1.T11.3.1.11.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.11.3.1" class="ltx_text" style="font-size:80%;">16</span></td>
</tr>
<tr id="A1.T11.3.1.12" class="ltx_tr">
<td id="A1.T11.3.1.12.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.12.1.1" class="ltx_text" style="font-size:80%;">Learning rate</span></td>
<td id="A1.T11.3.1.12.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.12.2.1" class="ltx_text" style="font-size:80%;">0.001</span></td>
<td id="A1.T11.3.1.12.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.12.3.1" class="ltx_text" style="font-size:80%;">0.005</span></td>
</tr>
<tr id="A1.T11.3.1.13" class="ltx_tr">
<td id="A1.T11.3.1.13.1" class="ltx_td ltx_align_left" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.13.1.1" class="ltx_text" style="font-size:80%;">Warm-up steps</span></td>
<td id="A1.T11.3.1.13.2" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.13.2.1" class="ltx_text" style="font-size:80%;">100</span></td>
<td id="A1.T11.3.1.13.3" class="ltx_td ltx_align_center" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.13.3.1" class="ltx_text" style="font-size:80%;">50000</span></td>
</tr>
<tr id="A1.T11.3.1.14" class="ltx_tr">
<td id="A1.T11.3.1.14.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.14.1.1" class="ltx_text" style="font-size:80%;">Effective batch size</span></td>
<td id="A1.T11.3.1.14.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.14.2.1" class="ltx_text" style="font-size:80%;">768</span></td>
<td id="A1.T11.3.1.14.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:2pt;padding-bottom:2pt;"><span id="A1.T11.3.1.14.3.1" class="ltx_text" style="font-size:80%;">2048</span></td>
</tr>
</table>
</span></div>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:80%;">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Tasks</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.1" class="ltx_p"><span id="A1.SS3.p1.1.1" class="ltx_text" style="font-size:80%;">We provide the details about our training tasks below as well as provide some qualitative examples in the Table </span><a href="#S4.T10" title="Table 10 ‣ 4.3.2 Joint Decoding ‣ 4.3 Strategies for Improving Performance ‣ 4.2.2 Open-ended Instruction Following ‣ 4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref" style="font-size:80%;"><span class="ltx_text ltx_ref_tag">10</span></a><span id="A1.SS3.p1.1.2" class="ltx_text" style="font-size:80%;"> to better understand the tasks.</span></p>
</div>
<div id="A1.SS3.p2" class="ltx_para ltx_noindent">
<p id="A1.SS3.p2.1" class="ltx_p"><span id="A1.SS3.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ASR</span><span id="A1.SS3.p2.1.2" class="ltx_text" style="font-size:80%;">: We use a combination of 5 publicly available datasets for the ASR task, which totals to 3k hours of paired audio and text data. We evaluate performance on the standard benchmarks for ASR.</span></p>
</div>
<div id="A1.SS3.p3" class="ltx_para ltx_noindent">
<p id="A1.SS3.p3.1" class="ltx_p"><span id="A1.SS3.p3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ST</span><span id="A1.SS3.p3.1.2" class="ltx_text" style="font-size:80%;">: We train our models to predict translations in multiple different languages from the audios recorded with English speech. The tokenizer of the backbone LLM limits the choice of what can be a potential target language. For our case, we train and evaluate on German, French, and Romanian translations from the EuroParl dataset </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A1.SS3.p3.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx53" title="" class="ltx_ref">53</a><span id="A1.SS3.p3.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="A1.SS3.p3.1.5" class="ltx_text" style="font-size:80%;">. We also augment the training data with German and Catalan translations from the CoVost2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A1.SS3.p3.1.6.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx28" title="" class="ltx_ref">28</a><span id="A1.SS3.p3.1.7.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="A1.SS3.p3.1.8" class="ltx_text" style="font-size:80%;"> dataset .</span></p>
</div>
<div id="A1.SS3.p4" class="ltx_para ltx_noindent">
<p id="A1.SS3.p4.1" class="ltx_p"><span id="A1.SS3.p4.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">IC/SF</span><span id="A1.SS3.p4.1.2" class="ltx_text" style="font-size:80%;">: We train and evaluate our models on a subset of the SLURP dataset </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A1.SS3.p4.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx25" title="" class="ltx_ref">25</a><span id="A1.SS3.p4.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="A1.SS3.p4.1.5" class="ltx_text" style="font-size:80%;"> that consists of 10 intent classes and 4 slot labels. This also allows us to study the generalization ability of our models to unseen class labels and we separately study it in the Section </span><a href="#S4.SS2" title="4.2 Generalization Across Instructions ‣ 4 Results ‣ SpeechVerse: A Large-scale Generalizable Audio Language Model" class="ltx_ref" style="font-size:80%;"><span class="ltx_text ltx_ref_tag">4.2</span></a><span id="A1.SS3.p4.1.6" class="ltx_text" style="font-size:80%;">. The intent classes and slot labels that are chosen for the "seen" subset are the ones that occur most frequently in the training data.
The training prompt used for this task is designed to contain the description of each class label.</span></p>
</div>
<div id="A1.SS3.p5" class="ltx_para ltx_noindent">
<p id="A1.SS3.p5.1" class="ltx_p"><span id="A1.SS3.p5.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">KWE</span><span id="A1.SS3.p5.1.2" class="ltx_text" style="font-size:80%;">: The goal of this task is to identify important keywords in the content of the speech in the audio. Since no publicly available dataset exists for this task, we synthetically extract keywords from the ground truth transcripts using a text-based keyword extraction model</span><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://huggingface.co/Voicelab/vlt5-base-keywords" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:50%;">https://huggingface.co/Voicelab/vlt5-base-keywords</a></span></span></span><span id="A1.SS3.p5.1.3" class="ltx_text" style="font-size:80%;">. These are then used as labels for training and evaluating our models.</span></p>
</div>
<div id="A1.SS3.p6" class="ltx_para ltx_noindent">
<p id="A1.SS3.p6.1" class="ltx_p"><span id="A1.SS3.p6.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">KWS</span><span id="A1.SS3.p6.1.2" class="ltx_text" style="font-size:80%;">: This is a binary classification task to detect whether a specified keyword was spoken in the audio or not. We create positive samples by randomly selecting keywords from the ground truth transcripts and negative samples by choosing a keyword that does not appear in the transcript. Positive and negative examples are created in 70-30 ratio respectively for both training and evaluation.</span></p>
</div>
<div id="A1.SS3.p7" class="ltx_para ltx_noindent">
<p id="A1.SS3.p7.1" class="ltx_p"><span id="A1.SS3.p7.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ER</span><span id="A1.SS3.p7.1.2" class="ltx_text" style="font-size:80%;">: For emotion recognition, we classify speech into one of four main emotion classes: neutral, happy, sad, and angry, chosen based on the availability of the training samples in the MSP-Podcast v1.11 dataset </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A1.SS3.p7.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx54" title="" class="ltx_ref">54</a><span id="A1.SS3.p7.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="A1.SS3.p7.1.5" class="ltx_text" style="font-size:80%;">. We report metrics on the corresponding four-emotion subset of the Test1 split of the dataset.</span></p>
</div>
<div id="A1.SS3.p8" class="ltx_para ltx_noindent">
<p id="A1.SS3.p8.1" class="ltx_p"><span id="A1.SS3.p8.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ASC</span><span id="A1.SS3.p8.1.2" class="ltx_text" style="font-size:80%;">: For audio sentiment classification, we classify speech as positive, negative, or neutral in sentiment. The sentiment labels were obtained by thresholding the valence scale (annotated from 1 to 7) with 3 and 5. We train on the entire training split of the MSP-Podcast v1.11 dataset, and evaluate on the corresponding Test1 split.</span></p>
</div>
<div id="A1.SS3.p9" class="ltx_para ltx_noindent">
<p id="A1.SS3.p9.1" class="ltx_p"><span id="A1.SS3.p9.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SC</span><span id="A1.SS3.p9.1.2" class="ltx_text" style="font-size:80%;">: For speaker counting, we identify whether one or two speakers are present. We train on segments from Fisher dataset transcripts </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A1.SS3.p9.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx29" title="" class="ltx_ref">29</a>, <a href="#bib.bibx30" title="" class="ltx_ref">30</a><span id="A1.SS3.p9.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="A1.SS3.p9.1.5" class="ltx_text" style="font-size:80%;"> with one or two speakers, and evaluate on the Fisher test split used in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A1.SS3.p9.1.6.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx55" title="" class="ltx_ref">55</a><span id="A1.SS3.p9.1.7.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="A1.SS3.p9.1.8" class="ltx_text" style="font-size:80%;">.</span></p>
</div>
<div id="A1.SS3.p10" class="ltx_para ltx_noindent">
<p id="A1.SS3.p10.1" class="ltx_p"><span id="A1.SS3.p10.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">AC</span><span id="A1.SS3.p10.1.2" class="ltx_text" style="font-size:80%;">: We train our models to classify speech into five accents of English language: Canadian, Indian, Australian, British, and American, using metadata from the Mozilla Common Voice dataset.</span></p>
</div>
<div id="A1.SS3.p11" class="ltx_para ltx_noindent">
<p id="A1.SS3.p11.1" class="ltx_p"><span id="A1.SS3.p11.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">SNS</span><span id="A1.SS3.p11.1.2" class="ltx_text" style="font-size:80%;">: In this task, we identify whether speech is present in the audio. We collect a diverse set of audios with and without speech for training our models and evaluate them on a combination of speech segments from Hub5 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="A1.SS3.p11.1.3.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bibx56" title="" class="ltx_ref">56</a><span id="A1.SS3.p11.1.4.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="A1.SS3.p11.1.5" class="ltx_text" style="font-size:80%;"> dataset and held-out non-speech segments in our in-house collection.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.08293" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.08295" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.08295">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.08295" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.08296" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 14:48:03 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
