<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.14294] DASB - Discrete Audio and Speech Benchmark</title><meta property="og:description" content="Discrete audio tokens have recently gained considerable attention for their potential to connect audio and language processing, enabling the creation of modern multimodal large language models.
Ideal audio tokens must …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DASB - Discrete Audio and Speech Benchmark">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="DASB - Discrete Audio and Speech Benchmark">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.14294">

<!--Generated on Fri Jul  5 19:36:19 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">DASB - Discrete Audio and Speech Benchmark</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pooneh Mousavi<sup id="id12.12.id1" class="ltx_sup"><span id="id12.12.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Luca Della Libera<sup id="id13.13.id2" class="ltx_sup"><span id="id13.13.id2.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Jarod Duret<sup id="id14.14.id3" class="ltx_sup">3</sup>, Artem Ploujnikov<sup id="id15.15.id4" class="ltx_sup"><span id="id15.15.id4.1" class="ltx_text ltx_font_italic">4,2</span></sup>,
<br class="ltx_break"><span id="id5.5.1" class="ltx_text ltx_font_bold">Cem Subakan<sup id="id5.5.1.1" class="ltx_sup"><span id="id5.5.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">5,2,1</span></sup>,</span> <span id="id6.6.2" class="ltx_text ltx_font_bold">Mirco Ravanelli<sup id="id6.6.2.1" class="ltx_sup"><span id="id6.6.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,2,4</span></sup></span> 
<br class="ltx_break"><sup id="id16.16.id5" class="ltx_sup">1</sup>Concordia University <sup id="id17.17.id6" class="ltx_sup">2</sup>Mila - Quebec AI Institute <sup id="id18.18.id7" class="ltx_sup">3</sup>Avignon Université
<br class="ltx_break"><sup id="id19.19.id8" class="ltx_sup">4</sup>Université de Montréal <sup id="id20.20.id9" class="ltx_sup">5</sup>Université Laval
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id21.id1" class="ltx_p">Discrete audio tokens have recently gained considerable attention for their potential to connect audio and language processing, enabling the creation of modern multimodal large language models.
Ideal audio tokens must effectively preserve phonetic and semantic content along with paralinguistic information, speaker identity, and other details.
While several types of audio tokens have been recently proposed, identifying the optimal tokenizer for various tasks is challenging due to the inconsistent evaluation settings in existing studies.
To address this gap, we release the Discrete Audio and Speech Benchmark (DASB), a comprehensive leaderboard for benchmarking discrete audio tokens across a wide range of discriminative tasks, including speech recognition, speaker identification and verification, emotion recognition, keyword spotting, and intent classification, as well as generative tasks such as speech enhancement, separation, and text-to-speech. Our results show that, on average, semantic tokens outperform compression tokens across most discriminative and generative tasks. However, the performance gap between semantic tokens and standard continuous representations remains substantial, highlighting the need for further research in this field.
</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Traditional speech and audio processing systems have long relied on handcrafted low-level features such as <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">Mel-Frequency Cepstral Coefficients</span> and <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">Filterbanks</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Recently, self-supervised learning (SSL) led to outstanding performance improvements by learning more complex, robust, and general speech features through deep neural networks. Notable models include Wav2Vec2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, WavLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and HuBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In all these cases, the rich information in speech and audio signals is encoded into a sequence of continuous vectors.
Even though continuous vectors have proven effective in capturing the complex details embedded in speech and audio, there is a growing interest in discrete representations. Discrete audio representations, known as audio tokens, transform the original waveform into a finite set of vectors. These tokens are derived using methods such as quantization of self-supervised learning (SSL) models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, neural compression techniques (codecs)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, or hybrid approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> that combine both methods.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text ltx_font_italic">What is driving the interest in audio tokens</span>?
Arguably, this trend is linked to the remarkable success of autoregressive Large Language Models (LLMs) such as LLama <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, PALM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, and GPT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Unlike audio, these models operate on text, which is inherently discrete.
Inspired by their effectiveness, researchers are exploring audio language models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> by representing the audio as a sequence of discrete tokens.
Moreover, audio and text tokens can be naturally combined, paving the way for the development of modern multi-modal LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> capable of processing audio, text, and visual data.
Discrete tokens also simplify audio generation tasks like speech enhancement and synthesis by turning them into classification problems instead of regression models  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Finally, they also enable efficient data compression for better transmission and storage.
The main drawback of audio tokens is the inevitable loss of information introduced by the discretization process. We ideally aim for audio tokens that preserves crucial information of the original waveform, including phonetic and linguistic content, speaker identities, emotions, and other paralinguistic cues. However, despite the growing trend toward audio tokens, there is still a lack of standardized evaluation benchmarks, with different studies employing varied experimental settings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Without a consistent framework for measuring and comparing performance, it becomes challenging to determine which audio tokens perform optimally across various tasks.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.14294/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="237" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The workflow of DASB consists of three steps. First, a discrete audio encoder converts the audio signal into discrete tokens (<span id="S1.F1.4.1" class="ltx_text ltx_font_italic">left</span>). Then, the tokens are combined using attention and fed to a neural model for the final prediction (<span id="S1.F1.5.2" class="ltx_text ltx_font_italic">middle</span>).
For generative tasks, the predicted tokens are passed to a discrete decoder, which converts them back into an audio waveform (<span id="S1.F1.6.3" class="ltx_text ltx_font_italic">right</span>). Both the encoder and decoder are pretrained and frozen during downstream model training.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">To address this gap, we introduce the <span id="S1.p3.1.1" class="ltx_text ltx_font_bold">D</span>iscrete <span id="S1.p3.1.2" class="ltx_text ltx_font_bold">A</span>udio and <span id="S1.p3.1.3" class="ltx_text ltx_font_bold">S</span>peech <span id="S1.p3.1.4" class="ltx_text ltx_font_bold">B</span>enchmark (DASB). DASB systematically assesses various audio tokens across several common speech processing tasks. In particular, our contribution is the following:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i1.p1.1" class="ltx_p">We benchmark a diverse set of discrete audio encoders from all three categories: semantic (Discrete HuBERT, Discrete WavLM, Discrete Wav2Vec2), <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">compression</span> (EnCodec <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, DAC  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>), and <span id="S1.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">hybrid</span> (SpeechTokenizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>).</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:0.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We consider a wide range of discriminative tasks, including speech, speaker, emotion recognition, keyword spotting, and intent classification. We also tackle generative tasks, such as speech enhancement, separation, and text-to-speech.
For a more reliable assessment, we consider different downstream architectures for each task, following the insights in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
To the best of our knowledge, this is the first comprehensive benchmark of audio tokens that covers both discriminative and generative tasks.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:0.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S1.I1.i3.p1.1" class="ltx_p">We publicly release DASB<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/speechbrain/benchmarks/tree/DASB" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/speechbrain/benchmarks/tree/DASB</a></span></span></span> as a modular code repository built on the popular SpeechBrain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> toolkit and licensed under Apache 2.0.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">Several research efforts have recently explored using discrete audio tokens as an alternative to continuous features.
Some studies focused on using discrete features for speech recognition and speech translation  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, specifically evaluating the tokens obtained from the quantized versions of the HuBERT model. Similarly, Yang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> examined discrete features for speech recognition and text-to-speech.
Audio tokens have been proposed for speech enhancement as well. For example, Wang et al.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> investigated the application of semantic tokens to speech enhancement, whereas Erdogan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> proposed a hybrid tokenizer called TokenSplit for both speech enhancement and separation.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">While previous studies investigated the use of compression or hybrid tokens <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, these efforts were often limited to specific applications and a few audio tokenizers. In particular, previous benchmarking attempts focused on one category of tokenizers, either semantic or compression-based, and mostly on discriminative or generative tasks. For instance, Puvvada et al.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> compared the performance of EnCodec and DAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> for speaker verification, speaker diarization, and speech recognition. Mousavi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> benchmarked various discriminative and generative tasks with semantic tokens. Wu et al.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> provided a comprehensive study of the quality of resynthesized sound with compression and hybrid tokenizers. The latter attempt used pretrained models for speech, speaker, and emotion recognition, and assessed how much information is preserved by feeding them resynthesized audio.
However, it did not address the direct use of tokenized input for training downstream tasks, nor did it deeply analyze the role of semantic tokens. Our analyses, instead, suggest that semantic tokens outperform other tokenizers.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">To the best of our knowledge, the proposed DASB benchmark is the first to compare several audio tokenizers from three categories (semantic, compression, and hybrid) across many discriminative and generative speech tasks of broad practical interests. Moreover, unlike previous works on discrete audio tokens, we draw inspiration from the findings presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> for reliably benchmarking continuous SSL representations and we consider different downstream architectures for each task.
Similar to the approach taken by SUPERB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> for continuous representation, we offer a standardized evaluation benchmark where researchers can easily evaluate novel audio tokens.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Benchmark Design</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">The pipeline of DASB, illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, consists of three components: Audio Encoder, Downstream Model, and Audio Decoder.
The main features of the considered tokenizers are summarized in Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Discrete Audio Encoder ‣ 3 Benchmark Design ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, while Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Discrete Audio Encoder ‣ 3 Benchmark Design ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> reports the time and memory resources required by both encoders and decoders. The following subsections describe each module in detail.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Discrete Audio Encoder</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.6" class="ltx_p">The audio encoder converts the audio signal into a sequence of discrete tokens. It is pretrained on large amounts of unlabeled data and remains frozen during the training of downstream tasks.
Different encoders may compress the information in the original waveform at different rates. The compression level is measured by the bitrate, defined as:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\text{bitrate}=\log_{2}{V}\cdot C\cdot R," display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mtext id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2a.cmml">bitrate</mtext><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><msub id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml"><mi id="S3.E1.m1.1.1.1.1.3.1.2" xref="S3.E1.m1.1.1.1.1.3.1.2.cmml">log</mi><mn id="S3.E1.m1.1.1.1.1.3.1.3" xref="S3.E1.m1.1.1.1.1.3.1.3.cmml">2</mn></msub><mo lspace="0.167em" id="S3.E1.m1.1.1.1.1.3a" xref="S3.E1.m1.1.1.1.1.3.cmml">⁡</mo><mrow id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">V</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">⋅</mo><mi id="S3.E1.m1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.3.2.3.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.3.2.1a" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">⋅</mo><mi id="S3.E1.m1.1.1.1.1.3.2.4" xref="S3.E1.m1.1.1.1.1.3.2.4.cmml">R</mi></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><ci id="S3.E1.m1.1.1.1.1.2a.cmml" xref="S3.E1.m1.1.1.1.1.2"><mtext id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2">bitrate</mtext></ci><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><apply id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.1.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1">subscript</csymbol><log id="S3.E1.m1.1.1.1.1.3.1.2.cmml" xref="S3.E1.m1.1.1.1.1.3.1.2"></log><cn type="integer" id="S3.E1.m1.1.1.1.1.3.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3.1.3">2</cn></apply><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><ci id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.1">⋅</ci><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">𝑉</ci><ci id="S3.E1.m1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3">𝐶</ci><ci id="S3.E1.m1.1.1.1.1.3.2.4.cmml" xref="S3.E1.m1.1.1.1.1.3.2.4">𝑅</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\text{bitrate}=\log_{2}{V}\cdot C\cdot R,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.5" class="ltx_p">where <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">C</annotation></semantics></math> is the number of codebooks, <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">V</annotation></semantics></math> is the number of vectors in each codebook (vocabulary), and <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">R</annotation></semantics></math> is the rate of codes per second. It is worth mentioning that a single sequence of tokens might be insufficient to capture the rich and complex information embedded in speech signals. The encoders thus often output multiple discrete sequences, with each sequence corresponding to a different codebook <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">C</annotation></semantics></math>. The encoders can operate at different bitrates simply by adjusting the number of codebooks <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">C</annotation></semantics></math>.
For a fairer comparison, we define three different distinct bitrate ranges that we have identified from the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>: <span id="S3.SS1.p1.5.1" class="ltx_text ltx_font_italic">low</span> (0-1.5 kbps), <span id="S3.SS1.p1.5.2" class="ltx_text ltx_font_italic">medium</span> (2.9-6 kbps), and <span id="S3.SS1.p1.5.3" class="ltx_text ltx_font_italic">high</span> (24 kbps). We consider this approach to prevent the trivial conclusion that some audio tokens perform better than others simply due to a higher bitrate.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The design of DASB is flexible, allowing for easy integration and benchmarking of various tokenizers. Using the terminology from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, we categorize audio tokens into three classes: semantic, compression, and hybrid tokenizers.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Key Features of the Discrete Audio Encoders. #Params is computed for medium bitrate.</figcaption>
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:393.6pt;height:93.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="S3.T1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:390.3pt;height:93.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-105.9pt,25.3pt) scale(0.648147615960933,0.648147615960933) ;">
<table id="S3.T1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S3.T1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">#Params</span></th>
<th id="S3.T1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Sampling Rate</span></th>
<th id="S3.T1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3"><span id="S3.T1.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Bitrate (kbps)</span></th>
<th id="S3.T1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3"><span id="S3.T1.1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">#Codebooks</span></th>
</tr>
<tr id="S3.T1.1.1.1.2.2" class="ltx_tr">
<th id="S3.T1.1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.1.2.2.1.1" class="ltx_text ltx_font_bold">low</span></th>
<th id="S3.T1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.1.2.2.2.1" class="ltx_text ltx_font_bold">medium</span></th>
<th id="S3.T1.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.2.2.3.1" class="ltx_text ltx_font_bold">high</span></th>
<th id="S3.T1.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.1.2.2.4.1" class="ltx_text ltx_font_bold">low</span></th>
<th id="S3.T1.1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.1.2.2.5.1" class="ltx_text ltx_font_bold">medium</span></th>
<th id="S3.T1.1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.1.1.1.2.2.6.1" class="ltx_text ltx_font_bold">high</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1.3.1" class="ltx_tr">
<td id="S3.T1.1.1.1.3.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete HuBERT</td>
<td id="S3.T1.1.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">309.0M</td>
<td id="S3.T1.1.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16KHz</td>
<td id="S3.T1.1.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.98</td>
<td id="S3.T1.1.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">2.9</td>
<td id="S3.T1.1.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T1.1.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="S3.T1.1.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">6</td>
<td id="S3.T1.1.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S3.T1.1.1.1.4.2" class="ltx_tr">
<td id="S3.T1.1.1.1.4.2.1" class="ltx_td ltx_align_left ltx_border_r">Discrete WavLM</td>
<td id="S3.T1.1.1.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">309.0M</td>
<td id="S3.T1.1.1.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r">16KHz</td>
<td id="S3.T1.1.1.1.4.2.4" class="ltx_td ltx_align_center">0.98</td>
<td id="S3.T1.1.1.1.4.2.5" class="ltx_td ltx_align_center">2.9</td>
<td id="S3.T1.1.1.1.4.2.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T1.1.1.1.4.2.7" class="ltx_td ltx_align_center">2</td>
<td id="S3.T1.1.1.1.4.2.8" class="ltx_td ltx_align_center">6</td>
<td id="S3.T1.1.1.1.4.2.9" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S3.T1.1.1.1.5.3" class="ltx_tr">
<td id="S3.T1.1.1.1.5.3.1" class="ltx_td ltx_align_left ltx_border_r">Discrete Wav2Vec2</td>
<td id="S3.T1.1.1.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r">309.0M</td>
<td id="S3.T1.1.1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r">16KHz</td>
<td id="S3.T1.1.1.1.5.3.4" class="ltx_td ltx_align_center">0.98</td>
<td id="S3.T1.1.1.1.5.3.5" class="ltx_td ltx_align_center">2.9</td>
<td id="S3.T1.1.1.1.5.3.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T1.1.1.1.5.3.7" class="ltx_td ltx_align_center">2</td>
<td id="S3.T1.1.1.1.5.3.8" class="ltx_td ltx_align_center">6</td>
<td id="S3.T1.1.1.1.5.3.9" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S3.T1.1.1.1.6.4" class="ltx_tr">
<td id="S3.T1.1.1.1.6.4.1" class="ltx_td ltx_align_left ltx_border_r">EnCodec <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>
</td>
<td id="S3.T1.1.1.1.6.4.2" class="ltx_td ltx_align_center ltx_border_r">17.9M</td>
<td id="S3.T1.1.1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_r">24KHz</td>
<td id="S3.T1.1.1.1.6.4.4" class="ltx_td ltx_align_center">1.5</td>
<td id="S3.T1.1.1.1.6.4.5" class="ltx_td ltx_align_center">6.0</td>
<td id="S3.T1.1.1.1.6.4.6" class="ltx_td ltx_align_center ltx_border_r">24.0</td>
<td id="S3.T1.1.1.1.6.4.7" class="ltx_td ltx_align_center">2</td>
<td id="S3.T1.1.1.1.6.4.8" class="ltx_td ltx_align_center">8</td>
<td id="S3.T1.1.1.1.6.4.9" class="ltx_td ltx_align_center">32</td>
</tr>
<tr id="S3.T1.1.1.1.7.5" class="ltx_tr">
<td id="S3.T1.1.1.1.7.5.1" class="ltx_td ltx_align_left ltx_border_r">DAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</td>
<td id="S3.T1.1.1.1.7.5.2" class="ltx_td ltx_align_center ltx_border_r">22.4M</td>
<td id="S3.T1.1.1.1.7.5.3" class="ltx_td ltx_align_center ltx_border_r">24KHz</td>
<td id="S3.T1.1.1.1.7.5.4" class="ltx_td ltx_align_center">1.5</td>
<td id="S3.T1.1.1.1.7.5.5" class="ltx_td ltx_align_center">6.0</td>
<td id="S3.T1.1.1.1.7.5.6" class="ltx_td ltx_align_center ltx_border_r">24.0</td>
<td id="S3.T1.1.1.1.7.5.7" class="ltx_td ltx_align_center">2</td>
<td id="S3.T1.1.1.1.7.5.8" class="ltx_td ltx_align_center">8</td>
<td id="S3.T1.1.1.1.7.5.9" class="ltx_td ltx_align_center">32</td>
</tr>
<tr id="S3.T1.1.1.1.8.6" class="ltx_tr">
<td id="S3.T1.1.1.1.8.6.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">SpeechTokenizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S3.T1.1.1.1.8.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">85.3M</td>
<td id="S3.T1.1.1.1.8.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">16KHz</td>
<td id="S3.T1.1.1.1.8.6.4" class="ltx_td ltx_align_center ltx_border_b">1.0</td>
<td id="S3.T1.1.1.1.8.6.5" class="ltx_td ltx_align_center ltx_border_b">4.0</td>
<td id="S3.T1.1.1.1.8.6.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="S3.T1.1.1.1.8.6.7" class="ltx_td ltx_align_center ltx_border_b">2</td>
<td id="S3.T1.1.1.1.8.6.8" class="ltx_td ltx_align_center ltx_border_b">8</td>
<td id="S3.T1.1.1.1.8.6.9" class="ltx_td ltx_align_center ltx_border_b">-</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Semantic</span> tokens <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> are generated by clustering or quantizing layers from SSL models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The tokenization process typically involves selecting specific layers from a pretrained SSL model and applying the k-means algorithm to group their representations. Semantic tokens primarily capture high-level information, such as phonetic, semantic, and syntactic information.
They are not optimized for waveform reconstruction, making them potentially better suited for discriminative tasks like speech recognition. Recent studies, however, have shown that semantic tokens can also be effective in generative tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.
We adopt the tokenization algorithm proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. In particular, we consider three widely-used open-source SSL models: Wav2Vec2-large, WavLM-large, and HuBERT-large, each composed of 24 layers.
Then, we cluster six of these layers using the k-means algorithm and select two layers from the lower part (1, 3) to capture low-level information, two from the middle layers (7, 12), and two from the higher layers (18, 23) to encode content and meaning as well.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.8" class="ltx_p"><span id="S3.SS1.p4.8.1" class="ltx_text ltx_font_bold">Compression</span> tokens <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> are mainly used for audio compression. They are trained to accurately reconstruct the original audio, making them potentially suitable for audio generation tasks. We integrated two publicly available compression-based tokenizers in our baseline. EnCodec <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> has three main components: (i) an encoder network <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">E</annotation></semantics></math> consisting of a 1D convolution followed by a two-layer LSTM that processes the audio input and produces a latent representation <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mi id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">z</annotation></semantics></math>; (ii) a quantization layer <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mi id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">Q</annotation></semantics></math> that compresses <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><mi id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><ci id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">z</annotation></semantics></math> into <math id="S3.SS1.p4.5.m5.1" class="ltx_Math" alttext="z_{q}" display="inline"><semantics id="S3.SS1.p4.5.m5.1a"><msub id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml"><mi id="S3.SS1.p4.5.m5.1.1.2" xref="S3.SS1.p4.5.m5.1.1.2.cmml">z</mi><mi id="S3.SS1.p4.5.m5.1.1.3" xref="S3.SS1.p4.5.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2">𝑧</ci><ci id="S3.SS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">z_{q}</annotation></semantics></math> using Residual Vector Quantization (RVQ) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, where distinct codebooks quantizes residuals in multiple steps; and (iii) a decoder network <math id="S3.SS1.p4.6.m6.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS1.p4.6.m6.1a"><mi id="S3.SS1.p4.6.m6.1.1" xref="S3.SS1.p4.6.m6.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.1b"><ci id="S3.SS1.p4.6.m6.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.1c">G</annotation></semantics></math> that mirrors the encoder and reconstructs the time-domain signal <math id="S3.SS1.p4.7.m7.1" class="ltx_Math" alttext="\hat{x}" display="inline"><semantics id="S3.SS1.p4.7.m7.1a"><mover accent="true" id="S3.SS1.p4.7.m7.1.1" xref="S3.SS1.p4.7.m7.1.1.cmml"><mi id="S3.SS1.p4.7.m7.1.1.2" xref="S3.SS1.p4.7.m7.1.1.2.cmml">x</mi><mo id="S3.SS1.p4.7.m7.1.1.1" xref="S3.SS1.p4.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m7.1b"><apply id="S3.SS1.p4.7.m7.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1"><ci id="S3.SS1.p4.7.m7.1.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1.1">^</ci><ci id="S3.SS1.p4.7.m7.1.1.2.cmml" xref="S3.SS1.p4.7.m7.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m7.1c">\hat{x}</annotation></semantics></math> from <math id="S3.SS1.p4.8.m8.1" class="ltx_Math" alttext="z_{q}" display="inline"><semantics id="S3.SS1.p4.8.m8.1a"><msub id="S3.SS1.p4.8.m8.1.1" xref="S3.SS1.p4.8.m8.1.1.cmml"><mi id="S3.SS1.p4.8.m8.1.1.2" xref="S3.SS1.p4.8.m8.1.1.2.cmml">z</mi><mi id="S3.SS1.p4.8.m8.1.1.3" xref="S3.SS1.p4.8.m8.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.8.m8.1b"><apply id="S3.SS1.p4.8.m8.1.1.cmml" xref="S3.SS1.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.8.m8.1.1.1.cmml" xref="S3.SS1.p4.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p4.8.m8.1.1.2.cmml" xref="S3.SS1.p4.8.m8.1.1.2">𝑧</ci><ci id="S3.SS1.p4.8.m8.1.1.3.cmml" xref="S3.SS1.p4.8.m8.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.8.m8.1c">z_{q}</annotation></semantics></math>. The system is trained end-to-end to minimize reconstruction loss over time and frequency domains. It also adopts a perceptual loss using discriminators at different resolutions. EnCodec offers multiple models at low to medium bitrates (1.5 to 24 kbps). DAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> is an improved version of EnCodec. It combines advances in high-fidelity audio generation with better vector quantization techniques from the image domain, along with improved adversarial and reconstruction losses. DAC also supports quantizer dropout, allowing a single model to support variable bitrates.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">Hybrid</span> tokenizers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> unify semantic and acoustic tokens by disentangling different aspects of speech information hierarchically. SpeechTokenizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> is a unified speech tokenizer for large language models. It combines semantic and acoustic tokens, separating different speech information across RVQ layers. The model is based on RVQ-GANs, similar to EnCodec, and uses a convolutional encoder-decoder network from EnCodec. A two-layer BiLSTM replaces the original two-layer LSTM to improve semantic modeling. A semantic teacher guides the first RVQ quantizer, allowing the first layer tokens to capture content information effectively. With a residual structure, the subsequent quantizers capture the remaining paralinguistic information.
SpeechTokenizer employs HuBERT as the semantic teacher to capture content information. The training procedure maximizes the cosine similarity between the RVQ layer outputs and the semantic teacher representations. HuBERT Layer 9 units represent semantic tokens, while EnCodec codes represent acoustic tokens.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.14294/assets/x2.png" id="S3.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="20" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.14294/assets/x3.png" id="S3.F2.2.g1" class="ltx_graphics ltx_img_square" width="462" height="495" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F2.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.14294/assets/x4.png" id="S3.F2.3.g1" class="ltx_graphics ltx_img_square" width="462" height="495" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F2.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.14294/assets/x5.png" id="S3.F2.4.g1" class="ltx_graphics ltx_img_square" width="462" height="495" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F2.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.14294/assets/x6.png" id="S3.F2.5.g1" class="ltx_graphics ltx_img_square" width="462" height="495" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Time and memory required to process an utterance of 16 seconds for encoders and decoders of the considered audio tokenizers on an NVIDIA GeForce RTX 3070 GPU @ 8 GB.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Downstream Model</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.16" class="ltx_p">In this step, we employ neural networks to solve supervised tasks of common interest. To achieve this, we first assign each discrete token to a corresponding embedding vector through a lookup table. Subsequently, we dynamically combine the embeddings from different codebooks using attention, enabling the model to adjust the importance of codebooks for the specific task of interest. The attention mechanism consists of a simple multi-layer perceptron (MLP) that takes the embeddings of the audio tokens as input. The MLP generates a score for each selected codebook, which is normalized by a softmax function as shown in the following equations:</p>
<table id="A6.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.19" class="ltx_Math" alttext="\displaystyle z_{c,t}=f\big{(}\text{emb}(d_{c,t})\big{)},\;a_{c,t}=\frac{\exp(z_{c,t})}{\sum_{k=1}^{C}\exp(z_{k,t})},\;h_{t}=\sum_{c}a_{c,t}z_{c,t}," display="inline"><semantics id="S3.E2.m1.19a"><mrow id="S3.E2.m1.19.19.1"><mrow id="S3.E2.m1.19.19.1.1.2" xref="S3.E2.m1.19.19.1.1.3.cmml"><mrow id="S3.E2.m1.19.19.1.1.1.1" xref="S3.E2.m1.19.19.1.1.1.1.cmml"><msub id="S3.E2.m1.19.19.1.1.1.1.3" xref="S3.E2.m1.19.19.1.1.1.1.3.cmml"><mi id="S3.E2.m1.19.19.1.1.1.1.3.2" xref="S3.E2.m1.19.19.1.1.1.1.3.2.cmml">z</mi><mrow id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">c</mi><mo id="S3.E2.m1.2.2.2.4.1" xref="S3.E2.m1.2.2.2.3.cmml">,</mo><mi id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">t</mi></mrow></msub><mo id="S3.E2.m1.19.19.1.1.1.1.2" xref="S3.E2.m1.19.19.1.1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.19.19.1.1.1.1.1" xref="S3.E2.m1.19.19.1.1.1.1.1.cmml"><mi id="S3.E2.m1.19.19.1.1.1.1.1.3" xref="S3.E2.m1.19.19.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.19.19.1.1.1.1.1.2" xref="S3.E2.m1.19.19.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.19.19.1.1.1.1.1.1.1" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.cmml"><mo maxsize="120%" minsize="120%" id="S3.E2.m1.19.19.1.1.1.1.1.1.1.2" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.cmml"><mtext id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.3a.cmml">emb</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.2.cmml">d</mi><mrow id="S3.E2.m1.4.4.2.4" xref="S3.E2.m1.4.4.2.3.cmml"><mi id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml">c</mi><mo id="S3.E2.m1.4.4.2.4.1" xref="S3.E2.m1.4.4.2.3.cmml">,</mo><mi id="S3.E2.m1.4.4.2.2" xref="S3.E2.m1.4.4.2.2.cmml">t</mi></mrow></msub><mo stretchy="false" id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo maxsize="120%" minsize="120%" id="S3.E2.m1.19.19.1.1.1.1.1.1.1.3" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo rspace="0.447em" id="S3.E2.m1.19.19.1.1.2.3" xref="S3.E2.m1.19.19.1.1.3a.cmml">,</mo><mrow id="S3.E2.m1.19.19.1.1.2.2.2" xref="S3.E2.m1.19.19.1.1.2.2.3.cmml"><mrow id="S3.E2.m1.19.19.1.1.2.2.1.1" xref="S3.E2.m1.19.19.1.1.2.2.1.1.cmml"><msub id="S3.E2.m1.19.19.1.1.2.2.1.1.2" xref="S3.E2.m1.19.19.1.1.2.2.1.1.2.cmml"><mi id="S3.E2.m1.19.19.1.1.2.2.1.1.2.2" xref="S3.E2.m1.19.19.1.1.2.2.1.1.2.2.cmml">a</mi><mrow id="S3.E2.m1.6.6.2.4" xref="S3.E2.m1.6.6.2.3.cmml"><mi id="S3.E2.m1.5.5.1.1" xref="S3.E2.m1.5.5.1.1.cmml">c</mi><mo id="S3.E2.m1.6.6.2.4.1" xref="S3.E2.m1.6.6.2.3.cmml">,</mo><mi id="S3.E2.m1.6.6.2.2" xref="S3.E2.m1.6.6.2.2.cmml">t</mi></mrow></msub><mo id="S3.E2.m1.19.19.1.1.2.2.1.1.1" xref="S3.E2.m1.19.19.1.1.2.2.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S3.E2.m1.14.14" xref="S3.E2.m1.14.14.cmml"><mfrac id="S3.E2.m1.14.14a" xref="S3.E2.m1.14.14.cmml"><mrow id="S3.E2.m1.10.10.4.4" xref="S3.E2.m1.10.10.4.5.cmml"><mi id="S3.E2.m1.9.9.3.3" xref="S3.E2.m1.9.9.3.3.cmml">exp</mi><mo id="S3.E2.m1.10.10.4.4a" xref="S3.E2.m1.10.10.4.5.cmml">⁡</mo><mrow id="S3.E2.m1.10.10.4.4.1" xref="S3.E2.m1.10.10.4.5.cmml"><mo stretchy="false" id="S3.E2.m1.10.10.4.4.1.2" xref="S3.E2.m1.10.10.4.5.cmml">(</mo><msub id="S3.E2.m1.10.10.4.4.1.1" xref="S3.E2.m1.10.10.4.4.1.1.cmml"><mi id="S3.E2.m1.10.10.4.4.1.1.2" xref="S3.E2.m1.10.10.4.4.1.1.2.cmml">z</mi><mrow id="S3.E2.m1.8.8.2.2.2.4" xref="S3.E2.m1.8.8.2.2.2.3.cmml"><mi id="S3.E2.m1.7.7.1.1.1.1" xref="S3.E2.m1.7.7.1.1.1.1.cmml">c</mi><mo id="S3.E2.m1.8.8.2.2.2.4.1" xref="S3.E2.m1.8.8.2.2.2.3.cmml">,</mo><mi id="S3.E2.m1.8.8.2.2.2.2" xref="S3.E2.m1.8.8.2.2.2.2.cmml">t</mi></mrow></msub><mo stretchy="false" id="S3.E2.m1.10.10.4.4.1.3" xref="S3.E2.m1.10.10.4.5.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.14.14.8" xref="S3.E2.m1.14.14.8.cmml"><msubsup id="S3.E2.m1.14.14.8.5" xref="S3.E2.m1.14.14.8.5.cmml"><mo id="S3.E2.m1.14.14.8.5.2.2" xref="S3.E2.m1.14.14.8.5.2.2.cmml">∑</mo><mrow id="S3.E2.m1.14.14.8.5.2.3" xref="S3.E2.m1.14.14.8.5.2.3.cmml"><mi id="S3.E2.m1.14.14.8.5.2.3.2" xref="S3.E2.m1.14.14.8.5.2.3.2.cmml">k</mi><mo id="S3.E2.m1.14.14.8.5.2.3.1" xref="S3.E2.m1.14.14.8.5.2.3.1.cmml">=</mo><mn id="S3.E2.m1.14.14.8.5.2.3.3" xref="S3.E2.m1.14.14.8.5.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.14.14.8.5.3" xref="S3.E2.m1.14.14.8.5.3.cmml">C</mi></msubsup><mrow id="S3.E2.m1.14.14.8.4.1" xref="S3.E2.m1.14.14.8.4.2.cmml"><mi id="S3.E2.m1.13.13.7.3" xref="S3.E2.m1.13.13.7.3.cmml">exp</mi><mo id="S3.E2.m1.14.14.8.4.1a" xref="S3.E2.m1.14.14.8.4.2.cmml">⁡</mo><mrow id="S3.E2.m1.14.14.8.4.1.1" xref="S3.E2.m1.14.14.8.4.2.cmml"><mo stretchy="false" id="S3.E2.m1.14.14.8.4.1.1.2" xref="S3.E2.m1.14.14.8.4.2.cmml">(</mo><msub id="S3.E2.m1.14.14.8.4.1.1.1" xref="S3.E2.m1.14.14.8.4.1.1.1.cmml"><mi id="S3.E2.m1.14.14.8.4.1.1.1.2" xref="S3.E2.m1.14.14.8.4.1.1.1.2.cmml">z</mi><mrow id="S3.E2.m1.12.12.6.2.2.4" xref="S3.E2.m1.12.12.6.2.2.3.cmml"><mi id="S3.E2.m1.11.11.5.1.1.1" xref="S3.E2.m1.11.11.5.1.1.1.cmml">k</mi><mo id="S3.E2.m1.12.12.6.2.2.4.1" xref="S3.E2.m1.12.12.6.2.2.3.cmml">,</mo><mi id="S3.E2.m1.12.12.6.2.2.2" xref="S3.E2.m1.12.12.6.2.2.2.cmml">t</mi></mrow></msub><mo stretchy="false" id="S3.E2.m1.14.14.8.4.1.1.3" xref="S3.E2.m1.14.14.8.4.2.cmml">)</mo></mrow></mrow></mrow></mfrac></mstyle></mrow><mo rspace="0.447em" id="S3.E2.m1.19.19.1.1.2.2.2.3" xref="S3.E2.m1.19.19.1.1.2.2.3a.cmml">,</mo><mrow id="S3.E2.m1.19.19.1.1.2.2.2.2" xref="S3.E2.m1.19.19.1.1.2.2.2.2.cmml"><msub id="S3.E2.m1.19.19.1.1.2.2.2.2.2" xref="S3.E2.m1.19.19.1.1.2.2.2.2.2.cmml"><mi id="S3.E2.m1.19.19.1.1.2.2.2.2.2.2" xref="S3.E2.m1.19.19.1.1.2.2.2.2.2.2.cmml">h</mi><mi id="S3.E2.m1.19.19.1.1.2.2.2.2.2.3" xref="S3.E2.m1.19.19.1.1.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E2.m1.19.19.1.1.2.2.2.2.1" xref="S3.E2.m1.19.19.1.1.2.2.2.2.1.cmml">=</mo><mrow id="S3.E2.m1.19.19.1.1.2.2.2.2.3" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.cmml"><mstyle displaystyle="true" id="S3.E2.m1.19.19.1.1.2.2.2.2.3.1" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.cmml"><munder id="S3.E2.m1.19.19.1.1.2.2.2.2.3.1a" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.cmml"><mo movablelimits="false" id="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.2" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.2.cmml">∑</mo><mi id="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.3" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.3.cmml">c</mi></munder></mstyle><mrow id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.cmml"><msub id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2.cmml"><mi id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2.2" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2.2.cmml">a</mi><mrow id="S3.E2.m1.16.16.2.4" xref="S3.E2.m1.16.16.2.3.cmml"><mi id="S3.E2.m1.15.15.1.1" xref="S3.E2.m1.15.15.1.1.cmml">c</mi><mo id="S3.E2.m1.16.16.2.4.1" xref="S3.E2.m1.16.16.2.3.cmml">,</mo><mi id="S3.E2.m1.16.16.2.2" xref="S3.E2.m1.16.16.2.2.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.1" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.1.cmml">​</mo><msub id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3.cmml"><mi id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3.2" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3.2.cmml">z</mi><mrow id="S3.E2.m1.18.18.2.4" xref="S3.E2.m1.18.18.2.3.cmml"><mi id="S3.E2.m1.17.17.1.1" xref="S3.E2.m1.17.17.1.1.cmml">c</mi><mo id="S3.E2.m1.18.18.2.4.1" xref="S3.E2.m1.18.18.2.3.cmml">,</mo><mi id="S3.E2.m1.18.18.2.2" xref="S3.E2.m1.18.18.2.2.cmml">t</mi></mrow></msub></mrow></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.19.19.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.19b"><apply id="S3.E2.m1.19.19.1.1.3.cmml" xref="S3.E2.m1.19.19.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.3a.cmml" xref="S3.E2.m1.19.19.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.19.19.1.1.1.1.cmml" xref="S3.E2.m1.19.19.1.1.1.1"><eq id="S3.E2.m1.19.19.1.1.1.1.2.cmml" xref="S3.E2.m1.19.19.1.1.1.1.2"></eq><apply id="S3.E2.m1.19.19.1.1.1.1.3.cmml" xref="S3.E2.m1.19.19.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.1.1.3.1.cmml" xref="S3.E2.m1.19.19.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.19.19.1.1.1.1.3.2.cmml" xref="S3.E2.m1.19.19.1.1.1.1.3.2">𝑧</ci><list id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.4"><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">𝑐</ci><ci id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2">𝑡</ci></list></apply><apply id="S3.E2.m1.19.19.1.1.1.1.1.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1"><times id="S3.E2.m1.19.19.1.1.1.1.1.2.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.2"></times><ci id="S3.E2.m1.19.19.1.1.1.1.1.3.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.3">𝑓</ci><apply id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1"><times id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.3"><mtext id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.3">emb</mtext></ci><apply id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.19.19.1.1.1.1.1.1.1.1.1.1.1.2">𝑑</ci><list id="S3.E2.m1.4.4.2.3.cmml" xref="S3.E2.m1.4.4.2.4"><ci id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1.1">𝑐</ci><ci id="S3.E2.m1.4.4.2.2.cmml" xref="S3.E2.m1.4.4.2.2">𝑡</ci></list></apply></apply></apply></apply><apply id="S3.E2.m1.19.19.1.1.2.2.3.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.2.2.3a.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.19.19.1.1.2.2.1.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.1.1"><eq id="S3.E2.m1.19.19.1.1.2.2.1.1.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.1.1.1"></eq><apply id="S3.E2.m1.19.19.1.1.2.2.1.1.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.2.2.1.1.2.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.1.1.2">subscript</csymbol><ci id="S3.E2.m1.19.19.1.1.2.2.1.1.2.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.1.1.2.2">𝑎</ci><list id="S3.E2.m1.6.6.2.3.cmml" xref="S3.E2.m1.6.6.2.4"><ci id="S3.E2.m1.5.5.1.1.cmml" xref="S3.E2.m1.5.5.1.1">𝑐</ci><ci id="S3.E2.m1.6.6.2.2.cmml" xref="S3.E2.m1.6.6.2.2">𝑡</ci></list></apply><apply id="S3.E2.m1.14.14.cmml" xref="S3.E2.m1.14.14"><divide id="S3.E2.m1.14.14.9.cmml" xref="S3.E2.m1.14.14"></divide><apply id="S3.E2.m1.10.10.4.5.cmml" xref="S3.E2.m1.10.10.4.4"><exp id="S3.E2.m1.9.9.3.3.cmml" xref="S3.E2.m1.9.9.3.3"></exp><apply id="S3.E2.m1.10.10.4.4.1.1.cmml" xref="S3.E2.m1.10.10.4.4.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.4.4.1.1.1.cmml" xref="S3.E2.m1.10.10.4.4.1.1">subscript</csymbol><ci id="S3.E2.m1.10.10.4.4.1.1.2.cmml" xref="S3.E2.m1.10.10.4.4.1.1.2">𝑧</ci><list id="S3.E2.m1.8.8.2.2.2.3.cmml" xref="S3.E2.m1.8.8.2.2.2.4"><ci id="S3.E2.m1.7.7.1.1.1.1.cmml" xref="S3.E2.m1.7.7.1.1.1.1">𝑐</ci><ci id="S3.E2.m1.8.8.2.2.2.2.cmml" xref="S3.E2.m1.8.8.2.2.2.2">𝑡</ci></list></apply></apply><apply id="S3.E2.m1.14.14.8.cmml" xref="S3.E2.m1.14.14.8"><apply id="S3.E2.m1.14.14.8.5.cmml" xref="S3.E2.m1.14.14.8.5"><csymbol cd="ambiguous" id="S3.E2.m1.14.14.8.5.1.cmml" xref="S3.E2.m1.14.14.8.5">superscript</csymbol><apply id="S3.E2.m1.14.14.8.5.2.cmml" xref="S3.E2.m1.14.14.8.5"><csymbol cd="ambiguous" id="S3.E2.m1.14.14.8.5.2.1.cmml" xref="S3.E2.m1.14.14.8.5">subscript</csymbol><sum id="S3.E2.m1.14.14.8.5.2.2.cmml" xref="S3.E2.m1.14.14.8.5.2.2"></sum><apply id="S3.E2.m1.14.14.8.5.2.3.cmml" xref="S3.E2.m1.14.14.8.5.2.3"><eq id="S3.E2.m1.14.14.8.5.2.3.1.cmml" xref="S3.E2.m1.14.14.8.5.2.3.1"></eq><ci id="S3.E2.m1.14.14.8.5.2.3.2.cmml" xref="S3.E2.m1.14.14.8.5.2.3.2">𝑘</ci><cn type="integer" id="S3.E2.m1.14.14.8.5.2.3.3.cmml" xref="S3.E2.m1.14.14.8.5.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.14.14.8.5.3.cmml" xref="S3.E2.m1.14.14.8.5.3">𝐶</ci></apply><apply id="S3.E2.m1.14.14.8.4.2.cmml" xref="S3.E2.m1.14.14.8.4.1"><exp id="S3.E2.m1.13.13.7.3.cmml" xref="S3.E2.m1.13.13.7.3"></exp><apply id="S3.E2.m1.14.14.8.4.1.1.1.cmml" xref="S3.E2.m1.14.14.8.4.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.14.14.8.4.1.1.1.1.cmml" xref="S3.E2.m1.14.14.8.4.1.1.1">subscript</csymbol><ci id="S3.E2.m1.14.14.8.4.1.1.1.2.cmml" xref="S3.E2.m1.14.14.8.4.1.1.1.2">𝑧</ci><list id="S3.E2.m1.12.12.6.2.2.3.cmml" xref="S3.E2.m1.12.12.6.2.2.4"><ci id="S3.E2.m1.11.11.5.1.1.1.cmml" xref="S3.E2.m1.11.11.5.1.1.1">𝑘</ci><ci id="S3.E2.m1.12.12.6.2.2.2.cmml" xref="S3.E2.m1.12.12.6.2.2.2">𝑡</ci></list></apply></apply></apply></apply></apply><apply id="S3.E2.m1.19.19.1.1.2.2.2.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2"><eq id="S3.E2.m1.19.19.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.1"></eq><apply id="S3.E2.m1.19.19.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.2.2.2.2.2.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.19.19.1.1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.2.2">ℎ</ci><ci id="S3.E2.m1.19.19.1.1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.2.3">𝑡</ci></apply><apply id="S3.E2.m1.19.19.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3"><apply id="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.1">subscript</csymbol><sum id="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.2"></sum><ci id="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.3.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.1.3">𝑐</ci></apply><apply id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2"><times id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.1"></times><apply id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2">subscript</csymbol><ci id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.2.2">𝑎</ci><list id="S3.E2.m1.16.16.2.3.cmml" xref="S3.E2.m1.16.16.2.4"><ci id="S3.E2.m1.15.15.1.1.cmml" xref="S3.E2.m1.15.15.1.1">𝑐</ci><ci id="S3.E2.m1.16.16.2.2.cmml" xref="S3.E2.m1.16.16.2.2">𝑡</ci></list></apply><apply id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3.1.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3">subscript</csymbol><ci id="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3.2.cmml" xref="S3.E2.m1.19.19.1.1.2.2.2.2.3.2.3.2">𝑧</ci><list id="S3.E2.m1.18.18.2.3.cmml" xref="S3.E2.m1.18.18.2.4"><ci id="S3.E2.m1.17.17.1.1.cmml" xref="S3.E2.m1.17.17.1.1">𝑐</ci><ci id="S3.E2.m1.18.18.2.2.cmml" xref="S3.E2.m1.18.18.2.2">𝑡</ci></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.19c">\displaystyle z_{c,t}=f\big{(}\text{emb}(d_{c,t})\big{)},\;a_{c,t}=\frac{\exp(z_{c,t})}{\sum_{k=1}^{C}\exp(z_{k,t})},\;h_{t}=\sum_{c}a_{c,t}z_{c,t},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.15" class="ltx_p">where <math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="d_{c,t}" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><msub id="S3.SS2.p1.1.m1.2.3" xref="S3.SS2.p1.1.m1.2.3.cmml"><mi id="S3.SS2.p1.1.m1.2.3.2" xref="S3.SS2.p1.1.m1.2.3.2.cmml">d</mi><mrow id="S3.SS2.p1.1.m1.2.2.2.4" xref="S3.SS2.p1.1.m1.2.2.2.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.1.cmml">c</mi><mo id="S3.SS2.p1.1.m1.2.2.2.4.1" xref="S3.SS2.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p1.1.m1.2.2.2.2" xref="S3.SS2.p1.1.m1.2.2.2.2.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><apply id="S3.SS2.p1.1.m1.2.3.cmml" xref="S3.SS2.p1.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.2.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3">subscript</csymbol><ci id="S3.SS2.p1.1.m1.2.3.2.cmml" xref="S3.SS2.p1.1.m1.2.3.2">𝑑</ci><list id="S3.SS2.p1.1.m1.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.2.2.2.4"><ci id="S3.SS2.p1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1.1">𝑐</ci><ci id="S3.SS2.p1.1.m1.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2.2.2">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">d_{c,t}</annotation></semantics></math> is the discrete token obtained from codebook <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">c</annotation></semantics></math>, at time <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">t</annotation></semantics></math> and, <math id="S3.SS2.p1.4.m4.2" class="ltx_Math" alttext="z_{c,t}" display="inline"><semantics id="S3.SS2.p1.4.m4.2a"><msub id="S3.SS2.p1.4.m4.2.3" xref="S3.SS2.p1.4.m4.2.3.cmml"><mi id="S3.SS2.p1.4.m4.2.3.2" xref="S3.SS2.p1.4.m4.2.3.2.cmml">z</mi><mrow id="S3.SS2.p1.4.m4.2.2.2.4" xref="S3.SS2.p1.4.m4.2.2.2.3.cmml"><mi id="S3.SS2.p1.4.m4.1.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.1.cmml">c</mi><mo id="S3.SS2.p1.4.m4.2.2.2.4.1" xref="S3.SS2.p1.4.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p1.4.m4.2.2.2.2" xref="S3.SS2.p1.4.m4.2.2.2.2.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.2b"><apply id="S3.SS2.p1.4.m4.2.3.cmml" xref="S3.SS2.p1.4.m4.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.2.3.1.cmml" xref="S3.SS2.p1.4.m4.2.3">subscript</csymbol><ci id="S3.SS2.p1.4.m4.2.3.2.cmml" xref="S3.SS2.p1.4.m4.2.3.2">𝑧</ci><list id="S3.SS2.p1.4.m4.2.2.2.3.cmml" xref="S3.SS2.p1.4.m4.2.2.2.4"><ci id="S3.SS2.p1.4.m4.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1">𝑐</ci><ci id="S3.SS2.p1.4.m4.2.2.2.2.cmml" xref="S3.SS2.p1.4.m4.2.2.2.2">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.2c">z_{c,t}</annotation></semantics></math> represents the score assigned to codebook <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">c</annotation></semantics></math>
at time <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">t</annotation></semantics></math> by the MLP function <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><mi id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><ci id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">f</annotation></semantics></math>. The function <math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="\text{emb}(\cdot)" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mrow id="S3.SS2.p1.8.m8.1.2" xref="S3.SS2.p1.8.m8.1.2.cmml"><mtext id="S3.SS2.p1.8.m8.1.2.2" xref="S3.SS2.p1.8.m8.1.2.2a.cmml">emb</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.p1.8.m8.1.2.1" xref="S3.SS2.p1.8.m8.1.2.1.cmml">​</mo><mrow id="S3.SS2.p1.8.m8.1.2.3.2" xref="S3.SS2.p1.8.m8.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.8.m8.1.2.3.2.1" xref="S3.SS2.p1.8.m8.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">⋅</mo><mo stretchy="false" id="S3.SS2.p1.8.m8.1.2.3.2.2" xref="S3.SS2.p1.8.m8.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><apply id="S3.SS2.p1.8.m8.1.2.cmml" xref="S3.SS2.p1.8.m8.1.2"><times id="S3.SS2.p1.8.m8.1.2.1.cmml" xref="S3.SS2.p1.8.m8.1.2.1"></times><ci id="S3.SS2.p1.8.m8.1.2.2a.cmml" xref="S3.SS2.p1.8.m8.1.2.2"><mtext id="S3.SS2.p1.8.m8.1.2.2.cmml" xref="S3.SS2.p1.8.m8.1.2.2">emb</mtext></ci><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">\text{emb}(\cdot)</annotation></semantics></math> refers to the lookup table that assigns embeddings to each discrete token. The variable <math id="S3.SS2.p1.9.m9.2" class="ltx_Math" alttext="a_{c,t}" display="inline"><semantics id="S3.SS2.p1.9.m9.2a"><msub id="S3.SS2.p1.9.m9.2.3" xref="S3.SS2.p1.9.m9.2.3.cmml"><mi id="S3.SS2.p1.9.m9.2.3.2" xref="S3.SS2.p1.9.m9.2.3.2.cmml">a</mi><mrow id="S3.SS2.p1.9.m9.2.2.2.4" xref="S3.SS2.p1.9.m9.2.2.2.3.cmml"><mi id="S3.SS2.p1.9.m9.1.1.1.1" xref="S3.SS2.p1.9.m9.1.1.1.1.cmml">c</mi><mo id="S3.SS2.p1.9.m9.2.2.2.4.1" xref="S3.SS2.p1.9.m9.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p1.9.m9.2.2.2.2" xref="S3.SS2.p1.9.m9.2.2.2.2.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.2b"><apply id="S3.SS2.p1.9.m9.2.3.cmml" xref="S3.SS2.p1.9.m9.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.9.m9.2.3.1.cmml" xref="S3.SS2.p1.9.m9.2.3">subscript</csymbol><ci id="S3.SS2.p1.9.m9.2.3.2.cmml" xref="S3.SS2.p1.9.m9.2.3.2">𝑎</ci><list id="S3.SS2.p1.9.m9.2.2.2.3.cmml" xref="S3.SS2.p1.9.m9.2.2.2.4"><ci id="S3.SS2.p1.9.m9.1.1.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1.1.1">𝑐</ci><ci id="S3.SS2.p1.9.m9.2.2.2.2.cmml" xref="S3.SS2.p1.9.m9.2.2.2.2">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.2c">a_{c,t}</annotation></semantics></math> denotes the attention assigned to the codebook <math id="S3.SS2.p1.10.m10.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p1.10.m10.1a"><mi id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><ci id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">c</annotation></semantics></math> at time <math id="S3.SS2.p1.11.m11.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p1.11.m11.1a"><mi id="S3.SS2.p1.11.m11.1.1" xref="S3.SS2.p1.11.m11.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m11.1b"><ci id="S3.SS2.p1.11.m11.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m11.1c">t</annotation></semantics></math>, and lastly <math id="S3.SS2.p1.12.m12.1" class="ltx_Math" alttext="h_{t}" display="inline"><semantics id="S3.SS2.p1.12.m12.1a"><msub id="S3.SS2.p1.12.m12.1.1" xref="S3.SS2.p1.12.m12.1.1.cmml"><mi id="S3.SS2.p1.12.m12.1.1.2" xref="S3.SS2.p1.12.m12.1.1.2.cmml">h</mi><mi id="S3.SS2.p1.12.m12.1.1.3" xref="S3.SS2.p1.12.m12.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m12.1b"><apply id="S3.SS2.p1.12.m12.1.1.cmml" xref="S3.SS2.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.12.m12.1.1.1.cmml" xref="S3.SS2.p1.12.m12.1.1">subscript</csymbol><ci id="S3.SS2.p1.12.m12.1.1.2.cmml" xref="S3.SS2.p1.12.m12.1.1.2">ℎ</ci><ci id="S3.SS2.p1.12.m12.1.1.3.cmml" xref="S3.SS2.p1.12.m12.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m12.1c">h_{t}</annotation></semantics></math> is the representation that is fed to the downstream MLP model.
We would like to note that the MLP learns different codebook combinations <math id="S3.SS2.p1.13.m13.1" class="ltx_Math" alttext="h_{t}" display="inline"><semantics id="S3.SS2.p1.13.m13.1a"><msub id="S3.SS2.p1.13.m13.1.1" xref="S3.SS2.p1.13.m13.1.1.cmml"><mi id="S3.SS2.p1.13.m13.1.1.2" xref="S3.SS2.p1.13.m13.1.1.2.cmml">h</mi><mi id="S3.SS2.p1.13.m13.1.1.3" xref="S3.SS2.p1.13.m13.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.13.m13.1b"><apply id="S3.SS2.p1.13.m13.1.1.cmml" xref="S3.SS2.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.13.m13.1.1.1.cmml" xref="S3.SS2.p1.13.m13.1.1">subscript</csymbol><ci id="S3.SS2.p1.13.m13.1.1.2.cmml" xref="S3.SS2.p1.13.m13.1.1.2">ℎ</ci><ci id="S3.SS2.p1.13.m13.1.1.3.cmml" xref="S3.SS2.p1.13.m13.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m13.1c">h_{t}</annotation></semantics></math> at each time step <math id="S3.SS2.p1.14.m14.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p1.14.m14.1a"><mi id="S3.SS2.p1.14.m14.1.1" xref="S3.SS2.p1.14.m14.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.14.m14.1b"><ci id="S3.SS2.p1.14.m14.1.1.cmml" xref="S3.SS2.p1.14.m14.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.14.m14.1c">t</annotation></semantics></math> depending on the attention weights <math id="S3.SS2.p1.15.m15.2" class="ltx_Math" alttext="a_{c,t}" display="inline"><semantics id="S3.SS2.p1.15.m15.2a"><msub id="S3.SS2.p1.15.m15.2.3" xref="S3.SS2.p1.15.m15.2.3.cmml"><mi id="S3.SS2.p1.15.m15.2.3.2" xref="S3.SS2.p1.15.m15.2.3.2.cmml">a</mi><mrow id="S3.SS2.p1.15.m15.2.2.2.4" xref="S3.SS2.p1.15.m15.2.2.2.3.cmml"><mi id="S3.SS2.p1.15.m15.1.1.1.1" xref="S3.SS2.p1.15.m15.1.1.1.1.cmml">c</mi><mo id="S3.SS2.p1.15.m15.2.2.2.4.1" xref="S3.SS2.p1.15.m15.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p1.15.m15.2.2.2.2" xref="S3.SS2.p1.15.m15.2.2.2.2.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.15.m15.2b"><apply id="S3.SS2.p1.15.m15.2.3.cmml" xref="S3.SS2.p1.15.m15.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.15.m15.2.3.1.cmml" xref="S3.SS2.p1.15.m15.2.3">subscript</csymbol><ci id="S3.SS2.p1.15.m15.2.3.2.cmml" xref="S3.SS2.p1.15.m15.2.3.2">𝑎</ci><list id="S3.SS2.p1.15.m15.2.2.2.3.cmml" xref="S3.SS2.p1.15.m15.2.2.2.4"><ci id="S3.SS2.p1.15.m15.1.1.1.1.cmml" xref="S3.SS2.p1.15.m15.1.1.1.1">𝑐</ci><ci id="S3.SS2.p1.15.m15.2.2.2.2.cmml" xref="S3.SS2.p1.15.m15.2.2.2.2">𝑡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.15.m15.2c">a_{c,t}</annotation></semantics></math>, enabling the model to extract the necessary information when required. We also considered summing all embeddings, as has been done in previous literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, but found that attention weights performed slightly better.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.3" class="ltx_p">The combined representations <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="h_{t}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">h</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ℎ</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">h_{t}</annotation></semantics></math> are fed into neural models designed for different tasks.
The downstream models are jointly trained with their attention and embedding layers in an end-to-end fashion.
For discriminative tasks, the model outputs either a single prediction (e.g., for emotion recognition) or a sequence of predictions (e.g., for speech recognition).
For generative tasks (e.g., speech enhancement), the neural network outputs the targeted tokens per codebook, with the output shape being <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="C\times L" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mrow id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.cmml">×</mo><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><times id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1"></times><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝐶</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">C\times L</annotation></semantics></math>, where <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">L</annotation></semantics></math> is the sequence length. The predicted audio tokens are converted into an audio waveform via an audio decoder, as explained in the next section.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Discrete Audio Decoder</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">The decoder, used for generative tasks only, converts the predicted tokens into audio signals. The decoder is frozen during training.
The choice of decoder depends on the encoder used in the first step. For compression and hybrid tokenizers, we use their built-in decoder. For semantic tokens, we use the scalable vocoder proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, which is a modified HiFi-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> pretrained with LibriSpeech-960h <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. The scalable vocoder accepts a variable number of multi-layer semantic tokens as input and can handle different bitrates using a layer dropout mechanism.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">In the following sections, we describe the discriminative and generative tasks considered in our experiments. For a more reliable evaluation, we tested two downstream architectures for each task.
For detailed information about the hyperparameters used in each experiment, refer to Appendix
<a href="#A6" title="Appendix F Hyperparameters ‣ Appendix E Additional Results ‣ Appendix D Additional Analysis of Discrete Audio Decoders ‣ Appendix C Dataset and Downstream Models ‣ Appendix B Discrete Audio Models Details ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Discriminative Tasks</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">For the downstream architectures and training procedures, we follow the best-performing approaches for classic continuous self-supervised representations proposed in  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para ltx_noindent">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Automatic Speech Recognition (ASR)</span>: The goal of ASR is converting speech signals into written text. We address two ASR tasks. The first task involves English ASR using the popular LibriSpeech dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Training and validation are performed on the train-clean-100 and dev-clean subsets, respectively, while testing is conducted on the test-clean and test-other subsets.
The downstream architecture for this task consists of two layers of Bidirectional Long Short-Term Memory (BiLSTM) followed by a linear layer for mapping audio to characters. The second architecture utilizes ContextNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> with unitary strides to maintain the frame rate of the encoder models.
Additionally, we explore low-resource languages, specifically Welsh (Cymraeg) and Basque (Euskera) datasets extracted from CommonVoice 17.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. Here, we evaluate the performance using both the BiLSTM architecture and a two-layer dense neural network mapping frame representations to character probabilities. We use the Word Error Rate (WER) as the error metric for all ASR tasks.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Speaker Identification/Verification (SID, SV)</span>: Speaker Identification involves classifying each utterance by its speaker identity as a multi-class classification, with the same predefined set of speakers for both training and testing. The evaluation metric is the accuracy. Automatic Speaker Verification (ASV), instead, involves training a binary classifier to determine whether the speakers in a pair of utterances are the same. The evaluation metric adopted in this case is the equal error rate (EER). We use the widely-used VoxCeleb1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> train and test splits for both tasks. First, we test the X-vector <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> architecture with AM-Softmax <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> loss for training the speaker embeddings. For verification, we use the cosine similarity between speaker representations. As a second architecture, we replace the X-vectors with an ECAPA-TDNN neural network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Emotion Recognition (ER)</span>: The task involves predicting one of the four classes: <span id="S4.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">happy</span>, <span id="S4.I1.i3.p1.1.3" class="ltx_text ltx_font_italic">sad</span>, <span id="S4.I1.i3.p1.1.4" class="ltx_text ltx_font_italic">angry</span>, and <span id="S4.I1.i3.p1.1.5" class="ltx_text ltx_font_italic">neutral</span>. We use the popular IEMOCAP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> dataset, which contains about 10k samples from 10 speakers. As a first architecture, we directly input the representations into a linear classification layer after averaging them along the time axis. For the second downstream architecture, we use ECAPA-TDNN. The evaluation metric is the accuracy.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Intent Classification (IC)</span>: This task aims to determine the intention or purpose given utterance a speech recording. In particular, we here aim to classify each utterance into one of 18 scenarios, including <span id="S4.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">calendar</span>, <span id="S4.I1.i4.p1.1.3" class="ltx_text ltx_font_italic">email</span>, and <span id="S4.I1.i4.p1.1.4" class="ltx_text ltx_font_italic">alarm</span>. For this task, we utilize the SLURP dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, which comprises around 72k audio recordings of single-turn user interactions with a home assistant.
We employ ECAPA-TDNN and a two-layer BiLSTM (followed by a linear classifier) as downstream architectures. We evaluate the performance using the accuracy.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para ltx_noindent">
<p id="S4.I1.i5.p1.1" class="ltx_p"><span id="S4.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Keyword Spotting (KS)</span>: Keyword Spotting involves detecting predefined keywords by classifying utterances into a set of specified words. We use the Speech Commands dataset v1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> for this task, as done in SUPERB. The dataset includes ten classes of keywords, a class for silence, and an unknown class to account for false positives. We employ both the X-vector and ECAPA-TDNN architectures. The evaluation metric is the accuracy.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Generative Tasks</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Speech Enhancement (SE)</span>:
Speech enhancement aims to improve audio quality by cleaning up noisy input recordings.
For this task, we utilize the popular VoiceBank dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.
We employ two downstream architectures: a non-autoregressive Conformer encoder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, and a convolutional recurrent deep neural network (CRDNN).
The input tokens are extracted from the noisy signal, while target tokens from the clean one. Training is performed using the cross-entropy loss.
The speech quality is assessed using the deep noise suppression mean opinion score (DNSMOS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. The intelligibility is evaluated through the differential word error rate (dWER) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, which measures the WER between the transcribed enhanced signal and the transcribed target signal. The transcriptions are obtained using the small version of Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. Additionally, to measure speaker fidelity, we use the cosine similarity (SpkSim) between X-vectors extracted from the enhanced signal and the target signal using the base variant of WavLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> fine-tuned for speaker verification.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Speech Separation (SS)</span>: Speech separation aims to isolate individual voices from an audio recording containing multiple speakers. For this task, we use the Libri2Mix dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, which contains mixtures of two overlapping speakers. We employ two downstream architectures: a non-autoregressive Conformer encoder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, and a convolutional recurrent deep neural network (CRDNN).
The input tokens are extracted from the mixture, while target tokens from each of the two sources. Training is performed using the cross-entropy loss with permutation invariant training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.
To measure performance, we employ the same metrics as speech enhancement.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para ltx_noindent">
<p id="S4.I2.i3.p1.1" class="ltx_p"><span id="S4.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Text-to-Speech (TTS)</span>: The task involves generating raw speech audio from a given text input. For downstream architectures, we consider both a small and a large autoregressive Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. We train all models on the LJSpeech dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. To assess the speech quality, we use a pretrained UTokyo-SaruLab System (UTMOS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, which is specifically designed for TTS and trained to predict human Mean Opinion scores. To measure pronunciation accuracy, we use the dWER metric. This involves comparing the transcriptions provided by a speech recognizer for the synthesized speech sample with the transcriptions from the ground truth. As for enhancement and separation, we considered the small version of Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Benchmarking results for discriminative tasks.</figcaption>
<div id="S4.T2.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:437.0pt;height:369.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="S4.T2.7.7" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:369.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.5pt,13.2pt) scale(0.933463113292097,0.933463113292097) ;">
<table id="S4.T2.7.7.7" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.7.7.7.8.1" class="ltx_tr">
<td id="S4.T2.7.7.7.8.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T2.7.7.7.8.1.1.1" class="ltx_text ltx_font_bold">Models/Tasks</span></td>
<td id="S4.T2.7.7.7.8.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S4.T2.7.7.7.8.1.2.1" class="ltx_text ltx_font_bold">ASR-En</span></td>
<td id="S4.T2.7.7.7.8.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S4.T2.7.7.7.8.1.3.1" class="ltx_text ltx_font_bold">ASR-multiling</span></td>
<td id="S4.T2.7.7.7.8.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.8.1.4.1" class="ltx_text ltx_font_bold">ER</span></td>
<td id="S4.T2.7.7.7.8.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.8.1.5.1" class="ltx_text ltx_font_bold">IC</span></td>
<td id="S4.T2.7.7.7.8.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.8.1.6.1" class="ltx_text ltx_font_bold">KS</span></td>
<td id="S4.T2.7.7.7.8.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.8.1.7.1" class="ltx_text ltx_font_bold">SI</span></td>
<td id="S4.T2.7.7.7.8.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.8.1.8.1" class="ltx_text ltx_font_bold">SV</span></td>
</tr>
<tr id="S4.T2.7.7.7.7" class="ltx_tr">
<td id="S4.T2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">
<span id="S4.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">WER</span> <math id="S4.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">
<span id="S4.T2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">WER</span> <math id="S4.T2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T2.2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T2.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.3.3.3.3.3.1" class="ltx_text"><span id="S4.T2.3.3.3.3.3.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="S4.T2.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.3.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T2.3.3.3.3.3.1.m1.1.1" xref="S4.T2.3.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.3.1.m1.1b"><ci id="S4.T2.3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T2.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.4.4.4.4.4.1" class="ltx_text"><span id="S4.T2.4.4.4.4.4.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="S4.T2.4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.4.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T2.4.4.4.4.4.1.m1.1.1" xref="S4.T2.4.4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.4.1.m1.1b"><ci id="S4.T2.4.4.4.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T2.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.5.5.5.5.5.1" class="ltx_text"><span id="S4.T2.5.5.5.5.5.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="S4.T2.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.5.5.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T2.5.5.5.5.5.1.m1.1.1" xref="S4.T2.5.5.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.5.5.1.m1.1b"><ci id="S4.T2.5.5.5.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.5.5.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T2.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.6.6.6.6.6.1" class="ltx_text"><span id="S4.T2.6.6.6.6.6.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="S4.T2.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.6.6.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T2.6.6.6.6.6.1.m1.1.1" xref="S4.T2.6.6.6.6.6.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.6.6.1.m1.1b"><ci id="S4.T2.6.6.6.6.6.1.m1.1.1.cmml" xref="S4.T2.6.6.6.6.6.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.6.6.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T2.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T2.7.7.7.7.7.1" class="ltx_text"><span id="S4.T2.7.7.7.7.7.1.1" class="ltx_text ltx_font_bold">EER</span> <math id="S4.T2.7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.7.7.7.7.7.1.m1.1a"><mo stretchy="false" id="S4.T2.7.7.7.7.7.1.m1.1.1" xref="S4.T2.7.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.7.7.1.m1.1b"><ci id="S4.T2.7.7.7.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S4.T2.7.7.7.9.2" class="ltx_tr">
<td id="S4.T2.7.7.7.9.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.9.2.1.1" class="ltx_text ltx_font_bold">Clean</span></td>
<td id="S4.T2.7.7.7.9.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.9.2.2.1" class="ltx_text ltx_font_bold">Other</span></td>
<td id="S4.T2.7.7.7.9.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.9.2.3.1" class="ltx_text ltx_font_bold">Welsh</span></td>
<td id="S4.T2.7.7.7.9.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.9.2.4.1" class="ltx_text ltx_font_bold">Basque</span></td>
</tr>
<tr id="S4.T2.7.7.7.10.3" class="ltx_tr">
<td id="S4.T2.7.7.7.10.3.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="S4.T2.7.7.7.10.3.1.1" class="ltx_text ltx_font_italic">Low Bitrate</span></td>
</tr>
<tr id="S4.T2.7.7.7.11.4" class="ltx_tr">
<td id="S4.T2.7.7.7.11.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete Hubert</td>
<td id="S4.T2.7.7.7.11.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.11.4.2.1" class="ltx_text ltx_font_bold">8.99</span></td>
<td id="S4.T2.7.7.7.11.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.11.4.3.1" class="ltx_text ltx_font_bold">21.14</span></td>
<td id="S4.T2.7.7.7.11.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.11.4.4.1" class="ltx_text ltx_font_bold">58.50</span></td>
<td id="S4.T2.7.7.7.11.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.11.4.5.1" class="ltx_text ltx_font_bold">26.83</span></td>
<td id="S4.T2.7.7.7.11.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.20</td>
<td id="S4.T2.7.7.7.11.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.70</td>
<td id="S4.T2.7.7.7.11.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.54</td>
<td id="S4.T2.7.7.7.11.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.90</td>
<td id="S4.T2.7.7.7.11.4.10" class="ltx_td ltx_align_center ltx_border_t">24.99</td>
</tr>
<tr id="S4.T2.7.7.7.12.5" class="ltx_tr">
<td id="S4.T2.7.7.7.12.5.1" class="ltx_td ltx_align_left ltx_border_r">Discrete WavLM</td>
<td id="S4.T2.7.7.7.12.5.2" class="ltx_td ltx_align_center">11.72</td>
<td id="S4.T2.7.7.7.12.5.3" class="ltx_td ltx_align_center ltx_border_r">27.56</td>
<td id="S4.T2.7.7.7.12.5.4" class="ltx_td ltx_align_center">60.37</td>
<td id="S4.T2.7.7.7.12.5.5" class="ltx_td ltx_align_center ltx_border_r">28.63</td>
<td id="S4.T2.7.7.7.12.5.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.12.5.6.1" class="ltx_text ltx_font_bold">59.80</span></td>
<td id="S4.T2.7.7.7.12.5.7" class="ltx_td ltx_align_center ltx_border_r">73.40</td>
<td id="S4.T2.7.7.7.12.5.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.12.5.8.1" class="ltx_text ltx_font_bold">97.94</span></td>
<td id="S4.T2.7.7.7.12.5.9" class="ltx_td ltx_align_center ltx_border_r">0.70</td>
<td id="S4.T2.7.7.7.12.5.10" class="ltx_td ltx_align_center">26.02</td>
</tr>
<tr id="S4.T2.7.7.7.13.6" class="ltx_tr">
<td id="S4.T2.7.7.7.13.6.1" class="ltx_td ltx_align_left ltx_border_r">Discrete Wav2Vec2</td>
<td id="S4.T2.7.7.7.13.6.2" class="ltx_td ltx_align_center">12.14</td>
<td id="S4.T2.7.7.7.13.6.3" class="ltx_td ltx_align_center ltx_border_r">28.65</td>
<td id="S4.T2.7.7.7.13.6.4" class="ltx_td ltx_align_center">66.30</td>
<td id="S4.T2.7.7.7.13.6.5" class="ltx_td ltx_align_center ltx_border_r">32.25</td>
<td id="S4.T2.7.7.7.13.6.6" class="ltx_td ltx_align_center ltx_border_r">57.80</td>
<td id="S4.T2.7.7.7.13.6.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.13.6.7.1" class="ltx_text ltx_font_bold">74.10</span></td>
<td id="S4.T2.7.7.7.13.6.8" class="ltx_td ltx_align_center ltx_border_r">96.16</td>
<td id="S4.T2.7.7.7.13.6.9" class="ltx_td ltx_align_center ltx_border_r">0.40</td>
<td id="S4.T2.7.7.7.13.6.10" class="ltx_td ltx_align_center">33.53</td>
</tr>
<tr id="S4.T2.7.7.7.14.7" class="ltx_tr">
<td id="S4.T2.7.7.7.14.7.1" class="ltx_td ltx_align_left ltx_border_r">EnCodec</td>
<td id="S4.T2.7.7.7.14.7.2" class="ltx_td ltx_align_center">52.37</td>
<td id="S4.T2.7.7.7.14.7.3" class="ltx_td ltx_align_center ltx_border_r">77.04</td>
<td id="S4.T2.7.7.7.14.7.4" class="ltx_td ltx_align_center">92.01</td>
<td id="S4.T2.7.7.7.14.7.5" class="ltx_td ltx_align_center ltx_border_r">58.20</td>
<td id="S4.T2.7.7.7.14.7.6" class="ltx_td ltx_align_center ltx_border_r">44.70</td>
<td id="S4.T2.7.7.7.14.7.7" class="ltx_td ltx_align_center ltx_border_r">31.50</td>
<td id="S4.T2.7.7.7.14.7.8" class="ltx_td ltx_align_center ltx_border_r">86.00</td>
<td id="S4.T2.7.7.7.14.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.14.7.9.1" class="ltx_text ltx_font_bold">58.30</span></td>
<td id="S4.T2.7.7.7.14.7.10" class="ltx_td ltx_align_center"><span id="S4.T2.7.7.7.14.7.10.1" class="ltx_text ltx_font_bold">17.40</span></td>
</tr>
<tr id="S4.T2.7.7.7.15.8" class="ltx_tr">
<td id="S4.T2.7.7.7.15.8.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="S4.T2.7.7.7.15.8.2" class="ltx_td ltx_align_center">63.96</td>
<td id="S4.T2.7.7.7.15.8.3" class="ltx_td ltx_align_center ltx_border_r">83.61</td>
<td id="S4.T2.7.7.7.15.8.4" class="ltx_td ltx_align_center">94.86</td>
<td id="S4.T2.7.7.7.15.8.5" class="ltx_td ltx_align_center ltx_border_r">66.29</td>
<td id="S4.T2.7.7.7.15.8.6" class="ltx_td ltx_align_center ltx_border_r">49.20</td>
<td id="S4.T2.7.7.7.15.8.7" class="ltx_td ltx_align_center ltx_border_r">22.10</td>
<td id="S4.T2.7.7.7.15.8.8" class="ltx_td ltx_align_center ltx_border_r">81.00</td>
<td id="S4.T2.7.7.7.15.8.9" class="ltx_td ltx_align_center ltx_border_r">45.10</td>
<td id="S4.T2.7.7.7.15.8.10" class="ltx_td ltx_align_center">20.62</td>
</tr>
<tr id="S4.T2.7.7.7.16.9" class="ltx_tr">
<td id="S4.T2.7.7.7.16.9.1" class="ltx_td ltx_align_left ltx_border_r">SpeechTokenizer</td>
<td id="S4.T2.7.7.7.16.9.2" class="ltx_td ltx_align_center">19.77</td>
<td id="S4.T2.7.7.7.16.9.3" class="ltx_td ltx_align_center ltx_border_r">43.12</td>
<td id="S4.T2.7.7.7.16.9.4" class="ltx_td ltx_align_center">76.67</td>
<td id="S4.T2.7.7.7.16.9.5" class="ltx_td ltx_align_center ltx_border_r">47.92</td>
<td id="S4.T2.7.7.7.16.9.6" class="ltx_td ltx_align_center ltx_border_r">49.10</td>
<td id="S4.T2.7.7.7.16.9.7" class="ltx_td ltx_align_center ltx_border_r">57.90</td>
<td id="S4.T2.7.7.7.16.9.8" class="ltx_td ltx_align_center ltx_border_r">95.09</td>
<td id="S4.T2.7.7.7.16.9.9" class="ltx_td ltx_align_center ltx_border_r">47.40</td>
<td id="S4.T2.7.7.7.16.9.10" class="ltx_td ltx_align_center">20.41</td>
</tr>
<tr id="S4.T2.7.7.7.17.10" class="ltx_tr">
<td id="S4.T2.7.7.7.17.10.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="S4.T2.7.7.7.17.10.1.1" class="ltx_text ltx_font_italic">Medium Bitrate</span></td>
</tr>
<tr id="S4.T2.7.7.7.18.11" class="ltx_tr">
<td id="S4.T2.7.7.7.18.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete Hubert</td>
<td id="S4.T2.7.7.7.18.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.18.11.2.1" class="ltx_text ltx_font_bold">7.91</span></td>
<td id="S4.T2.7.7.7.18.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.18.11.3.1" class="ltx_text ltx_font_bold">18.95</span></td>
<td id="S4.T2.7.7.7.18.11.4" class="ltx_td ltx_align_center ltx_border_t">54.77</td>
<td id="S4.T2.7.7.7.18.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">23.63</td>
<td id="S4.T2.7.7.7.18.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.18.11.6.1" class="ltx_text ltx_font_bold">62.10</span></td>
<td id="S4.T2.7.7.7.18.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.50</td>
<td id="S4.T2.7.7.7.18.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.69</td>
<td id="S4.T2.7.7.7.18.11.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67.40</td>
<td id="S4.T2.7.7.7.18.11.10" class="ltx_td ltx_align_center ltx_border_t">15.71</td>
</tr>
<tr id="S4.T2.7.7.7.19.12" class="ltx_tr">
<td id="S4.T2.7.7.7.19.12.1" class="ltx_td ltx_align_left ltx_border_r">Discrete WavLM</td>
<td id="S4.T2.7.7.7.19.12.2" class="ltx_td ltx_align_center">8.52</td>
<td id="S4.T2.7.7.7.19.12.3" class="ltx_td ltx_align_center ltx_border_r">20.35</td>
<td id="S4.T2.7.7.7.19.12.4" class="ltx_td ltx_align_center"><span id="S4.T2.7.7.7.19.12.4.1" class="ltx_text ltx_font_bold">54.22</span></td>
<td id="S4.T2.7.7.7.19.12.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.19.12.5.1" class="ltx_text ltx_font_bold">22.06</span></td>
<td id="S4.T2.7.7.7.19.12.6" class="ltx_td ltx_align_center ltx_border_r">57.60</td>
<td id="S4.T2.7.7.7.19.12.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.19.12.7.1" class="ltx_text ltx_font_bold">78.00</span></td>
<td id="S4.T2.7.7.7.19.12.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.19.12.8.1" class="ltx_text ltx_font_bold">98.09</span></td>
<td id="S4.T2.7.7.7.19.12.9" class="ltx_td ltx_align_center ltx_border_r">80.80</td>
<td id="S4.T2.7.7.7.19.12.10" class="ltx_td ltx_align_center">8.00</td>
</tr>
<tr id="S4.T2.7.7.7.20.13" class="ltx_tr">
<td id="S4.T2.7.7.7.20.13.1" class="ltx_td ltx_align_left ltx_border_r">Discrete Wav2Vec2</td>
<td id="S4.T2.7.7.7.20.13.2" class="ltx_td ltx_align_center">8.76</td>
<td id="S4.T2.7.7.7.20.13.3" class="ltx_td ltx_align_center ltx_border_r">21.32</td>
<td id="S4.T2.7.7.7.20.13.4" class="ltx_td ltx_align_center">60.39</td>
<td id="S4.T2.7.7.7.20.13.5" class="ltx_td ltx_align_center ltx_border_r">26.64</td>
<td id="S4.T2.7.7.7.20.13.6" class="ltx_td ltx_align_center ltx_border_r">59.10</td>
<td id="S4.T2.7.7.7.20.13.7" class="ltx_td ltx_align_center ltx_border_r">75.10</td>
<td id="S4.T2.7.7.7.20.13.8" class="ltx_td ltx_align_center ltx_border_r">96.64</td>
<td id="S4.T2.7.7.7.20.13.9" class="ltx_td ltx_align_center ltx_border_r">65.47</td>
<td id="S4.T2.7.7.7.20.13.10" class="ltx_td ltx_align_center">17.64</td>
</tr>
<tr id="S4.T2.7.7.7.21.14" class="ltx_tr">
<td id="S4.T2.7.7.7.21.14.1" class="ltx_td ltx_align_left ltx_border_r">EnCodec</td>
<td id="S4.T2.7.7.7.21.14.2" class="ltx_td ltx_align_center">46.80</td>
<td id="S4.T2.7.7.7.21.14.3" class="ltx_td ltx_align_center ltx_border_r">74.24</td>
<td id="S4.T2.7.7.7.21.14.4" class="ltx_td ltx_align_center">91.23</td>
<td id="S4.T2.7.7.7.21.14.5" class="ltx_td ltx_align_center ltx_border_r">47.95</td>
<td id="S4.T2.7.7.7.21.14.6" class="ltx_td ltx_align_center ltx_border_r">51.30</td>
<td id="S4.T2.7.7.7.21.14.7" class="ltx_td ltx_align_center ltx_border_r">31.40</td>
<td id="S4.T2.7.7.7.21.14.8" class="ltx_td ltx_align_center ltx_border_r">88.70</td>
<td id="S4.T2.7.7.7.21.14.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.21.14.9.1" class="ltx_text ltx_font_bold">91.90</span></td>
<td id="S4.T2.7.7.7.21.14.10" class="ltx_td ltx_align_center"><span id="S4.T2.7.7.7.21.14.10.1" class="ltx_text ltx_font_bold">7.81</span></td>
</tr>
<tr id="S4.T2.7.7.7.22.15" class="ltx_tr">
<td id="S4.T2.7.7.7.22.15.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="S4.T2.7.7.7.22.15.2" class="ltx_td ltx_align_center">59.54</td>
<td id="S4.T2.7.7.7.22.15.3" class="ltx_td ltx_align_center ltx_border_r">81.48</td>
<td id="S4.T2.7.7.7.22.15.4" class="ltx_td ltx_align_center">97.43</td>
<td id="S4.T2.7.7.7.22.15.5" class="ltx_td ltx_align_center ltx_border_r">56.16</td>
<td id="S4.T2.7.7.7.22.15.6" class="ltx_td ltx_align_center ltx_border_r">45.80</td>
<td id="S4.T2.7.7.7.22.15.7" class="ltx_td ltx_align_center ltx_border_r">18.90</td>
<td id="S4.T2.7.7.7.22.15.8" class="ltx_td ltx_align_center ltx_border_r">76.60</td>
<td id="S4.T2.7.7.7.22.15.9" class="ltx_td ltx_align_center ltx_border_r">83.80</td>
<td id="S4.T2.7.7.7.22.15.10" class="ltx_td ltx_align_center">11.78</td>
</tr>
<tr id="S4.T2.7.7.7.23.16" class="ltx_tr">
<td id="S4.T2.7.7.7.23.16.1" class="ltx_td ltx_align_left ltx_border_r">SpeechTokenizer</td>
<td id="S4.T2.7.7.7.23.16.2" class="ltx_td ltx_align_center">18.32</td>
<td id="S4.T2.7.7.7.23.16.3" class="ltx_td ltx_align_center ltx_border_r">41.21</td>
<td id="S4.T2.7.7.7.23.16.4" class="ltx_td ltx_align_center">75.17</td>
<td id="S4.T2.7.7.7.23.16.5" class="ltx_td ltx_align_center ltx_border_r">38.94</td>
<td id="S4.T2.7.7.7.23.16.6" class="ltx_td ltx_align_center ltx_border_r">52.10</td>
<td id="S4.T2.7.7.7.23.16.7" class="ltx_td ltx_align_center ltx_border_r">57.80</td>
<td id="S4.T2.7.7.7.23.16.8" class="ltx_td ltx_align_center ltx_border_r">94.86</td>
<td id="S4.T2.7.7.7.23.16.9" class="ltx_td ltx_align_center ltx_border_r">91.40</td>
<td id="S4.T2.7.7.7.23.16.10" class="ltx_td ltx_align_center">7.88</td>
</tr>
<tr id="S4.T2.7.7.7.24.17" class="ltx_tr">
<td id="S4.T2.7.7.7.24.17.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="S4.T2.7.7.7.24.17.1.1" class="ltx_text ltx_font_italic">High Bitrate</span></td>
</tr>
<tr id="S4.T2.7.7.7.25.18" class="ltx_tr">
<td id="S4.T2.7.7.7.25.18.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">EnCodec</td>
<td id="S4.T2.7.7.7.25.18.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.25.18.2.1" class="ltx_text ltx_font_bold">45.18</span></td>
<td id="S4.T2.7.7.7.25.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.25.18.3.1" class="ltx_text ltx_font_bold">72.56</span></td>
<td id="S4.T2.7.7.7.25.18.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.25.18.4.1" class="ltx_text ltx_font_bold">93.40</span></td>
<td id="S4.T2.7.7.7.25.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.25.18.5.1" class="ltx_text ltx_font_bold">87.65</span></td>
<td id="S4.T2.7.7.7.25.18.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.40</td>
<td id="S4.T2.7.7.7.25.18.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.25.18.7.1" class="ltx_text ltx_font_bold">19.60</span></td>
<td id="S4.T2.7.7.7.25.18.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.25.18.8.1" class="ltx_text ltx_font_bold">83.60</span></td>
<td id="S4.T2.7.7.7.25.18.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.7.7.7.25.18.9.1" class="ltx_text ltx_font_bold">92.81</span></td>
<td id="S4.T2.7.7.7.25.18.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.7.7.7.25.18.10.1" class="ltx_text ltx_font_bold">7.18</span></td>
</tr>
<tr id="S4.T2.7.7.7.26.19" class="ltx_tr">
<td id="S4.T2.7.7.7.26.19.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="S4.T2.7.7.7.26.19.2" class="ltx_td ltx_align_center">99.53</td>
<td id="S4.T2.7.7.7.26.19.3" class="ltx_td ltx_align_center ltx_border_r">99.38</td>
<td id="S4.T2.7.7.7.26.19.4" class="ltx_td ltx_align_center">99.40</td>
<td id="S4.T2.7.7.7.26.19.5" class="ltx_td ltx_align_center ltx_border_r">99.68</td>
<td id="S4.T2.7.7.7.26.19.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.7.7.7.26.19.6.1" class="ltx_text ltx_font_bold">46.00</span></td>
<td id="S4.T2.7.7.7.26.19.7" class="ltx_td ltx_align_center ltx_border_r">15.70</td>
<td id="S4.T2.7.7.7.26.19.8" class="ltx_td ltx_align_center ltx_border_r">75.20</td>
<td id="S4.T2.7.7.7.26.19.9" class="ltx_td ltx_align_center ltx_border_r">85.61</td>
<td id="S4.T2.7.7.7.26.19.10" class="ltx_td ltx_align_center">10.89</td>
</tr>
<tr id="S4.T2.7.7.7.27.20" class="ltx_tr">
<td id="S4.T2.7.7.7.27.20.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="S4.T2.7.7.7.27.20.1.1" class="ltx_text ltx_font_italic">Continuous Baseline</span></td>
</tr>
<tr id="S4.T2.7.7.7.28.21" class="ltx_tr">
<td id="S4.T2.7.7.7.28.21.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">SSL</td>
<td id="S4.T2.7.7.7.28.21.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.370</td>
<td id="S4.T2.7.7.7.28.21.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">7.04</td>
<td id="S4.T2.7.7.7.28.21.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">41.77</td>
<td id="S4.T2.7.7.7.28.21.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">14.32</td>
<td id="S4.T2.7.7.7.28.21.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">63.10</td>
<td id="S4.T2.7.7.7.28.21.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">86.10</td>
<td id="S4.T2.7.7.7.28.21.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">99.00</td>
<td id="S4.T2.7.7.7.28.21.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">99.70</td>
<td id="S4.T2.7.7.7.28.21.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">2.10</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Benchmarking results for generative tasks. N.C. indicates “Not Converged". </figcaption>
<div id="S4.T3.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:393.6pt;height:270.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="S4.T3.8.8" class="ltx_inline-block ltx_transformed_outer" style="width:390.3pt;height:270.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-77.3pt,53.6pt) scale(0.716209702766986,0.716209702766986) ;">
<table id="S4.T3.8.8.8" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.8.8.8.9.1" class="ltx_tr">
<th id="S4.T3.8.8.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.8.8.8.9.1.1.1" class="ltx_text ltx_font_bold">Models/Tasks</span></th>
<td id="S4.T3.8.8.8.9.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T3.8.8.8.9.1.2.1" class="ltx_text ltx_font_bold">SE</span></td>
<td id="S4.T3.8.8.8.9.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="S4.T3.8.8.8.9.1.3.1" class="ltx_text ltx_font_bold">SS</span></td>
<td id="S4.T3.8.8.8.9.1.4" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="S4.T3.8.8.8.9.1.4.1" class="ltx_text ltx_font_bold">TTS</span></td>
</tr>
<tr id="S4.T3.8.8.8.8" class="ltx_tr">
<td id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">DNSMOS <math id="S4.T3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.1.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S4.T3.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.2.2.2.2.2.1" class="ltx_text ltx_font_bold">dWER</span> <math id="S4.T3.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T3.2.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T3.3.3.3.3.3.1" class="ltx_text ltx_font_bold">SpkSim</span> <math id="S4.T3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.3.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T3.3.3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.3.m1.1b"><ci id="S4.T3.3.3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T3.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.4.4.4.4.4.1" class="ltx_text ltx_font_bold">DNSMOS</span> <math id="S4.T3.4.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.4.4.4.4.4.m1.1a"><mo stretchy="false" id="S4.T3.4.4.4.4.4.m1.1.1" xref="S4.T3.4.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.4.4.m1.1b"><ci id="S4.T3.4.4.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T3.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.5.5.5.5.5.1" class="ltx_text ltx_font_bold">dWER</span> <math id="S4.T3.5.5.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.5.5.5.5.5.m1.1a"><mo stretchy="false" id="S4.T3.5.5.5.5.5.m1.1.1" xref="S4.T3.5.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.5.5.m1.1b"><ci id="S4.T3.5.5.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.5.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T3.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T3.6.6.6.6.6.1" class="ltx_text ltx_font_bold">SpkSim</span> <math id="S4.T3.6.6.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.6.6.6.6.6.m1.1a"><mo stretchy="false" id="S4.T3.6.6.6.6.6.m1.1.1" xref="S4.T3.6.6.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.6.6.m1.1b"><ci id="S4.T3.6.6.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T3.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.7.7.7.7.7.1" class="ltx_text ltx_font_bold">UTMOS</span> <math id="S4.T3.7.7.7.7.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.7.7.7.7.7.m1.1a"><mo stretchy="false" id="S4.T3.7.7.7.7.7.m1.1.1" xref="S4.T3.7.7.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.7.7.m1.1b"><ci id="S4.T3.7.7.7.7.7.m1.1.1.cmml" xref="S4.T3.7.7.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.7.7.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T3.8.8.8.8.8" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T3.8.8.8.8.8.1" class="ltx_text ltx_font_bold">dWER</span> <math id="S4.T3.8.8.8.8.8.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.8.8.8.8.8.m1.1a"><mo stretchy="false" id="S4.T3.8.8.8.8.8.m1.1.1" xref="S4.T3.8.8.8.8.8.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.8.8.m1.1b"><ci id="S4.T3.8.8.8.8.8.m1.1.1.cmml" xref="S4.T3.8.8.8.8.8.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.8.8.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T3.8.8.8.10.2" class="ltx_tr">
<th id="S4.T3.8.8.8.10.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="S4.T3.8.8.8.10.2.1.1" class="ltx_text ltx_font_italic">Low Bitrate</span></th>
</tr>
<tr id="S4.T3.8.8.8.11.3" class="ltx_tr">
<th id="S4.T3.8.8.8.11.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete HuBERT</th>
<td id="S4.T3.8.8.8.11.3.2" class="ltx_td ltx_align_center ltx_border_t">3.33</td>
<td id="S4.T3.8.8.8.11.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.8.11.3.3.1" class="ltx_text ltx_font_bold">15.47</span></td>
<td id="S4.T3.8.8.8.11.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.824</td>
<td id="S4.T3.8.8.8.11.3.5" class="ltx_td ltx_align_center ltx_border_t">3.52</td>
<td id="S4.T3.8.8.8.11.3.6" class="ltx_td ltx_align_center ltx_border_t">80.86</td>
<td id="S4.T3.8.8.8.11.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.840</td>
<td id="S4.T3.8.8.8.11.3.8" class="ltx_td ltx_align_center ltx_border_t">3.24</td>
<td id="S4.T3.8.8.8.11.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.8.11.3.9.1" class="ltx_text ltx_font_bold">2.55</span></td>
</tr>
<tr id="S4.T3.8.8.8.12.4" class="ltx_tr">
<th id="S4.T3.8.8.8.12.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="S4.T3.8.8.8.12.4.2" class="ltx_td ltx_align_center">3.26</td>
<td id="S4.T3.8.8.8.12.4.3" class="ltx_td ltx_align_center">16.52</td>
<td id="S4.T3.8.8.8.12.4.4" class="ltx_td ltx_align_center ltx_border_r">0.830</td>
<td id="S4.T3.8.8.8.12.4.5" class="ltx_td ltx_align_center">3.43</td>
<td id="S4.T3.8.8.8.12.4.6" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.12.4.6.1" class="ltx_text ltx_font_bold">62.34</span></td>
<td id="S4.T3.8.8.8.12.4.7" class="ltx_td ltx_align_center ltx_border_r">0.847</td>
<td id="S4.T3.8.8.8.12.4.8" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.12.4.8.1" class="ltx_text ltx_font_bold">3.84</span></td>
<td id="S4.T3.8.8.8.12.4.9" class="ltx_td ltx_align_center">3.01</td>
</tr>
<tr id="S4.T3.8.8.8.13.5" class="ltx_tr">
<th id="S4.T3.8.8.8.13.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="S4.T3.8.8.8.13.5.2" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.13.5.2.1" class="ltx_text ltx_font_bold">3.55</span></td>
<td id="S4.T3.8.8.8.13.5.3" class="ltx_td ltx_align_center">18.86</td>
<td id="S4.T3.8.8.8.13.5.4" class="ltx_td ltx_align_center ltx_border_r">0.779</td>
<td id="S4.T3.8.8.8.13.5.5" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.13.5.5.1" class="ltx_text ltx_font_bold">3.75</span></td>
<td id="S4.T3.8.8.8.13.5.6" class="ltx_td ltx_align_center">96.70</td>
<td id="S4.T3.8.8.8.13.5.7" class="ltx_td ltx_align_center ltx_border_r">0.787</td>
<td id="S4.T3.8.8.8.13.5.8" class="ltx_td ltx_align_center">3.32</td>
<td id="S4.T3.8.8.8.13.5.9" class="ltx_td ltx_align_center">3.45</td>
</tr>
<tr id="S4.T3.8.8.8.14.6" class="ltx_tr">
<th id="S4.T3.8.8.8.14.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="S4.T3.8.8.8.14.6.2" class="ltx_td ltx_align_center">3.15</td>
<td id="S4.T3.8.8.8.14.6.3" class="ltx_td ltx_align_center">34.35</td>
<td id="S4.T3.8.8.8.14.6.4" class="ltx_td ltx_align_center ltx_border_r">0.852</td>
<td id="S4.T3.8.8.8.14.6.5" class="ltx_td ltx_align_center">3.11</td>
<td id="S4.T3.8.8.8.14.6.6" class="ltx_td ltx_align_center">83.55</td>
<td id="S4.T3.8.8.8.14.6.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.8.8.8.14.6.7.1" class="ltx_text ltx_font_bold">0.877</span></td>
<td id="S4.T3.8.8.8.14.6.8" class="ltx_td ltx_align_center">1.46</td>
<td id="S4.T3.8.8.8.14.6.9" class="ltx_td ltx_align_center">8.85</td>
</tr>
<tr id="S4.T3.8.8.8.15.7" class="ltx_tr">
<th id="S4.T3.8.8.8.15.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="S4.T3.8.8.8.15.7.2" class="ltx_td ltx_align_center">3.30</td>
<td id="S4.T3.8.8.8.15.7.3" class="ltx_td ltx_align_center">57.41</td>
<td id="S4.T3.8.8.8.15.7.4" class="ltx_td ltx_align_center ltx_border_r">0.853</td>
<td id="S4.T3.8.8.8.15.7.5" class="ltx_td ltx_align_center">3.01</td>
<td id="S4.T3.8.8.8.15.7.6" class="ltx_td ltx_align_center">102.00</td>
<td id="S4.T3.8.8.8.15.7.7" class="ltx_td ltx_align_center ltx_border_r">0.854</td>
<td id="S4.T3.8.8.8.15.7.8" class="ltx_td ltx_align_center">1.97</td>
<td id="S4.T3.8.8.8.15.7.9" class="ltx_td ltx_align_center">10.68</td>
</tr>
<tr id="S4.T3.8.8.8.16.8" class="ltx_tr">
<th id="S4.T3.8.8.8.16.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="S4.T3.8.8.8.16.8.2" class="ltx_td ltx_align_center">3.18</td>
<td id="S4.T3.8.8.8.16.8.3" class="ltx_td ltx_align_center">30.13</td>
<td id="S4.T3.8.8.8.16.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.8.8.8.16.8.4.1" class="ltx_text ltx_font_bold">0.858</span></td>
<td id="S4.T3.8.8.8.16.8.5" class="ltx_td ltx_align_center">3.13</td>
<td id="S4.T3.8.8.8.16.8.6" class="ltx_td ltx_align_center">85.25</td>
<td id="S4.T3.8.8.8.16.8.7" class="ltx_td ltx_align_center ltx_border_r">0.874</td>
<td id="S4.T3.8.8.8.16.8.8" class="ltx_td ltx_align_center">2.51</td>
<td id="S4.T3.8.8.8.16.8.9" class="ltx_td ltx_align_center">3.69</td>
</tr>
<tr id="S4.T3.8.8.8.17.9" class="ltx_tr">
<th id="S4.T3.8.8.8.17.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="S4.T3.8.8.8.17.9.1.1" class="ltx_text ltx_font_italic">Medium Bitrate</span></th>
</tr>
<tr id="S4.T3.8.8.8.18.10" class="ltx_tr">
<th id="S4.T3.8.8.8.18.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete HuBERT</th>
<td id="S4.T3.8.8.8.18.10.2" class="ltx_td ltx_align_center ltx_border_t">3.48</td>
<td id="S4.T3.8.8.8.18.10.3" class="ltx_td ltx_align_center ltx_border_t">12.62</td>
<td id="S4.T3.8.8.8.18.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.875</td>
<td id="S4.T3.8.8.8.18.10.5" class="ltx_td ltx_align_center ltx_border_t">3.70</td>
<td id="S4.T3.8.8.8.18.10.6" class="ltx_td ltx_align_center ltx_border_t">66.29</td>
<td id="S4.T3.8.8.8.18.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.891</td>
<td id="S4.T3.8.8.8.18.10.8" class="ltx_td ltx_align_center ltx_border_t">3.80</td>
<td id="S4.T3.8.8.8.18.10.9" class="ltx_td ltx_align_center ltx_border_t">3.40</td>
</tr>
<tr id="S4.T3.8.8.8.19.11" class="ltx_tr">
<th id="S4.T3.8.8.8.19.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="S4.T3.8.8.8.19.11.2" class="ltx_td ltx_align_center">3.48</td>
<td id="S4.T3.8.8.8.19.11.3" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.19.11.3.1" class="ltx_text ltx_font_bold">10.18</span></td>
<td id="S4.T3.8.8.8.19.11.4" class="ltx_td ltx_align_center ltx_border_r">0.889</td>
<td id="S4.T3.8.8.8.19.11.5" class="ltx_td ltx_align_center">3.68</td>
<td id="S4.T3.8.8.8.19.11.6" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.19.11.6.1" class="ltx_text ltx_font_bold">34.03</span></td>
<td id="S4.T3.8.8.8.19.11.7" class="ltx_td ltx_align_center ltx_border_r">0.912</td>
<td id="S4.T3.8.8.8.19.11.8" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.19.11.8.1" class="ltx_text ltx_font_bold">3.82</span></td>
<td id="S4.T3.8.8.8.19.11.9" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.19.11.9.1" class="ltx_text ltx_font_bold">2.45</span></td>
</tr>
<tr id="S4.T3.8.8.8.20.12" class="ltx_tr">
<th id="S4.T3.8.8.8.20.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="S4.T3.8.8.8.20.12.2" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.20.12.2.1" class="ltx_text ltx_font_bold">3.54</span></td>
<td id="S4.T3.8.8.8.20.12.3" class="ltx_td ltx_align_center">17.60</td>
<td id="S4.T3.8.8.8.20.12.4" class="ltx_td ltx_align_center ltx_border_r">0.858</td>
<td id="S4.T3.8.8.8.20.12.5" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.20.12.5.1" class="ltx_text ltx_font_bold">3.75</span></td>
<td id="S4.T3.8.8.8.20.12.6" class="ltx_td ltx_align_center">78.42</td>
<td id="S4.T3.8.8.8.20.12.7" class="ltx_td ltx_align_center ltx_border_r">0.866</td>
<td id="S4.T3.8.8.8.20.12.8" class="ltx_td ltx_align_center">3.68</td>
<td id="S4.T3.8.8.8.20.12.9" class="ltx_td ltx_align_center">2.89</td>
</tr>
<tr id="S4.T3.8.8.8.21.13" class="ltx_tr">
<th id="S4.T3.8.8.8.21.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="S4.T3.8.8.8.21.13.2" class="ltx_td ltx_align_center">3.10</td>
<td id="S4.T3.8.8.8.21.13.3" class="ltx_td ltx_align_center">19.07</td>
<td id="S4.T3.8.8.8.21.13.4" class="ltx_td ltx_align_center ltx_border_r">0.885</td>
<td id="S4.T3.8.8.8.21.13.5" class="ltx_td ltx_align_center">3.09</td>
<td id="S4.T3.8.8.8.21.13.6" class="ltx_td ltx_align_center">48.57</td>
<td id="S4.T3.8.8.8.21.13.7" class="ltx_td ltx_align_center ltx_border_r">0.906</td>
<td id="S4.T3.8.8.8.21.13.8" class="ltx_td ltx_align_center">1.50</td>
<td id="S4.T3.8.8.8.21.13.9" class="ltx_td ltx_align_center">94.6</td>
</tr>
<tr id="S4.T3.8.8.8.22.14" class="ltx_tr">
<th id="S4.T3.8.8.8.22.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="S4.T3.8.8.8.22.14.2" class="ltx_td ltx_align_center">3.49</td>
<td id="S4.T3.8.8.8.22.14.3" class="ltx_td ltx_align_center">31.14</td>
<td id="S4.T3.8.8.8.22.14.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.8.8.8.22.14.4.1" class="ltx_text ltx_font_bold">0.906</span></td>
<td id="S4.T3.8.8.8.22.14.5" class="ltx_td ltx_align_center">3.26</td>
<td id="S4.T3.8.8.8.22.14.6" class="ltx_td ltx_align_center">55.43</td>
<td id="S4.T3.8.8.8.22.14.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.8.8.8.22.14.7.1" class="ltx_text ltx_font_bold">0.924</span></td>
<td id="S4.T3.8.8.8.22.14.8" class="ltx_td ltx_align_center">1.71</td>
<td id="S4.T3.8.8.8.22.14.9" class="ltx_td ltx_align_center">71.26</td>
</tr>
<tr id="S4.T3.8.8.8.23.15" class="ltx_tr">
<th id="S4.T3.8.8.8.23.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="S4.T3.8.8.8.23.15.2" class="ltx_td ltx_align_center">3.49</td>
<td id="S4.T3.8.8.8.23.15.3" class="ltx_td ltx_align_center">23.44</td>
<td id="S4.T3.8.8.8.23.15.4" class="ltx_td ltx_align_center ltx_border_r">0.876</td>
<td id="S4.T3.8.8.8.23.15.5" class="ltx_td ltx_align_center">3.42</td>
<td id="S4.T3.8.8.8.23.15.6" class="ltx_td ltx_align_center">60.75</td>
<td id="S4.T3.8.8.8.23.15.7" class="ltx_td ltx_align_center ltx_border_r">0.906</td>
<td id="S4.T3.8.8.8.23.15.8" class="ltx_td ltx_align_center">1.96</td>
<td id="S4.T3.8.8.8.23.15.9" class="ltx_td ltx_align_center">53.26</td>
</tr>
<tr id="S4.T3.8.8.8.24.16" class="ltx_tr">
<th id="S4.T3.8.8.8.24.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="S4.T3.8.8.8.24.16.1.1" class="ltx_text ltx_font_italic">High Bitrate</span></th>
</tr>
<tr id="S4.T3.8.8.8.25.17" class="ltx_tr">
<th id="S4.T3.8.8.8.25.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">EnCodec</th>
<td id="S4.T3.8.8.8.25.17.2" class="ltx_td ltx_align_center ltx_border_t">2.87</td>
<td id="S4.T3.8.8.8.25.17.3" class="ltx_td ltx_align_center ltx_border_t">68.22</td>
<td id="S4.T3.8.8.8.25.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.814</td>
<td id="S4.T3.8.8.8.25.17.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.8.25.17.5.1" class="ltx_text ltx_font_bold">2.95</span></td>
<td id="S4.T3.8.8.8.25.17.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.8.8.8.25.17.6.1" class="ltx_text ltx_font_bold">97.73</span></td>
<td id="S4.T3.8.8.8.25.17.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.8.8.8.25.17.7.1" class="ltx_text ltx_font_bold">0.839</span></td>
<td id="S4.T3.8.8.8.25.17.8" class="ltx_td ltx_align_center ltx_border_t">N.C</td>
<td id="S4.T3.8.8.8.25.17.9" class="ltx_td ltx_align_center ltx_border_t">N.C</td>
</tr>
<tr id="S4.T3.8.8.8.26.18" class="ltx_tr">
<th id="S4.T3.8.8.8.26.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="S4.T3.8.8.8.26.18.2" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.26.18.2.1" class="ltx_text ltx_font_bold">2.95</span></td>
<td id="S4.T3.8.8.8.26.18.3" class="ltx_td ltx_align_center"><span id="S4.T3.8.8.8.26.18.3.1" class="ltx_text ltx_font_bold">46.07</span></td>
<td id="S4.T3.8.8.8.26.18.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.8.8.8.26.18.4.1" class="ltx_text ltx_font_bold">0.860</span></td>
<td id="S4.T3.8.8.8.26.18.5" class="ltx_td ltx_align_center">2.53</td>
<td id="S4.T3.8.8.8.26.18.6" class="ltx_td ltx_align_center">208</td>
<td id="S4.T3.8.8.8.26.18.7" class="ltx_td ltx_align_center ltx_border_r">0.784</td>
<td id="S4.T3.8.8.8.26.18.8" class="ltx_td ltx_align_center">N.C</td>
<td id="S4.T3.8.8.8.26.18.9" class="ltx_td ltx_align_center">N.C</td>
</tr>
<tr id="S4.T3.8.8.8.27.19" class="ltx_tr">
<th id="S4.T3.8.8.8.27.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="S4.T3.8.8.8.27.19.1.1" class="ltx_text ltx_font_italic">Continuous Baseline</span></th>
</tr>
<tr id="S4.T3.8.8.8.28.20" class="ltx_tr">
<th id="S4.T3.8.8.8.28.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">SSL</th>
<td id="S4.T3.8.8.8.28.20.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.49</td>
<td id="S4.T3.8.8.8.28.20.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.92</td>
<td id="S4.T3.8.8.8.28.20.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.928</td>
<td id="S4.T3.8.8.8.28.20.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.68</td>
<td id="S4.T3.8.8.8.28.20.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">9.97</td>
<td id="S4.T3.8.8.8.28.20.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.939</td>
<td id="S4.T3.8.8.8.28.20.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.71</td>
<td id="S4.T3.8.8.8.28.20.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">2.94</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Comparison of Discrete Audio Models</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.p1.1" class="ltx_p">Tables <a href="#S4.T2" title="Table 2 ‣ 4.2 Generative Tasks ‣ 4 Experiments ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S4.T3" title="Table 3 ‣ 4.2 Generative Tasks ‣ 4 Experiments ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> show the performance of discriminative and generative tasks among the two downstream architectures explored. For each value in the table, we report the best performance obtained with the two downstream architectures.
Detailed results for each architecture, along with the settings for each experiment using continuous SSL models, are provided in Appendix <a href="#A5" title="Appendix E Additional Results ‣ Appendix D Additional Analysis of Discrete Audio Decoders ‣ Appendix C Dataset and Downstream Models ‣ Appendix B Discrete Audio Models Details ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p">We observe a significant variation in the tokenizer performance across different tasks. This result suggests that the optimal choice of tokenizer depends on the specific task at hand. However, some interesting patterns emerge. For instance, semantic tokens significantly outperform compression tokens for most discriminative tasks. This trend is due to the ability of semantic tokens to capture high-level information from the audio signal as also observed in existing findings in the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. The only exceptions are speaker recognition tasks, where EnCodec achieves the best results. This suggests that compression tokens better encode speaker information. It is consistent with a previous study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> that shows discrete tokens obtained from quantization of SSL layers remove speaker information.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.p3.1" class="ltx_p">Semantic tokens show the best performance for generative tasks as well, achieving the highest MOS and dWER scores, indicating better overall quality and intelligibility in the generated outputs. However, for preserving speaker identity, compression tokens are more effective, as shown by superior speaker similarity (SpkSim) metrics. We think our findings for generative tasks are particularly interesting. While prior research efforts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> explored the use of semantic tokens for generation, they did not include a comparison with the performance of compression tokens. It is important to remark that the success observed with both semantic tokens relies heavily on the effectiveness of the decoder architecture used in our benchmark. Our scalable decoder minimizes distortions and artifacts in the generated speech, leading to better performance on various generative tasks.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.p4.1" class="ltx_p">In Table  <a href="#S5.T4" title="Table 4 ‣ 5.2 Impact of Bitrate ‣ 5 Results ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (right), we present the ranking aggregation for the considered tokenizers (medium bitrate). Each model is individually ranked for every task, and we compute the average position across all ranks. This analysis shows that discrete WavLM generates the top-performing audio tokens. While the continuous version of WavLM ranks highest in the SUPERB benchmark, our findings demonstrate for the first time that this model maintains strong performance even after tokenization.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para ltx_noindent">
<p id="S5.SS1.p5.1" class="ltx_p">Our comparison between discrete tokens and the best continuous baseline reveals a significant performance gap favoring continuous representations. This suggests that tokenization loses valuable information, such as phonetics, speaker identity, and emotion. Addressing this information loss is a key challenge for future generations of audio tokens.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Impact of Bitrate</h3>

<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p">We also study the impact of different bitrates on the performance of the tokenizers. Tables <a href="#S4.T2" title="Table 2 ‣ 4.2 Generative Tasks ‣ 4 Experiments ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S4.T3" title="Table 3 ‣ 4.2 Generative Tasks ‣ 4 Experiments ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> show that a medium bitrate achieves the best results for both discriminative and generative tasks. Interestingly, higher bitrates, when available (e.g., for EnCodec and DAC), tend to degrade performance. While higher bitrates can potentially preserve more information, they also increase the output dimensionality of the model, making the task more challenging to solve.
In some cases, we found the task so challenging with high bitrates that the model did not converge, as observed in the case of TTS.
It is worth noting that semantic tokens have a lower bitrate than compression tokens, as shown in Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Discrete Audio Encoder ‣ 3 Benchmark Design ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For example, in the medium bitrate range, discrete WavLM has a bitrate of 2.9 kbps, while EnCodec has 6.0 kbps. This difference is due to the varying number of codebooks (6 vs. 8) and sampling rates (16 kHz vs. 24 kHz). Despite their lower bitrate, semantic tokens provide better performance.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.p2.1" class="ltx_p">Another aspect we investigate is the efficiency of the encoders and decoders, as this could impact some applications. Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Discrete Audio Encoder ‣ 3 Benchmark Design ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the time and memory usage for each encoder-decoder pair across all bitrate ranges.
For semantic tokens, the encoder is a large neural network and is computationally demanding. In contrast, the decoders are based on a compact HiFi-GAN model and are very efficient. For streaming tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> where time and memory are critical, EnCodec turned out to be a better candidate due to the efficiency of both its encoder and decoder models.</p>
</div>
<figure id="S5.T4" class="ltx_table">

<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S5.T4.6.1" class="ltx_text ltx_font_bold">(left)</span> Evaluating various discrete decoders on the speech re-synthesis task (medium bitrate). <span id="S5.T4.7.2" class="ltx_text ltx_font_bold">(right)</span> Ranking aggregation for models (medium bitrate). </figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S5.T4.3" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:114.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.1pt,14.8pt) scale(0.793932283820765,0.793932283820765) ;">
<table id="S5.T4.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.3.3.3" class="ltx_tr">
<th id="S5.T4.3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T4.3.3.3.4.1" class="ltx_text ltx_font_bold">Models/Metrics</span></th>
<th id="S5.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">DNSMOS <math id="S5.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T4.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T4.1.1.1.1.1.m1.1.1" xref="S5.T4.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.1.m1.1b"><ci id="S5.T4.1.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S5.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S5.T4.2.2.2.2.1" class="ltx_text ltx_font_bold">dWER <math id="S5.T4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T4.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T4.2.2.2.2.1.m1.1.1" xref="S5.T4.2.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.2.1.m1.1b"><ci id="S5.T4.2.2.2.2.1.m1.1.1.cmml" xref="S5.T4.2.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S5.T4.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T4.3.3.3.3.1" class="ltx_text ltx_font_bold">SpkSim <math id="S5.T4.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T4.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S5.T4.3.3.3.3.1.m1.1.1" xref="S5.T4.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.3.1.m1.1b"><ci id="S5.T4.3.3.3.3.1.m1.1.1.cmml" xref="S5.T4.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.3.3.4.1" class="ltx_tr">
<th id="S5.T4.3.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete HuBERT</th>
<td id="S5.T4.3.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.68</td>
<td id="S5.T4.3.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.60</td>
<td id="S5.T4.3.3.4.1.4" class="ltx_td ltx_align_center ltx_border_t">0.92</td>
</tr>
<tr id="S5.T4.3.3.5.2" class="ltx_tr">
<th id="S5.T4.3.3.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="S5.T4.3.3.5.2.2" class="ltx_td ltx_align_center ltx_border_r">3.64</td>
<td id="S5.T4.3.3.5.2.3" class="ltx_td ltx_align_center ltx_border_r">5.19</td>
<td id="S5.T4.3.3.5.2.4" class="ltx_td ltx_align_center">0.94</td>
</tr>
<tr id="S5.T4.3.3.6.3" class="ltx_tr">
<th id="S5.T4.3.3.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="S5.T4.3.3.6.3.2" class="ltx_td ltx_align_center ltx_border_r">3.71</td>
<td id="S5.T4.3.3.6.3.3" class="ltx_td ltx_align_center ltx_border_r">8.72</td>
<td id="S5.T4.3.3.6.3.4" class="ltx_td ltx_align_center">0.91</td>
</tr>
<tr id="S5.T4.3.3.7.4" class="ltx_tr">
<th id="S5.T4.3.3.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="S5.T4.3.3.7.4.2" class="ltx_td ltx_align_center ltx_border_r">3.54</td>
<td id="S5.T4.3.3.7.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.3.7.4.3.1" class="ltx_text ltx_font_bold">2.16</span></td>
<td id="S5.T4.3.3.7.4.4" class="ltx_td ltx_align_center">0.98</td>
</tr>
<tr id="S5.T4.3.3.8.5" class="ltx_tr">
<th id="S5.T4.3.3.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="S5.T4.3.3.8.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.3.3.8.5.2.1" class="ltx_text ltx_font_bold">3.74</span></td>
<td id="S5.T4.3.3.8.5.3" class="ltx_td ltx_align_center ltx_border_r">2.36</td>
<td id="S5.T4.3.3.8.5.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.3.8.5.4.1" class="ltx_text ltx_font_bold">0.99</span></td>
</tr>
<tr id="S5.T4.3.3.9.6" class="ltx_tr">
<th id="S5.T4.3.3.9.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="S5.T4.3.3.9.6.2" class="ltx_td ltx_align_center ltx_border_r">3.58</td>
<td id="S5.T4.3.3.9.6.3" class="ltx_td ltx_align_center ltx_border_r">5.12</td>
<td id="S5.T4.3.3.9.6.4" class="ltx_td ltx_align_center">0.94</td>
</tr>
<tr id="S5.T4.3.3.10.7" class="ltx_tr">
<th id="S5.T4.3.3.10.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">Continuous SSL</th>
<td id="S5.T4.3.3.10.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">3.73</td>
<td id="S5.T4.3.3.10.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">2.33</td>
<td id="S5.T4.3.3.10.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">0.98</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S5.T4.8" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:195.1pt;height:117.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.3pt,4.4pt) scale(0.930039441206304,0.930039441206304) ;">
<table id="S5.T4.8.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.8.1.1.1" class="ltx_tr">
<th id="S5.T4.8.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T4.8.1.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S5.T4.8.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T4.8.1.1.1.2.1" class="ltx_text ltx_font_bold">Disc.</span></th>
<th id="S5.T4.8.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T4.8.1.1.1.3.1" class="ltx_text ltx_font_bold">Gen.</span></th>
<th id="S5.T4.8.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T4.8.1.1.1.4.1" class="ltx_text ltx_font_bold">Comb.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.8.1.2.1" class="ltx_tr">
<th id="S5.T4.8.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete HuBERT</th>
<td id="S5.T4.8.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">2.66</td>
<td id="S5.T4.8.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">3.62</td>
<td id="S5.T4.8.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">3.11</td>
</tr>
<tr id="S5.T4.8.1.3.2" class="ltx_tr">
<th id="S5.T4.8.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="S5.T4.8.1.3.2.2" class="ltx_td ltx_align_center"><span id="S5.T4.8.1.3.2.2.1" class="ltx_text ltx_font_bold">2.00</span></td>
<td id="S5.T4.8.1.3.2.3" class="ltx_td ltx_align_center">2.75</td>
<td id="S5.T4.8.1.3.2.4" class="ltx_td ltx_align_center"><span id="S5.T4.8.1.3.2.4.1" class="ltx_text ltx_font_bold">1.94</span></td>
</tr>
<tr id="S5.T4.8.1.4.3" class="ltx_tr">
<th id="S5.T4.8.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="S5.T4.8.1.4.3.2" class="ltx_td ltx_align_center">3.33</td>
<td id="S5.T4.8.1.4.3.3" class="ltx_td ltx_align_center"><span id="S5.T4.8.1.4.3.3.1" class="ltx_text ltx_font_bold">2.68</span></td>
<td id="S5.T4.8.1.4.3.4" class="ltx_td ltx_align_center">3.41</td>
</tr>
<tr id="S5.T4.8.1.5.4" class="ltx_tr">
<th id="S5.T4.8.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="S5.T4.8.1.5.4.2" class="ltx_td ltx_align_center">4.11</td>
<td id="S5.T4.8.1.5.4.3" class="ltx_td ltx_align_center">3.93</td>
<td id="S5.T4.8.1.5.4.4" class="ltx_td ltx_align_center">4.23</td>
</tr>
<tr id="S5.T4.8.1.6.5" class="ltx_tr">
<th id="S5.T4.8.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="S5.T4.8.1.6.5.2" class="ltx_td ltx_align_center">5.55</td>
<td id="S5.T4.8.1.6.5.3" class="ltx_td ltx_align_center">4 .06</td>
<td id="S5.T4.8.1.6.5.4" class="ltx_td ltx_align_center">4.64</td>
</tr>
<tr id="S5.T4.8.1.7.6" class="ltx_tr">
<th id="S5.T4.8.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">SpeechTokenizer</th>
<td id="S5.T4.8.1.7.6.2" class="ltx_td ltx_align_center ltx_border_b">3.44</td>
<td id="S5.T4.8.1.7.6.3" class="ltx_td ltx_align_center ltx_border_b">3.81</td>
<td id="S5.T4.8.1.7.6.4" class="ltx_td ltx_align_center ltx_border_b">3.64</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Analysis of Discrete Audio Decoder</h3>

<div id="S5.SS3.p1" class="ltx_para ltx_noindent">
<p id="S5.SS3.p1.1" class="ltx_p">Finally, we present a comparative evaluation of the decoders in Table <a href="#S5.T4" title="Table 4 ‣ 5.2 Impact of Bitrate ‣ 5 Results ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (left).
The decoder evaluation is conducted on the LibriSpeech test-clean subset using a speech re-synthesis task,
where we extract the tokens from each discrete audio encoder and reconstruct the speech using the associated decoders. Then, we evaluate the reconstructed speech based on speaker similarity, Mean Opinion Score (MOS), and differential Word Error Rate (dWER). The goal of this experiment is to establish if a given system is able to provide a high-fidelity reconstruction of the input audio after encoding it in the discrete space. This is especially important to establish for generative tasks.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para ltx_noindent">
<p id="S5.SS3.p2.1" class="ltx_p">The results show that the built-in decoders of compression tokens outperform other models in preserving speaker similarity, further confirming that current semantic tokens do not adequately preserve speaker information. Compression-based tokens also achieve better dWER scores. However, in terms of speech quality (assessed with DNSMOS), there are no significant differences between semantic and compression-based tokens.
This trend indicates that while semantic tokens produce good-quality audio, they may be slightly more prone to semantic degradation (e.g., mispronunciations of words or phonemes). As expected, continuous baselines perform better than their discrete counterparts. Additional analysis on low and high settings can be found in Appendix <a href="#A4" title="Appendix D Additional Analysis of Discrete Audio Decoders ‣ Appendix C Dataset and Downstream Models ‣ Appendix B Discrete Audio Models Details ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">This paper introduces DASB, a comprehensive benchmark designed to evaluate the performance of discrete audio tokens across diverse tasks of broad interest. We employ various evaluation metrics, downstream architectures, and bitrates for more robust comparisons. Interestingly, our findings reveal that semantic tokens outperform, on average, compression tokens in both generative and discriminative tasks.
In particular, discrete WavLM emerged as the top-performing model, making it a natural candidate for adoption in multi-modal text+audio LLMs.
A significant performance gap, however, persists when compared to traditional self-supervised continuous representations.
This highlights the need for further research, which we believe is essential for better incorporating audio tokens into large multimodal language models.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p">One limitation we encountered is the proprietary nature of some audio tokenizers, such as Soundstream <cite class="ltx_cite ltx_citemacro_citet">zeghidour2021soundstream [<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, which are not publicly accessible. Additionally, the benchmark is currently limited to speech tasks, but we plan to broaden it including music and sound processing. Our goal is to help the research community establish a shared benchmark and evaluation protocol for discrete audio representations. We will thus keep expanding DASB by continuously incorporating novel tokenizers and tasks.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgements</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">We acknowledge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC) and the Digital Research Alliance of Canada (alliancecan.ca). We thank OVHCloud for donating part of the GPU computing resources needed for this work.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Lawrence Rabiner and Biing-Hwang Juang.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Fundamentals of Speech Recognition</span>.

</span>
<span class="ltx_bibblock">Prentice-Hall Signal Processing Series, 1993.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech representations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">International Conference on Neural Information Processing Systems (NeurIPS)</span>, volume 33, pages 12449–12460, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, et al.

</span>
<span class="ltx_bibblock">WavLM: Large-scale self-supervised pre-training for full stack speech processing.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">IEEE Journal of Selected Topics in Signal Processing</span>, 16(6):1505–1518, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed.

</span>
<span class="ltx_bibblock">HuBERT: Self-supervised speech representation learning by masked prediction of hidden units.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, 29:3451–3460, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Adam Polyak, Yossi Adi, Jade Copet, Eugene Kharitonov, Kushal Lakhotia, Wei-Ning Hsu, Abdelrahman Mohamed, and Emmanuel Dupoux.

</span>
<span class="ltx_bibblock">Speech resynthesis from discrete disentangled self-supervised representations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 3615–3619, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Dan Wells, Hao Tang, and Korin Richmond.

</span>
<span class="ltx_bibblock">Phonetic analysis of self-supervised representations of English speech.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 3583–3587, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Yu-An Chung, Yu Zhang, Wei Han, Chung-Cheng Chiu, James Qin, Ruoming Pang, and Yonghui Wu.

</span>
<span class="ltx_bibblock">w2v-BERT: Combining contrastive learning and masked language modeling for self-supervised speech pre-training.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</span>, pages 244–250, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Xin Zhang, Dong Zhang, Shimin Li, Yaqian Zhou, and Xipeng Qiu.

</span>
<span class="ltx_bibblock">SpeechTokenizer: Unified speech tokenizer for speech large language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations (ICLR)</span>, 2024.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Zhihao Du, Shiliang Zhang, Kai Hu, and Siqi Zheng.

</span>
<span class="ltx_bibblock">FunCodec: A fundamental, reproducible and integrable open-source toolkit for neural speech codec.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2309.07405</span>, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al.

</span>
<span class="ltx_bibblock">PaLM: scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Research</span>, 24, 2024.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In Jill Burstein, Christy Doran, and Thamar Solorio, editors, <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Conference of the North American Chapter of the Association for Computational Linguistics (NAACL): Human Language Technologies, Volume 1 (Long and Short Papers)</span>, pages 4171–4186, 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang.

</span>
<span class="ltx_bibblock">GPT understands, too.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">AI Open</span>, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Aaron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu.

</span>
<span class="ltx_bibblock">Neural discrete representation learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the 31st International Conference on Neural Information Processing Systems</span>, NIPS’17, 2017.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Paul K. Rubenstein, Chulayuth Asawaroengchai, Duc Dung Nguyen, Ankur Bapna, Zalán Borsos, Félix de Chaumont Quitry, Peter Chen, Dalia El Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, et al.

</span>
<span class="ltx_bibblock">AudioPaLM: A large language model that can speak and listen.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.12925</span>, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Jiaming Wang, Zhihao Du, Qian Chen, Yunfei Chu, Zhifu Gao, Zerui Li, Kai Hu, Xiaohuan Zhou, Jin Xu, Ziyang Ma, Wen Wang, Siqi Zheng, Chang Zhou, Zhijie Yan, and Shiliang Zhang.

</span>
<span class="ltx_bibblock">LauraGPT: Listen, attend, understand, and regenerate audio with GPT.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.04673</span>, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Tianrui Wang, Long Zhou, Ziqiang Zhang, Yu Wu, Shujie Liu, Yashesh Gaur, Zhuo Chen, Jinyu Li, and Furu Wei.

</span>
<span class="ltx_bibblock">VioLA: Unified codec language models for speech recognition, synthesis, and translation.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.16107</span>, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Chengyi Wang, Sanyuan Chen, Yu Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, Lei He, Sheng Zhao, and Furu Wei.

</span>
<span class="ltx_bibblock">Neural codec language models are zero-shot text to speech synthesizers.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2301.02111</span>, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Xiaofei Wang, Manthan Thakker, Zhuo Chen, Naoyuki Kanda, Sefik Emre Eskimez, Sanyuan Chen, Min Tang, Shujie Liu, Jinyu Li, and Takuya Yoshioka.

</span>
<span class="ltx_bibblock">SpeechX: Neural codec language model as a versatile speech transformer.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.06873</span>, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Andrea Agostinelli et al.

</span>
<span class="ltx_bibblock">MusicLM: Generating music from text.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2301.11325</span>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Felix Kreuk, Gabriel Synnaeve, Adam Polyak, Uriel Singer, Alexandre Défossez, Jade Copet, Devi Parikh, Yaniv Taigman, and Yossi Adi.

</span>
<span class="ltx_bibblock">AudioGen: Textually guided audio generation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations (ICLR)</span>, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Gemini Team, Google.

</span>
<span class="ltx_bibblock">Gemini: A family of highly capable multimodal models.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2312.11805</span>, 2023.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Ian J. Goodfellow, Yoshua Bengio, and Aaron Courville.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Deep Learning</span>.

</span>
<span class="ltx_bibblock">MIT Press, 2016.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Haibin Wu, Ho-Lam Chung, Yi-Cheng Lin, Yuan-Kuei Wu, Xuanjun Chen, Yu-Chi Pai, Hsiu-Hsuan Wang, Kai-Wei Chang, Alexander H Liu, and Hung-yi Lee.

</span>
<span class="ltx_bibblock">Codec-SUPERB: An in-depth analysis of sound codec models.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2402.13071</span>, 2024.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Krishna C. Puvvada, Nithin Rao Koluguri, Kunal Dhawan, Jagadeesh Balam, and Boris Ginsburg.

</span>
<span class="ltx_bibblock">Discrete audio representation as an alternative to Mel-spectrograms for speaker and speech recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 12111–12115, 2024.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Ziqian Wang, Xinfa Zhu, Zihan Zhang, YuanJun Lv, Ning Jiang, Guoqing Zhao, and Lei Xie.

</span>
<span class="ltx_bibblock">SELM: Speech enhancement using discrete tokens and language models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 11561–11565, 2024.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Dong Zhang, Rong Ye, Tom Ko, Mingxuan Wang, and Yaqian Zhou.

</span>
<span class="ltx_bibblock">DUB: Discrete unit back-translation for speech translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Findings of the Association for Computational Linguistics: ACL</span>, pages 7147–7164, 2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Xuankai Chang, Brian Yan, Kwanghee Choi, Jee-Weon Jung, Yichen Lu, Soumi Maiti, Roshan Sharma, Jiatong Shi, Jinchuan Tian, Shinji Watanabe, Yuya Fujita, et al.

</span>
<span class="ltx_bibblock">Exploring speech recognition, translation, and understanding with discrete speech units: A comparative study.

</span>
<span class="ltx_bibblock">In <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 11481–11485, 2024.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Alexandre Défossez, Jade Copet, Gabriel Synnaeve, and Yossi Adi.

</span>
<span class="ltx_bibblock">High fidelity neural audio compression.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Transactions on Machine Learning Research (TMLR)</span>, 2023.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Rithesh Kumar, Prem Seetharaman, Alejandro Luebs, Ishaan Kumar, and Kundan Kumar.

</span>
<span class="ltx_bibblock">High-fidelity audio compression with improved RVQGAN.

</span>
<span class="ltx_bibblock">In <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">International Conference on Neural Information Processing Systems (NeurIPS)</span>, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Salah Zaiem, Youcef Kemiche, Titouan Parcollet, Slim Essid, and Mirco Ravanelli.

</span>
<span class="ltx_bibblock">Speech self-supervised representation benchmarking: Are we doing it right?

</span>
<span class="ltx_bibblock">In <span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 2873–2877, 2023.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Mirco Ravanelli, Titouan Parcollet, Peter Plantinga, Aku Rouhe, Samuele Cornell, Loren Lugosch, Cem Subakan, Nauman Dawalatabad, Abdelwahab Heba, Jianyuan Zhong, et al.

</span>
<span class="ltx_bibblock">SpeechBrain: A general-purpose speech toolkit.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.04624</span>, 2021.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Xuankai Chang, Brian Yan, Yuya Fujita, Takashi Maekaku, and Shinji Watanabe.

</span>
<span class="ltx_bibblock">Exploration of efficient end-to-end ASR using discretized input from self-supervised learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 1399–1403, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Yifan Yang, Feiyu Shen, Chenpeng Du, Ziyang Ma, Kai Yu, Daniel Povey, and Xie Chen.

</span>
<span class="ltx_bibblock">Towards universal speech discrete tokens: A case study for ASR and TTS.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 10401–10405, 2024.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Hakan Erdogan, Scott Wisdom, Xuankai Chang, Zalán Borsos, Marco Tagliasacchi, Neil Zeghidour, and John R Hershey.

</span>
<span class="ltx_bibblock">TokenSplit: Using discrete speech representations for direct, refined, and transcript-conditioned speech separation and recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 3462–3466, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Siyang Wang and Éva Székely.

</span>
<span class="ltx_bibblock">Evaluating text-to-speech synthesis from a large discrete token-based speech language model.

</span>
<span class="ltx_bibblock">In <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING)</span>, pages 6464–6474, 2024.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Chengyi Wang, Sanyuan Chen, Yu Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, et al.

</span>
<span class="ltx_bibblock">Neural codec language models are zero-shot text to speech synthesizers.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2301.02111</span>, 2023.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Eugene Kharitonov, Damien Vincent, Zalán Borsos, Raphaël Marinier, Sertan Girgin, Olivier Pietquin, Matt Sharifi, Marco Tagliasacchi, and Neil Zeghidour.

</span>
<span class="ltx_bibblock">Speak, read and prompt: High-fidelity text-to-speech with minimal supervision.

</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Transactions of the Association for Computational Linguistics</span>, 11:1703–1718, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Pooneh Mousavi, Jarod Duret, Salah Zaiem, Luca Della Libera, Artem Ploujnikov, Cem Subakan, and Mirco Ravanelli.

</span>
<span class="ltx_bibblock">How should we extract discrete audio tokens from self-supervised models?, 2024.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Shu wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I Jeff Lai, Kushal Lakhotia, Yist Y. Lin, Andy T. Liu, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, et al.

</span>
<span class="ltx_bibblock">SUPERB: Speech Processing Universal PERformance Benchmark.

</span>
<span class="ltx_bibblock">In <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 1194–1198, 2021.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Jean-Marc Valin, Koen Vos, and Timothy Terriberry.

</span>
<span class="ltx_bibblock">Definition of the Opus audio codec.

</span>
<span class="ltx_bibblock">Technical report, 2012.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Martin Dietz, Markus Multrus, Vaclav Eksler, Vladimir Malenovsky, Erik Norvell, Harald Pobloth, Lei Miao, Zhe Wang, Lasse Laaksonen, Adriana Vasilache, et al.

</span>
<span class="ltx_bibblock">Overview of the EVS codec architecture.

</span>
<span class="ltx_bibblock">In <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 5698–5702, 2015.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco Tagliasacchi.

</span>
<span class="ltx_bibblock">SoundStream: An end-to-end neural audio codec.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, pages 495–507, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Zalán Borsos, Raphaël Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi, Dominik Roblek, Olivier Teboul, David Grangier, Marco Tagliasacchi, and Neil Zeghidour.

</span>
<span class="ltx_bibblock">AudioLM: A language modeling approach to audio generation.

</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, 31:2523–2533, 2023.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Dongchao Yang, Songxiang Liu, Rongjie Huang, Jinchuan Tian, Chao Weng, and Yuexian Zou.

</span>
<span class="ltx_bibblock">HiFi-Codec: Group-residual vector quantization for high fidelity audio codec.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.02765</span>, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Matěj Korvas, Ondřej Plátek, Ondřej Dušek, Lukáš Žilka, and Filip Jurčíček.

</span>
<span class="ltx_bibblock">Free English and Czech telephone speech corpus shared under the CC-BY-SA 3.0 license.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">International Conference on Language Resources and Evaluation (LREC)</span>, pages 4423–4428, 2014.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Wei Han, Zhengdong Zhang, Yu Zhang, Jiahui Yu, Chung-Cheng Chiu, James Qin, Anmol Gulati, Ruoming Pang, and Yonghui Wu.

</span>
<span class="ltx_bibblock">ContextNet: Improving convolutional neural networks for automatic speech recognition with global context.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 3610–3614, 2020.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Rosana Ardila, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael Henretty, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber.

</span>
<span class="ltx_bibblock">Common Voice: A massively-multilingual speech corpus.

</span>
<span class="ltx_bibblock">In <span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Language Resources and Evaluation Conference (LREC)</span>, pages 4218–4222, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Arsha Nagrani, Joon Son Chung, and Andrew Zisserman.

</span>
<span class="ltx_bibblock">VoxCeleb: A large-scale speaker identification dataset.

</span>
<span class="ltx_bibblock">In <span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 2616–2620, 2017.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
David Snyder, Daniel Garcia-Romero, Gregory Sell, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">X-vectors: Robust DNN embeddings for speaker recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 5329–5333, 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Feng Wang, Jian Cheng, Weiyang Liu, and Haijun Liu.

</span>
<span class="ltx_bibblock">Additive margin softmax for face verification.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing Letters</span>, 25(7):926–930, 2018.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Brecht Desplanques, Jenthe Thienpondt, and Kris Demuynck.

</span>
<span class="ltx_bibblock">ECAPA-TDNN: Emphasized channel attention, propagation and aggregation in TDNN based speaker verification.

</span>
<span class="ltx_bibblock">In <span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 3830–3834, 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim, Jeannette N Chang, Sungbok Lee, and Shrikanth S Narayanan.

</span>
<span class="ltx_bibblock">IEMOCAP: Interactive emotional dyadic motion capture database.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Language resources and evaluation</span>, 42:335–359, 2008.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Emanuele Bastianelli, Andrea Vanzo, Pawel Swietojanski, and Verena Rieser.

</span>
<span class="ltx_bibblock">SLURP: A spoken language understanding resource package.

</span>
<span class="ltx_bibblock">In <span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">Conference on Empirical Methods in Natural Language Processing (EMNLP)</span>, pages 7252–7262, 2020.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Pete Warden.

</span>
<span class="ltx_bibblock">Speech Commands: A dataset for limited-vocabulary speech recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1804.03209</span>, 2018.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Cassia Valentini-Botinhao, Xin Wang, Shinji Takaki, and Junichi Yamagishi.

</span>
<span class="ltx_bibblock">Investigating RNN-based speech enhancement methods for noise-robust text-to-speech.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">Speech Synthesis Workshop</span>, pages 146–152, 2016.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, and Ruoming Pang.

</span>
<span class="ltx_bibblock">Conformer: Convolution-augmented transformer for speech recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 5036–5040, 2020.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Chandan KA Reddy, Vishak Gopal, and Ross Cutler.

</span>
<span class="ltx_bibblock">DNSMOS P.835: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, 2022.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Zhong-Qiu Wang et al.

</span>
<span class="ltx_bibblock">Sequential multi-frame neural beamforming for speech separation and enhancement.

</span>
<span class="ltx_bibblock">In <span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">IEEE Spoken Language Technology (SLT) Workshop</span>, pages 905–911, 2021.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Robust speech recognition via large-scale weak supervision.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2212.04356</span>, 2022.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Joris Cosentino, Manuel Pariente, Samuele Cornell, Antoine Deleforge, and Emmanuel Vincent.

</span>
<span class="ltx_bibblock">LibriMix: An open-source dataset for generalizable speech separation.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2005.11262</span>, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
M. Kolbæk, D. Yu, Z.-H. Tan, and J. Jensen.

</span>
<span class="ltx_bibblock">Multitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, 25:1901–1913, 2017.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">International Conference on Neural Information Processing Systems (NeurIPS)</span>, pages 6000–6010, 2017.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Keith Ito.

</span>
<span class="ltx_bibblock">The LJ speech dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://keithito.com/LJ-Speech-Dataset/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://keithito.com/LJ-Speech-Dataset/</a>, 2017.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Saeki Takaaki et al.

</span>
<span class="ltx_bibblock">UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 4521–4525, 2022.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Benjamin van Niekerk, Marc-André Carbonneau, Julian Zaïdi, Matthew Baas, Hugo Seuté, and Herman Kamper.

</span>
<span class="ltx_bibblock">A comparison of discrete and soft speech units for improved voice conversion.

</span>
<span class="ltx_bibblock">In <span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 6562–6566, 2022.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Yi-Chiao Wu, Israel D. Gebru, Dejan Marković, and Alexander Richard.

</span>
<span class="ltx_bibblock">Audiodec: An open-source streaming high-fidelity neural audio codec.

</span>
<span class="ltx_bibblock">In <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 1–5, 2023.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Harishchandra Dubey, Ashkan Aazami, Vishak Gopal, Babak Naderi, Sebastian Braun, Ross Cutler, Alex Ju, Mehdi Zohourian, Min Tang, Mehrsa Golestaneh, et al.

</span>
<span class="ltx_bibblock">ICASSP 2023 deep noise suppression challenge.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">IEEE Open Journal of Signal Processing</span>, 2024.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Jort F Gemmeke, Daniel PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R Channing Moore, Manoj Plakal, and Marvin Ritter.

</span>
<span class="ltx_bibblock">Audio Set: An ontology and human-labeled dataset for audio events.

</span>
<span class="ltx_bibblock">In <span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 776–780, 2017.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Eduardo Fonseca, Xavier Favory, Jordi Pons, Frederic Font, and Xavier Serra.

</span>
<span class="ltx_bibblock">FSD50K: an open dataset of human-labeled sound events.

</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, 30:829–852, 2021.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Dmitry Bogdanov, Minz Won, Philip Tovstogan, Alastair Porter, and Xavier Serra.

</span>
<span class="ltx_bibblock">The MTG-Jamendo dataset for automatic music tagging.

</span>
<span class="ltx_bibblock">In <span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning (ICML)</span>, 2019.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Gautham J Mysore.

</span>
<span class="ltx_bibblock">Can we automatically transform speech recorded on common consumer devices in real-world environments into professional production quality speech?—A dataset, insights, and challenges.

</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing Letters</span>, 22(8):1006–1010, 2014.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Junichi Yamagishi, Christophe Veaux, and Kirsten MacDonald.

</span>
<span class="ltx_bibblock">CSTR VCTK Corpus: English multi-speaker corpus for CSTR voice cloning toolkit (version 0.92), 2019.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Zafar Rafii, Antoine Liutkus, Fabian-Robert Stöter, Stylianos Ioannis Mimilakis, and Rachel Bittner.

</span>
<span class="ltx_bibblock">The MUSDB18 corpus for music separation.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.5281/zenodo.1117372" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.1117372</a>, 2017.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, Rj Skerrv-Ryan, Rif A. Saurous, Yannis Agiomvrgiannakis, and Yonghui Wu.

</span>
<span class="ltx_bibblock">Natural TTS synthesis by conditioning WaveNet on Mel spectrogram predictions.

</span>
<span class="ltx_bibblock">In <span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 4779–4783, 2018.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Hideyuki Tachibana, Katsuya Uenoyama, and Shunsuke Aihara.

</span>
<span class="ltx_bibblock">Efficiently trainable text-to-speech system based on deep convolutional networks with guided attention.

</span>
<span class="ltx_bibblock">In <span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>, pages 4784–4788, 2018.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>General Information</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Computational Resources</h3>

<div id="A1.SS1.p1" class="ltx_para ltx_noindent">
<p id="A1.SS1.p1.1" class="ltx_p">We designed our benchmark to be computationally accessible. Every task runs on GPUs with 32 GB or more of VRAM. Tasks like keyword spotting takes only 8 hours, while speech recognition (e.g, ASR-Basque) might require about 30 hours on a single NVIDIA V100 GPU.</p>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Impact</h3>

<div id="A1.SS2.p1" class="ltx_para ltx_noindent">
<p id="A1.SS2.p1.1" class="ltx_p">We believe DASB can have a positive impact on the research community. We do not foresee a direct negative societal impact or misuse of our benchmark. However, we acknowledge that DASB can potentially accelerate progress in multi-modal large language models, which, in turn, have a wide range of potential positive and negative uses that society is still working to assess.</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Hosting and Maintenance Plan</h3>

<div id="A1.SS3.p1" class="ltx_para ltx_noindent">
<p id="A1.SS3.p1.1" class="ltx_p">DASB platform is hosted and version-tracked via GitHub.
It is available at <a target="_blank" href="https://github.com/speechbrain/benchmarks" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/speechbrain/benchmarks</a>.
DASB is a community-driven and open-source initiative.
We plan to extend it by running additional experiments and including new audio tokenizers and tasks. We welcome external contributors.

<br class="ltx_break"></p>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Licensing</h3>

<div id="A1.SS4.p1" class="ltx_para">
<p id="A1.SS4.p1.1" class="ltx_p">Our work is licensed under Apache 2.0 (<a target="_blank" href="https://www.apache.org/licenses/LICENSE-2.0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.apache.org/licenses/LICENSE-2.0</a>).</p>
</div>
<figure id="A1.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Licenses for the models used in our benchmark.</figcaption>
<div id="A1.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:305.9pt;height:148.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-65.5pt,31.7pt) scale(0.7,0.7) ;">
<div id="A1.T5.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:211.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(87.7pt,-42.8pt) scale(1.67942946350393,1.67942946350393) ;">
<table id="A1.T5.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T5.1.1.1.1.1" class="ltx_tr">
<th id="A1.T5.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="A1.T5.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="A1.T5.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T5.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">License</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T5.1.1.1.2.1" class="ltx_tr">
<th id="A1.T5.1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">HuBERT-large</th>
<td id="A1.T5.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://www.apache.org/licenses/LICENSE-2.0" title="" class="ltx_ref ltx_href">Apache 2.0</a></td>
</tr>
<tr id="A1.T5.1.1.1.3.2" class="ltx_tr">
<th id="A1.T5.1.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">WavLM-large</th>
<td id="A1.T5.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://creativecommons.org/licenses/by-sa/2.0/" title="" class="ltx_ref ltx_href">ATTRIBUTION-SHAREALIKE 2.0</a></td>
</tr>
<tr id="A1.T5.1.1.1.4.3" class="ltx_tr">
<th id="A1.T5.1.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Wav2vec2-large</th>
<td id="A1.T5.1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://www.apache.org/licenses/LICENSE-2.0" title="" class="ltx_ref ltx_href">Apache 2.0</a></td>
</tr>
<tr id="A1.T5.1.1.1.5.4" class="ltx_tr">
<th id="A1.T5.1.1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">EnCodec</th>
<td id="A1.T5.1.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://opensource.org/license/mit" title="" class="ltx_ref ltx_href">MIT license</a></td>
</tr>
<tr id="A1.T5.1.1.1.6.5" class="ltx_tr">
<th id="A1.T5.1.1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">DAC</th>
<td id="A1.T5.1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://opensource.org/license/mit" title="" class="ltx_ref ltx_href">MIT license</a></td>
</tr>
<tr id="A1.T5.1.1.1.7.6" class="ltx_tr">
<th id="A1.T5.1.1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">SpeechTokenizer</th>
<td id="A1.T5.1.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><a target="_blank" href="https://www.apache.org/licenses/LICENSE-2.0" title="" class="ltx_ref ltx_href">Apache 2.0</a></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Author Statement</h3>

<div id="A1.SS5.p1" class="ltx_para ltx_noindent">
<p id="A1.SS5.p1.1" class="ltx_p">We, the authors, will bear all responsibility in case of violation of rights.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Discrete Audio Models Details</h2>

<figure id="A2.tab1" class="ltx_table">

<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Features of the Considered Discrete Audio Encoders.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="A2.tab1.1" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:437.0pt;height:107pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="A2.tab1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:107pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-150.3pt,36.9pt) scale(0.590577291977552,0.590577291977552) ;">
<table id="A2.tab1.1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A2.tab1.1.1.1.1.1" class="ltx_tr">
<td id="A2.tab1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A2.tab1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="A2.tab1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A2.tab1.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="A2.tab1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.tab1.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Repo</span></td>
</tr>
<tr id="A2.tab1.1.1.1.2.2" class="ltx_tr">
<td id="A2.tab1.1.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete Hubert <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">LibriSpeech960<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://huggingface.co/poonehmousavi/SSL_Quantization" title="" class="ltx_ref ltx_href">huggingface.co/poonehmousavi/SSL_Quantization</a></td>
</tr>
<tr id="A2.tab1.1.1.1.3.3" class="ltx_tr">
<td id="A2.tab1.1.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete WavLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">LibriSpeech960<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://huggingface.co/poonehmousavi/SSL_Quantization" title="" class="ltx_ref ltx_href">huggingface.co/poonehmousavi/SSL_Quantization</a></td>
</tr>
<tr id="A2.tab1.1.1.1.4.4" class="ltx_tr">
<td id="A2.tab1.1.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete Wav2Vec2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">LibriSpeech960<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_t"><a target="_blank" href="https://huggingface.co/poonehmousavi/SSL_Quantization" title="" class="ltx_ref ltx_href">huggingface.co/poonehmousavi/SSL_Quantization</a></td>
</tr>
<tr id="A2.tab1.1.1.1.5.5" class="ltx_tr">
<td id="A2.tab1.1.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">EnCodec <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.5.5.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<span id="A2.tab1.1.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.tab1.1.1.1.5.5.2.1.1" class="ltx_p" style="width:227.6pt;">DNS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>, CommonVoice <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>,</span>
</span>
</td>
<td id="A2.tab1.1.1.1.5.5.3" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="A2.tab1.1.1.1.6.6" class="ltx_tr">
<td id="A2.tab1.1.1.1.6.6.1" class="ltx_td"></td>
<td id="A2.tab1.1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_rr"><a target="_blank" href="https://github.com/facebookresearch/encodec" title="" class="ltx_ref ltx_href">github.com/facebookresearch/encodec</a></td>
<td id="A2.tab1.1.1.1.6.6.3" class="ltx_td"></td>
</tr>
<tr id="A2.tab1.1.1.1.7.7" class="ltx_tr">
<td id="A2.tab1.1.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">DAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.7.7.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<span id="A2.tab1.1.1.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.tab1.1.1.1.7.7.2.1.1" class="ltx_p" style="width:227.6pt;">DAPS<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>, DNS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>, CommonVoice <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>,</span>
</span>
</td>
<td id="A2.tab1.1.1.1.7.7.3" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="A2.tab1.1.1.1.8.8" class="ltx_tr">
<td id="A2.tab1.1.1.1.8.8.1" class="ltx_td"></td>
<td id="A2.tab1.1.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_rr"><a target="_blank" href="https://github.com/descriptinc/descript-audio-codec" title="" class="ltx_ref ltx_href">github.com/descriptinc/descript-audio-codec</a></td>
<td id="A2.tab1.1.1.1.8.8.3" class="ltx_td"></td>
</tr>
<tr id="A2.tab1.1.1.1.9.9" class="ltx_tr">
<td id="A2.tab1.1.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">SpeechTokenizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.9.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">LibriSpeech960<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="A2.tab1.1.1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><a target="_blank" href="https://github.com/ZhangXInFD/SpeechTokenizer" title="" class="ltx_ref ltx_href">github.com/ZhangXInFD/SpeechTokenizer</a></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<section id="A3" class="ltx_appendix ltx_figure_panel">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Dataset and Downstream Models</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">Table <a href="#A3.T7" title="Table 7 ‣ Appendix C Dataset and Downstream Models ‣ Appendix B Discrete Audio Models Details ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> provides a summary of the datasets and the two downstream architectures used for each task.</p>
</div>
<figure id="A3.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Dataset and Downstream Models</figcaption>
<div id="A3.T7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:437.0pt;height:89.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="A3.T7.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:89.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-219.1pt,45.2pt) scale(0.497334940636947,0.497334940636947) ;">
<table id="A3.T7.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T7.1.1.1.1.1" class="ltx_tr">
<th id="A3.T7.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="A3.T7.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="A3.T7.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="A3.T7.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Task</span></th>
<th id="A3.T7.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="A3.T7.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">1st Architecture</span></th>
<th id="A3.T7.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="A3.T7.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">2nd Architecture</span></th>
<th id="A3.T7.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A3.T7.1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Dataset Link</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T7.1.1.1.2.1" class="ltx_tr">
<td id="A3.T7.1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">LibriSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="A3.T7.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Speech Recognition</td>
<td id="A3.T7.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BiLSTM</td>
<td id="A3.T7.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ContextNet</td>
<td id="A3.T7.1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><a href="openslr.org/12" title="" class="ltx_ref ltx_url ltx_font_typewriter">openslr.org/12</a></td>
</tr>
<tr id="A3.T7.1.1.1.3.2" class="ltx_tr">
<td id="A3.T7.1.1.1.3.2.1" class="ltx_td ltx_align_left ltx_border_r">CommonVoice 17.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>
</td>
<td id="A3.T7.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">Speech Recognition</td>
<td id="A3.T7.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">BiLSTM</td>
<td id="A3.T7.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r">Linear</td>
<td id="A3.T7.1.1.1.3.2.5" class="ltx_td ltx_align_center"><a target="_blank" href="https://commonvoice.mozilla.org/en/datasets" title="" class="ltx_ref ltx_href">commonvoice.mozilla.org/en/datasets</a></td>
</tr>
<tr id="A3.T7.1.1.1.4.3" class="ltx_tr">
<td id="A3.T7.1.1.1.4.3.1" class="ltx_td ltx_align_left ltx_border_r">VoxCeleb1 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="A3.T7.1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">speaker verification/identification</td>
<td id="A3.T7.1.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">ECAPA-TDNN</td>
<td id="A3.T7.1.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r">X-Vectors</td>
<td id="A3.T7.1.1.1.4.3.5" class="ltx_td ltx_align_center"><a target="_blank" href="https://www.robots.ox.ac.uk/%C2%A0vgg/data/voxceleb/vox1.html" title="" class="ltx_ref ltx_href">robots.ox.ac.uk/ vgg/data/voxceleb/vox1.html</a></td>
</tr>
<tr id="A3.T7.1.1.1.5.4" class="ltx_tr">
<td id="A3.T7.1.1.1.5.4.1" class="ltx_td ltx_align_left ltx_border_r">IEMOCAP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
<td id="A3.T7.1.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">Emotion Recognition</td>
<td id="A3.T7.1.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r">ECAPA-TDNN</td>
<td id="A3.T7.1.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r">Time-Pooling + Linear</td>
<td id="A3.T7.1.1.1.5.4.5" class="ltx_td ltx_align_center"><a target="_blank" href="https://sail.usc.edu/iemocap/" title="" class="ltx_ref ltx_href">sail.usc.edu/iemocap/</a></td>
</tr>
<tr id="A3.T7.1.1.1.6.5" class="ltx_tr">
<td id="A3.T7.1.1.1.6.5.1" class="ltx_td ltx_align_left ltx_border_r">Speech Commands <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</td>
<td id="A3.T7.1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r">Keyword Spotting</td>
<td id="A3.T7.1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r">X -Vectors</td>
<td id="A3.T7.1.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r">ECAPA-TDNN</td>
<td id="A3.T7.1.1.1.6.5.5" class="ltx_td ltx_align_center"><a target="_blank" href="https://www.tensorflow.org/datasets/catalog/speech_commands" title="" class="ltx_ref ltx_href">tensorflow.org/datasets/catalog/speech_commands</a></td>
</tr>
<tr id="A3.T7.1.1.1.7.6" class="ltx_tr">
<td id="A3.T7.1.1.1.7.6.1" class="ltx_td ltx_align_left ltx_border_r">SLURP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>
</td>
<td id="A3.T7.1.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r">Intent Classification</td>
<td id="A3.T7.1.1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r">BiLSTM + Linear</td>
<td id="A3.T7.1.1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r">Time-Pooling + Linear</td>
<td id="A3.T7.1.1.1.7.6.5" class="ltx_td ltx_align_center"><a target="_blank" href="https://zenodo.org/record/4274930" title="" class="ltx_ref ltx_href">zenodo.org/record/4274930</a></td>
</tr>
<tr id="A3.T7.1.1.1.8.7" class="ltx_tr">
<td id="A3.T7.1.1.1.8.7.1" class="ltx_td ltx_align_left ltx_border_r">VoiceBank <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>
</td>
<td id="A3.T7.1.1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r">Speech Enhancement</td>
<td id="A3.T7.1.1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r">Conformer</td>
<td id="A3.T7.1.1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r">CRDNN</td>
<td id="A3.T7.1.1.1.8.7.5" class="ltx_td ltx_align_center"><a target="_blank" href="https://datashare.ed.ac.uk/handle/10283/2791" title="" class="ltx_ref ltx_href">datashare.ed.ac.uk/handle/10283/2791</a></td>
</tr>
<tr id="A3.T7.1.1.1.9.8" class="ltx_tr">
<td id="A3.T7.1.1.1.9.8.1" class="ltx_td ltx_align_left ltx_border_r">Libri2Mix <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>
</td>
<td id="A3.T7.1.1.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r">Speech Separation</td>
<td id="A3.T7.1.1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_r">Conformer</td>
<td id="A3.T7.1.1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r">CRDNN</td>
<td id="A3.T7.1.1.1.9.8.5" class="ltx_td ltx_align_center"><a target="_blank" href="https://github.com/JorisCos/LibriMix" title="" class="ltx_ref ltx_href">github.com/JorisCos/LibriMix</a></td>
</tr>
<tr id="A3.T7.1.1.1.10.9" class="ltx_tr">
<td id="A3.T7.1.1.1.10.9.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">LJSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>
</td>
<td id="A3.T7.1.1.1.10.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Text-to-Speech</td>
<td id="A3.T7.1.1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Shallow Transformer</td>
<td id="A3.T7.1.1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Deep Transformer</td>
<td id="A3.T7.1.1.1.10.9.5" class="ltx_td ltx_align_center ltx_border_b"><a target="_blank" href="https://keithito.com/LJ-Speech-Dataset/" title="" class="ltx_ref ltx_href">keithito.com/LJ-Speech-Dataset/</a></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional Analysis of Discrete Audio Decoders</h2>

<div id="A4.p1" class="ltx_para ltx_noindent">
<p id="A4.p1.1" class="ltx_p">In this section, we expand on the results from Section <a href="#S5.SS3" title="5.3 Analysis of Discrete Audio Decoder ‣ 5 Results ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a> by including low and high bitrates in addition to the medium bitrate. Additionally, for speaker similarity, we measure the cosine similarity between X-vectors extracted from the reconstructed and target signals using two different models: WavLM (SpkSim WavLM) and ECAPA-TDNN (SpkSim ECAPA), both fine-tuned for speaker verification. When analyzing low and high bitrate settings, distinct trends emerge compared to the medium bitrate. At low bitrates, the models perform worse in terms of speaker similarity, MOS, and dWER, as expected. This is particularly pronounced for compression-based decoders, where the degradation is more significant in terms of dWER. In contrast, at high bitrate, there is an overall small improvement in all metrics. In particular, the DAC model consistently outperforms EnCodec across all evaluated metrics, even for high bitrate settings.</p>
</div>
<div id="A4.p2" class="ltx_para ltx_noindent">
<p id="A4.p2.1" class="ltx_p">The analysis shows that bitrate significantly impacts the performance of discrete decoders. Higher bitrates better preserve speech characteristics and result in lower error rates, while lower bitrates degrade these aspects. This highlights the trade-off between bitrate and speech synthesis quality.</p>
</div>
<figure id="A4.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Evaluation of various discrete decoders for the speech re-synthesis task at low, medium, and high bitrates.</figcaption>
<div id="A4.T8.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:393.3pt;height:317.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-21.8pt,17.6pt) scale(0.9,0.9) ;">
<div id="A4.T8.4.4" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:352.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(17.7pt,-14.4pt) scale(1.08873570785644,1.08873570785644) ;">
<table id="A4.T8.4.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A4.T8.4.4.4.4" class="ltx_tr">
<th id="A4.T8.4.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="A4.T8.4.4.4.4.5.1" class="ltx_text ltx_font_bold">Models/Metrics</span></th>
<td id="A4.T8.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A4.T8.1.1.1.1.1.1" class="ltx_text ltx_font_bold">SpkSim ECAPA</span> <math id="A4.T8.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A4.T8.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A4.T8.1.1.1.1.1.m1.1.1" xref="A4.T8.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T8.1.1.1.1.1.m1.1b"><ci id="A4.T8.1.1.1.1.1.m1.1.1.cmml" xref="A4.T8.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A4.T8.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A4.T8.2.2.2.2.2.1" class="ltx_text ltx_font_bold">SpkSim WavLM</span> <math id="A4.T8.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A4.T8.2.2.2.2.2.m1.1a"><mo stretchy="false" id="A4.T8.2.2.2.2.2.m1.1.1" xref="A4.T8.2.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T8.2.2.2.2.2.m1.1b"><ci id="A4.T8.2.2.2.2.2.m1.1.1.cmml" xref="A4.T8.2.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.2.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A4.T8.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A4.T8.3.3.3.3.3.1" class="ltx_text ltx_font_bold">DNSMOS</span> <math id="A4.T8.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A4.T8.3.3.3.3.3.m1.1a"><mo stretchy="false" id="A4.T8.3.3.3.3.3.m1.1.1" xref="A4.T8.3.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T8.3.3.3.3.3.m1.1b"><ci id="A4.T8.3.3.3.3.3.m1.1.1.cmml" xref="A4.T8.3.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.3.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A4.T8.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="A4.T8.4.4.4.4.4.1" class="ltx_text ltx_font_bold">dWER</span> <math id="A4.T8.4.4.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A4.T8.4.4.4.4.4.m1.1a"><mo stretchy="false" id="A4.T8.4.4.4.4.4.m1.1.1" xref="A4.T8.4.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T8.4.4.4.4.4.m1.1b"><ci id="A4.T8.4.4.4.4.4.m1.1.1.cmml" xref="A4.T8.4.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.4.4.4.4.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="A4.T8.4.4.4.5.1" class="ltx_tr">
<th id="A4.T8.4.4.4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5"><span id="A4.T8.4.4.4.5.1.1.1" class="ltx_text ltx_font_italic">Low Bitrate</span></th>
</tr>
<tr id="A4.T8.4.4.4.6.2" class="ltx_tr">
<th id="A4.T8.4.4.4.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete Hubert</th>
<td id="A4.T8.4.4.4.6.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.34</td>
<td id="A4.T8.4.4.4.6.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.87</td>
<td id="A4.T8.4.4.4.6.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.51</td>
<td id="A4.T8.4.4.4.6.2.5" class="ltx_td ltx_align_center ltx_border_t">8.25</td>
</tr>
<tr id="A4.T8.4.4.4.7.3" class="ltx_tr">
<th id="A4.T8.4.4.4.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="A4.T8.4.4.4.7.3.2" class="ltx_td ltx_align_center ltx_border_r">0.34</td>
<td id="A4.T8.4.4.4.7.3.3" class="ltx_td ltx_align_center ltx_border_r">0.88</td>
<td id="A4.T8.4.4.4.7.3.4" class="ltx_td ltx_align_center ltx_border_r">3.45</td>
<td id="A4.T8.4.4.4.7.3.5" class="ltx_td ltx_align_center"><span id="A4.T8.4.4.4.7.3.5.1" class="ltx_text ltx_font_bold">7.01</span></td>
</tr>
<tr id="A4.T8.4.4.4.8.4" class="ltx_tr">
<th id="A4.T8.4.4.4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="A4.T8.4.4.4.8.4.2" class="ltx_td ltx_align_center ltx_border_r">0.28</td>
<td id="A4.T8.4.4.4.8.4.3" class="ltx_td ltx_align_center ltx_border_r">0.82</td>
<td id="A4.T8.4.4.4.8.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A4.T8.4.4.4.8.4.4.1" class="ltx_text ltx_font_bold">3.73</span></td>
<td id="A4.T8.4.4.4.8.4.5" class="ltx_td ltx_align_center">10.58</td>
</tr>
<tr id="A4.T8.4.4.4.9.5" class="ltx_tr">
<th id="A4.T8.4.4.4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="A4.T8.4.4.4.9.5.2" class="ltx_td ltx_align_center ltx_border_r">0.52</td>
<td id="A4.T8.4.4.4.9.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="A4.T8.4.4.4.9.5.3.1" class="ltx_text ltx_font_bold">0.92</span></td>
<td id="A4.T8.4.4.4.9.5.4" class="ltx_td ltx_align_center ltx_border_r">3.20</td>
<td id="A4.T8.4.4.4.9.5.5" class="ltx_td ltx_align_center">11.71</td>
</tr>
<tr id="A4.T8.4.4.4.10.6" class="ltx_tr">
<th id="A4.T8.4.4.4.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="A4.T8.4.4.4.10.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A4.T8.4.4.4.10.6.2.1" class="ltx_text ltx_font_bold">0.54</span></td>
<td id="A4.T8.4.4.4.10.6.3" class="ltx_td ltx_align_center ltx_border_r">0.91</td>
<td id="A4.T8.4.4.4.10.6.4" class="ltx_td ltx_align_center ltx_border_r">3.42</td>
<td id="A4.T8.4.4.4.10.6.5" class="ltx_td ltx_align_center">14.02</td>
</tr>
<tr id="A4.T8.4.4.4.11.7" class="ltx_tr">
<th id="A4.T8.4.4.4.11.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="A4.T8.4.4.4.11.7.2" class="ltx_td ltx_align_center ltx_border_r">0.22</td>
<td id="A4.T8.4.4.4.11.7.3" class="ltx_td ltx_align_center ltx_border_r">0.72</td>
<td id="A4.T8.4.4.4.11.7.4" class="ltx_td ltx_align_center ltx_border_r">3.21</td>
<td id="A4.T8.4.4.4.11.7.5" class="ltx_td ltx_align_center">45.7</td>
</tr>
<tr id="A4.T8.4.4.4.12.8" class="ltx_tr">
<th id="A4.T8.4.4.4.12.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5"><span id="A4.T8.4.4.4.12.8.1.1" class="ltx_text ltx_font_italic">Medium Bitrate</span></th>
</tr>
<tr id="A4.T8.4.4.4.13.9" class="ltx_tr">
<th id="A4.T8.4.4.4.13.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete Hubert</th>
<td id="A4.T8.4.4.4.13.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.47</td>
<td id="A4.T8.4.4.4.13.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.92</td>
<td id="A4.T8.4.4.4.13.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.68</td>
<td id="A4.T8.4.4.4.13.9.5" class="ltx_td ltx_align_center ltx_border_t">6.60</td>
</tr>
<tr id="A4.T8.4.4.4.14.10" class="ltx_tr">
<th id="A4.T8.4.4.4.14.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="A4.T8.4.4.4.14.10.2" class="ltx_td ltx_align_center ltx_border_r">0.53</td>
<td id="A4.T8.4.4.4.14.10.3" class="ltx_td ltx_align_center ltx_border_r">0.94</td>
<td id="A4.T8.4.4.4.14.10.4" class="ltx_td ltx_align_center ltx_border_r">3.64</td>
<td id="A4.T8.4.4.4.14.10.5" class="ltx_td ltx_align_center">5.19</td>
</tr>
<tr id="A4.T8.4.4.4.15.11" class="ltx_tr">
<th id="A4.T8.4.4.4.15.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="A4.T8.4.4.4.15.11.2" class="ltx_td ltx_align_center ltx_border_r">0.43</td>
<td id="A4.T8.4.4.4.15.11.3" class="ltx_td ltx_align_center ltx_border_r">0.91</td>
<td id="A4.T8.4.4.4.15.11.4" class="ltx_td ltx_align_center ltx_border_r">3.71</td>
<td id="A4.T8.4.4.4.15.11.5" class="ltx_td ltx_align_center">8.72</td>
</tr>
<tr id="A4.T8.4.4.4.16.12" class="ltx_tr">
<th id="A4.T8.4.4.4.16.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="A4.T8.4.4.4.16.12.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A4.T8.4.4.4.16.12.2.1" class="ltx_text ltx_font_bold">0.87</span></td>
<td id="A4.T8.4.4.4.16.12.3" class="ltx_td ltx_align_center ltx_border_r">0.98</td>
<td id="A4.T8.4.4.4.16.12.4" class="ltx_td ltx_align_center ltx_border_r">3.54</td>
<td id="A4.T8.4.4.4.16.12.5" class="ltx_td ltx_align_center"><span id="A4.T8.4.4.4.16.12.5.1" class="ltx_text ltx_font_bold">2.16</span></td>
</tr>
<tr id="A4.T8.4.4.4.17.13" class="ltx_tr">
<th id="A4.T8.4.4.4.17.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="A4.T8.4.4.4.17.13.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A4.T8.4.4.4.17.13.2.1" class="ltx_text ltx_font_bold">0.87</span></td>
<td id="A4.T8.4.4.4.17.13.3" class="ltx_td ltx_align_center ltx_border_r"><span id="A4.T8.4.4.4.17.13.3.1" class="ltx_text ltx_font_bold">0.99</span></td>
<td id="A4.T8.4.4.4.17.13.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A4.T8.4.4.4.17.13.4.1" class="ltx_text ltx_font_bold">3.74</span></td>
<td id="A4.T8.4.4.4.17.13.5" class="ltx_td ltx_align_center">2.36</td>
</tr>
<tr id="A4.T8.4.4.4.18.14" class="ltx_tr">
<th id="A4.T8.4.4.4.18.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="A4.T8.4.4.4.18.14.2" class="ltx_td ltx_align_center ltx_border_r">0.65</td>
<td id="A4.T8.4.4.4.18.14.3" class="ltx_td ltx_align_center ltx_border_r">0.94</td>
<td id="A4.T8.4.4.4.18.14.4" class="ltx_td ltx_align_center ltx_border_r">3.58</td>
<td id="A4.T8.4.4.4.18.14.5" class="ltx_td ltx_align_center">5.12</td>
</tr>
<tr id="A4.T8.4.4.4.19.15" class="ltx_tr">
<th id="A4.T8.4.4.4.19.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5"><span id="A4.T8.4.4.4.19.15.1.1" class="ltx_text ltx_font_italic">High Bitrate</span></th>
</tr>
<tr id="A4.T8.4.4.4.20.16" class="ltx_tr">
<th id="A4.T8.4.4.4.20.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">EnCodec</th>
<td id="A4.T8.4.4.4.20.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.94</td>
<td id="A4.T8.4.4.4.20.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.99</td>
<td id="A4.T8.4.4.4.20.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.69</td>
<td id="A4.T8.4.4.4.20.16.5" class="ltx_td ltx_align_center ltx_border_t">1.47</td>
</tr>
<tr id="A4.T8.4.4.4.21.17" class="ltx_tr">
<th id="A4.T8.4.4.4.21.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">DAC</th>
<td id="A4.T8.4.4.4.21.17.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="A4.T8.4.4.4.21.17.2.1" class="ltx_text ltx_font_bold">0.98</span></td>
<td id="A4.T8.4.4.4.21.17.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="A4.T8.4.4.4.21.17.3.1" class="ltx_text ltx_font_bold">100</span></td>
<td id="A4.T8.4.4.4.21.17.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="A4.T8.4.4.4.21.17.4.1" class="ltx_text ltx_font_bold">3.79</span></td>
<td id="A4.T8.4.4.4.21.17.5" class="ltx_td ltx_align_center ltx_border_b"><span id="A4.T8.4.4.4.21.17.5.1" class="ltx_text ltx_font_bold">0.73</span></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Additional Results</h2>

<div id="A5.p1" class="ltx_para ltx_noindent">
<p id="A5.p1.1" class="ltx_p">Tables <a href="#A5.T9" title="Table 9 ‣ Appendix E Additional Results ‣ Appendix D Additional Analysis of Discrete Audio Decoders ‣ Appendix C Dataset and Downstream Models ‣ Appendix B Discrete Audio Models Details ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> - <a href="#A5.T12" title="Table 12 ‣ Appendix E Additional Results ‣ Appendix D Additional Analysis of Discrete Audio Decoders ‣ Appendix C Dataset and Downstream Models ‣ Appendix B Discrete Audio Models Details ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> show the results obtained with 2 different downstream architectures. Note that table <a href="#A3.T7" title="Table 7 ‣ Appendix C Dataset and Downstream Models ‣ Appendix B Discrete Audio Models Details ‣ DASB - Discrete Audio and Speech Benchmark" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> indicates the first and second architectures explored for each task. For the continuous baseline, we follow the same architecture as the discrete experiments except for TTS. For the TTS continuous baseline, we use a modified Tacotron2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> architecture enhanced with guided attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> that predicts SSL representations instead of Mel spectrograms.</p>
</div>
<div id="A5.p2" class="ltx_para ltx_noindent">
<p id="A5.p2.1" class="ltx_p">Varying the architecture of the downstream decoder leads to significant variations in task performance. For ASR tasks, BiLSTM performs better. For classification tasks, ECAPA-TDNN shows the best performance, except for keyword spotting where X-vector is slightly better. For speech enhancement and separation, Conformer shows the best performance. For TTS, a notable pattern is observed: semantic tokens yield the best results with shallow models, while acoustic and hybrid tokens perform better with deeper models but still underperform compared to semantic tokens. One reason might be that discrete SSL models retain higher-level features closer to phonetic transcriptions, requiring lower-capacity models to capture the relationship between raw text and such representations. Higher-capacity models can lead to slower training and potential overfitting. In contrast, shallow models appear to underfit acoustic tokens, resulting in high dWERs and speech-like sounds with only surface resemblance to the original sentence, rather than intelligible speech.</p>
</div>
<figure id="A5.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Results for discriminative tasks with the first downstream architecture.</figcaption>
<div id="A5.T9.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:437.0pt;height:369.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="A5.T9.7.7" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:369.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.5pt,13.2pt) scale(0.933463113292097,0.933463113292097) ;">
<table id="A5.T9.7.7.7" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A5.T9.7.7.7.8.1" class="ltx_tr">
<td id="A5.T9.7.7.7.8.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="3"><span id="A5.T9.7.7.7.8.1.1.1" class="ltx_text ltx_font_bold">Models/Tasks</span></td>
<td id="A5.T9.7.7.7.8.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="A5.T9.7.7.7.8.1.2.1" class="ltx_text ltx_font_bold">ASR-En</span></td>
<td id="A5.T9.7.7.7.8.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="A5.T9.7.7.7.8.1.3.1" class="ltx_text ltx_font_bold">ASR-multiling</span></td>
<td id="A5.T9.7.7.7.8.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.8.1.4.1" class="ltx_text ltx_font_bold">ER</span></td>
<td id="A5.T9.7.7.7.8.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.8.1.5.1" class="ltx_text ltx_font_bold">IC</span></td>
<td id="A5.T9.7.7.7.8.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.8.1.6.1" class="ltx_text ltx_font_bold">KS</span></td>
<td id="A5.T9.7.7.7.8.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.8.1.7.1" class="ltx_text ltx_font_bold">SI</span></td>
<td id="A5.T9.7.7.7.8.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.8.1.8.1" class="ltx_text ltx_font_bold">SV</span></td>
</tr>
<tr id="A5.T9.7.7.7.7" class="ltx_tr">
<td id="A5.T9.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">
<span id="A5.T9.1.1.1.1.1.1" class="ltx_text ltx_font_bold">WER</span> <math id="A5.T9.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T9.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A5.T9.1.1.1.1.1.m1.1.1" xref="A5.T9.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T9.1.1.1.1.1.m1.1b"><ci id="A5.T9.1.1.1.1.1.m1.1.1.cmml" xref="A5.T9.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T9.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A5.T9.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">
<span id="A5.T9.2.2.2.2.2.1" class="ltx_text ltx_font_bold">WER</span> <math id="A5.T9.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T9.2.2.2.2.2.m1.1a"><mo stretchy="false" id="A5.T9.2.2.2.2.2.m1.1.1" xref="A5.T9.2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T9.2.2.2.2.2.m1.1b"><ci id="A5.T9.2.2.2.2.2.m1.1.1.cmml" xref="A5.T9.2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T9.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A5.T9.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T9.3.3.3.3.3.1" class="ltx_text"><span id="A5.T9.3.3.3.3.3.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="A5.T9.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T9.3.3.3.3.3.1.m1.1a"><mo stretchy="false" id="A5.T9.3.3.3.3.3.1.m1.1.1" xref="A5.T9.3.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T9.3.3.3.3.3.1.m1.1b"><ci id="A5.T9.3.3.3.3.3.1.m1.1.1.cmml" xref="A5.T9.3.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T9.3.3.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="A5.T9.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T9.4.4.4.4.4.1" class="ltx_text"><span id="A5.T9.4.4.4.4.4.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="A5.T9.4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T9.4.4.4.4.4.1.m1.1a"><mo stretchy="false" id="A5.T9.4.4.4.4.4.1.m1.1.1" xref="A5.T9.4.4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T9.4.4.4.4.4.1.m1.1b"><ci id="A5.T9.4.4.4.4.4.1.m1.1.1.cmml" xref="A5.T9.4.4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T9.4.4.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="A5.T9.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T9.5.5.5.5.5.1" class="ltx_text"><span id="A5.T9.5.5.5.5.5.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="A5.T9.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T9.5.5.5.5.5.1.m1.1a"><mo stretchy="false" id="A5.T9.5.5.5.5.5.1.m1.1.1" xref="A5.T9.5.5.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T9.5.5.5.5.5.1.m1.1b"><ci id="A5.T9.5.5.5.5.5.1.m1.1.1.cmml" xref="A5.T9.5.5.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T9.5.5.5.5.5.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="A5.T9.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T9.6.6.6.6.6.1" class="ltx_text"><span id="A5.T9.6.6.6.6.6.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="A5.T9.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T9.6.6.6.6.6.1.m1.1a"><mo stretchy="false" id="A5.T9.6.6.6.6.6.1.m1.1.1" xref="A5.T9.6.6.6.6.6.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T9.6.6.6.6.6.1.m1.1b"><ci id="A5.T9.6.6.6.6.6.1.m1.1.1.cmml" xref="A5.T9.6.6.6.6.6.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T9.6.6.6.6.6.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="A5.T9.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="A5.T9.7.7.7.7.7.1" class="ltx_text"><span id="A5.T9.7.7.7.7.7.1.1" class="ltx_text ltx_font_bold">EER</span> <math id="A5.T9.7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T9.7.7.7.7.7.1.m1.1a"><mo stretchy="false" id="A5.T9.7.7.7.7.7.1.m1.1.1" xref="A5.T9.7.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T9.7.7.7.7.7.1.m1.1b"><ci id="A5.T9.7.7.7.7.7.1.m1.1.1.cmml" xref="A5.T9.7.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T9.7.7.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="A5.T9.7.7.7.9.2" class="ltx_tr">
<td id="A5.T9.7.7.7.9.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.9.2.1.1" class="ltx_text ltx_font_bold">Clean</span></td>
<td id="A5.T9.7.7.7.9.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.9.2.2.1" class="ltx_text ltx_font_bold">Other</span></td>
<td id="A5.T9.7.7.7.9.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.9.2.3.1" class="ltx_text ltx_font_bold">Welsh</span></td>
<td id="A5.T9.7.7.7.9.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.9.2.4.1" class="ltx_text ltx_font_bold">Basque</span></td>
</tr>
<tr id="A5.T9.7.7.7.10.3" class="ltx_tr">
<td id="A5.T9.7.7.7.10.3.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="A5.T9.7.7.7.10.3.1.1" class="ltx_text ltx_font_italic">Low Bitrate</span></td>
</tr>
<tr id="A5.T9.7.7.7.11.4" class="ltx_tr">
<td id="A5.T9.7.7.7.11.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete Hubert</td>
<td id="A5.T9.7.7.7.11.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.11.4.2.1" class="ltx_text ltx_font_bold">8.99</span></td>
<td id="A5.T9.7.7.7.11.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.11.4.3.1" class="ltx_text ltx_font_bold">21.14</span></td>
<td id="A5.T9.7.7.7.11.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.11.4.4.1" class="ltx_text ltx_font_bold">58.50</span></td>
<td id="A5.T9.7.7.7.11.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.11.4.5.1" class="ltx_text ltx_font_bold">26.83</span></td>
<td id="A5.T9.7.7.7.11.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.20</td>
<td id="A5.T9.7.7.7.11.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.70</td>
<td id="A5.T9.7.7.7.11.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.54</td>
<td id="A5.T9.7.7.7.11.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.90</td>
<td id="A5.T9.7.7.7.11.4.10" class="ltx_td ltx_align_center ltx_border_t">24.99</td>
</tr>
<tr id="A5.T9.7.7.7.12.5" class="ltx_tr">
<td id="A5.T9.7.7.7.12.5.1" class="ltx_td ltx_align_left ltx_border_r">Discrete WavLM</td>
<td id="A5.T9.7.7.7.12.5.2" class="ltx_td ltx_align_center">11.72</td>
<td id="A5.T9.7.7.7.12.5.3" class="ltx_td ltx_align_center ltx_border_r">27.56</td>
<td id="A5.T9.7.7.7.12.5.4" class="ltx_td ltx_align_center">60.37</td>
<td id="A5.T9.7.7.7.12.5.5" class="ltx_td ltx_align_center ltx_border_r">28.63</td>
<td id="A5.T9.7.7.7.12.5.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.12.5.6.1" class="ltx_text ltx_font_bold">59.80</span></td>
<td id="A5.T9.7.7.7.12.5.7" class="ltx_td ltx_align_center ltx_border_r">73.40</td>
<td id="A5.T9.7.7.7.12.5.8" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.12.5.8.1" class="ltx_text ltx_font_bold">97.94</span></td>
<td id="A5.T9.7.7.7.12.5.9" class="ltx_td ltx_align_center ltx_border_r">0.70</td>
<td id="A5.T9.7.7.7.12.5.10" class="ltx_td ltx_align_center">26.02</td>
</tr>
<tr id="A5.T9.7.7.7.13.6" class="ltx_tr">
<td id="A5.T9.7.7.7.13.6.1" class="ltx_td ltx_align_left ltx_border_r">Discrete Wav2Vec2</td>
<td id="A5.T9.7.7.7.13.6.2" class="ltx_td ltx_align_center">12.14</td>
<td id="A5.T9.7.7.7.13.6.3" class="ltx_td ltx_align_center ltx_border_r">28.65</td>
<td id="A5.T9.7.7.7.13.6.4" class="ltx_td ltx_align_center">66.30</td>
<td id="A5.T9.7.7.7.13.6.5" class="ltx_td ltx_align_center ltx_border_r">32.25</td>
<td id="A5.T9.7.7.7.13.6.6" class="ltx_td ltx_align_center ltx_border_r">57.80</td>
<td id="A5.T9.7.7.7.13.6.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.13.6.7.1" class="ltx_text ltx_font_bold">74.10</span></td>
<td id="A5.T9.7.7.7.13.6.8" class="ltx_td ltx_align_center ltx_border_r">96.16</td>
<td id="A5.T9.7.7.7.13.6.9" class="ltx_td ltx_align_center ltx_border_r">0.40</td>
<td id="A5.T9.7.7.7.13.6.10" class="ltx_td ltx_align_center">33.53</td>
</tr>
<tr id="A5.T9.7.7.7.14.7" class="ltx_tr">
<td id="A5.T9.7.7.7.14.7.1" class="ltx_td ltx_align_left ltx_border_r">EnCodec</td>
<td id="A5.T9.7.7.7.14.7.2" class="ltx_td ltx_align_center">52.37</td>
<td id="A5.T9.7.7.7.14.7.3" class="ltx_td ltx_align_center ltx_border_r">77.04</td>
<td id="A5.T9.7.7.7.14.7.4" class="ltx_td ltx_align_center">92.01</td>
<td id="A5.T9.7.7.7.14.7.5" class="ltx_td ltx_align_center ltx_border_r">58.20</td>
<td id="A5.T9.7.7.7.14.7.6" class="ltx_td ltx_align_center ltx_border_r">44.70</td>
<td id="A5.T9.7.7.7.14.7.7" class="ltx_td ltx_align_center ltx_border_r">31.50</td>
<td id="A5.T9.7.7.7.14.7.8" class="ltx_td ltx_align_center ltx_border_r">86.00</td>
<td id="A5.T9.7.7.7.14.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.14.7.9.1" class="ltx_text ltx_font_bold">58.30</span></td>
<td id="A5.T9.7.7.7.14.7.10" class="ltx_td ltx_align_center"><span id="A5.T9.7.7.7.14.7.10.1" class="ltx_text ltx_font_bold">17.40</span></td>
</tr>
<tr id="A5.T9.7.7.7.15.8" class="ltx_tr">
<td id="A5.T9.7.7.7.15.8.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="A5.T9.7.7.7.15.8.2" class="ltx_td ltx_align_center">63.96</td>
<td id="A5.T9.7.7.7.15.8.3" class="ltx_td ltx_align_center ltx_border_r">83.61</td>
<td id="A5.T9.7.7.7.15.8.4" class="ltx_td ltx_align_center">94.86</td>
<td id="A5.T9.7.7.7.15.8.5" class="ltx_td ltx_align_center ltx_border_r">66.29</td>
<td id="A5.T9.7.7.7.15.8.6" class="ltx_td ltx_align_center ltx_border_r">49.20</td>
<td id="A5.T9.7.7.7.15.8.7" class="ltx_td ltx_align_center ltx_border_r">22.10</td>
<td id="A5.T9.7.7.7.15.8.8" class="ltx_td ltx_align_center ltx_border_r">81.00</td>
<td id="A5.T9.7.7.7.15.8.9" class="ltx_td ltx_align_center ltx_border_r">1.10</td>
<td id="A5.T9.7.7.7.15.8.10" class="ltx_td ltx_align_center">29.99</td>
</tr>
<tr id="A5.T9.7.7.7.16.9" class="ltx_tr">
<td id="A5.T9.7.7.7.16.9.1" class="ltx_td ltx_align_left ltx_border_r">SpeechTokenizer</td>
<td id="A5.T9.7.7.7.16.9.2" class="ltx_td ltx_align_center">19.77</td>
<td id="A5.T9.7.7.7.16.9.3" class="ltx_td ltx_align_center ltx_border_r">43.12</td>
<td id="A5.T9.7.7.7.16.9.4" class="ltx_td ltx_align_center">76.67</td>
<td id="A5.T9.7.7.7.16.9.5" class="ltx_td ltx_align_center ltx_border_r">47.92</td>
<td id="A5.T9.7.7.7.16.9.6" class="ltx_td ltx_align_center ltx_border_r">49.10</td>
<td id="A5.T9.7.7.7.16.9.7" class="ltx_td ltx_align_center ltx_border_r">57.90</td>
<td id="A5.T9.7.7.7.16.9.8" class="ltx_td ltx_align_center ltx_border_r">95.09</td>
<td id="A5.T9.7.7.7.16.9.9" class="ltx_td ltx_align_center ltx_border_r">47.40</td>
<td id="A5.T9.7.7.7.16.9.10" class="ltx_td ltx_align_center">20.41</td>
</tr>
<tr id="A5.T9.7.7.7.17.10" class="ltx_tr">
<td id="A5.T9.7.7.7.17.10.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="A5.T9.7.7.7.17.10.1.1" class="ltx_text ltx_font_italic">Medium Bitrate</span></td>
</tr>
<tr id="A5.T9.7.7.7.18.11" class="ltx_tr">
<td id="A5.T9.7.7.7.18.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete Hubert</td>
<td id="A5.T9.7.7.7.18.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.18.11.2.1" class="ltx_text ltx_font_bold">7.91</span></td>
<td id="A5.T9.7.7.7.18.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.18.11.3.1" class="ltx_text ltx_font_bold">18.95</span></td>
<td id="A5.T9.7.7.7.18.11.4" class="ltx_td ltx_align_center ltx_border_t">54.77</td>
<td id="A5.T9.7.7.7.18.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">23.63</td>
<td id="A5.T9.7.7.7.18.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.18.11.6.1" class="ltx_text ltx_font_bold">62.10</span></td>
<td id="A5.T9.7.7.7.18.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.50</td>
<td id="A5.T9.7.7.7.18.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.69</td>
<td id="A5.T9.7.7.7.18.11.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67.40</td>
<td id="A5.T9.7.7.7.18.11.10" class="ltx_td ltx_align_center ltx_border_t">15.71</td>
</tr>
<tr id="A5.T9.7.7.7.19.12" class="ltx_tr">
<td id="A5.T9.7.7.7.19.12.1" class="ltx_td ltx_align_left ltx_border_r">Discrete WavLM</td>
<td id="A5.T9.7.7.7.19.12.2" class="ltx_td ltx_align_center">8.52</td>
<td id="A5.T9.7.7.7.19.12.3" class="ltx_td ltx_align_center ltx_border_r">20.35</td>
<td id="A5.T9.7.7.7.19.12.4" class="ltx_td ltx_align_center"><span id="A5.T9.7.7.7.19.12.4.1" class="ltx_text ltx_font_bold">54.22</span></td>
<td id="A5.T9.7.7.7.19.12.5" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.19.12.5.1" class="ltx_text ltx_font_bold">22.06</span></td>
<td id="A5.T9.7.7.7.19.12.6" class="ltx_td ltx_align_center ltx_border_r">57.60</td>
<td id="A5.T9.7.7.7.19.12.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.19.12.7.1" class="ltx_text ltx_font_bold">78.00</span></td>
<td id="A5.T9.7.7.7.19.12.8" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.19.12.8.1" class="ltx_text ltx_font_bold">98.09</span></td>
<td id="A5.T9.7.7.7.19.12.9" class="ltx_td ltx_align_center ltx_border_r">80.80</td>
<td id="A5.T9.7.7.7.19.12.10" class="ltx_td ltx_align_center">8.00</td>
</tr>
<tr id="A5.T9.7.7.7.20.13" class="ltx_tr">
<td id="A5.T9.7.7.7.20.13.1" class="ltx_td ltx_align_left ltx_border_r">Discrete Wav2Vec2</td>
<td id="A5.T9.7.7.7.20.13.2" class="ltx_td ltx_align_center">8.76</td>
<td id="A5.T9.7.7.7.20.13.3" class="ltx_td ltx_align_center ltx_border_r">21.32</td>
<td id="A5.T9.7.7.7.20.13.4" class="ltx_td ltx_align_center">60.39</td>
<td id="A5.T9.7.7.7.20.13.5" class="ltx_td ltx_align_center ltx_border_r">26.64</td>
<td id="A5.T9.7.7.7.20.13.6" class="ltx_td ltx_align_center ltx_border_r">59.10</td>
<td id="A5.T9.7.7.7.20.13.7" class="ltx_td ltx_align_center ltx_border_r">75.10</td>
<td id="A5.T9.7.7.7.20.13.8" class="ltx_td ltx_align_center ltx_border_r">96.64</td>
<td id="A5.T9.7.7.7.20.13.9" class="ltx_td ltx_align_center ltx_border_r">65.47</td>
<td id="A5.T9.7.7.7.20.13.10" class="ltx_td ltx_align_center">17.64</td>
</tr>
<tr id="A5.T9.7.7.7.21.14" class="ltx_tr">
<td id="A5.T9.7.7.7.21.14.1" class="ltx_td ltx_align_left ltx_border_r">EnCodec</td>
<td id="A5.T9.7.7.7.21.14.2" class="ltx_td ltx_align_center">46.80</td>
<td id="A5.T9.7.7.7.21.14.3" class="ltx_td ltx_align_center ltx_border_r">74.24</td>
<td id="A5.T9.7.7.7.21.14.4" class="ltx_td ltx_align_center">91.23</td>
<td id="A5.T9.7.7.7.21.14.5" class="ltx_td ltx_align_center ltx_border_r">47.95</td>
<td id="A5.T9.7.7.7.21.14.6" class="ltx_td ltx_align_center ltx_border_r">51.30</td>
<td id="A5.T9.7.7.7.21.14.7" class="ltx_td ltx_align_center ltx_border_r">31.40</td>
<td id="A5.T9.7.7.7.21.14.8" class="ltx_td ltx_align_center ltx_border_r">88.70</td>
<td id="A5.T9.7.7.7.21.14.9" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.21.14.9.1" class="ltx_text ltx_font_bold">91.90</span></td>
<td id="A5.T9.7.7.7.21.14.10" class="ltx_td ltx_align_center"><span id="A5.T9.7.7.7.21.14.10.1" class="ltx_text ltx_font_bold">7.81</span></td>
</tr>
<tr id="A5.T9.7.7.7.22.15" class="ltx_tr">
<td id="A5.T9.7.7.7.22.15.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="A5.T9.7.7.7.22.15.2" class="ltx_td ltx_align_center">59.54</td>
<td id="A5.T9.7.7.7.22.15.3" class="ltx_td ltx_align_center ltx_border_r">81.48</td>
<td id="A5.T9.7.7.7.22.15.4" class="ltx_td ltx_align_center">97.43</td>
<td id="A5.T9.7.7.7.22.15.5" class="ltx_td ltx_align_center ltx_border_r">56.16</td>
<td id="A5.T9.7.7.7.22.15.6" class="ltx_td ltx_align_center ltx_border_r">45.80</td>
<td id="A5.T9.7.7.7.22.15.7" class="ltx_td ltx_align_center ltx_border_r">18.90</td>
<td id="A5.T9.7.7.7.22.15.8" class="ltx_td ltx_align_center ltx_border_r">76.60</td>
<td id="A5.T9.7.7.7.22.15.9" class="ltx_td ltx_align_center ltx_border_r">83.80</td>
<td id="A5.T9.7.7.7.22.15.10" class="ltx_td ltx_align_center">11.78</td>
</tr>
<tr id="A5.T9.7.7.7.23.16" class="ltx_tr">
<td id="A5.T9.7.7.7.23.16.1" class="ltx_td ltx_align_left ltx_border_r">SpeechTokenizer</td>
<td id="A5.T9.7.7.7.23.16.2" class="ltx_td ltx_align_center">18.32</td>
<td id="A5.T9.7.7.7.23.16.3" class="ltx_td ltx_align_center ltx_border_r">41.21</td>
<td id="A5.T9.7.7.7.23.16.4" class="ltx_td ltx_align_center">75.17</td>
<td id="A5.T9.7.7.7.23.16.5" class="ltx_td ltx_align_center ltx_border_r">38.94</td>
<td id="A5.T9.7.7.7.23.16.6" class="ltx_td ltx_align_center ltx_border_r">52.10</td>
<td id="A5.T9.7.7.7.23.16.7" class="ltx_td ltx_align_center ltx_border_r">57.80</td>
<td id="A5.T9.7.7.7.23.16.8" class="ltx_td ltx_align_center ltx_border_r">94.86</td>
<td id="A5.T9.7.7.7.23.16.9" class="ltx_td ltx_align_center ltx_border_r">91.40</td>
<td id="A5.T9.7.7.7.23.16.10" class="ltx_td ltx_align_center">7.88</td>
</tr>
<tr id="A5.T9.7.7.7.24.17" class="ltx_tr">
<td id="A5.T9.7.7.7.24.17.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="A5.T9.7.7.7.24.17.1.1" class="ltx_text ltx_font_italic">High Bitrate</span></td>
</tr>
<tr id="A5.T9.7.7.7.25.18" class="ltx_tr">
<td id="A5.T9.7.7.7.25.18.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">EnCodec</td>
<td id="A5.T9.7.7.7.25.18.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.25.18.2.1" class="ltx_text ltx_font_bold">45.18</span></td>
<td id="A5.T9.7.7.7.25.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.25.18.3.1" class="ltx_text ltx_font_bold">72.56</span></td>
<td id="A5.T9.7.7.7.25.18.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.25.18.4.1" class="ltx_text ltx_font_bold">93.40</span></td>
<td id="A5.T9.7.7.7.25.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.25.18.5.1" class="ltx_text ltx_font_bold">87.65</span></td>
<td id="A5.T9.7.7.7.25.18.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.40</td>
<td id="A5.T9.7.7.7.25.18.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.25.18.7.1" class="ltx_text ltx_font_bold">19.60</span></td>
<td id="A5.T9.7.7.7.25.18.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.25.18.8.1" class="ltx_text ltx_font_bold">83.60</span></td>
<td id="A5.T9.7.7.7.25.18.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T9.7.7.7.25.18.9.1" class="ltx_text ltx_font_bold">92.81</span></td>
<td id="A5.T9.7.7.7.25.18.10" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T9.7.7.7.25.18.10.1" class="ltx_text ltx_font_bold">7.18</span></td>
</tr>
<tr id="A5.T9.7.7.7.26.19" class="ltx_tr">
<td id="A5.T9.7.7.7.26.19.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="A5.T9.7.7.7.26.19.2" class="ltx_td ltx_align_center">99.53</td>
<td id="A5.T9.7.7.7.26.19.3" class="ltx_td ltx_align_center ltx_border_r">99.38</td>
<td id="A5.T9.7.7.7.26.19.4" class="ltx_td ltx_align_center">99.40</td>
<td id="A5.T9.7.7.7.26.19.5" class="ltx_td ltx_align_center ltx_border_r">99.74</td>
<td id="A5.T9.7.7.7.26.19.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T9.7.7.7.26.19.6.1" class="ltx_text ltx_font_bold">46.00</span></td>
<td id="A5.T9.7.7.7.26.19.7" class="ltx_td ltx_align_center ltx_border_r">15.70</td>
<td id="A5.T9.7.7.7.26.19.8" class="ltx_td ltx_align_center ltx_border_r">75.20</td>
<td id="A5.T9.7.7.7.26.19.9" class="ltx_td ltx_align_center ltx_border_r">85.61</td>
<td id="A5.T9.7.7.7.26.19.10" class="ltx_td ltx_align_center">10.89</td>
</tr>
<tr id="A5.T9.7.7.7.27.20" class="ltx_tr">
<td id="A5.T9.7.7.7.27.20.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="A5.T9.7.7.7.27.20.1.1" class="ltx_text ltx_font_italic">Continuous Baseline</span></td>
</tr>
<tr id="A5.T9.7.7.7.28.21" class="ltx_tr">
<td id="A5.T9.7.7.7.28.21.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">SSL</td>
<td id="A5.T9.7.7.7.28.21.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.370</td>
<td id="A5.T9.7.7.7.28.21.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">7.04</td>
<td id="A5.T9.7.7.7.28.21.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">41.77</td>
<td id="A5.T9.7.7.7.28.21.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">14.32</td>
<td id="A5.T9.7.7.7.28.21.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">63.10</td>
<td id="A5.T9.7.7.7.28.21.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">86.10</td>
<td id="A5.T9.7.7.7.28.21.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">99.00</td>
<td id="A5.T9.7.7.7.28.21.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">99.70</td>
<td id="A5.T9.7.7.7.28.21.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">2.10</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
<figure id="A5.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Results for discriminative tasks with the second downstream architecture.</figcaption>
<div id="A5.T10.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:437.0pt;height:361.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="A5.T10.7.7" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:361.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.5pt,17.1pt) scale(0.913684425504245,0.913684425504245) ;">
<table id="A5.T10.7.7.7" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A5.T10.7.7.7.8.1" class="ltx_tr">
<td id="A5.T10.7.7.7.8.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="3"><span id="A5.T10.7.7.7.8.1.1.1" class="ltx_text ltx_font_bold">Models/Tasks</span></td>
<td id="A5.T10.7.7.7.8.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="A5.T10.7.7.7.8.1.2.1" class="ltx_text ltx_font_bold">ASR-En</span></td>
<td id="A5.T10.7.7.7.8.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="A5.T10.7.7.7.8.1.3.1" class="ltx_text ltx_font_bold">ASR-multiling</span></td>
<td id="A5.T10.7.7.7.8.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.8.1.4.1" class="ltx_text ltx_font_bold">ER</span></td>
<td id="A5.T10.7.7.7.8.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.8.1.5.1" class="ltx_text ltx_font_bold">IC</span></td>
<td id="A5.T10.7.7.7.8.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.8.1.6.1" class="ltx_text ltx_font_bold">KS</span></td>
<td id="A5.T10.7.7.7.8.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.8.1.7.1" class="ltx_text ltx_font_bold">SI</span></td>
<td id="A5.T10.7.7.7.8.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T10.7.7.7.8.1.8.1" class="ltx_text ltx_font_bold">SV</span></td>
</tr>
<tr id="A5.T10.7.7.7.7" class="ltx_tr">
<td id="A5.T10.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">
<span id="A5.T10.1.1.1.1.1.1" class="ltx_text ltx_font_bold">WER</span> <math id="A5.T10.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T10.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A5.T10.1.1.1.1.1.m1.1.1" xref="A5.T10.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T10.1.1.1.1.1.m1.1b"><ci id="A5.T10.1.1.1.1.1.m1.1.1.cmml" xref="A5.T10.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A5.T10.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">
<span id="A5.T10.2.2.2.2.2.1" class="ltx_text ltx_font_bold">WER</span> <math id="A5.T10.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T10.2.2.2.2.2.m1.1a"><mo stretchy="false" id="A5.T10.2.2.2.2.2.m1.1.1" xref="A5.T10.2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T10.2.2.2.2.2.m1.1b"><ci id="A5.T10.2.2.2.2.2.m1.1.1.cmml" xref="A5.T10.2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A5.T10.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T10.3.3.3.3.3.1" class="ltx_text"><span id="A5.T10.3.3.3.3.3.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="A5.T10.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T10.3.3.3.3.3.1.m1.1a"><mo stretchy="false" id="A5.T10.3.3.3.3.3.1.m1.1.1" xref="A5.T10.3.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T10.3.3.3.3.3.1.m1.1b"><ci id="A5.T10.3.3.3.3.3.1.m1.1.1.cmml" xref="A5.T10.3.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.3.3.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="A5.T10.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T10.4.4.4.4.4.1" class="ltx_text"><span id="A5.T10.4.4.4.4.4.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="A5.T10.4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T10.4.4.4.4.4.1.m1.1a"><mo stretchy="false" id="A5.T10.4.4.4.4.4.1.m1.1.1" xref="A5.T10.4.4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T10.4.4.4.4.4.1.m1.1b"><ci id="A5.T10.4.4.4.4.4.1.m1.1.1.cmml" xref="A5.T10.4.4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.4.4.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="A5.T10.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T10.5.5.5.5.5.1" class="ltx_text"><span id="A5.T10.5.5.5.5.5.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="A5.T10.5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T10.5.5.5.5.5.1.m1.1a"><mo stretchy="false" id="A5.T10.5.5.5.5.5.1.m1.1.1" xref="A5.T10.5.5.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T10.5.5.5.5.5.1.m1.1b"><ci id="A5.T10.5.5.5.5.5.1.m1.1.1.cmml" xref="A5.T10.5.5.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.5.5.5.5.5.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="A5.T10.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T10.6.6.6.6.6.1" class="ltx_text"><span id="A5.T10.6.6.6.6.6.1.1" class="ltx_text ltx_font_bold">ACC</span> <math id="A5.T10.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T10.6.6.6.6.6.1.m1.1a"><mo stretchy="false" id="A5.T10.6.6.6.6.6.1.m1.1.1" xref="A5.T10.6.6.6.6.6.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T10.6.6.6.6.6.1.m1.1b"><ci id="A5.T10.6.6.6.6.6.1.m1.1.1.cmml" xref="A5.T10.6.6.6.6.6.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.6.6.6.6.6.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="A5.T10.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="A5.T10.7.7.7.7.7.1" class="ltx_text"><span id="A5.T10.7.7.7.7.7.1.1" class="ltx_text ltx_font_bold">EER</span> <math id="A5.T10.7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T10.7.7.7.7.7.1.m1.1a"><mo stretchy="false" id="A5.T10.7.7.7.7.7.1.m1.1.1" xref="A5.T10.7.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T10.7.7.7.7.7.1.m1.1b"><ci id="A5.T10.7.7.7.7.7.1.m1.1.1.cmml" xref="A5.T10.7.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.7.7.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="A5.T10.7.7.7.9.2" class="ltx_tr">
<td id="A5.T10.7.7.7.9.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T10.7.7.7.9.2.1.1" class="ltx_text ltx_font_bold">Clean</span></td>
<td id="A5.T10.7.7.7.9.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.9.2.2.1" class="ltx_text ltx_font_bold">Other</span></td>
<td id="A5.T10.7.7.7.9.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T10.7.7.7.9.2.3.1" class="ltx_text ltx_font_bold">Welsh</span></td>
<td id="A5.T10.7.7.7.9.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.9.2.4.1" class="ltx_text ltx_font_bold">Basque</span></td>
</tr>
<tr id="A5.T10.7.7.7.10.3" class="ltx_tr">
<td id="A5.T10.7.7.7.10.3.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="A5.T10.7.7.7.10.3.1.1" class="ltx_text ltx_font_italic">Low Bitrate</span></td>
</tr>
<tr id="A5.T10.7.7.7.11.4" class="ltx_tr">
<td id="A5.T10.7.7.7.11.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete Hubert</td>
<td id="A5.T10.7.7.7.11.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T10.7.7.7.11.4.2.1" class="ltx_text ltx_font_bold">11.99</span></td>
<td id="A5.T10.7.7.7.11.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.11.4.3.1" class="ltx_text ltx_font_bold">23.45</span></td>
<td id="A5.T10.7.7.7.11.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T10.7.7.7.11.4.4.1" class="ltx_text ltx_font_bold">97.30</span></td>
<td id="A5.T10.7.7.7.11.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.11.4.5.1" class="ltx_text ltx_font_bold">99.20</span></td>
<td id="A5.T10.7.7.7.11.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.11.4.6.1" class="ltx_text ltx_font_bold">61.40</span></td>
<td id="A5.T10.7.7.7.11.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.80</td>
<td id="A5.T10.7.7.7.11.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.54</td>
<td id="A5.T10.7.7.7.11.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.60</td>
<td id="A5.T10.7.7.7.11.4.10" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T10.7.7.7.11.4.10.1" class="ltx_text ltx_font_bold">18.34</span></td>
</tr>
<tr id="A5.T10.7.7.7.12.5" class="ltx_tr">
<td id="A5.T10.7.7.7.12.5.1" class="ltx_td ltx_align_left ltx_border_r">Discrete WavLM</td>
<td id="A5.T10.7.7.7.12.5.2" class="ltx_td ltx_align_center">14.98</td>
<td id="A5.T10.7.7.7.12.5.3" class="ltx_td ltx_align_center ltx_border_r">30.32</td>
<td id="A5.T10.7.7.7.12.5.4" class="ltx_td ltx_align_center">100.00</td>
<td id="A5.T10.7.7.7.12.5.5" class="ltx_td ltx_align_center ltx_border_r">99.29</td>
<td id="A5.T10.7.7.7.12.5.6" class="ltx_td ltx_align_center ltx_border_r">61.20</td>
<td id="A5.T10.7.7.7.12.5.7" class="ltx_td ltx_align_center ltx_border_r">57.70</td>
<td id="A5.T10.7.7.7.12.5.8" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.12.5.8.1" class="ltx_text ltx_font_bold">97.80</span></td>
<td id="A5.T10.7.7.7.12.5.9" class="ltx_td ltx_align_center ltx_border_r">14.00</td>
<td id="A5.T10.7.7.7.12.5.10" class="ltx_td ltx_align_center">18.45</td>
</tr>
<tr id="A5.T10.7.7.7.13.6" class="ltx_tr">
<td id="A5.T10.7.7.7.13.6.1" class="ltx_td ltx_align_left ltx_border_r">Discrete Wav2Vec2</td>
<td id="A5.T10.7.7.7.13.6.2" class="ltx_td ltx_align_center">15.45</td>
<td id="A5.T10.7.7.7.13.6.3" class="ltx_td ltx_align_center ltx_border_r">35.30</td>
<td id="A5.T10.7.7.7.13.6.4" class="ltx_td ltx_align_center">99.89</td>
<td id="A5.T10.7.7.7.13.6.5" class="ltx_td ltx_align_center ltx_border_r">98.39</td>
<td id="A5.T10.7.7.7.13.6.6" class="ltx_td ltx_align_center ltx_border_r">59.50</td>
<td id="A5.T10.7.7.7.13.6.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.13.6.7.1" class="ltx_text ltx_font_bold">60.20</span></td>
<td id="A5.T10.7.7.7.13.6.8" class="ltx_td ltx_align_center ltx_border_r">96.52</td>
<td id="A5.T10.7.7.7.13.6.9" class="ltx_td ltx_align_center ltx_border_r">5.80</td>
<td id="A5.T10.7.7.7.13.6.10" class="ltx_td ltx_align_center">23.5830</td>
</tr>
<tr id="A5.T10.7.7.7.14.7" class="ltx_tr">
<td id="A5.T10.7.7.7.14.7.1" class="ltx_td ltx_align_left ltx_border_r">EnCodec</td>
<td id="A5.T10.7.7.7.14.7.2" class="ltx_td ltx_align_center">90.84</td>
<td id="A5.T10.7.7.7.14.7.3" class="ltx_td ltx_align_center ltx_border_r">94.97</td>
<td id="A5.T10.7.7.7.14.7.4" class="ltx_td ltx_align_center">99.88</td>
<td id="A5.T10.7.7.7.14.7.5" class="ltx_td ltx_align_center ltx_border_r">100.00</td>
<td id="A5.T10.7.7.7.14.7.6" class="ltx_td ltx_align_center ltx_border_r">40.20</td>
<td id="A5.T10.7.7.7.14.7.7" class="ltx_td ltx_align_center ltx_border_r">18.40</td>
<td id="A5.T10.7.7.7.14.7.8" class="ltx_td ltx_align_center ltx_border_r">88.50</td>
<td id="A5.T10.7.7.7.14.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.14.7.9.1" class="ltx_text ltx_font_bold">34.70</span></td>
<td id="A5.T10.7.7.7.14.7.10" class="ltx_td ltx_align_center">23.08</td>
</tr>
<tr id="A5.T10.7.7.7.15.8" class="ltx_tr">
<td id="A5.T10.7.7.7.15.8.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="A5.T10.7.7.7.15.8.2" class="ltx_td ltx_align_center">125.00</td>
<td id="A5.T10.7.7.7.15.8.3" class="ltx_td ltx_align_center ltx_border_r">119.00</td>
<td id="A5.T10.7.7.7.15.8.4" class="ltx_td ltx_align_center">100.00</td>
<td id="A5.T10.7.7.7.15.8.5" class="ltx_td ltx_align_center ltx_border_r">100.00</td>
<td id="A5.T10.7.7.7.15.8.6" class="ltx_td ltx_align_center ltx_border_r">47.20</td>
<td id="A5.T10.7.7.7.15.8.7" class="ltx_td ltx_align_center ltx_border_r">17.70</td>
<td id="A5.T10.7.7.7.15.8.8" class="ltx_td ltx_align_center ltx_border_r">83.90</td>
<td id="A5.T10.7.7.7.15.8.9" class="ltx_td ltx_align_center ltx_border_r">21.50</td>
<td id="A5.T10.7.7.7.15.8.10" class="ltx_td ltx_align_center">27.92</td>
</tr>
<tr id="A5.T10.7.7.7.16.9" class="ltx_tr">
<td id="A5.T10.7.7.7.16.9.1" class="ltx_td ltx_align_left ltx_border_r">SpeechTokenizer</td>
<td id="A5.T10.7.7.7.16.9.2" class="ltx_td ltx_align_center">26.50</td>
<td id="A5.T10.7.7.7.16.9.3" class="ltx_td ltx_align_center ltx_border_r">47.91</td>
<td id="A5.T10.7.7.7.16.9.4" class="ltx_td ltx_align_center">100.00</td>
<td id="A5.T10.7.7.7.16.9.5" class="ltx_td ltx_align_center ltx_border_r">99.11</td>
<td id="A5.T10.7.7.7.16.9.6" class="ltx_td ltx_align_center ltx_border_r">50.40</td>
<td id="A5.T10.7.7.7.16.9.7" class="ltx_td ltx_align_center ltx_border_r">49.10</td>
<td id="A5.T10.7.7.7.16.9.8" class="ltx_td ltx_align_center ltx_border_r">94.55</td>
<td id="A5.T10.7.7.7.16.9.9" class="ltx_td ltx_align_center ltx_border_r">24.50</td>
<td id="A5.T10.7.7.7.16.9.10" class="ltx_td ltx_align_center">25.92</td>
</tr>
<tr id="A5.T10.7.7.7.17.10" class="ltx_tr">
<td id="A5.T10.7.7.7.17.10.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="A5.T10.7.7.7.17.10.1.1" class="ltx_text ltx_font_italic">Medium Bitrate</span></td>
</tr>
<tr id="A5.T10.7.7.7.18.11" class="ltx_tr">
<td id="A5.T10.7.7.7.18.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Discrete Hubert</td>
<td id="A5.T10.7.7.7.18.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T10.7.7.7.18.11.2.1" class="ltx_text ltx_font_bold">10.91</span></td>
<td id="A5.T10.7.7.7.18.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.18.11.3.1" class="ltx_text ltx_font_bold">21.65</span></td>
<td id="A5.T10.7.7.7.18.11.4" class="ltx_td ltx_align_center ltx_border_t">95.81</td>
<td id="A5.T10.7.7.7.18.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.20</td>
<td id="A5.T10.7.7.7.18.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.18.11.6.1" class="ltx_text ltx_font_bold">64.80</span></td>
<td id="A5.T10.7.7.7.18.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.10</td>
<td id="A5.T10.7.7.7.18.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94.38</td>
<td id="A5.T10.7.7.7.18.11.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14.80</td>
<td id="A5.T10.7.7.7.18.11.10" class="ltx_td ltx_align_center ltx_border_t">17.67</td>
</tr>
<tr id="A5.T10.7.7.7.19.12" class="ltx_tr">
<td id="A5.T10.7.7.7.19.12.1" class="ltx_td ltx_align_left ltx_border_r">Discrete WavLM</td>
<td id="A5.T10.7.7.7.19.12.2" class="ltx_td ltx_align_center">11.12</td>
<td id="A5.T10.7.7.7.19.12.3" class="ltx_td ltx_align_center ltx_border_r">22.63</td>
<td id="A5.T10.7.7.7.19.12.4" class="ltx_td ltx_align_center">96.51</td>
<td id="A5.T10.7.7.7.19.12.5" class="ltx_td ltx_align_center ltx_border_r">97.38</td>
<td id="A5.T10.7.7.7.19.12.6" class="ltx_td ltx_align_center ltx_border_r">60.60</td>
<td id="A5.T10.7.7.7.19.12.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.19.12.7.1" class="ltx_text ltx_font_bold">63.80</span></td>
<td id="A5.T10.7.7.7.19.12.8" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.19.12.8.1" class="ltx_text ltx_font_bold">97.85</span></td>
<td id="A5.T10.7.7.7.19.12.9" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.19.12.9.1" class="ltx_text ltx_font_bold">25.60</span></td>
<td id="A5.T10.7.7.7.19.12.10" class="ltx_td ltx_align_center"><span id="A5.T10.7.7.7.19.12.10.1" class="ltx_text ltx_font_bold">15.74</span></td>
</tr>
<tr id="A5.T10.7.7.7.20.13" class="ltx_tr">
<td id="A5.T10.7.7.7.20.13.1" class="ltx_td ltx_align_left ltx_border_r">Discrete Wav2Vec2</td>
<td id="A5.T10.7.7.7.20.13.2" class="ltx_td ltx_align_center">12.48</td>
<td id="A5.T10.7.7.7.20.13.3" class="ltx_td ltx_align_center ltx_border_r">25.40</td>
<td id="A5.T10.7.7.7.20.13.4" class="ltx_td ltx_align_center"><span id="A5.T10.7.7.7.20.13.4.1" class="ltx_text ltx_font_bold">94.34</span></td>
<td id="A5.T10.7.7.7.20.13.5" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.20.13.5.1" class="ltx_text ltx_font_bold">95.76</span></td>
<td id="A5.T10.7.7.7.20.13.6" class="ltx_td ltx_align_center ltx_border_r">61.90</td>
<td id="A5.T10.7.7.7.20.13.7" class="ltx_td ltx_align_center ltx_border_r">63.00</td>
<td id="A5.T10.7.7.7.20.13.8" class="ltx_td ltx_align_center ltx_border_r">96.92</td>
<td id="A5.T10.7.7.7.20.13.9" class="ltx_td ltx_align_center ltx_border_r">11.70</td>
<td id="A5.T10.7.7.7.20.13.10" class="ltx_td ltx_align_center">19.07</td>
</tr>
<tr id="A5.T10.7.7.7.21.14" class="ltx_tr">
<td id="A5.T10.7.7.7.21.14.1" class="ltx_td ltx_align_left ltx_border_r">EnCodec</td>
<td id="A5.T10.7.7.7.21.14.2" class="ltx_td ltx_align_center">124.00</td>
<td id="A5.T10.7.7.7.21.14.3" class="ltx_td ltx_align_center ltx_border_r">119.00</td>
<td id="A5.T10.7.7.7.21.14.4" class="ltx_td ltx_align_center">99.82</td>
<td id="A5.T10.7.7.7.21.14.5" class="ltx_td ltx_align_center ltx_border_r">99.98</td>
<td id="A5.T10.7.7.7.21.14.6" class="ltx_td ltx_align_center ltx_border_r">41.50</td>
<td id="A5.T10.7.7.7.21.14.7" class="ltx_td ltx_align_center ltx_border_r">18.20</td>
<td id="A5.T10.7.7.7.21.14.8" class="ltx_td ltx_align_center ltx_border_r">89.10</td>
<td id="A5.T10.7.7.7.21.14.9" class="ltx_td ltx_align_center ltx_border_r">30.10</td>
<td id="A5.T10.7.7.7.21.14.10" class="ltx_td ltx_align_center">21.73</td>
</tr>
<tr id="A5.T10.7.7.7.22.15" class="ltx_tr">
<td id="A5.T10.7.7.7.22.15.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="A5.T10.7.7.7.22.15.2" class="ltx_td ltx_align_center">124.00</td>
<td id="A5.T10.7.7.7.22.15.3" class="ltx_td ltx_align_center ltx_border_r">122.00</td>
<td id="A5.T10.7.7.7.22.15.4" class="ltx_td ltx_align_center">99.96</td>
<td id="A5.T10.7.7.7.22.15.5" class="ltx_td ltx_align_center ltx_border_r">100.00</td>
<td id="A5.T10.7.7.7.22.15.6" class="ltx_td ltx_align_center ltx_border_r">46.80</td>
<td id="A5.T10.7.7.7.22.15.7" class="ltx_td ltx_align_center ltx_border_r">16.40</td>
<td id="A5.T10.7.7.7.22.15.8" class="ltx_td ltx_align_center ltx_border_r">80.30</td>
<td id="A5.T10.7.7.7.22.15.9" class="ltx_td ltx_align_center ltx_border_r">15.90</td>
<td id="A5.T10.7.7.7.22.15.10" class="ltx_td ltx_align_center">29.75</td>
</tr>
<tr id="A5.T10.7.7.7.23.16" class="ltx_tr">
<td id="A5.T10.7.7.7.23.16.1" class="ltx_td ltx_align_left ltx_border_r">SpeechTokenizer</td>
<td id="A5.T10.7.7.7.23.16.2" class="ltx_td ltx_align_center">118.00</td>
<td id="A5.T10.7.7.7.23.16.3" class="ltx_td ltx_align_center ltx_border_r">117.00</td>
<td id="A5.T10.7.7.7.23.16.4" class="ltx_td ltx_align_center">97.08</td>
<td id="A5.T10.7.7.7.23.16.5" class="ltx_td ltx_align_center ltx_border_r">96.49</td>
<td id="A5.T10.7.7.7.23.16.6" class="ltx_td ltx_align_center ltx_border_r">56.60</td>
<td id="A5.T10.7.7.7.23.16.7" class="ltx_td ltx_align_center ltx_border_r">47.60</td>
<td id="A5.T10.7.7.7.23.16.8" class="ltx_td ltx_align_center ltx_border_r">89.10</td>
<td id="A5.T10.7.7.7.23.16.9" class="ltx_td ltx_align_center ltx_border_r">32.80</td>
<td id="A5.T10.7.7.7.23.16.10" class="ltx_td ltx_align_center">20.15</td>
</tr>
<tr id="A5.T10.7.7.7.24.17" class="ltx_tr">
<td id="A5.T10.7.7.7.24.17.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="A5.T10.7.7.7.24.17.1.1" class="ltx_text ltx_font_italic">High Bitrate</span></td>
</tr>
<tr id="A5.T10.7.7.7.25.18" class="ltx_tr">
<td id="A5.T10.7.7.7.25.18.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">EnCodec</td>
<td id="A5.T10.7.7.7.25.18.2" class="ltx_td ltx_align_center ltx_border_t">124.00</td>
<td id="A5.T10.7.7.7.25.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.25.18.3.1" class="ltx_text ltx_font_bold">122.00</span></td>
<td id="A5.T10.7.7.7.25.18.4" class="ltx_td ltx_align_center ltx_border_t">100.00</td>
<td id="A5.T10.7.7.7.25.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.25.18.5.1" class="ltx_text ltx_font_bold">99.93</span></td>
<td id="A5.T10.7.7.7.25.18.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.40</td>
<td id="A5.T10.7.7.7.25.18.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.25.18.7.1" class="ltx_text ltx_font_bold">17.10</span></td>
<td id="A5.T10.7.7.7.25.18.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.25.18.8.1" class="ltx_text ltx_font_bold">80.40</span></td>
<td id="A5.T10.7.7.7.25.18.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T10.7.7.7.25.18.9.1" class="ltx_text ltx_font_bold">23.40</span></td>
<td id="A5.T10.7.7.7.25.18.10" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T10.7.7.7.25.18.10.1" class="ltx_text ltx_font_bold">25.52</span></td>
</tr>
<tr id="A5.T10.7.7.7.26.19" class="ltx_tr">
<td id="A5.T10.7.7.7.26.19.1" class="ltx_td ltx_align_left ltx_border_r">DAC</td>
<td id="A5.T10.7.7.7.26.19.2" class="ltx_td ltx_align_center"><span id="A5.T10.7.7.7.26.19.2.1" class="ltx_text ltx_font_bold">122.00</span></td>
<td id="A5.T10.7.7.7.26.19.3" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.26.19.3.1" class="ltx_text ltx_font_bold">122.00</span></td>
<td id="A5.T10.7.7.7.26.19.4" class="ltx_td ltx_align_center"><span id="A5.T10.7.7.7.26.19.4.1" class="ltx_text ltx_font_bold">99.74</span></td>
<td id="A5.T10.7.7.7.26.19.5" class="ltx_td ltx_align_center ltx_border_r">100.00</td>
<td id="A5.T10.7.7.7.26.19.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T10.7.7.7.26.19.6.1" class="ltx_text ltx_font_bold">47.70</span></td>
<td id="A5.T10.7.7.7.26.19.7" class="ltx_td ltx_align_center ltx_border_r">15.40</td>
<td id="A5.T10.7.7.7.26.19.8" class="ltx_td ltx_align_center ltx_border_r">76.00</td>
<td id="A5.T10.7.7.7.26.19.9" class="ltx_td ltx_align_center ltx_border_r">16.40</td>
<td id="A5.T10.7.7.7.26.19.10" class="ltx_td ltx_align_center">29.94</td>
</tr>
<tr id="A5.T10.7.7.7.27.20" class="ltx_tr">
<td id="A5.T10.7.7.7.27.20.1" class="ltx_td ltx_align_center ltx_border_t" colspan="10"><span id="A5.T10.7.7.7.27.20.1.1" class="ltx_text ltx_font_italic">Continuous Baseline</span></td>
</tr>
<tr id="A5.T10.7.7.7.28.21" class="ltx_tr">
<td id="A5.T10.7.7.7.28.21.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">SSL</td>
<td id="A5.T10.7.7.7.28.21.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">10.05</td>
<td id="A5.T10.7.7.7.28.21.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">13.80</td>
<td id="A5.T10.7.7.7.28.21.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">68.72</td>
<td id="A5.T10.7.7.7.28.21.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">48.60</td>
<td id="A5.T10.7.7.7.28.21.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">68.60</td>
<td id="A5.T10.7.7.7.28.21.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">75.20</td>
<td id="A5.T10.7.7.7.28.21.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">98.70</td>
<td id="A5.T10.7.7.7.28.21.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">88.40</td>
<td id="A5.T10.7.7.7.28.21.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.31</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A5.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Results for generative tasks with the first downstream architecture. N.C. indicates “Not Converged".</figcaption>
<div id="A5.T11.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:393.6pt;height:272.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="A5.T11.8.8" class="ltx_inline-block ltx_transformed_outer" style="width:390.3pt;height:272.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-75.7pt,52.8pt) scale(0.720618037423838,0.720618037423838) ;">
<table id="A5.T11.8.8.8" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A5.T11.8.8.8.9.1" class="ltx_tr">
<th id="A5.T11.8.8.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T11.8.8.8.9.1.1.1" class="ltx_text ltx_font_bold">Models/Tasks</span></th>
<td id="A5.T11.8.8.8.9.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="A5.T11.8.8.8.9.1.2.1" class="ltx_text ltx_font_bold">SE</span></td>
<td id="A5.T11.8.8.8.9.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="A5.T11.8.8.8.9.1.3.1" class="ltx_text ltx_font_bold">SS</span></td>
<td id="A5.T11.8.8.8.9.1.4" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="A5.T11.8.8.8.9.1.4.1" class="ltx_text ltx_font_bold">TTS</span></td>
</tr>
<tr id="A5.T11.8.8.8.8" class="ltx_tr">
<td id="A5.T11.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T11.1.1.1.1.1.1" class="ltx_text ltx_font_bold">DNSMOS</span> <math id="A5.T11.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T11.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A5.T11.1.1.1.1.1.m1.1.1" xref="A5.T11.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T11.1.1.1.1.1.m1.1b"><ci id="A5.T11.1.1.1.1.1.m1.1.1.cmml" xref="A5.T11.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T11.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T11.2.2.2.2.2.1" class="ltx_text ltx_font_bold">dWER</span> <math id="A5.T11.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T11.2.2.2.2.2.m1.1a"><mo stretchy="false" id="A5.T11.2.2.2.2.2.m1.1.1" xref="A5.T11.2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T11.2.2.2.2.2.m1.1b"><ci id="A5.T11.2.2.2.2.2.m1.1.1.cmml" xref="A5.T11.2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A5.T11.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A5.T11.3.3.3.3.3.1" class="ltx_text ltx_font_bold">SpkSim</span> <math id="A5.T11.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T11.3.3.3.3.3.m1.1a"><mo stretchy="false" id="A5.T11.3.3.3.3.3.m1.1.1" xref="A5.T11.3.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T11.3.3.3.3.3.m1.1b"><ci id="A5.T11.3.3.3.3.3.m1.1.1.cmml" xref="A5.T11.3.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.3.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T11.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T11.4.4.4.4.4.1" class="ltx_text ltx_font_bold">DNSMOS</span> <math id="A5.T11.4.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T11.4.4.4.4.4.m1.1a"><mo stretchy="false" id="A5.T11.4.4.4.4.4.m1.1.1" xref="A5.T11.4.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T11.4.4.4.4.4.m1.1b"><ci id="A5.T11.4.4.4.4.4.m1.1.1.cmml" xref="A5.T11.4.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.4.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T11.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T11.5.5.5.5.5.1" class="ltx_text ltx_font_bold">dWER</span> <math id="A5.T11.5.5.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T11.5.5.5.5.5.m1.1a"><mo stretchy="false" id="A5.T11.5.5.5.5.5.m1.1.1" xref="A5.T11.5.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T11.5.5.5.5.5.m1.1b"><ci id="A5.T11.5.5.5.5.5.m1.1.1.cmml" xref="A5.T11.5.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.5.5.5.5.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A5.T11.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A5.T11.6.6.6.6.6.1" class="ltx_text ltx_font_bold">SpkSim</span> <math id="A5.T11.6.6.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T11.6.6.6.6.6.m1.1a"><mo stretchy="false" id="A5.T11.6.6.6.6.6.m1.1.1" xref="A5.T11.6.6.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T11.6.6.6.6.6.m1.1b"><ci id="A5.T11.6.6.6.6.6.m1.1.1.cmml" xref="A5.T11.6.6.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.6.6.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T11.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T11.7.7.7.7.7.1" class="ltx_text ltx_font_bold">UTMOS</span> <math id="A5.T11.7.7.7.7.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T11.7.7.7.7.7.m1.1a"><mo stretchy="false" id="A5.T11.7.7.7.7.7.m1.1.1" xref="A5.T11.7.7.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T11.7.7.7.7.7.m1.1b"><ci id="A5.T11.7.7.7.7.7.m1.1.1.cmml" xref="A5.T11.7.7.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.7.7.7.7.7.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T11.8.8.8.8.8" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T11.8.8.8.8.8.1" class="ltx_text ltx_font_bold">dWER</span> <math id="A5.T11.8.8.8.8.8.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T11.8.8.8.8.8.m1.1a"><mo stretchy="false" id="A5.T11.8.8.8.8.8.m1.1.1" xref="A5.T11.8.8.8.8.8.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T11.8.8.8.8.8.m1.1b"><ci id="A5.T11.8.8.8.8.8.m1.1.1.cmml" xref="A5.T11.8.8.8.8.8.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.8.8.8.8.8.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="A5.T11.8.8.8.10.2" class="ltx_tr">
<th id="A5.T11.8.8.8.10.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="A5.T11.8.8.8.10.2.1.1" class="ltx_text ltx_font_italic">Low Bitrate</span></th>
</tr>
<tr id="A5.T11.8.8.8.11.3" class="ltx_tr">
<th id="A5.T11.8.8.8.11.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete Hubert</th>
<td id="A5.T11.8.8.8.11.3.2" class="ltx_td ltx_align_center ltx_border_t">3.33</td>
<td id="A5.T11.8.8.8.11.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T11.8.8.8.11.3.3.1" class="ltx_text ltx_font_bold">15.47</span></td>
<td id="A5.T11.8.8.8.11.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.824</td>
<td id="A5.T11.8.8.8.11.3.5" class="ltx_td ltx_align_center ltx_border_t">3.52</td>
<td id="A5.T11.8.8.8.11.3.6" class="ltx_td ltx_align_center ltx_border_t">80.86</td>
<td id="A5.T11.8.8.8.11.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.840</td>
<td id="A5.T11.8.8.8.11.3.8" class="ltx_td ltx_align_center ltx_border_t">3.25</td>
<td id="A5.T11.8.8.8.11.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T11.8.8.8.11.3.9.1" class="ltx_text ltx_font_bold">2.93</span></td>
</tr>
<tr id="A5.T11.8.8.8.12.4" class="ltx_tr">
<th id="A5.T11.8.8.8.12.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="A5.T11.8.8.8.12.4.2" class="ltx_td ltx_align_center">3.26</td>
<td id="A5.T11.8.8.8.12.4.3" class="ltx_td ltx_align_center">16.52</td>
<td id="A5.T11.8.8.8.12.4.4" class="ltx_td ltx_align_center ltx_border_r">0.830</td>
<td id="A5.T11.8.8.8.12.4.5" class="ltx_td ltx_align_center">3.43</td>
<td id="A5.T11.8.8.8.12.4.6" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.12.4.6.1" class="ltx_text ltx_font_bold">62.34</span></td>
<td id="A5.T11.8.8.8.12.4.7" class="ltx_td ltx_align_center ltx_border_r">0.847</td>
<td id="A5.T11.8.8.8.12.4.8" class="ltx_td ltx_align_center">2.74</td>
<td id="A5.T11.8.8.8.12.4.9" class="ltx_td ltx_align_center">12.69</td>
</tr>
<tr id="A5.T11.8.8.8.13.5" class="ltx_tr">
<th id="A5.T11.8.8.8.13.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="A5.T11.8.8.8.13.5.2" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.13.5.2.1" class="ltx_text ltx_font_bold">3.55</span></td>
<td id="A5.T11.8.8.8.13.5.3" class="ltx_td ltx_align_center">18.86</td>
<td id="A5.T11.8.8.8.13.5.4" class="ltx_td ltx_align_center ltx_border_r">0.779</td>
<td id="A5.T11.8.8.8.13.5.5" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.13.5.5.1" class="ltx_text ltx_font_bold">3.75</span></td>
<td id="A5.T11.8.8.8.13.5.6" class="ltx_td ltx_align_center">96.70</td>
<td id="A5.T11.8.8.8.13.5.7" class="ltx_td ltx_align_center ltx_border_r">0.787</td>
<td id="A5.T11.8.8.8.13.5.8" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.13.5.8.1" class="ltx_text ltx_font_bold">3.32</span></td>
<td id="A5.T11.8.8.8.13.5.9" class="ltx_td ltx_align_center">3.45</td>
</tr>
<tr id="A5.T11.8.8.8.14.6" class="ltx_tr">
<th id="A5.T11.8.8.8.14.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="A5.T11.8.8.8.14.6.2" class="ltx_td ltx_align_center">3.15</td>
<td id="A5.T11.8.8.8.14.6.3" class="ltx_td ltx_align_center">34.35</td>
<td id="A5.T11.8.8.8.14.6.4" class="ltx_td ltx_align_center ltx_border_r">0.852</td>
<td id="A5.T11.8.8.8.14.6.5" class="ltx_td ltx_align_center">3.11</td>
<td id="A5.T11.8.8.8.14.6.6" class="ltx_td ltx_align_center">83.55</td>
<td id="A5.T11.8.8.8.14.6.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T11.8.8.8.14.6.7.1" class="ltx_text ltx_font_bold">0.877</span></td>
<td id="A5.T11.8.8.8.14.6.8" class="ltx_td ltx_align_center">1.46</td>
<td id="A5.T11.8.8.8.14.6.9" class="ltx_td ltx_align_center">8.84</td>
</tr>
<tr id="A5.T11.8.8.8.15.7" class="ltx_tr">
<th id="A5.T11.8.8.8.15.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="A5.T11.8.8.8.15.7.2" class="ltx_td ltx_align_center">3.30</td>
<td id="A5.T11.8.8.8.15.7.3" class="ltx_td ltx_align_center">57.41</td>
<td id="A5.T11.8.8.8.15.7.4" class="ltx_td ltx_align_center ltx_border_r">0.853</td>
<td id="A5.T11.8.8.8.15.7.5" class="ltx_td ltx_align_center">3.01</td>
<td id="A5.T11.8.8.8.15.7.6" class="ltx_td ltx_align_center">102.00</td>
<td id="A5.T11.8.8.8.15.7.7" class="ltx_td ltx_align_center ltx_border_r">0.854</td>
<td id="A5.T11.8.8.8.15.7.8" class="ltx_td ltx_align_center">1.97</td>
<td id="A5.T11.8.8.8.15.7.9" class="ltx_td ltx_align_center">10.66</td>
</tr>
<tr id="A5.T11.8.8.8.16.8" class="ltx_tr">
<th id="A5.T11.8.8.8.16.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="A5.T11.8.8.8.16.8.2" class="ltx_td ltx_align_center">3.18</td>
<td id="A5.T11.8.8.8.16.8.3" class="ltx_td ltx_align_center">30.13</td>
<td id="A5.T11.8.8.8.16.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T11.8.8.8.16.8.4.1" class="ltx_text ltx_font_bold">0.858</span></td>
<td id="A5.T11.8.8.8.16.8.5" class="ltx_td ltx_align_center">3.13</td>
<td id="A5.T11.8.8.8.16.8.6" class="ltx_td ltx_align_center">85.25</td>
<td id="A5.T11.8.8.8.16.8.7" class="ltx_td ltx_align_center ltx_border_r">0.874</td>
<td id="A5.T11.8.8.8.16.8.8" class="ltx_td ltx_align_center">2.55</td>
<td id="A5.T11.8.8.8.16.8.9" class="ltx_td ltx_align_center">16.42</td>
</tr>
<tr id="A5.T11.8.8.8.17.9" class="ltx_tr">
<th id="A5.T11.8.8.8.17.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="A5.T11.8.8.8.17.9.1.1" class="ltx_text ltx_font_italic">Medium Bitrate</span></th>
</tr>
<tr id="A5.T11.8.8.8.18.10" class="ltx_tr">
<th id="A5.T11.8.8.8.18.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete HuBERT</th>
<td id="A5.T11.8.8.8.18.10.2" class="ltx_td ltx_align_center ltx_border_t">3.48</td>
<td id="A5.T11.8.8.8.18.10.3" class="ltx_td ltx_align_center ltx_border_t">12.62</td>
<td id="A5.T11.8.8.8.18.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.875</td>
<td id="A5.T11.8.8.8.18.10.5" class="ltx_td ltx_align_center ltx_border_t">3.70</td>
<td id="A5.T11.8.8.8.18.10.6" class="ltx_td ltx_align_center ltx_border_t">66.29</td>
<td id="A5.T11.8.8.8.18.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.891</td>
<td id="A5.T11.8.8.8.18.10.8" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T11.8.8.8.18.10.8.1" class="ltx_text ltx_font_bold">3.78</span></td>
<td id="A5.T11.8.8.8.18.10.9" class="ltx_td ltx_align_center ltx_border_t">16.09</td>
</tr>
<tr id="A5.T11.8.8.8.19.11" class="ltx_tr">
<th id="A5.T11.8.8.8.19.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="A5.T11.8.8.8.19.11.2" class="ltx_td ltx_align_center">3.48</td>
<td id="A5.T11.8.8.8.19.11.3" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.19.11.3.1" class="ltx_text ltx_font_bold">10.18</span></td>
<td id="A5.T11.8.8.8.19.11.4" class="ltx_td ltx_align_center ltx_border_r">0.889</td>
<td id="A5.T11.8.8.8.19.11.5" class="ltx_td ltx_align_center">3.68</td>
<td id="A5.T11.8.8.8.19.11.6" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.19.11.6.1" class="ltx_text ltx_font_bold">34.03</span></td>
<td id="A5.T11.8.8.8.19.11.7" class="ltx_td ltx_align_center ltx_border_r">0.912</td>
<td id="A5.T11.8.8.8.19.11.8" class="ltx_td ltx_align_center">3.77</td>
<td id="A5.T11.8.8.8.19.11.9" class="ltx_td ltx_align_center">14.76</td>
</tr>
<tr id="A5.T11.8.8.8.20.12" class="ltx_tr">
<th id="A5.T11.8.8.8.20.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="A5.T11.8.8.8.20.12.2" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.20.12.2.1" class="ltx_text ltx_font_bold">3.54</span></td>
<td id="A5.T11.8.8.8.20.12.3" class="ltx_td ltx_align_center">17.60</td>
<td id="A5.T11.8.8.8.20.12.4" class="ltx_td ltx_align_center ltx_border_r">0.858</td>
<td id="A5.T11.8.8.8.20.12.5" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.20.12.5.1" class="ltx_text ltx_font_bold">3.75</span></td>
<td id="A5.T11.8.8.8.20.12.6" class="ltx_td ltx_align_center">78.42</td>
<td id="A5.T11.8.8.8.20.12.7" class="ltx_td ltx_align_center ltx_border_r">0.866</td>
<td id="A5.T11.8.8.8.20.12.8" class="ltx_td ltx_align_center">3.68</td>
<td id="A5.T11.8.8.8.20.12.9" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.20.12.9.1" class="ltx_text ltx_font_bold">5.98</span></td>
</tr>
<tr id="A5.T11.8.8.8.21.13" class="ltx_tr">
<th id="A5.T11.8.8.8.21.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="A5.T11.8.8.8.21.13.2" class="ltx_td ltx_align_center">3.10</td>
<td id="A5.T11.8.8.8.21.13.3" class="ltx_td ltx_align_center">19.07</td>
<td id="A5.T11.8.8.8.21.13.4" class="ltx_td ltx_align_center ltx_border_r">0.885</td>
<td id="A5.T11.8.8.8.21.13.5" class="ltx_td ltx_align_center">3.09</td>
<td id="A5.T11.8.8.8.21.13.6" class="ltx_td ltx_align_center">48.57</td>
<td id="A5.T11.8.8.8.21.13.7" class="ltx_td ltx_align_center ltx_border_r">0.906</td>
<td id="A5.T11.8.8.8.21.13.8" class="ltx_td ltx_align_center">1.43</td>
<td id="A5.T11.8.8.8.21.13.9" class="ltx_td ltx_align_center">92.4</td>
</tr>
<tr id="A5.T11.8.8.8.22.14" class="ltx_tr">
<th id="A5.T11.8.8.8.22.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="A5.T11.8.8.8.22.14.2" class="ltx_td ltx_align_center">3.49</td>
<td id="A5.T11.8.8.8.22.14.3" class="ltx_td ltx_align_center">31.14</td>
<td id="A5.T11.8.8.8.22.14.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T11.8.8.8.22.14.4.1" class="ltx_text ltx_font_bold">0.906</span></td>
<td id="A5.T11.8.8.8.22.14.5" class="ltx_td ltx_align_center">3.26</td>
<td id="A5.T11.8.8.8.22.14.6" class="ltx_td ltx_align_center">55.43</td>
<td id="A5.T11.8.8.8.22.14.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T11.8.8.8.22.14.7.1" class="ltx_text ltx_font_bold">0.924</span></td>
<td id="A5.T11.8.8.8.22.14.8" class="ltx_td ltx_align_center">1.71</td>
<td id="A5.T11.8.8.8.22.14.9" class="ltx_td ltx_align_center">71.25</td>
</tr>
<tr id="A5.T11.8.8.8.23.15" class="ltx_tr">
<th id="A5.T11.8.8.8.23.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="A5.T11.8.8.8.23.15.2" class="ltx_td ltx_align_center">3.49</td>
<td id="A5.T11.8.8.8.23.15.3" class="ltx_td ltx_align_center">23.44</td>
<td id="A5.T11.8.8.8.23.15.4" class="ltx_td ltx_align_center ltx_border_r">0.876</td>
<td id="A5.T11.8.8.8.23.15.5" class="ltx_td ltx_align_center">3.42</td>
<td id="A5.T11.8.8.8.23.15.6" class="ltx_td ltx_align_center">60.75</td>
<td id="A5.T11.8.8.8.23.15.7" class="ltx_td ltx_align_center ltx_border_r">0.906</td>
<td id="A5.T11.8.8.8.23.15.8" class="ltx_td ltx_align_center">1.97</td>
<td id="A5.T11.8.8.8.23.15.9" class="ltx_td ltx_align_center">53.26</td>
</tr>
<tr id="A5.T11.8.8.8.24.16" class="ltx_tr">
<th id="A5.T11.8.8.8.24.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="A5.T11.8.8.8.24.16.1.1" class="ltx_text ltx_font_italic">High Bitrate</span></th>
</tr>
<tr id="A5.T11.8.8.8.25.17" class="ltx_tr">
<th id="A5.T11.8.8.8.25.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">EnCodec</th>
<td id="A5.T11.8.8.8.25.17.2" class="ltx_td ltx_align_center ltx_border_t">2.87</td>
<td id="A5.T11.8.8.8.25.17.3" class="ltx_td ltx_align_center ltx_border_t">68.22</td>
<td id="A5.T11.8.8.8.25.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.814</td>
<td id="A5.T11.8.8.8.25.17.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T11.8.8.8.25.17.5.1" class="ltx_text ltx_font_bold">2.95</span></td>
<td id="A5.T11.8.8.8.25.17.6" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T11.8.8.8.25.17.6.1" class="ltx_text ltx_font_bold">97.73</span></td>
<td id="A5.T11.8.8.8.25.17.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T11.8.8.8.25.17.7.1" class="ltx_text ltx_font_bold">0.839</span></td>
<td id="A5.T11.8.8.8.25.17.8" class="ltx_td ltx_align_center ltx_border_t">N.C</td>
<td id="A5.T11.8.8.8.25.17.9" class="ltx_td ltx_align_center ltx_border_t">N.C</td>
</tr>
<tr id="A5.T11.8.8.8.26.18" class="ltx_tr">
<th id="A5.T11.8.8.8.26.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="A5.T11.8.8.8.26.18.2" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.26.18.2.1" class="ltx_text ltx_font_bold">2.95</span></td>
<td id="A5.T11.8.8.8.26.18.3" class="ltx_td ltx_align_center"><span id="A5.T11.8.8.8.26.18.3.1" class="ltx_text ltx_font_bold">46.07</span></td>
<td id="A5.T11.8.8.8.26.18.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T11.8.8.8.26.18.4.1" class="ltx_text ltx_font_bold">0.860</span></td>
<td id="A5.T11.8.8.8.26.18.5" class="ltx_td ltx_align_center">2.53</td>
<td id="A5.T11.8.8.8.26.18.6" class="ltx_td ltx_align_center">208</td>
<td id="A5.T11.8.8.8.26.18.7" class="ltx_td ltx_align_center ltx_border_r">0.784</td>
<td id="A5.T11.8.8.8.26.18.8" class="ltx_td ltx_align_center">N.C</td>
<td id="A5.T11.8.8.8.26.18.9" class="ltx_td ltx_align_center">N.C</td>
</tr>
<tr id="A5.T11.8.8.8.27.19" class="ltx_tr">
<th id="A5.T11.8.8.8.27.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="A5.T11.8.8.8.27.19.1.1" class="ltx_text ltx_font_italic">Continuous Baseline</span></th>
</tr>
<tr id="A5.T11.8.8.8.28.20" class="ltx_tr">
<th id="A5.T11.8.8.8.28.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">SSL</th>
<td id="A5.T11.8.8.8.28.20.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.49</td>
<td id="A5.T11.8.8.8.28.20.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.92</td>
<td id="A5.T11.8.8.8.28.20.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.928</td>
<td id="A5.T11.8.8.8.28.20.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.68</td>
<td id="A5.T11.8.8.8.28.20.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">9.97</td>
<td id="A5.T11.8.8.8.28.20.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.939</td>
<td id="A5.T11.8.8.8.28.20.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">2.86</td>
<td id="A5.T11.8.8.8.28.20.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.687</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
<figure id="A5.T12" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Results for generative tasks with the second downstream architecture. N.C. indicates “Not Converged".</figcaption>
<div id="A5.T12.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:393.6pt;height:272.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<div id="A5.T12.8.8" class="ltx_inline-block ltx_transformed_outer" style="width:390.3pt;height:272.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-75.7pt,52.8pt) scale(0.720618037423838,0.720618037423838) ;">
<table id="A5.T12.8.8.8" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A5.T12.8.8.8.9.1" class="ltx_tr">
<th id="A5.T12.8.8.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="A5.T12.8.8.8.9.1.1.1" class="ltx_text ltx_font_bold">Models/Tasks</span></th>
<td id="A5.T12.8.8.8.9.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="A5.T12.8.8.8.9.1.2.1" class="ltx_text ltx_font_bold">SE</span></td>
<td id="A5.T12.8.8.8.9.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3"><span id="A5.T12.8.8.8.9.1.3.1" class="ltx_text ltx_font_bold">SS</span></td>
<td id="A5.T12.8.8.8.9.1.4" class="ltx_td ltx_align_center ltx_border_t" colspan="2"><span id="A5.T12.8.8.8.9.1.4.1" class="ltx_text ltx_font_bold">TTS</span></td>
</tr>
<tr id="A5.T12.8.8.8.8" class="ltx_tr">
<td id="A5.T12.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T12.1.1.1.1.1.1" class="ltx_text ltx_font_bold">DNSMOS</span> <math id="A5.T12.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T12.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A5.T12.1.1.1.1.1.m1.1.1" xref="A5.T12.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T12.1.1.1.1.1.m1.1b"><ci id="A5.T12.1.1.1.1.1.m1.1.1.cmml" xref="A5.T12.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T12.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T12.2.2.2.2.2.1" class="ltx_text ltx_font_bold">dWER</span> <math id="A5.T12.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T12.2.2.2.2.2.m1.1a"><mo stretchy="false" id="A5.T12.2.2.2.2.2.m1.1.1" xref="A5.T12.2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T12.2.2.2.2.2.m1.1b"><ci id="A5.T12.2.2.2.2.2.m1.1.1.cmml" xref="A5.T12.2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A5.T12.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A5.T12.3.3.3.3.3.1" class="ltx_text ltx_font_bold">SpkSim</span> <math id="A5.T12.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T12.3.3.3.3.3.m1.1a"><mo stretchy="false" id="A5.T12.3.3.3.3.3.m1.1.1" xref="A5.T12.3.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T12.3.3.3.3.3.m1.1b"><ci id="A5.T12.3.3.3.3.3.m1.1.1.cmml" xref="A5.T12.3.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.3.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T12.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T12.4.4.4.4.4.1" class="ltx_text ltx_font_bold">DNSMOS</span> <math id="A5.T12.4.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T12.4.4.4.4.4.m1.1a"><mo stretchy="false" id="A5.T12.4.4.4.4.4.m1.1.1" xref="A5.T12.4.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T12.4.4.4.4.4.m1.1b"><ci id="A5.T12.4.4.4.4.4.m1.1.1.cmml" xref="A5.T12.4.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.4.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T12.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T12.5.5.5.5.5.1" class="ltx_text ltx_font_bold">dWER</span> <math id="A5.T12.5.5.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T12.5.5.5.5.5.m1.1a"><mo stretchy="false" id="A5.T12.5.5.5.5.5.m1.1.1" xref="A5.T12.5.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T12.5.5.5.5.5.m1.1b"><ci id="A5.T12.5.5.5.5.5.m1.1.1.cmml" xref="A5.T12.5.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.5.5.5.5.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A5.T12.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A5.T12.6.6.6.6.6.1" class="ltx_text ltx_font_bold">SpkSim</span> <math id="A5.T12.6.6.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T12.6.6.6.6.6.m1.1a"><mo stretchy="false" id="A5.T12.6.6.6.6.6.m1.1.1" xref="A5.T12.6.6.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T12.6.6.6.6.6.m1.1b"><ci id="A5.T12.6.6.6.6.6.m1.1.1.cmml" xref="A5.T12.6.6.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.6.6.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T12.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T12.7.7.7.7.7.1" class="ltx_text ltx_font_bold">UTMOS</span> <math id="A5.T12.7.7.7.7.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="A5.T12.7.7.7.7.7.m1.1a"><mo stretchy="false" id="A5.T12.7.7.7.7.7.m1.1.1" xref="A5.T12.7.7.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A5.T12.7.7.7.7.7.m1.1b"><ci id="A5.T12.7.7.7.7.7.m1.1.1.cmml" xref="A5.T12.7.7.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.7.7.7.7.7.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="A5.T12.8.8.8.8.8" class="ltx_td ltx_align_center ltx_border_t">
<span id="A5.T12.8.8.8.8.8.1" class="ltx_text ltx_font_bold">dWER</span> <math id="A5.T12.8.8.8.8.8.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T12.8.8.8.8.8.m1.1a"><mo stretchy="false" id="A5.T12.8.8.8.8.8.m1.1.1" xref="A5.T12.8.8.8.8.8.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T12.8.8.8.8.8.m1.1b"><ci id="A5.T12.8.8.8.8.8.m1.1.1.cmml" xref="A5.T12.8.8.8.8.8.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T12.8.8.8.8.8.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="A5.T12.8.8.8.10.2" class="ltx_tr">
<th id="A5.T12.8.8.8.10.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="A5.T12.8.8.8.10.2.1.1" class="ltx_text ltx_font_italic">Low Bitrate</span></th>
</tr>
<tr id="A5.T12.8.8.8.11.3" class="ltx_tr">
<th id="A5.T12.8.8.8.11.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete HuBERT</th>
<td id="A5.T12.8.8.8.11.3.2" class="ltx_td ltx_align_center ltx_border_t">3.31</td>
<td id="A5.T12.8.8.8.11.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T12.8.8.8.11.3.3.1" class="ltx_text ltx_font_bold">13.98</span></td>
<td id="A5.T12.8.8.8.11.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.821</td>
<td id="A5.T12.8.8.8.11.3.5" class="ltx_td ltx_align_center ltx_border_t">3.52</td>
<td id="A5.T12.8.8.8.11.3.6" class="ltx_td ltx_align_center ltx_border_t">97.58</td>
<td id="A5.T12.8.8.8.11.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.817</td>
<td id="A5.T12.8.8.8.11.3.8" class="ltx_td ltx_align_center ltx_border_t">3.24</td>
<td id="A5.T12.8.8.8.11.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T12.8.8.8.11.3.9.1" class="ltx_text ltx_font_bold">2.55</span></td>
</tr>
<tr id="A5.T12.8.8.8.12.4" class="ltx_tr">
<th id="A5.T12.8.8.8.12.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="A5.T12.8.8.8.12.4.2" class="ltx_td ltx_align_center">3.27</td>
<td id="A5.T12.8.8.8.12.4.3" class="ltx_td ltx_align_center">16.50</td>
<td id="A5.T12.8.8.8.12.4.4" class="ltx_td ltx_align_center ltx_border_r">0.825</td>
<td id="A5.T12.8.8.8.12.4.5" class="ltx_td ltx_align_center">3.44</td>
<td id="A5.T12.8.8.8.12.4.6" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.12.4.6.1" class="ltx_text ltx_font_bold">60.12</span></td>
<td id="A5.T12.8.8.8.12.4.7" class="ltx_td ltx_align_center ltx_border_r">0.834</td>
<td id="A5.T12.8.8.8.12.4.8" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.12.4.8.1" class="ltx_text ltx_font_bold">3.84</span></td>
<td id="A5.T12.8.8.8.12.4.9" class="ltx_td ltx_align_center">3.01</td>
</tr>
<tr id="A5.T12.8.8.8.13.5" class="ltx_tr">
<th id="A5.T12.8.8.8.13.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="A5.T12.8.8.8.13.5.2" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.13.5.2.1" class="ltx_text ltx_font_bold">3.55</span></td>
<td id="A5.T12.8.8.8.13.5.3" class="ltx_td ltx_align_center">17.17</td>
<td id="A5.T12.8.8.8.13.5.4" class="ltx_td ltx_align_center ltx_border_r">0.777</td>
<td id="A5.T12.8.8.8.13.5.5" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.13.5.5.1" class="ltx_text ltx_font_bold">3.74</span></td>
<td id="A5.T12.8.8.8.13.5.6" class="ltx_td ltx_align_center">95.20</td>
<td id="A5.T12.8.8.8.13.5.7" class="ltx_td ltx_align_center ltx_border_r">0.785</td>
<td id="A5.T12.8.8.8.13.5.8" class="ltx_td ltx_align_center">3.32</td>
<td id="A5.T12.8.8.8.13.5.9" class="ltx_td ltx_align_center">3.45</td>
</tr>
<tr id="A5.T12.8.8.8.14.6" class="ltx_tr">
<th id="A5.T12.8.8.8.14.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="A5.T12.8.8.8.14.6.2" class="ltx_td ltx_align_center">3.16</td>
<td id="A5.T12.8.8.8.14.6.3" class="ltx_td ltx_align_center">45.07</td>
<td id="A5.T12.8.8.8.14.6.4" class="ltx_td ltx_align_center ltx_border_r">0.851</td>
<td id="A5.T12.8.8.8.14.6.5" class="ltx_td ltx_align_center">2.32</td>
<td id="A5.T12.8.8.8.14.6.6" class="ltx_td ltx_align_center">99.17</td>
<td id="A5.T12.8.8.8.14.6.7" class="ltx_td ltx_align_center ltx_border_r">0.495</td>
<td id="A5.T12.8.8.8.14.6.8" class="ltx_td ltx_align_center">1.40</td>
<td id="A5.T12.8.8.8.14.6.9" class="ltx_td ltx_align_center">53.50</td>
</tr>
<tr id="A5.T12.8.8.8.15.7" class="ltx_tr">
<th id="A5.T12.8.8.8.15.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="A5.T12.8.8.8.15.7.2" class="ltx_td ltx_align_center">3.31</td>
<td id="A5.T12.8.8.8.15.7.3" class="ltx_td ltx_align_center">59.28</td>
<td id="A5.T12.8.8.8.15.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T12.8.8.8.15.7.4.1" class="ltx_text ltx_font_bold">0.863</span></td>
<td id="A5.T12.8.8.8.15.7.5" class="ltx_td ltx_align_center">2.88</td>
<td id="A5.T12.8.8.8.15.7.6" class="ltx_td ltx_align_center">138</td>
<td id="A5.T12.8.8.8.15.7.7" class="ltx_td ltx_align_center ltx_border_r">0.804</td>
<td id="A5.T12.8.8.8.15.7.8" class="ltx_td ltx_align_center">1.81</td>
<td id="A5.T12.8.8.8.15.7.9" class="ltx_td ltx_align_center">19.77</td>
</tr>
<tr id="A5.T12.8.8.8.16.8" class="ltx_tr">
<th id="A5.T12.8.8.8.16.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="A5.T12.8.8.8.16.8.2" class="ltx_td ltx_align_center">3.32</td>
<td id="A5.T12.8.8.8.16.8.3" class="ltx_td ltx_align_center">27.54</td>
<td id="A5.T12.8.8.8.16.8.4" class="ltx_td ltx_align_center ltx_border_r">0.860</td>
<td id="A5.T12.8.8.8.16.8.5" class="ltx_td ltx_align_center">3.14</td>
<td id="A5.T12.8.8.8.16.8.6" class="ltx_td ltx_align_center">90.68</td>
<td id="A5.T12.8.8.8.16.8.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T12.8.8.8.16.8.7.1" class="ltx_text ltx_font_bold">0.846</span></td>
<td id="A5.T12.8.8.8.16.8.8" class="ltx_td ltx_align_center">2.51</td>
<td id="A5.T12.8.8.8.16.8.9" class="ltx_td ltx_align_center">3.69</td>
</tr>
<tr id="A5.T12.8.8.8.17.9" class="ltx_tr">
<th id="A5.T12.8.8.8.17.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="A5.T12.8.8.8.17.9.1.1" class="ltx_text ltx_font_italic">Medium Bitrate</span></th>
</tr>
<tr id="A5.T12.8.8.8.18.10" class="ltx_tr">
<th id="A5.T12.8.8.8.18.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Discrete HuBERT</th>
<td id="A5.T12.8.8.8.18.10.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T12.8.8.8.18.10.2.1" class="ltx_text ltx_font_bold">3.48</span></td>
<td id="A5.T12.8.8.8.18.10.3" class="ltx_td ltx_align_center ltx_border_t">13.71</td>
<td id="A5.T12.8.8.8.18.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.857</td>
<td id="A5.T12.8.8.8.18.10.5" class="ltx_td ltx_align_center ltx_border_t">3.72</td>
<td id="A5.T12.8.8.8.18.10.6" class="ltx_td ltx_align_center ltx_border_t">91.63</td>
<td id="A5.T12.8.8.8.18.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.843</td>
<td id="A5.T12.8.8.8.18.10.8" class="ltx_td ltx_align_center ltx_border_t">3.80</td>
<td id="A5.T12.8.8.8.18.10.9" class="ltx_td ltx_align_center ltx_border_t">3.40</td>
</tr>
<tr id="A5.T12.8.8.8.19.11" class="ltx_tr">
<th id="A5.T12.8.8.8.19.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete WavLM</th>
<td id="A5.T12.8.8.8.19.11.2" class="ltx_td ltx_align_center">3.47</td>
<td id="A5.T12.8.8.8.19.11.3" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.19.11.3.1" class="ltx_text ltx_font_bold">9.63</span></td>
<td id="A5.T12.8.8.8.19.11.4" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T12.8.8.8.19.11.4.1" class="ltx_text ltx_font_bold">0.878</span></td>
<td id="A5.T12.8.8.8.19.11.5" class="ltx_td ltx_align_center">3.68</td>
<td id="A5.T12.8.8.8.19.11.6" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.19.11.6.1" class="ltx_text ltx_font_bold">37.53</span></td>
<td id="A5.T12.8.8.8.19.11.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T12.8.8.8.19.11.7.1" class="ltx_text ltx_font_bold">0.902</span></td>
<td id="A5.T12.8.8.8.19.11.8" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.19.11.8.1" class="ltx_text ltx_font_bold">3.82</span></td>
<td id="A5.T12.8.8.8.19.11.9" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.19.11.9.1" class="ltx_text ltx_font_bold">2.45</span></td>
</tr>
<tr id="A5.T12.8.8.8.20.12" class="ltx_tr">
<th id="A5.T12.8.8.8.20.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Discrete Wav2Vec2</th>
<td id="A5.T12.8.8.8.20.12.2" class="ltx_td ltx_align_center">3.53</td>
<td id="A5.T12.8.8.8.20.12.3" class="ltx_td ltx_align_center">16.58</td>
<td id="A5.T12.8.8.8.20.12.4" class="ltx_td ltx_align_center ltx_border_r">0.853</td>
<td id="A5.T12.8.8.8.20.12.5" class="ltx_td ltx_align_center"><span id="A5.T12.8.8.8.20.12.5.1" class="ltx_text ltx_font_bold">3.74</span></td>
<td id="A5.T12.8.8.8.20.12.6" class="ltx_td ltx_align_center">83.86</td>
<td id="A5.T12.8.8.8.20.12.7" class="ltx_td ltx_align_center ltx_border_r">0.831</td>
<td id="A5.T12.8.8.8.20.12.8" class="ltx_td ltx_align_center">3.68</td>
<td id="A5.T12.8.8.8.20.12.9" class="ltx_td ltx_align_center">2.89</td>
</tr>
<tr id="A5.T12.8.8.8.21.13" class="ltx_tr">
<th id="A5.T12.8.8.8.21.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EnCodec</th>
<td id="A5.T12.8.8.8.21.13.2" class="ltx_td ltx_align_center">3.04</td>
<td id="A5.T12.8.8.8.21.13.3" class="ltx_td ltx_align_center">84.78</td>
<td id="A5.T12.8.8.8.21.13.4" class="ltx_td ltx_align_center ltx_border_r">0.796</td>
<td id="A5.T12.8.8.8.21.13.5" class="ltx_td ltx_align_center">3.06</td>
<td id="A5.T12.8.8.8.21.13.6" class="ltx_td ltx_align_center">70.25</td>
<td id="A5.T12.8.8.8.21.13.7" class="ltx_td ltx_align_center ltx_border_r">0.882</td>
<td id="A5.T12.8.8.8.21.13.8" class="ltx_td ltx_align_center">1.50</td>
<td id="A5.T12.8.8.8.21.13.9" class="ltx_td ltx_align_center">94.62</td>
</tr>
<tr id="A5.T12.8.8.8.22.14" class="ltx_tr">
<th id="A5.T12.8.8.8.22.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="A5.T12.8.8.8.22.14.2" class="ltx_td ltx_align_center">3.35</td>
<td id="A5.T12.8.8.8.22.14.3" class="ltx_td ltx_align_center">71.07</td>
<td id="A5.T12.8.8.8.22.14.4" class="ltx_td ltx_align_center ltx_border_r">0.831</td>
<td id="A5.T12.8.8.8.22.14.5" class="ltx_td ltx_align_center">3.12</td>
<td id="A5.T12.8.8.8.22.14.6" class="ltx_td ltx_align_center">95.11</td>
<td id="A5.T12.8.8.8.22.14.7" class="ltx_td ltx_align_center ltx_border_r">0.872</td>
<td id="A5.T12.8.8.8.22.14.8" class="ltx_td ltx_align_center">1.47</td>
<td id="A5.T12.8.8.8.22.14.9" class="ltx_td ltx_align_center">77.00</td>
</tr>
<tr id="A5.T12.8.8.8.23.15" class="ltx_tr">
<th id="A5.T12.8.8.8.23.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SpeechTokenizer</th>
<td id="A5.T12.8.8.8.23.15.2" class="ltx_td ltx_align_center">2.12</td>
<td id="A5.T12.8.8.8.23.15.3" class="ltx_td ltx_align_center">99.62</td>
<td id="A5.T12.8.8.8.23.15.4" class="ltx_td ltx_align_center ltx_border_r">0.549</td>
<td id="A5.T12.8.8.8.23.15.5" class="ltx_td ltx_align_center">3.10</td>
<td id="A5.T12.8.8.8.23.15.6" class="ltx_td ltx_align_center">89.78</td>
<td id="A5.T12.8.8.8.23.15.7" class="ltx_td ltx_align_center ltx_border_r">0.862</td>
<td id="A5.T12.8.8.8.23.15.8" class="ltx_td ltx_align_center">1.85</td>
<td id="A5.T12.8.8.8.23.15.9" class="ltx_td ltx_align_center">64.26</td>
</tr>
<tr id="A5.T12.8.8.8.24.16" class="ltx_tr">
<th id="A5.T12.8.8.8.24.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="A5.T12.8.8.8.24.16.1.1" class="ltx_text ltx_font_italic">High Bitrate</span></th>
</tr>
<tr id="A5.T12.8.8.8.25.17" class="ltx_tr">
<th id="A5.T12.8.8.8.25.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">EnCodec</th>
<td id="A5.T12.8.8.8.25.17.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T12.8.8.8.25.17.2.1" class="ltx_text ltx_font_bold">2.93</span></td>
<td id="A5.T12.8.8.8.25.17.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T12.8.8.8.25.17.3.1" class="ltx_text ltx_font_bold">95.06</span></td>
<td id="A5.T12.8.8.8.25.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A5.T12.8.8.8.25.17.4.1" class="ltx_text ltx_font_bold">0.780</span></td>
<td id="A5.T12.8.8.8.25.17.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T12.8.8.8.25.17.5.1" class="ltx_text ltx_font_bold">2.96</span></td>
<td id="A5.T12.8.8.8.25.17.6" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T12.8.8.8.25.17.6.1" class="ltx_text ltx_font_bold">157</span></td>
<td id="A5.T12.8.8.8.25.17.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.768</td>
<td id="A5.T12.8.8.8.25.17.8" class="ltx_td ltx_align_center ltx_border_t">N.C</td>
<td id="A5.T12.8.8.8.25.17.9" class="ltx_td ltx_align_center ltx_border_t">N.C</td>
</tr>
<tr id="A5.T12.8.8.8.26.18" class="ltx_tr">
<th id="A5.T12.8.8.8.26.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">DAC</th>
<td id="A5.T12.8.8.8.26.18.2" class="ltx_td ltx_align_center">2.22</td>
<td id="A5.T12.8.8.8.26.18.3" class="ltx_td ltx_align_center">99.62</td>
<td id="A5.T12.8.8.8.26.18.4" class="ltx_td ltx_align_center ltx_border_r">0.571</td>
<td id="A5.T12.8.8.8.26.18.5" class="ltx_td ltx_align_center">2.31</td>
<td id="A5.T12.8.8.8.26.18.6" class="ltx_td ltx_align_center">234</td>
<td id="A5.T12.8.8.8.26.18.7" class="ltx_td ltx_align_center ltx_border_r"><span id="A5.T12.8.8.8.26.18.7.1" class="ltx_text ltx_font_bold">0.787</span></td>
<td id="A5.T12.8.8.8.26.18.8" class="ltx_td ltx_align_center">N.C</td>
<td id="A5.T12.8.8.8.26.18.9" class="ltx_td ltx_align_center">N.C</td>
</tr>
<tr id="A5.T12.8.8.8.27.19" class="ltx_tr">
<th id="A5.T12.8.8.8.27.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="9"><span id="A5.T12.8.8.8.27.19.1.1" class="ltx_text ltx_font_italic">Continuous Baseline</span></th>
</tr>
<tr id="A5.T12.8.8.8.28.20" class="ltx_tr">
<th id="A5.T12.8.8.8.28.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">SSL</th>
<td id="A5.T12.8.8.8.28.20.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.42</td>
<td id="A5.T12.8.8.8.28.20.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">6.05</td>
<td id="A5.T12.8.8.8.28.20.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.861</td>
<td id="A5.T12.8.8.8.28.20.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3.43</td>
<td id="A5.T12.8.8.8.28.20.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">24.92</td>
<td id="A5.T12.8.8.8.28.20.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.873</td>
<td id="A5.T12.8.8.8.28.20.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">2.86</td>
<td id="A5.T12.8.8.8.28.20.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">4.687</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Hyperparameters</h2>

<div id="A6.p1" class="ltx_para ltx_noindent">
<p id="A6.p1.1" class="ltx_p">We maintain the embedding dimension at 1024 for consistency across all experiments. Training continues until convergence or until the validation loss stops improving. For detailed settings for each experiment, please visit the <a target="_blank" href="https://github.com/speechbrain/benchmarks/tree/DASB/benchmarks/DASB" title="" class="ltx_ref ltx_href">GitHub repository</a>.</p>
</div>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.14292" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.14294" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.14294">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.14294" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.14296" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 19:36:19 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
