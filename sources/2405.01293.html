<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.01293] Low-resource speech recognition and dialect identification of Irish in a multi-task framework</title><meta property="og:description" content="This paper explores the use of Hybrid CTC/Attention encoder-decoder models trained with Intermediate CTC (InterCTC) for Irish (Gaelic) low-resource speech recognition (ASR) and dialect identification (DID). Results are‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Low-resource speech recognition and dialect identification of Irish in a multi-task framework">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Low-resource speech recognition and dialect identification of Irish in a multi-task framework">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.01293">

<!--Generated on Wed Jun  5 13:01:02 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="font-size:90%;">Low-resource speech recognition and dialect identification of Irish in a multi-task framework
</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text" style="font-size:90%;">This paper explores the use of Hybrid CTC/Attention encoder-decoder models trained with Intermediate CTC (InterCTC) for Irish (Gaelic) low-resource speech recognition (ASR) and dialect identification (DID). Results are compared to the current best performing models trained for ASR (TDNN-HMM) and DID (ECAPA-TDNN). An optimal InterCTC setting is initially established using a Conformer encoder. This setting is then used to train a model with an E-branchformer encoder and the performance of both architectures are compared. A multi-task fine-tuning approach is adopted for language model (LM) shallow fusion. The experiments yielded an improvement in DID accuracy of 10.8% relative to a baseline ECAPA-TDNN, and WER performance approaching the TDNN-HMM model. This multi-task approach emerges as a promising strategy for Irish low-resource ASR and DID.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text" style="font-size:90%;">Irish (Gaelic) is a highly inflected, minority language indigenous to the island of Ireland. A difficulty in developing speech technology for the language is the high degree of dialect variation across different speaker communities. There are three major native dialects of Irish, namely Ulster (Ul), Connaught (Co) and Munster (Mu), along with many sub-varieties. The L1 Irish speaking communities are found in limited remote areas called </span><span id="S1.p1.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Gaeltachta√≠</span><span id="S1.p1.1.3" class="ltx_text" style="font-size:90%;">. However, there is a considerable number of L2 speakers as Irish is also taught as a compulsory subject in primary and secondary schools. This paper focuses on the native dialects and the data used is overwhelmingly of L1 speakers.</span></p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text" style="font-size:90%;">Irish, being a low-resource language, poses a tough challenge for automatic speech recognition (ASR). Limited data makes it hard to create accurate and adaptable ASR models for Irish, impacting their effectiveness. Additionally, the fact that there is no single standard spoken variety of Irish adds to the complexity: it is therefore crucial to identify these dialects to optimise the ASR process. As part of the ABAIR initiative, which is developing speech technologies for the Irish language, a TDNN-HMM ASR system </span><span id="S1.p2.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">√âist</span><span id="S1.p2.1.3" class="ltx_text" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib1" title="" class="ltx_ref">1</a><span id="S1.p2.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.6" class="ltx_text" style="font-size:90%;"> has been developed and is available for public use</span><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>www.abair.ie</span></span></span><span id="S1.p2.1.7" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text" style="font-size:90%;">Previous work established that Irish dialect bias in ASR could not be adequately mitigated through corpus balancing alone </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S1.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.4" class="ltx_text" style="font-size:90%;">. Spoken dialect identification (DID) of Irish was explored in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S1.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.7" class="ltx_text" style="font-size:90%;">, where an ECAPA-TDNN model achieved a classification accuracy of 73%, surpassing the performance of wav2vec 2.0 XLS-R </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S1.p3.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.10" class="ltx_text" style="font-size:90%;"> after finetuning. Further to this result, the output logits of a text-based classifier were fused with the acoustic classifier which improved classification accuracy to 76%, demonstrating the importance of dialect features for classification in both the acoustic and the text domain. This paper aims to explore innovative approaches that could improve both ASR and DID performance in a multi-task setting.</span></p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text" style="font-size:90%;">Multi-task training is a promising strategy that uses shared knowledge across related tasks. It has been shown to be an effective method for language identification in multilingual ASR systems¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S1.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.4" class="ltx_text" style="font-size:90%;">. Recognizing its potential to enhance model adaptability, this paper explores Intermediate CTC, which has been used for multilingual speech recognition </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S1.p4.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.7" class="ltx_text" style="font-size:90%;">, for multi-task Irish speech recognition and dialect identification.</span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text" style="font-size:90%;">Spoken language identification (LID) is the process of automatically identifying the language of a speaker from speech. Classical i-vectors </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.4" class="ltx_text" style="font-size:90%;"> were the state-of-the-art for LID before the introduction of acoustic embeddings extracted from DNNs, namely x-vectors </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.7" class="ltx_text" style="font-size:90%;">. Phonetically-aware acoustic features from acoustic models pretrained for ASR have been shown to outperform classical acoustic features for LID. Phonetic features extracted from a phone-discriminative model, initially trained as an ASR acoustic model, were explored in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S2.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.10" class="ltx_text" style="font-size:90%;">, and led to an improvement over conventional acoustic features. Similarly, in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S2.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.13" class="ltx_text" style="font-size:90%;">, ASR-based phone posteriorgram features were used for accent identification of English, and improved performance over filter-bank features. In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib12" title="" class="ltx_ref">12</a><span id="S2.p1.1.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.16" class="ltx_text" style="font-size:90%;"> a Conformer model was initially trained for ASR with CTC, and subsequently used as a feature extractor, which yielded comparable and in some cases better acoustic features than classical multilingual bottleneck features for LID, without the need for phone-alignment information to train the feature extractor. The winners of the 2021 Oriental Language Recognition challenge¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.17.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib13" title="" class="ltx_ref">13</a><span id="S2.p1.1.18.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.19" class="ltx_text" style="font-size:90%;"> pretrained an encoder-decoder U2++ Conformer model with ASR, before finetuning the encoder component for LID, demonstrating that conditioning an LID model to be phonetically-aware is a strong strategy¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.20.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S2.p1.1.21.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.22" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p2.1.1.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S2.p2.1.2.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p2.1.3" class="ltx_text" style="font-size:90%;"> explored jointly training an RNN-T model for language identification and ASR. It was found that the best jointly trained model in their study surpassed the performance of monolingual ASR by 6.4‚Äì9.2% WER, and surpassed the LID system with a reduction in error rate of 53.9‚Äì56.1%.</span></p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text" style="font-size:90%;">However, identifying the dialects within a single language is likely to be a more difficult task than the identification of completely separate languages. </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S2.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p3.1.4" class="ltx_text" style="font-size:90%;"> investigates many configurations of combining ASR and DID, but most notably, their Japanese multi-dialect ASR system, which models ASR and DID in a multi-task set-up, outperforms the baseline system. Extending the vocabulary of a grapheme-based multi-dialect E2E ASR model for English to include a label for the dialect of a speaker is explored in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="S2.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p3.1.7" class="ltx_text" style="font-size:90%;">, and this multi-task approach was found to outperform models trained on single dialects.</span></p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text" style="font-size:90%;">Intermediate CTC (InterCTC) was originally proposed as a regularisation technique for deep encoders by incorporating the CTC loss of the intermediate layers as part of a multi-task objective¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S2.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.4" class="ltx_text" style="font-size:90%;">. It has been proven to be effective for the joint modelling of ASR and a speech classification task, as in¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S2.p4.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.7" class="ltx_text" style="font-size:90%;"> for multilingual speech recognition and language identification, achieving state-of-the-art results. Similarly, this method also achieved state-of-the-art Aphasia speech recognition and detection performance in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S2.p4.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.10" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text" style="font-size:90%;">In this paper, we explore the use of a hybrid CTC/Attention-based encoder-decoder model for Irish dialect identification and speech recognition. We explore the usefulness of InterCTC for both of these tasks by introducing an auxiliary task to predict dialect. The assignment of the auxiliary task to different encoder layers is varied systematically to find the optimum setting. Improvements to the encoder architecture are investigated, and shallow fusion with a transformer language model (LM) fine-tuned for multi-task DID and ASR shallow fusion is tested.</span></p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Data</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Acoustic data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">The data used in these experiments has either been recorded by the ABAIR project or drawn from external sources and are summarised in Table¬†</span><a href="#S3.T1" title="Table 1 ‚Ä£ 3.1 Acoustic data ‚Ä£ 3 Data ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S3.SS1.p1.1.2" class="ltx_text" style="font-size:90%;">. The recordings made in-house are divided into two corpora: M√≠leGl√≥r and Synthesis. The M√≠leGl√≥r (A thousand voices) data collection platform was created with speech recognition development in mind. Dialect-appropriate textual prompts were selected or crafted for recording. The dataset of 45.7h and 369 speakers includes crowdsourced recordings where participants recorded utterances using their own devices in varied recording environments as well as live recordings where the authors had control over the microphones used and the acoustic environment. The meta-data pertaining to the linguistc background of speakers is also collected, enabling selection of L1 vs L2 speakers. The Synthesis corpus of 25.6h is comprised of recordings of 5 L1 speakers used to create the ABAIR synthetic voices.</span></p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text" style="font-size:90%;">The audiobooks used are from different sources: recordings made at home by two Mu Irish speakers reading the books </span><span id="S3.SS1.p2.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Mo Sg√©al F√©in</span><span id="S3.SS1.p2.1.3" class="ltx_text" style="font-size:90%;"> and </span><span id="S3.SS1.p2.1.4" class="ltx_text ltx_font_italic" style="font-size:90%;">An tOile√°nach</span><span id="S3.SS1.p2.1.5" class="ltx_text" style="font-size:90%;"> were used. A collection of stories published by </span><span id="S3.SS1.p2.1.6" class="ltx_text ltx_font_italic" style="font-size:90%;">Cois Life</span><span id="S3.SS1.p2.1.7" class="ltx_text" style="font-size:90%;"> as well as a collection of short stories from </span><span id="S3.SS1.p2.1.8" class="ltx_text ltx_font_italic" style="font-size:90%;">√âabhl√≥id</span><span id="S3.SS1.p2.1.9" class="ltx_text" style="font-size:90%;"> were used as well. A spontaneous speech corpus of broadcast material named </span><span id="S3.SS1.p2.1.10" class="ltx_text ltx_font_italic" style="font-size:90%;">Corpas na Cainte Beo</span><span id="S3.SS1.p2.1.11" class="ltx_text" style="font-size:90%;"> provided by Foras na Gaeilge‚Äôs New English-Irish Dictionary project, which is tagged with dialect information, is also used. This corpus was provided to ABAIR without audio-text alignment. The alignment procedure employed is detailed in Section¬†</span><a href="#S3.SS1.SSS1" title="3.1.1 Alignment of Spontaneous Speech Corpus ‚Ä£ 3.1 Acoustic data ‚Ä£ 3 Data ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3.1.1</span></a><span id="S3.SS1.p2.1.12" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Speech corpora</figcaption>
<table id="S3.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.3.1.1" class="ltx_tr">
<th id="S3.T1.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S3.T1.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Type</span></th>
<th id="S3.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.3.1.1.2.1" class="ltx_text" style="font-size:90%;">Duration (h)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.3.2.1" class="ltx_tr">
<th id="S3.T1.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S3.T1.3.2.1.1.1" class="ltx_text" style="font-size:90%;">Audiobooks</span></th>
<td id="S3.T1.3.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.3.2.1.2.1" class="ltx_text" style="font-size:90%;">33.6</span></td>
</tr>
<tr id="S3.T1.3.3.2" class="ltx_tr">
<th id="S3.T1.3.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S3.T1.3.3.2.1.1" class="ltx_text" style="font-size:90%;">Synthesis</span></th>
<td id="S3.T1.3.3.2.2" class="ltx_td ltx_align_center"><span id="S3.T1.3.3.2.2.1" class="ltx_text" style="font-size:90%;">25.6</span></td>
</tr>
<tr id="S3.T1.3.4.3" class="ltx_tr">
<th id="S3.T1.3.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S3.T1.3.4.3.1.1" class="ltx_text" style="font-size:90%;">M√≠leGl√≥r</span></th>
<td id="S3.T1.3.4.3.2" class="ltx_td ltx_align_center"><span id="S3.T1.3.4.3.2.1" class="ltx_text" style="font-size:90%;">45.7</span></td>
</tr>
<tr id="S3.T1.3.5.4" class="ltx_tr">
<th id="S3.T1.3.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S3.T1.3.5.4.1.1" class="ltx_text" style="font-size:90%;">Corpas na Cainte Beo</span></th>
<td id="S3.T1.3.5.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.3.5.4.2.1" class="ltx_text" style="font-size:90%;">200.8</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Alignment of Spontaneous Speech Corpus</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p"><span id="S3.SS1.SSS1.p1.1.1" class="ltx_text" style="font-size:90%;">The alignment of the spontaneous speech corpus was done in two stages, firstly using CTC-Segmentation as described in¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.SSS1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S3.SS1.SSS1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.SSS1.p1.1.4" class="ltx_text" style="font-size:90%;"> using the ESPnet toolkit¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.SSS1.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S3.SS1.SSS1.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.SSS1.p1.1.7" class="ltx_text" style="font-size:90%;">. CTC-Segmentation utilizes CTC log-posteriors to determine utterance timings in the audio given a ground-truth text. Initially, a forward pass is executed, wherein transition probabilities are mapped into a trellis diagram of the ground-truth token sequence across all time steps. The algorithm backtracks from the most probable timing of the last token and finds the most probable path through the trellis diagram. A confidence score is computed for each utterance, based on per-token probabilities within the trellis. A Conformer encoder </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.SSS1.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S3.SS1.SSS1.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.SSS1.p1.1.10" class="ltx_text" style="font-size:90%;"> which uses XLS-R 300M as the frontend with the CTC objective is trained on all available Irish data and used for alignment. CTC-segmentation requires inference over the entire audio sequence of a file, which when using Transformer-based encoders with quadratic memory-based complexity, can be an issue for longer files. Following the implementation in¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.SSS1.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S3.SS1.SSS1.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.SSS1.p1.1.13" class="ltx_text" style="font-size:90%;">, files above 600s are partitioned into smaller segments of audio. Inference is calculated on these segments and the CTC-posteriors of the segments are subsequently concatenated. As splitting audio abruptly can lead to distortions, an overlap of 1s is used and these overlap posteriors are later discarded for scoring.</span></p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.1" class="ltx_p"><span id="S3.SS1.SSS1.p2.1.1" class="ltx_text" style="font-size:90%;">The resulting alignment contained speech segments longer than the conventional maximum of 20s for ASR. To split these files into segments 20s in length, Kaldi-based scripts are used. A biased LM is created according to the transcripts of the input data and together with a TDNN-HMM acoustic model, the data is split into reasonable chunks</span><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>kaldi/egs/wsj/s5/steps/cleanup/segment_long_utterances_nnet3.sh</span></span></span><span id="S3.SS1.SSS1.p2.1.2" class="ltx_text" style="font-size:90%;">. An additional step was taken to ensure the resulting splits match their transcripts by removing bad portions or to make minor modifications to allow for disfluencies or repetitions</span><span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>kaldi/egs/wsj/s5/steps/cleanup/clean_and_segment_data_nnet3.sh</span></span></span><span id="S3.SS1.SSS1.p2.1.3" class="ltx_text" style="font-size:90%;">. Implementation details for both of these scripts can be found in¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.SSS1.p2.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S3.SS1.SSS1.p2.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.SSS1.p2.1.6" class="ltx_text" style="font-size:90%;">. 200h out of a total 320h were successfully aligned using this process.</span></p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Construction of train, validation and test sets</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p"><span id="S3.SS1.SSS2.p1.1.1" class="ltx_text" style="font-size:90%;">The train set contains 290h in total, and the validation and test sets contain 1.7h and 3.5h respectively. These were constructed such that there was no overlap of speakers or utterance texts between the sets. As this paper is focusing on ASR and dialect identification of L1 speakers of Irish, the M√≠leGl√≥r corpus is the most appropriate set to use to construct the validation and test sets. As noted, specific meta-data relating to the linguistic background of each speaker was collected and therefore, including only L1 speakers of Irish in the test sets can be done easily. Also, the authors had control over the text prompts used when recording and could ensure their dialect appropriateness. One issue with this corpus which pertains to Ulster speakers particularly, is that only a limited set of 3000 recording prompts were used for Ul recordings. Therefore, there is less variability of utterance texts in the Ul portion of this corpus, compared to Co and Mu. Avoiding overlap of texts would necessitate a large portion of Ul data to be discarded from any set. To avoid this, a portion 0.2h of Ul data from the Audiobook collection was added to the test set. Details of the validation and test sets are presented in Table¬†</span><a href="#S3.T2" title="Table 2 ‚Ä£ 3.1.2 Construction of train, validation and test sets ‚Ä£ 3.1 Acoustic data ‚Ä£ 3 Data ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S3.SS1.SSS2.p1.1.2" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Breakdown of validation and test sets with number of speakers and duration</figcaption>
<table id="S3.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.3.1.1" class="ltx_tr">
<th id="S3.T2.3.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S3.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S3.T2.3.1.1.2.1" class="ltx_text" style="font-size:90%;">Validation set</span></th>
<th id="S3.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S3.T2.3.1.1.3.1" class="ltx_text" style="font-size:90%;">Test set</span></th>
</tr>
<tr id="S3.T2.3.2.2" class="ltx_tr">
<th id="S3.T2.3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S3.T2.3.2.2.1.1" class="ltx_text" style="font-size:90%;">Dialect</span></th>
<th id="S3.T2.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T2.3.2.2.2.1" class="ltx_text" style="font-size:90%;">#spks</span></th>
<th id="S3.T2.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S3.T2.3.2.2.3.1" class="ltx_text" style="font-size:90%;">dur (h)</span></th>
<th id="S3.T2.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T2.3.2.2.4.1" class="ltx_text" style="font-size:90%;">#spks</span></th>
<th id="S3.T2.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S3.T2.3.2.2.5.1" class="ltx_text" style="font-size:90%;">dur (h)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.3.3.1" class="ltx_tr">
<th id="S3.T2.3.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S3.T2.3.3.1.1.1" class="ltx_text" style="font-size:90%;">Ul</span></th>
<td id="S3.T2.3.3.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.3.3.1.2.1" class="ltx_text" style="font-size:90%;">9</span></td>
<td id="S3.T2.3.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.3.3.1.3.1" class="ltx_text" style="font-size:90%;">0.55h</span></td>
<td id="S3.T2.3.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.3.3.1.4.1" class="ltx_text" style="font-size:90%;">17</span></td>
<td id="S3.T2.3.3.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.3.3.1.5.1" class="ltx_text" style="font-size:90%;">1.03h</span></td>
</tr>
<tr id="S3.T2.3.4.2" class="ltx_tr">
<th id="S3.T2.3.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S3.T2.3.4.2.1.1" class="ltx_text" style="font-size:90%;">Co</span></th>
<td id="S3.T2.3.4.2.2" class="ltx_td ltx_align_center"><span id="S3.T2.3.4.2.2.1" class="ltx_text" style="font-size:90%;">4</span></td>
<td id="S3.T2.3.4.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.3.4.2.3.1" class="ltx_text" style="font-size:90%;">0.55h</span></td>
<td id="S3.T2.3.4.2.4" class="ltx_td ltx_align_center"><span id="S3.T2.3.4.2.4.1" class="ltx_text" style="font-size:90%;">12</span></td>
<td id="S3.T2.3.4.2.5" class="ltx_td ltx_align_center"><span id="S3.T2.3.4.2.5.1" class="ltx_text" style="font-size:90%;">1.29h</span></td>
</tr>
<tr id="S3.T2.3.5.3" class="ltx_tr">
<th id="S3.T2.3.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S3.T2.3.5.3.1.1" class="ltx_text" style="font-size:90%;">Mu</span></th>
<td id="S3.T2.3.5.3.2" class="ltx_td ltx_align_center"><span id="S3.T2.3.5.3.2.1" class="ltx_text" style="font-size:90%;">5</span></td>
<td id="S3.T2.3.5.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.3.5.3.3.1" class="ltx_text" style="font-size:90%;">0.55h</span></td>
<td id="S3.T2.3.5.3.4" class="ltx_td ltx_align_center"><span id="S3.T2.3.5.3.4.1" class="ltx_text" style="font-size:90%;">20</span></td>
<td id="S3.T2.3.5.3.5" class="ltx_td ltx_align_center"><span id="S3.T2.3.5.3.5.1" class="ltx_text" style="font-size:90%;">1.15h</span></td>
</tr>
<tr id="S3.T2.3.6.4" class="ltx_tr">
<th id="S3.T2.3.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T2.3.6.4.1.1" class="ltx_text" style="font-size:90%;">Total</span></th>
<td id="S3.T2.3.6.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.3.6.4.2.1" class="ltx_text" style="font-size:90%;">18</span></td>
<td id="S3.T2.3.6.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T2.3.6.4.3.1" class="ltx_text" style="font-size:90%;">1.66h</span></td>
<td id="S3.T2.3.6.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.3.6.4.4.1" class="ltx_text" style="font-size:90%;">49</span></td>
<td id="S3.T2.3.6.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T2.3.6.4.5.1" class="ltx_text" style="font-size:90%;">3.47h</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Text corpora for shallow-fusion experiment</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">The transformer language model used in the shallow-fusion experiment is trained in two stages. Firstly, the model is trained with text-only data, and then it is fine-tuned with corpora containing dialect information. In the first stage, two corpora were used: i) Paracrawl, which is the Irish part of the ga-en pairs from ParaCrawl v7 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S3.SS2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p1.1.4" class="ltx_text" style="font-size:90%;">; and ii) ConLL17, the Irish data from the CoNLL 2017 Shared Task on Universal Dependancy Parsing </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a><span id="S3.SS2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p1.1.7" class="ltx_text" style="font-size:90%;">. As these corpora were scraped from the web, they contain many symbols and characters from different languages. There is only a limited amount of textual data available on the web in the Irish language and therefore, the two corpora contain some overlap. To overcome these issues, an aggressive multi-stage cleaning process was employed: i) a conventional text-cleaning script for Irish was used, which transliterates certain characters and removes unnecessary punctuation symbols. After this, any sentence that contained symbols outside of the limited character set of Irish was removed. The corpus was then sorted and uniqued on a sentence level to ensure that overlap between the two corpora is resolved. This resulted in a corpus of 58m words, a reduction of almost 50% of the combined size of the Paracrawl and CoNLL 2017 and is used to pretrain the transformer LM used for shallow fusion.</span></p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">The second collection of texts that were used include dialect information at the sentence level, which is generally not available in Irish corpora. One useful source that is tagged with dialect is the Historical Irish Corpus of the Royal Irish Academy. This corpus consists of texts written between 1900-50, before the introduction of the standard written form, so morphosyntactic and lexical markers of dialect are salient in these texts (for more details, see </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S3.SS2.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p2.1.4" class="ltx_text" style="font-size:90%;">). Alongside this corpus, the transcripts from the entire Spontaneous Speech Corpus were used, as well as the transcripts from the training set. See for Table¬†</span><a href="#S3.T3" title="Table 3 ‚Ä£ 3.2 Text corpora for shallow-fusion experiment ‚Ä£ 3 Data ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S3.SS2.p2.1.5" class="ltx_text" style="font-size:90%;"> for information regarding these corpora.</span></p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Text corpora used for LM training and multi-task fine-tuning</figcaption>
<table id="S3.T3.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.3.1.1" class="ltx_tr">
<th id="S3.T3.3.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S3.T3.3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S3.T3.3.1.1.2.1" class="ltx_text" style="font-size:90%;">Corpus</span></th>
<th id="S3.T3.3.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S3.T3.3.1.1.3.1" class="ltx_text" style="font-size:90%;">#words</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.3.2.1" class="ltx_tr">
<th id="S3.T3.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T3.3.2.1.1.1" class="ltx_text" style="font-size:90%;">Training</span></th>
<td id="S3.T3.3.2.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T3.3.2.1.2.1" class="ltx_text" style="font-size:90%;">Paracrawl</span></td>
<td id="S3.T3.3.2.1.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T3.3.2.1.3.1" class="ltx_text" style="font-size:90%;">63.1m</span></td>
</tr>
<tr id="S3.T3.3.3.2" class="ltx_tr">
<td id="S3.T3.3.3.2.1" class="ltx_td ltx_align_left"><span id="S3.T3.3.3.2.1.1" class="ltx_text" style="font-size:90%;">ConLL17</span></td>
<td id="S3.T3.3.3.2.2" class="ltx_td ltx_align_left"><span id="S3.T3.3.3.2.2.1" class="ltx_text" style="font-size:90%;">49.4m</span></td>
</tr>
<tr id="S3.T3.3.4.3" class="ltx_tr">
<th id="S3.T3.3.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T3.3.4.3.1.1" class="ltx_text" style="font-size:90%;">Fine-tuning</span></th>
<td id="S3.T3.3.4.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T3.3.4.3.2.1" class="ltx_text" style="font-size:90%;">Historical</span></td>
<td id="S3.T3.3.4.3.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T3.3.4.3.3.1" class="ltx_text" style="font-size:90%;">4.5m</span></td>
</tr>
<tr id="S3.T3.3.5.4" class="ltx_tr">
<td id="S3.T3.3.5.4.1" class="ltx_td ltx_align_left"><span id="S3.T3.3.5.4.1.1" class="ltx_text" style="font-size:90%;">Spontaneous Speech</span></td>
<td id="S3.T3.3.5.4.2" class="ltx_td ltx_align_left"><span id="S3.T3.3.5.4.2.1" class="ltx_text" style="font-size:90%;">4.4m</span></td>
</tr>
<tr id="S3.T3.3.6.5" class="ltx_tr">
<th id="S3.T3.3.6.5.1" class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_r"></th>
<td id="S3.T3.3.6.5.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T3.3.6.5.2.1" class="ltx_text" style="font-size:90%;">Training</span></td>
<td id="S3.T3.3.6.5.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T3.3.6.5.3.1" class="ltx_text" style="font-size:90%;">0.9m</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Method</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Hybrid CTC/Attention</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Hybrid </span><span id="S4.SS1.p1.1.2" class="ltx_text" style="font-size:90%;">CTC</span><span id="S4.SS1.p1.1.3" class="ltx_text" style="font-size:90%;">/</span><span id="S4.SS1.p1.1.4" class="ltx_text" style="font-size:90%;">Attention</span><span id="S4.SS1.p1.1.5" class="ltx_text" style="font-size:90%;">-based encoder-decoder models </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S4.SS1.p1.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.8" class="ltx_text" style="font-size:90%;"> utilize two principal techniques in ASR, namely Connectionist Temporal Classification CTC </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.9.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib29" title="" class="ltx_ref">29</a><span id="S4.SS1.p1.1.10.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.11" class="ltx_text" style="font-size:90%;"> and the attention mechanism. The process can be summarized as follows:</span></p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.5" class="ltx_p"><span id="S4.SS1.p2.5.1" class="ltx_text" style="font-size:90%;">The encoder, denoted as a function </span><math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi mathsize="90%" id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">E</annotation></semantics></math><span id="S4.SS1.p2.5.2" class="ltx_text" style="font-size:90%;">, transforms an acoustic sequence </span><math id="S4.SS1.p2.2.m2.4" class="ltx_Math" alttext="X=\{x_{1},x_{2},\ldots,x_{T}\}" display="inline"><semantics id="S4.SS1.p2.2.m2.4a"><mrow id="S4.SS1.p2.2.m2.4.4" xref="S4.SS1.p2.2.m2.4.4.cmml"><mi mathsize="90%" id="S4.SS1.p2.2.m2.4.4.5" xref="S4.SS1.p2.2.m2.4.4.5.cmml">X</mi><mo mathsize="90%" id="S4.SS1.p2.2.m2.4.4.4" xref="S4.SS1.p2.2.m2.4.4.4.cmml">=</mo><mrow id="S4.SS1.p2.2.m2.4.4.3.3" xref="S4.SS1.p2.2.m2.4.4.3.4.cmml"><mo maxsize="90%" minsize="90%" id="S4.SS1.p2.2.m2.4.4.3.3.4" xref="S4.SS1.p2.2.m2.4.4.3.4.cmml">{</mo><msub id="S4.SS1.p2.2.m2.2.2.1.1.1" xref="S4.SS1.p2.2.m2.2.2.1.1.1.cmml"><mi mathsize="90%" id="S4.SS1.p2.2.m2.2.2.1.1.1.2" xref="S4.SS1.p2.2.m2.2.2.1.1.1.2.cmml">x</mi><mn mathsize="90%" id="S4.SS1.p2.2.m2.2.2.1.1.1.3" xref="S4.SS1.p2.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo mathsize="90%" id="S4.SS1.p2.2.m2.4.4.3.3.5" xref="S4.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p2.2.m2.3.3.2.2.2" xref="S4.SS1.p2.2.m2.3.3.2.2.2.cmml"><mi mathsize="90%" id="S4.SS1.p2.2.m2.3.3.2.2.2.2" xref="S4.SS1.p2.2.m2.3.3.2.2.2.2.cmml">x</mi><mn mathsize="90%" id="S4.SS1.p2.2.m2.3.3.2.2.2.3" xref="S4.SS1.p2.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo mathsize="90%" id="S4.SS1.p2.2.m2.4.4.3.3.6" xref="S4.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">‚Ä¶</mi><mo mathsize="90%" id="S4.SS1.p2.2.m2.4.4.3.3.7" xref="S4.SS1.p2.2.m2.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p2.2.m2.4.4.3.3.3" xref="S4.SS1.p2.2.m2.4.4.3.3.3.cmml"><mi mathsize="90%" id="S4.SS1.p2.2.m2.4.4.3.3.3.2" xref="S4.SS1.p2.2.m2.4.4.3.3.3.2.cmml">x</mi><mi mathsize="90%" id="S4.SS1.p2.2.m2.4.4.3.3.3.3" xref="S4.SS1.p2.2.m2.4.4.3.3.3.3.cmml">T</mi></msub><mo maxsize="90%" minsize="90%" id="S4.SS1.p2.2.m2.4.4.3.3.8" xref="S4.SS1.p2.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.4b"><apply id="S4.SS1.p2.2.m2.4.4.cmml" xref="S4.SS1.p2.2.m2.4.4"><eq id="S4.SS1.p2.2.m2.4.4.4.cmml" xref="S4.SS1.p2.2.m2.4.4.4"></eq><ci id="S4.SS1.p2.2.m2.4.4.5.cmml" xref="S4.SS1.p2.2.m2.4.4.5">ùëã</ci><set id="S4.SS1.p2.2.m2.4.4.3.4.cmml" xref="S4.SS1.p2.2.m2.4.4.3.3"><apply id="S4.SS1.p2.2.m2.2.2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.2.2.1.1.1.1.cmml" xref="S4.SS1.p2.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.2.m2.2.2.1.1.1.2.cmml" xref="S4.SS1.p2.2.m2.2.2.1.1.1.2">ùë•</ci><cn type="integer" id="S4.SS1.p2.2.m2.2.2.1.1.1.3.cmml" xref="S4.SS1.p2.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S4.SS1.p2.2.m2.3.3.2.2.2.cmml" xref="S4.SS1.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.3.3.2.2.2.1.cmml" xref="S4.SS1.p2.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S4.SS1.p2.2.m2.3.3.2.2.2.2.cmml" xref="S4.SS1.p2.2.m2.3.3.2.2.2.2">ùë•</ci><cn type="integer" id="S4.SS1.p2.2.m2.3.3.2.2.2.3.cmml" xref="S4.SS1.p2.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">‚Ä¶</ci><apply id="S4.SS1.p2.2.m2.4.4.3.3.3.cmml" xref="S4.SS1.p2.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p2.2.m2.4.4.3.3.3.1.cmml" xref="S4.SS1.p2.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S4.SS1.p2.2.m2.4.4.3.3.3.2.cmml" xref="S4.SS1.p2.2.m2.4.4.3.3.3.2">ùë•</ci><ci id="S4.SS1.p2.2.m2.4.4.3.3.3.3.cmml" xref="S4.SS1.p2.2.m2.4.4.3.3.3.3">ùëá</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.4c">X=\{x_{1},x_{2},\ldots,x_{T}\}</annotation></semantics></math><span id="S4.SS1.p2.5.3" class="ltx_text" style="font-size:90%;"> into a series of embeddings </span><math id="S4.SS1.p2.3.m3.4" class="ltx_Math" alttext="H=\{h_{1},h_{2},\ldots,h_{N}\}" display="inline"><semantics id="S4.SS1.p2.3.m3.4a"><mrow id="S4.SS1.p2.3.m3.4.4" xref="S4.SS1.p2.3.m3.4.4.cmml"><mi mathsize="90%" id="S4.SS1.p2.3.m3.4.4.5" xref="S4.SS1.p2.3.m3.4.4.5.cmml">H</mi><mo mathsize="90%" id="S4.SS1.p2.3.m3.4.4.4" xref="S4.SS1.p2.3.m3.4.4.4.cmml">=</mo><mrow id="S4.SS1.p2.3.m3.4.4.3.3" xref="S4.SS1.p2.3.m3.4.4.3.4.cmml"><mo maxsize="90%" minsize="90%" id="S4.SS1.p2.3.m3.4.4.3.3.4" xref="S4.SS1.p2.3.m3.4.4.3.4.cmml">{</mo><msub id="S4.SS1.p2.3.m3.2.2.1.1.1" xref="S4.SS1.p2.3.m3.2.2.1.1.1.cmml"><mi mathsize="90%" id="S4.SS1.p2.3.m3.2.2.1.1.1.2" xref="S4.SS1.p2.3.m3.2.2.1.1.1.2.cmml">h</mi><mn mathsize="90%" id="S4.SS1.p2.3.m3.2.2.1.1.1.3" xref="S4.SS1.p2.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo mathsize="90%" id="S4.SS1.p2.3.m3.4.4.3.3.5" xref="S4.SS1.p2.3.m3.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p2.3.m3.3.3.2.2.2" xref="S4.SS1.p2.3.m3.3.3.2.2.2.cmml"><mi mathsize="90%" id="S4.SS1.p2.3.m3.3.3.2.2.2.2" xref="S4.SS1.p2.3.m3.3.3.2.2.2.2.cmml">h</mi><mn mathsize="90%" id="S4.SS1.p2.3.m3.3.3.2.2.2.3" xref="S4.SS1.p2.3.m3.3.3.2.2.2.3.cmml">2</mn></msub><mo mathsize="90%" id="S4.SS1.p2.3.m3.4.4.3.3.6" xref="S4.SS1.p2.3.m3.4.4.3.4.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">‚Ä¶</mi><mo mathsize="90%" id="S4.SS1.p2.3.m3.4.4.3.3.7" xref="S4.SS1.p2.3.m3.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p2.3.m3.4.4.3.3.3" xref="S4.SS1.p2.3.m3.4.4.3.3.3.cmml"><mi mathsize="90%" id="S4.SS1.p2.3.m3.4.4.3.3.3.2" xref="S4.SS1.p2.3.m3.4.4.3.3.3.2.cmml">h</mi><mi mathsize="90%" id="S4.SS1.p2.3.m3.4.4.3.3.3.3" xref="S4.SS1.p2.3.m3.4.4.3.3.3.3.cmml">N</mi></msub><mo maxsize="90%" minsize="90%" id="S4.SS1.p2.3.m3.4.4.3.3.8" xref="S4.SS1.p2.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.4b"><apply id="S4.SS1.p2.3.m3.4.4.cmml" xref="S4.SS1.p2.3.m3.4.4"><eq id="S4.SS1.p2.3.m3.4.4.4.cmml" xref="S4.SS1.p2.3.m3.4.4.4"></eq><ci id="S4.SS1.p2.3.m3.4.4.5.cmml" xref="S4.SS1.p2.3.m3.4.4.5">ùêª</ci><set id="S4.SS1.p2.3.m3.4.4.3.4.cmml" xref="S4.SS1.p2.3.m3.4.4.3.3"><apply id="S4.SS1.p2.3.m3.2.2.1.1.1.cmml" xref="S4.SS1.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.2.2.1.1.1.1.cmml" xref="S4.SS1.p2.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS1.p2.3.m3.2.2.1.1.1.2">‚Ñé</ci><cn type="integer" id="S4.SS1.p2.3.m3.2.2.1.1.1.3.cmml" xref="S4.SS1.p2.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="S4.SS1.p2.3.m3.3.3.2.2.2.cmml" xref="S4.SS1.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.3.3.2.2.2.1.cmml" xref="S4.SS1.p2.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S4.SS1.p2.3.m3.3.3.2.2.2.2.cmml" xref="S4.SS1.p2.3.m3.3.3.2.2.2.2">‚Ñé</ci><cn type="integer" id="S4.SS1.p2.3.m3.3.3.2.2.2.3.cmml" xref="S4.SS1.p2.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">‚Ä¶</ci><apply id="S4.SS1.p2.3.m3.4.4.3.3.3.cmml" xref="S4.SS1.p2.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p2.3.m3.4.4.3.3.3.1.cmml" xref="S4.SS1.p2.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S4.SS1.p2.3.m3.4.4.3.3.3.2.cmml" xref="S4.SS1.p2.3.m3.4.4.3.3.3.2">‚Ñé</ci><ci id="S4.SS1.p2.3.m3.4.4.3.3.3.3.cmml" xref="S4.SS1.p2.3.m3.4.4.3.3.3.3">ùëÅ</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.4c">H=\{h_{1},h_{2},\ldots,h_{N}\}</annotation></semantics></math><span id="S4.SS1.p2.5.4" class="ltx_text" style="font-size:90%;">, where </span><math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mi mathsize="90%" id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><ci id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">T</annotation></semantics></math><span id="S4.SS1.p2.5.5" class="ltx_text" style="font-size:90%;"> represents the length of the input sequence, and </span><math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mi mathsize="90%" id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><ci id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">N</annotation></semantics></math><span id="S4.SS1.p2.5.6" class="ltx_text" style="font-size:90%;"> is the length of the encoded embeddings.</span></p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.1" class="ltx_Math" alttext="\mathbb{H}=E(X)" display="block"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.2" xref="S4.E1.m1.1.2.cmml"><mi mathsize="90%" id="S4.E1.m1.1.2.2" xref="S4.E1.m1.1.2.2.cmml">‚Ñç</mi><mo mathsize="90%" id="S4.E1.m1.1.2.1" xref="S4.E1.m1.1.2.1.cmml">=</mo><mrow id="S4.E1.m1.1.2.3" xref="S4.E1.m1.1.2.3.cmml"><mi mathsize="90%" id="S4.E1.m1.1.2.3.2" xref="S4.E1.m1.1.2.3.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.2.3.1" xref="S4.E1.m1.1.2.3.1.cmml">‚Äã</mo><mrow id="S4.E1.m1.1.2.3.3.2" xref="S4.E1.m1.1.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S4.E1.m1.1.2.3.3.2.1" xref="S4.E1.m1.1.2.3.cmml">(</mo><mi mathsize="90%" id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml">X</mi><mo maxsize="90%" minsize="90%" id="S4.E1.m1.1.2.3.3.2.2" xref="S4.E1.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.2.cmml" xref="S4.E1.m1.1.2"><eq id="S4.E1.m1.1.2.1.cmml" xref="S4.E1.m1.1.2.1"></eq><ci id="S4.E1.m1.1.2.2.cmml" xref="S4.E1.m1.1.2.2">‚Ñç</ci><apply id="S4.E1.m1.1.2.3.cmml" xref="S4.E1.m1.1.2.3"><times id="S4.E1.m1.1.2.3.1.cmml" xref="S4.E1.m1.1.2.3.1"></times><ci id="S4.E1.m1.1.2.3.2.cmml" xref="S4.E1.m1.1.2.3.2">ùê∏</ci><ci id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1">ùëã</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">\mathbb{H}=E(X)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p2.7" class="ltx_p"><span id="S4.SS1.p2.7.1" class="ltx_text" style="font-size:90%;">These embeddings </span><math id="S4.SS1.p2.6.m1.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S4.SS1.p2.6.m1.1a"><mi mathsize="90%" id="S4.SS1.p2.6.m1.1.1" xref="S4.SS1.p2.6.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m1.1b"><ci id="S4.SS1.p2.6.m1.1.1.cmml" xref="S4.SS1.p2.6.m1.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m1.1c">H</annotation></semantics></math><span id="S4.SS1.p2.7.2" class="ltx_text" style="font-size:90%;"> can optionally be converted into text using CTC, generating a preliminary textual output </span><math id="S4.SS1.p2.7.m2.1" class="ltx_Math" alttext="P_{\text{Enc}}(T|X)" display="inline"><semantics id="S4.SS1.p2.7.m2.1a"><mrow id="S4.SS1.p2.7.m2.1.1" xref="S4.SS1.p2.7.m2.1.1.cmml"><msub id="S4.SS1.p2.7.m2.1.1.3" xref="S4.SS1.p2.7.m2.1.1.3.cmml"><mi mathsize="90%" id="S4.SS1.p2.7.m2.1.1.3.2" xref="S4.SS1.p2.7.m2.1.1.3.2.cmml">P</mi><mtext mathsize="90%" id="S4.SS1.p2.7.m2.1.1.3.3" xref="S4.SS1.p2.7.m2.1.1.3.3a.cmml">Enc</mtext></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p2.7.m2.1.1.2" xref="S4.SS1.p2.7.m2.1.1.2.cmml">‚Äã</mo><mrow id="S4.SS1.p2.7.m2.1.1.1.1" xref="S4.SS1.p2.7.m2.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.SS1.p2.7.m2.1.1.1.1.2" xref="S4.SS1.p2.7.m2.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS1.p2.7.m2.1.1.1.1.1" xref="S4.SS1.p2.7.m2.1.1.1.1.1.cmml"><mi mathsize="90%" id="S4.SS1.p2.7.m2.1.1.1.1.1.2" xref="S4.SS1.p2.7.m2.1.1.1.1.1.2.cmml">T</mi><mo fence="false" mathsize="90%" id="S4.SS1.p2.7.m2.1.1.1.1.1.1" xref="S4.SS1.p2.7.m2.1.1.1.1.1.1.cmml">|</mo><mi mathsize="90%" id="S4.SS1.p2.7.m2.1.1.1.1.1.3" xref="S4.SS1.p2.7.m2.1.1.1.1.1.3.cmml">X</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.SS1.p2.7.m2.1.1.1.1.3" xref="S4.SS1.p2.7.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m2.1b"><apply id="S4.SS1.p2.7.m2.1.1.cmml" xref="S4.SS1.p2.7.m2.1.1"><times id="S4.SS1.p2.7.m2.1.1.2.cmml" xref="S4.SS1.p2.7.m2.1.1.2"></times><apply id="S4.SS1.p2.7.m2.1.1.3.cmml" xref="S4.SS1.p2.7.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.7.m2.1.1.3.1.cmml" xref="S4.SS1.p2.7.m2.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.7.m2.1.1.3.2.cmml" xref="S4.SS1.p2.7.m2.1.1.3.2">ùëÉ</ci><ci id="S4.SS1.p2.7.m2.1.1.3.3a.cmml" xref="S4.SS1.p2.7.m2.1.1.3.3"><mtext mathsize="63%" id="S4.SS1.p2.7.m2.1.1.3.3.cmml" xref="S4.SS1.p2.7.m2.1.1.3.3">Enc</mtext></ci></apply><apply id="S4.SS1.p2.7.m2.1.1.1.1.1.cmml" xref="S4.SS1.p2.7.m2.1.1.1.1"><csymbol cd="latexml" id="S4.SS1.p2.7.m2.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.7.m2.1.1.1.1.1.1">conditional</csymbol><ci id="S4.SS1.p2.7.m2.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.7.m2.1.1.1.1.1.2">ùëá</ci><ci id="S4.SS1.p2.7.m2.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.7.m2.1.1.1.1.1.3">ùëã</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m2.1c">P_{\text{Enc}}(T|X)</annotation></semantics></math><span id="S4.SS1.p2.7.3" class="ltx_text" style="font-size:90%;">.</span></p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.2" class="ltx_Math" alttext="P_{\text{Enc}}(T\,|\,X)={\text{CTC}(\mathbb{H})}" display="block"><semantics id="S4.E2.m1.2a"><mrow id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml"><mrow id="S4.E2.m1.2.2.1" xref="S4.E2.m1.2.2.1.cmml"><msub id="S4.E2.m1.2.2.1.3" xref="S4.E2.m1.2.2.1.3.cmml"><mi mathsize="90%" id="S4.E2.m1.2.2.1.3.2" xref="S4.E2.m1.2.2.1.3.2.cmml">P</mi><mtext mathsize="90%" id="S4.E2.m1.2.2.1.3.3" xref="S4.E2.m1.2.2.1.3.3a.cmml">Enc</mtext></msub><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.1.2" xref="S4.E2.m1.2.2.1.2.cmml">‚Äã</mo><mrow id="S4.E2.m1.2.2.1.1.1" xref="S4.E2.m1.2.2.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E2.m1.2.2.1.1.1.2" xref="S4.E2.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.2.2.1.1.1.1" xref="S4.E2.m1.2.2.1.1.1.1.cmml"><mi mathsize="90%" id="S4.E2.m1.2.2.1.1.1.1.2" xref="S4.E2.m1.2.2.1.1.1.1.2.cmml">T</mi><mo fence="false" lspace="0.448em" mathsize="90%" rspace="0.448em" id="S4.E2.m1.2.2.1.1.1.1.1" xref="S4.E2.m1.2.2.1.1.1.1.1.cmml">|</mo><mi mathsize="90%" id="S4.E2.m1.2.2.1.1.1.1.3" xref="S4.E2.m1.2.2.1.1.1.1.3.cmml">X</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E2.m1.2.2.1.1.1.3" xref="S4.E2.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S4.E2.m1.2.2.2" xref="S4.E2.m1.2.2.2.cmml">=</mo><mrow id="S4.E2.m1.2.2.3" xref="S4.E2.m1.2.2.3.cmml"><mtext mathsize="90%" id="S4.E2.m1.2.2.3.2" xref="S4.E2.m1.2.2.3.2a.cmml">CTC</mtext><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.3.1" xref="S4.E2.m1.2.2.3.1.cmml">‚Äã</mo><mrow id="S4.E2.m1.2.2.3.3.2" xref="S4.E2.m1.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S4.E2.m1.2.2.3.3.2.1" xref="S4.E2.m1.2.2.3.cmml">(</mo><mi mathsize="90%" id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml">‚Ñç</mi><mo maxsize="90%" minsize="90%" id="S4.E2.m1.2.2.3.3.2.2" xref="S4.E2.m1.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.2b"><apply id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2"><eq id="S4.E2.m1.2.2.2.cmml" xref="S4.E2.m1.2.2.2"></eq><apply id="S4.E2.m1.2.2.1.cmml" xref="S4.E2.m1.2.2.1"><times id="S4.E2.m1.2.2.1.2.cmml" xref="S4.E2.m1.2.2.1.2"></times><apply id="S4.E2.m1.2.2.1.3.cmml" xref="S4.E2.m1.2.2.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.1.3.1.cmml" xref="S4.E2.m1.2.2.1.3">subscript</csymbol><ci id="S4.E2.m1.2.2.1.3.2.cmml" xref="S4.E2.m1.2.2.1.3.2">ùëÉ</ci><ci id="S4.E2.m1.2.2.1.3.3a.cmml" xref="S4.E2.m1.2.2.1.3.3"><mtext mathsize="63%" id="S4.E2.m1.2.2.1.3.3.cmml" xref="S4.E2.m1.2.2.1.3.3">Enc</mtext></ci></apply><apply id="S4.E2.m1.2.2.1.1.1.1.cmml" xref="S4.E2.m1.2.2.1.1.1"><csymbol cd="latexml" id="S4.E2.m1.2.2.1.1.1.1.1.cmml" xref="S4.E2.m1.2.2.1.1.1.1.1">conditional</csymbol><ci id="S4.E2.m1.2.2.1.1.1.1.2.cmml" xref="S4.E2.m1.2.2.1.1.1.1.2">ùëá</ci><ci id="S4.E2.m1.2.2.1.1.1.1.3.cmml" xref="S4.E2.m1.2.2.1.1.1.1.3">ùëã</ci></apply></apply><apply id="S4.E2.m1.2.2.3.cmml" xref="S4.E2.m1.2.2.3"><times id="S4.E2.m1.2.2.3.1.cmml" xref="S4.E2.m1.2.2.3.1"></times><ci id="S4.E2.m1.2.2.3.2a.cmml" xref="S4.E2.m1.2.2.3.2"><mtext mathsize="90%" id="S4.E2.m1.2.2.3.2.cmml" xref="S4.E2.m1.2.2.3.2">CTC</mtext></ci><ci id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1">‚Ñç</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.2c">P_{\text{Enc}}(T\,|\,X)={\text{CTC}(\mathbb{H})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.3" class="ltx_p"><span id="S4.SS1.p3.3.1" class="ltx_text" style="font-size:90%;">The decoder, utilizing an auto-regressive approach and denoted by </span><math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="Dec" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mrow id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mi mathsize="90%" id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p3.1.m1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p3.1.m1.1.1.1a" xref="S4.SS1.p3.1.m1.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S4.SS1.p3.1.m1.1.1.4" xref="S4.SS1.p3.1.m1.1.1.4.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><times id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1"></times><ci id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">ùê∑</ci><ci id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3">ùëí</ci><ci id="S4.SS1.p3.1.m1.1.1.4.cmml" xref="S4.SS1.p3.1.m1.1.1.4">ùëê</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">Dec</annotation></semantics></math><span id="S4.SS1.p3.3.2" class="ltx_text" style="font-size:90%;">, predicts the text output </span><math id="S4.SS1.p3.2.m2.4" class="ltx_Math" alttext="Y=\{y_{1},y_{2},\ldots,y_{K}\}" display="inline"><semantics id="S4.SS1.p3.2.m2.4a"><mrow id="S4.SS1.p3.2.m2.4.4" xref="S4.SS1.p3.2.m2.4.4.cmml"><mi mathsize="90%" id="S4.SS1.p3.2.m2.4.4.5" xref="S4.SS1.p3.2.m2.4.4.5.cmml">Y</mi><mo mathsize="90%" id="S4.SS1.p3.2.m2.4.4.4" xref="S4.SS1.p3.2.m2.4.4.4.cmml">=</mo><mrow id="S4.SS1.p3.2.m2.4.4.3.3" xref="S4.SS1.p3.2.m2.4.4.3.4.cmml"><mo maxsize="90%" minsize="90%" id="S4.SS1.p3.2.m2.4.4.3.3.4" xref="S4.SS1.p3.2.m2.4.4.3.4.cmml">{</mo><msub id="S4.SS1.p3.2.m2.2.2.1.1.1" xref="S4.SS1.p3.2.m2.2.2.1.1.1.cmml"><mi mathsize="90%" id="S4.SS1.p3.2.m2.2.2.1.1.1.2" xref="S4.SS1.p3.2.m2.2.2.1.1.1.2.cmml">y</mi><mn mathsize="90%" id="S4.SS1.p3.2.m2.2.2.1.1.1.3" xref="S4.SS1.p3.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo mathsize="90%" id="S4.SS1.p3.2.m2.4.4.3.3.5" xref="S4.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p3.2.m2.3.3.2.2.2" xref="S4.SS1.p3.2.m2.3.3.2.2.2.cmml"><mi mathsize="90%" id="S4.SS1.p3.2.m2.3.3.2.2.2.2" xref="S4.SS1.p3.2.m2.3.3.2.2.2.2.cmml">y</mi><mn mathsize="90%" id="S4.SS1.p3.2.m2.3.3.2.2.2.3" xref="S4.SS1.p3.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo mathsize="90%" id="S4.SS1.p3.2.m2.4.4.3.3.6" xref="S4.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">‚Ä¶</mi><mo mathsize="90%" id="S4.SS1.p3.2.m2.4.4.3.3.7" xref="S4.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><msub id="S4.SS1.p3.2.m2.4.4.3.3.3" xref="S4.SS1.p3.2.m2.4.4.3.3.3.cmml"><mi mathsize="90%" id="S4.SS1.p3.2.m2.4.4.3.3.3.2" xref="S4.SS1.p3.2.m2.4.4.3.3.3.2.cmml">y</mi><mi mathsize="90%" id="S4.SS1.p3.2.m2.4.4.3.3.3.3" xref="S4.SS1.p3.2.m2.4.4.3.3.3.3.cmml">K</mi></msub><mo maxsize="90%" minsize="90%" id="S4.SS1.p3.2.m2.4.4.3.3.8" xref="S4.SS1.p3.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.4b"><apply id="S4.SS1.p3.2.m2.4.4.cmml" xref="S4.SS1.p3.2.m2.4.4"><eq id="S4.SS1.p3.2.m2.4.4.4.cmml" xref="S4.SS1.p3.2.m2.4.4.4"></eq><ci id="S4.SS1.p3.2.m2.4.4.5.cmml" xref="S4.SS1.p3.2.m2.4.4.5">ùëå</ci><set id="S4.SS1.p3.2.m2.4.4.3.4.cmml" xref="S4.SS1.p3.2.m2.4.4.3.3"><apply id="S4.SS1.p3.2.m2.2.2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.2.2.1.1.1.1.cmml" xref="S4.SS1.p3.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.2.m2.2.2.1.1.1.2.cmml" xref="S4.SS1.p3.2.m2.2.2.1.1.1.2">ùë¶</ci><cn type="integer" id="S4.SS1.p3.2.m2.2.2.1.1.1.3.cmml" xref="S4.SS1.p3.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S4.SS1.p3.2.m2.3.3.2.2.2.cmml" xref="S4.SS1.p3.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.3.3.2.2.2.1.cmml" xref="S4.SS1.p3.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S4.SS1.p3.2.m2.3.3.2.2.2.2.cmml" xref="S4.SS1.p3.2.m2.3.3.2.2.2.2">ùë¶</ci><cn type="integer" id="S4.SS1.p3.2.m2.3.3.2.2.2.3.cmml" xref="S4.SS1.p3.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">‚Ä¶</ci><apply id="S4.SS1.p3.2.m2.4.4.3.3.3.cmml" xref="S4.SS1.p3.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.4.4.3.3.3.1.cmml" xref="S4.SS1.p3.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S4.SS1.p3.2.m2.4.4.3.3.3.2.cmml" xref="S4.SS1.p3.2.m2.4.4.3.3.3.2">ùë¶</ci><ci id="S4.SS1.p3.2.m2.4.4.3.3.3.3.cmml" xref="S4.SS1.p3.2.m2.4.4.3.3.3.3">ùêæ</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.4c">Y=\{y_{1},y_{2},\ldots,y_{K}\}</annotation></semantics></math><span id="S4.SS1.p3.3.3" class="ltx_text" style="font-size:90%;"> given the acoustic embeddings </span><math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mi mathsize="90%" id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><ci id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">H</annotation></semantics></math><span id="S4.SS1.p3.3.4" class="ltx_text" style="font-size:90%;">.</span></p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.4" class="ltx_Math" alttext="P(y_{k}|X,Y_{1:k-1})=\text{Dec}(\mathbb{H},T_{1:k-1})" display="block"><semantics id="S4.E3.m1.4a"><mrow id="S4.E3.m1.4.4" xref="S4.E3.m1.4.4.cmml"><mrow id="S4.E3.m1.3.3.1" xref="S4.E3.m1.3.3.1.cmml"><mi mathsize="90%" id="S4.E3.m1.3.3.1.3" xref="S4.E3.m1.3.3.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.3.3.1.2" xref="S4.E3.m1.3.3.1.2.cmml">‚Äã</mo><mrow id="S4.E3.m1.3.3.1.1.1" xref="S4.E3.m1.3.3.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E3.m1.3.3.1.1.1.2" xref="S4.E3.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S4.E3.m1.3.3.1.1.1.1" xref="S4.E3.m1.3.3.1.1.1.1.cmml"><msub id="S4.E3.m1.3.3.1.1.1.1.3" xref="S4.E3.m1.3.3.1.1.1.1.3.cmml"><mi mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.3.2" xref="S4.E3.m1.3.3.1.1.1.1.3.2.cmml">y</mi><mi mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.3.3" xref="S4.E3.m1.3.3.1.1.1.1.3.3.cmml">k</mi></msub><mo fence="false" mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.2" xref="S4.E3.m1.3.3.1.1.1.1.2.cmml">|</mo><mrow id="S4.E3.m1.3.3.1.1.1.1.1.1" xref="S4.E3.m1.3.3.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml">X</mi><mo mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.1.1.2" xref="S4.E3.m1.3.3.1.1.1.1.1.2.cmml">,</mo><msub id="S4.E3.m1.3.3.1.1.1.1.1.1.1" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml">Y</mi><mrow id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml"><mn mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.2" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" mathsize="90%" rspace="0.278em" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.1" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.1.cmml">:</mo><mrow id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.cmml"><mi mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.2" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.2.cmml">k</mi><mo mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.1" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.1.cmml">‚àí</mo><mn mathsize="90%" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.3" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></mrow></msub></mrow></mrow><mo maxsize="90%" minsize="90%" id="S4.E3.m1.3.3.1.1.1.3" xref="S4.E3.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S4.E3.m1.4.4.3" xref="S4.E3.m1.4.4.3.cmml">=</mo><mrow id="S4.E3.m1.4.4.2" xref="S4.E3.m1.4.4.2.cmml"><mtext mathsize="90%" id="S4.E3.m1.4.4.2.3" xref="S4.E3.m1.4.4.2.3a.cmml">Dec</mtext><mo lspace="0em" rspace="0em" id="S4.E3.m1.4.4.2.2" xref="S4.E3.m1.4.4.2.2.cmml">‚Äã</mo><mrow id="S4.E3.m1.4.4.2.1.1" xref="S4.E3.m1.4.4.2.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S4.E3.m1.4.4.2.1.1.2" xref="S4.E3.m1.4.4.2.1.2.cmml">(</mo><mi mathsize="90%" id="S4.E3.m1.2.2" xref="S4.E3.m1.2.2.cmml">‚Ñç</mi><mo mathsize="90%" id="S4.E3.m1.4.4.2.1.1.3" xref="S4.E3.m1.4.4.2.1.2.cmml">,</mo><msub id="S4.E3.m1.4.4.2.1.1.1" xref="S4.E3.m1.4.4.2.1.1.1.cmml"><mi mathsize="90%" id="S4.E3.m1.4.4.2.1.1.1.2" xref="S4.E3.m1.4.4.2.1.1.1.2.cmml">T</mi><mrow id="S4.E3.m1.4.4.2.1.1.1.3" xref="S4.E3.m1.4.4.2.1.1.1.3.cmml"><mn mathsize="90%" id="S4.E3.m1.4.4.2.1.1.1.3.2" xref="S4.E3.m1.4.4.2.1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" mathsize="90%" rspace="0.278em" id="S4.E3.m1.4.4.2.1.1.1.3.1" xref="S4.E3.m1.4.4.2.1.1.1.3.1.cmml">:</mo><mrow id="S4.E3.m1.4.4.2.1.1.1.3.3" xref="S4.E3.m1.4.4.2.1.1.1.3.3.cmml"><mi mathsize="90%" id="S4.E3.m1.4.4.2.1.1.1.3.3.2" xref="S4.E3.m1.4.4.2.1.1.1.3.3.2.cmml">k</mi><mo mathsize="90%" id="S4.E3.m1.4.4.2.1.1.1.3.3.1" xref="S4.E3.m1.4.4.2.1.1.1.3.3.1.cmml">‚àí</mo><mn mathsize="90%" id="S4.E3.m1.4.4.2.1.1.1.3.3.3" xref="S4.E3.m1.4.4.2.1.1.1.3.3.3.cmml">1</mn></mrow></mrow></msub><mo maxsize="90%" minsize="90%" id="S4.E3.m1.4.4.2.1.1.4" xref="S4.E3.m1.4.4.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.4b"><apply id="S4.E3.m1.4.4.cmml" xref="S4.E3.m1.4.4"><eq id="S4.E3.m1.4.4.3.cmml" xref="S4.E3.m1.4.4.3"></eq><apply id="S4.E3.m1.3.3.1.cmml" xref="S4.E3.m1.3.3.1"><times id="S4.E3.m1.3.3.1.2.cmml" xref="S4.E3.m1.3.3.1.2"></times><ci id="S4.E3.m1.3.3.1.3.cmml" xref="S4.E3.m1.3.3.1.3">ùëÉ</ci><apply id="S4.E3.m1.3.3.1.1.1.1.cmml" xref="S4.E3.m1.3.3.1.1.1"><csymbol cd="latexml" id="S4.E3.m1.3.3.1.1.1.1.2.cmml" xref="S4.E3.m1.3.3.1.1.1.1.2">conditional</csymbol><apply id="S4.E3.m1.3.3.1.1.1.1.3.cmml" xref="S4.E3.m1.3.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S4.E3.m1.3.3.1.1.1.1.3">subscript</csymbol><ci id="S4.E3.m1.3.3.1.1.1.1.3.2.cmml" xref="S4.E3.m1.3.3.1.1.1.1.3.2">ùë¶</ci><ci id="S4.E3.m1.3.3.1.1.1.1.3.3.cmml" xref="S4.E3.m1.3.3.1.1.1.1.3.3">ùëò</ci></apply><list id="S4.E3.m1.3.3.1.1.1.1.1.2.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1"><ci id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1">ùëã</ci><apply id="S4.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.2">ùëå</ci><apply id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3"><ci id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.1">:</ci><cn type="integer" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.2">1</cn><apply id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3"><minus id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.1"></minus><ci id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.2">ùëò</ci><cn type="integer" id="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E3.m1.3.3.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></list></apply></apply><apply id="S4.E3.m1.4.4.2.cmml" xref="S4.E3.m1.4.4.2"><times id="S4.E3.m1.4.4.2.2.cmml" xref="S4.E3.m1.4.4.2.2"></times><ci id="S4.E3.m1.4.4.2.3a.cmml" xref="S4.E3.m1.4.4.2.3"><mtext mathsize="90%" id="S4.E3.m1.4.4.2.3.cmml" xref="S4.E3.m1.4.4.2.3">Dec</mtext></ci><interval closure="open" id="S4.E3.m1.4.4.2.1.2.cmml" xref="S4.E3.m1.4.4.2.1.1"><ci id="S4.E3.m1.2.2.cmml" xref="S4.E3.m1.2.2">‚Ñç</ci><apply id="S4.E3.m1.4.4.2.1.1.1.cmml" xref="S4.E3.m1.4.4.2.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.4.4.2.1.1.1.1.cmml" xref="S4.E3.m1.4.4.2.1.1.1">subscript</csymbol><ci id="S4.E3.m1.4.4.2.1.1.1.2.cmml" xref="S4.E3.m1.4.4.2.1.1.1.2">ùëá</ci><apply id="S4.E3.m1.4.4.2.1.1.1.3.cmml" xref="S4.E3.m1.4.4.2.1.1.1.3"><ci id="S4.E3.m1.4.4.2.1.1.1.3.1.cmml" xref="S4.E3.m1.4.4.2.1.1.1.3.1">:</ci><cn type="integer" id="S4.E3.m1.4.4.2.1.1.1.3.2.cmml" xref="S4.E3.m1.4.4.2.1.1.1.3.2">1</cn><apply id="S4.E3.m1.4.4.2.1.1.1.3.3.cmml" xref="S4.E3.m1.4.4.2.1.1.1.3.3"><minus id="S4.E3.m1.4.4.2.1.1.1.3.3.1.cmml" xref="S4.E3.m1.4.4.2.1.1.1.3.3.1"></minus><ci id="S4.E3.m1.4.4.2.1.1.1.3.3.2.cmml" xref="S4.E3.m1.4.4.2.1.1.1.3.3.2">ùëò</ci><cn type="integer" id="S4.E3.m1.4.4.2.1.1.1.3.3.3.cmml" xref="S4.E3.m1.4.4.2.1.1.1.3.3.3">1</cn></apply></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.4c">P(y_{k}|X,Y_{1:k-1})=\text{Dec}(\mathbb{H},T_{1:k-1})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.3" class="ltx_Math" alttext="P_{\text{Dec}}(T|X)\approx\prod_{k}^{K}P(t_{k}|X,T_{1:k-1})" display="block"><semantics id="S4.E4.m1.3a"><mrow id="S4.E4.m1.3.3" xref="S4.E4.m1.3.3.cmml"><mrow id="S4.E4.m1.2.2.1" xref="S4.E4.m1.2.2.1.cmml"><msub id="S4.E4.m1.2.2.1.3" xref="S4.E4.m1.2.2.1.3.cmml"><mi mathsize="90%" id="S4.E4.m1.2.2.1.3.2" xref="S4.E4.m1.2.2.1.3.2.cmml">P</mi><mtext mathsize="90%" id="S4.E4.m1.2.2.1.3.3" xref="S4.E4.m1.2.2.1.3.3a.cmml">Dec</mtext></msub><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.1.2" xref="S4.E4.m1.2.2.1.2.cmml">‚Äã</mo><mrow id="S4.E4.m1.2.2.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E4.m1.2.2.1.1.1.2" xref="S4.E4.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.2.2.1.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.cmml"><mi mathsize="90%" id="S4.E4.m1.2.2.1.1.1.1.2" xref="S4.E4.m1.2.2.1.1.1.1.2.cmml">T</mi><mo fence="false" mathsize="90%" id="S4.E4.m1.2.2.1.1.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.1.cmml">|</mo><mi mathsize="90%" id="S4.E4.m1.2.2.1.1.1.1.3" xref="S4.E4.m1.2.2.1.1.1.1.3.cmml">X</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E4.m1.2.2.1.1.1.3" xref="S4.E4.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" rspace="0.111em" id="S4.E4.m1.3.3.3" xref="S4.E4.m1.3.3.3.cmml">‚âà</mo><mrow id="S4.E4.m1.3.3.2" xref="S4.E4.m1.3.3.2.cmml"><munderover id="S4.E4.m1.3.3.2.2" xref="S4.E4.m1.3.3.2.2.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" id="S4.E4.m1.3.3.2.2.2.2" xref="S4.E4.m1.3.3.2.2.2.2.cmml">‚àè</mo><mi mathsize="90%" id="S4.E4.m1.3.3.2.2.2.3" xref="S4.E4.m1.3.3.2.2.2.3.cmml">k</mi><mi mathsize="90%" id="S4.E4.m1.3.3.2.2.3" xref="S4.E4.m1.3.3.2.2.3.cmml">K</mi></munderover><mrow id="S4.E4.m1.3.3.2.1" xref="S4.E4.m1.3.3.2.1.cmml"><mi mathsize="90%" id="S4.E4.m1.3.3.2.1.3" xref="S4.E4.m1.3.3.2.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.3.3.2.1.2" xref="S4.E4.m1.3.3.2.1.2.cmml">‚Äã</mo><mrow id="S4.E4.m1.3.3.2.1.1.1" xref="S4.E4.m1.3.3.2.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E4.m1.3.3.2.1.1.1.2" xref="S4.E4.m1.3.3.2.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.3.3.2.1.1.1.1" xref="S4.E4.m1.3.3.2.1.1.1.1.cmml"><msub id="S4.E4.m1.3.3.2.1.1.1.1.3" xref="S4.E4.m1.3.3.2.1.1.1.1.3.cmml"><mi mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.3.2" xref="S4.E4.m1.3.3.2.1.1.1.1.3.2.cmml">t</mi><mi mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.3.3" xref="S4.E4.m1.3.3.2.1.1.1.1.3.3.cmml">k</mi></msub><mo fence="false" mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.2" xref="S4.E4.m1.3.3.2.1.1.1.1.2.cmml">|</mo><mrow id="S4.E4.m1.3.3.2.1.1.1.1.1.1" xref="S4.E4.m1.3.3.2.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml">X</mi><mo mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.2" xref="S4.E4.m1.3.3.2.1.1.1.1.1.2.cmml">,</mo><msub id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.2" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.2.cmml">T</mi><mrow id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.cmml"><mn mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.2" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" mathsize="90%" rspace="0.278em" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.1" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.1.cmml">:</mo><mrow id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.cmml"><mi mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.2" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.2.cmml">k</mi><mo mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.1" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.1.cmml">‚àí</mo><mn mathsize="90%" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.3" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></mrow></msub></mrow></mrow><mo maxsize="90%" minsize="90%" id="S4.E4.m1.3.3.2.1.1.1.3" xref="S4.E4.m1.3.3.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.3b"><apply id="S4.E4.m1.3.3.cmml" xref="S4.E4.m1.3.3"><approx id="S4.E4.m1.3.3.3.cmml" xref="S4.E4.m1.3.3.3"></approx><apply id="S4.E4.m1.2.2.1.cmml" xref="S4.E4.m1.2.2.1"><times id="S4.E4.m1.2.2.1.2.cmml" xref="S4.E4.m1.2.2.1.2"></times><apply id="S4.E4.m1.2.2.1.3.cmml" xref="S4.E4.m1.2.2.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.3.1.cmml" xref="S4.E4.m1.2.2.1.3">subscript</csymbol><ci id="S4.E4.m1.2.2.1.3.2.cmml" xref="S4.E4.m1.2.2.1.3.2">ùëÉ</ci><ci id="S4.E4.m1.2.2.1.3.3a.cmml" xref="S4.E4.m1.2.2.1.3.3"><mtext mathsize="63%" id="S4.E4.m1.2.2.1.3.3.cmml" xref="S4.E4.m1.2.2.1.3.3">Dec</mtext></ci></apply><apply id="S4.E4.m1.2.2.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1"><csymbol cd="latexml" id="S4.E4.m1.2.2.1.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1.1.1">conditional</csymbol><ci id="S4.E4.m1.2.2.1.1.1.1.2.cmml" xref="S4.E4.m1.2.2.1.1.1.1.2">ùëá</ci><ci id="S4.E4.m1.2.2.1.1.1.1.3.cmml" xref="S4.E4.m1.2.2.1.1.1.1.3">ùëã</ci></apply></apply><apply id="S4.E4.m1.3.3.2.cmml" xref="S4.E4.m1.3.3.2"><apply id="S4.E4.m1.3.3.2.2.cmml" xref="S4.E4.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.2.2.1.cmml" xref="S4.E4.m1.3.3.2.2">superscript</csymbol><apply id="S4.E4.m1.3.3.2.2.2.cmml" xref="S4.E4.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.2.2.2.1.cmml" xref="S4.E4.m1.3.3.2.2">subscript</csymbol><csymbol cd="latexml" id="S4.E4.m1.3.3.2.2.2.2.cmml" xref="S4.E4.m1.3.3.2.2.2.2">product</csymbol><ci id="S4.E4.m1.3.3.2.2.2.3.cmml" xref="S4.E4.m1.3.3.2.2.2.3">ùëò</ci></apply><ci id="S4.E4.m1.3.3.2.2.3.cmml" xref="S4.E4.m1.3.3.2.2.3">ùêæ</ci></apply><apply id="S4.E4.m1.3.3.2.1.cmml" xref="S4.E4.m1.3.3.2.1"><times id="S4.E4.m1.3.3.2.1.2.cmml" xref="S4.E4.m1.3.3.2.1.2"></times><ci id="S4.E4.m1.3.3.2.1.3.cmml" xref="S4.E4.m1.3.3.2.1.3">ùëÉ</ci><apply id="S4.E4.m1.3.3.2.1.1.1.1.cmml" xref="S4.E4.m1.3.3.2.1.1.1"><csymbol cd="latexml" id="S4.E4.m1.3.3.2.1.1.1.1.2.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.2">conditional</csymbol><apply id="S4.E4.m1.3.3.2.1.1.1.1.3.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.2.1.1.1.1.3.1.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.3.3.2.1.1.1.1.3.2.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.3.2">ùë°</ci><ci id="S4.E4.m1.3.3.2.1.1.1.1.3.3.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.3.3">ùëò</ci></apply><list id="S4.E4.m1.3.3.2.1.1.1.1.1.2.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1"><ci id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1">ùëã</ci><apply id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.2">ùëá</ci><apply id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3"><ci id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.1">:</ci><cn type="integer" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.2">1</cn><apply id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3"><minus id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.1"></minus><ci id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.2">ùëò</ci><cn type="integer" id="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E4.m1.3.3.2.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.3c">P_{\text{Dec}}(T|X)\approx\prod_{k}^{K}P(t_{k}|X,T_{1:k-1})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text" style="font-size:90%;">During training, the model is optimized using the weighted sum of the CTC loss and the decoder loss, with a weight set to 0.3 . The final hypothesis is generated during inference by jointly decoding the output of the encoder and decoder using beam search. This hybrid approach effectively combines the robust alignment capabilities of CTC with the contextual sensitivity of the attention mechanism to improve ASR performance.</span></p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Intermediate CTC</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">Intermediate CTC (InterCTC) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S4.SS2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p1.1.4" class="ltx_text" style="font-size:90%;"> was introduced as a regularization technique for deep encoder networks and to facilitate multi-task learning </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S4.SS2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p1.1.7" class="ltx_text" style="font-size:90%;">. A CTC module is applied to the output of an intermediate encoder layer with index </span><math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi mathsize="90%" id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">ùëí</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">e</annotation></semantics></math><span id="S4.SS2.p1.1.8" class="ltx_text" style="font-size:90%;">. Self-conditioned CTC is also applied, where subsequent encoder layers incorporate these intermediate predictions into their input. The rearranged Equation 1 is expressed as follows:</span></p>
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.1" class="ltx_Math" alttext="\mathbb{H}_{e}=\text{Enc}_{1:e}(\mathbb{X})" display="block"><semantics id="S4.E5.m1.1a"><mrow id="S4.E5.m1.1.2" xref="S4.E5.m1.1.2.cmml"><msub id="S4.E5.m1.1.2.2" xref="S4.E5.m1.1.2.2.cmml"><mi mathsize="90%" id="S4.E5.m1.1.2.2.2" xref="S4.E5.m1.1.2.2.2.cmml">‚Ñç</mi><mi mathsize="90%" id="S4.E5.m1.1.2.2.3" xref="S4.E5.m1.1.2.2.3.cmml">e</mi></msub><mo mathsize="90%" id="S4.E5.m1.1.2.1" xref="S4.E5.m1.1.2.1.cmml">=</mo><mrow id="S4.E5.m1.1.2.3" xref="S4.E5.m1.1.2.3.cmml"><msub id="S4.E5.m1.1.2.3.2" xref="S4.E5.m1.1.2.3.2.cmml"><mtext mathsize="90%" id="S4.E5.m1.1.2.3.2.2" xref="S4.E5.m1.1.2.3.2.2a.cmml">Enc</mtext><mrow id="S4.E5.m1.1.2.3.2.3" xref="S4.E5.m1.1.2.3.2.3.cmml"><mn mathsize="90%" id="S4.E5.m1.1.2.3.2.3.2" xref="S4.E5.m1.1.2.3.2.3.2.cmml">1</mn><mo lspace="0.278em" mathsize="90%" rspace="0.278em" id="S4.E5.m1.1.2.3.2.3.1" xref="S4.E5.m1.1.2.3.2.3.1.cmml">:</mo><mi mathsize="90%" id="S4.E5.m1.1.2.3.2.3.3" xref="S4.E5.m1.1.2.3.2.3.3.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E5.m1.1.2.3.1" xref="S4.E5.m1.1.2.3.1.cmml">‚Äã</mo><mrow id="S4.E5.m1.1.2.3.3.2" xref="S4.E5.m1.1.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S4.E5.m1.1.2.3.3.2.1" xref="S4.E5.m1.1.2.3.cmml">(</mo><mi mathsize="90%" id="S4.E5.m1.1.1" xref="S4.E5.m1.1.1.cmml">ùïè</mi><mo maxsize="90%" minsize="90%" id="S4.E5.m1.1.2.3.3.2.2" xref="S4.E5.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.1b"><apply id="S4.E5.m1.1.2.cmml" xref="S4.E5.m1.1.2"><eq id="S4.E5.m1.1.2.1.cmml" xref="S4.E5.m1.1.2.1"></eq><apply id="S4.E5.m1.1.2.2.cmml" xref="S4.E5.m1.1.2.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.2.2.1.cmml" xref="S4.E5.m1.1.2.2">subscript</csymbol><ci id="S4.E5.m1.1.2.2.2.cmml" xref="S4.E5.m1.1.2.2.2">‚Ñç</ci><ci id="S4.E5.m1.1.2.2.3.cmml" xref="S4.E5.m1.1.2.2.3">ùëí</ci></apply><apply id="S4.E5.m1.1.2.3.cmml" xref="S4.E5.m1.1.2.3"><times id="S4.E5.m1.1.2.3.1.cmml" xref="S4.E5.m1.1.2.3.1"></times><apply id="S4.E5.m1.1.2.3.2.cmml" xref="S4.E5.m1.1.2.3.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.2.3.2.1.cmml" xref="S4.E5.m1.1.2.3.2">subscript</csymbol><ci id="S4.E5.m1.1.2.3.2.2a.cmml" xref="S4.E5.m1.1.2.3.2.2"><mtext mathsize="90%" id="S4.E5.m1.1.2.3.2.2.cmml" xref="S4.E5.m1.1.2.3.2.2">Enc</mtext></ci><apply id="S4.E5.m1.1.2.3.2.3.cmml" xref="S4.E5.m1.1.2.3.2.3"><ci id="S4.E5.m1.1.2.3.2.3.1.cmml" xref="S4.E5.m1.1.2.3.2.3.1">:</ci><cn type="integer" id="S4.E5.m1.1.2.3.2.3.2.cmml" xref="S4.E5.m1.1.2.3.2.3.2">1</cn><ci id="S4.E5.m1.1.2.3.2.3.3.cmml" xref="S4.E5.m1.1.2.3.2.3.3">ùëí</ci></apply></apply><ci id="S4.E5.m1.1.1.cmml" xref="S4.E5.m1.1.1">ùïè</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.1c">\mathbb{H}_{e}=\text{Enc}_{1:e}(\mathbb{X})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<table id="S4.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E6.m1.2" class="ltx_Math" alttext="P(Z_{\text{Inter}}|X)=\text{CTC}(\mathbb{H}_{e})" display="block"><semantics id="S4.E6.m1.2a"><mrow id="S4.E6.m1.2.2" xref="S4.E6.m1.2.2.cmml"><mrow id="S4.E6.m1.1.1.1" xref="S4.E6.m1.1.1.1.cmml"><mi mathsize="90%" id="S4.E6.m1.1.1.1.3" xref="S4.E6.m1.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.2" xref="S4.E6.m1.1.1.1.2.cmml">‚Äã</mo><mrow id="S4.E6.m1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E6.m1.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E6.m1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.cmml"><msub id="S4.E6.m1.1.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S4.E6.m1.1.1.1.1.1.1.2.2" xref="S4.E6.m1.1.1.1.1.1.1.2.2.cmml">Z</mi><mtext mathsize="90%" id="S4.E6.m1.1.1.1.1.1.1.2.3" xref="S4.E6.m1.1.1.1.1.1.1.2.3a.cmml">Inter</mtext></msub><mo fence="false" mathsize="90%" id="S4.E6.m1.1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.1.cmml">|</mo><mi mathsize="90%" id="S4.E6.m1.1.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.1.1.3.cmml">X</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E6.m1.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S4.E6.m1.2.2.3" xref="S4.E6.m1.2.2.3.cmml">=</mo><mrow id="S4.E6.m1.2.2.2" xref="S4.E6.m1.2.2.2.cmml"><mtext mathsize="90%" id="S4.E6.m1.2.2.2.3" xref="S4.E6.m1.2.2.2.3a.cmml">CTC</mtext><mo lspace="0em" rspace="0em" id="S4.E6.m1.2.2.2.2" xref="S4.E6.m1.2.2.2.2.cmml">‚Äã</mo><mrow id="S4.E6.m1.2.2.2.1.1" xref="S4.E6.m1.2.2.2.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E6.m1.2.2.2.1.1.2" xref="S4.E6.m1.2.2.2.1.1.1.cmml">(</mo><msub id="S4.E6.m1.2.2.2.1.1.1" xref="S4.E6.m1.2.2.2.1.1.1.cmml"><mi mathsize="90%" id="S4.E6.m1.2.2.2.1.1.1.2" xref="S4.E6.m1.2.2.2.1.1.1.2.cmml">‚Ñç</mi><mi mathsize="90%" id="S4.E6.m1.2.2.2.1.1.1.3" xref="S4.E6.m1.2.2.2.1.1.1.3.cmml">e</mi></msub><mo maxsize="90%" minsize="90%" id="S4.E6.m1.2.2.2.1.1.3" xref="S4.E6.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.2b"><apply id="S4.E6.m1.2.2.cmml" xref="S4.E6.m1.2.2"><eq id="S4.E6.m1.2.2.3.cmml" xref="S4.E6.m1.2.2.3"></eq><apply id="S4.E6.m1.1.1.1.cmml" xref="S4.E6.m1.1.1.1"><times id="S4.E6.m1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.2"></times><ci id="S4.E6.m1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.3">ùëÉ</ci><apply id="S4.E6.m1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E6.m1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.E6.m1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.1.1.2.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.2.2">ùëç</ci><ci id="S4.E6.m1.1.1.1.1.1.1.2.3a.cmml" xref="S4.E6.m1.1.1.1.1.1.1.2.3"><mtext mathsize="63%" id="S4.E6.m1.1.1.1.1.1.1.2.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.2.3">Inter</mtext></ci></apply><ci id="S4.E6.m1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.3">ùëã</ci></apply></apply><apply id="S4.E6.m1.2.2.2.cmml" xref="S4.E6.m1.2.2.2"><times id="S4.E6.m1.2.2.2.2.cmml" xref="S4.E6.m1.2.2.2.2"></times><ci id="S4.E6.m1.2.2.2.3a.cmml" xref="S4.E6.m1.2.2.2.3"><mtext mathsize="90%" id="S4.E6.m1.2.2.2.3.cmml" xref="S4.E6.m1.2.2.2.3">CTC</mtext></ci><apply id="S4.E6.m1.2.2.2.1.1.1.cmml" xref="S4.E6.m1.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.E6.m1.2.2.2.1.1.1.1.cmml" xref="S4.E6.m1.2.2.2.1.1">subscript</csymbol><ci id="S4.E6.m1.2.2.2.1.1.1.2.cmml" xref="S4.E6.m1.2.2.2.1.1.1.2">‚Ñç</ci><ci id="S4.E6.m1.2.2.2.1.1.1.3.cmml" xref="S4.E6.m1.2.2.2.1.1.1.3">ùëí</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.2c">P(Z_{\text{Inter}}|X)=\text{CTC}(\mathbb{H}_{e})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<table id="S4.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E7.m1.1" class="ltx_Math" alttext="\mathbb{H}=\text{Enc}_{e+1:E}(\texttt{NRM}(\mathbb{H}_{e})+\texttt{LIN}(Z_{\text{Inter}}))" display="block"><semantics id="S4.E7.m1.1a"><mrow id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml"><mi mathsize="90%" id="S4.E7.m1.1.1.3" xref="S4.E7.m1.1.1.3.cmml">‚Ñç</mi><mo mathsize="90%" id="S4.E7.m1.1.1.2" xref="S4.E7.m1.1.1.2.cmml">=</mo><mrow id="S4.E7.m1.1.1.1" xref="S4.E7.m1.1.1.1.cmml"><msub id="S4.E7.m1.1.1.1.3" xref="S4.E7.m1.1.1.1.3.cmml"><mtext mathsize="90%" id="S4.E7.m1.1.1.1.3.2" xref="S4.E7.m1.1.1.1.3.2a.cmml">Enc</mtext><mrow id="S4.E7.m1.1.1.1.3.3" xref="S4.E7.m1.1.1.1.3.3.cmml"><mrow id="S4.E7.m1.1.1.1.3.3.2" xref="S4.E7.m1.1.1.1.3.3.2.cmml"><mi mathsize="90%" id="S4.E7.m1.1.1.1.3.3.2.2" xref="S4.E7.m1.1.1.1.3.3.2.2.cmml">e</mi><mo mathsize="90%" id="S4.E7.m1.1.1.1.3.3.2.1" xref="S4.E7.m1.1.1.1.3.3.2.1.cmml">+</mo><mn mathsize="90%" id="S4.E7.m1.1.1.1.3.3.2.3" xref="S4.E7.m1.1.1.1.3.3.2.3.cmml">1</mn></mrow><mo lspace="0.278em" mathsize="90%" rspace="0.278em" id="S4.E7.m1.1.1.1.3.3.1" xref="S4.E7.m1.1.1.1.3.3.1.cmml">:</mo><mi mathsize="90%" id="S4.E7.m1.1.1.1.3.3.3" xref="S4.E7.m1.1.1.1.3.3.3.cmml">E</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E7.m1.1.1.1.2" xref="S4.E7.m1.1.1.1.2.cmml">‚Äã</mo><mrow id="S4.E7.m1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E7.m1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E7.m1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.cmml"><mrow id="S4.E7.m1.1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.1.3a.cmml">NRM</mtext><mo lspace="0em" rspace="0em" id="S4.E7.m1.1.1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S4.E7.m1.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">‚Ñç</mi><mi mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">e</mi></msub><mo maxsize="90%" minsize="90%" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.3.cmml">+</mo><mrow id="S4.E7.m1.1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.2.3" xref="S4.E7.m1.1.1.1.1.1.1.2.3a.cmml">LIN</mtext><mo lspace="0em" rspace="0em" id="S4.E7.m1.1.1.1.1.1.1.2.2" xref="S4.E7.m1.1.1.1.1.1.1.2.2.cmml">‚Äã</mo><mrow id="S4.E7.m1.1.1.1.1.1.1.2.1.1" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E7.m1.1.1.1.1.1.1.2.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msub id="S4.E7.m1.1.1.1.1.1.1.2.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.cmml"><mi mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.2.cmml">Z</mi><mtext mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.3a.cmml">Inter</mtext></msub><mo maxsize="90%" minsize="90%" id="S4.E7.m1.1.1.1.1.1.1.2.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo maxsize="90%" minsize="90%" id="S4.E7.m1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.1b"><apply id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1"><eq id="S4.E7.m1.1.1.2.cmml" xref="S4.E7.m1.1.1.2"></eq><ci id="S4.E7.m1.1.1.3.cmml" xref="S4.E7.m1.1.1.3">‚Ñç</ci><apply id="S4.E7.m1.1.1.1.cmml" xref="S4.E7.m1.1.1.1"><times id="S4.E7.m1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.2"></times><apply id="S4.E7.m1.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.3.1.cmml" xref="S4.E7.m1.1.1.1.3">subscript</csymbol><ci id="S4.E7.m1.1.1.1.3.2a.cmml" xref="S4.E7.m1.1.1.1.3.2"><mtext mathsize="90%" id="S4.E7.m1.1.1.1.3.2.cmml" xref="S4.E7.m1.1.1.1.3.2">Enc</mtext></ci><apply id="S4.E7.m1.1.1.1.3.3.cmml" xref="S4.E7.m1.1.1.1.3.3"><ci id="S4.E7.m1.1.1.1.3.3.1.cmml" xref="S4.E7.m1.1.1.1.3.3.1">:</ci><apply id="S4.E7.m1.1.1.1.3.3.2.cmml" xref="S4.E7.m1.1.1.1.3.3.2"><plus id="S4.E7.m1.1.1.1.3.3.2.1.cmml" xref="S4.E7.m1.1.1.1.3.3.2.1"></plus><ci id="S4.E7.m1.1.1.1.3.3.2.2.cmml" xref="S4.E7.m1.1.1.1.3.3.2.2">ùëí</ci><cn type="integer" id="S4.E7.m1.1.1.1.3.3.2.3.cmml" xref="S4.E7.m1.1.1.1.3.3.2.3">1</cn></apply><ci id="S4.E7.m1.1.1.1.3.3.3.cmml" xref="S4.E7.m1.1.1.1.3.3.3">ùê∏</ci></apply></apply><apply id="S4.E7.m1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1"><plus id="S4.E7.m1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.3"></plus><apply id="S4.E7.m1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1"><times id="S4.E7.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.2"></times><ci id="S4.E7.m1.1.1.1.1.1.1.1.3a.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.3">NRM</mtext></ci><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.2">‚Ñç</ci><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.3">ùëí</ci></apply></apply><apply id="S4.E7.m1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2"><times id="S4.E7.m1.1.1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2.2"></times><ci id="S4.E7.m1.1.1.1.1.1.1.2.3a.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="90%" id="S4.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2.3">LIN</mtext></ci><apply id="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.2">ùëç</ci><ci id="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.3a.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.3"><mtext mathsize="63%" id="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.2.1.1.1.3">Inter</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.1c">\mathbb{H}=\text{Enc}_{e+1:E}(\texttt{NRM}(\mathbb{H}_{e})+\texttt{LIN}(Z_{\text{Inter}}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.5" class="ltx_p"><span id="S4.SS2.p1.5.1" class="ltx_text" style="font-size:90%;">where
</span><math id="S4.SS2.p1.2.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S4.SS2.p1.2.m1.1a"><mi mathsize="90%" id="S4.SS2.p1.2.m1.1.1" xref="S4.SS2.p1.2.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m1.1b"><ci id="S4.SS2.p1.2.m1.1.1.cmml" xref="S4.SS2.p1.2.m1.1.1">ùê∏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m1.1c">E</annotation></semantics></math><span id="S4.SS2.p1.5.2" class="ltx_text" style="font-size:90%;"> represents the encoder layers, and </span><math id="S4.SS2.p1.3.m2.1" class="ltx_Math" alttext="Z_{\text{Inter}}" display="inline"><semantics id="S4.SS2.p1.3.m2.1a"><msub id="S4.SS2.p1.3.m2.1.1" xref="S4.SS2.p1.3.m2.1.1.cmml"><mi mathsize="90%" id="S4.SS2.p1.3.m2.1.1.2" xref="S4.SS2.p1.3.m2.1.1.2.cmml">Z</mi><mtext mathsize="90%" id="S4.SS2.p1.3.m2.1.1.3" xref="S4.SS2.p1.3.m2.1.1.3a.cmml">Inter</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m2.1b"><apply id="S4.SS2.p1.3.m2.1.1.cmml" xref="S4.SS2.p1.3.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m2.1.1.1.cmml" xref="S4.SS2.p1.3.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.3.m2.1.1.2.cmml" xref="S4.SS2.p1.3.m2.1.1.2">ùëç</ci><ci id="S4.SS2.p1.3.m2.1.1.3a.cmml" xref="S4.SS2.p1.3.m2.1.1.3"><mtext mathsize="63%" id="S4.SS2.p1.3.m2.1.1.3.cmml" xref="S4.SS2.p1.3.m2.1.1.3">Inter</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m2.1c">Z_{\text{Inter}}</annotation></semantics></math><span id="S4.SS2.p1.5.3" class="ltx_text" style="font-size:90%;"> is the latent sequence of the InterCTC target sequence </span><math id="S4.SS2.p1.4.m3.3" class="ltx_Math" alttext="T_{\text{Inter}}=(t^{\prime}_{k}|k=1,...,K^{\prime})" display="inline"><semantics id="S4.SS2.p1.4.m3.3a"><mrow id="S4.SS2.p1.4.m3.3.3" xref="S4.SS2.p1.4.m3.3.3.cmml"><msub id="S4.SS2.p1.4.m3.3.3.3" xref="S4.SS2.p1.4.m3.3.3.3.cmml"><mi mathsize="90%" id="S4.SS2.p1.4.m3.3.3.3.2" xref="S4.SS2.p1.4.m3.3.3.3.2.cmml">T</mi><mtext mathsize="90%" id="S4.SS2.p1.4.m3.3.3.3.3" xref="S4.SS2.p1.4.m3.3.3.3.3a.cmml">Inter</mtext></msub><mo mathsize="90%" id="S4.SS2.p1.4.m3.3.3.2" xref="S4.SS2.p1.4.m3.3.3.2.cmml">=</mo><mrow id="S4.SS2.p1.4.m3.3.3.1.1" xref="S4.SS2.p1.4.m3.3.3.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.2" xref="S4.SS2.p1.4.m3.3.3.1.1.1.cmml">(</mo><mrow id="S4.SS2.p1.4.m3.3.3.1.1.1" xref="S4.SS2.p1.4.m3.3.3.1.1.1.cmml"><mrow id="S4.SS2.p1.4.m3.3.3.1.1.1.3" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.cmml"><msubsup id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.cmml"><mi mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.2" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.2.cmml">t</mi><mi mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.3" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.3.cmml">k</mi><mo mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.3" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.3.cmml">‚Ä≤</mo></msubsup><mo fence="false" mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.3.1" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.1.cmml">|</mo><mi mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.3.3" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.3.cmml">k</mi></mrow><mo mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.2" xref="S4.SS2.p1.4.m3.3.3.1.1.1.2.cmml">=</mo><mrow id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.2.cmml"><mn mathsize="90%" id="S4.SS2.p1.4.m3.1.1" xref="S4.SS2.p1.4.m3.1.1.cmml">1</mn><mo mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.2" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.2.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S4.SS2.p1.4.m3.2.2" xref="S4.SS2.p1.4.m3.2.2.cmml">‚Ä¶</mi><mo mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.3" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.2.cmml">,</mo><msup id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.2" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.2.cmml">K</mi><mo mathsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.3" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.3.cmml">‚Ä≤</mo></msup></mrow></mrow><mo maxsize="90%" minsize="90%" id="S4.SS2.p1.4.m3.3.3.1.1.3" xref="S4.SS2.p1.4.m3.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m3.3b"><apply id="S4.SS2.p1.4.m3.3.3.cmml" xref="S4.SS2.p1.4.m3.3.3"><eq id="S4.SS2.p1.4.m3.3.3.2.cmml" xref="S4.SS2.p1.4.m3.3.3.2"></eq><apply id="S4.SS2.p1.4.m3.3.3.3.cmml" xref="S4.SS2.p1.4.m3.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m3.3.3.3.1.cmml" xref="S4.SS2.p1.4.m3.3.3.3">subscript</csymbol><ci id="S4.SS2.p1.4.m3.3.3.3.2.cmml" xref="S4.SS2.p1.4.m3.3.3.3.2">ùëá</ci><ci id="S4.SS2.p1.4.m3.3.3.3.3a.cmml" xref="S4.SS2.p1.4.m3.3.3.3.3"><mtext mathsize="63%" id="S4.SS2.p1.4.m3.3.3.3.3.cmml" xref="S4.SS2.p1.4.m3.3.3.3.3">Inter</mtext></ci></apply><apply id="S4.SS2.p1.4.m3.3.3.1.1.1.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1"><eq id="S4.SS2.p1.4.m3.3.3.1.1.1.2.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.2"></eq><apply id="S4.SS2.p1.4.m3.3.3.1.1.1.3.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3"><csymbol cd="latexml" id="S4.SS2.p1.4.m3.3.3.1.1.1.3.1.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.1">conditional</csymbol><apply id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.1.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2">subscript</csymbol><apply id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.1.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2">superscript</csymbol><ci id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.2.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.2">ùë°</ci><ci id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.3.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.2.3">‚Ä≤</ci></apply><ci id="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.3.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.2.3">ùëò</ci></apply><ci id="S4.SS2.p1.4.m3.3.3.1.1.1.3.3.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.3.3">ùëò</ci></apply><list id="S4.SS2.p1.4.m3.3.3.1.1.1.1.2.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.1"><cn type="integer" id="S4.SS2.p1.4.m3.1.1.cmml" xref="S4.SS2.p1.4.m3.1.1">1</cn><ci id="S4.SS2.p1.4.m3.2.2.cmml" xref="S4.SS2.p1.4.m3.2.2">‚Ä¶</ci><apply id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1">superscript</csymbol><ci id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.2">ùêæ</ci><ci id="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p1.4.m3.3.3.1.1.1.1.1.1.3">‚Ä≤</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m3.3c">T_{\text{Inter}}=(t^{\prime}_{k}|k=1,...,K^{\prime})</annotation></semantics></math><span id="S4.SS2.p1.5.4" class="ltx_text" style="font-size:90%;">. The functions </span><span id="S4.SS2.p1.5.5" class="ltx_text ltx_font_typewriter" style="font-size:90%;">NRM(¬∑)</span><span id="S4.SS2.p1.5.6" class="ltx_text" style="font-size:90%;"> and </span><span id="S4.SS2.p1.5.7" class="ltx_text ltx_font_typewriter" style="font-size:90%;">LIN(¬∑)</span><span id="S4.SS2.p1.5.8" class="ltx_text" style="font-size:90%;"> correspond to a normalization layer and a linear layer, respectively. The InterCTC loss is the negative log likelihood of generating </span><math id="S4.SS2.p1.5.m4.1" class="ltx_Math" alttext="T_{\text{Inter}}" display="inline"><semantics id="S4.SS2.p1.5.m4.1a"><msub id="S4.SS2.p1.5.m4.1.1" xref="S4.SS2.p1.5.m4.1.1.cmml"><mi mathsize="90%" id="S4.SS2.p1.5.m4.1.1.2" xref="S4.SS2.p1.5.m4.1.1.2.cmml">T</mi><mtext mathsize="90%" id="S4.SS2.p1.5.m4.1.1.3" xref="S4.SS2.p1.5.m4.1.1.3a.cmml">Inter</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m4.1b"><apply id="S4.SS2.p1.5.m4.1.1.cmml" xref="S4.SS2.p1.5.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.5.m4.1.1.1.cmml" xref="S4.SS2.p1.5.m4.1.1">subscript</csymbol><ci id="S4.SS2.p1.5.m4.1.1.2.cmml" xref="S4.SS2.p1.5.m4.1.1.2">ùëá</ci><ci id="S4.SS2.p1.5.m4.1.1.3a.cmml" xref="S4.SS2.p1.5.m4.1.1.3"><mtext mathsize="63%" id="S4.SS2.p1.5.m4.1.1.3.cmml" xref="S4.SS2.p1.5.m4.1.1.3">Inter</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m4.1c">T_{\text{Inter}}</annotation></semantics></math><span id="S4.SS2.p1.5.9" class="ltx_text" style="font-size:90%;">:</span></p>
<table id="S4.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E8.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{Inter}}=-\log P_{\text{Inter}}(T_{\text{Inter}}|X)" display="block"><semantics id="S4.E8.m1.1a"><mrow id="S4.E8.m1.1.1" xref="S4.E8.m1.1.1.cmml"><msub id="S4.E8.m1.1.1.3" xref="S4.E8.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S4.E8.m1.1.1.3.2" xref="S4.E8.m1.1.1.3.2.cmml">‚Ñí</mi><mtext mathsize="90%" id="S4.E8.m1.1.1.3.3" xref="S4.E8.m1.1.1.3.3a.cmml">Inter</mtext></msub><mo mathsize="90%" id="S4.E8.m1.1.1.2" xref="S4.E8.m1.1.1.2.cmml">=</mo><mrow id="S4.E8.m1.1.1.1" xref="S4.E8.m1.1.1.1.cmml"><mo mathsize="90%" rspace="0.167em" id="S4.E8.m1.1.1.1a" xref="S4.E8.m1.1.1.1.cmml">‚àí</mo><mrow id="S4.E8.m1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.cmml"><mrow id="S4.E8.m1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S4.E8.m1.1.1.1.1.3.1" xref="S4.E8.m1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S4.E8.m1.1.1.1.1.3a" xref="S4.E8.m1.1.1.1.1.3.cmml">‚Å°</mo><msub id="S4.E8.m1.1.1.1.1.3.2" xref="S4.E8.m1.1.1.1.1.3.2.cmml"><mi mathsize="90%" id="S4.E8.m1.1.1.1.1.3.2.2" xref="S4.E8.m1.1.1.1.1.3.2.2.cmml">P</mi><mtext mathsize="90%" id="S4.E8.m1.1.1.1.1.3.2.3" xref="S4.E8.m1.1.1.1.1.3.2.3a.cmml">Inter</mtext></msub></mrow><mo lspace="0em" rspace="0em" id="S4.E8.m1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S4.E8.m1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E8.m1.1.1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E8.m1.1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.cmml"><msub id="S4.E8.m1.1.1.1.1.1.1.1.2" xref="S4.E8.m1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="90%" id="S4.E8.m1.1.1.1.1.1.1.1.2.2" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2.cmml">T</mi><mtext mathsize="90%" id="S4.E8.m1.1.1.1.1.1.1.1.2.3" xref="S4.E8.m1.1.1.1.1.1.1.1.2.3a.cmml">Inter</mtext></msub><mo fence="false" mathsize="90%" id="S4.E8.m1.1.1.1.1.1.1.1.1" xref="S4.E8.m1.1.1.1.1.1.1.1.1.cmml">|</mo><mi mathsize="90%" id="S4.E8.m1.1.1.1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.1.1.1.3.cmml">X</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E8.m1.1.1.1.1.1.1.3" xref="S4.E8.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E8.m1.1b"><apply id="S4.E8.m1.1.1.cmml" xref="S4.E8.m1.1.1"><eq id="S4.E8.m1.1.1.2.cmml" xref="S4.E8.m1.1.1.2"></eq><apply id="S4.E8.m1.1.1.3.cmml" xref="S4.E8.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.3.1.cmml" xref="S4.E8.m1.1.1.3">subscript</csymbol><ci id="S4.E8.m1.1.1.3.2.cmml" xref="S4.E8.m1.1.1.3.2">‚Ñí</ci><ci id="S4.E8.m1.1.1.3.3a.cmml" xref="S4.E8.m1.1.1.3.3"><mtext mathsize="63%" id="S4.E8.m1.1.1.3.3.cmml" xref="S4.E8.m1.1.1.3.3">Inter</mtext></ci></apply><apply id="S4.E8.m1.1.1.1.cmml" xref="S4.E8.m1.1.1.1"><minus id="S4.E8.m1.1.1.1.2.cmml" xref="S4.E8.m1.1.1.1"></minus><apply id="S4.E8.m1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1"><times id="S4.E8.m1.1.1.1.1.2.cmml" xref="S4.E8.m1.1.1.1.1.2"></times><apply id="S4.E8.m1.1.1.1.1.3.cmml" xref="S4.E8.m1.1.1.1.1.3"><log id="S4.E8.m1.1.1.1.1.3.1.cmml" xref="S4.E8.m1.1.1.1.1.3.1"></log><apply id="S4.E8.m1.1.1.1.1.3.2.cmml" xref="S4.E8.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.1.1.3.2.1.cmml" xref="S4.E8.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E8.m1.1.1.1.1.3.2.2.cmml" xref="S4.E8.m1.1.1.1.1.3.2.2">ùëÉ</ci><ci id="S4.E8.m1.1.1.1.1.3.2.3a.cmml" xref="S4.E8.m1.1.1.1.1.3.2.3"><mtext mathsize="63%" id="S4.E8.m1.1.1.1.1.3.2.3.cmml" xref="S4.E8.m1.1.1.1.1.3.2.3">Inter</mtext></ci></apply></apply><apply id="S4.E8.m1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E8.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.E8.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E8.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.2">ùëá</ci><ci id="S4.E8.m1.1.1.1.1.1.1.1.2.3a.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.3"><mtext mathsize="63%" id="S4.E8.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.2.3">Inter</mtext></ci></apply><ci id="S4.E8.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E8.m1.1.1.1.1.1.1.1.3">ùëã</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m1.1c">\mathcal{L}_{\text{Inter}}=-\log P_{\text{Inter}}(T_{\text{Inter}}|X)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.8" class="ltx_p"><span id="S4.SS2.p1.8.1" class="ltx_text" style="font-size:90%;">The selection of </span><math id="S4.SS2.p1.6.m1.1" class="ltx_Math" alttext="T_{\text{Inter}}" display="inline"><semantics id="S4.SS2.p1.6.m1.1a"><msub id="S4.SS2.p1.6.m1.1.1" xref="S4.SS2.p1.6.m1.1.1.cmml"><mi mathsize="90%" id="S4.SS2.p1.6.m1.1.1.2" xref="S4.SS2.p1.6.m1.1.1.2.cmml">T</mi><mtext mathsize="90%" id="S4.SS2.p1.6.m1.1.1.3" xref="S4.SS2.p1.6.m1.1.1.3a.cmml">Inter</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m1.1b"><apply id="S4.SS2.p1.6.m1.1.1.cmml" xref="S4.SS2.p1.6.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m1.1.1.1.cmml" xref="S4.SS2.p1.6.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.6.m1.1.1.2.cmml" xref="S4.SS2.p1.6.m1.1.1.2">ùëá</ci><ci id="S4.SS2.p1.6.m1.1.1.3a.cmml" xref="S4.SS2.p1.6.m1.1.1.3"><mtext mathsize="63%" id="S4.SS2.p1.6.m1.1.1.3.cmml" xref="S4.SS2.p1.6.m1.1.1.3">Inter</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m1.1c">T_{\text{Inter}}</annotation></semantics></math><span id="S4.SS2.p1.8.2" class="ltx_text" style="font-size:90%;"> depends on the task. During training, the intermediate layer is optimized to accurately predict </span><math id="S4.SS2.p1.7.m2.1" class="ltx_Math" alttext="T_{\text{Inter}}" display="inline"><semantics id="S4.SS2.p1.7.m2.1a"><msub id="S4.SS2.p1.7.m2.1.1" xref="S4.SS2.p1.7.m2.1.1.cmml"><mi mathsize="90%" id="S4.SS2.p1.7.m2.1.1.2" xref="S4.SS2.p1.7.m2.1.1.2.cmml">T</mi><mtext mathsize="90%" id="S4.SS2.p1.7.m2.1.1.3" xref="S4.SS2.p1.7.m2.1.1.3a.cmml">Inter</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m2.1b"><apply id="S4.SS2.p1.7.m2.1.1.cmml" xref="S4.SS2.p1.7.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.7.m2.1.1.1.cmml" xref="S4.SS2.p1.7.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.7.m2.1.1.2.cmml" xref="S4.SS2.p1.7.m2.1.1.2">ùëá</ci><ci id="S4.SS2.p1.7.m2.1.1.3a.cmml" xref="S4.SS2.p1.7.m2.1.1.3"><mtext mathsize="63%" id="S4.SS2.p1.7.m2.1.1.3.cmml" xref="S4.SS2.p1.7.m2.1.1.3">Inter</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m2.1c">T_{\text{Inter}}</annotation></semantics></math><span id="S4.SS2.p1.8.3" class="ltx_text" style="font-size:90%;"> by integrating </span><math id="S4.SS2.p1.8.m3.1" class="ltx_Math" alttext="\mathcal{L}_{\text{Inter}}" display="inline"><semantics id="S4.SS2.p1.8.m3.1a"><msub id="S4.SS2.p1.8.m3.1.1" xref="S4.SS2.p1.8.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S4.SS2.p1.8.m3.1.1.2" xref="S4.SS2.p1.8.m3.1.1.2.cmml">‚Ñí</mi><mtext mathsize="90%" id="S4.SS2.p1.8.m3.1.1.3" xref="S4.SS2.p1.8.m3.1.1.3a.cmml">Inter</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m3.1b"><apply id="S4.SS2.p1.8.m3.1.1.cmml" xref="S4.SS2.p1.8.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.8.m3.1.1.1.cmml" xref="S4.SS2.p1.8.m3.1.1">subscript</csymbol><ci id="S4.SS2.p1.8.m3.1.1.2.cmml" xref="S4.SS2.p1.8.m3.1.1.2">‚Ñí</ci><ci id="S4.SS2.p1.8.m3.1.1.3a.cmml" xref="S4.SS2.p1.8.m3.1.1.3"><mtext mathsize="63%" id="S4.SS2.p1.8.m3.1.1.3.cmml" xref="S4.SS2.p1.8.m3.1.1.3">Inter</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m3.1c">\mathcal{L}_{\text{Inter}}</annotation></semantics></math><span id="S4.SS2.p1.8.4" class="ltx_text" style="font-size:90%;"> into the loss function:</span></p>
<table id="S4.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E9.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\prime}_{\text{CTC}}=\alpha L_{\text{Inter}}+(1-\alpha)\mathcal{L}_{\text{CTC}}" display="block"><semantics id="S4.E9.m1.1a"><mrow id="S4.E9.m1.1.1" xref="S4.E9.m1.1.1.cmml"><msubsup id="S4.E9.m1.1.1.3" xref="S4.E9.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S4.E9.m1.1.1.3.2.2" xref="S4.E9.m1.1.1.3.2.2.cmml">‚Ñí</mi><mtext mathsize="90%" id="S4.E9.m1.1.1.3.3" xref="S4.E9.m1.1.1.3.3a.cmml">CTC</mtext><mo mathsize="90%" id="S4.E9.m1.1.1.3.2.3" xref="S4.E9.m1.1.1.3.2.3.cmml">‚Ä≤</mo></msubsup><mo mathsize="90%" id="S4.E9.m1.1.1.2" xref="S4.E9.m1.1.1.2.cmml">=</mo><mrow id="S4.E9.m1.1.1.1" xref="S4.E9.m1.1.1.1.cmml"><mrow id="S4.E9.m1.1.1.1.3" xref="S4.E9.m1.1.1.1.3.cmml"><mi mathsize="90%" id="S4.E9.m1.1.1.1.3.2" xref="S4.E9.m1.1.1.1.3.2.cmml">Œ±</mi><mo lspace="0em" rspace="0em" id="S4.E9.m1.1.1.1.3.1" xref="S4.E9.m1.1.1.1.3.1.cmml">‚Äã</mo><msub id="S4.E9.m1.1.1.1.3.3" xref="S4.E9.m1.1.1.1.3.3.cmml"><mi mathsize="90%" id="S4.E9.m1.1.1.1.3.3.2" xref="S4.E9.m1.1.1.1.3.3.2.cmml">L</mi><mtext mathsize="90%" id="S4.E9.m1.1.1.1.3.3.3" xref="S4.E9.m1.1.1.1.3.3.3a.cmml">Inter</mtext></msub></mrow><mo mathsize="90%" id="S4.E9.m1.1.1.1.2" xref="S4.E9.m1.1.1.1.2.cmml">+</mo><mrow id="S4.E9.m1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.cmml"><mrow id="S4.E9.m1.1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E9.m1.1.1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E9.m1.1.1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml"><mn mathsize="90%" id="S4.E9.m1.1.1.1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo mathsize="90%" id="S4.E9.m1.1.1.1.1.1.1.1.1" xref="S4.E9.m1.1.1.1.1.1.1.1.1.cmml">‚àí</mo><mi mathsize="90%" id="S4.E9.m1.1.1.1.1.1.1.1.3" xref="S4.E9.m1.1.1.1.1.1.1.1.3.cmml">Œ±</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E9.m1.1.1.1.1.1.1.3" xref="S4.E9.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E9.m1.1.1.1.1.2" xref="S4.E9.m1.1.1.1.1.2.cmml">‚Äã</mo><msub id="S4.E9.m1.1.1.1.1.3" xref="S4.E9.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S4.E9.m1.1.1.1.1.3.2" xref="S4.E9.m1.1.1.1.1.3.2.cmml">‚Ñí</mi><mtext mathsize="90%" id="S4.E9.m1.1.1.1.1.3.3" xref="S4.E9.m1.1.1.1.1.3.3a.cmml">CTC</mtext></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E9.m1.1b"><apply id="S4.E9.m1.1.1.cmml" xref="S4.E9.m1.1.1"><eq id="S4.E9.m1.1.1.2.cmml" xref="S4.E9.m1.1.1.2"></eq><apply id="S4.E9.m1.1.1.3.cmml" xref="S4.E9.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.3.1.cmml" xref="S4.E9.m1.1.1.3">subscript</csymbol><apply id="S4.E9.m1.1.1.3.2.cmml" xref="S4.E9.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.3.2.1.cmml" xref="S4.E9.m1.1.1.3">superscript</csymbol><ci id="S4.E9.m1.1.1.3.2.2.cmml" xref="S4.E9.m1.1.1.3.2.2">‚Ñí</ci><ci id="S4.E9.m1.1.1.3.2.3.cmml" xref="S4.E9.m1.1.1.3.2.3">‚Ä≤</ci></apply><ci id="S4.E9.m1.1.1.3.3a.cmml" xref="S4.E9.m1.1.1.3.3"><mtext mathsize="63%" id="S4.E9.m1.1.1.3.3.cmml" xref="S4.E9.m1.1.1.3.3">CTC</mtext></ci></apply><apply id="S4.E9.m1.1.1.1.cmml" xref="S4.E9.m1.1.1.1"><plus id="S4.E9.m1.1.1.1.2.cmml" xref="S4.E9.m1.1.1.1.2"></plus><apply id="S4.E9.m1.1.1.1.3.cmml" xref="S4.E9.m1.1.1.1.3"><times id="S4.E9.m1.1.1.1.3.1.cmml" xref="S4.E9.m1.1.1.1.3.1"></times><ci id="S4.E9.m1.1.1.1.3.2.cmml" xref="S4.E9.m1.1.1.1.3.2">ùõº</ci><apply id="S4.E9.m1.1.1.1.3.3.cmml" xref="S4.E9.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.3.3.1.cmml" xref="S4.E9.m1.1.1.1.3.3">subscript</csymbol><ci id="S4.E9.m1.1.1.1.3.3.2.cmml" xref="S4.E9.m1.1.1.1.3.3.2">ùêø</ci><ci id="S4.E9.m1.1.1.1.3.3.3a.cmml" xref="S4.E9.m1.1.1.1.3.3.3"><mtext mathsize="63%" id="S4.E9.m1.1.1.1.3.3.3.cmml" xref="S4.E9.m1.1.1.1.3.3.3">Inter</mtext></ci></apply></apply><apply id="S4.E9.m1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1.1"><times id="S4.E9.m1.1.1.1.1.2.cmml" xref="S4.E9.m1.1.1.1.1.2"></times><apply id="S4.E9.m1.1.1.1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1"><minus id="S4.E9.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.E9.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.2">1</cn><ci id="S4.E9.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E9.m1.1.1.1.1.1.1.1.3">ùõº</ci></apply><apply id="S4.E9.m1.1.1.1.1.3.cmml" xref="S4.E9.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.1.3.1.cmml" xref="S4.E9.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E9.m1.1.1.1.1.3.2.cmml" xref="S4.E9.m1.1.1.1.1.3.2">‚Ñí</ci><ci id="S4.E9.m1.1.1.1.1.3.3a.cmml" xref="S4.E9.m1.1.1.1.1.3.3"><mtext mathsize="63%" id="S4.E9.m1.1.1.1.1.3.3.cmml" xref="S4.E9.m1.1.1.1.1.3.3">CTC</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m1.1c">\mathcal{L}^{\prime}_{\text{CTC}}=\alpha L_{\text{Inter}}+(1-\alpha)\mathcal{L}_{\text{CTC}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.9" class="ltx_p"><span id="S4.SS2.p1.9.1" class="ltx_text" style="font-size:90%;">Here, the InterCTC weight </span><math id="S4.SS2.p1.9.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS2.p1.9.m1.1a"><mi mathsize="90%" id="S4.SS2.p1.9.m1.1.1" xref="S4.SS2.p1.9.m1.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m1.1b"><ci id="S4.SS2.p1.9.m1.1.1.cmml" xref="S4.SS2.p1.9.m1.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m1.1c">\alpha</annotation></semantics></math><span id="S4.SS2.p1.9.2" class="ltx_text" style="font-size:90%;"> serves as a hyper-parameter. The updated overall loss function is derived by inserting Equation </span><a href="#S4.E9" title="In 4.2 Intermediate CTC ‚Ä£ 4 Method ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">9</span></a><span id="S4.SS2.p1.9.3" class="ltx_text" style="font-size:90%;"> into Equation 5:</span></p>
<table id="S4.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E10.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\prime}=\lambda\mathcal{L}^{\prime}_{\text{CTC}}+(1-\lambda)\mathcal{L}_{\text{Dec}}" display="block"><semantics id="S4.E10.m1.1a"><mrow id="S4.E10.m1.1.1" xref="S4.E10.m1.1.1.cmml"><msup id="S4.E10.m1.1.1.3" xref="S4.E10.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S4.E10.m1.1.1.3.2" xref="S4.E10.m1.1.1.3.2.cmml">‚Ñí</mi><mo mathsize="90%" id="S4.E10.m1.1.1.3.3" xref="S4.E10.m1.1.1.3.3.cmml">‚Ä≤</mo></msup><mo mathsize="90%" id="S4.E10.m1.1.1.2" xref="S4.E10.m1.1.1.2.cmml">=</mo><mrow id="S4.E10.m1.1.1.1" xref="S4.E10.m1.1.1.1.cmml"><mrow id="S4.E10.m1.1.1.1.3" xref="S4.E10.m1.1.1.1.3.cmml"><mi mathsize="90%" id="S4.E10.m1.1.1.1.3.2" xref="S4.E10.m1.1.1.1.3.2.cmml">Œª</mi><mo lspace="0em" rspace="0em" id="S4.E10.m1.1.1.1.3.1" xref="S4.E10.m1.1.1.1.3.1.cmml">‚Äã</mo><msubsup id="S4.E10.m1.1.1.1.3.3" xref="S4.E10.m1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S4.E10.m1.1.1.1.3.3.2.2" xref="S4.E10.m1.1.1.1.3.3.2.2.cmml">‚Ñí</mi><mtext mathsize="90%" id="S4.E10.m1.1.1.1.3.3.3" xref="S4.E10.m1.1.1.1.3.3.3a.cmml">CTC</mtext><mo mathsize="90%" id="S4.E10.m1.1.1.1.3.3.2.3" xref="S4.E10.m1.1.1.1.3.3.2.3.cmml">‚Ä≤</mo></msubsup></mrow><mo mathsize="90%" id="S4.E10.m1.1.1.1.2" xref="S4.E10.m1.1.1.1.2.cmml">+</mo><mrow id="S4.E10.m1.1.1.1.1" xref="S4.E10.m1.1.1.1.1.cmml"><mrow id="S4.E10.m1.1.1.1.1.1.1" xref="S4.E10.m1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S4.E10.m1.1.1.1.1.1.1.2" xref="S4.E10.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E10.m1.1.1.1.1.1.1.1" xref="S4.E10.m1.1.1.1.1.1.1.1.cmml"><mn mathsize="90%" id="S4.E10.m1.1.1.1.1.1.1.1.2" xref="S4.E10.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo mathsize="90%" id="S4.E10.m1.1.1.1.1.1.1.1.1" xref="S4.E10.m1.1.1.1.1.1.1.1.1.cmml">‚àí</mo><mi mathsize="90%" id="S4.E10.m1.1.1.1.1.1.1.1.3" xref="S4.E10.m1.1.1.1.1.1.1.1.3.cmml">Œª</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E10.m1.1.1.1.1.1.1.3" xref="S4.E10.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E10.m1.1.1.1.1.2" xref="S4.E10.m1.1.1.1.1.2.cmml">‚Äã</mo><msub id="S4.E10.m1.1.1.1.1.3" xref="S4.E10.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S4.E10.m1.1.1.1.1.3.2" xref="S4.E10.m1.1.1.1.1.3.2.cmml">‚Ñí</mi><mtext mathsize="90%" id="S4.E10.m1.1.1.1.1.3.3" xref="S4.E10.m1.1.1.1.1.3.3a.cmml">Dec</mtext></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E10.m1.1b"><apply id="S4.E10.m1.1.1.cmml" xref="S4.E10.m1.1.1"><eq id="S4.E10.m1.1.1.2.cmml" xref="S4.E10.m1.1.1.2"></eq><apply id="S4.E10.m1.1.1.3.cmml" xref="S4.E10.m1.1.1.3"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.3.1.cmml" xref="S4.E10.m1.1.1.3">superscript</csymbol><ci id="S4.E10.m1.1.1.3.2.cmml" xref="S4.E10.m1.1.1.3.2">‚Ñí</ci><ci id="S4.E10.m1.1.1.3.3.cmml" xref="S4.E10.m1.1.1.3.3">‚Ä≤</ci></apply><apply id="S4.E10.m1.1.1.1.cmml" xref="S4.E10.m1.1.1.1"><plus id="S4.E10.m1.1.1.1.2.cmml" xref="S4.E10.m1.1.1.1.2"></plus><apply id="S4.E10.m1.1.1.1.3.cmml" xref="S4.E10.m1.1.1.1.3"><times id="S4.E10.m1.1.1.1.3.1.cmml" xref="S4.E10.m1.1.1.1.3.1"></times><ci id="S4.E10.m1.1.1.1.3.2.cmml" xref="S4.E10.m1.1.1.1.3.2">ùúÜ</ci><apply id="S4.E10.m1.1.1.1.3.3.cmml" xref="S4.E10.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.1.3.3.1.cmml" xref="S4.E10.m1.1.1.1.3.3">subscript</csymbol><apply id="S4.E10.m1.1.1.1.3.3.2.cmml" xref="S4.E10.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.1.3.3.2.1.cmml" xref="S4.E10.m1.1.1.1.3.3">superscript</csymbol><ci id="S4.E10.m1.1.1.1.3.3.2.2.cmml" xref="S4.E10.m1.1.1.1.3.3.2.2">‚Ñí</ci><ci id="S4.E10.m1.1.1.1.3.3.2.3.cmml" xref="S4.E10.m1.1.1.1.3.3.2.3">‚Ä≤</ci></apply><ci id="S4.E10.m1.1.1.1.3.3.3a.cmml" xref="S4.E10.m1.1.1.1.3.3.3"><mtext mathsize="63%" id="S4.E10.m1.1.1.1.3.3.3.cmml" xref="S4.E10.m1.1.1.1.3.3.3">CTC</mtext></ci></apply></apply><apply id="S4.E10.m1.1.1.1.1.cmml" xref="S4.E10.m1.1.1.1.1"><times id="S4.E10.m1.1.1.1.1.2.cmml" xref="S4.E10.m1.1.1.1.1.2"></times><apply id="S4.E10.m1.1.1.1.1.1.1.1.cmml" xref="S4.E10.m1.1.1.1.1.1.1"><minus id="S4.E10.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E10.m1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.E10.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E10.m1.1.1.1.1.1.1.1.2">1</cn><ci id="S4.E10.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E10.m1.1.1.1.1.1.1.1.3">ùúÜ</ci></apply><apply id="S4.E10.m1.1.1.1.1.3.cmml" xref="S4.E10.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.1.1.3.1.cmml" xref="S4.E10.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.E10.m1.1.1.1.1.3.2.cmml" xref="S4.E10.m1.1.1.1.1.3.2">‚Ñí</ci><ci id="S4.E10.m1.1.1.1.1.3.3a.cmml" xref="S4.E10.m1.1.1.1.1.3.3"><mtext mathsize="63%" id="S4.E10.m1.1.1.1.1.3.3.cmml" xref="S4.E10.m1.1.1.1.1.3.3">Dec</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E10.m1.1c">\mathcal{L}^{\prime}=\lambda\mathcal{L}^{\prime}_{\text{CTC}}+(1-\lambda)\mathcal{L}_{\text{Dec}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.10" class="ltx_p"><span id="S4.SS2.p1.10.1" class="ltx_text" style="font-size:90%;">It is noteworthy that CTC can be applied to multiple encoder layers with different target sequences for each. Where the target sequence differs from the decoder output, this is considered as an auxiliary task. The average of all InterCTC losses is used as </span><math id="S4.SS2.p1.10.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{Inter}}" display="inline"><semantics id="S4.SS2.p1.10.m1.1a"><msub id="S4.SS2.p1.10.m1.1.1" xref="S4.SS2.p1.10.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S4.SS2.p1.10.m1.1.1.2" xref="S4.SS2.p1.10.m1.1.1.2.cmml">‚Ñí</mi><mtext mathsize="90%" id="S4.SS2.p1.10.m1.1.1.3" xref="S4.SS2.p1.10.m1.1.1.3a.cmml">Inter</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m1.1b"><apply id="S4.SS2.p1.10.m1.1.1.cmml" xref="S4.SS2.p1.10.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.10.m1.1.1.1.cmml" xref="S4.SS2.p1.10.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.10.m1.1.1.2.cmml" xref="S4.SS2.p1.10.m1.1.1.2">‚Ñí</ci><ci id="S4.SS2.p1.10.m1.1.1.3a.cmml" xref="S4.SS2.p1.10.m1.1.1.3"><mtext mathsize="63%" id="S4.SS2.p1.10.m1.1.1.3.cmml" xref="S4.SS2.p1.10.m1.1.1.3">Inter</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m1.1c">\mathcal{L}_{\text{Inter}}</annotation></semantics></math><span id="S4.SS2.p1.10.2" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Dialect identification as an auxiliary task</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text" style="font-size:90%;">Using the above model structure, dialect is captured by a combination of two methods. Firstly, it is captured explicitly in the text output sequence, by prepending a dialect tag to the text to be predicted:</span></p>
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span id="S4.Ex1.1" class="ltx_text ltx_markedasmath" style="font-size:90%;">[CO] <span id="S4.Ex1.1.1" class="ltx_text ltx_font_italic">anois teacht an earraigh</span></span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS3.p1.2" class="ltx_p"><span id="S4.SS3.p1.2.1" class="ltx_text" style="font-size:90%;">The vocabulary of the ASR model is extended to include dialect tags in the following way:</span></p>
<table id="S4.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E11.m1.3" class="ltx_Math" alttext="V^{\prime}=V\cup\{[UL],[CO],[MU]\}" display="block"><semantics id="S4.E11.m1.3a"><mrow id="S4.E11.m1.3.3" xref="S4.E11.m1.3.3.cmml"><msup id="S4.E11.m1.3.3.5" xref="S4.E11.m1.3.3.5.cmml"><mi mathsize="90%" id="S4.E11.m1.3.3.5.2" xref="S4.E11.m1.3.3.5.2.cmml">V</mi><mo mathsize="90%" id="S4.E11.m1.3.3.5.3" xref="S4.E11.m1.3.3.5.3.cmml">‚Ä≤</mo></msup><mo mathsize="90%" id="S4.E11.m1.3.3.4" xref="S4.E11.m1.3.3.4.cmml">=</mo><mrow id="S4.E11.m1.3.3.3" xref="S4.E11.m1.3.3.3.cmml"><mi mathsize="90%" id="S4.E11.m1.3.3.3.5" xref="S4.E11.m1.3.3.3.5.cmml">V</mi><mo mathsize="90%" id="S4.E11.m1.3.3.3.4" xref="S4.E11.m1.3.3.3.4.cmml">‚à™</mo><mrow id="S4.E11.m1.3.3.3.3.3" xref="S4.E11.m1.3.3.3.3.4.cmml"><mo maxsize="90%" minsize="90%" id="S4.E11.m1.3.3.3.3.3.4" xref="S4.E11.m1.3.3.3.3.4.cmml">{</mo><mrow id="S4.E11.m1.1.1.1.1.1.1.1" xref="S4.E11.m1.1.1.1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S4.E11.m1.1.1.1.1.1.1.1.2" xref="S4.E11.m1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S4.E11.m1.1.1.1.1.1.1.1.1" xref="S4.E11.m1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S4.E11.m1.1.1.1.1.1.1.1.1.2" xref="S4.E11.m1.1.1.1.1.1.1.1.1.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="S4.E11.m1.1.1.1.1.1.1.1.1.1" xref="S4.E11.m1.1.1.1.1.1.1.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S4.E11.m1.1.1.1.1.1.1.1.1.3" xref="S4.E11.m1.1.1.1.1.1.1.1.1.3.cmml">L</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E11.m1.1.1.1.1.1.1.1.3" xref="S4.E11.m1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow><mo mathsize="90%" id="S4.E11.m1.3.3.3.3.3.5" xref="S4.E11.m1.3.3.3.3.4.cmml">,</mo><mrow id="S4.E11.m1.2.2.2.2.2.2.1" xref="S4.E11.m1.2.2.2.2.2.2.2.cmml"><mo maxsize="90%" minsize="90%" id="S4.E11.m1.2.2.2.2.2.2.1.2" xref="S4.E11.m1.2.2.2.2.2.2.2.1.cmml">[</mo><mrow id="S4.E11.m1.2.2.2.2.2.2.1.1" xref="S4.E11.m1.2.2.2.2.2.2.1.1.cmml"><mi mathsize="90%" id="S4.E11.m1.2.2.2.2.2.2.1.1.2" xref="S4.E11.m1.2.2.2.2.2.2.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.E11.m1.2.2.2.2.2.2.1.1.1" xref="S4.E11.m1.2.2.2.2.2.2.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S4.E11.m1.2.2.2.2.2.2.1.1.3" xref="S4.E11.m1.2.2.2.2.2.2.1.1.3.cmml">O</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E11.m1.2.2.2.2.2.2.1.3" xref="S4.E11.m1.2.2.2.2.2.2.2.1.cmml">]</mo></mrow><mo mathsize="90%" id="S4.E11.m1.3.3.3.3.3.6" xref="S4.E11.m1.3.3.3.3.4.cmml">,</mo><mrow id="S4.E11.m1.3.3.3.3.3.3.1" xref="S4.E11.m1.3.3.3.3.3.3.2.cmml"><mo maxsize="90%" minsize="90%" id="S4.E11.m1.3.3.3.3.3.3.1.2" xref="S4.E11.m1.3.3.3.3.3.3.2.1.cmml">[</mo><mrow id="S4.E11.m1.3.3.3.3.3.3.1.1" xref="S4.E11.m1.3.3.3.3.3.3.1.1.cmml"><mi mathsize="90%" id="S4.E11.m1.3.3.3.3.3.3.1.1.2" xref="S4.E11.m1.3.3.3.3.3.3.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.E11.m1.3.3.3.3.3.3.1.1.1" xref="S4.E11.m1.3.3.3.3.3.3.1.1.1.cmml">‚Äã</mo><mi mathsize="90%" id="S4.E11.m1.3.3.3.3.3.3.1.1.3" xref="S4.E11.m1.3.3.3.3.3.3.1.1.3.cmml">U</mi></mrow><mo maxsize="90%" minsize="90%" id="S4.E11.m1.3.3.3.3.3.3.1.3" xref="S4.E11.m1.3.3.3.3.3.3.2.1.cmml">]</mo></mrow><mo maxsize="90%" minsize="90%" id="S4.E11.m1.3.3.3.3.3.7" xref="S4.E11.m1.3.3.3.3.4.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E11.m1.3b"><apply id="S4.E11.m1.3.3.cmml" xref="S4.E11.m1.3.3"><eq id="S4.E11.m1.3.3.4.cmml" xref="S4.E11.m1.3.3.4"></eq><apply id="S4.E11.m1.3.3.5.cmml" xref="S4.E11.m1.3.3.5"><csymbol cd="ambiguous" id="S4.E11.m1.3.3.5.1.cmml" xref="S4.E11.m1.3.3.5">superscript</csymbol><ci id="S4.E11.m1.3.3.5.2.cmml" xref="S4.E11.m1.3.3.5.2">ùëâ</ci><ci id="S4.E11.m1.3.3.5.3.cmml" xref="S4.E11.m1.3.3.5.3">‚Ä≤</ci></apply><apply id="S4.E11.m1.3.3.3.cmml" xref="S4.E11.m1.3.3.3"><union id="S4.E11.m1.3.3.3.4.cmml" xref="S4.E11.m1.3.3.3.4"></union><ci id="S4.E11.m1.3.3.3.5.cmml" xref="S4.E11.m1.3.3.3.5">ùëâ</ci><set id="S4.E11.m1.3.3.3.3.4.cmml" xref="S4.E11.m1.3.3.3.3.3"><apply id="S4.E11.m1.1.1.1.1.1.1.2.cmml" xref="S4.E11.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E11.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.E11.m1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S4.E11.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E11.m1.1.1.1.1.1.1.1.1"><times id="S4.E11.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E11.m1.1.1.1.1.1.1.1.1.1"></times><ci id="S4.E11.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E11.m1.1.1.1.1.1.1.1.1.2">ùëà</ci><ci id="S4.E11.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E11.m1.1.1.1.1.1.1.1.1.3">ùêø</ci></apply></apply><apply id="S4.E11.m1.2.2.2.2.2.2.2.cmml" xref="S4.E11.m1.2.2.2.2.2.2.1"><csymbol cd="latexml" id="S4.E11.m1.2.2.2.2.2.2.2.1.cmml" xref="S4.E11.m1.2.2.2.2.2.2.1.2">delimited-[]</csymbol><apply id="S4.E11.m1.2.2.2.2.2.2.1.1.cmml" xref="S4.E11.m1.2.2.2.2.2.2.1.1"><times id="S4.E11.m1.2.2.2.2.2.2.1.1.1.cmml" xref="S4.E11.m1.2.2.2.2.2.2.1.1.1"></times><ci id="S4.E11.m1.2.2.2.2.2.2.1.1.2.cmml" xref="S4.E11.m1.2.2.2.2.2.2.1.1.2">ùê∂</ci><ci id="S4.E11.m1.2.2.2.2.2.2.1.1.3.cmml" xref="S4.E11.m1.2.2.2.2.2.2.1.1.3">ùëÇ</ci></apply></apply><apply id="S4.E11.m1.3.3.3.3.3.3.2.cmml" xref="S4.E11.m1.3.3.3.3.3.3.1"><csymbol cd="latexml" id="S4.E11.m1.3.3.3.3.3.3.2.1.cmml" xref="S4.E11.m1.3.3.3.3.3.3.1.2">delimited-[]</csymbol><apply id="S4.E11.m1.3.3.3.3.3.3.1.1.cmml" xref="S4.E11.m1.3.3.3.3.3.3.1.1"><times id="S4.E11.m1.3.3.3.3.3.3.1.1.1.cmml" xref="S4.E11.m1.3.3.3.3.3.3.1.1.1"></times><ci id="S4.E11.m1.3.3.3.3.3.3.1.1.2.cmml" xref="S4.E11.m1.3.3.3.3.3.3.1.1.2">ùëÄ</ci><ci id="S4.E11.m1.3.3.3.3.3.3.1.1.3.cmml" xref="S4.E11.m1.3.3.3.3.3.3.1.1.3">ùëà</ci></apply></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E11.m1.3c">V^{\prime}=V\cup\{[UL],[CO],[MU]\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
<p id="S4.SS3.p1.3" class="ltx_p"><span id="S4.SS3.p1.3.1" class="ltx_text" style="font-size:90%;">This approach jointly models the ASR task and the speech classification task effectively.</span></p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text" style="font-size:90%;">The second method to capture dialect is to use a DID InterCTC objective, where the ground truth of an utterance is the dialect tag of the speaker. During inference, the dialect of an utterance is predicted using InterCTC greedy search.</span></p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Model structure</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text" style="font-size:90%;">The model training in these experiments adopts the hybrid CTC/Attention-based encoder-decoder framework. Two encoder architectures, namely the Conformer and the E-branchformer¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S4.SS4.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS4.p1.1.4" class="ltx_text" style="font-size:90%;">, are investigated. These encoders were proposed as improvements to the transformer encoder architecture, which captures global acoustic contextual information using the attention mechanism. The Conformer in addition to utilizing convolutional layers to capture local contexts, which is particularly important for speech, also makes use of the attention mechanism to capture global information. On the other hand, the E-branchformer has superseded the Conformer encoder as the state-of-the-art encoder, by capturing the local and global contexts in parallel branches before merging the outputs. For the front-end module, a self-supervised learning model (SSL) was chosen, namely the multilingual XLS-R 300M¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S4.SS4.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS4.p1.1.7" class="ltx_text" style="font-size:90%;">, which is trained on 436k hours of data from 128 languages. Despite the absence of Irish in this multilingual training set, this model was deemed to be more appropriate for Irish speech recognition and the dialect disambiguation than other acoustic SSL models typically trained monolingually on English data. All models trained use a transformer decoder.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Setup</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">In these experiments, the hybrid CTC/Attention-based encoder-decoder structure is explored for jointly modelling Irish speech recognition and dialect identification, using the ESPnet toolkit¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S5.SS1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS1.p1.1.4" class="ltx_text" style="font-size:90%;">. See Section 4.3 for details on how dialect is incorporated. Accuracy is used to report DID performance, as the test set is quite balanced with respect to the number of utterances per dialect. Throughout all experiments, the XLS-R 300M was used as a front-end module for acoustic feature extraction. All encoder-decoder models are trained with a transformer decoder with 6 blocks, each having 2048 hidden units and 4 attention heads. Three different encoders are tested in these experiments, a Conformer encoder and a small and large E-branchformer encoder. The Conformer encoder has 12 blocks, each having 2048 hidden units and 4 attention heads, and Conformer-based models trained here have 113m trainable parameters. The small E-branchformer model has 45.8m trainable parameters, with 12 blocks, each with 1048 linear units, an output size of 256 and 4 attention heads. The larger model has 130m trainable parameters and uses 2048 linear units and an output size of 256, while the remaining parameters are kept the same. The cgMLP module of the E-branchformer encoders has 3072 units and the convolution kernel size is 31. Speed perturbation with warping factors of 0.9, 1.0 and 1.1 as well as Spectral Augment are used to augment the training data.</span></p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text" style="font-size:90%;">A modular TDNN-HMM ASR model is trained with speed perturbation and spectral augment as a comparison for ASR performance and an ECAPA-TDNN model is trained with speed perturbation and added noise and reverberation as a comparison for DID performance.</span></p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>ASR baseline models</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p"><span id="S5.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">Despite the advance of End-to-End ASR models, the hybrid TDNN-HMM is still a robust model for low-resource languages and was still the best performing model for Irish¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a><span id="S5.SS2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS2.p1.1.4" class="ltx_text" style="font-size:90%;">. A TDNN-HMM model was trained as the baseline to compare with the CTC/Attention encoder-decoder architecture, following the same set-up as </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a><span id="S5.SS2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS2.p1.1.7" class="ltx_text" style="font-size:90%;">. A 4-gram LM is trained using both the training and fine-tuning text corpora listed in Section </span><a href="#S3.SS2" title="3.2 Text corpora for shallow-fusion experiment ‚Ä£ 3 Data ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3.2</span></a><span id="S5.SS2.p1.1.8" class="ltx_text" style="font-size:90%;"> and Table¬†</span><a href="#S3.T3" title="Table 3 ‚Ä£ 3.2 Text corpora for shallow-fusion experiment ‚Ä£ 3 Data ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S5.SS2.p1.1.9" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">To evaluate both the effectiveness of InterCTC on DID and ASR performance and the impact of multi-task learning on ASR performance, three Conformer-based models are trained and compared with the hybrid TDNN-HMM baseline. The first Conformer-based model, which will be referred to as Conformer (ASR) and is the second row in Table¬†</span><a href="#S5.T4" title="Table 4 ‚Ä£ 5.2 ASR baseline models ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S5.SS2.p2.1.2" class="ltx_text" style="font-size:90%;">, is trained for ASR only with an ASR InterCTC objective in layers 3, 6 and 9. This model is designed to compare the capability of the model architecture on the ASR task with TDNN-HMM on the ASR task. The second Conformer model, which will be referred to as Conformer (multi-task) and is the third row in Table¬†</span><a href="#S5.T4" title="Table 4 ‚Ä£ 5.2 ASR baseline models ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S5.SS2.p2.1.3" class="ltx_text" style="font-size:90%;">, is trained for multi-task ASR and DID with InterCTC DID and ASR objectives defined for encoder layers 3, 6 and 9.
The third model Conformer (no InterCTC), see the fourth row in Table¬†</span><a href="#S5.T4" title="Table 4 ‚Ä£ 5.2 ASR baseline models ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S5.SS2.p2.1.4" class="ltx_text" style="font-size:90%;">, is trained for multi-task ASR and DID without InterCTC.</span></p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p"><span id="S5.SS2.p3.1.1" class="ltx_text" style="font-size:90%;">Table¬†</span><a href="#S5.T4" title="Table 4 ‚Ä£ 5.2 ASR baseline models ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S5.SS2.p3.1.2" class="ltx_text" style="font-size:90%;"> presents the ASR performance of these models. The TDNN-HMM baseline outperforms the best performing Conformer model, specifically Conformer (ASR), by 16.5% relative WER. Conformer (multi-task) performs worse than Conformer (ASR) by 13% relative, suggesting that jointly modelling DID and ASR leads to ASR performance degradation. Conformer (no InterCTC) performs less well, showing that the addition of InterCTC leads to WER improvements.</span></p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance of ASR baselines.</figcaption>
<table id="S5.T4.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.3.1.1" class="ltx_tr">
<th id="S5.T4.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S5.T4.3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.3.1.1.2.1" class="ltx_text" style="font-size:90%;">Objective</span></th>
<th id="S5.T4.3.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_rr ltx_border_tt"><span id="S5.T4.3.1.1.3.1" class="ltx_text" style="font-size:90%;">InterCTC</span></th>
<th id="S5.T4.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T4.3.1.1.4.1" class="ltx_text" style="font-size:90%;">WER</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.3.2.1" class="ltx_tr">
<td id="S5.T4.3.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T4.3.2.1.1.1" class="ltx_text" style="font-size:90%;">TDNN-HMM</span></td>
<td id="S5.T4.3.2.1.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T4.3.2.1.3" class="ltx_td ltx_border_rr ltx_border_t"></td>
<td id="S5.T4.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.2.1.4.1" class="ltx_text" style="font-size:90%;">13.2</span></td>
</tr>
<tr id="S5.T4.3.3.2" class="ltx_tr">
<td id="S5.T4.3.3.2.1" class="ltx_td ltx_align_left"><span id="S5.T4.3.3.2.1.1" class="ltx_text" style="font-size:90%;">Conformer</span></td>
<td id="S5.T4.3.3.2.2" class="ltx_td ltx_align_left"><span id="S5.T4.3.3.2.2.1" class="ltx_text" style="font-size:90%;">ASR</span></td>
<td id="S5.T4.3.3.2.3" class="ltx_td ltx_align_left ltx_border_rr"><span id="S5.T4.3.3.2.3.1" class="ltx_text" style="font-size:90%;">yes</span></td>
<td id="S5.T4.3.3.2.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.3.2.4.1" class="ltx_text" style="font-size:90%;">15.8</span></td>
</tr>
<tr id="S5.T4.3.4.3" class="ltx_tr">
<td id="S5.T4.3.4.3.1" class="ltx_td ltx_align_left"><span id="S5.T4.3.4.3.1.1" class="ltx_text" style="font-size:90%;">Conformer</span></td>
<td id="S5.T4.3.4.3.2" class="ltx_td ltx_align_left"><span id="S5.T4.3.4.3.2.1" class="ltx_text" style="font-size:90%;">ASR + DID</span></td>
<td id="S5.T4.3.4.3.3" class="ltx_td ltx_align_left ltx_border_rr"><span id="S5.T4.3.4.3.3.1" class="ltx_text" style="font-size:90%;">yes</span></td>
<td id="S5.T4.3.4.3.4" class="ltx_td ltx_align_center"><span id="S5.T4.3.4.3.4.1" class="ltx_text" style="font-size:90%;">18.1</span></td>
</tr>
<tr id="S5.T4.3.5.4" class="ltx_tr">
<td id="S5.T4.3.5.4.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T4.3.5.4.1.1" class="ltx_text" style="font-size:90%;">Conformer</span></td>
<td id="S5.T4.3.5.4.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T4.3.5.4.2.1" class="ltx_text" style="font-size:90%;">ASR + DID</span></td>
<td id="S5.T4.3.5.4.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_rr"><span id="S5.T4.3.5.4.3.1" class="ltx_text" style="font-size:90%;">no</span></td>
<td id="S5.T4.3.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.3.5.4.4.1" class="ltx_text" style="font-size:90%;">18.9</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>DID baseline models</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p"><span id="S5.SS3.p1.1.1" class="ltx_text" style="font-size:90%;">Previous work </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS3.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S5.SS3.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS3.p1.1.4" class="ltx_text" style="font-size:90%;"> demonstrates that the ECAPA-TDNN performs well for Irish DID, outperforming wav2vec 2.0, hence an ECAPA-TDNN model was trained using SpeechBrain </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS3.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib32" title="" class="ltx_ref">32</a><span id="S5.SS3.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS3.p1.1.7" class="ltx_text" style="font-size:90%;"> following the same setup as </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS3.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S5.SS3.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS3.p1.1.10" class="ltx_text" style="font-size:90%;">, serving as the baseline model for the DID task. The embedding model is initialised from an ECAPA-TDNN trained for language identification using the VoxLingua107 corpus </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS3.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib33" title="" class="ltx_ref">33</a><span id="S5.SS3.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS3.p1.1.13" class="ltx_text" style="font-size:90%;">. The model is trained using the Additive Angular Margin loss </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS3.p1.1.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib34" title="" class="ltx_ref">34</a><span id="S5.SS3.p1.1.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS3.p1.1.16" class="ltx_text" style="font-size:90%;"> and speed perturbation, adding noise and reverberation are applied as data augmentation.</span></p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p"><span id="S5.SS3.p2.1.1" class="ltx_text" style="font-size:90%;">In Table¬†</span><a href="#S5.T5" title="Table 5 ‚Ä£ 5.3 DID baseline models ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S5.SS3.p2.1.2" class="ltx_text" style="font-size:90%;">, the DID performance of the ECAPA-TDNN is compared with a Conformer (multi-task) and a Conformer (no InterCTC). Both Conformer models outperform the ECAPA-TDNN model by a wide margin. Interestingly, InterCTC with the multi-task objective assigned to layers 3, 6 and 9 does not lead to a gain in DID accuracy compared to the model trained without InterCTC.</span></p>
</div>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance of DID baselines.</figcaption>
<table id="S5.T5.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T5.3.1.1" class="ltx_tr">
<th id="S5.T5.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_rr ltx_border_tt"><span id="S5.T5.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S5.T5.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T5.3.1.1.2.1" class="ltx_text" style="font-size:90%;">DID Acc.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T5.3.2.1" class="ltx_tr">
<th id="S5.T5.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr ltx_border_t"><span id="S5.T5.3.2.1.1.1" class="ltx_text" style="font-size:90%;">ECAPA-TDNN</span></th>
<td id="S5.T5.3.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.3.2.1.2.1" class="ltx_text" style="font-size:90%;">72.5</span></td>
</tr>
<tr id="S5.T5.3.3.2" class="ltx_tr">
<th id="S5.T5.3.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_rr"><span id="S5.T5.3.3.2.1.1" class="ltx_text" style="font-size:90%;">Conformer (multitask)</span></th>
<td id="S5.T5.3.3.2.2" class="ltx_td ltx_align_center"><span id="S5.T5.3.3.2.2.1" class="ltx_text" style="font-size:90%;">78.6</span></td>
</tr>
<tr id="S5.T5.3.4.3" class="ltx_tr">
<th id="S5.T5.3.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_rr"><span id="S5.T5.3.4.3.1.1" class="ltx_text" style="font-size:90%;">Conformer (no InterCTC)</span></th>
<td id="S5.T5.3.4.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T5.3.4.3.2.1" class="ltx_text" style="font-size:90%;">79.7</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Experiment 1</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p"><span id="S5.SS4.p1.1.1" class="ltx_text" style="font-size:90%;">In this experiment, assigning InterCTC objectives to layers of the Conformer encoder is explored. The assignment of the Multi-task and DID InterCTC objectives, detailed in Section 4.3, to the encoder layers is varied systematically. An additional model trained to perform both ASR and DID without InterCTC is included here for comparison.</span></p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p"><span id="S5.SS4.p2.1.1" class="ltx_text" style="font-size:90%;">Table¬†</span><a href="#S5.T6" title="Table 6 ‚Ä£ 5.4 Experiment 1 ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S5.SS4.p2.1.2" class="ltx_text" style="font-size:90%;"> shows the results of the InterCTC configurations for DID accuracy and WER. Row 1 shows the performance of baseline Conformer (no InterCTC), and row 7 shows the performance for baseline Conformer (multi-task). As mentioned before, the Conformer (no InterCTC) model achieved a DID accuracy of 79.7%. However, in comparison with the models trained with InterCTC, its ASR performance is relatively poor at 18.9% WER, suggesting that InterCTC is most helpful for ASR performance as opposed to the speech classification task of DID. Surprisingly, the models trained with DID InterCTC objectives only, as in rows 2-4, performed worse in DID accuracy than the baseline on row 7, which was trained with multi-task CTC objectives. However, the ASR performance of the these models (rows 2-4) varies considerably: row 2 trained with DID InterCTC objective in layers 3, 6 and 9 garnered the best WER (16.6%) in this experiment; row 4, where the only InterCTC objective was assigned to layer 3, achieved the worst WER in the experiment (19.4%). The best performing system (row 6) is trained with the DID objective in layer 3 and the multi-task objective in layers 6 and 9. This model achieved the highest DID accuracy in this experiment, a boost of 10.8% relative to the ECAPA-TDNN baseline. The same model also achieved the second lowest WER among the models trained for both ASR and DID, with 16.7% WER. This model is chosen as the best configuration of InterCTC objectives for joint DID and ASR modelling for Experiments 2 and 3.</span></p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>DID and ASR performance with varying InterCTC settings. Row 1 is Conformer (no InterCTC) and row 7 is Conformer (multi-task) from the baseline experiments</figcaption>
<table id="S5.T6.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T6.3.1.1" class="ltx_tr">
<th id="S5.T6.3.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="S5.T6.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T6.3.1.1.2.1" class="ltx_text" style="font-size:90%;">Inter-CTC</span></th>
<th id="S5.T6.3.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S5.T6.3.1.1.3.1" class="ltx_text" style="font-size:90%;">DID</span></th>
<th id="S5.T6.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S5.T6.3.1.1.4.1" class="ltx_text" style="font-size:90%;">WER</span></th>
</tr>
<tr id="S5.T6.3.2.2" class="ltx_tr">
<th id="S5.T6.3.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S5.T6.3.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column"><span id="S5.T6.3.2.2.2.1" class="ltx_text" style="font-size:90%;">Multitask</span></th>
<th id="S5.T6.3.2.2.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_r"><span id="S5.T6.3.2.2.3.1" class="ltx_text" style="font-size:90%;">DID</span></th>
<th id="S5.T6.3.2.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S5.T6.3.2.2.4.1" class="ltx_text" style="font-size:90%;">Acc</span></th>
<th id="S5.T6.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.3.2.2.5.1" class="ltx_text" style="font-size:90%;">All</span></th>
<th id="S5.T6.3.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.3.2.2.6.1" class="ltx_text" style="font-size:90%;">Ul</span></th>
<th id="S5.T6.3.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.3.2.2.7.1" class="ltx_text" style="font-size:90%;">Co</span></th>
<th id="S5.T6.3.2.2.8" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.3.2.2.8.1" class="ltx_text" style="font-size:90%;">Mu</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T6.3.3.1" class="ltx_tr">
<td id="S5.T6.3.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.3.3.1.1.1" class="ltx_text" style="font-size:90%;">1*</span></td>
<td id="S5.T6.3.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S5.T6.3.3.1.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T6.3.3.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.3.3.1.3.1" class="ltx_text" style="font-size:90%;">79.7</span></td>
<td id="S5.T6.3.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.3.3.1.4.1" class="ltx_text" style="font-size:90%;">18.9</span></td>
<td id="S5.T6.3.3.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.3.3.1.5.1" class="ltx_text" style="font-size:90%;">18.6</span></td>
<td id="S5.T6.3.3.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.3.3.1.6.1" class="ltx_text" style="font-size:90%;">20.7</span></td>
<td id="S5.T6.3.3.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S5.T6.3.3.1.7.1" class="ltx_text" style="font-size:90%;">17.2</span></td>
</tr>
<tr id="S5.T6.3.4.2" class="ltx_tr">
<td id="S5.T6.3.4.2.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.3.4.2.1.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="S5.T6.3.4.2.2" class="ltx_td ltx_align_left"><span id="S5.T6.3.4.2.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T6.3.4.2.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_r"><span id="S5.T6.3.4.2.3.1" class="ltx_text" style="font-size:90%;">L 3, 6, 9</span></td>
<td id="S5.T6.3.4.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S5.T6.3.4.2.4.1" class="ltx_text" style="font-size:90%;">78.4</span></td>
<td id="S5.T6.3.4.2.5" class="ltx_td ltx_align_center"><span id="S5.T6.3.4.2.5.1" class="ltx_text" style="font-size:90%;">16.6</span></td>
<td id="S5.T6.3.4.2.6" class="ltx_td ltx_align_center"><span id="S5.T6.3.4.2.6.1" class="ltx_text" style="font-size:90%;">16.2</span></td>
<td id="S5.T6.3.4.2.7" class="ltx_td ltx_align_center"><span id="S5.T6.3.4.2.7.1" class="ltx_text" style="font-size:90%;">18.0</span></td>
<td id="S5.T6.3.4.2.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T6.3.4.2.8.1" class="ltx_text" style="font-size:90%;">15.4</span></td>
</tr>
<tr id="S5.T6.3.5.3" class="ltx_tr">
<td id="S5.T6.3.5.3.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.3.5.3.1.1" class="ltx_text" style="font-size:90%;">3</span></td>
<td id="S5.T6.3.5.3.2" class="ltx_td ltx_align_left"><span id="S5.T6.3.5.3.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T6.3.5.3.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_r"><span id="S5.T6.3.5.3.3.1" class="ltx_text" style="font-size:90%;">L 3, 6</span></td>
<td id="S5.T6.3.5.3.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S5.T6.3.5.3.4.1" class="ltx_text" style="font-size:90%;">69.1</span></td>
<td id="S5.T6.3.5.3.5" class="ltx_td ltx_align_center"><span id="S5.T6.3.5.3.5.1" class="ltx_text" style="font-size:90%;">18.7</span></td>
<td id="S5.T6.3.5.3.6" class="ltx_td ltx_align_center"><span id="S5.T6.3.5.3.6.1" class="ltx_text" style="font-size:90%;">17.9</span></td>
<td id="S5.T6.3.5.3.7" class="ltx_td ltx_align_center"><span id="S5.T6.3.5.3.7.1" class="ltx_text" style="font-size:90%;">20.1</span></td>
<td id="S5.T6.3.5.3.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T6.3.5.3.8.1" class="ltx_text" style="font-size:90%;">17.8</span></td>
</tr>
<tr id="S5.T6.3.6.4" class="ltx_tr">
<td id="S5.T6.3.6.4.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.3.6.4.1.1" class="ltx_text" style="font-size:90%;">4</span></td>
<td id="S5.T6.3.6.4.2" class="ltx_td ltx_align_left"><span id="S5.T6.3.6.4.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T6.3.6.4.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_r"><span id="S5.T6.3.6.4.3.1" class="ltx_text" style="font-size:90%;">L 3</span></td>
<td id="S5.T6.3.6.4.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S5.T6.3.6.4.4.1" class="ltx_text" style="font-size:90%;">75.3</span></td>
<td id="S5.T6.3.6.4.5" class="ltx_td ltx_align_center"><span id="S5.T6.3.6.4.5.1" class="ltx_text" style="font-size:90%;">19.4</span></td>
<td id="S5.T6.3.6.4.6" class="ltx_td ltx_align_center"><span id="S5.T6.3.6.4.6.1" class="ltx_text" style="font-size:90%;">19.3</span></td>
<td id="S5.T6.3.6.4.7" class="ltx_td ltx_align_center"><span id="S5.T6.3.6.4.7.1" class="ltx_text" style="font-size:90%;">20.0</span></td>
<td id="S5.T6.3.6.4.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T6.3.6.4.8.1" class="ltx_text" style="font-size:90%;">18.4</span></td>
</tr>
<tr id="S5.T6.3.7.5" class="ltx_tr">
<td id="S5.T6.3.7.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.3.7.5.1.1" class="ltx_text" style="font-size:90%;">5</span></td>
<td id="S5.T6.3.7.5.2" class="ltx_td ltx_align_left"><span id="S5.T6.3.7.5.2.1" class="ltx_text" style="font-size:90%;">L 9</span></td>
<td id="S5.T6.3.7.5.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_r"><span id="S5.T6.3.7.5.3.1" class="ltx_text" style="font-size:90%;">L 3, 6</span></td>
<td id="S5.T6.3.7.5.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S5.T6.3.7.5.4.1" class="ltx_text" style="font-size:90%;">77.0</span></td>
<td id="S5.T6.3.7.5.5" class="ltx_td ltx_align_center"><span id="S5.T6.3.7.5.5.1" class="ltx_text" style="font-size:90%;">18.2</span></td>
<td id="S5.T6.3.7.5.6" class="ltx_td ltx_align_center"><span id="S5.T6.3.7.5.6.1" class="ltx_text" style="font-size:90%;">17.8</span></td>
<td id="S5.T6.3.7.5.7" class="ltx_td ltx_align_center"><span id="S5.T6.3.7.5.7.1" class="ltx_text" style="font-size:90%;">19.3</span></td>
<td id="S5.T6.3.7.5.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T6.3.7.5.8.1" class="ltx_text" style="font-size:90%;">17.3</span></td>
</tr>
<tr id="S5.T6.3.8.6" class="ltx_tr">
<td id="S5.T6.3.8.6.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T6.3.8.6.1.1" class="ltx_text" style="font-size:90%;">6</span></td>
<td id="S5.T6.3.8.6.2" class="ltx_td ltx_align_left"><span id="S5.T6.3.8.6.2.1" class="ltx_text" style="font-size:90%;">L 6, 9</span></td>
<td id="S5.T6.3.8.6.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_r"><span id="S5.T6.3.8.6.3.1" class="ltx_text" style="font-size:90%;">L 3</span></td>
<td id="S5.T6.3.8.6.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S5.T6.3.8.6.4.1" class="ltx_text" style="font-size:90%;">80.3</span></td>
<td id="S5.T6.3.8.6.5" class="ltx_td ltx_align_center"><span id="S5.T6.3.8.6.5.1" class="ltx_text" style="font-size:90%;">16.7</span></td>
<td id="S5.T6.3.8.6.6" class="ltx_td ltx_align_center"><span id="S5.T6.3.8.6.6.1" class="ltx_text" style="font-size:90%;">16.4</span></td>
<td id="S5.T6.3.8.6.7" class="ltx_td ltx_align_center"><span id="S5.T6.3.8.6.7.1" class="ltx_text" style="font-size:90%;">18.2</span></td>
<td id="S5.T6.3.8.6.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T6.3.8.6.8.1" class="ltx_text" style="font-size:90%;">15.2</span></td>
</tr>
<tr id="S5.T6.3.9.7" class="ltx_tr">
<td id="S5.T6.3.9.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T6.3.9.7.1.1" class="ltx_text" style="font-size:90%;">7*</span></td>
<td id="S5.T6.3.9.7.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T6.3.9.7.2.1" class="ltx_text" style="font-size:90%;">L 3, 6, 9</span></td>
<td id="S5.T6.3.9.7.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_bb ltx_border_r"><span id="S5.T6.3.9.7.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S5.T6.3.9.7.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T6.3.9.7.4.1" class="ltx_text" style="font-size:90%;">78.6</span></td>
<td id="S5.T6.3.9.7.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.3.9.7.5.1" class="ltx_text" style="font-size:90%;">18.1</span></td>
<td id="S5.T6.3.9.7.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.3.9.7.6.1" class="ltx_text" style="font-size:90%;">17.8</span></td>
<td id="S5.T6.3.9.7.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.3.9.7.7.1" class="ltx_text" style="font-size:90%;">19.3</span></td>
<td id="S5.T6.3.9.7.8" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S5.T6.3.9.7.8.1" class="ltx_text" style="font-size:90%;">17.1</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Experiment 2</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p"><span id="S5.SS5.p1.1.1" class="ltx_text" style="font-size:90%;">The E-branchformer architecture using the best InterCTC configuration established in Experiment 1 is explored to compare the performance of the Conformer and the E-branchformer encoder. Two models are trained using the E-branchformer encoder - a smaller version (45.8m trainable parameters) and a larger version (130m trainable parameters). For further details see Section¬†</span><a href="#S5.SS1" title="5.1 Setup ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5.1</span></a><span id="S5.SS5.p1.1.2" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p"><span id="S5.SS5.p2.1.1" class="ltx_text" style="font-size:90%;">The best configuration (row 6 in Table¬†</span><a href="#S5.T6" title="Table 6 ‚Ä£ 5.4 Experiment 1 ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S5.SS5.p2.1.2" class="ltx_text" style="font-size:90%;">) of Experiment¬†1 is selected to compare the performance of Conformer and E-branchformer encoders in this experiment. Results are presented in Table¬†</span><a href="#S5.T7" title="Table 7 ‚Ä£ 5.5 Experiment 2 ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">7</span></a><span id="S5.SS5.p2.1.3" class="ltx_text" style="font-size:90%;">. E-branchformer Small is the best performing model in terms of DID, with an accuracy of 81.4%, an improvement of 1.1% absolute. The model‚Äôs WER performance however is worse, suggesting that the smaller number of trainable parameters more strongly affects WER performance than it does DID performance. E-branchformer Large performs slightly worse than the Conformer model in terms of DID, but it has a relative WER performance gain of 6%.</span></p>
</div>
<figure id="S5.T7" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 7: </span>DID &amp; ASR performance for Conformer and E-branchformer encoders and multi-task LM shallow fusion.</figcaption>
<table id="S5.T7.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T7.3.1.1" class="ltx_tr">
<th id="S5.T7.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S5.T7.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Encoder</span></th>
<th id="S5.T7.3.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S5.T7.3.1.1.2.1" class="ltx_text" style="font-size:90%;">DID</span></th>
<th id="S5.T7.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="S5.T7.3.1.1.3.1" class="ltx_text" style="font-size:90%;">WER</span></th>
</tr>
<tr id="S5.T7.3.2.2" class="ltx_tr">
<th id="S5.T7.3.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S5.T7.3.2.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S5.T7.3.2.2.2.1" class="ltx_text" style="font-size:90%;">Acc</span></th>
<th id="S5.T7.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.3.2.2.3.1" class="ltx_text" style="font-size:90%;">All</span></th>
<th id="S5.T7.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.3.2.2.4.1" class="ltx_text" style="font-size:90%;">Ul</span></th>
<th id="S5.T7.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.3.2.2.5.1" class="ltx_text" style="font-size:90%;">Co</span></th>
<th id="S5.T7.3.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.3.2.2.6.1" class="ltx_text" style="font-size:90%;">Mu</span></th>
</tr>
<tr id="S5.T7.3.3.3" class="ltx_tr">
<th id="S5.T7.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.3.3.3.1.1" class="ltx_text" style="font-size:90%;">Conformer</span></th>
<th id="S5.T7.3.3.3.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.3.3.3.2.1" class="ltx_text" style="font-size:90%;">80.3</span></th>
<th id="S5.T7.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T7.3.3.3.3.1" class="ltx_text" style="font-size:90%;">16.7</span></th>
<th id="S5.T7.3.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T7.3.3.3.4.1" class="ltx_text" style="font-size:90%;">16.4</span></th>
<th id="S5.T7.3.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T7.3.3.3.5.1" class="ltx_text" style="font-size:90%;">18.2</span></th>
<th id="S5.T7.3.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T7.3.3.3.6.1" class="ltx_text" style="font-size:90%;">15.2</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T7.3.4.1" class="ltx_tr">
<th id="S5.T7.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.3.4.1.1.1" class="ltx_text" style="font-size:90%;">E-Branchformer Small</span></th>
<th id="S5.T7.3.4.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.3.4.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">81.5</span></th>
<td id="S5.T7.3.4.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.3.4.1.3.1" class="ltx_text" style="font-size:90%;">17.7</span></td>
<td id="S5.T7.3.4.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.3.4.1.4.1" class="ltx_text" style="font-size:90%;">17.6</span></td>
<td id="S5.T7.3.4.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.3.4.1.5.1" class="ltx_text" style="font-size:90%;">19.1</span></td>
<td id="S5.T7.3.4.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.3.4.1.6.1" class="ltx_text" style="font-size:90%;">16.3</span></td>
</tr>
<tr id="S5.T7.3.5.2" class="ltx_tr">
<th id="S5.T7.3.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S5.T7.3.5.2.1.1" class="ltx_text" style="font-size:90%;">E-Branchformer Large</span></th>
<th id="S5.T7.3.5.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T7.3.5.2.2.1" class="ltx_text" style="font-size:90%;">80.0</span></th>
<td id="S5.T7.3.5.2.3" class="ltx_td ltx_align_center"><span id="S5.T7.3.5.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">15.7</span></td>
<td id="S5.T7.3.5.2.4" class="ltx_td ltx_align_center"><span id="S5.T7.3.5.2.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">15.5</span></td>
<td id="S5.T7.3.5.2.5" class="ltx_td ltx_align_center"><span id="S5.T7.3.5.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">17.0</span></td>
<td id="S5.T7.3.5.2.6" class="ltx_td ltx_align_center"><span id="S5.T7.3.5.2.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">14.5</span></td>
</tr>
<tr id="S5.T7.3.6.3" class="ltx_tr">
<th id="S5.T7.3.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S5.T7.3.6.3.1.1" class="ltx_text" style="font-size:90%;">¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† + LM</span></th>
<th id="S5.T7.3.6.3.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S5.T7.3.6.3.2.1" class="ltx_text" style="font-size:90%;">80.8</span></th>
<td id="S5.T7.3.6.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T7.3.6.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">13.5</span></td>
<td id="S5.T7.3.6.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T7.3.6.3.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">13.0</span></td>
<td id="S5.T7.3.6.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T7.3.6.3.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">14.9</span></td>
<td id="S5.T7.3.6.3.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T7.3.6.3.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">12.3</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Experiment 3</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p"><span id="S5.SS6.p1.1.1" class="ltx_text" style="font-size:90%;">This experiment explores the usefulness of multi-task shallow fusion. A transformer language model was initially trained with a larger corpus of Irish text and fine-tuned on a smaller dialect-tagged corpus of Irish text for multi-task DID and ASR shallow fusion. For details of the corpora used, see Table¬†</span><a href="#S3.T3" title="Table 3 ‚Ä£ 3.2 Text corpora for shallow-fusion experiment ‚Ä£ 3 Data ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S5.SS6.p1.1.2" class="ltx_text" style="font-size:90%;">. A grid-search found 0.3 to be the optimal weight for shallow fusion.</span></p>
</div>
<div id="S5.SS6.p2" class="ltx_para">
<p id="S5.SS6.p2.1" class="ltx_p"><span id="S5.SS6.p2.1.1" class="ltx_text" style="font-size:90%;">The results for LM shallow fusion can also be seen in Table¬†</span><a href="#S5.T7" title="Table 7 ‚Ä£ 5.5 Experiment 2 ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">7</span></a><span id="S5.SS6.p2.1.2" class="ltx_text" style="font-size:90%;">. A slight improvement in DID classification accuracy of 0.8% was gained through shallow fusion, but its most significant contribution is, unsurprisingly, a reduction of WER by 2.2%.</span></p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion and Conclusions</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text" style="font-size:90%;">The hybrid CTC/Attention-based encoder-decoder architecture emerges as a good strategy for Irish multi-task ASR and DID. The best results were obtained from the E-branchformer Large model with the optimal InterCTC setting (established in Experiment 1) and multi-task LM shallow fusion, where the LM was fine-tuned with dialect labels prepended to the text. That the inclusion of LM shallow fusion improves DID accuracy slightly is an encouraging finding. Perhaps with more available dialect-tagged text corpora, such an approach could garner further improvement.</span></p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text" style="font-size:90%;">The present DID results are promising in that they surpass the previous best model trained (ECAPA-TDNN). The best DID accuracy obtained here is 81.5% compared to 73% obtained in¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S6.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S6.p2.1.4" class="ltx_text" style="font-size:90%;">. The overall contribution of InterCTC to DID accuracy is slight, as can be seen by comparing row 1 in Table¬†</span><a href="#S5.T6" title="Table 6 ‚Ä£ 5.4 Experiment 1 ‚Ä£ 5 Experiments ‚Ä£ Low-resource speech recognition and dialect identification of Irish in a multi-task framework" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S6.p2.1.5" class="ltx_text" style="font-size:90%;"> with the other rows. Only in one case (row 6) does the inclusion of InterCTC yield a DID improvement. This differs from what was found in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p2.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S6.p2.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S6.p2.1.8" class="ltx_text" style="font-size:90%;"> and </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p2.1.9.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S6.p2.1.10.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S6.p2.1.11" class="ltx_text" style="font-size:90%;">, where InterCTC improved the speech classification accuracy more considerably.</span></p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p"><span id="S6.p3.1.1" class="ltx_text" style="font-size:90%;">As regards WER, training for multi-task DID and ASR does lead to some performance degradation. However, when the InterCTC objectives are optimally set, the WER degradation is greatly lessened. While the ASR performance of these E2E models is not better than the modular TDNN-HMM model, the gap between the two approaches is reduced a great deal and this approach promises to be a fruitful avenue for continued exploration.</span></p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgements</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p"><span id="S7.p1.1.1" class="ltx_text" style="font-size:90%;">This work is part of the ABAIR initiative, which is supported by the Department of Tourism, Culture, Arts, the Gaeltacht, Sport and Media, with funding from the National Lottery, as part of the 20-year Strategy for Irish. The authors gratefully acknowledge the speakers and publishers that have contributed to this work.</span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Liam Lonergan, Mengjie Qian, Harald Berthelsen, Andy Murphy, Christoph Wendler, Neasa¬†N√≠ Chiar√°in, Christer Gobl, and Ailbhe¬†N√≠ Chasaide,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">‚ÄúAutomatic speech recognition for irish: the abair-√©ist system,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 4th Celtic Language Technology Workshop within LREC2022</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 47‚Äì51.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Liam Lonergan, Mengjie Qian, Neasa N√≠ Chiar√°in, Christer Gobl, and Ailbhe N√≠ Chasaide,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">‚ÄúTowards Dialect-inclusive Recognition in a Low-resource Language: Are Balanced Corpora the Answer?,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH 2023</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 5082‚Äì5086.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Liam Lonergan, Mengjie Qian, Neasa N√≠¬†Chiar√°in, Christer Gobl, and Ailbhe N√≠¬†Chasaide,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">‚ÄúTowards spoken dialect identification of irish,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2nd annual meeting of the Special Interest Group of Under-resourced Languages, a Workshop at Interspeech 2023, Dublin, Ireland</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, and Michael Auli,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">‚ÄúXLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2022</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 2278‚Äì2282.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Shubham Toshniwal, Tara¬†N. Sainath, Ron¬†J. Weiss, Bo¬†Li, Pedro Moreno, Eugene Weinstein, and Kanishka Rao,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">‚ÄúMultilingual Speech Recognition with a Single End-to-End Model,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 4904‚Äì4908.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
William Chen, Brian Yan, Jiatong Shi, Yifan Peng, Soumi Maiti, and Shinji Watanabe,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">‚ÄúImproving massively multilingual asr with auxiliary ctc objectives,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2023, pp. 1‚Äì5.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
David Mart√≠nez, Old≈ôich Plchot, Luk√°≈° Burget, Ond≈ôej Glembek, and Pavel Matƒõjka,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">‚ÄúLanguage recognition in ivectors space,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2011</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, 2011, pp. 861‚Äì864.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Najim Dehak, Patrick¬†J Kenny, R√©da Dehak, Pierre Dumouchel, and Pierre Ouellet,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">‚ÄúFront-end factor analysis for speaker verification,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Audio, Speech, and Language Processing</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, vol. 19, no. 4, pp. 788‚Äì798, 2010.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
David Snyder, Daniel Garcia-Romero, Gregory Sell, Daniel Povey, and Sanjeev Khudanpur,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">‚ÄúX-vectors: Robust dnn embeddings for speaker recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2018, pp. 5329‚Äì5333.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Zhiyuan Tang, Dong Wang, Yixiang Chen, Lantian Li, and Andrew Abel,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">‚ÄúPhonetic temporal neural model for language identification,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, vol. 26, no. 1, pp. 134‚Äì144, 2017.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Houjun Huang, Xu¬†Xiang, Yexin Yang, Rao Ma, and Yanmin Qian,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">‚ÄúAISpeech-SJTU Accent Identification System for the Accented English Speech Recognition Challenge,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 6254‚Äì6258.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Rapha√´l Duroselle, Md¬†Sahidullah, Denis Jouvet, and Irina Illina,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">‚ÄúModeling and training strategies for language recognition systems,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2021</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Binling Wang, Wenxuan Hu, Jing Li, Yiming Zhi, Zheng Li, Qingyang Hong, Lin Li, Dong Wang, Liming Song, and Cheng Yang,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">‚ÄúOLR 2021 challenge: Datasets, rules and baselines,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2021, pp. 1097‚Äì1103.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Anqi Lyu, Zhiming Wang, and Huijia Zhu,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">‚ÄúAnt Multilingual Recognition System for OLR 2021 Challenge,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2022</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 3684‚Äì3688.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Surabhi Punjabi, Harish Arsikere, Zeynab Raeesy, Chander Chandak, Nikhil Bhave, Ankish Bansal, Markus M√ºller, Sergio Murillo, Ariya Rastrow, Andreas Stolcke, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">‚ÄúJoint ASR and language identification using RNN-T: An efficient approach to dynamic language switching,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2021, pp. 7218‚Äì7222.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Ryo Imaizumi, Ryo Masumura, Sayaka Shiota, Hitoshi Kiya, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">‚ÄúEnd-to-end japanese multi-dialect speech recognition and dialect identification with multi-task learning,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">APSIPA Transactions on Signal and Information Processing</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, vol. 11, no. 1, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Bo¬†Li, Tara¬†N. Sainath, Khe¬†Chai Sim, Michiel Bacchiani, Eugene Weinstein, Patrick Nguyen, Zhifeng Chen, Yanghui Wu, and Kanishka Rao,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">‚ÄúMulti-Dialect Speech Recognition with a Single Sequence-to-Sequence Model,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 4749‚Äì4753.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Jaesong Lee and Shinji Watanabe,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">‚ÄúIntermediate loss regularization for ctc-based speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2021, pp. 6224‚Äì6228.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Ramon Sanabria and Florian Metze,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">‚ÄúHierarchical multitask learning with ctc,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE Spoken Language Technology Workshop (SLT)</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2018, pp. 485‚Äì490.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Jiyang Tang, William Chen, Xuankai Chang, Shinji Watanabe, and Brian MacWhinney,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">‚ÄúA New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. INTERSPEECH 2023</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 1528‚Äì1532.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Ludwig K√ºrzinger, Dominik Winkelbauer, Lujun Li, Tobias Watzel, and Gerhard Rigoll,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">‚ÄúCtc-segmentation of large corpora for german end-to-end speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Speech and Computer</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">. Springer, 2020, pp. 267‚Äì278.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Shinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro Nishitoba, Yuya Unno, Nelson Enrique Yalta Soplin, Jahn Heymann, Matthew Wiesner, Nanxin Chen, Adithya Renduchintala, and Tsubasa Ochiai,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">‚ÄúESPnet: End-to-End Speech Processing Toolkit,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2018</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 2207‚Äì2211.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu¬†Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, and Ruoming Pang,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">‚ÄúConformer: Convolution-augmented Transformer for Speech Recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2020</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, 2020, pp. 5036‚Äì5040.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Shinnosuke Takamichi, Ludwig K√ºrzinger, Takaaki Saeki, Sayaka Shiota, and Shinji Watanabe,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">‚ÄúJtubespeech: corpus of japanese speech collected from youtube for speech recognition and speaker verification,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv e-prints</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, pp. arXiv‚Äì2112, 2021.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Vimal Manohar, Daniel Povey, and Sanjeev Khudanpur,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">‚ÄúJHU Kaldi system for Arabic MGB-3 ASR challenge using diarization, audio-transcript alignment and transfer learning,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE automatic speech recognition and understanding workshop (ASRU)</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2017, pp. 346‚Äì352.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Marta Ba√±√≥n, Pinzhen Chen, Barry Haddow, Kenneth Heafield, Hieu Hoang, Miquel Espl√†-Gomis, Mikel¬†L. Forcada, Amir Kamran, Faheem Kirefu, Philipp Koehn, Sergio Ortiz¬†Rojas, Leopoldo Pla¬†Sempere, Gema Ram√≠rez-S√°nchez, Elsa Sarr√≠as, Marek Strelec, Brian Thompson, William Waites, Dion Wiggins, and Jaume Zaragoza,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">‚ÄúParaCrawl: Web-Scale Acquisition of Parallel Corpora,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, Eds., Online, July 2020, pp. 4555‚Äì4567, Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Daniel Zeman, Martin Popel, Milan Straka, Jan Hajiƒç, Joakim Nivre, Filip Ginter, Juhani Luotolahti, Sampo Pyysalo, Slav Petrov, Martin Potthast, Francis Tyers, Elena Badmaeva, Memduh Gokirmak, Anna Nedoluzhko, Silvie Cinkov√°, Jan Hajiƒç¬†jr., Jaroslava Hlav√°ƒçov√°, V√°clava Kettnerov√°, Zde≈àka Ure≈°ov√°, Jenna Kanerva, Stina Ojala, Anna Missil√§, Christopher¬†D. Manning, Sebastian Schuster, Siva Reddy, Dima Taji, Nizar Habash, Herman Leung, Marie-Catherine de¬†Marneffe, Manuela Sanguinetti, Maria Simi, Hiroshi Kanayama, Valeria de¬†Paiva, Kira Droganova, H√©ctor Mart√≠nez¬†Alonso, √áaƒürƒ± √á√∂ltekin, Umut Sulubacak, Hans Uszkoreit, Vivien Macketanz, Aljoscha Burchardt, Kim Harris, Katrin Marheinecke, Georg Rehm, Tolga Kayadelen, Mohammed Attia, Ali Elkahky, Zhuoran Yu, Emily Pitler, Saran Lertpradit, Michael Mandl, Jesse Kirchner, Hector¬†Fernandez Alcalde, Jana Strnadov√°, Esha Banerjee, Ruli Manurung, Antonio Stella, Atsuko Shimada,
Sookyoung Kwak, Gustavo Mendon√ßa, Tatiana Lando, Rattima Nitisaroj, and Josie Li,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">‚ÄúCoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, Jan Hajiƒç and Dan Zeman, Eds., Vancouver, Canada, Aug. 2017, pp. 1‚Äì19, Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Shinji Watanabe, Takaaki Hori, Suyoun Kim, John¬†R Hershey, and Tomoki Hayashi,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">‚ÄúHybrid ctc/attention architecture for end-to-end speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Journal of Selected Topics in Signal Processing</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, vol. 11, no. 8, pp. 1240‚Äì1253, 2017.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Alex Graves, Santiago Fern√°ndez, Faustino Gomez, and J√ºrgen Schmidhuber,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">‚ÄúConnectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 23rd international conference on Machine learning</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, 2006, pp. 369‚Äì376.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Kwangyoun Kim, Felix Wu, Yifan Peng, Jing Pan, Prashant Sridhar, Kyu¬†J Han, and Shinji Watanabe,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">‚ÄúE-branchformer: Branchformer with enhanced merging for speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE Spoken Language Technology Workshop (SLT)</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2023, pp. 84‚Äì91.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Liam Lonergan, Mengjie Qian, Neasa¬†N√≠ Chiar√°in, Christer Gobl, and Ailbhe¬†N√≠ Chasaide,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">‚ÄúCross-dialect lexicon optimisation for an endangered language ASR system: the case of Irish,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2022</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, 2022, pp. 4865‚Äì4869.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Mirco Ravanelli, Titouan Parcollet, Peter Plantinga, Aku Rouhe, Samuele Cornell, Loren Lugosch, Cem Subakan, Nauman Dawalatabad, Abdelwahab Heba, Jianyuan Zhong, Ju-Chieh Chou, Sung-Lin Yeh, Szu-Wei Fu, Chien-Feng Liao, Elena Rastorgueva, Fran√ßois Grondin, William Aris, Hwidong Na, Yan Gao, Renato¬†De Mori, and Yoshua Bengio,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSpeechBrain: A general-purpose speech toolkit,‚Äù 2021,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">arXiv:2106.04624.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
J√∂rgen Valk and Tanel Alum√§e,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">‚ÄúVoxLingua107: a dataset for spoken language recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. IEEE SLT Workshop</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">‚ÄúArcface: Additive angular margin loss for deep face recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 4690‚Äì4699.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.01292" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.01293" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.01293">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.01293" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.01294" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 13:01:02 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
