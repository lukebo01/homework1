<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.06580] Exploring Differences between Human Perception and Model Inference in Audio Event Recognition</title><meta property="og:description" content="Audio Event Recognition (AER) traditionally focuses on detecting and identifying audio events. Most existing AER models tend to detect all potential events without considering their varying significance across differenâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Exploring Differences between Human Perception and Model Inference in Audio Event Recognition">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Exploring Differences between Human Perception and Model Inference in Audio Event Recognition">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.06580">

<!--Generated on Sat Oct  5 21:39:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Audio Event Recognition,  Human Perception in Audio,  Semantic Audio Events
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
Exploring Differences between Human Perception and Model Inference in Audio Event Recognition
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yizhou Tan1, Yanru Wu1, Yuanbo Hou2, Xin Xu3, Hui Bu3 
<br class="ltx_break">Shengchen Li1, Dick Botteldooren2, Mark D. Plumbley4

<br class="ltx_break">1Xiâ€™an Jiaotong-Liverpool University, Suzhou, China 
<br class="ltx_break">2WAVES Research Group, Ghent University, Belgium
3Beijing AISHELL Technology Co., Ltd, China 
<br class="ltx_break">4University of Surrey, Guildford, United Kingdom 
<br class="ltx_break">{Yizhou.Tan22, Yanru.Wu21}@student.xjtlu.edu.cn, Shengchen.Li@xjtlu.edu.cn 
<br class="ltx_break">{Yuanbo.Hou, Dick.Botteldooren}@UGent.be,
{Xuxin, Buhui}@aishelldata.com,
M.Plumbley@Surrey.ac.uk
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Audio Event Recognition (AER) traditionally focuses on detecting and identifying audio events. Most existing AER models tend to detect all potential events without considering their varying significance across different contexts. This makes the AER results detected by existing models often have a large discrepancy with human auditory perception. Although this is a critical and significant issue, it has not been extensively studied by the Detection and Classification of Sound Scenes and Events (DCASE) community because solving it is time-consuming and labour-intensive. To address this issue, this paper introduces the concept of semantic importance in AER, focusing on exploring the differences between human perception and model inference. This paper constructs a Multi-Annotated Foreground Audio Event Recognition (MAFAR) dataset, which comprises audio recordings labelled by 10 professional annotators. Through labelling frequency and variance, the MAFAR dataset facilitates the quantification of semantic importance and analysis of human perception. By comparing human annotations with the predictions of ensemble pre-trained models, this paper uncovers a significant gap between human perception and model inference in both semantic identification and existence detection of audio events. Experimental results reveal that human perception tends to ignore subtle or trivial events in the event semantic identification, while model inference is easily affected by events with noises. Meanwhile, in event existence detection, models are usually more sensitive than humans.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Audio Event Recognition, Human Perception in Audio, Semantic Audio Events

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Audio Event Recognition (AER) is vital for detecting and identifying audio events within an audio stream. With the advancement of AER research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, a large volume of labelled audio data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> has been generated to build systems capable of detecting all potential audio events. However, the importance of specific audio events can vary significantly depending on the context in which they occur <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. For example, the sound of a running car might be considered background noise in a bustling city, but the same sound in a remote forest could signify a rare human presence or an unusual occurrence.
Given that human perception naturally assigns different levels of attention to the same event in varying contexts, AER systems need to go beyond mere detection and incorporate an understanding of the semantic importance of audio events based on their environmental relevance.
This work aims to construct the notion of semantic importance in AER, drawing on human understanding to analyze the gap between current model inference and human perception.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Although several works have verified the scene of audio is identifiable <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and introduced the context information to improve the audio-pattern recognition performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, there are few researches to explore how to quantify the semantic importance. This work assumes that the semantic importance of the same events may vary among individuals or groups. Due to cognitive and cultural differences, individuals may focus on specific events to varying degrees, indicating that the sole annotation of ground truth can not quantitatively reflect semantic importance.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To solve the data annotation problem, this work constructs an available Multi-Annotated Foreground Audio Event Recognition (MAFAR) dataset containing 180 minutes of audio data and 10 different sets of labels.
The dataset was collected during a real trip in 4 cities, including Shanghai, London, Gent, and Rotterdam, by a GoPro device. During the annotation process, each audio file was independently labelled by 10 professional annotators. Unlike conventional datasets with predefined labels, this work did not provide a closed label set in advance. Instead, annotators were asked to label â€œprominent and noticeableâ€ events as foreground events using descriptive texts to reflect their original perception. In the later experiments, these descriptive texts were aligned to a subset (86 classes) of the large-scale AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> by a large language model GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, but the alignment is not compulsory for future works.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Based on the MAFAR dataset, this work tries to use the variance and frequency in the annotation distribution to define the perception of the human group in two dimensions: event semantic identification and existence detection. The variance reflects the level of agreement among annotators regarding event identification, while the frequency indicates the interest weight of the existing events. Based on this definition, this work explores the differences between human perception and model inference in two key areas: event semantic identification and event existence detection.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">By comparing the variance of human annotation and ensemble model inference, the experiments uncover humans tend to overlook subtle or trivial events in event semantic identification, while models are more prone to being influenced by noisy events. In event existence detection, by adjusting annotation frequency thresholds to set the different ground truths, the changes in model performance highlight that models have greater sensitivity than humans, effectively identifying events even at lower annotation frequencies.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">This paper is organized as follows:
Section II introduces the MAFAR dataset.
Section III shows the benchmark method and results of measuring the differences between human perception and model inference.
Section IV discusses the potential reason for the results.
Section V concludes our work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">MAFAR Dataset</span>
</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2409.06580/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="110" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The process of label alignment is assisted by GPT-4.
</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">All data from the MAFAR dataset was collected from a trip in Shanghai, London, Gent, and Rotterdam by a GoPro device, while the GoPro was worn on the chest of a person walking through these cities. The raw data is stored in video format, consisting of 25 files and 180 minutes in total. For each file, 10 professional annotators are required to annotate the â€œprominent and noticeableâ€ events in the audio, mainly referring to the audio information and supplemented by visual information. The annotation comprises the file name, start time, end time and a descriptive text of the labelled period. (Dataset homepage: <a target="_blank" href="https://github.com/Voltmeter00/MAFAR" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Voltmeter00/MAFAR</a>)</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Annotation Guidelines for Humans</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Since there is no pre-given set of categories, the whole annotation process mainly relies on human perceptions and the following guidelines:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Foreground sounds are distinctly prominent and noticeable in the scene while watching the video or listening to the audio. These sounds are crucial to the scene and significantly contribute to the overall experience.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Annotate the timestamps for the start and end of the foreground sound. The duration is not restricted, and the focus should be on the completeness of the event.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p">Use simple words to describe the audio events, adding adjectives like â€œclose,â€ â€œloud,â€ â€œsharp,â€ etc.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Label Alignment via Large Language Model</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To facilitate the involvement of descriptive text labels in training deep learning models, this work tries to align human annotations with a commonly used label set, namely 527 classes of AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
The challenges were encountered in translating free-form natural language descriptions into predefined categories. Descriptive and subjective terms were often used by human annotators to label the audio events, making the direct mapping to a fixed set of categories complex.
A large language model (LLM), specifically GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, was utilized to assist in converting human-generated labels into AudioSet labels, with the following pipeline:</p>
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">The GPT-4 tried to align the provided descriptive texts to the most relevant AudioSet class, as shown in Fig. <a href="#S2.F1" title="Figure 1 â€£ II MAFAR Dataset â€£ Exploring Differences between Human Perception and Model Inference in Audio Event Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2409.06580/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="207" height="207" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The frequency of 86 classes of audio events after label alignment.</figcaption>
</figure>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2409.06580/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="392" height="317" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Subfigures (a) and (b) show the top 40 classes that are the most difficult to reach agreement in humans and models, respectively. The orange bars indicate the overlapped classes between the top 40 classes in humans and machines. Subfigure (c) shows the top 40 classes with the largest gap between human perception and model inference, where each <math id="S2.F3.3.m1.1" class="ltx_Math" alttext="a_{c}&lt;0" display="inline"><semantics id="S2.F3.3.m1.1b"><mrow id="S2.F3.3.m1.1.1" xref="S2.F3.3.m1.1.1.cmml"><msub id="S2.F3.3.m1.1.1.2" xref="S2.F3.3.m1.1.1.2.cmml"><mi id="S2.F3.3.m1.1.1.2.2" xref="S2.F3.3.m1.1.1.2.2.cmml">a</mi><mi id="S2.F3.3.m1.1.1.2.3" xref="S2.F3.3.m1.1.1.2.3.cmml">c</mi></msub><mo id="S2.F3.3.m1.1.1.1" xref="S2.F3.3.m1.1.1.1.cmml">&lt;</mo><mn id="S2.F3.3.m1.1.1.3" xref="S2.F3.3.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.3.m1.1c"><apply id="S2.F3.3.m1.1.1.cmml" xref="S2.F3.3.m1.1.1"><lt id="S2.F3.3.m1.1.1.1.cmml" xref="S2.F3.3.m1.1.1.1"></lt><apply id="S2.F3.3.m1.1.1.2.cmml" xref="S2.F3.3.m1.1.1.2"><csymbol cd="ambiguous" id="S2.F3.3.m1.1.1.2.1.cmml" xref="S2.F3.3.m1.1.1.2">subscript</csymbol><ci id="S2.F3.3.m1.1.1.2.2.cmml" xref="S2.F3.3.m1.1.1.2.2">ğ‘</ci><ci id="S2.F3.3.m1.1.1.2.3.cmml" xref="S2.F3.3.m1.1.1.2.3">ğ‘</ci></apply><cn type="integer" id="S2.F3.3.m1.1.1.3.cmml" xref="S2.F3.3.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.3.m1.1d">a_{c}&lt;0</annotation></semantics></math> and <math id="S2.F3.4.m2.1" class="ltx_Math" alttext="a_{c}&gt;0" display="inline"><semantics id="S2.F3.4.m2.1b"><mrow id="S2.F3.4.m2.1.1" xref="S2.F3.4.m2.1.1.cmml"><msub id="S2.F3.4.m2.1.1.2" xref="S2.F3.4.m2.1.1.2.cmml"><mi id="S2.F3.4.m2.1.1.2.2" xref="S2.F3.4.m2.1.1.2.2.cmml">a</mi><mi id="S2.F3.4.m2.1.1.2.3" xref="S2.F3.4.m2.1.1.2.3.cmml">c</mi></msub><mo id="S2.F3.4.m2.1.1.1" xref="S2.F3.4.m2.1.1.1.cmml">&gt;</mo><mn id="S2.F3.4.m2.1.1.3" xref="S2.F3.4.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F3.4.m2.1c"><apply id="S2.F3.4.m2.1.1.cmml" xref="S2.F3.4.m2.1.1"><gt id="S2.F3.4.m2.1.1.1.cmml" xref="S2.F3.4.m2.1.1.1"></gt><apply id="S2.F3.4.m2.1.1.2.cmml" xref="S2.F3.4.m2.1.1.2"><csymbol cd="ambiguous" id="S2.F3.4.m2.1.1.2.1.cmml" xref="S2.F3.4.m2.1.1.2">subscript</csymbol><ci id="S2.F3.4.m2.1.1.2.2.cmml" xref="S2.F3.4.m2.1.1.2.2">ğ‘</ci><ci id="S2.F3.4.m2.1.1.2.3.cmml" xref="S2.F3.4.m2.1.1.2.3">ğ‘</ci></apply><cn type="integer" id="S2.F3.4.m2.1.1.3.cmml" xref="S2.F3.4.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.4.m2.1d">a_{c}&gt;0</annotation></semantics></math> provide 20 classes.</figcaption>
</figure>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">A manual review was still necessary after GPT-4. Labels, particularly for more complex or less common audio events, were reviewed by experimenters, and adjustments were made where required to ensure the labels accurately reflected the audio content.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p">After the initial label mapping by GPT-4 and subsequent manual adjustments, a final consistency check was conducted to ensure uniformity across all annotations.</p>
</div>
</li>
</ol>
<p id="S2.SS2.p1.2" class="ltx_p">At last, the descriptive texts in the MAFAR dataset are aligned to a subset of the AudioSet label set, containing 86 classes. The frequency of aligned classes can be found in Fig. <a href="#S2.F2" title="Figure 2 â€£ item 1 â€£ II-B Label Alignment via Large Language Model â€£ II MAFAR Dataset â€£ Exploring Differences between Human Perception and Model Inference in Audio Event Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Benchmark Methods and Resutls</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This work introduces event semantic identification and existence detection to compare the semantic importance in human perception and model inference. The model inference is simulated by an ensemble model group of 6 state-of-the-art (SOTA) pre-trained models on AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, including Transformer-based EAT-Base <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and EAT-Large <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, pure convolutional neural network (CNN)-based PANNs-16k <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and PANNs-8k <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, as well as two extra models (with mAP = 0.495 and 0.504), which are currently under review and will be publicly available soon.
For model predictions, this work converts the ensemble of modelsâ€™ output probabilities of audio events to hard labels using a threshold of 0.5, which simulates modelsâ€™ recognition of prominent and noticeable events to comprehensively compare the foreground events labelled by 10 professional annotators in Section <a href="#S2" title="II MAFAR Dataset â€£ Exploring Differences between Human Perception and Model Inference in Audio Event Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Difference in Event Semantic Identification</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">For the semantic identification of events <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, humans and models may exhibit different tendencies for specific classes, creating a gap between them<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. However, a major challenge arises when comparing these identifying tendencies: significant differences can exist between individual human perceptions, and in extreme cases, the variation between two humans may be larger than that between humans and machines. Inspired by Carlini et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, which verified the ensemble agreement of models could reflect the representativeness of samples, this work proposes measuring the consistency of agreement between human and model groups to better understand their respective tendencies.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.5" class="ltx_p">Specifically, for each audio segment <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">x</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">x_{i}</annotation></semantics></math>, human and model groups will provide an annotated and predicted label set, <math id="S3.SS1.p2.2.m2.3" class="ltx_Math" alttext="H_{i}=\{y_{i}^{1},y_{i}^{2},\cdots,y_{i}^{s}|y_{i}^{s}\in R^{N}\}" display="inline"><semantics id="S3.SS1.p2.2.m2.3a"><mrow id="S3.SS1.p2.2.m2.3.3" xref="S3.SS1.p2.2.m2.3.3.cmml"><msub id="S3.SS1.p2.2.m2.3.3.4" xref="S3.SS1.p2.2.m2.3.3.4.cmml"><mi id="S3.SS1.p2.2.m2.3.3.4.2" xref="S3.SS1.p2.2.m2.3.3.4.2.cmml">H</mi><mi id="S3.SS1.p2.2.m2.3.3.4.3" xref="S3.SS1.p2.2.m2.3.3.4.3.cmml">i</mi></msub><mo id="S3.SS1.p2.2.m2.3.3.3" xref="S3.SS1.p2.2.m2.3.3.3.cmml">=</mo><mrow id="S3.SS1.p2.2.m2.3.3.2.2" xref="S3.SS1.p2.2.m2.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.3.3.2.2.3" xref="S3.SS1.p2.2.m2.3.3.2.3.1.cmml">{</mo><mrow id="S3.SS1.p2.2.m2.2.2.1.1.1.3" xref="S3.SS1.p2.2.m2.2.2.1.1.1.4.cmml"><msubsup id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.2" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.2.cmml">y</mi><mi id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.3" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.3.cmml">i</mi><mn id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.3" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.SS1.p2.2.m2.2.2.1.1.1.3.4" xref="S3.SS1.p2.2.m2.2.2.1.1.1.4.cmml">,</mo><msubsup id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.cmml"><mi id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.2.cmml">y</mi><mi id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.3" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.3.cmml">i</mi><mn id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.3" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS1.p2.2.m2.2.2.1.1.1.3.5" xref="S3.SS1.p2.2.m2.2.2.1.1.1.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">â‹¯</mi><mo id="S3.SS1.p2.2.m2.2.2.1.1.1.3.6" xref="S3.SS1.p2.2.m2.2.2.1.1.1.4.cmml">,</mo><msubsup id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.cmml"><mi id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.2" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.2.cmml">y</mi><mi id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.3" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.3.cmml">i</mi><mi id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.3" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.3.cmml">s</mi></msubsup></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.3.3.2.2.4" xref="S3.SS1.p2.2.m2.3.3.2.3.1.cmml">|</mo><mrow id="S3.SS1.p2.2.m2.3.3.2.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.2.cmml"><msubsup id="S3.SS1.p2.2.m2.3.3.2.2.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2.cmml"><mi id="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.2" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.2.cmml">y</mi><mi id="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.3" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.3.cmml">i</mi><mi id="S3.SS1.p2.2.m2.3.3.2.2.2.2.3" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2.3.cmml">s</mi></msubsup><mo id="S3.SS1.p2.2.m2.3.3.2.2.2.1" xref="S3.SS1.p2.2.m2.3.3.2.2.2.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.2.m2.3.3.2.2.2.3" xref="S3.SS1.p2.2.m2.3.3.2.2.2.3.cmml"><mi id="S3.SS1.p2.2.m2.3.3.2.2.2.3.2" xref="S3.SS1.p2.2.m2.3.3.2.2.2.3.2.cmml">R</mi><mi id="S3.SS1.p2.2.m2.3.3.2.2.2.3.3" xref="S3.SS1.p2.2.m2.3.3.2.2.2.3.3.cmml">N</mi></msup></mrow><mo stretchy="false" id="S3.SS1.p2.2.m2.3.3.2.2.5" xref="S3.SS1.p2.2.m2.3.3.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.3b"><apply id="S3.SS1.p2.2.m2.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3"><eq id="S3.SS1.p2.2.m2.3.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3.3"></eq><apply id="S3.SS1.p2.2.m2.3.3.4.cmml" xref="S3.SS1.p2.2.m2.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.3.4.1.cmml" xref="S3.SS1.p2.2.m2.3.3.4">subscript</csymbol><ci id="S3.SS1.p2.2.m2.3.3.4.2.cmml" xref="S3.SS1.p2.2.m2.3.3.4.2">ğ»</ci><ci id="S3.SS1.p2.2.m2.3.3.4.3.cmml" xref="S3.SS1.p2.2.m2.3.3.4.3">ğ‘–</ci></apply><apply id="S3.SS1.p2.2.m2.3.3.2.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2"><csymbol cd="latexml" id="S3.SS1.p2.2.m2.3.3.2.3.1.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.3">conditional-set</csymbol><list id="S3.SS1.p2.2.m2.2.2.1.1.1.4.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3"><apply id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.2.3">ğ‘–</ci></apply><cn type="integer" id="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2">superscript</csymbol><apply id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.2.3">ğ‘–</ci></apply><cn type="integer" id="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.2.2.3">2</cn></apply><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">â‹¯</ci><apply id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3">superscript</csymbol><apply id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.3.cmml" xref="S3.SS1.p2.2.m2.2.2.1.1.1.3.3.3">ğ‘ </ci></apply></list><apply id="S3.SS1.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2"><in id="S3.SS1.p2.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.1"></in><apply id="S3.SS1.p2.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p2.2.m2.3.3.2.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.2.3">ğ‘ </ci></apply><apply id="S3.SS1.p2.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.3.2.2.2.3.1.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.3">superscript</csymbol><ci id="S3.SS1.p2.2.m2.3.3.2.2.2.3.2.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.3.2">ğ‘…</ci><ci id="S3.SS1.p2.2.m2.3.3.2.2.2.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3.2.2.2.3.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.3c">H_{i}=\{y_{i}^{1},y_{i}^{2},\cdots,y_{i}^{s}|y_{i}^{s}\in R^{N}\}</annotation></semantics></math>
and <math id="S3.SS1.p2.3.m3.6" class="ltx_Math" alttext="M_{i}=\{\hat{y_{i}^{1}},\hat{y_{i}^{2}},\cdots,\hat{y_{i}^{t}}|\hat{y_{i}^{t}}\in R^{N}\}" display="inline"><semantics id="S3.SS1.p2.3.m3.6a"><mrow id="S3.SS1.p2.3.m3.6.6" xref="S3.SS1.p2.3.m3.6.6.cmml"><msub id="S3.SS1.p2.3.m3.6.6.4" xref="S3.SS1.p2.3.m3.6.6.4.cmml"><mi id="S3.SS1.p2.3.m3.6.6.4.2" xref="S3.SS1.p2.3.m3.6.6.4.2.cmml">M</mi><mi id="S3.SS1.p2.3.m3.6.6.4.3" xref="S3.SS1.p2.3.m3.6.6.4.3.cmml">i</mi></msub><mo id="S3.SS1.p2.3.m3.6.6.3" xref="S3.SS1.p2.3.m3.6.6.3.cmml">=</mo><mrow id="S3.SS1.p2.3.m3.6.6.2.2" xref="S3.SS1.p2.3.m3.6.6.2.3.cmml"><mo stretchy="false" id="S3.SS1.p2.3.m3.6.6.2.2.3" xref="S3.SS1.p2.3.m3.6.6.2.3.1.cmml">{</mo><mrow id="S3.SS1.p2.3.m3.5.5.1.1.1.2" xref="S3.SS1.p2.3.m3.5.5.1.1.1.1.cmml"><mover accent="true" id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><msubsup id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2.2.2" xref="S3.SS1.p2.3.m3.1.1.2.2.2.cmml">y</mi><mi id="S3.SS1.p2.3.m3.1.1.2.2.3" xref="S3.SS1.p2.3.m3.1.1.2.2.3.cmml">i</mi><mn id="S3.SS1.p2.3.m3.1.1.2.3" xref="S3.SS1.p2.3.m3.1.1.2.3.cmml">1</mn></msubsup><mo id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">^</mo></mover><mo id="S3.SS1.p2.3.m3.5.5.1.1.1.2.1" xref="S3.SS1.p2.3.m3.5.5.1.1.1.1.cmml">,</mo><mover accent="true" id="S3.SS1.p2.3.m3.2.2" xref="S3.SS1.p2.3.m3.2.2.cmml"><msubsup id="S3.SS1.p2.3.m3.2.2.2" xref="S3.SS1.p2.3.m3.2.2.2.cmml"><mi id="S3.SS1.p2.3.m3.2.2.2.2.2" xref="S3.SS1.p2.3.m3.2.2.2.2.2.cmml">y</mi><mi id="S3.SS1.p2.3.m3.2.2.2.2.3" xref="S3.SS1.p2.3.m3.2.2.2.2.3.cmml">i</mi><mn id="S3.SS1.p2.3.m3.2.2.2.3" xref="S3.SS1.p2.3.m3.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS1.p2.3.m3.2.2.1" xref="S3.SS1.p2.3.m3.2.2.1.cmml">^</mo></mover><mo id="S3.SS1.p2.3.m3.5.5.1.1.1.2.2" xref="S3.SS1.p2.3.m3.5.5.1.1.1.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p2.3.m3.3.3" xref="S3.SS1.p2.3.m3.3.3.cmml">â‹¯</mi><mo id="S3.SS1.p2.3.m3.5.5.1.1.1.2.3" xref="S3.SS1.p2.3.m3.5.5.1.1.1.1.cmml">,</mo><mover accent="true" id="S3.SS1.p2.3.m3.4.4" xref="S3.SS1.p2.3.m3.4.4.cmml"><msubsup id="S3.SS1.p2.3.m3.4.4.2" xref="S3.SS1.p2.3.m3.4.4.2.cmml"><mi id="S3.SS1.p2.3.m3.4.4.2.2.2" xref="S3.SS1.p2.3.m3.4.4.2.2.2.cmml">y</mi><mi id="S3.SS1.p2.3.m3.4.4.2.2.3" xref="S3.SS1.p2.3.m3.4.4.2.2.3.cmml">i</mi><mi id="S3.SS1.p2.3.m3.4.4.2.3" xref="S3.SS1.p2.3.m3.4.4.2.3.cmml">t</mi></msubsup><mo id="S3.SS1.p2.3.m3.4.4.1" xref="S3.SS1.p2.3.m3.4.4.1.cmml">^</mo></mover></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.6.6.2.2.4" xref="S3.SS1.p2.3.m3.6.6.2.3.1.cmml">|</mo><mrow id="S3.SS1.p2.3.m3.6.6.2.2.2" xref="S3.SS1.p2.3.m3.6.6.2.2.2.cmml"><mover accent="true" id="S3.SS1.p2.3.m3.6.6.2.2.2.2" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.cmml"><msubsup id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.cmml"><mi id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.2" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.3" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.3.cmml">i</mi><mi id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.3" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.3.cmml">t</mi></msubsup><mo id="S3.SS1.p2.3.m3.6.6.2.2.2.2.1" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.1.cmml">^</mo></mover><mo id="S3.SS1.p2.3.m3.6.6.2.2.2.1" xref="S3.SS1.p2.3.m3.6.6.2.2.2.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.3.m3.6.6.2.2.2.3" xref="S3.SS1.p2.3.m3.6.6.2.2.2.3.cmml"><mi id="S3.SS1.p2.3.m3.6.6.2.2.2.3.2" xref="S3.SS1.p2.3.m3.6.6.2.2.2.3.2.cmml">R</mi><mi id="S3.SS1.p2.3.m3.6.6.2.2.2.3.3" xref="S3.SS1.p2.3.m3.6.6.2.2.2.3.3.cmml">N</mi></msup></mrow><mo stretchy="false" id="S3.SS1.p2.3.m3.6.6.2.2.5" xref="S3.SS1.p2.3.m3.6.6.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.6b"><apply id="S3.SS1.p2.3.m3.6.6.cmml" xref="S3.SS1.p2.3.m3.6.6"><eq id="S3.SS1.p2.3.m3.6.6.3.cmml" xref="S3.SS1.p2.3.m3.6.6.3"></eq><apply id="S3.SS1.p2.3.m3.6.6.4.cmml" xref="S3.SS1.p2.3.m3.6.6.4"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.6.6.4.1.cmml" xref="S3.SS1.p2.3.m3.6.6.4">subscript</csymbol><ci id="S3.SS1.p2.3.m3.6.6.4.2.cmml" xref="S3.SS1.p2.3.m3.6.6.4.2">ğ‘€</ci><ci id="S3.SS1.p2.3.m3.6.6.4.3.cmml" xref="S3.SS1.p2.3.m3.6.6.4.3">ğ‘–</ci></apply><apply id="S3.SS1.p2.3.m3.6.6.2.3.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2"><csymbol cd="latexml" id="S3.SS1.p2.3.m3.6.6.2.3.1.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.3">conditional-set</csymbol><list id="S3.SS1.p2.3.m3.5.5.1.1.1.1.cmml" xref="S3.SS1.p2.3.m3.5.5.1.1.1.2"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><ci id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1">^</ci><apply id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.2.1.cmml" xref="S3.SS1.p2.3.m3.1.1.2">superscript</csymbol><apply id="S3.SS1.p2.3.m3.1.1.2.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.2.2.1.cmml" xref="S3.SS1.p2.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.2.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.3.m3.1.1.2.2.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.2.3">ğ‘–</ci></apply><cn type="integer" id="S3.SS1.p2.3.m3.1.1.2.3.cmml" xref="S3.SS1.p2.3.m3.1.1.2.3">1</cn></apply></apply><apply id="S3.SS1.p2.3.m3.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2"><ci id="S3.SS1.p2.3.m3.2.2.1.cmml" xref="S3.SS1.p2.3.m3.2.2.1">^</ci><apply id="S3.SS1.p2.3.m3.2.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.2.2.2">superscript</csymbol><apply id="S3.SS1.p2.3.m3.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.p2.3.m3.2.2.2.2.3">ğ‘–</ci></apply><cn type="integer" id="S3.SS1.p2.3.m3.2.2.2.3.cmml" xref="S3.SS1.p2.3.m3.2.2.2.3">2</cn></apply></apply><ci id="S3.SS1.p2.3.m3.3.3.cmml" xref="S3.SS1.p2.3.m3.3.3">â‹¯</ci><apply id="S3.SS1.p2.3.m3.4.4.cmml" xref="S3.SS1.p2.3.m3.4.4"><ci id="S3.SS1.p2.3.m3.4.4.1.cmml" xref="S3.SS1.p2.3.m3.4.4.1">^</ci><apply id="S3.SS1.p2.3.m3.4.4.2.cmml" xref="S3.SS1.p2.3.m3.4.4.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.4.4.2.1.cmml" xref="S3.SS1.p2.3.m3.4.4.2">superscript</csymbol><apply id="S3.SS1.p2.3.m3.4.4.2.2.cmml" xref="S3.SS1.p2.3.m3.4.4.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.4.4.2.2.1.cmml" xref="S3.SS1.p2.3.m3.4.4.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.4.4.2.2.2.cmml" xref="S3.SS1.p2.3.m3.4.4.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.3.m3.4.4.2.2.3.cmml" xref="S3.SS1.p2.3.m3.4.4.2.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p2.3.m3.4.4.2.3.cmml" xref="S3.SS1.p2.3.m3.4.4.2.3">ğ‘¡</ci></apply></apply></list><apply id="S3.SS1.p2.3.m3.6.6.2.2.2.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2"><in id="S3.SS1.p2.3.m3.6.6.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.1"></in><apply id="S3.SS1.p2.3.m3.6.6.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2"><ci id="S3.SS1.p2.3.m3.6.6.2.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.1">^</ci><apply id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.2.3">ğ‘–</ci></apply><ci id="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.3.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.2.2.3">ğ‘¡</ci></apply></apply><apply id="S3.SS1.p2.3.m3.6.6.2.2.2.3.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.6.6.2.2.2.3.1.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.3">superscript</csymbol><ci id="S3.SS1.p2.3.m3.6.6.2.2.2.3.2.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.3.2">ğ‘…</ci><ci id="S3.SS1.p2.3.m3.6.6.2.2.2.3.3.cmml" xref="S3.SS1.p2.3.m3.6.6.2.2.2.3.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.6c">M_{i}=\{\hat{y_{i}^{1}},\hat{y_{i}^{2}},\cdots,\hat{y_{i}^{t}}|\hat{y_{i}^{t}}\in R^{N}\}</annotation></semantics></math> respectively, where N is the classes amount. The agreement extent in the humans <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="A_{h}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">A</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">ğ´</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">A_{h}</annotation></semantics></math> and models <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="A_{m}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">A</mi><mi id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">ğ´</ci><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">A_{m}</annotation></semantics></math> can be further represented by the variance of the corresponding label set:</p>
<table id="S5.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1.m1.6" class="ltx_Math" alttext="\displaystyle A_{h}[c]=\frac{1}{P(c,H)}\sum_{i=P(c,H)}\textit{Var}(H_{i})" display="inline"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml"><mrow id="S3.E1.m1.6.6.3" xref="S3.E1.m1.6.6.3.cmml"><msub id="S3.E1.m1.6.6.3.2" xref="S3.E1.m1.6.6.3.2.cmml"><mi id="S3.E1.m1.6.6.3.2.2" xref="S3.E1.m1.6.6.3.2.2.cmml">A</mi><mi id="S3.E1.m1.6.6.3.2.3" xref="S3.E1.m1.6.6.3.2.3.cmml">h</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.3.1" xref="S3.E1.m1.6.6.3.1.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.3.3.2" xref="S3.E1.m1.6.6.3.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.3.3.2.1" xref="S3.E1.m1.6.6.3.3.1.1.cmml">[</mo><mi id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">c</mi><mo stretchy="false" id="S3.E1.m1.6.6.3.3.2.2" xref="S3.E1.m1.6.6.3.3.1.1.cmml">]</mo></mrow></mrow><mo id="S3.E1.m1.6.6.2" xref="S3.E1.m1.6.6.2.cmml">=</mo><mrow id="S3.E1.m1.6.6.1" xref="S3.E1.m1.6.6.1.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mfrac id="S3.E1.m1.2.2a" xref="S3.E1.m1.2.2.cmml"><mn id="S3.E1.m1.2.2.4" xref="S3.E1.m1.2.2.4.cmml">1</mn><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.2.5.2" xref="S3.E1.m1.2.2.2.5.1.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.5.2.1" xref="S3.E1.m1.2.2.2.5.1.cmml">(</mo><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">c</mi><mo id="S3.E1.m1.2.2.2.5.2.2" xref="S3.E1.m1.2.2.2.5.1.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">H</mi><mo stretchy="false" id="S3.E1.m1.2.2.2.5.2.3" xref="S3.E1.m1.2.2.2.5.1.cmml">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.2" xref="S3.E1.m1.6.6.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.1.1" xref="S3.E1.m1.6.6.1.1.cmml"><mstyle displaystyle="true" id="S3.E1.m1.6.6.1.1.2" xref="S3.E1.m1.6.6.1.1.2.cmml"><munder id="S3.E1.m1.6.6.1.1.2a" xref="S3.E1.m1.6.6.1.1.2.cmml"><mo movablelimits="false" id="S3.E1.m1.6.6.1.1.2.2" xref="S3.E1.m1.6.6.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.4.4.2" xref="S3.E1.m1.4.4.2.cmml"><mi id="S3.E1.m1.4.4.2.4" xref="S3.E1.m1.4.4.2.4.cmml">i</mi><mo id="S3.E1.m1.4.4.2.3" xref="S3.E1.m1.4.4.2.3.cmml">=</mo><mrow id="S3.E1.m1.4.4.2.5" xref="S3.E1.m1.4.4.2.5.cmml"><mi id="S3.E1.m1.4.4.2.5.2" xref="S3.E1.m1.4.4.2.5.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.2.5.1" xref="S3.E1.m1.4.4.2.5.1.cmml">â€‹</mo><mrow id="S3.E1.m1.4.4.2.5.3.2" xref="S3.E1.m1.4.4.2.5.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.2.5.3.2.1" xref="S3.E1.m1.4.4.2.5.3.1.cmml">(</mo><mi id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml">c</mi><mo id="S3.E1.m1.4.4.2.5.3.2.2" xref="S3.E1.m1.4.4.2.5.3.1.cmml">,</mo><mi id="S3.E1.m1.4.4.2.2" xref="S3.E1.m1.4.4.2.2.cmml">H</mi><mo stretchy="false" id="S3.E1.m1.4.4.2.5.3.2.3" xref="S3.E1.m1.4.4.2.5.3.1.cmml">)</mo></mrow></mrow></mrow></munder></mstyle><mrow id="S3.E1.m1.6.6.1.1.1" xref="S3.E1.m1.6.6.1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S3.E1.m1.6.6.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.3a.cmml">Var</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.6.6.1.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.6.6.1.1.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.2.cmml">H</mi><mi id="S3.E1.m1.6.6.1.1.1.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.6b"><apply id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6"><eq id="S3.E1.m1.6.6.2.cmml" xref="S3.E1.m1.6.6.2"></eq><apply id="S3.E1.m1.6.6.3.cmml" xref="S3.E1.m1.6.6.3"><times id="S3.E1.m1.6.6.3.1.cmml" xref="S3.E1.m1.6.6.3.1"></times><apply id="S3.E1.m1.6.6.3.2.cmml" xref="S3.E1.m1.6.6.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.3.2.1.cmml" xref="S3.E1.m1.6.6.3.2">subscript</csymbol><ci id="S3.E1.m1.6.6.3.2.2.cmml" xref="S3.E1.m1.6.6.3.2.2">ğ´</ci><ci id="S3.E1.m1.6.6.3.2.3.cmml" xref="S3.E1.m1.6.6.3.2.3">â„</ci></apply><apply id="S3.E1.m1.6.6.3.3.1.cmml" xref="S3.E1.m1.6.6.3.3.2"><csymbol cd="latexml" id="S3.E1.m1.6.6.3.3.1.1.cmml" xref="S3.E1.m1.6.6.3.3.2.1">delimited-[]</csymbol><ci id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5">ğ‘</ci></apply></apply><apply id="S3.E1.m1.6.6.1.cmml" xref="S3.E1.m1.6.6.1"><times id="S3.E1.m1.6.6.1.2.cmml" xref="S3.E1.m1.6.6.1.2"></times><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><divide id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2"></divide><cn type="integer" id="S3.E1.m1.2.2.4.cmml" xref="S3.E1.m1.2.2.4">1</cn><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"><times id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.3"></times><ci id="S3.E1.m1.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.4">ğ‘ƒ</ci><interval closure="open" id="S3.E1.m1.2.2.2.5.1.cmml" xref="S3.E1.m1.2.2.2.5.2"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">ğ‘</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">ğ»</ci></interval></apply></apply><apply id="S3.E1.m1.6.6.1.1.cmml" xref="S3.E1.m1.6.6.1.1"><apply id="S3.E1.m1.6.6.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.1.1.2.1.cmml" xref="S3.E1.m1.6.6.1.1.2">subscript</csymbol><sum id="S3.E1.m1.6.6.1.1.2.2.cmml" xref="S3.E1.m1.6.6.1.1.2.2"></sum><apply id="S3.E1.m1.4.4.2.cmml" xref="S3.E1.m1.4.4.2"><eq id="S3.E1.m1.4.4.2.3.cmml" xref="S3.E1.m1.4.4.2.3"></eq><ci id="S3.E1.m1.4.4.2.4.cmml" xref="S3.E1.m1.4.4.2.4">ğ‘–</ci><apply id="S3.E1.m1.4.4.2.5.cmml" xref="S3.E1.m1.4.4.2.5"><times id="S3.E1.m1.4.4.2.5.1.cmml" xref="S3.E1.m1.4.4.2.5.1"></times><ci id="S3.E1.m1.4.4.2.5.2.cmml" xref="S3.E1.m1.4.4.2.5.2">ğ‘ƒ</ci><interval closure="open" id="S3.E1.m1.4.4.2.5.3.1.cmml" xref="S3.E1.m1.4.4.2.5.3.2"><ci id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1">ğ‘</ci><ci id="S3.E1.m1.4.4.2.2.cmml" xref="S3.E1.m1.4.4.2.2">ğ»</ci></interval></apply></apply></apply><apply id="S3.E1.m1.6.6.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1"><times id="S3.E1.m1.6.6.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.2"></times><ci id="S3.E1.m1.6.6.1.1.1.3a.cmml" xref="S3.E1.m1.6.6.1.1.1.3"><mtext class="ltx_mathvariant_italic" id="S3.E1.m1.6.6.1.1.1.3.cmml" xref="S3.E1.m1.6.6.1.1.1.3">Var</mtext></ci><apply id="S3.E1.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.2">ğ»</ci><ci id="S3.E1.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.6c">\displaystyle A_{h}[c]=\frac{1}{P(c,H)}\sum_{i=P(c,H)}\textit{Var}(H_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2.m1.6" class="ltx_Math" alttext="\displaystyle A_{m}[c]=\frac{1}{P(c,M)}\sum_{i=P(c,M)}\textit{Var}(M_{i})" display="inline"><semantics id="S3.E2.m1.6a"><mrow id="S3.E2.m1.6.6" xref="S3.E2.m1.6.6.cmml"><mrow id="S3.E2.m1.6.6.3" xref="S3.E2.m1.6.6.3.cmml"><msub id="S3.E2.m1.6.6.3.2" xref="S3.E2.m1.6.6.3.2.cmml"><mi id="S3.E2.m1.6.6.3.2.2" xref="S3.E2.m1.6.6.3.2.2.cmml">A</mi><mi id="S3.E2.m1.6.6.3.2.3" xref="S3.E2.m1.6.6.3.2.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.6.6.3.1" xref="S3.E2.m1.6.6.3.1.cmml">â€‹</mo><mrow id="S3.E2.m1.6.6.3.3.2" xref="S3.E2.m1.6.6.3.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.3.3.2.1" xref="S3.E2.m1.6.6.3.3.1.1.cmml">[</mo><mi id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml">c</mi><mo stretchy="false" id="S3.E2.m1.6.6.3.3.2.2" xref="S3.E2.m1.6.6.3.3.1.1.cmml">]</mo></mrow></mrow><mo id="S3.E2.m1.6.6.2" xref="S3.E2.m1.6.6.2.cmml">=</mo><mrow id="S3.E2.m1.6.6.1" xref="S3.E2.m1.6.6.1.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mfrac id="S3.E2.m1.2.2a" xref="S3.E2.m1.2.2.cmml"><mn id="S3.E2.m1.2.2.4" xref="S3.E2.m1.2.2.4.cmml">1</mn><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.2.5.2" xref="S3.E2.m1.2.2.2.5.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.5.2.1" xref="S3.E2.m1.2.2.2.5.1.cmml">(</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">c</mi><mo id="S3.E2.m1.2.2.2.5.2.2" xref="S3.E2.m1.2.2.2.5.1.cmml">,</mo><mi id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">M</mi><mo stretchy="false" id="S3.E2.m1.2.2.2.5.2.3" xref="S3.E2.m1.2.2.2.5.1.cmml">)</mo></mrow></mrow></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E2.m1.6.6.1.2" xref="S3.E2.m1.6.6.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.6.6.1.1" xref="S3.E2.m1.6.6.1.1.cmml"><mstyle displaystyle="true" id="S3.E2.m1.6.6.1.1.2" xref="S3.E2.m1.6.6.1.1.2.cmml"><munder id="S3.E2.m1.6.6.1.1.2a" xref="S3.E2.m1.6.6.1.1.2.cmml"><mo movablelimits="false" id="S3.E2.m1.6.6.1.1.2.2" xref="S3.E2.m1.6.6.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.4.4.2" xref="S3.E2.m1.4.4.2.cmml"><mi id="S3.E2.m1.4.4.2.4" xref="S3.E2.m1.4.4.2.4.cmml">i</mi><mo id="S3.E2.m1.4.4.2.3" xref="S3.E2.m1.4.4.2.3.cmml">=</mo><mrow id="S3.E2.m1.4.4.2.5" xref="S3.E2.m1.4.4.2.5.cmml"><mi id="S3.E2.m1.4.4.2.5.2" xref="S3.E2.m1.4.4.2.5.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.2.5.1" xref="S3.E2.m1.4.4.2.5.1.cmml">â€‹</mo><mrow id="S3.E2.m1.4.4.2.5.3.2" xref="S3.E2.m1.4.4.2.5.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.2.5.3.2.1" xref="S3.E2.m1.4.4.2.5.3.1.cmml">(</mo><mi id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml">c</mi><mo id="S3.E2.m1.4.4.2.5.3.2.2" xref="S3.E2.m1.4.4.2.5.3.1.cmml">,</mo><mi id="S3.E2.m1.4.4.2.2" xref="S3.E2.m1.4.4.2.2.cmml">M</mi><mo stretchy="false" id="S3.E2.m1.4.4.2.5.3.2.3" xref="S3.E2.m1.4.4.2.5.3.1.cmml">)</mo></mrow></mrow></mrow></munder></mstyle><mrow id="S3.E2.m1.6.6.1.1.1" xref="S3.E2.m1.6.6.1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S3.E2.m1.6.6.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.3a.cmml">Var</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.6.6.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.6.6.1.1.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.1.1.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.6.6.1.1.1.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.6.6.1.1.1.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.2.cmml">M</mi><mi id="S3.E2.m1.6.6.1.1.1.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E2.m1.6.6.1.1.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.6b"><apply id="S3.E2.m1.6.6.cmml" xref="S3.E2.m1.6.6"><eq id="S3.E2.m1.6.6.2.cmml" xref="S3.E2.m1.6.6.2"></eq><apply id="S3.E2.m1.6.6.3.cmml" xref="S3.E2.m1.6.6.3"><times id="S3.E2.m1.6.6.3.1.cmml" xref="S3.E2.m1.6.6.3.1"></times><apply id="S3.E2.m1.6.6.3.2.cmml" xref="S3.E2.m1.6.6.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.3.2.1.cmml" xref="S3.E2.m1.6.6.3.2">subscript</csymbol><ci id="S3.E2.m1.6.6.3.2.2.cmml" xref="S3.E2.m1.6.6.3.2.2">ğ´</ci><ci id="S3.E2.m1.6.6.3.2.3.cmml" xref="S3.E2.m1.6.6.3.2.3">ğ‘š</ci></apply><apply id="S3.E2.m1.6.6.3.3.1.cmml" xref="S3.E2.m1.6.6.3.3.2"><csymbol cd="latexml" id="S3.E2.m1.6.6.3.3.1.1.cmml" xref="S3.E2.m1.6.6.3.3.2.1">delimited-[]</csymbol><ci id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5">ğ‘</ci></apply></apply><apply id="S3.E2.m1.6.6.1.cmml" xref="S3.E2.m1.6.6.1"><times id="S3.E2.m1.6.6.1.2.cmml" xref="S3.E2.m1.6.6.1.2"></times><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><divide id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2"></divide><cn type="integer" id="S3.E2.m1.2.2.4.cmml" xref="S3.E2.m1.2.2.4">1</cn><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><times id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"></times><ci id="S3.E2.m1.2.2.2.4.cmml" xref="S3.E2.m1.2.2.2.4">ğ‘ƒ</ci><interval closure="open" id="S3.E2.m1.2.2.2.5.1.cmml" xref="S3.E2.m1.2.2.2.5.2"><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">ğ‘</ci><ci id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2">ğ‘€</ci></interval></apply></apply><apply id="S3.E2.m1.6.6.1.1.cmml" xref="S3.E2.m1.6.6.1.1"><apply id="S3.E2.m1.6.6.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.1.1.2.1.cmml" xref="S3.E2.m1.6.6.1.1.2">subscript</csymbol><sum id="S3.E2.m1.6.6.1.1.2.2.cmml" xref="S3.E2.m1.6.6.1.1.2.2"></sum><apply id="S3.E2.m1.4.4.2.cmml" xref="S3.E2.m1.4.4.2"><eq id="S3.E2.m1.4.4.2.3.cmml" xref="S3.E2.m1.4.4.2.3"></eq><ci id="S3.E2.m1.4.4.2.4.cmml" xref="S3.E2.m1.4.4.2.4">ğ‘–</ci><apply id="S3.E2.m1.4.4.2.5.cmml" xref="S3.E2.m1.4.4.2.5"><times id="S3.E2.m1.4.4.2.5.1.cmml" xref="S3.E2.m1.4.4.2.5.1"></times><ci id="S3.E2.m1.4.4.2.5.2.cmml" xref="S3.E2.m1.4.4.2.5.2">ğ‘ƒ</ci><interval closure="open" id="S3.E2.m1.4.4.2.5.3.1.cmml" xref="S3.E2.m1.4.4.2.5.3.2"><ci id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1.1">ğ‘</ci><ci id="S3.E2.m1.4.4.2.2.cmml" xref="S3.E2.m1.4.4.2.2">ğ‘€</ci></interval></apply></apply></apply><apply id="S3.E2.m1.6.6.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1"><times id="S3.E2.m1.6.6.1.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1.2"></times><ci id="S3.E2.m1.6.6.1.1.1.3a.cmml" xref="S3.E2.m1.6.6.1.1.1.3"><mtext class="ltx_mathvariant_italic" id="S3.E2.m1.6.6.1.1.1.3.cmml" xref="S3.E2.m1.6.6.1.1.1.3">Var</mtext></ci><apply id="S3.E2.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.2">ğ‘€</ci><ci id="S3.E2.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.6c">\displaystyle A_{m}[c]=\frac{1}{P(c,M)}\sum_{i=P(c,M)}\textit{Var}(M_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p2.14" class="ltx_p">where <math id="S3.SS1.p2.6.m1.1" class="ltx_Math" alttext="\textit{Var}(\cdot)" display="inline"><semantics id="S3.SS1.p2.6.m1.1a"><mrow id="S3.SS1.p2.6.m1.1.2" xref="S3.SS1.p2.6.m1.1.2.cmml"><mtext class="ltx_mathvariant_italic" id="S3.SS1.p2.6.m1.1.2.2" xref="S3.SS1.p2.6.m1.1.2.2a.cmml">Var</mtext><mo lspace="0em" rspace="0em" id="S3.SS1.p2.6.m1.1.2.1" xref="S3.SS1.p2.6.m1.1.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.6.m1.1.2.3.2" xref="S3.SS1.p2.6.m1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.6.m1.1.2.3.2.1" xref="S3.SS1.p2.6.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.p2.6.m1.1.1" xref="S3.SS1.p2.6.m1.1.1.cmml">â‹…</mo><mo stretchy="false" id="S3.SS1.p2.6.m1.1.2.3.2.2" xref="S3.SS1.p2.6.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m1.1b"><apply id="S3.SS1.p2.6.m1.1.2.cmml" xref="S3.SS1.p2.6.m1.1.2"><times id="S3.SS1.p2.6.m1.1.2.1.cmml" xref="S3.SS1.p2.6.m1.1.2.1"></times><ci id="S3.SS1.p2.6.m1.1.2.2a.cmml" xref="S3.SS1.p2.6.m1.1.2.2"><mtext class="ltx_mathvariant_italic" id="S3.SS1.p2.6.m1.1.2.2.cmml" xref="S3.SS1.p2.6.m1.1.2.2">Var</mtext></ci><ci id="S3.SS1.p2.6.m1.1.1.cmml" xref="S3.SS1.p2.6.m1.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m1.1c">\textit{Var}(\cdot)</annotation></semantics></math> means the variance calculation, <math id="S3.SS1.p2.7.m2.1" class="ltx_Math" alttext="A[c]" display="inline"><semantics id="S3.SS1.p2.7.m2.1a"><mrow id="S3.SS1.p2.7.m2.1.2" xref="S3.SS1.p2.7.m2.1.2.cmml"><mi id="S3.SS1.p2.7.m2.1.2.2" xref="S3.SS1.p2.7.m2.1.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.7.m2.1.2.1" xref="S3.SS1.p2.7.m2.1.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.7.m2.1.2.3.2" xref="S3.SS1.p2.7.m2.1.2.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.7.m2.1.2.3.2.1" xref="S3.SS1.p2.7.m2.1.2.3.1.1.cmml">[</mo><mi id="S3.SS1.p2.7.m2.1.1" xref="S3.SS1.p2.7.m2.1.1.cmml">c</mi><mo stretchy="false" id="S3.SS1.p2.7.m2.1.2.3.2.2" xref="S3.SS1.p2.7.m2.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m2.1b"><apply id="S3.SS1.p2.7.m2.1.2.cmml" xref="S3.SS1.p2.7.m2.1.2"><times id="S3.SS1.p2.7.m2.1.2.1.cmml" xref="S3.SS1.p2.7.m2.1.2.1"></times><ci id="S3.SS1.p2.7.m2.1.2.2.cmml" xref="S3.SS1.p2.7.m2.1.2.2">ğ´</ci><apply id="S3.SS1.p2.7.m2.1.2.3.1.cmml" xref="S3.SS1.p2.7.m2.1.2.3.2"><csymbol cd="latexml" id="S3.SS1.p2.7.m2.1.2.3.1.1.cmml" xref="S3.SS1.p2.7.m2.1.2.3.2.1">delimited-[]</csymbol><ci id="S3.SS1.p2.7.m2.1.1.cmml" xref="S3.SS1.p2.7.m2.1.1">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m2.1c">A[c]</annotation></semantics></math> means the <math id="S3.SS1.p2.8.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p2.8.m3.1a"><mi id="S3.SS1.p2.8.m3.1.1" xref="S3.SS1.p2.8.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m3.1b"><ci id="S3.SS1.p2.8.m3.1.1.cmml" xref="S3.SS1.p2.8.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m3.1c">c</annotation></semantics></math>-th class, <math id="S3.SS1.p2.9.m4.2" class="ltx_Math" alttext="P(c,H)" display="inline"><semantics id="S3.SS1.p2.9.m4.2a"><mrow id="S3.SS1.p2.9.m4.2.3" xref="S3.SS1.p2.9.m4.2.3.cmml"><mi id="S3.SS1.p2.9.m4.2.3.2" xref="S3.SS1.p2.9.m4.2.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.9.m4.2.3.1" xref="S3.SS1.p2.9.m4.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.9.m4.2.3.3.2" xref="S3.SS1.p2.9.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.9.m4.2.3.3.2.1" xref="S3.SS1.p2.9.m4.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p2.9.m4.1.1" xref="S3.SS1.p2.9.m4.1.1.cmml">c</mi><mo id="S3.SS1.p2.9.m4.2.3.3.2.2" xref="S3.SS1.p2.9.m4.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p2.9.m4.2.2" xref="S3.SS1.p2.9.m4.2.2.cmml">H</mi><mo stretchy="false" id="S3.SS1.p2.9.m4.2.3.3.2.3" xref="S3.SS1.p2.9.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m4.2b"><apply id="S3.SS1.p2.9.m4.2.3.cmml" xref="S3.SS1.p2.9.m4.2.3"><times id="S3.SS1.p2.9.m4.2.3.1.cmml" xref="S3.SS1.p2.9.m4.2.3.1"></times><ci id="S3.SS1.p2.9.m4.2.3.2.cmml" xref="S3.SS1.p2.9.m4.2.3.2">ğ‘ƒ</ci><interval closure="open" id="S3.SS1.p2.9.m4.2.3.3.1.cmml" xref="S3.SS1.p2.9.m4.2.3.3.2"><ci id="S3.SS1.p2.9.m4.1.1.cmml" xref="S3.SS1.p2.9.m4.1.1">ğ‘</ci><ci id="S3.SS1.p2.9.m4.2.2.cmml" xref="S3.SS1.p2.9.m4.2.2">ğ»</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m4.2c">P(c,H)</annotation></semantics></math> is an index function to ensure that the variance calculation only involves segments, which may potentially have the events of class <math id="S3.SS1.p2.10.m5.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p2.10.m5.1a"><mi id="S3.SS1.p2.10.m5.1.1" xref="S3.SS1.p2.10.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m5.1b"><ci id="S3.SS1.p2.10.m5.1.1.cmml" xref="S3.SS1.p2.10.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m5.1c">c</annotation></semantics></math>, namely <math id="S3.SS1.p2.11.m6.5" class="ltx_Math" alttext="P(c,H)=\{i|sum(H_{i})[c]&gt;0\}" display="inline"><semantics id="S3.SS1.p2.11.m6.5a"><mrow id="S3.SS1.p2.11.m6.5.5" xref="S3.SS1.p2.11.m6.5.5.cmml"><mrow id="S3.SS1.p2.11.m6.5.5.3" xref="S3.SS1.p2.11.m6.5.5.3.cmml"><mi id="S3.SS1.p2.11.m6.5.5.3.2" xref="S3.SS1.p2.11.m6.5.5.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m6.5.5.3.1" xref="S3.SS1.p2.11.m6.5.5.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.11.m6.5.5.3.3.2" xref="S3.SS1.p2.11.m6.5.5.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.11.m6.5.5.3.3.2.1" xref="S3.SS1.p2.11.m6.5.5.3.3.1.cmml">(</mo><mi id="S3.SS1.p2.11.m6.1.1" xref="S3.SS1.p2.11.m6.1.1.cmml">c</mi><mo id="S3.SS1.p2.11.m6.5.5.3.3.2.2" xref="S3.SS1.p2.11.m6.5.5.3.3.1.cmml">,</mo><mi id="S3.SS1.p2.11.m6.2.2" xref="S3.SS1.p2.11.m6.2.2.cmml">H</mi><mo stretchy="false" id="S3.SS1.p2.11.m6.5.5.3.3.2.3" xref="S3.SS1.p2.11.m6.5.5.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p2.11.m6.5.5.2" xref="S3.SS1.p2.11.m6.5.5.2.cmml">=</mo><mrow id="S3.SS1.p2.11.m6.5.5.1.1" xref="S3.SS1.p2.11.m6.5.5.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.11.m6.5.5.1.1.2" xref="S3.SS1.p2.11.m6.5.5.1.2.1.cmml">{</mo><mi id="S3.SS1.p2.11.m6.4.4" xref="S3.SS1.p2.11.m6.4.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m6.5.5.1.1.3" xref="S3.SS1.p2.11.m6.5.5.1.2.1.cmml">|</mo><mrow id="S3.SS1.p2.11.m6.5.5.1.1.1" xref="S3.SS1.p2.11.m6.5.5.1.1.1.cmml"><mrow id="S3.SS1.p2.11.m6.5.5.1.1.1.1" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.cmml"><mi id="S3.SS1.p2.11.m6.5.5.1.1.1.1.3" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.2" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.SS1.p2.11.m6.5.5.1.1.1.1.4" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.2a" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.SS1.p2.11.m6.5.5.1.1.1.1.5" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.2b" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.2" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.2" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.2.cmml">H</mi><mi id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.3" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.3" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.2c" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.2" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.1.cmml"><mo stretchy="false" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.2.1" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.1.1.cmml">[</mo><mi id="S3.SS1.p2.11.m6.3.3" xref="S3.SS1.p2.11.m6.3.3.cmml">c</mi><mo stretchy="false" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.2.2" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.1.1.cmml">]</mo></mrow></mrow><mo id="S3.SS1.p2.11.m6.5.5.1.1.1.2" xref="S3.SS1.p2.11.m6.5.5.1.1.1.2.cmml">&gt;</mo><mn id="S3.SS1.p2.11.m6.5.5.1.1.1.3" xref="S3.SS1.p2.11.m6.5.5.1.1.1.3.cmml">0</mn></mrow><mo stretchy="false" id="S3.SS1.p2.11.m6.5.5.1.1.4" xref="S3.SS1.p2.11.m6.5.5.1.2.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m6.5b"><apply id="S3.SS1.p2.11.m6.5.5.cmml" xref="S3.SS1.p2.11.m6.5.5"><eq id="S3.SS1.p2.11.m6.5.5.2.cmml" xref="S3.SS1.p2.11.m6.5.5.2"></eq><apply id="S3.SS1.p2.11.m6.5.5.3.cmml" xref="S3.SS1.p2.11.m6.5.5.3"><times id="S3.SS1.p2.11.m6.5.5.3.1.cmml" xref="S3.SS1.p2.11.m6.5.5.3.1"></times><ci id="S3.SS1.p2.11.m6.5.5.3.2.cmml" xref="S3.SS1.p2.11.m6.5.5.3.2">ğ‘ƒ</ci><interval closure="open" id="S3.SS1.p2.11.m6.5.5.3.3.1.cmml" xref="S3.SS1.p2.11.m6.5.5.3.3.2"><ci id="S3.SS1.p2.11.m6.1.1.cmml" xref="S3.SS1.p2.11.m6.1.1">ğ‘</ci><ci id="S3.SS1.p2.11.m6.2.2.cmml" xref="S3.SS1.p2.11.m6.2.2">ğ»</ci></interval></apply><apply id="S3.SS1.p2.11.m6.5.5.1.2.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1"><csymbol cd="latexml" id="S3.SS1.p2.11.m6.5.5.1.2.1.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.2">conditional-set</csymbol><ci id="S3.SS1.p2.11.m6.4.4.cmml" xref="S3.SS1.p2.11.m6.4.4">ğ‘–</ci><apply id="S3.SS1.p2.11.m6.5.5.1.1.1.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1"><gt id="S3.SS1.p2.11.m6.5.5.1.1.1.2.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.2"></gt><apply id="S3.SS1.p2.11.m6.5.5.1.1.1.1.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1"><times id="S3.SS1.p2.11.m6.5.5.1.1.1.1.2.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.2"></times><ci id="S3.SS1.p2.11.m6.5.5.1.1.1.1.3.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.3">ğ‘ </ci><ci id="S3.SS1.p2.11.m6.5.5.1.1.1.1.4.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.4">ğ‘¢</ci><ci id="S3.SS1.p2.11.m6.5.5.1.1.1.1.5.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.5">ğ‘š</ci><apply id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.2">ğ»</ci><ci id="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.1.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.2"><csymbol cd="latexml" id="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.1.1.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.1.6.2.1">delimited-[]</csymbol><ci id="S3.SS1.p2.11.m6.3.3.cmml" xref="S3.SS1.p2.11.m6.3.3">ğ‘</ci></apply></apply><cn type="integer" id="S3.SS1.p2.11.m6.5.5.1.1.1.3.cmml" xref="S3.SS1.p2.11.m6.5.5.1.1.1.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m6.5c">P(c,H)=\{i|sum(H_{i})[c]&gt;0\}</annotation></semantics></math>. The <math id="S3.SS1.p2.12.m7.2" class="ltx_Math" alttext="P(c,H)" display="inline"><semantics id="S3.SS1.p2.12.m7.2a"><mrow id="S3.SS1.p2.12.m7.2.3" xref="S3.SS1.p2.12.m7.2.3.cmml"><mi id="S3.SS1.p2.12.m7.2.3.2" xref="S3.SS1.p2.12.m7.2.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.12.m7.2.3.1" xref="S3.SS1.p2.12.m7.2.3.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.12.m7.2.3.3.2" xref="S3.SS1.p2.12.m7.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.12.m7.2.3.3.2.1" xref="S3.SS1.p2.12.m7.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p2.12.m7.1.1" xref="S3.SS1.p2.12.m7.1.1.cmml">c</mi><mo id="S3.SS1.p2.12.m7.2.3.3.2.2" xref="S3.SS1.p2.12.m7.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p2.12.m7.2.2" xref="S3.SS1.p2.12.m7.2.2.cmml">H</mi><mo stretchy="false" id="S3.SS1.p2.12.m7.2.3.3.2.3" xref="S3.SS1.p2.12.m7.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m7.2b"><apply id="S3.SS1.p2.12.m7.2.3.cmml" xref="S3.SS1.p2.12.m7.2.3"><times id="S3.SS1.p2.12.m7.2.3.1.cmml" xref="S3.SS1.p2.12.m7.2.3.1"></times><ci id="S3.SS1.p2.12.m7.2.3.2.cmml" xref="S3.SS1.p2.12.m7.2.3.2">ğ‘ƒ</ci><interval closure="open" id="S3.SS1.p2.12.m7.2.3.3.1.cmml" xref="S3.SS1.p2.12.m7.2.3.3.2"><ci id="S3.SS1.p2.12.m7.1.1.cmml" xref="S3.SS1.p2.12.m7.1.1">ğ‘</ci><ci id="S3.SS1.p2.12.m7.2.2.cmml" xref="S3.SS1.p2.12.m7.2.2">ğ»</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m7.2c">P(c,H)</annotation></semantics></math> is mainly used to prevent the variance from being affected by the frequency of event appearance. For the class <math id="S3.SS1.p2.13.m8.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p2.13.m8.1a"><mi id="S3.SS1.p2.13.m8.1.1" xref="S3.SS1.p2.13.m8.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m8.1b"><ci id="S3.SS1.p2.13.m8.1.1.cmml" xref="S3.SS1.p2.13.m8.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m8.1c">c</annotation></semantics></math>, the consistency of agreement extent <math id="S3.SS1.p2.14.m9.1" class="ltx_Math" alttext="a_{c}" display="inline"><semantics id="S3.SS1.p2.14.m9.1a"><msub id="S3.SS1.p2.14.m9.1.1" xref="S3.SS1.p2.14.m9.1.1.cmml"><mi id="S3.SS1.p2.14.m9.1.1.2" xref="S3.SS1.p2.14.m9.1.1.2.cmml">a</mi><mi id="S3.SS1.p2.14.m9.1.1.3" xref="S3.SS1.p2.14.m9.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.14.m9.1b"><apply id="S3.SS1.p2.14.m9.1.1.cmml" xref="S3.SS1.p2.14.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.14.m9.1.1.1.cmml" xref="S3.SS1.p2.14.m9.1.1">subscript</csymbol><ci id="S3.SS1.p2.14.m9.1.1.2.cmml" xref="S3.SS1.p2.14.m9.1.1.2">ğ‘</ci><ci id="S3.SS1.p2.14.m9.1.1.3.cmml" xref="S3.SS1.p2.14.m9.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.14.m9.1c">a_{c}</annotation></semantics></math> could be represented as follows:</p>
<table id="S5.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.2" class="ltx_Math" alttext="\displaystyle a_{c}=(A_{h}-A_{m})[c]" display="inline"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msub id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml"><mi id="S3.E3.m1.2.2.3.2" xref="S3.E3.m1.2.2.3.2.cmml">a</mi><mi id="S3.E3.m1.2.2.3.3" xref="S3.E3.m1.2.2.3.3.cmml">c</mi></msub><mo id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml">=</mo><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.2.2.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.2.2" xref="S3.E3.m1.2.2.1.1.1.1.2.2.cmml">A</mi><mi id="S3.E3.m1.2.2.1.1.1.1.2.3" xref="S3.E3.m1.2.2.1.1.1.1.2.3.cmml">h</mi></msub><mo id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E3.m1.2.2.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.3.2" xref="S3.E3.m1.2.2.1.1.1.1.3.2.cmml">A</mi><mi id="S3.E3.m1.2.2.1.1.1.1.3.3" xref="S3.E3.m1.2.2.1.1.1.1.3.3.cmml">m</mi></msub></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.3.2" xref="S3.E3.m1.2.2.1.3.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.3.2.1" xref="S3.E3.m1.2.2.1.3.1.1.cmml">[</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">c</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.3.2.2" xref="S3.E3.m1.2.2.1.3.1.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"></eq><apply id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.3.1.cmml" xref="S3.E3.m1.2.2.3">subscript</csymbol><ci id="S3.E3.m1.2.2.3.2.cmml" xref="S3.E3.m1.2.2.3.2">ğ‘</ci><ci id="S3.E3.m1.2.2.3.3.cmml" xref="S3.E3.m1.2.2.3.3">ğ‘</ci></apply><apply id="S3.E3.m1.2.2.1.cmml" xref="S3.E3.m1.2.2.1"><times id="S3.E3.m1.2.2.1.2.cmml" xref="S3.E3.m1.2.2.1.2"></times><apply id="S3.E3.m1.2.2.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1"><minus id="S3.E3.m1.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1"></minus><apply id="S3.E3.m1.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2">ğ´</ci><ci id="S3.E3.m1.2.2.1.1.1.1.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.3">â„</ci></apply><apply id="S3.E3.m1.2.2.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3.2">ğ´</ci><ci id="S3.E3.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.3.3">ğ‘š</ci></apply></apply><apply id="S3.E3.m1.2.2.1.3.1.cmml" xref="S3.E3.m1.2.2.1.3.2"><csymbol cd="latexml" id="S3.E3.m1.2.2.1.3.1.1.cmml" xref="S3.E3.m1.2.2.1.3.2.1">delimited-[]</csymbol><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">\displaystyle a_{c}=(A_{h}-A_{m})[c]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p2.17" class="ltx_p">where the <math id="S3.SS1.p2.15.m1.1" class="ltx_Math" alttext="a_{c}&gt;0" display="inline"><semantics id="S3.SS1.p2.15.m1.1a"><mrow id="S3.SS1.p2.15.m1.1.1" xref="S3.SS1.p2.15.m1.1.1.cmml"><msub id="S3.SS1.p2.15.m1.1.1.2" xref="S3.SS1.p2.15.m1.1.1.2.cmml"><mi id="S3.SS1.p2.15.m1.1.1.2.2" xref="S3.SS1.p2.15.m1.1.1.2.2.cmml">a</mi><mi id="S3.SS1.p2.15.m1.1.1.2.3" xref="S3.SS1.p2.15.m1.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS1.p2.15.m1.1.1.1" xref="S3.SS1.p2.15.m1.1.1.1.cmml">&gt;</mo><mn id="S3.SS1.p2.15.m1.1.1.3" xref="S3.SS1.p2.15.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.15.m1.1b"><apply id="S3.SS1.p2.15.m1.1.1.cmml" xref="S3.SS1.p2.15.m1.1.1"><gt id="S3.SS1.p2.15.m1.1.1.1.cmml" xref="S3.SS1.p2.15.m1.1.1.1"></gt><apply id="S3.SS1.p2.15.m1.1.1.2.cmml" xref="S3.SS1.p2.15.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.15.m1.1.1.2.1.cmml" xref="S3.SS1.p2.15.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.15.m1.1.1.2.2.cmml" xref="S3.SS1.p2.15.m1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p2.15.m1.1.1.2.3.cmml" xref="S3.SS1.p2.15.m1.1.1.2.3">ğ‘</ci></apply><cn type="integer" id="S3.SS1.p2.15.m1.1.1.3.cmml" xref="S3.SS1.p2.15.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.15.m1.1c">a_{c}&gt;0</annotation></semantics></math> means that the extent of disagreement in humans is greater than the model, conversely <math id="S3.SS1.p2.16.m2.1" class="ltx_Math" alttext="a_{c}&lt;0" display="inline"><semantics id="S3.SS1.p2.16.m2.1a"><mrow id="S3.SS1.p2.16.m2.1.1" xref="S3.SS1.p2.16.m2.1.1.cmml"><msub id="S3.SS1.p2.16.m2.1.1.2" xref="S3.SS1.p2.16.m2.1.1.2.cmml"><mi id="S3.SS1.p2.16.m2.1.1.2.2" xref="S3.SS1.p2.16.m2.1.1.2.2.cmml">a</mi><mi id="S3.SS1.p2.16.m2.1.1.2.3" xref="S3.SS1.p2.16.m2.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS1.p2.16.m2.1.1.1" xref="S3.SS1.p2.16.m2.1.1.1.cmml">&lt;</mo><mn id="S3.SS1.p2.16.m2.1.1.3" xref="S3.SS1.p2.16.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.16.m2.1b"><apply id="S3.SS1.p2.16.m2.1.1.cmml" xref="S3.SS1.p2.16.m2.1.1"><lt id="S3.SS1.p2.16.m2.1.1.1.cmml" xref="S3.SS1.p2.16.m2.1.1.1"></lt><apply id="S3.SS1.p2.16.m2.1.1.2.cmml" xref="S3.SS1.p2.16.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.16.m2.1.1.2.1.cmml" xref="S3.SS1.p2.16.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.16.m2.1.1.2.2.cmml" xref="S3.SS1.p2.16.m2.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p2.16.m2.1.1.2.3.cmml" xref="S3.SS1.p2.16.m2.1.1.2.3">ğ‘</ci></apply><cn type="integer" id="S3.SS1.p2.16.m2.1.1.3.cmml" xref="S3.SS1.p2.16.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.16.m2.1c">a_{c}&lt;0</annotation></semantics></math>. By ranking the <math id="S3.SS1.p2.17.m3.1" class="ltx_Math" alttext="a_{c}" display="inline"><semantics id="S3.SS1.p2.17.m3.1a"><msub id="S3.SS1.p2.17.m3.1.1" xref="S3.SS1.p2.17.m3.1.1.cmml"><mi id="S3.SS1.p2.17.m3.1.1.2" xref="S3.SS1.p2.17.m3.1.1.2.cmml">a</mi><mi id="S3.SS1.p2.17.m3.1.1.3" xref="S3.SS1.p2.17.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.17.m3.1b"><apply id="S3.SS1.p2.17.m3.1.1.cmml" xref="S3.SS1.p2.17.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.17.m3.1.1.1.cmml" xref="S3.SS1.p2.17.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.17.m3.1.1.2.cmml" xref="S3.SS1.p2.17.m3.1.1.2">ğ‘</ci><ci id="S3.SS1.p2.17.m3.1.1.3.cmml" xref="S3.SS1.p2.17.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.17.m3.1c">a_{c}</annotation></semantics></math>, it is possible to find those classes with significant gaps between human perception and model inference.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.2" class="ltx_p">Fig. <a href="#S2.F3" title="Figure 3 â€£ item 1 â€£ II-B Label Alignment via Large Language Model â€£ II MAFAR Dataset â€£ Exploring Differences between Human Perception and Model Inference in Audio Event Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the disagreement and gap between human perception and model inference in terms of semantic event identification. In subfigure (a) and (b), comparing with humans and models, the results show that there are 10 same classes in the top 40 classes with the highest group disagreement. The difference is that models are more easily affected by vehicle noise, such as bus, ship, truck, ambulance, subway and Traffic noise, etc., while human seems to find it harder to achieve agreement on subtle, trivial or easily covered events, such as tearing, roll, cough, etc. Intuitively, this result aligns with common sense, as people in cities usually filter out persistent background noise, and different people may pay inconsistent attention to those subtle events <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Fig. <a href="#S2.F3" title="Figure 3 â€£ item 1 â€£ II-B Label Alignment via Large Language Model â€£ II MAFAR Dataset â€£ Exploring Differences between Human Perception and Model Inference in Audio Event Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (c) further shows the specific class with significant inconsistency of agreement between humans and models. Compared with models, most events that are harder for humans to reach achievement (<math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="a_{c}&gt;0" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><msub id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2.2" xref="S3.SS1.p3.1.m1.1.1.2.2.cmml">a</mi><mi id="S3.SS1.p3.1.m1.1.1.2.3" xref="S3.SS1.p3.1.m1.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS1.p3.1.m1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.cmml">&gt;</mo><mn id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><gt id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1"></gt><apply id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.2.1.cmml" xref="S3.SS1.p3.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p3.1.m1.1.1.2.3.cmml" xref="S3.SS1.p3.1.m1.1.1.2.3">ğ‘</ci></apply><cn type="integer" id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">a_{c}&gt;0</annotation></semantics></math>) are consistent with Fig. <a href="#S2.F3" title="Figure 3 â€£ item 1 â€£ II-B Label Alignment via Large Language Model â€£ II MAFAR Dataset â€£ Exploring Differences between Human Perception and Model Inference in Audio Event Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (a). For <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="a_{c}&lt;0" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mrow id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><msub id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2.2" xref="S3.SS1.p3.2.m2.1.1.2.2.cmml">a</mi><mi id="S3.SS1.p3.2.m2.1.1.2.3" xref="S3.SS1.p3.2.m2.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS1.p3.2.m2.1.1.1" xref="S3.SS1.p3.2.m2.1.1.1.cmml">&lt;</mo><mn id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><lt id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1.1"></lt><apply id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p3.2.m2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.2.3">ğ‘</ci></apply><cn type="integer" id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">a_{c}&lt;0</annotation></semantics></math>, besides the vehicle noise, it is obvious that models are also affected by semantic-similar classes, such as rain and rain on surface, domestic animals, horse, and Moo.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Difference in Event Existence Detection</span>
</h3>

<figure id="S3.F4" class="ltx_figure"><img src="/html/2409.06580/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="184" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The ensemble results of the existing AudioSet pre-trained models in event existence detection. The ground truth threshold of the existence of interested events is based on the total amount of labelled events from 10 annotators. Since there could be more than one event in segments, the ground truth threshold could exceed 10.</figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In addition to semantic identification, some AER tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> focus solely on detecting the existence of audio events. Existence detection is typically a binary classification applied for data pre-processing or anomalous detection, allowing for greater tolerance of semantic misidentification. The multi-person independent annotations in the MAFAR dataset provide an opportunity to explore the gap between human perception and model inference in event existence detection.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.2" class="ltx_p">Specifically, the labels from multiple annotators can be used to construct various â€œground truthsâ€ regarding the existence of events <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. By counting the number of labels for the same time period, an adjustable threshold can be set to define the ground truth according to the level of human agreement. To assign greater weight to individuals who annotate more events in the same period, this work adopts the total number of labelled events into the threshold judgment process instead of the annotator amount:</p>
<table id="S5.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4.m1.4" class="ltx_Math" alttext="\displaystyle y_{true}=\begin{cases}1,&amp;\text{if }\textit{sum}(H_{i})\geq\textit{threshold},\\
0,&amp;\text{else}\end{cases}" display="inline"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.5" xref="S3.E4.m1.4.5.cmml"><msub id="S3.E4.m1.4.5.2" xref="S3.E4.m1.4.5.2.cmml"><mi id="S3.E4.m1.4.5.2.2" xref="S3.E4.m1.4.5.2.2.cmml">y</mi><mrow id="S3.E4.m1.4.5.2.3" xref="S3.E4.m1.4.5.2.3.cmml"><mi id="S3.E4.m1.4.5.2.3.2" xref="S3.E4.m1.4.5.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.5.2.3.1" xref="S3.E4.m1.4.5.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.4.5.2.3.3" xref="S3.E4.m1.4.5.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.5.2.3.1a" xref="S3.E4.m1.4.5.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.4.5.2.3.4" xref="S3.E4.m1.4.5.2.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.5.2.3.1b" xref="S3.E4.m1.4.5.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.4.5.2.3.5" xref="S3.E4.m1.4.5.2.3.5.cmml">e</mi></mrow></msub><mo id="S3.E4.m1.4.5.1" xref="S3.E4.m1.4.5.1.cmml">=</mo><mrow id="S3.E4.m1.4.4a" xref="S3.E4.m1.4.5.3.1.cmml"><mo id="S3.E4.m1.4.4a.5" xref="S3.E4.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S3.E4.m1.4.4.4a" xref="S3.E4.m1.4.5.3.1.cmml"><mtr id="S3.E4.m1.4.4.4aa" xref="S3.E4.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.4.4.4ab" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.4.5.3.1.cmml"><mn id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml">1</mn><mo id="S3.E4.m1.1.1.1.1.1.1.3.1" xref="S3.E4.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.4.4.4ac" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.2.1.1" xref="S3.E4.m1.2.2.2.2.2.1.1.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.2.1.1.1" xref="S3.E4.m1.2.2.2.2.2.1.1.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.2.1.1.1.1" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.2.1.1.1.1.3" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.3c.cmml"><mtext id="S3.E4.m1.2.2.2.2.2.1.1.1.1.3a" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.3c.cmml">ifÂ </mtext><mtext class="ltx_mathvariant_italic" id="S3.E4.m1.2.2.2.2.2.1.1.1.1.3b" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.3c.cmml">sum</mtext></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.2.2.1.1.1.1.2" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.2.cmml">H</mi><mi id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.2.2.2.2.2.1.1.1.2" xref="S3.E4.m1.2.2.2.2.2.1.1.1.2.cmml">â‰¥</mo><mtext class="ltx_mathvariant_italic" id="S3.E4.m1.2.2.2.2.2.1.1.1.3" xref="S3.E4.m1.2.2.2.2.2.1.1.1.3a.cmml">threshold</mtext></mrow><mo id="S3.E4.m1.2.2.2.2.2.1.1.2" xref="S3.E4.m1.2.2.2.2.2.1.1.1.cmml">,</mo></mrow></mtd></mtr><mtr id="S3.E4.m1.4.4.4ad" xref="S3.E4.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.4.4.4ae" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.3.3.3.3.1.1.3" xref="S3.E4.m1.4.5.3.1.cmml"><mn id="S3.E4.m1.3.3.3.3.1.1.1" xref="S3.E4.m1.3.3.3.3.1.1.1.cmml">0</mn><mo id="S3.E4.m1.3.3.3.3.1.1.3.1" xref="S3.E4.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.4.4.4af" xref="S3.E4.m1.4.5.3.1.cmml"><mtext id="S3.E4.m1.4.4.4.4.2.1" xref="S3.E4.m1.4.4.4.4.2.1a.cmml">else</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.5.cmml" xref="S3.E4.m1.4.5"><eq id="S3.E4.m1.4.5.1.cmml" xref="S3.E4.m1.4.5.1"></eq><apply id="S3.E4.m1.4.5.2.cmml" xref="S3.E4.m1.4.5.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.5.2.1.cmml" xref="S3.E4.m1.4.5.2">subscript</csymbol><ci id="S3.E4.m1.4.5.2.2.cmml" xref="S3.E4.m1.4.5.2.2">ğ‘¦</ci><apply id="S3.E4.m1.4.5.2.3.cmml" xref="S3.E4.m1.4.5.2.3"><times id="S3.E4.m1.4.5.2.3.1.cmml" xref="S3.E4.m1.4.5.2.3.1"></times><ci id="S3.E4.m1.4.5.2.3.2.cmml" xref="S3.E4.m1.4.5.2.3.2">ğ‘¡</ci><ci id="S3.E4.m1.4.5.2.3.3.cmml" xref="S3.E4.m1.4.5.2.3.3">ğ‘Ÿ</ci><ci id="S3.E4.m1.4.5.2.3.4.cmml" xref="S3.E4.m1.4.5.2.3.4">ğ‘¢</ci><ci id="S3.E4.m1.4.5.2.3.5.cmml" xref="S3.E4.m1.4.5.2.3.5">ğ‘’</ci></apply></apply><apply id="S3.E4.m1.4.5.3.1.cmml" xref="S3.E4.m1.4.4a"><csymbol cd="latexml" id="S3.E4.m1.4.5.3.1.1.cmml" xref="S3.E4.m1.4.4a.5">cases</csymbol><cn type="integer" id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1">1</cn><apply id="S3.E4.m1.2.2.2.2.2.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1"><geq id="S3.E4.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.2"></geq><apply id="S3.E4.m1.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1"><times id="S3.E4.m1.2.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.2"></times><ci id="S3.E4.m1.2.2.2.2.2.1.1.1.1.3c.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.3"><mrow id="S3.E4.m1.2.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.3"><mtext id="S3.E4.m1.2.2.2.2.2.1.1.1.1.3a.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.3">ifÂ </mtext><mtext class="ltx_mathvariant_italic" id="S3.E4.m1.2.2.2.2.2.1.1.1.1.3b.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.3">sum</mtext></mrow></ci><apply id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.2">ğ»</ci><ci id="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><ci id="S3.E4.m1.2.2.2.2.2.1.1.1.3a.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.3"><mtext class="ltx_mathvariant_italic" id="S3.E4.m1.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1.1.3">threshold</mtext></ci></apply><cn type="integer" id="S3.E4.m1.3.3.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1">0</cn><ci id="S3.E4.m1.4.4.4.4.2.1a.cmml" xref="S3.E4.m1.4.4.4.4.2.1"><mtext id="S3.E4.m1.4.4.4.4.2.1.cmml" xref="S3.E4.m1.4.4.4.4.2.1">else</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">\displaystyle y_{true}=\begin{cases}1,&amp;\text{if }\textit{sum}(H_{i})\geq\textit{threshold},\\
0,&amp;\text{else}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.1" class="ltx_p">where <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="y_{true}=1" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><msub id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2.2" xref="S3.SS2.p2.1.m1.1.1.2.2.cmml">y</mi><mrow id="S3.SS2.p2.1.m1.1.1.2.3" xref="S3.SS2.p2.1.m1.1.1.2.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2.3.2" xref="S3.SS2.p2.1.m1.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.2.3.1" xref="S3.SS2.p2.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.1.m1.1.1.2.3.3" xref="S3.SS2.p2.1.m1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.2.3.1a" xref="S3.SS2.p2.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.1.m1.1.1.2.3.4" xref="S3.SS2.p2.1.m1.1.1.2.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.2.3.1b" xref="S3.SS2.p2.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.1.m1.1.1.2.3.5" xref="S3.SS2.p2.1.m1.1.1.2.3.5.cmml">e</mi></mrow></msub><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><eq id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></eq><apply id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.2.1.cmml" xref="S3.SS2.p2.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2.2">ğ‘¦</ci><apply id="S3.SS2.p2.1.m1.1.1.2.3.cmml" xref="S3.SS2.p2.1.m1.1.1.2.3"><times id="S3.SS2.p2.1.m1.1.1.2.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.2.3.1"></times><ci id="S3.SS2.p2.1.m1.1.1.2.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2.3.2">ğ‘¡</ci><ci id="S3.SS2.p2.1.m1.1.1.2.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S3.SS2.p2.1.m1.1.1.2.3.4.cmml" xref="S3.SS2.p2.1.m1.1.1.2.3.4">ğ‘¢</ci><ci id="S3.SS2.p2.1.m1.1.1.2.3.5.cmml" xref="S3.SS2.p2.1.m1.1.1.2.3.5">ğ‘’</ci></apply></apply><cn type="integer" id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">y_{true}=1</annotation></semantics></math> represents the existence of the event.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.2" class="ltx_p">For the AudioSet pre-trained models used in this work, as they are pre-trained multi-class classification tasks, this work uses the maximum value of ensemble prediction of 527 classes as the result of event existence detection:</p>
<table id="S5.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E5.m1.4" class="ltx_Math" alttext="\displaystyle y_{pre}=\begin{cases}1,&amp;\text{if }\textit{max}(y^{\prime})&gt;0.5,\\
0,&amp;\text{else}\end{cases}" display="inline"><semantics id="S3.E5.m1.4a"><mrow id="S3.E5.m1.4.5" xref="S3.E5.m1.4.5.cmml"><msub id="S3.E5.m1.4.5.2" xref="S3.E5.m1.4.5.2.cmml"><mi id="S3.E5.m1.4.5.2.2" xref="S3.E5.m1.4.5.2.2.cmml">y</mi><mrow id="S3.E5.m1.4.5.2.3" xref="S3.E5.m1.4.5.2.3.cmml"><mi id="S3.E5.m1.4.5.2.3.2" xref="S3.E5.m1.4.5.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.5.2.3.1" xref="S3.E5.m1.4.5.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.4.5.2.3.3" xref="S3.E5.m1.4.5.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.5.2.3.1a" xref="S3.E5.m1.4.5.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.4.5.2.3.4" xref="S3.E5.m1.4.5.2.3.4.cmml">e</mi></mrow></msub><mo id="S3.E5.m1.4.5.1" xref="S3.E5.m1.4.5.1.cmml">=</mo><mrow id="S3.E5.m1.4.4a" xref="S3.E5.m1.4.5.3.1.cmml"><mo id="S3.E5.m1.4.4a.5" xref="S3.E5.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S3.E5.m1.4.4.4a" xref="S3.E5.m1.4.5.3.1.cmml"><mtr id="S3.E5.m1.4.4.4aa" xref="S3.E5.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.4.4.4ab" xref="S3.E5.m1.4.5.3.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1.1.3" xref="S3.E5.m1.4.5.3.1.cmml"><mn id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.cmml">1</mn><mo id="S3.E5.m1.1.1.1.1.1.1.3.1" xref="S3.E5.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.4.4.4ac" xref="S3.E5.m1.4.5.3.1.cmml"><mrow id="S3.E5.m1.2.2.2.2.2.1.1" xref="S3.E5.m1.2.2.2.2.2.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.2.2.2.1.1.1" xref="S3.E5.m1.2.2.2.2.2.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.2.2.2.1.1.1.1" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.cmml"><mrow id="S3.E5.m1.2.2.2.2.2.1.1.1.1.3" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.3c.cmml"><mtext id="S3.E5.m1.2.2.2.2.2.1.1.1.1.3a" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.3c.cmml">ifÂ </mtext><mtext class="ltx_mathvariant_italic" id="S3.E5.m1.2.2.2.2.2.1.1.1.1.3b" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.3c.cmml">max</mtext></mrow><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.2.1.1.1.1.2" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.2.cmml">y</mi><mo id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.2.2.2.2.2.1.1.1.2" xref="S3.E5.m1.2.2.2.2.2.1.1.1.2.cmml">&gt;</mo><mn id="S3.E5.m1.2.2.2.2.2.1.1.1.3" xref="S3.E5.m1.2.2.2.2.2.1.1.1.3.cmml">0.5</mn></mrow><mo id="S3.E5.m1.2.2.2.2.2.1.1.2" xref="S3.E5.m1.2.2.2.2.2.1.1.1.cmml">,</mo></mrow></mtd></mtr><mtr id="S3.E5.m1.4.4.4ad" xref="S3.E5.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.4.4.4ae" xref="S3.E5.m1.4.5.3.1.cmml"><mrow id="S3.E5.m1.3.3.3.3.1.1.3" xref="S3.E5.m1.4.5.3.1.cmml"><mn id="S3.E5.m1.3.3.3.3.1.1.1" xref="S3.E5.m1.3.3.3.3.1.1.1.cmml">0</mn><mo id="S3.E5.m1.3.3.3.3.1.1.3.1" xref="S3.E5.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.4.4.4af" xref="S3.E5.m1.4.5.3.1.cmml"><mtext id="S3.E5.m1.4.4.4.4.2.1" xref="S3.E5.m1.4.4.4.4.2.1a.cmml">else</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.4b"><apply id="S3.E5.m1.4.5.cmml" xref="S3.E5.m1.4.5"><eq id="S3.E5.m1.4.5.1.cmml" xref="S3.E5.m1.4.5.1"></eq><apply id="S3.E5.m1.4.5.2.cmml" xref="S3.E5.m1.4.5.2"><csymbol cd="ambiguous" id="S3.E5.m1.4.5.2.1.cmml" xref="S3.E5.m1.4.5.2">subscript</csymbol><ci id="S3.E5.m1.4.5.2.2.cmml" xref="S3.E5.m1.4.5.2.2">ğ‘¦</ci><apply id="S3.E5.m1.4.5.2.3.cmml" xref="S3.E5.m1.4.5.2.3"><times id="S3.E5.m1.4.5.2.3.1.cmml" xref="S3.E5.m1.4.5.2.3.1"></times><ci id="S3.E5.m1.4.5.2.3.2.cmml" xref="S3.E5.m1.4.5.2.3.2">ğ‘</ci><ci id="S3.E5.m1.4.5.2.3.3.cmml" xref="S3.E5.m1.4.5.2.3.3">ğ‘Ÿ</ci><ci id="S3.E5.m1.4.5.2.3.4.cmml" xref="S3.E5.m1.4.5.2.3.4">ğ‘’</ci></apply></apply><apply id="S3.E5.m1.4.5.3.1.cmml" xref="S3.E5.m1.4.4a"><csymbol cd="latexml" id="S3.E5.m1.4.5.3.1.1.cmml" xref="S3.E5.m1.4.4a.5">cases</csymbol><cn type="integer" id="S3.E5.m1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1">1</cn><apply id="S3.E5.m1.2.2.2.2.2.1.1.1.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1"><gt id="S3.E5.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.2"></gt><apply id="S3.E5.m1.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1"><times id="S3.E5.m1.2.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.2"></times><ci id="S3.E5.m1.2.2.2.2.2.1.1.1.1.3c.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.3"><mrow id="S3.E5.m1.2.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.3"><mtext id="S3.E5.m1.2.2.2.2.2.1.1.1.1.3a.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.3">ifÂ </mtext><mtext class="ltx_mathvariant_italic" id="S3.E5.m1.2.2.2.2.2.1.1.1.1.3b.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.3">max</mtext></mrow></ci><apply id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.2">ğ‘¦</ci><ci id="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.1.1.1.1.3">â€²</ci></apply></apply><cn type="float" id="S3.E5.m1.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E5.m1.2.2.2.2.2.1.1.1.3">0.5</cn></apply><cn type="integer" id="S3.E5.m1.3.3.3.3.1.1.1.cmml" xref="S3.E5.m1.3.3.3.3.1.1.1">0</cn><ci id="S3.E5.m1.4.4.4.4.2.1a.cmml" xref="S3.E5.m1.4.4.4.4.2.1"><mtext id="S3.E5.m1.4.4.4.4.2.1.cmml" xref="S3.E5.m1.4.4.4.4.2.1">else</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.4c">\displaystyle y_{pre}=\begin{cases}1,&amp;\text{if }\textit{max}(y^{\prime})&gt;0.5,\\
0,&amp;\text{else}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.1" class="ltx_p">where <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="y^{\prime}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><msup id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">y</mi><mo id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğ‘¦</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">y^{\prime}</annotation></semantics></math> is the averaged output of all ensemble models.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Fig. <a href="#S3.F4" title="Figure 4 â€£ III-B Difference in Event Existence Detection â€£ III Benchmark Methods and Resutls â€£ Exploring Differences between Human Perception and Model Inference in Audio Event Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the Precision, Recall and F-measure scores <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> of the ensemble pre-trained models with different ground truth thresholds. With the threshold for the number of human labels increasing, the results show that the Precision and F-measure gradually reduce, while the Recall has a subtle increase. This tendency illustrates that machine inference tends to align with the <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\textit{threshold}=1" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mrow id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2a.cmml">threshold</mtext><mo id="S3.SS2.p4.1.m1.1.1.1" xref="S3.SS2.p4.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><eq id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1.1"></eq><ci id="S3.SS2.p4.1.m1.1.1.2a.cmml" xref="S3.SS2.p4.1.m1.1.1.2"><mtext class="ltx_mathvariant_italic" id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">threshold</mtext></ci><cn type="integer" id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\textit{threshold}=1</annotation></semantics></math>, namely that the ground truth is the union set of all labelling results, indicating that models are more sensitive to event existence detection than humans. The Recall curve also indicates that the benchmark tends to ignore 15%-20% human-interested events, and this ignoring alleviates slightly as the ground truth threshold increases.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Discussion</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">For the gaps between human perception and current model inference, we suspect that the reason may lie in the labelling sides, where sounds are taken out of context and given way more attention than they would have in real life. Particularly for the AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, videos from the YouTube source are uploaded by people who already bias the data towards salient events, as these are typically considered more noteworthy by the public.
Meanwhile, under the existing evaluation criteria of AER (e.g., mAP<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>), most methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> tend to adopt a series of techniques to alleviate the influence of imbalanced data for better performance, while these techniques also may further magnify the salience of some trivial events. Given the current research trends, audio event recognition models may face a dilemma between pursuing better performance metrics and aligning with real human perception, which is worth noting for AER researchers and the DCASE community.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This work proposes the MAFAR dataset to quantify human perception in AER-related tasks and promote future research on semantic importance in AER systems. By comparing the distribution of labels from multiple annotators, the study captures differences and highlights the gap between human perception and model inference in event semantic identification and existence detection. Experimental results reveal that human perception and model inference have a significant gap in subtle or noisy audio events of semantic identification. In contrast, the ensemble of pre-trained models shows more sensitivity than humans in event existence detection. These gaps may arise from biased datasets and model evaluation criteria, amplifying the salience of certain events. This work calls for more attention to this issue and will continue to annotate more audio clips in different scenes to expand the scale of the MAFAR dataset.
</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
TeckÂ Kai Chan and ChengÂ Siong Chin,

</span>
<span class="ltx_bibblock">â€œA comprehensive review of polyphonic sound event detection,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, vol. 8, pp. 103339â€“103373, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Annamaria Mesaros, Toni Heittola, Tuomas Virtanen, and MarkÂ D Plumbley,

</span>
<span class="ltx_bibblock">â€œSound event detection: A tutorial,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing Magazine</span>, vol. 38, no. 5, pp. 67â€“83, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Yizhou Tan, Haojun Ai, Shengchen Li, and Feng Zhang,

</span>
<span class="ltx_bibblock">â€œTransductive feature space regularization for few-shot bioacoustic event detection,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">24th International Speech Communication Association, Interspeech 2023</span>, 2023, pp. 571â€“575.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Yuanbo Hou, Qiaoqiao Ren, Huizhong Zhang, Andrew Mitchell, Francesco Aletta, Jian Kang, and Dick Botteldooren,

</span>
<span class="ltx_bibblock">â€œAi-based soundscape analysis: Jointly identifying sound sources and predicting annoyance,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">The Journal of the Acoustical Society of America</span>, vol. 154, no. 5, pp. 3145â€“3157, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
JortÂ F Gemmeke, DanielÂ PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, RÂ Channing Moore, Manoj Plakal, and Marvin Ritter,

</span>
<span class="ltx_bibblock">â€œAudio set: An ontology and human-labeled dataset for audio events,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)</span>. IEEE, 2017, pp. 776â€“780.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Ines Nolasco, Shubhr Singh, Ariana Strandburg-Peshkin, Lisa Gill, Hanna Pamula, Joe Morford, Michael Emmerson, Frants Jensens, Helen Whitehead, Ivan Kiskin, Ester Vidana-Villa, Vincent Lostanlen, Veronica Morfi, and Dan Stowell,

</span>
<span class="ltx_bibblock">â€œDCASE 2022 Task 5: Few-shot Bioacoustic Event Detection Development Set,â€ Mar. 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Annamaria Mesaros, Toni Heittola, and Tuomas Virtanen,

</span>
<span class="ltx_bibblock">â€œTut database for acoustic scene classification and sound event detection,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">2016 24th European Signal Processing Conference (EUSIPCO)</span>. IEEE, 2016, pp. 1128â€“1132.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Archontis Politis, Sharath Adavanne, and Tuomas Virtanen,

</span>
<span class="ltx_bibblock">â€œA dataset of reverberant spatial sound scenes with moving sources for sound event localization and detection,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2006.01919</span>, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
KarolÂ J Piczak,

</span>
<span class="ltx_bibblock">â€œEsc: Dataset for environmental sound classification,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the 23rd ACM international conference on Multimedia</span>, 2015, pp. 1015â€“1018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Eduardo Fonseca, Manoj Plakal, DanielÂ PW Ellis, Frederic Font, Xavier Favory, and Xavier Serra,

</span>
<span class="ltx_bibblock">â€œLearning sound event classifiers from web audio with noisy labels,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2019, pp. 21â€“25.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Aude Oliva and Antonio Torralba,

</span>
<span class="ltx_bibblock">â€œThe role of context in object recognition,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Trends in cognitive sciences</span>, vol. 11, no. 12, pp. 520â€“527, 2007.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Jakob AbeÃŸer,

</span>
<span class="ltx_bibblock">â€œA review of deep learning based methods for acoustic scene classification,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Applied Sciences</span>, vol. 10, no. 6, pp. 2020, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Yiqiang Cai, Shengchen Li, and XiÂ Shao,

</span>
<span class="ltx_bibblock">â€œLeveraging self-supervised audio representations for data-efficient acoustic scene classification,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2408.14862</span>, 2024.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Yiqiang Cai, Peihong Zhang, and Shengchen Li,

</span>
<span class="ltx_bibblock">â€œTf-sepnet: An efficient 1d kernel design in cnns for low-complexity acoustic scene classification,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2024, pp. 821â€“825.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Yizhou Tan, Haojun Ai, Shengchen Li, and MarkÂ D. Plumbley,

</span>
<span class="ltx_bibblock">â€œAcoustic scene classification across cities and devices via feature disentanglement,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, vol. 32, pp. 1286â€“1297, 2024.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Yuanbo Hou, BoÂ Kang, Andrew Mitchell, Wenwu Wang, Jian Kang, and Dick Botteldooren,

</span>
<span class="ltx_bibblock">â€œCooperative scene-event modelling for acoustic scene classification,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, vol. 32, pp. 68â€“82, 2024.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Toni Heittola, Annamaria Mesaros, Antti Eronen, and Tuomas Virtanen,

</span>
<span class="ltx_bibblock">â€œContext-dependent sound event detection,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">EURASIP Journal on audio, speech, and music processing</span>, vol. 2013, pp. 1â€“13, 2013.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Noriyuki Tonami, Keisuke Imoto, Ryotaro Nagase, Yuki Okamoto, Takahiro Fukumori, and Yoichi Yamashita,

</span>
<span class="ltx_bibblock">â€œSound event detection guided by semantic contexts of scenes,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2022, pp. 801â€“805.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Feng-Ju Chang, Jing Liu, Martin Radfar, Athanasios Mouchtaris, Maurizio Omologo, Ariya Rastrow, and Siegfried Kunzmann,

</span>
<span class="ltx_bibblock">â€œContext-aware transformer transducer for speech recognition,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</span>. IEEE, 2021, pp. 503â€“510.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, FlorenciaÂ Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, etÂ al.,

</span>
<span class="ltx_bibblock">â€œGpt-4 technical report,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.08774</span>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Wenxi Chen, Yuzhe Liang, Ziyang Ma, Zhisheng Zheng, and Xie Chen,

</span>
<span class="ltx_bibblock">â€œEat: Self-supervised pre-training with efficient audio transformer,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI-24</span>, Kate Larson, Ed. 8 2024, pp. 3807â€“3815, International Joint Conferences on Artificial Intelligence Organization,

</span>
<span class="ltx_bibblock">Main Track.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Qiuqiang Kong, Yin Cao, Turab Iqbal, Yuxuan Wang, Wenwu Wang, and MarkÂ D Plumbley,

</span>
<span class="ltx_bibblock">â€œPanns: Large-scale pretrained audio neural networks for audio pattern recognition,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, vol. 28, pp. 2880â€“2894, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Yuanbo Hou, Qiuqiang Kong, Jun Wang, and Shengchen Li,

</span>
<span class="ltx_bibblock">â€œPolyphonic audio tagging with sequentially labelled data using crnn with learnable gated linear units,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Proceedings of the Detection and Classification of Acoustic Scenes and Events 2018 Workshop (DCASE2018)</span>, 2018, pp. 78â€“82.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Yong Xu, Qiuqiang Kong, Wenwu Wang, and MarkÂ D Plumbley,

</span>
<span class="ltx_bibblock">â€œLarge-scale weakly supervised audio classification using gated convolutional neural network,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)</span>. IEEE, 2018, pp. 121â€“125.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Taejun Kim, Jongpil Lee, and Juhan Nam,

</span>
<span class="ltx_bibblock">â€œComparison and analysis of samplecnn architectures for audio classification,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">IEEE Journal of Selected Topics in Signal Processing</span>, vol. 13, no. 2, pp. 285â€“297, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Yuan Gong, Yu-An Chung, and James Glass,

</span>
<span class="ltx_bibblock">â€œPsla: Improving audio tagging with pretraining, sampling, labeling, and aggregation,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span>, vol. 29, pp. 3292â€“3306, 2021.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Taiwo Kolajo and Olawande Daramola,

</span>
<span class="ltx_bibblock">â€œHuman-centric and semantics-based explainable event detection: a survey,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence Review</span>, vol. 56, no. Suppl 1, pp. 119â€“158, 2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Nicholas Carlini, Ulfar Erlingsson, and Nicolas Papernot,

</span>
<span class="ltx_bibblock">â€œDistribution density, tails, and outliers in machine learning: Metrics and applications,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1910.13427</span>, 2019.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Michael Stocker,

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Hear where we are: Sound, ecology, and sense of place</span>,

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media, 2013.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Stefano Rovetta, Zied Mnasri, and Francesco Masulli,

</span>
<span class="ltx_bibblock">â€œDetection of hazardous road events from audio streams: An ensemble outlier detection approach,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">2020 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)</span>. IEEE, 2020, pp. 1â€“6.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Paul Primus, Verena Haunschmid, Patrick Praher, and Gerhard Widmer,

</span>
<span class="ltx_bibblock">â€œAnomalous sound detection as a simple binary classification problem with careful selection of proxy outlier examples,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2011.02949</span>, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Kevin Wilkinghoff,

</span>
<span class="ltx_bibblock">â€œSub-cluster adacos: Learning representations for anomalous sound detection,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">2021 International Joint Conference on Neural Networks (IJCNN)</span>. IEEE, 2021, pp. 1â€“8.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Kaori Suefusa, Tomoya Nishida, Harsh Purohit, Ryo Tanabe, Takashi Endo, and Yohei Kawaguchi,

</span>
<span class="ltx_bibblock">â€œAnomalous sound detection based on interpolation deep neural network,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>. IEEE, 2020, pp. 271â€“275.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Gordon Wichern, Ankush Chakrabarty, Zhong-Qiu Wang, and Jonathan LeÂ Roux,

</span>
<span class="ltx_bibblock">â€œAnomalous sound detection using attentive neural processes,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</span>. IEEE, 2021, pp. 186â€“190.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Mark Cartwright, Graham Dove, AnaÂ Elisa MÃ©ndezÂ MÃ©ndez, JuanÂ P Bello, and Oded Nov,

</span>
<span class="ltx_bibblock">â€œCrowdsourcing multi-label audio annotation tasks with citizen scientists,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2019 CHI conference on human factors in computing systems</span>, 2019, pp. 1â€“11.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Eric Humphrey, Simon Durand, and Brian McFee,

</span>
<span class="ltx_bibblock">â€œOpenmic-2018: An open data-set for multiple instrument recognition.,â€

</span>
<span class="ltx_bibblock">in <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">ISMIR</span>, 2018, pp. 438â€“444.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Dan Stowell, Dimitrios Giannoulis, Emmanouil Benetos, Mathieu Lagrange, and MarkÂ D Plumbley,

</span>
<span class="ltx_bibblock">â€œDetection and classification of acoustic scenes and events,â€

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Multimedia</span>, vol. 17, no. 10, pp. 1733â€“1746, 2015.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.06579" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.06580" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.06580">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.06580" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.06581" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 21:39:06 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
