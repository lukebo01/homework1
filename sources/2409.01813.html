<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.01813] Reassessing Noise Augmentation Methods in the Context of Adversarial Speech</title><meta property="og:description" content="In this study, we investigate if noise-augmented training can concurrently improve adversarial robustness in automatic speech recognition (ASR) systems. We conduct a comparative analysis of the adversarial robustness o…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Reassessing Noise Augmentation Methods in the Context of Adversarial Speech">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Reassessing Noise Augmentation Methods in the Context of Adversarial Speech">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.01813">

<!--Generated on Sun Oct  6 01:37:38 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.2" class="ltx_ERROR undefined">\name</span>
<p id="p1.3" class="ltx_p">[affiliation=1,2,*]KarlaPizzi
<span id="p1.3.1" class="ltx_ERROR undefined">\name</span>[affiliation=3,*]Matías P.Pizarro B.
<span id="p1.3.2" class="ltx_ERROR undefined">\name</span>[affiliation=3]AsjaFischer</p>
</div>
<h1 class="ltx_title ltx_title_document">Reassessing Noise Augmentation Methods 
<br class="ltx_break">in the Context of Adversarial Speech</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id10.id1" class="ltx_p">In this study, we investigate if noise-augmented training can concurrently improve adversarial robustness in automatic speech recognition (ASR) systems. We conduct a comparative analysis of the adversarial robustness of four different state-of-the-art ASR architectures, where each of the ASR architectures is trained under three different augmentation conditions: one subject to background noise, speed variations, and reverberations, another subject to speed variations only, and a third without any form of data
augmentation.
The results demonstrate that noise augmentation not only improves model performance on noisy speech but also the model's robustness to adversarial attacks.
</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>automatic speech recognition, adversarial attacks, adversarial robustness, noise robustness
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Adversarial attacks, also known as evasion attacks, on machine learning models have garnered significant attention due to their potential to compromise the models' reliability and security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
While early research primarily focused on adversarial attacks on computer vision models, there has been a growing interest in the vulnerability of audio processing models, particularly speech processing systems, to such attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
Concurrently, efforts to enhance noise robustness have been undertaken to improve the usability of speech processing systems in various environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
However, the relationship between noise robustness and adversarial robustness in the audio domain remains largely unexplored.
This paper contributes to filling this gap by investigating whether noise-augmented training can also improve adversarial robustness of speech recognition systems.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Noise robustness, also known as environmental robustness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> reflects a model's ability to maintain performance despite exposure to various forms of noise and perturbations. Given that real-world audio data often includes inherent noise and environmental disturbances, ensuring noise robustness is essential for reliable audio processing and analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Adversarial robustness, on the other hand, refers to a model's ability to resist adversarial attacks and maintain accurate predictions when faced with manipulated audio samples.
These attacks introduce perturbations that are often imperceptible to humans and can deceive the model into making incorrect predictions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
In automatic speech recognition (ASR) systems, adversarial attacks can compromise security and privacy, potentially leading to unauthorized access or incorrect processing of sensitive data.
For instance, an attacker could alter an audio signal to mislead an ASR system into executing unintended commands, such as purchasing an unwanted product or navigating to a malicious webpage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
Thus, adversarial robustness is critical for model security, enabling the detection and prevention of malicious attacks on audio systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Understanding the interplay between noise robustness and adversarial robustness in the audio domain is crucial <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
We hypothesize that ASR models with enhanced resistance to acoustic perturbations may inherently exhibit a degree of robustness to adversarial attacks.
To test this hypothesis, we conduct a comprehensive empirical analysis, evaluating the impact of noise-augmented training on the adversarial defense capabilities of various state-of-the-art ASR models.
Our study encompasses a range of noise types, in particular background disturbances, and reverberations, and assesses the models' robustness against attacks in the white-box scenario.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section provides an overview of adversarial attacks and various types of robustness concerning ASR systems.
We also discuss the interdependency between adversarial and noise robustness, drawing on literature from the image domain.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Adversarial Attacks</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Adversarial examples are inputs intentionally modified to induce errors in machine learning models.
These perturbations, often imperceptible to humans, can significantly degrade model performance.
In speech recognition, adversarial examples exploit ASR system vulnerabilities, resulting in incorrect transcriptions.
This study employs a targeted white-box attack to analyze the models' susceptibility to adversarial attacks.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> introduced the first efficient white-box targeted attack against ASR systems, known as the C&amp;W attack. Assuming the attacker has full access to the model, they can create manipulated audio data that transcribes to a specific target phrase.
Originally designed for Mozilla's DeepSpeech model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, the C&amp;W attack is a gradient-based method that iteratively computes adversarial noise.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">The attack minimizes the following loss function with respect to a perturbation <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mi id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\delta</annotation></semantics></math>:</p>
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.6" class="ltx_Math" alttext="L(x,\delta,\hat{y})=l_{m}(f(x+\delta),\hat{y})+c\cdot|\delta|_{2}^{2}\enspace," display="block"><semantics id="S2.Ex1.m1.6a"><mrow id="S2.Ex1.m1.6.6.1" xref="S2.Ex1.m1.6.6.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1" xref="S2.Ex1.m1.6.6.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.3" xref="S2.Ex1.m1.6.6.1.1.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.3.1" xref="S2.Ex1.m1.6.6.1.1.3.1.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.3.3.2" xref="S2.Ex1.m1.6.6.1.1.3.3.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.3.3.2.1" xref="S2.Ex1.m1.6.6.1.1.3.3.1.cmml">(</mo><mi id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml">x</mi><mo id="S2.Ex1.m1.6.6.1.1.3.3.2.2" xref="S2.Ex1.m1.6.6.1.1.3.3.1.cmml">,</mo><mi id="S2.Ex1.m1.2.2" xref="S2.Ex1.m1.2.2.cmml">δ</mi><mo id="S2.Ex1.m1.6.6.1.1.3.3.2.3" xref="S2.Ex1.m1.6.6.1.1.3.3.1.cmml">,</mo><mover accent="true" id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml"><mi id="S2.Ex1.m1.3.3.2" xref="S2.Ex1.m1.3.3.2.cmml">y</mi><mo id="S2.Ex1.m1.3.3.1" xref="S2.Ex1.m1.3.3.1.cmml">^</mo></mover><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.3.3.2.4" xref="S2.Ex1.m1.6.6.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.6.6.1.1.2" xref="S2.Ex1.m1.6.6.1.1.2.cmml">=</mo><mrow id="S2.Ex1.m1.6.6.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.cmml"><msub id="S2.Ex1.m1.6.6.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.1.1.3.2.cmml">l</mi><mi id="S2.Ex1.m1.6.6.1.1.1.1.3.3" xref="S2.Ex1.m1.6.6.1.1.1.1.3.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.cmml">δ</mi></mrow><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml">,</mo><mover accent="true" id="S2.Ex1.m1.4.4" xref="S2.Ex1.m1.4.4.cmml"><mi id="S2.Ex1.m1.4.4.2" xref="S2.Ex1.m1.4.4.2.cmml">y</mi><mo id="S2.Ex1.m1.4.4.1" xref="S2.Ex1.m1.4.4.1.cmml">^</mo></mover><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.4" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.6.6.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.2.cmml">+</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.1.3.2.cmml">c</mi><mo lspace="0.222em" rspace="0.222em" id="S2.Ex1.m1.6.6.1.1.1.3.1" xref="S2.Ex1.m1.6.6.1.1.1.3.1.cmml">⋅</mo><msubsup id="S2.Ex1.m1.6.6.1.1.1.3.3" xref="S2.Ex1.m1.6.6.1.1.1.3.3.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.2" xref="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.2.1" xref="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.1.1.cmml">|</mo><mi id="S2.Ex1.m1.5.5" xref="S2.Ex1.m1.5.5.cmml">δ</mi><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.2.2" xref="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.1.1.cmml">|</mo></mrow><mn id="S2.Ex1.m1.6.6.1.1.1.3.3.2.3" xref="S2.Ex1.m1.6.6.1.1.1.3.3.2.3.cmml">2</mn><mn id="S2.Ex1.m1.6.6.1.1.1.3.3.3" xref="S2.Ex1.m1.6.6.1.1.1.3.3.3.cmml">2</mn></msubsup></mrow></mrow></mrow><mo id="S2.Ex1.m1.6.6.1.2" xref="S2.Ex1.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.6b"><apply id="S2.Ex1.m1.6.6.1.1.cmml" xref="S2.Ex1.m1.6.6.1"><eq id="S2.Ex1.m1.6.6.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2"></eq><apply id="S2.Ex1.m1.6.6.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.3"><times id="S2.Ex1.m1.6.6.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.3.1"></times><ci id="S2.Ex1.m1.6.6.1.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.3.2">𝐿</ci><vector id="S2.Ex1.m1.6.6.1.1.3.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.3.3.2"><ci id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1">𝑥</ci><ci id="S2.Ex1.m1.2.2.cmml" xref="S2.Ex1.m1.2.2">𝛿</ci><apply id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3"><ci id="S2.Ex1.m1.3.3.1.cmml" xref="S2.Ex1.m1.3.3.1">^</ci><ci id="S2.Ex1.m1.3.3.2.cmml" xref="S2.Ex1.m1.3.3.2">𝑦</ci></apply></vector></apply><apply id="S2.Ex1.m1.6.6.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1"><plus id="S2.Ex1.m1.6.6.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.2"></plus><apply id="S2.Ex1.m1.6.6.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1"><times id="S2.Ex1.m1.6.6.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.2"></times><apply id="S2.Ex1.m1.6.6.1.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.3">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.1.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.3.2">𝑙</ci><ci id="S2.Ex1.m1.6.6.1.1.1.1.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.3.3">𝑚</ci></apply><interval closure="open" id="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1"><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1"><times id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2"></times><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3">𝑓</ci><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1"><plus id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.1"></plus><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3">𝛿</ci></apply></apply><apply id="S2.Ex1.m1.4.4.cmml" xref="S2.Ex1.m1.4.4"><ci id="S2.Ex1.m1.4.4.1.cmml" xref="S2.Ex1.m1.4.4.1">^</ci><ci id="S2.Ex1.m1.4.4.2.cmml" xref="S2.Ex1.m1.4.4.2">𝑦</ci></apply></interval></apply><apply id="S2.Ex1.m1.6.6.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3"><ci id="S2.Ex1.m1.6.6.1.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.1">⋅</ci><ci id="S2.Ex1.m1.6.6.1.1.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.2">𝑐</ci><apply id="S2.Ex1.m1.6.6.1.1.1.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.3.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.3">superscript</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.3.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.3.3.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.3">subscript</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.2"><abs id="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.3.2.2.2.1"></abs><ci id="S2.Ex1.m1.5.5.cmml" xref="S2.Ex1.m1.5.5">𝛿</ci></apply><cn type="integer" id="S2.Ex1.m1.6.6.1.1.1.3.3.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.3.2.3">2</cn></apply><cn type="integer" id="S2.Ex1.m1.6.6.1.1.1.3.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.3.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.6c">L(x,\delta,\hat{y})=l_{m}(f(x+\delta),\hat{y})+c\cdot|\delta|_{2}^{2}\enspace,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.SS1.p3.9" class="ltx_p">where <math id="S2.SS1.p3.2.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS1.p3.2.m1.1a"><mi id="S2.SS1.p3.2.m1.1.1" xref="S2.SS1.p3.2.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m1.1b"><ci id="S2.SS1.p3.2.m1.1.1.cmml" xref="S2.SS1.p3.2.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m1.1c">x</annotation></semantics></math> represents the benign audio signal, <math id="S2.SS1.p3.3.m2.1" class="ltx_Math" alttext="f(\cdot)" display="inline"><semantics id="S2.SS1.p3.3.m2.1a"><mrow id="S2.SS1.p3.3.m2.1.2" xref="S2.SS1.p3.3.m2.1.2.cmml"><mi id="S2.SS1.p3.3.m2.1.2.2" xref="S2.SS1.p3.3.m2.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p3.3.m2.1.2.1" xref="S2.SS1.p3.3.m2.1.2.1.cmml">​</mo><mrow id="S2.SS1.p3.3.m2.1.2.3.2" xref="S2.SS1.p3.3.m2.1.2.cmml"><mo stretchy="false" id="S2.SS1.p3.3.m2.1.2.3.2.1" xref="S2.SS1.p3.3.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS1.p3.3.m2.1.1" xref="S2.SS1.p3.3.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S2.SS1.p3.3.m2.1.2.3.2.2" xref="S2.SS1.p3.3.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m2.1b"><apply id="S2.SS1.p3.3.m2.1.2.cmml" xref="S2.SS1.p3.3.m2.1.2"><times id="S2.SS1.p3.3.m2.1.2.1.cmml" xref="S2.SS1.p3.3.m2.1.2.1"></times><ci id="S2.SS1.p3.3.m2.1.2.2.cmml" xref="S2.SS1.p3.3.m2.1.2.2">𝑓</ci><ci id="S2.SS1.p3.3.m2.1.1.cmml" xref="S2.SS1.p3.3.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m2.1c">f(\cdot)</annotation></semantics></math> is the ASR model's function mapping an audio input to the most likely word sequence, <math id="S2.SS1.p3.4.m3.1" class="ltx_Math" alttext="l_{m}" display="inline"><semantics id="S2.SS1.p3.4.m3.1a"><msub id="S2.SS1.p3.4.m3.1.1" xref="S2.SS1.p3.4.m3.1.1.cmml"><mi id="S2.SS1.p3.4.m3.1.1.2" xref="S2.SS1.p3.4.m3.1.1.2.cmml">l</mi><mi id="S2.SS1.p3.4.m3.1.1.3" xref="S2.SS1.p3.4.m3.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m3.1b"><apply id="S2.SS1.p3.4.m3.1.1.cmml" xref="S2.SS1.p3.4.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.4.m3.1.1.1.cmml" xref="S2.SS1.p3.4.m3.1.1">subscript</csymbol><ci id="S2.SS1.p3.4.m3.1.1.2.cmml" xref="S2.SS1.p3.4.m3.1.1.2">𝑙</ci><ci id="S2.SS1.p3.4.m3.1.1.3.cmml" xref="S2.SS1.p3.4.m3.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m3.1c">l_{m}</annotation></semantics></math> is the loss function measuring the accuracy of the ASR system's prediction of the target transcription <math id="S2.SS1.p3.5.m4.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="S2.SS1.p3.5.m4.1a"><mover accent="true" id="S2.SS1.p3.5.m4.1.1" xref="S2.SS1.p3.5.m4.1.1.cmml"><mi id="S2.SS1.p3.5.m4.1.1.2" xref="S2.SS1.p3.5.m4.1.1.2.cmml">y</mi><mo id="S2.SS1.p3.5.m4.1.1.1" xref="S2.SS1.p3.5.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m4.1b"><apply id="S2.SS1.p3.5.m4.1.1.cmml" xref="S2.SS1.p3.5.m4.1.1"><ci id="S2.SS1.p3.5.m4.1.1.1.cmml" xref="S2.SS1.p3.5.m4.1.1.1">^</ci><ci id="S2.SS1.p3.5.m4.1.1.2.cmml" xref="S2.SS1.p3.5.m4.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m4.1c">\hat{y}</annotation></semantics></math>, and <math id="S2.SS1.p3.6.m5.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S2.SS1.p3.6.m5.1a"><mi id="S2.SS1.p3.6.m5.1.1" xref="S2.SS1.p3.6.m5.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.6.m5.1b"><ci id="S2.SS1.p3.6.m5.1.1.cmml" xref="S2.SS1.p3.6.m5.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.6.m5.1c">\delta</annotation></semantics></math> is the perturbation constrained to be smaller than a predefined value <math id="S2.SS1.p3.7.m6.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S2.SS1.p3.7.m6.1a"><mi id="S2.SS1.p3.7.m6.1.1" xref="S2.SS1.p3.7.m6.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.7.m6.1b"><ci id="S2.SS1.p3.7.m6.1.1.cmml" xref="S2.SS1.p3.7.m6.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.7.m6.1c">\epsilon</annotation></semantics></math>.
This value is decreased iteratively to minimize distortion.
The parameter <math id="S2.SS1.p3.8.m7.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S2.SS1.p3.8.m7.1a"><mi id="S2.SS1.p3.8.m7.1.1" xref="S2.SS1.p3.8.m7.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.8.m7.1b"><ci id="S2.SS1.p3.8.m7.1.1.cmml" xref="S2.SS1.p3.8.m7.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.8.m7.1c">c</annotation></semantics></math>, which balances the model's loss against the perturbation, starts small to find an initial adversarial example and then increases to minimize <math id="S2.SS1.p3.9.m8.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S2.SS1.p3.9.m8.1a"><mi id="S2.SS1.p3.9.m8.1.1" xref="S2.SS1.p3.9.m8.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.9.m8.1b"><ci id="S2.SS1.p3.9.m8.1.1.cmml" xref="S2.SS1.p3.9.m8.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.9.m8.1c">\delta</annotation></semantics></math>.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">The resulting adversarial audio files closely resemble the original samples in terms of their dB scale, while leading to a different transcription output by the ASR system.
Figure <a href="#S2.F1" title="Figure 1 ‣ 2.2 Model Robustness ‣ 2 Background and Related Work ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> compares the original spectrum of a benign audio clip with its corresponding C&amp;W adversarial counterpart.
Note that in line with the definition of adversarial noise, the noise is treated as simply additive.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Model Robustness</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">This paper considers two notions of robustness: noise robustness and adversarial robustness.
We evaluate how noise robustness, achieved through noise-augmented training, impacts adversarial robustness.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.01813/assets/plots/2094-142345-0055.png" id="S2.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S2.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Original audio clip.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.01813/assets/plots/2094-142345-0055_cw.png" id="S2.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S2.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">C&amp;W adversarial example.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.01813/assets/plots/2094-142345-0055_cw_noise.png" id="S2.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S2.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">Adversarial noise signal.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">The spectrogram of (a) the original audio signal is compared to (b) the spectrogram of its corresponding C&amp;W adversarial example and (c) the spectrogram of the adversarial noise.
Transcription of the original audio signal:
``but you know more about that than i do sir''.
Transcription of the targeted C&amp;W adversarial example:
``yes my dear watson i have solved the mystery''.
</span></figcaption>
</figure>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Noise Robustness</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.1" class="ltx_p">Environmental noise is a common challenge in real-world audio processing, requiring ASR systems to handle disturbances like background chatter, traffic noise, and reverberation.
General noise, similar to adversarial noise, can cause non-targeted misclassifications, affecting accuracy and user experience.
Strategies to enhance noise robustness include noise augmentation, denoising algorithms, and robust feature extraction techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S2.SS2.SSS1.p2" class="ltx_para">
<p id="S2.SS2.SSS1.p2.1" class="ltx_p">Noise-augmented training is widely recognized as a reliable method for improving noise resilience <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
This technique integrates noise-perturbed data during neural network training by adding specific noise types to clean data.
Leading ASR systems, such as SpeechBrain, use noise augmentation in their training protocols, with the selection and weighting of noise types being crucial for effectiveness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
<div id="S2.SS2.SSS1.p3" class="ltx_para">
<p id="S2.SS2.SSS1.p3.1" class="ltx_p">While some approaches focus on architectural modifications to inherently enhance noise robustness, such as changes in hidden layers or input data representation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, we focus on noise-augmented training without altering model architecture or processing pipelines.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.01813/assets/plots/7729-102255-0034.png" id="S2.F2.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S2.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">Original audio clip.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.01813/assets/plots/7729-102255-0034_noise_26022.png" id="S2.F2.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S2.F2.sf2.3.2" class="ltx_text" style="font-size:90%;">Noisy original audio clip.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.01813/assets/plots/7729-102255-0034_noise_26022_noise.png" id="S2.F2.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S2.F2.sf3.3.2" class="ltx_text" style="font-size:90%;">Noise signal.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">The spectrogram of the original audio signal (a) is compared to the spectrogram of its corresponding noisy example, which in this case is constructed by adding background noise to the original audio signal (b) and the spectrogram of the noise (c), which is the difference between the original and its noisy counterpart.
Transcription of the original audio signal:
"to their sorrow they were soon undeceived".
Predicted text for the noisy benign example:
"to their sorrow they were assumes under seats".
</span></figcaption>
</figure>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>Adversarial Robustness</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">Adversarial robustness concerns a model's ability to withstand artificially created noise designed to mislead it, as outlined in Section <a href="#S2.SS1" title="2.1 Adversarial Attacks ‣ 2 Background and Related Work ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.
Various techniques have been proposed to enhance this robustness, including adversarial training, defensive distillation, gradient masking, regularization techniques, robust optimization, and feature denoising during training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
During inference, techniques like input transformations and randomization are employed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="S2.SS2.SSS2.p2" class="ltx_para">
<p id="S2.SS2.SSS2.p2.1" class="ltx_p">Adversarial training involves training the model on both clean and adversarially perturbed samples to enhance its resilience against adversarial manipulations.
However, this process is computationally intensive, especially for large datasets.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> highlighted that while adversarial training is effective for simple datasets, it struggles to scale for high-dimensional data like speech, leaving many blind spots.</p>
</div>
<div id="S2.SS2.SSS2.p3" class="ltx_para">
<p id="S2.SS2.SSS2.p3.1" class="ltx_p">This paper evaluates whether noise robustness can enhance adversarial robustness.
If successful, this approach could potentially reduce the computational resources needed for generating adversarial examples during training, thereby minimizing blind spots without compromising robustness.</p>
</div>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3 </span>Correlation between Robustness Notions</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p id="S2.SS2.SSS3.p1.1" class="ltx_p">Noise robustness enables a model to maintain accuracy amid naturally occurring acoustic disturbances, while adversarial robustness refers to resistance against maliciously engineered inputs.
The relationship between these robustness types in the image domain is debated: some studies argue for their independence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, while others suggest a synergistic relationship <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.
The consensus on their interrelation remains elusive.</p>
</div>
<div id="S2.SS2.SSS3.p2" class="ltx_para">
<p id="S2.SS2.SSS3.p2.1" class="ltx_p">Conclusions from image-based research do not directly apply to the audio domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.
ASR systems possess unique characteristics, and audio adversarial attacks can exploit phenomena like psychoacoustic hiding, absent in visual contexts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
While many studies focus on one type of robustness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, few have examined both in the audio context <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
<div id="S2.SS2.SSS3.p3" class="ltx_para">
<p id="S2.SS2.SSS3.p3.1" class="ltx_p">Driven by the ongoing debate in the image domain and the lack of comprehensive studies in the audio domain, this research investigates the interrelation between adversarial and noise robustness in ASR models.
We evaluate features related to the success of adversarial example generation and the effort required to produce these examples.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe the methodology used in our experiments.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>ASR Models</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We analyze end-to-end ASR systems, which directly transform spoken language into text using a single, unified model, differing from traditional systems with separate stages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.
We utilize SpeechBrain, an open-source platform for speech technologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
SpeechBrain ASR systems typically consist of three components:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Tokenizer</span>: Processes input transcripts to determine corresponding tokens during training and maps output tokens back to text during inference.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Acoustic Model</span>: Maps feature vectors derived from the raw input speech into probability distributions over the tokens.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Language Model (optional)</span>: Enhances prediction accuracy by evaluating the most probable sequences.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">We analyze four different architectures from the SpeechBrain toolkit:</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p"><span id="S3.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">wav2vec:</span> Uses a unigram tokenizer encoding 31 characters and a well-established pre-trained model <em id="S3.I2.i1.p1.1.2" class="ltx_emph ltx_font_italic">wav2vec</em><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>wav2vec 2.0 pre-trained model, see <a target="_blank" href="https://huggingface.co/facebook/wav2vec2-large-960h-lv60-self" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/facebook/wav2vec2-large-960h-lv60-self</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> as the acoustic model, fine-tuned with a vanilla DNN with CTC loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p"><span id="S3.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">seq2seq 1:</span> Uses a unigram tokenizer with 5000 sub-word units, a CRDNN acoustic model with attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, and a transformer-based pre-trained language model<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Transformer pre-trained language model, see <a target="_blank" href="https://speechbrain.readthedocs.io/en/latest/API/speechbrain.lobes.models.transformer.TransformerLM.html#module-speechbrain.lobes.models.transformer.TransformerLM" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://speechbrain.readthedocs.io/en/latest/API/speechbrain.lobes.models.transformer.TransformerLM.html#module-speechbrain.lobes.models.transformer.TransformerLM</a></span></span></span>.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p"><span id="S3.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">seq2seq 2:</span> Similar to seq2seq 1, but with a tokenizer with only 1000 sub-word units and an RNN-based pre-trained language model<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>RNN pre-trained language model, see <a target="_blank" href="https://speechbrain.readthedocs.io/en/latest/API/speechbrain.lobes.models.RNNLM.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://speechbrain.readthedocs.io/en/latest/API/speechbrain.lobes.models.RNNLM.html</a></span></span></span>.</p>
</div>
</li>
<li id="S3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i4.p1" class="ltx_para">
<p id="S3.I2.i4.p1.1" class="ltx_p"><span id="S3.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">Transformer:</span> Uses a unigram tokenizer with 5000 sub-word units, a transformer acoustic model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, and a transformer-based language model.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">For each architecture, we employed three different training regimes:</p>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p"><span id="S3.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">1 – Baseline (no augmentation)</span>: This model serves as a control, trained on a clean dataset without any augmentation to establish standard performance under ideal conditions.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p"><span id="S3.I3.i2.p1.1.1" class="ltx_text ltx_font_bold" style="color:#0000FF;">2<span id="S3.I3.i2.p1.1.1.1" class="ltx_text" style="color:#000000;"> – Augmentation with speed variations</span></span>: Introduces temporal variability in the training data by applying speed perturbations, simulating natural speech tempo variations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p"><span id="S3.I3.i3.p1.1.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">3<span id="S3.I3.i3.p1.1.1.1" class="ltx_text" style="color:#000000;"> – Augmentation with speed variations, background noise, and reverberation</span></span>: Combines speed variations with background noises and reverberations to mimic challenging and realistic acoustic environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">Each model's architecture and training parameters are detailed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Dataset</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We use the LibriSpeech dataset, a widely recognized corpus for ASR research that includes thousands of hours of read English speech from audiobooks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.
It is often used as a benchmark for evaluating speech recognition models.
Our models are trained on the first 100 hours of the clean LibriSpeech dataset.
Note that some pre-trained models, like wav2vec, may have been exposed to larger portions of LibriSpeech.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">For speech augmentation, we apply several techniques to artificially corrupt the clean audio signals provided by SpeechBrain.
These techniques include:</p>
<ul id="S3.I4" class="ltx_itemize">
<li id="S3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i1.p1" class="ltx_para">
<p id="S3.I4.i1.p1.1" class="ltx_p"><span id="S3.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">Reverberation</span>: Applied to 10% of the files to simulate echo effects.</p>
</div>
</li>
<li id="S3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i2.p1" class="ltx_para">
<p id="S3.I4.i2.p1.1" class="ltx_p"><span id="S3.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">Background Noise</span>: Random samples from the Freesound portion of the MUSAN corpus, which include 843 recordings of music, speech, and background noises <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
The recordings are incorporated into the clean signal at random signal-to-noise ratios.</p>
</div>
</li>
<li id="S3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i3.p1" class="ltx_para">
<p id="S3.I4.i3.p1.1" class="ltx_p"><span id="S3.I4.i3.p1.1.1" class="ltx_text ltx_font_bold">Speed Variations</span>: The audio signal is re-sampled at three different speeds: reduced by 5%, original rate, and increased by 5%.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">These augmentation techniques help simulate real-world acoustic environments and assess the robustness of ASR systems under varying conditions.
Figure <a href="#S2.F2" title="Figure 2 ‣ 2.2.1 Noise Robustness ‣ 2.2 Model Robustness ‣ 2 Background and Related Work ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the spectrum of a benign audio clip and its corresponding noisy counterpart.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Adversarial Attacks</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In our experiments, we utilize the C&amp;W attack, a prominent adversarial technique initially designed to target the DeepSpeech ASR system.
The implementation by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> for SpeechBrain enables us to evaluate the robustness of different SpeechBrain-based models.
We generate 300 adversarial examples per architecture per model using the C&amp;W attack.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">For the C&amp;W attack, we base our implementation on the <span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_typewriter">robust_speech</span> framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, adhering to the parameters defined therein for consistency and comparability, with the maximum number of iterations set to 3000.
This allow us to systematically assess the vulnerability of SpeechBrain models to sophisticated adversarial threats.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Statistical Tests</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.3" class="ltx_p">To assess whether adversarial samples generated for two different training regimes have the same underlying distribution, we apply the Kolmogorov-Smirnov (KS) test.
We use a significance level of <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="\alpha=0.05" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mrow id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">α</mi><mo id="S3.SS4.p1.1.m1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><eq id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1"></eq><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">𝛼</ci><cn type="float" id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\alpha=0.05</annotation></semantics></math>.
For <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="p\leq 0.05" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mrow id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">p</mi><mo id="S3.SS4.p1.2.m2.1.1.1" xref="S3.SS4.p1.2.m2.1.1.1.cmml">≤</mo><mn id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><leq id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1"></leq><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">𝑝</ci><cn type="float" id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">p\leq 0.05</annotation></semantics></math>, any KS statistic above <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><mn id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><cn type="float" id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">0.1</annotation></semantics></math> indicates a statistically significant difference.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section outlines the experiments conducted to evaluate the robustness of ASR models against noise and adversarial attacks.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Evaluating Noise Robustness</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In our initial experiment, we assess the effectiveness of noise-augmented training on enhancing noise robustness in SpeechBrain models.
For each architecture, we verify whether this training method improves the models' performance against natural acoustic perturbations, as described in subsection <a href="#S3.SS2" title="3.2 Dataset ‣ 3 Methodology ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.
The evaluation involves two metrics:</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.5" class="ltx_p"><span id="S4.I1.i1.p1.5.1" class="ltx_text ltx_font_bold">Word Error Rate (WER)</span>: WER is a standard ASR performance metric that compares the recognized word sequence with the reference text. It is defined as:</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.1" class="ltx_Math" alttext="\text{WER}=100\cdot\frac{S+D+I}{N}\enspace," display="block"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml"><mtext id="S4.E1.m1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.2a.cmml">WER</mtext><mo id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S4.E1.m1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.3.cmml"><mn id="S4.E1.m1.1.1.1.1.3.2" xref="S4.E1.m1.1.1.1.1.3.2.cmml">100</mn><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.1.1.1.1.3.1" xref="S4.E1.m1.1.1.1.1.3.1.cmml">⋅</mo><mfrac id="S4.E1.m1.1.1.1.1.3.3" xref="S4.E1.m1.1.1.1.1.3.3.cmml"><mrow id="S4.E1.m1.1.1.1.1.3.3.2" xref="S4.E1.m1.1.1.1.1.3.3.2.cmml"><mi id="S4.E1.m1.1.1.1.1.3.3.2.2" xref="S4.E1.m1.1.1.1.1.3.3.2.2.cmml">S</mi><mo id="S4.E1.m1.1.1.1.1.3.3.2.1" xref="S4.E1.m1.1.1.1.1.3.3.2.1.cmml">+</mo><mi id="S4.E1.m1.1.1.1.1.3.3.2.3" xref="S4.E1.m1.1.1.1.1.3.3.2.3.cmml">D</mi><mo id="S4.E1.m1.1.1.1.1.3.3.2.1a" xref="S4.E1.m1.1.1.1.1.3.3.2.1.cmml">+</mo><mi id="S4.E1.m1.1.1.1.1.3.3.2.4" xref="S4.E1.m1.1.1.1.1.3.3.2.4.cmml">I</mi></mrow><mi id="S4.E1.m1.1.1.1.1.3.3.3" xref="S4.E1.m1.1.1.1.1.3.3.3.cmml">N</mi></mfrac></mrow></mrow><mo lspace="0.500em" id="S4.E1.m1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1"><eq id="S4.E1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1"></eq><ci id="S4.E1.m1.1.1.1.1.2a.cmml" xref="S4.E1.m1.1.1.1.1.2"><mtext id="S4.E1.m1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.2">WER</mtext></ci><apply id="S4.E1.m1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.3"><ci id="S4.E1.m1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.1">⋅</ci><cn type="integer" id="S4.E1.m1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2">100</cn><apply id="S4.E1.m1.1.1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3"><divide id="S4.E1.m1.1.1.1.1.3.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3"></divide><apply id="S4.E1.m1.1.1.1.1.3.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2"><plus id="S4.E1.m1.1.1.1.1.3.3.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.1"></plus><ci id="S4.E1.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.2">𝑆</ci><ci id="S4.E1.m1.1.1.1.1.3.3.2.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.3">𝐷</ci><ci id="S4.E1.m1.1.1.1.1.3.3.2.4.cmml" xref="S4.E1.m1.1.1.1.1.3.3.2.4">𝐼</ci></apply><ci id="S4.E1.m1.1.1.1.1.3.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.3.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">\text{WER}=100\cdot\frac{S+D+I}{N}\enspace,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.I1.i1.p1.4" class="ltx_p">where <math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><mi id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><ci id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">S</annotation></semantics></math>, <math id="S4.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.I1.i1.p1.2.m2.1a"><mi id="S4.I1.i1.p1.2.m2.1.1" xref="S4.I1.i1.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.2.m2.1b"><ci id="S4.I1.i1.p1.2.m2.1.1.cmml" xref="S4.I1.i1.p1.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.2.m2.1c">D</annotation></semantics></math>, and <math id="S4.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S4.I1.i1.p1.3.m3.1a"><mi id="S4.I1.i1.p1.3.m3.1.1" xref="S4.I1.i1.p1.3.m3.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.3.m3.1b"><ci id="S4.I1.i1.p1.3.m3.1.1.cmml" xref="S4.I1.i1.p1.3.m3.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.3.m3.1c">I</annotation></semantics></math> represent the numbers of substituted, deleted, and inserted words, respectively, and <math id="S4.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.I1.i1.p1.4.m4.1a"><mi id="S4.I1.i1.p1.4.m4.1.1" xref="S4.I1.i1.p1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.4.m4.1b"><ci id="S4.I1.i1.p1.4.m4.1.1.cmml" xref="S4.I1.i1.p1.4.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.4.m4.1c">N</annotation></semantics></math> denotes the total word count of the reference text.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.3" class="ltx_p"><span id="S4.I1.i2.p1.3.1" class="ltx_text ltx_font_bold">Success Rate</span>: The success rate is the percentage of samples correctly recognized as the given reference text. It is calculated as:</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.1" class="ltx_Math" alttext="\text{Succ.\ rate}=100\cdot\frac{N_{S}}{N_{T}}\enspace," display="block"><semantics id="S4.E2.m1.1a"><mrow id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mrow id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mtext id="S4.E2.m1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.2a.cmml">Succ. rate</mtext><mo id="S4.E2.m1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.3.cmml"><mn id="S4.E2.m1.1.1.1.1.3.2" xref="S4.E2.m1.1.1.1.1.3.2.cmml">100</mn><mo lspace="0.222em" rspace="0.222em" id="S4.E2.m1.1.1.1.1.3.1" xref="S4.E2.m1.1.1.1.1.3.1.cmml">⋅</mo><mfrac id="S4.E2.m1.1.1.1.1.3.3" xref="S4.E2.m1.1.1.1.1.3.3.cmml"><msub id="S4.E2.m1.1.1.1.1.3.3.2" xref="S4.E2.m1.1.1.1.1.3.3.2.cmml"><mi id="S4.E2.m1.1.1.1.1.3.3.2.2" xref="S4.E2.m1.1.1.1.1.3.3.2.2.cmml">N</mi><mi id="S4.E2.m1.1.1.1.1.3.3.2.3" xref="S4.E2.m1.1.1.1.1.3.3.2.3.cmml">S</mi></msub><msub id="S4.E2.m1.1.1.1.1.3.3.3" xref="S4.E2.m1.1.1.1.1.3.3.3.cmml"><mi id="S4.E2.m1.1.1.1.1.3.3.3.2" xref="S4.E2.m1.1.1.1.1.3.3.3.2.cmml">N</mi><mi id="S4.E2.m1.1.1.1.1.3.3.3.3" xref="S4.E2.m1.1.1.1.1.3.3.3.3.cmml">T</mi></msub></mfrac></mrow></mrow><mo lspace="0.500em" id="S4.E2.m1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1"><eq id="S4.E2.m1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1"></eq><ci id="S4.E2.m1.1.1.1.1.2a.cmml" xref="S4.E2.m1.1.1.1.1.2"><mtext id="S4.E2.m1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.2">Succ. rate</mtext></ci><apply id="S4.E2.m1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.3"><ci id="S4.E2.m1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.1">⋅</ci><cn type="integer" id="S4.E2.m1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.2">100</cn><apply id="S4.E2.m1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3"><divide id="S4.E2.m1.1.1.1.1.3.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.3"></divide><apply id="S4.E2.m1.1.1.1.1.3.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.3.2.1.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2.2">𝑁</ci><ci id="S4.E2.m1.1.1.1.1.3.3.2.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3.2.3">𝑆</ci></apply><apply id="S4.E2.m1.1.1.1.1.3.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.3.3.3.1.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.3.3.3.2.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.2">𝑁</ci><ci id="S4.E2.m1.1.1.1.1.3.3.3.3.cmml" xref="S4.E2.m1.1.1.1.1.3.3.3.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">\text{Succ.\ rate}=100\cdot\frac{N_{S}}{N_{T}}\enspace,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.I1.i2.p1.2" class="ltx_p">where <math id="S4.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="N_{S}" display="inline"><semantics id="S4.I1.i2.p1.1.m1.1a"><msub id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml"><mi id="S4.I1.i2.p1.1.m1.1.1.2" xref="S4.I1.i2.p1.1.m1.1.1.2.cmml">N</mi><mi id="S4.I1.i2.p1.1.m1.1.1.3" xref="S4.I1.i2.p1.1.m1.1.1.3.cmml">S</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b"><apply id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.I1.i2.p1.1.m1.1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.I1.i2.p1.1.m1.1.1.2.cmml" xref="S4.I1.i2.p1.1.m1.1.1.2">𝑁</ci><ci id="S4.I1.i2.p1.1.m1.1.1.3.cmml" xref="S4.I1.i2.p1.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">N_{S}</annotation></semantics></math> is the number of audio clips with no transcription error compared to the reference text, out of a total of <math id="S4.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="N_{T}" display="inline"><semantics id="S4.I1.i2.p1.2.m2.1a"><msub id="S4.I1.i2.p1.2.m2.1.1" xref="S4.I1.i2.p1.2.m2.1.1.cmml"><mi id="S4.I1.i2.p1.2.m2.1.1.2" xref="S4.I1.i2.p1.2.m2.1.1.2.cmml">N</mi><mi id="S4.I1.i2.p1.2.m2.1.1.3" xref="S4.I1.i2.p1.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.2.m2.1b"><apply id="S4.I1.i2.p1.2.m2.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.I1.i2.p1.2.m2.1.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.I1.i2.p1.2.m2.1.1.2.cmml" xref="S4.I1.i2.p1.2.m2.1.1.2">𝑁</ci><ci id="S4.I1.i2.p1.2.m2.1.1.3.cmml" xref="S4.I1.i2.p1.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.2.m2.1c">N_{T}</annotation></semantics></math> examples.
For benign samples, the ground truth serves as the reference, whereas for C&amp;W adversarial examples, we use the target transcription.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evaluating Adversarial Robustness</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">We employ two distinct types of distortion measurements to quantify the imperceptibility of adversarial perturbations, offering insights into the audibility of the attacks.
Let <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="x(t)" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.2" xref="S4.SS2.p1.1.m1.1.2.cmml"><mi id="S4.SS2.p1.1.m1.1.2.2" xref="S4.SS2.p1.1.m1.1.2.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.1.m1.1.2.1" xref="S4.SS2.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S4.SS2.p1.1.m1.1.2.3.2" xref="S4.SS2.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p1.1.m1.1.2.3.2.1" xref="S4.SS2.p1.1.m1.1.2.cmml">(</mo><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">t</mi><mo stretchy="false" id="S4.SS2.p1.1.m1.1.2.3.2.2" xref="S4.SS2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.2"><times id="S4.SS2.p1.1.m1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.2.1"></times><ci id="S4.SS2.p1.1.m1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.2.2">𝑥</ci><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">x(t)</annotation></semantics></math> denote the original continuous audio file and <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="X(k)" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.2" xref="S4.SS2.p1.2.m2.1.2.cmml"><mi id="S4.SS2.p1.2.m2.1.2.2" xref="S4.SS2.p1.2.m2.1.2.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.2.m2.1.2.1" xref="S4.SS2.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S4.SS2.p1.2.m2.1.2.3.2" xref="S4.SS2.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S4.SS2.p1.2.m2.1.2.3.2.1" xref="S4.SS2.p1.2.m2.1.2.cmml">(</mo><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">k</mi><mo stretchy="false" id="S4.SS2.p1.2.m2.1.2.3.2.2" xref="S4.SS2.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.2.cmml" xref="S4.SS2.p1.2.m2.1.2"><times id="S4.SS2.p1.2.m2.1.2.1.cmml" xref="S4.SS2.p1.2.m2.1.2.1"></times><ci id="S4.SS2.p1.2.m2.1.2.2.cmml" xref="S4.SS2.p1.2.m2.1.2.2">𝑋</ci><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">X(k)</annotation></semantics></math> denote the discretized version:</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.2" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">dB<math id="S4.I2.i1.p1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{x}}" display="inline"><semantics id="S4.I2.i1.p1.1.1.m1.1a"><msub id="S4.I2.i1.p1.1.1.m1.1.1" xref="S4.I2.i1.p1.1.1.m1.1.1.cmml"><mi id="S4.I2.i1.p1.1.1.m1.1.1a" xref="S4.I2.i1.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S4.I2.i1.p1.1.1.m1.1.1.1" xref="S4.I2.i1.p1.1.1.m1.1.1.1a.cmml">x</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.1.1.m1.1b"><apply id="S4.I2.i1.p1.1.1.m1.1.1.cmml" xref="S4.I2.i1.p1.1.1.m1.1.1"><ci id="S4.I2.i1.p1.1.1.m1.1.1.1a.cmml" xref="S4.I2.i1.p1.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.I2.i1.p1.1.1.m1.1.1.1.cmml" xref="S4.I2.i1.p1.1.1.m1.1.1.1">x</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.1.1.m1.1c">{}_{\text{x}}</annotation></semantics></math></span>: <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> quantified the distortion of adversarial examples by first calculating the relative loudness of an audio signal <math id="S4.I2.i1.p1.2.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.I2.i1.p1.2.m1.1a"><mi id="S4.I2.i1.p1.2.m1.1.1" xref="S4.I2.i1.p1.2.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.2.m1.1b"><ci id="S4.I2.i1.p1.2.m1.1.1.cmml" xref="S4.I2.i1.p1.2.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.2.m1.1c">x</annotation></semantics></math> given by:</p>
<table id="S7.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.Ex2.m1.2" class="ltx_Math" alttext="\displaystyle\text{dB}(x)=20\cdot\max_{t}\log_{10}x(t)\text{.}" display="inline"><semantics id="S4.Ex2.m1.2a"><mrow id="S4.Ex2.m1.2.3" xref="S4.Ex2.m1.2.3.cmml"><mrow id="S4.Ex2.m1.2.3.2" xref="S4.Ex2.m1.2.3.2.cmml"><mtext id="S4.Ex2.m1.2.3.2.2" xref="S4.Ex2.m1.2.3.2.2a.cmml">dB</mtext><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.2.3.2.1" xref="S4.Ex2.m1.2.3.2.1.cmml">​</mo><mrow id="S4.Ex2.m1.2.3.2.3.2" xref="S4.Ex2.m1.2.3.2.cmml"><mo stretchy="false" id="S4.Ex2.m1.2.3.2.3.2.1" xref="S4.Ex2.m1.2.3.2.cmml">(</mo><mi id="S4.Ex2.m1.1.1" xref="S4.Ex2.m1.1.1.cmml">x</mi><mo stretchy="false" id="S4.Ex2.m1.2.3.2.3.2.2" xref="S4.Ex2.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex2.m1.2.3.1" xref="S4.Ex2.m1.2.3.1.cmml">=</mo><mrow id="S4.Ex2.m1.2.3.3" xref="S4.Ex2.m1.2.3.3.cmml"><mrow id="S4.Ex2.m1.2.3.3.2" xref="S4.Ex2.m1.2.3.3.2.cmml"><mn id="S4.Ex2.m1.2.3.3.2.2" xref="S4.Ex2.m1.2.3.3.2.2.cmml">20</mn><mo lspace="0.222em" rspace="0.222em" id="S4.Ex2.m1.2.3.3.2.1" xref="S4.Ex2.m1.2.3.3.2.1.cmml">⋅</mo><mrow id="S4.Ex2.m1.2.3.3.2.3" xref="S4.Ex2.m1.2.3.3.2.3.cmml"><munder id="S4.Ex2.m1.2.3.3.2.3.1" xref="S4.Ex2.m1.2.3.3.2.3.1.cmml"><mi id="S4.Ex2.m1.2.3.3.2.3.1.2" xref="S4.Ex2.m1.2.3.3.2.3.1.2.cmml">max</mi><mi id="S4.Ex2.m1.2.3.3.2.3.1.3" xref="S4.Ex2.m1.2.3.3.2.3.1.3.cmml">t</mi></munder><mo lspace="0.167em" id="S4.Ex2.m1.2.3.3.2.3a" xref="S4.Ex2.m1.2.3.3.2.3.cmml">⁡</mo><mrow id="S4.Ex2.m1.2.3.3.2.3.2" xref="S4.Ex2.m1.2.3.3.2.3.2.cmml"><msub id="S4.Ex2.m1.2.3.3.2.3.2.1" xref="S4.Ex2.m1.2.3.3.2.3.2.1.cmml"><mi id="S4.Ex2.m1.2.3.3.2.3.2.1.2" xref="S4.Ex2.m1.2.3.3.2.3.2.1.2.cmml">log</mi><mn id="S4.Ex2.m1.2.3.3.2.3.2.1.3" xref="S4.Ex2.m1.2.3.3.2.3.2.1.3.cmml">10</mn></msub><mo lspace="0.167em" id="S4.Ex2.m1.2.3.3.2.3.2a" xref="S4.Ex2.m1.2.3.3.2.3.2.cmml">⁡</mo><mi id="S4.Ex2.m1.2.3.3.2.3.2.2" xref="S4.Ex2.m1.2.3.3.2.3.2.2.cmml">x</mi></mrow></mrow></mrow><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.2.3.3.1" xref="S4.Ex2.m1.2.3.3.1.cmml">​</mo><mrow id="S4.Ex2.m1.2.3.3.3.2" xref="S4.Ex2.m1.2.3.3.cmml"><mo stretchy="false" id="S4.Ex2.m1.2.3.3.3.2.1" xref="S4.Ex2.m1.2.3.3.cmml">(</mo><mi id="S4.Ex2.m1.2.2" xref="S4.Ex2.m1.2.2.cmml">t</mi><mo stretchy="false" id="S4.Ex2.m1.2.3.3.3.2.2" xref="S4.Ex2.m1.2.3.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.Ex2.m1.2.3.3.1a" xref="S4.Ex2.m1.2.3.3.1.cmml">​</mo><mtext id="S4.Ex2.m1.2.3.3.4" xref="S4.Ex2.m1.2.3.3.4a.cmml">.</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m1.2b"><apply id="S4.Ex2.m1.2.3.cmml" xref="S4.Ex2.m1.2.3"><eq id="S4.Ex2.m1.2.3.1.cmml" xref="S4.Ex2.m1.2.3.1"></eq><apply id="S4.Ex2.m1.2.3.2.cmml" xref="S4.Ex2.m1.2.3.2"><times id="S4.Ex2.m1.2.3.2.1.cmml" xref="S4.Ex2.m1.2.3.2.1"></times><ci id="S4.Ex2.m1.2.3.2.2a.cmml" xref="S4.Ex2.m1.2.3.2.2"><mtext id="S4.Ex2.m1.2.3.2.2.cmml" xref="S4.Ex2.m1.2.3.2.2">dB</mtext></ci><ci id="S4.Ex2.m1.1.1.cmml" xref="S4.Ex2.m1.1.1">𝑥</ci></apply><apply id="S4.Ex2.m1.2.3.3.cmml" xref="S4.Ex2.m1.2.3.3"><times id="S4.Ex2.m1.2.3.3.1.cmml" xref="S4.Ex2.m1.2.3.3.1"></times><apply id="S4.Ex2.m1.2.3.3.2.cmml" xref="S4.Ex2.m1.2.3.3.2"><ci id="S4.Ex2.m1.2.3.3.2.1.cmml" xref="S4.Ex2.m1.2.3.3.2.1">⋅</ci><cn type="integer" id="S4.Ex2.m1.2.3.3.2.2.cmml" xref="S4.Ex2.m1.2.3.3.2.2">20</cn><apply id="S4.Ex2.m1.2.3.3.2.3.cmml" xref="S4.Ex2.m1.2.3.3.2.3"><apply id="S4.Ex2.m1.2.3.3.2.3.1.cmml" xref="S4.Ex2.m1.2.3.3.2.3.1"><csymbol cd="ambiguous" id="S4.Ex2.m1.2.3.3.2.3.1.1.cmml" xref="S4.Ex2.m1.2.3.3.2.3.1">subscript</csymbol><max id="S4.Ex2.m1.2.3.3.2.3.1.2.cmml" xref="S4.Ex2.m1.2.3.3.2.3.1.2"></max><ci id="S4.Ex2.m1.2.3.3.2.3.1.3.cmml" xref="S4.Ex2.m1.2.3.3.2.3.1.3">𝑡</ci></apply><apply id="S4.Ex2.m1.2.3.3.2.3.2.cmml" xref="S4.Ex2.m1.2.3.3.2.3.2"><apply id="S4.Ex2.m1.2.3.3.2.3.2.1.cmml" xref="S4.Ex2.m1.2.3.3.2.3.2.1"><csymbol cd="ambiguous" id="S4.Ex2.m1.2.3.3.2.3.2.1.1.cmml" xref="S4.Ex2.m1.2.3.3.2.3.2.1">subscript</csymbol><log id="S4.Ex2.m1.2.3.3.2.3.2.1.2.cmml" xref="S4.Ex2.m1.2.3.3.2.3.2.1.2"></log><cn type="integer" id="S4.Ex2.m1.2.3.3.2.3.2.1.3.cmml" xref="S4.Ex2.m1.2.3.3.2.3.2.1.3">10</cn></apply><ci id="S4.Ex2.m1.2.3.3.2.3.2.2.cmml" xref="S4.Ex2.m1.2.3.3.2.3.2.2">𝑥</ci></apply></apply></apply><ci id="S4.Ex2.m1.2.2.cmml" xref="S4.Ex2.m1.2.2">𝑡</ci><ci id="S4.Ex2.m1.2.3.3.4a.cmml" xref="S4.Ex2.m1.2.3.3.4"><mtext id="S4.Ex2.m1.2.3.3.4.cmml" xref="S4.Ex2.m1.2.3.3.4">.</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m1.2c">\displaystyle\text{dB}(x)=20\cdot\max_{t}\log_{10}x(t)\text{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.I2.i1.p1.4" class="ltx_p">Subsequently, the distortion level is determined as the difference between the relative loudness of the perturbation <math id="S4.I2.i1.p1.3.m1.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S4.I2.i1.p1.3.m1.1a"><mi id="S4.I2.i1.p1.3.m1.1.1" xref="S4.I2.i1.p1.3.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.3.m1.1b"><ci id="S4.I2.i1.p1.3.m1.1.1.cmml" xref="S4.I2.i1.p1.3.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.3.m1.1c">\delta</annotation></semantics></math> and the audio signal <math id="S4.I2.i1.p1.4.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.I2.i1.p1.4.m2.1a"><mi id="S4.I2.i1.p1.4.m2.1.1" xref="S4.I2.i1.p1.4.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.4.m2.1b"><ci id="S4.I2.i1.p1.4.m2.1.1.cmml" xref="S4.I2.i1.p1.4.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.4.m2.1c">x</annotation></semantics></math>, defined as:</p>
<table id="S7.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.Ex3.m1.3" class="ltx_Math" alttext="\displaystyle\text{dB}_{\text{x}}(\delta)=\text{dB}(x)-\text{dB}(\delta)\text{,}" display="inline"><semantics id="S4.Ex3.m1.3a"><mrow id="S4.Ex3.m1.3.4" xref="S4.Ex3.m1.3.4.cmml"><mrow id="S4.Ex3.m1.3.4.2" xref="S4.Ex3.m1.3.4.2.cmml"><msub id="S4.Ex3.m1.3.4.2.2" xref="S4.Ex3.m1.3.4.2.2.cmml"><mtext id="S4.Ex3.m1.3.4.2.2.2" xref="S4.Ex3.m1.3.4.2.2.2a.cmml">dB</mtext><mtext id="S4.Ex3.m1.3.4.2.2.3" xref="S4.Ex3.m1.3.4.2.2.3a.cmml">x</mtext></msub><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.3.4.2.1" xref="S4.Ex3.m1.3.4.2.1.cmml">​</mo><mrow id="S4.Ex3.m1.3.4.2.3.2" xref="S4.Ex3.m1.3.4.2.cmml"><mo stretchy="false" id="S4.Ex3.m1.3.4.2.3.2.1" xref="S4.Ex3.m1.3.4.2.cmml">(</mo><mi id="S4.Ex3.m1.1.1" xref="S4.Ex3.m1.1.1.cmml">δ</mi><mo stretchy="false" id="S4.Ex3.m1.3.4.2.3.2.2" xref="S4.Ex3.m1.3.4.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex3.m1.3.4.1" xref="S4.Ex3.m1.3.4.1.cmml">=</mo><mrow id="S4.Ex3.m1.3.4.3" xref="S4.Ex3.m1.3.4.3.cmml"><mrow id="S4.Ex3.m1.3.4.3.2" xref="S4.Ex3.m1.3.4.3.2.cmml"><mtext id="S4.Ex3.m1.3.4.3.2.2" xref="S4.Ex3.m1.3.4.3.2.2a.cmml">dB</mtext><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.3.4.3.2.1" xref="S4.Ex3.m1.3.4.3.2.1.cmml">​</mo><mrow id="S4.Ex3.m1.3.4.3.2.3.2" xref="S4.Ex3.m1.3.4.3.2.cmml"><mo stretchy="false" id="S4.Ex3.m1.3.4.3.2.3.2.1" xref="S4.Ex3.m1.3.4.3.2.cmml">(</mo><mi id="S4.Ex3.m1.2.2" xref="S4.Ex3.m1.2.2.cmml">x</mi><mo stretchy="false" id="S4.Ex3.m1.3.4.3.2.3.2.2" xref="S4.Ex3.m1.3.4.3.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex3.m1.3.4.3.1" xref="S4.Ex3.m1.3.4.3.1.cmml">−</mo><mrow id="S4.Ex3.m1.3.4.3.3" xref="S4.Ex3.m1.3.4.3.3.cmml"><mtext id="S4.Ex3.m1.3.4.3.3.2" xref="S4.Ex3.m1.3.4.3.3.2a.cmml">dB</mtext><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.3.4.3.3.1" xref="S4.Ex3.m1.3.4.3.3.1.cmml">​</mo><mrow id="S4.Ex3.m1.3.4.3.3.3.2" xref="S4.Ex3.m1.3.4.3.3.cmml"><mo stretchy="false" id="S4.Ex3.m1.3.4.3.3.3.2.1" xref="S4.Ex3.m1.3.4.3.3.cmml">(</mo><mi id="S4.Ex3.m1.3.3" xref="S4.Ex3.m1.3.3.cmml">δ</mi><mo stretchy="false" id="S4.Ex3.m1.3.4.3.3.3.2.2" xref="S4.Ex3.m1.3.4.3.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.3.4.3.3.1a" xref="S4.Ex3.m1.3.4.3.3.1.cmml">​</mo><mtext id="S4.Ex3.m1.3.4.3.3.4" xref="S4.Ex3.m1.3.4.3.3.4a.cmml">,</mtext></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex3.m1.3b"><apply id="S4.Ex3.m1.3.4.cmml" xref="S4.Ex3.m1.3.4"><eq id="S4.Ex3.m1.3.4.1.cmml" xref="S4.Ex3.m1.3.4.1"></eq><apply id="S4.Ex3.m1.3.4.2.cmml" xref="S4.Ex3.m1.3.4.2"><times id="S4.Ex3.m1.3.4.2.1.cmml" xref="S4.Ex3.m1.3.4.2.1"></times><apply id="S4.Ex3.m1.3.4.2.2.cmml" xref="S4.Ex3.m1.3.4.2.2"><csymbol cd="ambiguous" id="S4.Ex3.m1.3.4.2.2.1.cmml" xref="S4.Ex3.m1.3.4.2.2">subscript</csymbol><ci id="S4.Ex3.m1.3.4.2.2.2a.cmml" xref="S4.Ex3.m1.3.4.2.2.2"><mtext id="S4.Ex3.m1.3.4.2.2.2.cmml" xref="S4.Ex3.m1.3.4.2.2.2">dB</mtext></ci><ci id="S4.Ex3.m1.3.4.2.2.3a.cmml" xref="S4.Ex3.m1.3.4.2.2.3"><mtext mathsize="70%" id="S4.Ex3.m1.3.4.2.2.3.cmml" xref="S4.Ex3.m1.3.4.2.2.3">x</mtext></ci></apply><ci id="S4.Ex3.m1.1.1.cmml" xref="S4.Ex3.m1.1.1">𝛿</ci></apply><apply id="S4.Ex3.m1.3.4.3.cmml" xref="S4.Ex3.m1.3.4.3"><minus id="S4.Ex3.m1.3.4.3.1.cmml" xref="S4.Ex3.m1.3.4.3.1"></minus><apply id="S4.Ex3.m1.3.4.3.2.cmml" xref="S4.Ex3.m1.3.4.3.2"><times id="S4.Ex3.m1.3.4.3.2.1.cmml" xref="S4.Ex3.m1.3.4.3.2.1"></times><ci id="S4.Ex3.m1.3.4.3.2.2a.cmml" xref="S4.Ex3.m1.3.4.3.2.2"><mtext id="S4.Ex3.m1.3.4.3.2.2.cmml" xref="S4.Ex3.m1.3.4.3.2.2">dB</mtext></ci><ci id="S4.Ex3.m1.2.2.cmml" xref="S4.Ex3.m1.2.2">𝑥</ci></apply><apply id="S4.Ex3.m1.3.4.3.3.cmml" xref="S4.Ex3.m1.3.4.3.3"><times id="S4.Ex3.m1.3.4.3.3.1.cmml" xref="S4.Ex3.m1.3.4.3.3.1"></times><ci id="S4.Ex3.m1.3.4.3.3.2a.cmml" xref="S4.Ex3.m1.3.4.3.3.2"><mtext id="S4.Ex3.m1.3.4.3.3.2.cmml" xref="S4.Ex3.m1.3.4.3.3.2">dB</mtext></ci><ci id="S4.Ex3.m1.3.3.cmml" xref="S4.Ex3.m1.3.3">𝛿</ci><ci id="S4.Ex3.m1.3.4.3.3.4a.cmml" xref="S4.Ex3.m1.3.4.3.3.4"><mtext id="S4.Ex3.m1.3.4.3.3.4.cmml" xref="S4.Ex3.m1.3.4.3.3.4">,</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex3.m1.3c">\displaystyle\text{dB}_{\text{x}}(\delta)=\text{dB}(x)-\text{dB}(\delta)\text{,}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.I2.i1.p1.6" class="ltx_p">assuming equal lengths of <math id="S4.I2.i1.p1.5.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.I2.i1.p1.5.m1.1a"><mi id="S4.I2.i1.p1.5.m1.1.1" xref="S4.I2.i1.p1.5.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.5.m1.1b"><ci id="S4.I2.i1.p1.5.m1.1.1.cmml" xref="S4.I2.i1.p1.5.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.5.m1.1c">x</annotation></semantics></math> and <math id="S4.I2.i1.p1.6.m2.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S4.I2.i1.p1.6.m2.1a"><mi id="S4.I2.i1.p1.6.m2.1.1" xref="S4.I2.i1.p1.6.m2.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i1.p1.6.m2.1b"><ci id="S4.I2.i1.p1.6.m2.1.1.cmml" xref="S4.I2.i1.p1.6.m2.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i1.p1.6.m2.1c">\delta</annotation></semantics></math>.
</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">SNR<math id="S4.I2.i2.p1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{Seg}}" display="inline"><semantics id="S4.I2.i2.p1.1.1.m1.1a"><msub id="S4.I2.i2.p1.1.1.m1.1.1" xref="S4.I2.i2.p1.1.1.m1.1.1.cmml"><mi id="S4.I2.i2.p1.1.1.m1.1.1a" xref="S4.I2.i2.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S4.I2.i2.p1.1.1.m1.1.1.1" xref="S4.I2.i2.p1.1.1.m1.1.1.1a.cmml">Seg</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.1.1.m1.1b"><apply id="S4.I2.i2.p1.1.1.m1.1.1.cmml" xref="S4.I2.i2.p1.1.1.m1.1.1"><ci id="S4.I2.i2.p1.1.1.m1.1.1.1a.cmml" xref="S4.I2.i2.p1.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.I2.i2.p1.1.1.m1.1.1.1.cmml" xref="S4.I2.i2.p1.1.1.m1.1.1.1">Seg</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i2.p1.1.1.m1.1c">{}_{\text{Seg}}</annotation></semantics></math></span>: The Segmental Signal-to-Noise Ratio quantifies noise energy in decibels over the entire audio signal.
This metric is determined by calculating energy ratios of individual frames and averaging them, aligning more closely with human auditory perception compared to the non-segmental approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</p>
<table id="S4.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex4.m1.3" class="ltx_Math" alttext="\text{SNR${}_{\text{Seg}}$}=\frac{10}{M}\cdot\sum_{m=0}^{M-1}\log_{10}\frac{\sum_{k=mF}^{mF+F-1}X(k)^{2}}{\sum_{k=mF}^{mF+F-1}\delta(k)^{2}}\text{,}\enspace" display="block"><semantics id="S4.Ex4.m1.3a"><mrow id="S4.Ex4.m1.3.4" xref="S4.Ex4.m1.3.4.cmml"><mrow id="S4.Ex4.m1.1.1.1" xref="S4.Ex4.m1.1.1.1b.cmml"><mtext id="S4.Ex4.m1.1.1.1a" xref="S4.Ex4.m1.1.1.1b.cmml">SNR</mtext><msub id="S4.Ex4.m1.1.1.1.m1.1.1" xref="S4.Ex4.m1.1.1.1.m1.1.1.cmml"><mi id="S4.Ex4.m1.1.1.1.m1.1.1a" xref="S4.Ex4.m1.1.1.1.m1.1.1.cmml"></mi><mtext id="S4.Ex4.m1.1.1.1.m1.1.1.1" xref="S4.Ex4.m1.1.1.1.m1.1.1.1.cmml">Seg</mtext></msub></mrow><mo id="S4.Ex4.m1.3.4.1" xref="S4.Ex4.m1.3.4.1.cmml">=</mo><mrow id="S4.Ex4.m1.3.4.2" xref="S4.Ex4.m1.3.4.2.cmml"><mfrac id="S4.Ex4.m1.3.4.2.2" xref="S4.Ex4.m1.3.4.2.2.cmml"><mn id="S4.Ex4.m1.3.4.2.2.2" xref="S4.Ex4.m1.3.4.2.2.2.cmml">10</mn><mi id="S4.Ex4.m1.3.4.2.2.3" xref="S4.Ex4.m1.3.4.2.2.3.cmml">M</mi></mfrac><mo lspace="0.222em" rspace="0.055em" id="S4.Ex4.m1.3.4.2.1" xref="S4.Ex4.m1.3.4.2.1.cmml">⋅</mo><mrow id="S4.Ex4.m1.3.4.2.3" xref="S4.Ex4.m1.3.4.2.3.cmml"><munderover id="S4.Ex4.m1.3.4.2.3.1" xref="S4.Ex4.m1.3.4.2.3.1.cmml"><mo movablelimits="false" id="S4.Ex4.m1.3.4.2.3.1.2.2" xref="S4.Ex4.m1.3.4.2.3.1.2.2.cmml">∑</mo><mrow id="S4.Ex4.m1.3.4.2.3.1.2.3" xref="S4.Ex4.m1.3.4.2.3.1.2.3.cmml"><mi id="S4.Ex4.m1.3.4.2.3.1.2.3.2" xref="S4.Ex4.m1.3.4.2.3.1.2.3.2.cmml">m</mi><mo id="S4.Ex4.m1.3.4.2.3.1.2.3.1" xref="S4.Ex4.m1.3.4.2.3.1.2.3.1.cmml">=</mo><mn id="S4.Ex4.m1.3.4.2.3.1.2.3.3" xref="S4.Ex4.m1.3.4.2.3.1.2.3.3.cmml">0</mn></mrow><mrow id="S4.Ex4.m1.3.4.2.3.1.3" xref="S4.Ex4.m1.3.4.2.3.1.3.cmml"><mi id="S4.Ex4.m1.3.4.2.3.1.3.2" xref="S4.Ex4.m1.3.4.2.3.1.3.2.cmml">M</mi><mo id="S4.Ex4.m1.3.4.2.3.1.3.1" xref="S4.Ex4.m1.3.4.2.3.1.3.1.cmml">−</mo><mn id="S4.Ex4.m1.3.4.2.3.1.3.3" xref="S4.Ex4.m1.3.4.2.3.1.3.3.cmml">1</mn></mrow></munderover><mrow id="S4.Ex4.m1.3.4.2.3.2" xref="S4.Ex4.m1.3.4.2.3.2.cmml"><msub id="S4.Ex4.m1.3.4.2.3.2.1" xref="S4.Ex4.m1.3.4.2.3.2.1.cmml"><mi id="S4.Ex4.m1.3.4.2.3.2.1.2" xref="S4.Ex4.m1.3.4.2.3.2.1.2.cmml">log</mi><mn id="S4.Ex4.m1.3.4.2.3.2.1.3" xref="S4.Ex4.m1.3.4.2.3.2.1.3.cmml">10</mn></msub><mo lspace="0.167em" id="S4.Ex4.m1.3.4.2.3.2a" xref="S4.Ex4.m1.3.4.2.3.2.cmml">⁡</mo><mrow id="S4.Ex4.m1.3.4.2.3.2.2" xref="S4.Ex4.m1.3.4.2.3.2.2.cmml"><mfrac id="S4.Ex4.m1.3.3" xref="S4.Ex4.m1.3.3.cmml"><mrow id="S4.Ex4.m1.2.2.1" xref="S4.Ex4.m1.2.2.1.cmml"><msubsup id="S4.Ex4.m1.2.2.1.2" xref="S4.Ex4.m1.2.2.1.2.cmml"><mo id="S4.Ex4.m1.2.2.1.2.2.2" xref="S4.Ex4.m1.2.2.1.2.2.2.cmml">∑</mo><mrow id="S4.Ex4.m1.2.2.1.2.2.3" xref="S4.Ex4.m1.2.2.1.2.2.3.cmml"><mi id="S4.Ex4.m1.2.2.1.2.2.3.2" xref="S4.Ex4.m1.2.2.1.2.2.3.2.cmml">k</mi><mo id="S4.Ex4.m1.2.2.1.2.2.3.1" xref="S4.Ex4.m1.2.2.1.2.2.3.1.cmml">=</mo><mrow id="S4.Ex4.m1.2.2.1.2.2.3.3" xref="S4.Ex4.m1.2.2.1.2.2.3.3.cmml"><mi id="S4.Ex4.m1.2.2.1.2.2.3.3.2" xref="S4.Ex4.m1.2.2.1.2.2.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.2.2.1.2.2.3.3.1" xref="S4.Ex4.m1.2.2.1.2.2.3.3.1.cmml">​</mo><mi id="S4.Ex4.m1.2.2.1.2.2.3.3.3" xref="S4.Ex4.m1.2.2.1.2.2.3.3.3.cmml">F</mi></mrow></mrow><mrow id="S4.Ex4.m1.2.2.1.2.3" xref="S4.Ex4.m1.2.2.1.2.3.cmml"><mrow id="S4.Ex4.m1.2.2.1.2.3.2" xref="S4.Ex4.m1.2.2.1.2.3.2.cmml"><mrow id="S4.Ex4.m1.2.2.1.2.3.2.2" xref="S4.Ex4.m1.2.2.1.2.3.2.2.cmml"><mi id="S4.Ex4.m1.2.2.1.2.3.2.2.2" xref="S4.Ex4.m1.2.2.1.2.3.2.2.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.2.2.1.2.3.2.2.1" xref="S4.Ex4.m1.2.2.1.2.3.2.2.1.cmml">​</mo><mi id="S4.Ex4.m1.2.2.1.2.3.2.2.3" xref="S4.Ex4.m1.2.2.1.2.3.2.2.3.cmml">F</mi></mrow><mo id="S4.Ex4.m1.2.2.1.2.3.2.1" xref="S4.Ex4.m1.2.2.1.2.3.2.1.cmml">+</mo><mi id="S4.Ex4.m1.2.2.1.2.3.2.3" xref="S4.Ex4.m1.2.2.1.2.3.2.3.cmml">F</mi></mrow><mo id="S4.Ex4.m1.2.2.1.2.3.1" xref="S4.Ex4.m1.2.2.1.2.3.1.cmml">−</mo><mn id="S4.Ex4.m1.2.2.1.2.3.3" xref="S4.Ex4.m1.2.2.1.2.3.3.cmml">1</mn></mrow></msubsup><mrow id="S4.Ex4.m1.2.2.1.3" xref="S4.Ex4.m1.2.2.1.3.cmml"><mi id="S4.Ex4.m1.2.2.1.3.2" xref="S4.Ex4.m1.2.2.1.3.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.2.2.1.3.1" xref="S4.Ex4.m1.2.2.1.3.1.cmml">​</mo><msup id="S4.Ex4.m1.2.2.1.3.3" xref="S4.Ex4.m1.2.2.1.3.3.cmml"><mrow id="S4.Ex4.m1.2.2.1.3.3.2.2" xref="S4.Ex4.m1.2.2.1.3.3.cmml"><mo stretchy="false" id="S4.Ex4.m1.2.2.1.3.3.2.2.1" xref="S4.Ex4.m1.2.2.1.3.3.cmml">(</mo><mi id="S4.Ex4.m1.2.2.1.1" xref="S4.Ex4.m1.2.2.1.1.cmml">k</mi><mo stretchy="false" id="S4.Ex4.m1.2.2.1.3.3.2.2.2" xref="S4.Ex4.m1.2.2.1.3.3.cmml">)</mo></mrow><mn id="S4.Ex4.m1.2.2.1.3.3.3" xref="S4.Ex4.m1.2.2.1.3.3.3.cmml">2</mn></msup></mrow></mrow><mrow id="S4.Ex4.m1.3.3.2" xref="S4.Ex4.m1.3.3.2.cmml"><msubsup id="S4.Ex4.m1.3.3.2.2" xref="S4.Ex4.m1.3.3.2.2.cmml"><mo id="S4.Ex4.m1.3.3.2.2.2.2" xref="S4.Ex4.m1.3.3.2.2.2.2.cmml">∑</mo><mrow id="S4.Ex4.m1.3.3.2.2.2.3" xref="S4.Ex4.m1.3.3.2.2.2.3.cmml"><mi id="S4.Ex4.m1.3.3.2.2.2.3.2" xref="S4.Ex4.m1.3.3.2.2.2.3.2.cmml">k</mi><mo id="S4.Ex4.m1.3.3.2.2.2.3.1" xref="S4.Ex4.m1.3.3.2.2.2.3.1.cmml">=</mo><mrow id="S4.Ex4.m1.3.3.2.2.2.3.3" xref="S4.Ex4.m1.3.3.2.2.2.3.3.cmml"><mi id="S4.Ex4.m1.3.3.2.2.2.3.3.2" xref="S4.Ex4.m1.3.3.2.2.2.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.3.3.2.2.2.3.3.1" xref="S4.Ex4.m1.3.3.2.2.2.3.3.1.cmml">​</mo><mi id="S4.Ex4.m1.3.3.2.2.2.3.3.3" xref="S4.Ex4.m1.3.3.2.2.2.3.3.3.cmml">F</mi></mrow></mrow><mrow id="S4.Ex4.m1.3.3.2.2.3" xref="S4.Ex4.m1.3.3.2.2.3.cmml"><mrow id="S4.Ex4.m1.3.3.2.2.3.2" xref="S4.Ex4.m1.3.3.2.2.3.2.cmml"><mrow id="S4.Ex4.m1.3.3.2.2.3.2.2" xref="S4.Ex4.m1.3.3.2.2.3.2.2.cmml"><mi id="S4.Ex4.m1.3.3.2.2.3.2.2.2" xref="S4.Ex4.m1.3.3.2.2.3.2.2.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.3.3.2.2.3.2.2.1" xref="S4.Ex4.m1.3.3.2.2.3.2.2.1.cmml">​</mo><mi id="S4.Ex4.m1.3.3.2.2.3.2.2.3" xref="S4.Ex4.m1.3.3.2.2.3.2.2.3.cmml">F</mi></mrow><mo id="S4.Ex4.m1.3.3.2.2.3.2.1" xref="S4.Ex4.m1.3.3.2.2.3.2.1.cmml">+</mo><mi id="S4.Ex4.m1.3.3.2.2.3.2.3" xref="S4.Ex4.m1.3.3.2.2.3.2.3.cmml">F</mi></mrow><mo id="S4.Ex4.m1.3.3.2.2.3.1" xref="S4.Ex4.m1.3.3.2.2.3.1.cmml">−</mo><mn id="S4.Ex4.m1.3.3.2.2.3.3" xref="S4.Ex4.m1.3.3.2.2.3.3.cmml">1</mn></mrow></msubsup><mrow id="S4.Ex4.m1.3.3.2.3" xref="S4.Ex4.m1.3.3.2.3.cmml"><mi id="S4.Ex4.m1.3.3.2.3.2" xref="S4.Ex4.m1.3.3.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.3.3.2.3.1" xref="S4.Ex4.m1.3.3.2.3.1.cmml">​</mo><msup id="S4.Ex4.m1.3.3.2.3.3" xref="S4.Ex4.m1.3.3.2.3.3.cmml"><mrow id="S4.Ex4.m1.3.3.2.3.3.2.2" xref="S4.Ex4.m1.3.3.2.3.3.cmml"><mo stretchy="false" id="S4.Ex4.m1.3.3.2.3.3.2.2.1" xref="S4.Ex4.m1.3.3.2.3.3.cmml">(</mo><mi id="S4.Ex4.m1.3.3.2.1" xref="S4.Ex4.m1.3.3.2.1.cmml">k</mi><mo stretchy="false" id="S4.Ex4.m1.3.3.2.3.3.2.2.2" xref="S4.Ex4.m1.3.3.2.3.3.cmml">)</mo></mrow><mn id="S4.Ex4.m1.3.3.2.3.3.3" xref="S4.Ex4.m1.3.3.2.3.3.3.cmml">2</mn></msup></mrow></mrow></mfrac><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.3.4.2.3.2.2.1" xref="S4.Ex4.m1.3.4.2.3.2.2.1.cmml">​</mo><mtext id="S4.Ex4.m1.3.4.2.3.2.2.2" xref="S4.Ex4.m1.3.4.2.3.2.2.2a.cmml">,</mtext></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex4.m1.3b"><apply id="S4.Ex4.m1.3.4.cmml" xref="S4.Ex4.m1.3.4"><eq id="S4.Ex4.m1.3.4.1.cmml" xref="S4.Ex4.m1.3.4.1"></eq><ci id="S4.Ex4.m1.1.1.1b.cmml" xref="S4.Ex4.m1.1.1.1"><mrow id="S4.Ex4.m1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1"><mtext id="S4.Ex4.m1.1.1.1a.cmml" xref="S4.Ex4.m1.1.1.1">SNR</mtext><msub id="S4.Ex4.m1.1.1.1.m1.1.1.cmml" xref="S4.Ex4.m1.1.1.1.m1.1.1"><mi id="S4.Ex4.m1.1.1.1.m1.1.1a.cmml" xref="S4.Ex4.m1.1.1.1.m1.1.1"></mi><mtext id="S4.Ex4.m1.1.1.1.m1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1.m1.1.1.1">Seg</mtext></msub></mrow></ci><apply id="S4.Ex4.m1.3.4.2.cmml" xref="S4.Ex4.m1.3.4.2"><ci id="S4.Ex4.m1.3.4.2.1.cmml" xref="S4.Ex4.m1.3.4.2.1">⋅</ci><apply id="S4.Ex4.m1.3.4.2.2.cmml" xref="S4.Ex4.m1.3.4.2.2"><divide id="S4.Ex4.m1.3.4.2.2.1.cmml" xref="S4.Ex4.m1.3.4.2.2"></divide><cn type="integer" id="S4.Ex4.m1.3.4.2.2.2.cmml" xref="S4.Ex4.m1.3.4.2.2.2">10</cn><ci id="S4.Ex4.m1.3.4.2.2.3.cmml" xref="S4.Ex4.m1.3.4.2.2.3">𝑀</ci></apply><apply id="S4.Ex4.m1.3.4.2.3.cmml" xref="S4.Ex4.m1.3.4.2.3"><apply id="S4.Ex4.m1.3.4.2.3.1.cmml" xref="S4.Ex4.m1.3.4.2.3.1"><csymbol cd="ambiguous" id="S4.Ex4.m1.3.4.2.3.1.1.cmml" xref="S4.Ex4.m1.3.4.2.3.1">superscript</csymbol><apply id="S4.Ex4.m1.3.4.2.3.1.2.cmml" xref="S4.Ex4.m1.3.4.2.3.1"><csymbol cd="ambiguous" id="S4.Ex4.m1.3.4.2.3.1.2.1.cmml" xref="S4.Ex4.m1.3.4.2.3.1">subscript</csymbol><sum id="S4.Ex4.m1.3.4.2.3.1.2.2.cmml" xref="S4.Ex4.m1.3.4.2.3.1.2.2"></sum><apply id="S4.Ex4.m1.3.4.2.3.1.2.3.cmml" xref="S4.Ex4.m1.3.4.2.3.1.2.3"><eq id="S4.Ex4.m1.3.4.2.3.1.2.3.1.cmml" xref="S4.Ex4.m1.3.4.2.3.1.2.3.1"></eq><ci id="S4.Ex4.m1.3.4.2.3.1.2.3.2.cmml" xref="S4.Ex4.m1.3.4.2.3.1.2.3.2">𝑚</ci><cn type="integer" id="S4.Ex4.m1.3.4.2.3.1.2.3.3.cmml" xref="S4.Ex4.m1.3.4.2.3.1.2.3.3">0</cn></apply></apply><apply id="S4.Ex4.m1.3.4.2.3.1.3.cmml" xref="S4.Ex4.m1.3.4.2.3.1.3"><minus id="S4.Ex4.m1.3.4.2.3.1.3.1.cmml" xref="S4.Ex4.m1.3.4.2.3.1.3.1"></minus><ci id="S4.Ex4.m1.3.4.2.3.1.3.2.cmml" xref="S4.Ex4.m1.3.4.2.3.1.3.2">𝑀</ci><cn type="integer" id="S4.Ex4.m1.3.4.2.3.1.3.3.cmml" xref="S4.Ex4.m1.3.4.2.3.1.3.3">1</cn></apply></apply><apply id="S4.Ex4.m1.3.4.2.3.2.cmml" xref="S4.Ex4.m1.3.4.2.3.2"><apply id="S4.Ex4.m1.3.4.2.3.2.1.cmml" xref="S4.Ex4.m1.3.4.2.3.2.1"><csymbol cd="ambiguous" id="S4.Ex4.m1.3.4.2.3.2.1.1.cmml" xref="S4.Ex4.m1.3.4.2.3.2.1">subscript</csymbol><log id="S4.Ex4.m1.3.4.2.3.2.1.2.cmml" xref="S4.Ex4.m1.3.4.2.3.2.1.2"></log><cn type="integer" id="S4.Ex4.m1.3.4.2.3.2.1.3.cmml" xref="S4.Ex4.m1.3.4.2.3.2.1.3">10</cn></apply><apply id="S4.Ex4.m1.3.4.2.3.2.2.cmml" xref="S4.Ex4.m1.3.4.2.3.2.2"><times id="S4.Ex4.m1.3.4.2.3.2.2.1.cmml" xref="S4.Ex4.m1.3.4.2.3.2.2.1"></times><apply id="S4.Ex4.m1.3.3.cmml" xref="S4.Ex4.m1.3.3"><divide id="S4.Ex4.m1.3.3.3.cmml" xref="S4.Ex4.m1.3.3"></divide><apply id="S4.Ex4.m1.2.2.1.cmml" xref="S4.Ex4.m1.2.2.1"><apply id="S4.Ex4.m1.2.2.1.2.cmml" xref="S4.Ex4.m1.2.2.1.2"><csymbol cd="ambiguous" id="S4.Ex4.m1.2.2.1.2.1.cmml" xref="S4.Ex4.m1.2.2.1.2">superscript</csymbol><apply id="S4.Ex4.m1.2.2.1.2.2.cmml" xref="S4.Ex4.m1.2.2.1.2"><csymbol cd="ambiguous" id="S4.Ex4.m1.2.2.1.2.2.1.cmml" xref="S4.Ex4.m1.2.2.1.2">subscript</csymbol><sum id="S4.Ex4.m1.2.2.1.2.2.2.cmml" xref="S4.Ex4.m1.2.2.1.2.2.2"></sum><apply id="S4.Ex4.m1.2.2.1.2.2.3.cmml" xref="S4.Ex4.m1.2.2.1.2.2.3"><eq id="S4.Ex4.m1.2.2.1.2.2.3.1.cmml" xref="S4.Ex4.m1.2.2.1.2.2.3.1"></eq><ci id="S4.Ex4.m1.2.2.1.2.2.3.2.cmml" xref="S4.Ex4.m1.2.2.1.2.2.3.2">𝑘</ci><apply id="S4.Ex4.m1.2.2.1.2.2.3.3.cmml" xref="S4.Ex4.m1.2.2.1.2.2.3.3"><times id="S4.Ex4.m1.2.2.1.2.2.3.3.1.cmml" xref="S4.Ex4.m1.2.2.1.2.2.3.3.1"></times><ci id="S4.Ex4.m1.2.2.1.2.2.3.3.2.cmml" xref="S4.Ex4.m1.2.2.1.2.2.3.3.2">𝑚</ci><ci id="S4.Ex4.m1.2.2.1.2.2.3.3.3.cmml" xref="S4.Ex4.m1.2.2.1.2.2.3.3.3">𝐹</ci></apply></apply></apply><apply id="S4.Ex4.m1.2.2.1.2.3.cmml" xref="S4.Ex4.m1.2.2.1.2.3"><minus id="S4.Ex4.m1.2.2.1.2.3.1.cmml" xref="S4.Ex4.m1.2.2.1.2.3.1"></minus><apply id="S4.Ex4.m1.2.2.1.2.3.2.cmml" xref="S4.Ex4.m1.2.2.1.2.3.2"><plus id="S4.Ex4.m1.2.2.1.2.3.2.1.cmml" xref="S4.Ex4.m1.2.2.1.2.3.2.1"></plus><apply id="S4.Ex4.m1.2.2.1.2.3.2.2.cmml" xref="S4.Ex4.m1.2.2.1.2.3.2.2"><times id="S4.Ex4.m1.2.2.1.2.3.2.2.1.cmml" xref="S4.Ex4.m1.2.2.1.2.3.2.2.1"></times><ci id="S4.Ex4.m1.2.2.1.2.3.2.2.2.cmml" xref="S4.Ex4.m1.2.2.1.2.3.2.2.2">𝑚</ci><ci id="S4.Ex4.m1.2.2.1.2.3.2.2.3.cmml" xref="S4.Ex4.m1.2.2.1.2.3.2.2.3">𝐹</ci></apply><ci id="S4.Ex4.m1.2.2.1.2.3.2.3.cmml" xref="S4.Ex4.m1.2.2.1.2.3.2.3">𝐹</ci></apply><cn type="integer" id="S4.Ex4.m1.2.2.1.2.3.3.cmml" xref="S4.Ex4.m1.2.2.1.2.3.3">1</cn></apply></apply><apply id="S4.Ex4.m1.2.2.1.3.cmml" xref="S4.Ex4.m1.2.2.1.3"><times id="S4.Ex4.m1.2.2.1.3.1.cmml" xref="S4.Ex4.m1.2.2.1.3.1"></times><ci id="S4.Ex4.m1.2.2.1.3.2.cmml" xref="S4.Ex4.m1.2.2.1.3.2">𝑋</ci><apply id="S4.Ex4.m1.2.2.1.3.3.cmml" xref="S4.Ex4.m1.2.2.1.3.3"><csymbol cd="ambiguous" id="S4.Ex4.m1.2.2.1.3.3.1.cmml" xref="S4.Ex4.m1.2.2.1.3.3">superscript</csymbol><ci id="S4.Ex4.m1.2.2.1.1.cmml" xref="S4.Ex4.m1.2.2.1.1">𝑘</ci><cn type="integer" id="S4.Ex4.m1.2.2.1.3.3.3.cmml" xref="S4.Ex4.m1.2.2.1.3.3.3">2</cn></apply></apply></apply><apply id="S4.Ex4.m1.3.3.2.cmml" xref="S4.Ex4.m1.3.3.2"><apply id="S4.Ex4.m1.3.3.2.2.cmml" xref="S4.Ex4.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.Ex4.m1.3.3.2.2.1.cmml" xref="S4.Ex4.m1.3.3.2.2">superscript</csymbol><apply id="S4.Ex4.m1.3.3.2.2.2.cmml" xref="S4.Ex4.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.Ex4.m1.3.3.2.2.2.1.cmml" xref="S4.Ex4.m1.3.3.2.2">subscript</csymbol><sum id="S4.Ex4.m1.3.3.2.2.2.2.cmml" xref="S4.Ex4.m1.3.3.2.2.2.2"></sum><apply id="S4.Ex4.m1.3.3.2.2.2.3.cmml" xref="S4.Ex4.m1.3.3.2.2.2.3"><eq id="S4.Ex4.m1.3.3.2.2.2.3.1.cmml" xref="S4.Ex4.m1.3.3.2.2.2.3.1"></eq><ci id="S4.Ex4.m1.3.3.2.2.2.3.2.cmml" xref="S4.Ex4.m1.3.3.2.2.2.3.2">𝑘</ci><apply id="S4.Ex4.m1.3.3.2.2.2.3.3.cmml" xref="S4.Ex4.m1.3.3.2.2.2.3.3"><times id="S4.Ex4.m1.3.3.2.2.2.3.3.1.cmml" xref="S4.Ex4.m1.3.3.2.2.2.3.3.1"></times><ci id="S4.Ex4.m1.3.3.2.2.2.3.3.2.cmml" xref="S4.Ex4.m1.3.3.2.2.2.3.3.2">𝑚</ci><ci id="S4.Ex4.m1.3.3.2.2.2.3.3.3.cmml" xref="S4.Ex4.m1.3.3.2.2.2.3.3.3">𝐹</ci></apply></apply></apply><apply id="S4.Ex4.m1.3.3.2.2.3.cmml" xref="S4.Ex4.m1.3.3.2.2.3"><minus id="S4.Ex4.m1.3.3.2.2.3.1.cmml" xref="S4.Ex4.m1.3.3.2.2.3.1"></minus><apply id="S4.Ex4.m1.3.3.2.2.3.2.cmml" xref="S4.Ex4.m1.3.3.2.2.3.2"><plus id="S4.Ex4.m1.3.3.2.2.3.2.1.cmml" xref="S4.Ex4.m1.3.3.2.2.3.2.1"></plus><apply id="S4.Ex4.m1.3.3.2.2.3.2.2.cmml" xref="S4.Ex4.m1.3.3.2.2.3.2.2"><times id="S4.Ex4.m1.3.3.2.2.3.2.2.1.cmml" xref="S4.Ex4.m1.3.3.2.2.3.2.2.1"></times><ci id="S4.Ex4.m1.3.3.2.2.3.2.2.2.cmml" xref="S4.Ex4.m1.3.3.2.2.3.2.2.2">𝑚</ci><ci id="S4.Ex4.m1.3.3.2.2.3.2.2.3.cmml" xref="S4.Ex4.m1.3.3.2.2.3.2.2.3">𝐹</ci></apply><ci id="S4.Ex4.m1.3.3.2.2.3.2.3.cmml" xref="S4.Ex4.m1.3.3.2.2.3.2.3">𝐹</ci></apply><cn type="integer" id="S4.Ex4.m1.3.3.2.2.3.3.cmml" xref="S4.Ex4.m1.3.3.2.2.3.3">1</cn></apply></apply><apply id="S4.Ex4.m1.3.3.2.3.cmml" xref="S4.Ex4.m1.3.3.2.3"><times id="S4.Ex4.m1.3.3.2.3.1.cmml" xref="S4.Ex4.m1.3.3.2.3.1"></times><ci id="S4.Ex4.m1.3.3.2.3.2.cmml" xref="S4.Ex4.m1.3.3.2.3.2">𝛿</ci><apply id="S4.Ex4.m1.3.3.2.3.3.cmml" xref="S4.Ex4.m1.3.3.2.3.3"><csymbol cd="ambiguous" id="S4.Ex4.m1.3.3.2.3.3.1.cmml" xref="S4.Ex4.m1.3.3.2.3.3">superscript</csymbol><ci id="S4.Ex4.m1.3.3.2.1.cmml" xref="S4.Ex4.m1.3.3.2.1">𝑘</ci><cn type="integer" id="S4.Ex4.m1.3.3.2.3.3.3.cmml" xref="S4.Ex4.m1.3.3.2.3.3.3">2</cn></apply></apply></apply></apply><ci id="S4.Ex4.m1.3.4.2.3.2.2.2a.cmml" xref="S4.Ex4.m1.3.4.2.3.2.2.2"><mtext id="S4.Ex4.m1.3.4.2.3.2.2.2.cmml" xref="S4.Ex4.m1.3.4.2.3.2.2.2">,</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex4.m1.3c">\text{SNR${}_{\text{Seg}}$}=\frac{10}{M}\cdot\sum_{m=0}^{M-1}\log_{10}\frac{\sum_{k=mF}^{mF+F-1}X(k)^{2}}{\sum_{k=mF}^{mF+F-1}\delta(k)^{2}}\text{,}\enspace</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.I2.i2.p1.7" class="ltx_p">where <math id="S4.I2.i2.p1.2.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.I2.i2.p1.2.m1.1a"><mi id="S4.I2.i2.p1.2.m1.1.1" xref="S4.I2.i2.p1.2.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.2.m1.1b"><ci id="S4.I2.i2.p1.2.m1.1.1.cmml" xref="S4.I2.i2.p1.2.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i2.p1.2.m1.1c">M</annotation></semantics></math> represents the number of frames in a signal, <math id="S4.I2.i2.p1.3.m2.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S4.I2.i2.p1.3.m2.1a"><mi id="S4.I2.i2.p1.3.m2.1.1" xref="S4.I2.i2.p1.3.m2.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.3.m2.1b"><ci id="S4.I2.i2.p1.3.m2.1.1.cmml" xref="S4.I2.i2.p1.3.m2.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i2.p1.3.m2.1c">F</annotation></semantics></math> is the frame length, <math id="S4.I2.i2.p1.4.m3.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S4.I2.i2.p1.4.m3.1a"><mi id="S4.I2.i2.p1.4.m3.1.1" xref="S4.I2.i2.p1.4.m3.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.4.m3.1b"><ci id="S4.I2.i2.p1.4.m3.1.1.cmml" xref="S4.I2.i2.p1.4.m3.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i2.p1.4.m3.1c">X</annotation></semantics></math> denotes the clean audio signal, and <math id="S4.I2.i2.p1.5.m4.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S4.I2.i2.p1.5.m4.1a"><mi id="S4.I2.i2.p1.5.m4.1.1" xref="S4.I2.i2.p1.5.m4.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.5.m4.1b"><ci id="S4.I2.i2.p1.5.m4.1.1.cmml" xref="S4.I2.i2.p1.5.m4.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i2.p1.5.m4.1c">\delta</annotation></semantics></math> the adversarial perturbation, assuming equal lengths of <math id="S4.I2.i2.p1.6.m5.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S4.I2.i2.p1.6.m5.1a"><mi id="S4.I2.i2.p1.6.m5.1.1" xref="S4.I2.i2.p1.6.m5.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.6.m5.1b"><ci id="S4.I2.i2.p1.6.m5.1.1.cmml" xref="S4.I2.i2.p1.6.m5.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i2.p1.6.m5.1c">X</annotation></semantics></math> and <math id="S4.I2.i2.p1.7.m6.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S4.I2.i2.p1.7.m6.1a"><mi id="S4.I2.i2.p1.7.m6.1.1" xref="S4.I2.i2.p1.7.m6.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S4.I2.i2.p1.7.m6.1b"><ci id="S4.I2.i2.p1.7.m6.1.1.cmml" xref="S4.I2.i2.p1.7.m6.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I2.i2.p1.7.m6.1c">\delta</annotation></semantics></math>.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.2" class="ltx_p">Higher values of dB<math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="{}_{\text{x}}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><msub id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1a" xref="S4.SS2.p3.1.m1.1.1.cmml"></mi><mtext id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1a.cmml">x</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><ci id="S4.SS2.p3.1.m1.1.1.1a.cmml" xref="S4.SS2.p3.1.m1.1.1.1"><mtext mathsize="70%" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1">x</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">{}_{\text{x}}</annotation></semantics></math> and SNR<math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="{}_{\text{Seg}}" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><msub id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1a" xref="S4.SS2.p3.2.m2.1.1.cmml"></mi><mtext id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1a.cmml">Seg</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><ci id="S4.SS2.p3.2.m2.1.1.1a.cmml" xref="S4.SS2.p3.2.m2.1.1.1"><mtext mathsize="70%" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1">Seg</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">{}_{\text{Seg}}</annotation></semantics></math> indicate a lower amount of added noise.
In the context of evaluating adversarial robustness in ASR systems, we expect these values to be lower for models trained with augmentation methods, indicating that these models require more noise for adversarial samples to succeed.
For targeted adversarial examples, such as those generated by the C&amp;W method, the reference text for WER and success rate calculations correspond to the malicious target transcription.
From the attacker's perspective, targeted attacks aim to minimize WER and maximize success rate relative to the target transcription.
This comprehensive approach allows us to dissect the nuances of adversarial robustness, understanding the trade-offs between attack efficacy, computational expense, and stealthiness in the context of our SpeechBrain models.
</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In the following we present and discuss the results of our experiments.
A demo is available at <a target="_blank" href="https://matiuste.github.io/SPSC_24/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://matiuste.github.io/SPSC_24/</a>.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T1.5.6.1" class="ltx_tr">
<th id="S5.T1.5.6.1.1" class="ltx_td ltx_th ltx_th_row" colspan="2"></th>
<th id="S5.T1.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2"><span id="S5.T1.5.6.1.2.1" class="ltx_text ltx_font_bold">Benign Data</span></th>
<th id="S5.T1.5.6.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2"><span id="S5.T1.5.6.1.3.1" class="ltx_text ltx_font_bold">Noisy Data</span></th>
<td id="S5.T1.5.6.1.4" class="ltx_td"></td>
</tr>
<tr id="S5.T1.5.5" class="ltx_tr">
<th id="S5.T1.5.5.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row"><span id="S5.T1.5.5.6.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S5.T1.5.5.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row"><span id="S5.T1.5.5.7.1" class="ltx_text ltx_font_bold">Augm.</span></th>
<th id="S5.T1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S5.T1.1.1.1.1" class="ltx_text ltx_font_bold">Succ. rate <math id="S5.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.1.1.1.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.m1.1b"><ci id="S5.T1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S5.T1.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S5.T1.2.2.2.1" class="ltx_text ltx_font_bold">WER <math id="S5.T1.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.2.2.2.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T1.2.2.2.1.m1.1.1" xref="S5.T1.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.1.m1.1b"><ci id="S5.T1.2.2.2.1.m1.1.1.cmml" xref="S5.T1.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S5.T1.3.3.3" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S5.T1.3.3.3.1" class="ltx_text ltx_font_bold">Succ. rate <math id="S5.T1.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.3.3.3.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T1.3.3.3.1.m1.1.1" xref="S5.T1.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.3.1.m1.1b"><ci id="S5.T1.3.3.3.1.m1.1.1.cmml" xref="S5.T1.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S5.T1.4.4.4" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S5.T1.4.4.4.1" class="ltx_text ltx_font_bold">WER <math id="S5.T1.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.4.4.4.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T1.4.4.4.1.m1.1.1" xref="S5.T1.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.4.1.m1.1b"><ci id="S5.T1.4.4.4.1.m1.1.1.cmml" xref="S5.T1.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S5.T1.5.5.5" class="ltx_td ltx_align_right ltx_th ltx_th_column">
<math id="S5.T1.5.5.5.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S5.T1.5.5.5.m1.1a"><mi mathvariant="normal" id="S5.T1.5.5.5.m1.1.1" xref="S5.T1.5.5.5.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.5.m1.1b"><ci id="S5.T1.5.5.5.m1.1.1.cmml" xref="S5.T1.5.5.5.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.5.m1.1c">\Delta</annotation></semantics></math><span id="S5.T1.5.5.5.1" class="ltx_text ltx_font_bold"> WER</span>
</th>
</tr>
<tr id="S5.T1.5.7.2" class="ltx_tr">
<th id="S5.T1.5.7.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S5.T1.5.7.2.1.1" class="ltx_text">Wav2vec</span></th>
<th id="S5.T1.5.7.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="S5.T1.5.7.2.3" class="ltx_td ltx_align_right ltx_border_t">85.67%</td>
<td id="S5.T1.5.7.2.4" class="ltx_td ltx_align_right ltx_border_t">3.11%</td>
<td id="S5.T1.5.7.2.5" class="ltx_td ltx_align_right ltx_border_t">81.33%</td>
<td id="S5.T1.5.7.2.6" class="ltx_td ltx_align_right ltx_border_t">5.39%</td>
<td id="S5.T1.5.7.2.7" class="ltx_td ltx_align_right ltx_border_t">2.28%</td>
</tr>
<tr id="S5.T1.5.8.3" class="ltx_tr">
<th id="S5.T1.5.8.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T1.5.8.3.1.1" class="ltx_text" style="color:#0000FF;">2</span></th>
<td id="S5.T1.5.8.3.2" class="ltx_td ltx_align_right">87.00%</td>
<td id="S5.T1.5.8.3.3" class="ltx_td ltx_align_right">2.84%</td>
<td id="S5.T1.5.8.3.4" class="ltx_td ltx_align_right"><span id="S5.T1.5.8.3.4.1" class="ltx_text ltx_font_bold" style="color:#0000FF;">83.00%</span></td>
<td id="S5.T1.5.8.3.5" class="ltx_td ltx_align_right"><span id="S5.T1.5.8.3.5.1" class="ltx_text ltx_font_bold" style="color:#0000FF;">5.06%</span></td>
<td id="S5.T1.5.8.3.6" class="ltx_td ltx_align_right">2.22%</td>
</tr>
<tr id="S5.T1.5.9.4" class="ltx_tr">
<th id="S5.T1.5.9.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T1.5.9.4.1.1" class="ltx_text" style="color:#FF0000;">3</span></th>
<td id="S5.T1.5.9.4.2" class="ltx_td ltx_align_right">86.33%</td>
<td id="S5.T1.5.9.4.3" class="ltx_td ltx_align_right">2.95%</td>
<td id="S5.T1.5.9.4.4" class="ltx_td ltx_align_right">82.33%</td>
<td id="S5.T1.5.9.4.5" class="ltx_td ltx_align_right">5.12%</td>
<td id="S5.T1.5.9.4.6" class="ltx_td ltx_align_right">2.17%</td>
</tr>
<tr id="S5.T1.5.10.5" class="ltx_tr">
<th id="S5.T1.5.10.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" rowspan="3">
<span id="S5.T1.5.10.5.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S5.T1.5.10.5.1.2" class="ltx_text">Seq2seq 1</span>
</th>
<th id="S5.T1.5.10.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S5.T1.5.10.5.3" class="ltx_td ltx_align_right">70.33%</td>
<td id="S5.T1.5.10.5.4" class="ltx_td ltx_align_right">8.18%</td>
<td id="S5.T1.5.10.5.5" class="ltx_td ltx_align_right">54.33%</td>
<td id="S5.T1.5.10.5.6" class="ltx_td ltx_align_right">19.52%</td>
<td id="S5.T1.5.10.5.7" class="ltx_td ltx_align_right">11.35%</td>
</tr>
<tr id="S5.T1.5.11.6" class="ltx_tr">
<th id="S5.T1.5.11.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T1.5.11.6.1.1" class="ltx_text" style="color:#0000FF;">2</span></th>
<td id="S5.T1.5.11.6.2" class="ltx_td ltx_align_right">71.33%</td>
<td id="S5.T1.5.11.6.3" class="ltx_td ltx_align_right">8.06%</td>
<td id="S5.T1.5.11.6.4" class="ltx_td ltx_align_right">55.67%</td>
<td id="S5.T1.5.11.6.5" class="ltx_td ltx_align_right">20.02%</td>
<td id="S5.T1.5.11.6.6" class="ltx_td ltx_align_right">11.96%</td>
</tr>
<tr id="S5.T1.5.12.7" class="ltx_tr">
<th id="S5.T1.5.12.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T1.5.12.7.1.1" class="ltx_text" style="color:#FF0000;">3</span></th>
<td id="S5.T1.5.12.7.2" class="ltx_td ltx_align_right">71.00%</td>
<td id="S5.T1.5.12.7.3" class="ltx_td ltx_align_right">8.57%</td>
<td id="S5.T1.5.12.7.4" class="ltx_td ltx_align_right"><span id="S5.T1.5.12.7.4.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">65.33%</span></td>
<td id="S5.T1.5.12.7.5" class="ltx_td ltx_align_right"><span id="S5.T1.5.12.7.5.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">11.51%</span></td>
<td id="S5.T1.5.12.7.6" class="ltx_td ltx_align_right">2.95%</td>
</tr>
<tr id="S5.T1.5.13.8" class="ltx_tr">
<th id="S5.T1.5.13.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" rowspan="3">
<span id="S5.T1.5.13.8.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S5.T1.5.13.8.1.2" class="ltx_text">Seq2seq 2</span>
</th>
<th id="S5.T1.5.13.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S5.T1.5.13.8.3" class="ltx_td ltx_align_right">67.00%</td>
<td id="S5.T1.5.13.8.4" class="ltx_td ltx_align_right">9.23%</td>
<td id="S5.T1.5.13.8.5" class="ltx_td ltx_align_right">53.33%</td>
<td id="S5.T1.5.13.8.6" class="ltx_td ltx_align_right">21.08%</td>
<td id="S5.T1.5.13.8.7" class="ltx_td ltx_align_right">11.85%</td>
</tr>
<tr id="S5.T1.5.14.9" class="ltx_tr">
<th id="S5.T1.5.14.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T1.5.14.9.1.1" class="ltx_text" style="color:#0000FF;">2</span></th>
<td id="S5.T1.5.14.9.2" class="ltx_td ltx_align_right">71.33%</td>
<td id="S5.T1.5.14.9.3" class="ltx_td ltx_align_right">8.18%</td>
<td id="S5.T1.5.14.9.4" class="ltx_td ltx_align_right">54.67%</td>
<td id="S5.T1.5.14.9.5" class="ltx_td ltx_align_right">20.02%</td>
<td id="S5.T1.5.14.9.6" class="ltx_td ltx_align_right">11.85%</td>
</tr>
<tr id="S5.T1.5.15.10" class="ltx_tr">
<th id="S5.T1.5.15.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T1.5.15.10.1.1" class="ltx_text" style="color:#FF0000;">3</span></th>
<td id="S5.T1.5.15.10.2" class="ltx_td ltx_align_right">66.67%</td>
<td id="S5.T1.5.15.10.3" class="ltx_td ltx_align_right">10.01%</td>
<td id="S5.T1.5.15.10.4" class="ltx_td ltx_align_right"><span id="S5.T1.5.15.10.4.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">56.67%</span></td>
<td id="S5.T1.5.15.10.5" class="ltx_td ltx_align_right"><span id="S5.T1.5.15.10.5.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">14.35%</span></td>
<td id="S5.T1.5.15.10.6" class="ltx_td ltx_align_right">4.34%</td>
</tr>
<tr id="S5.T1.5.16.11" class="ltx_tr">
<th id="S5.T1.5.16.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" rowspan="3">
<span id="S5.T1.5.16.11.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S5.T1.5.16.11.1.2" class="ltx_text">Transformer</span>
</th>
<th id="S5.T1.5.16.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="S5.T1.5.16.11.3" class="ltx_td ltx_align_right">65.00%</td>
<td id="S5.T1.5.16.11.4" class="ltx_td ltx_align_right">9.90%</td>
<td id="S5.T1.5.16.11.5" class="ltx_td ltx_align_right">52.33%</td>
<td id="S5.T1.5.16.11.6" class="ltx_td ltx_align_right">19.91%</td>
<td id="S5.T1.5.16.11.7" class="ltx_td ltx_align_right">10.01%</td>
</tr>
<tr id="S5.T1.5.17.12" class="ltx_tr">
<th id="S5.T1.5.17.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T1.5.17.12.1.1" class="ltx_text" style="color:#0000FF;">2</span></th>
<td id="S5.T1.5.17.12.2" class="ltx_td ltx_align_right">66.67%</td>
<td id="S5.T1.5.17.12.3" class="ltx_td ltx_align_right">9.29%</td>
<td id="S5.T1.5.17.12.4" class="ltx_td ltx_align_right">53.00%</td>
<td id="S5.T1.5.17.12.5" class="ltx_td ltx_align_right">19.47%</td>
<td id="S5.T1.5.17.12.6" class="ltx_td ltx_align_right">10.18%</td>
</tr>
<tr id="S5.T1.5.18.13" class="ltx_tr">
<th id="S5.T1.5.18.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T1.5.18.13.1.1" class="ltx_text" style="color:#FF0000;">3</span></th>
<td id="S5.T1.5.18.13.2" class="ltx_td ltx_align_right">68.00%</td>
<td id="S5.T1.5.18.13.3" class="ltx_td ltx_align_right">8.51%</td>
<td id="S5.T1.5.18.13.4" class="ltx_td ltx_align_right"><span id="S5.T1.5.18.13.4.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">53.67%</span></td>
<td id="S5.T1.5.18.13.5" class="ltx_td ltx_align_right"><span id="S5.T1.5.18.13.5.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">18.85%</span></td>
<td id="S5.T1.5.18.13.6" class="ltx_td ltx_align_right">10.34%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.7.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S5.T1.8.2" class="ltx_text" style="font-size:90%;">Performance of the considered ASR systems on benign and noisy data, averaged over 300 utterances.
WER and success rate are measured w.r.t. the ground truth transcription.
The arrows indicate the direction for models that are more noise robust, e.g., models with a higher success rate are considered more robust against noisy examples.
The bold numbers indicate the most robust system per model with respect to the chosen parameter.
</span></figcaption>
</figure>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.7.8.1" class="ltx_tr">
<td id="S5.T2.7.8.1.1" class="ltx_td" colspan="2"></td>
<th id="S5.T2.7.8.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="5"><span id="S5.T2.7.8.1.2.1" class="ltx_text ltx_font_bold">C&amp;W Adversarial Data</span></th>
</tr>
<tr id="S5.T2.7.7" class="ltx_tr">
<th id="S5.T2.7.7.8" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T2.7.7.8.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S5.T2.7.7.9" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T2.7.7.9.1" class="ltx_text ltx_font_bold">Augm.</span></th>
<th id="S5.T2.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S5.T2.1.1.1.1" class="ltx_text ltx_font_bold">Succ. rate <math id="S5.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.1.1.1.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T2.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S5.T2.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S5.T2.2.2.2.1" class="ltx_text ltx_font_bold">WER <math id="S5.T2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.2.2.2.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T2.2.2.2.1.m1.1.1" xref="S5.T2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.1.m1.1b"><ci id="S5.T2.2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S5.T2.3.3.3" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S5.T2.3.3.3.1" class="ltx_text ltx_font_bold">First hit <math id="S5.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.3.3.3.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T2.3.3.3.1.m1.1.1" xref="S5.T2.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.1.m1.1b"><ci id="S5.T2.3.3.3.1.m1.1.1.cmml" xref="S5.T2.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S5.T2.5.5.5" class="ltx_td ltx_align_right ltx_th ltx_th_column">
<span id="S5.T2.4.4.4.m1.1.1.1" class="ltx_text ltx_markedasmath ltx_font_bold">dB<math id="S5.T2.4.4.4.m1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{x}}" display="inline"><semantics id="S5.T2.4.4.4.m1.1.1.1.m1.1a"><msub id="S5.T2.4.4.4.m1.1.1.1.m1.1.1" xref="S5.T2.4.4.4.m1.1.1.1.m1.1.1.cmml"><mi id="S5.T2.4.4.4.m1.1.1.1.m1.1.1a" xref="S5.T2.4.4.4.m1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_bold" id="S5.T2.4.4.4.m1.1.1.1.m1.1.1.1" xref="S5.T2.4.4.4.m1.1.1.1.m1.1.1.1a.cmml">x</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.m1.1.1.1.m1.1b"><apply id="S5.T2.4.4.4.m1.1.1.1.m1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1.1.m1.1.1"><ci id="S5.T2.4.4.4.m1.1.1.1.m1.1.1.1a.cmml" xref="S5.T2.4.4.4.m1.1.1.1.m1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T2.4.4.4.m1.1.1.1.m1.1.1.1.cmml" xref="S5.T2.4.4.4.m1.1.1.1.m1.1.1.1">x</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.m1.1.1.1.m1.1c">{}_{\text{x}}</annotation></semantics></math></span><span id="S5.T2.5.5.5.1" class="ltx_text ltx_font_bold"> <math id="S5.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.5.5.5.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T2.5.5.5.1.m1.1.1" xref="S5.T2.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.1.m1.1b"><ci id="S5.T2.5.5.5.1.m1.1.1.cmml" xref="S5.T2.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math></span>
</th>
<th id="S5.T2.7.7.7" class="ltx_td ltx_align_right ltx_th ltx_th_column">
<math id="S5.T2.6.6.6.m1.1" class="ltx_Math" alttext="\text{SNR}_{\text{seg}}" display="inline"><semantics id="S5.T2.6.6.6.m1.1a"><msub id="S5.T2.6.6.6.m1.1.1" xref="S5.T2.6.6.6.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T2.6.6.6.m1.1.1.2" xref="S5.T2.6.6.6.m1.1.1.2a.cmml">SNR</mtext><mtext class="ltx_mathvariant_bold" id="S5.T2.6.6.6.m1.1.1.3" xref="S5.T2.6.6.6.m1.1.1.3a.cmml">seg</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.6.m1.1b"><apply id="S5.T2.6.6.6.m1.1.1.cmml" xref="S5.T2.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.6.6.6.m1.1.1.1.cmml" xref="S5.T2.6.6.6.m1.1.1">subscript</csymbol><ci id="S5.T2.6.6.6.m1.1.1.2a.cmml" xref="S5.T2.6.6.6.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T2.6.6.6.m1.1.1.2.cmml" xref="S5.T2.6.6.6.m1.1.1.2">SNR</mtext></ci><ci id="S5.T2.6.6.6.m1.1.1.3a.cmml" xref="S5.T2.6.6.6.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T2.6.6.6.m1.1.1.3.cmml" xref="S5.T2.6.6.6.m1.1.1.3">seg</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.6.m1.1c">\text{SNR}_{\text{seg}}</annotation></semantics></math><span id="S5.T2.7.7.7.1" class="ltx_text ltx_font_bold"> <math id="S5.T2.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.7.7.7.1.m1.1a"><mo mathcolor="#808080" stretchy="false" id="S5.T2.7.7.7.1.m1.1.1" xref="S5.T2.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.7.1.m1.1b"><ci id="S5.T2.7.7.7.1.m1.1.1.cmml" xref="S5.T2.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math></span>
</th>
</tr>
<tr id="S5.T2.7.9.2" class="ltx_tr">
<td id="S5.T2.7.9.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S5.T2.7.9.2.1.1" class="ltx_text">Wav2vec</span></td>
<td id="S5.T2.7.9.2.2" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S5.T2.7.9.2.3" class="ltx_td ltx_align_right ltx_border_t">100.0%</td>
<td id="S5.T2.7.9.2.4" class="ltx_td ltx_align_right ltx_border_t">0.00</td>
<td id="S5.T2.7.9.2.5" class="ltx_td ltx_align_right ltx_border_t">155</td>
<td id="S5.T2.7.9.2.6" class="ltx_td ltx_align_right ltx_border_t">35.41</td>
<td id="S5.T2.7.9.2.7" class="ltx_td ltx_align_right ltx_border_t">18.54</td>
</tr>
<tr id="S5.T2.7.10.3" class="ltx_tr">
<td id="S5.T2.7.10.3.1" class="ltx_td ltx_align_center"><span id="S5.T2.7.10.3.1.1" class="ltx_text" style="color:#0000FF;">2</span></td>
<td id="S5.T2.7.10.3.2" class="ltx_td ltx_align_right"><span id="S5.T2.7.10.3.2.1" class="ltx_text ltx_font_bold" style="color:#0000FF;">99.6%</span></td>
<td id="S5.T2.7.10.3.3" class="ltx_td ltx_align_right"><span id="S5.T2.7.10.3.3.1" class="ltx_text ltx_font_bold" style="color:#0000FF;">0.05</span></td>
<td id="S5.T2.7.10.3.4" class="ltx_td ltx_align_right"><span id="S5.T2.7.10.3.4.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#0000FF;">343</span></td>
<td id="S5.T2.7.10.3.5" class="ltx_td ltx_align_right"><span id="S5.T2.7.10.3.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#0000FF;">29.59</span></td>
<td id="S5.T2.7.10.3.6" class="ltx_td ltx_align_right"><span id="S5.T2.7.10.3.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#0000FF;">14.08</span></td>
</tr>
<tr id="S5.T2.7.11.4" class="ltx_tr">
<td id="S5.T2.7.11.4.1" class="ltx_td ltx_align_center"><span id="S5.T2.7.11.4.1.1" class="ltx_text" style="color:#FF0000;">3</span></td>
<td id="S5.T2.7.11.4.2" class="ltx_td ltx_align_right">100.0%</td>
<td id="S5.T2.7.11.4.3" class="ltx_td ltx_align_right">0.00</td>
<td id="S5.T2.7.11.4.4" class="ltx_td ltx_align_right">158</td>
<td id="S5.T2.7.11.4.5" class="ltx_td ltx_align_right">35.40</td>
<td id="S5.T2.7.11.4.6" class="ltx_td ltx_align_right">18.28</td>
</tr>
<tr id="S5.T2.7.12.5" class="ltx_tr">
<td id="S5.T2.7.12.5.1" class="ltx_td ltx_align_center" rowspan="3">
<span id="S5.T2.7.12.5.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S5.T2.7.12.5.1.2" class="ltx_text">Seq2seq 1</span>
</td>
<td id="S5.T2.7.12.5.2" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.7.12.5.3" class="ltx_td ltx_align_right">88.3%</td>
<td id="S5.T2.7.12.5.4" class="ltx_td ltx_align_right">5.53</td>
<td id="S5.T2.7.12.5.5" class="ltx_td ltx_align_right">454</td>
<td id="S5.T2.7.12.5.6" class="ltx_td ltx_align_right">27.21</td>
<td id="S5.T2.7.12.5.7" class="ltx_td ltx_align_right">9.34</td>
</tr>
<tr id="S5.T2.7.13.6" class="ltx_tr">
<td id="S5.T2.7.13.6.1" class="ltx_td ltx_align_center"><span id="S5.T2.7.13.6.1.1" class="ltx_text" style="color:#0000FF;">2</span></td>
<td id="S5.T2.7.13.6.2" class="ltx_td ltx_align_right">86.0%</td>
<td id="S5.T2.7.13.6.3" class="ltx_td ltx_align_right">7.16</td>
<td id="S5.T2.7.13.6.4" class="ltx_td ltx_align_right">323</td>
<td id="S5.T2.7.13.6.5" class="ltx_td ltx_align_right">27.46</td>
<td id="S5.T2.7.13.6.6" class="ltx_td ltx_align_right">9.47</td>
</tr>
<tr id="S5.T2.7.14.7" class="ltx_tr">
<td id="S5.T2.7.14.7.1" class="ltx_td ltx_align_center"><span id="S5.T2.7.14.7.1.1" class="ltx_text" style="color:#FF0000;">3</span></td>
<td id="S5.T2.7.14.7.2" class="ltx_td ltx_align_right"><span id="S5.T2.7.14.7.2.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">74.0%</span></td>
<td id="S5.T2.7.14.7.3" class="ltx_td ltx_align_right"><span id="S5.T2.7.14.7.3.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#FF0000;">14.89</span></td>
<td id="S5.T2.7.14.7.4" class="ltx_td ltx_align_right"><span id="S5.T2.7.14.7.4.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">479</span></td>
<td id="S5.T2.7.14.7.5" class="ltx_td ltx_align_right"><span id="S5.T2.7.14.7.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#FF0000;">23.92</span></td>
<td id="S5.T2.7.14.7.6" class="ltx_td ltx_align_right"><span id="S5.T2.7.14.7.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#FF0000;">6.69</span></td>
</tr>
<tr id="S5.T2.7.15.8" class="ltx_tr">
<td id="S5.T2.7.15.8.1" class="ltx_td ltx_align_center" rowspan="3">
<span id="S5.T2.7.15.8.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S5.T2.7.15.8.1.2" class="ltx_text">Seq2seq 2</span>
</td>
<td id="S5.T2.7.15.8.2" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.7.15.8.3" class="ltx_td ltx_align_right">98.3%</td>
<td id="S5.T2.7.15.8.4" class="ltx_td ltx_align_right">0.47</td>
<td id="S5.T2.7.15.8.5" class="ltx_td ltx_align_right">107</td>
<td id="S5.T2.7.15.8.6" class="ltx_td ltx_align_right">41.99</td>
<td id="S5.T2.7.15.8.7" class="ltx_td ltx_align_right">19.37</td>
</tr>
<tr id="S5.T2.7.16.9" class="ltx_tr">
<td id="S5.T2.7.16.9.1" class="ltx_td ltx_align_center"><span id="S5.T2.7.16.9.1.1" class="ltx_text" style="color:#0000FF;">2</span></td>
<td id="S5.T2.7.16.9.2" class="ltx_td ltx_align_right">99.6%</td>
<td id="S5.T2.7.16.9.3" class="ltx_td ltx_align_right">0.05</td>
<td id="S5.T2.7.16.9.4" class="ltx_td ltx_align_right">113</td>
<td id="S5.T2.7.16.9.5" class="ltx_td ltx_align_right">41.13</td>
<td id="S5.T2.7.16.9.6" class="ltx_td ltx_align_right">18.84</td>
</tr>
<tr id="S5.T2.7.17.10" class="ltx_tr">
<td id="S5.T2.7.17.10.1" class="ltx_td ltx_align_center"><span id="S5.T2.7.17.10.1.1" class="ltx_text" style="color:#FF0000;">3</span></td>
<td id="S5.T2.7.17.10.2" class="ltx_td ltx_align_right"><span id="S5.T2.7.17.10.2.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">96.0%</span></td>
<td id="S5.T2.7.17.10.3" class="ltx_td ltx_align_right"><span id="S5.T2.7.17.10.3.1" class="ltx_text ltx_font_bold" style="color:#FF0000;">1.53</span></td>
<td id="S5.T2.7.17.10.4" class="ltx_td ltx_align_right"><span id="S5.T2.7.17.10.4.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#FF0000;">186</span></td>
<td id="S5.T2.7.17.10.5" class="ltx_td ltx_align_right"><span id="S5.T2.7.17.10.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#FF0000;">37.65</span></td>
<td id="S5.T2.7.17.10.6" class="ltx_td ltx_align_right"><span id="S5.T2.7.17.10.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#FF0000;">15.93</span></td>
</tr>
<tr id="S5.T2.7.18.11" class="ltx_tr">
<td id="S5.T2.7.18.11.1" class="ltx_td ltx_align_center" rowspan="3">
<span id="S5.T2.7.18.11.1.1" class="ltx_ERROR undefined">\hdashline</span><span id="S5.T2.7.18.11.1.2" class="ltx_text">Transformer</span>
</td>
<td id="S5.T2.7.18.11.2" class="ltx_td ltx_align_center">1</td>
<td id="S5.T2.7.18.11.3" class="ltx_td ltx_align_right">100.0%</td>
<td id="S5.T2.7.18.11.4" class="ltx_td ltx_align_right">0.00</td>
<td id="S5.T2.7.18.11.5" class="ltx_td ltx_align_right">19</td>
<td id="S5.T2.7.18.11.6" class="ltx_td ltx_align_right">56.26</td>
<td id="S5.T2.7.18.11.7" class="ltx_td ltx_align_right">28.89</td>
</tr>
<tr id="S5.T2.7.19.12" class="ltx_tr">
<td id="S5.T2.7.19.12.1" class="ltx_td ltx_align_center"><span id="S5.T2.7.19.12.1.1" class="ltx_text" style="color:#0000FF;">2</span></td>
<td id="S5.T2.7.19.12.2" class="ltx_td ltx_align_right">100.0%</td>
<td id="S5.T2.7.19.12.3" class="ltx_td ltx_align_right">0.00</td>
<td id="S5.T2.7.19.12.4" class="ltx_td ltx_align_right">18</td>
<td id="S5.T2.7.19.12.5" class="ltx_td ltx_align_right"><span id="S5.T2.7.19.12.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#0000FF;">54.52</span></td>
<td id="S5.T2.7.19.12.6" class="ltx_td ltx_align_right"><span id="S5.T2.7.19.12.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#0000FF;">27.23</span></td>
</tr>
<tr id="S5.T2.7.20.13" class="ltx_tr">
<td id="S5.T2.7.20.13.1" class="ltx_td ltx_align_center"><span id="S5.T2.7.20.13.1.1" class="ltx_text" style="color:#FF0000;">3</span></td>
<td id="S5.T2.7.20.13.2" class="ltx_td ltx_align_right">100.0%</td>
<td id="S5.T2.7.20.13.3" class="ltx_td ltx_align_right">0.00</td>
<td id="S5.T2.7.20.13.4" class="ltx_td ltx_align_right"><span id="S5.T2.7.20.13.4.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" style="color:#FF0000;">20</span></td>
<td id="S5.T2.7.20.13.5" class="ltx_td ltx_align_right"><span id="S5.T2.7.20.13.5.1" class="ltx_text ltx_framed ltx_framed_underline">54.90</span></td>
<td id="S5.T2.7.20.13.6" class="ltx_td ltx_align_right"><span id="S5.T2.7.20.13.6.1" class="ltx_text ltx_framed ltx_framed_underline">27.59</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.9.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.10.2" class="ltx_text" style="font-size:90%;">Results for C&amp;W targeted attack.
All values are averaged over 300 adversarial examples.
WER and success rate are measured w.r.t. the target adversarial transcription.
The arrows indicate the direction for models that are more robust against adversarial examples, e.g., models with a lower success rate are considered more robust against adversarial examples.
The bold numbers indicate the more robust model with respect to the chosen parameter.
Underlined numbers show a statistical significant difference between training regime 1 and the considered training regime according to the KS test.
</span></figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluating Noise Robustness</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">In evaluating noise robustness, the reference text for WER and success rate calculations is the ground-truth transcript of the clean test sample.
We aim for ASR models to exhibit low WER and high success rate, indicating accurate recognition of the ground-truth transcription.
This step is essential to validate the effectiveness of our noise-augmented training regimen before examining the relationship between noise and adversarial robustness.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Our experimental results corroborate that models subjected to noise-augmented training exhibit enhanced robustness when confronted with speech samples with environmental noise.
For each model considered in Table <a href="#S5.T1" title="Table 1 ‣ 5 Results ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the success rate and WER for noisy data have improved with noise-augmented training (the models marked in blue or red).
This is evidenced by a lower WER in comparison to their counterparts trained without any augmentation (marked in black).</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">This improvement is particularly pronounced for the seq2seq models, which build on minimal pre-trained components, while the enhancement is less apparent for the wav2vec and transformer models that rely more on pre-trained parts, especially for feature extraction.
Interestingly, the wav2vec-based models maintain a high success rate even with noisy data, whereas for all other architectures, the success rate drops significantly.
This could be attributed to the fact that the wav2vec models incorporate pre-trained models that were exposed to noisy data during training.
These findings indicate that noise-augmented training indeed enhances noise robustness, although the extent of improvement varies depending on the architecture.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">In the next experiment, we evaluate if it also enhances adversarial robustness.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluating Adversarial Robustness</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In the subsequent experiment, we focus on assessing adversarial robustness.
For every C&amp;W adversarial example
we gather data similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.
To gauge the severity of performance degradation, we compare the success rate of adversarial attacks against our models (see Eq. <a href="#S4.E2" title="In 2nd item ‣ 4.1 Evaluating Noise Robustness ‣ 4 Experiments ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) and analyze the WER (see Eq. <a href="#S4.E1" title="In 1st item ‣ 4.1 Evaluating Noise Robustness ‣ 4 Experiments ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
Additionally, we evaluate the computational complexity of generating adversarial examples by recording the first hit, defined as the number of iterations required to craft the first successful adversarial example.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Table <a href="#S5.T2" title="Table 2 ‣ 5 Results ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> encapsulates the success rate, computational effort, and perceptibility metrics across various architectures and models for the targeted C&amp;W attack.
Our findings reveal that for the seq2seq models trained from scratch, those that underwent noise-augmented training demonstrate a slightly reduced adversarial success rate, a higher WER, or more perceptible noise, indicating improved robustness to adversarial attacks.
Again, the effects on improved adversarial robustness are most apparent for the seq2seq-based models.
Similarly to the noise robustness, only minor improvements can be seen for the wav2vec- and transformer-based models.
Interestingly, we did not find a clear connection between the model's WER on the benign data (see Table <a href="#S5.T1" title="Table 1 ‣ 5 Results ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, fourth column) and the adversarial success rate (see Table <a href="#S5.T2" title="Table 2 ‣ 5 Results ‣ Reassessing Noise Augmentation Methods in the Context of Adversarial Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, third column).</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Our findings indicate that incorporating speed or noise augmentation into the training process enhances the adversarial robustness of most models when confronted with targeted white-box attacks.
In cases where data augmentation does not lead to higher robustness compared to the base model, it also does not result in a severe robustness reduction.
This underlines that noise augmentation should be used as a standard routine in the training of neural network-based ASR systems.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion and Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Our comprehensive study has shed light on the efficacy of noise augmentation as a strategy for improving the adversarial robustness of automatic speech recognition (ASR) systems.
By conducting a systematic comparative analysis of four state-of-the-art ASR architectures, each trained with different augmentation techniques and subjected to targeted white-box attacks, we have provided empirical evidence supporting the benefits of noise augmentation.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Our findings reveal that across the board, ASR models trained with noise augmentation – encompassing background noise, speed variations – and reverberations exhibit enhanced robustness against adversarial attacks compared to those without such augmentation.
Interestingly, the implementation of speed variations alone as a form of augmentation also contributed positively to the robustness of the models, albeit to a lesser extent than the combination of multiple noise types.
This hints that robustness gains may be attributed to the increased diversity and volume of the dataset.
Through our investigation, it becomes evident that incorporating speed and noise augmentation into the training pipeline is beneficial for both noise robustness and adversarial robustness.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">The findings from our study suggest several intriguing directions for further research.
First, while noise augmentation has proven effective, understanding the optimal combination and intensity of different augmentation types remains an open question.
The relative contributions of background noise, speed variations, and reverberations need to be quantified to develop more targeted augmentation strategies.
Additionally, the role of dataset size and diversity in enhancing robustness merits deeper exploration.
Our results indicate that simply increasing the dataset size with varied augmentations can lead to significant robustness improvements.
Future studies could systematically vary the size and diversity of training data to better understand this relationship.
Moreover, our research highlights the complex interplay between different forms of augmentation and their impact on adversarial robustness.
A thorough investigation into how these augmentations interact with various attack types could provide more granular insights into defense mechanisms.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">For future work, we believe that exploring the interplay between noise augmentation and other defense strategies, such as adversarial training and model ensembling, could yield a more robust and multi-faceted approach to securing ASR systems against a wide array of threats.
Combining these strategies could leverage the strengths of each, potentially leading to ASR systems that are not only robust against noise and adversarial attacks but also adaptable to evolving threats in real-world applications.
By continuing to refine augmentation techniques and exploring their integration with other defensive measures, we can move towards developing ASR systems that are both resilient and reliable in the face of diverse and sophisticated adversarial challenges.
</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgements</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This work was partly supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy – EXC 2092 CASA – 390781972 and the Wilhelm and Günter Esser Foundation.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus, ``Intriguing properties of neural networks,'' <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6199</em>, 2013.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
N. Carlini and D. Wagner, ``Audio adversarial examples: Targeted attacks on speech-to-text,'' in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2018 IEEE security and privacy workshops (SPW)</em>.   IEEE, 2018, pp. 1–7.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y. Qin, N. Carlini, G. Cottrell, I. Goodfellow, and C. Raffel, ``Imperceptible, robust, and targeted adversarial examples for automatic speech recognition,'' in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   PMLR, 2019, pp. 5231–5240.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
L. Schönherr, K. Kohls, S. Zeiler, T. Holz, and D. Kolossa, ``Adversarial attacks against automatic speech recognition systems via psychoacoustic hiding,'' <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Network and Distributed System Security Symposium (NDSS)</em>, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R. F. Olivier, ``Assessing and enhancing adversarial robustness in context and applications to speech security,'' Ph.D. dissertation, Carnegie Mellon University, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
M. Dua, Akanksha, and S. Dua, ``Noise robust automatic speech recognition: review and analysis,'' <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">International Journal of Speech Technology</em>, vol. 26, no. 2, pp. 475–519, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T. Ko, V. Peddinti, D. Povey, M. L. Seltzer, and S. Khudanpur, ``A study on data augmentation of reverberant speech for robust speech recognition,'' in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2017, pp. 5220–5224.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
T. Virtanen, R. Singh, and B. Raj, <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Techniques for noise robustness in automatic speech recognition</em>.   John Wiley &amp; Sons, 2012.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
R. Olivier and B. Raj, ``There is more than one kind of robustness: Fooling Whisper with adversarial examples,'' in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proc. INTERSPEECH 2023</em>, 2023, pp. 4394–4398.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta, A. Coates <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Deep speech: Scaling up end-to-end speech recognition,'' <em id="bib.bib10.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.5567</em>, 2014.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A. Abe, K. Yamamoto, and S. Nakagawa, ``Robust speech recognition using DNN-HMM acoustic model combining noise-aware training with spectral subtraction,'' in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2015</em>, 2015, pp. 2849–2853.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
D. Stoller, S. Ewert, and S. Dixon, ``Wave-u-net: A multi-scale neural network for end-to-end audio source separation,'' in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27, 2018</em>, E. Gómez, X. Hu, E. Humphrey, and E. Benetos, Eds., 2018, pp. 334–340.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
S. Bagheri and D. Giacobello, ``Exploiting Multi-Channel Speech Presence Probability in Parametric Multi-Channel Wiener Filter,'' in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>, 2019, pp. 101–105.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
N. Alamdari, A. Azarang, and N. Kehtarnavaz, ``Improving deep speech denoising by noisy2noisy signal mapping,'' <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Applied Acoustics</em>, vol. 172, p. 107631, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M. Ravanelli, T. Parcollet, P. Plantinga, A. Rouhe, S. Cornell, L. Lugosch, C. Subakan, N. Dawalatabad, A. Heba, J. Zhong <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Speechbrain: A general-purpose speech toolkit,'' <em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.04624</em>, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
I. J. Goodfellow, J. Shlens, and C. Szegedy, ``Explaining and harnessing adversarial examples,'' <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6572</em>, 2014.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, ``Towards deep learning models resistant to adversarial attacks,'' <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">6th International Conference on Learning Representations (ICLR)</em>, 2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami, ``Distillation as a defense to adversarial perturbations against deep neural networks,'' in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">2016 IEEE symposium on security and privacy (SP)</em>.   IEEE, 2016, pp. 582–597.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
F. Tramèr, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel, ``Ensemble adversarial training: Attacks and defenses,'' <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">6th International Conference on Learning Representations (ICLR)</em>, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
D. Jakubovitz and R. Giryes, ``Improving DNN robustness to adversarial attacks using jacobian regularization,'' in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European conference on computer vision (ECCV)</em>, 2018, pp. 514–529.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
E. Wong and Z. Kolter, ``Provable defenses against adversarial examples via the convex outer adversarial polytope,'' in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.   PMLR, 2018, pp. 5286–5295.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
C. Xie, Y. Wu, L. v. d. Maaten, A. L. Yuille, and K. He, ``Feature denoising for improving adversarial robustness,'' in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, 2019, pp. 501–509.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
W. Xu, D. Evans, and Y. Qi, ``Feature squeezing: Detecting adversarial examples in deep neural networks,'' <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Network and Distributed Systems Security Symposium (NDSS)</em>, 2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
M. Pizarro, D. Kolossa, and A. Fischer, ``Robustifying automatic speech recognition by extracting slowly varying features,'' in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proc. 2021 ISCA Symposium on Security and Privacy in Speech Communication</em>, 2021, pp. 37–41.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
H. Zhang, H. Chen, Z. Song, D. Boning, I. S. Dhillon, and C.-J. Hsieh, ``The limitations of adversarial training and the blind-spot attack,'' <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">7th International Conference on Learning Representations (ICLR)</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
A. Fawzi, S.-M. Moosavi-Dezfooli, and P. Frossard, ``Robustness of classifiers: from adversarial to random noise,'' <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol. 29, 2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Laugros, A. Caplier, and M. Ospici, ``Are adversarial robustness and common perturbation robustness independant attributes?'' in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops</em>, 2019.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
J. Gilmer, N. Ford, N. Carlini, and E. Cubuk, ``Adversarial examples are a natural consequence of test error in noise,'' in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.   PMLR, 2019, pp. 2280–2289.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
B. Li, C. Chen, W. Wang, and L. Carin, ``Certified adversarial robustness with additive noise,'' <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol. 32, 2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
P. Żelasko, S. Joshi, Y. Shao, J. Villalba, J. Trmal, N. Dehak, and S. Khudanpur, ``Adversarial attacks and defenses for speech recognition systems,'' <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.17122</em>, 2021.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
R. Olivier and B. Raj, ``Recent improvements of ASR models in the face of adversarial attacks,'' in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2022</em>, 2022, pp. 4113–4117.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M. P. Pizarro B., D. Kolossa, and A. Fischer, ``Distriblock: Identifying adversarial audio samples by leveraging characteristics of the output distribution,'' in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">The 40th Conference on Uncertainty in Artificial Intelligence</em>, 2024.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
R. Prabhavalkar, T. Hori, T. N. Sainath, R. Schlüter, and S. Watanabe, ``End-to-end speech recognition: A survey,'' <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol. 32, pp. 325–351, 2024.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A. Baevski, H. Zhou, A. Mohamed, and M. Auli, ``Wav2vec 2.0: A framework for self-supervised learning of speech representations,'' in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>, ser. NIPS'20.   Red Hook, NY, USA: Curran Associates Inc., 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
A. Graves, S. Fernández, F. Gomez, and J. Schmidhuber, ``Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,'' in <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd International Conference on Machine Learning</em>, ser. ICML '06.   New York, NY, USA: Association for Computing Machinery, 2006, p. 369–376.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
S. Hochreiter and J. Schmidhuber, ``Long short-term memory,'' <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Neural Comput.</em>, vol. 9, no. 8, p. 1735–1780, nov 1997.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
J. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Bengio, ``Attention-based models for speech recognition,'' in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1</em>, ser. NIPS'15.   Cambridge, MA, USA: MIT Press, 2015, p. 577–585.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
W. Chan, N. Jaitly, Q. Le, and O. Vinyals, ``Listen, attend and spell: A neural network for large vocabulary conversational speech recognition,'' in <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2016, pp. 4960–4964.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, ``Attention is all you need,'' in <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds., vol. 30.   Curran Associates, Inc., 2017.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
T. Wolf and et al., ``Transformers: State-of-the-art natural language processing,'' in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>.   Online: Association for Computational Linguistics, Oct. 2020, pp. 38–45.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
T. Ko, V. Peddinti, D. Povey, and S. Khudanpur, ``Audio augmentation for speech recognition.'' in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, vol. 2015, 2015, p. 3586.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
D. S. Park, W. Chan, Y. Zhang, C.-C. Chiu, B. Zoph, E. D. Cubuk, and Q. V. Le, ``Specaugment: A simple data augmentation method for automatic speech recognition,'' <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.08779</em>, 2019.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
D. S. Park, Y. Zhang, C.-C. Chiu, Y. Chen, B. Li, W. Chan, Q. V. Le, and Y. Wu, ``Specaugment on large scale datasets,'' in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.   IEEE, 2020, pp. 6879–6883.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, ``Librispeech: an ASR corpus based on public domain audio books,'' in <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>.   IEEE, 2015, pp. 5206–5210.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
P. Mermelstein, ``Evaluation of a segmental SNR measure as an indicator of the quality of ADPCM coded speech,'' <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">The Journal of the Acoustical Society of America</em>, vol. 66, no. 6, pp. 1664–1667, 12 1979.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
K. Markert, D. Mirdita, and K. Böttinger, ``Language dependencies in adversarial attacks on speech recognition systems,'' in <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proc. 2021 ISCA Symposium on Security and Privacy in Speech Communication</em>, 2021, pp. 25–31.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.01812" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.01813" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.01813">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.01813" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.01814" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 01:37:38 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
