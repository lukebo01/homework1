<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.07937] Speech Robust Bench: A Robustness Benchmark For Speech Recognition</title><meta property="og:description" content="As Automatic Speech Recognition (ASR) models become ever more pervasive, it is important to ensure that they make reliable predictions under corruptions present in the physical and digital world.
We propose Speech Robu…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Speech Robust Bench: A Robustness Benchmark For Speech Recognition">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Speech Robust Bench: A Robustness Benchmark For Speech Recognition">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.07937">

<!--Generated on Fri Apr  5 17:50:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Machine Learning,  ICML">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Speech Robust Bench: A Robustness Benchmark For Speech Recognition</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Muhammad A. Shah
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">David Solans Noguero
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mikko A. Heikkilä
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nicolas Kourtellis
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">As Automatic Speech Recognition (ASR) models become ever more pervasive, it is important to ensure that they make reliable predictions under corruptions present in the physical and digital world.
We propose <span id="id1.id1.1" class="ltx_text ltx_font_typewriter">Speech Robust Bench (SRB)</span>, a comprehensive benchmark for evaluating the robustness of ASR models to diverse corruptions. <span id="id1.id1.2" class="ltx_text ltx_font_typewriter">SRB</span> is composed of 69 input perturbations which are intended to simulate various corruptions that ASR models may encounter in the physical and digital world. We use <span id="id1.id1.3" class="ltx_text ltx_font_typewriter">SRB</span> to evaluate the robustness of several state-of-the-art ASR models and observe that model size and certain modeling choices such as discrete representations, and self-training appear to be conducive to robustness. We extend this analysis to measure the robustness of ASR models on data from various demographic subgroups, namely English and Spanish speakers, and males and females, and observed noticeable disparities in the model’s robustness across subgroups. We believe that <span id="id1.id1.4" class="ltx_text ltx_font_typewriter">SRB</span> will facilitate future research towards robust ASR models, by making it easier to conduct comprehensive and comparable robustness evaluations.</p>
</div>
<div class="ltx_keywords">Machine Learning, ICML
</div>
<div id="p2" class="ltx_para">
<br class="ltx_break">
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Robustness to input perturbations is a highly desirable attribute in Machine Learning (ML) models. When deployed in the real world, ML models are likely to encounter noise and corruptions arising from a myriad of sources, including the environment, sensing apparatus, and even malicious actors. The ability of the models to counteract these sources of noise and continue to make accurate predictions has significant implications for their safety, security, and reliability.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">As novel ML models continue to be developed <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">and deployed</span> at an ever-increasing rate, it has become all the more important to ensure that their robustness is well understood. To this end, prior works have developed robustness benchmarks that evaluate various aspects of a model’s performance under a variety of input perturbations. These benchmarks have proven to be invaluable to the advancement of research into more robust models because (1) they enable meaningful comparisons across existing and new models, which allows progress to be accurately tracked, and (2) make it easier for researchers to evaluate the robustness of their models, thereby reducing the barrier to entry into robustness research. While robustness benchmarks have been proposed in prior works for vision <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Dietterich, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>; Hendrycks et al., <a href="#bib.bib14" title="" class="ltx_ref">2021a</a>, <a href="#bib.bib15" title="" class="ltx_ref">b</a>; Croce et al., <a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite> and natural language processing <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib48" title="" class="ltx_ref">2021a</a>, <a href="#bib.bib51" title="" class="ltx_ref">2022b</a>)</cite> tasks, the development of such benchmarks for Automatic Speech Recognition (ASR) models has received little attention beyond benchmarks based on simple digit sequence recognition <cite class="ltx_cite ltx_citemacro_citep">(Hirsch &amp; Pearce, <a href="#bib.bib18" title="" class="ltx_ref">2000</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In the absence of standardized benchmarks, prior works have tried to evaluate the robustness of ASR models in various different ways. For example, several works have used a combination of distortions from various datasets to perturb the input audio <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>; Wen et al., <a href="#bib.bib52" title="" class="ltx_ref">2016</a>; Chen et al., <a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite>, however, since the choice of dataset varies among studies, their results are not comparable. Other, more recent, works <cite class="ltx_cite ltx_citemacro_citep">(Likhomanenko et al., <a href="#bib.bib30" title="" class="ltx_ref">2020</a>; Radford et al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>; Hsu et al., <a href="#bib.bib20" title="" class="ltx_ref">2021b</a>)</cite> have evaluated the robustness of models by computing their transcription accuracy on multiple speech datasets that may have perturbations from the real world. Since the type of perturbations present in these datasets is not controlled and is unknown, this evaluation method does not inform about the
specific type of perturbations the models may be weak against.
Moreover, prior works rarely evaluate their proposed models against adversarial attacks (unless they are proposing defenses), and thus neglect to highlight potential security vulnerabilities of the models.
</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we propose <span id="S1.p4.1.1" class="ltx_text ltx_font_typewriter">Speech Robust Bench (SRB)</span>, a standardized robustness benchmark for ASR models. Following the design of successful robustness benchmarks for image recognition <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Dietterich, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>; Croce et al., <a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite>, <span id="S1.p4.1.2" class="ltx_text ltx_font_typewriter">SRB</span> is composed of two parts: (1) a comprehensive bank of perturbations, and (2) a set of robustness metrics. The perturbations bank contains a comprehensive set of perturbations that represent common distortions arising from the environment or equipment, variations in speaker attributes, semantic preserving special effects found in digital media, and adversarial attacks. Meanwhile, the metrics we propose, following the methodology of <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Dietterich, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, measure two aspects of robustness: the transcription accuracy of the models, as well as the stability of the predicted transcripts under randomized perturbations.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To highlight the need for and the benefits of doing systematic robustness assessment, we evaluate the robustness of several popular ASR models using <span id="S1.p5.1.1" class="ltx_text ltx_font_typewriter">SRB</span>, and compare their robustness. We observe that while Whisper <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite> is the most robust <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">on average</span> among the models we tested, it is outperformed by other, smaller, models on several perturbations. Further analyses reveal that larger models tend to be more robust than smaller models, even if the latter are trained on significantly more data. We further extend our analysis by evaluating the models’ robustness for the various population sub-groups, namely, English and non-English (Spanish) speakers, and male and female speakers. We find that significant disparities exist across these sub-groups, thus identifying areas where future work could provide improvements, and demonstrating the utility of <span id="S1.p5.1.3" class="ltx_text ltx_font_typewriter">SRB</span> in fairness evaluations as well.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To summarize we make the following contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We present <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">SRB</span>, a robustness benchmark for ASR models, which can result in directly comparable robustness evaluations and facilitate progress.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:-2.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We open source our code <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/ahmedshah1494/speech_robust_bench/tree/release" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/ahmedshah1494/speech_robust_bench/tree/release</a></span></span></span> with clear documentation of existing use cases and support easy extensibility.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:-2.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We release perturbed versions of the Librispeech test set, and the test set of the Spanish subset of Multi-Lingual Librispeech to facilitate out-of-the-box robustness evaluations for the research community.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:-2.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We demonstrate the use of <span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_typewriter">SRB</span> by conducting a fine-grained robustness analysis for several popular models. We extend our analysis by using <span id="S1.I1.i4.p1.1.2" class="ltx_text ltx_font_typewriter">SRB</span> to uncover disparities in the robustness of ASR for various sub-groups of speakers. This highlights the broad utility of such benchmarks to the field of trustworthy AI.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Robust Automatic Speech Recognition</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Over the years, several techniques have been proposed for making Automatic Speech Recognition (ASR) models robust to input perturbations, such as noise and other signal corruptions <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib29" title="" class="ltx_ref">2014</a>)</cite>. We can divide these techniques into two high-level categories: i) model-based and ii) feature-based. i) Model-based techniques modify the models to make them more robust. Examples of such approaches include adapting pre-trained models <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a href="#bib.bib57" title="" class="ltx_ref">2009</a>; Juang &amp; Rahim, <a href="#bib.bib22" title="" class="ltx_ref">1996</a>)</cite>, denoising the audio before processing <cite class="ltx_cite ltx_citemacro_citep">(Mohammadiha et al., <a href="#bib.bib33" title="" class="ltx_ref">2013</a>; Wilson et al., <a href="#bib.bib54" title="" class="ltx_ref">2008</a>)</cite>, and training ASR models on noisy data <cite class="ltx_cite ltx_citemacro_citep">(Likhomanenko et al., <a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite>. Since model based strategies generally require access to noisy data <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib29" title="" class="ltx_ref">2014</a>)</cite>, they are most effective if the sources of noise, and/or the exact environment in which the ASR model will be deployed in are known, and one can gather data to represent them. ii) Feature-based approaches, on the other hand, involve developing handcrafted features that are invariant to noise and corruptions in the signal <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib29" title="" class="ltx_ref">2014</a>)</cite>. Several of these features are inspired by biological audition <cite class="ltx_cite ltx_citemacro_citep">(Kim &amp; Stern, <a href="#bib.bib23" title="" class="ltx_ref">2016</a>; Hermansky et al., <a href="#bib.bib17" title="" class="ltx_ref">1991</a>; Hermansky &amp; Sharma, <a href="#bib.bib16" title="" class="ltx_ref">1998</a>)</cite>, while others use signal processing techniques <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib29" title="" class="ltx_ref">2014</a>)</cite>. Generally, these methods are designed to extract the components of the audio signal salient for speech production and perception, while discarding irrelevant components <cite class="ltx_cite ltx_citemacro_citep">(Stern &amp; Morgan, <a href="#bib.bib44" title="" class="ltx_ref">2012</a>)</cite>. Consequently, they do not require precise knowledge of the environment and noise distributions. Recently, however, handcrafted features have fallen out of favor, and have been replaced by features learned via end-to-end training of deep learning models on large amounts of data <cite class="ltx_cite ltx_citemacro_citep">(Baevski et al., <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Hsu et al., <a href="#bib.bib19" title="" class="ltx_ref">2021a</a>; Likhomanenko et al., <a href="#bib.bib30" title="" class="ltx_ref">2020</a>; Radford et al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>. Proponents of these techniques posit that models trained on larger datasets become more robust. Our evaluations in § <a href="#S4" title="4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> reveal that there are several input perturbations against which smaller models trained on less data outperform larger models trained on more data.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Adversarial Robustness</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Adversarial perturbations are perturbations that can change the response of a model when added to their inputs, but are either imperceptible to humans or perceptually and semantically irrelevant enough to be ignored by them <cite class="ltx_cite ltx_citemacro_citep">(Szegedy et al., <a href="#bib.bib45" title="" class="ltx_ref">2014</a>; Goodfellow et al., <a href="#bib.bib12" title="" class="ltx_ref">2014</a>)</cite>. Adversarially perturbed inputs are known as <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">adversarial attacks</span>. They can be targeted (aiming to change a prediction to a specific incorrect class), or un-targeted (aiming to change a prediction to any incorrect class, <cite class="ltx_cite ltx_citemacro_citet">Akhtar et al. <a href="#bib.bib1" title="" class="ltx_ref">2021</a></cite>). The design of adversarial attacks is determined by the level of knowledge the attacker is assumed to have about the target model. Attacks that assume full knowledge of the target model’s architecture and weights (<span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">white-box</span> threat model) often use gradient-based optimization techniques <cite class="ltx_cite ltx_citemacro_citep">(Szegedy et al., <a href="#bib.bib45" title="" class="ltx_ref">2014</a>; Goodfellow et al., <a href="#bib.bib12" title="" class="ltx_ref">2014</a>; Madry et al., <a href="#bib.bib32" title="" class="ltx_ref">2018</a>; Laidlaw et al., <a href="#bib.bib27" title="" class="ltx_ref">2021</a>; Akhtar et al., <a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite>.
Attackers who do not have any knowledge of the target models architecture and only have query access to it (<span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_italic">black-box</span> threat model) typically use gradient-free optimization methods <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib50" title="" class="ltx_ref">2022a</a>; Andriushchenko et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>; Wicker et al., <a href="#bib.bib53" title="" class="ltx_ref">2018</a>; Chen et al., <a href="#bib.bib8" title="" class="ltx_ref">2017</a>; Zhao et al., <a href="#bib.bib58" title="" class="ltx_ref">2020</a>; Vo et al., <a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite>. An intriguing property of adversarial perturbations is that they transfer between models <cite class="ltx_cite ltx_citemacro_citep">(Papernot et al., <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite>, and inputs <cite class="ltx_cite ltx_citemacro_citep">(Akhtar et al., <a href="#bib.bib1" title="" class="ltx_ref">2021</a>; Neekhara et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>. Our <span id="S2.SS2.p1.1.4" class="ltx_text ltx_font_typewriter">SRB</span> includes two types of white box adversarial attacks: those that generate perturbations specific to each input <cite class="ltx_cite ltx_citemacro_citep">(Madry et al., <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>, and those that generate perturbations that cause models to mis-transcribe multiple inputs <cite class="ltx_cite ltx_citemacro_citep">(Neekhara et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Robustness Benchmarks</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Robustness benchmarks have unified robustness evaluations and enabled fair comparisons between various models and robustness enhancing techniques in several domains, including vision, Natural Language Processing (NLP) and ASR.
In the domain of vision, <cite class="ltx_cite ltx_citemacro_citet">Croce et al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite> propose an adversarial robustness benchmark and leaderboard based on AutoAttack <cite class="ltx_cite ltx_citemacro_citep">(Croce &amp; Hein, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>, while <cite class="ltx_cite ltx_citemacro_citet">Hendrycks &amp; Dietterich (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Hendrycks et al. (<a href="#bib.bib14" title="" class="ltx_ref">2021a</a>)</cite> propose benchmarks and metrics for measuring the robustness of image recognition models to non-adversarial perturbations. In the domain of NLP, <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a href="#bib.bib48" title="" class="ltx_ref">2021a</a>)</cite> propose a benchmark to evaluate models under various lexical and semantic perturbations, such as typos, distractors, and word replacements. However, in the domain of ASR, there is a lack of similar comprehensive benchmarks that measure the robustness of ASR models on diverse corruptions. The current benchmarks are often specialized to one (or few) types of perturbations such as reverberation <cite class="ltx_cite ltx_citemacro_citep">(Nakamura et al., <a href="#bib.bib34" title="" class="ltx_ref">2000</a>; Kinoshita et al., <a href="#bib.bib24" title="" class="ltx_ref">2013</a>; Jeub et al., <a href="#bib.bib21" title="" class="ltx_ref">2009</a>)</cite>, environmental noise <cite class="ltx_cite ltx_citemacro_citep">(Barker et al., <a href="#bib.bib5" title="" class="ltx_ref">2018</a>; Piczak, <a href="#bib.bib39" title="" class="ltx_ref">2015</a>)</cite>, and accented speech <cite class="ltx_cite ltx_citemacro_citep">(Lander, <a href="#bib.bib28" title="" class="ltx_ref">2022</a>; Shi et al., <a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite>. While there is some initial work in developing more comprehensive benchmarks <cite class="ltx_cite ltx_citemacro_citep">(Hirsch &amp; Pearce, <a href="#bib.bib18" title="" class="ltx_ref">2000</a>)</cite>, it is limited to relatively simple data consisting of spoken sequences of digits, which lack the complexity of long sentences that modern ASR models are expected to transcribe.
Some recent works <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>; Likhomanenko et al., <a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite> have evaluated the robustness of ASR models by computing transcription accuracy on several speech datasets. We find that this evaluation method is too coarse to pinpoint the strengths and weaknesses of the models; for example, <cite class="ltx_cite ltx_citemacro_citet">Likhomanenko et al. (<a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite> present the word error rates for three settings: clean, noisy, and extreme, for each dataset, from which it is difficult to determine the kinds of noise or distortions the model has difficulties with. Furthermore, most robustness evaluations of ASR models do not consider adversarial robustness, and thus neglect to highlight potential security vulnerabilities of the models.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Speech Robust Bench</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Overview</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">At a high level our benchmark consists of two components: (1) a bank of perturbations that are representative of various scenarios that the model could encounter when deployed in the wild (§ <a href="#S3.SS3" title="3.3 Perturbations ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>), and (2) a set of metrics for quantifying the robustness of the ASR models and facilitating comparisons among them (§ <a href="#S3.SS5" title="3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>). Given an ASR model (§ <a href="#S3.SS4" title="3.4 Models and Transcription ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>) to be evaluated and dataset consisting of audio utterances and reference transcripts (§ <a href="#S3.SS2" title="3.2 Dataset ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>), the procedure for evaluating the robustness of the target ASR model using our benchmark involves the following three steps, as illustrated in Figure <a href="#S3.F1" title="Figure 1 ‣ 3.1 Overview ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. First, the input audio is perturbed using a comprehensive bank of perturbations (§ <a href="#S3.SS3" title="3.3 Perturbations ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>). In the case of deterministic perturbations only a single perturbed audio is produced, while in the case of randomized perturbations we obtain several perturbed audios that are used to test the stability of the model’s prediction. Then the perturbed audio is transcribed by the target ASR model. Since some of our metrics are normalized by the error of a baseline ASR model (see § <a href="#S3.SS5.SSS0.Px2" title="3.5.2. Normalized Word Error Rate (NWER) ‣ 3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>), transcripts from the baseline model are also obtained. Finally, the reference transcript and the predicted transcripts from the baseline and target ASR models are used to compute the metrics described in § <a href="#S3.SS5" title="3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2403.07937/assets/icml/figures/eval-pipeline.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="139" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">An illustration of the processes involved in using our benchmark to evaluate the robustness of ASR models.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Dataset</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We have designed <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">SRB</span> to be largely agnostic to the evaluation data to make it more broadly applicable across various speech recognition domains. In principle, <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">SRB</span> can be used with any dataset that contains utterances and reference transcripts, however, we recommend using datasets with high-quality clean audio and accurate transcripts so that pre-existing corruptions in the dataset do not confound the robustness metrics obtained from the benchmark. For this reason, our evaluation in § <a href="#S4" title="4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> uses clean speech from Librispeech <cite class="ltx_cite ltx_citemacro_citep">(Panayotov et al., <a href="#bib.bib37" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2403.07937/assets/icml/figures/taxonomy.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="293" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">Taxonomy of perturbations currently used in <span id="S3.F2.4.2.1" class="ltx_text ltx_font_typewriter">SRB</span>.</span></figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Perturbations</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The taxonomy of the perturbations used in our benchmark is presented in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2 Dataset ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The perturbations are of two broad types: 1) non-adversarial and 2) adversarial.
The non-adversarial perturbations fall under one of three categories: 1.i) common corruptions, such as white noise, environmental noise, and room impulse response, that may be introduced by the environment or by other sources, 1.ii) semantically irrelevant perturbations such as special effects that may be encountered in digital media, and 1.iii) speaker attribute perturbation, such as voice/accent transformations.
The adversarial perturbations fall under two categories: specific and general. 2.i) General adversarial perturbations are designed to be agnostic to the utterance, to the model, or to both. 2.ii) Specific adversarial perturbations, on the other hand, are crafted to cause a specific model to mistranscribe a specific utterance, and, in general, they are not expected to be very effective on other models and utterances.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Each perturbation is applied at 4 levels of severity, which is modulated by adjusting the parameters and attributes of the perturbation. The perturbations and their parameters and attributes are discussed in detail in Appendix <a href="#A1" title="Appendix A Perturbation Generation/Application Procedure ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Models and Transcription</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Once perturbed, the utterances are transcribed by the (target) ASR model being evaluated, as well as a baseline model. The transcripts from the baseline model are needed to compute the metrics described in § <a href="#S3.SS5" title="3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>. In <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_typewriter">SRB</span> we use Deepspeech <cite class="ltx_cite ltx_citemacro_citep">(Amodei et al., <a href="#bib.bib2" title="" class="ltx_ref">2016</a>)</cite> as baseline. Indeed, in principle, any model other than the target model(s) can be used. We recommend using a model that does not exhibit counter-intuitive behavior, such as unusually high error rate on relatively mild corruptions or lower error rate on more severe corruptions, to make results easier to understand.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Metrics</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Similar to <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Dietterich, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, <span id="S3.SS5.p1.1.1" class="ltx_text ltx_font_typewriter">SRB</span> measures robustness along two dimensions: utility and stability of the model’s prediction under input perturbations.
<span id="S3.SS5.p1.1.2" class="ltx_text ltx_font_typewriter">SRB</span> measures the utility of the model with the widely used <span id="S3.SS5.p1.1.3" class="ltx_text ltx_font_italic">Word Error Rate</span> (WER, see § <a href="#S3.SS5.SSS0.Px1" title="3.5.1. Word Error Rate (WER) ‣ 3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>). When aggregating WER over multiple perturbations we follow the practice of <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Dietterich, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite> and normalize the WER of the target model by the WER of a baseline model. Doing so penalizes errors on “easy” corruptions more than errors on “harder” corruptions. This normalized metric is called <span id="S3.SS5.p1.1.4" class="ltx_text ltx_font_italic">Normalized WER</span> (NWER, see § <a href="#S3.SS5.SSS0.Px2" title="3.5.2. Normalized Word Error Rate (NWER) ‣ 3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>). Meanwhile, <span id="S3.SS5.p1.1.5" class="ltx_text ltx_font_typewriter">SRB</span> measures the prediction stability of the model by computing the variance in the WER caused by corrupting the signal with multiple corruption samples drawn from the same distribution. We call this metric <span id="S3.SS5.p1.1.6" class="ltx_text ltx_font_italic">WER Variance</span> (WERV, see § <a href="#S3.SS5.SSS0.Px3" title="3.5.3. Word Error Rate Variance (WERV) ‣ 3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>).</p>
</div>
<section id="S3.SS5.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">3.5.1. Word Error Rate (WER)
<br class="ltx_break">
</h4>

<div id="S3.SS5.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS5.SSS0.Px1.p1.2" class="ltx_p">Following the common practice from ASR literature, the WER is computed as the word-level edit distance between the reference and the predicted transcripts, normalized by the length of the reference. The edit distance is computed as the total number of word substitutions, deletions, and additions required to transform the reference transcript into the predicted transcript.
When WER is computed over multiple pairs of predicted and reference transcripts, it is common practice to treat all the predicted transcripts as one long text segment <math id="S3.SS5.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="S3.SS5.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px1.p1.1.m1.1c">\mathcal{X}</annotation></semantics></math>, and likewise consider all the reference transcripts as a single long text segment <math id="S3.SS5.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S3.SS5.SSS0.Px1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS5.SSS0.Px1.p1.2.m2.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px1.p1.2.m2.1b"><ci id="S3.SS5.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS0.Px1.p1.2.m2.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px1.p1.2.m2.1c">\mathcal{R}</annotation></semantics></math>. This means that the number of substitutions, deletions, and additions for all the pairs are summed, and divided by the sum of the lengths of the reference transcripts. Formally, this can be written as</p>
<table id="A2.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1.m1.9" class="ltx_Math" alttext="\displaystyle WER^{M}(\mathcal{X},\mathcal{R}):=100\frac{\sum_{x\in\mathcal{X},r\in\mathcal{R}}ED(M(x),r)}{\sum_{r\in\mathcal{R}}|r|}," display="inline"><semantics id="S3.E1.m1.9a"><mrow id="S3.E1.m1.9.9.1" xref="S3.E1.m1.9.9.1.1.cmml"><mrow id="S3.E1.m1.9.9.1.1" xref="S3.E1.m1.9.9.1.1.cmml"><mrow id="S3.E1.m1.9.9.1.1.2" xref="S3.E1.m1.9.9.1.1.2.cmml"><mi id="S3.E1.m1.9.9.1.1.2.2" xref="S3.E1.m1.9.9.1.1.2.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.9.9.1.1.2.1" xref="S3.E1.m1.9.9.1.1.2.1.cmml">​</mo><mi id="S3.E1.m1.9.9.1.1.2.3" xref="S3.E1.m1.9.9.1.1.2.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.9.9.1.1.2.1a" xref="S3.E1.m1.9.9.1.1.2.1.cmml">​</mo><msup id="S3.E1.m1.9.9.1.1.2.4" xref="S3.E1.m1.9.9.1.1.2.4.cmml"><mi id="S3.E1.m1.9.9.1.1.2.4.2" xref="S3.E1.m1.9.9.1.1.2.4.2.cmml">R</mi><mi id="S3.E1.m1.9.9.1.1.2.4.3" xref="S3.E1.m1.9.9.1.1.2.4.3.cmml">M</mi></msup><mo lspace="0em" rspace="0em" id="S3.E1.m1.9.9.1.1.2.1b" xref="S3.E1.m1.9.9.1.1.2.1.cmml">​</mo><mrow id="S3.E1.m1.9.9.1.1.2.5.2" xref="S3.E1.m1.9.9.1.1.2.5.1.cmml"><mo stretchy="false" id="S3.E1.m1.9.9.1.1.2.5.2.1" xref="S3.E1.m1.9.9.1.1.2.5.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.7.7" xref="S3.E1.m1.7.7.cmml">𝒳</mi><mo id="S3.E1.m1.9.9.1.1.2.5.2.2" xref="S3.E1.m1.9.9.1.1.2.5.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.8.8" xref="S3.E1.m1.8.8.cmml">ℛ</mi><mo rspace="0.278em" stretchy="false" id="S3.E1.m1.9.9.1.1.2.5.2.3" xref="S3.E1.m1.9.9.1.1.2.5.1.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S3.E1.m1.9.9.1.1.1" xref="S3.E1.m1.9.9.1.1.1.cmml">:=</mo><mrow id="S3.E1.m1.9.9.1.1.3" xref="S3.E1.m1.9.9.1.1.3.cmml"><mn id="S3.E1.m1.9.9.1.1.3.2" xref="S3.E1.m1.9.9.1.1.3.2.cmml">100</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.9.9.1.1.3.1" xref="S3.E1.m1.9.9.1.1.3.1.cmml">​</mo><mstyle displaystyle="true" id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml"><mfrac id="S3.E1.m1.6.6a" xref="S3.E1.m1.6.6.cmml"><mrow id="S3.E1.m1.5.5.5" xref="S3.E1.m1.5.5.5.cmml"><msub id="S3.E1.m1.5.5.5.6" xref="S3.E1.m1.5.5.5.6.cmml"><mo id="S3.E1.m1.5.5.5.6.2" xref="S3.E1.m1.5.5.5.6.2.cmml">∑</mo><mrow id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.3.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml">𝒳</mi></mrow><mo id="S3.E1.m1.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.3a.cmml">,</mo><mrow id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.cmml">r</mi><mo id="S3.E1.m1.2.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.2.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.2.3.cmml">ℛ</mi></mrow></mrow></msub><mrow id="S3.E1.m1.5.5.5.5" xref="S3.E1.m1.5.5.5.5.cmml"><mi id="S3.E1.m1.5.5.5.5.3" xref="S3.E1.m1.5.5.5.5.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.5.2" xref="S3.E1.m1.5.5.5.5.2.cmml">​</mo><mi id="S3.E1.m1.5.5.5.5.4" xref="S3.E1.m1.5.5.5.5.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.5.2a" xref="S3.E1.m1.5.5.5.5.2.cmml">​</mo><mrow id="S3.E1.m1.5.5.5.5.1.1" xref="S3.E1.m1.5.5.5.5.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.5.5.1.1.2" xref="S3.E1.m1.5.5.5.5.1.2.cmml">(</mo><mrow id="S3.E1.m1.5.5.5.5.1.1.1" xref="S3.E1.m1.5.5.5.5.1.1.1.cmml"><mi id="S3.E1.m1.5.5.5.5.1.1.1.2" xref="S3.E1.m1.5.5.5.5.1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.5.1.1.1.1" xref="S3.E1.m1.5.5.5.5.1.1.1.1.cmml">​</mo><mrow id="S3.E1.m1.5.5.5.5.1.1.1.3.2" xref="S3.E1.m1.5.5.5.5.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.5.5.1.1.1.3.2.1" xref="S3.E1.m1.5.5.5.5.1.1.1.cmml">(</mo><mi id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml">x</mi><mo stretchy="false" id="S3.E1.m1.5.5.5.5.1.1.1.3.2.2" xref="S3.E1.m1.5.5.5.5.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.5.5.5.5.1.1.3" xref="S3.E1.m1.5.5.5.5.1.2.cmml">,</mo><mi id="S3.E1.m1.4.4.4.4" xref="S3.E1.m1.4.4.4.4.cmml">r</mi><mo stretchy="false" id="S3.E1.m1.5.5.5.5.1.1.4" xref="S3.E1.m1.5.5.5.5.1.2.cmml">)</mo></mrow></mrow></mrow><mrow id="S3.E1.m1.6.6.6" xref="S3.E1.m1.6.6.6.cmml"><msub id="S3.E1.m1.6.6.6.2" xref="S3.E1.m1.6.6.6.2.cmml"><mo id="S3.E1.m1.6.6.6.2.2" xref="S3.E1.m1.6.6.6.2.2.cmml">∑</mo><mrow id="S3.E1.m1.6.6.6.2.3" xref="S3.E1.m1.6.6.6.2.3.cmml"><mi id="S3.E1.m1.6.6.6.2.3.2" xref="S3.E1.m1.6.6.6.2.3.2.cmml">r</mi><mo id="S3.E1.m1.6.6.6.2.3.1" xref="S3.E1.m1.6.6.6.2.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.6.6.6.2.3.3" xref="S3.E1.m1.6.6.6.2.3.3.cmml">ℛ</mi></mrow></msub><mrow id="S3.E1.m1.6.6.6.3.2" xref="S3.E1.m1.6.6.6.3.1.cmml"><mo lspace="0em" stretchy="false" id="S3.E1.m1.6.6.6.3.2.1" xref="S3.E1.m1.6.6.6.3.1.1.cmml">|</mo><mi id="S3.E1.m1.6.6.6.1" xref="S3.E1.m1.6.6.6.1.cmml">r</mi><mo stretchy="false" id="S3.E1.m1.6.6.6.3.2.2" xref="S3.E1.m1.6.6.6.3.1.1.cmml">|</mo></mrow></mrow></mfrac></mstyle></mrow></mrow><mo id="S3.E1.m1.9.9.1.2" xref="S3.E1.m1.9.9.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.9b"><apply id="S3.E1.m1.9.9.1.1.cmml" xref="S3.E1.m1.9.9.1"><csymbol cd="latexml" id="S3.E1.m1.9.9.1.1.1.cmml" xref="S3.E1.m1.9.9.1.1.1">assign</csymbol><apply id="S3.E1.m1.9.9.1.1.2.cmml" xref="S3.E1.m1.9.9.1.1.2"><times id="S3.E1.m1.9.9.1.1.2.1.cmml" xref="S3.E1.m1.9.9.1.1.2.1"></times><ci id="S3.E1.m1.9.9.1.1.2.2.cmml" xref="S3.E1.m1.9.9.1.1.2.2">𝑊</ci><ci id="S3.E1.m1.9.9.1.1.2.3.cmml" xref="S3.E1.m1.9.9.1.1.2.3">𝐸</ci><apply id="S3.E1.m1.9.9.1.1.2.4.cmml" xref="S3.E1.m1.9.9.1.1.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.2.4.1.cmml" xref="S3.E1.m1.9.9.1.1.2.4">superscript</csymbol><ci id="S3.E1.m1.9.9.1.1.2.4.2.cmml" xref="S3.E1.m1.9.9.1.1.2.4.2">𝑅</ci><ci id="S3.E1.m1.9.9.1.1.2.4.3.cmml" xref="S3.E1.m1.9.9.1.1.2.4.3">𝑀</ci></apply><interval closure="open" id="S3.E1.m1.9.9.1.1.2.5.1.cmml" xref="S3.E1.m1.9.9.1.1.2.5.2"><ci id="S3.E1.m1.7.7.cmml" xref="S3.E1.m1.7.7">𝒳</ci><ci id="S3.E1.m1.8.8.cmml" xref="S3.E1.m1.8.8">ℛ</ci></interval></apply><apply id="S3.E1.m1.9.9.1.1.3.cmml" xref="S3.E1.m1.9.9.1.1.3"><times id="S3.E1.m1.9.9.1.1.3.1.cmml" xref="S3.E1.m1.9.9.1.1.3.1"></times><cn type="integer" id="S3.E1.m1.9.9.1.1.3.2.cmml" xref="S3.E1.m1.9.9.1.1.3.2">100</cn><apply id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6"><divide id="S3.E1.m1.6.6.7.cmml" xref="S3.E1.m1.6.6"></divide><apply id="S3.E1.m1.5.5.5.cmml" xref="S3.E1.m1.5.5.5"><apply id="S3.E1.m1.5.5.5.6.cmml" xref="S3.E1.m1.5.5.5.6"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.6.1.cmml" xref="S3.E1.m1.5.5.5.6">subscript</csymbol><sum id="S3.E1.m1.5.5.5.6.2.cmml" xref="S3.E1.m1.5.5.5.6.2"></sum><apply id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><in id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"></in><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">𝒳</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2"><in id="S3.E1.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.1"></in><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2">𝑟</ci><ci id="S3.E1.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3">ℛ</ci></apply></apply></apply><apply id="S3.E1.m1.5.5.5.5.cmml" xref="S3.E1.m1.5.5.5.5"><times id="S3.E1.m1.5.5.5.5.2.cmml" xref="S3.E1.m1.5.5.5.5.2"></times><ci id="S3.E1.m1.5.5.5.5.3.cmml" xref="S3.E1.m1.5.5.5.5.3">𝐸</ci><ci id="S3.E1.m1.5.5.5.5.4.cmml" xref="S3.E1.m1.5.5.5.5.4">𝐷</ci><interval closure="open" id="S3.E1.m1.5.5.5.5.1.2.cmml" xref="S3.E1.m1.5.5.5.5.1.1"><apply id="S3.E1.m1.5.5.5.5.1.1.1.cmml" xref="S3.E1.m1.5.5.5.5.1.1.1"><times id="S3.E1.m1.5.5.5.5.1.1.1.1.cmml" xref="S3.E1.m1.5.5.5.5.1.1.1.1"></times><ci id="S3.E1.m1.5.5.5.5.1.1.1.2.cmml" xref="S3.E1.m1.5.5.5.5.1.1.1.2">𝑀</ci><ci id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3">𝑥</ci></apply><ci id="S3.E1.m1.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4">𝑟</ci></interval></apply></apply><apply id="S3.E1.m1.6.6.6.cmml" xref="S3.E1.m1.6.6.6"><apply id="S3.E1.m1.6.6.6.2.cmml" xref="S3.E1.m1.6.6.6.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.6.2.1.cmml" xref="S3.E1.m1.6.6.6.2">subscript</csymbol><sum id="S3.E1.m1.6.6.6.2.2.cmml" xref="S3.E1.m1.6.6.6.2.2"></sum><apply id="S3.E1.m1.6.6.6.2.3.cmml" xref="S3.E1.m1.6.6.6.2.3"><in id="S3.E1.m1.6.6.6.2.3.1.cmml" xref="S3.E1.m1.6.6.6.2.3.1"></in><ci id="S3.E1.m1.6.6.6.2.3.2.cmml" xref="S3.E1.m1.6.6.6.2.3.2">𝑟</ci><ci id="S3.E1.m1.6.6.6.2.3.3.cmml" xref="S3.E1.m1.6.6.6.2.3.3">ℛ</ci></apply></apply><apply id="S3.E1.m1.6.6.6.3.1.cmml" xref="S3.E1.m1.6.6.6.3.2"><abs id="S3.E1.m1.6.6.6.3.1.1.cmml" xref="S3.E1.m1.6.6.6.3.2.1"></abs><ci id="S3.E1.m1.6.6.6.1.cmml" xref="S3.E1.m1.6.6.6.1">𝑟</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.9c">\displaystyle WER^{M}(\mathcal{X},\mathcal{R}):=100\frac{\sum_{x\in\mathcal{X},r\in\mathcal{R}}ED(M(x),r)}{\sum_{r\in\mathcal{R}}|r|},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS5.SSS0.Px1.p1.3" class="ltx_p">where <math id="S3.SS5.SSS0.Px1.p1.3.m1.1" class="ltx_Math" alttext="ED" display="inline"><semantics id="S3.SS5.SSS0.Px1.p1.3.m1.1a"><mrow id="S3.SS5.SSS0.Px1.p1.3.m1.1.1" xref="S3.SS5.SSS0.Px1.p1.3.m1.1.1.cmml"><mi id="S3.SS5.SSS0.Px1.p1.3.m1.1.1.2" xref="S3.SS5.SSS0.Px1.p1.3.m1.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS0.Px1.p1.3.m1.1.1.1" xref="S3.SS5.SSS0.Px1.p1.3.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS0.Px1.p1.3.m1.1.1.3" xref="S3.SS5.SSS0.Px1.p1.3.m1.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px1.p1.3.m1.1b"><apply id="S3.SS5.SSS0.Px1.p1.3.m1.1.1.cmml" xref="S3.SS5.SSS0.Px1.p1.3.m1.1.1"><times id="S3.SS5.SSS0.Px1.p1.3.m1.1.1.1.cmml" xref="S3.SS5.SSS0.Px1.p1.3.m1.1.1.1"></times><ci id="S3.SS5.SSS0.Px1.p1.3.m1.1.1.2.cmml" xref="S3.SS5.SSS0.Px1.p1.3.m1.1.1.2">𝐸</ci><ci id="S3.SS5.SSS0.Px1.p1.3.m1.1.1.3.cmml" xref="S3.SS5.SSS0.Px1.p1.3.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px1.p1.3.m1.1c">ED</annotation></semantics></math> computes the edit distance.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.2.1.1" class="ltx_tr">
<td id="S3.T1.2.1.1.1" class="ltx_td ltx_align_left"><span id="S3.T1.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Language</span></td>
<td id="S3.T1.2.1.1.2" class="ltx_td ltx_align_left"><span id="S3.T1.2.1.1.2.1" class="ltx_text" style="font-size:90%;">Model</span></td>
<td id="S3.T1.2.1.1.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.1.1.3.1" class="ltx_text" style="font-size:90%;">Data (h)</span></td>
<td id="S3.T1.2.1.1.4" class="ltx_td ltx_align_center"><span id="S3.T1.2.1.1.4.1" class="ltx_text" style="font-size:90%;">#Params (M)</span></td>
<td id="S3.T1.2.1.1.5" class="ltx_td ltx_align_center"><span id="S3.T1.2.1.1.5.1" class="ltx_text" style="font-size:90%;">WER</span></td>
</tr>
<tr id="S3.T1.2.2.2" class="ltx_tr">
<td id="S3.T1.2.2.2.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="6"><span id="S3.T1.2.2.2.1.1" class="ltx_text" style="font-size:90%;">EN</span></td>
<td id="S3.T1.2.2.2.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T1.2.2.2.2.1" class="ltx_text" style="font-size:90%;">wav2vec2-large-960h-lv60-self (</span><span id="S3.T1.2.2.2.2.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">w2v2-lg-slf</span><span id="S3.T1.2.2.2.2.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.2.2.2.4.1" class="ltx_text" style="font-size:90%;">(</span>Xu et al.<span id="S3.T1.2.2.2.2.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib55" title="" class="ltx_ref">2021</a><span id="S3.T1.2.2.2.2.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.2.2.3.1" class="ltx_text" style="font-size:90%;">60,000</span></td>
<td id="S3.T1.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.2.2.4.1" class="ltx_text" style="font-size:90%;">317</span></td>
<td id="S3.T1.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.2.2.5.1" class="ltx_text" style="font-size:90%;">1.8</span></td>
</tr>
<tr id="S3.T1.2.3.3" class="ltx_tr">
<td id="S3.T1.2.3.3.1" class="ltx_td ltx_align_left">
<span id="S3.T1.2.3.3.1.1" class="ltx_text" style="font-size:90%;">wav2vec2-large-robust-ft-libri-960h (</span><span id="S3.T1.2.3.3.1.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">w2v2-lg-rob</span><span id="S3.T1.2.3.3.1.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.3.3.1.4.1" class="ltx_text" style="font-size:90%;">(</span>Hsu et al.<span id="S3.T1.2.3.3.1.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib20" title="" class="ltx_ref">2021b</a><span id="S3.T1.2.3.3.1.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.3.3.2" class="ltx_td ltx_align_center"><span id="S3.T1.2.3.3.2.1" class="ltx_text" style="font-size:90%;">63,000</span></td>
<td id="S3.T1.2.3.3.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.3.3.3.1" class="ltx_text" style="font-size:90%;">317</span></td>
<td id="S3.T1.2.3.3.4" class="ltx_td ltx_align_center"><span id="S3.T1.2.3.3.4.1" class="ltx_text" style="font-size:90%;">2.6</span></td>
</tr>
<tr id="S3.T1.2.4.4" class="ltx_tr">
<td id="S3.T1.2.4.4.1" class="ltx_td ltx_align_left">
<span id="S3.T1.2.4.4.1.1" class="ltx_text" style="font-size:90%;">hubert-large-ls960-ft (</span><span id="S3.T1.2.4.4.1.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">hubt-lg</span><span id="S3.T1.2.4.4.1.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.4.4.1.4.1" class="ltx_text" style="font-size:90%;">(</span>Hsu et al.<span id="S3.T1.2.4.4.1.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib19" title="" class="ltx_ref">2021a</a><span id="S3.T1.2.4.4.1.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.4.4.2" class="ltx_td ltx_align_center"><span id="S3.T1.2.4.4.2.1" class="ltx_text" style="font-size:90%;">60,000</span></td>
<td id="S3.T1.2.4.4.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.4.4.3.1" class="ltx_text" style="font-size:90%;">300</span></td>
<td id="S3.T1.2.4.4.4" class="ltx_td ltx_align_center"><span id="S3.T1.2.4.4.4.1" class="ltx_text" style="font-size:90%;">2.1</span></td>
</tr>
<tr id="S3.T1.2.5.5" class="ltx_tr">
<td id="S3.T1.2.5.5.1" class="ltx_td ltx_align_left">
<span id="S3.T1.2.5.5.1.1" class="ltx_text" style="font-size:90%;">wav2vec2-base-960h (</span><span id="S3.T1.2.5.5.1.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">w2v2-bs</span><span id="S3.T1.2.5.5.1.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.5.5.1.4.1" class="ltx_text" style="font-size:90%;">(</span>Baevski et al.<span id="S3.T1.2.5.5.1.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib4" title="" class="ltx_ref">2020</a><span id="S3.T1.2.5.5.1.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.5.5.2" class="ltx_td ltx_align_center"><span id="S3.T1.2.5.5.2.1" class="ltx_text" style="font-size:90%;">960</span></td>
<td id="S3.T1.2.5.5.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.5.5.3.1" class="ltx_text" style="font-size:90%;">95</span></td>
<td id="S3.T1.2.5.5.4" class="ltx_td ltx_align_center"><span id="S3.T1.2.5.5.4.1" class="ltx_text" style="font-size:90%;">4.9</span></td>
</tr>
<tr id="S3.T1.2.6.6" class="ltx_tr">
<td id="S3.T1.2.6.6.1" class="ltx_td ltx_align_left">
<span id="S3.T1.2.6.6.1.1" class="ltx_text" style="font-size:90%;">whisper-tiny.en (</span><span id="S3.T1.2.6.6.1.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">wsp-tn.en</span><span id="S3.T1.2.6.6.1.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.6.6.1.4.1" class="ltx_text" style="font-size:90%;">(</span>Radford et al.<span id="S3.T1.2.6.6.1.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib42" title="" class="ltx_ref">2023</a><span id="S3.T1.2.6.6.1.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.6.6.2" class="ltx_td ltx_align_center"><span id="S3.T1.2.6.6.2.1" class="ltx_text" style="font-size:90%;">680,000</span></td>
<td id="S3.T1.2.6.6.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.6.6.3.1" class="ltx_text" style="font-size:90%;">39</span></td>
<td id="S3.T1.2.6.6.4" class="ltx_td ltx_align_center"><span id="S3.T1.2.6.6.4.1" class="ltx_text" style="font-size:90%;">6.4</span></td>
</tr>
<tr id="S3.T1.2.7.7" class="ltx_tr">
<td id="S3.T1.2.7.7.1" class="ltx_td ltx_align_left">
<span id="S3.T1.2.7.7.1.1" class="ltx_text" style="font-size:90%;">deepspeech (</span><span id="S3.T1.2.7.7.1.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">ds</span><span id="S3.T1.2.7.7.1.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.7.7.1.4.1" class="ltx_text" style="font-size:90%;">(</span>Amodei et al.<span id="S3.T1.2.7.7.1.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib2" title="" class="ltx_ref">2016</a><span id="S3.T1.2.7.7.1.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.7.7.2" class="ltx_td ltx_align_center"><span id="S3.T1.2.7.7.2.1" class="ltx_text" style="font-size:90%;">960</span></td>
<td id="S3.T1.2.7.7.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.7.7.3.1" class="ltx_text" style="font-size:90%;">86</span></td>
<td id="S3.T1.2.7.7.4" class="ltx_td ltx_align_center"><span id="S3.T1.2.7.7.4.1" class="ltx_text" style="font-size:90%;">17.7</span></td>
</tr>
<tr id="S3.T1.2.8.8" class="ltx_tr">
<td id="S3.T1.2.8.8.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S3.T1.2.8.8.1.1" class="ltx_text" style="font-size:90%;">ES</span></td>
<td id="S3.T1.2.8.8.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T1.2.8.8.2.1" class="ltx_text" style="font-size:90%;">wav2vec2-large-xlsr-53-spanish (</span><span id="S3.T1.2.8.8.2.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">w2v2-lg-es</span><span id="S3.T1.2.8.8.2.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.8.8.2.4.1" class="ltx_text" style="font-size:90%;">(</span>Conneau et al.<span id="S3.T1.2.8.8.2.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib9" title="" class="ltx_ref">2020</a><span id="S3.T1.2.8.8.2.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.8.8.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.8.8.3.1" class="ltx_text" style="font-size:90%;">54350</span></td>
<td id="S3.T1.2.8.8.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.8.8.4.1" class="ltx_text" style="font-size:90%;">315</span></td>
<td id="S3.T1.2.8.8.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.8.8.5.1" class="ltx_text" style="font-size:90%;">6.8</span></td>
</tr>
<tr id="S3.T1.2.9.9" class="ltx_tr">
<td id="S3.T1.2.9.9.1" class="ltx_td ltx_align_left">
<span id="S3.T1.2.9.9.1.1" class="ltx_text" style="font-size:90%;">wav2vec2-base-10k-voxpopuli-ft-es (</span><span id="S3.T1.2.9.9.1.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">w2v2-bs-es</span><span id="S3.T1.2.9.9.1.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.9.9.1.4.1" class="ltx_text" style="font-size:90%;">(</span>Wang et al.<span id="S3.T1.2.9.9.1.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib49" title="" class="ltx_ref">2021b</a><span id="S3.T1.2.9.9.1.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.9.9.2" class="ltx_td ltx_align_center"><span id="S3.T1.2.9.9.2.1" class="ltx_text" style="font-size:90%;">10116</span></td>
<td id="S3.T1.2.9.9.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.9.9.3.1" class="ltx_text" style="font-size:90%;">94</span></td>
<td id="S3.T1.2.9.9.4" class="ltx_td ltx_align_center"><span id="S3.T1.2.9.9.4.1" class="ltx_text" style="font-size:90%;">25.7</span></td>
</tr>
<tr id="S3.T1.2.10.10" class="ltx_tr">
<td id="S3.T1.2.10.10.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S3.T1.2.10.10.1.1" class="ltx_text" style="font-size:90%;">Multi</span></td>
<td id="S3.T1.2.10.10.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T1.2.10.10.2.1" class="ltx_text" style="font-size:90%;">whisper-large-v2 (</span><span id="S3.T1.2.10.10.2.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">wsp-lg</span><span id="S3.T1.2.10.10.2.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.10.10.2.4.1" class="ltx_text" style="font-size:90%;">(</span>Radford et al.<span id="S3.T1.2.10.10.2.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib42" title="" class="ltx_ref">2023</a><span id="S3.T1.2.10.10.2.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.10.10.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.10.10.3.1" class="ltx_text" style="font-size:90%;">680,000</span></td>
<td id="S3.T1.2.10.10.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.10.10.4.1" class="ltx_text" style="font-size:90%;">1.550</span></td>
<td id="S3.T1.2.10.10.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.2.10.10.5.1" class="ltx_text" style="font-size:90%;">3.9/5.8</span></td>
</tr>
<tr id="S3.T1.2.11.11" class="ltx_tr">
<td id="S3.T1.2.11.11.1" class="ltx_td ltx_align_left">
<span id="S3.T1.2.11.11.1.1" class="ltx_text" style="font-size:90%;">whisper-tiny (</span><span id="S3.T1.2.11.11.1.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">wsp-tn</span><span id="S3.T1.2.11.11.1.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.11.11.1.4.1" class="ltx_text" style="font-size:90%;">(</span>Radford et al.<span id="S3.T1.2.11.11.1.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib42" title="" class="ltx_ref">2023</a><span id="S3.T1.2.11.11.1.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.11.11.2" class="ltx_td ltx_align_center"><span id="S3.T1.2.11.11.2.1" class="ltx_text" style="font-size:90%;">680000</span></td>
<td id="S3.T1.2.11.11.3" class="ltx_td ltx_align_center"><span id="S3.T1.2.11.11.3.1" class="ltx_text" style="font-size:90%;">39</span></td>
<td id="S3.T1.2.11.11.4" class="ltx_td ltx_align_center"><span id="S3.T1.2.11.11.4.1" class="ltx_text" style="font-size:90%;">8.2/23.3</span></td>
</tr>
<tr id="S3.T1.2.12.12" class="ltx_tr">
<td id="S3.T1.2.12.12.1" class="ltx_td ltx_border_bb"></td>
<td id="S3.T1.2.12.12.2" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S3.T1.2.12.12.2.1" class="ltx_text" style="font-size:90%;">mms-1b-fl102 (</span><span id="S3.T1.2.12.12.2.2" class="ltx_text ltx_font_sansserif" style="font-size:90%;">mms</span><span id="S3.T1.2.12.12.2.3" class="ltx_text" style="font-size:90%;">) </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T1.2.12.12.2.4.1" class="ltx_text" style="font-size:90%;">(</span>Pratap et al.<span id="S3.T1.2.12.12.2.5.2.1.1" class="ltx_text" style="font-size:90%;">, </span><a href="#bib.bib41" title="" class="ltx_ref">2023</a><span id="S3.T1.2.12.12.2.6.3" class="ltx_text" style="font-size:90%;">)</span></cite>
</td>
<td id="S3.T1.2.12.12.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.2.12.12.3.1" class="ltx_text" style="font-size:90%;">55000</span></td>
<td id="S3.T1.2.12.12.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.2.12.12.4.1" class="ltx_text" style="font-size:90%;">964</span></td>
<td id="S3.T1.2.12.12.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.2.12.12.5.1" class="ltx_text" style="font-size:90%;">15.4/15.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Models used in our evaluations. The model names correspond to the names of their pretrained checkpoints in the Huggingface library (<a target="_blank" href="https://huggingface.co/models" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/models</a>). The abbreviations of these names are in the parentheses after them. Some of the unilingual models are pre-trained on multilingual data but are fine-tuned on only one language and thus can not transcribe any other language. Multilingual models have been pre-trained and fine-tuned on multiple languages so the same DNN can transcribe several languages. The WER of multilingual models is presented as English/Spanish</figcaption>
</figure>
</section>
<section id="S3.SS5.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">3.5.2. Normalized Word Error Rate (NWER)
<br class="ltx_break">
</h4>

<div id="S3.SS5.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS5.SSS0.Px2.p1.1" class="ltx_p">Since our benchmark consists of several corruptions, each at several levels of severity, it is intractable to compare the WER of each model for each corruption-severity pair. We therefore require an aggregate metric to summarize the WER for all the pairs. Since all the corruption-severity pairs do not present the same level of difficulty, simply summing or averaging the WERs over all the pairs will not present an accurate picture of the model’s robustness. Ideally, we should penalize errors on easier corruption-severity pairs more than errors on harder pairs.</p>
</div>
<div id="S3.SS5.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS5.SSS0.Px2.p2.1" class="ltx_p">To incorporate the difficulty of the various corruption-severity pairs, we follow the approach of <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Dietterich, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, and compute the Normalized Word Error Rate (NWER). NWER is computed as a weighted sum of the WERs corresponding to the various corruption-severity pairs, where the weight is the inverse of the difficulty of the corruption-severity pairs. Following <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Dietterich, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, we use the WER of a baseline model (<math id="S3.SS5.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="M_{\text{base}}" display="inline"><semantics id="S3.SS5.SSS0.Px2.p2.1.m1.1a"><msub id="S3.SS5.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.2" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.2.cmml">M</mi><mtext id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3a.cmml">base</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.1.m1.1b"><apply id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.2">𝑀</ci><ci id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3a.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3">base</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.1.m1.1c">M_{\text{base}}</annotation></semantics></math>) as an estimate of the difficulty. This way errors on easier corruption-severity pairs are penalized more heavily than errors on more difficult corruption-severity pairs, when the difficulty is measured by the baseline model performance. Thus, NWER can be formally defined as</p>
<table id="A2.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2.m1.13" class="ltx_Math" alttext="\displaystyle NWER^{M}_{c,s}(\mathcal{X},\mathcal{R}):=\frac{WER^{M}_{c,s}(\mathcal{X},\mathcal{R})}{WER^{M_{\text{base}}}_{c,s}(\mathcal{X},\mathcal{R})}," display="inline"><semantics id="S3.E2.m1.13a"><mrow id="S3.E2.m1.13.13.1" xref="S3.E2.m1.13.13.1.1.cmml"><mrow id="S3.E2.m1.13.13.1.1" xref="S3.E2.m1.13.13.1.1.cmml"><mrow id="S3.E2.m1.13.13.1.1.2" xref="S3.E2.m1.13.13.1.1.2.cmml"><mi id="S3.E2.m1.13.13.1.1.2.2" xref="S3.E2.m1.13.13.1.1.2.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.13.13.1.1.2.1" xref="S3.E2.m1.13.13.1.1.2.1.cmml">​</mo><mi id="S3.E2.m1.13.13.1.1.2.3" xref="S3.E2.m1.13.13.1.1.2.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.13.13.1.1.2.1a" xref="S3.E2.m1.13.13.1.1.2.1.cmml">​</mo><mi id="S3.E2.m1.13.13.1.1.2.4" xref="S3.E2.m1.13.13.1.1.2.4.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.13.13.1.1.2.1b" xref="S3.E2.m1.13.13.1.1.2.1.cmml">​</mo><msubsup id="S3.E2.m1.13.13.1.1.2.5" xref="S3.E2.m1.13.13.1.1.2.5.cmml"><mi id="S3.E2.m1.13.13.1.1.2.5.2.2" xref="S3.E2.m1.13.13.1.1.2.5.2.2.cmml">R</mi><mrow id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">c</mi><mo id="S3.E2.m1.2.2.2.4.1" xref="S3.E2.m1.2.2.2.3.cmml">,</mo><mi id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">s</mi></mrow><mi id="S3.E2.m1.13.13.1.1.2.5.2.3" xref="S3.E2.m1.13.13.1.1.2.5.2.3.cmml">M</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E2.m1.13.13.1.1.2.1c" xref="S3.E2.m1.13.13.1.1.2.1.cmml">​</mo><mrow id="S3.E2.m1.13.13.1.1.2.6.2" xref="S3.E2.m1.13.13.1.1.2.6.1.cmml"><mo stretchy="false" id="S3.E2.m1.13.13.1.1.2.6.2.1" xref="S3.E2.m1.13.13.1.1.2.6.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.11.11" xref="S3.E2.m1.11.11.cmml">𝒳</mi><mo id="S3.E2.m1.13.13.1.1.2.6.2.2" xref="S3.E2.m1.13.13.1.1.2.6.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.12.12" xref="S3.E2.m1.12.12.cmml">ℛ</mi><mo rspace="0.278em" stretchy="false" id="S3.E2.m1.13.13.1.1.2.6.2.3" xref="S3.E2.m1.13.13.1.1.2.6.1.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S3.E2.m1.13.13.1.1.1" xref="S3.E2.m1.13.13.1.1.1.cmml">:=</mo><mstyle displaystyle="true" id="S3.E2.m1.10.10" xref="S3.E2.m1.10.10.cmml"><mfrac id="S3.E2.m1.10.10a" xref="S3.E2.m1.10.10.cmml"><mrow id="S3.E2.m1.6.6.4" xref="S3.E2.m1.6.6.4.cmml"><mi id="S3.E2.m1.6.6.4.6" xref="S3.E2.m1.6.6.4.6.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.6.6.4.5" xref="S3.E2.m1.6.6.4.5.cmml">​</mo><mi id="S3.E2.m1.6.6.4.7" xref="S3.E2.m1.6.6.4.7.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.6.6.4.5a" xref="S3.E2.m1.6.6.4.5.cmml">​</mo><msubsup id="S3.E2.m1.6.6.4.8" xref="S3.E2.m1.6.6.4.8.cmml"><mi id="S3.E2.m1.6.6.4.8.2.2" xref="S3.E2.m1.6.6.4.8.2.2.cmml">R</mi><mrow id="S3.E2.m1.4.4.2.2.2.4" xref="S3.E2.m1.4.4.2.2.2.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.cmml">c</mi><mo id="S3.E2.m1.4.4.2.2.2.4.1" xref="S3.E2.m1.4.4.2.2.2.3.cmml">,</mo><mi id="S3.E2.m1.4.4.2.2.2.2" xref="S3.E2.m1.4.4.2.2.2.2.cmml">s</mi></mrow><mi id="S3.E2.m1.6.6.4.8.2.3" xref="S3.E2.m1.6.6.4.8.2.3.cmml">M</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E2.m1.6.6.4.5b" xref="S3.E2.m1.6.6.4.5.cmml">​</mo><mrow id="S3.E2.m1.6.6.4.9.2" xref="S3.E2.m1.6.6.4.9.1.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.4.9.2.1" xref="S3.E2.m1.6.6.4.9.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.5.5.3.3" xref="S3.E2.m1.5.5.3.3.cmml">𝒳</mi><mo id="S3.E2.m1.6.6.4.9.2.2" xref="S3.E2.m1.6.6.4.9.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.6.6.4.4" xref="S3.E2.m1.6.6.4.4.cmml">ℛ</mi><mo stretchy="false" id="S3.E2.m1.6.6.4.9.2.3" xref="S3.E2.m1.6.6.4.9.1.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.10.10.8" xref="S3.E2.m1.10.10.8.cmml"><mi id="S3.E2.m1.10.10.8.6" xref="S3.E2.m1.10.10.8.6.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.10.10.8.5" xref="S3.E2.m1.10.10.8.5.cmml">​</mo><mi id="S3.E2.m1.10.10.8.7" xref="S3.E2.m1.10.10.8.7.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.10.10.8.5a" xref="S3.E2.m1.10.10.8.5.cmml">​</mo><msubsup id="S3.E2.m1.10.10.8.8" xref="S3.E2.m1.10.10.8.8.cmml"><mi id="S3.E2.m1.10.10.8.8.2.2" xref="S3.E2.m1.10.10.8.8.2.2.cmml">R</mi><mrow id="S3.E2.m1.8.8.6.2.2.4" xref="S3.E2.m1.8.8.6.2.2.3.cmml"><mi id="S3.E2.m1.7.7.5.1.1.1" xref="S3.E2.m1.7.7.5.1.1.1.cmml">c</mi><mo id="S3.E2.m1.8.8.6.2.2.4.1" xref="S3.E2.m1.8.8.6.2.2.3.cmml">,</mo><mi id="S3.E2.m1.8.8.6.2.2.2" xref="S3.E2.m1.8.8.6.2.2.2.cmml">s</mi></mrow><msub id="S3.E2.m1.10.10.8.8.2.3" xref="S3.E2.m1.10.10.8.8.2.3.cmml"><mi id="S3.E2.m1.10.10.8.8.2.3.2" xref="S3.E2.m1.10.10.8.8.2.3.2.cmml">M</mi><mtext id="S3.E2.m1.10.10.8.8.2.3.3" xref="S3.E2.m1.10.10.8.8.2.3.3a.cmml">base</mtext></msub></msubsup><mo lspace="0em" rspace="0em" id="S3.E2.m1.10.10.8.5b" xref="S3.E2.m1.10.10.8.5.cmml">​</mo><mrow id="S3.E2.m1.10.10.8.9.2" xref="S3.E2.m1.10.10.8.9.1.cmml"><mo stretchy="false" id="S3.E2.m1.10.10.8.9.2.1" xref="S3.E2.m1.10.10.8.9.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.9.9.7.3" xref="S3.E2.m1.9.9.7.3.cmml">𝒳</mi><mo id="S3.E2.m1.10.10.8.9.2.2" xref="S3.E2.m1.10.10.8.9.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.10.10.8.4" xref="S3.E2.m1.10.10.8.4.cmml">ℛ</mi><mo stretchy="false" id="S3.E2.m1.10.10.8.9.2.3" xref="S3.E2.m1.10.10.8.9.1.cmml">)</mo></mrow></mrow></mfrac></mstyle></mrow><mo id="S3.E2.m1.13.13.1.2" xref="S3.E2.m1.13.13.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.13b"><apply id="S3.E2.m1.13.13.1.1.cmml" xref="S3.E2.m1.13.13.1"><csymbol cd="latexml" id="S3.E2.m1.13.13.1.1.1.cmml" xref="S3.E2.m1.13.13.1.1.1">assign</csymbol><apply id="S3.E2.m1.13.13.1.1.2.cmml" xref="S3.E2.m1.13.13.1.1.2"><times id="S3.E2.m1.13.13.1.1.2.1.cmml" xref="S3.E2.m1.13.13.1.1.2.1"></times><ci id="S3.E2.m1.13.13.1.1.2.2.cmml" xref="S3.E2.m1.13.13.1.1.2.2">𝑁</ci><ci id="S3.E2.m1.13.13.1.1.2.3.cmml" xref="S3.E2.m1.13.13.1.1.2.3">𝑊</ci><ci id="S3.E2.m1.13.13.1.1.2.4.cmml" xref="S3.E2.m1.13.13.1.1.2.4">𝐸</ci><apply id="S3.E2.m1.13.13.1.1.2.5.cmml" xref="S3.E2.m1.13.13.1.1.2.5"><csymbol cd="ambiguous" id="S3.E2.m1.13.13.1.1.2.5.1.cmml" xref="S3.E2.m1.13.13.1.1.2.5">subscript</csymbol><apply id="S3.E2.m1.13.13.1.1.2.5.2.cmml" xref="S3.E2.m1.13.13.1.1.2.5"><csymbol cd="ambiguous" id="S3.E2.m1.13.13.1.1.2.5.2.1.cmml" xref="S3.E2.m1.13.13.1.1.2.5">superscript</csymbol><ci id="S3.E2.m1.13.13.1.1.2.5.2.2.cmml" xref="S3.E2.m1.13.13.1.1.2.5.2.2">𝑅</ci><ci id="S3.E2.m1.13.13.1.1.2.5.2.3.cmml" xref="S3.E2.m1.13.13.1.1.2.5.2.3">𝑀</ci></apply><list id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.4"><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">𝑐</ci><ci id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2">𝑠</ci></list></apply><interval closure="open" id="S3.E2.m1.13.13.1.1.2.6.1.cmml" xref="S3.E2.m1.13.13.1.1.2.6.2"><ci id="S3.E2.m1.11.11.cmml" xref="S3.E2.m1.11.11">𝒳</ci><ci id="S3.E2.m1.12.12.cmml" xref="S3.E2.m1.12.12">ℛ</ci></interval></apply><apply id="S3.E2.m1.10.10.cmml" xref="S3.E2.m1.10.10"><divide id="S3.E2.m1.10.10.9.cmml" xref="S3.E2.m1.10.10"></divide><apply id="S3.E2.m1.6.6.4.cmml" xref="S3.E2.m1.6.6.4"><times id="S3.E2.m1.6.6.4.5.cmml" xref="S3.E2.m1.6.6.4.5"></times><ci id="S3.E2.m1.6.6.4.6.cmml" xref="S3.E2.m1.6.6.4.6">𝑊</ci><ci id="S3.E2.m1.6.6.4.7.cmml" xref="S3.E2.m1.6.6.4.7">𝐸</ci><apply id="S3.E2.m1.6.6.4.8.cmml" xref="S3.E2.m1.6.6.4.8"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.4.8.1.cmml" xref="S3.E2.m1.6.6.4.8">subscript</csymbol><apply id="S3.E2.m1.6.6.4.8.2.cmml" xref="S3.E2.m1.6.6.4.8"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.4.8.2.1.cmml" xref="S3.E2.m1.6.6.4.8">superscript</csymbol><ci id="S3.E2.m1.6.6.4.8.2.2.cmml" xref="S3.E2.m1.6.6.4.8.2.2">𝑅</ci><ci id="S3.E2.m1.6.6.4.8.2.3.cmml" xref="S3.E2.m1.6.6.4.8.2.3">𝑀</ci></apply><list id="S3.E2.m1.4.4.2.2.2.3.cmml" xref="S3.E2.m1.4.4.2.2.2.4"><ci id="S3.E2.m1.3.3.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1">𝑐</ci><ci id="S3.E2.m1.4.4.2.2.2.2.cmml" xref="S3.E2.m1.4.4.2.2.2.2">𝑠</ci></list></apply><interval closure="open" id="S3.E2.m1.6.6.4.9.1.cmml" xref="S3.E2.m1.6.6.4.9.2"><ci id="S3.E2.m1.5.5.3.3.cmml" xref="S3.E2.m1.5.5.3.3">𝒳</ci><ci id="S3.E2.m1.6.6.4.4.cmml" xref="S3.E2.m1.6.6.4.4">ℛ</ci></interval></apply><apply id="S3.E2.m1.10.10.8.cmml" xref="S3.E2.m1.10.10.8"><times id="S3.E2.m1.10.10.8.5.cmml" xref="S3.E2.m1.10.10.8.5"></times><ci id="S3.E2.m1.10.10.8.6.cmml" xref="S3.E2.m1.10.10.8.6">𝑊</ci><ci id="S3.E2.m1.10.10.8.7.cmml" xref="S3.E2.m1.10.10.8.7">𝐸</ci><apply id="S3.E2.m1.10.10.8.8.cmml" xref="S3.E2.m1.10.10.8.8"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.8.8.1.cmml" xref="S3.E2.m1.10.10.8.8">subscript</csymbol><apply id="S3.E2.m1.10.10.8.8.2.cmml" xref="S3.E2.m1.10.10.8.8"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.8.8.2.1.cmml" xref="S3.E2.m1.10.10.8.8">superscript</csymbol><ci id="S3.E2.m1.10.10.8.8.2.2.cmml" xref="S3.E2.m1.10.10.8.8.2.2">𝑅</ci><apply id="S3.E2.m1.10.10.8.8.2.3.cmml" xref="S3.E2.m1.10.10.8.8.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.8.8.2.3.1.cmml" xref="S3.E2.m1.10.10.8.8.2.3">subscript</csymbol><ci id="S3.E2.m1.10.10.8.8.2.3.2.cmml" xref="S3.E2.m1.10.10.8.8.2.3.2">𝑀</ci><ci id="S3.E2.m1.10.10.8.8.2.3.3a.cmml" xref="S3.E2.m1.10.10.8.8.2.3.3"><mtext mathsize="50%" id="S3.E2.m1.10.10.8.8.2.3.3.cmml" xref="S3.E2.m1.10.10.8.8.2.3.3">base</mtext></ci></apply></apply><list id="S3.E2.m1.8.8.6.2.2.3.cmml" xref="S3.E2.m1.8.8.6.2.2.4"><ci id="S3.E2.m1.7.7.5.1.1.1.cmml" xref="S3.E2.m1.7.7.5.1.1.1">𝑐</ci><ci id="S3.E2.m1.8.8.6.2.2.2.cmml" xref="S3.E2.m1.8.8.6.2.2.2">𝑠</ci></list></apply><interval closure="open" id="S3.E2.m1.10.10.8.9.1.cmml" xref="S3.E2.m1.10.10.8.9.2"><ci id="S3.E2.m1.9.9.7.3.cmml" xref="S3.E2.m1.9.9.7.3">𝒳</ci><ci id="S3.E2.m1.10.10.8.4.cmml" xref="S3.E2.m1.10.10.8.4">ℛ</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.13c">\displaystyle NWER^{M}_{c,s}(\mathcal{X},\mathcal{R}):=\frac{WER^{M}_{c,s}(\mathcal{X},\mathcal{R})}{WER^{M_{\text{base}}}_{c,s}(\mathcal{X},\mathcal{R})},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS5.SSS0.Px2.p2.5" class="ltx_p">where <math id="S3.SS5.SSS0.Px2.p2.2.m1.2" class="ltx_Math" alttext="WER^{M}_{c,s}" display="inline"><semantics id="S3.SS5.SSS0.Px2.p2.2.m1.2a"><mrow id="S3.SS5.SSS0.Px2.p2.2.m1.2.3" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.2" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.1" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.1.cmml">​</mo><mi id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.3" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.1a" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.1.cmml">​</mo><msubsup id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.cmml"><mi id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.2" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.2.cmml">R</mi><mrow id="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.4" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.2.m1.1.1.1.1" xref="S3.SS5.SSS0.Px2.p2.2.m1.1.1.1.1.cmml">c</mi><mo id="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.4.1" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.2" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.2.cmml">s</mi></mrow><mi id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.3" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.3.cmml">M</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.2.m1.2b"><apply id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3"><times id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.2">𝑊</ci><ci id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.3">𝐸</ci><apply id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.1.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4">subscript</csymbol><apply id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.1.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4">superscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.2.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.2">𝑅</ci><ci id="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.3.4.2.3">𝑀</ci></apply><list id="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.4"><ci id="S3.SS5.SSS0.Px2.p2.2.m1.1.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.1.1.1.1">𝑐</ci><ci id="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.2.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m1.2.2.2.2">𝑠</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.2.m1.2c">WER^{M}_{c,s}</annotation></semantics></math> and <math id="S3.SS5.SSS0.Px2.p2.3.m2.2" class="ltx_Math" alttext="WER^{M_{\text{base}}}_{c,s}" display="inline"><semantics id="S3.SS5.SSS0.Px2.p2.3.m2.2a"><mrow id="S3.SS5.SSS0.Px2.p2.3.m2.2.3" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.2" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.1" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.1.cmml">​</mo><mi id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.3" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.1a" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.1.cmml">​</mo><msubsup id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.cmml"><mi id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.2" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.2.cmml">R</mi><mrow id="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.4" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.3.m2.1.1.1.1" xref="S3.SS5.SSS0.Px2.p2.3.m2.1.1.1.1.cmml">c</mi><mo id="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.4.1" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.2" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.2.cmml">s</mi></mrow><msub id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.2" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.2.cmml">M</mi><mtext id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.3" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.3a.cmml">base</mtext></msub></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.3.m2.2b"><apply id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3"><times id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.2">𝑊</ci><ci id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.3">𝐸</ci><apply id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.1.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4">subscript</csymbol><apply id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.1.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4">superscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.2.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.2">𝑅</ci><apply id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3">subscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.2">𝑀</ci><ci id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.3a.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.3"><mtext mathsize="50%" id="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.3.4.2.3.3">base</mtext></ci></apply></apply><list id="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.4"><ci id="S3.SS5.SSS0.Px2.p2.3.m2.1.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.1.1.1.1">𝑐</ci><ci id="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.2.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m2.2.2.2.2">𝑠</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.3.m2.2c">WER^{M_{\text{base}}}_{c,s}</annotation></semantics></math> are the WERs of target and baseline models under corruption <math id="S3.SS5.SSS0.Px2.p2.4.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS5.SSS0.Px2.p2.4.m3.1a"><mi id="S3.SS5.SSS0.Px2.p2.4.m3.1.1" xref="S3.SS5.SSS0.Px2.p2.4.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.4.m3.1b"><ci id="S3.SS5.SSS0.Px2.p2.4.m3.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m3.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.4.m3.1c">c</annotation></semantics></math> at severity <math id="S3.SS5.SSS0.Px2.p2.5.m4.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS5.SSS0.Px2.p2.5.m4.1a"><mi id="S3.SS5.SSS0.Px2.p2.5.m4.1.1" xref="S3.SS5.SSS0.Px2.p2.5.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.5.m4.1b"><ci id="S3.SS5.SSS0.Px2.p2.5.m4.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m4.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.5.m4.1c">s</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS5.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">3.5.3. Word Error Rate Variance (WERV)
<br class="ltx_break">
</h4>

<div id="S3.SS5.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS5.SSS0.Px3.p1.1" class="ltx_p">To evaluate the stability of a target model’s predictions with corrupted inputs, we compute the variance over the model’s predictions on repeated random noise sampled from a fixed distribution. We differ from <cite class="ltx_cite ltx_citemacro_citet">Hendrycks &amp; Dietterich (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite> who use the co-called flip rate, since their metric is only compatible with class predictions, not with sequence predictions as we have in ASR.
Instead, we propose to compute the variance in the WER over repeated random samples of corruption. Similar in aim to <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks &amp; Dietterich, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, this yields a metric that measures how much the model’s predictions fluctuate in presence of noise.</p>
</div>
<div id="S3.SS5.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS5.SSS0.Px3.p2.7" class="ltx_p">Concretely, given a set of utterances <math id="S3.SS5.SSS0.Px3.p2.1.m1.3" class="ltx_Math" alttext="\mathcal{X}=\{x_{1},...,x_{N}\}" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.1.m1.3a"><mrow id="S3.SS5.SSS0.Px3.p2.1.m1.3.3" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.4" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.4.cmml">𝒳</mi><mo id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.3" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.3" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.3.cmml">{</mo><msub id="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1" xref="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.2" xref="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.3" xref="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.4" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS5.SSS0.Px3.p2.1.m1.1.1" xref="S3.SS5.SSS0.Px3.p2.1.m1.1.1.cmml">…</mi><mo id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.5" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.2" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.2.cmml">x</mi><mi id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.3" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.3.cmml">N</mi></msub><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.6" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.1.m1.3b"><apply id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3"><eq id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.3.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.3"></eq><ci id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.4.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.4">𝒳</ci><set id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.3.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2"><apply id="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS5.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.1.1">…</ci><apply id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.2">𝑥</ci><ci id="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS5.SSS0.Px3.p2.1.m1.3.3.2.2.2.3">𝑁</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.1.m1.3c">\mathcal{X}=\{x_{1},...,x_{N}\}</annotation></semantics></math>, we corrupt each utterance, <math id="S3.SS5.SSS0.Px3.p2.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.2.m2.1a"><msub id="S3.SS5.SSS0.Px3.p2.2.m2.1.1" xref="S3.SS5.SSS0.Px3.p2.2.m2.1.1.cmml"><mi id="S3.SS5.SSS0.Px3.p2.2.m2.1.1.2" xref="S3.SS5.SSS0.Px3.p2.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS5.SSS0.Px3.p2.2.m2.1.1.3" xref="S3.SS5.SSS0.Px3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.2.m2.1b"><apply id="S3.SS5.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.2.m2.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px3.p2.2.m2.1.1.2.cmml" xref="S3.SS5.SSS0.Px3.p2.2.m2.1.1.2">𝑥</ci><ci id="S3.SS5.SSS0.Px3.p2.2.m2.1.1.3.cmml" xref="S3.SS5.SSS0.Px3.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.2.m2.1c">x_{i}</annotation></semantics></math>, with <math id="S3.SS5.SSS0.Px3.p2.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.3.m3.1a"><mi id="S3.SS5.SSS0.Px3.p2.3.m3.1.1" xref="S3.SS5.SSS0.Px3.p2.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.3.m3.1b"><ci id="S3.SS5.SSS0.Px3.p2.3.m3.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.3.m3.1c">K</annotation></semantics></math> random corruption samples to obtain <math id="S3.SS5.SSS0.Px3.p2.4.m4.5" class="ltx_Math" alttext="\tilde{x}_{i}^{(1)},...,\tilde{x}_{i}^{(K)}" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.4.m4.5a"><mrow id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.3.cmml"><msubsup id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.cmml"><mover accent="true" id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.cmml"><mi id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.2" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.2.cmml">x</mi><mo id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.1" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.1.cmml">~</mo></mover><mi id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.3" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.3.cmml">i</mi><mrow id="S3.SS5.SSS0.Px3.p2.4.m4.1.1.1.3" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.4.m4.1.1.1.3.1" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.cmml">(</mo><mn id="S3.SS5.SSS0.Px3.p2.4.m4.1.1.1.1" xref="S3.SS5.SSS0.Px3.p2.4.m4.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.4.m4.1.1.1.3.2" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.3" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS5.SSS0.Px3.p2.4.m4.3.3" xref="S3.SS5.SSS0.Px3.p2.4.m4.3.3.cmml">…</mi><mo id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.4" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.3.cmml">,</mo><msubsup id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.cmml"><mover accent="true" id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.cmml"><mi id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.2" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.2.cmml">x</mi><mo id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.1" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.1.cmml">~</mo></mover><mi id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.3" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.3.cmml">i</mi><mrow id="S3.SS5.SSS0.Px3.p2.4.m4.2.2.1.3" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.4.m4.2.2.1.3.1" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.cmml">(</mo><mi id="S3.SS5.SSS0.Px3.p2.4.m4.2.2.1.1" xref="S3.SS5.SSS0.Px3.p2.4.m4.2.2.1.1.cmml">K</mi><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.4.m4.2.2.1.3.2" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.cmml">)</mo></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.4.m4.5b"><list id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.3.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2"><apply id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1">superscript</csymbol><apply id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1">subscript</csymbol><apply id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2"><ci id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.1">~</ci><ci id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.2.2">𝑥</ci></apply><ci id="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.3.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.4.4.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.SS5.SSS0.Px3.p2.4.m4.1.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.1.1.1.1">1</cn></apply><ci id="S3.SS5.SSS0.Px3.p2.4.m4.3.3.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.3.3">…</ci><apply id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2">superscript</csymbol><apply id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2">subscript</csymbol><apply id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2"><ci id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.1">~</ci><ci id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.2.2">𝑥</ci></apply><ci id="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.3.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.5.5.2.2.2.3">𝑖</ci></apply><ci id="S3.SS5.SSS0.Px3.p2.4.m4.2.2.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.4.m4.2.2.1.1">𝐾</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.4.m4.5c">\tilde{x}_{i}^{(1)},...,\tilde{x}_{i}^{(K)}</annotation></semantics></math>. We organize the corrupted samples into <math id="S3.SS5.SSS0.Px3.p2.5.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.5.m5.1a"><mi id="S3.SS5.SSS0.Px3.p2.5.m5.1.1" xref="S3.SS5.SSS0.Px3.p2.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.5.m5.1b"><ci id="S3.SS5.SSS0.Px3.p2.5.m5.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.5.m5.1c">K</annotation></semantics></math> datasets, <math id="S3.SS5.SSS0.Px3.p2.6.m6.5" class="ltx_Math" alttext="\tilde{\mathcal{X}}^{(1)},...,\tilde{\mathcal{X}}{(K)}" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.6.m6.5a"><mrow id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.3.cmml"><msup id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.cmml"><mover accent="true" id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.2.cmml">𝒳</mi><mo id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.1" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.1.cmml">~</mo></mover><mrow id="S3.SS5.SSS0.Px3.p2.6.m6.1.1.1.3" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.6.m6.1.1.1.3.1" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.cmml">(</mo><mn id="S3.SS5.SSS0.Px3.p2.6.m6.1.1.1.1" xref="S3.SS5.SSS0.Px3.p2.6.m6.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.6.m6.1.1.1.3.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.cmml">)</mo></mrow></msup><mo id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.3" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS5.SSS0.Px3.p2.6.m6.3.3" xref="S3.SS5.SSS0.Px3.p2.6.m6.3.3.cmml">…</mi><mo id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.4" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.3.cmml">,</mo><mrow id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.cmml"><mover accent="true" id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.2.cmml">𝒳</mi><mo id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.1" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.1" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.1.cmml">​</mo><mrow id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.3.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.3.2.1" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.cmml">(</mo><mi id="S3.SS5.SSS0.Px3.p2.6.m6.2.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.2.2.cmml">K</mi><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.3.2.2" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.6.m6.5b"><list id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.3.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2"><apply id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1">superscript</csymbol><apply id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2"><ci id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.1">~</ci><ci id="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.4.4.1.1.2.2">𝒳</ci></apply><cn type="integer" id="S3.SS5.SSS0.Px3.p2.6.m6.1.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.1.1.1.1">1</cn></apply><ci id="S3.SS5.SSS0.Px3.p2.6.m6.3.3.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.3.3">…</ci><apply id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2"><times id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.1"></times><apply id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2"><ci id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.1">~</ci><ci id="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.5.5.2.2.2.2">𝒳</ci></apply><ci id="S3.SS5.SSS0.Px3.p2.6.m6.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.6.m6.2.2">𝐾</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.6.m6.5c">\tilde{\mathcal{X}}^{(1)},...,\tilde{\mathcal{X}}{(K)}</annotation></semantics></math>, where <math id="S3.SS5.SSS0.Px3.p2.7.m7.6" class="ltx_Math" alttext="{\tilde{\mathcal{X}}^{(k)}=\{x_{1}^{(k)},...,x_{N}^{(k)}\}}" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.7.m7.6a"><mrow id="S3.SS5.SSS0.Px3.p2.7.m7.6.6" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.cmml"><msup id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.cmml"><mover accent="true" id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.2.cmml">𝒳</mi><mo id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.1" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.1.cmml">~</mo></mover><mrow id="S3.SS5.SSS0.Px3.p2.7.m7.1.1.1.3" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.7.m7.1.1.1.3.1" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.cmml">(</mo><mi id="S3.SS5.SSS0.Px3.p2.7.m7.1.1.1.1" xref="S3.SS5.SSS0.Px3.p2.7.m7.1.1.1.1.cmml">k</mi><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.7.m7.1.1.1.3.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.cmml">)</mo></mrow></msup><mo id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.3" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.3.cmml">=</mo><mrow id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.3" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.3.cmml">{</mo><msubsup id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.cmml"><mi id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.2.cmml">x</mi><mn id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.3" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.3.cmml">1</mn><mrow id="S3.SS5.SSS0.Px3.p2.7.m7.2.2.1.3" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.7.m7.2.2.1.3.1" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.cmml">(</mo><mi id="S3.SS5.SSS0.Px3.p2.7.m7.2.2.1.1" xref="S3.SS5.SSS0.Px3.p2.7.m7.2.2.1.1.cmml">k</mi><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.7.m7.2.2.1.3.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.4" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS5.SSS0.Px3.p2.7.m7.4.4" xref="S3.SS5.SSS0.Px3.p2.7.m7.4.4.cmml">…</mi><mo id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.5" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.3.cmml">,</mo><msubsup id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.cmml"><mi id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.2.cmml">x</mi><mi id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.3" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.3.cmml">N</mi><mrow id="S3.SS5.SSS0.Px3.p2.7.m7.3.3.1.3" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.cmml"><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.7.m7.3.3.1.3.1" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.cmml">(</mo><mi id="S3.SS5.SSS0.Px3.p2.7.m7.3.3.1.1" xref="S3.SS5.SSS0.Px3.p2.7.m7.3.3.1.1.cmml">k</mi><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.7.m7.3.3.1.3.2" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.cmml">)</mo></mrow></msubsup><mo stretchy="false" id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.6" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.7.m7.6b"><apply id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6"><eq id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.3.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.3"></eq><apply id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4">superscript</csymbol><apply id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2"><ci id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.1">~</ci><ci id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.4.2.2">𝒳</ci></apply><ci id="S3.SS5.SSS0.Px3.p2.7.m7.1.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.1.1.1.1">𝑘</ci></apply><set id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.3.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2"><apply id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1">superscript</csymbol><apply id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.2">𝑥</ci><cn type="integer" id="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.3.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.5.5.1.1.1.2.3">1</cn></apply><ci id="S3.SS5.SSS0.Px3.p2.7.m7.2.2.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.2.2.1.1">𝑘</ci></apply><ci id="S3.SS5.SSS0.Px3.p2.7.m7.4.4.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.4.4">…</ci><apply id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2">superscript</csymbol><apply id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.2.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.2">𝑥</ci><ci id="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.3.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.6.6.2.2.2.2.3">𝑁</ci></apply><ci id="S3.SS5.SSS0.Px3.p2.7.m7.3.3.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.7.m7.3.3.1.1">𝑘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.7.m7.6c">{\tilde{\mathcal{X}}^{(k)}=\{x_{1}^{(k)},...,x_{N}^{(k)}\}}</annotation></semantics></math>.
WERV can now be computed as:
</p>
<table id="A2.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.5" class="ltx_Math" alttext="\displaystyle\text{WERV}(\tilde{\mathcal{X}}^{(1:k)},\mathcal{R}):=Var_{k:1\rightarrow K}\left[WER(\tilde{\mathcal{X}}^{(k)},r_{i})\right]\vspace{-8mm}" display="inline"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5.5" xref="S3.E3.m1.5.5.cmml"><mrow id="S3.E3.m1.4.4.1" xref="S3.E3.m1.4.4.1.cmml"><mtext id="S3.E3.m1.4.4.1.3" xref="S3.E3.m1.4.4.1.3a.cmml">WERV</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.2" xref="S3.E3.m1.4.4.1.2.cmml">​</mo><mrow id="S3.E3.m1.4.4.1.1.1" xref="S3.E3.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.2" xref="S3.E3.m1.4.4.1.1.2.cmml">(</mo><msup id="S3.E3.m1.4.4.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.4.4.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.4.4.1.1.1.1.2.2" xref="S3.E3.m1.4.4.1.1.1.1.2.2.cmml">𝒳</mi><mo id="S3.E3.m1.4.4.1.1.1.1.2.1" xref="S3.E3.m1.4.4.1.1.1.1.2.1.cmml">~</mo></mover><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mn id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml">:</mo><mi id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml">k</mi></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="S3.E3.m1.4.4.1.1.1.3" xref="S3.E3.m1.4.4.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">ℛ</mi><mo rspace="0.278em" stretchy="false" id="S3.E3.m1.4.4.1.1.1.4" xref="S3.E3.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S3.E3.m1.5.5.3" xref="S3.E3.m1.5.5.3.cmml">:=</mo><mrow id="S3.E3.m1.5.5.2" xref="S3.E3.m1.5.5.2.cmml"><mi id="S3.E3.m1.5.5.2.3" xref="S3.E3.m1.5.5.2.3.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.2.2" xref="S3.E3.m1.5.5.2.2.cmml">​</mo><mi id="S3.E3.m1.5.5.2.4" xref="S3.E3.m1.5.5.2.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.2.2a" xref="S3.E3.m1.5.5.2.2.cmml">​</mo><msub id="S3.E3.m1.5.5.2.5" xref="S3.E3.m1.5.5.2.5.cmml"><mi id="S3.E3.m1.5.5.2.5.2" xref="S3.E3.m1.5.5.2.5.2.cmml">r</mi><mrow id="S3.E3.m1.5.5.2.5.3" xref="S3.E3.m1.5.5.2.5.3.cmml"><mi id="S3.E3.m1.5.5.2.5.3.2" xref="S3.E3.m1.5.5.2.5.3.2.cmml">k</mi><mo lspace="0.278em" rspace="0.278em" id="S3.E3.m1.5.5.2.5.3.1" xref="S3.E3.m1.5.5.2.5.3.1.cmml">:</mo><mrow id="S3.E3.m1.5.5.2.5.3.3" xref="S3.E3.m1.5.5.2.5.3.3.cmml"><mn id="S3.E3.m1.5.5.2.5.3.3.2" xref="S3.E3.m1.5.5.2.5.3.3.2.cmml">1</mn><mo stretchy="false" id="S3.E3.m1.5.5.2.5.3.3.1" xref="S3.E3.m1.5.5.2.5.3.3.1.cmml">→</mo><mi id="S3.E3.m1.5.5.2.5.3.3.3" xref="S3.E3.m1.5.5.2.5.3.3.3.cmml">K</mi></mrow></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.2.2b" xref="S3.E3.m1.5.5.2.2.cmml">​</mo><mrow id="S3.E3.m1.5.5.2.1.1" xref="S3.E3.m1.5.5.2.1.2.cmml"><mo id="S3.E3.m1.5.5.2.1.1.2" xref="S3.E3.m1.5.5.2.1.2.1.cmml">[</mo><mrow id="S3.E3.m1.5.5.2.1.1.1" xref="S3.E3.m1.5.5.2.1.1.1.cmml"><mi id="S3.E3.m1.5.5.2.1.1.1.4" xref="S3.E3.m1.5.5.2.1.1.1.4.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.2.1.1.1.3" xref="S3.E3.m1.5.5.2.1.1.1.3.cmml">​</mo><mi id="S3.E3.m1.5.5.2.1.1.1.5" xref="S3.E3.m1.5.5.2.1.1.1.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.2.1.1.1.3a" xref="S3.E3.m1.5.5.2.1.1.1.3.cmml">​</mo><mi id="S3.E3.m1.5.5.2.1.1.1.6" xref="S3.E3.m1.5.5.2.1.1.1.6.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.2.1.1.1.3b" xref="S3.E3.m1.5.5.2.1.1.1.3.cmml">​</mo><mrow id="S3.E3.m1.5.5.2.1.1.1.2.2" xref="S3.E3.m1.5.5.2.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.2.1.1.1.2.2.3" xref="S3.E3.m1.5.5.2.1.1.1.2.3.cmml">(</mo><msup id="S3.E3.m1.5.5.2.1.1.1.1.1.1" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.5.5.2.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.2" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.2.cmml">𝒳</mi><mo id="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.1" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mrow id="S3.E3.m1.2.2.1.3" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.3.1" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml">k</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.3.2" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="S3.E3.m1.5.5.2.1.1.1.2.2.4" xref="S3.E3.m1.5.5.2.1.1.1.2.3.cmml">,</mo><msub id="S3.E3.m1.5.5.2.1.1.1.2.2.2" xref="S3.E3.m1.5.5.2.1.1.1.2.2.2.cmml"><mi id="S3.E3.m1.5.5.2.1.1.1.2.2.2.2" xref="S3.E3.m1.5.5.2.1.1.1.2.2.2.2.cmml">r</mi><mi id="S3.E3.m1.5.5.2.1.1.1.2.2.2.3" xref="S3.E3.m1.5.5.2.1.1.1.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E3.m1.5.5.2.1.1.1.2.2.5" xref="S3.E3.m1.5.5.2.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.5.5.2.1.1.3" xref="S3.E3.m1.5.5.2.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.5b"><apply id="S3.E3.m1.5.5.cmml" xref="S3.E3.m1.5.5"><csymbol cd="latexml" id="S3.E3.m1.5.5.3.cmml" xref="S3.E3.m1.5.5.3">assign</csymbol><apply id="S3.E3.m1.4.4.1.cmml" xref="S3.E3.m1.4.4.1"><times id="S3.E3.m1.4.4.1.2.cmml" xref="S3.E3.m1.4.4.1.2"></times><ci id="S3.E3.m1.4.4.1.3a.cmml" xref="S3.E3.m1.4.4.1.3"><mtext id="S3.E3.m1.4.4.1.3.cmml" xref="S3.E3.m1.4.4.1.3">WERV</mtext></ci><interval closure="open" id="S3.E3.m1.4.4.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1"><apply id="S3.E3.m1.4.4.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.4.4.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2"><ci id="S3.E3.m1.4.4.1.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.1">~</ci><ci id="S3.E3.m1.4.4.1.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.2">𝒳</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1"><ci id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1">:</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2">1</cn><ci id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3">𝑘</ci></apply></apply><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">ℛ</ci></interval></apply><apply id="S3.E3.m1.5.5.2.cmml" xref="S3.E3.m1.5.5.2"><times id="S3.E3.m1.5.5.2.2.cmml" xref="S3.E3.m1.5.5.2.2"></times><ci id="S3.E3.m1.5.5.2.3.cmml" xref="S3.E3.m1.5.5.2.3">𝑉</ci><ci id="S3.E3.m1.5.5.2.4.cmml" xref="S3.E3.m1.5.5.2.4">𝑎</ci><apply id="S3.E3.m1.5.5.2.5.cmml" xref="S3.E3.m1.5.5.2.5"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.2.5.1.cmml" xref="S3.E3.m1.5.5.2.5">subscript</csymbol><ci id="S3.E3.m1.5.5.2.5.2.cmml" xref="S3.E3.m1.5.5.2.5.2">𝑟</ci><apply id="S3.E3.m1.5.5.2.5.3.cmml" xref="S3.E3.m1.5.5.2.5.3"><ci id="S3.E3.m1.5.5.2.5.3.1.cmml" xref="S3.E3.m1.5.5.2.5.3.1">:</ci><ci id="S3.E3.m1.5.5.2.5.3.2.cmml" xref="S3.E3.m1.5.5.2.5.3.2">𝑘</ci><apply id="S3.E3.m1.5.5.2.5.3.3.cmml" xref="S3.E3.m1.5.5.2.5.3.3"><ci id="S3.E3.m1.5.5.2.5.3.3.1.cmml" xref="S3.E3.m1.5.5.2.5.3.3.1">→</ci><cn type="integer" id="S3.E3.m1.5.5.2.5.3.3.2.cmml" xref="S3.E3.m1.5.5.2.5.3.3.2">1</cn><ci id="S3.E3.m1.5.5.2.5.3.3.3.cmml" xref="S3.E3.m1.5.5.2.5.3.3.3">𝐾</ci></apply></apply></apply><apply id="S3.E3.m1.5.5.2.1.2.cmml" xref="S3.E3.m1.5.5.2.1.1"><csymbol cd="latexml" id="S3.E3.m1.5.5.2.1.2.1.cmml" xref="S3.E3.m1.5.5.2.1.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.5.5.2.1.1.1.cmml" xref="S3.E3.m1.5.5.2.1.1.1"><times id="S3.E3.m1.5.5.2.1.1.1.3.cmml" xref="S3.E3.m1.5.5.2.1.1.1.3"></times><ci id="S3.E3.m1.5.5.2.1.1.1.4.cmml" xref="S3.E3.m1.5.5.2.1.1.1.4">𝑊</ci><ci id="S3.E3.m1.5.5.2.1.1.1.5.cmml" xref="S3.E3.m1.5.5.2.1.1.1.5">𝐸</ci><ci id="S3.E3.m1.5.5.2.1.1.1.6.cmml" xref="S3.E3.m1.5.5.2.1.1.1.6">𝑅</ci><interval closure="open" id="S3.E3.m1.5.5.2.1.1.1.2.3.cmml" xref="S3.E3.m1.5.5.2.1.1.1.2.2"><apply id="S3.E3.m1.5.5.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.2"><ci id="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.1">~</ci><ci id="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.5.5.2.1.1.1.1.1.1.2.2">𝒳</ci></apply><ci id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1">𝑘</ci></apply><apply id="S3.E3.m1.5.5.2.1.1.1.2.2.2.cmml" xref="S3.E3.m1.5.5.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.2.1.1.1.2.2.2.1.cmml" xref="S3.E3.m1.5.5.2.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E3.m1.5.5.2.1.1.1.2.2.2.2.cmml" xref="S3.E3.m1.5.5.2.1.1.1.2.2.2.2">𝑟</ci><ci id="S3.E3.m1.5.5.2.1.1.1.2.2.2.3.cmml" xref="S3.E3.m1.5.5.2.1.1.1.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.5c">\displaystyle\text{WERV}(\tilde{\mathcal{X}}^{(1:k)},\mathcal{R}):=Var_{k:1\rightarrow K}\left[WER(\tilde{\mathcal{X}}^{(k)},r_{i})\right]\vspace{-8mm}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS5.SSS0.Px3.p2.9" class="ltx_p">where <math id="S3.SS5.SSS0.Px3.p2.8.m1.1" class="ltx_Math" alttext="r_{i}" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.8.m1.1a"><msub id="S3.SS5.SSS0.Px3.p2.8.m1.1.1" xref="S3.SS5.SSS0.Px3.p2.8.m1.1.1.cmml"><mi id="S3.SS5.SSS0.Px3.p2.8.m1.1.1.2" xref="S3.SS5.SSS0.Px3.p2.8.m1.1.1.2.cmml">r</mi><mi id="S3.SS5.SSS0.Px3.p2.8.m1.1.1.3" xref="S3.SS5.SSS0.Px3.p2.8.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.8.m1.1b"><apply id="S3.SS5.SSS0.Px3.p2.8.m1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.8.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.8.m1.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.8.m1.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px3.p2.8.m1.1.1.2.cmml" xref="S3.SS5.SSS0.Px3.p2.8.m1.1.1.2">𝑟</ci><ci id="S3.SS5.SSS0.Px3.p2.8.m1.1.1.3.cmml" xref="S3.SS5.SSS0.Px3.p2.8.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.8.m1.1c">r_{i}</annotation></semantics></math> is the reference transcript for utterance <math id="S3.SS5.SSS0.Px3.p2.9.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS5.SSS0.Px3.p2.9.m2.1a"><msub id="S3.SS5.SSS0.Px3.p2.9.m2.1.1" xref="S3.SS5.SSS0.Px3.p2.9.m2.1.1.cmml"><mi id="S3.SS5.SSS0.Px3.p2.9.m2.1.1.2" xref="S3.SS5.SSS0.Px3.p2.9.m2.1.1.2.cmml">x</mi><mi id="S3.SS5.SSS0.Px3.p2.9.m2.1.1.3" xref="S3.SS5.SSS0.Px3.p2.9.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px3.p2.9.m2.1b"><apply id="S3.SS5.SSS0.Px3.p2.9.m2.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.9.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px3.p2.9.m2.1.1.1.cmml" xref="S3.SS5.SSS0.Px3.p2.9.m2.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px3.p2.9.m2.1.1.2.cmml" xref="S3.SS5.SSS0.Px3.p2.9.m2.1.1.2">𝑥</ci><ci id="S3.SS5.SSS0.Px3.p2.9.m2.1.1.3.cmml" xref="S3.SS5.SSS0.Px3.p2.9.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px3.p2.9.m2.1c">x_{i}</annotation></semantics></math>.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We evaluate several recent and popular ASR DNNs (see Table <a href="#S3.T1" title="Table 1 ‣ 3.5.1. Word Error Rate (WER) ‣ 3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) using <span id="S4.p1.1.1" class="ltx_text ltx_font_typewriter">SRB</span> and analyze the results to uncover fine-grained differences in their robustness to non-adversarial and adversarial input perturbations. Our analysis is two-pronged. First, we focus on the primary goal of <span id="S4.p1.1.2" class="ltx_text ltx_font_typewriter">SRB</span>, which is to measure the robustness of the models to various input perturbations. As a case study, we use <span id="S4.p1.1.3" class="ltx_text ltx_font_typewriter">SRB</span> to evaluate the prediction accuracy and stability of the English ASR models as different perturbations are introduced. As mentioned in § <a href="#S3.SS2" title="3.2 Dataset ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we use English speech from Librispeech <cite class="ltx_cite ltx_citemacro_citep">(Panayotov et al., <a href="#bib.bib37" title="" class="ltx_ref">2015</a>)</cite>. We extend our analysis by studying the relationship between robustness and various model characteristics, such as the number of parameters and size of the training data. Having considered robustness averaged over the entire population (represented in the dataset), we extend our analysis to the robustness of the models for various population sub-groups, namely English speech, non-English (Spanish) speech, male speakers, and female speakers. Prior works <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib31" title="" class="ltx_ref">2022</a>; Veliche &amp; Fung, <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite> observe that there is disparity in transcription accuracy between subgroups.
Our analysis augments these observations by showing that inter-group disparities in robustness may also exist, and thus demonstrating the utility of <span id="S4.p1.1.4" class="ltx_text ltx_font_typewriter">SRB</span> in the broader field of trustworthy AI. The Spanish speech is obtained from the Spanish test set in Multi-Lingual Librispeech <cite class="ltx_cite ltx_citemacro_citep">(Pratap et al., <a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Robustness of English ASR Models</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluate the robustness of English DNNs from Table <a href="#S3.T1" title="Table 1 ‣ 3.5.1. Word Error Rate (WER) ‣ 3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> on the non-adversarial and adversarial perturbations in <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">SRB</span>. Figures <a href="#S4.F3.sf1" title="Figure 3(a) ‣ Figure 3 ‣ 4.1 Robustness of English ASR Models ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> and <a href="#S4.F3.sf2" title="Figure 3(b) ‣ Figure 3 ‣ 4.1 Robustness of English ASR Models ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> present aggregate metrics showing overall robustness of the ASR models along the two dimensions of utility, which is measured by NWER, and stability, which is measured by WERV (see § <a href="#S3.SS5" title="3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a> for details on metrics).
In terms of both utility and stability, we note that <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_sansserif">wsp-lg</span> is the most robust model on average, followed by <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_sansserif">hubt-lg</span>. This high-level analysis gives us an overview of the robustness of many popular state-of-the-art ASR models. Next, we conduct more fine-grained analyses to better determine under which conditions the models’ performance deteriorates.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/overall_cwe.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="598" height="570" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/overall_werv.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="598" height="639" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Overall utility and stability of English ASR models. Panel (a) shows the NWER for English ASR models under non-adversarial and adversarial perturbations, averaged across all perturbations and severities. The green markers and line show the average WER across the two perturbation types. Panel (b) shows the variance in WER (WERV) caused by the addition of random Gaussian noise and randomly selected environmental noise at fixed SNR of 10 dB.</span></figcaption>
</figure>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">4.1.1. Robustness to Non-Adversarial Perturbations
<br class="ltx_break">
</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">We first consider non-adversarial perturbations. In the following, we measure the robustness of the candidate models under each perturbation and at each severity level to identify potential failure modes.</p>
</div>
<section id="S4.SS1.SSS0.Px1.SPx1" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Robustness vs. Perturbation Type:</h5>

<div id="S4.SS1.SSS0.Px1.SPx1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.SPx1.p1.1" class="ltx_p">We aggregate the NWER over all severity levels for the different perturbation types and plot the results in Figure <a href="#A2.F7" title="Figure 7 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> in Appendix <a href="#A2" title="Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>. The trends observed in Figure <a href="#S4.F3.sf1" title="Figure 3(a) ‣ Figure 3 ‣ 4.1 Robustness of English ASR Models ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> persist across most perturbations with <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.1" class="ltx_text ltx_font_sansserif">wsp-lg</span> generally having the lowest NWER, followed by <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.2" class="ltx_text ltx_font_sansserif">hubt-lg</span> and then the Wav2Vec2.0-large models (<span id="S4.SS1.SSS0.Px1.SPx1.p1.1.3" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span> and <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.4" class="ltx_text ltx_font_sansserif">w2v2-lg-rob</span>). Interestingly, <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.5" class="ltx_text ltx_font_sansserif">wsp-lg</span> <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.6" class="ltx_text ltx_font_italic">does not</span> achieve the lowest NWER on 6 perturbations: gain, phasing, resampling, RIR, tempo reduction, and voice conversion, where it is outperformed by <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.7" class="ltx_text ltx_font_sansserif">hubt-lg</span>. It is rather surprising that despite being trained on more than ten times the amount of data, <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.8" class="ltx_text ltx_font_sansserif">wsp-lg</span> is outperformed by both <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.9" class="ltx_text ltx_font_sansserif">hubt-lg</span> and <span id="S4.SS1.SSS0.Px1.SPx1.p1.1.10" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span> on fairly common perturbations such as RIR, resampling, and tempo reduction.</p>
</div>
<div id="S4.SS1.SSS0.Px1.SPx1.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.SPx1.p2.1" class="ltx_p"><span id="S4.SS1.SSS0.Px1.SPx1.p2.1.1" class="ltx_text ltx_font_italic">While <span id="S4.SS1.SSS0.Px1.SPx1.p2.1.1.1" class="ltx_text ltx_font_sansserif">wsp-lg</span> is, in general, highly robust, the detailed analysis of its robustness, enabled by <span id="S4.SS1.SSS0.Px1.SPx1.p2.1.1.2" class="ltx_text ltx_font_typewriter">SRB</span>, uncovers several areas where it falls short.</span></p>
</div>
</section>
<section id="S4.SS1.SSS0.Px1.SPx2" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Robustness vs. Perturbation Severity:</h5>

<div id="S4.SS1.SSS0.Px1.SPx2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.SPx2.p1.1" class="ltx_p">We aggregate the NWER for all perturbations at each severity level and plot the results in Figure <a href="#A2.F8" title="Figure 8 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> in Appendix <a href="#A2" title="Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>. We observe that <span id="S4.SS1.SSS0.Px1.SPx2.p1.1.1" class="ltx_text ltx_font_sansserif">wsp-lg</span> achieves the lowest NWER across all severities by a margin. We also note that at severities up to 3, the NWER of <span id="S4.SS1.SSS0.Px1.SPx2.p1.1.2" class="ltx_text ltx_font_sansserif">hubt-lg</span> is significantly lower than the NWER of Wav2Vec models. Finally, we observe that the NWER of <span id="S4.SS1.SSS0.Px1.SPx2.p1.1.3" class="ltx_text ltx_font_sansserif">wsp-tn.en</span> increases drastically at severity 4, even going above <span id="S4.SS1.SSS0.Px1.SPx2.p1.1.4" class="ltx_text ltx_font_sansserif">ds</span>, which indicates that the performance of <span id="S4.SS1.SSS0.Px1.SPx2.p1.1.5" class="ltx_text ltx_font_sansserif">wsp-tn</span> is very brittle under severely corrupted inputs.</p>
</div>
<div id="S4.SS1.SSS0.Px1.SPx2.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.SPx2.p2.1" class="ltx_p"><span id="S4.SS1.SSS0.Px1.SPx2.p2.1.1" class="ltx_text ltx_font_sansserif ltx_font_italic">wsp-lg<span id="S4.SS1.SSS0.Px1.SPx2.p2.1.1.1" class="ltx_text ltx_font_serif"> is able to withstand more severe corruptions better than other models.</span></span></p>
</div>
</section>
<section id="S4.SS1.SSS0.Px1.SPx3" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Prediction Stability Under Perturbations:</h5>

<div id="S4.SS1.SSS0.Px1.SPx3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.SPx3.p1.1" class="ltx_p">To evaluate prediction stability, we perturb each utterance with 30 samples of Gaussian noise and 30 randomly drawn environmental noise recordings from the MS-SNSD dataset and compute the WERV. The results are presented in Figure <a href="#A2.F9" title="Figure 9 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> in Appendix <a href="#A2" title="Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>. We note that the predictions of the models are generally more stable against environmental noise than against Gaussian white noise at the same SNR. Most notably, the WERV of <span id="S4.SS1.SSS0.Px1.SPx3.p1.1.1" class="ltx_text ltx_font_sansserif">wsp-tn.en</span> goes from being the second lowest against environmental noise to being the second highest against Gaussian noise. Even the WERV of <span id="S4.SS1.SSS0.Px1.SPx3.p1.1.2" class="ltx_text ltx_font_sansserif">wsp-lg</span> increases significantly against Gaussian noise. In contrast, <span id="S4.SS1.SSS0.Px1.SPx3.p1.1.3" class="ltx_text ltx_font_sansserif">hubt-lg</span> maintains low WERV on both types of noise.</p>
</div>
<div id="S4.SS1.SSS0.Px1.SPx3.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.SPx3.p2.1" class="ltx_p"><span id="S4.SS1.SSS0.Px1.SPx3.p2.1.1" class="ltx_text ltx_font_italic">Some models (<span id="S4.SS1.SSS0.Px1.SPx3.p2.1.1.1" class="ltx_text ltx_font_sansserif">hubt-lg</span>,
<span id="S4.SS1.SSS0.Px1.SPx3.p2.1.1.2" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span>,
<span id="S4.SS1.SSS0.Px1.SPx3.p2.1.1.3" class="ltx_text ltx_font_sansserif">ds</span>) are more stable on Gaussian noise, while others (
<span id="S4.SS1.SSS0.Px1.SPx3.p2.1.1.4" class="ltx_text ltx_font_sansserif">wsp-lg</span>,
<span id="S4.SS1.SSS0.Px1.SPx3.p2.1.1.5" class="ltx_text ltx_font_sansserif">w2v2-bs</span>,
<span id="S4.SS1.SSS0.Px1.SPx3.p2.1.1.6" class="ltx_text ltx_font_sansserif">w2v2-lg-rob</span>) are more stable on environmental noise.</span></p>
</div>
</section>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">4.1.2. Robustness to Adversarial Perturbations
<br class="ltx_break">
</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">We evaluate the English-only DNNs from Table <a href="#S3.T1" title="Table 1 ‣ 3.5.1. Word Error Rate (WER) ‣ 3.5 Metrics ‣ 3 Speech Robust Bench ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> on the untargeted utterance-agnostic perturbations and untargeted specific perturbations. Figure <a href="#A2.F10" title="Figure 10 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> in Appendix <a href="#A2" title="Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a> shows the WER of the DNNs on the two perturbations as well as their average. In terms of average WER <span id="S4.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span> emerges as the most robust model followed by <span id="S4.SS1.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_sansserif">wsp-lg</span>. However, looking at the breakdown by perturbation types, we find that while <span id="S4.SS1.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_sansserif">wsp-lg</span> is almost equally susceptible to general and specific perturbations, <span id="S4.SS1.SSS0.Px2.p1.1.4" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span> is much more vulnerable to specific perturbations, but significantly less vulnerable to general perturbations. Therefore, under black- or grey-box scenarios, <span id="S4.SS1.SSS0.Px2.p1.1.5" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span> may be a better choice, while under the white-box threat model <span id="S4.SS1.SSS0.Px2.p1.1.6" class="ltx_text ltx_font_sansserif">wsp-lg</span> may be more robust. Considering the three DNNs that are based on Wav2Vec-2 Large: <span id="S4.SS1.SSS0.Px2.p1.1.7" class="ltx_text ltx_font_sansserif">hubt-lg</span>, <span id="S4.SS1.SSS0.Px2.p1.1.8" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span> and <span id="S4.SS1.SSS0.Px2.p1.1.9" class="ltx_text ltx_font_sansserif">w2v2-lg-rob</span>, we note that <span id="S4.SS1.SSS0.Px2.p1.1.10" class="ltx_text ltx_font_sansserif">hubt-lg</span> achieves the lowest WER against specific adversarial perturbations, while <span id="S4.SS1.SSS0.Px2.p1.1.11" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span> achieves the lowest WER against general adversarial perturbations. Meanwhile <span id="S4.SS1.SSS0.Px2.p1.1.12" class="ltx_text ltx_font_sansserif">w2v2-lg-rob</span> performs similarly as <span id="S4.SS1.SSS0.Px2.p1.1.13" class="ltx_text ltx_font_sansserif">w2v2-bs</span>.
We note that: (1) the self-training used in <span id="S4.SS1.SSS0.Px2.p1.1.14" class="ltx_text ltx_font_sansserif">w2v2-lg-slf</span> may induce robustness to utterance-agnostic adversarial attacks, (2) the discrete representations of <span id="S4.SS1.SSS0.Px2.p1.1.15" class="ltx_text ltx_font_sansserif">hubt-lg</span> may induce robustness to specific adversarial attacks, and (3) diversifying training data has little to no effect on adversarial robustness.
Finally, <span id="S4.SS1.SSS0.Px2.p1.1.16" class="ltx_text ltx_font_sansserif">wsp-tn.en</span> is highly vulnerable to specific adversarial attacks.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">4.1.3 Robustness vs. Model Attributes
<br class="ltx_break">
</h4>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">To determine if the prevailing practice of training DNNs with more parameters on larger datasets is yielding improvements in robustness, we plot NWER against the number of model parameters and the size of the training data of all the candidate models. These plots are shown in Figures <a href="#S4.F4.sf1" title="Figure 4(a) ‣ Figure 4 ‣ 4.1.3 Robustness vs. Model Attributes ‣ 4.1 Robustness of English ASR Models ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> and <a href="#S4.F4.sf2" title="Figure 4(b) ‣ Figure 4 ‣ 4.1.3 Robustness vs. Model Attributes ‣ 4.1 Robustness of English ASR Models ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a>. We note that increasing model size is correlated with improved robustness (lower NWER), however, the effect is more inconsistent and weaker for adversarial perturbations. To further isolate the impact of the model size we control the architecture and training data and plot the NWER of models from the same family in Figure <a href="#S4.F4.sf3" title="Figure 4(c) ‣ Figure 4 ‣ 4.1.3 Robustness vs. Model Attributes ‣ 4.1 Robustness of English ASR Models ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(c)</span></a>, which have similar architectures and training datasets. We note that larger models are more robust in the Whisper and Wav2Vec-2.0 families, but, surprisingly, not in the HuBert family. On the other hand, increasing training data appears to have only a minor influence on robustness.</p>
</div>
<div id="S4.SS1.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p2.1" class="ltx_p"><span id="S4.SS1.SSS0.Px3.p2.1.1" class="ltx_text ltx_font_italic">Larger models tend to be more robust, while smaller models, even if they are trained on large datasets, are less robust.</span></p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/params-cwe.png" id="S4.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="460" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/data-cwe.png" id="S4.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="460" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/family-cwe.png" id="S4.F4.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="398" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">NWER on non-adversarial and adversarial perturbations plotted against the number of parameters (a &amp; c) and hours of training data used to train the DNN (b). Figures (a) and (b) plot all the models, while (c) plots three families of models (indicated by the color). The models within the family share similar architectures, and training datasets.</span></figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Robustness for Population Sub-Groups</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In the preceding analysis, we considered robustness aggregated over the entire population (i.e. dataset). However, populations are generally not homogeneous, and, thus, the robustness of the model may differ on various population sub-groups. Prior works have commonly analyzed sub-group fairness of ASR models by comparing the overall WER for each sub-group on a benchmark dataset <cite class="ltx_cite ltx_citemacro_citep">(Koenecke et al., <a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite>. It is possible that models that are fair <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">on average</span>, may not be fair under certain conditions. In the following, we use <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">SRB</span> to uncover and analyze the disparities in the models’ in robustness across four sub-groups: English and Spanish speakers, and males and females. We find that disparities indeed exist, with multi-lingual models generally being more robust for English than Spanish (Figure <a href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ 4.2.1. Robustness on Non-English (Spanish) Speech ‣ 4.2 Robustness for Population Sub-Groups ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>), and most models being less robust for females than males (Figure <a href="#A2.F12" title="Figure 12 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>).</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">4.2.1. Robustness on Non-English (Spanish) Speech
<br class="ltx_break">
</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">The overall NWER of the Spanish ASR models under non-adversarial perturbations is presented in Figure <a href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ 4.2.1. Robustness on Non-English (Spanish) Speech ‣ 4.2 Robustness for Population Sub-Groups ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>, and the NWER for each perturbation is presented in Figure <a href="#A2.F11" title="Figure 11 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> in Appendix <a href="#A2" title="Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>. We observe that <span id="S4.SS2.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_sansserif">w2v2-lg-es</span> is the most robust model, followed by <span id="S4.SS2.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_sansserif">wsp-lg</span> and <span id="S4.SS2.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_sansserif">mms</span>. It is interesting that despite having 33% more parameters and being trained on 10<math id="S4.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a"><mo id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b"><times id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">\times</annotation></semantics></math> more data, <span id="S4.SS2.SSS0.Px1.p1.1.4" class="ltx_text ltx_font_sansserif">wsp-lg</span> is outperformed by <span id="S4.SS2.SSS0.Px1.p1.1.5" class="ltx_text ltx_font_sansserif">w2v2-lg-es</span>, thus <span id="S4.SS2.SSS0.Px1.p1.1.6" class="ltx_text ltx_font_italic">indicating that simply scaling the model and training data is not sufficient to achieve robustness, particularly in the multi-lingual setting</span>. Extending this analysis further, we measure the degradation in WER of <span id="S4.SS2.SSS0.Px1.p1.1.7" class="ltx_text ltx_font_sansserif">wsp-lg</span> on each perturbation when transcribing English and Spanish, and plot the results in Figure <a href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ 4.2.1. Robustness on Non-English (Spanish) Speech ‣ 4.2 Robustness for Population Sub-Groups ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>. We observe that while the degradation is greater for Spanish under all perturbations, <span id="S4.SS2.SSS0.Px1.p1.1.8" class="ltx_text ltx_font_sansserif">wsp-lg</span> struggles particularly on RIR.</p>
</div>
<div id="S4.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p2.1" class="ltx_p"><span id="S4.SS2.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_sansserif ltx_font_italic">wsp-lg<span id="S4.SS2.SSS0.Px1.p2.1.1.1" class="ltx_text ltx_font_serif"> is not the most robust model on Spanish, and struggles on simple perturbations like RIR.</span></span></p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/overall_cwe_es.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="633" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/es_v_en.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="525" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.2" class="ltx_text" style="font-size:90%;">(a)The average NWER of Spanish only and Multi-Lingual models on Spanish utterances, and (b) The average degradation (across severities) in the WER of <span id="S4.F5.4.2.1" class="ltx_text ltx_font_sansserif">wsp-lg</span> caused by various perturbations (x-axis).</span></figcaption>
</figure>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">4.2.2. Robustness and Gender
<br class="ltx_break">
</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.3" class="ltx_p">To measure the disparity in prediction accuracy across genders (males/females), we compute the log of the ratio of the WERs of the ASR model on female and male speakers. We call this measure the Log WER Ratio (LWERR) and formally it can be written as</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.5" class="ltx_Math" alttext="LWERR:=\log_{2}\frac{WER^{M}(\mathcal{X}_{f},\mathcal{R}_{f})}{WER^{M}(\mathcal{X}_{m},\mathcal{R}_{m})}," display="block"><semantics id="S4.E4.m1.5a"><mrow id="S4.E4.m1.5.5.1" xref="S4.E4.m1.5.5.1.1.cmml"><mrow id="S4.E4.m1.5.5.1.1" xref="S4.E4.m1.5.5.1.1.cmml"><mrow id="S4.E4.m1.5.5.1.1.2" xref="S4.E4.m1.5.5.1.1.2.cmml"><mi id="S4.E4.m1.5.5.1.1.2.2" xref="S4.E4.m1.5.5.1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.5.5.1.1.2.1" xref="S4.E4.m1.5.5.1.1.2.1.cmml">​</mo><mi id="S4.E4.m1.5.5.1.1.2.3" xref="S4.E4.m1.5.5.1.1.2.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.5.5.1.1.2.1a" xref="S4.E4.m1.5.5.1.1.2.1.cmml">​</mo><mi id="S4.E4.m1.5.5.1.1.2.4" xref="S4.E4.m1.5.5.1.1.2.4.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.5.5.1.1.2.1b" xref="S4.E4.m1.5.5.1.1.2.1.cmml">​</mo><mi id="S4.E4.m1.5.5.1.1.2.5" xref="S4.E4.m1.5.5.1.1.2.5.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.5.5.1.1.2.1c" xref="S4.E4.m1.5.5.1.1.2.1.cmml">​</mo><mi id="S4.E4.m1.5.5.1.1.2.6" xref="S4.E4.m1.5.5.1.1.2.6.cmml">R</mi></mrow><mo lspace="0.278em" rspace="0.278em" id="S4.E4.m1.5.5.1.1.1" xref="S4.E4.m1.5.5.1.1.1.cmml">:=</mo><mrow id="S4.E4.m1.5.5.1.1.3" xref="S4.E4.m1.5.5.1.1.3.cmml"><msub id="S4.E4.m1.5.5.1.1.3.1" xref="S4.E4.m1.5.5.1.1.3.1.cmml"><mi id="S4.E4.m1.5.5.1.1.3.1.2" xref="S4.E4.m1.5.5.1.1.3.1.2.cmml">log</mi><mn id="S4.E4.m1.5.5.1.1.3.1.3" xref="S4.E4.m1.5.5.1.1.3.1.3.cmml">2</mn></msub><mo lspace="0.167em" id="S4.E4.m1.5.5.1.1.3a" xref="S4.E4.m1.5.5.1.1.3.cmml">⁡</mo><mfrac id="S4.E4.m1.4.4" xref="S4.E4.m1.4.4.cmml"><mrow id="S4.E4.m1.2.2.2" xref="S4.E4.m1.2.2.2.cmml"><mi id="S4.E4.m1.2.2.2.4" xref="S4.E4.m1.2.2.2.4.cmml">W</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.2.3" xref="S4.E4.m1.2.2.2.3.cmml">​</mo><mi id="S4.E4.m1.2.2.2.5" xref="S4.E4.m1.2.2.2.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.2.3a" xref="S4.E4.m1.2.2.2.3.cmml">​</mo><msup id="S4.E4.m1.2.2.2.6" xref="S4.E4.m1.2.2.2.6.cmml"><mi id="S4.E4.m1.2.2.2.6.2" xref="S4.E4.m1.2.2.2.6.2.cmml">R</mi><mi id="S4.E4.m1.2.2.2.6.3" xref="S4.E4.m1.2.2.2.6.3.cmml">M</mi></msup><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.2.3b" xref="S4.E4.m1.2.2.2.3.cmml">​</mo><mrow id="S4.E4.m1.2.2.2.2.2" xref="S4.E4.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S4.E4.m1.2.2.2.2.2.3" xref="S4.E4.m1.2.2.2.2.3.cmml">(</mo><msub id="S4.E4.m1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.2.cmml">𝒳</mi><mi id="S4.E4.m1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.3.cmml">f</mi></msub><mo id="S4.E4.m1.2.2.2.2.2.4" xref="S4.E4.m1.2.2.2.2.3.cmml">,</mo><msub id="S4.E4.m1.2.2.2.2.2.2" xref="S4.E4.m1.2.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.2.2.2.2.2.2.2" xref="S4.E4.m1.2.2.2.2.2.2.2.cmml">ℛ</mi><mi id="S4.E4.m1.2.2.2.2.2.2.3" xref="S4.E4.m1.2.2.2.2.2.2.3.cmml">f</mi></msub><mo stretchy="false" id="S4.E4.m1.2.2.2.2.2.5" xref="S4.E4.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S4.E4.m1.4.4.4" xref="S4.E4.m1.4.4.4.cmml"><mi id="S4.E4.m1.4.4.4.4" xref="S4.E4.m1.4.4.4.4.cmml">W</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.4.3" xref="S4.E4.m1.4.4.4.3.cmml">​</mo><mi id="S4.E4.m1.4.4.4.5" xref="S4.E4.m1.4.4.4.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.4.3a" xref="S4.E4.m1.4.4.4.3.cmml">​</mo><msup id="S4.E4.m1.4.4.4.6" xref="S4.E4.m1.4.4.4.6.cmml"><mi id="S4.E4.m1.4.4.4.6.2" xref="S4.E4.m1.4.4.4.6.2.cmml">R</mi><mi id="S4.E4.m1.4.4.4.6.3" xref="S4.E4.m1.4.4.4.6.3.cmml">M</mi></msup><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.4.3b" xref="S4.E4.m1.4.4.4.3.cmml">​</mo><mrow id="S4.E4.m1.4.4.4.2.2" xref="S4.E4.m1.4.4.4.2.3.cmml"><mo stretchy="false" id="S4.E4.m1.4.4.4.2.2.3" xref="S4.E4.m1.4.4.4.2.3.cmml">(</mo><msub id="S4.E4.m1.3.3.3.1.1.1" xref="S4.E4.m1.3.3.3.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.3.3.3.1.1.1.2" xref="S4.E4.m1.3.3.3.1.1.1.2.cmml">𝒳</mi><mi id="S4.E4.m1.3.3.3.1.1.1.3" xref="S4.E4.m1.3.3.3.1.1.1.3.cmml">m</mi></msub><mo id="S4.E4.m1.4.4.4.2.2.4" xref="S4.E4.m1.4.4.4.2.3.cmml">,</mo><msub id="S4.E4.m1.4.4.4.2.2.2" xref="S4.E4.m1.4.4.4.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E4.m1.4.4.4.2.2.2.2" xref="S4.E4.m1.4.4.4.2.2.2.2.cmml">ℛ</mi><mi id="S4.E4.m1.4.4.4.2.2.2.3" xref="S4.E4.m1.4.4.4.2.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.E4.m1.4.4.4.2.2.5" xref="S4.E4.m1.4.4.4.2.3.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow><mo id="S4.E4.m1.5.5.1.2" xref="S4.E4.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.5b"><apply id="S4.E4.m1.5.5.1.1.cmml" xref="S4.E4.m1.5.5.1"><csymbol cd="latexml" id="S4.E4.m1.5.5.1.1.1.cmml" xref="S4.E4.m1.5.5.1.1.1">assign</csymbol><apply id="S4.E4.m1.5.5.1.1.2.cmml" xref="S4.E4.m1.5.5.1.1.2"><times id="S4.E4.m1.5.5.1.1.2.1.cmml" xref="S4.E4.m1.5.5.1.1.2.1"></times><ci id="S4.E4.m1.5.5.1.1.2.2.cmml" xref="S4.E4.m1.5.5.1.1.2.2">𝐿</ci><ci id="S4.E4.m1.5.5.1.1.2.3.cmml" xref="S4.E4.m1.5.5.1.1.2.3">𝑊</ci><ci id="S4.E4.m1.5.5.1.1.2.4.cmml" xref="S4.E4.m1.5.5.1.1.2.4">𝐸</ci><ci id="S4.E4.m1.5.5.1.1.2.5.cmml" xref="S4.E4.m1.5.5.1.1.2.5">𝑅</ci><ci id="S4.E4.m1.5.5.1.1.2.6.cmml" xref="S4.E4.m1.5.5.1.1.2.6">𝑅</ci></apply><apply id="S4.E4.m1.5.5.1.1.3.cmml" xref="S4.E4.m1.5.5.1.1.3"><apply id="S4.E4.m1.5.5.1.1.3.1.cmml" xref="S4.E4.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S4.E4.m1.5.5.1.1.3.1.1.cmml" xref="S4.E4.m1.5.5.1.1.3.1">subscript</csymbol><log id="S4.E4.m1.5.5.1.1.3.1.2.cmml" xref="S4.E4.m1.5.5.1.1.3.1.2"></log><cn type="integer" id="S4.E4.m1.5.5.1.1.3.1.3.cmml" xref="S4.E4.m1.5.5.1.1.3.1.3">2</cn></apply><apply id="S4.E4.m1.4.4.cmml" xref="S4.E4.m1.4.4"><divide id="S4.E4.m1.4.4.5.cmml" xref="S4.E4.m1.4.4"></divide><apply id="S4.E4.m1.2.2.2.cmml" xref="S4.E4.m1.2.2.2"><times id="S4.E4.m1.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.3"></times><ci id="S4.E4.m1.2.2.2.4.cmml" xref="S4.E4.m1.2.2.2.4">𝑊</ci><ci id="S4.E4.m1.2.2.2.5.cmml" xref="S4.E4.m1.2.2.2.5">𝐸</ci><apply id="S4.E4.m1.2.2.2.6.cmml" xref="S4.E4.m1.2.2.2.6"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.6.1.cmml" xref="S4.E4.m1.2.2.2.6">superscript</csymbol><ci id="S4.E4.m1.2.2.2.6.2.cmml" xref="S4.E4.m1.2.2.2.6.2">𝑅</ci><ci id="S4.E4.m1.2.2.2.6.3.cmml" xref="S4.E4.m1.2.2.2.6.3">𝑀</ci></apply><interval closure="open" id="S4.E4.m1.2.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.2.2"><apply id="S4.E4.m1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.2">𝒳</ci><ci id="S4.E4.m1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3">𝑓</ci></apply><apply id="S4.E4.m1.2.2.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.2.2.2.1.cmml" xref="S4.E4.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S4.E4.m1.2.2.2.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.2.2.2.2">ℛ</ci><ci id="S4.E4.m1.2.2.2.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.2.2.2.3">𝑓</ci></apply></interval></apply><apply id="S4.E4.m1.4.4.4.cmml" xref="S4.E4.m1.4.4.4"><times id="S4.E4.m1.4.4.4.3.cmml" xref="S4.E4.m1.4.4.4.3"></times><ci id="S4.E4.m1.4.4.4.4.cmml" xref="S4.E4.m1.4.4.4.4">𝑊</ci><ci id="S4.E4.m1.4.4.4.5.cmml" xref="S4.E4.m1.4.4.4.5">𝐸</ci><apply id="S4.E4.m1.4.4.4.6.cmml" xref="S4.E4.m1.4.4.4.6"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.4.6.1.cmml" xref="S4.E4.m1.4.4.4.6">superscript</csymbol><ci id="S4.E4.m1.4.4.4.6.2.cmml" xref="S4.E4.m1.4.4.4.6.2">𝑅</ci><ci id="S4.E4.m1.4.4.4.6.3.cmml" xref="S4.E4.m1.4.4.4.6.3">𝑀</ci></apply><interval closure="open" id="S4.E4.m1.4.4.4.2.3.cmml" xref="S4.E4.m1.4.4.4.2.2"><apply id="S4.E4.m1.3.3.3.1.1.1.cmml" xref="S4.E4.m1.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.3.1.1.1.1.cmml" xref="S4.E4.m1.3.3.3.1.1.1">subscript</csymbol><ci id="S4.E4.m1.3.3.3.1.1.1.2.cmml" xref="S4.E4.m1.3.3.3.1.1.1.2">𝒳</ci><ci id="S4.E4.m1.3.3.3.1.1.1.3.cmml" xref="S4.E4.m1.3.3.3.1.1.1.3">𝑚</ci></apply><apply id="S4.E4.m1.4.4.4.2.2.2.cmml" xref="S4.E4.m1.4.4.4.2.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.4.2.2.2.1.cmml" xref="S4.E4.m1.4.4.4.2.2.2">subscript</csymbol><ci id="S4.E4.m1.4.4.4.2.2.2.2.cmml" xref="S4.E4.m1.4.4.4.2.2.2.2">ℛ</ci><ci id="S4.E4.m1.4.4.4.2.2.2.3.cmml" xref="S4.E4.m1.4.4.4.2.2.2.3">𝑚</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.5c">LWERR:=\log_{2}\frac{WER^{M}(\mathcal{X}_{f},\mathcal{R}_{f})}{WER^{M}(\mathcal{X}_{m},\mathcal{R}_{m})},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.SSS0.Px2.p1.2" class="ltx_p">where the <math id="S4.SS2.SSS0.Px2.p1.1.m1.2" class="ltx_Math" alttext="(\mathcal{X}_{f},\mathcal{R}_{f})" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.2a"><mrow id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.3" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml">(</mo><msub id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.cmml">𝒳</mi><mi id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3.cmml">f</mi></msub><mo id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.4" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml">,</mo><msub id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.cmml">ℛ</mi><mi id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3.cmml">f</mi></msub><mo stretchy="false" id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.5" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.2b"><interval closure="open" id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.3.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2"><apply id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2">𝒳</ci><ci id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3">𝑓</ci></apply><apply id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.2">ℛ</ci><ci id="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.2.2.2.2.3">𝑓</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.2c">(\mathcal{X}_{f},\mathcal{R}_{f})</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px2.p1.2.m2.2" class="ltx_Math" alttext="(\mathcal{X}_{m},\mathcal{R}_{m})" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.2.m2.2a"><mrow id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.3.cmml"><mo stretchy="false" id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.3" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.3.cmml">(</mo><msub id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.2.cmml">𝒳</mi><mi id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.3" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.3.cmml">m</mi></msub><mo id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.4" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.3.cmml">,</mo><msub id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.2.cmml">ℛ</mi><mi id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.3" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.5" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.m2.2b"><interval closure="open" id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.3.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2"><apply id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.2">𝒳</ci><ci id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.1.3">𝑚</ci></apply><apply id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2">subscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.2">ℛ</ci><ci id="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.3.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.2.2.2.2.3">𝑚</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.m2.2c">(\mathcal{X}_{m},\mathcal{R}_{m})</annotation></semantics></math> represent the subsets of utterances by females and males respectively. A positive value of LWERR indicates that the model is biased against females and a negative value indicates that the model is biased against males.</p>
</div>
<div id="S4.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p2.1" class="ltx_p">The average LWERR values for English and non-English (Spanish) models are shown in Figure <a href="#A2.F12" title="Figure 12 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> and a breakdown by perturbations is shown in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.2.2. Robustness and Gender ‣ 4.2 Robustness for Population Sub-Groups ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. We note that, on average, the models are biased against females, and the bias is exacerbated when transcribing Spanish. From Figure <a href="#S4.F6.sf1" title="Figure 6(a) ‣ Figure 6 ‣ 4.2.2. Robustness and Gender ‣ 4.2 Robustness for Population Sub-Groups ‣ 4 Evaluation ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> we observe that on clean data the English models are generally weakly biased against females, with <span id="S4.SS2.SSS0.Px2.p2.1.1" class="ltx_text ltx_font_sansserif">ds</span> being the most biased and <span id="S4.SS2.SSS0.Px2.p2.1.2" class="ltx_text ltx_font_sansserif">hubt-lg</span> the least. <span id="S4.SS2.SSS0.Px2.p2.1.3" class="ltx_text ltx_font_sansserif">wsp-lg</span> is an exception in that it is slightly biased against males. The bias of the models diminishes significantly under environmental and Gaussian noise, but, interestingly it is exacerbated (against females) under room impulse response augmentation, and phasing. Perturbations that mask or shift the spectrogram, such as filtering, resampling, and pitch and speech modulation, have somewhat expected results – perturbations that shift increase the pitch or mask higher frequencies tend to increase WER for females, and vice-versa. Interestingly, we observe that utterance-agnostic adversarial attacks biased 4/7 models against female speakers, with <span id="S4.SS2.SSS0.Px2.p2.1.4" class="ltx_text ltx_font_sansserif">wsp-lg</span> exhibiting the most significant increase in bias.</p>
</div>
<div id="S4.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p3.1" class="ltx_p">The bias against female speakers is more pronounced in the Spanish ASR models. Unlike English models, the bias does not diminish under noise indicating that the Spanish models have considerably less robustness against noise for female speakers. The trends for the other utterances remain the same as the ones observed in English models, except the increase in bias due to the addition of room impulse response is much greater.</p>
</div>
<div id="S4.SS2.SSS0.Px2.p4" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p4.1" class="ltx_p"><span id="S4.SS2.SSS0.Px2.p4.1.1" class="ltx_text ltx_font_italic">To summarize, using our benchmark to conduct a fairness analysis reveals that (1) certain perturbations, like room impulse response and adversarial attacks disproportionately degrade the performance of models for female speakers, and (2) the disparity across genders is greater in Spanish models and input perturbations tend to further exacerbate this disparity.</span></p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/lwerr_augs.png" id="S4.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">English</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/lwerr_augs_es.png" id="S4.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="210" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">Spanish</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">Log WER Ratio for (a) English, (b) Spanish models under various perturbations. WERs are averaged across severity levels before computing the Log WER Ratio.</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper we have proposed, <span id="S5.p1.1.1" class="ltx_text ltx_font_typewriter">SRB</span>, a comprehensive benchmark designed to standardize the robustness evaluations of ASR models. To the best of our knowledge, <span id="S5.p1.1.2" class="ltx_text ltx_font_typewriter">SRB</span>, is the first ASR robustness benchmark that contains long-form speech, and expands the set of distortions to include special effects, speaker attribute modification and adversarial attacks. We present case studies to demonstrate the utility of <span id="S5.p1.1.3" class="ltx_text ltx_font_typewriter">SRB</span> in evaluating the robustness of ASR models, as well as its potential to facilitate evaluations of other aspects of trustworthy AI, particularly fairness. Our analysis reveals that while the latest large models, trained on vast quantities of data, are more robust than their counterparts <span id="S5.p1.1.4" class="ltx_text ltx_font_italic">on average</span>, under certain types of perturbations they are outperformed by smaller models trained on lesser data. Furthermore, our analysis reveals that model size generally has a greater impact on robustness than the size of the training dataset, which runs somewhat counter to the prevailing wisdom espoused by recent works <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>; Likhomanenko et al., <a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite>. We also use <span id="S5.p1.1.5" class="ltx_text ltx_font_typewriter">SRB</span> to measure the disparities in the robustness of ASR models on data generated by different population subgroups, namely speakers’ language and gender. We find that multi-lingual models are generally more robust for English speech than non-English (Spanish) speech. We also find that under certain perturbations models may be more robust for one gender than the other. We believe that <span id="S5.p1.1.6" class="ltx_text ltx_font_typewriter">SRB</span> will enable rigorous robustness evaluations of ASR models in a highly standardized manner that will allow comparisons between existing and new approaches and thus facilitate progress tracking. Furthermore, we also release transformed test sets in English and Spanish to facilitate robustness evaluations for researchers and model developers. We believe that this will make robustness evaluations more prevalent and encourage model developers to consider robustness as a key metric to improve.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Impact statement</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgments</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">The execution of this work was funded by the European Union’s Horizon 2020 RIA SPATIAL project (Grant Agreement No. 101021808), RIA ELOQUENCE project (Grant Agreement No. 101135916) and from the Spanish Project 6G-RIEMANN (Grant Agreement No. 2022/0005420). The authors bear the sole responsibility for the content presented in this paper, and any interpretations or conclusions drawn from it do not reflect the official position of the funding agencies.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Akhtar et al. (2021)</span>
<span class="ltx_bibblock">
Akhtar, N., Mian, A., Kardan, N., and Shah, M.

</span>
<span class="ltx_bibblock">Advances in adversarial attacks and defenses in computer vision: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 9:155161–155196, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amodei et al. (2016)</span>
<span class="ltx_bibblock">
Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., Case, C., Casper, J., Catanzaro, B., Cheng, Q., Chen, G., et al.

</span>
<span class="ltx_bibblock">Deep speech 2: End-to-end speech recognition in english and mandarin.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, pp.  173–182. PMLR, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andriushchenko et al. (2020)</span>
<span class="ltx_bibblock">
Andriushchenko, M., Croce, F., Flammarion, N., and Hein, M.

</span>
<span class="ltx_bibblock">Square attack: a query-efficient black-box adversarial attack via random search.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em>, pp.  484–501. Springer, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski et al. (2020)</span>
<span class="ltx_bibblock">
Baevski, A., Zhou, Y., Mohamed, A., and Auli, M.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:12449–12460, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barker et al. (2018)</span>
<span class="ltx_bibblock">
Barker, J., Watanabe, S., Vincent, E., and Trmal, J.

</span>
<span class="ltx_bibblock">The fifth ’chime’ speech separation and recognition challenge: Dataset, task and baselines.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2018</em>, pp.  1561–1565, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/Interspeech.2018-1768</span>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Casanova et al. (2022)</span>
<span class="ltx_bibblock">
Casanova, E., Weber, J., Shulby, C. D., Junior, A. C., Gölge, E., and Ponti, M. A.

</span>
<span class="ltx_bibblock">Yourtts: Towards zero-shot multi-speaker tts and zero-shot voice conversion for everyone.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp.  2709–2720. PMLR, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Chen, C., Hou, N., Hu, Y., Shirol, S., and Chng, E. S.

</span>
<span class="ltx_bibblock">Noise-robust speech recognition with 10 minutes unparalleled in-domain data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp.  4298–4302. IEEE, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2017)</span>
<span class="ltx_bibblock">
Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., and Hsieh, C.-J.

</span>
<span class="ltx_bibblock">Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 10th ACM workshop on artificial intelligence and security</em>, pp.  15–26, 2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2020)</span>
<span class="ltx_bibblock">
Conneau, A., Baevski, A., Collobert, R., Mohamed, A., and Auli, M.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning for speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.13979</em>, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Croce &amp; Hein (2020)</span>
<span class="ltx_bibblock">
Croce, F. and Hein, M.

</span>
<span class="ltx_bibblock">Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>, pp.  2206–2216. PMLR, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Croce et al. (2020)</span>
<span class="ltx_bibblock">
Croce, F., Andriushchenko, M., Sehwag, V., Debenedetti, E., Flammarion, N., Chiang, M., Mittal, P., and Hein, M.

</span>
<span class="ltx_bibblock">Robustbench: a standardized adversarial robustness benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.09670</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. (2014)</span>
<span class="ltx_bibblock">
Goodfellow, I. J., Shlens, J., and Szegedy, C.

</span>
<span class="ltx_bibblock">Explaining and harnessing adversarial examples, 2014.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks &amp; Dietterich (2019)</span>
<span class="ltx_bibblock">
Hendrycks, D. and Dietterich, T.

</span>
<span class="ltx_bibblock">Benchmarking neural network robustness to common corruptions and perturbations.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.12261</em>, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021a)</span>
<span class="ltx_bibblock">
Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai, R., Zhu, T., Parajuli, S., Guo, M., et al.

</span>
<span class="ltx_bibblock">The many faces of robustness: A critical analysis of out-of-distribution generalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.  8340–8349, 2021a.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021b)</span>
<span class="ltx_bibblock">
Hendrycks, D., Zhao, K., Basart, S., Steinhardt, J., and Song, D.

</span>
<span class="ltx_bibblock">Natural adversarial examples.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  15262–15271, 2021b.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hermansky &amp; Sharma (1998)</span>
<span class="ltx_bibblock">
Hermansky, H. and Sharma, S.

</span>
<span class="ltx_bibblock">Traps-classifiers of temporal patterns.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Fifth International Conference on Spoken Language Processing</em>, 1998.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hermansky et al. (1991)</span>
<span class="ltx_bibblock">
Hermansky, H., Morgan, N., Bayya, A., and Kohn, P.

</span>
<span class="ltx_bibblock">Rasta-plp speech analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Int’l Conf. Acoustics, speech and signal processing</em>, volume 1, pp.  121–124, 1991.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hirsch &amp; Pearce (2000)</span>
<span class="ltx_bibblock">
Hirsch, H.-G. and Pearce, D.

</span>
<span class="ltx_bibblock">The aurora experimental framework for the performance evaluation of speech recognition systems under noisy conditions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">ASR2000-Automatic speech recognition: challenges for the new Millenium ISCA tutorial and research workshop (ITRW)</em>, 2000.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. (2021a)</span>
<span class="ltx_bibblock">
Hsu, W.-N., Bolte, B., Tsai, Y.-H. H., Lakhotia, K., Salakhutdinov, R., and Mohamed, A.

</span>
<span class="ltx_bibblock">Hubert: Self-supervised speech representation learning by masked prediction of hidden units.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 29:3451–3460, 2021a.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. (2021b)</span>
<span class="ltx_bibblock">
Hsu, W.-N., Sriram, A., Baevski, A., Likhomanenko, T., Xu, Q., Pratap, V., Kahn, J., Lee, A., Collobert, R., Synnaeve, G., et al.

</span>
<span class="ltx_bibblock">Robust wav2vec 2.0: Analyzing domain shift in self-supervised pre-training.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.01027</em>, 2021b.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeub et al. (2009)</span>
<span class="ltx_bibblock">
Jeub, M., Schafer, M., and Vary, P.

</span>
<span class="ltx_bibblock">A binaural room impulse response database for the evaluation of dereverberation algorithms.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">2009 16th International Conference on Digital Signal Processing</em>, pp.  1–5. IEEE, 2009.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Juang &amp; Rahim (1996)</span>
<span class="ltx_bibblock">
Juang, B.-H. and Rahim, M. G.

</span>
<span class="ltx_bibblock">Signal bias removal by maximum likelihood estimation for robust telephone speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Speech and Audio Processing</em>, 4(1):19, 1996.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim &amp; Stern (2016)</span>
<span class="ltx_bibblock">
Kim, C. and Stern, R. M.

</span>
<span class="ltx_bibblock">Power-normalized cepstral coefficients (pncc) for robust speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on audio, speech, and language processing</em>, 24(7):1315–1329, 2016.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kinoshita et al. (2013)</span>
<span class="ltx_bibblock">
Kinoshita, K., Delcroix, M., Yoshioka, T., Nakatani, T., Habets, E., Haeb-Umbach, R., Leutnant, V., Sehr, A., Kellermann, W., Maas, R., et al.

</span>
<span class="ltx_bibblock">The reverb challenge: A common evaluation framework for dereverberation and recognition of reverberant speech.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</em>, pp.  1–4. IEEE, 2013.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko et al. (2017)</span>
<span class="ltx_bibblock">
Ko, T., Peddinti, V., Povey, D., Seltzer, M. L., and Khudanpur, S.

</span>
<span class="ltx_bibblock">A study on data augmentation of reverberant speech for robust speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp.  5220–5224. IEEE, 2017.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koenecke et al. (2020)</span>
<span class="ltx_bibblock">
Koenecke, A., Nam, A., Lake, E., Nudell, J., Quartey, M., Mengesha, Z., Toups, C., Rickford, J. R., Jurafsky, D., and Goel, S.

</span>
<span class="ltx_bibblock">Racial disparities in automated speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the National Academy of Sciences</em>, 117(14):7684–7689, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laidlaw et al. (2021)</span>
<span class="ltx_bibblock">
Laidlaw, C., Singla, S., and Feizi, S.

</span>
<span class="ltx_bibblock">Perceptual adversarial robustness: Defense against unseen threat models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=dFwBosAcJkN" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=dFwBosAcJkN</a>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lander (2022)</span>
<span class="ltx_bibblock">
Lander, T.

</span>
<span class="ltx_bibblock">CSLU: Foreign Accented English Release 1.2, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.5683/SP2/K7EQTE" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5683/SP2/K7EQTE</a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2014)</span>
<span class="ltx_bibblock">
Li, J., Deng, L., Gong, Y., and Haeb-Umbach, R.

</span>
<span class="ltx_bibblock">An overview of noise-robust automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 22(4):745–777, 2014.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Likhomanenko et al. (2020)</span>
<span class="ltx_bibblock">
Likhomanenko, T., Xu, Q., Pratap, V., Tomasello, P., Kahn, J., Avidov, G., Collobert, R., and Synnaeve, G.

</span>
<span class="ltx_bibblock">Rethinking evaluation in asr: Are our models robust enough?

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11745</em>, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
Liu, C., Picheny, M., Sarı, L., Chitkara, P., Xiao, A., Zhang, X., Chou, M., Alvarado, A., Hazirbas, C., and Saraf, Y.

</span>
<span class="ltx_bibblock">Towards measuring fairness in speech recognition: Casual conversations dataset transcriptions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp.  6162–6166. IEEE, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madry et al. (2018)</span>
<span class="ltx_bibblock">
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.

</span>
<span class="ltx_bibblock">Towards deep learning models resistant to adversarial attacks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2018.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohammadiha et al. (2013)</span>
<span class="ltx_bibblock">
Mohammadiha, N., Smaragdis, P., and Leijon, A.

</span>
<span class="ltx_bibblock">Supervised and unsupervised speech enhancement using nonnegative matrix factorization.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on audio, speech, and language processing</em>, 21(10):2140–2151, 2013.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakamura et al. (2000)</span>
<span class="ltx_bibblock">
Nakamura, S., Hiyane, K., Asano, F., Nishiura, T., and Yamada, T.

</span>
<span class="ltx_bibblock">Acoustical sound database in real environments for sound scene understanding and hands-free speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">LREC</em>, pp.  965–968, 2000.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neekhara et al. (2019)</span>
<span class="ltx_bibblock">
Neekhara, P., Hussain, S., Pandey, P., Dubnov, S., McAuley, J., and Koushanfar, F.

</span>
<span class="ltx_bibblock">Universal adversarial perturbations for speech recognition systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.03828</em>, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Olivier &amp; Raj (2022)</span>
<span class="ltx_bibblock">
Olivier, R. and Raj, B.

</span>
<span class="ltx_bibblock">Recent improvements of asr models in the face of adversarial attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2203.16536" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2203.16536</a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panayotov et al. (2015)</span>
<span class="ltx_bibblock">
Panayotov, V., Chen, G., Povey, D., and Khudanpur, S.

</span>
<span class="ltx_bibblock">Librispeech: an asr corpus based on public domain audio books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>, pp.  5206–5210. IEEE, 2015.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papernot et al. (2016)</span>
<span class="ltx_bibblock">
Papernot, N., McDaniel, P., and Goodfellow, I.

</span>
<span class="ltx_bibblock">Transferability in machine learning: from phenomena to black-box attacks using adversarial samples.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1605.07277</em>, 2016.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Piczak (2015)</span>
<span class="ltx_bibblock">
Piczak, K. J.

</span>
<span class="ltx_bibblock">ESC: Dataset for Environmental Sound Classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd Annual ACM Conference on Multimedia</em>, pp.  1015–1018. ACM Press, 2015.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-3459-4.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/2733373.2806390</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dl.acm.org/citation.cfm?doid=2733373.2806390" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dl.acm.org/citation.cfm?doid=2733373.2806390</a>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pratap et al. (2020)</span>
<span class="ltx_bibblock">
Pratap, V., Xu, Q., Sriram, A., Synnaeve, G., and Collobert, R.

</span>
<span class="ltx_bibblock">Mls: A large-scale multilingual dataset for speech research.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.03411</em>, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pratap et al. (2023)</span>
<span class="ltx_bibblock">
Pratap, V., Tjandra, A., Shi, B., Tomasello, P., Babu, A., Kundu, S., Elkahky, A., Ni, Z., Vyas, A., Fazel-Zarandi, M., et al.

</span>
<span class="ltx_bibblock">Scaling speech technology to 1,000+ languages.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.13516</em>, 2023.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2023)</span>
<span class="ltx_bibblock">
Radford, A., Kim, J. W., Xu, T., Brockman, G., McLeavey, C., and Sutskever, I.

</span>
<span class="ltx_bibblock">Robust speech recognition via large-scale weak supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp.  28492–28518. PMLR, 2023.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2021)</span>
<span class="ltx_bibblock">
Shi, X., Yu, F., Lu, Y., Liang, Y., Feng, Q., Wang, D., Qian, Y., and Xie, L.

</span>
<span class="ltx_bibblock">The accented english speech recognition challenge 2020: open datasets, tracks, baselines, results and methods.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp.  6918–6922. IEEE, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stern &amp; Morgan (2012)</span>
<span class="ltx_bibblock">
Stern, R. M. and Morgan, N.

</span>
<span class="ltx_bibblock">Hearing is believing: Biologically inspired methods for robust automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE signal processing magazine</em>, 29(6):34–43, 2012.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szegedy et al. (2014)</span>
<span class="ltx_bibblock">
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., and Fergus, R.

</span>
<span class="ltx_bibblock">Intriguing properties of neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2014.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1312.6199" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1312.6199</a>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Veliche &amp; Fung (2023)</span>
<span class="ltx_bibblock">
Veliche, I.-E. and Fung, P.

</span>
<span class="ltx_bibblock">Improving fairness and robustness in end-to-end speech recognition through unsupervised clustering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp.  1–5. IEEE, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vo et al. (2022)</span>
<span class="ltx_bibblock">
Vo, V. Q., Abbasnejad, E., and Ranasinghe, D. C.

</span>
<span class="ltx_bibblock">Query efficient decision based sparse attacks against black-box deep learning models.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.00091</em>, 2022.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021a)</span>
<span class="ltx_bibblock">
Wang, B., Xu, C., Wang, S., Gan, Z., Cheng, Y., Gao, J., Awadallah, A. H., and Li, B.

</span>
<span class="ltx_bibblock">Adversarial glue: A multi-task benchmark for robustness evaluation of language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.02840</em>, 2021a.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2021b)</span>
<span class="ltx_bibblock">
Wang, C., Riviere, M., Lee, A., Wu, A., Talnikar, C., Haziza, D., Williamson, M., Pino, J., and Dupoux, E.

</span>
<span class="ltx_bibblock">Voxpopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.00390</em>, 2021b.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022a)</span>
<span class="ltx_bibblock">
Wang, C., Zhang, M., Zhao, J., and Kuang, X.

</span>
<span class="ltx_bibblock">Black-box adversarial attacks on deep neural networks: A survey.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">2022 4th International Conference on Data Intelligence and Security (ICDIS)</em>, pp.  88–93. IEEE, 2022a.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022b)</span>
<span class="ltx_bibblock">
Wang, X., Wang, H., and Yang, D.

</span>
<span class="ltx_bibblock">Measure and improve robustness in nlp models: A survey.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pp.  4569–4586, 2022b.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. (2016)</span>
<span class="ltx_bibblock">
Wen, W., Wu, C., Wang, Y., Chen, Y., and Li, H.

</span>
<span class="ltx_bibblock">Learning structured sparsity in deep neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">NIPS</em>, 2016.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wicker et al. (2018)</span>
<span class="ltx_bibblock">
Wicker, M., Huang, X., and Kwiatkowska, M.

</span>
<span class="ltx_bibblock">Feature-guided black-box safety testing of deep neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Tools and Algorithms for the Construction and Analysis of Systems: 24th International Conference, TACAS 2018, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2018, Thessaloniki, Greece, April 14-20, 2018, Proceedings, Part I 24</em>, pp.  408–426. Springer, 2018.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilson et al. (2008)</span>
<span class="ltx_bibblock">
Wilson, K. W., Raj, B., Smaragdis, P., and Divakaran, A.

</span>
<span class="ltx_bibblock">Speech denoising using nonnegative matrix factorization with priors.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">2008 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, pp.  4029–4032. IEEE, 2008.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2021)</span>
<span class="ltx_bibblock">
Xu, Q., Baevski, A., Likhomanenko, T., Tomasello, P., Conneau, A., Collobert, R., Synnaeve, G., and Auli, M.

</span>
<span class="ltx_bibblock">Self-training and pre-training are complementary for speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp.  3030–3034. IEEE, 2021.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yamagishi et al. (2019)</span>
<span class="ltx_bibblock">
Yamagishi, J., Veaux, C., and MacDonald, K.

</span>
<span class="ltx_bibblock">CSTR VCTK Corpus: English multi-speaker corpus for CSTR voice cloning toolkit (version 0.92), 2019.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2009)</span>
<span class="ltx_bibblock">
Yu, K., Gales, M., and Woodland, P. C.

</span>
<span class="ltx_bibblock">Unsupervised adaptation with discriminative mapping transforms.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Audio, Speech, and Language Processing</em>, 17(4):714–723, 2009.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2020)</span>
<span class="ltx_bibblock">
Zhao, P., Chen, P.-Y., Wang, S., and Lin, X.

</span>
<span class="ltx_bibblock">Towards query-efficient black-box adversary with zeroth-order natural gradient descent.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, pp.  6909–6916, 2020.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Perturbation Generation/Application Procedure</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Below we provide further details on the implementation of these perturbations.</p>
</div>
<section id="A1.SS0.SSS0.P0.SPx1" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Gaussian Noise:</h5>

<div id="A1.SS0.SSS0.P0.SPx1.p1" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx1.p1.1" class="ltx_p">A noise vector of the same length as the audio signal is sample from a standard normal distribution, scaled such that its magnitude corresponds to a specific SNR, and then added to the audio signal. We use <span id="A1.SS0.SSS0.P0.SPx1.p1.1.1" class="ltx_text ltx_font_typewriter">torchaudio.function.add_noise</span> to add the noise to the speech at a given SNR.</p>
</div>
</section>
<section id="A1.SS0.SSS0.P0.SPx2" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Environmental Noise</h5>

<div id="A1.SS0.SSS0.P0.SPx2.p1" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx2.p1.1" class="ltx_p">: We use the recordings of environmental noises from the <span id="A1.SS0.SSS0.P0.SPx2.p1.1.1" class="ltx_text ltx_font_typewriter">noise-test</span> subset of the ESC-50 dataset  <cite class="ltx_cite ltx_citemacro_citep">(Piczak, <a href="#bib.bib39" title="" class="ltx_ref">2015</a>)</cite>. For each test utterance we sample a random environmental noise and add it to the audio signal at the specified SNR. We clip the noise if it is longer than the speech, and repeat it if it is longer than the speech. We use <span id="A1.SS0.SSS0.P0.SPx2.p1.1.2" class="ltx_text ltx_font_typewriter">torchaudio.function.add_noise</span> to add the noise to the speech at a given SNR.</p>
</div>
</section>
<section id="A1.SS0.SSS0.P0.SPx3" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Room Impulse Response:</h5>

<div id="A1.SS0.SSS0.P0.SPx3.p1" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx3.p1.1" class="ltx_p">The 6000 simulated RIRs from <cite class="ltx_cite ltx_citemacro_citep">(Ko et al., <a href="#bib.bib25" title="" class="ltx_ref">2017</a>)</cite> are applied to clean recordings and the SNR is measured. The 100th, 99th, 66th, 33rd, and 1st quantiles of the RIRs are computed. RIRs with SNRs between the 100th and 99th quantile are assigned sev 1, those with SNRs between the 99th and 66th quantile are assigned sev 2, and so on. The Table <a href="#A1.T2" title="Table 2 ‣ Untargeted Utterance Agnostic Adversarial Attack: ‣ Appendix A Perturbation Generation/Application Procedure ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the average SNR in each severity level. During evaluation, a random RIR having the given severity level is sampled for each test recording.</p>
</div>
</section>
<section id="A1.SS0.SSS0.P0.SPx4" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Resampling, Speed, Pitch, and Gain Perturbations:</h5>

<div id="A1.SS0.SSS0.P0.SPx4.p1" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx4.p1.1" class="ltx_p">The resampling speed, pitch, and gain perturbations were applied using the <span id="A1.SS0.SSS0.P0.SPx4.p1.1.1" class="ltx_text ltx_font_typewriter">Resample</span> <span id="A1.SS0.SSS0.P0.SPx4.p1.1.2" class="ltx_text ltx_font_typewriter">Speed</span>, <span id="A1.SS0.SSS0.P0.SPx4.p1.1.3" class="ltx_text ltx_font_typewriter">PitchShift</span> and <span id="A1.SS0.SSS0.P0.SPx4.p1.1.4" class="ltx_text ltx_font_typewriter">Vol</span> transforms from <span id="A1.SS0.SSS0.P0.SPx4.p1.1.5" class="ltx_text ltx_font_typewriter">torchaudio</span>.</p>
</div>
</section>
<section id="A1.SS0.SSS0.P0.SPx5" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Echo, Phaser, Tempo and High/Low-Pass Filters:</h5>

<div id="A1.SS0.SSS0.P0.SPx5.p1" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx5.p1.1" class="ltx_p">These effects are applied via SoX filters of the same name. We used <span id="A1.SS0.SSS0.P0.SPx5.p1.1.1" class="ltx_text ltx_font_typewriter">torchaudio.sox_effects.apply_effects_tensor</span> to apply these filters to the audio. The args for each filter are as follows:</p>
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p"><span id="A1.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">echo 0.8 0.9 &lt;delay&gt; 0.3</span></p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p"><span id="A1.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">phaser 0.6 0.8 3 &lt;decay&gt; 2 ’-t’</span></p>
</div>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p id="A1.I1.i3.p1.1" class="ltx_p"><span id="A1.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Tempo &lt;factor&gt; 30</span></p>
</div>
</li>
<li id="A1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i4.p1" class="ltx_para">
<p id="A1.I1.i4.p1.1" class="ltx_p"><span id="A1.I1.i4.p1.1.1" class="ltx_text ltx_font_typewriter">sinc &lt;lo-freq&gt;</span></p>
</div>
</li>
<li id="A1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i5.p1" class="ltx_para">
<p id="A1.I1.i5.p1.1" class="ltx_p"><span id="A1.I1.i5.p1.1.1" class="ltx_text ltx_font_typewriter">sinc 0-&lt;hi-freq&gt;</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1.SS0.SSS0.P0.SPx6" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Voice Conversion</h5>

<div id="A1.SS0.SSS0.P0.SPx6.p1" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx6.p1.1" class="ltx_p">We use use YourTTS <cite class="ltx_cite ltx_citemacro_citep">(Casanova et al., <a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite> from Coqui.ai<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/coqui-ai/TTS" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/coqui-ai/TTS</a></span></span></span> to synthesize audio from textual transcripts in a given speaker’s style. The transcripts from the test clean subset of LibriSpeech are used. The target speakers are drawn from the VCTK corpus <cite class="ltx_cite ltx_citemacro_citep">(Yamagishi et al., <a href="#bib.bib56" title="" class="ltx_ref">2019</a>)</cite>, which contains accented speech from 12 accents. For each transcript a random speaker is chosen to synthesize the audio.</p>
</div>
</section>
<section id="A1.SS0.SSS0.P0.SPx7" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Untargeted Adversarial Attack:</h5>

<div id="A1.SS0.SSS0.P0.SPx7.p1" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx7.p1.4" class="ltx_p">The adversarial perturbations are computed using an <span id="A1.SS0.SSS0.P0.SPx7.p1.4.1" class="ltx_text ltx_font_italic">untargeted</span> PGD adversarial attack. The attack is computed as follows. First, the maximum possible L2 norm of the noise is determined by solving the equation for SNR for the norm of the noise.</p>
<table id="A2.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="A1.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span id="A1.E5.2.1.1.1" class="ltx_text ltx_markedasmath">SNR</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E5.m2.3" class="ltx_Math" alttext="\displaystyle=20\log_{10}\left(\frac{||x||_{2}}{||\delta||_{2}}\right)" display="inline"><semantics id="A1.E5.m2.3a"><mrow id="A1.E5.m2.3.3" xref="A1.E5.m2.3.3.cmml"><mi id="A1.E5.m2.3.3.3" xref="A1.E5.m2.3.3.3.cmml"></mi><mo id="A1.E5.m2.3.3.2" xref="A1.E5.m2.3.3.2.cmml">=</mo><mrow id="A1.E5.m2.3.3.1" xref="A1.E5.m2.3.3.1.cmml"><mn id="A1.E5.m2.3.3.1.3" xref="A1.E5.m2.3.3.1.3.cmml">20</mn><mo lspace="0.167em" rspace="0em" id="A1.E5.m2.3.3.1.2" xref="A1.E5.m2.3.3.1.2.cmml">​</mo><mrow id="A1.E5.m2.3.3.1.1.1" xref="A1.E5.m2.3.3.1.1.2.cmml"><msub id="A1.E5.m2.3.3.1.1.1.1" xref="A1.E5.m2.3.3.1.1.1.1.cmml"><mi id="A1.E5.m2.3.3.1.1.1.1.2" xref="A1.E5.m2.3.3.1.1.1.1.2.cmml">log</mi><mn id="A1.E5.m2.3.3.1.1.1.1.3" xref="A1.E5.m2.3.3.1.1.1.1.3.cmml">10</mn></msub><mo id="A1.E5.m2.3.3.1.1.1a" xref="A1.E5.m2.3.3.1.1.2.cmml">⁡</mo><mrow id="A1.E5.m2.3.3.1.1.1.2" xref="A1.E5.m2.3.3.1.1.2.cmml"><mo id="A1.E5.m2.3.3.1.1.1.2.1" xref="A1.E5.m2.3.3.1.1.2.cmml">(</mo><mstyle displaystyle="true" id="A1.E5.m2.2.2" xref="A1.E5.m2.2.2.cmml"><mfrac id="A1.E5.m2.2.2a" xref="A1.E5.m2.2.2.cmml"><msub id="A1.E5.m2.1.1.1" xref="A1.E5.m2.1.1.1.cmml"><mrow id="A1.E5.m2.1.1.1.3.2" xref="A1.E5.m2.1.1.1.3.1.cmml"><mo stretchy="false" id="A1.E5.m2.1.1.1.3.2.1" xref="A1.E5.m2.1.1.1.3.1.1.cmml">‖</mo><mi id="A1.E5.m2.1.1.1.1" xref="A1.E5.m2.1.1.1.1.cmml">x</mi><mo stretchy="false" id="A1.E5.m2.1.1.1.3.2.2" xref="A1.E5.m2.1.1.1.3.1.1.cmml">‖</mo></mrow><mn id="A1.E5.m2.1.1.1.4" xref="A1.E5.m2.1.1.1.4.cmml">2</mn></msub><msub id="A1.E5.m2.2.2.2" xref="A1.E5.m2.2.2.2.cmml"><mrow id="A1.E5.m2.2.2.2.3.2" xref="A1.E5.m2.2.2.2.3.1.cmml"><mo stretchy="false" id="A1.E5.m2.2.2.2.3.2.1" xref="A1.E5.m2.2.2.2.3.1.1.cmml">‖</mo><mi id="A1.E5.m2.2.2.2.1" xref="A1.E5.m2.2.2.2.1.cmml">δ</mi><mo stretchy="false" id="A1.E5.m2.2.2.2.3.2.2" xref="A1.E5.m2.2.2.2.3.1.1.cmml">‖</mo></mrow><mn id="A1.E5.m2.2.2.2.4" xref="A1.E5.m2.2.2.2.4.cmml">2</mn></msub></mfrac></mstyle><mo id="A1.E5.m2.3.3.1.1.1.2.2" xref="A1.E5.m2.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E5.m2.3b"><apply id="A1.E5.m2.3.3.cmml" xref="A1.E5.m2.3.3"><eq id="A1.E5.m2.3.3.2.cmml" xref="A1.E5.m2.3.3.2"></eq><csymbol cd="latexml" id="A1.E5.m2.3.3.3.cmml" xref="A1.E5.m2.3.3.3">absent</csymbol><apply id="A1.E5.m2.3.3.1.cmml" xref="A1.E5.m2.3.3.1"><times id="A1.E5.m2.3.3.1.2.cmml" xref="A1.E5.m2.3.3.1.2"></times><cn type="integer" id="A1.E5.m2.3.3.1.3.cmml" xref="A1.E5.m2.3.3.1.3">20</cn><apply id="A1.E5.m2.3.3.1.1.2.cmml" xref="A1.E5.m2.3.3.1.1.1"><apply id="A1.E5.m2.3.3.1.1.1.1.cmml" xref="A1.E5.m2.3.3.1.1.1.1"><csymbol cd="ambiguous" id="A1.E5.m2.3.3.1.1.1.1.1.cmml" xref="A1.E5.m2.3.3.1.1.1.1">subscript</csymbol><log id="A1.E5.m2.3.3.1.1.1.1.2.cmml" xref="A1.E5.m2.3.3.1.1.1.1.2"></log><cn type="integer" id="A1.E5.m2.3.3.1.1.1.1.3.cmml" xref="A1.E5.m2.3.3.1.1.1.1.3">10</cn></apply><apply id="A1.E5.m2.2.2.cmml" xref="A1.E5.m2.2.2"><divide id="A1.E5.m2.2.2.3.cmml" xref="A1.E5.m2.2.2"></divide><apply id="A1.E5.m2.1.1.1.cmml" xref="A1.E5.m2.1.1.1"><csymbol cd="ambiguous" id="A1.E5.m2.1.1.1.2.cmml" xref="A1.E5.m2.1.1.1">subscript</csymbol><apply id="A1.E5.m2.1.1.1.3.1.cmml" xref="A1.E5.m2.1.1.1.3.2"><csymbol cd="latexml" id="A1.E5.m2.1.1.1.3.1.1.cmml" xref="A1.E5.m2.1.1.1.3.2.1">norm</csymbol><ci id="A1.E5.m2.1.1.1.1.cmml" xref="A1.E5.m2.1.1.1.1">𝑥</ci></apply><cn type="integer" id="A1.E5.m2.1.1.1.4.cmml" xref="A1.E5.m2.1.1.1.4">2</cn></apply><apply id="A1.E5.m2.2.2.2.cmml" xref="A1.E5.m2.2.2.2"><csymbol cd="ambiguous" id="A1.E5.m2.2.2.2.2.cmml" xref="A1.E5.m2.2.2.2">subscript</csymbol><apply id="A1.E5.m2.2.2.2.3.1.cmml" xref="A1.E5.m2.2.2.2.3.2"><csymbol cd="latexml" id="A1.E5.m2.2.2.2.3.1.1.cmml" xref="A1.E5.m2.2.2.2.3.2.1">norm</csymbol><ci id="A1.E5.m2.2.2.2.1.cmml" xref="A1.E5.m2.2.2.2.1">𝛿</ci></apply><cn type="integer" id="A1.E5.m2.2.2.2.4.cmml" xref="A1.E5.m2.2.2.2.4">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E5.m2.3c">\displaystyle=20\log_{10}\left(\frac{||x||_{2}}{||\delta||_{2}}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
<tbody id="A1.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E6.m1.1" class="ltx_Math" alttext="\displaystyle\epsilon_{\text{SNR}}=||\delta||_{2}" display="inline"><semantics id="A1.E6.m1.1a"><mrow id="A1.E6.m1.1.2" xref="A1.E6.m1.1.2.cmml"><msub id="A1.E6.m1.1.2.2" xref="A1.E6.m1.1.2.2.cmml"><mi id="A1.E6.m1.1.2.2.2" xref="A1.E6.m1.1.2.2.2.cmml">ϵ</mi><mtext id="A1.E6.m1.1.2.2.3" xref="A1.E6.m1.1.2.2.3a.cmml">SNR</mtext></msub><mo id="A1.E6.m1.1.2.1" xref="A1.E6.m1.1.2.1.cmml">=</mo><msub id="A1.E6.m1.1.2.3" xref="A1.E6.m1.1.2.3.cmml"><mrow id="A1.E6.m1.1.2.3.2.2" xref="A1.E6.m1.1.2.3.2.1.cmml"><mo stretchy="false" id="A1.E6.m1.1.2.3.2.2.1" xref="A1.E6.m1.1.2.3.2.1.1.cmml">‖</mo><mi id="A1.E6.m1.1.1" xref="A1.E6.m1.1.1.cmml">δ</mi><mo stretchy="false" id="A1.E6.m1.1.2.3.2.2.2" xref="A1.E6.m1.1.2.3.2.1.1.cmml">‖</mo></mrow><mn id="A1.E6.m1.1.2.3.3" xref="A1.E6.m1.1.2.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.E6.m1.1b"><apply id="A1.E6.m1.1.2.cmml" xref="A1.E6.m1.1.2"><eq id="A1.E6.m1.1.2.1.cmml" xref="A1.E6.m1.1.2.1"></eq><apply id="A1.E6.m1.1.2.2.cmml" xref="A1.E6.m1.1.2.2"><csymbol cd="ambiguous" id="A1.E6.m1.1.2.2.1.cmml" xref="A1.E6.m1.1.2.2">subscript</csymbol><ci id="A1.E6.m1.1.2.2.2.cmml" xref="A1.E6.m1.1.2.2.2">italic-ϵ</ci><ci id="A1.E6.m1.1.2.2.3a.cmml" xref="A1.E6.m1.1.2.2.3"><mtext mathsize="70%" id="A1.E6.m1.1.2.2.3.cmml" xref="A1.E6.m1.1.2.2.3">SNR</mtext></ci></apply><apply id="A1.E6.m1.1.2.3.cmml" xref="A1.E6.m1.1.2.3"><csymbol cd="ambiguous" id="A1.E6.m1.1.2.3.1.cmml" xref="A1.E6.m1.1.2.3">subscript</csymbol><apply id="A1.E6.m1.1.2.3.2.1.cmml" xref="A1.E6.m1.1.2.3.2.2"><csymbol cd="latexml" id="A1.E6.m1.1.2.3.2.1.1.cmml" xref="A1.E6.m1.1.2.3.2.2.1">norm</csymbol><ci id="A1.E6.m1.1.1.cmml" xref="A1.E6.m1.1.1">𝛿</ci></apply><cn type="integer" id="A1.E6.m1.1.2.3.3.cmml" xref="A1.E6.m1.1.2.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E6.m1.1c">\displaystyle\epsilon_{\text{SNR}}=||\delta||_{2}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E6.m2.2" class="ltx_Math" alttext="\displaystyle=10^{-\frac{\text{SNR}}{20}}||x||_{2}," display="inline"><semantics id="A1.E6.m2.2a"><mrow id="A1.E6.m2.2.2.1" xref="A1.E6.m2.2.2.1.1.cmml"><mrow id="A1.E6.m2.2.2.1.1" xref="A1.E6.m2.2.2.1.1.cmml"><mi id="A1.E6.m2.2.2.1.1.2" xref="A1.E6.m2.2.2.1.1.2.cmml"></mi><mo id="A1.E6.m2.2.2.1.1.1" xref="A1.E6.m2.2.2.1.1.1.cmml">=</mo><mrow id="A1.E6.m2.2.2.1.1.3" xref="A1.E6.m2.2.2.1.1.3.cmml"><msup id="A1.E6.m2.2.2.1.1.3.2" xref="A1.E6.m2.2.2.1.1.3.2.cmml"><mn id="A1.E6.m2.2.2.1.1.3.2.2" xref="A1.E6.m2.2.2.1.1.3.2.2.cmml">10</mn><mrow id="A1.E6.m2.2.2.1.1.3.2.3" xref="A1.E6.m2.2.2.1.1.3.2.3.cmml"><mo id="A1.E6.m2.2.2.1.1.3.2.3a" xref="A1.E6.m2.2.2.1.1.3.2.3.cmml">−</mo><mfrac id="A1.E6.m2.2.2.1.1.3.2.3.2" xref="A1.E6.m2.2.2.1.1.3.2.3.2.cmml"><mtext id="A1.E6.m2.2.2.1.1.3.2.3.2.2" xref="A1.E6.m2.2.2.1.1.3.2.3.2.2a.cmml">SNR</mtext><mn id="A1.E6.m2.2.2.1.1.3.2.3.2.3" xref="A1.E6.m2.2.2.1.1.3.2.3.2.3.cmml">20</mn></mfrac></mrow></msup><mo lspace="0em" rspace="0em" id="A1.E6.m2.2.2.1.1.3.1" xref="A1.E6.m2.2.2.1.1.3.1.cmml">​</mo><msub id="A1.E6.m2.2.2.1.1.3.3" xref="A1.E6.m2.2.2.1.1.3.3.cmml"><mrow id="A1.E6.m2.2.2.1.1.3.3.2.2" xref="A1.E6.m2.2.2.1.1.3.3.2.1.cmml"><mo stretchy="false" id="A1.E6.m2.2.2.1.1.3.3.2.2.1" xref="A1.E6.m2.2.2.1.1.3.3.2.1.1.cmml">‖</mo><mi id="A1.E6.m2.1.1" xref="A1.E6.m2.1.1.cmml">x</mi><mo stretchy="false" id="A1.E6.m2.2.2.1.1.3.3.2.2.2" xref="A1.E6.m2.2.2.1.1.3.3.2.1.1.cmml">‖</mo></mrow><mn id="A1.E6.m2.2.2.1.1.3.3.3" xref="A1.E6.m2.2.2.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><mo id="A1.E6.m2.2.2.1.2" xref="A1.E6.m2.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.E6.m2.2b"><apply id="A1.E6.m2.2.2.1.1.cmml" xref="A1.E6.m2.2.2.1"><eq id="A1.E6.m2.2.2.1.1.1.cmml" xref="A1.E6.m2.2.2.1.1.1"></eq><csymbol cd="latexml" id="A1.E6.m2.2.2.1.1.2.cmml" xref="A1.E6.m2.2.2.1.1.2">absent</csymbol><apply id="A1.E6.m2.2.2.1.1.3.cmml" xref="A1.E6.m2.2.2.1.1.3"><times id="A1.E6.m2.2.2.1.1.3.1.cmml" xref="A1.E6.m2.2.2.1.1.3.1"></times><apply id="A1.E6.m2.2.2.1.1.3.2.cmml" xref="A1.E6.m2.2.2.1.1.3.2"><csymbol cd="ambiguous" id="A1.E6.m2.2.2.1.1.3.2.1.cmml" xref="A1.E6.m2.2.2.1.1.3.2">superscript</csymbol><cn type="integer" id="A1.E6.m2.2.2.1.1.3.2.2.cmml" xref="A1.E6.m2.2.2.1.1.3.2.2">10</cn><apply id="A1.E6.m2.2.2.1.1.3.2.3.cmml" xref="A1.E6.m2.2.2.1.1.3.2.3"><minus id="A1.E6.m2.2.2.1.1.3.2.3.1.cmml" xref="A1.E6.m2.2.2.1.1.3.2.3"></minus><apply id="A1.E6.m2.2.2.1.1.3.2.3.2.cmml" xref="A1.E6.m2.2.2.1.1.3.2.3.2"><divide id="A1.E6.m2.2.2.1.1.3.2.3.2.1.cmml" xref="A1.E6.m2.2.2.1.1.3.2.3.2"></divide><ci id="A1.E6.m2.2.2.1.1.3.2.3.2.2a.cmml" xref="A1.E6.m2.2.2.1.1.3.2.3.2.2"><mtext mathsize="50%" id="A1.E6.m2.2.2.1.1.3.2.3.2.2.cmml" xref="A1.E6.m2.2.2.1.1.3.2.3.2.2">SNR</mtext></ci><cn type="integer" id="A1.E6.m2.2.2.1.1.3.2.3.2.3.cmml" xref="A1.E6.m2.2.2.1.1.3.2.3.2.3">20</cn></apply></apply></apply><apply id="A1.E6.m2.2.2.1.1.3.3.cmml" xref="A1.E6.m2.2.2.1.1.3.3"><csymbol cd="ambiguous" id="A1.E6.m2.2.2.1.1.3.3.1.cmml" xref="A1.E6.m2.2.2.1.1.3.3">subscript</csymbol><apply id="A1.E6.m2.2.2.1.1.3.3.2.1.cmml" xref="A1.E6.m2.2.2.1.1.3.3.2.2"><csymbol cd="latexml" id="A1.E6.m2.2.2.1.1.3.3.2.1.1.cmml" xref="A1.E6.m2.2.2.1.1.3.3.2.2.1">norm</csymbol><ci id="A1.E6.m2.1.1.cmml" xref="A1.E6.m2.1.1">𝑥</ci></apply><cn type="integer" id="A1.E6.m2.2.2.1.1.3.3.3.cmml" xref="A1.E6.m2.2.2.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E6.m2.2c">\displaystyle=10^{-\frac{\text{SNR}}{20}}||x||_{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="A1.SS0.SSS0.P0.SPx7.p1.3" class="ltx_p">where <math id="A1.SS0.SSS0.P0.SPx7.p1.1.m1.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="A1.SS0.SSS0.P0.SPx7.p1.1.m1.1a"><mi id="A1.SS0.SSS0.P0.SPx7.p1.1.m1.1.1" xref="A1.SS0.SSS0.P0.SPx7.p1.1.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.P0.SPx7.p1.1.m1.1b"><ci id="A1.SS0.SSS0.P0.SPx7.p1.1.m1.1.1.cmml" xref="A1.SS0.SSS0.P0.SPx7.p1.1.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.P0.SPx7.p1.1.m1.1c">\delta</annotation></semantics></math> is the noise, <math id="A1.SS0.SSS0.P0.SPx7.p1.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="A1.SS0.SSS0.P0.SPx7.p1.2.m2.1a"><mi id="A1.SS0.SSS0.P0.SPx7.p1.2.m2.1.1" xref="A1.SS0.SSS0.P0.SPx7.p1.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.P0.SPx7.p1.2.m2.1b"><ci id="A1.SS0.SSS0.P0.SPx7.p1.2.m2.1.1.cmml" xref="A1.SS0.SSS0.P0.SPx7.p1.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.P0.SPx7.p1.2.m2.1c">x</annotation></semantics></math> is the audio signal and SNR is the upper bound on the SNR in the final signal. Then, we follow the approach of <cite class="ltx_cite ltx_citemacro_citep">(Madry et al., <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite> and optimize <math id="A1.SS0.SSS0.P0.SPx7.p1.3.m3.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="A1.SS0.SSS0.P0.SPx7.p1.3.m3.1a"><mi id="A1.SS0.SSS0.P0.SPx7.p1.3.m3.1.1" xref="A1.SS0.SSS0.P0.SPx7.p1.3.m3.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.P0.SPx7.p1.3.m3.1b"><ci id="A1.SS0.SSS0.P0.SPx7.p1.3.m3.1.1.cmml" xref="A1.SS0.SSS0.P0.SPx7.p1.3.m3.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.P0.SPx7.p1.3.m3.1c">\delta</annotation></semantics></math> using Projected Gradient Descent (PGD) to maximize the divergence between the true and predicted transcriptions.</p>
</div>
</section>
<section id="A1.SS0.SSS0.P0.SPx8" class="ltx_subparagraph">
<h5 class="ltx_title ltx_title_subparagraph">Untargeted Utterance Agnostic Adversarial Attack:</h5>

<div id="A1.SS0.SSS0.P0.SPx8.p1" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx8.p1.1" class="ltx_p">We use the method of <cite class="ltx_cite ltx_citemacro_citep">(Neekhara et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite> to compute utterance agnostic adversarial perturbations. Concretely, we compute a single perturbation vector that can cause the accuracy of the model on several (ideally all) inputs to degrade severely. The main difference between the universal attack and the PGD attack is that the latter computes a perturbation vector for each input, whereas the former computes a single perturbation that is expected to successfully attack any input to the model. Once we compute the perturbation we add it to the audio signal at the specified SNR.</p>
</div>
<div id="A1.SS0.SSS0.P0.SPx8.p2" class="ltx_para">
<p id="A1.SS0.SSS0.P0.SPx8.p2.1" class="ltx_p">We use the <span id="A1.SS0.SSS0.P0.SPx8.p2.1.1" class="ltx_text ltx_font_typewriter">robust_speech</span> package <cite class="ltx_cite ltx_citemacro_citep">(Olivier &amp; Raj, <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite> to generate adversarial perturbations.</p>
<table id="A2.EGx5" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="A1.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A1.E7.m1.1" class="ltx_Math" alttext="\displaystyle\delta" display="inline"><semantics id="A1.E7.m1.1a"><mi id="A1.E7.m1.1.1" xref="A1.E7.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="A1.E7.m1.1b"><ci id="A1.E7.m1.1.1.cmml" xref="A1.E7.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.E7.m1.1c">\displaystyle\delta</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="A1.E7.m2.3" class="ltx_Math" alttext="\displaystyle=\max_{\hat{\delta}:||\hat{\delta}||_{2}\leq\epsilon_{\text{SNR}}}D(h_{\hat{\delta}},r)" display="inline"><semantics id="A1.E7.m2.3a"><mrow id="A1.E7.m2.3.3" xref="A1.E7.m2.3.3.cmml"><mi id="A1.E7.m2.3.3.3" xref="A1.E7.m2.3.3.3.cmml"></mi><mo id="A1.E7.m2.3.3.2" xref="A1.E7.m2.3.3.2.cmml">=</mo><mrow id="A1.E7.m2.3.3.1" xref="A1.E7.m2.3.3.1.cmml"><mrow id="A1.E7.m2.3.3.1.3" xref="A1.E7.m2.3.3.1.3.cmml"><munder id="A1.E7.m2.3.3.1.3.1" xref="A1.E7.m2.3.3.1.3.1.cmml"><mi id="A1.E7.m2.3.3.1.3.1.2" xref="A1.E7.m2.3.3.1.3.1.2.cmml">max</mi><mrow id="A1.E7.m2.1.1.1" xref="A1.E7.m2.1.1.1.cmml"><mover accent="true" id="A1.E7.m2.1.1.1.3" xref="A1.E7.m2.1.1.1.3.cmml"><mi id="A1.E7.m2.1.1.1.3.2" xref="A1.E7.m2.1.1.1.3.2.cmml">δ</mi><mo id="A1.E7.m2.1.1.1.3.1" xref="A1.E7.m2.1.1.1.3.1.cmml">^</mo></mover><mo lspace="0.278em" rspace="0.278em" id="A1.E7.m2.1.1.1.2" xref="A1.E7.m2.1.1.1.2.cmml">:</mo><mrow id="A1.E7.m2.1.1.1.4" xref="A1.E7.m2.1.1.1.4.cmml"><msub id="A1.E7.m2.1.1.1.4.2" xref="A1.E7.m2.1.1.1.4.2.cmml"><mrow id="A1.E7.m2.1.1.1.4.2.2.2" xref="A1.E7.m2.1.1.1.4.2.2.1.cmml"><mo maxsize="142%" minsize="142%" id="A1.E7.m2.1.1.1.4.2.2.2.1" xref="A1.E7.m2.1.1.1.4.2.2.1.1.cmml">‖</mo><mover accent="true" id="A1.E7.m2.1.1.1.1" xref="A1.E7.m2.1.1.1.1.cmml"><mi id="A1.E7.m2.1.1.1.1.2" xref="A1.E7.m2.1.1.1.1.2.cmml">δ</mi><mo id="A1.E7.m2.1.1.1.1.1" xref="A1.E7.m2.1.1.1.1.1.cmml">^</mo></mover><mo maxsize="142%" minsize="142%" id="A1.E7.m2.1.1.1.4.2.2.2.2" xref="A1.E7.m2.1.1.1.4.2.2.1.1.cmml">‖</mo></mrow><mn id="A1.E7.m2.1.1.1.4.2.3" xref="A1.E7.m2.1.1.1.4.2.3.cmml">2</mn></msub><mo id="A1.E7.m2.1.1.1.4.1" xref="A1.E7.m2.1.1.1.4.1.cmml">≤</mo><msub id="A1.E7.m2.1.1.1.4.3" xref="A1.E7.m2.1.1.1.4.3.cmml"><mi id="A1.E7.m2.1.1.1.4.3.2" xref="A1.E7.m2.1.1.1.4.3.2.cmml">ϵ</mi><mtext id="A1.E7.m2.1.1.1.4.3.3" xref="A1.E7.m2.1.1.1.4.3.3a.cmml">SNR</mtext></msub></mrow></mrow></munder><mo lspace="0.167em" id="A1.E7.m2.3.3.1.3a" xref="A1.E7.m2.3.3.1.3.cmml">⁡</mo><mi id="A1.E7.m2.3.3.1.3.2" xref="A1.E7.m2.3.3.1.3.2.cmml">D</mi></mrow><mo lspace="0em" rspace="0em" id="A1.E7.m2.3.3.1.2" xref="A1.E7.m2.3.3.1.2.cmml">​</mo><mrow id="A1.E7.m2.3.3.1.1.1" xref="A1.E7.m2.3.3.1.1.2.cmml"><mo stretchy="false" id="A1.E7.m2.3.3.1.1.1.2" xref="A1.E7.m2.3.3.1.1.2.cmml">(</mo><msub id="A1.E7.m2.3.3.1.1.1.1" xref="A1.E7.m2.3.3.1.1.1.1.cmml"><mi id="A1.E7.m2.3.3.1.1.1.1.2" xref="A1.E7.m2.3.3.1.1.1.1.2.cmml">h</mi><mover accent="true" id="A1.E7.m2.3.3.1.1.1.1.3" xref="A1.E7.m2.3.3.1.1.1.1.3.cmml"><mi id="A1.E7.m2.3.3.1.1.1.1.3.2" xref="A1.E7.m2.3.3.1.1.1.1.3.2.cmml">δ</mi><mo id="A1.E7.m2.3.3.1.1.1.1.3.1" xref="A1.E7.m2.3.3.1.1.1.1.3.1.cmml">^</mo></mover></msub><mo id="A1.E7.m2.3.3.1.1.1.3" xref="A1.E7.m2.3.3.1.1.2.cmml">,</mo><mi id="A1.E7.m2.2.2" xref="A1.E7.m2.2.2.cmml">r</mi><mo stretchy="false" id="A1.E7.m2.3.3.1.1.1.4" xref="A1.E7.m2.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E7.m2.3b"><apply id="A1.E7.m2.3.3.cmml" xref="A1.E7.m2.3.3"><eq id="A1.E7.m2.3.3.2.cmml" xref="A1.E7.m2.3.3.2"></eq><csymbol cd="latexml" id="A1.E7.m2.3.3.3.cmml" xref="A1.E7.m2.3.3.3">absent</csymbol><apply id="A1.E7.m2.3.3.1.cmml" xref="A1.E7.m2.3.3.1"><times id="A1.E7.m2.3.3.1.2.cmml" xref="A1.E7.m2.3.3.1.2"></times><apply id="A1.E7.m2.3.3.1.3.cmml" xref="A1.E7.m2.3.3.1.3"><apply id="A1.E7.m2.3.3.1.3.1.cmml" xref="A1.E7.m2.3.3.1.3.1"><csymbol cd="ambiguous" id="A1.E7.m2.3.3.1.3.1.1.cmml" xref="A1.E7.m2.3.3.1.3.1">subscript</csymbol><max id="A1.E7.m2.3.3.1.3.1.2.cmml" xref="A1.E7.m2.3.3.1.3.1.2"></max><apply id="A1.E7.m2.1.1.1.cmml" xref="A1.E7.m2.1.1.1"><ci id="A1.E7.m2.1.1.1.2.cmml" xref="A1.E7.m2.1.1.1.2">:</ci><apply id="A1.E7.m2.1.1.1.3.cmml" xref="A1.E7.m2.1.1.1.3"><ci id="A1.E7.m2.1.1.1.3.1.cmml" xref="A1.E7.m2.1.1.1.3.1">^</ci><ci id="A1.E7.m2.1.1.1.3.2.cmml" xref="A1.E7.m2.1.1.1.3.2">𝛿</ci></apply><apply id="A1.E7.m2.1.1.1.4.cmml" xref="A1.E7.m2.1.1.1.4"><leq id="A1.E7.m2.1.1.1.4.1.cmml" xref="A1.E7.m2.1.1.1.4.1"></leq><apply id="A1.E7.m2.1.1.1.4.2.cmml" xref="A1.E7.m2.1.1.1.4.2"><csymbol cd="ambiguous" id="A1.E7.m2.1.1.1.4.2.1.cmml" xref="A1.E7.m2.1.1.1.4.2">subscript</csymbol><apply id="A1.E7.m2.1.1.1.4.2.2.1.cmml" xref="A1.E7.m2.1.1.1.4.2.2.2"><csymbol cd="latexml" id="A1.E7.m2.1.1.1.4.2.2.1.1.cmml" xref="A1.E7.m2.1.1.1.4.2.2.2.1">norm</csymbol><apply id="A1.E7.m2.1.1.1.1.cmml" xref="A1.E7.m2.1.1.1.1"><ci id="A1.E7.m2.1.1.1.1.1.cmml" xref="A1.E7.m2.1.1.1.1.1">^</ci><ci id="A1.E7.m2.1.1.1.1.2.cmml" xref="A1.E7.m2.1.1.1.1.2">𝛿</ci></apply></apply><cn type="integer" id="A1.E7.m2.1.1.1.4.2.3.cmml" xref="A1.E7.m2.1.1.1.4.2.3">2</cn></apply><apply id="A1.E7.m2.1.1.1.4.3.cmml" xref="A1.E7.m2.1.1.1.4.3"><csymbol cd="ambiguous" id="A1.E7.m2.1.1.1.4.3.1.cmml" xref="A1.E7.m2.1.1.1.4.3">subscript</csymbol><ci id="A1.E7.m2.1.1.1.4.3.2.cmml" xref="A1.E7.m2.1.1.1.4.3.2">italic-ϵ</ci><ci id="A1.E7.m2.1.1.1.4.3.3a.cmml" xref="A1.E7.m2.1.1.1.4.3.3"><mtext mathsize="50%" id="A1.E7.m2.1.1.1.4.3.3.cmml" xref="A1.E7.m2.1.1.1.4.3.3">SNR</mtext></ci></apply></apply></apply></apply><ci id="A1.E7.m2.3.3.1.3.2.cmml" xref="A1.E7.m2.3.3.1.3.2">𝐷</ci></apply><interval closure="open" id="A1.E7.m2.3.3.1.1.2.cmml" xref="A1.E7.m2.3.3.1.1.1"><apply id="A1.E7.m2.3.3.1.1.1.1.cmml" xref="A1.E7.m2.3.3.1.1.1.1"><csymbol cd="ambiguous" id="A1.E7.m2.3.3.1.1.1.1.1.cmml" xref="A1.E7.m2.3.3.1.1.1.1">subscript</csymbol><ci id="A1.E7.m2.3.3.1.1.1.1.2.cmml" xref="A1.E7.m2.3.3.1.1.1.1.2">ℎ</ci><apply id="A1.E7.m2.3.3.1.1.1.1.3.cmml" xref="A1.E7.m2.3.3.1.1.1.1.3"><ci id="A1.E7.m2.3.3.1.1.1.1.3.1.cmml" xref="A1.E7.m2.3.3.1.1.1.1.3.1">^</ci><ci id="A1.E7.m2.3.3.1.1.1.1.3.2.cmml" xref="A1.E7.m2.3.3.1.1.1.1.3.2">𝛿</ci></apply></apply><ci id="A1.E7.m2.2.2.cmml" xref="A1.E7.m2.2.2">𝑟</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E7.m2.3c">\displaystyle=\max_{\hat{\delta}:||\hat{\delta}||_{2}\leq\epsilon_{\text{SNR}}}D(h_{\hat{\delta}},r)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<figure id="A1.T2" class="ltx_table">
<table id="A1.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T2.2.1.1" class="ltx_tr">
<th id="A1.T2.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Perturbation</th>
<td id="A1.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt">Sev 1</td>
<td id="A1.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Sev 2</td>
<td id="A1.T2.2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Sev 3</td>
<td id="A1.T2.2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">Sev 4</td>
</tr>
<tr id="A1.T2.2.2.2" class="ltx_tr">
<th id="A1.T2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Gaussian Noise</th>
<td id="A1.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">10 dB</td>
<td id="A1.T2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">5 dB</td>
<td id="A1.T2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">1 dB</td>
<td id="A1.T2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">-10 dB</td>
</tr>
<tr id="A1.T2.2.3.3" class="ltx_tr">
<th id="A1.T2.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Environmental Noise</th>
<td id="A1.T2.2.3.3.2" class="ltx_td ltx_align_center">10 dB</td>
<td id="A1.T2.2.3.3.3" class="ltx_td ltx_align_center">5 dB</td>
<td id="A1.T2.2.3.3.4" class="ltx_td ltx_align_center">1 dB</td>
<td id="A1.T2.2.3.3.5" class="ltx_td ltx_align_center">-10 dB</td>
</tr>
<tr id="A1.T2.2.4.4" class="ltx_tr">
<th id="A1.T2.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">RIR</th>
<td id="A1.T2.2.4.4.2" class="ltx_td ltx_align_center">2.66 dB</td>
<td id="A1.T2.2.4.4.3" class="ltx_td ltx_align_center">-1.48 dB</td>
<td id="A1.T2.2.4.4.4" class="ltx_td ltx_align_center">-2.82 dB</td>
<td id="A1.T2.2.4.4.5" class="ltx_td ltx_align_center">-4.10 dB</td>
</tr>
<tr id="A1.T2.2.5.5" class="ltx_tr">
<th id="A1.T2.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Resampling</th>
<td id="A1.T2.2.5.5.2" class="ltx_td ltx_align_center">0.75x</td>
<td id="A1.T2.2.5.5.3" class="ltx_td ltx_align_center">0.5x</td>
<td id="A1.T2.2.5.5.4" class="ltx_td ltx_align_center">0.25x</td>
<td id="A1.T2.2.5.5.5" class="ltx_td ltx_align_center">0.125x</td>
</tr>
<tr id="A1.T2.2.6.6" class="ltx_tr">
<th id="A1.T2.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Speed-up</th>
<td id="A1.T2.2.6.6.2" class="ltx_td ltx_align_center ltx_border_t">1.25x</td>
<td id="A1.T2.2.6.6.3" class="ltx_td ltx_align_center ltx_border_t">1.5x</td>
<td id="A1.T2.2.6.6.4" class="ltx_td ltx_align_center ltx_border_t">1.75x</td>
<td id="A1.T2.2.6.6.5" class="ltx_td ltx_align_center ltx_border_t">2x</td>
</tr>
<tr id="A1.T2.2.7.7" class="ltx_tr">
<th id="A1.T2.2.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Slow-down</th>
<td id="A1.T2.2.7.7.2" class="ltx_td ltx_align_center">0.875x</td>
<td id="A1.T2.2.7.7.3" class="ltx_td ltx_align_center">0.75</td>
<td id="A1.T2.2.7.7.4" class="ltx_td ltx_align_center">0.625x</td>
<td id="A1.T2.2.7.7.5" class="ltx_td ltx_align_center">0.5x</td>
</tr>
<tr id="A1.T2.2.8.8" class="ltx_tr">
<th id="A1.T2.2.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">tempo-up</th>
<td id="A1.T2.2.8.8.2" class="ltx_td ltx_align_center">1.25x</td>
<td id="A1.T2.2.8.8.3" class="ltx_td ltx_align_center">1.5x</td>
<td id="A1.T2.2.8.8.4" class="ltx_td ltx_align_center">1.75x</td>
<td id="A1.T2.2.8.8.5" class="ltx_td ltx_align_center">2x</td>
</tr>
<tr id="A1.T2.2.9.9" class="ltx_tr">
<th id="A1.T2.2.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">tempo-down</th>
<td id="A1.T2.2.9.9.2" class="ltx_td ltx_align_center">0.875x</td>
<td id="A1.T2.2.9.9.3" class="ltx_td ltx_align_center">0.75</td>
<td id="A1.T2.2.9.9.4" class="ltx_td ltx_align_center">0.625x</td>
<td id="A1.T2.2.9.9.5" class="ltx_td ltx_align_center">0.5x</td>
</tr>
<tr id="A1.T2.2.10.10" class="ltx_tr">
<th id="A1.T2.2.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Pitch Step-up</th>
<td id="A1.T2.2.10.10.2" class="ltx_td ltx_align_center">0.25 oct</td>
<td id="A1.T2.2.10.10.3" class="ltx_td ltx_align_center">0.5 oct</td>
<td id="A1.T2.2.10.10.4" class="ltx_td ltx_align_center">0.75 oct</td>
<td id="A1.T2.2.10.10.5" class="ltx_td ltx_align_center">1 oct</td>
</tr>
<tr id="A1.T2.2.11.11" class="ltx_tr">
<th id="A1.T2.2.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Pitch Step-down</th>
<td id="A1.T2.2.11.11.2" class="ltx_td ltx_align_center">0.25 oct</td>
<td id="A1.T2.2.11.11.3" class="ltx_td ltx_align_center">0.5 oct</td>
<td id="A1.T2.2.11.11.4" class="ltx_td ltx_align_center">0.75 oct</td>
<td id="A1.T2.2.11.11.5" class="ltx_td ltx_align_center">1 oct</td>
</tr>
<tr id="A1.T2.2.12.12" class="ltx_tr">
<th id="A1.T2.2.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Gain (factor)</th>
<td id="A1.T2.2.12.12.2" class="ltx_td ltx_align_center">10x</td>
<td id="A1.T2.2.12.12.3" class="ltx_td ltx_align_center">20x</td>
<td id="A1.T2.2.12.12.4" class="ltx_td ltx_align_center">30x</td>
<td id="A1.T2.2.12.12.5" class="ltx_td ltx_align_center">40x</td>
</tr>
<tr id="A1.T2.2.13.13" class="ltx_tr">
<th id="A1.T2.2.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Echo (delay)</th>
<td id="A1.T2.2.13.13.2" class="ltx_td ltx_align_center">125 ms</td>
<td id="A1.T2.2.13.13.3" class="ltx_td ltx_align_center">250 ms</td>
<td id="A1.T2.2.13.13.4" class="ltx_td ltx_align_center">500 ms</td>
<td id="A1.T2.2.13.13.5" class="ltx_td ltx_align_center">1000 ms</td>
</tr>
<tr id="A1.T2.2.14.14" class="ltx_tr">
<th id="A1.T2.2.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Phaser (decay)</th>
<td id="A1.T2.2.14.14.2" class="ltx_td ltx_align_center">0.3 s</td>
<td id="A1.T2.2.14.14.3" class="ltx_td ltx_align_center">0.5 s</td>
<td id="A1.T2.2.14.14.4" class="ltx_td ltx_align_center">0.7 s</td>
<td id="A1.T2.2.14.14.5" class="ltx_td ltx_align_center">0.9 s</td>
</tr>
<tr id="A1.T2.2.15.15" class="ltx_tr">
<th id="A1.T2.2.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Low-pass filter</th>
<td id="A1.T2.2.15.15.2" class="ltx_td ltx_align_center">4 kHz</td>
<td id="A1.T2.2.15.15.3" class="ltx_td ltx_align_center">2833 kHz</td>
<td id="A1.T2.2.15.15.4" class="ltx_td ltx_align_center">1666 kHz</td>
<td id="A1.T2.2.15.15.5" class="ltx_td ltx_align_center">500 kHz</td>
</tr>
<tr id="A1.T2.2.16.16" class="ltx_tr">
<th id="A1.T2.2.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">High-pass filter</th>
<td id="A1.T2.2.16.16.2" class="ltx_td ltx_align_center">500 kHz</td>
<td id="A1.T2.2.16.16.3" class="ltx_td ltx_align_center">1333 kHz</td>
<td id="A1.T2.2.16.16.4" class="ltx_td ltx_align_center">2166 kHz</td>
<td id="A1.T2.2.16.16.5" class="ltx_td ltx_align_center">3000 kHz</td>
</tr>
<tr id="A1.T2.2.17.17" class="ltx_tr">
<th id="A1.T2.2.17.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Voice Conversion</th>
<td id="A1.T2.2.17.17.2" class="ltx_td ltx_align_center ltx_border_t" colspan="4">N/A</td>
</tr>
<tr id="A1.T2.2.18.18" class="ltx_tr">
<th id="A1.T2.2.18.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">PGD Attack</th>
<td id="A1.T2.2.18.18.2" class="ltx_td ltx_align_center ltx_border_t">40 dB</td>
<td id="A1.T2.2.18.18.3" class="ltx_td ltx_align_center ltx_border_t">30 dB</td>
<td id="A1.T2.2.18.18.4" class="ltx_td ltx_align_center ltx_border_t">20 dB</td>
<td id="A1.T2.2.18.18.5" class="ltx_td ltx_align_center ltx_border_t">10dB</td>
</tr>
<tr id="A1.T2.2.19.19" class="ltx_tr">
<th id="A1.T2.2.19.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Utterance Agnostic Attack</th>
<td id="A1.T2.2.19.19.2" class="ltx_td ltx_align_center ltx_border_bb">40 dB</td>
<td id="A1.T2.2.19.19.3" class="ltx_td ltx_align_center ltx_border_bb">30 dB</td>
<td id="A1.T2.2.19.19.4" class="ltx_td ltx_align_center ltx_border_bb">20 dB</td>
<td id="A1.T2.2.19.19.5" class="ltx_td ltx_align_center ltx_border_bb">10dB</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="A1.T2.4.2" class="ltx_text" style="font-size:90%;">The parameters defining the various severity levels of the perturbations used in the proposed benchmark.</span></figcaption>
</figure>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Fine Grained Analyses</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">The following figures present fine-grained analyses of robustness. These figures may be referenced by the main text but were not included in the main body in the interest of space. Figures <a href="#A2.F7" title="Figure 7 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, and <a href="#A2.F11" title="Figure 11 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> present the breakdown by perturbation of the robustness of models on English and Spanish, respectively. Figure <a href="#A2.F9" title="Figure 9 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> presents a similar breakdown for prediction stability of the models, while Figure <a href="#A2.F8" title="Figure 8 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> presents a breakdown of robustness by severity. Figure <a href="#A2.F10" title="Figure 10 ‣ Appendix B Fine Grained Analyses ‣ Speech Robust Bench: A Robustness Benchmark For Speech Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> presents the robustness of models to adversarial attacks.</p>
</div>
<figure id="A2.F7" class="ltx_figure"><img src="/html/2403.07937/assets/icml/figures/augs-nonadv-cwe.png" id="A2.F7.g1" class="ltx_graphics ltx_img_landscape" width="538" height="284" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A2.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="A2.F7.3.2" class="ltx_text" style="font-size:90%;">NWER of the models on different augmentations, averaged over all severities.</span></figcaption>
</figure>
<figure id="A2.F8" class="ltx_figure"><img src="/html/2403.07937/assets/icml/figures/sev-cwe.png" id="A2.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="124" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="A2.F8.3.2" class="ltx_text" style="font-size:90%;">NWER as the severity of the augmentation is increased.</span></figcaption>
</figure>
<figure id="A2.F9" class="ltx_figure"><img src="/html/2403.07937/assets/icml/figures/pertRob-werv-noise.png" id="A2.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="A2.F9.3.2" class="ltx_text" style="font-size:90%;">The WERV of various models under Gaussian noise and environmental noise of SNR 10 dB</span></figcaption>
</figure>
<figure id="A2.F10" class="ltx_figure"><img src="/html/2403.07937/assets/icml/figures/adv.png" id="A2.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="180" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="A2.F10.3.2" class="ltx_text" style="font-size:90%;">The WER of the various models under general (blue) and specific (orange) adversarial perturbations. The green markers and line show the average WER on both perturbation types.</span></figcaption>
</figure>
<figure id="A2.F11" class="ltx_figure"><img src="/html/2403.07937/assets/icml/figures/augs-nonadv-cwe-es.png" id="A2.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="218" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="A2.F11.3.2" class="ltx_text" style="font-size:90%;">The NWER of Spanish only and Multi-Lingual models on Spanish utterances under various perturbations.</span></figcaption>
</figure>
<figure id="A2.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A2.F12.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/lwerr_en.png" id="A2.F12.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="475" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F12.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A2.F12.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.07937/assets/icml/figures/lwerr_es.png" id="A2.F12.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="526" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F12.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="A2.F12.3.2" class="ltx_text" style="font-size:90%;">Log WER Ratio between male and female speakers from Librispeech (English) (a) and Spanish Multilingual Librispeech (b).</span></figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.07936" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.07937" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.07937">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.07937" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.07938" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 17:50:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
