<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.10598] Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge</title><meta property="og:description" content="As computer-based applications are becoming more integrated into our daily lives, the importance of Speech Emotion Recognition (SER) has increased significantly.
Promoting research with innovative approaches in SER, th‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.10598">

<!--Generated on Sat Jul  6 00:48:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="font-size:90%;">Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text" style="font-size:90%;">As computer-based applications are becoming more integrated into our daily lives, the importance of Speech Emotion Recognition (SER) has increased significantly.
Promoting research with innovative approaches in SER, the Odyssey 2024 Speech Emotion Recognition Challenge was organized as part of the Odyssey 2024 Speaker and Language Recognition Workshop.
In this paper we describe the Double Multi-Head Attention Multimodal System developed for this challenge.
Pre-trained self-supervised models were used to extract informative acoustic and text features.
An early fusion strategy was adopted, where a Multi-Head Attention layer transforms these mixed features into complementary contextualized representations.
A second attention mechanism is then applied to pool these representations into an utterance-level vector.
Our proposed system achieved the third position in the categorical task ranking with a 34.41% Macro-F1 score, where 31 teams participated in total.</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text" style="font-size:90%;">Natural Human-Computer Interaction (HCI) is becoming more and more important as machines and computer-based applications are gaining significance in our daily lives </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib1" title="" class="ltx_ref">1</a><span id="S1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.4" class="ltx_text" style="font-size:90%;">.
A key step in HCI is to recognize and address people‚Äôs emotional states.
In addition, automatic emotion detection and classification are essential for automated tutoring systems, call centers, gaming, personal assistants and more.
For these reasons, progress in these technologies can enable transformative applications in diverse areas such as healthcare, security and defense, education and entertainment.
Humans use various modalities to express their emotions, such as speech, text, facial expressions or gestures.
Because of the subtle expressive behaviors that arise during human interactions, automatic emotion recognition from speech in realistic domains is still a challenging task </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S1.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.7" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text" style="font-size:90%;">Speech is essential for expressing a person‚Äôs emotional state through prosody and/or paralinguistic context.
In the domain of Speech Emotion Recognition (SER), Machine Learning (ML) models have been constructed relying on the utilization of hand-crafted features, such as Mel-frequency Cepstral Coefficients (MFCC), pitch, energy, entropy or zero-crossing rate </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S1.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.4" class="ltx_text" style="font-size:90%;">.
The correlation between different emotions and specific speech features is still uncertain, and ongoing research is being conducted to investigate specific speech representations that can effectively capture human emotions‚Äô patterns.
However, deep learning-based models do not require the extraction of a large set of hand-crafted features because they can learn the features that are relevant to the task from spectrograms or even directly from raw waveforms. Nevertheless, a large amount of training data is needed to construct these complex systems because a lack of it could result in poor generalization performance on unseen data conditions.</span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text" style="font-size:90%;">Emotions can also be captured using text information.
Several techniques have been developed to represent and model this type of data.
In many Natural Language Processing (NLP) applications, word and sentence embeddings (such as Word2Vec </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S1.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.4" class="ltx_text" style="font-size:90%;"> or BERT-based </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S1.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.7" class="ltx_text" style="font-size:90%;">) have proven to be the most efficient representations, yielding significant improvements in deep learning models performance.
Despite offering an enhanced representation of textual information, these techniques have certain limitations when applying them effectively to different tasks.
One of the principal difficulties is that training these models requires huge amounts of data and computational power.</span></p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text" style="font-size:90%;">The Odyssey2024 Speech Emotion Recognition Challenge </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S1.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.4" class="ltx_text" style="font-size:90%;"> was organized as part of the Odyssey 2024 Speaker and Language Recognition Workshop to compare different emotion recognition systems submitted by teams all around the world.
The challenge consists of two independent tasks allowing to compare different emotion recognition systems submitted by teams all around the world.
The first task objective is to classify speech segments across the eight categorical emotional classes provided: anger, happiness, sadness, fear, surprise, contempt, disgust and a neutral state.
The second task consists of predicting emotional attributes for arousal (calm to active), valence (negative to positive), and dominance (weak to strong).
The challenge uses recordings from the MSP-Podcast corpus, which contains speech segments obtained from audio-sharing websites </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S1.p4.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.7" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text" style="font-size:90%;">In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S1.p5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p5.1.4" class="ltx_text" style="font-size:90%;">, the authors proposed a sub-vector-based multi-head attention pooling to efficiently obtain discriminative speaker embeddings given non-fixed-length speech utterances.
In this system, a Convolutional Neural Network (CNN) encodes short-term speaker features from the spectrogram, which are split into homogeneous sub-vectors.
Each self-attention pooling head is applied over a split of sub-vectors.
This mechanism allows the model to attend to the most informative patterns from different positions of the encoded sequence.
In a later work </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p5.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S1.p5.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p5.1.7" class="ltx_text" style="font-size:90%;">, the authors present the Double Multi-Head Attention (DMHA), where a second self-attention pooling is applied.
This additional pooling layer allows the model to select which head context vectors are the most relevant to produce an enhanced utterance-level vector.
Since this network is trained as a speaker classifier, it can be easily adapted to solve Speaker Classification tasks such as SER </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p5.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S1.p5.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p5.1.10" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text" style="font-size:90%;">In this paper we describe our Double Multi-Head Attention Multimodal System.
We used this architecture for the Odyssey 2024 Speech Emotion Recognition Challenge categorical recognition task.
Since self-supervised pre-trained models learn universal representations from massive unlabeled speech data and adapt effectively across various downstream tasks, several pre-trained versions of these architectures were explored to extract acoustic features.
Additionally, speech utterances were automatically transcribed with Whisper </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S1.p6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p6.1.4" class="ltx_text" style="font-size:90%;"> and then text features were extracted using a pre-trained BERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p6.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S1.p6.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p6.1.7" class="ltx_text" style="font-size:90%;"> model.
A Multi-Head Attention layer is used to transform these speech and text features into contextualized representations.
Using this attention technique allows the model to learn complex relationships between acoustic and linguistic information.
These contextualized representations are then pooled into an utterance-level vector using a second attention mechanism.
Finally, we used a set of fully connected layers to classify the corresponding emotions.
Models were trained by applying an on-line data augmentation process.
Three different models were used in a hard-voting ensemble to achieve the third position in the Task 1 Challenge ranking, where 31 teams participated in total.</span></p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p"><span id="S1.p7.1.1" class="ltx_text" style="font-size:90%;">The rest of this paper is structured as follows.
In Section 2 we describe several studies that are related to our work.
In Section 3 Double Multi-Head Attention is explained.
Section 4 details our proposed system.
In Section 5 experimental setups and results are included.
Concluding remarks are given in Section 6.</span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text" style="font-size:90%;">Deep Neural Networks have demonstrated remarkable success in extracting emotions from speech signals in the last years </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.4" class="ltx_text" style="font-size:90%;">.
Commonly, a SER system includes a feature extraction component and a pooling layer that aggregates the extracted features into a single utterance-level vector.
Finally, a classification layer takes the pooled vector as input and outputs each emotion probability.
Nevertheless, the automatic recognition of emotions from speech in realistic domains remains a significant challenge, primarily due to the intricate nature of expressive behaviors that manifest during human interactions.</span></p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text" style="font-size:90%;">One major obstacle in SER is still the lack of substantial amounts of labelled data needed to construct complex enough deep learning models </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="S2.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p2.1.4" class="ltx_text" style="font-size:90%;">.
To address this problem, several data augmentation methods were developed to generate synthetic data </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S2.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p2.1.7" class="ltx_text" style="font-size:90%;">.
Additionally, unsupervised or self-supervised pre-training of neural networks emerged as an effective technique for settings where labelled data is scarce.
The key idea is to learn general representations in a setup where substantial amounts of data are available.
These learned representations are then used to improve performance on a downstream task for which the amount of data is limited.
This is particularly interesting for tasks like SER, where a substantial effort to obtain labelled data is required.</span></p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text" style="font-size:90%;">SER systems take audio signals as input.
In order to improve the performance of these systems, a feature extraction process is usually applied.
In this process, features are extracted from the audio signal by changing the speech waveform to a form of parametric representation.
Several options are available to parametrically represent the speech signal for the recognition process.
The Mel-frequency Cepstral Coefficients (MFCC) feature extraction strategy is recognized as one of the most effective and universally adopted techniques in the speech recognition domain </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S2.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p3.1.4" class="ltx_text" style="font-size:90%;">.
Nevertheless, there are no guarantees that these hand-crafted features are optimal for all speech-related tasks and they might limit the potential of the powerful representation of DNN systems.</span></p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text" style="font-size:90%;">To mitigate this drawback, some works aim to extract learnable acoustic features from the raw audio waveforms.
In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S2.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.4" class="ltx_text" style="font-size:90%;">, the wav2vec2.0 architecture quantizes continuous speech data into discrete units automatically and then guesses the correct discrete units at randomly masked locations using Transformers </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S2.p4.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.7" class="ltx_text" style="font-size:90%;">.
XLS-R </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S2.p4.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.10" class="ltx_text" style="font-size:90%;"> is a large-scale model for cross-lingual speech representation learning based on wav2vec2.0.
Since it covers a wide range of languages, data regimes and domains, it shows a remarkable generalization capacity.
Hidden-Unit BERT (HuBERT) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S2.p4.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.13" class="ltx_text" style="font-size:90%;"> is another self-supervised speech representation learning approach, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss.
WavLM </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S2.p4.1.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.16" class="ltx_text" style="font-size:90%;"> jointly learns masked speech prediction and denoising in pre-training.
Some inputs are simulated noisy/overlapped speech with masks and the target is to predict the pseudo-label of the original speech on the masked region like HuBERT.
By doing this, wavLM learns universal speech representations from massive unlabeled speech data and adapts effectively across various speech processing tasks.</span></p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text" style="font-size:90%;">Regarding text feature extraction methods, word embeddings have become the standard representation in many natural language processing tasks, being Word2Vec </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S2.p5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p5.1.4" class="ltx_text" style="font-size:90%;"> and GloVe </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p5.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S2.p5.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p5.1.7" class="ltx_text" style="font-size:90%;"> some of the most widely adopted.
Both unsupervised models have shown great success in a range of NLP tasks such as sentiment analysis, document indexing, and topic model analysis.
Nevertheless, a significant drawback of these models is that they ignore word order, which results in a loss of syntactic and semantic information of words in sentences.
By extracting representations from text data to capture the context, BERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p5.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S2.p5.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p5.1.10" class="ltx_text" style="font-size:90%;"> models are used to solve this limitation.
BERT stands for Bidirectional Encoder Representations from Transformers and is a language model trained on large amounts of unlabelled text data that has achieved state-of-the-art results on many NLP tasks.
In order to enhance the performance of emotion recognition, several studies have effectively combined speech-based representations with BERT-based embeddings </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p5.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a><span id="S2.p5.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p5.1.13" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p"><span id="S2.p6.1.1" class="ltx_text" style="font-size:90%;">Pooling strategies can be classified into two main classes: statistical and learning-based pooling.
Within the statistical pooling strategies, the most commonly used are average pooling and statistical pooling </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a><span id="S2.p6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p6.1.4" class="ltx_text" style="font-size:90%;">.
These strategies assume that all elements of the pooling component input vectors contribute equally to the utterance-level vector creation.
Since every frame may not provide equal speech discriminative information, many works applied self-attention mechanisms for weighted learning-based pooling layers.
Single-head attention pooling with different self-attentive scoring functions was explored in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p6.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a><span id="S2.p6.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p6.1.7" class="ltx_text" style="font-size:90%;">.
Also, multi-head attention pooling approaches were applied successfully in several works </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p6.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S2.p6.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p6.1.10" class="ltx_text" style="font-size:90%;">.
Because pooling layers behave differently with different datasets, network structures or loss functions, it is difficult to conclude which one is the best, if there is one.
Pooling functions with learnable parameters achieved better results than the simple pooling layers such as the average pooling and statistical pooling in most cases, with a weakness of higher computational complexity than the latter.</span></p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p"><span id="S2.p7.1.1" class="ltx_text" style="font-size:90%;">Multimodal emotion recognition (MER) aims to identify human emotional states by combining different data modalities such as text, speech, images or videos.
With the advance of deep learning technologies and the increasing availability of multimodal datasets many MER systems have been explored </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p7.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a><span id="S2.p7.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p7.1.4" class="ltx_text" style="font-size:90%;">.
The expressiveness of unimodal information is naturally restricted, so it frequently fails to fully convey the wide range of human emotions.
Since spoken data consists of audio and text information, studies have explored the combination of acoustic features and linguistic content for emotion recognition.
The fusion of diverse types of signals to obtain complementary information is key to improving model performance in MER.
These approaches implement this combination by mixing either each modality embeddings (known as early fusion) or decision scores (late fusion) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p7.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a><span id="S2.p7.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p7.1.7" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Double Multi-Head Attention</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p"><span id="S3.p1.1.1" class="ltx_text" style="font-size:90%;">Attention mechanisms have become a standard component of deep learning networks, contributing to remarkable results improvements </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib37" title="" class="ltx_ref">37</a><span id="S3.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p1.1.4" class="ltx_text" style="font-size:90%;">.
In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S3.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p1.1.7" class="ltx_text" style="font-size:90%;">, a Multi-Head Attention (MHA) mechanism was proposed.
Instead of performing a single attention function, first the queries, keys and values are projected </span><math id="S3.p1.1.m1.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.p1.1.m1.1a"><mi mathsize="90%" id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">H</annotation></semantics></math><span id="S3.p1.1.8" class="ltx_text" style="font-size:90%;"> times with different learned linear projections.
Then, an attention function is applied over each of these projected versions of queries, keys and values.</span></p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.2" class="ltx_p"><span id="S3.p2.2.1" class="ltx_text" style="font-size:90%;">In </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p2.2.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S3.p2.2.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p2.2.4" class="ltx_text" style="font-size:90%;">, the authors used a sub-vector-based MHA pooling as an efficient mechanism to obtain discriminative speaker embeddings from speech utterances.
Frame-level features are split into </span><math id="S3.p2.1.m1.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.p2.1.m1.1a"><mi mathsize="90%" id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">H</annotation></semantics></math><span id="S3.p2.2.5" class="ltx_text" style="font-size:90%;"> sets of equally-sized sub-vectors and an attention pooling is applied over each set of sub-vectors.
The attention performed over each set of sub-vectors is a dot-product attention, where the keys and the values projections are the sub-vectors and there is only one trainable query.
In contrast with standard MHA </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p2.2.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S3.p2.2.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p2.2.8" class="ltx_text" style="font-size:90%;">, this sub-vector MHA outputs </span><math id="S3.p2.2.m2.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.p2.2.m2.1a"><mi mathsize="90%" id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">H</annotation></semantics></math><span id="S3.p2.2.9" class="ltx_text" style="font-size:90%;"> pooled vectors and significantly reduces the number of learnable parameters.</span></p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text" style="font-size:90%;">In the architecture designed in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S3.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p3.1.4" class="ltx_text" style="font-size:90%;">, the authors extracted speech features from the spectrogram using a CNN component.
In this paper we extract features directly from the raw waveform with pre-trained self-supervised models, allowing to remove the CNN component.
Combining this removal with a Data Augmentation process enables to significantly increase the number of parameters of the model without losing its generalization ability beyond the training data.
Motivated by this, we experiment replacing the efficient sub-vector MHA </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S3.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p3.1.7" class="ltx_text" style="font-size:90%;"> layer with a standard MHA </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p3.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S3.p3.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p3.1.10" class="ltx_text" style="font-size:90%;"> layer, allowing the model to capture more complex relationships and patterns.</span></p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text" style="font-size:90%;">In a later work </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S3.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p4.1.4" class="ltx_text" style="font-size:90%;">, the authors presented the Double MHA (DMHA) approach.
After a first sub-vector-based MHA layer, a second attention layer is applied.
This additional layer uses an attention pooling mechanism over the first layer output vectors by performing a dot-product attention, where the keys and the values projections are the vectors and there is only one trainable query.
This second layer allows the model to select which vectors are the most relevant to produce the final pooled vector.</span></p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p"><span id="S3.p5.1.1" class="ltx_text" style="font-size:90%;">Standard and sub-vector variants for the first attention layer of the DMHA are formulated in subsections </span><a href="#S3.SS1" title="3.1 Standard Multi-Head Attention ‚Ä£ 3 Double Multi-Head Attention ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3.1</span></a><span id="S3.p5.1.2" class="ltx_text" style="font-size:90%;"> and </span><a href="#S3.SS2" title="3.2 Sub-vector Multi-Head Attention ‚Ä£ 3 Double Multi-Head Attention ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3.2</span></a><span id="S3.p5.1.3" class="ltx_text" style="font-size:90%;">.
The second attention layer of the DMHA architecture is explained in subsection </span><a href="#S3.SS3" title="3.3 Attention Pooling ‚Ä£ 3 Double Multi-Head Attention ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3.3</span></a><span id="S3.p5.1.4" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Standard Multi-Head Attention</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.8" class="ltx_p"><span id="S3.SS1.p1.8.1" class="ltx_text" style="font-size:90%;">Given a sequence of hidden-states </span><math id="S3.SS1.p1.1.m1.5" class="ltx_Math" alttext="\{h_{t}\in\mathbb{R}^{D}\mbox{ }|\mbox{ }t=1,...,T\}" display="inline"><semantics id="S3.SS1.p1.1.m1.5a"><mrow id="S3.SS1.p1.1.m1.5.5.2" xref="S3.SS1.p1.1.m1.5.5.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS1.p1.1.m1.5.5.2.3" xref="S3.SS1.p1.1.m1.5.5.3.1.cmml">{</mo><mrow id="S3.SS1.p1.1.m1.4.4.1.1" xref="S3.SS1.p1.1.m1.4.4.1.1.cmml"><msub id="S3.SS1.p1.1.m1.4.4.1.1.2" xref="S3.SS1.p1.1.m1.4.4.1.1.2.cmml"><mi mathsize="90%" id="S3.SS1.p1.1.m1.4.4.1.1.2.2" xref="S3.SS1.p1.1.m1.4.4.1.1.2.2.cmml">h</mi><mi mathsize="90%" id="S3.SS1.p1.1.m1.4.4.1.1.2.3" xref="S3.SS1.p1.1.m1.4.4.1.1.2.3.cmml">t</mi></msub><mo mathsize="90%" id="S3.SS1.p1.1.m1.4.4.1.1.1" xref="S3.SS1.p1.1.m1.4.4.1.1.1.cmml">‚àà</mo><mrow id="S3.SS1.p1.1.m1.4.4.1.1.3" xref="S3.SS1.p1.1.m1.4.4.1.1.3.cmml"><msup id="S3.SS1.p1.1.m1.4.4.1.1.3.2" xref="S3.SS1.p1.1.m1.4.4.1.1.3.2.cmml"><mi mathsize="90%" id="S3.SS1.p1.1.m1.4.4.1.1.3.2.2" xref="S3.SS1.p1.1.m1.4.4.1.1.3.2.2.cmml">‚Ñù</mi><mi mathsize="90%" id="S3.SS1.p1.1.m1.4.4.1.1.3.2.3" xref="S3.SS1.p1.1.m1.4.4.1.1.3.2.3.cmml">D</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.4.4.1.1.3.1" xref="S3.SS1.p1.1.m1.4.4.1.1.3.1.cmml">‚Äã</mo><mtext mathsize="90%" id="S3.SS1.p1.1.m1.4.4.1.1.3.3" xref="S3.SS1.p1.1.m1.4.4.1.1.3.3a.cmml">¬†</mtext></mrow></mrow><mo lspace="0em" mathsize="90%" rspace="0em" id="S3.SS1.p1.1.m1.5.5.2.4" xref="S3.SS1.p1.1.m1.5.5.3.1.cmml">|</mo><mrow id="S3.SS1.p1.1.m1.5.5.2.2" xref="S3.SS1.p1.1.m1.5.5.2.2.cmml"><mrow id="S3.SS1.p1.1.m1.5.5.2.2.2" xref="S3.SS1.p1.1.m1.5.5.2.2.2.cmml"><mtext mathsize="90%" id="S3.SS1.p1.1.m1.5.5.2.2.2.2" xref="S3.SS1.p1.1.m1.5.5.2.2.2.2a.cmml">¬†</mtext><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.5.5.2.2.2.1" xref="S3.SS1.p1.1.m1.5.5.2.2.2.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS1.p1.1.m1.5.5.2.2.2.3" xref="S3.SS1.p1.1.m1.5.5.2.2.2.3.cmml">t</mi></mrow><mo mathsize="90%" id="S3.SS1.p1.1.m1.5.5.2.2.1" xref="S3.SS1.p1.1.m1.5.5.2.2.1.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.5.5.2.2.3.2" xref="S3.SS1.p1.1.m1.5.5.2.2.3.1.cmml"><mn mathsize="90%" id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">1</mn><mo mathsize="90%" id="S3.SS1.p1.1.m1.5.5.2.2.3.2.1" xref="S3.SS1.p1.1.m1.5.5.2.2.3.1.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.SS1.p1.1.m1.5.5.2.2.3.2.2" xref="S3.SS1.p1.1.m1.5.5.2.2.3.1.cmml">,</mo><mi mathsize="90%" id="S3.SS1.p1.1.m1.3.3" xref="S3.SS1.p1.1.m1.3.3.cmml">T</mi></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.SS1.p1.1.m1.5.5.2.5" xref="S3.SS1.p1.1.m1.5.5.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.5b"><apply id="S3.SS1.p1.1.m1.5.5.3.cmml" xref="S3.SS1.p1.1.m1.5.5.2"><csymbol cd="latexml" id="S3.SS1.p1.1.m1.5.5.3.1.cmml" xref="S3.SS1.p1.1.m1.5.5.2.3">conditional-set</csymbol><apply id="S3.SS1.p1.1.m1.4.4.1.1.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1"><in id="S3.SS1.p1.1.m1.4.4.1.1.1.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.1"></in><apply id="S3.SS1.p1.1.m1.4.4.1.1.2.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.4.4.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.4.4.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.2.2">‚Ñé</ci><ci id="S3.SS1.p1.1.m1.4.4.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.2.3">ùë°</ci></apply><apply id="S3.SS1.p1.1.m1.4.4.1.1.3.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.3"><times id="S3.SS1.p1.1.m1.4.4.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.3.1"></times><apply id="S3.SS1.p1.1.m1.4.4.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.4.4.1.1.3.2.1.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.3.2">superscript</csymbol><ci id="S3.SS1.p1.1.m1.4.4.1.1.3.2.2.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.3.2.2">‚Ñù</ci><ci id="S3.SS1.p1.1.m1.4.4.1.1.3.2.3.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.3.2.3">ùê∑</ci></apply><ci id="S3.SS1.p1.1.m1.4.4.1.1.3.3a.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.3.3"><mtext mathsize="90%" id="S3.SS1.p1.1.m1.4.4.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.4.4.1.1.3.3">¬†</mtext></ci></apply></apply><apply id="S3.SS1.p1.1.m1.5.5.2.2.cmml" xref="S3.SS1.p1.1.m1.5.5.2.2"><eq id="S3.SS1.p1.1.m1.5.5.2.2.1.cmml" xref="S3.SS1.p1.1.m1.5.5.2.2.1"></eq><apply id="S3.SS1.p1.1.m1.5.5.2.2.2.cmml" xref="S3.SS1.p1.1.m1.5.5.2.2.2"><times id="S3.SS1.p1.1.m1.5.5.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.5.5.2.2.2.1"></times><ci id="S3.SS1.p1.1.m1.5.5.2.2.2.2a.cmml" xref="S3.SS1.p1.1.m1.5.5.2.2.2.2"><mtext mathsize="90%" id="S3.SS1.p1.1.m1.5.5.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.5.5.2.2.2.2">¬†</mtext></ci><ci id="S3.SS1.p1.1.m1.5.5.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.5.5.2.2.2.3">ùë°</ci></apply><list id="S3.SS1.p1.1.m1.5.5.2.2.3.1.cmml" xref="S3.SS1.p1.1.m1.5.5.2.2.3.2"><cn type="integer" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">1</cn><ci id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2">‚Ä¶</ci><ci id="S3.SS1.p1.1.m1.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3">ùëá</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.5c">\{h_{t}\in\mathbb{R}^{D}\mbox{ }|\mbox{ }t=1,...,T\}</annotation></semantics></math><span id="S3.SS1.p1.8.2" class="ltx_text" style="font-size:90%;">, the output of a </span><math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi mathsize="90%" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">H</annotation></semantics></math><span id="S3.SS1.p1.8.3" class="ltx_text" style="font-size:90%;">-headed standard MHA </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1.p1.8.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S3.SS1.p1.8.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS1.p1.8.6" class="ltx_text" style="font-size:90%;"> layer are </span><math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi mathsize="90%" id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">T</annotation></semantics></math><span id="S3.SS1.p1.8.7" class="ltx_text" style="font-size:90%;"> vectors.
These are computed using learnable matrices </span><math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="W_{j}^{Q}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msubsup id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p1.4.m4.1.1.2.2" xref="S3.SS1.p1.4.m4.1.1.2.2.cmml">W</mi><mi mathsize="90%" id="S3.SS1.p1.4.m4.1.1.2.3" xref="S3.SS1.p1.4.m4.1.1.2.3.cmml">j</mi><mi mathsize="90%" id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">Q</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">superscript</csymbol><apply id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.2.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2.2">ùëä</ci><ci id="S3.SS1.p1.4.m4.1.1.2.3.cmml" xref="S3.SS1.p1.4.m4.1.1.2.3">ùëó</ci></apply><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">ùëÑ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">W_{j}^{Q}</annotation></semantics></math><span id="S3.SS1.p1.8.8" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="W_{j}^{K}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><msubsup id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p1.5.m5.1.1.2.2" xref="S3.SS1.p1.5.m5.1.1.2.2.cmml">W</mi><mi mathsize="90%" id="S3.SS1.p1.5.m5.1.1.2.3" xref="S3.SS1.p1.5.m5.1.1.2.3.cmml">j</mi><mi mathsize="90%" id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">K</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">superscript</csymbol><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2">ùëä</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3">ùëó</ci></apply><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">ùêæ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">W_{j}^{K}</annotation></semantics></math><span id="S3.SS1.p1.8.9" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="W_{j}^{V}\in\mathbb{R}^{D\times D}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mrow id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><msubsup id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml"><mi mathsize="90%" id="S3.SS1.p1.6.m6.1.1.2.2.2" xref="S3.SS1.p1.6.m6.1.1.2.2.2.cmml">W</mi><mi mathsize="90%" id="S3.SS1.p1.6.m6.1.1.2.2.3" xref="S3.SS1.p1.6.m6.1.1.2.2.3.cmml">j</mi><mi mathsize="90%" id="S3.SS1.p1.6.m6.1.1.2.3" xref="S3.SS1.p1.6.m6.1.1.2.3.cmml">V</mi></msubsup><mo mathsize="90%" id="S3.SS1.p1.6.m6.1.1.1" xref="S3.SS1.p1.6.m6.1.1.1.cmml">‚àà</mo><msup id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml"><mi mathsize="90%" id="S3.SS1.p1.6.m6.1.1.3.2" xref="S3.SS1.p1.6.m6.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS1.p1.6.m6.1.1.3.3" xref="S3.SS1.p1.6.m6.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS1.p1.6.m6.1.1.3.3.2" xref="S3.SS1.p1.6.m6.1.1.3.3.2.cmml">D</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.SS1.p1.6.m6.1.1.3.3.1" xref="S3.SS1.p1.6.m6.1.1.3.3.1.cmml">√ó</mo><mi mathsize="90%" id="S3.SS1.p1.6.m6.1.1.3.3.3" xref="S3.SS1.p1.6.m6.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><in id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1"></in><apply id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.2.1.cmml" xref="S3.SS1.p1.6.m6.1.1.2">superscript</csymbol><apply id="S3.SS1.p1.6.m6.1.1.2.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.2.2.1.cmml" xref="S3.SS1.p1.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.2.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2.2.2">ùëä</ci><ci id="S3.SS1.p1.6.m6.1.1.2.2.3.cmml" xref="S3.SS1.p1.6.m6.1.1.2.2.3">ùëó</ci></apply><ci id="S3.SS1.p1.6.m6.1.1.2.3.cmml" xref="S3.SS1.p1.6.m6.1.1.2.3">ùëâ</ci></apply><apply id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.3.2">‚Ñù</ci><apply id="S3.SS1.p1.6.m6.1.1.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3"><times id="S3.SS1.p1.6.m6.1.1.3.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3.1"></times><ci id="S3.SS1.p1.6.m6.1.1.3.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3.2">ùê∑</ci><ci id="S3.SS1.p1.6.m6.1.1.3.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3.3">ùê∑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">W_{j}^{V}\in\mathbb{R}^{D\times D}</annotation></semantics></math><span id="S3.SS1.p1.8.10" class="ltx_text" style="font-size:90%;"> for each head </span><math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi mathsize="90%" id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">ùëó</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">j</annotation></semantics></math><span id="S3.SS1.p1.8.11" class="ltx_text" style="font-size:90%;">, and </span><math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="W^{O}\in\mathbb{R}^{HD\times D}" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mrow id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><msup id="S3.SS1.p1.8.m8.1.1.2" xref="S3.SS1.p1.8.m8.1.1.2.cmml"><mi mathsize="90%" id="S3.SS1.p1.8.m8.1.1.2.2" xref="S3.SS1.p1.8.m8.1.1.2.2.cmml">W</mi><mi mathsize="90%" id="S3.SS1.p1.8.m8.1.1.2.3" xref="S3.SS1.p1.8.m8.1.1.2.3.cmml">O</mi></msup><mo mathsize="90%" id="S3.SS1.p1.8.m8.1.1.1" xref="S3.SS1.p1.8.m8.1.1.1.cmml">‚àà</mo><msup id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml"><mi mathsize="90%" id="S3.SS1.p1.8.m8.1.1.3.2" xref="S3.SS1.p1.8.m8.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS1.p1.8.m8.1.1.3.3" xref="S3.SS1.p1.8.m8.1.1.3.3.cmml"><mrow id="S3.SS1.p1.8.m8.1.1.3.3.2" xref="S3.SS1.p1.8.m8.1.1.3.3.2.cmml"><mi mathsize="90%" id="S3.SS1.p1.8.m8.1.1.3.3.2.2" xref="S3.SS1.p1.8.m8.1.1.3.3.2.2.cmml">H</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.8.m8.1.1.3.3.2.1" xref="S3.SS1.p1.8.m8.1.1.3.3.2.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS1.p1.8.m8.1.1.3.3.2.3" xref="S3.SS1.p1.8.m8.1.1.3.3.2.3.cmml">D</mi></mrow><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.SS1.p1.8.m8.1.1.3.3.1" xref="S3.SS1.p1.8.m8.1.1.3.3.1.cmml">√ó</mo><mi mathsize="90%" id="S3.SS1.p1.8.m8.1.1.3.3.3" xref="S3.SS1.p1.8.m8.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><in id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1.1"></in><apply id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.2.1.cmml" xref="S3.SS1.p1.8.m8.1.1.2">superscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.2.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2.2">ùëä</ci><ci id="S3.SS1.p1.8.m8.1.1.2.3.cmml" xref="S3.SS1.p1.8.m8.1.1.2.3">ùëÇ</ci></apply><apply id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.3.1.cmml" xref="S3.SS1.p1.8.m8.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.3.2.cmml" xref="S3.SS1.p1.8.m8.1.1.3.2">‚Ñù</ci><apply id="S3.SS1.p1.8.m8.1.1.3.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3.3"><times id="S3.SS1.p1.8.m8.1.1.3.3.1.cmml" xref="S3.SS1.p1.8.m8.1.1.3.3.1"></times><apply id="S3.SS1.p1.8.m8.1.1.3.3.2.cmml" xref="S3.SS1.p1.8.m8.1.1.3.3.2"><times id="S3.SS1.p1.8.m8.1.1.3.3.2.1.cmml" xref="S3.SS1.p1.8.m8.1.1.3.3.2.1"></times><ci id="S3.SS1.p1.8.m8.1.1.3.3.2.2.cmml" xref="S3.SS1.p1.8.m8.1.1.3.3.2.2">ùêª</ci><ci id="S3.SS1.p1.8.m8.1.1.3.3.2.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3.3.2.3">ùê∑</ci></apply><ci id="S3.SS1.p1.8.m8.1.1.3.3.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3.3.3">ùê∑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">W^{O}\in\mathbb{R}^{HD\times D}</annotation></semantics></math><span id="S3.SS1.p1.8.12" class="ltx_text" style="font-size:90%;">:</span></p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\mbox{MHA}(X)=\mbox{concat}\left(\mbox{head}_{1},\dots,\mbox{head}_{H}\right)W^{O}," display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.4" xref="S3.E1.m1.3.3.1.1.4.cmml"><mtext mathsize="90%" id="S3.E1.m1.3.3.1.1.4.2" xref="S3.E1.m1.3.3.1.1.4.2a.cmml">MHA</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.1" xref="S3.E1.m1.3.3.1.1.4.1.cmml">‚Äã</mo><mrow id="S3.E1.m1.3.3.1.1.4.3.2" xref="S3.E1.m1.3.3.1.1.4.cmml"><mo maxsize="90%" minsize="90%" id="S3.E1.m1.3.3.1.1.4.3.2.1" xref="S3.E1.m1.3.3.1.1.4.cmml">(</mo><mi mathsize="90%" id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">X</mi><mo maxsize="90%" minsize="90%" id="S3.E1.m1.3.3.1.1.4.3.2.2" xref="S3.E1.m1.3.3.1.1.4.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml"><mtext mathsize="90%" id="S3.E1.m1.3.3.1.1.2.4" xref="S3.E1.m1.3.3.1.1.2.4a.cmml">concat</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.2.3" xref="S3.E1.m1.3.3.1.1.2.3.cmml">‚Äã</mo><mrow id="S3.E1.m1.3.3.1.1.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.3.cmml"><mo id="S3.E1.m1.3.3.1.1.2.2.2.3" xref="S3.E1.m1.3.3.1.1.2.2.3.cmml">(</mo><msub id="S3.E1.m1.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml"><mtext mathsize="90%" id="S3.E1.m1.3.3.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2a.cmml">head</mtext><mn mathsize="90%" id="S3.E1.m1.3.3.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.E1.m1.3.3.1.1.2.2.2.4" xref="S3.E1.m1.3.3.1.1.2.2.3.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.E1.m1.3.3.1.1.2.2.2.5" xref="S3.E1.m1.3.3.1.1.2.2.3.cmml">,</mo><msub id="S3.E1.m1.3.3.1.1.2.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.2.cmml"><mtext mathsize="90%" id="S3.E1.m1.3.3.1.1.2.2.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.2.2a.cmml">head</mtext><mi mathsize="90%" id="S3.E1.m1.3.3.1.1.2.2.2.2.3" xref="S3.E1.m1.3.3.1.1.2.2.2.2.3.cmml">H</mi></msub><mo id="S3.E1.m1.3.3.1.1.2.2.2.6" xref="S3.E1.m1.3.3.1.1.2.2.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.2.3a" xref="S3.E1.m1.3.3.1.1.2.3.cmml">‚Äã</mo><msup id="S3.E1.m1.3.3.1.1.2.5" xref="S3.E1.m1.3.3.1.1.2.5.cmml"><mi mathsize="90%" id="S3.E1.m1.3.3.1.1.2.5.2" xref="S3.E1.m1.3.3.1.1.2.5.2.cmml">W</mi><mi mathsize="90%" id="S3.E1.m1.3.3.1.1.2.5.3" xref="S3.E1.m1.3.3.1.1.2.5.3.cmml">O</mi></msup></mrow></mrow><mo mathsize="90%" id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3"></eq><apply id="S3.E1.m1.3.3.1.1.4.cmml" xref="S3.E1.m1.3.3.1.1.4"><times id="S3.E1.m1.3.3.1.1.4.1.cmml" xref="S3.E1.m1.3.3.1.1.4.1"></times><ci id="S3.E1.m1.3.3.1.1.4.2a.cmml" xref="S3.E1.m1.3.3.1.1.4.2"><mtext mathsize="90%" id="S3.E1.m1.3.3.1.1.4.2.cmml" xref="S3.E1.m1.3.3.1.1.4.2">MHA</mtext></ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ùëã</ci></apply><apply id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"><times id="S3.E1.m1.3.3.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.3"></times><ci id="S3.E1.m1.3.3.1.1.2.4a.cmml" xref="S3.E1.m1.3.3.1.1.2.4"><mtext mathsize="90%" id="S3.E1.m1.3.3.1.1.2.4.cmml" xref="S3.E1.m1.3.3.1.1.2.4">concat</mtext></ci><vector id="S3.E1.m1.3.3.1.1.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2"><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.2a.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2"><mtext mathsize="90%" id="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2">head</mtext></ci><cn type="integer" id="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3">1</cn></apply><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">‚Ä¶</ci><apply id="S3.E1.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.2.2.2.2.2a.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.2.2"><mtext mathsize="90%" id="S3.E1.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.2.2">head</mtext></ci><ci id="S3.E1.m1.3.3.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.2.3">ùêª</ci></apply></vector><apply id="S3.E1.m1.3.3.1.1.2.5.cmml" xref="S3.E1.m1.3.3.1.1.2.5"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.5.1.cmml" xref="S3.E1.m1.3.3.1.1.2.5">superscript</csymbol><ci id="S3.E1.m1.3.3.1.1.2.5.2.cmml" xref="S3.E1.m1.3.3.1.1.2.5.2">ùëä</ci><ci id="S3.E1.m1.3.3.1.1.2.5.3.cmml" xref="S3.E1.m1.3.3.1.1.2.5.3">ùëÇ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\mbox{MHA}(X)=\mbox{concat}\left(\mbox{head}_{1},\dots,\mbox{head}_{H}\right)W^{O},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.10" class="ltx_p"><span id="S3.SS1.p1.10.1" class="ltx_text" style="font-size:90%;">where </span><math id="S3.SS1.p1.9.m1.1" class="ltx_Math" alttext="X\in\mathbb{R}^{T\times D}" display="inline"><semantics id="S3.SS1.p1.9.m1.1a"><mrow id="S3.SS1.p1.9.m1.1.1" xref="S3.SS1.p1.9.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p1.9.m1.1.1.2" xref="S3.SS1.p1.9.m1.1.1.2.cmml">X</mi><mo mathsize="90%" id="S3.SS1.p1.9.m1.1.1.1" xref="S3.SS1.p1.9.m1.1.1.1.cmml">‚àà</mo><msup id="S3.SS1.p1.9.m1.1.1.3" xref="S3.SS1.p1.9.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.SS1.p1.9.m1.1.1.3.2" xref="S3.SS1.p1.9.m1.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS1.p1.9.m1.1.1.3.3" xref="S3.SS1.p1.9.m1.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS1.p1.9.m1.1.1.3.3.2" xref="S3.SS1.p1.9.m1.1.1.3.3.2.cmml">T</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.SS1.p1.9.m1.1.1.3.3.1" xref="S3.SS1.p1.9.m1.1.1.3.3.1.cmml">√ó</mo><mi mathsize="90%" id="S3.SS1.p1.9.m1.1.1.3.3.3" xref="S3.SS1.p1.9.m1.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m1.1b"><apply id="S3.SS1.p1.9.m1.1.1.cmml" xref="S3.SS1.p1.9.m1.1.1"><in id="S3.SS1.p1.9.m1.1.1.1.cmml" xref="S3.SS1.p1.9.m1.1.1.1"></in><ci id="S3.SS1.p1.9.m1.1.1.2.cmml" xref="S3.SS1.p1.9.m1.1.1.2">ùëã</ci><apply id="S3.SS1.p1.9.m1.1.1.3.cmml" xref="S3.SS1.p1.9.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m1.1.1.3.1.cmml" xref="S3.SS1.p1.9.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.9.m1.1.1.3.2.cmml" xref="S3.SS1.p1.9.m1.1.1.3.2">‚Ñù</ci><apply id="S3.SS1.p1.9.m1.1.1.3.3.cmml" xref="S3.SS1.p1.9.m1.1.1.3.3"><times id="S3.SS1.p1.9.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.9.m1.1.1.3.3.1"></times><ci id="S3.SS1.p1.9.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.9.m1.1.1.3.3.2">ùëá</ci><ci id="S3.SS1.p1.9.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.9.m1.1.1.3.3.3">ùê∑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m1.1c">X\in\mathbb{R}^{T\times D}</annotation></semantics></math><span id="S3.SS1.p1.10.2" class="ltx_text" style="font-size:90%;"> is the result of packing together the input sequence </span><math id="S3.SS1.p1.10.m2.3" class="ltx_Math" alttext="h_{1},...,h_{T}" display="inline"><semantics id="S3.SS1.p1.10.m2.3a"><mrow id="S3.SS1.p1.10.m2.3.3.2" xref="S3.SS1.p1.10.m2.3.3.3.cmml"><msub id="S3.SS1.p1.10.m2.2.2.1.1" xref="S3.SS1.p1.10.m2.2.2.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p1.10.m2.2.2.1.1.2" xref="S3.SS1.p1.10.m2.2.2.1.1.2.cmml">h</mi><mn mathsize="90%" id="S3.SS1.p1.10.m2.2.2.1.1.3" xref="S3.SS1.p1.10.m2.2.2.1.1.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.SS1.p1.10.m2.3.3.2.3" xref="S3.SS1.p1.10.m2.3.3.3.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS1.p1.10.m2.1.1" xref="S3.SS1.p1.10.m2.1.1.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.SS1.p1.10.m2.3.3.2.4" xref="S3.SS1.p1.10.m2.3.3.3.cmml">,</mo><msub id="S3.SS1.p1.10.m2.3.3.2.2" xref="S3.SS1.p1.10.m2.3.3.2.2.cmml"><mi mathsize="90%" id="S3.SS1.p1.10.m2.3.3.2.2.2" xref="S3.SS1.p1.10.m2.3.3.2.2.2.cmml">h</mi><mi mathsize="90%" id="S3.SS1.p1.10.m2.3.3.2.2.3" xref="S3.SS1.p1.10.m2.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m2.3b"><list id="S3.SS1.p1.10.m2.3.3.3.cmml" xref="S3.SS1.p1.10.m2.3.3.2"><apply id="S3.SS1.p1.10.m2.2.2.1.1.cmml" xref="S3.SS1.p1.10.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m2.2.2.1.1.1.cmml" xref="S3.SS1.p1.10.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m2.2.2.1.1.2.cmml" xref="S3.SS1.p1.10.m2.2.2.1.1.2">‚Ñé</ci><cn type="integer" id="S3.SS1.p1.10.m2.2.2.1.1.3.cmml" xref="S3.SS1.p1.10.m2.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p1.10.m2.1.1.cmml" xref="S3.SS1.p1.10.m2.1.1">‚Ä¶</ci><apply id="S3.SS1.p1.10.m2.3.3.2.2.cmml" xref="S3.SS1.p1.10.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m2.3.3.2.2.1.cmml" xref="S3.SS1.p1.10.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p1.10.m2.3.3.2.2.2.cmml" xref="S3.SS1.p1.10.m2.3.3.2.2.2">‚Ñé</ci><ci id="S3.SS1.p1.10.m2.3.3.2.2.3.cmml" xref="S3.SS1.p1.10.m2.3.3.2.2.3">ùëá</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m2.3c">h_{1},...,h_{T}</annotation></semantics></math><span id="S3.SS1.p1.10.3" class="ltx_text" style="font-size:90%;"> and</span></p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\mbox{head}_{j}=\mbox{softmax}\left(\frac{XW_{j}^{Q}(XW_{j}^{K})^{T}}{\sqrt{D}}\right)XW_{j}^{V}." display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><msub id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml"><mtext mathsize="90%" id="S3.E2.m1.2.2.1.1.2.2" xref="S3.E2.m1.2.2.1.1.2.2a.cmml">head</mtext><mi mathsize="90%" id="S3.E2.m1.2.2.1.1.2.3" xref="S3.E2.m1.2.2.1.1.2.3.cmml">j</mi></msub><mo mathsize="90%" id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mtext mathsize="90%" id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2a.cmml">softmax</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1" xref="S3.E2.m1.2.2.1.1.3.1.cmml">‚Äã</mo><mrow id="S3.E2.m1.2.2.1.1.3.3.2" xref="S3.E2.m1.1.1.cmml"><mo id="S3.E2.m1.2.2.1.1.3.3.2.1" xref="S3.E2.m1.1.1.cmml">(</mo><mfrac id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">‚Äã</mo><msubsup id="S3.E2.m1.1.1.1.4" xref="S3.E2.m1.1.1.1.4.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.1.4.2.2" xref="S3.E2.m1.1.1.1.4.2.2.cmml">W</mi><mi mathsize="90%" id="S3.E2.m1.1.1.1.4.2.3" xref="S3.E2.m1.1.1.1.4.2.3.cmml">j</mi><mi mathsize="90%" id="S3.E2.m1.1.1.1.4.3" xref="S3.E2.m1.1.1.1.4.3.cmml">Q</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.2a" xref="S3.E2.m1.1.1.1.2.cmml">‚Äã</mo><msup id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">‚Äã</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.2.cmml">W</mi><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.3.cmml">j</mi><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3.cmml">K</mi></msubsup></mrow><mo maxsize="90%" minsize="90%" id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi mathsize="90%" id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml">T</mi></msup></mrow><msqrt id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml">D</mi></msqrt></mfrac><mo id="S3.E2.m1.2.2.1.1.3.3.2.2" xref="S3.E2.m1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1a" xref="S3.E2.m1.2.2.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E2.m1.2.2.1.1.3.4" xref="S3.E2.m1.2.2.1.1.3.4.cmml">X</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.1b" xref="S3.E2.m1.2.2.1.1.3.1.cmml">‚Äã</mo><msubsup id="S3.E2.m1.2.2.1.1.3.5" xref="S3.E2.m1.2.2.1.1.3.5.cmml"><mi mathsize="90%" id="S3.E2.m1.2.2.1.1.3.5.2.2" xref="S3.E2.m1.2.2.1.1.3.5.2.2.cmml">W</mi><mi mathsize="90%" id="S3.E2.m1.2.2.1.1.3.5.2.3" xref="S3.E2.m1.2.2.1.1.3.5.2.3.cmml">j</mi><mi mathsize="90%" id="S3.E2.m1.2.2.1.1.3.5.3" xref="S3.E2.m1.2.2.1.1.3.5.3.cmml">V</mi></msubsup></mrow></mrow><mo lspace="0em" mathsize="90%" id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"></eq><apply id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2a.cmml" xref="S3.E2.m1.2.2.1.1.2.2"><mtext mathsize="90%" id="S3.E2.m1.2.2.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2">head</mtext></ci><ci id="S3.E2.m1.2.2.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.3">ùëó</ci></apply><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><times id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1"></times><ci id="S3.E2.m1.2.2.1.1.3.2a.cmml" xref="S3.E2.m1.2.2.1.1.3.2"><mtext mathsize="90%" id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2">softmax</mtext></ci><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2"><divide id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2"></divide><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">ùëã</ci><apply id="S3.E2.m1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.4.1.cmml" xref="S3.E2.m1.1.1.1.4">superscript</csymbol><apply id="S3.E2.m1.1.1.1.4.2.cmml" xref="S3.E2.m1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.4.2.1.cmml" xref="S3.E2.m1.1.1.1.4">subscript</csymbol><ci id="S3.E2.m1.1.1.1.4.2.2.cmml" xref="S3.E2.m1.1.1.1.4.2.2">ùëä</ci><ci id="S3.E2.m1.1.1.1.4.2.3.cmml" xref="S3.E2.m1.1.1.1.4.2.3">ùëó</ci></apply><ci id="S3.E2.m1.1.1.1.4.3.cmml" xref="S3.E2.m1.1.1.1.4.3">ùëÑ</ci></apply><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"></times><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2">ùëã</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.2">ùëä</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.3">ùëó</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3">ùêæ</ci></apply></apply><ci id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3">ùëá</ci></apply></apply><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><root id="S3.E2.m1.1.1.3a.cmml" xref="S3.E2.m1.1.1.3"></root><ci id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2">ùê∑</ci></apply></apply><ci id="S3.E2.m1.2.2.1.1.3.4.cmml" xref="S3.E2.m1.2.2.1.1.3.4">ùëã</ci><apply id="S3.E2.m1.2.2.1.1.3.5.cmml" xref="S3.E2.m1.2.2.1.1.3.5"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.5.1.cmml" xref="S3.E2.m1.2.2.1.1.3.5">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.3.5.2.cmml" xref="S3.E2.m1.2.2.1.1.3.5"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.5.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.5">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.5.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.5.2.2">ùëä</ci><ci id="S3.E2.m1.2.2.1.1.3.5.2.3.cmml" xref="S3.E2.m1.2.2.1.1.3.5.2.3">ùëó</ci></apply><ci id="S3.E2.m1.2.2.1.1.3.5.3.cmml" xref="S3.E2.m1.2.2.1.1.3.5.3">ùëâ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\mbox{head}_{j}=\mbox{softmax}\left(\frac{XW_{j}^{Q}(XW_{j}^{K})^{T}}{\sqrt{D}}\right)XW_{j}^{V}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.11" class="ltx_p"><span id="S3.SS1.p1.11.1" class="ltx_text" style="font-size:90%;">This mechanism, which we refer to as standard MHA (sometimes also referred to as Global MHA), allows the model to jointly attend to information from different representation subspaces at different positions.</span></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Sub-vector Multi-Head Attention</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.9" class="ltx_p"><span id="S3.SS2.p1.9.1" class="ltx_text" style="font-size:90%;">Given a sequence of hidden-states </span><math id="S3.SS2.p1.1.m1.5" class="ltx_Math" alttext="\{h_{t}\in\mathbb{R}^{D}\mbox{ }|\mbox{ }t=1,...,T\}" display="inline"><semantics id="S3.SS2.p1.1.m1.5a"><mrow id="S3.SS2.p1.1.m1.5.5.2" xref="S3.SS2.p1.1.m1.5.5.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.1.m1.5.5.2.3" xref="S3.SS2.p1.1.m1.5.5.3.1.cmml">{</mo><mrow id="S3.SS2.p1.1.m1.4.4.1.1" xref="S3.SS2.p1.1.m1.4.4.1.1.cmml"><msub id="S3.SS2.p1.1.m1.4.4.1.1.2" xref="S3.SS2.p1.1.m1.4.4.1.1.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.1.m1.4.4.1.1.2.2" xref="S3.SS2.p1.1.m1.4.4.1.1.2.2.cmml">h</mi><mi mathsize="90%" id="S3.SS2.p1.1.m1.4.4.1.1.2.3" xref="S3.SS2.p1.1.m1.4.4.1.1.2.3.cmml">t</mi></msub><mo mathsize="90%" id="S3.SS2.p1.1.m1.4.4.1.1.1" xref="S3.SS2.p1.1.m1.4.4.1.1.1.cmml">‚àà</mo><mrow id="S3.SS2.p1.1.m1.4.4.1.1.3" xref="S3.SS2.p1.1.m1.4.4.1.1.3.cmml"><msup id="S3.SS2.p1.1.m1.4.4.1.1.3.2" xref="S3.SS2.p1.1.m1.4.4.1.1.3.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.1.m1.4.4.1.1.3.2.2" xref="S3.SS2.p1.1.m1.4.4.1.1.3.2.2.cmml">‚Ñù</mi><mi mathsize="90%" id="S3.SS2.p1.1.m1.4.4.1.1.3.2.3" xref="S3.SS2.p1.1.m1.4.4.1.1.3.2.3.cmml">D</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.4.4.1.1.3.1" xref="S3.SS2.p1.1.m1.4.4.1.1.3.1.cmml">‚Äã</mo><mtext mathsize="90%" id="S3.SS2.p1.1.m1.4.4.1.1.3.3" xref="S3.SS2.p1.1.m1.4.4.1.1.3.3a.cmml">¬†</mtext></mrow></mrow><mo lspace="0em" mathsize="90%" rspace="0em" id="S3.SS2.p1.1.m1.5.5.2.4" xref="S3.SS2.p1.1.m1.5.5.3.1.cmml">|</mo><mrow id="S3.SS2.p1.1.m1.5.5.2.2" xref="S3.SS2.p1.1.m1.5.5.2.2.cmml"><mrow id="S3.SS2.p1.1.m1.5.5.2.2.2" xref="S3.SS2.p1.1.m1.5.5.2.2.2.cmml"><mtext mathsize="90%" id="S3.SS2.p1.1.m1.5.5.2.2.2.2" xref="S3.SS2.p1.1.m1.5.5.2.2.2.2a.cmml">¬†</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.p1.1.m1.5.5.2.2.2.1" xref="S3.SS2.p1.1.m1.5.5.2.2.2.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p1.1.m1.5.5.2.2.2.3" xref="S3.SS2.p1.1.m1.5.5.2.2.2.3.cmml">t</mi></mrow><mo mathsize="90%" id="S3.SS2.p1.1.m1.5.5.2.2.1" xref="S3.SS2.p1.1.m1.5.5.2.2.1.cmml">=</mo><mrow id="S3.SS2.p1.1.m1.5.5.2.2.3.2" xref="S3.SS2.p1.1.m1.5.5.2.2.3.1.cmml"><mn mathsize="90%" id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">1</mn><mo mathsize="90%" id="S3.SS2.p1.1.m1.5.5.2.2.3.2.1" xref="S3.SS2.p1.1.m1.5.5.2.2.3.1.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS2.p1.1.m1.2.2" xref="S3.SS2.p1.1.m1.2.2.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.SS2.p1.1.m1.5.5.2.2.3.2.2" xref="S3.SS2.p1.1.m1.5.5.2.2.3.1.cmml">,</mo><mi mathsize="90%" id="S3.SS2.p1.1.m1.3.3" xref="S3.SS2.p1.1.m1.3.3.cmml">T</mi></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.1.m1.5.5.2.5" xref="S3.SS2.p1.1.m1.5.5.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.5b"><apply id="S3.SS2.p1.1.m1.5.5.3.cmml" xref="S3.SS2.p1.1.m1.5.5.2"><csymbol cd="latexml" id="S3.SS2.p1.1.m1.5.5.3.1.cmml" xref="S3.SS2.p1.1.m1.5.5.2.3">conditional-set</csymbol><apply id="S3.SS2.p1.1.m1.4.4.1.1.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1"><in id="S3.SS2.p1.1.m1.4.4.1.1.1.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.1"></in><apply id="S3.SS2.p1.1.m1.4.4.1.1.2.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.4.4.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.4.4.1.1.2.2.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.2.2">‚Ñé</ci><ci id="S3.SS2.p1.1.m1.4.4.1.1.2.3.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.2.3">ùë°</ci></apply><apply id="S3.SS2.p1.1.m1.4.4.1.1.3.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.3"><times id="S3.SS2.p1.1.m1.4.4.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.3.1"></times><apply id="S3.SS2.p1.1.m1.4.4.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.4.4.1.1.3.2.1.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.3.2">superscript</csymbol><ci id="S3.SS2.p1.1.m1.4.4.1.1.3.2.2.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.3.2.2">‚Ñù</ci><ci id="S3.SS2.p1.1.m1.4.4.1.1.3.2.3.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.3.2.3">ùê∑</ci></apply><ci id="S3.SS2.p1.1.m1.4.4.1.1.3.3a.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.3.3"><mtext mathsize="90%" id="S3.SS2.p1.1.m1.4.4.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.4.4.1.1.3.3">¬†</mtext></ci></apply></apply><apply id="S3.SS2.p1.1.m1.5.5.2.2.cmml" xref="S3.SS2.p1.1.m1.5.5.2.2"><eq id="S3.SS2.p1.1.m1.5.5.2.2.1.cmml" xref="S3.SS2.p1.1.m1.5.5.2.2.1"></eq><apply id="S3.SS2.p1.1.m1.5.5.2.2.2.cmml" xref="S3.SS2.p1.1.m1.5.5.2.2.2"><times id="S3.SS2.p1.1.m1.5.5.2.2.2.1.cmml" xref="S3.SS2.p1.1.m1.5.5.2.2.2.1"></times><ci id="S3.SS2.p1.1.m1.5.5.2.2.2.2a.cmml" xref="S3.SS2.p1.1.m1.5.5.2.2.2.2"><mtext mathsize="90%" id="S3.SS2.p1.1.m1.5.5.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.5.5.2.2.2.2">¬†</mtext></ci><ci id="S3.SS2.p1.1.m1.5.5.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.5.5.2.2.2.3">ùë°</ci></apply><list id="S3.SS2.p1.1.m1.5.5.2.2.3.1.cmml" xref="S3.SS2.p1.1.m1.5.5.2.2.3.2"><cn type="integer" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">1</cn><ci id="S3.SS2.p1.1.m1.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2">‚Ä¶</ci><ci id="S3.SS2.p1.1.m1.3.3.cmml" xref="S3.SS2.p1.1.m1.3.3">ùëá</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.5c">\{h_{t}\in\mathbb{R}^{D}\mbox{ }|\mbox{ }t=1,...,T\}</annotation></semantics></math><span id="S3.SS2.p1.9.2" class="ltx_text" style="font-size:90%;">, the output of a </span><math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi mathsize="90%" id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">H</annotation></semantics></math><span id="S3.SS2.p1.9.3" class="ltx_text" style="font-size:90%;">-headed sub-vector MHA </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2.p1.9.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S3.SS2.p1.9.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS2.p1.9.6" class="ltx_text" style="font-size:90%;"> layer are </span><math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi mathsize="90%" id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">H</annotation></semantics></math><span id="S3.SS2.p1.9.7" class="ltx_text" style="font-size:90%;"> vectors.
Each hidden state </span><math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="h_{t}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><msub id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">h</mi><mi mathsize="90%" id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">‚Ñé</ci><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">h_{t}</annotation></semantics></math><span id="S3.SS2.p1.9.8" class="ltx_text" style="font-size:90%;"> is split into </span><math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi mathsize="90%" id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">H</annotation></semantics></math><span id="S3.SS2.p1.9.9" class="ltx_text" style="font-size:90%;"> new hidden states so that </span><math id="S3.SS2.p1.6.m6.3" class="ltx_Math" alttext="h_{t}=[h_{t1},...,h_{tH}]" display="inline"><semantics id="S3.SS2.p1.6.m6.3a"><mrow id="S3.SS2.p1.6.m6.3.3" xref="S3.SS2.p1.6.m6.3.3.cmml"><msub id="S3.SS2.p1.6.m6.3.3.4" xref="S3.SS2.p1.6.m6.3.3.4.cmml"><mi mathsize="90%" id="S3.SS2.p1.6.m6.3.3.4.2" xref="S3.SS2.p1.6.m6.3.3.4.2.cmml">h</mi><mi mathsize="90%" id="S3.SS2.p1.6.m6.3.3.4.3" xref="S3.SS2.p1.6.m6.3.3.4.3.cmml">t</mi></msub><mo mathsize="90%" id="S3.SS2.p1.6.m6.3.3.3" xref="S3.SS2.p1.6.m6.3.3.3.cmml">=</mo><mrow id="S3.SS2.p1.6.m6.3.3.2.2" xref="S3.SS2.p1.6.m6.3.3.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.6.m6.3.3.2.2.3" xref="S3.SS2.p1.6.m6.3.3.2.3.cmml">[</mo><msub id="S3.SS2.p1.6.m6.2.2.1.1.1" xref="S3.SS2.p1.6.m6.2.2.1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.6.m6.2.2.1.1.1.2" xref="S3.SS2.p1.6.m6.2.2.1.1.1.2.cmml">h</mi><mrow id="S3.SS2.p1.6.m6.2.2.1.1.1.3" xref="S3.SS2.p1.6.m6.2.2.1.1.1.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.6.m6.2.2.1.1.1.3.2" xref="S3.SS2.p1.6.m6.2.2.1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.6.m6.2.2.1.1.1.3.1" xref="S3.SS2.p1.6.m6.2.2.1.1.1.3.1.cmml">‚Äã</mo><mn mathsize="90%" id="S3.SS2.p1.6.m6.2.2.1.1.1.3.3" xref="S3.SS2.p1.6.m6.2.2.1.1.1.3.3.cmml">1</mn></mrow></msub><mo mathsize="90%" id="S3.SS2.p1.6.m6.3.3.2.2.4" xref="S3.SS2.p1.6.m6.3.3.2.3.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.SS2.p1.6.m6.3.3.2.2.5" xref="S3.SS2.p1.6.m6.3.3.2.3.cmml">,</mo><msub id="S3.SS2.p1.6.m6.3.3.2.2.2" xref="S3.SS2.p1.6.m6.3.3.2.2.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.6.m6.3.3.2.2.2.2" xref="S3.SS2.p1.6.m6.3.3.2.2.2.2.cmml">h</mi><mrow id="S3.SS2.p1.6.m6.3.3.2.2.2.3" xref="S3.SS2.p1.6.m6.3.3.2.2.2.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.6.m6.3.3.2.2.2.3.2" xref="S3.SS2.p1.6.m6.3.3.2.2.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.6.m6.3.3.2.2.2.3.1" xref="S3.SS2.p1.6.m6.3.3.2.2.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p1.6.m6.3.3.2.2.2.3.3" xref="S3.SS2.p1.6.m6.3.3.2.2.2.3.3.cmml">H</mi></mrow></msub><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.6.m6.3.3.2.2.6" xref="S3.SS2.p1.6.m6.3.3.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.3b"><apply id="S3.SS2.p1.6.m6.3.3.cmml" xref="S3.SS2.p1.6.m6.3.3"><eq id="S3.SS2.p1.6.m6.3.3.3.cmml" xref="S3.SS2.p1.6.m6.3.3.3"></eq><apply id="S3.SS2.p1.6.m6.3.3.4.cmml" xref="S3.SS2.p1.6.m6.3.3.4"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.3.3.4.1.cmml" xref="S3.SS2.p1.6.m6.3.3.4">subscript</csymbol><ci id="S3.SS2.p1.6.m6.3.3.4.2.cmml" xref="S3.SS2.p1.6.m6.3.3.4.2">‚Ñé</ci><ci id="S3.SS2.p1.6.m6.3.3.4.3.cmml" xref="S3.SS2.p1.6.m6.3.3.4.3">ùë°</ci></apply><list id="S3.SS2.p1.6.m6.3.3.2.3.cmml" xref="S3.SS2.p1.6.m6.3.3.2.2"><apply id="S3.SS2.p1.6.m6.2.2.1.1.1.cmml" xref="S3.SS2.p1.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.2.2.1.1.1.1.cmml" xref="S3.SS2.p1.6.m6.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.6.m6.2.2.1.1.1.2.cmml" xref="S3.SS2.p1.6.m6.2.2.1.1.1.2">‚Ñé</ci><apply id="S3.SS2.p1.6.m6.2.2.1.1.1.3.cmml" xref="S3.SS2.p1.6.m6.2.2.1.1.1.3"><times id="S3.SS2.p1.6.m6.2.2.1.1.1.3.1.cmml" xref="S3.SS2.p1.6.m6.2.2.1.1.1.3.1"></times><ci id="S3.SS2.p1.6.m6.2.2.1.1.1.3.2.cmml" xref="S3.SS2.p1.6.m6.2.2.1.1.1.3.2">ùë°</ci><cn type="integer" id="S3.SS2.p1.6.m6.2.2.1.1.1.3.3.cmml" xref="S3.SS2.p1.6.m6.2.2.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">‚Ä¶</ci><apply id="S3.SS2.p1.6.m6.3.3.2.2.2.cmml" xref="S3.SS2.p1.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.6.m6.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.6.m6.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.6.m6.3.3.2.2.2.2">‚Ñé</ci><apply id="S3.SS2.p1.6.m6.3.3.2.2.2.3.cmml" xref="S3.SS2.p1.6.m6.3.3.2.2.2.3"><times id="S3.SS2.p1.6.m6.3.3.2.2.2.3.1.cmml" xref="S3.SS2.p1.6.m6.3.3.2.2.2.3.1"></times><ci id="S3.SS2.p1.6.m6.3.3.2.2.2.3.2.cmml" xref="S3.SS2.p1.6.m6.3.3.2.2.2.3.2">ùë°</ci><ci id="S3.SS2.p1.6.m6.3.3.2.2.2.3.3.cmml" xref="S3.SS2.p1.6.m6.3.3.2.2.2.3.3">ùêª</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.3c">h_{t}=[h_{t1},...,h_{tH}]</annotation></semantics></math><span id="S3.SS2.p1.9.10" class="ltx_text" style="font-size:90%;">, where </span><math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="h_{tj}\in\mathbb{R}^{D/H}" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><mrow id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><msub id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.7.m7.1.1.2.2" xref="S3.SS2.p1.7.m7.1.1.2.2.cmml">h</mi><mrow id="S3.SS2.p1.7.m7.1.1.2.3" xref="S3.SS2.p1.7.m7.1.1.2.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.7.m7.1.1.2.3.2" xref="S3.SS2.p1.7.m7.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.7.m7.1.1.2.3.1" xref="S3.SS2.p1.7.m7.1.1.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p1.7.m7.1.1.2.3.3" xref="S3.SS2.p1.7.m7.1.1.2.3.3.cmml">j</mi></mrow></msub><mo mathsize="90%" id="S3.SS2.p1.7.m7.1.1.1" xref="S3.SS2.p1.7.m7.1.1.1.cmml">‚àà</mo><msup id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.7.m7.1.1.3.2" xref="S3.SS2.p1.7.m7.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS2.p1.7.m7.1.1.3.3" xref="S3.SS2.p1.7.m7.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.7.m7.1.1.3.3.2" xref="S3.SS2.p1.7.m7.1.1.3.3.2.cmml">D</mi><mo maxsize="90%" minsize="90%" stretchy="true" symmetric="true" id="S3.SS2.p1.7.m7.1.1.3.3.1" xref="S3.SS2.p1.7.m7.1.1.3.3.1.cmml">/</mo><mi mathsize="90%" id="S3.SS2.p1.7.m7.1.1.3.3.3" xref="S3.SS2.p1.7.m7.1.1.3.3.3.cmml">H</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><in id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1.1"></in><apply id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.2.1.cmml" xref="S3.SS2.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.2.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2.2">‚Ñé</ci><apply id="S3.SS2.p1.7.m7.1.1.2.3.cmml" xref="S3.SS2.p1.7.m7.1.1.2.3"><times id="S3.SS2.p1.7.m7.1.1.2.3.1.cmml" xref="S3.SS2.p1.7.m7.1.1.2.3.1"></times><ci id="S3.SS2.p1.7.m7.1.1.2.3.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2.3.2">ùë°</ci><ci id="S3.SS2.p1.7.m7.1.1.2.3.3.cmml" xref="S3.SS2.p1.7.m7.1.1.2.3.3">ùëó</ci></apply></apply><apply id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.3.1.cmml" xref="S3.SS2.p1.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.3.2.cmml" xref="S3.SS2.p1.7.m7.1.1.3.2">‚Ñù</ci><apply id="S3.SS2.p1.7.m7.1.1.3.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3"><divide id="S3.SS2.p1.7.m7.1.1.3.3.1.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3.1"></divide><ci id="S3.SS2.p1.7.m7.1.1.3.3.2.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3.2">ùê∑</ci><ci id="S3.SS2.p1.7.m7.1.1.3.3.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3.3">ùêª</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">h_{tj}\in\mathbb{R}^{D/H}</annotation></semantics></math><span id="S3.SS2.p1.9.11" class="ltx_text" style="font-size:90%;">.
Now, for each head </span><math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mi mathsize="90%" id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">ùëó</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">j</annotation></semantics></math><span id="S3.SS2.p1.9.12" class="ltx_text" style="font-size:90%;">, self-attention is applied over </span><math id="S3.SS2.p1.9.m9.3" class="ltx_Math" alttext="[h_{1j},...,h_{Tj}]" display="inline"><semantics id="S3.SS2.p1.9.m9.3a"><mrow id="S3.SS2.p1.9.m9.3.3.2" xref="S3.SS2.p1.9.m9.3.3.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.9.m9.3.3.2.3" xref="S3.SS2.p1.9.m9.3.3.3.cmml">[</mo><msub id="S3.SS2.p1.9.m9.2.2.1.1" xref="S3.SS2.p1.9.m9.2.2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.9.m9.2.2.1.1.2" xref="S3.SS2.p1.9.m9.2.2.1.1.2.cmml">h</mi><mrow id="S3.SS2.p1.9.m9.2.2.1.1.3" xref="S3.SS2.p1.9.m9.2.2.1.1.3.cmml"><mn mathsize="90%" id="S3.SS2.p1.9.m9.2.2.1.1.3.2" xref="S3.SS2.p1.9.m9.2.2.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.2.2.1.1.3.1" xref="S3.SS2.p1.9.m9.2.2.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p1.9.m9.2.2.1.1.3.3" xref="S3.SS2.p1.9.m9.2.2.1.1.3.3.cmml">j</mi></mrow></msub><mo mathsize="90%" id="S3.SS2.p1.9.m9.3.3.2.4" xref="S3.SS2.p1.9.m9.3.3.3.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.SS2.p1.9.m9.3.3.2.5" xref="S3.SS2.p1.9.m9.3.3.3.cmml">,</mo><msub id="S3.SS2.p1.9.m9.3.3.2.2" xref="S3.SS2.p1.9.m9.3.3.2.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.9.m9.3.3.2.2.2" xref="S3.SS2.p1.9.m9.3.3.2.2.2.cmml">h</mi><mrow id="S3.SS2.p1.9.m9.3.3.2.2.3" xref="S3.SS2.p1.9.m9.3.3.2.2.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.9.m9.3.3.2.2.3.2" xref="S3.SS2.p1.9.m9.3.3.2.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.9.m9.3.3.2.2.3.1" xref="S3.SS2.p1.9.m9.3.3.2.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p1.9.m9.3.3.2.2.3.3" xref="S3.SS2.p1.9.m9.3.3.2.2.3.3.cmml">j</mi></mrow></msub><mo maxsize="90%" minsize="90%" id="S3.SS2.p1.9.m9.3.3.2.6" xref="S3.SS2.p1.9.m9.3.3.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.3b"><list id="S3.SS2.p1.9.m9.3.3.3.cmml" xref="S3.SS2.p1.9.m9.3.3.2"><apply id="S3.SS2.p1.9.m9.2.2.1.1.cmml" xref="S3.SS2.p1.9.m9.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.9.m9.2.2.1.1.1.cmml" xref="S3.SS2.p1.9.m9.2.2.1.1">subscript</csymbol><ci id="S3.SS2.p1.9.m9.2.2.1.1.2.cmml" xref="S3.SS2.p1.9.m9.2.2.1.1.2">‚Ñé</ci><apply id="S3.SS2.p1.9.m9.2.2.1.1.3.cmml" xref="S3.SS2.p1.9.m9.2.2.1.1.3"><times id="S3.SS2.p1.9.m9.2.2.1.1.3.1.cmml" xref="S3.SS2.p1.9.m9.2.2.1.1.3.1"></times><cn type="integer" id="S3.SS2.p1.9.m9.2.2.1.1.3.2.cmml" xref="S3.SS2.p1.9.m9.2.2.1.1.3.2">1</cn><ci id="S3.SS2.p1.9.m9.2.2.1.1.3.3.cmml" xref="S3.SS2.p1.9.m9.2.2.1.1.3.3">ùëó</ci></apply></apply><ci id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">‚Ä¶</ci><apply id="S3.SS2.p1.9.m9.3.3.2.2.cmml" xref="S3.SS2.p1.9.m9.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.9.m9.3.3.2.2.1.cmml" xref="S3.SS2.p1.9.m9.3.3.2.2">subscript</csymbol><ci id="S3.SS2.p1.9.m9.3.3.2.2.2.cmml" xref="S3.SS2.p1.9.m9.3.3.2.2.2">‚Ñé</ci><apply id="S3.SS2.p1.9.m9.3.3.2.2.3.cmml" xref="S3.SS2.p1.9.m9.3.3.2.2.3"><times id="S3.SS2.p1.9.m9.3.3.2.2.3.1.cmml" xref="S3.SS2.p1.9.m9.3.3.2.2.3.1"></times><ci id="S3.SS2.p1.9.m9.3.3.2.2.3.2.cmml" xref="S3.SS2.p1.9.m9.3.3.2.2.3.2">ùëá</ci><ci id="S3.SS2.p1.9.m9.3.3.2.2.3.3.cmml" xref="S3.SS2.p1.9.m9.3.3.2.2.3.3">ùëó</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.3c">[h_{1j},...,h_{Tj}]</annotation></semantics></math><span id="S3.SS2.p1.9.13" class="ltx_text" style="font-size:90%;">.
Each head weights are defined as:</span></p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_Math" alttext="w_{tj}=\frac{\text{exp}\left(\frac{h_{tj}^{T}u_{j}}{\sqrt{d_{h}}}\right)}{\sum_{l=1}^{T}\text{exp}\left(\frac{h_{lj}^{T}u_{j}}{\sqrt{d_{h}}}\right)}," display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.1.2.cmml"><mi mathsize="90%" id="S3.E3.m1.3.3.1.1.2.2" xref="S3.E3.m1.3.3.1.1.2.2.cmml">w</mi><mrow id="S3.E3.m1.3.3.1.1.2.3" xref="S3.E3.m1.3.3.1.1.2.3.cmml"><mi mathsize="90%" id="S3.E3.m1.3.3.1.1.2.3.2" xref="S3.E3.m1.3.3.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.2.3.1" xref="S3.E3.m1.3.3.1.1.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E3.m1.3.3.1.1.2.3.3" xref="S3.E3.m1.3.3.1.1.2.3.3.cmml">j</mi></mrow></msub><mo mathsize="90%" id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mtext mathsize="90%" id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3a.cmml">exp</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E3.m1.1.1.1.4.2" xref="S3.E3.m1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.4.2.1" xref="S3.E3.m1.1.1.1.1.cmml">(</mo><mfrac id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><msubsup id="S3.E3.m1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.2.2.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.cmml">h</mi><mrow id="S3.E3.m1.1.1.1.1.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.2.3.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.2.2.3.2" xref="S3.E3.m1.1.1.1.1.2.2.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.2.3.1" xref="S3.E3.m1.1.1.1.1.2.2.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.2.2.3.3" xref="S3.E3.m1.1.1.1.1.2.2.2.3.3.cmml">j</mi></mrow><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.1" xref="S3.E3.m1.1.1.1.1.2.1.cmml">‚Äã</mo><msub id="S3.E3.m1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.2.3.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.3.2" xref="S3.E3.m1.1.1.1.1.2.3.2.cmml">u</mi><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.2.3.3" xref="S3.E3.m1.1.1.1.1.2.3.3.cmml">j</mi></msub></mrow><msqrt id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><msub id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml"><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.3.2.2" xref="S3.E3.m1.1.1.1.1.3.2.2.cmml">d</mi><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.3.2.3" xref="S3.E3.m1.1.1.1.1.3.2.3.cmml">h</mi></msub></msqrt></mfrac><mo id="S3.E3.m1.1.1.1.4.2.2" xref="S3.E3.m1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><msubsup id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.2.cmml"><mo maxsize="90%" minsize="90%" stretchy="true" id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml">‚àë</mo><mrow id="S3.E3.m1.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.3.cmml"><mi mathsize="90%" id="S3.E3.m1.2.2.2.2.2.3.2" xref="S3.E3.m1.2.2.2.2.2.3.2.cmml">l</mi><mo mathsize="90%" id="S3.E3.m1.2.2.2.2.2.3.1" xref="S3.E3.m1.2.2.2.2.2.3.1.cmml">=</mo><mn mathsize="90%" id="S3.E3.m1.2.2.2.2.2.3.3" xref="S3.E3.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="S3.E3.m1.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.3.cmml">T</mi></msubsup><mrow id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml"><mtext mathsize="90%" id="S3.E3.m1.2.2.2.3.2" xref="S3.E3.m1.2.2.2.3.2a.cmml">exp</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.3.1" xref="S3.E3.m1.2.2.2.3.1.cmml">‚Äã</mo><mrow id="S3.E3.m1.2.2.2.3.3.2" xref="S3.E3.m1.2.2.2.1.cmml"><mo id="S3.E3.m1.2.2.2.3.3.2.1" xref="S3.E3.m1.2.2.2.1.cmml">(</mo><mfrac id="S3.E3.m1.2.2.2.1" xref="S3.E3.m1.2.2.2.1.cmml"><mrow id="S3.E3.m1.2.2.2.1.2" xref="S3.E3.m1.2.2.2.1.2.cmml"><msubsup id="S3.E3.m1.2.2.2.1.2.2" xref="S3.E3.m1.2.2.2.1.2.2.cmml"><mi mathsize="90%" id="S3.E3.m1.2.2.2.1.2.2.2.2" xref="S3.E3.m1.2.2.2.1.2.2.2.2.cmml">h</mi><mrow id="S3.E3.m1.2.2.2.1.2.2.2.3" xref="S3.E3.m1.2.2.2.1.2.2.2.3.cmml"><mi mathsize="90%" id="S3.E3.m1.2.2.2.1.2.2.2.3.2" xref="S3.E3.m1.2.2.2.1.2.2.2.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.1.2.2.2.3.1" xref="S3.E3.m1.2.2.2.1.2.2.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E3.m1.2.2.2.1.2.2.2.3.3" xref="S3.E3.m1.2.2.2.1.2.2.2.3.3.cmml">j</mi></mrow><mi mathsize="90%" id="S3.E3.m1.2.2.2.1.2.2.3" xref="S3.E3.m1.2.2.2.1.2.2.3.cmml">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.1.2.1" xref="S3.E3.m1.2.2.2.1.2.1.cmml">‚Äã</mo><msub id="S3.E3.m1.2.2.2.1.2.3" xref="S3.E3.m1.2.2.2.1.2.3.cmml"><mi mathsize="90%" id="S3.E3.m1.2.2.2.1.2.3.2" xref="S3.E3.m1.2.2.2.1.2.3.2.cmml">u</mi><mi mathsize="90%" id="S3.E3.m1.2.2.2.1.2.3.3" xref="S3.E3.m1.2.2.2.1.2.3.3.cmml">j</mi></msub></mrow><msqrt id="S3.E3.m1.2.2.2.1.3" xref="S3.E3.m1.2.2.2.1.3.cmml"><msub id="S3.E3.m1.2.2.2.1.3.2" xref="S3.E3.m1.2.2.2.1.3.2.cmml"><mi mathsize="90%" id="S3.E3.m1.2.2.2.1.3.2.2" xref="S3.E3.m1.2.2.2.1.3.2.2.cmml">d</mi><mi mathsize="90%" id="S3.E3.m1.2.2.2.1.3.2.3" xref="S3.E3.m1.2.2.2.1.3.2.3.cmml">h</mi></msub></msqrt></mfrac><mo id="S3.E3.m1.2.2.2.3.3.2.2" xref="S3.E3.m1.2.2.2.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><mo mathsize="90%" id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1"><eq id="S3.E3.m1.3.3.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1"></eq><apply id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2">ùë§</ci><apply id="S3.E3.m1.3.3.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.3"><times id="S3.E3.m1.3.3.1.1.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.3.1"></times><ci id="S3.E3.m1.3.3.1.1.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.3.2">ùë°</ci><ci id="S3.E3.m1.3.3.1.1.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.3.3">ùëó</ci></apply></apply><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><divide id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2"></divide><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.3"><mtext mathsize="90%" id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3">exp</mtext></ci><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.4.2"><divide id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.4.2"></divide><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><times id="S3.E3.m1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.1"></times><apply id="S3.E3.m1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2">‚Ñé</ci><apply id="S3.E3.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.3"><times id="S3.E3.m1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.3.1"></times><ci id="S3.E3.m1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.3.2">ùë°</ci><ci id="S3.E3.m1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.3.3">ùëó</ci></apply></apply><ci id="S3.E3.m1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3">ùëá</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.3.2">ùë¢</ci><ci id="S3.E3.m1.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3.3">ùëó</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><root id="S3.E3.m1.1.1.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.1.3"></root><apply id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2.2">ùëë</ci><ci id="S3.E3.m1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.2.3">‚Ñé</ci></apply></apply></apply></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><apply id="S3.E3.m1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2">superscript</csymbol><apply id="S3.E3.m1.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2">subscript</csymbol><sum id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"></sum><apply id="S3.E3.m1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.3"><eq id="S3.E3.m1.2.2.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.3.1"></eq><ci id="S3.E3.m1.2.2.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.3.2">ùëô</ci><cn type="integer" id="S3.E3.m1.2.2.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.3">ùëá</ci></apply><apply id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"><times id="S3.E3.m1.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.3.1"></times><ci id="S3.E3.m1.2.2.2.3.2a.cmml" xref="S3.E3.m1.2.2.2.3.2"><mtext mathsize="90%" id="S3.E3.m1.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.3.2">exp</mtext></ci><apply id="S3.E3.m1.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.3.3.2"><divide id="S3.E3.m1.2.2.2.1.1.cmml" xref="S3.E3.m1.2.2.2.3.3.2"></divide><apply id="S3.E3.m1.2.2.2.1.2.cmml" xref="S3.E3.m1.2.2.2.1.2"><times id="S3.E3.m1.2.2.2.1.2.1.cmml" xref="S3.E3.m1.2.2.2.1.2.1"></times><apply id="S3.E3.m1.2.2.2.1.2.2.cmml" xref="S3.E3.m1.2.2.2.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.1.2.2.1.cmml" xref="S3.E3.m1.2.2.2.1.2.2">superscript</csymbol><apply id="S3.E3.m1.2.2.2.1.2.2.2.cmml" xref="S3.E3.m1.2.2.2.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.1.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.1.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.1.2.2.2.2">‚Ñé</ci><apply id="S3.E3.m1.2.2.2.1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.1.2.2.2.3"><times id="S3.E3.m1.2.2.2.1.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.1.2.2.2.3.1"></times><ci id="S3.E3.m1.2.2.2.1.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.1.2.2.2.3.2">ùëô</ci><ci id="S3.E3.m1.2.2.2.1.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.2.1.2.2.2.3.3">ùëó</ci></apply></apply><ci id="S3.E3.m1.2.2.2.1.2.2.3.cmml" xref="S3.E3.m1.2.2.2.1.2.2.3">ùëá</ci></apply><apply id="S3.E3.m1.2.2.2.1.2.3.cmml" xref="S3.E3.m1.2.2.2.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.1.2.3.1.cmml" xref="S3.E3.m1.2.2.2.1.2.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.1.2.3.2.cmml" xref="S3.E3.m1.2.2.2.1.2.3.2">ùë¢</ci><ci id="S3.E3.m1.2.2.2.1.2.3.3.cmml" xref="S3.E3.m1.2.2.2.1.2.3.3">ùëó</ci></apply></apply><apply id="S3.E3.m1.2.2.2.1.3.cmml" xref="S3.E3.m1.2.2.2.1.3"><root id="S3.E3.m1.2.2.2.1.3a.cmml" xref="S3.E3.m1.2.2.2.1.3"></root><apply id="S3.E3.m1.2.2.2.1.3.2.cmml" xref="S3.E3.m1.2.2.2.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.1.3.2.1.cmml" xref="S3.E3.m1.2.2.2.1.3.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.1.3.2.2.cmml" xref="S3.E3.m1.2.2.2.1.3.2.2">ùëë</ci><ci id="S3.E3.m1.2.2.2.1.3.2.3.cmml" xref="S3.E3.m1.2.2.2.1.3.2.3">‚Ñé</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">w_{tj}=\frac{\text{exp}\left(\frac{h_{tj}^{T}u_{j}}{\sqrt{d_{h}}}\right)}{\sum_{l=1}^{T}\text{exp}\left(\frac{h_{lj}^{T}u_{j}}{\sqrt{d_{h}}}\right)},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.16" class="ltx_p"><span id="S3.SS2.p1.16.1" class="ltx_text" style="font-size:90%;">where </span><math id="S3.SS2.p1.10.m1.1" class="ltx_Math" alttext="w_{tj}" display="inline"><semantics id="S3.SS2.p1.10.m1.1a"><msub id="S3.SS2.p1.10.m1.1.1" xref="S3.SS2.p1.10.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.10.m1.1.1.2" xref="S3.SS2.p1.10.m1.1.1.2.cmml">w</mi><mrow id="S3.SS2.p1.10.m1.1.1.3" xref="S3.SS2.p1.10.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.10.m1.1.1.3.2" xref="S3.SS2.p1.10.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.10.m1.1.1.3.1" xref="S3.SS2.p1.10.m1.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p1.10.m1.1.1.3.3" xref="S3.SS2.p1.10.m1.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m1.1b"><apply id="S3.SS2.p1.10.m1.1.1.cmml" xref="S3.SS2.p1.10.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m1.1.1.1.cmml" xref="S3.SS2.p1.10.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.10.m1.1.1.2.cmml" xref="S3.SS2.p1.10.m1.1.1.2">ùë§</ci><apply id="S3.SS2.p1.10.m1.1.1.3.cmml" xref="S3.SS2.p1.10.m1.1.1.3"><times id="S3.SS2.p1.10.m1.1.1.3.1.cmml" xref="S3.SS2.p1.10.m1.1.1.3.1"></times><ci id="S3.SS2.p1.10.m1.1.1.3.2.cmml" xref="S3.SS2.p1.10.m1.1.1.3.2">ùë°</ci><ci id="S3.SS2.p1.10.m1.1.1.3.3.cmml" xref="S3.SS2.p1.10.m1.1.1.3.3">ùëó</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m1.1c">w_{tj}</annotation></semantics></math><span id="S3.SS2.p1.16.2" class="ltx_text" style="font-size:90%;"> corresponds to the attention weight of the head </span><math id="S3.SS2.p1.11.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.p1.11.m2.1a"><mi mathsize="90%" id="S3.SS2.p1.11.m2.1.1" xref="S3.SS2.p1.11.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m2.1b"><ci id="S3.SS2.p1.11.m2.1.1.cmml" xref="S3.SS2.p1.11.m2.1.1">ùëó</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m2.1c">j</annotation></semantics></math><span id="S3.SS2.p1.16.3" class="ltx_text" style="font-size:90%;"> on the step </span><math id="S3.SS2.p1.12.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p1.12.m3.1a"><mi mathsize="90%" id="S3.SS2.p1.12.m3.1.1" xref="S3.SS2.p1.12.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m3.1b"><ci id="S3.SS2.p1.12.m3.1.1.cmml" xref="S3.SS2.p1.12.m3.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m3.1c">t</annotation></semantics></math><span id="S3.SS2.p1.16.4" class="ltx_text" style="font-size:90%;"> of the sequence, </span><math id="S3.SS2.p1.13.m4.1" class="ltx_Math" alttext="u_{j}\in\mathbb{R}^{D/H}" display="inline"><semantics id="S3.SS2.p1.13.m4.1a"><mrow id="S3.SS2.p1.13.m4.1.1" xref="S3.SS2.p1.13.m4.1.1.cmml"><msub id="S3.SS2.p1.13.m4.1.1.2" xref="S3.SS2.p1.13.m4.1.1.2.cmml"><mi mathsize="90%" id="S3.SS2.p1.13.m4.1.1.2.2" xref="S3.SS2.p1.13.m4.1.1.2.2.cmml">u</mi><mi mathsize="90%" id="S3.SS2.p1.13.m4.1.1.2.3" xref="S3.SS2.p1.13.m4.1.1.2.3.cmml">j</mi></msub><mo mathsize="90%" id="S3.SS2.p1.13.m4.1.1.1" xref="S3.SS2.p1.13.m4.1.1.1.cmml">‚àà</mo><msup id="S3.SS2.p1.13.m4.1.1.3" xref="S3.SS2.p1.13.m4.1.1.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.13.m4.1.1.3.2" xref="S3.SS2.p1.13.m4.1.1.3.2.cmml">‚Ñù</mi><mrow id="S3.SS2.p1.13.m4.1.1.3.3" xref="S3.SS2.p1.13.m4.1.1.3.3.cmml"><mi mathsize="90%" id="S3.SS2.p1.13.m4.1.1.3.3.2" xref="S3.SS2.p1.13.m4.1.1.3.3.2.cmml">D</mi><mo maxsize="90%" minsize="90%" stretchy="true" symmetric="true" id="S3.SS2.p1.13.m4.1.1.3.3.1" xref="S3.SS2.p1.13.m4.1.1.3.3.1.cmml">/</mo><mi mathsize="90%" id="S3.SS2.p1.13.m4.1.1.3.3.3" xref="S3.SS2.p1.13.m4.1.1.3.3.3.cmml">H</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.13.m4.1b"><apply id="S3.SS2.p1.13.m4.1.1.cmml" xref="S3.SS2.p1.13.m4.1.1"><in id="S3.SS2.p1.13.m4.1.1.1.cmml" xref="S3.SS2.p1.13.m4.1.1.1"></in><apply id="S3.SS2.p1.13.m4.1.1.2.cmml" xref="S3.SS2.p1.13.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.13.m4.1.1.2.1.cmml" xref="S3.SS2.p1.13.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.13.m4.1.1.2.2.cmml" xref="S3.SS2.p1.13.m4.1.1.2.2">ùë¢</ci><ci id="S3.SS2.p1.13.m4.1.1.2.3.cmml" xref="S3.SS2.p1.13.m4.1.1.2.3">ùëó</ci></apply><apply id="S3.SS2.p1.13.m4.1.1.3.cmml" xref="S3.SS2.p1.13.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.13.m4.1.1.3.1.cmml" xref="S3.SS2.p1.13.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.13.m4.1.1.3.2.cmml" xref="S3.SS2.p1.13.m4.1.1.3.2">‚Ñù</ci><apply id="S3.SS2.p1.13.m4.1.1.3.3.cmml" xref="S3.SS2.p1.13.m4.1.1.3.3"><divide id="S3.SS2.p1.13.m4.1.1.3.3.1.cmml" xref="S3.SS2.p1.13.m4.1.1.3.3.1"></divide><ci id="S3.SS2.p1.13.m4.1.1.3.3.2.cmml" xref="S3.SS2.p1.13.m4.1.1.3.3.2">ùê∑</ci><ci id="S3.SS2.p1.13.m4.1.1.3.3.3.cmml" xref="S3.SS2.p1.13.m4.1.1.3.3.3">ùêª</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m4.1c">u_{j}\in\mathbb{R}^{D/H}</annotation></semantics></math><span id="S3.SS2.p1.16.5" class="ltx_text" style="font-size:90%;"> is a trainable parameter and </span><math id="S3.SS2.p1.14.m5.1" class="ltx_Math" alttext="d_{h}" display="inline"><semantics id="S3.SS2.p1.14.m5.1a"><msub id="S3.SS2.p1.14.m5.1.1" xref="S3.SS2.p1.14.m5.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.14.m5.1.1.2" xref="S3.SS2.p1.14.m5.1.1.2.cmml">d</mi><mi mathsize="90%" id="S3.SS2.p1.14.m5.1.1.3" xref="S3.SS2.p1.14.m5.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.14.m5.1b"><apply id="S3.SS2.p1.14.m5.1.1.cmml" xref="S3.SS2.p1.14.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.14.m5.1.1.1.cmml" xref="S3.SS2.p1.14.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.14.m5.1.1.2.cmml" xref="S3.SS2.p1.14.m5.1.1.2">ùëë</ci><ci id="S3.SS2.p1.14.m5.1.1.3.cmml" xref="S3.SS2.p1.14.m5.1.1.3">‚Ñé</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.14.m5.1c">d_{h}</annotation></semantics></math><span id="S3.SS2.p1.16.6" class="ltx_text" style="font-size:90%;"> corresponds to the hidden state dimension </span><math id="S3.SS2.p1.15.m6.1" class="ltx_Math" alttext="D/H" display="inline"><semantics id="S3.SS2.p1.15.m6.1a"><mrow id="S3.SS2.p1.15.m6.1.1" xref="S3.SS2.p1.15.m6.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.15.m6.1.1.2" xref="S3.SS2.p1.15.m6.1.1.2.cmml">D</mi><mo maxsize="90%" minsize="90%" stretchy="true" symmetric="true" id="S3.SS2.p1.15.m6.1.1.1" xref="S3.SS2.p1.15.m6.1.1.1.cmml">/</mo><mi mathsize="90%" id="S3.SS2.p1.15.m6.1.1.3" xref="S3.SS2.p1.15.m6.1.1.3.cmml">H</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.15.m6.1b"><apply id="S3.SS2.p1.15.m6.1.1.cmml" xref="S3.SS2.p1.15.m6.1.1"><divide id="S3.SS2.p1.15.m6.1.1.1.cmml" xref="S3.SS2.p1.15.m6.1.1.1"></divide><ci id="S3.SS2.p1.15.m6.1.1.2.cmml" xref="S3.SS2.p1.15.m6.1.1.2">ùê∑</ci><ci id="S3.SS2.p1.15.m6.1.1.3.cmml" xref="S3.SS2.p1.15.m6.1.1.3">ùêª</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.15.m6.1c">D/H</annotation></semantics></math><span id="S3.SS2.p1.16.7" class="ltx_text" style="font-size:90%;">.
We then compute a pooled representation </span><math id="S3.SS2.p1.16.m7.1" class="ltx_Math" alttext="c_{j}" display="inline"><semantics id="S3.SS2.p1.16.m7.1a"><msub id="S3.SS2.p1.16.m7.1.1" xref="S3.SS2.p1.16.m7.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p1.16.m7.1.1.2" xref="S3.SS2.p1.16.m7.1.1.2.cmml">c</mi><mi mathsize="90%" id="S3.SS2.p1.16.m7.1.1.3" xref="S3.SS2.p1.16.m7.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.16.m7.1b"><apply id="S3.SS2.p1.16.m7.1.1.cmml" xref="S3.SS2.p1.16.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.16.m7.1.1.1.cmml" xref="S3.SS2.p1.16.m7.1.1">subscript</csymbol><ci id="S3.SS2.p1.16.m7.1.1.2.cmml" xref="S3.SS2.p1.16.m7.1.1.2">ùëê</ci><ci id="S3.SS2.p1.16.m7.1.1.3.cmml" xref="S3.SS2.p1.16.m7.1.1.3">ùëó</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.16.m7.1c">c_{j}</annotation></semantics></math><span id="S3.SS2.p1.16.8" class="ltx_text" style="font-size:90%;"> for each head:</span></p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="c_{j}=\sum_{t=1}^{T}w_{tj}^{{}^{\prime}}h_{tj}" display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><msub id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.2.2" xref="S3.E4.m1.1.1.2.2.cmml">c</mi><mi mathsize="90%" id="S3.E4.m1.1.1.2.3" xref="S3.E4.m1.1.1.2.3.cmml">j</mi></msub><mo mathsize="90%" rspace="0.111em" id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><munderover id="S3.E4.m1.1.1.3.1" xref="S3.E4.m1.1.1.3.1.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" id="S3.E4.m1.1.1.3.1.2.2" xref="S3.E4.m1.1.1.3.1.2.2.cmml">‚àë</mo><mrow id="S3.E4.m1.1.1.3.1.2.3" xref="S3.E4.m1.1.1.3.1.2.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.3.1.2.3.2" xref="S3.E4.m1.1.1.3.1.2.3.2.cmml">t</mi><mo mathsize="90%" id="S3.E4.m1.1.1.3.1.2.3.1" xref="S3.E4.m1.1.1.3.1.2.3.1.cmml">=</mo><mn mathsize="90%" id="S3.E4.m1.1.1.3.1.2.3.3" xref="S3.E4.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="S3.E4.m1.1.1.3.1.3" xref="S3.E4.m1.1.1.3.1.3.cmml">T</mi></munderover><mrow id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml"><msubsup id="S3.E4.m1.1.1.3.2.2" xref="S3.E4.m1.1.1.3.2.2.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.3.2.2.2.2" xref="S3.E4.m1.1.1.3.2.2.2.2.cmml">w</mi><mrow id="S3.E4.m1.1.1.3.2.2.2.3" xref="S3.E4.m1.1.1.3.2.2.2.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.3.2.2.2.3.2" xref="S3.E4.m1.1.1.3.2.2.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.2.2.2.3.1" xref="S3.E4.m1.1.1.3.2.2.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E4.m1.1.1.3.2.2.2.3.3" xref="S3.E4.m1.1.1.3.2.2.2.3.3.cmml">j</mi></mrow><msup id="S3.E4.m1.1.1.3.2.2.3" xref="S3.E4.m1.1.1.3.2.2.3.cmml"><mi id="S3.E4.m1.1.1.3.2.2.3a" xref="S3.E4.m1.1.1.3.2.2.3.cmml"></mi><mo mathsize="90%" id="S3.E4.m1.1.1.3.2.2.3.1" xref="S3.E4.m1.1.1.3.2.2.3.1.cmml">‚Ä≤</mo></msup></msubsup><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.2.1" xref="S3.E4.m1.1.1.3.2.1.cmml">‚Äã</mo><msub id="S3.E4.m1.1.1.3.2.3" xref="S3.E4.m1.1.1.3.2.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.3.2.3.2" xref="S3.E4.m1.1.1.3.2.3.2.cmml">h</mi><mrow id="S3.E4.m1.1.1.3.2.3.3" xref="S3.E4.m1.1.1.3.2.3.3.cmml"><mi mathsize="90%" id="S3.E4.m1.1.1.3.2.3.3.2" xref="S3.E4.m1.1.1.3.2.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.2.3.3.1" xref="S3.E4.m1.1.1.3.2.3.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.E4.m1.1.1.3.2.3.3.3" xref="S3.E4.m1.1.1.3.2.3.3.3.cmml">j</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"></eq><apply id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.2.2">ùëê</ci><ci id="S3.E4.m1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.2.3">ùëó</ci></apply><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><apply id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.1.1.cmml" xref="S3.E4.m1.1.1.3.1">superscript</csymbol><apply id="S3.E4.m1.1.1.3.1.2.cmml" xref="S3.E4.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.1.2.1.cmml" xref="S3.E4.m1.1.1.3.1">subscript</csymbol><sum id="S3.E4.m1.1.1.3.1.2.2.cmml" xref="S3.E4.m1.1.1.3.1.2.2"></sum><apply id="S3.E4.m1.1.1.3.1.2.3.cmml" xref="S3.E4.m1.1.1.3.1.2.3"><eq id="S3.E4.m1.1.1.3.1.2.3.1.cmml" xref="S3.E4.m1.1.1.3.1.2.3.1"></eq><ci id="S3.E4.m1.1.1.3.1.2.3.2.cmml" xref="S3.E4.m1.1.1.3.1.2.3.2">ùë°</ci><cn type="integer" id="S3.E4.m1.1.1.3.1.2.3.3.cmml" xref="S3.E4.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.1.1.3.1.3.cmml" xref="S3.E4.m1.1.1.3.1.3">ùëá</ci></apply><apply id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2"><times id="S3.E4.m1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.3.2.1"></times><apply id="S3.E4.m1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.2.1.cmml" xref="S3.E4.m1.1.1.3.2.2">superscript</csymbol><apply id="S3.E4.m1.1.1.3.2.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.2.2.1.cmml" xref="S3.E4.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.2.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2.2.2">ùë§</ci><apply id="S3.E4.m1.1.1.3.2.2.2.3.cmml" xref="S3.E4.m1.1.1.3.2.2.2.3"><times id="S3.E4.m1.1.1.3.2.2.2.3.1.cmml" xref="S3.E4.m1.1.1.3.2.2.2.3.1"></times><ci id="S3.E4.m1.1.1.3.2.2.2.3.2.cmml" xref="S3.E4.m1.1.1.3.2.2.2.3.2">ùë°</ci><ci id="S3.E4.m1.1.1.3.2.2.2.3.3.cmml" xref="S3.E4.m1.1.1.3.2.2.2.3.3">ùëó</ci></apply></apply><apply id="S3.E4.m1.1.1.3.2.2.3.cmml" xref="S3.E4.m1.1.1.3.2.2.3"><ci id="S3.E4.m1.1.1.3.2.2.3.1.cmml" xref="S3.E4.m1.1.1.3.2.2.3.1">‚Ä≤</ci></apply></apply><apply id="S3.E4.m1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.1.1.3.2.3.2">‚Ñé</ci><apply id="S3.E4.m1.1.1.3.2.3.3.cmml" xref="S3.E4.m1.1.1.3.2.3.3"><times id="S3.E4.m1.1.1.3.2.3.3.1.cmml" xref="S3.E4.m1.1.1.3.2.3.3.1"></times><ci id="S3.E4.m1.1.1.3.2.3.3.2.cmml" xref="S3.E4.m1.1.1.3.2.3.3.2">ùë°</ci><ci id="S3.E4.m1.1.1.3.2.3.3.3.cmml" xref="S3.E4.m1.1.1.3.2.3.3.3">ùëó</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">c_{j}=\sum_{t=1}^{T}w_{tj}^{{}^{\prime}}h_{tj}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.4" class="ltx_p"><span id="S3.SS2.p2.4.1" class="ltx_text" style="font-size:90%;">Each self-attention pooling for the head </span><math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi mathsize="90%" id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ùëó</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">j</annotation></semantics></math><span id="S3.SS2.p2.4.2" class="ltx_text" style="font-size:90%;"> is a dot-product attention over </span><math id="S3.SS2.p2.2.m2.3" class="ltx_Math" alttext="[h_{1j},...,h_{Tj}]" display="inline"><semantics id="S3.SS2.p2.2.m2.3a"><mrow id="S3.SS2.p2.2.m2.3.3.2" xref="S3.SS2.p2.2.m2.3.3.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.2.m2.3.3.2.3" xref="S3.SS2.p2.2.m2.3.3.3.cmml">[</mo><msub id="S3.SS2.p2.2.m2.2.2.1.1" xref="S3.SS2.p2.2.m2.2.2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.2.m2.2.2.1.1.2" xref="S3.SS2.p2.2.m2.2.2.1.1.2.cmml">h</mi><mrow id="S3.SS2.p2.2.m2.2.2.1.1.3" xref="S3.SS2.p2.2.m2.2.2.1.1.3.cmml"><mn mathsize="90%" id="S3.SS2.p2.2.m2.2.2.1.1.3.2" xref="S3.SS2.p2.2.m2.2.2.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p2.2.m2.2.2.1.1.3.1" xref="S3.SS2.p2.2.m2.2.2.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p2.2.m2.2.2.1.1.3.3" xref="S3.SS2.p2.2.m2.2.2.1.1.3.3.cmml">j</mi></mrow></msub><mo mathsize="90%" id="S3.SS2.p2.2.m2.3.3.2.4" xref="S3.SS2.p2.2.m2.3.3.3.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.SS2.p2.2.m2.3.3.2.5" xref="S3.SS2.p2.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS2.p2.2.m2.3.3.2.2" xref="S3.SS2.p2.2.m2.3.3.2.2.cmml"><mi mathsize="90%" id="S3.SS2.p2.2.m2.3.3.2.2.2" xref="S3.SS2.p2.2.m2.3.3.2.2.2.cmml">h</mi><mrow id="S3.SS2.p2.2.m2.3.3.2.2.3" xref="S3.SS2.p2.2.m2.3.3.2.2.3.cmml"><mi mathsize="90%" id="S3.SS2.p2.2.m2.3.3.2.2.3.2" xref="S3.SS2.p2.2.m2.3.3.2.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.2.m2.3.3.2.2.3.1" xref="S3.SS2.p2.2.m2.3.3.2.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p2.2.m2.3.3.2.2.3.3" xref="S3.SS2.p2.2.m2.3.3.2.2.3.3.cmml">j</mi></mrow></msub><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.2.m2.3.3.2.6" xref="S3.SS2.p2.2.m2.3.3.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.3b"><list id="S3.SS2.p2.2.m2.3.3.3.cmml" xref="S3.SS2.p2.2.m2.3.3.2"><apply id="S3.SS2.p2.2.m2.2.2.1.1.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.2">‚Ñé</ci><apply id="S3.SS2.p2.2.m2.2.2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.3"><times id="S3.SS2.p2.2.m2.2.2.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.3.1"></times><cn type="integer" id="S3.SS2.p2.2.m2.2.2.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.3.2">1</cn><ci id="S3.SS2.p2.2.m2.2.2.1.1.3.3.cmml" xref="S3.SS2.p2.2.m2.2.2.1.1.3.3">ùëó</ci></apply></apply><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">‚Ä¶</ci><apply id="S3.SS2.p2.2.m2.3.3.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.3.3.2.2.1.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS2.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.2">‚Ñé</ci><apply id="S3.SS2.p2.2.m2.3.3.2.2.3.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.3"><times id="S3.SS2.p2.2.m2.3.3.2.2.3.1.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.3.1"></times><ci id="S3.SS2.p2.2.m2.3.3.2.2.3.2.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.3.2">ùëá</ci><ci id="S3.SS2.p2.2.m2.3.3.2.2.3.3.cmml" xref="S3.SS2.p2.2.m2.3.3.2.2.3.3">ùëó</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.3c">[h_{1j},...,h_{Tj}]</annotation></semantics></math><span id="S3.SS2.p2.4.3" class="ltx_text" style="font-size:90%;">, where the keys and the values are both </span><math id="S3.SS2.p2.3.m3.3" class="ltx_Math" alttext="[h_{1j},...,h_{Tj}]" display="inline"><semantics id="S3.SS2.p2.3.m3.3a"><mrow id="S3.SS2.p2.3.m3.3.3.2" xref="S3.SS2.p2.3.m3.3.3.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.3.m3.3.3.2.3" xref="S3.SS2.p2.3.m3.3.3.3.cmml">[</mo><msub id="S3.SS2.p2.3.m3.2.2.1.1" xref="S3.SS2.p2.3.m3.2.2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.3.m3.2.2.1.1.2" xref="S3.SS2.p2.3.m3.2.2.1.1.2.cmml">h</mi><mrow id="S3.SS2.p2.3.m3.2.2.1.1.3" xref="S3.SS2.p2.3.m3.2.2.1.1.3.cmml"><mn mathsize="90%" id="S3.SS2.p2.3.m3.2.2.1.1.3.2" xref="S3.SS2.p2.3.m3.2.2.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.2.2.1.1.3.1" xref="S3.SS2.p2.3.m3.2.2.1.1.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p2.3.m3.2.2.1.1.3.3" xref="S3.SS2.p2.3.m3.2.2.1.1.3.3.cmml">j</mi></mrow></msub><mo mathsize="90%" id="S3.SS2.p2.3.m3.3.3.2.4" xref="S3.SS2.p2.3.m3.3.3.3.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.SS2.p2.3.m3.3.3.2.5" xref="S3.SS2.p2.3.m3.3.3.3.cmml">,</mo><msub id="S3.SS2.p2.3.m3.3.3.2.2" xref="S3.SS2.p2.3.m3.3.3.2.2.cmml"><mi mathsize="90%" id="S3.SS2.p2.3.m3.3.3.2.2.2" xref="S3.SS2.p2.3.m3.3.3.2.2.2.cmml">h</mi><mrow id="S3.SS2.p2.3.m3.3.3.2.2.3" xref="S3.SS2.p2.3.m3.3.3.2.2.3.cmml"><mi mathsize="90%" id="S3.SS2.p2.3.m3.3.3.2.2.3.2" xref="S3.SS2.p2.3.m3.3.3.2.2.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.3.3.2.2.3.1" xref="S3.SS2.p2.3.m3.3.3.2.2.3.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS2.p2.3.m3.3.3.2.2.3.3" xref="S3.SS2.p2.3.m3.3.3.2.2.3.3.cmml">j</mi></mrow></msub><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.3.m3.3.3.2.6" xref="S3.SS2.p2.3.m3.3.3.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.3b"><list id="S3.SS2.p2.3.m3.3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3.2"><apply id="S3.SS2.p2.3.m3.2.2.1.1.cmml" xref="S3.SS2.p2.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.2.2.1.1.1.cmml" xref="S3.SS2.p2.3.m3.2.2.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.2.2.1.1.2.cmml" xref="S3.SS2.p2.3.m3.2.2.1.1.2">‚Ñé</ci><apply id="S3.SS2.p2.3.m3.2.2.1.1.3.cmml" xref="S3.SS2.p2.3.m3.2.2.1.1.3"><times id="S3.SS2.p2.3.m3.2.2.1.1.3.1.cmml" xref="S3.SS2.p2.3.m3.2.2.1.1.3.1"></times><cn type="integer" id="S3.SS2.p2.3.m3.2.2.1.1.3.2.cmml" xref="S3.SS2.p2.3.m3.2.2.1.1.3.2">1</cn><ci id="S3.SS2.p2.3.m3.2.2.1.1.3.3.cmml" xref="S3.SS2.p2.3.m3.2.2.1.1.3.3">ùëó</ci></apply></apply><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">‚Ä¶</ci><apply id="S3.SS2.p2.3.m3.3.3.2.2.cmml" xref="S3.SS2.p2.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.3.3.2.2.1.cmml" xref="S3.SS2.p2.3.m3.3.3.2.2">subscript</csymbol><ci id="S3.SS2.p2.3.m3.3.3.2.2.2.cmml" xref="S3.SS2.p2.3.m3.3.3.2.2.2">‚Ñé</ci><apply id="S3.SS2.p2.3.m3.3.3.2.2.3.cmml" xref="S3.SS2.p2.3.m3.3.3.2.2.3"><times id="S3.SS2.p2.3.m3.3.3.2.2.3.1.cmml" xref="S3.SS2.p2.3.m3.3.3.2.2.3.1"></times><ci id="S3.SS2.p2.3.m3.3.3.2.2.3.2.cmml" xref="S3.SS2.p2.3.m3.3.3.2.2.3.2">ùëá</ci><ci id="S3.SS2.p2.3.m3.3.3.2.2.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3.2.2.3.3">ùëó</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.3c">[h_{1j},...,h_{Tj}]</annotation></semantics></math><span id="S3.SS2.p2.4.4" class="ltx_text" style="font-size:90%;"> and there is only one trainable query </span><math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="u_{j}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><msub id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">u</mi><mi mathsize="90%" id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ùë¢</ci><ci id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3">ùëó</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">u_{j}</annotation></semantics></math><span id="S3.SS2.p2.4.5" class="ltx_text" style="font-size:90%;">.
With this design, this mechanism allows the model to efficiently attend to the most informative patterns from different positions of the hidden states sequence, significantly reducing the number of learnable parameters.</span></p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Attention Pooling</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.6" class="ltx_p"><span id="S3.SS3.p1.6.1" class="ltx_text" style="font-size:90%;">Let </span><math id="S3.SS3.p1.1.m1.5" class="ltx_Math" alttext="\{c_{l}\in\mathbb{R}^{C}\mbox{ }|\mbox{ }l=1,...,L\}" display="inline"><semantics id="S3.SS3.p1.1.m1.5a"><mrow id="S3.SS3.p1.1.m1.5.5.2" xref="S3.SS3.p1.1.m1.5.5.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.1.m1.5.5.2.3" xref="S3.SS3.p1.1.m1.5.5.3.1.cmml">{</mo><mrow id="S3.SS3.p1.1.m1.4.4.1.1" xref="S3.SS3.p1.1.m1.4.4.1.1.cmml"><msub id="S3.SS3.p1.1.m1.4.4.1.1.2" xref="S3.SS3.p1.1.m1.4.4.1.1.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.4.4.1.1.2.2" xref="S3.SS3.p1.1.m1.4.4.1.1.2.2.cmml">c</mi><mi mathsize="90%" id="S3.SS3.p1.1.m1.4.4.1.1.2.3" xref="S3.SS3.p1.1.m1.4.4.1.1.2.3.cmml">l</mi></msub><mo mathsize="90%" id="S3.SS3.p1.1.m1.4.4.1.1.1" xref="S3.SS3.p1.1.m1.4.4.1.1.1.cmml">‚àà</mo><mrow id="S3.SS3.p1.1.m1.4.4.1.1.3" xref="S3.SS3.p1.1.m1.4.4.1.1.3.cmml"><msup id="S3.SS3.p1.1.m1.4.4.1.1.3.2" xref="S3.SS3.p1.1.m1.4.4.1.1.3.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.4.4.1.1.3.2.2" xref="S3.SS3.p1.1.m1.4.4.1.1.3.2.2.cmml">‚Ñù</mi><mi mathsize="90%" id="S3.SS3.p1.1.m1.4.4.1.1.3.2.3" xref="S3.SS3.p1.1.m1.4.4.1.1.3.2.3.cmml">C</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.4.4.1.1.3.1" xref="S3.SS3.p1.1.m1.4.4.1.1.3.1.cmml">‚Äã</mo><mtext mathsize="90%" id="S3.SS3.p1.1.m1.4.4.1.1.3.3" xref="S3.SS3.p1.1.m1.4.4.1.1.3.3a.cmml">¬†</mtext></mrow></mrow><mo lspace="0em" mathsize="90%" rspace="0em" id="S3.SS3.p1.1.m1.5.5.2.4" xref="S3.SS3.p1.1.m1.5.5.3.1.cmml">|</mo><mrow id="S3.SS3.p1.1.m1.5.5.2.2" xref="S3.SS3.p1.1.m1.5.5.2.2.cmml"><mrow id="S3.SS3.p1.1.m1.5.5.2.2.2" xref="S3.SS3.p1.1.m1.5.5.2.2.2.cmml"><mtext mathsize="90%" id="S3.SS3.p1.1.m1.5.5.2.2.2.2" xref="S3.SS3.p1.1.m1.5.5.2.2.2.2a.cmml">¬†</mtext><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.5.5.2.2.2.1" xref="S3.SS3.p1.1.m1.5.5.2.2.2.1.cmml">‚Äã</mo><mi mathsize="90%" id="S3.SS3.p1.1.m1.5.5.2.2.2.3" xref="S3.SS3.p1.1.m1.5.5.2.2.2.3.cmml">l</mi></mrow><mo mathsize="90%" id="S3.SS3.p1.1.m1.5.5.2.2.1" xref="S3.SS3.p1.1.m1.5.5.2.2.1.cmml">=</mo><mrow id="S3.SS3.p1.1.m1.5.5.2.2.3.2" xref="S3.SS3.p1.1.m1.5.5.2.2.3.1.cmml"><mn mathsize="90%" id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">1</mn><mo mathsize="90%" id="S3.SS3.p1.1.m1.5.5.2.2.3.2.1" xref="S3.SS3.p1.1.m1.5.5.2.2.3.1.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS3.p1.1.m1.2.2" xref="S3.SS3.p1.1.m1.2.2.cmml">‚Ä¶</mi><mo mathsize="90%" id="S3.SS3.p1.1.m1.5.5.2.2.3.2.2" xref="S3.SS3.p1.1.m1.5.5.2.2.3.1.cmml">,</mo><mi mathsize="90%" id="S3.SS3.p1.1.m1.3.3" xref="S3.SS3.p1.1.m1.3.3.cmml">L</mi></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.1.m1.5.5.2.5" xref="S3.SS3.p1.1.m1.5.5.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.5b"><apply id="S3.SS3.p1.1.m1.5.5.3.cmml" xref="S3.SS3.p1.1.m1.5.5.2"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.5.5.3.1.cmml" xref="S3.SS3.p1.1.m1.5.5.2.3">conditional-set</csymbol><apply id="S3.SS3.p1.1.m1.4.4.1.1.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1"><in id="S3.SS3.p1.1.m1.4.4.1.1.1.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.1"></in><apply id="S3.SS3.p1.1.m1.4.4.1.1.2.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.4.4.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.4.4.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.2.2">ùëê</ci><ci id="S3.SS3.p1.1.m1.4.4.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.2.3">ùëô</ci></apply><apply id="S3.SS3.p1.1.m1.4.4.1.1.3.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.3"><times id="S3.SS3.p1.1.m1.4.4.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.3.1"></times><apply id="S3.SS3.p1.1.m1.4.4.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.4.4.1.1.3.2.1.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.3.2">superscript</csymbol><ci id="S3.SS3.p1.1.m1.4.4.1.1.3.2.2.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.3.2.2">‚Ñù</ci><ci id="S3.SS3.p1.1.m1.4.4.1.1.3.2.3.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.3.2.3">ùê∂</ci></apply><ci id="S3.SS3.p1.1.m1.4.4.1.1.3.3a.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.3.3"><mtext mathsize="90%" id="S3.SS3.p1.1.m1.4.4.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.4.4.1.1.3.3">¬†</mtext></ci></apply></apply><apply id="S3.SS3.p1.1.m1.5.5.2.2.cmml" xref="S3.SS3.p1.1.m1.5.5.2.2"><eq id="S3.SS3.p1.1.m1.5.5.2.2.1.cmml" xref="S3.SS3.p1.1.m1.5.5.2.2.1"></eq><apply id="S3.SS3.p1.1.m1.5.5.2.2.2.cmml" xref="S3.SS3.p1.1.m1.5.5.2.2.2"><times id="S3.SS3.p1.1.m1.5.5.2.2.2.1.cmml" xref="S3.SS3.p1.1.m1.5.5.2.2.2.1"></times><ci id="S3.SS3.p1.1.m1.5.5.2.2.2.2a.cmml" xref="S3.SS3.p1.1.m1.5.5.2.2.2.2"><mtext mathsize="90%" id="S3.SS3.p1.1.m1.5.5.2.2.2.2.cmml" xref="S3.SS3.p1.1.m1.5.5.2.2.2.2">¬†</mtext></ci><ci id="S3.SS3.p1.1.m1.5.5.2.2.2.3.cmml" xref="S3.SS3.p1.1.m1.5.5.2.2.2.3">ùëô</ci></apply><list id="S3.SS3.p1.1.m1.5.5.2.2.3.1.cmml" xref="S3.SS3.p1.1.m1.5.5.2.2.3.2"><cn type="integer" id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">1</cn><ci id="S3.SS3.p1.1.m1.2.2.cmml" xref="S3.SS3.p1.1.m1.2.2">‚Ä¶</ci><ci id="S3.SS3.p1.1.m1.3.3.cmml" xref="S3.SS3.p1.1.m1.3.3">ùêø</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.5c">\{c_{l}\in\mathbb{R}^{C}\mbox{ }|\mbox{ }l=1,...,L\}</annotation></semantics></math><span id="S3.SS3.p1.6.2" class="ltx_text" style="font-size:90%;"> be the output vectors of the first attention layer.
If standard MHA is used in the first layer, </span><math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi mathsize="90%" id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">ùêø</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">L</annotation></semantics></math><span id="S3.SS3.p1.6.3" class="ltx_text" style="font-size:90%;"> is equal to </span><math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi mathsize="90%" id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">T</annotation></semantics></math><span id="S3.SS3.p1.6.4" class="ltx_text" style="font-size:90%;">; if sub-vector MHA is used, </span><math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi mathsize="90%" id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">ùêø</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">L</annotation></semantics></math><span id="S3.SS3.p1.6.5" class="ltx_text" style="font-size:90%;"> is equal to </span><math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mi mathsize="90%" id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">H</annotation></semantics></math><span id="S3.SS3.p1.6.6" class="ltx_text" style="font-size:90%;">.
Self-attention is now used to pool these vectors to obtain an overall utterance-level vector </span><math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><mi mathsize="90%" id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><ci id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">c</annotation></semantics></math><span id="S3.SS3.p1.6.7" class="ltx_text" style="font-size:90%;">:</span></p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.2" class="ltx_Math" alttext="w_{i}^{{}^{\prime}}=\frac{\text{exp}\left(\frac{c_{i}^{T}u^{{}^{\prime}}}{\sqrt{C}}\right)}{\sum_{l=1}^{L}\text{exp}\left(\frac{c_{l}^{T}u^{{}^{\prime}}}{\sqrt{C}}\right)}" display="block"><semantics id="S3.E5.m1.2a"><mrow id="S3.E5.m1.2.3" xref="S3.E5.m1.2.3.cmml"><msubsup id="S3.E5.m1.2.3.2" xref="S3.E5.m1.2.3.2.cmml"><mi mathsize="90%" id="S3.E5.m1.2.3.2.2.2" xref="S3.E5.m1.2.3.2.2.2.cmml">w</mi><mi mathsize="90%" id="S3.E5.m1.2.3.2.2.3" xref="S3.E5.m1.2.3.2.2.3.cmml">i</mi><msup id="S3.E5.m1.2.3.2.3" xref="S3.E5.m1.2.3.2.3.cmml"><mi id="S3.E5.m1.2.3.2.3a" xref="S3.E5.m1.2.3.2.3.cmml"></mi><mo mathsize="90%" id="S3.E5.m1.2.3.2.3.1" xref="S3.E5.m1.2.3.2.3.1.cmml">‚Ä≤</mo></msup></msubsup><mo mathsize="90%" id="S3.E5.m1.2.3.1" xref="S3.E5.m1.2.3.1.cmml">=</mo><mfrac id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml"><mtext mathsize="90%" id="S3.E5.m1.1.1.1.3" xref="S3.E5.m1.1.1.1.3a.cmml">exp</mtext><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E5.m1.1.1.1.4.2" xref="S3.E5.m1.1.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.4.2.1" xref="S3.E5.m1.1.1.1.1.cmml">(</mo><mfrac id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml"><msubsup id="S3.E5.m1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.2.2.cmml"><mi mathsize="90%" id="S3.E5.m1.1.1.1.1.2.2.2.2" xref="S3.E5.m1.1.1.1.1.2.2.2.2.cmml">c</mi><mi mathsize="90%" id="S3.E5.m1.1.1.1.1.2.2.2.3" xref="S3.E5.m1.1.1.1.1.2.2.2.3.cmml">i</mi><mi mathsize="90%" id="S3.E5.m1.1.1.1.1.2.2.3" xref="S3.E5.m1.1.1.1.1.2.2.3.cmml">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.2.1" xref="S3.E5.m1.1.1.1.1.2.1.cmml">‚Äã</mo><msup id="S3.E5.m1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.2.3.cmml"><mi mathsize="90%" id="S3.E5.m1.1.1.1.1.2.3.2" xref="S3.E5.m1.1.1.1.1.2.3.2.cmml">u</mi><msup id="S3.E5.m1.1.1.1.1.2.3.3" xref="S3.E5.m1.1.1.1.1.2.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.2.3.3a" xref="S3.E5.m1.1.1.1.1.2.3.3.cmml"></mi><mo mathsize="90%" id="S3.E5.m1.1.1.1.1.2.3.3.1" xref="S3.E5.m1.1.1.1.1.2.3.3.1.cmml">‚Ä≤</mo></msup></msup></mrow><msqrt id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.2.cmml">C</mi></msqrt></mfrac><mo id="S3.E5.m1.1.1.1.4.2.2" xref="S3.E5.m1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E5.m1.2.2.2" xref="S3.E5.m1.2.2.2.cmml"><msubsup id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.2.cmml"><mo maxsize="90%" minsize="90%" stretchy="true" id="S3.E5.m1.2.2.2.2.2.2" xref="S3.E5.m1.2.2.2.2.2.2.cmml">‚àë</mo><mrow id="S3.E5.m1.2.2.2.2.2.3" xref="S3.E5.m1.2.2.2.2.2.3.cmml"><mi mathsize="90%" id="S3.E5.m1.2.2.2.2.2.3.2" xref="S3.E5.m1.2.2.2.2.2.3.2.cmml">l</mi><mo mathsize="90%" id="S3.E5.m1.2.2.2.2.2.3.1" xref="S3.E5.m1.2.2.2.2.2.3.1.cmml">=</mo><mn mathsize="90%" id="S3.E5.m1.2.2.2.2.2.3.3" xref="S3.E5.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="S3.E5.m1.2.2.2.2.3" xref="S3.E5.m1.2.2.2.2.3.cmml">L</mi></msubsup><mrow id="S3.E5.m1.2.2.2.3" xref="S3.E5.m1.2.2.2.3.cmml"><mtext mathsize="90%" id="S3.E5.m1.2.2.2.3.2" xref="S3.E5.m1.2.2.2.3.2a.cmml">exp</mtext><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.3.1" xref="S3.E5.m1.2.2.2.3.1.cmml">‚Äã</mo><mrow id="S3.E5.m1.2.2.2.3.3.2" xref="S3.E5.m1.2.2.2.1.cmml"><mo id="S3.E5.m1.2.2.2.3.3.2.1" xref="S3.E5.m1.2.2.2.1.cmml">(</mo><mfrac id="S3.E5.m1.2.2.2.1" xref="S3.E5.m1.2.2.2.1.cmml"><mrow id="S3.E5.m1.2.2.2.1.2" xref="S3.E5.m1.2.2.2.1.2.cmml"><msubsup id="S3.E5.m1.2.2.2.1.2.2" xref="S3.E5.m1.2.2.2.1.2.2.cmml"><mi mathsize="90%" id="S3.E5.m1.2.2.2.1.2.2.2.2" xref="S3.E5.m1.2.2.2.1.2.2.2.2.cmml">c</mi><mi mathsize="90%" id="S3.E5.m1.2.2.2.1.2.2.2.3" xref="S3.E5.m1.2.2.2.1.2.2.2.3.cmml">l</mi><mi mathsize="90%" id="S3.E5.m1.2.2.2.1.2.2.3" xref="S3.E5.m1.2.2.2.1.2.2.3.cmml">T</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.1.2.1" xref="S3.E5.m1.2.2.2.1.2.1.cmml">‚Äã</mo><msup id="S3.E5.m1.2.2.2.1.2.3" xref="S3.E5.m1.2.2.2.1.2.3.cmml"><mi mathsize="90%" id="S3.E5.m1.2.2.2.1.2.3.2" xref="S3.E5.m1.2.2.2.1.2.3.2.cmml">u</mi><msup id="S3.E5.m1.2.2.2.1.2.3.3" xref="S3.E5.m1.2.2.2.1.2.3.3.cmml"><mi id="S3.E5.m1.2.2.2.1.2.3.3a" xref="S3.E5.m1.2.2.2.1.2.3.3.cmml"></mi><mo mathsize="90%" id="S3.E5.m1.2.2.2.1.2.3.3.1" xref="S3.E5.m1.2.2.2.1.2.3.3.1.cmml">‚Ä≤</mo></msup></msup></mrow><msqrt id="S3.E5.m1.2.2.2.1.3" xref="S3.E5.m1.2.2.2.1.3.cmml"><mi mathsize="90%" id="S3.E5.m1.2.2.2.1.3.2" xref="S3.E5.m1.2.2.2.1.3.2.cmml">C</mi></msqrt></mfrac><mo id="S3.E5.m1.2.2.2.3.3.2.2" xref="S3.E5.m1.2.2.2.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.2b"><apply id="S3.E5.m1.2.3.cmml" xref="S3.E5.m1.2.3"><eq id="S3.E5.m1.2.3.1.cmml" xref="S3.E5.m1.2.3.1"></eq><apply id="S3.E5.m1.2.3.2.cmml" xref="S3.E5.m1.2.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.3.2.1.cmml" xref="S3.E5.m1.2.3.2">superscript</csymbol><apply id="S3.E5.m1.2.3.2.2.cmml" xref="S3.E5.m1.2.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.3.2.2.1.cmml" xref="S3.E5.m1.2.3.2">subscript</csymbol><ci id="S3.E5.m1.2.3.2.2.2.cmml" xref="S3.E5.m1.2.3.2.2.2">ùë§</ci><ci id="S3.E5.m1.2.3.2.2.3.cmml" xref="S3.E5.m1.2.3.2.2.3">ùëñ</ci></apply><apply id="S3.E5.m1.2.3.2.3.cmml" xref="S3.E5.m1.2.3.2.3"><ci id="S3.E5.m1.2.3.2.3.1.cmml" xref="S3.E5.m1.2.3.2.3.1">‚Ä≤</ci></apply></apply><apply id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2"><divide id="S3.E5.m1.2.2.3.cmml" xref="S3.E5.m1.2.2"></divide><apply id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><times id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.2"></times><ci id="S3.E5.m1.1.1.1.3a.cmml" xref="S3.E5.m1.1.1.1.3"><mtext mathsize="90%" id="S3.E5.m1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.3">exp</mtext></ci><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.4.2"><divide id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.4.2"></divide><apply id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"><times id="S3.E5.m1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2.1"></times><apply id="S3.E5.m1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2.2">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2.2.2">ùëê</ci><ci id="S3.E5.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.2.2.3">ùëñ</ci></apply><ci id="S3.E5.m1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.2.3">ùëá</ci></apply><apply id="S3.E5.m1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.2.3">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.2.3.2">ùë¢</ci><apply id="S3.E5.m1.1.1.1.1.2.3.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3.3"><ci id="S3.E5.m1.1.1.1.1.2.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.2.3.3.1">‚Ä≤</ci></apply></apply></apply><apply id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"><root id="S3.E5.m1.1.1.1.1.3a.cmml" xref="S3.E5.m1.1.1.1.1.3"></root><ci id="S3.E5.m1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2">ùê∂</ci></apply></apply></apply><apply id="S3.E5.m1.2.2.2.cmml" xref="S3.E5.m1.2.2.2"><apply id="S3.E5.m1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2">superscript</csymbol><apply id="S3.E5.m1.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2">subscript</csymbol><sum id="S3.E5.m1.2.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2.2.2"></sum><apply id="S3.E5.m1.2.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2.2.3"><eq id="S3.E5.m1.2.2.2.2.2.3.1.cmml" xref="S3.E5.m1.2.2.2.2.2.3.1"></eq><ci id="S3.E5.m1.2.2.2.2.2.3.2.cmml" xref="S3.E5.m1.2.2.2.2.2.3.2">ùëô</ci><cn type="integer" id="S3.E5.m1.2.2.2.2.2.3.3.cmml" xref="S3.E5.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.E5.m1.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2.3">ùêø</ci></apply><apply id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.3"><times id="S3.E5.m1.2.2.2.3.1.cmml" xref="S3.E5.m1.2.2.2.3.1"></times><ci id="S3.E5.m1.2.2.2.3.2a.cmml" xref="S3.E5.m1.2.2.2.3.2"><mtext mathsize="90%" id="S3.E5.m1.2.2.2.3.2.cmml" xref="S3.E5.m1.2.2.2.3.2">exp</mtext></ci><apply id="S3.E5.m1.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.3.3.2"><divide id="S3.E5.m1.2.2.2.1.1.cmml" xref="S3.E5.m1.2.2.2.3.3.2"></divide><apply id="S3.E5.m1.2.2.2.1.2.cmml" xref="S3.E5.m1.2.2.2.1.2"><times id="S3.E5.m1.2.2.2.1.2.1.cmml" xref="S3.E5.m1.2.2.2.1.2.1"></times><apply id="S3.E5.m1.2.2.2.1.2.2.cmml" xref="S3.E5.m1.2.2.2.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.1.2.2.1.cmml" xref="S3.E5.m1.2.2.2.1.2.2">superscript</csymbol><apply id="S3.E5.m1.2.2.2.1.2.2.2.cmml" xref="S3.E5.m1.2.2.2.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.1.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.1.2.2">subscript</csymbol><ci id="S3.E5.m1.2.2.2.1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.1.2.2.2.2">ùëê</ci><ci id="S3.E5.m1.2.2.2.1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.1.2.2.2.3">ùëô</ci></apply><ci id="S3.E5.m1.2.2.2.1.2.2.3.cmml" xref="S3.E5.m1.2.2.2.1.2.2.3">ùëá</ci></apply><apply id="S3.E5.m1.2.2.2.1.2.3.cmml" xref="S3.E5.m1.2.2.2.1.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.1.2.3.1.cmml" xref="S3.E5.m1.2.2.2.1.2.3">superscript</csymbol><ci id="S3.E5.m1.2.2.2.1.2.3.2.cmml" xref="S3.E5.m1.2.2.2.1.2.3.2">ùë¢</ci><apply id="S3.E5.m1.2.2.2.1.2.3.3.cmml" xref="S3.E5.m1.2.2.2.1.2.3.3"><ci id="S3.E5.m1.2.2.2.1.2.3.3.1.cmml" xref="S3.E5.m1.2.2.2.1.2.3.3.1">‚Ä≤</ci></apply></apply></apply><apply id="S3.E5.m1.2.2.2.1.3.cmml" xref="S3.E5.m1.2.2.2.1.3"><root id="S3.E5.m1.2.2.2.1.3a.cmml" xref="S3.E5.m1.2.2.2.1.3"></root><ci id="S3.E5.m1.2.2.2.1.3.2.cmml" xref="S3.E5.m1.2.2.2.1.3.2">ùê∂</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.2c">w_{i}^{{}^{\prime}}=\frac{\text{exp}\left(\frac{c_{i}^{T}u^{{}^{\prime}}}{\sqrt{C}}\right)}{\sum_{l=1}^{L}\text{exp}\left(\frac{c_{l}^{T}u^{{}^{\prime}}}{\sqrt{C}}\right)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="c=\sum_{l=1}^{L}w_{l}^{{}^{\prime}}c_{l}" display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><mi mathsize="90%" id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2.cmml">c</mi><mo mathsize="90%" rspace="0.111em" id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml"><munderover id="S3.E6.m1.1.1.3.1" xref="S3.E6.m1.1.1.3.1.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" stretchy="true" id="S3.E6.m1.1.1.3.1.2.2" xref="S3.E6.m1.1.1.3.1.2.2.cmml">‚àë</mo><mrow id="S3.E6.m1.1.1.3.1.2.3" xref="S3.E6.m1.1.1.3.1.2.3.cmml"><mi mathsize="90%" id="S3.E6.m1.1.1.3.1.2.3.2" xref="S3.E6.m1.1.1.3.1.2.3.2.cmml">l</mi><mo mathsize="90%" id="S3.E6.m1.1.1.3.1.2.3.1" xref="S3.E6.m1.1.1.3.1.2.3.1.cmml">=</mo><mn mathsize="90%" id="S3.E6.m1.1.1.3.1.2.3.3" xref="S3.E6.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="S3.E6.m1.1.1.3.1.3" xref="S3.E6.m1.1.1.3.1.3.cmml">L</mi></munderover><mrow id="S3.E6.m1.1.1.3.2" xref="S3.E6.m1.1.1.3.2.cmml"><msubsup id="S3.E6.m1.1.1.3.2.2" xref="S3.E6.m1.1.1.3.2.2.cmml"><mi mathsize="90%" id="S3.E6.m1.1.1.3.2.2.2.2" xref="S3.E6.m1.1.1.3.2.2.2.2.cmml">w</mi><mi mathsize="90%" id="S3.E6.m1.1.1.3.2.2.2.3" xref="S3.E6.m1.1.1.3.2.2.2.3.cmml">l</mi><msup id="S3.E6.m1.1.1.3.2.2.3" xref="S3.E6.m1.1.1.3.2.2.3.cmml"><mi id="S3.E6.m1.1.1.3.2.2.3a" xref="S3.E6.m1.1.1.3.2.2.3.cmml"></mi><mo mathsize="90%" id="S3.E6.m1.1.1.3.2.2.3.1" xref="S3.E6.m1.1.1.3.2.2.3.1.cmml">‚Ä≤</mo></msup></msubsup><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.3.2.1" xref="S3.E6.m1.1.1.3.2.1.cmml">‚Äã</mo><msub id="S3.E6.m1.1.1.3.2.3" xref="S3.E6.m1.1.1.3.2.3.cmml"><mi mathsize="90%" id="S3.E6.m1.1.1.3.2.3.2" xref="S3.E6.m1.1.1.3.2.3.2.cmml">c</mi><mi mathsize="90%" id="S3.E6.m1.1.1.3.2.3.3" xref="S3.E6.m1.1.1.3.2.3.3.cmml">l</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><eq id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"></eq><ci id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2">ùëê</ci><apply id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"><apply id="S3.E6.m1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.1.1.cmml" xref="S3.E6.m1.1.1.3.1">superscript</csymbol><apply id="S3.E6.m1.1.1.3.1.2.cmml" xref="S3.E6.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.1.2.1.cmml" xref="S3.E6.m1.1.1.3.1">subscript</csymbol><sum id="S3.E6.m1.1.1.3.1.2.2.cmml" xref="S3.E6.m1.1.1.3.1.2.2"></sum><apply id="S3.E6.m1.1.1.3.1.2.3.cmml" xref="S3.E6.m1.1.1.3.1.2.3"><eq id="S3.E6.m1.1.1.3.1.2.3.1.cmml" xref="S3.E6.m1.1.1.3.1.2.3.1"></eq><ci id="S3.E6.m1.1.1.3.1.2.3.2.cmml" xref="S3.E6.m1.1.1.3.1.2.3.2">ùëô</ci><cn type="integer" id="S3.E6.m1.1.1.3.1.2.3.3.cmml" xref="S3.E6.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E6.m1.1.1.3.1.3.cmml" xref="S3.E6.m1.1.1.3.1.3">ùêø</ci></apply><apply id="S3.E6.m1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.3.2"><times id="S3.E6.m1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.3.2.1"></times><apply id="S3.E6.m1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.2.1.cmml" xref="S3.E6.m1.1.1.3.2.2">superscript</csymbol><apply id="S3.E6.m1.1.1.3.2.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.2.2.1.cmml" xref="S3.E6.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.2.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2.2.2">ùë§</ci><ci id="S3.E6.m1.1.1.3.2.2.2.3.cmml" xref="S3.E6.m1.1.1.3.2.2.2.3">ùëô</ci></apply><apply id="S3.E6.m1.1.1.3.2.2.3.cmml" xref="S3.E6.m1.1.1.3.2.2.3"><ci id="S3.E6.m1.1.1.3.2.2.3.1.cmml" xref="S3.E6.m1.1.1.3.2.2.3.1">‚Ä≤</ci></apply></apply><apply id="S3.E6.m1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.3.1.cmml" xref="S3.E6.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.3.2.cmml" xref="S3.E6.m1.1.1.3.2.3.2">ùëê</ci><ci id="S3.E6.m1.1.1.3.2.3.3.cmml" xref="S3.E6.m1.1.1.3.2.3.3">ùëô</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">c=\sum_{l=1}^{L}w_{l}^{{}^{\prime}}c_{l}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.3" class="ltx_p"><span id="S3.SS3.p2.3.1" class="ltx_text" style="font-size:90%;">where </span><math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="w_{i}^{{}^{\prime}}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msubsup id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p2.1.m1.1.1.2.2" xref="S3.SS3.p2.1.m1.1.1.2.2.cmml">w</mi><mi mathsize="90%" id="S3.SS3.p2.1.m1.1.1.2.3" xref="S3.SS3.p2.1.m1.1.1.2.3.cmml">i</mi><msup id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3a" xref="S3.SS3.p2.1.m1.1.1.3.cmml"></mi><mo mathsize="90%" id="S3.SS3.p2.1.m1.1.1.3.1" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">‚Ä≤</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">superscript</csymbol><apply id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.2.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2.2">ùë§</ci><ci id="S3.SS3.p2.1.m1.1.1.2.3.cmml" xref="S3.SS3.p2.1.m1.1.1.2.3">ùëñ</ci></apply><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><ci id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.1">‚Ä≤</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">w_{i}^{{}^{\prime}}</annotation></semantics></math><span id="S3.SS3.p2.3.2" class="ltx_text" style="font-size:90%;"> corresponds to the aligned weight of </span><math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="c_{i}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">c</mi><mi mathsize="90%" id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ùëê</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">c_{i}</annotation></semantics></math><span id="S3.SS3.p2.3.3" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="u^{{}^{\prime}}\in\mathbb{R}^{C}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mrow id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><msup id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml"><mi mathsize="90%" id="S3.SS3.p2.3.m3.1.1.2.2" xref="S3.SS3.p2.3.m3.1.1.2.2.cmml">u</mi><msup id="S3.SS3.p2.3.m3.1.1.2.3" xref="S3.SS3.p2.3.m3.1.1.2.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2.3a" xref="S3.SS3.p2.3.m3.1.1.2.3.cmml"></mi><mo mathsize="90%" id="S3.SS3.p2.3.m3.1.1.2.3.1" xref="S3.SS3.p2.3.m3.1.1.2.3.1.cmml">‚Ä≤</mo></msup></msup><mo mathsize="90%" id="S3.SS3.p2.3.m3.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.cmml">‚àà</mo><msup id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml"><mi mathsize="90%" id="S3.SS3.p2.3.m3.1.1.3.2" xref="S3.SS3.p2.3.m3.1.1.3.2.cmml">‚Ñù</mi><mi mathsize="90%" id="S3.SS3.p2.3.m3.1.1.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.cmml">C</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><in id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1"></in><apply id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.2.1.cmml" xref="S3.SS3.p2.3.m3.1.1.2">superscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2.2">ùë¢</ci><apply id="S3.SS3.p2.3.m3.1.1.2.3.cmml" xref="S3.SS3.p2.3.m3.1.1.2.3"><ci id="S3.SS3.p2.3.m3.1.1.2.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.2.3.1">‚Ä≤</ci></apply></apply><apply id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.2">‚Ñù</ci><ci id="S3.SS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3">ùê∂</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">u^{{}^{\prime}}\in\mathbb{R}^{C}</annotation></semantics></math><span id="S3.SS3.p2.3.4" class="ltx_text" style="font-size:90%;"> is a trainable parameter.</span></p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text" style="font-size:90%;">With this method, each vector </span><math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mi mathsize="90%" id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">c</annotation></semantics></math><span id="S3.SS3.p3.1.2" class="ltx_text" style="font-size:90%;"> is computed as a weighted average of vectors, allowing the system to learn the relevance of each of these vectors for each utterance.</span></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>System Description</h2>

<figure id="S4.F1" class="ltx_figure"><img src="/html/2406.10598/assets/system_arch.png" id="S4.F1.g1" class="ltx_graphics ltx_img_portrait" width="196" height="284" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S4.F1.3.1" class="ltx_text ltx_font_italic">Double Multi-Head Attention Multimodal System architecture.</span></figcaption>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text" style="font-size:90%;">Figure </span><a href="#S4.F1" title="Figure 1 ‚Ä£ 4 System Description ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S4.p1.1.2" class="ltx_text" style="font-size:90%;"> illustrates the architecture of our proposed multimodal emotion-recognition framework.
The following subsections describe the components used in the Double Multi-Head Attention Multimodal System architecture.</span></p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Speech Features</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Acoustic features were extracted directly from the waveform using pre-trained self-supervised models.
Some of the most widely used and best-performing models to that end are wav2vec2.0 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S4.SS1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.4" class="ltx_text" style="font-size:90%;">, XLS-R </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S4.SS1.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.7" class="ltx_text" style="font-size:90%;">, HuBERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S4.SS1.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.10" class="ltx_text" style="font-size:90%;"> and wavLM </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S4.SS1.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.13" class="ltx_text" style="font-size:90%;">.
These pre-trained models get speech features representations using several Transformer layers.
Every model has different versions with variations in the number of Transformer layers, the dimension of the speech representations and the training data.
We experimented with the following:</span></p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text" style="font-size:90%;">wav2vec2.0: wav2vec2.0 model (‚Äùlarge-lv60k‚Äù architecture), pre-trained on 60,000 hours of unlabeled audio, not fine-tuned.</span></p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text" style="font-size:90%;">XLS-R: XLS-R model with 300 million parameters, pre-trained on 436,000 hours of unlabeled audio from multiple datasets in 128 languages, not fine-tuned.</span></p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text" style="font-size:90%;">HuBERT: HuBERT model (‚Äùlarge‚Äù architecture), pre-trained on 60,000 hours of unlabeled audio, not fine-tuned.</span></p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text" style="font-size:90%;">wavLM: wavLM Large model (‚Äùlarge‚Äù architecture), pre-trained on more than 80,000 hours, not fine-tuned.</span></p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text" style="font-size:90%;">Every one of these versions uses 24 Transformer layers to get 1024-dimensional speech representations.
Since every Transformer layer may produce a different level of complexity, a multi-level aggregation is often suggested </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib38" title="" class="ltx_ref">38</a><span id="S4.SS1.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p2.1.4" class="ltx_text" style="font-size:90%;">.
To explore this approach, we extract the acoustic features of each model performing a weighted sum of every Transformer layer, where the weights were learned by the model at the training stage.</span></p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Text Features</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">To extract text features from the waveforms we first used Whisper </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S4.SS2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p1.1.4" class="ltx_text" style="font-size:90%;"> to get audio transcriptions.
Whisper is an Automatic Speech Recognition Transformer-based system trained with up to 680,000 hours of multilingual and multitask data.
When compared to humans, this model approaches their accuracy and robustness.
A pre-trained BERT model was used to extract text features from the transcriptions.
The BERT large uncased pre-trained version was used, which was trained on lower-cased English text.
This version has a total of 340M parameters, using 24 Transformer layers to output 1024-dimensional text representations.
In this case, only the last Transformer layer output was used.</span></p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Double Multi-Head Attention Multimodal Fusion</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text" style="font-size:90%;">Given a speech segment, the input of the DMHA Multimodal Fusion component is the acoustic and text features.
Several studies have explored the combination of acoustic features and linguistic content for emotion recognition, concluding that the fusion of diverse types of signals is key to improving model performance </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS3.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib34" title="" class="ltx_ref">34</a><span id="S4.SS3.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS3.p1.1.4" class="ltx_text" style="font-size:90%;">.
Motivated by this, these acoustic and text features were mixed into a first MHA layer to let the model learn complementary information using self-attention scores.
Then, a second attention layer is applied to generate an utterance-level pooled vector.</span></p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.7" class="ltx_p"><span id="S4.SS3.p2.7.1" class="ltx_text" style="font-size:90%;">If there are </span><math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="T_{1}" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi mathsize="90%" id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">T</mi><mn mathsize="90%" id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">ùëá</ci><cn type="integer" id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">T_{1}</annotation></semantics></math><span id="S4.SS3.p2.7.2" class="ltx_text" style="font-size:90%;"> acoustic features and </span><math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="T_{2}" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><msub id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mi mathsize="90%" id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">T</mi><mn mathsize="90%" id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">ùëá</ci><cn type="integer" id="S4.SS3.p2.2.m2.1.1.3.cmml" xref="S4.SS3.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">T_{2}</annotation></semantics></math><span id="S4.SS3.p2.7.3" class="ltx_text" style="font-size:90%;"> text features, the </span><math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="T=T_{1}+T_{2}" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mi mathsize="90%" id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">T</mi><mo mathsize="90%" id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">=</mo><mrow id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml"><msub id="S4.SS3.p2.3.m3.1.1.3.2" xref="S4.SS3.p2.3.m3.1.1.3.2.cmml"><mi mathsize="90%" id="S4.SS3.p2.3.m3.1.1.3.2.2" xref="S4.SS3.p2.3.m3.1.1.3.2.2.cmml">T</mi><mn mathsize="90%" id="S4.SS3.p2.3.m3.1.1.3.2.3" xref="S4.SS3.p2.3.m3.1.1.3.2.3.cmml">1</mn></msub><mo mathsize="90%" id="S4.SS3.p2.3.m3.1.1.3.1" xref="S4.SS3.p2.3.m3.1.1.3.1.cmml">+</mo><msub id="S4.SS3.p2.3.m3.1.1.3.3" xref="S4.SS3.p2.3.m3.1.1.3.3.cmml"><mi mathsize="90%" id="S4.SS3.p2.3.m3.1.1.3.3.2" xref="S4.SS3.p2.3.m3.1.1.3.3.2.cmml">T</mi><mn mathsize="90%" id="S4.SS3.p2.3.m3.1.1.3.3.3" xref="S4.SS3.p2.3.m3.1.1.3.3.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><eq id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1"></eq><ci id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">ùëá</ci><apply id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3"><plus id="S4.SS3.p2.3.m3.1.1.3.1.cmml" xref="S4.SS3.p2.3.m3.1.1.3.1"></plus><apply id="S4.SS3.p2.3.m3.1.1.3.2.cmml" xref="S4.SS3.p2.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.3.2.1.cmml" xref="S4.SS3.p2.3.m3.1.1.3.2">subscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.3.2.2.cmml" xref="S4.SS3.p2.3.m3.1.1.3.2.2">ùëá</ci><cn type="integer" id="S4.SS3.p2.3.m3.1.1.3.2.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3.2.3">1</cn></apply><apply id="S4.SS3.p2.3.m3.1.1.3.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.3.3.1.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3">subscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.3.3.2.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3.2">ùëá</ci><cn type="integer" id="S4.SS3.p2.3.m3.1.1.3.3.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">T=T_{1}+T_{2}</annotation></semantics></math><span id="S4.SS3.p2.7.4" class="ltx_text" style="font-size:90%;"> features are input to the first MHA layer.
This first attention layer can consist of a sub-vector MHA or a standard MHA as described in section </span><a href="#S3" title="3 Double Multi-Head Attention ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S4.SS3.p2.7.5" class="ltx_text" style="font-size:90%;">.
If a </span><math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mi mathsize="90%" id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><ci id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">H</annotation></semantics></math><span id="S4.SS3.p2.7.6" class="ltx_text" style="font-size:90%;">-headed sub-vector MHA is used, this first layer will output </span><math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mi mathsize="90%" id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><ci id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">H</annotation></semantics></math><span id="S4.SS3.p2.7.7" class="ltx_text" style="font-size:90%;"> vectors.
In the case of a </span><math id="S4.SS3.p2.6.m6.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mi mathsize="90%" id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><ci id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1">ùêª</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">H</annotation></semantics></math><span id="S4.SS3.p2.7.8" class="ltx_text" style="font-size:90%;">-headed standard MHA, this first layer will output </span><math id="S4.SS3.p2.7.m7.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS3.p2.7.m7.1a"><mi mathsize="90%" id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><ci id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1">ùëá</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">T</annotation></semantics></math><span id="S4.SS3.p2.7.9" class="ltx_text" style="font-size:90%;"> vectors.
We experimented with 4-headed sub-vector and standard MHA layers.
This first MHA layer outputs multimodal contextualized representations which are then aggregated into a single utterance-level vector using a second attention layer with an attention pooling strategy as described in section </span><a href="#S3.SS3" title="3.3 Attention Pooling ‚Ä£ 3 Double Multi-Head Attention ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3.3</span></a><span id="S4.SS3.p2.7.10" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Classification Layer</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.2" class="ltx_p"><span id="S4.SS4.p1.2.1" class="ltx_text" style="font-size:90%;">The aggregated utterance-level vector </span><math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mi mathsize="90%" id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">c</annotation></semantics></math><span id="S4.SS4.p1.2.2" class="ltx_text" style="font-size:90%;"> obtained from the pooling component is fed into a classification layer.
This component consists of a set of fully connected layers: an input layer, several hidden layers and an output layer.
The input layer has the same width as </span><math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mi mathsize="90%" id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">c</annotation></semantics></math><span id="S4.SS4.p1.2.3" class="ltx_text" style="font-size:90%;">‚Äôs dimension.
The output layer has the same width as the number of classes of the task and a SoftMax layer is applied to get each class probability.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Database</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">We evaluate the effectiveness of the proposed multimodal emotion recognition system on the MSP-Podcast dataset </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S5.SS1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS1.p1.1.4" class="ltx_text" style="font-size:90%;">, which
contains speech segments obtained from audio-sharing websites.
The speaking turns have been perceptually annotated by at least five raters with categorical and attribute-based emotional labels.
Categorical eight emotional classes provided in the dataset are happiness, sadness, fear, surprise, contempt, disgust and a neutral state.
While the distribution for attribute-based emotional labels has balanced content, the distribution for emotional categories is less balanced.
The training set has 68,119 speaking turns.
The development set has 19,815 speaking segments from 454 speakers.
The test set comprises 2,347 unique segments from 187 speakers, for which the labels have not been made publicly available for the challenge.</span></p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text" style="font-size:90%;">It has been proven that using Data Augmentation techniques to increase the volume of the training data significantly improves the performance of speech recognition systems </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S5.SS1.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS1.p2.1.4" class="ltx_text" style="font-size:90%;">.
An online Data Augmentation process </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S5.SS1.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS1.p2.1.7" class="ltx_text" style="font-size:90%;"> was used applying speaker augmentation with speed perturbation </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1.p2.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib39" title="" class="ltx_ref">39</a><span id="S5.SS1.p2.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS1.p2.1.10" class="ltx_text" style="font-size:90%;">, room impulse responses (RIRs) from </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1.p2.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a><span id="S5.SS1.p2.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS1.p2.1.13" class="ltx_text" style="font-size:90%;"> and background noises from the MUSAN database </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1.p2.1.14.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib41" title="" class="ltx_ref">41</a><span id="S5.SS1.p2.1.15.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS1.p2.1.16" class="ltx_text" style="font-size:90%;"> directly to the waveform.</span></p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experimental Setup</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p"><span id="S5.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">Raw waveforms were normalized using their overall mean and standard deviation from the training dataset.
We trained our models using batches of size 32.
Every speech signal was randomly cropped with a 5.5-second window, given that the median of the training utterances length is 5.2 seconds.
When needed, a repetition padding was used.
Each waveform was augmented with a </span><math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mn mathsize="90%" id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><cn type="float" id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">0.5</annotation></semantics></math><span id="S5.SS2.p1.1.2" class="ltx_text" style="font-size:90%;"> probability.
In that case, one augmentation technique was randomly chosen from speed perturbation, RIRs or background noises.
Full-length waveforms without augmentation were used at the evaluation stage.</span></p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">Acoustic and text features were extracted using frozen self-supervised pre-trained models.
Each feature has a dimension equal to 1024.
Pre-computed Whisper transcriptions were used before extracting text features.
A 4-headed Double Multi-Head Multimodal Fusion was used as the pooling component.
We experimented using both standard and sub-vector-based MHA layers.
Finally, the 8-emotion classification was done by passing the pooled vector through the classification component.
The input layer of the classification component has the same width as the aggregated utterance-level vector dimension obtained from the pooling component.
The hidden layers of the classification component are a set of 4 512-dimensional dense layers.
Each of the input and hidden layers is followed by a Layer Normalization </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS2.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib42" title="" class="ltx_ref">42</a><span id="S5.SS2.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS2.p2.1.4" class="ltx_text" style="font-size:90%;">, Gaussian Error Linear Units (GELU) activations </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS2.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib43" title="" class="ltx_ref">43</a><span id="S5.SS2.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS2.p2.1.7" class="ltx_text" style="font-size:90%;"> and a </span><math id="S5.SS2.p2.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S5.SS2.p2.1.m1.1a"><mn mathsize="90%" id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><cn type="float" id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">0.1</annotation></semantics></math><span id="S5.SS2.p2.1.8" class="ltx_text" style="font-size:90%;"> probability of dropout.</span></p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p"><span id="S5.SS2.p3.1.1" class="ltx_text" style="font-size:90%;">Since the F1-score (macro) was the metric defined to evaluate the categorical emotions prediction task (task 1 from the Challenge), training and validation phases were monitored and evaluated with this score.
Each team had a maximum of three submissions per task and the submitted systems were evaluated in the test set, from which labels were not publicly available.
Every model was trained for 20 epochs, using early stopping to avoid overfitting.
All our models were trained and evaluated using 2 GPUs (NVIDIA GeForce GTX TITAN X, NVIDIA TITAN Xp or NVIDIA GeForce RTX 2080 Ti).
Every 20 epochs training took around 24 hours to finish.
AdamW </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS2.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib44" title="" class="ltx_ref">44</a><span id="S5.SS2.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS2.p3.1.4" class="ltx_text" style="font-size:90%;"> was selected as the optimizer.
Different learning rates were tried, using a 50% decay every 5 epochs without validation of F1-score improvement.</span></p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p"><span id="S5.SS2.p4.1.1" class="ltx_text" style="font-size:90%;">Regarding loss functions, we experimented with Weighted Cross-Entropy (WCE) Loss and Focal Loss </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS2.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib45" title="" class="ltx_ref">45</a><span id="S5.SS2.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS2.p4.1.4" class="ltx_text" style="font-size:90%;"> since they both act as effective alternatives to deal with class imbalance.
The training inverse frequency of each class was used as weights for the WCE Loss.
The Focal Loss function is a dynamically scaled cross-entropy loss, where the scaling factor decays to zero as confidence in the correct class increases.
Intuitively, this scaling factor can automatically down-weight the contribution of easy examples during training and rapidly focus the model on hard examples.
This scaling factor is governed by a parameter gamma, which was set to </span><math id="S5.SS2.p4.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.SS2.p4.1.m1.1a"><mn mathsize="90%" id="S5.SS2.p4.1.m1.1.1" xref="S5.SS2.p4.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p4.1.m1.1b"><cn type="integer" id="S5.SS2.p4.1.m1.1.1.cmml" xref="S5.SS2.p4.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p4.1.m1.1c">2</annotation></semantics></math><span id="S5.SS2.p4.1.5" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p"><span id="S5.SS2.p5.1.1" class="ltx_text" style="font-size:90%;">Once each model was trained, a per-class threshold adjustment was performed.
The idea is to adjust each class decision threshold to improve their precision and recall.
For each class, we convert the task to a binary classification by treating the rest as a whole one negative class.
Then, different thresholds were explored to maximize the training Macro F1-score.
Once every threshold is set, the way of predicting the final class is the following: if the class with the highest probability output surpass its corresponding threshold, then that class is predicted (no change is done).
If the class with the highest probability output do not surpass its corresponding threshold, then the class with the next highest probability is predicted.</span></p>
</div>
<div id="S5.SS2.p6" class="ltx_para">
<p id="S5.SS2.p6.1" class="ltx_p"><span id="S5.SS2.p6.1.1" class="ltx_text" style="font-size:90%;">After the training phase and threshold adjustments were applied, we experimented with mixing different models to get a 3-model ensemble.
The motivation for using ensemble models is to reduce the generalization error of the final prediction.
As long as the base models are diverse enough, the prediction error of the ensembled model can decrease.
A hard voting strategy was adopted for the ensemble.
In case of a tie, we used the prediction of a predefined model (the one with the best validation Macro F1-score).</span></p>
</div>
<figure id="S5.T1" class="ltx_table">
<p id="S5.T1.20" class="ltx_p ltx_align_center"><span id="S5.T1.20.20" class="ltx_text" style="font-size:90%;">


<span id="S5.T1.20.20.20" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S5.T1.1.1.1.1" class="ltx_tr">
<span id="S5.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2" style="padding-top:2.25pt;padding-bottom:2.25pt;"><span id="S5.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Configuration</span></span>
<span id="S5.T1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.1.1.1.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T1.1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Train Macro F1-score</span></span>
</span></span>
<span id="S5.T1.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.1.1.1.1.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Validation Macro F1-score</span> <math id="S5.T1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.1.1.1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.1.1.1.m1.1b"><ci id="S5.T1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.3.3.3.3" class="ltx_tr">
<span id="S5.T1.3.3.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2" style="padding-top:2.25pt;padding-bottom:2.25pt;">Ensemble of models</span>
<span id="S5.T1.2.2.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.2.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.2.2.2.2.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.2.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="34.88\%" display="inline"><semantics id="S5.T1.2.2.2.2.1.1.1.m1.1a"><mrow id="S5.T1.2.2.2.2.1.1.1.m1.1.1" xref="S5.T1.2.2.2.2.1.1.1.m1.1.1.cmml"><mn id="S5.T1.2.2.2.2.1.1.1.m1.1.1.2" xref="S5.T1.2.2.2.2.1.1.1.m1.1.1.2.cmml">34.88</mn><mo id="S5.T1.2.2.2.2.1.1.1.m1.1.1.1" xref="S5.T1.2.2.2.2.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.2.1.1.1.m1.1b"><apply id="S5.T1.2.2.2.2.1.1.1.m1.1.1.cmml" xref="S5.T1.2.2.2.2.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.2.2.2.2.1.1.1.m1.1.1.1.cmml" xref="S5.T1.2.2.2.2.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.2.2.2.2.1.1.1.m1.1.1.2.cmml" xref="S5.T1.2.2.2.2.1.1.1.m1.1.1.2">34.88</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.2.1.1.1.m1.1c">34.88\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.3.3.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.3.3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.3.3.3.3.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.3.3.3.3.2.1.1.m1.1" class="ltx_Math" alttext="33.80\%" display="inline"><semantics id="S5.T1.3.3.3.3.2.1.1.m1.1a"><mrow id="S5.T1.3.3.3.3.2.1.1.m1.1.1" xref="S5.T1.3.3.3.3.2.1.1.m1.1.1.cmml"><mn id="S5.T1.3.3.3.3.2.1.1.m1.1.1.2" xref="S5.T1.3.3.3.3.2.1.1.m1.1.1.2.cmml">33.80</mn><mo id="S5.T1.3.3.3.3.2.1.1.m1.1.1.1" xref="S5.T1.3.3.3.3.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.3.3.2.1.1.m1.1b"><apply id="S5.T1.3.3.3.3.2.1.1.m1.1.1.cmml" xref="S5.T1.3.3.3.3.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.3.3.3.3.2.1.1.m1.1.1.1.cmml" xref="S5.T1.3.3.3.3.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.3.3.3.3.2.1.1.m1.1.1.2.cmml" xref="S5.T1.3.3.3.3.2.1.1.m1.1.1.2">33.80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.3.3.2.1.1.m1.1c">33.80\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.5.5.5.5" class="ltx_tr">
<span id="S5.T1.5.5.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">WCE Loss</span>
<span id="S5.T1.5.5.5.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">XLS-R</span>
<span id="S5.T1.4.4.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.4.4.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.4.4.4.4.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.4.4.4.4.1.1.1.m1.1" class="ltx_Math" alttext="34.42\%" display="inline"><semantics id="S5.T1.4.4.4.4.1.1.1.m1.1a"><mrow id="S5.T1.4.4.4.4.1.1.1.m1.1.1" xref="S5.T1.4.4.4.4.1.1.1.m1.1.1.cmml"><mn id="S5.T1.4.4.4.4.1.1.1.m1.1.1.2" xref="S5.T1.4.4.4.4.1.1.1.m1.1.1.2.cmml">34.42</mn><mo id="S5.T1.4.4.4.4.1.1.1.m1.1.1.1" xref="S5.T1.4.4.4.4.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.4.4.1.1.1.m1.1b"><apply id="S5.T1.4.4.4.4.1.1.1.m1.1.1.cmml" xref="S5.T1.4.4.4.4.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.4.4.4.4.1.1.1.m1.1.1.1.cmml" xref="S5.T1.4.4.4.4.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.4.4.4.4.1.1.1.m1.1.1.2.cmml" xref="S5.T1.4.4.4.4.1.1.1.m1.1.1.2">34.42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.4.4.1.1.1.m1.1c">34.42\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.5.5.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.5.5.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.5.5.5.5.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.5.5.5.5.2.1.1.m1.1" class="ltx_Math" alttext="33.43\%" display="inline"><semantics id="S5.T1.5.5.5.5.2.1.1.m1.1a"><mrow id="S5.T1.5.5.5.5.2.1.1.m1.1.1" xref="S5.T1.5.5.5.5.2.1.1.m1.1.1.cmml"><mn id="S5.T1.5.5.5.5.2.1.1.m1.1.1.2" xref="S5.T1.5.5.5.5.2.1.1.m1.1.1.2.cmml">33.43</mn><mo id="S5.T1.5.5.5.5.2.1.1.m1.1.1.1" xref="S5.T1.5.5.5.5.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.5.5.2.1.1.m1.1b"><apply id="S5.T1.5.5.5.5.2.1.1.m1.1.1.cmml" xref="S5.T1.5.5.5.5.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.5.5.5.5.2.1.1.m1.1.1.1.cmml" xref="S5.T1.5.5.5.5.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.5.5.5.5.2.1.1.m1.1.1.2.cmml" xref="S5.T1.5.5.5.5.2.1.1.m1.1.1.2">33.43</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.5.5.2.1.1.m1.1c">33.43\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.7.7.7.7" class="ltx_tr">
<span id="S5.T1.7.7.7.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">Focal Loss</span>
<span id="S5.T1.7.7.7.7.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">XLS-R</span>
<span id="S5.T1.6.6.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.6.6.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.6.6.6.6.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.6.6.6.6.1.1.1.m1.1" class="ltx_Math" alttext="39.15\%" display="inline"><semantics id="S5.T1.6.6.6.6.1.1.1.m1.1a"><mrow id="S5.T1.6.6.6.6.1.1.1.m1.1.1" xref="S5.T1.6.6.6.6.1.1.1.m1.1.1.cmml"><mn id="S5.T1.6.6.6.6.1.1.1.m1.1.1.2" xref="S5.T1.6.6.6.6.1.1.1.m1.1.1.2.cmml">39.15</mn><mo id="S5.T1.6.6.6.6.1.1.1.m1.1.1.1" xref="S5.T1.6.6.6.6.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.6.6.1.1.1.m1.1b"><apply id="S5.T1.6.6.6.6.1.1.1.m1.1.1.cmml" xref="S5.T1.6.6.6.6.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.6.6.6.6.1.1.1.m1.1.1.1.cmml" xref="S5.T1.6.6.6.6.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.6.6.6.6.1.1.1.m1.1.1.2.cmml" xref="S5.T1.6.6.6.6.1.1.1.m1.1.1.2">39.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.6.6.1.1.1.m1.1c">39.15\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.7.7.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.7.7.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.7.7.7.7.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.7.7.7.7.2.1.1.m1.1" class="ltx_Math" alttext="33.37\%" display="inline"><semantics id="S5.T1.7.7.7.7.2.1.1.m1.1a"><mrow id="S5.T1.7.7.7.7.2.1.1.m1.1.1" xref="S5.T1.7.7.7.7.2.1.1.m1.1.1.cmml"><mn id="S5.T1.7.7.7.7.2.1.1.m1.1.1.2" xref="S5.T1.7.7.7.7.2.1.1.m1.1.1.2.cmml">33.37</mn><mo id="S5.T1.7.7.7.7.2.1.1.m1.1.1.1" xref="S5.T1.7.7.7.7.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.7.7.2.1.1.m1.1b"><apply id="S5.T1.7.7.7.7.2.1.1.m1.1.1.cmml" xref="S5.T1.7.7.7.7.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.7.7.7.7.2.1.1.m1.1.1.1.cmml" xref="S5.T1.7.7.7.7.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.7.7.7.7.2.1.1.m1.1.1.2.cmml" xref="S5.T1.7.7.7.7.2.1.1.m1.1.1.2">33.37</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.7.7.2.1.1.m1.1c">33.37\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.9.9.9.9" class="ltx_tr">
<span id="S5.T1.9.9.9.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">WCE Loss</span>
<span id="S5.T1.9.9.9.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">wav2vec2.0</span>
<span id="S5.T1.8.8.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.8.8.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.8.8.8.8.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.8.8.8.8.1.1.1.m1.1" class="ltx_Math" alttext="34.83\%" display="inline"><semantics id="S5.T1.8.8.8.8.1.1.1.m1.1a"><mrow id="S5.T1.8.8.8.8.1.1.1.m1.1.1" xref="S5.T1.8.8.8.8.1.1.1.m1.1.1.cmml"><mn id="S5.T1.8.8.8.8.1.1.1.m1.1.1.2" xref="S5.T1.8.8.8.8.1.1.1.m1.1.1.2.cmml">34.83</mn><mo id="S5.T1.8.8.8.8.1.1.1.m1.1.1.1" xref="S5.T1.8.8.8.8.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.8.8.8.8.1.1.1.m1.1b"><apply id="S5.T1.8.8.8.8.1.1.1.m1.1.1.cmml" xref="S5.T1.8.8.8.8.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.8.8.8.8.1.1.1.m1.1.1.1.cmml" xref="S5.T1.8.8.8.8.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.8.8.8.8.1.1.1.m1.1.1.2.cmml" xref="S5.T1.8.8.8.8.1.1.1.m1.1.1.2">34.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.8.8.8.1.1.1.m1.1c">34.83\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.9.9.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.9.9.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.9.9.9.9.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.9.9.9.9.2.1.1.m1.1" class="ltx_Math" alttext="32.69\%" display="inline"><semantics id="S5.T1.9.9.9.9.2.1.1.m1.1a"><mrow id="S5.T1.9.9.9.9.2.1.1.m1.1.1" xref="S5.T1.9.9.9.9.2.1.1.m1.1.1.cmml"><mn id="S5.T1.9.9.9.9.2.1.1.m1.1.1.2" xref="S5.T1.9.9.9.9.2.1.1.m1.1.1.2.cmml">32.69</mn><mo id="S5.T1.9.9.9.9.2.1.1.m1.1.1.1" xref="S5.T1.9.9.9.9.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.9.9.9.9.2.1.1.m1.1b"><apply id="S5.T1.9.9.9.9.2.1.1.m1.1.1.cmml" xref="S5.T1.9.9.9.9.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.9.9.9.9.2.1.1.m1.1.1.1.cmml" xref="S5.T1.9.9.9.9.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.9.9.9.9.2.1.1.m1.1.1.2.cmml" xref="S5.T1.9.9.9.9.2.1.1.m1.1.1.2">32.69</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.9.9.9.9.2.1.1.m1.1c">32.69\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.11.11.11.11" class="ltx_tr">
<span id="S5.T1.11.11.11.11.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">Focal Loss</span>
<span id="S5.T1.11.11.11.11.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">HuBERT</span>
<span id="S5.T1.10.10.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.10.10.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.10.10.10.10.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.10.10.10.10.1.1.1.m1.1" class="ltx_Math" alttext="37.84\%" display="inline"><semantics id="S5.T1.10.10.10.10.1.1.1.m1.1a"><mrow id="S5.T1.10.10.10.10.1.1.1.m1.1.1" xref="S5.T1.10.10.10.10.1.1.1.m1.1.1.cmml"><mn id="S5.T1.10.10.10.10.1.1.1.m1.1.1.2" xref="S5.T1.10.10.10.10.1.1.1.m1.1.1.2.cmml">37.84</mn><mo id="S5.T1.10.10.10.10.1.1.1.m1.1.1.1" xref="S5.T1.10.10.10.10.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.10.10.10.10.1.1.1.m1.1b"><apply id="S5.T1.10.10.10.10.1.1.1.m1.1.1.cmml" xref="S5.T1.10.10.10.10.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.10.10.10.10.1.1.1.m1.1.1.1.cmml" xref="S5.T1.10.10.10.10.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.10.10.10.10.1.1.1.m1.1.1.2.cmml" xref="S5.T1.10.10.10.10.1.1.1.m1.1.1.2">37.84</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.10.10.10.10.1.1.1.m1.1c">37.84\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.11.11.11.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.11.11.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.11.11.11.11.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.11.11.11.11.2.1.1.m1.1" class="ltx_Math" alttext="32.40\%" display="inline"><semantics id="S5.T1.11.11.11.11.2.1.1.m1.1a"><mrow id="S5.T1.11.11.11.11.2.1.1.m1.1.1" xref="S5.T1.11.11.11.11.2.1.1.m1.1.1.cmml"><mn id="S5.T1.11.11.11.11.2.1.1.m1.1.1.2" xref="S5.T1.11.11.11.11.2.1.1.m1.1.1.2.cmml">32.40</mn><mo id="S5.T1.11.11.11.11.2.1.1.m1.1.1.1" xref="S5.T1.11.11.11.11.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.11.11.11.11.2.1.1.m1.1b"><apply id="S5.T1.11.11.11.11.2.1.1.m1.1.1.cmml" xref="S5.T1.11.11.11.11.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.11.11.11.11.2.1.1.m1.1.1.1.cmml" xref="S5.T1.11.11.11.11.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.11.11.11.11.2.1.1.m1.1.1.2.cmml" xref="S5.T1.11.11.11.11.2.1.1.m1.1.1.2">32.40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.11.11.11.11.2.1.1.m1.1c">32.40\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.13.13.13.13" class="ltx_tr">
<span id="S5.T1.13.13.13.13.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">WCE Loss</span>
<span id="S5.T1.13.13.13.13.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">HuBERT</span>
<span id="S5.T1.12.12.12.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.12.12.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.12.12.12.12.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.12.12.12.12.1.1.1.m1.1" class="ltx_Math" alttext="36.73\%" display="inline"><semantics id="S5.T1.12.12.12.12.1.1.1.m1.1a"><mrow id="S5.T1.12.12.12.12.1.1.1.m1.1.1" xref="S5.T1.12.12.12.12.1.1.1.m1.1.1.cmml"><mn id="S5.T1.12.12.12.12.1.1.1.m1.1.1.2" xref="S5.T1.12.12.12.12.1.1.1.m1.1.1.2.cmml">36.73</mn><mo id="S5.T1.12.12.12.12.1.1.1.m1.1.1.1" xref="S5.T1.12.12.12.12.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.12.12.12.12.1.1.1.m1.1b"><apply id="S5.T1.12.12.12.12.1.1.1.m1.1.1.cmml" xref="S5.T1.12.12.12.12.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.12.12.12.12.1.1.1.m1.1.1.1.cmml" xref="S5.T1.12.12.12.12.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.12.12.12.12.1.1.1.m1.1.1.2.cmml" xref="S5.T1.12.12.12.12.1.1.1.m1.1.1.2">36.73</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.12.12.12.12.1.1.1.m1.1c">36.73\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.13.13.13.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.13.13.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.13.13.13.13.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.13.13.13.13.2.1.1.m1.1" class="ltx_Math" alttext="32.18\%" display="inline"><semantics id="S5.T1.13.13.13.13.2.1.1.m1.1a"><mrow id="S5.T1.13.13.13.13.2.1.1.m1.1.1" xref="S5.T1.13.13.13.13.2.1.1.m1.1.1.cmml"><mn id="S5.T1.13.13.13.13.2.1.1.m1.1.1.2" xref="S5.T1.13.13.13.13.2.1.1.m1.1.1.2.cmml">32.18</mn><mo id="S5.T1.13.13.13.13.2.1.1.m1.1.1.1" xref="S5.T1.13.13.13.13.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.13.13.13.13.2.1.1.m1.1b"><apply id="S5.T1.13.13.13.13.2.1.1.m1.1.1.cmml" xref="S5.T1.13.13.13.13.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.13.13.13.13.2.1.1.m1.1.1.1.cmml" xref="S5.T1.13.13.13.13.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.13.13.13.13.2.1.1.m1.1.1.2.cmml" xref="S5.T1.13.13.13.13.2.1.1.m1.1.1.2">32.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.13.13.13.13.2.1.1.m1.1c">32.18\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.15.15.15.15" class="ltx_tr">
<span id="S5.T1.15.15.15.15.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">WCE Loss</span>
<span id="S5.T1.15.15.15.15.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">wavLM</span>
<span id="S5.T1.14.14.14.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.14.14.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.14.14.14.14.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.14.14.14.14.1.1.1.m1.1" class="ltx_Math" alttext="32.48\%" display="inline"><semantics id="S5.T1.14.14.14.14.1.1.1.m1.1a"><mrow id="S5.T1.14.14.14.14.1.1.1.m1.1.1" xref="S5.T1.14.14.14.14.1.1.1.m1.1.1.cmml"><mn id="S5.T1.14.14.14.14.1.1.1.m1.1.1.2" xref="S5.T1.14.14.14.14.1.1.1.m1.1.1.2.cmml">32.48</mn><mo id="S5.T1.14.14.14.14.1.1.1.m1.1.1.1" xref="S5.T1.14.14.14.14.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.14.14.14.14.1.1.1.m1.1b"><apply id="S5.T1.14.14.14.14.1.1.1.m1.1.1.cmml" xref="S5.T1.14.14.14.14.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.14.14.14.14.1.1.1.m1.1.1.1.cmml" xref="S5.T1.14.14.14.14.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.14.14.14.14.1.1.1.m1.1.1.2.cmml" xref="S5.T1.14.14.14.14.1.1.1.m1.1.1.2">32.48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.14.14.14.14.1.1.1.m1.1c">32.48\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.15.15.15.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.15.15.15.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.15.15.15.15.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.15.15.15.15.2.1.1.m1.1" class="ltx_Math" alttext="31.44\%" display="inline"><semantics id="S5.T1.15.15.15.15.2.1.1.m1.1a"><mrow id="S5.T1.15.15.15.15.2.1.1.m1.1.1" xref="S5.T1.15.15.15.15.2.1.1.m1.1.1.cmml"><mn id="S5.T1.15.15.15.15.2.1.1.m1.1.1.2" xref="S5.T1.15.15.15.15.2.1.1.m1.1.1.2.cmml">31.44</mn><mo id="S5.T1.15.15.15.15.2.1.1.m1.1.1.1" xref="S5.T1.15.15.15.15.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.15.15.15.15.2.1.1.m1.1b"><apply id="S5.T1.15.15.15.15.2.1.1.m1.1.1.cmml" xref="S5.T1.15.15.15.15.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.15.15.15.15.2.1.1.m1.1.1.1.cmml" xref="S5.T1.15.15.15.15.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.15.15.15.15.2.1.1.m1.1.1.2.cmml" xref="S5.T1.15.15.15.15.2.1.1.m1.1.1.2">31.44</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.15.15.15.15.2.1.1.m1.1c">31.44\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.17.17.17.17" class="ltx_tr">
<span id="S5.T1.17.17.17.17.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">Focal Loss</span>
<span id="S5.T1.17.17.17.17.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">wav2vec2.0</span>
<span id="S5.T1.16.16.16.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.16.16.16.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.16.16.16.16.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.16.16.16.16.1.1.1.m1.1" class="ltx_Math" alttext="35.75\%" display="inline"><semantics id="S5.T1.16.16.16.16.1.1.1.m1.1a"><mrow id="S5.T1.16.16.16.16.1.1.1.m1.1.1" xref="S5.T1.16.16.16.16.1.1.1.m1.1.1.cmml"><mn id="S5.T1.16.16.16.16.1.1.1.m1.1.1.2" xref="S5.T1.16.16.16.16.1.1.1.m1.1.1.2.cmml">35.75</mn><mo id="S5.T1.16.16.16.16.1.1.1.m1.1.1.1" xref="S5.T1.16.16.16.16.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.16.16.16.16.1.1.1.m1.1b"><apply id="S5.T1.16.16.16.16.1.1.1.m1.1.1.cmml" xref="S5.T1.16.16.16.16.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.16.16.16.16.1.1.1.m1.1.1.1.cmml" xref="S5.T1.16.16.16.16.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.16.16.16.16.1.1.1.m1.1.1.2.cmml" xref="S5.T1.16.16.16.16.1.1.1.m1.1.1.2">35.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.16.16.16.16.1.1.1.m1.1c">35.75\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.17.17.17.17.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.17.17.17.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.17.17.17.17.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.17.17.17.17.2.1.1.m1.1" class="ltx_Math" alttext="31.27\%" display="inline"><semantics id="S5.T1.17.17.17.17.2.1.1.m1.1a"><mrow id="S5.T1.17.17.17.17.2.1.1.m1.1.1" xref="S5.T1.17.17.17.17.2.1.1.m1.1.1.cmml"><mn id="S5.T1.17.17.17.17.2.1.1.m1.1.1.2" xref="S5.T1.17.17.17.17.2.1.1.m1.1.1.2.cmml">31.27</mn><mo id="S5.T1.17.17.17.17.2.1.1.m1.1.1.1" xref="S5.T1.17.17.17.17.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.17.17.17.17.2.1.1.m1.1b"><apply id="S5.T1.17.17.17.17.2.1.1.m1.1.1.cmml" xref="S5.T1.17.17.17.17.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.17.17.17.17.2.1.1.m1.1.1.1.cmml" xref="S5.T1.17.17.17.17.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.17.17.17.17.2.1.1.m1.1.1.2.cmml" xref="S5.T1.17.17.17.17.2.1.1.m1.1.1.2">31.27</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.17.17.17.17.2.1.1.m1.1c">31.27\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.19.19.19.19" class="ltx_tr">
<span id="S5.T1.19.19.19.19.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">Focal Loss</span>
<span id="S5.T1.19.19.19.19.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">wavLM</span>
<span id="S5.T1.18.18.18.18.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.18.18.18.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.18.18.18.18.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.18.18.18.18.1.1.1.m1.1" class="ltx_Math" alttext="33.24\%" display="inline"><semantics id="S5.T1.18.18.18.18.1.1.1.m1.1a"><mrow id="S5.T1.18.18.18.18.1.1.1.m1.1.1" xref="S5.T1.18.18.18.18.1.1.1.m1.1.1.cmml"><mn id="S5.T1.18.18.18.18.1.1.1.m1.1.1.2" xref="S5.T1.18.18.18.18.1.1.1.m1.1.1.2.cmml">33.24</mn><mo id="S5.T1.18.18.18.18.1.1.1.m1.1.1.1" xref="S5.T1.18.18.18.18.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.18.18.18.18.1.1.1.m1.1b"><apply id="S5.T1.18.18.18.18.1.1.1.m1.1.1.cmml" xref="S5.T1.18.18.18.18.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.18.18.18.18.1.1.1.m1.1.1.1.cmml" xref="S5.T1.18.18.18.18.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.18.18.18.18.1.1.1.m1.1.1.2.cmml" xref="S5.T1.18.18.18.18.1.1.1.m1.1.1.2">33.24</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.18.18.18.18.1.1.1.m1.1c">33.24\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T1.19.19.19.19.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.19.19.19.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.19.19.19.19.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.19.19.19.19.2.1.1.m1.1" class="ltx_Math" alttext="30.77\%" display="inline"><semantics id="S5.T1.19.19.19.19.2.1.1.m1.1a"><mrow id="S5.T1.19.19.19.19.2.1.1.m1.1.1" xref="S5.T1.19.19.19.19.2.1.1.m1.1.1.cmml"><mn id="S5.T1.19.19.19.19.2.1.1.m1.1.1.2" xref="S5.T1.19.19.19.19.2.1.1.m1.1.1.2.cmml">30.77</mn><mo id="S5.T1.19.19.19.19.2.1.1.m1.1.1.1" xref="S5.T1.19.19.19.19.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.19.19.19.19.2.1.1.m1.1b"><apply id="S5.T1.19.19.19.19.2.1.1.m1.1.1.cmml" xref="S5.T1.19.19.19.19.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.19.19.19.19.2.1.1.m1.1.1.1.cmml" xref="S5.T1.19.19.19.19.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.19.19.19.19.2.1.1.m1.1.1.2.cmml" xref="S5.T1.19.19.19.19.2.1.1.m1.1.1.2">30.77</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.19.19.19.19.2.1.1.m1.1c">30.77\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T1.20.20.20.20" class="ltx_tr">
<span id="S5.T1.20.20.20.20.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2" style="padding-top:2.25pt;padding-bottom:2.25pt;">Challenge Official Baseline</span>
<span id="S5.T1.20.20.20.20.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.20.20.20.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.20.20.20.20.3.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span></span>
<span id="S5.T1.20.20.20.20.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T1.20.20.20.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T1.20.20.20.20.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T1.20.20.20.20.1.1.1.m1.1" class="ltx_Math" alttext="30.70\%" display="inline"><semantics id="S5.T1.20.20.20.20.1.1.1.m1.1a"><mrow id="S5.T1.20.20.20.20.1.1.1.m1.1.1" xref="S5.T1.20.20.20.20.1.1.1.m1.1.1.cmml"><mn id="S5.T1.20.20.20.20.1.1.1.m1.1.1.2" xref="S5.T1.20.20.20.20.1.1.1.m1.1.1.2.cmml">30.70</mn><mo id="S5.T1.20.20.20.20.1.1.1.m1.1.1.1" xref="S5.T1.20.20.20.20.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.20.20.20.20.1.1.1.m1.1b"><apply id="S5.T1.20.20.20.20.1.1.1.m1.1.1.cmml" xref="S5.T1.20.20.20.20.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T1.20.20.20.20.1.1.1.m1.1.1.1.cmml" xref="S5.T1.20.20.20.20.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T1.20.20.20.20.1.1.1.m1.1.1.2.cmml" xref="S5.T1.20.20.20.20.1.1.1.m1.1.1.2">30.70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.20.20.20.20.1.1.1.m1.1c">30.70\%</annotation></semantics></math></span>
</span></span></span>
</span>
</span></span></p>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span> <span id="S5.T1.24.1" class="ltx_text ltx_font_italic">Experimental results using the standard MHA mechanism in the DMHA component.
Threshold adjustment was applied to every model, except for the Challenge Official Baseline.
Ensemble of models combine the following three models: WCE Loss and XLS-R; WCE Loss and wav2vec2.0; WCE Loss and wavLM.</span></figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Results</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p"><span id="S5.SS3.p1.1.1" class="ltx_text" style="font-size:90%;">We trained several models combining different loss functions (WCE loss and Focal loss), pre-trained self-supervised speech features extractors (wav2vec2.0, XLS-R, HuBERT and wavLM) and MHA mechanisms (standard and sub-vector MHA).
A model ensemble using the following three configurations was also evaluated: WCE loss and XLS-R speech features extractor; WCE loss and wav2vec2.0 speech features extractor; WCE loss and wavLM speech features extractor.
The choice of these three models was motivated by the idea that extracting different patterns from the same speech utterance may contribute to the final system diversity.
After applying threshold adjustment, we evaluate them using Macro F1-score both in the training and validation datasets of the competition.
Applying threshold adjustment increased validation Macro F1-score approximately in a 1% absolute both for the Standard and the sub-vector-based models, being a useful strategy for this competition.</span></p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p"><span id="S5.SS3.p2.1.1" class="ltx_text" style="font-size:90%;">We can see from Table </span><a href="#S5.T1" title="Table 1 ‚Ä£ 5.2 Experimental Setup ‚Ä£ 5 Experiments ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S5.SS3.p2.1.2" class="ltx_text" style="font-size:90%;"> results that our best model is the ensemble of models.
This configuration was used to obtain our best submission ranking at the Challenge.
This model outperforms the challenge official baseline with a 3.1% absolute increase in the validation Macro F1-score.
In terms of relative improvement, our best model gained 10.1% validation Macro F1-score compared to the baseline.
When using standard MHA, models with XLS-R </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS3.p2.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S5.SS3.p2.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS3.p2.1.5" class="ltx_text" style="font-size:90%;"> as speech feature extractor were the ones with the best performance.</span></p>
</div>
<figure id="S5.T2" class="ltx_table">
<p id="S5.T2.18" class="ltx_p ltx_align_center"><span id="S5.T2.18.18" class="ltx_text" style="font-size:90%;">


<span id="S5.T2.18.18.18" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S5.T2.1.1.1.1" class="ltx_tr">
<span id="S5.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2" style="padding-top:2.25pt;padding-bottom:2.25pt;"><span id="S5.T2.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Configuration</span></span>
<span id="S5.T2.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T2.1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Train Macro F1-score</span></span>
</span></span>
<span id="S5.T2.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.1.1.1.1.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S5.T2.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Validation Macro F1-score</span> <math id="S5.T2.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T2.1.1.1.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1.cmml">‚Üì</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.1.m1.1.1">‚Üì</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.3.3.3.3" class="ltx_tr">
<span id="S5.T2.3.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">WCE Loss</span>
<span id="S5.T2.3.3.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">HuBERT</span>
<span id="S5.T2.2.2.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.2.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.2.2.2.2.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.2.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="37.88\%" display="inline"><semantics id="S5.T2.2.2.2.2.1.1.1.m1.1a"><mrow id="S5.T2.2.2.2.2.1.1.1.m1.1.1" xref="S5.T2.2.2.2.2.1.1.1.m1.1.1.cmml"><mn id="S5.T2.2.2.2.2.1.1.1.m1.1.1.2" xref="S5.T2.2.2.2.2.1.1.1.m1.1.1.2.cmml">37.88</mn><mo id="S5.T2.2.2.2.2.1.1.1.m1.1.1.1" xref="S5.T2.2.2.2.2.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.1.1.1.m1.1b"><apply id="S5.T2.2.2.2.2.1.1.1.m1.1.1.cmml" xref="S5.T2.2.2.2.2.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.2.2.2.2.1.1.1.m1.1.1.1.cmml" xref="S5.T2.2.2.2.2.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.2.2.2.2.1.1.1.m1.1.1.2.cmml" xref="S5.T2.2.2.2.2.1.1.1.m1.1.1.2">37.88</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.1.1.1.m1.1c">37.88\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T2.3.3.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.3.3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.3.3.3.3.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.3.3.3.3.2.1.1.m1.1" class="ltx_Math" alttext="30.84\%" display="inline"><semantics id="S5.T2.3.3.3.3.2.1.1.m1.1a"><mrow id="S5.T2.3.3.3.3.2.1.1.m1.1.1" xref="S5.T2.3.3.3.3.2.1.1.m1.1.1.cmml"><mn id="S5.T2.3.3.3.3.2.1.1.m1.1.1.2" xref="S5.T2.3.3.3.3.2.1.1.m1.1.1.2.cmml">30.84</mn><mo id="S5.T2.3.3.3.3.2.1.1.m1.1.1.1" xref="S5.T2.3.3.3.3.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.2.1.1.m1.1b"><apply id="S5.T2.3.3.3.3.2.1.1.m1.1.1.cmml" xref="S5.T2.3.3.3.3.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.3.3.3.3.2.1.1.m1.1.1.1.cmml" xref="S5.T2.3.3.3.3.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.3.3.3.3.2.1.1.m1.1.1.2.cmml" xref="S5.T2.3.3.3.3.2.1.1.m1.1.1.2">30.84</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.2.1.1.m1.1c">30.84\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.5.5.5.5" class="ltx_tr">
<span id="S5.T2.5.5.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">Focal Loss</span>
<span id="S5.T2.5.5.5.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">XLS-R</span>
<span id="S5.T2.4.4.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.4.4.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.4.4.4.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.4.4.4.4.1.1.1.m1.1" class="ltx_Math" alttext="37.41\%" display="inline"><semantics id="S5.T2.4.4.4.4.1.1.1.m1.1a"><mrow id="S5.T2.4.4.4.4.1.1.1.m1.1.1" xref="S5.T2.4.4.4.4.1.1.1.m1.1.1.cmml"><mn id="S5.T2.4.4.4.4.1.1.1.m1.1.1.2" xref="S5.T2.4.4.4.4.1.1.1.m1.1.1.2.cmml">37.41</mn><mo id="S5.T2.4.4.4.4.1.1.1.m1.1.1.1" xref="S5.T2.4.4.4.4.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.4.1.1.1.m1.1b"><apply id="S5.T2.4.4.4.4.1.1.1.m1.1.1.cmml" xref="S5.T2.4.4.4.4.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.4.4.4.4.1.1.1.m1.1.1.1.cmml" xref="S5.T2.4.4.4.4.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.4.4.4.4.1.1.1.m1.1.1.2.cmml" xref="S5.T2.4.4.4.4.1.1.1.m1.1.1.2">37.41</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.4.1.1.1.m1.1c">37.41\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T2.5.5.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.5.5.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.5.5.5.5.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.5.5.5.5.2.1.1.m1.1" class="ltx_Math" alttext="30.73\%" display="inline"><semantics id="S5.T2.5.5.5.5.2.1.1.m1.1a"><mrow id="S5.T2.5.5.5.5.2.1.1.m1.1.1" xref="S5.T2.5.5.5.5.2.1.1.m1.1.1.cmml"><mn id="S5.T2.5.5.5.5.2.1.1.m1.1.1.2" xref="S5.T2.5.5.5.5.2.1.1.m1.1.1.2.cmml">30.73</mn><mo id="S5.T2.5.5.5.5.2.1.1.m1.1.1.1" xref="S5.T2.5.5.5.5.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.5.2.1.1.m1.1b"><apply id="S5.T2.5.5.5.5.2.1.1.m1.1.1.cmml" xref="S5.T2.5.5.5.5.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.5.5.5.5.2.1.1.m1.1.1.1.cmml" xref="S5.T2.5.5.5.5.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.5.5.5.5.2.1.1.m1.1.1.2.cmml" xref="S5.T2.5.5.5.5.2.1.1.m1.1.1.2">30.73</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.5.2.1.1.m1.1c">30.73\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.6.6.6.6" class="ltx_tr">
<span id="S5.T2.6.6.6.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2" style="padding-top:2.25pt;padding-bottom:2.25pt;">Challenge Official Baseline</span>
<span id="S5.T2.6.6.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.6.6.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.6.6.6.6.3.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span></span>
<span id="S5.T2.6.6.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.6.6.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.6.6.6.6.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.6.6.6.6.1.1.1.m1.1" class="ltx_Math" alttext="30.70\%" display="inline"><semantics id="S5.T2.6.6.6.6.1.1.1.m1.1a"><mrow id="S5.T2.6.6.6.6.1.1.1.m1.1.1" xref="S5.T2.6.6.6.6.1.1.1.m1.1.1.cmml"><mn id="S5.T2.6.6.6.6.1.1.1.m1.1.1.2" xref="S5.T2.6.6.6.6.1.1.1.m1.1.1.2.cmml">30.70</mn><mo id="S5.T2.6.6.6.6.1.1.1.m1.1.1.1" xref="S5.T2.6.6.6.6.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.6.6.1.1.1.m1.1b"><apply id="S5.T2.6.6.6.6.1.1.1.m1.1.1.cmml" xref="S5.T2.6.6.6.6.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.6.6.6.6.1.1.1.m1.1.1.1.cmml" xref="S5.T2.6.6.6.6.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.6.6.6.6.1.1.1.m1.1.1.2.cmml" xref="S5.T2.6.6.6.6.1.1.1.m1.1.1.2">30.70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.6.6.1.1.1.m1.1c">30.70\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.8.8.8.8" class="ltx_tr">
<span id="S5.T2.8.8.8.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">WCE Loss</span>
<span id="S5.T2.8.8.8.8.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">XLS-R</span>
<span id="S5.T2.7.7.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.7.7.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.7.7.7.7.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.7.7.7.7.1.1.1.m1.1" class="ltx_Math" alttext="36.05\%" display="inline"><semantics id="S5.T2.7.7.7.7.1.1.1.m1.1a"><mrow id="S5.T2.7.7.7.7.1.1.1.m1.1.1" xref="S5.T2.7.7.7.7.1.1.1.m1.1.1.cmml"><mn id="S5.T2.7.7.7.7.1.1.1.m1.1.1.2" xref="S5.T2.7.7.7.7.1.1.1.m1.1.1.2.cmml">36.05</mn><mo id="S5.T2.7.7.7.7.1.1.1.m1.1.1.1" xref="S5.T2.7.7.7.7.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.7.7.1.1.1.m1.1b"><apply id="S5.T2.7.7.7.7.1.1.1.m1.1.1.cmml" xref="S5.T2.7.7.7.7.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.7.7.7.7.1.1.1.m1.1.1.1.cmml" xref="S5.T2.7.7.7.7.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.7.7.7.7.1.1.1.m1.1.1.2.cmml" xref="S5.T2.7.7.7.7.1.1.1.m1.1.1.2">36.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.7.7.1.1.1.m1.1c">36.05\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T2.8.8.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.8.8.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.8.8.8.8.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.8.8.8.8.2.1.1.m1.1" class="ltx_Math" alttext="30.53\%" display="inline"><semantics id="S5.T2.8.8.8.8.2.1.1.m1.1a"><mrow id="S5.T2.8.8.8.8.2.1.1.m1.1.1" xref="S5.T2.8.8.8.8.2.1.1.m1.1.1.cmml"><mn id="S5.T2.8.8.8.8.2.1.1.m1.1.1.2" xref="S5.T2.8.8.8.8.2.1.1.m1.1.1.2.cmml">30.53</mn><mo id="S5.T2.8.8.8.8.2.1.1.m1.1.1.1" xref="S5.T2.8.8.8.8.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.8.8.2.1.1.m1.1b"><apply id="S5.T2.8.8.8.8.2.1.1.m1.1.1.cmml" xref="S5.T2.8.8.8.8.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.8.8.8.8.2.1.1.m1.1.1.1.cmml" xref="S5.T2.8.8.8.8.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.8.8.8.8.2.1.1.m1.1.1.2.cmml" xref="S5.T2.8.8.8.8.2.1.1.m1.1.1.2">30.53</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.8.8.2.1.1.m1.1c">30.53\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.10.10.10.10" class="ltx_tr">
<span id="S5.T2.10.10.10.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">Focal Loss</span>
<span id="S5.T2.10.10.10.10.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">wav2vec2.0</span>
<span id="S5.T2.9.9.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.9.9.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.9.9.9.9.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.9.9.9.9.1.1.1.m1.1" class="ltx_Math" alttext="31.20\%" display="inline"><semantics id="S5.T2.9.9.9.9.1.1.1.m1.1a"><mrow id="S5.T2.9.9.9.9.1.1.1.m1.1.1" xref="S5.T2.9.9.9.9.1.1.1.m1.1.1.cmml"><mn id="S5.T2.9.9.9.9.1.1.1.m1.1.1.2" xref="S5.T2.9.9.9.9.1.1.1.m1.1.1.2.cmml">31.20</mn><mo id="S5.T2.9.9.9.9.1.1.1.m1.1.1.1" xref="S5.T2.9.9.9.9.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.9.9.1.1.1.m1.1b"><apply id="S5.T2.9.9.9.9.1.1.1.m1.1.1.cmml" xref="S5.T2.9.9.9.9.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.9.9.9.9.1.1.1.m1.1.1.1.cmml" xref="S5.T2.9.9.9.9.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.9.9.9.9.1.1.1.m1.1.1.2.cmml" xref="S5.T2.9.9.9.9.1.1.1.m1.1.1.2">31.20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.9.9.1.1.1.m1.1c">31.20\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T2.10.10.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.10.10.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.10.10.10.10.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.10.10.10.10.2.1.1.m1.1" class="ltx_Math" alttext="29.31\%" display="inline"><semantics id="S5.T2.10.10.10.10.2.1.1.m1.1a"><mrow id="S5.T2.10.10.10.10.2.1.1.m1.1.1" xref="S5.T2.10.10.10.10.2.1.1.m1.1.1.cmml"><mn id="S5.T2.10.10.10.10.2.1.1.m1.1.1.2" xref="S5.T2.10.10.10.10.2.1.1.m1.1.1.2.cmml">29.31</mn><mo id="S5.T2.10.10.10.10.2.1.1.m1.1.1.1" xref="S5.T2.10.10.10.10.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.10.10.2.1.1.m1.1b"><apply id="S5.T2.10.10.10.10.2.1.1.m1.1.1.cmml" xref="S5.T2.10.10.10.10.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.10.10.10.10.2.1.1.m1.1.1.1.cmml" xref="S5.T2.10.10.10.10.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.10.10.10.10.2.1.1.m1.1.1.2.cmml" xref="S5.T2.10.10.10.10.2.1.1.m1.1.1.2">29.31</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.10.10.2.1.1.m1.1c">29.31\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.12.12.12.12" class="ltx_tr">
<span id="S5.T2.12.12.12.12.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">WCE Loss</span>
<span id="S5.T2.12.12.12.12.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">wav2vec2.0</span>
<span id="S5.T2.11.11.11.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.11.11.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.11.11.11.11.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.11.11.11.11.1.1.1.m1.1" class="ltx_Math" alttext="30.29\%" display="inline"><semantics id="S5.T2.11.11.11.11.1.1.1.m1.1a"><mrow id="S5.T2.11.11.11.11.1.1.1.m1.1.1" xref="S5.T2.11.11.11.11.1.1.1.m1.1.1.cmml"><mn id="S5.T2.11.11.11.11.1.1.1.m1.1.1.2" xref="S5.T2.11.11.11.11.1.1.1.m1.1.1.2.cmml">30.29</mn><mo id="S5.T2.11.11.11.11.1.1.1.m1.1.1.1" xref="S5.T2.11.11.11.11.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.11.11.11.11.1.1.1.m1.1b"><apply id="S5.T2.11.11.11.11.1.1.1.m1.1.1.cmml" xref="S5.T2.11.11.11.11.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.11.11.11.11.1.1.1.m1.1.1.1.cmml" xref="S5.T2.11.11.11.11.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.11.11.11.11.1.1.1.m1.1.1.2.cmml" xref="S5.T2.11.11.11.11.1.1.1.m1.1.1.2">30.29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.11.11.11.1.1.1.m1.1c">30.29\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T2.12.12.12.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.12.12.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.12.12.12.12.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.12.12.12.12.2.1.1.m1.1" class="ltx_Math" alttext="28.93\%" display="inline"><semantics id="S5.T2.12.12.12.12.2.1.1.m1.1a"><mrow id="S5.T2.12.12.12.12.2.1.1.m1.1.1" xref="S5.T2.12.12.12.12.2.1.1.m1.1.1.cmml"><mn id="S5.T2.12.12.12.12.2.1.1.m1.1.1.2" xref="S5.T2.12.12.12.12.2.1.1.m1.1.1.2.cmml">28.93</mn><mo id="S5.T2.12.12.12.12.2.1.1.m1.1.1.1" xref="S5.T2.12.12.12.12.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.12.12.12.12.2.1.1.m1.1b"><apply id="S5.T2.12.12.12.12.2.1.1.m1.1.1.cmml" xref="S5.T2.12.12.12.12.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.12.12.12.12.2.1.1.m1.1.1.1.cmml" xref="S5.T2.12.12.12.12.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.12.12.12.12.2.1.1.m1.1.1.2.cmml" xref="S5.T2.12.12.12.12.2.1.1.m1.1.1.2">28.93</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.12.12.12.12.2.1.1.m1.1c">28.93\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.14.14.14.14" class="ltx_tr">
<span id="S5.T2.14.14.14.14.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">Focal Loss</span>
<span id="S5.T2.14.14.14.14.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">HuBERT</span>
<span id="S5.T2.13.13.13.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.13.13.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.13.13.13.13.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.13.13.13.13.1.1.1.m1.1" class="ltx_Math" alttext="31.94\%" display="inline"><semantics id="S5.T2.13.13.13.13.1.1.1.m1.1a"><mrow id="S5.T2.13.13.13.13.1.1.1.m1.1.1" xref="S5.T2.13.13.13.13.1.1.1.m1.1.1.cmml"><mn id="S5.T2.13.13.13.13.1.1.1.m1.1.1.2" xref="S5.T2.13.13.13.13.1.1.1.m1.1.1.2.cmml">31.94</mn><mo id="S5.T2.13.13.13.13.1.1.1.m1.1.1.1" xref="S5.T2.13.13.13.13.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.13.13.13.13.1.1.1.m1.1b"><apply id="S5.T2.13.13.13.13.1.1.1.m1.1.1.cmml" xref="S5.T2.13.13.13.13.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.13.13.13.13.1.1.1.m1.1.1.1.cmml" xref="S5.T2.13.13.13.13.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.13.13.13.13.1.1.1.m1.1.1.2.cmml" xref="S5.T2.13.13.13.13.1.1.1.m1.1.1.2">31.94</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.13.13.13.13.1.1.1.m1.1c">31.94\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T2.14.14.14.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.14.14.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.14.14.14.14.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.14.14.14.14.2.1.1.m1.1" class="ltx_Math" alttext="28.89\%" display="inline"><semantics id="S5.T2.14.14.14.14.2.1.1.m1.1a"><mrow id="S5.T2.14.14.14.14.2.1.1.m1.1.1" xref="S5.T2.14.14.14.14.2.1.1.m1.1.1.cmml"><mn id="S5.T2.14.14.14.14.2.1.1.m1.1.1.2" xref="S5.T2.14.14.14.14.2.1.1.m1.1.1.2.cmml">28.89</mn><mo id="S5.T2.14.14.14.14.2.1.1.m1.1.1.1" xref="S5.T2.14.14.14.14.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.14.14.14.14.2.1.1.m1.1b"><apply id="S5.T2.14.14.14.14.2.1.1.m1.1.1.cmml" xref="S5.T2.14.14.14.14.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.14.14.14.14.2.1.1.m1.1.1.1.cmml" xref="S5.T2.14.14.14.14.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.14.14.14.14.2.1.1.m1.1.1.2.cmml" xref="S5.T2.14.14.14.14.2.1.1.m1.1.1.2">28.89</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.14.14.14.14.2.1.1.m1.1c">28.89\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.16.16.16.16" class="ltx_tr">
<span id="S5.T2.16.16.16.16.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">Focal Loss</span>
<span id="S5.T2.16.16.16.16.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">wavLM</span>
<span id="S5.T2.15.15.15.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.15.15.15.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.15.15.15.15.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.15.15.15.15.1.1.1.m1.1" class="ltx_Math" alttext="32.28\%" display="inline"><semantics id="S5.T2.15.15.15.15.1.1.1.m1.1a"><mrow id="S5.T2.15.15.15.15.1.1.1.m1.1.1" xref="S5.T2.15.15.15.15.1.1.1.m1.1.1.cmml"><mn id="S5.T2.15.15.15.15.1.1.1.m1.1.1.2" xref="S5.T2.15.15.15.15.1.1.1.m1.1.1.2.cmml">32.28</mn><mo id="S5.T2.15.15.15.15.1.1.1.m1.1.1.1" xref="S5.T2.15.15.15.15.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.15.15.15.15.1.1.1.m1.1b"><apply id="S5.T2.15.15.15.15.1.1.1.m1.1.1.cmml" xref="S5.T2.15.15.15.15.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.15.15.15.15.1.1.1.m1.1.1.1.cmml" xref="S5.T2.15.15.15.15.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.15.15.15.15.1.1.1.m1.1.1.2.cmml" xref="S5.T2.15.15.15.15.1.1.1.m1.1.1.2">32.28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.15.15.15.15.1.1.1.m1.1c">32.28\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T2.16.16.16.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.16.16.16.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.16.16.16.16.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.16.16.16.16.2.1.1.m1.1" class="ltx_Math" alttext="27.67\%" display="inline"><semantics id="S5.T2.16.16.16.16.2.1.1.m1.1a"><mrow id="S5.T2.16.16.16.16.2.1.1.m1.1.1" xref="S5.T2.16.16.16.16.2.1.1.m1.1.1.cmml"><mn id="S5.T2.16.16.16.16.2.1.1.m1.1.1.2" xref="S5.T2.16.16.16.16.2.1.1.m1.1.1.2.cmml">27.67</mn><mo id="S5.T2.16.16.16.16.2.1.1.m1.1.1.1" xref="S5.T2.16.16.16.16.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.16.16.16.16.2.1.1.m1.1b"><apply id="S5.T2.16.16.16.16.2.1.1.m1.1.1.cmml" xref="S5.T2.16.16.16.16.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.16.16.16.16.2.1.1.m1.1.1.1.cmml" xref="S5.T2.16.16.16.16.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.16.16.16.16.2.1.1.m1.1.1.2.cmml" xref="S5.T2.16.16.16.16.2.1.1.m1.1.1.2">27.67</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.16.16.16.16.2.1.1.m1.1c">27.67\%</annotation></semantics></math></span>
</span></span></span>
<span id="S5.T2.18.18.18.18" class="ltx_tr">
<span id="S5.T2.18.18.18.18.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">WCE Loss</span>
<span id="S5.T2.18.18.18.18.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">wavLM</span>
<span id="S5.T2.17.17.17.17.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.17.17.17.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.17.17.17.17.1.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.17.17.17.17.1.1.1.m1.1" class="ltx_Math" alttext="31.69\%" display="inline"><semantics id="S5.T2.17.17.17.17.1.1.1.m1.1a"><mrow id="S5.T2.17.17.17.17.1.1.1.m1.1.1" xref="S5.T2.17.17.17.17.1.1.1.m1.1.1.cmml"><mn id="S5.T2.17.17.17.17.1.1.1.m1.1.1.2" xref="S5.T2.17.17.17.17.1.1.1.m1.1.1.2.cmml">31.69</mn><mo id="S5.T2.17.17.17.17.1.1.1.m1.1.1.1" xref="S5.T2.17.17.17.17.1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.17.17.17.17.1.1.1.m1.1b"><apply id="S5.T2.17.17.17.17.1.1.1.m1.1.1.cmml" xref="S5.T2.17.17.17.17.1.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.17.17.17.17.1.1.1.m1.1.1.1.cmml" xref="S5.T2.17.17.17.17.1.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.17.17.17.17.1.1.1.m1.1.1.2.cmml" xref="S5.T2.17.17.17.17.1.1.1.m1.1.1.2">31.69</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.17.17.17.17.1.1.1.m1.1c">31.69\%</annotation></semantics></math></span>
</span></span>
<span id="S5.T2.18.18.18.18.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" style="padding-top:2.25pt;padding-bottom:2.25pt;">
<span id="S5.T2.18.18.18.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.18.18.18.18.2.1.1" class="ltx_p" style="width:42.7pt;"><math id="S5.T2.18.18.18.18.2.1.1.m1.1" class="ltx_Math" alttext="26.13\%" display="inline"><semantics id="S5.T2.18.18.18.18.2.1.1.m1.1a"><mrow id="S5.T2.18.18.18.18.2.1.1.m1.1.1" xref="S5.T2.18.18.18.18.2.1.1.m1.1.1.cmml"><mn id="S5.T2.18.18.18.18.2.1.1.m1.1.1.2" xref="S5.T2.18.18.18.18.2.1.1.m1.1.1.2.cmml">26.13</mn><mo id="S5.T2.18.18.18.18.2.1.1.m1.1.1.1" xref="S5.T2.18.18.18.18.2.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.18.18.18.18.2.1.1.m1.1b"><apply id="S5.T2.18.18.18.18.2.1.1.m1.1.1.cmml" xref="S5.T2.18.18.18.18.2.1.1.m1.1.1"><csymbol cd="latexml" id="S5.T2.18.18.18.18.2.1.1.m1.1.1.1.cmml" xref="S5.T2.18.18.18.18.2.1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.T2.18.18.18.18.2.1.1.m1.1.1.2.cmml" xref="S5.T2.18.18.18.18.2.1.1.m1.1.1.2">26.13</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.18.18.18.18.2.1.1.m1.1c">26.13\%</annotation></semantics></math></span>
</span></span></span>
</span>
</span></span></p>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span> <span id="S5.T2.22.1" class="ltx_text ltx_font_italic">Experimental results using the sub-vector MHA mechanism in the DMHA component.
Threshold adjustment was applied to every model, except for the Challenge Official Baseline.</span></figcaption>
</figure>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p"><span id="S5.SS3.p3.1.1" class="ltx_text" style="font-size:90%;">Figure </span><a href="#S5.F2" title="Figure 2 ‚Ä£ 5.3 Results ‚Ä£ 5 Experiments ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S5.SS3.p3.1.2" class="ltx_text" style="font-size:90%;"> shows the validation confusion matrix for the ensemble model.
We can see that the system achieves the best results detecting happiness and anger.
There are some emotions that may be more similar and the model can confuse: when the real emotion is contempt, it predicts anger 30% of the time; a similar situation arises for surprise and happiness; disgust is predicted as anger or contempt around 45% of the cases.
Finally, fear is the worst performance class.</span></p>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="/html/2406.10598/assets/confusion_matrix_reds_dpi.png" id="S5.F2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="433" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S5.F2.3.1" class="ltx_text ltx_font_italic">Validation confusion matrix of the ensemble model.</span></figcaption>
</figure>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p"><span id="S5.SS3.p4.1.1" class="ltx_text" style="font-size:90%;">We used the trained model corresponding to the WCE loss and XLS-R speech feature extractor configuration with standard MHA to analyze the features fusion in the MHA layer.
To that end, each head attention weights of a particular audio sample were calculated.
For each head, every contextual representation uses learned attention weights (matrix rows) to attend to each of the speech and text features (matrix columns), as visualized in figures </span><a href="#S5.F3" title="Figure 3 ‚Ä£ 5.3 Results ‚Ä£ 5 Experiments ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S5.SS3.p4.1.2" class="ltx_text" style="font-size:90%;"> and </span><a href="#S5.F4" title="Figure 4 ‚Ä£ 5.3 Results ‚Ä£ 5 Experiments ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S5.SS3.p4.1.3" class="ltx_text" style="font-size:90%;">.
Figure </span><a href="#S5.F3" title="Figure 3 ‚Ä£ 5.3 Results ‚Ä£ 5 Experiments ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S5.SS3.p4.1.4" class="ltx_text" style="font-size:90%;"> shows that, for head 0, attention is focused both on some speech and text features (specially in rows 20 to 30) to generate contextual representations.
On the other hand, in figure </span><a href="#S5.F4" title="Figure 4 ‚Ä£ 5.3 Results ‚Ä£ 5 Experiments ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S5.SS3.p4.1.5" class="ltx_text" style="font-size:90%;"> we can see that, for head 1, some contextual representations attend mostly to speech features and others mostly to text features.
This shows how our Multi-Head Attention Multimodal Fusion creates complex contextual representations combining speech and text information in different ways.</span></p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2406.10598/assets/att_mixed.png" id="S5.F3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="459" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S5.F3.3.1" class="ltx_text ltx_font_italic">Head 0 attention weights visualization. The white vertical dashed line divides speech features from text features.</span></figcaption>
</figure>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2406.10598/assets/att_separated.png" id="S5.F4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="461" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S5.F4.3.1" class="ltx_text ltx_font_italic">Head 1 attention weights visualization. The white vertical dashed line divides speech features from text features.</span></figcaption>
</figure>
<div id="S5.SS3.p5" class="ltx_para">
<p id="S5.SS3.p5.1" class="ltx_p"><span id="S5.SS3.p5.1.1" class="ltx_text" style="font-size:90%;">The results of the experiments using the sub-vector MHA approach are shown in Table </span><a href="#S5.T2" title="Table 2 ‚Ä£ 5.3 Results ‚Ä£ 5 Experiments ‚Ä£ Double Multi-Head Attention Multimodal System for Odyssey 2024 Speech Emotion Recognition Challenge" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S5.SS3.p5.1.2" class="ltx_text" style="font-size:90%;">.
Given that both the configurations with WCE Loss and HuBERT speech feature extractor and with Focal Loss and XLS-R speech feature extractor surpass the baseline validation score, we conclude that combining a powerful self-supervised feature extractor with a sub-vector-based Double Multi-Head Attention Multimodal Fusion component can obtain good results for this task.
Since the sub-vector MHA has significantly less parameters than the standard MHA, this efficient architecture could be useful in settings where large models are not allowed and/or training data is scarce, which is a common scenario in SER.</span></p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text" style="font-size:90%;">In this paper we have described our Double Multi-Head Attention Multimodal System for the Odyssey 2024 Speech Emotion Recognition Challenge.
Acoustic and text features were extracted using pre-trained self-supervised models.
These multimodal features are mixed adopting an early fusion strategy.
First, an MHA layer generates complementary contextualized representations.
A second attention layer is then applied to pool these representations into an utterance-level vector.
For the first attention layer, we experimented with different mechanisms: standard MHA and sub-vector MHA.
Since the sub-vector variant has significantly less parameters than the standard one, our obtained results show that this efficient architecture could be useful in settings where large models are not allowed and/or training data is scarce.
On the other hand, applying standard MHA allows the model to capture complex relationships jointly attending to information from different representation subspaces.
In terms of relative improvement, our best model gained 10.1% validation Macro F1-score compared to the baseline.
This model outperforms the challenge official baseline with a 3.1% absolute increase in the validation Macro F1-score, achieving the third position in the categorical task ranking, where 31 teams participated in total.</span></p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgments</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p"><span id="S7.p1.1.1" class="ltx_text" style="font-size:90%;">This work has been promoted and financed by the Generalitat de Catalunya through the Aina project and by the Spanish Ministerio de Ciencia e Innovaci√≥n through the project AdaVoice PID2019-107579RB-I00.
The first author is supported by a FI grant from the Catalan government.</span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Bj√∂rn¬†W Schuller,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSpeech emotion recognition: Two decades in a nutshell, benchmarks, and ongoing trends,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Communications of the ACM</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, vol. 61, no. 5, pp. 90‚Äì99, 2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Carlos Busso, Murtaza Bulut, Shrikanth Narayanan, J¬†Gratch, and S¬†Marsella,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">‚ÄúToward effective automatic recognition systems of emotion in speech,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Social emotions in nature and artifact: emotions in human and human-computer interaction</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, vol. 7, no. 17, pp. 110‚Äì127, 2013.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Dimitrios Ververidis and Constantine Kotropoulos,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">‚ÄúEmotional speech recognition: Resources, features, and methods,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Speech communication</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, vol. 48, no. 9, pp. 1162‚Äì1181, 2006.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">‚ÄúEfficient estimation of word representations in vector space,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1301.3781</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">, 2013.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">‚ÄúBert: Pre-training of deep bidirectional transformers for language understanding,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1810.04805</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
L.¬†Goncalves, A.¬†N. Salman, A.¬†Reddy Naini, L.¬†Moro-Velazquez, T.¬†Thebaud, L.P. Garcia, N.¬†Dehak, B.¬†Sisman, and C.¬†Busso,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">‚ÄúOdyssey2024 - speech emotion recognition challenge: Dataset, baseline framework, and results,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Odyssey 2024: The Speaker and Language Recognition Workshop)</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, Quebec, Canada, June 2024, vol. To appear.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Reza Lotfian and Carlos Busso,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">‚ÄúBuilding naturalistic emotionally balanced speech corpus by retrieving emotional speech from existing podcast recordings,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Affective Computing</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, vol. 10, no. 4, pp. 471‚Äì483, 2017.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Miquel India, Pooyan Safari, and Javier Hernando,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSelf multi-head attention for speaker recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1906.09890</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Miquel India, Pooyan Safari, and Javier Hernando,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">‚ÄúDouble multi-head attention for speaker verification,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2021, pp. 6144‚Äì6148.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Federico Costa, Miquel¬†√Ängel India¬†Massana, and Francisco¬†Javier Hernando¬†Peric√°s,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSpeaker characterization by means of attention pooling,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IberSPEECH 2022: Granada, Spain, 14-16 November 2022</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">. International Speech Communication Association (ISCA), 2022, pp. 166‚Äì170.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Alec Radford, Jong¬†Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">‚ÄúRobust speech recognition via large-scale weak supervision,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">. PMLR, 2023, pp. 28492‚Äì28518.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Sarala Padi, Seyed¬†Omid Sadjadi, Dinesh Manocha, and Ram¬†D Sriram,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">‚ÄúMultimodal emotion recognition using transfer learning from speaker recognition and bert-based models,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2202.08974</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Omar Mohamed and Salah¬†A Aly,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">‚ÄúArabic speech emotion recognition employing wav2vec2. 0 and hubert based on baved dataset,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2110.04425</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Soonil Kwon et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">‚ÄúAtt-net: Enhanced emotion recognition system using lightweight self-attention module,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Applied Soft Computing</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, vol. 102, pp. 107101, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Sanghyun Lee, David¬†K Han, and Hanseok Ko,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">‚ÄúFusion-convbert: parallel convolution and bert fusion for speech emotion recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Sensors</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, vol. 20, no. 22, pp. 6688, 2020.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Yuanchao Li, Tianyu Zhao, Tatsuya Kawahara, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">‚ÄúImproved end-to-end speech emotion recognition using self attention mechanism and multitask learning.,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Interspeech</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 2803‚Äì2807.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Samuel Albanie, Arsha Nagrani, Andrea Vedaldi, and Andrew Zisserman,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">‚ÄúEmotion recognition in speech using cross-modal transfer in the wild,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 26th ACM international conference on Multimedia</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 292‚Äì301.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Aggelina Chatziagapi, Georgios Paraskevopoulos, Dimitris Sgouropoulos, Georgios Pantazopoulos, Malvina Nikandrou, Theodoros Giannakopoulos, Athanasios Katsamanis, Alexandros Potamianos, and Shrikanth Narayanan,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">‚ÄúData augmentation using gans for speech emotion recognition.,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Interspeech</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 171‚Äì175.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Weicheng Cai, Jinkun Chen, Jun Zhang, and Ming Li,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">‚ÄúOn-the-fly data loader and utterance-level aggregation for speaker and language recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, vol. 28, pp. 1038‚Äì1051, 2020.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Muhammad¬†Mohsin Kabir, M.¬†F. Mridha, Jungpil Shin, Israt Jahan, and Abu¬†Quwsar Ohi,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">‚ÄúA survey of speaker recognition: Fundamental theories, recognition methods and opportunities,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:90%;">, vol. 9, pp. 79236‚Äì79263, 2021.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">‚Äúwav2vec 2.0: A framework for self-supervised learning of speech representations,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, vol. 33, pp. 12449‚Äì12460, 2020.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan¬†N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">‚ÄúAttention is all you need,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, vol. 30, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">‚ÄúXls-r: Self-supervised cross-lingual speech representation learning at scale,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2111.09296</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung¬†Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">‚ÄúHubert: Self-supervised speech representation learning by masked prediction of hidden units,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, vol. 29, pp. 3451‚Äì3460, 2021.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu¬†Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">‚ÄúWavlm: Large-scale self-supervised pre-training for full stack speech processing,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Journal of Selected Topics in Signal Processing</span><span id="bib.bib25.4.2" class="ltx_text" style="font-size:90%;">, vol. 16, no. 6, pp. 1505‚Äì1518, 2022.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Jeffrey Pennington, Richard Socher, and Christopher¬†D Manning,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">‚ÄúGlove: Global vectors for word representation,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, 2014, pp. 1532‚Äì1543.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Wen Wu, Chao Zhang, and Philip¬†C Woodland,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">‚ÄúEmotion recognition by fusing time synchronous and time asynchronous representations,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2021, pp. 6269‚Äì6273.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Leonardo Pepino, Pablo Riera, Luciana Ferrer, and Agust√≠n Gravano,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">‚ÄúFusion approaches for emotion recognition from speech using acoustic and text-based features,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2020, pp. 6484‚Äì6488.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Sarthak Yadav and Atul Rai,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">‚ÄúLearning discriminative features for speaker identification and verification.,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Interspeech</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 2237‚Äì2241.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Hao Meng, Tianhao Yan, Fei Yuan, and Hongwei Wei,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSpeech emotion recognition from 3d log-mel spectrograms with deep learning network,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE access</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, vol. 7, pp. 125868‚Äì125881, 2019.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Pooyan Safari, Miquel India, and Javier Hernando,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSelf attention networks in speaker recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Applied Sciences</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, vol. 13, no. 11, pp. 6410, 2023.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Zhiming Wang, Kaisheng Yao, Xiaolong Li, and Shuo Fang,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">‚ÄúMulti-resolution multi-head attention in deep speaker embedding,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2020, pp. 6464‚Äì6468.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Yingke Zhu, Tom Ko, David Snyder, Brian Mak, and Daniel Povey,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSelf-attentive speaker embeddings for text-independent speaker verification.,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Interspeech</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, 2018, vol. 2018, pp. 3573‚Äì3577.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Hailun Lian, Cheng Lu, Sunan Li, Yan Zhao, Chuangao Tang, and Yuan Zong,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">‚ÄúA survey of deep learning-based multimodal emotion recognition: Speech, text, and face,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Entropy</span><span id="bib.bib34.4.2" class="ltx_text" style="font-size:90%;">, vol. 25, no. 10, pp. 1440, 2023.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Sharmeen M Saleem¬†Abdullah Abdullah, Siddeeq Y¬†Ameen Ameen, Mohammed¬†AM Sadeeq, and Subhi Zeebaree,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">‚ÄúMultimodal emotion recognition using deep learning,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Applied Science and Technology Trends</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, vol. 2, no. 01, pp. 73‚Äì79, 2021.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Shuai Liu, Peng Gao, Yating Li, Weina Fu, and Weiping Ding,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">‚ÄúMulti-modal fusion network with complementarity and importance for emotion recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information Sciences</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, vol. 619, pp. 679‚Äì694, 2023.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Zhaoyang Niu, Guoqiang Zhong, and Hui Yu,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">‚ÄúA review on the attention mechanism of deep learning,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Neurocomputing</span><span id="bib.bib37.4.2" class="ltx_text" style="font-size:90%;">, vol. 452, pp. 48‚Äì62, 2021.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Shu-wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I¬†Jeff Lai, Kushal Lakhotia, Yist¬†Y Lin, Andy¬†T Liu, Jiatong Shi, Xuankai Chang, Guan-Ting Lin, et¬†al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSuperb: Speech processing universal performance benchmark,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2105.01051</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Hitoshi Yamamoto, Kong¬†Aik Lee, Koji Okabe, and Takafumi Koshinaka,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">‚ÄúSpeaker augmentation and bandwidth extension for deep speaker embedding.,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Interspeech</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, 2019, pp. 406‚Äì410.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Tom Ko, Vijayaditya Peddinti, Daniel Povey, Michael¬†L Seltzer, and Sanjeev Khudanpur,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">‚ÄúA study on data augmentation of reverberant speech for robust speech recognition,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2017, pp. 5220‚Äì5224.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
David Snyder, Guoguo Chen, and Daniel Povey,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">‚ÄúMusan: A music, speech, and noise corpus,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1510.08484</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Jimmy¬†Lei Ba, Jamie¬†Ryan Kiros, and Geoffrey¬†E Hinton,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">‚ÄúLayer normalization,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1607.06450</span><span id="bib.bib42.4.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Dan Hendrycks and Kevin Gimpel,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">‚ÄúGaussian error linear units (gelus),‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1606.08415</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Ilya Loshchilov and Frank Hutter,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">‚ÄúDecoupled weight decay regularization,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1711.05101</span><span id="bib.bib44.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll√°r,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">‚ÄúFocal loss for dense object detection,‚Äù
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer vision</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">, 2017, pp. 2980‚Äì2988.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.10597" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.10598" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.10598">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.10598" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.10599" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Jul  6 00:48:16 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
