<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.08027] Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words</title><meta property="og:description" content="We develop a large language model (LLM) based automatic speech recognition (ASR) system that can be contextualized by providing keywords as prior information in text prompts.
We adopt decoder-only architecture and use …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.08027">

<!--Generated on Thu Sep  5 14:48:35 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kento Nozawa
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Preferred Elements, Inc.
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Takashi Masuko
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Preferred Elements, Inc.
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Toru Taniguchi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Preferred Elements, Inc.
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">We develop a large language model (LLM) based automatic speech recognition (ASR) system that can be contextualized by providing keywords as prior information in text prompts.
We adopt decoder-only architecture and use our in-house LLM, PLaMo-100B,
pre-trained from scratch using datasets dominated by Japanese and English texts as the decoder.
We adopt a pre-trained Whisper encoder as an audio encoder, and the audio embeddings from the audio encoder are projected to the text embedding space by an adapter layer and concatenated with text embeddings converted from text prompts to form inputs to the decoder.
By providing keywords as prior information in the text prompts, we can contextualize our LLM-based ASR system without modifying the model architecture to transcribe ambiguous words in the input audio accurately.
Experimental results demonstrate that providing keywords to the decoder can significantly improve the recognition performance of rare and ambiguous words.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent years, large language models (LLMs) have been attracting attention
thanks to their very high performance in natural language processing
<cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a href="#bib.bib8" title="" class="ltx_ref">2019</a>; Brown et al., <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Llama Team, AI @ Meta, <a href="#bib.bib22" title="" class="ltx_ref">2024</a>)</cite>.
The performance of LLMs can improve by increasing the amount of calculations,
the amount of data, and the number of model parameters,
as known as scaling law <cite class="ltx_cite ltx_citemacro_citep">(Kaplan et al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>.
Such pre-trained LLMs can solve different downstream tasks
by contextualizing input texts, namely, prompts <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>
without updating parameters.
In addition, supervised fine-tuning can further improve
the performance of LLMs for downstream tasks <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>.
However, supervised fine-tuning requires
many computational resources to update the parameters of LLMs.
Often, parameter efficient fine-tuning <cite class="ltx_cite ltx_citemacro_citep">(Ding et al., <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>,
where the subset of parameters is fixed,
compromises the performance of downstream tasks and computational resources: the amount of memory.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">There have also been many attempts to use voice input for decoder-only LLMs
to have the multi-modal capability <cite class="ltx_cite ltx_citemacro_citep">(Latif et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>.
In these models, outputs from audio encoders
are discretized <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>; Rubenstein et al., <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite> like text tokens in LLMs
or converted to token embeddings of LLMs by applying additional adapter modules
<cite class="ltx_cite ltx_citemacro_citep">(Shu et al., <a href="#bib.bib31" title="" class="ltx_ref">2023</a>; Wu et al., <a href="#bib.bib39" title="" class="ltx_ref">2023</a>; Fathullah et al., <a href="#bib.bib10" title="" class="ltx_ref">2024</a>)</cite>,
which are parameterized by shallow neural networks,
and concatenated with text embeddings as inputs of LLMs.
Thanks to the contextualization of LLMs by prompting,
LLMs can perform not only automatic speech recognition (ASR) but also other tasks,
such as speech translation and voice chat <cite class="ltx_cite ltx_citemacro_citep">(Chu et al., <a href="#bib.bib6" title="" class="ltx_ref">2024</a>; Llama Team, AI @ Meta, <a href="#bib.bib22" title="" class="ltx_ref">2024</a>)</cite>
by including instructions in the prompt texts to the LLMs.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Even to specialize ASR tasks, the LLM-based ASR systems can be contextualized
by providing prior information on input speech to the prompts
without modifying model architectures,
unlike conventional ASR contextualization techniques
<cite class="ltx_cite ltx_citemacro_citep">(Pundak et al., <a href="#bib.bib28" title="" class="ltx_ref">2018</a>; Zhao et al., <a href="#bib.bib42" title="" class="ltx_ref">2019</a>; Jain et al., <a href="#bib.bib15" title="" class="ltx_ref">2020</a>; Le et al., <a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite>.
For example, Speech LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Lakomkin et al., <a href="#bib.bib17" title="" class="ltx_ref">2024</a>)</cite> improved ASR performance
by adding video titles and descriptions to the text prompts.
Although the Speech LLaMA provides more general information along with input speech,
providing individual words or phrases similarly to the conventional ASR contextualization techniques will enable LLM-based ASR systems to transcribe named entities or domain-specific terms.
Specifically, some languages have many homonyms, such as Japanese and Chinese (especially when dropping tones);
individual words or phrases provided as prior information
help LLMs to distinguish such homonyms.
Therefore, we develop an LLM-based ASR system that takes keywords as prior information.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The main contributions of this paper are that
(1) we develop LLM-based ASR systems
that take keywords as prior information in text prompts,
and (2) experimentally show that providing keywords as prior information
improves the recognition performance of rare and ambiguous words.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Architecture</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Model Design</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We adopt an in-house 100B-parameter LLM
pre-trained on Japanese and English datasets from scratch,
referred to as PLaMo-100B<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The details of this model will be published. The blog post briefly explaining this model and datasets is available at <a target="_blank" href="https://tech.preferred.jp/ja/blog/plamo-100b" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://tech.preferred.jp/ja/blog/plamo-100b</a> in Japanese.</span></span></span>,
as a decoder,
and the encoder of pre-trained Whisper large-v3<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We used the checkpoint at <a target="_blank" href="https://huggingface.co/openai/whisper-large-v3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/openai/whisper-large-v3</a>.</span></span></span>
as an audio encoder, as shown in <a href="#S2.F1" title="In 2.1 Model Design ‣ 2 Architecture ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>.
We also construct an LLM-based ASR system
using Swallow-7B <cite class="ltx_cite ltx_citemacro_citep">(Fujii et al., <a href="#bib.bib11" title="" class="ltx_ref">2024</a>)</cite> as a decoder
that performed continual pre-training on LLaMA-2 7B <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite>
on Japanese and English datasets, where Japanese was dominant.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2408.08027/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="302" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Model architecture</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">In order to enjoy the expressiveness of
pre-trained encoder and decoder on massive data
and to simplify the training pipeline,
we do not modify the architecture of the pre-trained models and the input data format
as much as possible inspired by <cite class="ltx_cite ltx_citemacro_citet">Lakomkin et al. (<a href="#bib.bib17" title="" class="ltx_ref">2024</a>)</cite>.
To do so, we feed projected audio features as input token embeddings of decoders.
Since the dimensionality of the original audio features extracted by the encoder
does not match with text embeddings in the decoder,
we introduce a linear adapter layer to project the original audio features to a text embeddings space.
We stack four consecutive audio features before applying the adapter
to reduce the length of audio tokens <cite class="ltx_cite ltx_citemacro_citep">(Fathullah et al., <a href="#bib.bib10" title="" class="ltx_ref">2024</a>)</cite>.
The total number of parameters of the adapter is
<math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="(4\times\texttt{Audio feature dim})\times\texttt{token dim}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mrow id="S2.SS1.p2.1.m1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.1.m1.1.1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p2.1.m1.1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.cmml"><mn id="S2.SS1.p2.1.m1.1.1.1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.1.1.1.2.cmml">4</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p2.1.m1.1.1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.cmml">×</mo><mtext class="ltx_mathvariant_monospace" id="S2.SS1.p2.1.m1.1.1.1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3a.cmml">Audio feature dim</mtext></mrow><mo rspace="0.055em" stretchy="false" id="S2.SS1.p2.1.m1.1.1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">×</mo><mtext class="ltx_mathvariant_monospace" id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3a.cmml">token dim</mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><times id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2"></times><apply id="S2.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1"><times id="S2.SS1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1"></times><cn type="integer" id="S2.SS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.2">4</cn><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.3a.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S2.SS1.p2.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3">Audio feature dim</mtext></ci></apply><ci id="S2.SS1.p2.1.m1.1.1.3a.cmml" xref="S2.SS1.p2.1.m1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">token dim</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">(4\times\texttt{Audio feature dim})\times\texttt{token dim}</annotation></semantics></math> without bias.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Our 100B model does not fit in a single NVIDIA A/H100 GPU,
whose memory size is 80GB.
To overcome this limitation,
we use QLoRA fine-tuning <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al., <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>,
where the encoder and decoder’s linear weights are quantized <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al., <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>
and perform LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite> based fine-tuning.
Note that the linear adapter layer is not quantized
because this is initialized with random weights rather than pre-trained weights.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Prompt Design</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To contextualize the decoders,
we feed additional prior information in the prompt <cite class="ltx_cite ltx_citemacro_citep">(Lakomkin et al., <a href="#bib.bib17" title="" class="ltx_ref">2024</a>)</cite>.
We do not add special tokens to the decoder tokenizer like Whisper <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite>
to fix pre-trained embedding layers of the decoders.
We design two prompt templates depending on the language: Japanese or English.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">As a part of the prior information in the prompt,
we give a language identifier
inspired by Whisper’s language tag <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib29" title="" class="ltx_ref">2022</a>)</cite>.
Concretely, we give simple texts
“<span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">Language: en</span>” for English and

“<span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">言語：ja</span>”,

which has the same meaning in Japanese, for Japanese, respectively.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">For further contextualization to transcribe rate and ambiguous words,
we give keywords of the transcriptions,
e.g., “<span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_typewriter">Keywords: tokyo, machine learning, speech, large language model</span>”,
following <cite class="ltx_cite ltx_citemacro_citet">Lakomkin et al. (<a href="#bib.bib17" title="" class="ltx_ref">2024</a>)</cite>.
We use <span id="S2.SS2.p3.1.2" class="ltx_text ltx_font_typewriter">NA</span> representing “not available”
instead of keywords for samples not having keywords.
<a href="#S3.SS1" title="3.1 Keyword Generation ‣ 3 Datasets ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.1</span></a> describes how to create keywords.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">In summary, our input to the decoder for English datasets<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a href="#A1" title="Appendix A Japanese Prompt ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">A</span></a> gives the prompt template for Japanese datasets.</span></span></span>
is as follows:</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p ltx_align_center"><span id="S2.SS2.p5.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">&lt;bos&gt;[audio embeddings] Language: en ; Keywords: [keywords] ;
Transcription: [transcription]&lt;eos&gt;<span id="S2.SS2.p5.1.1.1" class="ltx_text ltx_font_serif">,</span></span></p>
</div>
<div id="S2.SS2.p6" class="ltx_para ltx_noindent">
<p id="S2.SS2.p6.1" class="ltx_p">where <span id="S2.SS2.p6.1.1" class="ltx_text ltx_font_typewriter">&lt;bos&gt;</span> and <span id="S2.SS2.p6.1.2" class="ltx_text ltx_font_typewriter">&lt;eos&gt;</span> are special tokens pre-defined by the decoder’s tokenizer,
<span id="S2.SS2.p6.1.3" class="ltx_text ltx_font_typewriter">[audio embeddings]</span> is a sequence of audio features
extracted by the audio encoder and the adapter,
<span id="S2.SS2.p6.1.4" class="ltx_text ltx_font_typewriter">[keywords]</span> is a list of keywords as shown above,
and <span id="S2.SS2.p6.1.5" class="ltx_text ltx_font_typewriter">[transcription]</span> is a ground-truth audio transcription.
At inference, we generate <span id="S2.SS2.p6.1.6" class="ltx_text ltx_font_typewriter">[transcription]&lt;eos&gt;</span>
conditioned on its prefix prompt, i.e., audio embeddings and text prior.
Note that depending on the pre-training procedure of the decoder,
the <span id="S2.SS2.p6.1.7" class="ltx_text ltx_font_typewriter">&lt;eos&gt;</span> token in the prompt is set to be identical to the <span id="S2.SS2.p6.1.8" class="ltx_text ltx_font_typewriter">&lt;bos&gt;</span> token
to align the input format for packing <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>,
where multiple sentences are packed into a single sequence of tokens
and <span id="S2.SS2.p6.1.9" class="ltx_text ltx_font_typewriter">&lt;bos&gt;</span> is the delimiter between two sentences.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Datasets</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We combined four publicly available datasets to fine-tune our models.
Since our decoders and the audio encoder were pre-trained
on at least Japanese and English datasets,
we included an English dataset as one of four datasets
to avoid catastrophic forgetting in the English domain.
We evaluated ASR performance on four datasets covering Japanese and English.
<a href="#S3.T1" title="In YODAS ‣ 3 Datasets ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tables</span> <span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S3.T2" title="Table 2 ‣ YODAS ‣ 3 Datasets ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarize the training and evaluation datasets.
We briefly explain datasets in the following.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">CommonVoice v8.0/16.1</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">We used Japanese subset of CommonVoice v8.0/16.1 <cite class="ltx_cite ltx_citemacro_citep">(Ardila et al., <a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite><span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://commonvoice.mozilla.org/en/datasets" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://commonvoice.mozilla.org/en/datasets</a></span></span></span>.
We used the original dev/test sets in CommonVoice v8.0 and v16.1 for evaluation.
In addition, we used the train set of CommonVoice v16.1 for training.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">LibriSpeech</h5>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.1" class="ltx_p">As the English dataset,
we used LibriSpeech <cite class="ltx_cite ltx_citemacro_citep">(Panayotov et al., <a href="#bib.bib27" title="" class="ltx_ref">2015</a>)</cite>,
which is a commonly used benchmark dataset.
We used the original train/dev/test sets in our experiments.
Although dev/test sets are further divided into clean/other sets,
that is, dev-clean/dev-other and test-clean/test-other sets,
we will report experimental results for merged dev/test sets
rather than individual clean/other sets for simplicity.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ReazonSpeech</h5>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p1.1" class="ltx_p">We used a subset of ReazonSpeech v1 <cite class="ltx_cite ltx_citemacro_citep">(Yin et al., <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite> for training,
where we removed samples not included in ReazonSpeech v2.
The ReazonSpeech dataset was automatically constructed
by bootstrapping labeling processes
using ASR models on Japanese television shows.
As mentioned in the limitation of this dataset <cite class="ltx_cite ltx_citemacro_citep">(Yin et al., <a href="#bib.bib40" title="" class="ltx_ref">2023</a>, Sec. 3)</cite>,
the original transcriptions of the television shows are inaccurate.
In our experiments, we also faced a missing transcriptions issue,
and we will discuss a few approaches to mitigate this issue in <a href="#S3.SS2" title="3.2 Dataset Bias via Prompt ‣ 3 Datasets ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">YODAS</h5>

<div id="S3.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px4.p1.8" class="ltx_p">We used the Japanese subset of YODAS v1 <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib21" title="" class="ltx_ref">2023</a>)</cite>,
which is constructed from YouTube videos with a Creative Commons license.
The subset has two further subsets
depending on how transcriptions are generated:
manual (<span id="S3.SS0.SSS0.Px4.p1.8.1" class="ltx_text ltx_font_typewriter">ja000</span>) or auto-generated (<span id="S3.SS0.SSS0.Px4.p1.8.2" class="ltx_text ltx_font_typewriter">ja100</span>).
Even in the manual subset,
some samples are not appropriate for ASR because their captions explain the whole video or background sounds.
Thus we selected samples whose quality is estimated to be relatively high
on a video-by-video basis.
Concretely, we filtered out videos
satisfying at least one of the following conditions:
1) character error rates (CERs) obtained by Whisper large-v3 of <math id="S3.SS0.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.1.m1.1a"><mrow id="S3.SS0.SSS0.Px4.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.cmml"><mn id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.cmml">40</mn><mo id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.1.m1.1c">40\%</annotation></semantics></math> or higher and
2) ratios of alphabetic (<span id="S3.SS0.SSS0.Px4.p1.8.3" class="ltx_text ltx_font_typewriter">[a-zA-Z]</span>) characters of <math id="S3.SS0.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="50\%" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.2.m2.1a"><mrow id="S3.SS0.SSS0.Px4.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.cmml"><mn id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2.cmml">50</mn><mo id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.1" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.2.m2.1b"><apply id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="latexml" id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.2.m2.1c">50\%</annotation></semantics></math> or higher.
Then from the manual subset,
we selected <math id="S3.SS0.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.3.m3.1a"><mn id="S3.SS0.SSS0.Px4.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.3.m3.1b"><cn type="integer" id="S3.SS0.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.3.m3.1c">10</annotation></semantics></math> hours of high-quality videos
(<math id="S3.SS0.SSS0.Px4.p1.4.m4.1" class="ltx_Math" alttext="87" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.4.m4.1a"><mn id="S3.SS0.SSS0.Px4.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1.cmml">87</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.4.m4.1b"><cn type="integer" id="S3.SS0.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1">87</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.4.m4.1c">87</annotation></semantics></math> videos with <math id="S3.SS0.SSS0.Px4.p1.5.m5.1" class="ltx_Math" alttext="8\,313" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.5.m5.1a"><mn id="S3.SS0.SSS0.Px4.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1.cmml">8 313</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.5.m5.1b"><cn type="integer" id="S3.SS0.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1">8313</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.5.m5.1c">8\,313</annotation></semantics></math> audio samples in total) as the test set
by checking audio samples and transcriptions manually,
and <math id="S3.SS0.SSS0.Px4.p1.6.m6.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.6.m6.1a"><mn id="S3.SS0.SSS0.Px4.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px4.p1.6.m6.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.6.m6.1b"><cn type="integer" id="S3.SS0.SSS0.Px4.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.6.m6.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.6.m6.1c">10</annotation></semantics></math> hours of videos randomly (<math id="S3.SS0.SSS0.Px4.p1.7.m7.1" class="ltx_Math" alttext="81" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.7.m7.1a"><mn id="S3.SS0.SSS0.Px4.p1.7.m7.1.1" xref="S3.SS0.SSS0.Px4.p1.7.m7.1.1.cmml">81</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.7.m7.1b"><cn type="integer" id="S3.SS0.SSS0.Px4.p1.7.m7.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.7.m7.1.1">81</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.7.m7.1c">81</annotation></semantics></math> videos with <math id="S3.SS0.SSS0.Px4.p1.8.m8.1" class="ltx_Math" alttext="8\,183" display="inline"><semantics id="S3.SS0.SSS0.Px4.p1.8.m8.1a"><mn id="S3.SS0.SSS0.Px4.p1.8.m8.1.1" xref="S3.SS0.SSS0.Px4.p1.8.m8.1.1.cmml">8 183</mn><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.8.m8.1b"><cn type="integer" id="S3.SS0.SSS0.Px4.p1.8.m8.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.8.m8.1.1">8183</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.8.m8.1c">8\,183</annotation></semantics></math> audio samples in total)
except for videos in the test set as a dev set.
Finally, the complement set of the dev and test sets is the train set.
As a result, the test set is clearer than the train/dev sets,
and the dev set is clearer than the train set.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Training dataset. In the training dataset, only YODAS is used twice. See <a href="#S3.SS2" title="3.2 Dataset Bias via Prompt ‣ 3 Datasets ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.2</span></a> for the reason.</figcaption>
<table id="S3.T1.11" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top">
<thead class="ltx_thead">
<tr id="S3.T1.11.12.1" class="ltx_tr">
<th id="S3.T1.11.12.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Name</th>
<th id="S3.T1.11.12.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Language</th>
<th id="S3.T1.11.12.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Keywords</th>
<th id="S3.T1.11.12.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"># samples</th>
<th id="S3.T1.11.12.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Hours</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.2.2" class="ltx_tr">
<td id="S3.T1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">CommonVoice v16.1</td>
<td id="S3.T1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Japanese</td>
<td id="S3.T1.2.2.5" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_right ltx_border_t"><math id="S3.T1.1.1.1.m1.1" class="ltx_Math" alttext="9\,616" display="inline"><semantics id="S3.T1.1.1.1.m1.1a"><mn id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">9 616</mn><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><cn type="integer" id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">9616</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">9\,616</annotation></semantics></math></td>
<td id="S3.T1.2.2.2" class="ltx_td ltx_align_right ltx_border_t"><math id="S3.T1.2.2.2.m1.1" class="ltx_Math" alttext="13.0" display="inline"><semantics id="S3.T1.2.2.2.m1.1a"><mn id="S3.T1.2.2.2.m1.1.1" xref="S3.T1.2.2.2.m1.1.1.cmml">13.0</mn><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.m1.1b"><cn type="float" id="S3.T1.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.m1.1.1">13.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.m1.1c">13.0</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.4.4" class="ltx_tr">
<td id="S3.T1.4.4.3" class="ltx_td ltx_align_center">LibriSpeech</td>
<td id="S3.T1.4.4.4" class="ltx_td ltx_align_center">English</td>
<td id="S3.T1.4.4.5" class="ltx_td"></td>
<td id="S3.T1.3.3.1" class="ltx_td ltx_align_right"><math id="S3.T1.3.3.1.m1.1" class="ltx_Math" alttext="281\,241" display="inline"><semantics id="S3.T1.3.3.1.m1.1a"><mn id="S3.T1.3.3.1.m1.1.1" xref="S3.T1.3.3.1.m1.1.1.cmml">281 241</mn><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.m1.1b"><cn type="integer" id="S3.T1.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.1.m1.1.1">281241</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.m1.1c">281\,241</annotation></semantics></math></td>
<td id="S3.T1.4.4.2" class="ltx_td ltx_align_right"><math id="S3.T1.4.4.2.m1.1" class="ltx_Math" alttext="961.1" display="inline"><semantics id="S3.T1.4.4.2.m1.1a"><mn id="S3.T1.4.4.2.m1.1.1" xref="S3.T1.4.4.2.m1.1.1.cmml">961.1</mn><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.2.m1.1b"><cn type="float" id="S3.T1.4.4.2.m1.1.1.cmml" xref="S3.T1.4.4.2.m1.1.1">961.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.2.m1.1c">961.1</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.6.6" class="ltx_tr">
<td id="S3.T1.6.6.3" class="ltx_td ltx_align_center">ReazonSpeech</td>
<td id="S3.T1.6.6.4" class="ltx_td ltx_align_center">Japanese</td>
<td id="S3.T1.6.6.5" class="ltx_td"></td>
<td id="S3.T1.5.5.1" class="ltx_td ltx_align_right"><math id="S3.T1.5.5.1.m1.1" class="ltx_Math" alttext="11\,073\,520" display="inline"><semantics id="S3.T1.5.5.1.m1.1a"><mn id="S3.T1.5.5.1.m1.1.1" xref="S3.T1.5.5.1.m1.1.1.cmml">11 073 520</mn><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.m1.1b"><cn type="integer" id="S3.T1.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.1.m1.1.1">11073520</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.m1.1c">11\,073\,520</annotation></semantics></math></td>
<td id="S3.T1.6.6.2" class="ltx_td ltx_align_right"><math id="S3.T1.6.6.2.m1.1" class="ltx_Math" alttext="18\,867.5" display="inline"><semantics id="S3.T1.6.6.2.m1.1a"><mn id="S3.T1.6.6.2.m1.1.1" xref="S3.T1.6.6.2.m1.1.1.cmml">18 867.5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.2.m1.1b"><cn type="float" id="S3.T1.6.6.2.m1.1.1.cmml" xref="S3.T1.6.6.2.m1.1.1">18867.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.2.m1.1c">18\,867.5</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.9.9" class="ltx_tr">
<td id="S3.T1.9.9.4" class="ltx_td ltx_align_center">YODAS</td>
<td id="S3.T1.9.9.5" class="ltx_td ltx_align_center">Japanese</td>
<td id="S3.T1.7.7.1" class="ltx_td ltx_align_center"><math id="S3.T1.7.7.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S3.T1.7.7.1.m1.1a"><mi mathvariant="normal" id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><ci id="S3.T1.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S3.T1.8.8.2" class="ltx_td ltx_align_right"><math id="S3.T1.8.8.2.m1.1" class="ltx_Math" alttext="1\,080\,953" display="inline"><semantics id="S3.T1.8.8.2.m1.1a"><mn id="S3.T1.8.8.2.m1.1.1" xref="S3.T1.8.8.2.m1.1.1.cmml">1 080 953</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.2.m1.1b"><cn type="integer" id="S3.T1.8.8.2.m1.1.1.cmml" xref="S3.T1.8.8.2.m1.1.1">1080953</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.2.m1.1c">1\,080\,953</annotation></semantics></math></td>
<td id="S3.T1.9.9.3" class="ltx_td ltx_align_right"><math id="S3.T1.9.9.3.m1.1" class="ltx_Math" alttext="1\,137.3" display="inline"><semantics id="S3.T1.9.9.3.m1.1a"><mn id="S3.T1.9.9.3.m1.1.1" xref="S3.T1.9.9.3.m1.1.1.cmml">1 137.3</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.3.m1.1b"><cn type="float" id="S3.T1.9.9.3.m1.1.1.cmml" xref="S3.T1.9.9.3.m1.1.1">1137.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.3.m1.1c">1\,137.3</annotation></semantics></math></td>
</tr>
<tr id="S3.T1.11.11" class="ltx_tr">
<td id="S3.T1.11.11.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Total</td>
<td id="S3.T1.11.11.4" class="ltx_td ltx_border_bb ltx_border_t"></td>
<td id="S3.T1.11.11.5" class="ltx_td ltx_border_bb ltx_border_t"></td>
<td id="S3.T1.10.10.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><math id="S3.T1.10.10.1.m1.1" class="ltx_Math" alttext="13\,703\,510" display="inline"><semantics id="S3.T1.10.10.1.m1.1a"><mn id="S3.T1.10.10.1.m1.1.1" xref="S3.T1.10.10.1.m1.1.1.cmml">13 703 510</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.1.m1.1b"><cn type="integer" id="S3.T1.10.10.1.m1.1.1.cmml" xref="S3.T1.10.10.1.m1.1.1">13703510</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.1.m1.1c">13\,703\,510</annotation></semantics></math></td>
<td id="S3.T1.11.11.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><math id="S3.T1.11.11.2.m1.1" class="ltx_Math" alttext="22\,713.6" display="inline"><semantics id="S3.T1.11.11.2.m1.1a"><mn id="S3.T1.11.11.2.m1.1.1" xref="S3.T1.11.11.2.m1.1.1.cmml">22 713.6</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.2.m1.1b"><cn type="float" id="S3.T1.11.11.2.m1.1.1.cmml" xref="S3.T1.11.11.2.m1.1.1">22713.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.2.m1.1c">22\,713.6</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Evaluation datasets</figcaption>
<table id="S3.T2.18" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top">
<thead class="ltx_thead">
<tr id="S3.T2.18.19.1" class="ltx_tr">
<th id="S3.T2.18.19.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Name</th>
<th id="S3.T2.18.19.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Set</th>
<th id="S3.T2.18.19.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Language</th>
<th id="S3.T2.18.19.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Keywords</th>
<th id="S3.T2.18.19.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"># samples</th>
<th id="S3.T2.18.19.1.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Hours</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.2.2" class="ltx_tr">
<td id="S3.T2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">CommonVoice v8</td>
<td id="S3.T2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">dev</td>
<td id="S3.T2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">Japanese</td>
<td id="S3.T2.2.2.6" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_right ltx_border_t"><math id="S3.T2.1.1.1.m1.1" class="ltx_Math" alttext="4\,124" display="inline"><semantics id="S3.T2.1.1.1.m1.1a"><mn id="S3.T2.1.1.1.m1.1.1" xref="S3.T2.1.1.1.m1.1.1.cmml">4 124</mn><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.m1.1b"><cn type="integer" id="S3.T2.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.m1.1.1">4124</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.m1.1c">4\,124</annotation></semantics></math></td>
<td id="S3.T2.2.2.2" class="ltx_td ltx_align_right ltx_border_t"><math id="S3.T2.2.2.2.m1.1" class="ltx_Math" alttext="5.7" display="inline"><semantics id="S3.T2.2.2.2.m1.1a"><mn id="S3.T2.2.2.2.m1.1.1" xref="S3.T2.2.2.2.m1.1.1.cmml">5.7</mn><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.m1.1b"><cn type="float" id="S3.T2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.m1.1.1">5.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.m1.1c">5.7</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.4.4" class="ltx_tr">
<td id="S3.T2.4.4.3" class="ltx_td ltx_align_center">CommonVoice v8</td>
<td id="S3.T2.4.4.4" class="ltx_td ltx_align_center">test</td>
<td id="S3.T2.4.4.5" class="ltx_td ltx_align_center">Japanese</td>
<td id="S3.T2.4.4.6" class="ltx_td"></td>
<td id="S3.T2.3.3.1" class="ltx_td ltx_align_right"><math id="S3.T2.3.3.1.m1.1" class="ltx_Math" alttext="4\,483" display="inline"><semantics id="S3.T2.3.3.1.m1.1a"><mn id="S3.T2.3.3.1.m1.1.1" xref="S3.T2.3.3.1.m1.1.1.cmml">4 483</mn><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.1.m1.1b"><cn type="integer" id="S3.T2.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.1.m1.1.1">4483</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.1.m1.1c">4\,483</annotation></semantics></math></td>
<td id="S3.T2.4.4.2" class="ltx_td ltx_align_right"><math id="S3.T2.4.4.2.m1.1" class="ltx_Math" alttext="6.5" display="inline"><semantics id="S3.T2.4.4.2.m1.1a"><mn id="S3.T2.4.4.2.m1.1.1" xref="S3.T2.4.4.2.m1.1.1.cmml">6.5</mn><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.2.m1.1b"><cn type="float" id="S3.T2.4.4.2.m1.1.1.cmml" xref="S3.T2.4.4.2.m1.1.1">6.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.2.m1.1c">6.5</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.6.6" class="ltx_tr">
<td id="S3.T2.6.6.3" class="ltx_td ltx_align_center">CommonVoice v16.1</td>
<td id="S3.T2.6.6.4" class="ltx_td ltx_align_center">dev</td>
<td id="S3.T2.6.6.5" class="ltx_td ltx_align_center">Japanese</td>
<td id="S3.T2.6.6.6" class="ltx_td"></td>
<td id="S3.T2.5.5.1" class="ltx_td ltx_align_right"><math id="S3.T2.5.5.1.m1.1" class="ltx_Math" alttext="6\,094" display="inline"><semantics id="S3.T2.5.5.1.m1.1a"><mn id="S3.T2.5.5.1.m1.1.1" xref="S3.T2.5.5.1.m1.1.1.cmml">6 094</mn><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.1.m1.1b"><cn type="integer" id="S3.T2.5.5.1.m1.1.1.cmml" xref="S3.T2.5.5.1.m1.1.1">6094</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.1.m1.1c">6\,094</annotation></semantics></math></td>
<td id="S3.T2.6.6.2" class="ltx_td ltx_align_right"><math id="S3.T2.6.6.2.m1.1" class="ltx_Math" alttext="7.9" display="inline"><semantics id="S3.T2.6.6.2.m1.1a"><mn id="S3.T2.6.6.2.m1.1.1" xref="S3.T2.6.6.2.m1.1.1.cmml">7.9</mn><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.2.m1.1b"><cn type="float" id="S3.T2.6.6.2.m1.1.1.cmml" xref="S3.T2.6.6.2.m1.1.1">7.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.2.m1.1c">7.9</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.8.8" class="ltx_tr">
<td id="S3.T2.8.8.3" class="ltx_td ltx_align_center">CommonVoice v16.1</td>
<td id="S3.T2.8.8.4" class="ltx_td ltx_align_center">test</td>
<td id="S3.T2.8.8.5" class="ltx_td ltx_align_center">Japanese</td>
<td id="S3.T2.8.8.6" class="ltx_td"></td>
<td id="S3.T2.7.7.1" class="ltx_td ltx_align_right"><math id="S3.T2.7.7.1.m1.1" class="ltx_Math" alttext="6\,094" display="inline"><semantics id="S3.T2.7.7.1.m1.1a"><mn id="S3.T2.7.7.1.m1.1.1" xref="S3.T2.7.7.1.m1.1.1.cmml">6 094</mn><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.1.m1.1b"><cn type="integer" id="S3.T2.7.7.1.m1.1.1.cmml" xref="S3.T2.7.7.1.m1.1.1">6094</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.1.m1.1c">6\,094</annotation></semantics></math></td>
<td id="S3.T2.8.8.2" class="ltx_td ltx_align_right"><math id="S3.T2.8.8.2.m1.1" class="ltx_Math" alttext="8.9" display="inline"><semantics id="S3.T2.8.8.2.m1.1a"><mn id="S3.T2.8.8.2.m1.1.1" xref="S3.T2.8.8.2.m1.1.1.cmml">8.9</mn><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.2.m1.1b"><cn type="float" id="S3.T2.8.8.2.m1.1.1.cmml" xref="S3.T2.8.8.2.m1.1.1">8.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.2.m1.1c">8.9</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.10.10" class="ltx_tr">
<td id="S3.T2.10.10.3" class="ltx_td ltx_align_center">LibriSpeech</td>
<td id="S3.T2.10.10.4" class="ltx_td ltx_align_center">dev</td>
<td id="S3.T2.10.10.5" class="ltx_td ltx_align_center">English</td>
<td id="S3.T2.10.10.6" class="ltx_td"></td>
<td id="S3.T2.9.9.1" class="ltx_td ltx_align_right"><math id="S3.T2.9.9.1.m1.1" class="ltx_Math" alttext="5\,567" display="inline"><semantics id="S3.T2.9.9.1.m1.1a"><mn id="S3.T2.9.9.1.m1.1.1" xref="S3.T2.9.9.1.m1.1.1.cmml">5 567</mn><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.1.m1.1b"><cn type="integer" id="S3.T2.9.9.1.m1.1.1.cmml" xref="S3.T2.9.9.1.m1.1.1">5567</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.1.m1.1c">5\,567</annotation></semantics></math></td>
<td id="S3.T2.10.10.2" class="ltx_td ltx_align_right"><math id="S3.T2.10.10.2.m1.1" class="ltx_Math" alttext="10.5" display="inline"><semantics id="S3.T2.10.10.2.m1.1a"><mn id="S3.T2.10.10.2.m1.1.1" xref="S3.T2.10.10.2.m1.1.1.cmml">10.5</mn><annotation-xml encoding="MathML-Content" id="S3.T2.10.10.2.m1.1b"><cn type="float" id="S3.T2.10.10.2.m1.1.1.cmml" xref="S3.T2.10.10.2.m1.1.1">10.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.10.2.m1.1c">10.5</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.12.12" class="ltx_tr">
<td id="S3.T2.12.12.3" class="ltx_td ltx_align_center">LibriSpeech</td>
<td id="S3.T2.12.12.4" class="ltx_td ltx_align_center">test</td>
<td id="S3.T2.12.12.5" class="ltx_td ltx_align_center">English</td>
<td id="S3.T2.12.12.6" class="ltx_td"></td>
<td id="S3.T2.11.11.1" class="ltx_td ltx_align_right"><math id="S3.T2.11.11.1.m1.1" class="ltx_Math" alttext="5\,559" display="inline"><semantics id="S3.T2.11.11.1.m1.1a"><mn id="S3.T2.11.11.1.m1.1.1" xref="S3.T2.11.11.1.m1.1.1.cmml">5 559</mn><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.1.m1.1b"><cn type="integer" id="S3.T2.11.11.1.m1.1.1.cmml" xref="S3.T2.11.11.1.m1.1.1">5559</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.1.m1.1c">5\,559</annotation></semantics></math></td>
<td id="S3.T2.12.12.2" class="ltx_td ltx_align_right"><math id="S3.T2.12.12.2.m1.1" class="ltx_Math" alttext="10.7" display="inline"><semantics id="S3.T2.12.12.2.m1.1a"><mn id="S3.T2.12.12.2.m1.1.1" xref="S3.T2.12.12.2.m1.1.1.cmml">10.7</mn><annotation-xml encoding="MathML-Content" id="S3.T2.12.12.2.m1.1b"><cn type="float" id="S3.T2.12.12.2.m1.1.1.cmml" xref="S3.T2.12.12.2.m1.1.1">10.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.12.2.m1.1c">10.7</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.15.15" class="ltx_tr">
<td id="S3.T2.15.15.4" class="ltx_td ltx_align_center">YODAS</td>
<td id="S3.T2.15.15.5" class="ltx_td ltx_align_center">dev</td>
<td id="S3.T2.15.15.6" class="ltx_td ltx_align_center">Japanese</td>
<td id="S3.T2.13.13.1" class="ltx_td ltx_align_center"><math id="S3.T2.13.13.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S3.T2.13.13.1.m1.1a"><mi mathvariant="normal" id="S3.T2.13.13.1.m1.1.1" xref="S3.T2.13.13.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S3.T2.13.13.1.m1.1b"><ci id="S3.T2.13.13.1.m1.1.1.cmml" xref="S3.T2.13.13.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.13.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S3.T2.14.14.2" class="ltx_td ltx_align_right"><math id="S3.T2.14.14.2.m1.1" class="ltx_Math" alttext="8\,183" display="inline"><semantics id="S3.T2.14.14.2.m1.1a"><mn id="S3.T2.14.14.2.m1.1.1" xref="S3.T2.14.14.2.m1.1.1.cmml">8 183</mn><annotation-xml encoding="MathML-Content" id="S3.T2.14.14.2.m1.1b"><cn type="integer" id="S3.T2.14.14.2.m1.1.1.cmml" xref="S3.T2.14.14.2.m1.1.1">8183</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.14.2.m1.1c">8\,183</annotation></semantics></math></td>
<td id="S3.T2.15.15.3" class="ltx_td ltx_align_right"><math id="S3.T2.15.15.3.m1.1" class="ltx_Math" alttext="10.0" display="inline"><semantics id="S3.T2.15.15.3.m1.1a"><mn id="S3.T2.15.15.3.m1.1.1" xref="S3.T2.15.15.3.m1.1.1.cmml">10.0</mn><annotation-xml encoding="MathML-Content" id="S3.T2.15.15.3.m1.1b"><cn type="float" id="S3.T2.15.15.3.m1.1.1.cmml" xref="S3.T2.15.15.3.m1.1.1">10.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.15.15.3.m1.1c">10.0</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.18.18" class="ltx_tr">
<td id="S3.T2.18.18.4" class="ltx_td ltx_align_center ltx_border_bb">YODAS</td>
<td id="S3.T2.18.18.5" class="ltx_td ltx_align_center ltx_border_bb">test</td>
<td id="S3.T2.18.18.6" class="ltx_td ltx_align_center ltx_border_bb">Japanese</td>
<td id="S3.T2.16.16.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S3.T2.16.16.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S3.T2.16.16.1.m1.1a"><mi mathvariant="normal" id="S3.T2.16.16.1.m1.1.1" xref="S3.T2.16.16.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S3.T2.16.16.1.m1.1b"><ci id="S3.T2.16.16.1.m1.1.1.cmml" xref="S3.T2.16.16.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.16.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S3.T2.17.17.2" class="ltx_td ltx_align_right ltx_border_bb"><math id="S3.T2.17.17.2.m1.1" class="ltx_Math" alttext="8\,313" display="inline"><semantics id="S3.T2.17.17.2.m1.1a"><mn id="S3.T2.17.17.2.m1.1.1" xref="S3.T2.17.17.2.m1.1.1.cmml">8 313</mn><annotation-xml encoding="MathML-Content" id="S3.T2.17.17.2.m1.1b"><cn type="integer" id="S3.T2.17.17.2.m1.1.1.cmml" xref="S3.T2.17.17.2.m1.1.1">8313</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.17.17.2.m1.1c">8\,313</annotation></semantics></math></td>
<td id="S3.T2.18.18.3" class="ltx_td ltx_align_right ltx_border_bb"><math id="S3.T2.18.18.3.m1.1" class="ltx_Math" alttext="10.0" display="inline"><semantics id="S3.T2.18.18.3.m1.1a"><mn id="S3.T2.18.18.3.m1.1.1" xref="S3.T2.18.18.3.m1.1.1.cmml">10.0</mn><annotation-xml encoding="MathML-Content" id="S3.T2.18.18.3.m1.1b"><cn type="float" id="S3.T2.18.18.3.m1.1.1.cmml" xref="S3.T2.18.18.3.m1.1.1">10.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.18.18.3.m1.1c">10.0</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Keyword Generation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We generated keywords for the YODAS datasets using another pre-trained language model
because all the ASR datasets do not explicitly provide keywords for the transcriptions.
We extracted keywords for each video
and used them for all the pairs of audio samples and transcriptions derived from the same video
since a pair of audio and transcription is a short clip of the original video in the YODAS datasets.
Thus, not all keywords appear in their transcriptions.
We believe this is a practical usage of keywords;
a user defines keywords once for a single audio recording
and reuses the keywords for all audio clips extracted from the recording
rather than giving different keywords for every shorter clip.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">To generate the keywords, we used Japanese Stable LM Base Gamma 7B<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://huggingface.co/stabilityai/japanese-stablelm-base-gamma-7b" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/stabilityai/japanese-stablelm-base-gamma-7b</a></span></span></span> model.
Generated keywords differed depending on random seeds used for the inferences of the model.
Due to this randomness, we extracted keywords
with different random seeds multiple times
and kept keywords generated <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\nicefrac{{1}}{{3}}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mpadded voffset="0.3em" id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml"><mn mathsize="70%" id="S3.SS1.p2.1.m1.1.1.2a" xref="S3.SS1.p2.1.m1.1.1.2.cmml">1</mn></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml"><mo stretchy="true" symmetric="true" id="S3.SS1.p2.1.m1.1.1.1a" xref="S3.SS1.p2.1.m1.1.1.1.cmml">/</mo></mpadded><mn mathsize="70%" id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><divide id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></divide><cn type="integer" id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">1</cn><cn type="integer" id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\nicefrac{{1}}{{3}}</annotation></semantics></math> or more times.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Dataset Bias via Prompt</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">In our preliminary experiments,
we found performance degradation due to keyword conditioning on the dataset
because we only introduced the keywords to the YODAS dataset
rather than multiple datasets during fine-tuning.
We suspect that, as a result, the decoders can memorize the training dataset’s bias
depending on whether keywords exist or not.
Concretely, the ReazonSpeech dataset,
which is the majority of the training dataset,
tends to drop a part of the transcription text
even if it exists in the speech part as the limitation in <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a href="#bib.bib21" title="" class="ltx_ref">2023</a>)</cite>.
Thus, if we give the placeholder keyword,

“<span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">キーワード：なし</span>”,

which is identical to “<span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">Keywords: na</span>” in Japanese,
to the prompts for samples from the YODAS dataset at inference,
our fine-tuned models transcribe the audio as if a sample from ReazonSpeech;
it drops the transcription partially.
This missing transcription error increases CERs due to deletion errors
as demonstrated in <a href="#S4.SS7" title="4.7 Dataset Bias Experiments ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.7</span></a>.
This tendency was more severe with the PLaMo-100B-based system than the Swallow-7B’s counterpart in our preliminary experiments.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">To mitigate this problem, we found approaches for fine-tuning and inference, respectively.
For the fine-tuning step,
we could reduce the bias by adding the YODAS dataset without keywords to the training dataset,
not to condition the placeholder keywords on the ReazonSpeech dataset.
For the inference step, we could reduce the degradation
by using random keywords to replace the placeholder keyword.
Unfortunately, the inference approach introduces additional latency,
though it mitigates the performance degradation.
Therefore, we used the approach for fine-tuning in our final experimental configuration.
As demonstrated in experiments,
we could only overcome this issue partially, which is future work.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We verified our ASR systems fine-tuned on the constructed training dataset
by conducting numerical experiments.
As a controlled experiment to evaluate keywords-based contextualization,
we also evaluated our ASR systems with slightly modified datasets and prompts;
we did not feed keywords even if they were available and removed keyword text from prompts.
We randomly shuffled keywords during fine-tuning and inference to make the model more robust regarding keyword ordering.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Baseline Model</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We used pre-trained Whisper large-v3 downloaded from Hugging Face as the baseline system.
Whisper has a typical transformer encoder-decoder architecture.
It differs from our models in that
the encoder and the decoder are connected through cross-attention
instead of the adapter layer and input token embeddings.
We explicitly specified the Whisper’s language tag for a fair comparison with our language identifier in the prompt.
We used <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">bf16</span> for its weights to fasten inference speed.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Pre-processing and Post-processing of Texts</h3>

<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pre-processing</h5>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">We applied Whisper’s text normalizers<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://github.com/openai/whisper/tree/main/whisper/normalizers" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/openai/whisper/tree/main/whisper/normalizers</a></span></span></span>
to the transcriptions and keywords
to use consistent pre-processing with the Whisper baseline.
In addition, we removed unnecessary whitespaces between non-ASCII characters
for the Japanese datasets.
After tokenization, we truncated keyword tokens
so that the sum over lengths of prompt, keywords, and transcription
becomes less than or equal to <math id="S4.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a"><mn id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">300</annotation></semantics></math> for our ASR systems.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Post-processing</h5>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.2" class="ltx_p">We noticed that the pre-trained Whisper model transcribed
characters or symbols that the text normalizers should remove.
As a result, Whisper’s evaluation metric values were severely worse than our systems.
For a fair comparison, we applied the text normalizers to the transcriptions generated by Whisper and our systems.
This post-processing mainly boosted the performance of the Whisper model because our systems rarely generated such unintended characters and symbols.
For example, CERs on the YODAS dev set of Whisper large-v3
were <math id="S4.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="16.88" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">16.88</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><cn type="float" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1">16.88</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">16.88</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="20.78" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.2.m2.1a"><mn id="S4.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">20.78</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.m2.1b"><cn type="float" id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1">20.78</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.m2.1c">20.78</annotation></semantics></math> with and without post-processing, respectively.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Optimization</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.3" class="ltx_p">We fine-tuned our models for only one epoch due to computational constraints.
We used AdamW optimizer <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter, <a href="#bib.bib24" title="" class="ltx_ref">2019</a>)</cite>
with paged implementation by <span id="S4.SS3.p1.3.1" class="ltx_text ltx_font_typewriter">bitsandbytes<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note"><span id="footnote7.1.1.1" class="ltx_text ltx_font_serif">7</span></span><a target="_blank" href="https://github.com/TimDettmers/bitsandbytes" title="" class="ltx_ref ltx_url">https://github.com/TimDettmers/bitsandbytes</a></span></span></span></span>
and gradient checkpointing to reduce peak GPU memory
to fine-tune PLaMo-100B-based models on even one H100 GPU.
We used a linear warmup with a cosine annealing learning scheduler <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter, <a href="#bib.bib23" title="" class="ltx_ref">2017</a>)</cite>,
whose warmup was <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mn id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">1</mn><mo id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">1\%</annotation></semantics></math> iterations.
We scaled the base learning rate with square root scaling
depending on the number of samples in mini-batches <cite class="ltx_cite ltx_citemacro_citep">(Hoffer et al., <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite>:
<math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathtt{lr}=\mathtt{base\_lr}\times\sqrt{\mathtt{bs}}" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">𝚕𝚛</mi><mo id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml"><mrow id="S4.SS3.p1.2.m2.1.1.3.2" xref="S4.SS3.p1.2.m2.1.1.3.2.cmml"><mi id="S4.SS3.p1.2.m2.1.1.3.2.2" xref="S4.SS3.p1.2.m2.1.1.3.2.2.cmml">𝚋𝚊𝚜𝚎</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.3.2.1" xref="S4.SS3.p1.2.m2.1.1.3.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS3.p1.2.m2.1.1.3.2.3" xref="S4.SS3.p1.2.m2.1.1.3.2.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.3.2.1a" xref="S4.SS3.p1.2.m2.1.1.3.2.1.cmml">​</mo><mi id="S4.SS3.p1.2.m2.1.1.3.2.4" xref="S4.SS3.p1.2.m2.1.1.3.2.4.cmml">𝚕𝚛</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.2.m2.1.1.3.1" xref="S4.SS3.p1.2.m2.1.1.3.1.cmml">×</mo><msqrt id="S4.SS3.p1.2.m2.1.1.3.3" xref="S4.SS3.p1.2.m2.1.1.3.3.cmml"><mi id="S4.SS3.p1.2.m2.1.1.3.3.2" xref="S4.SS3.p1.2.m2.1.1.3.3.2.cmml">𝚋𝚜</mi></msqrt></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><eq id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"></eq><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">𝚕𝚛</ci><apply id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3"><times id="S4.SS3.p1.2.m2.1.1.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.3.1"></times><apply id="S4.SS3.p1.2.m2.1.1.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.3.2"><times id="S4.SS3.p1.2.m2.1.1.3.2.1.cmml" xref="S4.SS3.p1.2.m2.1.1.3.2.1"></times><ci id="S4.SS3.p1.2.m2.1.1.3.2.2.cmml" xref="S4.SS3.p1.2.m2.1.1.3.2.2">𝚋𝚊𝚜𝚎</ci><ci id="S4.SS3.p1.2.m2.1.1.3.2.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3.2.3">_</ci><ci id="S4.SS3.p1.2.m2.1.1.3.2.4.cmml" xref="S4.SS3.p1.2.m2.1.1.3.2.4">𝚕𝚛</ci></apply><apply id="S4.SS3.p1.2.m2.1.1.3.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3"><root id="S4.SS3.p1.2.m2.1.1.3.3a.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3"></root><ci id="S4.SS3.p1.2.m2.1.1.3.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3.2">𝚋𝚜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\mathtt{lr}=\mathtt{base\_lr}\times\sqrt{\mathtt{bs}}</annotation></semantics></math>,
where <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="\mathtt{bs}=\mathtt{mini\_batch\_size\_per\_gpu}\times\mathtt{num\_gpus}" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mrow id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi id="S4.SS3.p1.3.m3.1.1.2" xref="S4.SS3.p1.3.m3.1.1.2.cmml">𝚋𝚜</mi><mo id="S4.SS3.p1.3.m3.1.1.1" xref="S4.SS3.p1.3.m3.1.1.1.cmml">=</mo><mrow id="S4.SS3.p1.3.m3.1.1.3" xref="S4.SS3.p1.3.m3.1.1.3.cmml"><mrow id="S4.SS3.p1.3.m3.1.1.3.2" xref="S4.SS3.p1.3.m3.1.1.3.2.cmml"><mrow id="S4.SS3.p1.3.m3.1.1.3.2.2" xref="S4.SS3.p1.3.m3.1.1.3.2.2.cmml"><mi id="S4.SS3.p1.3.m3.1.1.3.2.2.2" xref="S4.SS3.p1.3.m3.1.1.3.2.2.2.cmml">𝚖𝚒𝚗𝚒</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.2.2.1" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS3.p1.3.m3.1.1.3.2.2.3" xref="S4.SS3.p1.3.m3.1.1.3.2.2.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.2.2.1a" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.1.1.3.2.2.4" xref="S4.SS3.p1.3.m3.1.1.3.2.2.4.cmml">𝚋𝚊𝚝𝚌𝚑</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.2.2.1b" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS3.p1.3.m3.1.1.3.2.2.5" xref="S4.SS3.p1.3.m3.1.1.3.2.2.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.2.2.1c" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.1.1.3.2.2.6" xref="S4.SS3.p1.3.m3.1.1.3.2.2.6.cmml">𝚜𝚒𝚣𝚎</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.2.2.1d" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS3.p1.3.m3.1.1.3.2.2.7" xref="S4.SS3.p1.3.m3.1.1.3.2.2.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.2.2.1e" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.1.1.3.2.2.8" xref="S4.SS3.p1.3.m3.1.1.3.2.2.8.cmml">𝚙𝚎𝚛</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.2.2.1f" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS3.p1.3.m3.1.1.3.2.2.9" xref="S4.SS3.p1.3.m3.1.1.3.2.2.9.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.2.2.1g" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.1.1.3.2.2.10" xref="S4.SS3.p1.3.m3.1.1.3.2.2.10.cmml">𝚐𝚙𝚞</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.3.m3.1.1.3.2.1" xref="S4.SS3.p1.3.m3.1.1.3.2.1.cmml">×</mo><mi id="S4.SS3.p1.3.m3.1.1.3.2.3" xref="S4.SS3.p1.3.m3.1.1.3.2.3.cmml">𝚗𝚞𝚖</mi></mrow><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.1" xref="S4.SS3.p1.3.m3.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS3.p1.3.m3.1.1.3.3" xref="S4.SS3.p1.3.m3.1.1.3.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.1a" xref="S4.SS3.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.1.1.3.4" xref="S4.SS3.p1.3.m3.1.1.3.4.cmml">𝚐𝚙𝚞𝚜</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><eq id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1.1"></eq><ci id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">𝚋𝚜</ci><apply id="S4.SS3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3"><times id="S4.SS3.p1.3.m3.1.1.3.1.cmml" xref="S4.SS3.p1.3.m3.1.1.3.1"></times><apply id="S4.SS3.p1.3.m3.1.1.3.2.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2"><times id="S4.SS3.p1.3.m3.1.1.3.2.1.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.1"></times><apply id="S4.SS3.p1.3.m3.1.1.3.2.2.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2"><times id="S4.SS3.p1.3.m3.1.1.3.2.2.1.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.1"></times><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.2.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.2">𝚖𝚒𝚗𝚒</ci><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.3">_</ci><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.4.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.4">𝚋𝚊𝚝𝚌𝚑</ci><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.5.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.5">_</ci><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.6.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.6">𝚜𝚒𝚣𝚎</ci><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.7.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.7">_</ci><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.8.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.8">𝚙𝚎𝚛</ci><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.9.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.9">_</ci><ci id="S4.SS3.p1.3.m3.1.1.3.2.2.10.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.2.10">𝚐𝚙𝚞</ci></apply><ci id="S4.SS3.p1.3.m3.1.1.3.2.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2.3">𝚗𝚞𝚖</ci></apply><ci id="S4.SS3.p1.3.m3.1.1.3.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3.3">_</ci><ci id="S4.SS3.p1.3.m3.1.1.3.4.cmml" xref="S4.SS3.p1.3.m3.1.1.3.4">𝚐𝚙𝚞𝚜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">\mathtt{bs}=\mathtt{mini\_batch\_size\_per\_gpu}\times\mathtt{num\_gpus}</annotation></semantics></math>.
We minimized the cross-entropy loss over transcription tokens.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">PLaMo-100B hyper-parameters</h5>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.5" class="ltx_p">In AdamW’s hyper-parameters,
we decreased <math id="S4.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\beta_{2}=0.95" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a"><mrow id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml"><msub id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.2" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.2.cmml">β</mi><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.3" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.3.cmml">2</mn></msub><mo id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1"><eq id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1"></eq><apply id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.2">𝛽</ci><cn type="integer" id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.3">2</cn></apply><cn type="float" id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">\beta_{2}=0.95</annotation></semantics></math> from the default value <math id="S4.SS3.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="0.999" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.2.m2.1a"><mn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml">0.999</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.2.m2.1b"><cn type="float" id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1">0.999</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.2.m2.1c">0.999</annotation></semantics></math>
by following <cite class="ltx_cite ltx_citemacro_citet">Wortsman et al. (<a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite>
because we observed that fine-tuning PLaMo-100B-based models
is more likely to face loss spike issue<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a href="#A2.SS1" title="B.1 Attempts to Stabilize Fine-tuning ‣ Appendix B Details of Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">B.1</span></a> shares other attempts to stabilize fine-tuning.</span></span></span>.
We used <math id="S4.SS3.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathtt{base\_lr}=3.5\times 10^{-6}" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.3.m3.1a"><mrow id="S4.SS3.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.cmml"><mrow id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.2" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.2.cmml">𝚋𝚊𝚜𝚎</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.1" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.3" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.1a" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.1.cmml">​</mo><mi id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.4" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.4.cmml">𝚕𝚛</mi></mrow><mo id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.1" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.1.cmml">=</mo><mrow id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mn id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">3.5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.1" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">×</mo><msup id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.cmml"><mn id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.2" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.2.cmml">10</mn><mrow id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3.cmml"><mo id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3a" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3.cmml">−</mo><mn id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3.2" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.cmml">6</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.3.m3.1b"><apply id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1"><eq id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.1"></eq><apply id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2"><times id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.1"></times><ci id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.2">𝚋𝚊𝚜𝚎</ci><ci id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.3">_</ci><ci id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.4.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.2.4">𝚕𝚛</ci></apply><apply id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3"><times id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.1"></times><cn type="float" id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.2">3.5</cn><apply id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3">superscript</csymbol><cn type="integer" id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.2.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.2">10</cn><apply id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3"><minus id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3"></minus><cn type="integer" id="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3.2.cmml" xref="S4.SS3.SSS0.Px1.p1.3.m3.1.1.3.3.3.2">6</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.3.m3.1c">\mathtt{base\_lr}=3.5\times 10^{-6}</annotation></semantics></math>.
We used a mini-batch size of <math id="S4.SS3.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.4.m4.1a"><mn id="S4.SS3.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.4.m4.1b"><cn type="integer" id="S4.SS3.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.4.m4.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.4.m4.1c">6</annotation></semantics></math> per GPU
for both with and without keyword settings
for pair comparison in terms of the number of gradient updates.
We accelerated the training using distributed data-parallel <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>
with <math id="S4.SS3.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="72" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.5.m5.1a"><mn id="S4.SS3.SSS0.Px1.p1.5.m5.1.1" xref="S4.SS3.SSS0.Px1.p1.5.m5.1.1.cmml">72</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.5.m5.1b"><cn type="integer" id="S4.SS3.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m5.1.1">72</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.5.m5.1c">72</annotation></semantics></math> H100 GPUs.</p>
</div>
<div id="S4.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p2.7" class="ltx_p">We used <math id="S4.SS3.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="r=12" display="inline"><semantics id="S4.SS3.SSS0.Px1.p2.1.m1.1a"><mrow id="S4.SS3.SSS0.Px1.p2.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.2" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.2.cmml">r</mi><mo id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.1" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.3" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1"><eq id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.1"></eq><ci id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.2">𝑟</ci><cn type="integer" id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.1.m1.1c">r=12</annotation></semantics></math> and <math id="S4.SS3.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="\alpha=2\times r" display="inline"><semantics id="S4.SS3.SSS0.Px1.p2.2.m2.1a"><mrow id="S4.SS3.SSS0.Px1.p2.2.m2.1.1" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.2" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.2.cmml">α</mi><mo id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.1" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.cmml"><mn id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.2" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.1" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.1.cmml">×</mo><mi id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.3" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.3.cmml">r</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.2.m2.1b"><apply id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1"><eq id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.1"></eq><ci id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.2">𝛼</ci><apply id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3"><times id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.1"></times><cn type="integer" id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.2">2</cn><ci id="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px1.p2.2.m2.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.2.m2.1c">\alpha=2\times r</annotation></semantics></math> for QLoRA without dropout <cite class="ltx_cite ltx_citemacro_citep">(Srivastava et al., <a href="#bib.bib32" title="" class="ltx_ref">2014</a>)</cite>.
As a result, the number of learnable weights
is <math id="S4.SS3.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="218\,234\,880" display="inline"><semantics id="S4.SS3.SSS0.Px1.p2.3.m3.1a"><mn id="S4.SS3.SSS0.Px1.p2.3.m3.1.1" xref="S4.SS3.SSS0.Px1.p2.3.m3.1.1.cmml">218 234 880</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.3.m3.1b"><cn type="integer" id="S4.SS3.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.3.m3.1.1">218234880</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.3.m3.1c">218\,234\,880</annotation></semantics></math> out of <math id="S4.SS3.SSS0.Px1.p2.4.m4.1" class="ltx_Math" alttext="103\,098\,001\,920" display="inline"><semantics id="S4.SS3.SSS0.Px1.p2.4.m4.1a"><mn id="S4.SS3.SSS0.Px1.p2.4.m4.1.1" xref="S4.SS3.SSS0.Px1.p2.4.m4.1.1.cmml">103 098 001 920</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.4.m4.1b"><cn type="integer" id="S4.SS3.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.4.m4.1.1">103098001920</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.4.m4.1c">103\,098\,001\,920</annotation></semantics></math> (<math id="S4.SS3.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="0.21\%" display="inline"><semantics id="S4.SS3.SSS0.Px1.p2.5.m5.1a"><mrow id="S4.SS3.SSS0.Px1.p2.5.m5.1.1" xref="S4.SS3.SSS0.Px1.p2.5.m5.1.1.cmml"><mn id="S4.SS3.SSS0.Px1.p2.5.m5.1.1.2" xref="S4.SS3.SSS0.Px1.p2.5.m5.1.1.2.cmml">0.21</mn><mo id="S4.SS3.SSS0.Px1.p2.5.m5.1.1.1" xref="S4.SS3.SSS0.Px1.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.5.m5.1b"><apply id="S4.SS3.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.5.m5.1.1"><csymbol cd="latexml" id="S4.SS3.SSS0.Px1.p2.5.m5.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p2.5.m5.1.1.2">0.21</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.5.m5.1c">0.21\%</annotation></semantics></math>).
Note that as an implementation trick of the PLaMo-100B architecture,
self-attention’s three linear matrices for query/key/values <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a href="#bib.bib35" title="" class="ltx_ref">2017</a>)</cite>
are parameterized as a single matrix,
and its transformed features are split into query, key, and value representations.
Not to modify this implementation,
we introduced LoRA to the single-matrix
rather than three query, key, and value matrices as in the native implementation.
As a result, the number of LoRA weights for a set of query, key, and value of PLaMo-100B
is <math id="S4.SS3.SSS0.Px1.p2.6.m6.1" class="ltx_Math" alttext="(3d_{k}\times r+r\times d_{\mathrm{model}})" display="inline"><semantics id="S4.SS3.SSS0.Px1.p2.6.m6.1a"><mrow id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.2" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.cmml"><mrow id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.cmml"><mrow id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.cmml"><mn id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.2" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.1" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.1.cmml">​</mo><msub id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.cmml"><mi id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.2" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.2.cmml">d</mi><mi id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.3" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.3.cmml">k</mi></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.1" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.1.cmml">×</mo><mi id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.3" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.3.cmml">r</mi></mrow><mo id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.1" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.1.cmml">+</mo><mrow id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.2" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.2.cmml">r</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.1" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.1.cmml">×</mo><msub id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.cmml"><mi id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.2" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.2.cmml">d</mi><mi id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.3" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.3.cmml">model</mi></msub></mrow></mrow><mo stretchy="false" id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.3" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.6.m6.1b"><apply id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1"><plus id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.1"></plus><apply id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2"><times id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.1"></times><apply id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2"><times id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.1.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.1"></times><cn type="integer" id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.2.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.2">3</cn><apply id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.1.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3">subscript</csymbol><ci id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.2.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.2">𝑑</ci><ci id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.3.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.2.3.3">𝑘</ci></apply></apply><ci id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.2.3">𝑟</ci></apply><apply id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3"><times id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.1"></times><ci id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.2">𝑟</ci><apply id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.1.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3">subscript</csymbol><ci id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.2.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.2">𝑑</ci><ci id="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.3.cmml" xref="S4.SS3.SSS0.Px1.p2.6.m6.1.1.1.1.3.3.3">model</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.6.m6.1c">(3d_{k}\times r+r\times d_{\mathrm{model}})</annotation></semantics></math><span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>The terms <math id="footnote9.m1.1" class="ltx_Math" alttext="d_{k}" display="inline"><semantics id="footnote9.m1.1b"><msub id="footnote9.m1.1.1" xref="footnote9.m1.1.1.cmml"><mi id="footnote9.m1.1.1.2" xref="footnote9.m1.1.1.2.cmml">d</mi><mi id="footnote9.m1.1.1.3" xref="footnote9.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="footnote9.m1.1c"><apply id="footnote9.m1.1.1.cmml" xref="footnote9.m1.1.1"><csymbol cd="ambiguous" id="footnote9.m1.1.1.1.cmml" xref="footnote9.m1.1.1">subscript</csymbol><ci id="footnote9.m1.1.1.2.cmml" xref="footnote9.m1.1.1.2">𝑑</ci><ci id="footnote9.m1.1.1.3.cmml" xref="footnote9.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote9.m1.1d">d_{k}</annotation></semantics></math> and <math id="footnote9.m2.1" class="ltx_Math" alttext="d_{\mathrm{model}}" display="inline"><semantics id="footnote9.m2.1b"><msub id="footnote9.m2.1.1" xref="footnote9.m2.1.1.cmml"><mi id="footnote9.m2.1.1.2" xref="footnote9.m2.1.1.2.cmml">d</mi><mi id="footnote9.m2.1.1.3" xref="footnote9.m2.1.1.3.cmml">model</mi></msub><annotation-xml encoding="MathML-Content" id="footnote9.m2.1c"><apply id="footnote9.m2.1.1.cmml" xref="footnote9.m2.1.1"><csymbol cd="ambiguous" id="footnote9.m2.1.1.1.cmml" xref="footnote9.m2.1.1">subscript</csymbol><ci id="footnote9.m2.1.1.2.cmml" xref="footnote9.m2.1.1.2">𝑑</ci><ci id="footnote9.m2.1.1.3.cmml" xref="footnote9.m2.1.1.3">model</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote9.m2.1d">d_{\mathrm{model}}</annotation></semantics></math> are the same as in <cite class="ltx_cite ltx_citemacro_citet">Vaswani et al. (<a href="#bib.bib35" title="" class="ltx_ref">2017</a>)</cite>.</span></span></span>
instead of <math id="S4.SS3.SSS0.Px1.p2.7.m7.1" class="ltx_Math" alttext="3(d_{k}\times r+r\times d_{\mathrm{model}})" display="inline"><semantics id="S4.SS3.SSS0.Px1.p2.7.m7.1a"><mrow id="S4.SS3.SSS0.Px1.p2.7.m7.1.1" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.cmml"><mn id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.3" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.3.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.2" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.2.cmml">​</mo><mrow id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.2" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.cmml"><mrow id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.cmml"><msub id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.cmml"><mi id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.2" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.2.cmml">d</mi><mi id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.3" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.3.cmml">k</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.1" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.1.cmml">×</mo><mi id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.3" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.3.cmml">r</mi></mrow><mo id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.1" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.1.cmml">+</mo><mrow id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.2" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.2.cmml">r</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.1" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.1.cmml">×</mo><msub id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.cmml"><mi id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.2" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.2.cmml">d</mi><mi id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.3" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.3.cmml">model</mi></msub></mrow></mrow><mo stretchy="false" id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.3" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.7.m7.1b"><apply id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1"><times id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.2"></times><cn type="integer" id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.3">3</cn><apply id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1"><plus id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.1"></plus><apply id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2"><times id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.1"></times><apply id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.1.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.2.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.2">𝑑</ci><ci id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.3.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.2.3">𝑘</ci></apply><ci id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.2.3">𝑟</ci></apply><apply id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3"><times id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.1"></times><ci id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.2">𝑟</ci><apply id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.1.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3">subscript</csymbol><ci id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.2.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.2">𝑑</ci><ci id="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.3.cmml" xref="S4.SS3.SSS0.Px1.p2.7.m7.1.1.1.1.1.3.3.3">model</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.7.m7.1c">3(d_{k}\times r+r\times d_{\mathrm{model}})</annotation></semantics></math>
for a single head attention with the same dimensionality of
independent key, query, and value representations.
For the quantization of base weights for LoRA,
we used double quantized with <span id="S4.SS3.SSS0.Px1.p2.7.1" class="ltx_text ltx_font_typewriter">nf4</span> <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al., <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>
implemented by <span id="S4.SS3.SSS0.Px1.p2.7.2" class="ltx_text ltx_font_typewriter">bitsandbytes</span>.
During forward computation, quantized weights are de-quantized with the <span id="S4.SS3.SSS0.Px1.p2.7.3" class="ltx_text ltx_font_typewriter">bf16</span> format.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Swallow-7B hyper-parameters</h5>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.4" class="ltx_p">We fine-tuned <span id="S4.SS3.SSS0.Px2.p1.4.1" class="ltx_text ltx_font_typewriter">Swallow-7b-plus-hf<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note"><span id="footnote10.1.1.1" class="ltx_text ltx_font_serif">10</span></span><a target="_blank" href="https://huggingface.co/tokyotech-llm/Swallow-7b-plus-hf" title="" class="ltx_ref ltx_url">https://huggingface.co/tokyotech-llm/Swallow-7b-plus-hf</a></span></span></span></span>
as a smaller size decoder than PLaMo-100B.
We only describe the different hyper-parameters from PLaMo-100B’s setting.
We could use the default <math id="S4.SS3.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\beta_{2}=0.999" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><msub id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.2" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.2.cmml">β</mi><mn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.3" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.3.cmml">2</mn></msub><mo id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml">0.999</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1"><eq id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1"></eq><apply id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.2">𝛽</ci><cn type="integer" id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.3">2</cn></apply><cn type="float" id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3">0.999</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.1.m1.1c">\beta_{2}=0.999</annotation></semantics></math> in AdamW’s hyper-parameters without frequent loss spikes.
We used <math id="S4.SS3.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\mathtt{base\_lr}=7.5\times 10^{-6}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.2.m2.1a"><mrow id="S4.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml"><mrow id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.2.cmml">𝚋𝚊𝚜𝚎</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.1a" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.1.cmml">​</mo><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.4" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.4.cmml">𝚕𝚛</mi></mrow><mo id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml"><mn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.2.cmml">7.5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.1.cmml">×</mo><msup id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.cmml"><mn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.2.cmml">10</mn><mrow id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3.cmml"><mo id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3a" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3.cmml">−</mo><mn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3.2.cmml">6</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1"><eq id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1"></eq><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2"><times id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.1"></times><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.2">𝚋𝚊𝚜𝚎</ci><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.3">_</ci><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.4.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.4">𝚕𝚛</ci></apply><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3"><times id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.1"></times><cn type="float" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.2">7.5</cn><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3">superscript</csymbol><cn type="integer" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.2">10</cn><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3"><minus id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3"></minus><cn type="integer" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.3.3.2">6</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.2.m2.1c">\mathtt{base\_lr}=7.5\times 10^{-6}</annotation></semantics></math>
and mini-batch size of <math id="S4.SS3.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.3.m3.1a"><mn id="S4.SS3.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.3.m3.1b"><cn type="integer" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.3.m3.1c">64</annotation></semantics></math> per GPU.
We used <math id="S4.SS3.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.4.m4.1a"><mn id="S4.SS3.SSS0.Px2.p1.4.m4.1.1" xref="S4.SS3.SSS0.Px2.p1.4.m4.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.4.m4.1b"><cn type="integer" id="S4.SS3.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.4.m4.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.4.m4.1c">8</annotation></semantics></math> GPUs for distributed data-parallel
to perform a similar number of gradient updates to PLaMo-100B’s fine-tuning.</p>
</div>
<div id="S4.SS3.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p2.5" class="ltx_p">We independently introduced LoRA weights to query, key, and value matrices
because of the implementation difference from PLaMo-100B.
We used <math id="S4.SS3.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="r=16" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.1.m1.1a"><mrow id="S4.SS3.SSS0.Px2.p2.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2.cmml">r</mi><mo id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1"><eq id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1"></eq><ci id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2">𝑟</ci><cn type="integer" id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.1.m1.1c">r=16</annotation></semantics></math> and <math id="S4.SS3.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="\alpha=2\times r" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.2.m2.1a"><mrow id="S4.SS3.SSS0.Px2.p2.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.cmml">α</mi><mo id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.cmml"><mn id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.2" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">×</mo><mi id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.3" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.3.cmml">r</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1"><eq id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1"></eq><ci id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2">𝛼</ci><apply id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3"><times id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.1"></times><cn type="integer" id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.2">2</cn><ci id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.2.m2.1c">\alpha=2\times r</annotation></semantics></math> for QLoRA without dropout.
As a result, the number of learnable weights
is <math id="S4.SS3.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="72\,749\,056" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.3.m3.1a"><mn id="S4.SS3.SSS0.Px2.p2.3.m3.1.1" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.cmml">72 749 056</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.3.m3.1b"><cn type="integer" id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1">72749056</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.3.m3.1c">72\,749\,056</annotation></semantics></math> out of <math id="S4.SS3.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="7\,539\,687\,424" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.4.m4.1a"><mn id="S4.SS3.SSS0.Px2.p2.4.m4.1.1" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1.cmml">7 539 687 424</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.4.m4.1b"><cn type="integer" id="S4.SS3.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1">7539687424</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.4.m4.1c">7\,539\,687\,424</annotation></semantics></math> (<math id="S4.SS3.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="0.96\%" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.5.m5.1a"><mrow id="S4.SS3.SSS0.Px2.p2.5.m5.1.1" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.cmml"><mn id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.2" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.2.cmml">0.96</mn><mo id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.1" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.5.m5.1b"><apply id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1"><csymbol cd="latexml" id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.2">0.96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.5.m5.1c">0.96\%</annotation></semantics></math>).</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Transcription Generation</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.2" class="ltx_p">We transcribed audio with prompts
using the greedy search for all baseline/fine-tuned models and datasets.
For YODAS dev/test sets,
we also transcribed audio without keywords
to show the difference at inference depending on the existence of keywords.
In our preliminary attempts,
we allowed all models to generate <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="444" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mn id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">444</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><cn type="integer" id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">444</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">444</annotation></semantics></math> tokens for transcriptions,
which is the maximum number of tokens of Whisper large-v3 when specifying the language.
However, we observed that this value caused too many insertion errors
due to meaningless repetitions in several transcriptions,
unnecessarily worsening evaluation metrics.
To mitigate these undesirable insertions,
we computed the max token lengths of dev sets for each dataset and tokenizer,
as shown in <a href="#A2.T7" title="In Appendix B Details of Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">7</span></a> of <a href="#A2" title="Appendix B Details of Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">B</span></a>,
and used <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="1.25" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mn id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">1.25</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><cn type="float" id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">1.25</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">1.25</annotation></semantics></math> times those lengths as the max token lengths for transcription generation
for both dev and test sets.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Evaluation Metrics</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">As ASR performance metrics,
we will report character error rates (CERs) for the Japanese datasets: CommonVoice and YODAS,
and word error rates (WERs) for the English dataset: LibriSpeech.
We will also report keyword error rates (KWERs) for the YODAS dev/test sets,
where we selected keywords with a frequency of occurrence of <math id="S4.SS5.p1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS5.p1.1.m1.1a"><mn id="S4.SS5.p1.1.m1.1.1" xref="S4.SS5.p1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.1.m1.1b"><cn type="integer" id="S4.SS5.p1.1.m1.1.1.cmml" xref="S4.SS5.p1.1.m1.1.1">0</cn></annotation-xml></semantics></math> in train sets for evaluation
from those generated for dev/test sets.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Results</h3>

<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>
Evaluation metrics comparison.
Reported metric values are Character Error Rates (CERs)
except for the LibriSpeech dataset, whose metric is Word Error Rates (WERs).
“KW” stands for keywords in the header.
In the second and third columns,
check marks <math id="S4.T3.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.2.m1.1b"><mi mathvariant="normal" id="S4.T3.2.m1.1.1" xref="S4.T3.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.2.m1.1c"><ci id="S4.T3.2.m1.1.1.cmml" xref="S4.T3.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.m1.1d">\checkmark</annotation></semantics></math> represent the existence of keywords
at the training and inference steps, respectively.
</figcaption>
<table id="S4.T3.52" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.52.51.1" class="ltx_tr">
<th id="S4.T3.52.51.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.52.51.1.1.1" class="ltx_text" style="font-size:80%;">Model</span></th>
<th id="S4.T3.52.51.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.52.51.1.2.1" class="ltx_text" style="font-size:80%;">KW@Train</span></th>
<th id="S4.T3.52.51.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.52.51.1.3.1" class="ltx_text" style="font-size:80%;">KW@Inference</span></th>
<th id="S4.T3.52.51.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S4.T3.52.51.1.4.1" class="ltx_text" style="font-size:80%;">CommonVoice v8.0</span></th>
<th id="S4.T3.52.51.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S4.T3.52.51.1.5.1" class="ltx_text" style="font-size:80%;">CommonVoice v16.1</span></th>
<th id="S4.T3.52.51.1.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S4.T3.52.51.1.6.1" class="ltx_text" style="font-size:80%;">LibriSpeech</span></th>
<th id="S4.T3.52.51.1.7" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S4.T3.52.51.1.7.1" class="ltx_text" style="font-size:80%;">YODAS</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.52.52.1" class="ltx_tr">
<td id="S4.T3.52.52.1.1" class="ltx_td"></td>
<th id="S4.T3.52.52.1.2" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T3.52.52.1.3" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T3.52.52.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.52.52.1.4.1" class="ltx_text" style="font-size:80%;">Dev</span></th>
<th id="S4.T3.52.52.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.52.52.1.5.1" class="ltx_text" style="font-size:80%;">Test</span></th>
<th id="S4.T3.52.52.1.6" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.52.52.1.6.1" class="ltx_text" style="font-size:80%;">Dev</span></th>
<th id="S4.T3.52.52.1.7" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.52.52.1.7.1" class="ltx_text" style="font-size:80%;">Test</span></th>
<th id="S4.T3.52.52.1.8" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.52.52.1.8.1" class="ltx_text" style="font-size:80%;">Dev</span></th>
<th id="S4.T3.52.52.1.9" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.52.52.1.9.1" class="ltx_text" style="font-size:80%;">Test</span></th>
<th id="S4.T3.52.52.1.10" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.52.52.1.10.1" class="ltx_text" style="font-size:80%;">Dev</span></th>
<th id="S4.T3.52.52.1.11" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.52.52.1.11.1" class="ltx_text" style="font-size:80%;">Test</span></th>
</tr>
<tr id="S4.T3.10.8" class="ltx_tr">
<td id="S4.T3.10.8.9" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T3.10.8.9.1" class="ltx_text" style="font-size:80%;">PLaMo</span></td>
<td id="S4.T3.10.8.10" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.10.8.11" class="ltx_td ltx_border_t"></td>
<td id="S4.T3.3.1.1" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T3.3.1.1.m1.1" class="ltx_Math" alttext="4.37" display="inline"><semantics id="S4.T3.3.1.1.m1.1a"><mn mathsize="80%" id="S4.T3.3.1.1.m1.1.1" xref="S4.T3.3.1.1.m1.1.1.cmml">4.37</mn><annotation-xml encoding="MathML-Content" id="S4.T3.3.1.1.m1.1b"><cn type="float" id="S4.T3.3.1.1.m1.1.1.cmml" xref="S4.T3.3.1.1.m1.1.1">4.37</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.1.1.m1.1c">4.37</annotation></semantics></math></td>
<td id="S4.T3.4.2.2" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T3.4.2.2.m1.1" class="ltx_Math" alttext="5.83" display="inline"><semantics id="S4.T3.4.2.2.m1.1a"><mn mathsize="80%" id="S4.T3.4.2.2.m1.1.1" xref="S4.T3.4.2.2.m1.1.1.cmml">5.83</mn><annotation-xml encoding="MathML-Content" id="S4.T3.4.2.2.m1.1b"><cn type="float" id="S4.T3.4.2.2.m1.1.1.cmml" xref="S4.T3.4.2.2.m1.1.1">5.83</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.2.2.m1.1c">5.83</annotation></semantics></math></td>
<td id="S4.T3.5.3.3" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T3.5.3.3.m1.1" class="ltx_Math" alttext="\mathbf{9.57}" display="inline"><semantics id="S4.T3.5.3.3.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="80%" mathvariant="bold" id="S4.T3.5.3.3.m1.1.1" xref="S4.T3.5.3.3.m1.1.1.cmml">9.57</mn><annotation-xml encoding="MathML-Content" id="S4.T3.5.3.3.m1.1b"><cn type="float" id="S4.T3.5.3.3.m1.1.1.cmml" xref="S4.T3.5.3.3.m1.1.1">9.57</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.3.3.m1.1c">\mathbf{9.57}</annotation></semantics></math></td>
<td id="S4.T3.6.4.4" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T3.6.4.4.m1.1" class="ltx_Math" alttext="\mathbf{13.30}" display="inline"><semantics id="S4.T3.6.4.4.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="80%" mathvariant="bold" id="S4.T3.6.4.4.m1.1.1" xref="S4.T3.6.4.4.m1.1.1.cmml">13.30</mn><annotation-xml encoding="MathML-Content" id="S4.T3.6.4.4.m1.1b"><cn type="float" id="S4.T3.6.4.4.m1.1.1.cmml" xref="S4.T3.6.4.4.m1.1.1">13.30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.4.4.m1.1c">\mathbf{13.30}</annotation></semantics></math></td>
<td id="S4.T3.7.5.5" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T3.7.5.5.m1.1" class="ltx_Math" alttext="3.47" display="inline"><semantics id="S4.T3.7.5.5.m1.1a"><mn mathsize="80%" id="S4.T3.7.5.5.m1.1.1" xref="S4.T3.7.5.5.m1.1.1.cmml">3.47</mn><annotation-xml encoding="MathML-Content" id="S4.T3.7.5.5.m1.1b"><cn type="float" id="S4.T3.7.5.5.m1.1.1.cmml" xref="S4.T3.7.5.5.m1.1.1">3.47</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.5.5.m1.1c">3.47</annotation></semantics></math></td>
<td id="S4.T3.8.6.6" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T3.8.6.6.m1.1" class="ltx_Math" alttext="3.63" display="inline"><semantics id="S4.T3.8.6.6.m1.1a"><mn mathsize="80%" id="S4.T3.8.6.6.m1.1.1" xref="S4.T3.8.6.6.m1.1.1.cmml">3.63</mn><annotation-xml encoding="MathML-Content" id="S4.T3.8.6.6.m1.1b"><cn type="float" id="S4.T3.8.6.6.m1.1.1.cmml" xref="S4.T3.8.6.6.m1.1.1">3.63</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.6.6.m1.1c">3.63</annotation></semantics></math></td>
<td id="S4.T3.9.7.7" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T3.9.7.7.m1.1" class="ltx_Math" alttext="12.45" display="inline"><semantics id="S4.T3.9.7.7.m1.1a"><mn mathsize="80%" id="S4.T3.9.7.7.m1.1.1" xref="S4.T3.9.7.7.m1.1.1.cmml">12.45</mn><annotation-xml encoding="MathML-Content" id="S4.T3.9.7.7.m1.1b"><cn type="float" id="S4.T3.9.7.7.m1.1.1.cmml" xref="S4.T3.9.7.7.m1.1.1">12.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.7.7.m1.1c">12.45</annotation></semantics></math></td>
<td id="S4.T3.10.8.8" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T3.10.8.8.m1.1" class="ltx_Math" alttext="10.67" display="inline"><semantics id="S4.T3.10.8.8.m1.1a"><mn mathsize="80%" id="S4.T3.10.8.8.m1.1.1" xref="S4.T3.10.8.8.m1.1.1.cmml">10.67</mn><annotation-xml encoding="MathML-Content" id="S4.T3.10.8.8.m1.1b"><cn type="float" id="S4.T3.10.8.8.m1.1.1.cmml" xref="S4.T3.10.8.8.m1.1.1">10.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.8.8.m1.1c">10.67</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.19.17" class="ltx_tr">
<td id="S4.T3.19.17.10" class="ltx_td ltx_align_left"><span id="S4.T3.19.17.10.1" class="ltx_text" style="font-size:80%;">PLaMo</span></td>
<td id="S4.T3.11.9.1" class="ltx_td ltx_align_left"><math id="S4.T3.11.9.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.11.9.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.11.9.1.m1.1.1" xref="S4.T3.11.9.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.11.9.1.m1.1b"><ci id="S4.T3.11.9.1.m1.1.1.cmml" xref="S4.T3.11.9.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.9.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T3.19.17.11" class="ltx_td"></td>
<td id="S4.T3.12.10.2" class="ltx_td ltx_align_right"><math id="S4.T3.12.10.2.m1.1" class="ltx_Math" alttext="\mathbf{4.24}" display="inline"><semantics id="S4.T3.12.10.2.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="80%" mathvariant="bold" id="S4.T3.12.10.2.m1.1.1" xref="S4.T3.12.10.2.m1.1.1.cmml">4.24</mn><annotation-xml encoding="MathML-Content" id="S4.T3.12.10.2.m1.1b"><cn type="float" id="S4.T3.12.10.2.m1.1.1.cmml" xref="S4.T3.12.10.2.m1.1.1">4.24</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.10.2.m1.1c">\mathbf{4.24}</annotation></semantics></math></td>
<td id="S4.T3.13.11.3" class="ltx_td ltx_align_right"><math id="S4.T3.13.11.3.m1.1" class="ltx_Math" alttext="\mathbf{5.63}" display="inline"><semantics id="S4.T3.13.11.3.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="80%" mathvariant="bold" id="S4.T3.13.11.3.m1.1.1" xref="S4.T3.13.11.3.m1.1.1.cmml">5.63</mn><annotation-xml encoding="MathML-Content" id="S4.T3.13.11.3.m1.1b"><cn type="float" id="S4.T3.13.11.3.m1.1.1.cmml" xref="S4.T3.13.11.3.m1.1.1">5.63</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.11.3.m1.1c">\mathbf{5.63}</annotation></semantics></math></td>
<td id="S4.T3.14.12.4" class="ltx_td ltx_align_right"><math id="S4.T3.14.12.4.m1.1" class="ltx_Math" alttext="9.70" display="inline"><semantics id="S4.T3.14.12.4.m1.1a"><mn mathsize="80%" id="S4.T3.14.12.4.m1.1.1" xref="S4.T3.14.12.4.m1.1.1.cmml">9.70</mn><annotation-xml encoding="MathML-Content" id="S4.T3.14.12.4.m1.1b"><cn type="float" id="S4.T3.14.12.4.m1.1.1.cmml" xref="S4.T3.14.12.4.m1.1.1">9.70</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.12.4.m1.1c">9.70</annotation></semantics></math></td>
<td id="S4.T3.15.13.5" class="ltx_td ltx_align_right"><math id="S4.T3.15.13.5.m1.1" class="ltx_Math" alttext="13.67" display="inline"><semantics id="S4.T3.15.13.5.m1.1a"><mn mathsize="80%" id="S4.T3.15.13.5.m1.1.1" xref="S4.T3.15.13.5.m1.1.1.cmml">13.67</mn><annotation-xml encoding="MathML-Content" id="S4.T3.15.13.5.m1.1b"><cn type="float" id="S4.T3.15.13.5.m1.1.1.cmml" xref="S4.T3.15.13.5.m1.1.1">13.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.13.5.m1.1c">13.67</annotation></semantics></math></td>
<td id="S4.T3.16.14.6" class="ltx_td ltx_align_right"><math id="S4.T3.16.14.6.m1.1" class="ltx_Math" alttext="4.16" display="inline"><semantics id="S4.T3.16.14.6.m1.1a"><mn mathsize="80%" id="S4.T3.16.14.6.m1.1.1" xref="S4.T3.16.14.6.m1.1.1.cmml">4.16</mn><annotation-xml encoding="MathML-Content" id="S4.T3.16.14.6.m1.1b"><cn type="float" id="S4.T3.16.14.6.m1.1.1.cmml" xref="S4.T3.16.14.6.m1.1.1">4.16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.14.6.m1.1c">4.16</annotation></semantics></math></td>
<td id="S4.T3.17.15.7" class="ltx_td ltx_align_right"><math id="S4.T3.17.15.7.m1.1" class="ltx_Math" alttext="4.38" display="inline"><semantics id="S4.T3.17.15.7.m1.1a"><mn mathsize="80%" id="S4.T3.17.15.7.m1.1.1" xref="S4.T3.17.15.7.m1.1.1.cmml">4.38</mn><annotation-xml encoding="MathML-Content" id="S4.T3.17.15.7.m1.1b"><cn type="float" id="S4.T3.17.15.7.m1.1.1.cmml" xref="S4.T3.17.15.7.m1.1.1">4.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.15.7.m1.1c">4.38</annotation></semantics></math></td>
<td id="S4.T3.18.16.8" class="ltx_td ltx_align_right"><math id="S4.T3.18.16.8.m1.1" class="ltx_Math" alttext="12.93" display="inline"><semantics id="S4.T3.18.16.8.m1.1a"><mn mathsize="80%" id="S4.T3.18.16.8.m1.1.1" xref="S4.T3.18.16.8.m1.1.1.cmml">12.93</mn><annotation-xml encoding="MathML-Content" id="S4.T3.18.16.8.m1.1b"><cn type="float" id="S4.T3.18.16.8.m1.1.1.cmml" xref="S4.T3.18.16.8.m1.1.1">12.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.16.8.m1.1c">12.93</annotation></semantics></math></td>
<td id="S4.T3.19.17.9" class="ltx_td ltx_align_right"><math id="S4.T3.19.17.9.m1.1" class="ltx_Math" alttext="11.29" display="inline"><semantics id="S4.T3.19.17.9.m1.1a"><mn mathsize="80%" id="S4.T3.19.17.9.m1.1.1" xref="S4.T3.19.17.9.m1.1.1.cmml">11.29</mn><annotation-xml encoding="MathML-Content" id="S4.T3.19.17.9.m1.1b"><cn type="float" id="S4.T3.19.17.9.m1.1.1.cmml" xref="S4.T3.19.17.9.m1.1.1">11.29</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.17.9.m1.1c">11.29</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.23.21" class="ltx_tr">
<td id="S4.T3.23.21.5" class="ltx_td ltx_align_left"><span id="S4.T3.23.21.5.1" class="ltx_text" style="font-size:80%;">PLaMo</span></td>
<td id="S4.T3.20.18.1" class="ltx_td ltx_align_left"><math id="S4.T3.20.18.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.20.18.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.20.18.1.m1.1.1" xref="S4.T3.20.18.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.20.18.1.m1.1b"><ci id="S4.T3.20.18.1.m1.1.1.cmml" xref="S4.T3.20.18.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.20.18.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T3.21.19.2" class="ltx_td ltx_align_left"><math id="S4.T3.21.19.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.21.19.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.21.19.2.m1.1.1" xref="S4.T3.21.19.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.21.19.2.m1.1b"><ci id="S4.T3.21.19.2.m1.1.1.cmml" xref="S4.T3.21.19.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.21.19.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T3.23.21.6" class="ltx_td"></td>
<td id="S4.T3.23.21.7" class="ltx_td"></td>
<td id="S4.T3.23.21.8" class="ltx_td"></td>
<td id="S4.T3.23.21.9" class="ltx_td"></td>
<td id="S4.T3.23.21.10" class="ltx_td"></td>
<td id="S4.T3.23.21.11" class="ltx_td"></td>
<td id="S4.T3.22.20.3" class="ltx_td ltx_align_right"><math id="S4.T3.22.20.3.m1.1" class="ltx_Math" alttext="11.47" display="inline"><semantics id="S4.T3.22.20.3.m1.1a"><mn mathsize="80%" id="S4.T3.22.20.3.m1.1.1" xref="S4.T3.22.20.3.m1.1.1.cmml">11.47</mn><annotation-xml encoding="MathML-Content" id="S4.T3.22.20.3.m1.1b"><cn type="float" id="S4.T3.22.20.3.m1.1.1.cmml" xref="S4.T3.22.20.3.m1.1.1">11.47</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.22.20.3.m1.1c">11.47</annotation></semantics></math></td>
<td id="S4.T3.23.21.4" class="ltx_td ltx_align_right"><math id="S4.T3.23.21.4.m1.1" class="ltx_Math" alttext="\mathbf{9.48}" display="inline"><semantics id="S4.T3.23.21.4.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="80%" mathvariant="bold" id="S4.T3.23.21.4.m1.1.1" xref="S4.T3.23.21.4.m1.1.1.cmml">9.48</mn><annotation-xml encoding="MathML-Content" id="S4.T3.23.21.4.m1.1b"><cn type="float" id="S4.T3.23.21.4.m1.1.1.cmml" xref="S4.T3.23.21.4.m1.1.1">9.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.23.21.4.m1.1c">\mathbf{9.48}</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.31.29" class="ltx_tr">
<td id="S4.T3.31.29.9" class="ltx_td ltx_align_left"><span id="S4.T3.31.29.9.1" class="ltx_text" style="font-size:80%;">Swallow</span></td>
<td id="S4.T3.31.29.10" class="ltx_td"></td>
<td id="S4.T3.31.29.11" class="ltx_td"></td>
<td id="S4.T3.24.22.1" class="ltx_td ltx_align_right"><math id="S4.T3.24.22.1.m1.1" class="ltx_Math" alttext="4.99" display="inline"><semantics id="S4.T3.24.22.1.m1.1a"><mn mathsize="80%" id="S4.T3.24.22.1.m1.1.1" xref="S4.T3.24.22.1.m1.1.1.cmml">4.99</mn><annotation-xml encoding="MathML-Content" id="S4.T3.24.22.1.m1.1b"><cn type="float" id="S4.T3.24.22.1.m1.1.1.cmml" xref="S4.T3.24.22.1.m1.1.1">4.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.24.22.1.m1.1c">4.99</annotation></semantics></math></td>
<td id="S4.T3.25.23.2" class="ltx_td ltx_align_right"><math id="S4.T3.25.23.2.m1.1" class="ltx_Math" alttext="6.77" display="inline"><semantics id="S4.T3.25.23.2.m1.1a"><mn mathsize="80%" id="S4.T3.25.23.2.m1.1.1" xref="S4.T3.25.23.2.m1.1.1.cmml">6.77</mn><annotation-xml encoding="MathML-Content" id="S4.T3.25.23.2.m1.1b"><cn type="float" id="S4.T3.25.23.2.m1.1.1.cmml" xref="S4.T3.25.23.2.m1.1.1">6.77</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.25.23.2.m1.1c">6.77</annotation></semantics></math></td>
<td id="S4.T3.26.24.3" class="ltx_td ltx_align_right"><math id="S4.T3.26.24.3.m1.1" class="ltx_Math" alttext="10.22" display="inline"><semantics id="S4.T3.26.24.3.m1.1a"><mn mathsize="80%" id="S4.T3.26.24.3.m1.1.1" xref="S4.T3.26.24.3.m1.1.1.cmml">10.22</mn><annotation-xml encoding="MathML-Content" id="S4.T3.26.24.3.m1.1b"><cn type="float" id="S4.T3.26.24.3.m1.1.1.cmml" xref="S4.T3.26.24.3.m1.1.1">10.22</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.26.24.3.m1.1c">10.22</annotation></semantics></math></td>
<td id="S4.T3.27.25.4" class="ltx_td ltx_align_right"><math id="S4.T3.27.25.4.m1.1" class="ltx_Math" alttext="13.98" display="inline"><semantics id="S4.T3.27.25.4.m1.1a"><mn mathsize="80%" id="S4.T3.27.25.4.m1.1.1" xref="S4.T3.27.25.4.m1.1.1.cmml">13.98</mn><annotation-xml encoding="MathML-Content" id="S4.T3.27.25.4.m1.1b"><cn type="float" id="S4.T3.27.25.4.m1.1.1.cmml" xref="S4.T3.27.25.4.m1.1.1">13.98</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.27.25.4.m1.1c">13.98</annotation></semantics></math></td>
<td id="S4.T3.28.26.5" class="ltx_td ltx_align_right"><math id="S4.T3.28.26.5.m1.1" class="ltx_Math" alttext="4.22" display="inline"><semantics id="S4.T3.28.26.5.m1.1a"><mn mathsize="80%" id="S4.T3.28.26.5.m1.1.1" xref="S4.T3.28.26.5.m1.1.1.cmml">4.22</mn><annotation-xml encoding="MathML-Content" id="S4.T3.28.26.5.m1.1b"><cn type="float" id="S4.T3.28.26.5.m1.1.1.cmml" xref="S4.T3.28.26.5.m1.1.1">4.22</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.28.26.5.m1.1c">4.22</annotation></semantics></math></td>
<td id="S4.T3.29.27.6" class="ltx_td ltx_align_right"><math id="S4.T3.29.27.6.m1.1" class="ltx_Math" alttext="4.04" display="inline"><semantics id="S4.T3.29.27.6.m1.1a"><mn mathsize="80%" id="S4.T3.29.27.6.m1.1.1" xref="S4.T3.29.27.6.m1.1.1.cmml">4.04</mn><annotation-xml encoding="MathML-Content" id="S4.T3.29.27.6.m1.1b"><cn type="float" id="S4.T3.29.27.6.m1.1.1.cmml" xref="S4.T3.29.27.6.m1.1.1">4.04</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.29.27.6.m1.1c">4.04</annotation></semantics></math></td>
<td id="S4.T3.30.28.7" class="ltx_td ltx_align_right"><math id="S4.T3.30.28.7.m1.1" class="ltx_Math" alttext="12.72" display="inline"><semantics id="S4.T3.30.28.7.m1.1a"><mn mathsize="80%" id="S4.T3.30.28.7.m1.1.1" xref="S4.T3.30.28.7.m1.1.1.cmml">12.72</mn><annotation-xml encoding="MathML-Content" id="S4.T3.30.28.7.m1.1b"><cn type="float" id="S4.T3.30.28.7.m1.1.1.cmml" xref="S4.T3.30.28.7.m1.1.1">12.72</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.30.28.7.m1.1c">12.72</annotation></semantics></math></td>
<td id="S4.T3.31.29.8" class="ltx_td ltx_align_right"><math id="S4.T3.31.29.8.m1.1" class="ltx_Math" alttext="11.18" display="inline"><semantics id="S4.T3.31.29.8.m1.1a"><mn mathsize="80%" id="S4.T3.31.29.8.m1.1.1" xref="S4.T3.31.29.8.m1.1.1.cmml">11.18</mn><annotation-xml encoding="MathML-Content" id="S4.T3.31.29.8.m1.1b"><cn type="float" id="S4.T3.31.29.8.m1.1.1.cmml" xref="S4.T3.31.29.8.m1.1.1">11.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.31.29.8.m1.1c">11.18</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.40.38" class="ltx_tr">
<td id="S4.T3.40.38.10" class="ltx_td ltx_align_left"><span id="S4.T3.40.38.10.1" class="ltx_text" style="font-size:80%;">Swallow</span></td>
<td id="S4.T3.32.30.1" class="ltx_td ltx_align_left"><math id="S4.T3.32.30.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.32.30.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.32.30.1.m1.1.1" xref="S4.T3.32.30.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.32.30.1.m1.1b"><ci id="S4.T3.32.30.1.m1.1.1.cmml" xref="S4.T3.32.30.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.32.30.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T3.40.38.11" class="ltx_td"></td>
<td id="S4.T3.33.31.2" class="ltx_td ltx_align_right"><math id="S4.T3.33.31.2.m1.1" class="ltx_Math" alttext="5.05" display="inline"><semantics id="S4.T3.33.31.2.m1.1a"><mn mathsize="80%" id="S4.T3.33.31.2.m1.1.1" xref="S4.T3.33.31.2.m1.1.1.cmml">5.05</mn><annotation-xml encoding="MathML-Content" id="S4.T3.33.31.2.m1.1b"><cn type="float" id="S4.T3.33.31.2.m1.1.1.cmml" xref="S4.T3.33.31.2.m1.1.1">5.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.33.31.2.m1.1c">5.05</annotation></semantics></math></td>
<td id="S4.T3.34.32.3" class="ltx_td ltx_align_right"><math id="S4.T3.34.32.3.m1.1" class="ltx_Math" alttext="7.24" display="inline"><semantics id="S4.T3.34.32.3.m1.1a"><mn mathsize="80%" id="S4.T3.34.32.3.m1.1.1" xref="S4.T3.34.32.3.m1.1.1.cmml">7.24</mn><annotation-xml encoding="MathML-Content" id="S4.T3.34.32.3.m1.1b"><cn type="float" id="S4.T3.34.32.3.m1.1.1.cmml" xref="S4.T3.34.32.3.m1.1.1">7.24</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.34.32.3.m1.1c">7.24</annotation></semantics></math></td>
<td id="S4.T3.35.33.4" class="ltx_td ltx_align_right"><math id="S4.T3.35.33.4.m1.1" class="ltx_Math" alttext="10.32" display="inline"><semantics id="S4.T3.35.33.4.m1.1a"><mn mathsize="80%" id="S4.T3.35.33.4.m1.1.1" xref="S4.T3.35.33.4.m1.1.1.cmml">10.32</mn><annotation-xml encoding="MathML-Content" id="S4.T3.35.33.4.m1.1b"><cn type="float" id="S4.T3.35.33.4.m1.1.1.cmml" xref="S4.T3.35.33.4.m1.1.1">10.32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.35.33.4.m1.1c">10.32</annotation></semantics></math></td>
<td id="S4.T3.36.34.5" class="ltx_td ltx_align_right"><math id="S4.T3.36.34.5.m1.1" class="ltx_Math" alttext="13.85" display="inline"><semantics id="S4.T3.36.34.5.m1.1a"><mn mathsize="80%" id="S4.T3.36.34.5.m1.1.1" xref="S4.T3.36.34.5.m1.1.1.cmml">13.85</mn><annotation-xml encoding="MathML-Content" id="S4.T3.36.34.5.m1.1b"><cn type="float" id="S4.T3.36.34.5.m1.1.1.cmml" xref="S4.T3.36.34.5.m1.1.1">13.85</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.36.34.5.m1.1c">13.85</annotation></semantics></math></td>
<td id="S4.T3.37.35.6" class="ltx_td ltx_align_right"><math id="S4.T3.37.35.6.m1.1" class="ltx_Math" alttext="4.39" display="inline"><semantics id="S4.T3.37.35.6.m1.1a"><mn mathsize="80%" id="S4.T3.37.35.6.m1.1.1" xref="S4.T3.37.35.6.m1.1.1.cmml">4.39</mn><annotation-xml encoding="MathML-Content" id="S4.T3.37.35.6.m1.1b"><cn type="float" id="S4.T3.37.35.6.m1.1.1.cmml" xref="S4.T3.37.35.6.m1.1.1">4.39</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.37.35.6.m1.1c">4.39</annotation></semantics></math></td>
<td id="S4.T3.38.36.7" class="ltx_td ltx_align_right"><math id="S4.T3.38.36.7.m1.1" class="ltx_Math" alttext="4.41" display="inline"><semantics id="S4.T3.38.36.7.m1.1a"><mn mathsize="80%" id="S4.T3.38.36.7.m1.1.1" xref="S4.T3.38.36.7.m1.1.1.cmml">4.41</mn><annotation-xml encoding="MathML-Content" id="S4.T3.38.36.7.m1.1b"><cn type="float" id="S4.T3.38.36.7.m1.1.1.cmml" xref="S4.T3.38.36.7.m1.1.1">4.41</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.38.36.7.m1.1c">4.41</annotation></semantics></math></td>
<td id="S4.T3.39.37.8" class="ltx_td ltx_align_right"><math id="S4.T3.39.37.8.m1.1" class="ltx_Math" alttext="13.05" display="inline"><semantics id="S4.T3.39.37.8.m1.1a"><mn mathsize="80%" id="S4.T3.39.37.8.m1.1.1" xref="S4.T3.39.37.8.m1.1.1.cmml">13.05</mn><annotation-xml encoding="MathML-Content" id="S4.T3.39.37.8.m1.1b"><cn type="float" id="S4.T3.39.37.8.m1.1.1.cmml" xref="S4.T3.39.37.8.m1.1.1">13.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.39.37.8.m1.1c">13.05</annotation></semantics></math></td>
<td id="S4.T3.40.38.9" class="ltx_td ltx_align_right"><math id="S4.T3.40.38.9.m1.1" class="ltx_Math" alttext="11.06" display="inline"><semantics id="S4.T3.40.38.9.m1.1a"><mn mathsize="80%" id="S4.T3.40.38.9.m1.1.1" xref="S4.T3.40.38.9.m1.1.1.cmml">11.06</mn><annotation-xml encoding="MathML-Content" id="S4.T3.40.38.9.m1.1b"><cn type="float" id="S4.T3.40.38.9.m1.1.1.cmml" xref="S4.T3.40.38.9.m1.1.1">11.06</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.40.38.9.m1.1c">11.06</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.44.42" class="ltx_tr">
<td id="S4.T3.44.42.5" class="ltx_td ltx_align_left"><span id="S4.T3.44.42.5.1" class="ltx_text" style="font-size:80%;">Swallow</span></td>
<td id="S4.T3.41.39.1" class="ltx_td ltx_align_left"><math id="S4.T3.41.39.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.41.39.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.41.39.1.m1.1.1" xref="S4.T3.41.39.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.41.39.1.m1.1b"><ci id="S4.T3.41.39.1.m1.1.1.cmml" xref="S4.T3.41.39.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.41.39.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T3.42.40.2" class="ltx_td ltx_align_left"><math id="S4.T3.42.40.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.42.40.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T3.42.40.2.m1.1.1" xref="S4.T3.42.40.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.42.40.2.m1.1b"><ci id="S4.T3.42.40.2.m1.1.1.cmml" xref="S4.T3.42.40.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.42.40.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T3.44.42.6" class="ltx_td"></td>
<td id="S4.T3.44.42.7" class="ltx_td"></td>
<td id="S4.T3.44.42.8" class="ltx_td"></td>
<td id="S4.T3.44.42.9" class="ltx_td"></td>
<td id="S4.T3.44.42.10" class="ltx_td"></td>
<td id="S4.T3.44.42.11" class="ltx_td"></td>
<td id="S4.T3.43.41.3" class="ltx_td ltx_align_right"><math id="S4.T3.43.41.3.m1.1" class="ltx_Math" alttext="\mathbf{11.37}" display="inline"><semantics id="S4.T3.43.41.3.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="80%" mathvariant="bold" id="S4.T3.43.41.3.m1.1.1" xref="S4.T3.43.41.3.m1.1.1.cmml">11.37</mn><annotation-xml encoding="MathML-Content" id="S4.T3.43.41.3.m1.1b"><cn type="float" id="S4.T3.43.41.3.m1.1.1.cmml" xref="S4.T3.43.41.3.m1.1.1">11.37</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.43.41.3.m1.1c">\mathbf{11.37}</annotation></semantics></math></td>
<td id="S4.T3.44.42.4" class="ltx_td ltx_align_right"><math id="S4.T3.44.42.4.m1.1" class="ltx_Math" alttext="9.54" display="inline"><semantics id="S4.T3.44.42.4.m1.1a"><mn mathsize="80%" id="S4.T3.44.42.4.m1.1.1" xref="S4.T3.44.42.4.m1.1.1.cmml">9.54</mn><annotation-xml encoding="MathML-Content" id="S4.T3.44.42.4.m1.1b"><cn type="float" id="S4.T3.44.42.4.m1.1.1.cmml" xref="S4.T3.44.42.4.m1.1.1">9.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.44.42.4.m1.1c">9.54</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.52.50" class="ltx_tr">
<td id="S4.T3.52.50.9" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.52.50.9.1" class="ltx_text" style="font-size:80%;">Whisper</span></td>
<td id="S4.T3.52.50.10" class="ltx_td ltx_border_bb"></td>
<td id="S4.T3.52.50.11" class="ltx_td ltx_border_bb"></td>
<td id="S4.T3.45.43.1" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T3.45.43.1.m1.1" class="ltx_Math" alttext="6.60" display="inline"><semantics id="S4.T3.45.43.1.m1.1a"><mn mathsize="80%" id="S4.T3.45.43.1.m1.1.1" xref="S4.T3.45.43.1.m1.1.1.cmml">6.60</mn><annotation-xml encoding="MathML-Content" id="S4.T3.45.43.1.m1.1b"><cn type="float" id="S4.T3.45.43.1.m1.1.1.cmml" xref="S4.T3.45.43.1.m1.1.1">6.60</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.45.43.1.m1.1c">6.60</annotation></semantics></math></td>
<td id="S4.T3.46.44.2" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T3.46.44.2.m1.1" class="ltx_Math" alttext="8.55" display="inline"><semantics id="S4.T3.46.44.2.m1.1a"><mn mathsize="80%" id="S4.T3.46.44.2.m1.1.1" xref="S4.T3.46.44.2.m1.1.1.cmml">8.55</mn><annotation-xml encoding="MathML-Content" id="S4.T3.46.44.2.m1.1b"><cn type="float" id="S4.T3.46.44.2.m1.1.1.cmml" xref="S4.T3.46.44.2.m1.1.1">8.55</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.46.44.2.m1.1c">8.55</annotation></semantics></math></td>
<td id="S4.T3.47.45.3" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T3.47.45.3.m1.1" class="ltx_Math" alttext="11.92" display="inline"><semantics id="S4.T3.47.45.3.m1.1a"><mn mathsize="80%" id="S4.T3.47.45.3.m1.1.1" xref="S4.T3.47.45.3.m1.1.1.cmml">11.92</mn><annotation-xml encoding="MathML-Content" id="S4.T3.47.45.3.m1.1b"><cn type="float" id="S4.T3.47.45.3.m1.1.1.cmml" xref="S4.T3.47.45.3.m1.1.1">11.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.47.45.3.m1.1c">11.92</annotation></semantics></math></td>
<td id="S4.T3.48.46.4" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T3.48.46.4.m1.1" class="ltx_Math" alttext="15.24" display="inline"><semantics id="S4.T3.48.46.4.m1.1a"><mn mathsize="80%" id="S4.T3.48.46.4.m1.1.1" xref="S4.T3.48.46.4.m1.1.1.cmml">15.24</mn><annotation-xml encoding="MathML-Content" id="S4.T3.48.46.4.m1.1b"><cn type="float" id="S4.T3.48.46.4.m1.1.1.cmml" xref="S4.T3.48.46.4.m1.1.1">15.24</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.48.46.4.m1.1c">15.24</annotation></semantics></math></td>
<td id="S4.T3.49.47.5" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T3.49.47.5.m1.1" class="ltx_Math" alttext="\mathbf{2.89}" display="inline"><semantics id="S4.T3.49.47.5.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="80%" mathvariant="bold" id="S4.T3.49.47.5.m1.1.1" xref="S4.T3.49.47.5.m1.1.1.cmml">2.89</mn><annotation-xml encoding="MathML-Content" id="S4.T3.49.47.5.m1.1b"><cn type="float" id="S4.T3.49.47.5.m1.1.1.cmml" xref="S4.T3.49.47.5.m1.1.1">2.89</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.49.47.5.m1.1c">\mathbf{2.89}</annotation></semantics></math></td>
<td id="S4.T3.50.48.6" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T3.50.48.6.m1.1" class="ltx_Math" alttext="\mathbf{2.95}" display="inline"><semantics id="S4.T3.50.48.6.m1.1a"><mn class="ltx_mathvariant_bold" mathsize="80%" mathvariant="bold" id="S4.T3.50.48.6.m1.1.1" xref="S4.T3.50.48.6.m1.1.1.cmml">2.95</mn><annotation-xml encoding="MathML-Content" id="S4.T3.50.48.6.m1.1b"><cn type="float" id="S4.T3.50.48.6.m1.1.1.cmml" xref="S4.T3.50.48.6.m1.1.1">2.95</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.50.48.6.m1.1c">\mathbf{2.95}</annotation></semantics></math></td>
<td id="S4.T3.51.49.7" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T3.51.49.7.m1.1" class="ltx_Math" alttext="16.88" display="inline"><semantics id="S4.T3.51.49.7.m1.1a"><mn mathsize="80%" id="S4.T3.51.49.7.m1.1.1" xref="S4.T3.51.49.7.m1.1.1.cmml">16.88</mn><annotation-xml encoding="MathML-Content" id="S4.T3.51.49.7.m1.1b"><cn type="float" id="S4.T3.51.49.7.m1.1.1.cmml" xref="S4.T3.51.49.7.m1.1.1">16.88</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.51.49.7.m1.1c">16.88</annotation></semantics></math></td>
<td id="S4.T3.52.50.8" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T3.52.50.8.m1.1" class="ltx_Math" alttext="13.50" display="inline"><semantics id="S4.T3.52.50.8.m1.1a"><mn mathsize="80%" id="S4.T3.52.50.8.m1.1.1" xref="S4.T3.52.50.8.m1.1.1.cmml">13.50</mn><annotation-xml encoding="MathML-Content" id="S4.T3.52.50.8.m1.1b"><cn type="float" id="S4.T3.52.50.8.m1.1.1.cmml" xref="S4.T3.52.50.8.m1.1.1">13.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.52.50.8.m1.1c">13.50</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>
Keywords error rate comparison.
“KW” stands for keywords in the header.
In the second and third columns,
check marks <math id="S4.T4.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T4.2.m1.1b"><mi mathvariant="normal" id="S4.T4.2.m1.1.1" xref="S4.T4.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.2.m1.1c"><ci id="S4.T4.2.m1.1.1.cmml" xref="S4.T4.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.m1.1d">\checkmark</annotation></semantics></math> represent the existence of keywords
at the training and inference steps, respectively.
By using keywords for inference,
the evaluation metric values become much lower than not using keywords.
</figcaption>
<table id="S4.T4.22" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.22.21.1" class="ltx_tr">
<th id="S4.T4.22.21.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Model</th>
<th id="S4.T4.22.21.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">KW@Train</th>
<th id="S4.T4.22.21.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">KW@Inference</th>
<th id="S4.T4.22.21.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" colspan="2">YODAS</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.22.22.1" class="ltx_tr">
<td id="S4.T4.22.22.1.1" class="ltx_td"></td>
<th id="S4.T4.22.22.1.2" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T4.22.22.1.3" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T4.22.22.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column">Dev</th>
<th id="S4.T4.22.22.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column">Test</th>
</tr>
<tr id="S4.T4.4.2" class="ltx_tr">
<td id="S4.T4.4.2.3" class="ltx_td ltx_align_left ltx_border_t">PLaMo</td>
<td id="S4.T4.4.2.4" class="ltx_td ltx_border_t"></td>
<td id="S4.T4.4.2.5" class="ltx_td ltx_border_t"></td>
<td id="S4.T4.3.1.1" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T4.3.1.1.m1.1" class="ltx_Math" alttext="63.77" display="inline"><semantics id="S4.T4.3.1.1.m1.1a"><mn id="S4.T4.3.1.1.m1.1.1" xref="S4.T4.3.1.1.m1.1.1.cmml">63.77</mn><annotation-xml encoding="MathML-Content" id="S4.T4.3.1.1.m1.1b"><cn type="float" id="S4.T4.3.1.1.m1.1.1.cmml" xref="S4.T4.3.1.1.m1.1.1">63.77</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.1.1.m1.1c">63.77</annotation></semantics></math></td>
<td id="S4.T4.4.2.2" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T4.4.2.2.m1.1" class="ltx_Math" alttext="52.74" display="inline"><semantics id="S4.T4.4.2.2.m1.1a"><mn id="S4.T4.4.2.2.m1.1.1" xref="S4.T4.4.2.2.m1.1.1.cmml">52.74</mn><annotation-xml encoding="MathML-Content" id="S4.T4.4.2.2.m1.1b"><cn type="float" id="S4.T4.4.2.2.m1.1.1.cmml" xref="S4.T4.4.2.2.m1.1.1">52.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.2.2.m1.1c">52.74</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.7.5" class="ltx_tr">
<td id="S4.T4.7.5.4" class="ltx_td ltx_align_left">PLaMo</td>
<td id="S4.T4.5.3.1" class="ltx_td ltx_align_left"><math id="S4.T4.5.3.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T4.5.3.1.m1.1a"><mi mathvariant="normal" id="S4.T4.5.3.1.m1.1.1" xref="S4.T4.5.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.5.3.1.m1.1b"><ci id="S4.T4.5.3.1.m1.1.1.cmml" xref="S4.T4.5.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.3.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T4.7.5.5" class="ltx_td"></td>
<td id="S4.T4.6.4.2" class="ltx_td ltx_align_right"><math id="S4.T4.6.4.2.m1.1" class="ltx_Math" alttext="64.17" display="inline"><semantics id="S4.T4.6.4.2.m1.1a"><mn id="S4.T4.6.4.2.m1.1.1" xref="S4.T4.6.4.2.m1.1.1.cmml">64.17</mn><annotation-xml encoding="MathML-Content" id="S4.T4.6.4.2.m1.1b"><cn type="float" id="S4.T4.6.4.2.m1.1.1.cmml" xref="S4.T4.6.4.2.m1.1.1">64.17</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.4.2.m1.1c">64.17</annotation></semantics></math></td>
<td id="S4.T4.7.5.3" class="ltx_td ltx_align_right"><math id="S4.T4.7.5.3.m1.1" class="ltx_Math" alttext="58.21" display="inline"><semantics id="S4.T4.7.5.3.m1.1a"><mn id="S4.T4.7.5.3.m1.1.1" xref="S4.T4.7.5.3.m1.1.1.cmml">58.21</mn><annotation-xml encoding="MathML-Content" id="S4.T4.7.5.3.m1.1b"><cn type="float" id="S4.T4.7.5.3.m1.1.1.cmml" xref="S4.T4.7.5.3.m1.1.1">58.21</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.5.3.m1.1c">58.21</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.11.9" class="ltx_tr">
<td id="S4.T4.11.9.5" class="ltx_td ltx_align_left">PLaMo</td>
<td id="S4.T4.8.6.1" class="ltx_td ltx_align_left"><math id="S4.T4.8.6.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T4.8.6.1.m1.1a"><mi mathvariant="normal" id="S4.T4.8.6.1.m1.1.1" xref="S4.T4.8.6.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.8.6.1.m1.1b"><ci id="S4.T4.8.6.1.m1.1.1.cmml" xref="S4.T4.8.6.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.6.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T4.9.7.2" class="ltx_td ltx_align_left"><math id="S4.T4.9.7.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T4.9.7.2.m1.1a"><mi mathvariant="normal" id="S4.T4.9.7.2.m1.1.1" xref="S4.T4.9.7.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.9.7.2.m1.1b"><ci id="S4.T4.9.7.2.m1.1.1.cmml" xref="S4.T4.9.7.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.7.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T4.10.8.3" class="ltx_td ltx_align_right"><math id="S4.T4.10.8.3.m1.1" class="ltx_Math" alttext="24.29" display="inline"><semantics id="S4.T4.10.8.3.m1.1a"><mn id="S4.T4.10.8.3.m1.1.1" xref="S4.T4.10.8.3.m1.1.1.cmml">24.29</mn><annotation-xml encoding="MathML-Content" id="S4.T4.10.8.3.m1.1b"><cn type="float" id="S4.T4.10.8.3.m1.1.1.cmml" xref="S4.T4.10.8.3.m1.1.1">24.29</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.8.3.m1.1c">24.29</annotation></semantics></math></td>
<td id="S4.T4.11.9.4" class="ltx_td ltx_align_right"><math id="S4.T4.11.9.4.m1.1" class="ltx_Math" alttext="\mathbf{10.45}" display="inline"><semantics id="S4.T4.11.9.4.m1.1a"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S4.T4.11.9.4.m1.1.1" xref="S4.T4.11.9.4.m1.1.1.cmml">10.45</mn><annotation-xml encoding="MathML-Content" id="S4.T4.11.9.4.m1.1b"><cn type="float" id="S4.T4.11.9.4.m1.1.1.cmml" xref="S4.T4.11.9.4.m1.1.1">10.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.9.4.m1.1c">\mathbf{10.45}</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.13.11" class="ltx_tr">
<td id="S4.T4.13.11.3" class="ltx_td ltx_align_left">Swallow</td>
<td id="S4.T4.13.11.4" class="ltx_td"></td>
<td id="S4.T4.13.11.5" class="ltx_td"></td>
<td id="S4.T4.12.10.1" class="ltx_td ltx_align_right"><math id="S4.T4.12.10.1.m1.1" class="ltx_Math" alttext="64.17" display="inline"><semantics id="S4.T4.12.10.1.m1.1a"><mn id="S4.T4.12.10.1.m1.1.1" xref="S4.T4.12.10.1.m1.1.1.cmml">64.17</mn><annotation-xml encoding="MathML-Content" id="S4.T4.12.10.1.m1.1b"><cn type="float" id="S4.T4.12.10.1.m1.1.1.cmml" xref="S4.T4.12.10.1.m1.1.1">64.17</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.10.1.m1.1c">64.17</annotation></semantics></math></td>
<td id="S4.T4.13.11.2" class="ltx_td ltx_align_right"><math id="S4.T4.13.11.2.m1.1" class="ltx_Math" alttext="55.47" display="inline"><semantics id="S4.T4.13.11.2.m1.1a"><mn id="S4.T4.13.11.2.m1.1.1" xref="S4.T4.13.11.2.m1.1.1.cmml">55.47</mn><annotation-xml encoding="MathML-Content" id="S4.T4.13.11.2.m1.1b"><cn type="float" id="S4.T4.13.11.2.m1.1.1.cmml" xref="S4.T4.13.11.2.m1.1.1">55.47</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.13.11.2.m1.1c">55.47</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.16.14" class="ltx_tr">
<td id="S4.T4.16.14.4" class="ltx_td ltx_align_left">Swallow</td>
<td id="S4.T4.14.12.1" class="ltx_td ltx_align_left"><math id="S4.T4.14.12.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T4.14.12.1.m1.1a"><mi mathvariant="normal" id="S4.T4.14.12.1.m1.1.1" xref="S4.T4.14.12.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.14.12.1.m1.1b"><ci id="S4.T4.14.12.1.m1.1.1.cmml" xref="S4.T4.14.12.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.14.12.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T4.16.14.5" class="ltx_td"></td>
<td id="S4.T4.15.13.2" class="ltx_td ltx_align_right"><math id="S4.T4.15.13.2.m1.1" class="ltx_Math" alttext="65.99" display="inline"><semantics id="S4.T4.15.13.2.m1.1a"><mn id="S4.T4.15.13.2.m1.1.1" xref="S4.T4.15.13.2.m1.1.1.cmml">65.99</mn><annotation-xml encoding="MathML-Content" id="S4.T4.15.13.2.m1.1b"><cn type="float" id="S4.T4.15.13.2.m1.1.1.cmml" xref="S4.T4.15.13.2.m1.1.1">65.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.15.13.2.m1.1c">65.99</annotation></semantics></math></td>
<td id="S4.T4.16.14.3" class="ltx_td ltx_align_right"><math id="S4.T4.16.14.3.m1.1" class="ltx_Math" alttext="57.71" display="inline"><semantics id="S4.T4.16.14.3.m1.1a"><mn id="S4.T4.16.14.3.m1.1.1" xref="S4.T4.16.14.3.m1.1.1.cmml">57.71</mn><annotation-xml encoding="MathML-Content" id="S4.T4.16.14.3.m1.1b"><cn type="float" id="S4.T4.16.14.3.m1.1.1.cmml" xref="S4.T4.16.14.3.m1.1.1">57.71</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.16.14.3.m1.1c">57.71</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.20.18" class="ltx_tr">
<td id="S4.T4.20.18.5" class="ltx_td ltx_align_left">Swallow</td>
<td id="S4.T4.17.15.1" class="ltx_td ltx_align_left"><math id="S4.T4.17.15.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T4.17.15.1.m1.1a"><mi mathvariant="normal" id="S4.T4.17.15.1.m1.1.1" xref="S4.T4.17.15.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.17.15.1.m1.1b"><ci id="S4.T4.17.15.1.m1.1.1.cmml" xref="S4.T4.17.15.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.17.15.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T4.18.16.2" class="ltx_td ltx_align_left"><math id="S4.T4.18.16.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T4.18.16.2.m1.1a"><mi mathvariant="normal" id="S4.T4.18.16.2.m1.1.1" xref="S4.T4.18.16.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T4.18.16.2.m1.1b"><ci id="S4.T4.18.16.2.m1.1.1.cmml" xref="S4.T4.18.16.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.18.16.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T4.19.17.3" class="ltx_td ltx_align_right"><math id="S4.T4.19.17.3.m1.1" class="ltx_Math" alttext="\mathbf{21.46}" display="inline"><semantics id="S4.T4.19.17.3.m1.1a"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S4.T4.19.17.3.m1.1.1" xref="S4.T4.19.17.3.m1.1.1.cmml">21.46</mn><annotation-xml encoding="MathML-Content" id="S4.T4.19.17.3.m1.1b"><cn type="float" id="S4.T4.19.17.3.m1.1.1.cmml" xref="S4.T4.19.17.3.m1.1.1">21.46</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.19.17.3.m1.1c">\mathbf{21.46}</annotation></semantics></math></td>
<td id="S4.T4.20.18.4" class="ltx_td ltx_align_right"><math id="S4.T4.20.18.4.m1.1" class="ltx_Math" alttext="10.95" display="inline"><semantics id="S4.T4.20.18.4.m1.1a"><mn id="S4.T4.20.18.4.m1.1.1" xref="S4.T4.20.18.4.m1.1.1.cmml">10.95</mn><annotation-xml encoding="MathML-Content" id="S4.T4.20.18.4.m1.1b"><cn type="float" id="S4.T4.20.18.4.m1.1.1.cmml" xref="S4.T4.20.18.4.m1.1.1">10.95</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.20.18.4.m1.1c">10.95</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.22.20" class="ltx_tr">
<td id="S4.T4.22.20.3" class="ltx_td ltx_align_left ltx_border_bb">Whisper</td>
<td id="S4.T4.22.20.4" class="ltx_td ltx_border_bb"></td>
<td id="S4.T4.22.20.5" class="ltx_td ltx_border_bb"></td>
<td id="S4.T4.21.19.1" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T4.21.19.1.m1.1" class="ltx_Math" alttext="71.66" display="inline"><semantics id="S4.T4.21.19.1.m1.1a"><mn id="S4.T4.21.19.1.m1.1.1" xref="S4.T4.21.19.1.m1.1.1.cmml">71.66</mn><annotation-xml encoding="MathML-Content" id="S4.T4.21.19.1.m1.1b"><cn type="float" id="S4.T4.21.19.1.m1.1.1.cmml" xref="S4.T4.21.19.1.m1.1.1">71.66</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.21.19.1.m1.1c">71.66</annotation></semantics></math></td>
<td id="S4.T4.22.20.2" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T4.22.20.2.m1.1" class="ltx_Math" alttext="61.69" display="inline"><semantics id="S4.T4.22.20.2.m1.1a"><mn id="S4.T4.22.20.2.m1.1.1" xref="S4.T4.22.20.2.m1.1.1.cmml">61.69</mn><annotation-xml encoding="MathML-Content" id="S4.T4.22.20.2.m1.1b"><cn type="float" id="S4.T4.22.20.2.m1.1.1.cmml" xref="S4.T4.22.20.2.m1.1.1">61.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.22.20.2.m1.1c">61.69</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.6" class="ltx_p"><a href="#S4.T3" title="In 4.6 Results ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> shows CERs and WERs on dev/test sets.
CERs for Japanese datasets improved by replacing the Whisper decoder with PLaMo-100B or Swallow-7B,
probably because both models have a much larger number of parameters than the Whisper decoder,
and training datasets for pre-training and fine-tuning of the models
were dominated by Japanese text/audio data.
In addition, compared to the case without keywords,
CERs for YODAS dev/test sets improved significantly
by giving keywords for training and inference
with relative error rate reductions of
<math id="S4.SS6.p1.1.m1.1" class="ltx_Math" alttext="7.87\%" display="inline"><semantics id="S4.SS6.p1.1.m1.1a"><mrow id="S4.SS6.p1.1.m1.1.1" xref="S4.SS6.p1.1.m1.1.1.cmml"><mn id="S4.SS6.p1.1.m1.1.1.2" xref="S4.SS6.p1.1.m1.1.1.2.cmml">7.87</mn><mo id="S4.SS6.p1.1.m1.1.1.1" xref="S4.SS6.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.1.m1.1b"><apply id="S4.SS6.p1.1.m1.1.1.cmml" xref="S4.SS6.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS6.p1.1.m1.1.1.1.cmml" xref="S4.SS6.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p1.1.m1.1.1.2.cmml" xref="S4.SS6.p1.1.m1.1.1.2">7.87</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.1.m1.1c">7.87\%</annotation></semantics></math> (from <math id="S4.SS6.p1.2.m2.1" class="ltx_Math" alttext="12.45\%" display="inline"><semantics id="S4.SS6.p1.2.m2.1a"><mrow id="S4.SS6.p1.2.m2.1.1" xref="S4.SS6.p1.2.m2.1.1.cmml"><mn id="S4.SS6.p1.2.m2.1.1.2" xref="S4.SS6.p1.2.m2.1.1.2.cmml">12.45</mn><mo id="S4.SS6.p1.2.m2.1.1.1" xref="S4.SS6.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.2.m2.1b"><apply id="S4.SS6.p1.2.m2.1.1.cmml" xref="S4.SS6.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS6.p1.2.m2.1.1.1.cmml" xref="S4.SS6.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p1.2.m2.1.1.2.cmml" xref="S4.SS6.p1.2.m2.1.1.2">12.45</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.2.m2.1c">12.45\%</annotation></semantics></math> to <math id="S4.SS6.p1.3.m3.1" class="ltx_Math" alttext="11.47\%" display="inline"><semantics id="S4.SS6.p1.3.m3.1a"><mrow id="S4.SS6.p1.3.m3.1.1" xref="S4.SS6.p1.3.m3.1.1.cmml"><mn id="S4.SS6.p1.3.m3.1.1.2" xref="S4.SS6.p1.3.m3.1.1.2.cmml">11.47</mn><mo id="S4.SS6.p1.3.m3.1.1.1" xref="S4.SS6.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.3.m3.1b"><apply id="S4.SS6.p1.3.m3.1.1.cmml" xref="S4.SS6.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS6.p1.3.m3.1.1.1.cmml" xref="S4.SS6.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p1.3.m3.1.1.2.cmml" xref="S4.SS6.p1.3.m3.1.1.2">11.47</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.3.m3.1c">11.47\%</annotation></semantics></math> in CERs) for the dev set
and <math id="S4.SS6.p1.4.m4.1" class="ltx_Math" alttext="11.15\%" display="inline"><semantics id="S4.SS6.p1.4.m4.1a"><mrow id="S4.SS6.p1.4.m4.1.1" xref="S4.SS6.p1.4.m4.1.1.cmml"><mn id="S4.SS6.p1.4.m4.1.1.2" xref="S4.SS6.p1.4.m4.1.1.2.cmml">11.15</mn><mo id="S4.SS6.p1.4.m4.1.1.1" xref="S4.SS6.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.4.m4.1b"><apply id="S4.SS6.p1.4.m4.1.1.cmml" xref="S4.SS6.p1.4.m4.1.1"><csymbol cd="latexml" id="S4.SS6.p1.4.m4.1.1.1.cmml" xref="S4.SS6.p1.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p1.4.m4.1.1.2.cmml" xref="S4.SS6.p1.4.m4.1.1.2">11.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.4.m4.1c">11.15\%</annotation></semantics></math> (from <math id="S4.SS6.p1.5.m5.1" class="ltx_Math" alttext="10.67\%" display="inline"><semantics id="S4.SS6.p1.5.m5.1a"><mrow id="S4.SS6.p1.5.m5.1.1" xref="S4.SS6.p1.5.m5.1.1.cmml"><mn id="S4.SS6.p1.5.m5.1.1.2" xref="S4.SS6.p1.5.m5.1.1.2.cmml">10.67</mn><mo id="S4.SS6.p1.5.m5.1.1.1" xref="S4.SS6.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.5.m5.1b"><apply id="S4.SS6.p1.5.m5.1.1.cmml" xref="S4.SS6.p1.5.m5.1.1"><csymbol cd="latexml" id="S4.SS6.p1.5.m5.1.1.1.cmml" xref="S4.SS6.p1.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p1.5.m5.1.1.2.cmml" xref="S4.SS6.p1.5.m5.1.1.2">10.67</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.5.m5.1c">10.67\%</annotation></semantics></math> to <math id="S4.SS6.p1.6.m6.1" class="ltx_Math" alttext="9.48\%" display="inline"><semantics id="S4.SS6.p1.6.m6.1a"><mrow id="S4.SS6.p1.6.m6.1.1" xref="S4.SS6.p1.6.m6.1.1.cmml"><mn id="S4.SS6.p1.6.m6.1.1.2" xref="S4.SS6.p1.6.m6.1.1.2.cmml">9.48</mn><mo id="S4.SS6.p1.6.m6.1.1.1" xref="S4.SS6.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.6.m6.1b"><apply id="S4.SS6.p1.6.m6.1.1.cmml" xref="S4.SS6.p1.6.m6.1.1"><csymbol cd="latexml" id="S4.SS6.p1.6.m6.1.1.1.cmml" xref="S4.SS6.p1.6.m6.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p1.6.m6.1.1.2.cmml" xref="S4.SS6.p1.6.m6.1.1.2">9.48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.6.m6.1c">9.48\%</annotation></semantics></math> in CERs) for the test set for PLaMo-100B.
On the other hand, compared to Whisper large-v3,
the WERs of our models for LibriSpeech degraded
due to the small number of English samples in the training dataset,
though our models could avoid catastrophic forgetting in the English domain.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.1" class="ltx_p"><a href="#S4.T4" title="In 4.6 Results ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a> shows KWERs for YODAS dev/test sets.
As expected,
we could significantly improve KWERs by giving keywords as prior information.
Our model could not only improve transcriptions in terms of pronunciation
but also could select correct homonyms for named entities,
such as domain-specific terms and personal names,
by contextualizing the decoder with keywords
as shown in <a href="#S4.T5" title="In 4.6 Results ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S4.SS6.p3" class="ltx_para">
<p id="S4.SS6.p3.1" class="ltx_p">Comparing the results of PLaMo-100B with those of Swallow-7B in <a href="#S4.T3" title="In 4.6 Results ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>,
although PLaMo-100B outperformed Swallow-7B
for most of the evaluation sets except for the YODAS dev set,
improvements in CERs and KWERs were smaller
than expected from the increase in model size.
One of the reasons is that
the number of training epochs was insufficient for PLaMo-100B
due to limitations on computational costs.
Another reason is that
speech recognition is easier than other tasks,
such as speech translation and voice chat,
and 7B models may be sufficient for speech recognition
in terms of model sizes.
Indeed, this tendency is consistent with
<cite class="ltx_cite ltx_citemacro_citet">Llama Team, AI @ Meta (<a href="#bib.bib22" title="" class="ltx_ref">2024</a>, Table 31)</cite>
reporting that LLaMA 3.1 8B and 70B-based multi-task speech processing systems’ WERs,
where their difference was only <math id="S4.SS6.p3.1.m1.1" class="ltx_Math" alttext="1.4" display="inline"><semantics id="S4.SS6.p3.1.m1.1a"><mn id="S4.SS6.p3.1.m1.1.1" xref="S4.SS6.p3.1.m1.1.1.cmml">1.4</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.p3.1.m1.1b"><cn type="float" id="S4.SS6.p3.1.m1.1.1.cmml" xref="S4.SS6.p3.1.m1.1.1">1.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p3.1.m1.1c">1.4</annotation></semantics></math> at maximum.
Our future work is fine-tuning our model with PLaMo-100B using more data and the number of epochs and extending to other tasks.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>
Examples of recognition results in Japanese from YODAS dev/test sets
improved by providing keywords as prior information.
Keywords and corresponding recognized words are shown in bold (gothic),
and recognition errors are marked by underlines.
</figcaption>
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T5.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.1.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Ground truth</span></span>
</span>
</th>
<th id="S4.T5.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T5.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.1.2.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.1.1.2.1.1.1" class="ltx_text" style="font-size:90%;">Without keywords</span></span>
</span>
</th>
<th id="S4.T5.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T5.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.1.1.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.1.1.3.1.1.1" class="ltx_text" style="font-size:90%;">With keywords</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.2.1" class="ltx_tr">
<td id="S4.T5.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.2.1.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">阿蘇ローズベリー香園と</span></span>
</span>
</td>
<td id="S4.T5.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.2.1.2.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.2.1.2.1.1.1" class="ltx_text" style="font-size:90%;">阿蘇ローズベリー</span><span id="S4.T5.1.2.1.2.1.1.2" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">公</span><span id="S4.T5.1.2.1.2.1.1.3" class="ltx_text" style="font-size:90%;">園と</span></span>
</span>
</td>
<td id="S4.T5.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.2.1.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.2.1.3.1.1.1" class="ltx_text" style="font-size:90%;">阿蘇ローズベリー香園と</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.1.3.2" class="ltx_tr">
<td id="S4.T5.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.2.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.3.2.1.1.1.1" class="ltx_text" style="font-size:90%;">カラス天狗のウルトラマン</span></span>
</span>
</td>
<td id="S4.T5.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.2.2.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.3.2.2.1.1.1" class="ltx_text" style="font-size:90%;">カ</span><span id="S4.T5.1.3.2.2.1.1.2" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">ー</span><span id="S4.T5.1.3.2.2.1.1.3" class="ltx_text" style="font-size:90%;">ス</span><span id="S4.T5.1.3.2.2.1.1.4" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">ティング</span><span id="S4.T5.1.3.2.2.1.1.5" class="ltx_text" style="font-size:90%;">のウルトラマン</span></span>
</span>
</td>
<td id="S4.T5.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.3.2.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.3.2.3.1.1.1" class="ltx_text" style="font-size:90%;">カラス天狗のウルトラマン</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.1.4.3" class="ltx_tr">
<td id="S4.T5.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.3.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.4.3.1.1.1.1" class="ltx_text" style="font-size:90%;">ラズパイで</span><span id="S4.T5.1.4.3.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">handbrake</span><span id="S4.T5.1.4.3.1.1.1.3" class="ltx_text" style="font-size:90%;">いいですね</span></span>
</span>
</td>
<td id="S4.T5.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.3.2.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.4.3.2.1.1.1" class="ltx_text" style="font-size:90%;">ラズパイで</span><span id="S4.T5.1.4.3.2.1.1.2" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">ハンドブレーキ</span><span id="S4.T5.1.4.3.2.1.1.3" class="ltx_text" style="font-size:90%;">いいですね</span></span>
</span>
</td>
<td id="S4.T5.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.4.3.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.4.3.3.1.1.1" class="ltx_text" style="font-size:90%;">ラズパイで</span><span id="S4.T5.1.4.3.3.1.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">handbrake</span><span id="S4.T5.1.4.3.3.1.1.3" class="ltx_text" style="font-size:90%;">いいですね</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.1.5.4" class="ltx_tr">
<td id="S4.T5.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.4.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.5.4.1.1.1.1" class="ltx_text" style="font-size:90%;">堂満直聖26歳です</span></span>
</span>
</td>
<td id="S4.T5.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.4.2.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.5.4.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">道</span><span id="S4.T5.1.5.4.2.1.1.2" class="ltx_text" style="font-size:90%;">満直</span><span id="S4.T5.1.5.4.2.1.1.3" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">輝</span><span id="S4.T5.1.5.4.2.1.1.4" class="ltx_text" style="font-size:90%;">26歳です</span></span>
</span>
</td>
<td id="S4.T5.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T5.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.5.4.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.5.4.3.1.1.1" class="ltx_text" style="font-size:90%;">堂満直聖26歳です</span></span>
</span>
</td>
</tr>
<tr id="S4.T5.1.6.5" class="ltx_tr">
<td id="S4.T5.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="S4.T5.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.5.1.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.6.5.1.1.1.1" class="ltx_text" style="font-size:90%;">塚本秀春さんが代表で鍵のレプリカを受け取り</span></span>
</span>
</td>
<td id="S4.T5.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="S4.T5.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.5.2.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.6.5.2.1.1.1" class="ltx_text" style="font-size:90%;">塚本</span><span id="S4.T5.1.6.5.2.1.1.2" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">英治</span><span id="S4.T5.1.6.5.2.1.1.3" class="ltx_text" style="font-size:90%;">さんが代表で鍵のレプリカを受け取り</span></span>
</span>
</td>
<td id="S4.T5.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="S4.T5.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T5.1.6.5.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S4.T5.1.6.5.3.1.1.1" class="ltx_text" style="font-size:90%;">塚本秀春さんが代表で鍵のレプリカを受け取り</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>Dataset Bias Experiments</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">To demonstrate the issue discussed in <a href="#S3.SS2" title="3.2 Dataset Bias via Prompt ‣ 3 Datasets ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>,
we conducted a controlled experiment using Swallow-7B models.
We fine-tuned the same pre-trained Swallow-7B model,
represented by cross marks ✗ in <a href="#S4.T6" title="In 4.7 Dataset Bias Experiments ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">6</span></a>,
on another training dataset that always feeds keywords for the YODAS train set;
samples with keywords in the YODAS train set were shown twice to the model in the single epoch.
<a href="#S4.T6" title="In 4.7 Dataset Bias Experiments ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">6</span></a> reports KWERs and CERs on the YODAS dev set.
KWERs for transcriptions with keywords
improved by using the model fine-tuned on the new train set represented by ✗,
possibly by increasing the amount of training data with keywords.
However, KWERs and CERs were worst when keywords were not provided to the model at inference
(the second row from the bottom of <a href="#S4.T6" title="In 4.7 Dataset Bias Experiments ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">6</span></a>),
especially regarding deletions, which almost doubled.
As described in <a href="#S3.SS2" title="3.2 Dataset Bias via Prompt ‣ 3 Datasets ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>,
we suspect this is because only the YODAS train set has keywords,
and other samples, mainly ReazonSpeech, do not.
Thus, ReazonSpeech’s transcription error,
which tends to drop a part of the transcription text,
hurt the transcription of even YODAS dev/test sets
by not giving keywords at inference.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>
Detailed error analysis on the YODAS dev set with Swallow-7B models.
The cross marks ✗ represent the use of the YODSA train set with keywords only.
Recall that check marks <math id="S4.T6.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T6.2.m1.1b"><mi mathvariant="normal" id="S4.T6.2.m1.1.1" xref="S4.T6.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T6.2.m1.1c"><ci id="S4.T6.2.m1.1.1.cmml" xref="S4.T6.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.m1.1d">\checkmark</annotation></semantics></math> represent
the use of the YODAS train set with and without keywords,
and no marks represent the use of the set without keywords only.
The amount of data of the train set is the same for all conditions;
each audio sample in the YODAS train set is shown to the model twice in a single epoch.
</figcaption>
<table id="S4.T6.31" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.31.30.1" class="ltx_tr">
<th id="S4.T6.31.30.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">KW@Train</th>
<th id="S4.T6.31.30.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">KW@Inference</th>
<th id="S4.T6.31.30.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">KWER</th>
<th id="S4.T6.31.30.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">CER</th>
<th id="S4.T6.31.30.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Insertions</th>
<th id="S4.T6.31.30.1.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Deletions</th>
<th id="S4.T6.31.30.1.7" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">Substitutions</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.7.5" class="ltx_tr">
<th id="S4.T6.7.5.6" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S4.T6.7.5.7" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<td id="S4.T6.3.1.1" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T6.3.1.1.m1.1" class="ltx_Math" alttext="64.17" display="inline"><semantics id="S4.T6.3.1.1.m1.1a"><mn id="S4.T6.3.1.1.m1.1.1" xref="S4.T6.3.1.1.m1.1.1.cmml">64.17</mn><annotation-xml encoding="MathML-Content" id="S4.T6.3.1.1.m1.1b"><cn type="float" id="S4.T6.3.1.1.m1.1.1.cmml" xref="S4.T6.3.1.1.m1.1.1">64.17</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.1.1.m1.1c">64.17</annotation></semantics></math></td>
<td id="S4.T6.4.2.2" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T6.4.2.2.m1.1" class="ltx_Math" alttext="12.72" display="inline"><semantics id="S4.T6.4.2.2.m1.1a"><mn id="S4.T6.4.2.2.m1.1.1" xref="S4.T6.4.2.2.m1.1.1.cmml">12.72</mn><annotation-xml encoding="MathML-Content" id="S4.T6.4.2.2.m1.1b"><cn type="float" id="S4.T6.4.2.2.m1.1.1.cmml" xref="S4.T6.4.2.2.m1.1.1">12.72</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.2.2.m1.1c">12.72</annotation></semantics></math></td>
<td id="S4.T6.5.3.3" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T6.5.3.3.m1.1" class="ltx_Math" alttext="6\,105" display="inline"><semantics id="S4.T6.5.3.3.m1.1a"><mn id="S4.T6.5.3.3.m1.1.1" xref="S4.T6.5.3.3.m1.1.1.cmml">6 105</mn><annotation-xml encoding="MathML-Content" id="S4.T6.5.3.3.m1.1b"><cn type="integer" id="S4.T6.5.3.3.m1.1.1.cmml" xref="S4.T6.5.3.3.m1.1.1">6105</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.5.3.3.m1.1c">6\,105</annotation></semantics></math></td>
<td id="S4.T6.6.4.4" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T6.6.4.4.m1.1" class="ltx_Math" alttext="6\,961" display="inline"><semantics id="S4.T6.6.4.4.m1.1a"><mn id="S4.T6.6.4.4.m1.1.1" xref="S4.T6.6.4.4.m1.1.1.cmml">6 961</mn><annotation-xml encoding="MathML-Content" id="S4.T6.6.4.4.m1.1b"><cn type="integer" id="S4.T6.6.4.4.m1.1.1.cmml" xref="S4.T6.6.4.4.m1.1.1">6961</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.6.4.4.m1.1c">6\,961</annotation></semantics></math></td>
<td id="S4.T6.7.5.5" class="ltx_td ltx_align_right ltx_border_t"><math id="S4.T6.7.5.5.m1.1" class="ltx_Math" alttext="10\,519" display="inline"><semantics id="S4.T6.7.5.5.m1.1a"><mn id="S4.T6.7.5.5.m1.1.1" xref="S4.T6.7.5.5.m1.1.1.cmml">10 519</mn><annotation-xml encoding="MathML-Content" id="S4.T6.7.5.5.m1.1b"><cn type="integer" id="S4.T6.7.5.5.m1.1.1.cmml" xref="S4.T6.7.5.5.m1.1.1">10519</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.7.5.5.m1.1c">10\,519</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.13.11" class="ltx_tr">
<th id="S4.T6.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T6.8.6.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T6.8.6.1.m1.1a"><mi mathvariant="normal" id="S4.T6.8.6.1.m1.1.1" xref="S4.T6.8.6.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T6.8.6.1.m1.1b"><ci id="S4.T6.8.6.1.m1.1.1.cmml" xref="S4.T6.8.6.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.8.6.1.m1.1c">\checkmark</annotation></semantics></math></th>
<th id="S4.T6.13.11.7" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T6.9.7.2" class="ltx_td ltx_align_right"><math id="S4.T6.9.7.2.m1.1" class="ltx_Math" alttext="65.99" display="inline"><semantics id="S4.T6.9.7.2.m1.1a"><mn id="S4.T6.9.7.2.m1.1.1" xref="S4.T6.9.7.2.m1.1.1.cmml">65.99</mn><annotation-xml encoding="MathML-Content" id="S4.T6.9.7.2.m1.1b"><cn type="float" id="S4.T6.9.7.2.m1.1.1.cmml" xref="S4.T6.9.7.2.m1.1.1">65.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.9.7.2.m1.1c">65.99</annotation></semantics></math></td>
<td id="S4.T6.10.8.3" class="ltx_td ltx_align_right"><math id="S4.T6.10.8.3.m1.1" class="ltx_Math" alttext="13.05" display="inline"><semantics id="S4.T6.10.8.3.m1.1a"><mn id="S4.T6.10.8.3.m1.1.1" xref="S4.T6.10.8.3.m1.1.1.cmml">13.05</mn><annotation-xml encoding="MathML-Content" id="S4.T6.10.8.3.m1.1b"><cn type="float" id="S4.T6.10.8.3.m1.1.1.cmml" xref="S4.T6.10.8.3.m1.1.1">13.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.10.8.3.m1.1c">13.05</annotation></semantics></math></td>
<td id="S4.T6.11.9.4" class="ltx_td ltx_align_right"><math id="S4.T6.11.9.4.m1.1" class="ltx_Math" alttext="6\,428" display="inline"><semantics id="S4.T6.11.9.4.m1.1a"><mn id="S4.T6.11.9.4.m1.1.1" xref="S4.T6.11.9.4.m1.1.1.cmml">6 428</mn><annotation-xml encoding="MathML-Content" id="S4.T6.11.9.4.m1.1b"><cn type="integer" id="S4.T6.11.9.4.m1.1.1.cmml" xref="S4.T6.11.9.4.m1.1.1">6428</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.11.9.4.m1.1c">6\,428</annotation></semantics></math></td>
<td id="S4.T6.12.10.5" class="ltx_td ltx_align_right"><math id="S4.T6.12.10.5.m1.1" class="ltx_Math" alttext="6\,932" display="inline"><semantics id="S4.T6.12.10.5.m1.1a"><mn id="S4.T6.12.10.5.m1.1.1" xref="S4.T6.12.10.5.m1.1.1.cmml">6 932</mn><annotation-xml encoding="MathML-Content" id="S4.T6.12.10.5.m1.1b"><cn type="integer" id="S4.T6.12.10.5.m1.1.1.cmml" xref="S4.T6.12.10.5.m1.1.1">6932</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.12.10.5.m1.1c">6\,932</annotation></semantics></math></td>
<td id="S4.T6.13.11.6" class="ltx_td ltx_align_right"><math id="S4.T6.13.11.6.m1.1" class="ltx_Math" alttext="10\,828" display="inline"><semantics id="S4.T6.13.11.6.m1.1a"><mn id="S4.T6.13.11.6.m1.1.1" xref="S4.T6.13.11.6.m1.1.1.cmml">10 828</mn><annotation-xml encoding="MathML-Content" id="S4.T6.13.11.6.m1.1b"><cn type="integer" id="S4.T6.13.11.6.m1.1.1.cmml" xref="S4.T6.13.11.6.m1.1.1">10828</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.13.11.6.m1.1c">10\,828</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.20.18" class="ltx_tr">
<th id="S4.T6.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T6.14.12.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T6.14.12.1.m1.1a"><mi mathvariant="normal" id="S4.T6.14.12.1.m1.1.1" xref="S4.T6.14.12.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T6.14.12.1.m1.1b"><ci id="S4.T6.14.12.1.m1.1.1.cmml" xref="S4.T6.14.12.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.14.12.1.m1.1c">\checkmark</annotation></semantics></math></th>
<th id="S4.T6.15.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T6.15.13.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T6.15.13.2.m1.1a"><mi mathvariant="normal" id="S4.T6.15.13.2.m1.1.1" xref="S4.T6.15.13.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T6.15.13.2.m1.1b"><ci id="S4.T6.15.13.2.m1.1.1.cmml" xref="S4.T6.15.13.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.15.13.2.m1.1c">\checkmark</annotation></semantics></math></th>
<td id="S4.T6.16.14.3" class="ltx_td ltx_align_right"><math id="S4.T6.16.14.3.m1.1" class="ltx_Math" alttext="21.46" display="inline"><semantics id="S4.T6.16.14.3.m1.1a"><mn id="S4.T6.16.14.3.m1.1.1" xref="S4.T6.16.14.3.m1.1.1.cmml">21.46</mn><annotation-xml encoding="MathML-Content" id="S4.T6.16.14.3.m1.1b"><cn type="float" id="S4.T6.16.14.3.m1.1.1.cmml" xref="S4.T6.16.14.3.m1.1.1">21.46</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.16.14.3.m1.1c">21.46</annotation></semantics></math></td>
<td id="S4.T6.17.15.4" class="ltx_td ltx_align_right"><math id="S4.T6.17.15.4.m1.1" class="ltx_Math" alttext="11.37" display="inline"><semantics id="S4.T6.17.15.4.m1.1a"><mn id="S4.T6.17.15.4.m1.1.1" xref="S4.T6.17.15.4.m1.1.1.cmml">11.37</mn><annotation-xml encoding="MathML-Content" id="S4.T6.17.15.4.m1.1b"><cn type="float" id="S4.T6.17.15.4.m1.1.1.cmml" xref="S4.T6.17.15.4.m1.1.1">11.37</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.17.15.4.m1.1c">11.37</annotation></semantics></math></td>
<td id="S4.T6.18.16.5" class="ltx_td ltx_align_right"><math id="S4.T6.18.16.5.m1.1" class="ltx_Math" alttext="5\,991" display="inline"><semantics id="S4.T6.18.16.5.m1.1a"><mn id="S4.T6.18.16.5.m1.1.1" xref="S4.T6.18.16.5.m1.1.1.cmml">5 991</mn><annotation-xml encoding="MathML-Content" id="S4.T6.18.16.5.m1.1b"><cn type="integer" id="S4.T6.18.16.5.m1.1.1.cmml" xref="S4.T6.18.16.5.m1.1.1">5991</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.18.16.5.m1.1c">5\,991</annotation></semantics></math></td>
<td id="S4.T6.19.17.6" class="ltx_td ltx_align_right"><math id="S4.T6.19.17.6.m1.1" class="ltx_Math" alttext="6\,068" display="inline"><semantics id="S4.T6.19.17.6.m1.1a"><mn id="S4.T6.19.17.6.m1.1.1" xref="S4.T6.19.17.6.m1.1.1.cmml">6 068</mn><annotation-xml encoding="MathML-Content" id="S4.T6.19.17.6.m1.1b"><cn type="integer" id="S4.T6.19.17.6.m1.1.1.cmml" xref="S4.T6.19.17.6.m1.1.1">6068</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.19.17.6.m1.1c">6\,068</annotation></semantics></math></td>
<td id="S4.T6.20.18.7" class="ltx_td ltx_align_right"><math id="S4.T6.20.18.7.m1.1" class="ltx_Math" alttext="9\,014" display="inline"><semantics id="S4.T6.20.18.7.m1.1a"><mn id="S4.T6.20.18.7.m1.1.1" xref="S4.T6.20.18.7.m1.1.1.cmml">9 014</mn><annotation-xml encoding="MathML-Content" id="S4.T6.20.18.7.m1.1b"><cn type="integer" id="S4.T6.20.18.7.m1.1.1.cmml" xref="S4.T6.20.18.7.m1.1.1">9014</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.20.18.7.m1.1c">9\,014</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.25.23" class="ltx_tr">
<th id="S4.T6.25.23.6" class="ltx_td ltx_align_left ltx_th ltx_th_row">✗</th>
<th id="S4.T6.25.23.7" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T6.21.19.1" class="ltx_td ltx_align_right"><math id="S4.T6.21.19.1.m1.1" class="ltx_Math" alttext="72.47" display="inline"><semantics id="S4.T6.21.19.1.m1.1a"><mn id="S4.T6.21.19.1.m1.1.1" xref="S4.T6.21.19.1.m1.1.1.cmml">72.47</mn><annotation-xml encoding="MathML-Content" id="S4.T6.21.19.1.m1.1b"><cn type="float" id="S4.T6.21.19.1.m1.1.1.cmml" xref="S4.T6.21.19.1.m1.1.1">72.47</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.21.19.1.m1.1c">72.47</annotation></semantics></math></td>
<td id="S4.T6.22.20.2" class="ltx_td ltx_align_right"><math id="S4.T6.22.20.2.m1.1" class="ltx_Math" alttext="16.69" display="inline"><semantics id="S4.T6.22.20.2.m1.1a"><mn id="S4.T6.22.20.2.m1.1.1" xref="S4.T6.22.20.2.m1.1.1.cmml">16.69</mn><annotation-xml encoding="MathML-Content" id="S4.T6.22.20.2.m1.1b"><cn type="float" id="S4.T6.22.20.2.m1.1.1.cmml" xref="S4.T6.22.20.2.m1.1.1">16.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.22.20.2.m1.1c">16.69</annotation></semantics></math></td>
<td id="S4.T6.23.21.3" class="ltx_td ltx_align_right"><math id="S4.T6.23.21.3.m1.1" class="ltx_Math" alttext="64\,32" display="inline"><semantics id="S4.T6.23.21.3.m1.1a"><mn id="S4.T6.23.21.3.m1.1.1" xref="S4.T6.23.21.3.m1.1.1.cmml">64 32</mn><annotation-xml encoding="MathML-Content" id="S4.T6.23.21.3.m1.1b"><cn type="integer" id="S4.T6.23.21.3.m1.1.1.cmml" xref="S4.T6.23.21.3.m1.1.1">6432</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.23.21.3.m1.1c">64\,32</annotation></semantics></math></td>
<td id="S4.T6.24.22.4" class="ltx_td ltx_align_right"><math id="S4.T6.24.22.4.m1.1" class="ltx_Math" alttext="12\,621" display="inline"><semantics id="S4.T6.24.22.4.m1.1a"><mn id="S4.T6.24.22.4.m1.1.1" xref="S4.T6.24.22.4.m1.1.1.cmml">12 621</mn><annotation-xml encoding="MathML-Content" id="S4.T6.24.22.4.m1.1b"><cn type="integer" id="S4.T6.24.22.4.m1.1.1.cmml" xref="S4.T6.24.22.4.m1.1.1">12621</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.24.22.4.m1.1c">12\,621</annotation></semantics></math></td>
<td id="S4.T6.25.23.5" class="ltx_td ltx_align_right"><math id="S4.T6.25.23.5.m1.1" class="ltx_Math" alttext="11\,886" display="inline"><semantics id="S4.T6.25.23.5.m1.1a"><mn id="S4.T6.25.23.5.m1.1.1" xref="S4.T6.25.23.5.m1.1.1.cmml">11 886</mn><annotation-xml encoding="MathML-Content" id="S4.T6.25.23.5.m1.1b"><cn type="integer" id="S4.T6.25.23.5.m1.1.1.cmml" xref="S4.T6.25.23.5.m1.1.1">11886</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.25.23.5.m1.1c">11\,886</annotation></semantics></math></td>
</tr>
<tr id="S4.T6.31.29" class="ltx_tr">
<th id="S4.T6.31.29.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">✗</th>
<th id="S4.T6.26.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><math id="S4.T6.26.24.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T6.26.24.1.m1.1a"><mi mathvariant="normal" id="S4.T6.26.24.1.m1.1.1" xref="S4.T6.26.24.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T6.26.24.1.m1.1b"><ci id="S4.T6.26.24.1.m1.1.1.cmml" xref="S4.T6.26.24.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.26.24.1.m1.1c">\checkmark</annotation></semantics></math></th>
<td id="S4.T6.27.25.2" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T6.27.25.2.m1.1" class="ltx_Math" alttext="18.62" display="inline"><semantics id="S4.T6.27.25.2.m1.1a"><mn id="S4.T6.27.25.2.m1.1.1" xref="S4.T6.27.25.2.m1.1.1.cmml">18.62</mn><annotation-xml encoding="MathML-Content" id="S4.T6.27.25.2.m1.1b"><cn type="float" id="S4.T6.27.25.2.m1.1.1.cmml" xref="S4.T6.27.25.2.m1.1.1">18.62</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.27.25.2.m1.1c">18.62</annotation></semantics></math></td>
<td id="S4.T6.28.26.3" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T6.28.26.3.m1.1" class="ltx_Math" alttext="11.65" display="inline"><semantics id="S4.T6.28.26.3.m1.1a"><mn id="S4.T6.28.26.3.m1.1.1" xref="S4.T6.28.26.3.m1.1.1.cmml">11.65</mn><annotation-xml encoding="MathML-Content" id="S4.T6.28.26.3.m1.1b"><cn type="float" id="S4.T6.28.26.3.m1.1.1.cmml" xref="S4.T6.28.26.3.m1.1.1">11.65</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.28.26.3.m1.1c">11.65</annotation></semantics></math></td>
<td id="S4.T6.29.27.4" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T6.29.27.4.m1.1" class="ltx_Math" alttext="6\,556" display="inline"><semantics id="S4.T6.29.27.4.m1.1a"><mn id="S4.T6.29.27.4.m1.1.1" xref="S4.T6.29.27.4.m1.1.1.cmml">6 556</mn><annotation-xml encoding="MathML-Content" id="S4.T6.29.27.4.m1.1b"><cn type="integer" id="S4.T6.29.27.4.m1.1.1.cmml" xref="S4.T6.29.27.4.m1.1.1">6556</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.29.27.4.m1.1c">6\,556</annotation></semantics></math></td>
<td id="S4.T6.30.28.5" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T6.30.28.5.m1.1" class="ltx_Math" alttext="6\,037" display="inline"><semantics id="S4.T6.30.28.5.m1.1a"><mn id="S4.T6.30.28.5.m1.1.1" xref="S4.T6.30.28.5.m1.1.1.cmml">6 037</mn><annotation-xml encoding="MathML-Content" id="S4.T6.30.28.5.m1.1b"><cn type="integer" id="S4.T6.30.28.5.m1.1.1.cmml" xref="S4.T6.30.28.5.m1.1.1">6037</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.30.28.5.m1.1c">6\,037</annotation></semantics></math></td>
<td id="S4.T6.31.29.6" class="ltx_td ltx_align_right ltx_border_bb"><math id="S4.T6.31.29.6.m1.1" class="ltx_Math" alttext="8\,997" display="inline"><semantics id="S4.T6.31.29.6.m1.1a"><mn id="S4.T6.31.29.6.m1.1.1" xref="S4.T6.31.29.6.m1.1.1.cmml">8 997</mn><annotation-xml encoding="MathML-Content" id="S4.T6.31.29.6.m1.1b"><cn type="integer" id="S4.T6.31.29.6.m1.1.1.cmml" xref="S4.T6.31.29.6.m1.1.1">8997</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.31.29.6.m1.1c">8\,997</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS7.p2" class="ltx_para">
<p id="S4.SS7.p2.1" class="ltx_p">Recall that
we added both the YODAS dataset without and with keywords
to mitigate the issue of biasing to ReazonSpeech
for the training dataset with keywords for fine-tuning, which is represented by check marks <math id="S4.SS7.p2.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.SS7.p2.1.m1.1a"><mi mathvariant="normal" id="S4.SS7.p2.1.m1.1.1" xref="S4.SS7.p2.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.SS7.p2.1.m1.1b"><ci id="S4.SS7.p2.1.m1.1.1.cmml" xref="S4.SS7.p2.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p2.1.m1.1c">\checkmark</annotation></semantics></math> at “KW@Train” in
<a href="#S4.T3" title="In 4.6 Results ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tables</span> <span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S4.T4" title="Table 4 ‣ 4.6 Results ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#S4.T6" title="Table 6 ‣ 4.7 Dataset Bias Experiments ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
However, comparing CERs without keywords of PLaMo-100B models in <a href="#S4.T3" title="In 4.6 Results ‣ 4 Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>,
the model fine-tuned without keywords outperformed the model fine-tuned with keywords
on CommonVoice v16.1, LibriSpeech, and YODAS datasets.
We suspect that the size of ReazonSpeech is still much larger than other datasets,
and adding YODAS without keywords was not sufficient to completely solve this issue,
resulting in performance degradation of fine-tuning with keywords
compared to fine-tuning without keywords,
where YODAS without keywords was used twice in a single epoch
to make the train data size equivalent.
We suggest diversifying the training data as much as possible
if the goal is to train generalized ASR systems that can take prior texts via prompts.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We constructed an ASR system based on an in-house LLM PLaMo-100B
combined with the Whisper large-v3 encoder.
By contextualizing the LLM-based decoder
using keywords directly as prior information in the text prompt,
we showed that recognition performance for keywords
that did not appear in the train set
improved significantly in correcting pronunciations and selecting homonyms.
In future work,
training our models using more data, including other tasks and languages, is a promising direction to bring out the potential of our pre-trained LLMs.</p>
</div>
<section id="S5.SS0.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Author Contributions</h4>

<div id="S5.SS0.SSSx1.p1" class="ltx_para">
<p id="S5.SS0.SSSx1.p1.1" class="ltx_p">Kento Nozawa implemented a training and evaluation pipeline,
conducted numerical experiments,
and drafted the manuscript.
Takashi Masuko constructed all datasets and extracted their keywords,
implemented keywords error evaluation,
and wrote the manuscript.
Toru Taniguchi prototyped and supported training and evaluation pipelines,
revised the manuscript,
and managed this project.</p>
</div>
</section>
<section id="S5.SS0.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Acknowledgments</h4>

<div id="S5.SS0.SSSx2.p1" class="ltx_para">
<p id="S5.SS0.SSSx2.p1.1" class="ltx_p">This paper is based on results obtained from the project, “Research and Development Project of the Enhanced Infrastructures for Post 5G Information and Communication System” (JPNP 20017), subsidized by the New Energy and Industrial Technology Development Organization (NEDO).</p>
</div>
<div id="S5.SS0.SSSx2.p2" class="ltx_para">
<p id="S5.SS0.SSSx2.p2.1" class="ltx_p">We would like to thank (ex-) PFN/PFE members, especially Daiki Higurashi, Linsho Kaku, Toshiki Kataoka, Hiroaki Mikami, Shintarou Okada, Daisuke Okanohara, Shuji Suzuki, Seiya Tokui, Zijian Xu, and Shoichiro Yamaguchi, for their helpful discussions and/or implementation support; Toshihiko Yanase, Yuta Hirokawa, and Toru Komatsu for infrastructure-related support.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ansel et al. (2024)</span>
<span class="ltx_bibblock">
Jason Ansel, Edward Yang, Horace He, Natalia Gimelshein, Animesh Jain, Michael Voznesensky, Bin Bao, Peter Bell, David Berard, Evgeni Burovski, Geeta Chauhan, Anjali Chourdia, Will Constable, Alban Desmaison, Zachary DeVito, Elias Ellison, Will Feng, Jiong Gong, Michael Gschwind, Brian Hirsh, Sherlock Huang, Kshiteej Kalambarkar, Laurent Kirsch, Michael Lazos, Mario Lezcano, Yanbo Liang, Jason Liang, Yinghai Lu, C. K. Luk, Bert Maher, Yunjie Pan, Christian Puhrsch, Matthias Reso, Mark Saroufim, Marcos Yukio Siraichi, Helen Suk, Shunting Zhang, Michael Suo, Phil Tillet, Xu Zhao, Eikan Wang, Keren Zhou, Richard Zou, Xiaodong Wang, Ajit Mathews, William Wen, Gregory Chanan, Peng Wu, and Soumith Chintala.

</span>
<span class="ltx_bibblock">PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">ASPLOS</em>, pages 929–947, 2024.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ardila et al. (2020)</span>
<span class="ltx_bibblock">
Rosana Ardila, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael Henretty, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber.

</span>
<span class="ltx_bibblock">Common Voice: A Massively-Multilingual Speech Corpus.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">LREC</em>, pages 4218–4222, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biewald (2020)</span>
<span class="ltx_bibblock">
Lukas Biewald.

</span>
<span class="ltx_bibblock">Experiment Tracking with Weights and Biases, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.wandb.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.wandb.com/</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam Mccandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, pages 1877–1901, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et al. (2023)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.

</span>
<span class="ltx_bibblock">PaLM: Scaling Language Modeling with Pathways.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, pages 1–113, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chu et al. (2024)</span>
<span class="ltx_bibblock">
Yunfei Chu, Jin Xu, Qian Yang, Haojie Wei, Xipin Wei, Zhifang Guo, Yichong Leng, Yuanjun Lv, Jinzheng He, Junyang Lin, Chang Zhou, and Jingren Zhou.

</span>
<span class="ltx_bibblock">Qwen2-Audio Technical Report, 2024.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2407.10759v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2407.10759v1</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al. (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">QLoRA: Efficient Finetuning of Quantized LLMs.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, pages 10088–10115, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">NAACL-HLT</em>, pages 4171–4186, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al. (2022)</span>
<span class="ltx_bibblock">
Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, Jing Yi, Weilin Zhao, Xiaozhi Wang, Zhiyuan Liu, Hai-Tao Zheng, Jianfei Chen, Yang Liu, Jie Tang, Juanzi Li, and Maosong Sun.

</span>
<span class="ltx_bibblock">Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2203.06904v2" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2203.06904v2</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fathullah et al. (2024)</span>
<span class="ltx_bibblock">
Yassir Fathullah, Chunyang Wu, Egor Lakomkin, Junteng Jia, Yuan Shangguan, Ke Li, Jinxi Guo, Wenhan Xiong, Jay Mahadeokar, Ozlem Kalinli, Christian Fuegen, and Mike Seltzer.

</span>
<span class="ltx_bibblock">Prompting Large Language Models with Speech Recognition Abilities.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 13351–13355, 2024.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fujii et al. (2024)</span>
<span class="ltx_bibblock">
Kazuki Fujii, Taishi Nakamura, Mengsay Loem, Hiroki Iida, Masanari Ohi, Kakeru Hattori, Hirai Shota, Sakae Mizuki, Rio Yokota, and Naoaki Okazaki.

</span>
<span class="ltx_bibblock">Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities, 2024.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2404.17790v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2404.17790v1</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffer et al. (2017)</span>
<span class="ltx_bibblock">
Elad Hoffer, Itay Hubara, and Daniel Soudry.

</span>
<span class="ltx_bibblock">Train Longer, Generalize Better: Closing the Generalization Gap in Large Batch Training of Neural Networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, pages 1731–1741, 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2022.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hwang et al. (2023)</span>
<span class="ltx_bibblock">
Jeff Hwang, Moto Hira, Caroline Chen, Xiaohui Zhang, Zhaoheng Ni, Guangzhi Sun, Pingchuan Ma, Ruizhe Huang, Vineel Pratap, Yuekai Zhang, Anurag Kumar, Chin-Yun Yu, Chuang Zhu, Chunxi Liu, Jacob Kahn, Mirco Ravanelli, Peng Sun, Shinji Watanabe, Yangyang Shi, Yumeng Tao, Robin Scheibler, Samuele Cornell, Sean Kim, and Stavros Petridis.

</span>
<span class="ltx_bibblock">TorchAudio 2.1: Advancing Speech Recognition, Self-supervised Learning, and Audio Processing Components for PyTorch, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2310.17864v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2310.17864v1</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et al. (2020)</span>
<span class="ltx_bibblock">
Mahaveer Jain, Gil Keren, Jay Mahadeokar, Geoffrey Zweig, Florian Metze, and Yatharth Saraf.

</span>
<span class="ltx_bibblock">Contextual RNN-T for Open Domain ASR, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2006.03411v2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2006.03411v2</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et al. (2020)</span>
<span class="ltx_bibblock">
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.

</span>
<span class="ltx_bibblock">Scaling Laws for Neural Language Models, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2001.08361v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2001.08361v1</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lakomkin et al. (2024)</span>
<span class="ltx_bibblock">
Egor Lakomkin, Chunyang Wu, Yassir Fathullah, Ozlem Kalinli, Michael L. Seltzer, and Christian Fuegen.

</span>
<span class="ltx_bibblock">End-to-end Speech Recognition Contextualization with Large Language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 12406–12410, 2024.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Latif et al. (2023)</span>
<span class="ltx_bibblock">
Siddique Latif, Moazzam Shoukat, Fahad Shamshad, Muhammad Usama, Yi Ren, Heriberto Cuayáhuitl, Wenwu Wang, Xulong Zhang, Roberto Togneri, Erik Cambria, and Björn W. Schuller.

</span>
<span class="ltx_bibblock">Sparks of Large Audio Models: A Survey and Outlook, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2308.12792v3" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2308.12792v3</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le et al. (2021)</span>
<span class="ltx_bibblock">
Duc Le, Mahaveer Jain, Gil Keren, Suyoun Kim, Yangyang Shi, Jay Mahadeokar, Julian Chan, Yuan Shangguan, Christian Fuegen, Ozlem Kalinli, Yatharth Saraf, and Michael L. Seltzer.

</span>
<span class="ltx_bibblock">Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">INTRESPEECH</em>, pages 1772–1776, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Shen Li, Yanli Zhao, Rohan Varma, Omkar Salpekar, Pieter Noordhuis, Teng Li, Adam Paszke, Jeff Smith, Brian Vaughan, Pritam Damania, and Soumith Chintala.

</span>
<span class="ltx_bibblock">PyTorch Distributed: Experiences on Accelerating Data Parallel Training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">VLDB</em>, pages 3005–3018, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Xinjian Li, Shinnosuke Takamichi, Takaaki Saeki, William Chen, Sayaka Shiota, and Shinji Watanabe.

</span>
<span class="ltx_bibblock">YODAS: Youtube-Oriented Dataset for Audio and Speech.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ASRU</em>, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Llama Team, AI @ Meta (2024)</span>
<span class="ltx_bibblock">
Llama Team, AI @ Meta.

</span>
<span class="ltx_bibblock">The Llama 3 Herd of Models, 2024.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2407.21783v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2407.21783v1</a>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2017)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">SGDR: Stochastic Gradient Descent with Warm Restarts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2017.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2019)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled Weight Decay Regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mangrulkar et al. (2022)</span>
<span class="ltx_bibblock">
Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Benjamin Bossan.

</span>
<span class="ltx_bibblock">PEFT: State-of-the-art Parameter-Efficient Fine-Tuning Methods.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/huggingface/peft" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/peft</a>, 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Morishita et al. (2017)</span>
<span class="ltx_bibblock">
Makoto Morishita, Yusuke Oda, Graham Neubig, Koichiro Yoshino, Katsuhito Sudoh, and Satoshi Nakamura.

</span>
<span class="ltx_bibblock">An Empirical Study of Mini-Batch Creation Strategies for Neural Machine Translation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Workshop on Neural Machine Translation</em>, pages 61–68, 2017.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panayotov et al. (2015)</span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">LibriSpeech: An ASR Corpus based on Public Domain Audio Books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, pages 5206–5210, 2015.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pundak et al. (2018)</span>
<span class="ltx_bibblock">
Golan Pundak, Tara N. Sainath, Rohit Prabhavalkar, Anjuli Kannan, and Ding Zhao.

</span>
<span class="ltx_bibblock">Deep Context: End-to-end Contextual Speech Recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">SLT</em>, pages 418–425, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2022)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Robust Speech Recognition via Large-Scale Weak Supervision, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2212.04356v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2212.04356v1</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rubenstein et al. (2023)</span>
<span class="ltx_bibblock">
Paul K. Rubenstein, Chulayuth Asawaroengchai, Duc Dung Nguyen, Ankur Bapna, Zalán Borsos, Félix de Chaumont Quitry, Peter Chen, Dalia El Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, Dirk Padfield, James Qin, Danny Rozenberg, Tara Sainath, Johan Schalkwyk, Matt Sharifi, Michelle Tadmor Ramanovich, Marco Tagliasacchi, Alexandru Tudor, Mihajlo Velimirović, Damien Vincent, Jiahui Yu, Yongqiang Wang, Vicky Zayats, Neil Zeghidour, Yu Zhang, Zhishuai Zhang, Lukas Zilka, and Christian Frank.

</span>
<span class="ltx_bibblock">AudioPaLM: A Large Language Model That Can Speak and Listen, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2306.12925v1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2306.12925v1</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shu et al. (2023)</span>
<span class="ltx_bibblock">
Yu Shu, Siwei Dong, Guangyao Chen, Wenhao Huang, Ruihua Zhang, Daochen Shi, Qiqi Xiang, and Yemin Shi.

</span>
<span class="ltx_bibblock">LLaSM: Large Language and Speech Model, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2308.15930v3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2308.15930v3</a>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al. (2014)</span>
<span class="ltx_bibblock">
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, and Ruslan Salakhutdinov.

</span>
<span class="ltx_bibblock">Dropout: A Simple Way to Prevent Neural Networks from Overfitting.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 15:1929–1958, 2014.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">The Pandas Development Team (2020)</span>
<span class="ltx_bibblock">
The Pandas Development Team.

</span>
<span class="ltx_bibblock">pandas-dev/pandas: Pandas, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.5281/zenodo.3509134" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.3509134</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2307.09288v2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2307.09288v2</a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention Is All You Need.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, pages 5998–6008, 2017.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le.

</span>
<span class="ltx_bibblock">Finetuned Language Models are Zero-Shot Learners.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et al. (2020)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-Art Natural Language Processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">EMNLP: System Demonstrations</em>, pages 38–45, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wortsman et al. (2023)</span>
<span class="ltx_bibblock">
Mitchell Wortsman, Tim Dettmers, Luke Zettlemoyer, Ari Morcos, Ali Farhadi, and Ludwig Schmidt.

</span>
<span class="ltx_bibblock">Stable and Low-precision Training for Large-scale Vision-language Models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, pages 10271–10298, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Jian Wu, Yashesh Gaur, Zhuo Chen, Long Zhou, Yimeng Zhu, Tianrui Wang, Jinyu Li, Shujie Liu, Bo Ren, Linquan Liu, and Yu Wu.

</span>
<span class="ltx_bibblock">On Decoder-only Architecture for Speech-to-text and Large Language Model Integration.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">ASRU</em>, pages 1–8, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2023)</span>
<span class="ltx_bibblock">
Yue Yin, Daijiro Mori, and Seiji Fujimoto.

</span>
<span class="ltx_bibblock">ReazonSpeech: A Free and Massive Corpus for Japanese ASR.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">NLP</em>, pages 1134–1139, 2023.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, and Xipeng Qiu.

</span>
<span class="ltx_bibblock">SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2305.11000v2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2305.11000v2</a>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2019)</span>
<span class="ltx_bibblock">
Ding Zhao, Tara N. Sainath, David Rybach, Pat Rondon, Deepti Bhatia, Bo Li, and Ruoming Pang.

</span>
<span class="ltx_bibblock">Shallow-Fusion End-to-End Contextual Biasing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, pages 1418–1422, 2019.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Japanese Prompt</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">We used the following prompt for Japanese datasets:</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p ltx_align_center"><span id="A1.p2.1.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">&lt;bos&gt;[audio embeddings] 言語：ja； キーワード：[keywords]； 書き起こし： [transcription]&lt;eos&gt;<span id="A1.p2.1.1.1" class="ltx_text ltx_font_serif">,</span></span></p>
</div>
<div id="A1.p3" class="ltx_para">
<p id="A1.p3.1" class="ltx_p">where an example of keywords is “<span id="A1.p3.1.1" class="ltx_text ltx_font_typewriter">東京、機械学習</span>” and use “<span id="A1.p3.1.2" class="ltx_text ltx_font_typewriter">なし</span>” if keywords are unavailable.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Details of Experiments</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p"><a href="#A2.T7" title="In Appendix B Details of Experiments ‣ Enhancing Large Language Model-based Speech Recognition by Contextualization for Rare and Ambiguous Words" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">7</span></a> shows the max token length of dev sets using corresponding tokenizers.
Note that the numbers included the special token’s length, specifically, the single end of the token.</p>
</div>
<figure id="A2.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>
Max token lengths of transcriptions for dev sets.
</figcaption>
<table id="A2.T7.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A2.T7.12.13.1" class="ltx_tr">
<th id="A2.T7.12.13.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="A2.T7.12.13.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">CommonVoice v8.0</th>
<th id="A2.T7.12.13.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">CommonVoice v16.1</th>
<th id="A2.T7.12.13.1.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">LibriSpeech</th>
<th id="A2.T7.12.13.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">YODAS</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A2.T7.4.4" class="ltx_tr">
<th id="A2.T7.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">PLaMo</th>
<td id="A2.T7.1.1.1" class="ltx_td ltx_align_right ltx_border_t"><math id="A2.T7.1.1.1.m1.1" class="ltx_Math" alttext="51" display="inline"><semantics id="A2.T7.1.1.1.m1.1a"><mn id="A2.T7.1.1.1.m1.1.1" xref="A2.T7.1.1.1.m1.1.1.cmml">51</mn><annotation-xml encoding="MathML-Content" id="A2.T7.1.1.1.m1.1b"><cn type="integer" id="A2.T7.1.1.1.m1.1.1.cmml" xref="A2.T7.1.1.1.m1.1.1">51</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.1.1.1.m1.1c">51</annotation></semantics></math></td>
<td id="A2.T7.2.2.2" class="ltx_td ltx_align_right ltx_border_t"><math id="A2.T7.2.2.2.m1.1" class="ltx_Math" alttext="54" display="inline"><semantics id="A2.T7.2.2.2.m1.1a"><mn id="A2.T7.2.2.2.m1.1.1" xref="A2.T7.2.2.2.m1.1.1.cmml">54</mn><annotation-xml encoding="MathML-Content" id="A2.T7.2.2.2.m1.1b"><cn type="integer" id="A2.T7.2.2.2.m1.1.1.cmml" xref="A2.T7.2.2.2.m1.1.1">54</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.2.2.2.m1.1c">54</annotation></semantics></math></td>
<td id="A2.T7.3.3.3" class="ltx_td ltx_align_right ltx_border_t"><math id="A2.T7.3.3.3.m1.1" class="ltx_Math" alttext="122" display="inline"><semantics id="A2.T7.3.3.3.m1.1a"><mn id="A2.T7.3.3.3.m1.1.1" xref="A2.T7.3.3.3.m1.1.1.cmml">122</mn><annotation-xml encoding="MathML-Content" id="A2.T7.3.3.3.m1.1b"><cn type="integer" id="A2.T7.3.3.3.m1.1.1.cmml" xref="A2.T7.3.3.3.m1.1.1">122</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.3.3.3.m1.1c">122</annotation></semantics></math></td>
<td id="A2.T7.4.4.4" class="ltx_td ltx_align_right ltx_border_t"><math id="A2.T7.4.4.4.m1.1" class="ltx_Math" alttext="61" display="inline"><semantics id="A2.T7.4.4.4.m1.1a"><mn id="A2.T7.4.4.4.m1.1.1" xref="A2.T7.4.4.4.m1.1.1.cmml">61</mn><annotation-xml encoding="MathML-Content" id="A2.T7.4.4.4.m1.1b"><cn type="integer" id="A2.T7.4.4.4.m1.1.1.cmml" xref="A2.T7.4.4.4.m1.1.1">61</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.4.4.4.m1.1c">61</annotation></semantics></math></td>
</tr>
<tr id="A2.T7.8.8" class="ltx_tr">
<th id="A2.T7.8.8.5" class="ltx_td ltx_align_left ltx_th ltx_th_row">Swallow</th>
<td id="A2.T7.5.5.1" class="ltx_td ltx_align_right"><math id="A2.T7.5.5.1.m1.1" class="ltx_Math" alttext="52" display="inline"><semantics id="A2.T7.5.5.1.m1.1a"><mn id="A2.T7.5.5.1.m1.1.1" xref="A2.T7.5.5.1.m1.1.1.cmml">52</mn><annotation-xml encoding="MathML-Content" id="A2.T7.5.5.1.m1.1b"><cn type="integer" id="A2.T7.5.5.1.m1.1.1.cmml" xref="A2.T7.5.5.1.m1.1.1">52</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.5.5.1.m1.1c">52</annotation></semantics></math></td>
<td id="A2.T7.6.6.2" class="ltx_td ltx_align_right"><math id="A2.T7.6.6.2.m1.1" class="ltx_Math" alttext="54" display="inline"><semantics id="A2.T7.6.6.2.m1.1a"><mn id="A2.T7.6.6.2.m1.1.1" xref="A2.T7.6.6.2.m1.1.1.cmml">54</mn><annotation-xml encoding="MathML-Content" id="A2.T7.6.6.2.m1.1b"><cn type="integer" id="A2.T7.6.6.2.m1.1.1.cmml" xref="A2.T7.6.6.2.m1.1.1">54</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.6.6.2.m1.1c">54</annotation></semantics></math></td>
<td id="A2.T7.7.7.3" class="ltx_td ltx_align_right"><math id="A2.T7.7.7.3.m1.1" class="ltx_Math" alttext="132" display="inline"><semantics id="A2.T7.7.7.3.m1.1a"><mn id="A2.T7.7.7.3.m1.1.1" xref="A2.T7.7.7.3.m1.1.1.cmml">132</mn><annotation-xml encoding="MathML-Content" id="A2.T7.7.7.3.m1.1b"><cn type="integer" id="A2.T7.7.7.3.m1.1.1.cmml" xref="A2.T7.7.7.3.m1.1.1">132</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.7.7.3.m1.1c">132</annotation></semantics></math></td>
<td id="A2.T7.8.8.4" class="ltx_td ltx_align_right"><math id="A2.T7.8.8.4.m1.1" class="ltx_Math" alttext="62" display="inline"><semantics id="A2.T7.8.8.4.m1.1a"><mn id="A2.T7.8.8.4.m1.1.1" xref="A2.T7.8.8.4.m1.1.1.cmml">62</mn><annotation-xml encoding="MathML-Content" id="A2.T7.8.8.4.m1.1b"><cn type="integer" id="A2.T7.8.8.4.m1.1.1.cmml" xref="A2.T7.8.8.4.m1.1.1">62</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.8.8.4.m1.1c">62</annotation></semantics></math></td>
</tr>
<tr id="A2.T7.12.12" class="ltx_tr">
<th id="A2.T7.12.12.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Whisper</th>
<td id="A2.T7.9.9.1" class="ltx_td ltx_align_right ltx_border_bb"><math id="A2.T7.9.9.1.m1.1" class="ltx_Math" alttext="60" display="inline"><semantics id="A2.T7.9.9.1.m1.1a"><mn id="A2.T7.9.9.1.m1.1.1" xref="A2.T7.9.9.1.m1.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="A2.T7.9.9.1.m1.1b"><cn type="integer" id="A2.T7.9.9.1.m1.1.1.cmml" xref="A2.T7.9.9.1.m1.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.9.9.1.m1.1c">60</annotation></semantics></math></td>
<td id="A2.T7.10.10.2" class="ltx_td ltx_align_right ltx_border_bb"><math id="A2.T7.10.10.2.m1.1" class="ltx_Math" alttext="69" display="inline"><semantics id="A2.T7.10.10.2.m1.1a"><mn id="A2.T7.10.10.2.m1.1.1" xref="A2.T7.10.10.2.m1.1.1.cmml">69</mn><annotation-xml encoding="MathML-Content" id="A2.T7.10.10.2.m1.1b"><cn type="integer" id="A2.T7.10.10.2.m1.1.1.cmml" xref="A2.T7.10.10.2.m1.1.1">69</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.10.10.2.m1.1c">69</annotation></semantics></math></td>
<td id="A2.T7.11.11.3" class="ltx_td ltx_align_right ltx_border_bb"><math id="A2.T7.11.11.3.m1.1" class="ltx_Math" alttext="117" display="inline"><semantics id="A2.T7.11.11.3.m1.1a"><mn id="A2.T7.11.11.3.m1.1.1" xref="A2.T7.11.11.3.m1.1.1.cmml">117</mn><annotation-xml encoding="MathML-Content" id="A2.T7.11.11.3.m1.1b"><cn type="integer" id="A2.T7.11.11.3.m1.1.1.cmml" xref="A2.T7.11.11.3.m1.1.1">117</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.11.11.3.m1.1c">117</annotation></semantics></math></td>
<td id="A2.T7.12.12.4" class="ltx_td ltx_align_right ltx_border_bb"><math id="A2.T7.12.12.4.m1.1" class="ltx_Math" alttext="71" display="inline"><semantics id="A2.T7.12.12.4.m1.1a"><mn id="A2.T7.12.12.4.m1.1.1" xref="A2.T7.12.12.4.m1.1.1.cmml">71</mn><annotation-xml encoding="MathML-Content" id="A2.T7.12.12.4.m1.1b"><cn type="integer" id="A2.T7.12.12.4.m1.1.1.cmml" xref="A2.T7.12.12.4.m1.1.1">71</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T7.12.12.4.m1.1c">71</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Attempts to Stabilize Fine-tuning</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">In our preliminary experiments, we sometimes encountered loss spikes during the fine-tuning that caused severe ASR performance degradation.
We share our attempts to resolve these loss spikes below.</p>
</div>
<section id="A2.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Mini-batch creation</h5>

<div id="A2.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="A2.SS1.SSS0.Px1.p1.1" class="ltx_p">We attempted to accelerate the training speed by using length-grouped mini-batches implemented by <span id="A2.SS1.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">transformer<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note"><span id="footnote11.1.1.1" class="ltx_text ltx_font_serif">11</span></span><a target="_blank" href="https://github.com/huggingface/transformers/blob/v4.43.3/src/transformers/trainer_pt_utils.py#L593-L625" title="" class="ltx_ref ltx_url">https://github.com/huggingface/transformers/blob/v4.43.3/src/transformers/trainer_pt_utils.py#L593-L625</a></span></span></span></span>
to make sure that each mini-batch contains similar sequence lengths.
However, this causes training loss spikes
especially when the length of the sequence largely changes across mini-batches.
By following <cite class="ltx_cite ltx_citemacro_citet">Morishita et al. [<a href="#bib.bib26" title="" class="ltx_ref">2017</a>]</cite>
that conducted similar experiments on neural machine translation with non-transformer models,
we used random shuffling to create mini-batches instead of length grouping.</p>
</div>
</section>
<section id="A2.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Optimizer’s hyper-parameters</h5>

<div id="A2.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="A2.SS1.SSS0.Px2.p1.1" class="ltx_p">Even though we used randomly shuffled mini-batches,
the loss spike made the fine-tuning of PLaMo-100B models unstable.
Similar to experimental configurations
in <cite class="ltx_cite ltx_citemacro_citet">Touvron et al. [<a href="#bib.bib34" title="" class="ltx_ref">2023</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Wortsman et al. [<a href="#bib.bib38" title="" class="ltx_ref">2023</a>]</cite>,
reducing AdamW’s <math id="A2.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\beta_{2}" display="inline"><semantics id="A2.SS1.SSS0.Px2.p1.1.m1.1a"><msub id="A2.SS1.SSS0.Px2.p1.1.m1.1.1" xref="A2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="A2.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="A2.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">β</mi><mn id="A2.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="A2.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="A2.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A2.SS1.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A2.SS1.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="A2.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="A2.SS1.SSS0.Px2.p1.1.m1.1.1.2">𝛽</ci><cn type="integer" id="A2.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="A2.SS1.SSS0.Px2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.SSS0.Px2.p1.1.m1.1c">\beta_{2}</annotation></semantics></math> was effective
in avoiding the loss spikes to fine-tune PLaMo-100B models.</p>
</div>
</section>
<section id="A2.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Auxiliary loss</h5>

<div id="A2.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="A2.SS1.SSS0.Px3.p1.3" class="ltx_p">By following the pre-training of PLaMo-100B,
we also introduced the z-loss <cite class="ltx_cite ltx_citemacro_citep">[Chowdhery et al., <a href="#bib.bib5" title="" class="ltx_ref">2023</a>]</cite> with the coefficient term of <math id="A2.SS1.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="1e^{-4}" display="inline"><semantics id="A2.SS1.SSS0.Px3.p1.1.m1.1a"><mrow id="A2.SS1.SSS0.Px3.p1.1.m1.1.1" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.cmml"><mn id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.2" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.1" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml">​</mo><msup id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml"><mi id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.2" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.cmml"><mo id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3a" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.2" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.SSS0.Px3.p1.1.m1.1b"><apply id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1"><times id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.1"></times><cn type="integer" id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.2">1</cn><apply id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.1.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3">superscript</csymbol><ci id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.2.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.2">𝑒</ci><apply id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3"><minus id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.1.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.2.cmml" xref="A2.SS1.SSS0.Px3.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.SSS0.Px3.p1.1.m1.1c">1e^{-4}</annotation></semantics></math>
as an auxiliary loss to stabilize fine-tuning.
However, loss spikes still happened with AdamW,
whose <math id="A2.SS1.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\beta_{2}=0.999" display="inline"><semantics id="A2.SS1.SSS0.Px3.p1.2.m2.1a"><mrow id="A2.SS1.SSS0.Px3.p1.2.m2.1.1" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.cmml"><msub id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.cmml"><mi id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.2" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.2.cmml">β</mi><mn id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.3" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.1" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.1.cmml">=</mo><mn id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.3" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.3.cmml">0.999</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS1.SSS0.Px3.p1.2.m2.1b"><apply id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.cmml" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1"><eq id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.1"></eq><apply id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.1.cmml" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2">subscript</csymbol><ci id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.2.cmml" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.2">𝛽</ci><cn type="integer" id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.3.cmml" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.2.3">2</cn></apply><cn type="float" id="A2.SS1.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="A2.SS1.SSS0.Px3.p1.2.m2.1.1.3">0.999</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.SSS0.Px3.p1.2.m2.1c">\beta_{2}=0.999</annotation></semantics></math> for PLaMo-100B,
and reducing <math id="A2.SS1.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="\beta_{2}" display="inline"><semantics id="A2.SS1.SSS0.Px3.p1.3.m3.1a"><msub id="A2.SS1.SSS0.Px3.p1.3.m3.1.1" xref="A2.SS1.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="A2.SS1.SSS0.Px3.p1.3.m3.1.1.2" xref="A2.SS1.SSS0.Px3.p1.3.m3.1.1.2.cmml">β</mi><mn id="A2.SS1.SSS0.Px3.p1.3.m3.1.1.3" xref="A2.SS1.SSS0.Px3.p1.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS1.SSS0.Px3.p1.3.m3.1b"><apply id="A2.SS1.SSS0.Px3.p1.3.m3.1.1.cmml" xref="A2.SS1.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A2.SS1.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="A2.SS1.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><ci id="A2.SS1.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="A2.SS1.SSS0.Px3.p1.3.m3.1.1.2">𝛽</ci><cn type="integer" id="A2.SS1.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="A2.SS1.SSS0.Px3.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.SSS0.Px3.p1.3.m3.1c">\beta_{2}</annotation></semantics></math> was helpful enough to avoid the spikes.
As a result, we excluded the z-loss to avoid additional regularization.</p>
</div>
</section>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Libraries Used in Implementation</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">We could conduct our experiments smoothly thanks to the following open-sourced software.
All experiments were tracked by using <span id="A2.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">wandb</span> <cite class="ltx_cite ltx_citemacro_citep">[Biewald, <a href="#bib.bib3" title="" class="ltx_ref">2020</a>]</cite> that GENIAC provided.
In our implementations, we used <span id="A2.SS2.p1.1.2" class="ltx_text ltx_font_typewriter">transformers</span> <cite class="ltx_cite ltx_citemacro_citep">[Wolf et al., <a href="#bib.bib37" title="" class="ltx_ref">2020</a>]</cite> for encoder and decoder models’ implementations.
As LoRA’s implementation, we used <span id="A2.SS2.p1.1.3" class="ltx_text ltx_font_typewriter">peft</span> <cite class="ltx_cite ltx_citemacro_citep">[Mangrulkar et al., <a href="#bib.bib25" title="" class="ltx_ref">2022</a>]</cite>.
In addition, we used <span id="A2.SS2.p1.1.4" class="ltx_text ltx_font_typewriter">PyTorch</span> <cite class="ltx_cite ltx_citemacro_citep">[Ansel et al., <a href="#bib.bib1" title="" class="ltx_ref">2024</a>]</cite> for the training and evaluation pipeline and <span id="A2.SS2.p1.1.5" class="ltx_text ltx_font_typewriter">torchaudio</span> <cite class="ltx_cite ltx_citemacro_citep">[Hwang et al., <a href="#bib.bib14" title="" class="ltx_ref">2023</a>]</cite> for data-related implementation.
We created our <span id="A2.SS2.p1.1.6" class="ltx_text ltx_LaTeX_logo" style="letter-spacing:-0.2em; margin-right:0.1em;">L<span id="A2.SS2.p1.1.6.1" class="ltx_text" style="position:relative; bottom:0.4ex;font-variant:small-caps;;">a</span>T<span id="A2.SS2.p1.1.6.2" class="ltx_text" style="position:relative; bottom:-0.2ex;font-variant:small-caps;font-size:120%;">e</span>X</span> tables by using <span id="A2.SS2.p1.1.7" class="ltx_text ltx_font_typewriter">pandas</span> <cite class="ltx_cite ltx_citemacro_citep">[The Pandas Development Team, <a href="#bib.bib33" title="" class="ltx_ref">2020</a>]</cite>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.08026" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.08027" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.08027">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.08027" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.08028" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 14:48:35 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
