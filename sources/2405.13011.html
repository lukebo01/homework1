<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.13011] Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups</title><meta property="og:description" content="While civilized users employ social media to stay informed and discuss daily occurrences, haters perceive these platforms as fertile ground for attacking groups and individuals. The prevailing approach to counter this …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.13011">

<!--Generated on Wed Jun  5 17:49:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Bias,  toxicity,  identity groups,  NER,  hate speech">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andres Carvallo
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">CENIA</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_country">Chile</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tamara Quiroga
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text ltx_affiliation_institution">UC</span><span id="id4.2.id2" class="ltx_text ltx_affiliation_country">Chile</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Carlos Aspillaga
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_affiliation_institution">CENIA</span><span id="id6.2.id2" class="ltx_text ltx_affiliation_country">Chile</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marcelo Mendoza
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">UC</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_country">Chile</span>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id9.id1" class="ltx_p">While civilized users employ social media to stay informed and discuss daily occurrences, haters perceive these platforms as fertile ground for attacking groups and individuals. The prevailing approach to counter this phenomenon involves detecting such attacks by identifying toxic language. Effective platform measures aim to report haters and block their network access. In this context, employing hate speech detection methods aids in identifying these attacks amidst vast volumes of text, which are impossible for humans to analyze manually. In our study, we expand upon the usual hate speech detection methods, typically based on text classifiers, to develop a <span id="id9.id1.1" class="ltx_text ltx_font_bold">Named Entity Recognition (NER) System for Identity Groups</span>. To achieve this, we created a dataset that allows extending a conventional NER to recognize identity groups. Consequently, our tool not only detects whether a sentence contains an attack but also tags the sentence tokens corresponding to the mentioned group. Results indicate that the model performs competitively in identifying groups with an average f1-score of 0.75, outperforming in identifying ethnicity attack spans with an f1-score of 0.80 compared to other identity groups. Moreover, the tool shows an outstanding generalization capability to minority classes concerning sexual orientation and gender, achieving an f1-score of 0.77 and 0.72, respectively. We tested the utility of our tool in a case study on social media, annotating and comparing comments from Facebook related to news mentioning identity groups. The case study reveals differences in the types of attacks recorded, effectively detecting named entities related to the categories of the analyzed news articles. Entities are accurately tagged within their categories, with a negligible error rate for inter-category tagging.</p>
</div>
<div class="ltx_keywords">Bias, toxicity, identity groups, NER, hate speech
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Natural language processing</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Information extraction</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Social media platforms have attracted millions of users who gather information and comment on daily occurrences. The adoption of social media as the primary media of human interaction has become so deep that these platforms can now influence public opinion and generate polarizing dynamics that impact society. In this high-influence landscape, bad actors have found fertile ground to spread ideas and hate messages, targeting individuals and groups through the use of hate speech.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To counteract the harmful effects of toxic language, researchers and practitioners have developed methods for automatically detecting hate speech  <cite class="ltx_cite ltx_citemacro_citep">(MacAvaney et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>; Yin and Zubiaga, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>; Poletto et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>. Predominantly, these methods rely on text classifiers that determine whether a sentence contains an attack. Enhancements to these models include multiclass classifiers, which additionally identify if the sentence targets a specific group. Although their effectiveness has been questioned, revealing limitations in transfer learning scenarios, these models currently serve as the primary automatic tool for analyzing vast amounts of text on social media.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this study, we extend the conventional approach of hate speech detection, typically based on classification, by developing a Named Entity Recognition (NER) system to tag identity groups in text . The creation of a NER tool for annotating identity groups merges two approaches: the use of toxic language against a specific group, generally addressed from a multiclass classification perspective, and the tagging of enclosed text indicating a group, approached using NER. By integrating these two approaches, we have developed a system capable of tagging tokens that refer to a specific group.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The advantages of this approach over a traditional text classifier include not only the ability to detect toxic language in a sentence but also to pinpoint specific tokens related to the group. Furthermore, our tool directly links the attack to a particular identity group, with the tagged tokens referring to the identity group. This task is impossible with standard text classifiers, as they only provide annotations at the sentence level. On the other hand, our tool enhances what conventional NER systems can do. Typical NER tools are not trained to identify identity groups; they usually identify entities with broader granularity, such as person, organization, and location, among other categories. By expanding NER to include identity groups, our tool enables the annotation of large volumes of text, facilitating the analysis of threats to these groups. Another advantage of our tool is its ability to identify references to one or more groups within a sentence, facilitating intersectional analysis of categories.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Attacks can be executed in either a coupled or decoupled manner relative to the mention. A decoupled attack establishes an offensive relation to the mentioned entity. For example, the phrase ’inflame black people’ identifies the group with the token ’black people,’ while the toxicity is conveyed through the token ’inflame.’ In contrast, a coupled attack overlays the attack and the mention at the lexical level simultaneously through what is termed an ’offensive mention.’ An example of an ’offensive mention’ is the term ’n*r’, which refers to black people using toxic language. Our tool is capable of detecting both cases, including offensive mentions and decoupled attacks from the mention. In both scenarios, the specified group is identified through a decoupled mention from the attack or an offensive reference.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To address this challenge, we have merged two tasks, multiclass classification, and NER, by aligning two datasets: HateNorm <cite class="ltx_cite ltx_citemacro_citep">(Masud et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>, which focuses on text spans, and Jigsaw Toxicity <cite class="ltx_cite ltx_citemacro_citep">(Sorensen et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite>, the dataset used for the toxic comment classification challenge. To align these datasets, we propose a methodology for selecting sentences tagged using a NER trained on HateNorm and sentences annotated at the span-level based on a multiclass classifier developed from the Toxicity dataset. Since the Toxicity dataset is annotated at the sentence level, we apply the NER trained on HateNorm to detect groups and then classify the tagged spans using toxicity. If the annotation from toxicity matches the class predicted for the span text by the multiclass classifier, we annotate the short span in the detected class. Through this process, we align the Toxicity dataset with the tokens detected by the HateNorm NER, creating a dataset with text spans marked in specific identity groups. Subsequently, this dataset was utilized to fine-tune a conventional NER by adding identity groups to the detected entities. Experimental results show that the NER for identity groups performs well on test data.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">We developed a case study to illustrate the utility of our tool. The study is based on a dataset of news articles downloaded from ABC News, a source that categorizes news mentioning identity groups. Subsequently, we downloaded comments triggered by these news articles on Facebook. By utilizing our tool to annotate these comments, we describe differences in terms of the types of attacks and groups mentioned. The case study reveals differences in the types of attacks recorded, effectively detecting named entities related to the categories of the analyzed news articles. Entities are accurately tagged within their categories, with a negligible error rate for inter-category tagging.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">The main contributions of the paper are:</p>
</div>
<div id="S1.p9" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I1.ix1.p1" class="ltx_para">
<p id="S1.I1.ix1.p1.1" class="ltx_p">We align two datasets, Jigsaw toxicity, and HateNorm, to generate a dataset for training a Named Entity Recognition (NER) system that can detect mentions of identity groups.</p>
</div>
</li>
<li id="S1.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">–</span> 
<div id="S1.I1.ix2.p1" class="ltx_para">
<p id="S1.I1.ix2.p1.1" class="ltx_p">We apply the NER for identity groups to a case study comparing news across two social media platforms. The case reveals differences in the types of attacks and groups mentioned.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">The paper is structured as follows. Section <a href="#S2" title="2. Related work ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> introduces the related work. Section <a href="#S3" title="3. NER for identity Groups ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> describes the methodology employed in developing the NER (Named Entity Recognition) System for identity Groups. Section <a href="#S4" title="4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> introduces the case study. Finally, Section <a href="#S5" title="5. Conclusions ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> offers concluding remarks and outlines future work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In recent years, the field of detecting toxic comments and identifying specific text spans related to these comments has gained significant academic interest. The evolution from traditional methods to more advanced techniques, particularly the use of Large Language Models (LLMs), marks a pivotal shift in tackling online hate speech and offensive content  <cite class="ltx_cite ltx_citemacro_citep">(Alatawi et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2021</a>; Gambäck and Sikdar, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>; Saleh et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2023</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2021</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2018</a>; Del Vigna12 et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2017</a>)</cite>. Early research efforts, such as those by ElSherief et al. and Zampieri et al, laid foundational groundwork by focusing on linguistic analyses and the prediction of offensive post types in social media, offering critical insights into the nature of hate speech and its propagation online <cite class="ltx_cite ltx_citemacro_citep">(ElSherief et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2018</a>; Zampieri et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>. These studies underscored the importance of not only detecting toxic content but also understanding its targets and nuances, paving the way for more targeted approaches in subsequent research.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Subsequent works, including Shvets et al. and initiatives like the OSACT5 and HASOC shared tasks in 2022, expanded on these foundations by exploring specific aspects of social media hate speech, such as target identification and the detection of offensive language across various languages and regions <cite class="ltx_cite ltx_citemacro_citep">(Shvets et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>; Mubarak et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2022</a>; Satapara et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite>. These efforts highlight the growing complexity of hate speech detection and the need for models that can navigate the nuances of language and cultural context effectively.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Despite these advancements, a gap remains in the targeted identification within specific toxic text spans, a crucial aspect for understanding and mitigating the impact of online hate. This gap underscores the need for methodologies that go beyond detection to dissect the elements of toxic comments, including the identification of targeted identity groups  <cite class="ltx_cite ltx_citemacro_citep">(Goodall, <a href="#bib.bib13" title="" class="ltx_ref">2013</a>; Ștefăniță and Buf, <a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Our research addresses this need by leveraging Named Entity Recognition (NER) models to detect and identify the targeted identity group within toxic text spans. The application of NER and NLP techniques in fields such as medicine and education <cite class="ltx_cite ltx_citemacro_citep">(Alvarez et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2021</a>; Carvallo et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2023</a>; Muñoz-Castro et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2023</a>; Carvallo et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020a</a>; Carvallo and Parra, <a href="#bib.bib6" title="" class="ltx_ref">2019</a>; Carvallo et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2020b</a>)</cite> supports the feasibility and utility of this technology in our approach. Building upon the foundational work of earlier studies and the innovative use of LLMs for toxic comment detection  <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2023</a>; Mishra and Chatterjee, <a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>, our dataset and model approach represent a significant contribution to the field. By focusing on identity categories such as gender, sexual orientation, ethnicity, and religion, we provide a comprehensive tool for analyzing and combating hate speech in a nuanced manner. This contribution is particularly relevant in light of the collaborative efforts by the Conversation AI team with Jigsaw and Google on the <span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Jigsaw Toxicity Comment Classification dataset</span> and the <span id="S2.p4.1.2" class="ltx_text ltx_font_bold">HateNorm 2023 shared task</span>, which emphasize the critical need for nuanced, identity-specific analysis in toxic commentary detection  <cite class="ltx_cite ltx_citemacro_citep">(Sorensen et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2017</a>; Masud et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">In summary, our work not only builds upon the significant efforts of previous studies but also introduces an innovative approach to identifying targeted identity groups within toxic text spans. By integrating insights from the proposed papers and aligning them with the advancements in NER and LLM technologies, we aim to further the field’s understanding and capability in addressing the multifaceted nature of online hate speech.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>NER for identity Groups</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our proposed tool introduces a specialized Named Entity Recognition (NER) dataset aimed at training models to identify text spans featuring attacks against critical entity groups such as ethnicity, sexual orientation, gender, and religion. This dataset is uniquely structured to capture the nuances of language in these contexts, enabling the model to accurately detect forms of hate speech and discrimination in specific text spans in a comment.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2405.13011/assets/images/toxicity_NER_pipeline.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="348" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Pipeline Diagram for Classification, NER, and Identification of Text Spans Attacking Entity Groups</span></figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Figure <a href="#S3.F1" title="Figure 1 ‣ 3. NER for identity Groups ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows our methodology for generating the NER dataset, which is later used for training the final NER model. It starts with the Jigsaw toxicity dataset, primarily used for classification that consists of annotated texts with labels indicating targets of attacks. Although it does not provide specific text spans where these attacks occur, the Jigsaw dataset  <cite class="ltx_cite ltx_citemacro_citep">(Sorensen et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2017</a>)</cite> is the cornerstone of our entity extraction process, paving the way for the subsequent application of the trained NER model.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Our process begins with developing a transformer-based language model augmented with a classification layer. This model was designed to predict the category of the entity group targeted in a given text. Moreover, we further refined our approach by training a Named Entity Recognition (NER) model, incorporating a language model fitted with a token classification layer, and utilizing the HateNorm dataset <cite class="ltx_cite ltx_citemacro_citep">(Masud et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>. Unlike the Jigsaw dataset, HateNorm provides precise span annotations of mentions within texts but omits the classification of the targeted entity groups.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">We then applied the trained NER model to the Jigsaw toxicity dataset for entity extraction. The extracted entities were further processed through our classification model <span id="S3.p4.1.1" class="ltx_text ltx_font_bold">to select instances where the extracted text class aligns with the provided ground truth.</span> Accordingly, the dataset is composed solely of examples where the predicted class by the toxicity classifier, based on tokens identified by HateNorm’s Named Entity Recognition (NER), aligns with the human annotation provided at the sentence level by the Jigsaw toxicity dataset. Consequently, the dataset includes examples that match both the automatic annotation on the span and the human annotation at the sentence level. Therefore, under these conditions, the dataset is aligned in both annotations, ensuring that the examples have consistent annotations.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">The final step of our methodology is an exhaustive manual review and correction phase. This phase is indispensable in validating the entities identified by the HateNorm-based model. It ensures that the entities align accurately with the intended groups, eliminates irrelevant terms associated with the attacked entities, and verifies the contextual relevance of the entities within the attack narrative. This rigorous process is critical to extracting entities specifically within the context of an attack, thereby significantly enhancing the reliability of the final NER model.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">Consequently, the resultant dataset was employed to train a NER model, thoroughly cleaning and integrating both text spans and their respective targeted groups. This model mirrors the architecture of the initial language model, featuring a token classification layer.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p">Our integrated approach serves a dual purpose: it accurately pinpoints where in the text an attack is directed at a specific entity (such as race, ethnicity, gender, or sexual orientation) and identifies the specific entity being targeted. This dual functionality enables a more in-depth and nuanced analysis of the textual data, providing a comprehensive understanding of the context and nature of the attack. It is important to note that our analysis is tailored explicitly to scenarios where an entity group is the subject of the attack.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<p id="S3.F2.sf1.1" class="ltx_p ltx_align_center"><span id="S3.F2.sf1.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;"><img src="/html/2405.13011/assets/images/example_traditional_NER.png" id="S3.F2.sf1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="509" height="40" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F2.sf1.4.2" class="ltx_text" style="font-size:90%;">Traditional NER Annotations</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<p id="S3.F2.sf2.1" class="ltx_p ltx_align_center"><span id="S3.F2.sf2.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;"><img src="/html/2405.13011/assets/images/example_hatenorm_NER.png" id="S3.F2.sf2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="509" height="35" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F2.sf2.4.2" class="ltx_text" style="font-size:90%;">HateNorm NER Annotations</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<p id="S3.F2.sf3.1" class="ltx_p ltx_align_center"><span id="S3.F2.sf3.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;"><img src="/html/2405.13011/assets/images/example_proposed_NER.png" id="S3.F2.sf3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="509" height="31" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F2.sf3.4.2" class="ltx_text" style="font-size:90%;"> NER Annotations obtained using our strategy</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Comparative NER Annotations Identifying Attacked Entities and Their Text Spans</span></figcaption>
</figure>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.1" class="ltx_p">As seen in Figure <a href="#S3.F2" title="Figure 2 ‣ 3. NER for identity Groups ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we show three approaches to NER annotations, each representing a different depth of analysis. The first image illustrates traditional NER annotations, which involve identifying general knowledge entities such as organizations, locations, persons, or dates. The second example, from the HateNorm dataset, marks a significant shift towards domain-specific knowledge. Here, the annotations are nuanced, identifying specific text spans where an entity group is attacked. However, this method lacks specifying which entity group is under attack. The third example, representing our work, elevates the annotation process to a new level. It identifies the specific spans of text where attacks occur and distinctly annotates which entity group is being targeted, namely religion, ethnicity, sexual orientation, or gender.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S3.T1.3.2" class="ltx_text" style="font-size:90%;">Distribution of Entity Groups Across Dataset Partitions (Train, Validation, Testing, and Total)</span></figcaption>
<table id="S3.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.4.1.1" class="ltx_tr">
<td id="S3.T1.4.1.1.1" class="ltx_td ltx_border_tt"></td>
<th id="S3.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Total</th>
<th id="S3.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Religion</th>
<th id="S3.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Ethnicity</th>
<th id="S3.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Sexual Orientation</th>
<th id="S3.T1.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Gender</th>
</tr>
<tr id="S3.T1.4.2.2" class="ltx_tr">
<td id="S3.T1.4.2.2.1" class="ltx_td ltx_align_left ltx_border_t">Train</td>
<td id="S3.T1.4.2.2.2" class="ltx_td ltx_align_center ltx_border_t">72,678</td>
<td id="S3.T1.4.2.2.3" class="ltx_td ltx_align_center ltx_border_t">36,909</td>
<td id="S3.T1.4.2.2.4" class="ltx_td ltx_align_center ltx_border_t">26,807</td>
<td id="S3.T1.4.2.2.5" class="ltx_td ltx_align_center ltx_border_t">4,650</td>
<td id="S3.T1.4.2.2.6" class="ltx_td ltx_align_center ltx_border_t">4,312</td>
</tr>
<tr id="S3.T1.4.3.3" class="ltx_tr">
<td id="S3.T1.4.3.3.1" class="ltx_td ltx_align_left">Validation</td>
<td id="S3.T1.4.3.3.2" class="ltx_td ltx_align_center">3,970</td>
<td id="S3.T1.4.3.3.3" class="ltx_td ltx_align_center">1,954</td>
<td id="S3.T1.4.3.3.4" class="ltx_td ltx_align_center">1,553</td>
<td id="S3.T1.4.3.3.5" class="ltx_td ltx_align_center">250</td>
<td id="S3.T1.4.3.3.6" class="ltx_td ltx_align_center">213</td>
</tr>
<tr id="S3.T1.4.4.4" class="ltx_tr">
<td id="S3.T1.4.4.4.1" class="ltx_td ltx_align_left">Testing</td>
<td id="S3.T1.4.4.4.2" class="ltx_td ltx_align_center">4,190</td>
<td id="S3.T1.4.4.4.3" class="ltx_td ltx_align_center">2,139</td>
<td id="S3.T1.4.4.4.4" class="ltx_td ltx_align_center">1,477</td>
<td id="S3.T1.4.4.4.5" class="ltx_td ltx_align_center">244</td>
<td id="S3.T1.4.4.4.6" class="ltx_td ltx_align_center">230</td>
</tr>
<tr id="S3.T1.4.5.5" class="ltx_tr">
<td id="S3.T1.4.5.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Total</td>
<td id="S3.T1.4.5.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">80,838</td>
<td id="S3.T1.4.5.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">41,002</td>
<td id="S3.T1.4.5.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">29,837</td>
<td id="S3.T1.4.5.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">5,144</td>
<td id="S3.T1.4.5.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">4,755</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p9" class="ltx_para">
<p id="S3.p9.1" class="ltx_p">As seen in Table <a href="#S3.T1" title="Table 1 ‣ 3. NER for identity Groups ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the dataset employed for the NER task is segmented into three distinct subsets: training, validation, and testing. The training set, which serves as the foundation for model learning, is the most extensive, encompassing 72678 entities. Within this subset, the distribution of entities spans various categories, with Religion being the most represented at 36909 entities. Ethnicity follows, with a significant count of 26807 entities. In contrast, Sexual Orientation and Gender entities are less prevalent, totaling 4650 and 4312, respectively. The validation set, crucial for fine-tuning the model, includes a more modest total of 3970 entities. As the training set, Religion and Ethnicity dominate this subset, accounting for 1954 and 1553 entities, respectively. Entities representing Sexual Orientation and Gender are comparatively fewer, amounting to 250 and 213, respectively. In the testing set, which is critical for evaluating the model’s performance, there are 4190 entities. Here again, Religion and Ethnicity are the most represented categories, with 2139 and 1477 entities, respectively. Sexual Orientation and Gender maintain their trend of lower representation with 244 and 230 entities, respectively. When aggregating the totals across all subsets, the dataset comprises 80,838 entities. The category-wise aggregation reveals a consistent trend across the subsets, with Religion entities being the most numerous at 41002, followed by Ethnicity at 29837. Sexual Orientation and Gender entities, while essential, are less represented, with totals of 5144 and 4755, respectively. This distribution underscores the dataset’s emphasis on Religion and Ethnicity entities and highlights the challenge of achieving a balanced representation of different entity types in NER tasks.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S3.T2.3.2" class="ltx_text" style="font-size:90%;">Sample of Most Frequent Words in Spans for Each identity Group</span></figcaption>
<table id="S3.T2.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.4.1.1" class="ltx_tr">
<th id="S3.T2.4.1.1.1" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.1.1.1.1.1" class="ltx_p"><span id="S3.T2.4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Identity Group</span></span>
</span>
</th>
<th id="S3.T2.4.1.1.2" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S3.T2.4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.1.1.2.1.1" class="ltx_p"><span id="S3.T2.4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Words Sample</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.4.2.1" class="ltx_tr">
<td id="S3.T2.4.2.1.1" class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.4.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.2.1.1.1.1" class="ltx_p">Gender</span>
</span>
</td>
<td id="S3.T2.4.2.1.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S3.T2.4.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.2.1.2.1.1" class="ltx_p">women, male, men, transgender, feminism, transgendered, gender, man, woman, trans</span>
</span>
</td>
</tr>
<tr id="S3.T2.4.3.2" class="ltx_tr">
<td id="S3.T2.4.3.2.1" class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.4.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.3.2.1.1.1" class="ltx_p">Ethnicity</span>
</span>
</td>
<td id="S3.T2.4.3.2.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S3.T2.4.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.3.2.2.1.1" class="ltx_p">white, black, immigrants, non-white, racist, racism, asian, racial, african, latino</span>
</span>
</td>
</tr>
<tr id="S3.T2.4.4.3" class="ltx_tr">
<td id="S3.T2.4.4.3.1" class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.4.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.3.1.1.1" class="ltx_p">Sexual Orientation</span>
</span>
</td>
<td id="S3.T2.4.4.3.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t">
<span id="S3.T2.4.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.3.2.1.1" class="ltx_p">gay, lesbian, bisexual, LGBT, homosexual, homosexuality, same-sex, anti-gay, heterosexuals, homophobia</span>
</span>
</td>
</tr>
<tr id="S3.T2.4.5.4" class="ltx_tr">
<td id="S3.T2.4.5.4.1" class="ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.4.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.5.4.1.1.1" class="ltx_p">Religion</span>
</span>
</td>
<td id="S3.T2.4.5.4.2" class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T2.4.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.5.4.2.1.1" class="ltx_p">islam, catholic, muslim, jews, jewish, terrorism, islamophobia, palestinians, extremists, atheists</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p10" class="ltx_para">
<p id="S3.p10.1" class="ltx_p">As shown in Table <a href="#S3.T2" title="Table 2 ‣ 3. NER for identity Groups ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the table offers an insightful sample of the most frequent words associated with each identity group. This selection of words reflects an in-depth understanding of the context and nuances of each group, showcasing not just directly related terms but also those indicative of attacks or discrimination. For instance, in the context of the sexual orientation entity group, words such as ”homophobia” clearly demonstrate this dual relevance. They are inherently related to the group and carry connotations of the attacks these entities might face. This careful curation of words for each entity group - gender, ethnicity, sexual orientation, and religion - enhances the model’s ability to accurately identify and classify instances of attacks or discrimination in text. Notably, the chosen words encapsulate the group’s identity and the nature of the challenges or biases they can encounter, providing a substantial foundation for the NER model’s training and subsequent performance.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>. </span><span id="S3.T3.3.2" class="ltx_text" style="font-size:90%;">Performance Metrics of the NER Model</span></figcaption>
<table id="S3.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.4.1.1" class="ltx_tr">
<th id="S3.T3.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">Entity Group</th>
<th id="S3.T3.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Precision</th>
<th id="S3.T3.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Recall</th>
<th id="S3.T3.4.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">F1-Score</th>
<th id="S3.T3.4.1.1.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt">Support</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.4.2.1" class="ltx_tr">
<td id="S3.T3.4.2.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Religion</td>
<td id="S3.T3.4.2.1.2" class="ltx_td ltx_align_left ltx_border_t">0.76</td>
<td id="S3.T3.4.2.1.3" class="ltx_td ltx_align_left ltx_border_t">0.69</td>
<td id="S3.T3.4.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.72</td>
<td id="S3.T3.4.2.1.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">2139</td>
</tr>
<tr id="S3.T3.4.3.2" class="ltx_tr">
<td id="S3.T3.4.3.2.1" class="ltx_td ltx_align_left ltx_border_r">Ethnicity</td>
<td id="S3.T3.4.3.2.2" class="ltx_td ltx_align_left">0.80</td>
<td id="S3.T3.4.3.2.3" class="ltx_td ltx_align_left">0.80</td>
<td id="S3.T3.4.3.2.4" class="ltx_td ltx_align_left ltx_border_r">0.80</td>
<td id="S3.T3.4.3.2.5" class="ltx_td ltx_nopad_r ltx_align_left">1477</td>
</tr>
<tr id="S3.T3.4.4.3" class="ltx_tr">
<td id="S3.T3.4.4.3.1" class="ltx_td ltx_align_left ltx_border_r">Sexual Orientation</td>
<td id="S3.T3.4.4.3.2" class="ltx_td ltx_align_left">0.80</td>
<td id="S3.T3.4.4.3.3" class="ltx_td ltx_align_left">0.75</td>
<td id="S3.T3.4.4.3.4" class="ltx_td ltx_align_left ltx_border_r">0.77</td>
<td id="S3.T3.4.4.3.5" class="ltx_td ltx_nopad_r ltx_align_left">244</td>
</tr>
<tr id="S3.T3.4.5.4" class="ltx_tr">
<td id="S3.T3.4.5.4.1" class="ltx_td ltx_align_left ltx_border_r">Gender</td>
<td id="S3.T3.4.5.4.2" class="ltx_td ltx_align_left">0.72</td>
<td id="S3.T3.4.5.4.3" class="ltx_td ltx_align_left">0.73</td>
<td id="S3.T3.4.5.4.4" class="ltx_td ltx_align_left ltx_border_r">0.73</td>
<td id="S3.T3.4.5.4.5" class="ltx_td ltx_nopad_r ltx_align_left">230</td>
</tr>
<tr id="S3.T3.4.6.5" class="ltx_tr">
<td id="S3.T3.4.6.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Micro Avg</td>
<td id="S3.T3.4.6.5.2" class="ltx_td ltx_align_left ltx_border_t">0.77</td>
<td id="S3.T3.4.6.5.3" class="ltx_td ltx_align_left ltx_border_t">0.74</td>
<td id="S3.T3.4.6.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.75</td>
<td id="S3.T3.4.6.5.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">4090</td>
</tr>
<tr id="S3.T3.4.7.6" class="ltx_tr">
<td id="S3.T3.4.7.6.1" class="ltx_td ltx_align_left ltx_border_r">Macro Avg</td>
<td id="S3.T3.4.7.6.2" class="ltx_td ltx_align_left">0.77</td>
<td id="S3.T3.4.7.6.3" class="ltx_td ltx_align_left">0.74</td>
<td id="S3.T3.4.7.6.4" class="ltx_td ltx_align_left ltx_border_r">0.76</td>
<td id="S3.T3.4.7.6.5" class="ltx_td ltx_nopad_r ltx_align_left">4090</td>
</tr>
<tr id="S3.T3.4.8.7" class="ltx_tr">
<td id="S3.T3.4.8.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Weighted Avg</td>
<td id="S3.T3.4.8.7.2" class="ltx_td ltx_align_left ltx_border_bb">0.77</td>
<td id="S3.T3.4.8.7.3" class="ltx_td ltx_align_left ltx_border_bb">0.74</td>
<td id="S3.T3.4.8.7.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">0.75</td>
<td id="S3.T3.4.8.7.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">4090</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p11" class="ltx_para">
<p id="S3.p11.1" class="ltx_p">The performance metrics shown in Table <a href="#S3.T3" title="Table 3 ‣ 3. NER for identity Groups ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> reveal the final NER model’s proficiency, mainly for supporting class imbalance within the dataset. This model can generalize across classes within varying representation levels. For instance, the model achieves a high f1-score of 0.80 in the <span id="S3.p11.1.1" class="ltx_text ltx_font_italic">’Ethnicity’</span> category, which suggests strong performance despite potential data skewness. This is particularly noteworthy given the relatively lower number of examples in the <span id="S3.p11.1.2" class="ltx_text ltx_font_italic">’Sexual Orientation’</span> category (244 instances), where the model still manages an f1-score of 0.77, indicating its effective handling of class imbalance.
The <span id="S3.p11.1.3" class="ltx_text ltx_font_italic">’Religion’</span> category, with the highest support of 2139 instances, obtains a solid f1-score of 0.72, further reinforcing the model’s capability to maintain accuracy across different scales of data representation. Similarly, the <span id="S3.p11.1.4" class="ltx_text ltx_font_italic">’Gender’</span> category, despite having the most minor support (230 instances), shows a comparable f1-score of 0.73. This consistency across categories with varied instance counts highlights the model’s robustness.
Moreover, the balanced performance across micro, macro, and weighted averages (f1-scores of 0.75, 0.76, and 0.75, respectively) suggests the model is not overly biased towards any particular class, a critical factor in scenarios with imbalanced data. This adaptability is crucial for real-world applications where data representation might not be uniform.
The comprehensive approach to model evaluation, leveraging a mix of heuristic-based annotations, algorithmic classifications, and human validation, ensures that the model is usable for practical deployment. Its ability to accurately interpret and analyze text across a spectrum of scenarios, as evidenced by the metrics, demonstrates its potential for complex text analysis tasks where accuracy, sensitivity, and the ability to handle class imbalance are critical.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Case study</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Methodology and main findings</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The study case in which we applied our tool consists of a collection of news articles along with their corresponding comments on Facebook. We utilized ABC News as our information source, a network known for categorizing news items according to the identity groups mentioned in either the headline or body of the article.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>. </span><span id="S4.T4.3.2" class="ltx_text" style="font-size:90%;">News analyzed in the case study.</span></figcaption>
<div id="S4.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:381.6pt;height:275.6pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-167.6pt,120.8pt) scale(0.532405791661173,0.532405791661173) ;">
<table id="S4.T4.4.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.4.1.1.1" class="ltx_tr">
<td id="S4.T4.4.1.1.1.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T4.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ID</td>
<td id="S4.T4.4.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Headline</td>
<td id="S4.T4.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Date</td>
<td id="S4.T4.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Comments</td>
<td id="S4.T4.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Shares</td>
<td id="S4.T4.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">Reactions</td>
</tr>
<tr id="S4.T4.4.1.2.2" class="ltx_tr">
<td id="S4.T4.4.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="5">
<span id="S4.T4.4.1.2.2.1.1" class="ltx_text">
<span id="S4.T4.4.1.2.2.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:31.8pt;vertical-align:-12.4pt;"><span class="ltx_transformed_inner" style="width:31.8pt;transform:translate(-12.41pt,0pt) rotate(-90deg) ;">
<span id="S4.T4.4.1.2.2.1.1.1.1" class="ltx_p">Gender</span>
</span></span></span>
</td>
<td id="S4.T4.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">(1)</td>
<td id="S4.T4.4.1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">
<span id="S4.T4.4.1.2.2.3.1" class="ltx_ERROR undefined">\pbox</span>7.1cmThe Ohio Senate voted to pass a bill that would limit gender-affirming care for transgender minors</td>
<td id="S4.T4.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">12/13/23</td>
<td id="S4.T4.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">383</td>
<td id="S4.T4.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">36</td>
<td id="S4.T4.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_tt">596</td>
</tr>
<tr id="S4.T4.4.1.3.3" class="ltx_tr">
<td id="S4.T4.4.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r">(2)</td>
<td id="S4.T4.4.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.3.3.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmAustralia’s gender pay gap has fallen to a new low of 21.7 per cent. Do you think the gender pay gap is closing?</td>
<td id="S4.T4.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r">11/28/23</td>
<td id="S4.T4.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r">27</td>
<td id="S4.T4.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="S4.T4.4.1.3.3.6" class="ltx_td ltx_align_center">60</td>
</tr>
<tr id="S4.T4.4.1.4.4" class="ltx_tr">
<td id="S4.T4.4.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r">(3)</td>
<td id="S4.T4.4.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.4.4.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cm”It’s boss as, girls getting around with forklifts and [doing] something males always do,” Tahlia Quinlivan said.</td>
<td id="S4.T4.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">01/15/24</td>
<td id="S4.T4.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">159</td>
<td id="S4.T4.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r">11</td>
<td id="S4.T4.4.1.4.4.6" class="ltx_td ltx_align_center">251</td>
</tr>
<tr id="S4.T4.4.1.5.5" class="ltx_tr">
<td id="S4.T4.4.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r">(4)</td>
<td id="S4.T4.4.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.5.5.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmGender-affirming hormone therapy improves the mental health of transgender adolescents and teenagers, a new study released Wednesday in the New England Journal of Medicine showed.</td>
<td id="S4.T4.4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">01/19/23</td>
<td id="S4.T4.4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">258</td>
<td id="S4.T4.4.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r">13</td>
<td id="S4.T4.4.1.5.5.6" class="ltx_td ltx_align_center">712</td>
</tr>
<tr id="S4.T4.4.1.6.6" class="ltx_tr">
<td id="S4.T4.4.1.6.6.1" class="ltx_td ltx_align_center ltx_border_r">(5)</td>
<td id="S4.T4.4.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.6.6.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmIn almost six years as leader, Jacinda Ardern faced the aftermath of a massacre and delivered stinging rebukes to those questioning her age and gender. Here’s a look back at her time in office.</td>
<td id="S4.T4.4.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r">01/19/23</td>
<td id="S4.T4.4.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">35</td>
<td id="S4.T4.4.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="S4.T4.4.1.6.6.6" class="ltx_td ltx_align_center">205</td>
</tr>
<tr id="S4.T4.4.1.7.7" class="ltx_tr">
<td id="S4.T4.4.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="5">
<span id="S4.T4.4.1.7.7.1.1" class="ltx_text">
<span id="S4.T4.4.1.7.7.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:40.6pt;vertical-align:-17.8pt;"><span class="ltx_transformed_inner" style="width:40.7pt;transform:translate(-15.9pt,2.92pt) rotate(-90deg) ;">
<span id="S4.T4.4.1.7.7.1.1.1.1" class="ltx_p">Ethnicity</span>
</span></span></span>
</td>
<td id="S4.T4.4.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(6)</td>
<td id="S4.T4.4.1.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.7.7.3.1" class="ltx_ERROR undefined">\pbox</span>7.1cmGermany on Tuesday banned the neo-Nazi group Hammerskins Germany and raided homes of dozens of its members. The group is an offshoot of an American ring-wing extremist group and plays a prominent role across Europe.</td>
<td id="S4.T4.4.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">09/19/23</td>
<td id="S4.T4.4.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">159</td>
<td id="S4.T4.4.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33</td>
<td id="S4.T4.4.1.7.7.7" class="ltx_td ltx_align_center ltx_border_t">409</td>
</tr>
<tr id="S4.T4.4.1.8.8" class="ltx_tr">
<td id="S4.T4.4.1.8.8.1" class="ltx_td ltx_align_center ltx_border_r">(7)</td>
<td id="S4.T4.4.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.8.8.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmAn upstate New York museum is featuring homemade dolls depicting African American life as an homage to their makers and as a jumping off point into the history of oppression faced by the Black community.</td>
<td id="S4.T4.4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r">10/22/23</td>
<td id="S4.T4.4.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">103</td>
<td id="S4.T4.4.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="S4.T4.4.1.8.8.6" class="ltx_td ltx_align_center">185</td>
</tr>
<tr id="S4.T4.4.1.9.9" class="ltx_tr">
<td id="S4.T4.4.1.9.9.1" class="ltx_td ltx_align_center ltx_border_r">(8)</td>
<td id="S4.T4.4.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.9.9.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmSupreme Court rejects appeal of Derek Chauvin conviction in the killing og George Floyd</td>
<td id="S4.T4.4.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r">11/20/23</td>
<td id="S4.T4.4.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">733</td>
<td id="S4.T4.4.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r">72</td>
<td id="S4.T4.4.1.9.9.6" class="ltx_td ltx_align_center">1127</td>
</tr>
<tr id="S4.T4.4.1.10.10" class="ltx_tr">
<td id="S4.T4.4.1.10.10.1" class="ltx_td ltx_align_center ltx_border_r">(9)</td>
<td id="S4.T4.4.1.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.10.10.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmKing Charles, Princess Kate identified by British press as royals named in Dutch version of ”Endgame” amid racial controversy</td>
<td id="S4.T4.4.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r">12/01/23</td>
<td id="S4.T4.4.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">62</td>
<td id="S4.T4.4.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="S4.T4.4.1.10.10.6" class="ltx_td ltx_align_center">80</td>
</tr>
<tr id="S4.T4.4.1.11.11" class="ltx_tr">
<td id="S4.T4.4.1.11.11.1" class="ltx_td ltx_align_center ltx_border_r">(10)</td>
<td id="S4.T4.4.1.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.11.11.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmNazi flags to be banned under new Queensland hate symbol laws.</td>
<td id="S4.T4.4.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r">10/12/23</td>
<td id="S4.T4.4.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r">36</td>
<td id="S4.T4.4.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="S4.T4.4.1.11.11.6" class="ltx_td ltx_align_center">250</td>
</tr>
<tr id="S4.T4.4.1.12.12" class="ltx_tr">
<td id="S4.T4.4.1.12.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="5">
<span id="S4.T4.4.1.12.12.1.1" class="ltx_text">
<span id="S4.T4.4.1.12.12.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:79.5pt;vertical-align:-36.3pt;"><span class="ltx_transformed_inner" style="width:79.5pt;transform:translate(-36.26pt,0pt) rotate(-90deg) ;">
<span id="S4.T4.4.1.12.12.1.1.1.1" class="ltx_p">Sexual orientation</span>
</span></span></span>
</td>
<td id="S4.T4.4.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(11)</td>
<td id="S4.T4.4.1.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.12.12.3.1" class="ltx_ERROR undefined">\pbox</span>7.1cmThe Florida Department of Education has effectively banned AP Psychology</td>
<td id="S4.T4.4.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">08/03/23</td>
<td id="S4.T4.4.1.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">222</td>
<td id="S4.T4.4.1.12.12.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">24</td>
<td id="S4.T4.4.1.12.12.7" class="ltx_td ltx_align_center ltx_border_t">208</td>
</tr>
<tr id="S4.T4.4.1.13.13" class="ltx_tr">
<td id="S4.T4.4.1.13.13.1" class="ltx_td ltx_align_center ltx_border_r">(12)</td>
<td id="S4.T4.4.1.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.13.13.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmHate crimes in the U.S. remained at the same level in 2021 as they were in 2020, FBI says, even as hate crimes based on a person’s sexual orientation increased</td>
<td id="S4.T4.4.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r">12/12/22</td>
<td id="S4.T4.4.1.13.13.4" class="ltx_td ltx_align_center ltx_border_r">154</td>
<td id="S4.T4.4.1.13.13.5" class="ltx_td ltx_align_center ltx_border_r">16</td>
<td id="S4.T4.4.1.13.13.6" class="ltx_td ltx_align_center">122</td>
</tr>
<tr id="S4.T4.4.1.14.14" class="ltx_tr">
<td id="S4.T4.4.1.14.14.1" class="ltx_td ltx_align_center ltx_border_r">(13)</td>
<td id="S4.T4.4.1.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.14.14.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmA new bill proposed in one state would take Florida’s controversial ”Don’t say Gay” law even further</td>
<td id="S4.T4.4.1.14.14.3" class="ltx_td ltx_align_center ltx_border_r">02/08/23</td>
<td id="S4.T4.4.1.14.14.4" class="ltx_td ltx_align_center ltx_border_r">305</td>
<td id="S4.T4.4.1.14.14.5" class="ltx_td ltx_align_center ltx_border_r">21</td>
<td id="S4.T4.4.1.14.14.6" class="ltx_td ltx_align_center">265</td>
</tr>
<tr id="S4.T4.4.1.15.15" class="ltx_tr">
<td id="S4.T4.4.1.15.15.1" class="ltx_td ltx_align_center ltx_border_r">(14)</td>
<td id="S4.T4.4.1.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.15.15.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmFDA drops blood donation restrictions specific to gay and bisexual men</td>
<td id="S4.T4.4.1.15.15.3" class="ltx_td ltx_align_center ltx_border_r">05/14/23</td>
<td id="S4.T4.4.1.15.15.4" class="ltx_td ltx_align_center ltx_border_r">122</td>
<td id="S4.T4.4.1.15.15.5" class="ltx_td ltx_align_center ltx_border_r">18</td>
<td id="S4.T4.4.1.15.15.6" class="ltx_td ltx_align_center">147</td>
</tr>
<tr id="S4.T4.4.1.16.16" class="ltx_tr">
<td id="S4.T4.4.1.16.16.1" class="ltx_td ltx_align_center ltx_border_r">(15)</td>
<td id="S4.T4.4.1.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.16.16.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmThe Florida Board of Education votes to expand so-called ”Don’t Say Gay” rules through 12th grade</td>
<td id="S4.T4.4.1.16.16.3" class="ltx_td ltx_align_center ltx_border_r">04/19/23</td>
<td id="S4.T4.4.1.16.16.4" class="ltx_td ltx_align_center ltx_border_r">398</td>
<td id="S4.T4.4.1.16.16.5" class="ltx_td ltx_align_center ltx_border_r">63</td>
<td id="S4.T4.4.1.16.16.6" class="ltx_td ltx_align_center">400</td>
</tr>
<tr id="S4.T4.4.1.17.17" class="ltx_tr">
<td id="S4.T4.4.1.17.17.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="8">
<span id="S4.T4.4.1.17.17.1.1" class="ltx_text">
<span id="S4.T4.4.1.17.17.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:8.9pt;height:35.6pt;vertical-align:-15.3pt;"><span class="ltx_transformed_inner" style="width:35.7pt;transform:translate(-13.4pt,2.92pt) rotate(-90deg) ;">
<span id="S4.T4.4.1.17.17.1.1.1.1" class="ltx_p">Religion</span>
</span></span></span>
</td>
<td id="S4.T4.4.1.17.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(16)</td>
<td id="S4.T4.4.1.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.17.17.3.1" class="ltx_ERROR undefined">\pbox</span>7.1cmRamaswamy says he’s not ”pastor in chief” as GOP voters question his religion</td>
<td id="S4.T4.4.1.17.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">09/14/23</td>
<td id="S4.T4.4.1.17.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">101</td>
<td id="S4.T4.4.1.17.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13</td>
<td id="S4.T4.4.1.17.17.7" class="ltx_td ltx_align_center ltx_border_t">107</td>
</tr>
<tr id="S4.T4.4.1.18.18" class="ltx_tr">
<td id="S4.T4.4.1.18.18.1" class="ltx_td ltx_align_center ltx_border_r">(17)</td>
<td id="S4.T4.4.1.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.18.18.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmThe Israel-Hamas war has college campuses on edge. How some are tackling the issue</td>
<td id="S4.T4.4.1.18.18.3" class="ltx_td ltx_align_center ltx_border_r">11/29/23</td>
<td id="S4.T4.4.1.18.18.4" class="ltx_td ltx_align_center ltx_border_r">190</td>
<td id="S4.T4.4.1.18.18.5" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="S4.T4.4.1.18.18.6" class="ltx_td ltx_align_center">71</td>
</tr>
<tr id="S4.T4.4.1.19.19" class="ltx_tr">
<td id="S4.T4.4.1.19.19.1" class="ltx_td ltx_align_center ltx_border_r">(18)</td>
<td id="S4.T4.4.1.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.19.19.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmDeSantis, Trump court Iowa’s evangelical voters, promising Christian-focused policy</td>
<td id="S4.T4.4.1.19.19.3" class="ltx_td ltx_align_center ltx_border_r">12/28/23</td>
<td id="S4.T4.4.1.19.19.4" class="ltx_td ltx_align_center ltx_border_r">184</td>
<td id="S4.T4.4.1.19.19.5" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="S4.T4.4.1.19.19.6" class="ltx_td ltx_align_center">181</td>
</tr>
<tr id="S4.T4.4.1.20.20" class="ltx_tr">
<td id="S4.T4.4.1.20.20.1" class="ltx_td ltx_align_center ltx_border_r">(19)</td>
<td id="S4.T4.4.1.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.20.20.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmGen Z gym bros resurrecting Christianity as religion makes godlike gains on social media</td>
<td id="S4.T4.4.1.20.20.3" class="ltx_td ltx_align_center ltx_border_r">06/08/23</td>
<td id="S4.T4.4.1.20.20.4" class="ltx_td ltx_align_center ltx_border_r">77</td>
<td id="S4.T4.4.1.20.20.5" class="ltx_td ltx_align_center ltx_border_r">12</td>
<td id="S4.T4.4.1.20.20.6" class="ltx_td ltx_align_center">401</td>
</tr>
<tr id="S4.T4.4.1.21.21" class="ltx_tr">
<td id="S4.T4.4.1.21.21.1" class="ltx_td ltx_align_center ltx_border_r">(20)</td>
<td id="S4.T4.4.1.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.21.21.2.1" class="ltx_ERROR undefined">\pbox</span>7.1cmIslam is the world’s fastest growing religion due to migration and high birth rates</td>
<td id="S4.T4.4.1.21.21.3" class="ltx_td ltx_align_center ltx_border_r">06/28/23</td>
<td id="S4.T4.4.1.21.21.4" class="ltx_td ltx_align_center ltx_border_r">28</td>
<td id="S4.T4.4.1.21.21.5" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="S4.T4.4.1.21.21.6" class="ltx_td ltx_align_center">55</td>
</tr>
<tr id="S4.T4.4.1.22.22" class="ltx_tr">
<td id="S4.T4.4.1.22.22.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">Total</td>
<td id="S4.T4.4.1.22.22.2" class="ltx_td ltx_border_b ltx_border_r ltx_border_tt"></td>
<td id="S4.T4.4.1.22.22.3" class="ltx_td ltx_border_b ltx_border_r ltx_border_tt"></td>
<td id="S4.T4.4.1.22.22.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">3736</td>
<td id="S4.T4.4.1.22.22.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">367</td>
<td id="S4.T4.4.1.22.22.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt">5832</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">This organization of news by groups facilitated our search for content likely to generate related comments on social media concerning these groups. To compile the set of news articles for analysis, we employed the META Crowdtangle search tool, enabling access to content from one or more press outlets with public pages on Facebook. In the case of ABC News, we focused on their three most followed Facebook pages: <a target="_blank" href="https://www.facebook.com/ABCNews" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.facebook.com/ABCNews</a> (18 million users), <a target="_blank" href="https://www.facebook.com/abcnews.au" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.facebook.com/abcnews.au</a> (4.7 million users), and <a target="_blank" href="https://www.facebook.com/WorldNewsTonight" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.facebook.com/WorldNewsTonight</a> (5 million users). We utilized Crowdtangle’s search engine on the specified sources to assemble our news collection. The keywords used for different categories were <span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_italic">’gender’</span> for the <span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_italic">Gender</span> category, <span id="S4.SS1.p2.1.3" class="ltx_text ltx_font_italic">’racism ethnicities’</span> for <span id="S4.SS1.p2.1.4" class="ltx_text ltx_font_italic">Ethnicity</span>, <span id="S4.SS1.p2.1.5" class="ltx_text ltx_font_italic">’sexual orientation’</span> for <span id="S4.SS1.p2.1.6" class="ltx_text ltx_font_italic">Sexual Orientation</span>, and <span id="S4.SS1.p2.1.7" class="ltx_text ltx_font_italic">’religion’</span> for <span id="S4.SS1.p2.1.8" class="ltx_text ltx_font_italic">Religion</span>. Searches were parameterized over a one-year observation window. The first five news articles were collected for each category, resulting in 20 news articles for the case study. The news corpus comprises 3,736 comments, 367 shares, and 5,832 reactions. Details of the constructed corpus are provided in Table <a href="#S4.T4" title="Table 4 ‣ 4.1. Methodology and main findings ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">We applied our tool to each comment of every news article in our corpus. Table <a href="#S4.T5" title="Table 5 ‣ 4.1. Methodology and main findings ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, alongside the ID of each news item, displays the total number of comments in which the tool tagged mentions about any of the four analyzed categories. The ’intersections’ column indicates the count of co-occurrences of two or more mentions in the same comment. For instance, for news item (1), the intersection (G,G,26) is displayed, signifying 26 co-occurrences of mentions of two or more entities tagged in the ’gender’ category. The last column of Table <a href="#S4.T5" title="Table 5 ‣ 4.1. Methodology and main findings ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> provides examples of entity mentions identified by our tool.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.2.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>. </span><span id="S4.T5.3.2" class="ltx_text" style="font-size:90%;">Mentions per category.</span></figcaption>
<table id="S4.T5.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.4.1.1" class="ltx_tr">
<td id="S4.T5.4.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ID</td>
<td id="S4.T5.4.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Gender</td>
<td id="S4.T5.4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ethnicity</td>
<td id="S4.T5.4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Sexual Or.</td>
<td id="S4.T5.4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Religion</td>
<td id="S4.T5.4.1.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Intersections</td>
<td id="S4.T5.4.1.1.7" class="ltx_td ltx_align_left ltx_border_t">Examples</td>
</tr>
<tr id="S4.T5.4.2.2" class="ltx_tr">
<td id="S4.T5.4.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">(1)</td>
<td id="S4.T5.4.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">54</td>
<td id="S4.T5.4.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">2</td>
<td id="S4.T5.4.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">3</td>
<td id="S4.T5.4.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">0</td>
<td id="S4.T5.4.2.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">(G,G,26)</td>
<td id="S4.T5.4.2.2.7" class="ltx_td ltx_align_left ltx_border_tt">transgender, trans, women</td>
</tr>
<tr id="S4.T5.4.3.3" class="ltx_tr">
<td id="S4.T5.4.3.3.1" class="ltx_td ltx_align_center ltx_border_r">(2)</td>
<td id="S4.T5.4.3.3.2" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="S4.T5.4.3.3.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.3.3.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.3.3.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.3.3.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S4.T5.4.3.3.7" class="ltx_td ltx_align_left">pays women</td>
</tr>
<tr id="S4.T5.4.4.4" class="ltx_tr">
<td id="S4.T5.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r">(3)</td>
<td id="S4.T5.4.4.4.2" class="ltx_td ltx_align_center ltx_border_r">43</td>
<td id="S4.T5.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.4.4.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.4.4.6" class="ltx_td ltx_align_left ltx_border_r">(G,G,12)</td>
<td id="S4.T5.4.4.4.7" class="ltx_td ltx_align_left">women, men</td>
</tr>
<tr id="S4.T5.4.5.5" class="ltx_tr">
<td id="S4.T5.4.5.5.1" class="ltx_td ltx_align_center ltx_border_r">(4)</td>
<td id="S4.T5.4.5.5.2" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="S4.T5.4.5.5.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.5.5.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.5.5.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.5.5.6" class="ltx_td ltx_align_left ltx_border_r">(G,G,2)</td>
<td id="S4.T5.4.5.5.7" class="ltx_td ltx_align_left">transgender</td>
</tr>
<tr id="S4.T5.4.6.6" class="ltx_tr">
<td id="S4.T5.4.6.6.1" class="ltx_td ltx_align_center ltx_border_r">(5)</td>
<td id="S4.T5.4.6.6.2" class="ltx_td ltx_align_center ltx_border_r">3</td>
<td id="S4.T5.4.6.6.3" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="S4.T5.4.6.6.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.6.6.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.6.6.6" class="ltx_td ltx_align_left ltx_border_r">(G,G,1)</td>
<td id="S4.T5.4.6.6.7" class="ltx_td ltx_align_left">female misogyny, women</td>
</tr>
<tr id="S4.T5.4.7.7" class="ltx_tr">
<td id="S4.T5.4.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(6)</td>
<td id="S4.T5.4.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.4.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3</td>
<td id="S4.T5.4.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.4.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.4.7.7.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S4.T5.4.7.7.7" class="ltx_td ltx_align_left ltx_border_t">white</td>
</tr>
<tr id="S4.T5.4.8.8" class="ltx_tr">
<td id="S4.T5.4.8.8.1" class="ltx_td ltx_align_center ltx_border_r">(7)</td>
<td id="S4.T5.4.8.8.2" class="ltx_td ltx_align_center ltx_border_r">26</td>
<td id="S4.T5.4.8.8.3" class="ltx_td ltx_align_center ltx_border_r">18</td>
<td id="S4.T5.4.8.8.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.8.8.5" class="ltx_td ltx_align_center ltx_border_r">11</td>
<td id="S4.T5.4.8.8.6" class="ltx_td ltx_align_left ltx_border_r">(G,G,73),(R,R,12)</td>
<td id="S4.T5.4.8.8.7" class="ltx_td ltx_align_left">Hamas, Hamas bombed, Jews</td>
</tr>
<tr id="S4.T5.4.9.9" class="ltx_tr">
<td id="S4.T5.4.9.9.1" class="ltx_td ltx_align_center ltx_border_r">(8)</td>
<td id="S4.T5.4.9.9.2" class="ltx_td ltx_align_center ltx_border_r">6</td>
<td id="S4.T5.4.9.9.3" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="S4.T5.4.9.9.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.9.9.5" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="S4.T5.4.9.9.6" class="ltx_td ltx_align_left ltx_border_r">(R,R,3)</td>
<td id="S4.T5.4.9.9.7" class="ltx_td ltx_align_left">racists, Pakistan, man</td>
</tr>
<tr id="S4.T5.4.10.10" class="ltx_tr">
<td id="S4.T5.4.10.10.1" class="ltx_td ltx_align_center ltx_border_r">(9)</td>
<td id="S4.T5.4.10.10.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.10.10.3" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="S4.T5.4.10.10.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.10.10.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.10.10.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S4.T5.4.10.10.7" class="ltx_td ltx_align_left">white</td>
</tr>
<tr id="S4.T5.4.11.11" class="ltx_tr">
<td id="S4.T5.4.11.11.1" class="ltx_td ltx_align_center ltx_border_r">(10)</td>
<td id="S4.T5.4.11.11.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.11.11.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.11.11.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.11.11.5" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="S4.T5.4.11.11.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S4.T5.4.11.11.7" class="ltx_td ltx_align_left">Hamas</td>
</tr>
<tr id="S4.T5.4.12.12" class="ltx_tr">
<td id="S4.T5.4.12.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(11)</td>
<td id="S4.T5.4.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="S4.T5.4.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.4.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8</td>
<td id="S4.T5.4.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7</td>
<td id="S4.T5.4.12.12.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">(S,S,7),(R,R,2)</td>
<td id="S4.T5.4.12.12.7" class="ltx_td ltx_align_left ltx_border_t">globalist, gay mafia, christian</td>
</tr>
<tr id="S4.T5.4.13.13" class="ltx_tr">
<td id="S4.T5.4.13.13.1" class="ltx_td ltx_align_center ltx_border_r">(12)</td>
<td id="S4.T5.4.13.13.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.13.13.3" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="S4.T5.4.13.13.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.13.13.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.13.13.6" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S4.T5.4.13.13.7" class="ltx_td ltx_align_left">white christian nationalism</td>
</tr>
<tr id="S4.T5.4.14.14" class="ltx_tr">
<td id="S4.T5.4.14.14.1" class="ltx_td ltx_align_center ltx_border_r">(13)</td>
<td id="S4.T5.4.14.14.2" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="S4.T5.4.14.14.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.14.14.4" class="ltx_td ltx_align_center ltx_border_r">17</td>
<td id="S4.T5.4.14.14.5" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="S4.T5.4.14.14.6" class="ltx_td ltx_align_left ltx_border_r">(S,S,6),(R,R,1)</td>
<td id="S4.T5.4.14.14.7" class="ltx_td ltx_align_left">gay, tansgender, facist christians</td>
</tr>
<tr id="S4.T5.4.15.15" class="ltx_tr">
<td id="S4.T5.4.15.15.1" class="ltx_td ltx_align_center ltx_border_r">(14)</td>
<td id="S4.T5.4.15.15.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.15.15.3" class="ltx_td ltx_align_center ltx_border_r">2</td>
<td id="S4.T5.4.15.15.4" class="ltx_td ltx_align_center ltx_border_r">8</td>
<td id="S4.T5.4.15.15.5" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.15.15.6" class="ltx_td ltx_align_left ltx_border_r">(S,S,1)</td>
<td id="S4.T5.4.15.15.7" class="ltx_td ltx_align_left">gay, white</td>
</tr>
<tr id="S4.T5.4.16.16" class="ltx_tr">
<td id="S4.T5.4.16.16.1" class="ltx_td ltx_align_center ltx_border_r">(15)</td>
<td id="S4.T5.4.16.16.2" class="ltx_td ltx_align_center ltx_border_r">1</td>
<td id="S4.T5.4.16.16.3" class="ltx_td ltx_align_center ltx_border_r">4</td>
<td id="S4.T5.4.16.16.4" class="ltx_td ltx_align_center ltx_border_r">60</td>
<td id="S4.T5.4.16.16.5" class="ltx_td ltx_align_center ltx_border_r">3</td>
<td id="S4.T5.4.16.16.6" class="ltx_td ltx_align_left ltx_border_r">(S,S,22),(R,R,3)</td>
<td id="S4.T5.4.16.16.7" class="ltx_td ltx_align_left">gay, homosexuality, homosexual</td>
</tr>
<tr id="S4.T5.4.17.17" class="ltx_tr">
<td id="S4.T5.4.17.17.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">(16)</td>
<td id="S4.T5.4.17.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.4.17.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="S4.T5.4.17.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S4.T5.4.17.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="S4.T5.4.17.17.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S4.T5.4.17.17.7" class="ltx_td ltx_align_left ltx_border_t">religion, Jewish, white</td>
</tr>
<tr id="S4.T5.4.18.18" class="ltx_tr">
<td id="S4.T5.4.18.18.1" class="ltx_td ltx_align_center ltx_border_r">(17)</td>
<td id="S4.T5.4.18.18.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.18.18.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.18.18.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.18.18.5" class="ltx_td ltx_align_center ltx_border_r">7</td>
<td id="S4.T5.4.18.18.6" class="ltx_td ltx_align_left ltx_border_r">(R,R,6)</td>
<td id="S4.T5.4.18.18.7" class="ltx_td ltx_align_left">Allah, Israelis, murderers rapist</td>
</tr>
<tr id="S4.T5.4.19.19" class="ltx_tr">
<td id="S4.T5.4.19.19.1" class="ltx_td ltx_align_center ltx_border_r">(18)</td>
<td id="S4.T5.4.19.19.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.19.19.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.19.19.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.19.19.5" class="ltx_td ltx_align_center ltx_border_r">22</td>
<td id="S4.T5.4.19.19.6" class="ltx_td ltx_align_left ltx_border_r">(R,R,14)</td>
<td id="S4.T5.4.19.19.7" class="ltx_td ltx_align_left">christian, religion</td>
</tr>
<tr id="S4.T5.4.20.20" class="ltx_tr">
<td id="S4.T5.4.20.20.1" class="ltx_td ltx_align_center ltx_border_r">(19)</td>
<td id="S4.T5.4.20.20.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.20.20.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.20.20.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.20.20.5" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="S4.T5.4.20.20.6" class="ltx_td ltx_align_left ltx_border_r">(R,R,2)</td>
<td id="S4.T5.4.20.20.7" class="ltx_td ltx_align_left">religion, christianity</td>
</tr>
<tr id="S4.T5.4.21.21" class="ltx_tr">
<td id="S4.T5.4.21.21.1" class="ltx_td ltx_align_center ltx_border_r">(20)</td>
<td id="S4.T5.4.21.21.2" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.21.21.3" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.21.21.4" class="ltx_td ltx_align_center ltx_border_r">0</td>
<td id="S4.T5.4.21.21.5" class="ltx_td ltx_align_center ltx_border_r">14</td>
<td id="S4.T5.4.21.21.6" class="ltx_td ltx_align_left ltx_border_r">(R,R,20)</td>
<td id="S4.T5.4.21.21.7" class="ltx_td ltx_align_left">Islam</td>
</tr>
<tr id="S4.T5.4.22.22" class="ltx_tr">
<td id="S4.T5.4.22.22.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">Total</td>
<td id="S4.T5.4.22.22.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">145</td>
<td id="S4.T5.4.22.22.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">38</td>
<td id="S4.T5.4.22.22.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">96</td>
<td id="S4.T5.4.22.22.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">80</td>
<td id="S4.T5.4.22.22.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_tt">-</td>
<td id="S4.T5.4.22.22.7" class="ltx_td ltx_align_left ltx_border_b ltx_border_tt">-</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p">Table <a href="#S4.T5" title="Table 5 ‣ 4.1. Methodology and main findings ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> reveals that users’ most frequently used category in these news items is ’gender,’ with 145 comments. This is followed by ’sexual orientation’ with 96 comments, ’religion’ with 80, and ’ethnicity’ with 38 comments. Regarding intersections, the results indicate a dominance of intra-category intersections. Examples of such intersections include comments in news item (1), featuring 26 intra-category intersections in ’gender’, and news item (7) with 73 intra-category intersections in ’gender’. In news item (1), intra-category intersections are exemplified by overlaps between ’biological men’ and ’transgender’, and ’biological men’ and ’outperform women’. In news item (7), examples include intersections between ’Hamas’ and ’kill babies’, and ’Muslims’ and ’Zionist’. Additionally, Table <a href="#S4.T5" title="Table 5 ‣ 4.1. Methodology and main findings ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> also reveals inter-category intersections in four news items: intersections occur between ’gender’ and ’religion’ in the news item (7) and between ’sexual orientation’ and ’religion’ in news items (11), (13), and (15). Overall, a low level of inter-category intersectionality is observed.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">We examined the linear dependency between interaction variables (comments, shares, and reactions) and mentions of identity group categories. The Pearson linear correlation coefficients are presented in Table <a href="#S4.T6" title="Table 6 ‣ 4.1. Methodology and main findings ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.2.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>. </span><span id="S4.T6.3.2" class="ltx_text" style="font-size:90%;">Correlation between interaction variables and mentions.</span></figcaption>
<table id="S4.T6.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.4.1.1" class="ltx_tr">
<th id="S4.T6.4.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"></th>
<th id="S4.T6.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Comments</th>
<th id="S4.T6.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Shares</th>
<th id="S4.T6.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Reactions</th>
<th id="S4.T6.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Gender</th>
<th id="S4.T6.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Ethnicity</th>
<th id="S4.T6.4.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Sexual Or.</th>
<th id="S4.T6.4.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Religion</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.4.2.1" class="ltx_tr">
<th id="S4.T6.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Comments</th>
<td id="S4.T6.4.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.000</td>
<td id="S4.T6.4.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.880</td>
<td id="S4.T6.4.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.811</td>
<td id="S4.T6.4.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.219</td>
<td id="S4.T6.4.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.141</td>
<td id="S4.T6.4.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.340</td>
<td id="S4.T6.4.2.1.8" class="ltx_td ltx_align_center ltx_border_t">-0.027</td>
</tr>
<tr id="S4.T6.4.3.2" class="ltx_tr">
<th id="S4.T6.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Shares</th>
<td id="S4.T6.4.3.2.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.3.2.3" class="ltx_td ltx_align_center ltx_border_r">1.000</td>
<td id="S4.T6.4.3.2.4" class="ltx_td ltx_align_center ltx_border_r">0.737</td>
<td id="S4.T6.4.3.2.5" class="ltx_td ltx_align_center ltx_border_r">0.114</td>
<td id="S4.T6.4.3.2.6" class="ltx_td ltx_align_center ltx_border_r">0.203</td>
<td id="S4.T6.4.3.2.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.4.3.2.7.1" class="ltx_text ltx_font_bold">0.557</span></td>
<td id="S4.T6.4.3.2.8" class="ltx_td ltx_align_center">-0.180</td>
</tr>
<tr id="S4.T6.4.4.3" class="ltx_tr">
<th id="S4.T6.4.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Reactions</th>
<td id="S4.T6.4.4.3.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.4.3.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.4.3.4" class="ltx_td ltx_align_center ltx_border_r">1.000</td>
<td id="S4.T6.4.4.3.5" class="ltx_td ltx_align_center ltx_border_r">0.261</td>
<td id="S4.T6.4.4.3.6" class="ltx_td ltx_align_center ltx_border_r">0.141</td>
<td id="S4.T6.4.4.3.7" class="ltx_td ltx_align_center ltx_border_r">0.057</td>
<td id="S4.T6.4.4.3.8" class="ltx_td ltx_align_center">-0.181</td>
</tr>
<tr id="S4.T6.4.5.4" class="ltx_tr">
<th id="S4.T6.4.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Gender</th>
<td id="S4.T6.4.5.4.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.5.4.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.5.4.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.5.4.5" class="ltx_td ltx_align_center ltx_border_r">1.000</td>
<td id="S4.T6.4.5.4.6" class="ltx_td ltx_align_center ltx_border_r">0.284</td>
<td id="S4.T6.4.5.4.7" class="ltx_td ltx_align_center ltx_border_r">-0.110</td>
<td id="S4.T6.4.5.4.8" class="ltx_td ltx_align_center">-0.145</td>
</tr>
<tr id="S4.T6.4.6.5" class="ltx_tr">
<th id="S4.T6.4.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Ethnicity</th>
<td id="S4.T6.4.6.5.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.6.5.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.6.5.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.6.5.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.6.5.6" class="ltx_td ltx_align_center ltx_border_r">1.000</td>
<td id="S4.T6.4.6.5.7" class="ltx_td ltx_align_center ltx_border_r">0.075</td>
<td id="S4.T6.4.6.5.8" class="ltx_td ltx_align_center">0.177</td>
</tr>
<tr id="S4.T6.4.7.6" class="ltx_tr">
<th id="S4.T6.4.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Sexual Orientation</th>
<td id="S4.T6.4.7.6.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.7.6.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.7.6.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.7.6.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.7.6.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T6.4.7.6.7" class="ltx_td ltx_align_center ltx_border_r">1.000</td>
<td id="S4.T6.4.7.6.8" class="ltx_td ltx_align_center">-0.053</td>
</tr>
<tr id="S4.T6.4.8.7" class="ltx_tr">
<th id="S4.T6.4.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r">Religion</th>
<td id="S4.T6.4.8.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="S4.T6.4.8.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="S4.T6.4.8.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="S4.T6.4.8.7.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="S4.T6.4.8.7.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="S4.T6.4.8.7.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="S4.T6.4.8.7.8" class="ltx_td ltx_align_center ltx_border_b">1.000</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">Table <a href="#S4.T6" title="Table 6 ‣ 4.1. Methodology and main findings ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> reveals a low linear correlation between interaction variables and identity group categories. A linear dependency is observed only between the ’shares’ interaction variable and mentions of groups in the ’sexual orientation’ category, with a correlation of 0.557.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para ltx_noindent">
<p id="S4.SS1.p7.1" class="ltx_p"><span id="S4.SS1.p7.1.1" class="ltx_text ltx_font_bold">Main findings</span>. The main findings of the case study suggest a predominance of comments that involve mentions of ’gender’ and ’sexual orientation’, with a high level of intra-category intersectionality and low inter-category intersectionality. The study also reveals a weak correlation between interaction variables and mentions of groups, with the only significant linear dependence being between ’shares’ and mentions of ’sexual orientation’.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Inspection of relevant cases</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We examined several examples to illustrate the findings our tool can uncover. Three news articles were selected based on the volume of comments featuring mentions of identity groups detected by our tool. These are article (1) from the ’gender’ category, article (7) from the ’ethnicities’ category, and article (15) from the ’sexual orientation’ category.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Starting with article (1) (see Fig. <a href="#S4.F3" title="Figure 3 ‣ 4.2. Inspection of relevant cases ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), we present a few examples of comments triggered by its content. The article discusses the Ohio General Assembly’s decision to restrict transgender athletes’ participation in athletics. The bill limits gender-affirming initiatives for participating in girls’ sports. Fig. <a href="#S4.F3" title="Figure 3 ‣ 4.2. Inspection of relevant cases ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> displays comments on the news and user interactions, including responses and counter-responses. Selected examples from this information cascade show comments mentioning entities related to ’sexual orientation’ and ’gender’. Notably, no comment includes inter-group mentions, but some comments repeat mentions of the same group. This is evident in the first comment, mentioning both ’trans people’ and ’hate women,’ both from the ’gender’ category. There is no observed intersectionality between categories. The correct and wrong marks indicate whether the tool’s detection accurately represents an entity mentioned in a toxic discussion context, meaning both conditions must be met: a mention representing an attack or threat within an aggressive comment. In this article, all entity mentions correspond to mentions of aggressive interactions.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2405.13011/assets/case_1.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="589" height="198" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">News (1) showing interactions between users. Our tool detects some gender and sexual orientation attacks during the conversation.</span></figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">For news (7) (see Fig. <a href="#S4.F4" title="Figure 4 ‣ 4.2. Inspection of relevant cases ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), the story covers an exhibition of black dolls, highlighting the presence of slavery in the United States during the 18th century. Such a topic is expected to generate aggressive comments related to ’racism’ and ’ethnicities’, which is indeed observed in the initial interactions of the example. While the first comment suggests that racism no longer exists, the second delves into details of the exhibition, mentioning Anthony Johnson, an Angolan black man known for acquiring wealth in early 17th-century Virginia, one of the first African American landowners who, through a Virginia court ruling, legally owned a slave. The next three comments feature mentions that do not align with threatened entities. In the third comment, ’brutality’ is marked as an entity, a false positive. The same happens with the last comments, where ’black’ and ’black American’ are tagged as entities from the ’ethnicity’ category but not in the context of aggressive comments. Both instances show that these comments are healthy, lacking aggressive expressions, leading to the conclusion that these are false positives: while they tag entities that belong to ’ethnicity’, these mentions do not occur in the context of threatening or attacking comments.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2405.13011/assets/case_2.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="601" height="202" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">News (7) showing interactions between users. Our tool detects some attacks and mentions regarding racism and ethnicities during the conversation.</span></figcaption>
</figure>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">The third case, news (15) (see Fig. <a href="#S4.F5" title="Figure 5 ‣ 4.2. Inspection of relevant cases ‣ 4. Case study ‣ Unveiling Social Media Comments with a Novel Named Entity Recognition System for Identity Groups" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), falls under the ’sexual orientation’ category. It addresses the limitations imposed by the ’don’t say gay’ rules in Florida’s school education. A topic like this is expected to stir up conservative and liberal positions regarding ’sexual orientation’. The tool marks mention of entities related to ’sexual orientation,’ predominantly the mention of ’gay.’ Like the previous case, the first two comments are not aggressive and are marked as false positives, while the latter contain mentions considered threats. These last comments occur in the context of user replies, indicating, as in the previous cases, that aggression arises not concerning the news but from user interactions.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2405.13011/assets/case_3.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>. </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">News (15) showing interactions between users. Our tool detects some attacks and mentions regarding sexual orientation during the conversation.</span></figcaption>
</figure>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.1" class="ltx_p"><span id="S4.SS2.p5.1.1" class="ltx_text ltx_font_bold">Main findings</span>. The tool effectively detects named entities related to the categories of the analyzed news articles. Entities are accurately tagged within their categories, with a negligible error rate for inter-category tagging. However, false positives are observed with tags on tokens not corresponding to entity mentions (e.g., ’brutality’). In some instances, the tool fails to distinguish between aggressive and healthy contexts, marking mentioned entities regardless of the use of toxic language.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We have developed a versatile NER tool for identity group tagging, capable of effectively labeling groups across a broad range of categories such as ’gender’, ’sexual orientation’, ’religion’, and ’ethnicity’. This NER was trained by aligning two tasks: entity recognition from the <span id="S5.p1.1.1" class="ltx_text ltx_font_bold">HateNorm 2023 dataset</span>, which identifies text spans of named identity groups, and the <span id="S5.p1.1.2" class="ltx_text ltx_font_bold">Jigsaw Toxicity dataset</span>, created for sentence-level classification. By aligning both datasets, we fine-tuned a conventional NER, enabling it to recognize identity groups in the aforementioned categories. The tool performs well on the test set of the dataset. Subsequently, we applied the tool to social media comments as part of a case study. This study suggests a predominance of comments involving mentions of ’gender’ and ’sexual orientation’, with a high level of intra-category intersectionality and low inter-category intersectionality. It also reveals a weak correlation between interaction variables and group mentions, with the only significant linear dependence being between ’shares’ and mentions of ’sexual orientation’. An analysis of relevant cases shows that the tool effectively detects named entities related to the categories in the analyzed news articles. Entities are accurately tagged within their categories, with a negligible error rate for inter-category tagging. However, false positives occur with tags on tokens not corresponding to entity mentions. In some instances, the tool fails to distinguish between aggressive and healthy contexts, marking mentioned entities regardless of the use of toxic language, which is the main limitation of the tool.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">For future work, we aim to refine our NER tool to better differentiate between offensive and neutral mentions of identity groups. This involves expanding our dataset to include more examples from healthy conversations, enhancing the model’s ability to distinguish the context in which identity groups are mentioned. Furthermore, we plan to address the complexity of separating offensive mentions directly linked to an attack from those where the identity mention is separate. This distinction will lead us to explore Joint Entity Relation (JER) tagging, leveraging conditional parsing models for a more nuanced analysis. Incorporating advancements in Spanish language models, as seen in the works of Cañete et al. and Araujo et al., will also be crucial in broadening our tool’s linguistic and cultural applicability <cite class="ltx_cite ltx_citemacro_citep">(Cañete et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2022</a>; Araujo et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Study limitations</span>. In some instances, the NER tool fails to distinguish between aggressive and healthy contexts, marking mentioned entities regardless of the use of toxic language. Some examples also show that the NER tool produces false positives, mistaking the mention of a group for an attack. This indicates the need for more finely-grained annotations to distinguish between these cases, suggesting using JER-type models to address specific situations. The case study’s purpose is exploratory, and no generalizable conclusions can be drawn. It merely represents a case that provides preliminary evidence, requiring further studies to corroborate its findings. The case study does not represent a significant sample of the reality of social networks, as it is limited to only one information source and a single platform. A more comprehensive case study requires the analysis of multiple information sources.
Additionally, comparing different social networks is necessary to compare distinct age groups. We decided not to include additional categories studied in the problem of hate speech detection, such as disability, due to the limited number of annotated examples in this category within the Jigsaw toxicity dataset. Addressing this limitation would require a significant effort in manually annotating examples in a quantity equivalent to that of the datasets employed in this study.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alatawi et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hind S Alatawi, Areej M Alhothali, and Kawthar M Moria. 2021.

</span>
<span class="ltx_bibblock">Detecting white supremacist hate speech using domain specific word embedding with deep learning and BERT.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 9 (2021), 106363–106374.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alvarez et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Claudio Alvarez, Gustavo Zurita, Andrés Carvallo, Pablo Ramírez, Eugenio Bravo, and Nelson Baloian. 2021.

</span>
<span class="ltx_bibblock">Automatic content analysis of student moral discourse in a collaborative learning activity. In <em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Collaboration Technologies and Social Computing: 27th International Conference, CollabTech 2021, Virtual Event, August 31–September 3, 2021, Proceedings 27</em>. Springer, 3–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Araujo et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Vladimir Araujo, Andrés Carvallo, Souvik Kundu, José Cañete, Marcelo Mendoza, Robert E Mercer, Felipe Bravo-Marquez, Marie-Francine Moens, and Alvaro Soto. 2022.

</span>
<span class="ltx_bibblock">Evaluation benchmarks for Spanish sentence representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.07571</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cañete et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
José Cañete, Sebastian Donoso, Felipe Bravo-Marquez, Andrés Carvallo, and Vladimir Araujo. 2022.

</span>
<span class="ltx_bibblock">Albeto and distilbeto: Lightweight spanish language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.09145</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carvallo and Parra (2019)</span>
<span class="ltx_bibblock">
Andres Carvallo and Denis Parra. 2019.

</span>
<span class="ltx_bibblock">Comparing Word Embeddings for Document Screening based on Active Learning.. In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">BIRNDL@ SIGIR</em>. 100–107.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carvallo et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Andres Carvallo, Denis Parra, Hans Lobel, and Alvaro Soto. 2020a.

</span>
<span class="ltx_bibblock">Automatic document screening of medical literature using word and text embeddings in an active learning setting.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Scientometrics</em> 125, 3 (2020), 3047–3084.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carvallo et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Andres Carvallo, Denis Parra, Gabriel Rada, Daniel Pérez, Juan Ignacio Vasquez, and Camilo Vergara. 2020b.

</span>
<span class="ltx_bibblock">Neural language models for text classification in evidence-based medicine.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.00584</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carvallo et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Andrés Carvallo, Matías Rojas, Carlos Munoz-Castro, Claudio Aracena, Rodrigo Guerra, Benjamín Pizarro, and Jocelyn Dunstan. 2023.

</span>
<span class="ltx_bibblock">Automatic Section Classification in Spanish Clinical Narratives Using Chunked Named Entity Recognition. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Iberian Languages Evaluation Forum (IberLEF 2023), CEUR Workshop Proceedings. CEUR-WS. org</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Del Vigna12 et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Fabio Del Vigna12, Andrea Cimino23, Felice Dell’Orletta, Marinella Petrocchi, and Maurizio Tesconi. 2017.

</span>
<span class="ltx_bibblock">Hate me, hate me not: Hate speech detection on facebook. In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proceedings of the first Italian conference on cybersecurity (ITASEC17)</em>. 86–95.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ElSherief et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Mai ElSherief, Vivek Kulkarni, Dana Nguyen, William Yang Wang, and Elizabeth Belding. 2018.

</span>
<span class="ltx_bibblock">Hate lingo: A target-based linguistic analysis of hate speech in social media. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of the international AAAI conference on web and social media</em>, Vol. 12.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gambäck and Sikdar (2017)</span>
<span class="ltx_bibblock">
Björn Gambäck and Utpal Kumar Sikdar. 2017.

</span>
<span class="ltx_bibblock">Using convolutional neural networks to classify hate-speech. In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the first workshop on abusive language online</em>. 85–90.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodall (2013)</span>
<span class="ltx_bibblock">
Kay Goodall. 2013.

</span>
<span class="ltx_bibblock">Challenging hate speech: Incitement to hatred on grounds of sexual orientation in England, Wales and Northern Ireland.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Protection of Sexual Minorities since Stonewall</em>. Routledge, 79–100.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Lingyao Li, Lizhou Fan, Shubham Atreja, and Libby Hemphill. 2023.

</span>
<span class="ltx_bibblock">” HOT” ChatGPT: The promise of ChatGPT in detecting and discriminating hateful, offensive, and toxic comments on social media.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.10619</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MacAvaney et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Sean MacAvaney, Hao-Ren Yao, Eugene Yang, Katina Russell, Nazli Goharian, and Ophir Frieder. 2019.

</span>
<span class="ltx_bibblock">Hate speech detection: Challenges and solutions.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">PloS one</em> 14, 8 (2019), e0221152.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masud et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Sarah Masud, Manjot Bedi, Mohammad Aflah Khan, Md Shad Akhtar, and Tanmoy Chakraborty. 2022.

</span>
<span class="ltx_bibblock">Proactively Reducing the Hate Intensity of Online Posts via Hate Speech Normalization. In <em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em> (Washington DC, USA) <em id="bib.bib16.4.2" class="ltx_emph ltx_font_italic">(KDD ’22)</em>. Association for Computing Machinery, New York, NY, USA, 3524–3534.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3534678.3539161" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3534678.3539161</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra and Chatterjee (2023)</span>
<span class="ltx_bibblock">
Shyamal Mishra and Preetha Chatterjee. 2023.

</span>
<span class="ltx_bibblock">Exploring ChatGPT for Toxicity Detection in GitHub.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.13105</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mubarak et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Hamdy Mubarak, Hend Al-Khalifa, and AbdulMohsen Al-Thubaity. 2022.

</span>
<span class="ltx_bibblock">Overview of OSACT5 shared task on arabic offensive language and hate speech detection. In <em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Proceedinsg of the 5th Workshop on Open-Source Arabic Corpora and Processing Tools with Shared Tasks on Qur’an QA and Fine-Grained Hate Speech Detection</em>. 162–166.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muñoz-Castro et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Carlos Muñoz-Castro, Andrés Carvallo, Matías Rojas, Claudio Aracena, Rodrigo Guerra, Benjamín Pizarro, and Jocelyn Dunstan. 2023.

</span>
<span class="ltx_bibblock">LinkMed: Entity Recognition and Relation Extraction from Clinical Notes in Spanish.

</span>
<span class="ltx_bibblock">(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poletto et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Fabio Poletto, Valerio Basile, Manuela Sanguinetti, Cristina Bosco, and Viviana Patti. 2021.

</span>
<span class="ltx_bibblock">Resources and benchmark corpora for hate speech detection: a systematic review.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Language Resources and Evaluation</em> 55 (2021), 477–523.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saleh et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hind Saleh, Areej Alhothali, and Kawthar Moria. 2023.

</span>
<span class="ltx_bibblock">Detection of hate speech using BERT and hate speech word embedding with deep model.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Applied Artificial Intelligence</em> 37, 1 (2023), 2166719.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Satapara et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Shrey Satapara, Prasenjit Majumder, Thomas Mandl, Sandip Modha, Hiren Madhu, Tharindu Ranasinghe, Marcos Zampieri, Kai North, and Damith Premasiri. 2022.

</span>
<span class="ltx_bibblock">Overview of the hasoc subtrack at fire 2022: Hate speech and offensive content identification in english and indo-aryan languages. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 14th annual meeting of the forum for information retrieval evaluation</em>. 4–7.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shvets et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Alexander Shvets, Paula Fortuna, Juan Soler, and Leo Wanner. 2021.

</span>
<span class="ltx_bibblock">Targets and aspects in social media hate speech. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</em>. 179–190.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sorensen et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Jeffrey Sorensen, Julia Elliott, Lucas Dixon, Mark McDonald, and Nick Cukierski. 2017.

</span>
<span class="ltx_bibblock">Toxic Comment Classification Challenge.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Bencheng Wei, Jason Li, Ajay Gupta, Hafiza Umair, Atsu Vovor, and Natalie Durzynski. 2021.

</span>
<span class="ltx_bibblock">Offensive language and hate speech detection with deep learning and transfer learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.03305</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin and Zubiaga (2021)</span>
<span class="ltx_bibblock">
Wenjie Yin and Arkaitz Zubiaga. 2021.

</span>
<span class="ltx_bibblock">Towards generalisable hate speech detection: a review on obstacles and solutions.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">PeerJ Computer Science</em> 7 (2021), e598.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zampieri et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, and Ritesh Kumar. 2019.

</span>
<span class="ltx_bibblock">Predicting the type and target of offensive posts in social media.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1902.09666</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ziqi Zhang, David Robinson, and Jonathan Tepper. 2018.

</span>
<span class="ltx_bibblock">Detecting hate speech on twitter using a convolution-gru based deep neural network. In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">The Semantic Web: 15th International Conference, ESWC 2018, Heraklion, Crete, Greece, June 3–7, 2018, Proceedings 15</em>. Springer, 745–760.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ștefăniță and Buf (2021)</span>
<span class="ltx_bibblock">
Oana Ștefăniță and Diana-Maria Buf. 2021.

</span>
<span class="ltx_bibblock">Hate speech in social media and its effects on the LGBT community: A review of the current research.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Romanian Journal of Communication and Public Relations</em> 23, 1 (2021), 47–55.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethical aspects</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Statements on Ethical Considerations</span>. The study is conducted within the disciplinary line of a publicly funded research center. There has been no interference from supporters in the design or results of the study. The project underwent review by the institutional ethics committee, which approved it without any observations. Data has been securely stored for the purpose of the study and will be deleted after three years. All social media data has been anonymized to protect user privacy. The data has been collected from public sources. Access to META content is under an agreement for the use of the Crowdtangle platform, which allows for the use of its search engine on public pages and the HateNorm and Jigsaw toxicity datasets are public.</p>
</div>
<div id="Sx1.p2" class="ltx_para ltx_noindent">
<p id="Sx1.p2.1" class="ltx_p"><span id="Sx1.p2.1.1" class="ltx_text ltx_font_bold">Statements of Researcher Positionality</span>. The researchers involved in this study hold personal positions related to their own belief systems, political orientations, and religious beliefs. These views within the group are diverse and have not played a central role in the design and purpose of the study. There are no institutions with political or religious agendas influencing this study. The findings and conclusions of this study have not been subjected to review committees external to the author group, ensuring that they are conveyed without censorship or editorial influence from any group or institution.</p>
</div>
<div id="Sx1.p3" class="ltx_para ltx_noindent">
<p id="Sx1.p3.1" class="ltx_p"><span id="Sx1.p3.1.1" class="ltx_text ltx_font_bold">Adverse Impacts Statements</span>. This research does not present any evident adverse effects. It aims to enhance transparency in online discussions about controversial topics by providing additional resources to researchers and practitioners interested in analyzing mentions of identity groups on social media. The benefits of this study lie in strengthening the management tools of public forums, by gathering information regarding hate speech and the identification of mentions of identity groups on social media.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.13010" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.13011" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.13011">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.13011" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.13014" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 17:49:44 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
