<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.08368] ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana</title><meta property="og:description" content="Indigenous languages are a fundamental legacy in the development of human communication, embodying the unique identity and culture of local communities of America. The Second AmericasNLP Competition Track 1 of NeurIPS …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.08368">

<!--Generated on Sun May  5 19:14:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Monica Romero
</span><span class="ltx_author_notes">Corresponding Author: e-mail: monica.romero@alumnos.upm.es</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sandra Gomez
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Iván G.  Torre
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">Escuela Técnica Superior de Ingeniería de Sistemas Informáticos, ETSISI, Universidad Politécnica de Madrid, Alan Turing, 28031 Madrid, Spain
</span>
<span class="ltx_contact ltx_role_address">Departamento de Matemática Aplicada, ETSIAE, Universidad Politécnica de Madrid, Plaza Cardenal Cisneros, 28040 Madrid, Spain
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Indigenous languages are a fundamental legacy in the development of human communication, embodying the unique identity and culture of local communities of America. The Second AmericasNLP Competition Track 1 of NeurIPS 2022 proposed developing automatic speech recognition (ASR) systems for five indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana. In this paper, we propose a reliable ASR model for each target language by crawling speech corpora spanning diverse sources and applying data augmentation methods that resulted in the winning approach in this competition. To achieve this, we systematically investigated the impact of different hyperparameters by a Bayesian search on the performance of the language models, specifically focusing on the variants of the Wav2vec2.0 XLS-R model: 300M and 1B parameters. Moreover, we performed a global sensitivity analysis to assess the contribution of various hyperparametric configurations to the performances of our best models. Importantly, our results show that freeze fine-tuning updates and dropout rate are more vital parameters than the total number of epochs of lr. Additionally, we liberate our best models –with no other ASR model reported until now for two Wa'ikhana and Kotiria– and the many experiments performed to pave the way to other researchers to continue improving ASR in minority languages. This insight opens up interesting avenues for future work, allowing for the advancement of ASR techniques in the preservation of minority indigenous and acknowledging the complexities involved in this important endeavour.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Automatic speech recognition <span id="id2.id1" class="ltx_ERROR undefined">\sep</span>Natural language processing <span id="id3.id2" class="ltx_ERROR undefined">\sep</span>Low-resource languages <span id="id4.id3" class="ltx_ERROR undefined">\sep</span>Indigenous languages <span id="id5.id4" class="ltx_ERROR undefined">\sep</span>NeurIPS

</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">,</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.3" class="ltx_p">Indigenous languages are natural languages that have linguistically evolved in a particular region attributed to a specific community <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. They are a paramount heritage of the evolution of language, representing the identity and culture of the local communities and their cultural contributions constitute an immensely valuable legacy for society  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. The lexicon and grammar of indigenous languages contain knowledge about local ecosystems, traditional techniques, spiritual beliefs and political organization  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. These languages convey a diverse, rich, ancient narrative characterized by pluralism, heterogeneity, and depth  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. They encapsulate the wisdom and accumulated knowledge of generations, often closely tied to the land, natural resources and the local and ecological constraints  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. However, the small number of speaking inhabitants, the absence in many cases of writing tradition, the pressure of the dominant languages or even the dissolution of the native communities have led to a continuous and progressive extinction of indigenous languages during the last decades  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Actually, <math id="S1.p1.1.m1.1" class="ltx_Math" alttext="7000" display="inline"><semantics id="S1.p1.1.m1.1a"><mn id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">7000</mn><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><cn type="integer" id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1">7000</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">7000</annotation></semantics></math> languages are spoken worldwide and <math id="S1.p1.2.m2.1" class="ltx_Math" alttext="6000" display="inline"><semantics id="S1.p1.2.m2.1a"><mn id="S1.p1.2.m2.1.1" xref="S1.p1.2.m2.1.1.cmml">6000</mn><annotation-xml encoding="MathML-Content" id="S1.p1.2.m2.1b"><cn type="integer" id="S1.p1.2.m2.1.1.cmml" xref="S1.p1.2.m2.1.1">6000</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.2.m2.1c">6000</annotation></semantics></math> of them are considered Indigenous languages. However, nearly half are endangered, and approximately <math id="S1.p1.3.m3.1" class="ltx_Math" alttext="1500" display="inline"><semantics id="S1.p1.3.m3.1a"><mn id="S1.p1.3.m3.1.1" xref="S1.p1.3.m3.1.1.cmml">1500</mn><annotation-xml encoding="MathML-Content" id="S1.p1.3.m3.1b"><cn type="integer" id="S1.p1.3.m3.1.1.cmml" xref="S1.p1.3.m3.1.1">1500</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.3.m3.1c">1500</annotation></semantics></math> are at extreme risk of extinction  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Globalization and technological advances in Artificial Intelligence (AI) have further accelerated the hazard to minority languages because solutions based on Natural Language Processing (NLP) and AI are only available for a few dozen languages  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Preserving indigenous languages is an objective to safeguard local communities' heritage and cultural identity and is crucial for retaining critical knowledge associated with environmental interaction and understanding the social aspects of language evolution  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
<br class="ltx_break"></p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.3" class="ltx_p">To address the gap between AI solutions for majority and indigenous languages, the initiative Second AmericasNLP Competition Track 1 of NeurIPS 2022  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, proposed to the participants to develop automatic speech recognition (ASR) systems for five different indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana. Bribri is a Chibchan family language spoken by approximately <math id="S1.p2.1.m1.1" class="ltx_Math" alttext="7500" display="inline"><semantics id="S1.p2.1.m1.1a"><mn id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">7500</mn><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><cn type="integer" id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">7500</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">7500</annotation></semantics></math> speakers in areas of Costa Rica and Panama <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. Meanwhile, Guarani is spoken in Paraguay, Argentina, Bolivia and Brazil and is one of the most significant Amerindian languages in terms of numerical importance, with 6–10 million speakers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Kotiria –or Wanano– is one of the sixteen languages of the eastern branch of the Tukanoan language family  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> and it is spoken in the northwest of the Amazon region, in the territory between Brazil and Colombia. Approximately <math id="S1.p2.2.m2.1" class="ltx_Math" alttext="2000" display="inline"><semantics id="S1.p2.2.m2.1a"><mn id="S1.p2.2.m2.1.1" xref="S1.p2.2.m2.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><cn type="integer" id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">2000</annotation></semantics></math> speakers are distributed between Colombia and Brazil <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Then, Wa'ikhana –or Piratapuyo– is also an eastern Tukanoan language spoken in Brazil and Colombia with less than <math id="S1.p2.3.m3.1" class="ltx_Math" alttext="2000" display="inline"><semantics id="S1.p2.3.m3.1a"><mn id="S1.p2.3.m3.1.1" xref="S1.p2.3.m3.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S1.p2.3.m3.1b"><cn type="integer" id="S1.p2.3.m3.1.1.cmml" xref="S1.p2.3.m3.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.3.m3.1c">2000</annotation></semantics></math> speakers  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Finally, Quechua is a heterogeneous language spoken across the Andes, stretching from southern Colombia to northwest Argentina, encompassing a diverse family of languages and dialects  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> with more than 6.5 million speakers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
<br class="ltx_break"></p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Indigenous languages and, more generally, languages with limited or relatively fewer data available are denoted in AI and NLP as low-resource languages with a critical level of under-documentation  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. They pose a significant challenge for developing robust and accurate ASR systems, as actual algorithms primarily rely on the availability of substantial amounts of labelled data. Despite the difficulty of the task, ASR in low-resource languages has attracted the attention of the scientific community who have proposed new approaches to this issue, including speech augmentation techniques  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, semi-supervised models  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, fully unsupervised learning methods  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and transfer learning techniques  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> among others solutions.
<br class="ltx_break"></p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">In this paper, we present our winning approach in the ASR subtask of America's Challenge competition of Neurips 2022 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. For this purpose, we have trained and optimized an ASR system for each language: Bribri, Guarani, Kotiria, Wa'ikhana, and Quechua. This marks the first time an ASR model has been developed for the Wa'ikhana and Kotiria languages, and we report the first results for these languages in the literature. We addressed the challenge of limited training data by leveraging a semi-supervised model and subsequent fine-tuning using the Wav2vec2.0 framework and applying speed augmentation techniques. The training phase involved meticulous model selection based on performance metrics hyperparameter optimization. Additionally, we constructed comprehensive n-gram language models using text corpora for the decoding, but the Greedy Search algorithm, supplemented with heuristic corrections, showed better preciseness. Our ASR system showed an average Character Error Rate (CER) of 26.85, achieving the best solution in the competition.
<br class="ltx_break"></p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">The rest of the paper is organized as follows: Section 2 reviews previous research done in ASR of indigenous languages. Section 3 details the experimental setup adopted for the architecture, the techniques applied during training and the dataset creation. In Section 4, it is shown the experimental results for our best models with the most suitable hyperparameters and configurations. Finally, in Section 5, we discuss the results and extract the highlights of this research.
<br class="ltx_break"></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">A limited number of studies focus on Machine Learning techniques applied to the Indigenous languages of Latin America, most of them focused on the corpora analysis, NLP applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, Machine translation (MT) systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, sentimental analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> or just in showing the challenges of this task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. However, only recent initiatives aim to address the challenge of developing ASR systems  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> for the indigenous languages of America. This issue is shared with other minority languages worldwide, and recent initiatives have been carried out to develop ASR models for the Adi (India) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> or for the Cook Islands Māori <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> among others. For the languages that concern us in this work, there are no previously reported ASR systems for two of them: the Wa'ikhana and the Kotiria. Meanwhile, different investigations are reported for Quechua, Bribri and Guarani in the area of ASR. On the following paragraph, we summarize the most important investigations. 
<br class="ltx_break"></p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">The very first ASR system for the Quechua language was published in 2018, and it was able to recognize spoken numbers from one to ten with an accuracy greater than <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="90" display="inline"><semantics id="S2.p2.1.m1.1a"><mn id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">90</mn><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><cn type="integer" id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">90</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">90</annotation></semantics></math>% <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. It was based on Cepstral Coefficients (MFCC) features, and Dynamic Time Warping (DTW) and K-Nearest Neighbor (KNN) for classifying the characteristics. Then, the first complete E2E ASR system in Quechua was based on a pre-trained model and fine-tuned in a very limited domain of available data with results difficult to extrapolate to other domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. The most detailed ASR system of Quechua to date uses the Hidden Markov Model Toolkit (HTK) and evaluates the improvement when using the Gaussian HMM versus monophonic acoustic model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Later research shows that ASR in Quechua can be improved by adding to the training set Text To Speech (TTS) synthetic generated voices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. Similarly to Quechua, there are not many reported investigations on ASR applied to Guarani. The very first reported ASR system was based on Gaussian Mixture Models (GMM), HMM and n-grams <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> and trained and tested with a very limited amount of data. In 2020 and 2021 the OpenASR challenge for low resource languages included the Guarani as a target language increasing the interest of this language in the context of ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. Recent investigations included modern architectures based on Convolution Neural Network (CNN) and Factored Time Delay Neural Networks (TDNN-F) considerably improving previously reported results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. A more recent work compared three different pretrained models fine-tuned with 10 hours of labeled Guarani speech data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. Before the publication of the first ASR model for Guarani, in 2017 it was published an automatic text-to-voice aligner for the Bribri language but with acoustic models trained on other languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>. Initial explorations into ASR focused on Bribri investigated how vowel-tone separation can improve the accuracy of the ASR models when training data is scarce  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. Very recently, the first ASR E2E model based on self-supervised architecture for Bribri is reported in the context of the ASRU2023 ML-SUPERB Challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>.
<br class="ltx_break"></p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">Integrating ASR with other language processing techniques, such as word embeddings, and adopting a linguistic lens could significantly improve outcomes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, but it took a significant turn with the advent of self-supervised learning models, particularly XLS-R and Wav2vec2.0  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. These models capitalized on the power of contrastive learning to transform raw audio data into valuable speech representations, mitigating the need for extensive transcribed data, a common challenge in Indigenous language contexts. The path forward led to exploring Wav2vec2.0's potential for low-resource language scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> demonstrating remarkable adaptability and significant potential in addressing these languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> or other low-resource domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. More recently, weak supervision emerged as a viable approach for training resilient ASR models. This technique leverages large-scale, weakly supervised learning to harness the abundant yet imperfectly transcribed public data. However, it seems that this kind of approach may not be so appropriate for very low resource domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.
<br class="ltx_break"></p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p">It can be concluded that although ASR on indigenous languages has recently received some attention from the scientific community, there are not standardized benchmarks for the languages under study and not reported benchmarks for two of them. In this work, we improve this situation, reporting the best benchmarks for the languages under study in the NeurIPS competition, sharing with the community the granularity of the many training configurations experimented and the trained models.
<br class="ltx_break"></p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental setup and dataset description</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Main architecture and pre-trained models</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.6" class="ltx_p">The Wav2Vec 2.0 architecture, illustrated in Figure <a href="#S3.F1" title="Figure 1 ‣ 3.1 Main architecture and pre-trained models ‣ 3 Experimental setup and dataset description ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, constitutes a robust framework for ASR tasks. It comprises three core components: a Convolutional Neural Network (CNN)-based encoder network, a transformer-based context network, and a vector quantization module. These components work in tandem to transform raw audio samples, denoted as <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="x_{i}\in X" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><msub id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2.2" xref="S3.SS1.p1.1.m1.1.1.2.2.cmml">x</mi><mi id="S3.SS1.p1.1.m1.1.1.2.3" xref="S3.SS1.p1.1.m1.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">∈</mo><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">X</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><in id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></in><apply id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2.2">𝑥</ci><ci id="S3.SS1.p1.1.m1.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">x_{i}\in X</annotation></semantics></math>, into latent speech representations (<math id="S3.SS1.p1.2.m2.4" class="ltx_Math" alttext="z_{1},z_{2},\ldots,z_{T}" display="inline"><semantics id="S3.SS1.p1.2.m2.4a"><mrow id="S3.SS1.p1.2.m2.4.4.3" xref="S3.SS1.p1.2.m2.4.4.4.cmml"><msub id="S3.SS1.p1.2.m2.2.2.1.1" xref="S3.SS1.p1.2.m2.2.2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.2.2.1.1.2" xref="S3.SS1.p1.2.m2.2.2.1.1.2.cmml">z</mi><mn id="S3.SS1.p1.2.m2.2.2.1.1.3" xref="S3.SS1.p1.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.2.m2.4.4.3.4" xref="S3.SS1.p1.2.m2.4.4.4.cmml">,</mo><msub id="S3.SS1.p1.2.m2.3.3.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.cmml"><mi id="S3.SS1.p1.2.m2.3.3.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.cmml">z</mi><mn id="S3.SS1.p1.2.m2.3.3.2.2.3" xref="S3.SS1.p1.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p1.2.m2.4.4.3.5" xref="S3.SS1.p1.2.m2.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">…</mi><mo id="S3.SS1.p1.2.m2.4.4.3.6" xref="S3.SS1.p1.2.m2.4.4.4.cmml">,</mo><msub id="S3.SS1.p1.2.m2.4.4.3.3" xref="S3.SS1.p1.2.m2.4.4.3.3.cmml"><mi id="S3.SS1.p1.2.m2.4.4.3.3.2" xref="S3.SS1.p1.2.m2.4.4.3.3.2.cmml">z</mi><mi id="S3.SS1.p1.2.m2.4.4.3.3.3" xref="S3.SS1.p1.2.m2.4.4.3.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.4b"><list id="S3.SS1.p1.2.m2.4.4.4.cmml" xref="S3.SS1.p1.2.m2.4.4.3"><apply id="S3.SS1.p1.2.m2.2.2.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.2">𝑧</ci><cn type="integer" id="S3.SS1.p1.2.m2.2.2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.3">1</cn></apply><apply id="S3.SS1.p1.2.m2.3.3.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.2.2.1.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2">𝑧</ci><cn type="integer" id="S3.SS1.p1.2.m2.3.3.2.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.3">2</cn></apply><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">…</ci><apply id="S3.SS1.p1.2.m2.4.4.3.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.4.4.3.3.1.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.4.4.3.3.2.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.2">𝑧</ci><ci id="S3.SS1.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.4c">z_{1},z_{2},\ldots,z_{T}</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. First, the encoder network, denoted as <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="f:X\rightarrow Z" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">f</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">:</mo><mrow id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">X</mi><mo stretchy="false" id="S3.SS1.p1.3.m3.1.1.3.1" xref="S3.SS1.p1.3.m3.1.1.3.1.cmml">→</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml">Z</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><ci id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1">:</ci><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑓</ci><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><ci id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.1">→</ci><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">𝑋</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3">𝑍</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">f:X\rightarrow Z</annotation></semantics></math>, plays a pivotal role in this architecture. It consists of seven sequential blocks of temporal convolution layers, each equipped with 512 channels, strategic strides (5,2,2,2,2,2,2), and kernel sizes (10,3,3,3,3,2,2). This configuration allows the encoder to compress approximately 25 milliseconds of 16 kHz audio data into latent representations every 20 milliseconds. Following each convolution layer, layer normalization and GELU activation are applied to enhance feature extraction. The context network represented as <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="g:Z\rightarrow C" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">g</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">:</mo><mrow id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">Z</mi><mo stretchy="false" id="S3.SS1.p1.4.m4.1.1.3.1" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">→</mo><mi id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">C</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><ci id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1">:</ci><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝑔</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><ci id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.1">→</ci><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">𝑍</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">g:Z\rightarrow C</annotation></semantics></math>, takes these latent representations (<math id="S3.SS1.p1.5.m5.3" class="ltx_Math" alttext="z_{i},\ldots,z_{T}" display="inline"><semantics id="S3.SS1.p1.5.m5.3a"><mrow id="S3.SS1.p1.5.m5.3.3.2" xref="S3.SS1.p1.5.m5.3.3.3.cmml"><msub id="S3.SS1.p1.5.m5.2.2.1.1" xref="S3.SS1.p1.5.m5.2.2.1.1.cmml"><mi id="S3.SS1.p1.5.m5.2.2.1.1.2" xref="S3.SS1.p1.5.m5.2.2.1.1.2.cmml">z</mi><mi id="S3.SS1.p1.5.m5.2.2.1.1.3" xref="S3.SS1.p1.5.m5.2.2.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p1.5.m5.3.3.2.3" xref="S3.SS1.p1.5.m5.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">…</mi><mo id="S3.SS1.p1.5.m5.3.3.2.4" xref="S3.SS1.p1.5.m5.3.3.3.cmml">,</mo><msub id="S3.SS1.p1.5.m5.3.3.2.2" xref="S3.SS1.p1.5.m5.3.3.2.2.cmml"><mi id="S3.SS1.p1.5.m5.3.3.2.2.2" xref="S3.SS1.p1.5.m5.3.3.2.2.2.cmml">z</mi><mi id="S3.SS1.p1.5.m5.3.3.2.2.3" xref="S3.SS1.p1.5.m5.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.3b"><list id="S3.SS1.p1.5.m5.3.3.3.cmml" xref="S3.SS1.p1.5.m5.3.3.2"><apply id="S3.SS1.p1.5.m5.2.2.1.1.cmml" xref="S3.SS1.p1.5.m5.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.1.1.1.cmml" xref="S3.SS1.p1.5.m5.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.1.1.2.cmml" xref="S3.SS1.p1.5.m5.2.2.1.1.2">𝑧</ci><ci id="S3.SS1.p1.5.m5.2.2.1.1.3.cmml" xref="S3.SS1.p1.5.m5.2.2.1.1.3">𝑖</ci></apply><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">…</ci><apply id="S3.SS1.p1.5.m5.3.3.2.2.cmml" xref="S3.SS1.p1.5.m5.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.3.3.2.2.1.cmml" xref="S3.SS1.p1.5.m5.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.3.3.2.2.2.cmml" xref="S3.SS1.p1.5.m5.3.3.2.2.2">𝑧</ci><ci id="S3.SS1.p1.5.m5.3.3.2.2.3.cmml" xref="S3.SS1.p1.5.m5.3.3.2.2.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.3c">z_{i},\ldots,z_{T}</annotation></semantics></math>) and builds context representations (<math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="c_{i}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">c</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝑐</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">c_{i}</annotation></semantics></math>) that encapsulate the contextual information across the entire sequence of latent speech representations. We here leverage two different model sizes: one with 300M of parameters and the other with 1B parameters. The context network comprises 24 blocks (48 for the bigger model), each with a model dimension of 1024, an inner dimension of 4096, and 16 attention heads. This configuration enables it to capture intricate temporal and contextual dependencies within the audio data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.
<br class="ltx_break"></p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2404.08368/assets/figure_architecture.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="538" height="437" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Diagram of the Fine-tuning model.</span></figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.2" class="ltx_p">In the fine-tuning phase of our study, we evaluated two versions of the XLS-R (Cross-Lingual Speech Recognition) models framework: XLS-R-300M and XLS-R-1B <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. The numbers refer to the quantity of trainable parameters that each model possesses. These models were initially pre-trained on a vast dataset consisting of <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="436.000" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mn id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">436.000</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><cn type="float" id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">436.000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">436.000</annotation></semantics></math> hours of publicly available multilingual speech data sourced in <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mn id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><cn type="integer" id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">128</annotation></semantics></math> languages from various repositories, including CommonVoice <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, Babel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, Multilingual Librispeech (MLS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, VoxPopuli <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, and the VoxLingua107 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> datasets. During the fine-tuning phase, we assessed the performance of the XLS-R-300M and XLS-R-1B models for each indigenous language separately, utilizing the available training data for each language.
<br class="ltx_break"></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">For this work, we have used transcribed speech data collected from two sources: (i) the primary dataset provided by the organization of the AmericasNLP challenge and (ii) corpus collected from other publicly available sources. NeurIPS competition advocated using ancillary external resources to complement the primary dataset during the training but imposing usage restrictions on some databases. A summarized description of the train-dev-test database is depicted in table <a href="#S3.T1" title="Table 1 ‣ 3.2 Data ‣ 3 Experimental setup and dataset description ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
<br class="ltx_break"></p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.8" class="ltx_p">The database published by the competition included <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="0.72" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mn id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">0.72</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><cn type="float" id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">0.72</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">0.72</annotation></semantics></math>h The Pandialectal Corpus of the Bribri Language <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="0.46" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mn id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">0.46</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><cn type="float" id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">0.46</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">0.46</annotation></semantics></math>h from the Guarani Common Voice Mozilla database <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="3.49" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mn id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">3.49</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><cn type="float" id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">3.49</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">3.49</annotation></semantics></math>h from the Endangered Languages Archive (ELAR) (dk0137 and dk0491) for Kotiria <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>, <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="1.76" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mn id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">1.76</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><cn type="float" id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">1.76</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">1.76</annotation></semantics></math>h from ELAR for the Wa'khana <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> and <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="3.95" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mn id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">3.95</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><cn type="float" id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">3.95</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">3.95</annotation></semantics></math>h from the Siminchik dataset for the Quechua  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. All of these mentioned databases were subject to restriction during the competition, so it was not allowed to use data from those sources differently than the provided by the organization. In addition to the primary dataset, we enhanced the training process by collecting supplementary speech data. Specifically, we amassed <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="1.14" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mn id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">1.14</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><cn type="float" id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">1.14</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">1.14</annotation></semantics></math> hours of transcribed speech for the Bribri language <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>, <math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="21.8" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><mn id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml">21.8</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><cn type="float" id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">21.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">21.8</annotation></semantics></math> hours for Kotiria <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>, and <math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="7.07" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><mn id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml">7.07</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><cn type="float" id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">7.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">7.07</annotation></semantics></math> hours for Quechua <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>. However, it should be noted that no external data collection was obtained for Guarani and Wa'ikhana.
<br class="ltx_break"></p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.28" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.28.29.1" class="ltx_tr">
<th id="S3.T1.28.29.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S3.T1.28.29.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="4"><span id="S3.T1.28.29.1.2.1" class="ltx_text ltx_font_bold">Train</span></th>
<th id="S3.T1.28.29.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.28.29.1.3.1" class="ltx_text ltx_font_bold">Dev</span></th>
<th id="S3.T1.28.29.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.28.29.1.4.1" class="ltx_text ltx_font_bold">Test</span></th>
</tr>
<tr id="S3.T1.28.30.2" class="ltx_tr">
<th id="S3.T1.28.30.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S3.T1.28.30.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.28.30.2.2.1" class="ltx_text ltx_font_bold">Primary</span></th>
<th id="S3.T1.28.30.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.28.30.2.3.1" class="ltx_text ltx_font_bold">Speed Augm.</span></th>
<th id="S3.T1.28.30.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T1.28.30.2.4.1" class="ltx_text ltx_font_bold">External</span></th>
<th id="S3.T1.28.30.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.28.30.2.5.1" class="ltx_text ltx_font_bold">Total</span></th>
<th id="S3.T1.28.30.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.28.30.2.6.1" class="ltx_text ltx_font_bold">Primary</span></th>
<th id="S3.T1.28.30.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.28.30.2.7.1" class="ltx_text ltx_font_bold">Primary</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.6.6" class="ltx_tr">
<th id="S3.T1.6.6.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.6.6.7.1" class="ltx_text ltx_font_bold">Bribri</span></th>
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="S3.T1.1.1.1.m1.1" class="ltx_Math" alttext="0.49" display="inline"><semantics id="S3.T1.1.1.1.m1.1a"><mn id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">0.49</mn><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><cn type="float" id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">0.49</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">0.49</annotation></semantics></math>h</td>
<td id="S3.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="S3.T1.2.2.2.m1.1" class="ltx_Math" alttext="0.98" display="inline"><semantics id="S3.T1.2.2.2.m1.1a"><mn id="S3.T1.2.2.2.m1.1.1" xref="S3.T1.2.2.2.m1.1.1.cmml">0.98</mn><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.m1.1b"><cn type="float" id="S3.T1.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.m1.1.1">0.98</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.m1.1c">0.98</annotation></semantics></math>h</td>
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">
<math id="S3.T1.3.3.3.m1.1" class="ltx_Math" alttext="1.14" display="inline"><semantics id="S3.T1.3.3.3.m1.1a"><mn id="S3.T1.3.3.3.m1.1.1" xref="S3.T1.3.3.3.m1.1.1.cmml">1.14</mn><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.m1.1b"><cn type="float" id="S3.T1.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.m1.1.1">1.14</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.m1.1c">1.14</annotation></semantics></math>h</td>
<td id="S3.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<math id="S3.T1.4.4.4.m1.1" class="ltx_Math" alttext="2.61" display="inline"><semantics id="S3.T1.4.4.4.m1.1a"><mn id="S3.T1.4.4.4.m1.1.1" xref="S3.T1.4.4.4.m1.1.1.cmml">2.61</mn><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.m1.1b"><cn type="float" id="S3.T1.4.4.4.m1.1.1.cmml" xref="S3.T1.4.4.4.m1.1.1">2.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.m1.1c">2.61</annotation></semantics></math>h</td>
<td id="S3.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<math id="S3.T1.5.5.5.m1.1" class="ltx_Math" alttext="0.04" display="inline"><semantics id="S3.T1.5.5.5.m1.1a"><mn id="S3.T1.5.5.5.m1.1.1" xref="S3.T1.5.5.5.m1.1.1.cmml">0.04</mn><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.m1.1b"><cn type="float" id="S3.T1.5.5.5.m1.1.1.cmml" xref="S3.T1.5.5.5.m1.1.1">0.04</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.m1.1c">0.04</annotation></semantics></math>h</td>
<td id="S3.T1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<math id="S3.T1.6.6.6.m1.1" class="ltx_Math" alttext="0.19" display="inline"><semantics id="S3.T1.6.6.6.m1.1a"><mn id="S3.T1.6.6.6.m1.1.1" xref="S3.T1.6.6.6.m1.1.1.cmml">0.19</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.m1.1b"><cn type="float" id="S3.T1.6.6.6.m1.1.1.cmml" xref="S3.T1.6.6.6.m1.1.1">0.19</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.m1.1c">0.19</annotation></semantics></math>h</td>
</tr>
<tr id="S3.T1.11.11" class="ltx_tr">
<th id="S3.T1.11.11.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S3.T1.11.11.6.1" class="ltx_text ltx_font_bold">Guarani</span></th>
<td id="S3.T1.7.7.1" class="ltx_td ltx_align_center">
<math id="S3.T1.7.7.1.m1.1" class="ltx_Math" alttext="0.32" display="inline"><semantics id="S3.T1.7.7.1.m1.1a"><mn id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml">0.32</mn><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><cn type="float" id="S3.T1.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1">0.32</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">0.32</annotation></semantics></math>h</td>
<td id="S3.T1.8.8.2" class="ltx_td ltx_align_center">
<math id="S3.T1.8.8.2.m1.1" class="ltx_Math" alttext="0.65" display="inline"><semantics id="S3.T1.8.8.2.m1.1a"><mn id="S3.T1.8.8.2.m1.1.1" xref="S3.T1.8.8.2.m1.1.1.cmml">0.65</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.2.m1.1b"><cn type="float" id="S3.T1.8.8.2.m1.1.1.cmml" xref="S3.T1.8.8.2.m1.1.1">0.65</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.2.m1.1c">0.65</annotation></semantics></math>h</td>
<td id="S3.T1.11.11.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.9.9.3" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.9.9.3.m1.1" class="ltx_Math" alttext="0.97" display="inline"><semantics id="S3.T1.9.9.3.m1.1a"><mn id="S3.T1.9.9.3.m1.1.1" xref="S3.T1.9.9.3.m1.1.1.cmml">0.97</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.3.m1.1b"><cn type="float" id="S3.T1.9.9.3.m1.1.1.cmml" xref="S3.T1.9.9.3.m1.1.1">0.97</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.3.m1.1c">0.97</annotation></semantics></math>h</td>
<td id="S3.T1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.10.10.4.m1.1" class="ltx_Math" alttext="0.02" display="inline"><semantics id="S3.T1.10.10.4.m1.1a"><mn id="S3.T1.10.10.4.m1.1.1" xref="S3.T1.10.10.4.m1.1.1.cmml">0.02</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.4.m1.1b"><cn type="float" id="S3.T1.10.10.4.m1.1.1.cmml" xref="S3.T1.10.10.4.m1.1.1">0.02</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.4.m1.1c">0.02</annotation></semantics></math>h</td>
<td id="S3.T1.11.11.5" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.11.11.5.m1.1" class="ltx_Math" alttext="0.12" display="inline"><semantics id="S3.T1.11.11.5.m1.1a"><mn id="S3.T1.11.11.5.m1.1.1" xref="S3.T1.11.11.5.m1.1.1.cmml">0.12</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.5.m1.1b"><cn type="float" id="S3.T1.11.11.5.m1.1.1.cmml" xref="S3.T1.11.11.5.m1.1.1">0.12</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.5.m1.1c">0.12</annotation></semantics></math>h</td>
</tr>
<tr id="S3.T1.17.17" class="ltx_tr">
<th id="S3.T1.17.17.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S3.T1.17.17.7.1" class="ltx_text ltx_font_bold">Kotiria</span></th>
<td id="S3.T1.12.12.1" class="ltx_td ltx_align_center">
<math id="S3.T1.12.12.1.m1.1" class="ltx_Math" alttext="2.69" display="inline"><semantics id="S3.T1.12.12.1.m1.1a"><mn id="S3.T1.12.12.1.m1.1.1" xref="S3.T1.12.12.1.m1.1.1.cmml">2.69</mn><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.1.m1.1b"><cn type="float" id="S3.T1.12.12.1.m1.1.1.cmml" xref="S3.T1.12.12.1.m1.1.1">2.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.1.m1.1c">2.69</annotation></semantics></math>h</td>
<td id="S3.T1.13.13.2" class="ltx_td ltx_align_center">
<math id="S3.T1.13.13.2.m1.1" class="ltx_Math" alttext="5.43" display="inline"><semantics id="S3.T1.13.13.2.m1.1a"><mn id="S3.T1.13.13.2.m1.1.1" xref="S3.T1.13.13.2.m1.1.1.cmml">5.43</mn><annotation-xml encoding="MathML-Content" id="S3.T1.13.13.2.m1.1b"><cn type="float" id="S3.T1.13.13.2.m1.1.1.cmml" xref="S3.T1.13.13.2.m1.1.1">5.43</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.13.2.m1.1c">5.43</annotation></semantics></math>h</td>
<td id="S3.T1.14.14.3" class="ltx_td ltx_align_center">
<math id="S3.T1.14.14.3.m1.1" class="ltx_Math" alttext="21.8" display="inline"><semantics id="S3.T1.14.14.3.m1.1a"><mn id="S3.T1.14.14.3.m1.1.1" xref="S3.T1.14.14.3.m1.1.1.cmml">21.8</mn><annotation-xml encoding="MathML-Content" id="S3.T1.14.14.3.m1.1b"><cn type="float" id="S3.T1.14.14.3.m1.1.1.cmml" xref="S3.T1.14.14.3.m1.1.1">21.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.14.3.m1.1c">21.8</annotation></semantics></math>h</td>
<td id="S3.T1.15.15.4" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.15.15.4.m1.1" class="ltx_Math" alttext="29.87" display="inline"><semantics id="S3.T1.15.15.4.m1.1a"><mn id="S3.T1.15.15.4.m1.1.1" xref="S3.T1.15.15.4.m1.1.1.cmml">29.87</mn><annotation-xml encoding="MathML-Content" id="S3.T1.15.15.4.m1.1b"><cn type="float" id="S3.T1.15.15.4.m1.1.1.cmml" xref="S3.T1.15.15.4.m1.1.1">29.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.15.4.m1.1c">29.87</annotation></semantics></math>h</td>
<td id="S3.T1.16.16.5" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.16.16.5.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S3.T1.16.16.5.m1.1a"><mn id="S3.T1.16.16.5.m1.1.1" xref="S3.T1.16.16.5.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.16.16.5.m1.1b"><cn type="float" id="S3.T1.16.16.5.m1.1.1.cmml" xref="S3.T1.16.16.5.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.16.5.m1.1c">0.5</annotation></semantics></math>h</td>
<td id="S3.T1.17.17.6" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.17.17.6.m1.1" class="ltx_Math" alttext="0.3" display="inline"><semantics id="S3.T1.17.17.6.m1.1a"><mn id="S3.T1.17.17.6.m1.1.1" xref="S3.T1.17.17.6.m1.1.1.cmml">0.3</mn><annotation-xml encoding="MathML-Content" id="S3.T1.17.17.6.m1.1b"><cn type="float" id="S3.T1.17.17.6.m1.1.1.cmml" xref="S3.T1.17.17.6.m1.1.1">0.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.17.6.m1.1c">0.3</annotation></semantics></math>h</td>
</tr>
<tr id="S3.T1.22.22" class="ltx_tr">
<th id="S3.T1.22.22.6" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S3.T1.22.22.6.1" class="ltx_text ltx_font_bold">Wai'khana</span></th>
<td id="S3.T1.18.18.1" class="ltx_td ltx_align_center">
<math id="S3.T1.18.18.1.m1.1" class="ltx_Math" alttext="1.49" display="inline"><semantics id="S3.T1.18.18.1.m1.1a"><mn id="S3.T1.18.18.1.m1.1.1" xref="S3.T1.18.18.1.m1.1.1.cmml">1.49</mn><annotation-xml encoding="MathML-Content" id="S3.T1.18.18.1.m1.1b"><cn type="float" id="S3.T1.18.18.1.m1.1.1.cmml" xref="S3.T1.18.18.1.m1.1.1">1.49</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.18.18.1.m1.1c">1.49</annotation></semantics></math>h</td>
<td id="S3.T1.19.19.2" class="ltx_td ltx_align_center">
<math id="S3.T1.19.19.2.m1.1" class="ltx_Math" alttext="2.9" display="inline"><semantics id="S3.T1.19.19.2.m1.1a"><mn id="S3.T1.19.19.2.m1.1.1" xref="S3.T1.19.19.2.m1.1.1.cmml">2.9</mn><annotation-xml encoding="MathML-Content" id="S3.T1.19.19.2.m1.1b"><cn type="float" id="S3.T1.19.19.2.m1.1.1.cmml" xref="S3.T1.19.19.2.m1.1.1">2.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.19.19.2.m1.1c">2.9</annotation></semantics></math>h</td>
<td id="S3.T1.22.22.7" class="ltx_td ltx_align_center">-</td>
<td id="S3.T1.20.20.3" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.20.20.3.m1.1" class="ltx_Math" alttext="4.35" display="inline"><semantics id="S3.T1.20.20.3.m1.1a"><mn id="S3.T1.20.20.3.m1.1.1" xref="S3.T1.20.20.3.m1.1.1.cmml">4.35</mn><annotation-xml encoding="MathML-Content" id="S3.T1.20.20.3.m1.1b"><cn type="float" id="S3.T1.20.20.3.m1.1.1.cmml" xref="S3.T1.20.20.3.m1.1.1">4.35</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.20.20.3.m1.1c">4.35</annotation></semantics></math>h</td>
<td id="S3.T1.21.21.4" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.21.21.4.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S3.T1.21.21.4.m1.1a"><mn id="S3.T1.21.21.4.m1.1.1" xref="S3.T1.21.21.4.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S3.T1.21.21.4.m1.1b"><cn type="float" id="S3.T1.21.21.4.m1.1.1.cmml" xref="S3.T1.21.21.4.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.21.21.4.m1.1c">0.1</annotation></semantics></math>h</td>
<td id="S3.T1.22.22.5" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T1.22.22.5.m1.1" class="ltx_Math" alttext="0.21" display="inline"><semantics id="S3.T1.22.22.5.m1.1a"><mn id="S3.T1.22.22.5.m1.1.1" xref="S3.T1.22.22.5.m1.1.1.cmml">0.21</mn><annotation-xml encoding="MathML-Content" id="S3.T1.22.22.5.m1.1b"><cn type="float" id="S3.T1.22.22.5.m1.1.1.cmml" xref="S3.T1.22.22.5.m1.1.1">0.21</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.22.22.5.m1.1c">0.21</annotation></semantics></math>h</td>
</tr>
<tr id="S3.T1.28.28" class="ltx_tr">
<th id="S3.T1.28.28.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span id="S3.T1.28.28.7.1" class="ltx_text ltx_font_bold">Quechua</span></th>
<td id="S3.T1.23.23.1" class="ltx_td ltx_align_center ltx_border_b">
<math id="S3.T1.23.23.1.m1.1" class="ltx_Math" alttext="1.67" display="inline"><semantics id="S3.T1.23.23.1.m1.1a"><mn id="S3.T1.23.23.1.m1.1.1" xref="S3.T1.23.23.1.m1.1.1.cmml">1.67</mn><annotation-xml encoding="MathML-Content" id="S3.T1.23.23.1.m1.1b"><cn type="float" id="S3.T1.23.23.1.m1.1.1.cmml" xref="S3.T1.23.23.1.m1.1.1">1.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.23.23.1.m1.1c">1.67</annotation></semantics></math>h</td>
<td id="S3.T1.24.24.2" class="ltx_td ltx_align_center ltx_border_b">
<math id="S3.T1.24.24.2.m1.1" class="ltx_Math" alttext="3.38" display="inline"><semantics id="S3.T1.24.24.2.m1.1a"><mn id="S3.T1.24.24.2.m1.1.1" xref="S3.T1.24.24.2.m1.1.1.cmml">3.38</mn><annotation-xml encoding="MathML-Content" id="S3.T1.24.24.2.m1.1b"><cn type="float" id="S3.T1.24.24.2.m1.1.1.cmml" xref="S3.T1.24.24.2.m1.1.1">3.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.24.24.2.m1.1c">3.38</annotation></semantics></math>h</td>
<td id="S3.T1.25.25.3" class="ltx_td ltx_align_center ltx_border_b">
<math id="S3.T1.25.25.3.m1.1" class="ltx_Math" alttext="7.04" display="inline"><semantics id="S3.T1.25.25.3.m1.1a"><mn id="S3.T1.25.25.3.m1.1.1" xref="S3.T1.25.25.3.m1.1.1.cmml">7.04</mn><annotation-xml encoding="MathML-Content" id="S3.T1.25.25.3.m1.1b"><cn type="float" id="S3.T1.25.25.3.m1.1.1.cmml" xref="S3.T1.25.25.3.m1.1.1">7.04</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.25.25.3.m1.1c">7.04</annotation></semantics></math>h</td>
<td id="S3.T1.26.26.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<math id="S3.T1.26.26.4.m1.1" class="ltx_Math" alttext="12.05" display="inline"><semantics id="S3.T1.26.26.4.m1.1a"><mn id="S3.T1.26.26.4.m1.1.1" xref="S3.T1.26.26.4.m1.1.1.cmml">12.05</mn><annotation-xml encoding="MathML-Content" id="S3.T1.26.26.4.m1.1b"><cn type="float" id="S3.T1.26.26.4.m1.1.1.cmml" xref="S3.T1.26.26.4.m1.1.1">12.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.26.26.4.m1.1c">12.05</annotation></semantics></math>h</td>
<td id="S3.T1.27.27.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<math id="S3.T1.27.27.5.m1.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S3.T1.27.27.5.m1.1a"><mn id="S3.T1.27.27.5.m1.1.1" xref="S3.T1.27.27.5.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S3.T1.27.27.5.m1.1b"><cn type="float" id="S3.T1.27.27.5.m1.1.1.cmml" xref="S3.T1.27.27.5.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.27.27.5.m1.1c">0.2</annotation></semantics></math>h</td>
<td id="S3.T1.28.28.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<math id="S3.T1.28.28.6.m1.1" class="ltx_Math" alttext="2.08" display="inline"><semantics id="S3.T1.28.28.6.m1.1a"><mn id="S3.T1.28.28.6.m1.1.1" xref="S3.T1.28.28.6.m1.1.1.cmml">2.08</mn><annotation-xml encoding="MathML-Content" id="S3.T1.28.28.6.m1.1b"><cn type="float" id="S3.T1.28.28.6.m1.1.1.cmml" xref="S3.T1.28.28.6.m1.1.1">2.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.28.28.6.m1.1c">2.08</annotation></semantics></math>h</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.31.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.32.2" class="ltx_text" style="font-size:90%;">Detailed description of train-dev-test splits partitions for each language and data source. Primary refers to the corpus provided by the AmericasNLP organization, speed augmentation is performed only on the primary database and <span id="S3.T1.32.2.1" class="ltx_text ltx_font_italic">external</span> refers to corpus collected from other sources.</span></figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.6" class="ltx_p">To augment the diversity and variability of the assembled speech audios, we applied offline speed augmentation techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> to the primary database. Specifically, we augmented the audios at <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="x0.9" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">​</mo><mn id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></times><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝑥</ci><cn type="float" id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">x0.9</annotation></semantics></math> and <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="x1.1" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mrow id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.cmml">​</mo><mn id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">1.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><times id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1"></times><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝑥</ci><cn type="float" id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">1.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">x1.1</annotation></semantics></math> speed rate, effectively widening the spectrum of speech patterns encountered during training. This augmentation technique fortifies ASR models and enhances adaptability to varied speech styles and tempo changes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>. Summing up, the cumulative duration of recordings in the training dataset varied across different languages as follows (see table <a href="#S3.T1" title="Table 1 ‣ 3.2 Data ‣ 3 Experimental setup and dataset description ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>): <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="2.61" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mn id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">2.61</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><cn type="float" id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">2.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">2.61</annotation></semantics></math> hours for Bribri, less than one hour for Guarani, <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="29.87" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mn id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">29.87</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><cn type="float" id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">29.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">29.87</annotation></semantics></math> hours for Kotiria, <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="4.35" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mn id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">4.35</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><cn type="float" id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">4.35</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">4.35</annotation></semantics></math> hours for Wa'ikhana, and <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="12.05" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><mn id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">12.05</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><cn type="float" id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">12.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">12.05</annotation></semantics></math> hours for Quechua.
<br class="ltx_break"></p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Decoding strategy and Language Models</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.5" class="ltx_p">Different strategies were considered during decoding: greedy decoding and beam search n-gram language model decoding. For the beam search, 3-gram and 4-gram Kenlm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> models were constructed for each language. For each configuration, two models were trained depending on the data: one included only training transcription data, and the other included primary transcription data and text data from other corpora. Moreover, we constructed extensive language models for each target language by crawling text corpora spanning diverse sources like speech transcriptions, online texts, and books. The size of the text corpora collected for training the language models was relatively modest, with fewer than <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mn id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><cn type="integer" id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">100</annotation></semantics></math>k words secured for each language. Beam search hyperparameters <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\alpha</annotation></semantics></math> and <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\beta</annotation></semantics></math> were selected based on the dev set and searched during <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mn id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><cn type="integer" id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">50</annotation></semantics></math> trials with Bayesian optimization techniques by fixing a beam-width of <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mn id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><cn type="integer" id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">128</annotation></semantics></math>. 
<br class="ltx_break"></p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p">However, due to the lack of a standard normalization of the transcriptions and the low amount of data, this optimization did not lead to significant improvement and even degraded performance for some languages. Therefore, the final decoding strategy was only based on greedy search and heuristic corrections applied to correct textual errors such as capitalization, punctuation and reducing multiple spaces or letters.
<br class="ltx_break"></p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Hyperparameter Fine-tuning</h3>

<div id="S3.SS4.p1" class="ltx_para ltx_noindent">
<p id="S3.SS4.p1.1" class="ltx_p">We delve deeper into the experimental findings to understand the contribution of different hyperparameters on the performance of the language models, specifically focusing on the variants of the Wav2vec2.0 XLS-R model: 300M and 1B parameters. We studied and analyzed the impact of the most important hyperparameters: learning rate, maximum number of updates, freeze fine-tune updates, activation dropout, mask probability, and mask channel probability. The rationale behind our endeavour lies in the pursuit of hyperparameter fine-tuning, a process aimed at optimizing the efficacy of our language models. Hyperparameters serve as control parameters that govern various facets of the training process, thereby exerting a profound influence on model performance. However, while the best hyperparameters are usually published, it is not usual to find an exhaustive study dissecting their individual contribution impact and their complex correlations.
<br class="ltx_break"></p>
</div>
<div id="S3.SS4.p2" class="ltx_para ltx_noindent">
<p id="S3.SS4.p2.1" class="ltx_p">Our methodology for hyperparameter optimization revolves around an exhaustive Bayesian search <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> with the help of the Optuna hyperparameter optimization framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. We traverse a wide spectrum of hyperparameter configurations (see table <a href="#S3.T2" title="Table 2 ‣ 3.4 Hyperparameter Fine-tuning ‣ 3 Experimental setup and dataset description ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), assessing model performance at each juncture. This process enables us to chart the optimal course through the intricate landscape of hyperparameters, ultimately determining the most effective parameter settings for our specific task and model variations. Finally, two model checkpoints are considered during the test phase: the one with the lowest loss and the one with the lowest WER during training.
<br class="ltx_break"></p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.12.13.1" class="ltx_tr">
<th id="S3.T2.12.13.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S3.T2.12.13.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.12.13.1.2.1" class="ltx_text ltx_font_bold">Min value</span></th>
<th id="S3.T2.12.13.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.12.13.1.3.1" class="ltx_text ltx_font_bold">Max value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.2.2" class="ltx_tr">
<th id="S3.T2.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.2.2.3.1" class="ltx_text ltx_font_bold">Learning Rate</span></th>
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T2.1.1.1.m1.1" class="ltx_Math" alttext="10^{-6}" display="inline"><semantics id="S3.T2.1.1.1.m1.1a"><msup id="S3.T2.1.1.1.m1.1.1" xref="S3.T2.1.1.1.m1.1.1.cmml"><mn id="S3.T2.1.1.1.m1.1.1.2" xref="S3.T2.1.1.1.m1.1.1.2.cmml">10</mn><mrow id="S3.T2.1.1.1.m1.1.1.3" xref="S3.T2.1.1.1.m1.1.1.3.cmml"><mo id="S3.T2.1.1.1.m1.1.1.3a" xref="S3.T2.1.1.1.m1.1.1.3.cmml">−</mo><mn id="S3.T2.1.1.1.m1.1.1.3.2" xref="S3.T2.1.1.1.m1.1.1.3.2.cmml">6</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.m1.1b"><apply id="S3.T2.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.1.1.1.m1.1.1.1.cmml" xref="S3.T2.1.1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S3.T2.1.1.1.m1.1.1.2.cmml" xref="S3.T2.1.1.1.m1.1.1.2">10</cn><apply id="S3.T2.1.1.1.m1.1.1.3.cmml" xref="S3.T2.1.1.1.m1.1.1.3"><minus id="S3.T2.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.1.1.1.m1.1.1.3"></minus><cn type="integer" id="S3.T2.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.1.1.1.m1.1.1.3.2">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.m1.1c">10^{-6}</annotation></semantics></math></td>
<td id="S3.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S3.T2.2.2.2.m1.1" class="ltx_Math" alttext="10^{-3}" display="inline"><semantics id="S3.T2.2.2.2.m1.1a"><msup id="S3.T2.2.2.2.m1.1.1" xref="S3.T2.2.2.2.m1.1.1.cmml"><mn id="S3.T2.2.2.2.m1.1.1.2" xref="S3.T2.2.2.2.m1.1.1.2.cmml">10</mn><mrow id="S3.T2.2.2.2.m1.1.1.3" xref="S3.T2.2.2.2.m1.1.1.3.cmml"><mo id="S3.T2.2.2.2.m1.1.1.3a" xref="S3.T2.2.2.2.m1.1.1.3.cmml">−</mo><mn id="S3.T2.2.2.2.m1.1.1.3.2" xref="S3.T2.2.2.2.m1.1.1.3.2.cmml">3</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.m1.1b"><apply id="S3.T2.2.2.2.m1.1.1.cmml" xref="S3.T2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.2.2.2.m1.1.1.1.cmml" xref="S3.T2.2.2.2.m1.1.1">superscript</csymbol><cn type="integer" id="S3.T2.2.2.2.m1.1.1.2.cmml" xref="S3.T2.2.2.2.m1.1.1.2">10</cn><apply id="S3.T2.2.2.2.m1.1.1.3.cmml" xref="S3.T2.2.2.2.m1.1.1.3"><minus id="S3.T2.2.2.2.m1.1.1.3.1.cmml" xref="S3.T2.2.2.2.m1.1.1.3"></minus><cn type="integer" id="S3.T2.2.2.2.m1.1.1.3.2.cmml" xref="S3.T2.2.2.2.m1.1.1.3.2">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.m1.1c">10^{-3}</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.4.4" class="ltx_tr">
<th id="S3.T2.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S3.T2.4.4.3.1" class="ltx_text ltx_font_bold">Max number of updates</span></th>
<td id="S3.T2.3.3.1" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T2.3.3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.T2.3.3.1.m1.1a"><mn id="S3.T2.3.3.1.m1.1.1" xref="S3.T2.3.3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.1.m1.1b"><cn type="integer" id="S3.T2.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.1.m1.1c">10</annotation></semantics></math>k</td>
<td id="S3.T2.4.4.2" class="ltx_td ltx_align_center ltx_border_r">
<math id="S3.T2.4.4.2.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S3.T2.4.4.2.m1.1a"><mn id="S3.T2.4.4.2.m1.1.1" xref="S3.T2.4.4.2.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.2.m1.1b"><cn type="integer" id="S3.T2.4.4.2.m1.1.1.cmml" xref="S3.T2.4.4.2.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.2.m1.1c">100</annotation></semantics></math>k</td>
</tr>
<tr id="S3.T2.6.6" class="ltx_tr">
<th id="S3.T2.6.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S3.T2.6.6.3.1" class="ltx_text ltx_font_bold">Freeze fine-tune updates</span></th>
<td id="S3.T2.5.5.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S3.T2.5.5.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.T2.5.5.1.m1.1a"><mn id="S3.T2.5.5.1.m1.1.1" xref="S3.T2.5.5.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.1.m1.1b"><cn type="integer" id="S3.T2.5.5.1.m1.1.1.cmml" xref="S3.T2.5.5.1.m1.1.1">0</cn></annotation-xml></semantics></math></td>
<td id="S3.T2.6.6.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S3.T2.6.6.2.m1.1" class="ltx_Math" alttext="50000" display="inline"><semantics id="S3.T2.6.6.2.m1.1a"><mn id="S3.T2.6.6.2.m1.1.1" xref="S3.T2.6.6.2.m1.1.1.cmml">50000</mn><annotation-xml encoding="MathML-Content" id="S3.T2.6.6.2.m1.1b"><cn type="integer" id="S3.T2.6.6.2.m1.1.1.cmml" xref="S3.T2.6.6.2.m1.1.1">50000</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.6.2.m1.1c">50000</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.8.8" class="ltx_tr">
<th id="S3.T2.8.8.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S3.T2.8.8.3.1" class="ltx_text ltx_font_bold">Activation dropout</span></th>
<td id="S3.T2.7.7.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S3.T2.7.7.1.m1.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="S3.T2.7.7.1.m1.1a"><mn id="S3.T2.7.7.1.m1.1.1" xref="S3.T2.7.7.1.m1.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.1.m1.1b"><cn type="float" id="S3.T2.7.7.1.m1.1.1.cmml" xref="S3.T2.7.7.1.m1.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.1.m1.1c">0.01</annotation></semantics></math></td>
<td id="S3.T2.8.8.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S3.T2.8.8.2.m1.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S3.T2.8.8.2.m1.1a"><mn id="S3.T2.8.8.2.m1.1.1" xref="S3.T2.8.8.2.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S3.T2.8.8.2.m1.1b"><cn type="float" id="S3.T2.8.8.2.m1.1.1.cmml" xref="S3.T2.8.8.2.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.8.2.m1.1c">0.2</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.10.10" class="ltx_tr">
<th id="S3.T2.10.10.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S3.T2.10.10.3.1" class="ltx_text ltx_font_bold">Mask probability</span></th>
<td id="S3.T2.9.9.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S3.T2.9.9.1.m1.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S3.T2.9.9.1.m1.1a"><mn id="S3.T2.9.9.1.m1.1.1" xref="S3.T2.9.9.1.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.1.m1.1b"><cn type="float" id="S3.T2.9.9.1.m1.1.1.cmml" xref="S3.T2.9.9.1.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.1.m1.1c">0.2</annotation></semantics></math></td>
<td id="S3.T2.10.10.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S3.T2.10.10.2.m1.1" class="ltx_Math" alttext="0.7" display="inline"><semantics id="S3.T2.10.10.2.m1.1a"><mn id="S3.T2.10.10.2.m1.1.1" xref="S3.T2.10.10.2.m1.1.1.cmml">0.7</mn><annotation-xml encoding="MathML-Content" id="S3.T2.10.10.2.m1.1b"><cn type="float" id="S3.T2.10.10.2.m1.1.1.cmml" xref="S3.T2.10.10.2.m1.1.1">0.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.10.2.m1.1c">0.7</annotation></semantics></math></td>
</tr>
<tr id="S3.T2.12.12" class="ltx_tr">
<th id="S3.T2.12.12.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span id="S3.T2.12.12.3.1" class="ltx_text ltx_font_bold">Mask channel probability</span></th>
<td id="S3.T2.11.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S3.T2.11.11.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S3.T2.11.11.1.m1.1a"><mn id="S3.T2.11.11.1.m1.1.1" xref="S3.T2.11.11.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.1.m1.1b"><cn type="float" id="S3.T2.11.11.1.m1.1.1.cmml" xref="S3.T2.11.11.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.1.m1.1c">0.1</annotation></semantics></math></td>
<td id="S3.T2.12.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S3.T2.12.12.2.m1.1" class="ltx_Math" alttext="0.7" display="inline"><semantics id="S3.T2.12.12.2.m1.1a"><mn id="S3.T2.12.12.2.m1.1.1" xref="S3.T2.12.12.2.m1.1.1.cmml">0.7</mn><annotation-xml encoding="MathML-Content" id="S3.T2.12.12.2.m1.1b"><cn type="float" id="S3.T2.12.12.2.m1.1.1.cmml" xref="S3.T2.12.12.2.m1.1.1">0.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.12.2.m1.1c">0.7</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.14.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.15.2" class="ltx_text" style="font-size:90%;">Hyperparameter search range during the fine-tuning training phase.</span></figcaption>
</figure>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Sobol Sensitivity Analysis for Hyperparameter Explanation</h3>

<div id="S3.SS5.p1" class="ltx_para ltx_noindent">
<p id="S3.SS5.p1.1" class="ltx_p">Sobol Sensitivity Analysis is a relatively recent technique used for estimating the influence of individual variables on the output of complex mathematical models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. While it has been widely adopted across diverse scientific disciplines ranging from epidemiology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> to ecology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>, or <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>, it has only been recently introduced to the study of AI complex models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>, <a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>. We have utilized Sobol Sensitivity Analysis, to assess the impact of various hyperparameters on the performance of our language models designed for Quechua, Kotiria, Bribri, Guarani, and Wa'ikhana, producing new valuable and fresh insights in the realm of ASR.
<br class="ltx_break"></p>
</div>
<div id="S3.SS5.p2" class="ltx_para ltx_noindent">
<p id="S3.SS5.p2.1" class="ltx_p">Sobol Sensitivity Analysis measures how much of the variance in the model output can be attributed to the specific inputs or set of inputs. This approach considers only the inputs and outputs of the system under study, considering the function transformation as a black box. It provides two essential indices: the first-order (S1) index, which quantifies the individual contribution of each input parameter to the output variance, and the total-order (ST) index, which takes into account not only each parameter but also its interactions with all other parameters in the model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>.
<br class="ltx_break"></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">In this section, we delve into the outcomes of our investigation, where we explore the intricate interplay between hyperparameter configurations and the performance of diverse language models. The ensuing analysis, encapsulated in Table <a href="#S4.T3" title="Table 3 ‣ 4 Results ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, summarizes the best hyperparameter configuration obtained for each language.
<br class="ltx_break"></p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.35" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.35.36.1" class="ltx_tr">
<th id="S4.T3.35.36.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.35.36.1.1.1" class="ltx_text ltx_font_bold">Language</span></th>
<th id="S4.T3.35.36.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.35.36.1.2.1" class="ltx_text ltx_font_bold">Learning</span></th>
<th id="S4.T3.35.36.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.35.36.1.3.1" class="ltx_text ltx_font_bold">Max</span></th>
<th id="S4.T3.35.36.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S4.T3.35.36.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.35.36.1.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T3.35.36.1.4.1.1.1" class="ltx_text ltx_font_bold">Freeze</span></span>
</span>
</th>
<th id="S4.T3.35.36.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.35.36.1.5.1" class="ltx_text ltx_font_bold">Mask</span></th>
<th id="S4.T3.35.36.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.35.36.1.6.1" class="ltx_text ltx_font_bold">Activation</span></th>
<th id="S4.T3.35.36.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.35.36.1.7.1" class="ltx_text ltx_font_bold">WER</span></th>
<th id="S4.T3.35.36.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.35.36.1.8.1" class="ltx_text ltx_font_bold">CER</span></th>
</tr>
<tr id="S4.T3.35.37.2" class="ltx_tr">
<th id="S4.T3.35.37.2.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r"></th>
<th id="S4.T3.35.37.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S4.T3.35.37.2.2.1" class="ltx_text ltx_font_bold">Rate</span></th>
<th id="S4.T3.35.37.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S4.T3.35.37.2.3.1" class="ltx_text ltx_font_bold">Updates</span></th>
<th id="S4.T3.35.37.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r">
<span id="S4.T3.35.37.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.35.37.2.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S4.T3.35.37.2.4.1.1.1" class="ltx_text ltx_font_bold">Fine-Tune</span></span>
</span>
</th>
<th id="S4.T3.35.37.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S4.T3.35.37.2.5.1" class="ltx_text ltx_font_bold">Channel</span></th>
<th id="S4.T3.35.37.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S4.T3.35.37.2.6.1" class="ltx_text ltx_font_bold">Dropout</span></th>
<th id="S4.T3.35.37.2.7" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S4.T3.35.37.2.8" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.7.7" class="ltx_tr">
<td id="S4.T3.7.7.8" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Quechua</td>
<td id="S4.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.1.1.1.m1.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><mrow id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml"><mn id="S4.T3.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T3.1.1.1.m1.1.1.1" xref="S4.T3.1.1.1.m1.1.1.1.cmml">×</mo><msup id="S4.T3.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.m1.1.1.3.cmml"><mn id="S4.T3.1.1.1.m1.1.1.3.2" xref="S4.T3.1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T3.1.1.1.m1.1.1.3.3" xref="S4.T3.1.1.1.m1.1.1.3.3.cmml"><mo id="S4.T3.1.1.1.m1.1.1.3.3a" xref="S4.T3.1.1.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T3.1.1.1.m1.1.1.3.3.2" xref="S4.T3.1.1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1"><times id="S4.T3.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1.1"></times><cn type="integer" id="S4.T3.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.m1.1.1.2">1</cn><apply id="S4.T3.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T3.1.1.1.m1.1.1.3.1.cmml" xref="S4.T3.1.1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T3.1.1.1.m1.1.1.3.2.cmml" xref="S4.T3.1.1.1.m1.1.1.3.2">10</cn><apply id="S4.T3.1.1.1.m1.1.1.3.3.cmml" xref="S4.T3.1.1.1.m1.1.1.3.3"><minus id="S4.T3.1.1.1.m1.1.1.3.3.1.cmml" xref="S4.T3.1.1.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T3.1.1.1.m1.1.1.3.3.2.cmml" xref="S4.T3.1.1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">1\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T3.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.2.2.2.m1.1" class="ltx_Math" alttext="90k" display="inline"><semantics id="S4.T3.2.2.2.m1.1a"><mrow id="S4.T3.2.2.2.m1.1.1" xref="S4.T3.2.2.2.m1.1.1.cmml"><mn id="S4.T3.2.2.2.m1.1.1.2" xref="S4.T3.2.2.2.m1.1.1.2.cmml">90</mn><mo lspace="0em" rspace="0em" id="S4.T3.2.2.2.m1.1.1.1" xref="S4.T3.2.2.2.m1.1.1.1.cmml">​</mo><mi id="S4.T3.2.2.2.m1.1.1.3" xref="S4.T3.2.2.2.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><apply id="S4.T3.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1"><times id="S4.T3.2.2.2.m1.1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1.1"></times><cn type="integer" id="S4.T3.2.2.2.m1.1.1.2.cmml" xref="S4.T3.2.2.2.m1.1.1.2">90</cn><ci id="S4.T3.2.2.2.m1.1.1.3.cmml" xref="S4.T3.2.2.2.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">90k</annotation></semantics></math></td>
<td id="S4.T3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<math id="S4.T3.3.3.3.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.T3.3.3.3.m1.1a"><mn id="S4.T3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><cn type="integer" id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">5</annotation></semantics></math>k</td>
<td id="S4.T3.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.4.4.4.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.T3.4.4.4.m1.1a"><mn id="S4.T3.4.4.4.m1.1.1" xref="S4.T3.4.4.4.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><cn type="float" id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">0.5</annotation></semantics></math></td>
<td id="S4.T3.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.5.5.5.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.T3.5.5.5.m1.1a"><mn id="S4.T3.5.5.5.m1.1.1" xref="S4.T3.5.5.5.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><cn type="float" id="S4.T3.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">0.1</annotation></semantics></math></td>
<td id="S4.T3.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.6.6.6.m1.1" class="ltx_Math" alttext="48.98" display="inline"><semantics id="S4.T3.6.6.6.m1.1a"><mn id="S4.T3.6.6.6.m1.1.1" xref="S4.T3.6.6.6.m1.1.1.cmml">48.98</mn><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.m1.1b"><cn type="float" id="S4.T3.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1">48.98</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.m1.1c">48.98</annotation></semantics></math></td>
<td id="S4.T3.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T3.7.7.7.m1.1" class="ltx_Math" alttext="12.14" display="inline"><semantics id="S4.T3.7.7.7.m1.1a"><mn id="S4.T3.7.7.7.m1.1.1" xref="S4.T3.7.7.7.m1.1.1.cmml">12.14</mn><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.m1.1b"><cn type="float" id="S4.T3.7.7.7.m1.1.1.cmml" xref="S4.T3.7.7.7.m1.1.1">12.14</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.m1.1c">12.14</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.14.14" class="ltx_tr">
<td id="S4.T3.14.14.8" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">Kotiria</td>
<td id="S4.T3.8.8.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.8.8.1.m1.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="S4.T3.8.8.1.m1.1a"><mrow id="S4.T3.8.8.1.m1.1.1" xref="S4.T3.8.8.1.m1.1.1.cmml"><mn id="S4.T3.8.8.1.m1.1.1.2" xref="S4.T3.8.8.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T3.8.8.1.m1.1.1.1" xref="S4.T3.8.8.1.m1.1.1.1.cmml">×</mo><msup id="S4.T3.8.8.1.m1.1.1.3" xref="S4.T3.8.8.1.m1.1.1.3.cmml"><mn id="S4.T3.8.8.1.m1.1.1.3.2" xref="S4.T3.8.8.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T3.8.8.1.m1.1.1.3.3" xref="S4.T3.8.8.1.m1.1.1.3.3.cmml"><mo id="S4.T3.8.8.1.m1.1.1.3.3a" xref="S4.T3.8.8.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T3.8.8.1.m1.1.1.3.3.2" xref="S4.T3.8.8.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.1.m1.1b"><apply id="S4.T3.8.8.1.m1.1.1.cmml" xref="S4.T3.8.8.1.m1.1.1"><times id="S4.T3.8.8.1.m1.1.1.1.cmml" xref="S4.T3.8.8.1.m1.1.1.1"></times><cn type="integer" id="S4.T3.8.8.1.m1.1.1.2.cmml" xref="S4.T3.8.8.1.m1.1.1.2">1</cn><apply id="S4.T3.8.8.1.m1.1.1.3.cmml" xref="S4.T3.8.8.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T3.8.8.1.m1.1.1.3.1.cmml" xref="S4.T3.8.8.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T3.8.8.1.m1.1.1.3.2.cmml" xref="S4.T3.8.8.1.m1.1.1.3.2">10</cn><apply id="S4.T3.8.8.1.m1.1.1.3.3.cmml" xref="S4.T3.8.8.1.m1.1.1.3.3"><minus id="S4.T3.8.8.1.m1.1.1.3.3.1.cmml" xref="S4.T3.8.8.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T3.8.8.1.m1.1.1.3.3.2.cmml" xref="S4.T3.8.8.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.1.m1.1c">1\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T3.9.9.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.9.9.2.m1.1" class="ltx_Math" alttext="40k" display="inline"><semantics id="S4.T3.9.9.2.m1.1a"><mrow id="S4.T3.9.9.2.m1.1.1" xref="S4.T3.9.9.2.m1.1.1.cmml"><mn id="S4.T3.9.9.2.m1.1.1.2" xref="S4.T3.9.9.2.m1.1.1.2.cmml">40</mn><mo lspace="0em" rspace="0em" id="S4.T3.9.9.2.m1.1.1.1" xref="S4.T3.9.9.2.m1.1.1.1.cmml">​</mo><mi id="S4.T3.9.9.2.m1.1.1.3" xref="S4.T3.9.9.2.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.2.m1.1b"><apply id="S4.T3.9.9.2.m1.1.1.cmml" xref="S4.T3.9.9.2.m1.1.1"><times id="S4.T3.9.9.2.m1.1.1.1.cmml" xref="S4.T3.9.9.2.m1.1.1.1"></times><cn type="integer" id="S4.T3.9.9.2.m1.1.1.2.cmml" xref="S4.T3.9.9.2.m1.1.1.2">40</cn><ci id="S4.T3.9.9.2.m1.1.1.3.cmml" xref="S4.T3.9.9.2.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.2.m1.1c">40k</annotation></semantics></math></td>
<td id="S4.T3.10.10.3" class="ltx_td ltx_align_center ltx_border_r">
<math id="S4.T3.10.10.3.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.T3.10.10.3.m1.1a"><mn id="S4.T3.10.10.3.m1.1.1" xref="S4.T3.10.10.3.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.T3.10.10.3.m1.1b"><cn type="integer" id="S4.T3.10.10.3.m1.1.1.cmml" xref="S4.T3.10.10.3.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.10.3.m1.1c">5</annotation></semantics></math>k</td>
<td id="S4.T3.11.11.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.11.11.4.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.T3.11.11.4.m1.1a"><mn id="S4.T3.11.11.4.m1.1.1" xref="S4.T3.11.11.4.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.T3.11.11.4.m1.1b"><cn type="float" id="S4.T3.11.11.4.m1.1.1.cmml" xref="S4.T3.11.11.4.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.11.4.m1.1c">0.5</annotation></semantics></math></td>
<td id="S4.T3.12.12.5" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.12.12.5.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.T3.12.12.5.m1.1a"><mn id="S4.T3.12.12.5.m1.1.1" xref="S4.T3.12.12.5.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.5.m1.1b"><cn type="float" id="S4.T3.12.12.5.m1.1.1.cmml" xref="S4.T3.12.12.5.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.5.m1.1c">0.1</annotation></semantics></math></td>
<td id="S4.T3.13.13.6" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.13.13.6.m1.1" class="ltx_Math" alttext="79.69" display="inline"><semantics id="S4.T3.13.13.6.m1.1a"><mn id="S4.T3.13.13.6.m1.1.1" xref="S4.T3.13.13.6.m1.1.1.cmml">79.69</mn><annotation-xml encoding="MathML-Content" id="S4.T3.13.13.6.m1.1b"><cn type="float" id="S4.T3.13.13.6.m1.1.1.cmml" xref="S4.T3.13.13.6.m1.1.1">79.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.13.6.m1.1c">79.69</annotation></semantics></math></td>
<td id="S4.T3.14.14.7" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.14.14.7.m1.1" class="ltx_Math" alttext="36.59" display="inline"><semantics id="S4.T3.14.14.7.m1.1a"><mn id="S4.T3.14.14.7.m1.1.1" xref="S4.T3.14.14.7.m1.1.1.cmml">36.59</mn><annotation-xml encoding="MathML-Content" id="S4.T3.14.14.7.m1.1b"><cn type="float" id="S4.T3.14.14.7.m1.1.1.cmml" xref="S4.T3.14.14.7.m1.1.1">36.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.14.7.m1.1c">36.59</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.21.21" class="ltx_tr">
<td id="S4.T3.21.21.8" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">Bribri</td>
<td id="S4.T3.15.15.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.15.15.1.m1.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.T3.15.15.1.m1.1a"><mrow id="S4.T3.15.15.1.m1.1.1" xref="S4.T3.15.15.1.m1.1.1.cmml"><mn id="S4.T3.15.15.1.m1.1.1.2" xref="S4.T3.15.15.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T3.15.15.1.m1.1.1.1" xref="S4.T3.15.15.1.m1.1.1.1.cmml">×</mo><msup id="S4.T3.15.15.1.m1.1.1.3" xref="S4.T3.15.15.1.m1.1.1.3.cmml"><mn id="S4.T3.15.15.1.m1.1.1.3.2" xref="S4.T3.15.15.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T3.15.15.1.m1.1.1.3.3" xref="S4.T3.15.15.1.m1.1.1.3.3.cmml"><mo id="S4.T3.15.15.1.m1.1.1.3.3a" xref="S4.T3.15.15.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T3.15.15.1.m1.1.1.3.3.2" xref="S4.T3.15.15.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.15.15.1.m1.1b"><apply id="S4.T3.15.15.1.m1.1.1.cmml" xref="S4.T3.15.15.1.m1.1.1"><times id="S4.T3.15.15.1.m1.1.1.1.cmml" xref="S4.T3.15.15.1.m1.1.1.1"></times><cn type="integer" id="S4.T3.15.15.1.m1.1.1.2.cmml" xref="S4.T3.15.15.1.m1.1.1.2">1</cn><apply id="S4.T3.15.15.1.m1.1.1.3.cmml" xref="S4.T3.15.15.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T3.15.15.1.m1.1.1.3.1.cmml" xref="S4.T3.15.15.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T3.15.15.1.m1.1.1.3.2.cmml" xref="S4.T3.15.15.1.m1.1.1.3.2">10</cn><apply id="S4.T3.15.15.1.m1.1.1.3.3.cmml" xref="S4.T3.15.15.1.m1.1.1.3.3"><minus id="S4.T3.15.15.1.m1.1.1.3.3.1.cmml" xref="S4.T3.15.15.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T3.15.15.1.m1.1.1.3.3.2.cmml" xref="S4.T3.15.15.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.15.1.m1.1c">1\times 10^{-4}</annotation></semantics></math></td>
<td id="S4.T3.16.16.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.16.16.2.m1.1" class="ltx_Math" alttext="90k" display="inline"><semantics id="S4.T3.16.16.2.m1.1a"><mrow id="S4.T3.16.16.2.m1.1.1" xref="S4.T3.16.16.2.m1.1.1.cmml"><mn id="S4.T3.16.16.2.m1.1.1.2" xref="S4.T3.16.16.2.m1.1.1.2.cmml">90</mn><mo lspace="0em" rspace="0em" id="S4.T3.16.16.2.m1.1.1.1" xref="S4.T3.16.16.2.m1.1.1.1.cmml">​</mo><mi id="S4.T3.16.16.2.m1.1.1.3" xref="S4.T3.16.16.2.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.16.16.2.m1.1b"><apply id="S4.T3.16.16.2.m1.1.1.cmml" xref="S4.T3.16.16.2.m1.1.1"><times id="S4.T3.16.16.2.m1.1.1.1.cmml" xref="S4.T3.16.16.2.m1.1.1.1"></times><cn type="integer" id="S4.T3.16.16.2.m1.1.1.2.cmml" xref="S4.T3.16.16.2.m1.1.1.2">90</cn><ci id="S4.T3.16.16.2.m1.1.1.3.cmml" xref="S4.T3.16.16.2.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.16.2.m1.1c">90k</annotation></semantics></math></td>
<td id="S4.T3.17.17.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.17.17.3.m1.1" class="ltx_Math" alttext="8k" display="inline"><semantics id="S4.T3.17.17.3.m1.1a"><mrow id="S4.T3.17.17.3.m1.1.1" xref="S4.T3.17.17.3.m1.1.1.cmml"><mn id="S4.T3.17.17.3.m1.1.1.2" xref="S4.T3.17.17.3.m1.1.1.2.cmml">8</mn><mo lspace="0em" rspace="0em" id="S4.T3.17.17.3.m1.1.1.1" xref="S4.T3.17.17.3.m1.1.1.1.cmml">​</mo><mi id="S4.T3.17.17.3.m1.1.1.3" xref="S4.T3.17.17.3.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.17.17.3.m1.1b"><apply id="S4.T3.17.17.3.m1.1.1.cmml" xref="S4.T3.17.17.3.m1.1.1"><times id="S4.T3.17.17.3.m1.1.1.1.cmml" xref="S4.T3.17.17.3.m1.1.1.1"></times><cn type="integer" id="S4.T3.17.17.3.m1.1.1.2.cmml" xref="S4.T3.17.17.3.m1.1.1.2">8</cn><ci id="S4.T3.17.17.3.m1.1.1.3.cmml" xref="S4.T3.17.17.3.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.17.3.m1.1c">8k</annotation></semantics></math></td>
<td id="S4.T3.18.18.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.18.18.4.m1.1" class="ltx_Math" alttext="0.3" display="inline"><semantics id="S4.T3.18.18.4.m1.1a"><mn id="S4.T3.18.18.4.m1.1.1" xref="S4.T3.18.18.4.m1.1.1.cmml">0.3</mn><annotation-xml encoding="MathML-Content" id="S4.T3.18.18.4.m1.1b"><cn type="float" id="S4.T3.18.18.4.m1.1.1.cmml" xref="S4.T3.18.18.4.m1.1.1">0.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.18.4.m1.1c">0.3</annotation></semantics></math></td>
<td id="S4.T3.19.19.5" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.19.19.5.m1.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S4.T3.19.19.5.m1.1a"><mn id="S4.T3.19.19.5.m1.1.1" xref="S4.T3.19.19.5.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S4.T3.19.19.5.m1.1b"><cn type="float" id="S4.T3.19.19.5.m1.1.1.cmml" xref="S4.T3.19.19.5.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.19.5.m1.1c">0.2</annotation></semantics></math></td>
<td id="S4.T3.20.20.6" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.20.20.6.m1.1" class="ltx_Math" alttext="69.03" display="inline"><semantics id="S4.T3.20.20.6.m1.1a"><mn id="S4.T3.20.20.6.m1.1.1" xref="S4.T3.20.20.6.m1.1.1.cmml">69.03</mn><annotation-xml encoding="MathML-Content" id="S4.T3.20.20.6.m1.1b"><cn type="float" id="S4.T3.20.20.6.m1.1.1.cmml" xref="S4.T3.20.20.6.m1.1.1">69.03</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.20.20.6.m1.1c">69.03</annotation></semantics></math></td>
<td id="S4.T3.21.21.7" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.21.21.7.m1.1" class="ltx_Math" alttext="34.70" display="inline"><semantics id="S4.T3.21.21.7.m1.1a"><mn id="S4.T3.21.21.7.m1.1.1" xref="S4.T3.21.21.7.m1.1.1.cmml">34.70</mn><annotation-xml encoding="MathML-Content" id="S4.T3.21.21.7.m1.1b"><cn type="float" id="S4.T3.21.21.7.m1.1.1.cmml" xref="S4.T3.21.21.7.m1.1.1">34.70</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.21.21.7.m1.1c">34.70</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.28.28" class="ltx_tr">
<td id="S4.T3.28.28.8" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">Guarani</td>
<td id="S4.T3.22.22.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.22.22.1.m1.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="S4.T3.22.22.1.m1.1a"><mrow id="S4.T3.22.22.1.m1.1.1" xref="S4.T3.22.22.1.m1.1.1.cmml"><mn id="S4.T3.22.22.1.m1.1.1.2" xref="S4.T3.22.22.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T3.22.22.1.m1.1.1.1" xref="S4.T3.22.22.1.m1.1.1.1.cmml">×</mo><msup id="S4.T3.22.22.1.m1.1.1.3" xref="S4.T3.22.22.1.m1.1.1.3.cmml"><mn id="S4.T3.22.22.1.m1.1.1.3.2" xref="S4.T3.22.22.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T3.22.22.1.m1.1.1.3.3" xref="S4.T3.22.22.1.m1.1.1.3.3.cmml"><mo id="S4.T3.22.22.1.m1.1.1.3.3a" xref="S4.T3.22.22.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T3.22.22.1.m1.1.1.3.3.2" xref="S4.T3.22.22.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.22.22.1.m1.1b"><apply id="S4.T3.22.22.1.m1.1.1.cmml" xref="S4.T3.22.22.1.m1.1.1"><times id="S4.T3.22.22.1.m1.1.1.1.cmml" xref="S4.T3.22.22.1.m1.1.1.1"></times><cn type="integer" id="S4.T3.22.22.1.m1.1.1.2.cmml" xref="S4.T3.22.22.1.m1.1.1.2">1</cn><apply id="S4.T3.22.22.1.m1.1.1.3.cmml" xref="S4.T3.22.22.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T3.22.22.1.m1.1.1.3.1.cmml" xref="S4.T3.22.22.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T3.22.22.1.m1.1.1.3.2.cmml" xref="S4.T3.22.22.1.m1.1.1.3.2">10</cn><apply id="S4.T3.22.22.1.m1.1.1.3.3.cmml" xref="S4.T3.22.22.1.m1.1.1.3.3"><minus id="S4.T3.22.22.1.m1.1.1.3.3.1.cmml" xref="S4.T3.22.22.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T3.22.22.1.m1.1.1.3.3.2.cmml" xref="S4.T3.22.22.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.22.22.1.m1.1c">1\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T3.23.23.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.23.23.2.m1.1" class="ltx_Math" alttext="90k" display="inline"><semantics id="S4.T3.23.23.2.m1.1a"><mrow id="S4.T3.23.23.2.m1.1.1" xref="S4.T3.23.23.2.m1.1.1.cmml"><mn id="S4.T3.23.23.2.m1.1.1.2" xref="S4.T3.23.23.2.m1.1.1.2.cmml">90</mn><mo lspace="0em" rspace="0em" id="S4.T3.23.23.2.m1.1.1.1" xref="S4.T3.23.23.2.m1.1.1.1.cmml">​</mo><mi id="S4.T3.23.23.2.m1.1.1.3" xref="S4.T3.23.23.2.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.23.23.2.m1.1b"><apply id="S4.T3.23.23.2.m1.1.1.cmml" xref="S4.T3.23.23.2.m1.1.1"><times id="S4.T3.23.23.2.m1.1.1.1.cmml" xref="S4.T3.23.23.2.m1.1.1.1"></times><cn type="integer" id="S4.T3.23.23.2.m1.1.1.2.cmml" xref="S4.T3.23.23.2.m1.1.1.2">90</cn><ci id="S4.T3.23.23.2.m1.1.1.3.cmml" xref="S4.T3.23.23.2.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.23.23.2.m1.1c">90k</annotation></semantics></math></td>
<td id="S4.T3.24.24.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.24.24.3.m1.1" class="ltx_Math" alttext="9k" display="inline"><semantics id="S4.T3.24.24.3.m1.1a"><mrow id="S4.T3.24.24.3.m1.1.1" xref="S4.T3.24.24.3.m1.1.1.cmml"><mn id="S4.T3.24.24.3.m1.1.1.2" xref="S4.T3.24.24.3.m1.1.1.2.cmml">9</mn><mo lspace="0em" rspace="0em" id="S4.T3.24.24.3.m1.1.1.1" xref="S4.T3.24.24.3.m1.1.1.1.cmml">​</mo><mi id="S4.T3.24.24.3.m1.1.1.3" xref="S4.T3.24.24.3.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.24.24.3.m1.1b"><apply id="S4.T3.24.24.3.m1.1.1.cmml" xref="S4.T3.24.24.3.m1.1.1"><times id="S4.T3.24.24.3.m1.1.1.1.cmml" xref="S4.T3.24.24.3.m1.1.1.1"></times><cn type="integer" id="S4.T3.24.24.3.m1.1.1.2.cmml" xref="S4.T3.24.24.3.m1.1.1.2">9</cn><ci id="S4.T3.24.24.3.m1.1.1.3.cmml" xref="S4.T3.24.24.3.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.24.24.3.m1.1c">9k</annotation></semantics></math></td>
<td id="S4.T3.25.25.4" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.25.25.4.m1.1" class="ltx_Math" alttext="0.3" display="inline"><semantics id="S4.T3.25.25.4.m1.1a"><mn id="S4.T3.25.25.4.m1.1.1" xref="S4.T3.25.25.4.m1.1.1.cmml">0.3</mn><annotation-xml encoding="MathML-Content" id="S4.T3.25.25.4.m1.1b"><cn type="float" id="S4.T3.25.25.4.m1.1.1.cmml" xref="S4.T3.25.25.4.m1.1.1">0.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.25.25.4.m1.1c">0.3</annotation></semantics></math></td>
<td id="S4.T3.26.26.5" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.26.26.5.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.T3.26.26.5.m1.1a"><mn id="S4.T3.26.26.5.m1.1.1" xref="S4.T3.26.26.5.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.T3.26.26.5.m1.1b"><cn type="float" id="S4.T3.26.26.5.m1.1.1.cmml" xref="S4.T3.26.26.5.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.26.26.5.m1.1c">0.1</annotation></semantics></math></td>
<td id="S4.T3.27.27.6" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.27.27.6.m1.1" class="ltx_Math" alttext="62.91" display="inline"><semantics id="S4.T3.27.27.6.m1.1a"><mn id="S4.T3.27.27.6.m1.1.1" xref="S4.T3.27.27.6.m1.1.1.cmml">62.91</mn><annotation-xml encoding="MathML-Content" id="S4.T3.27.27.6.m1.1b"><cn type="float" id="S4.T3.27.27.6.m1.1.1.cmml" xref="S4.T3.27.27.6.m1.1.1">62.91</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.27.27.6.m1.1c">62.91</annotation></semantics></math></td>
<td id="S4.T3.28.28.7" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T3.28.28.7.m1.1" class="ltx_Math" alttext="15.59" display="inline"><semantics id="S4.T3.28.28.7.m1.1a"><mn id="S4.T3.28.28.7.m1.1.1" xref="S4.T3.28.28.7.m1.1.1.cmml">15.59</mn><annotation-xml encoding="MathML-Content" id="S4.T3.28.28.7.m1.1b"><cn type="float" id="S4.T3.28.28.7.m1.1.1.cmml" xref="S4.T3.28.28.7.m1.1.1">15.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.28.28.7.m1.1c">15.59</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.35.35" class="ltx_tr">
<td id="S4.T3.35.35.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r">Wa'ikhana</td>
<td id="S4.T3.29.29.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T3.29.29.1.m1.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="S4.T3.29.29.1.m1.1a"><mrow id="S4.T3.29.29.1.m1.1.1" xref="S4.T3.29.29.1.m1.1.1.cmml"><mn id="S4.T3.29.29.1.m1.1.1.2" xref="S4.T3.29.29.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T3.29.29.1.m1.1.1.1" xref="S4.T3.29.29.1.m1.1.1.1.cmml">×</mo><msup id="S4.T3.29.29.1.m1.1.1.3" xref="S4.T3.29.29.1.m1.1.1.3.cmml"><mn id="S4.T3.29.29.1.m1.1.1.3.2" xref="S4.T3.29.29.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.T3.29.29.1.m1.1.1.3.3" xref="S4.T3.29.29.1.m1.1.1.3.3.cmml"><mo id="S4.T3.29.29.1.m1.1.1.3.3a" xref="S4.T3.29.29.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.T3.29.29.1.m1.1.1.3.3.2" xref="S4.T3.29.29.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.29.29.1.m1.1b"><apply id="S4.T3.29.29.1.m1.1.1.cmml" xref="S4.T3.29.29.1.m1.1.1"><times id="S4.T3.29.29.1.m1.1.1.1.cmml" xref="S4.T3.29.29.1.m1.1.1.1"></times><cn type="integer" id="S4.T3.29.29.1.m1.1.1.2.cmml" xref="S4.T3.29.29.1.m1.1.1.2">1</cn><apply id="S4.T3.29.29.1.m1.1.1.3.cmml" xref="S4.T3.29.29.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.T3.29.29.1.m1.1.1.3.1.cmml" xref="S4.T3.29.29.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.T3.29.29.1.m1.1.1.3.2.cmml" xref="S4.T3.29.29.1.m1.1.1.3.2">10</cn><apply id="S4.T3.29.29.1.m1.1.1.3.3.cmml" xref="S4.T3.29.29.1.m1.1.1.3.3"><minus id="S4.T3.29.29.1.m1.1.1.3.3.1.cmml" xref="S4.T3.29.29.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.T3.29.29.1.m1.1.1.3.3.2.cmml" xref="S4.T3.29.29.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.29.29.1.m1.1c">1\times 10^{-5}</annotation></semantics></math></td>
<td id="S4.T3.30.30.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T3.30.30.2.m1.1" class="ltx_Math" alttext="130k" display="inline"><semantics id="S4.T3.30.30.2.m1.1a"><mrow id="S4.T3.30.30.2.m1.1.1" xref="S4.T3.30.30.2.m1.1.1.cmml"><mn id="S4.T3.30.30.2.m1.1.1.2" xref="S4.T3.30.30.2.m1.1.1.2.cmml">130</mn><mo lspace="0em" rspace="0em" id="S4.T3.30.30.2.m1.1.1.1" xref="S4.T3.30.30.2.m1.1.1.1.cmml">​</mo><mi id="S4.T3.30.30.2.m1.1.1.3" xref="S4.T3.30.30.2.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.30.30.2.m1.1b"><apply id="S4.T3.30.30.2.m1.1.1.cmml" xref="S4.T3.30.30.2.m1.1.1"><times id="S4.T3.30.30.2.m1.1.1.1.cmml" xref="S4.T3.30.30.2.m1.1.1.1"></times><cn type="integer" id="S4.T3.30.30.2.m1.1.1.2.cmml" xref="S4.T3.30.30.2.m1.1.1.2">130</cn><ci id="S4.T3.30.30.2.m1.1.1.3.cmml" xref="S4.T3.30.30.2.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.30.30.2.m1.1c">130k</annotation></semantics></math></td>
<td id="S4.T3.31.31.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T3.31.31.3.m1.1" class="ltx_Math" alttext="1k" display="inline"><semantics id="S4.T3.31.31.3.m1.1a"><mrow id="S4.T3.31.31.3.m1.1.1" xref="S4.T3.31.31.3.m1.1.1.cmml"><mn id="S4.T3.31.31.3.m1.1.1.2" xref="S4.T3.31.31.3.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.T3.31.31.3.m1.1.1.1" xref="S4.T3.31.31.3.m1.1.1.1.cmml">​</mo><mi id="S4.T3.31.31.3.m1.1.1.3" xref="S4.T3.31.31.3.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.31.31.3.m1.1b"><apply id="S4.T3.31.31.3.m1.1.1.cmml" xref="S4.T3.31.31.3.m1.1.1"><times id="S4.T3.31.31.3.m1.1.1.1.cmml" xref="S4.T3.31.31.3.m1.1.1.1"></times><cn type="integer" id="S4.T3.31.31.3.m1.1.1.2.cmml" xref="S4.T3.31.31.3.m1.1.1.2">1</cn><ci id="S4.T3.31.31.3.m1.1.1.3.cmml" xref="S4.T3.31.31.3.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.31.31.3.m1.1c">1k</annotation></semantics></math></td>
<td id="S4.T3.32.32.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T3.32.32.4.m1.1" class="ltx_Math" alttext="0.25" display="inline"><semantics id="S4.T3.32.32.4.m1.1a"><mn id="S4.T3.32.32.4.m1.1.1" xref="S4.T3.32.32.4.m1.1.1.cmml">0.25</mn><annotation-xml encoding="MathML-Content" id="S4.T3.32.32.4.m1.1b"><cn type="float" id="S4.T3.32.32.4.m1.1.1.cmml" xref="S4.T3.32.32.4.m1.1.1">0.25</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.32.32.4.m1.1c">0.25</annotation></semantics></math></td>
<td id="S4.T3.33.33.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T3.33.33.5.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.T3.33.33.5.m1.1a"><mn id="S4.T3.33.33.5.m1.1.1" xref="S4.T3.33.33.5.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.T3.33.33.5.m1.1b"><cn type="float" id="S4.T3.33.33.5.m1.1.1.cmml" xref="S4.T3.33.33.5.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.33.33.5.m1.1c">0.1</annotation></semantics></math></td>
<td id="S4.T3.34.34.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T3.34.34.6.m1.1" class="ltx_Math" alttext="68.42" display="inline"><semantics id="S4.T3.34.34.6.m1.1a"><mn id="S4.T3.34.34.6.m1.1.1" xref="S4.T3.34.34.6.m1.1.1.cmml">68.42</mn><annotation-xml encoding="MathML-Content" id="S4.T3.34.34.6.m1.1b"><cn type="float" id="S4.T3.34.34.6.m1.1.1.cmml" xref="S4.T3.34.34.6.m1.1.1">68.42</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.34.34.6.m1.1c">68.42</annotation></semantics></math></td>
<td id="S4.T3.35.35.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T3.35.35.7.m1.1" class="ltx_Math" alttext="35.23" display="inline"><semantics id="S4.T3.35.35.7.m1.1a"><mn id="S4.T3.35.35.7.m1.1.1" xref="S4.T3.35.35.7.m1.1.1.cmml">35.23</mn><annotation-xml encoding="MathML-Content" id="S4.T3.35.35.7.m1.1b"><cn type="float" id="S4.T3.35.35.7.m1.1.1.cmml" xref="S4.T3.35.35.7.m1.1.1">35.23</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.35.35.7.m1.1c">35.23</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.37.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.38.2" class="ltx_text" style="font-size:90%;">WER and CER for the best fine-tuning hyperparameter configurations for the Quechua, Kotiria, Bribri, Guarani and Wa'ikhana. Additional configurations and results can be found in the Supplementary Information.</span></figcaption>
</figure>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.11" class="ltx_p">The Quechua language model, benefiting from a substantial training dataset of <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="12.09" display="inline"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">12.09</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn type="float" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">12.09</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">12.09</annotation></semantics></math> hours, achieved the best performance with a WER of <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="48.98\%" display="inline"><semantics id="S4.p2.2.m2.1a"><mrow id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mn id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">48.98</mn><mo id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">48.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">48.98\%</annotation></semantics></math> and a CER of <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="12.14\%" display="inline"><semantics id="S4.p2.3.m3.1a"><mrow id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mn id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">12.14</mn><mo id="S4.p2.3.m3.1.1.1" xref="S4.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">12.14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">12.14\%</annotation></semantics></math>. This underscores the positive effect of data abundance on model performance. However, our investigation also unveiled a counterintuitive observation: the Kotiria language model, with the most extensive dataset of <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="29.92" display="inline"><semantics id="S4.p2.4.m4.1a"><mn id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">29.92</mn><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><cn type="float" id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">29.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">29.92</annotation></semantics></math> hours (see table <a href="#S3.T1" title="Table 1 ‣ 3.2 Data ‣ 3 Experimental setup and dataset description ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), showed the highest WER (<math id="S4.p2.5.m5.1" class="ltx_Math" alttext="79.69\%" display="inline"><semantics id="S4.p2.5.m5.1a"><mrow id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml"><mn id="S4.p2.5.m5.1.1.2" xref="S4.p2.5.m5.1.1.2.cmml">79.69</mn><mo id="S4.p2.5.m5.1.1.1" xref="S4.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><apply id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1"><csymbol cd="latexml" id="S4.p2.5.m5.1.1.1.cmml" xref="S4.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.p2.5.m5.1.1.2.cmml" xref="S4.p2.5.m5.1.1.2">79.69</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">79.69\%</annotation></semantics></math>) and CER (<math id="S4.p2.6.m6.1" class="ltx_Math" alttext="36.59\%" display="inline"><semantics id="S4.p2.6.m6.1a"><mrow id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml"><mn id="S4.p2.6.m6.1.1.2" xref="S4.p2.6.m6.1.1.2.cmml">36.59</mn><mo id="S4.p2.6.m6.1.1.1" xref="S4.p2.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.1b"><apply id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1"><csymbol cd="latexml" id="S4.p2.6.m6.1.1.1.cmml" xref="S4.p2.6.m6.1.1.1">percent</csymbol><cn type="float" id="S4.p2.6.m6.1.1.2.cmml" xref="S4.p2.6.m6.1.1.2">36.59</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.1c">36.59\%</annotation></semantics></math>) rates. This discrepancy could arise from language complexity, data quality or diversity. Remarkably, the Guarani language model, trained on the smallest dataset (<math id="S4.p2.7.m7.1" class="ltx_Math" alttext="0.97" display="inline"><semantics id="S4.p2.7.m7.1a"><mn id="S4.p2.7.m7.1.1" xref="S4.p2.7.m7.1.1.cmml">0.97</mn><annotation-xml encoding="MathML-Content" id="S4.p2.7.m7.1b"><cn type="float" id="S4.p2.7.m7.1.1.cmml" xref="S4.p2.7.m7.1.1">0.97</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.7.m7.1c">0.97</annotation></semantics></math> hours), achieved a WER of <math id="S4.p2.8.m8.1" class="ltx_Math" alttext="62.91\%" display="inline"><semantics id="S4.p2.8.m8.1a"><mrow id="S4.p2.8.m8.1.1" xref="S4.p2.8.m8.1.1.cmml"><mn id="S4.p2.8.m8.1.1.2" xref="S4.p2.8.m8.1.1.2.cmml">62.91</mn><mo id="S4.p2.8.m8.1.1.1" xref="S4.p2.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.8.m8.1b"><apply id="S4.p2.8.m8.1.1.cmml" xref="S4.p2.8.m8.1.1"><csymbol cd="latexml" id="S4.p2.8.m8.1.1.1.cmml" xref="S4.p2.8.m8.1.1.1">percent</csymbol><cn type="float" id="S4.p2.8.m8.1.1.2.cmml" xref="S4.p2.8.m8.1.1.2">62.91</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.8.m8.1c">62.91\%</annotation></semantics></math> and a CER of <math id="S4.p2.9.m9.1" class="ltx_Math" alttext="15.59\%" display="inline"><semantics id="S4.p2.9.m9.1a"><mrow id="S4.p2.9.m9.1.1" xref="S4.p2.9.m9.1.1.cmml"><mn id="S4.p2.9.m9.1.1.2" xref="S4.p2.9.m9.1.1.2.cmml">15.59</mn><mo id="S4.p2.9.m9.1.1.1" xref="S4.p2.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.9.m9.1b"><apply id="S4.p2.9.m9.1.1.cmml" xref="S4.p2.9.m9.1.1"><csymbol cd="latexml" id="S4.p2.9.m9.1.1.1.cmml" xref="S4.p2.9.m9.1.1.1">percent</csymbol><cn type="float" id="S4.p2.9.m9.1.1.2.cmml" xref="S4.p2.9.m9.1.1.2">15.59</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.9.m9.1c">15.59\%</annotation></semantics></math>. This suggests that meticulous hyperparameter tuning can bolster performance even when data availability is limited. This trend extended to the Bribri and Wa'ikhana language models, which exhibited intermediate performance levels despite varying dataset sizes (<math id="S4.p2.10.m10.1" class="ltx_Math" alttext="2.38" display="inline"><semantics id="S4.p2.10.m10.1a"><mn id="S4.p2.10.m10.1.1" xref="S4.p2.10.m10.1.1.cmml">2.38</mn><annotation-xml encoding="MathML-Content" id="S4.p2.10.m10.1b"><cn type="float" id="S4.p2.10.m10.1.1.cmml" xref="S4.p2.10.m10.1.1">2.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.10.m10.1c">2.38</annotation></semantics></math> and <math id="S4.p2.11.m11.1" class="ltx_Math" alttext="6.11" display="inline"><semantics id="S4.p2.11.m11.1a"><mn id="S4.p2.11.m11.1.1" xref="S4.p2.11.m11.1.1.cmml">6.11</mn><annotation-xml encoding="MathML-Content" id="S4.p2.11.m11.1b"><cn type="float" id="S4.p2.11.m11.1.1.cmml" xref="S4.p2.11.m11.1.1">6.11</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.11.m11.1c">6.11</annotation></semantics></math> hours, respectively). These outcomes, as shown in Table <a href="#S4.T3" title="Table 3 ‣ 4 Results ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, underscore the pivotal role of hyperparameter tuning in determining model performance. Additional configurations and results can be found in the Supplementary Information.
<br class="ltx_break"></p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.1" class="ltx_p">In addition, our research examined two variants of the Wav2vec2.0 XLS-R model: one with 300 million parameters and another with 1 billion parameters. Despite the difference in parameter count, both models yielded comparable results, except for Kotiria, where the bigger model showed significantly better performance. This suggests that the choice between these two models may be influenced by resource constraints, where the smaller model may be preferable for applications with limited resources, while the larger model could offer slightly improved performance when more data is available.
<br class="ltx_break"></p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2404.08368/assets/figure_results.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="294" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;">Character Error Rates (CER) for indigenous language models and Sobol index analysis of hyperparameter influence on model performance.</span></figcaption>
</figure>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.8" class="ltx_p">Analyzing the hyperparameters across different languages, it is noticeable that the learning rate is consistently set at either <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="S4.p4.1.m1.1a"><mrow id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml"><mn id="S4.p4.1.m1.1.1.2" xref="S4.p4.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p4.1.m1.1.1.1" xref="S4.p4.1.m1.1.1.1.cmml">×</mo><msup id="S4.p4.1.m1.1.1.3" xref="S4.p4.1.m1.1.1.3.cmml"><mn id="S4.p4.1.m1.1.1.3.2" xref="S4.p4.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.p4.1.m1.1.1.3.3" xref="S4.p4.1.m1.1.1.3.3.cmml"><mo id="S4.p4.1.m1.1.1.3.3a" xref="S4.p4.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.p4.1.m1.1.1.3.3.2" xref="S4.p4.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><apply id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1"><times id="S4.p4.1.m1.1.1.1.cmml" xref="S4.p4.1.m1.1.1.1"></times><cn type="integer" id="S4.p4.1.m1.1.1.2.cmml" xref="S4.p4.1.m1.1.1.2">1</cn><apply id="S4.p4.1.m1.1.1.3.cmml" xref="S4.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p4.1.m1.1.1.3.1.cmml" xref="S4.p4.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.p4.1.m1.1.1.3.2.cmml" xref="S4.p4.1.m1.1.1.3.2">10</cn><apply id="S4.p4.1.m1.1.1.3.3.cmml" xref="S4.p4.1.m1.1.1.3.3"><minus id="S4.p4.1.m1.1.1.3.3.1.cmml" xref="S4.p4.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.p4.1.m1.1.1.3.3.2.cmml" xref="S4.p4.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">1\times 10^{-5}</annotation></semantics></math> or <math id="S4.p4.2.m2.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.p4.2.m2.1a"><mrow id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml"><mn id="S4.p4.2.m2.1.1.2" xref="S4.p4.2.m2.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p4.2.m2.1.1.1" xref="S4.p4.2.m2.1.1.1.cmml">×</mo><msup id="S4.p4.2.m2.1.1.3" xref="S4.p4.2.m2.1.1.3.cmml"><mn id="S4.p4.2.m2.1.1.3.2" xref="S4.p4.2.m2.1.1.3.2.cmml">10</mn><mrow id="S4.p4.2.m2.1.1.3.3" xref="S4.p4.2.m2.1.1.3.3.cmml"><mo id="S4.p4.2.m2.1.1.3.3a" xref="S4.p4.2.m2.1.1.3.3.cmml">−</mo><mn id="S4.p4.2.m2.1.1.3.3.2" xref="S4.p4.2.m2.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><apply id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1"><times id="S4.p4.2.m2.1.1.1.cmml" xref="S4.p4.2.m2.1.1.1"></times><cn type="integer" id="S4.p4.2.m2.1.1.2.cmml" xref="S4.p4.2.m2.1.1.2">1</cn><apply id="S4.p4.2.m2.1.1.3.cmml" xref="S4.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.p4.2.m2.1.1.3.1.cmml" xref="S4.p4.2.m2.1.1.3">superscript</csymbol><cn type="integer" id="S4.p4.2.m2.1.1.3.2.cmml" xref="S4.p4.2.m2.1.1.3.2">10</cn><apply id="S4.p4.2.m2.1.1.3.3.cmml" xref="S4.p4.2.m2.1.1.3.3"><minus id="S4.p4.2.m2.1.1.3.3.1.cmml" xref="S4.p4.2.m2.1.1.3.3"></minus><cn type="integer" id="S4.p4.2.m2.1.1.3.3.2.cmml" xref="S4.p4.2.m2.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">1\times 10^{-4}</annotation></semantics></math>, although the search range is wider (see table <a href="#S3.T2" title="Table 2 ‣ 3.4 Hyperparameter Fine-tuning ‣ 3 Experimental setup and dataset description ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). This low learning rate aligns with previously reported investigations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, allowing precise weight adjustments during the fine-tuning phase. The learning rate is highly related to the maximum number of updates. In this case, the total number of iterations the model trains varies widely from <math id="S4.p4.3.m3.1" class="ltx_Math" alttext="40k" display="inline"><semantics id="S4.p4.3.m3.1a"><mrow id="S4.p4.3.m3.1.1" xref="S4.p4.3.m3.1.1.cmml"><mn id="S4.p4.3.m3.1.1.2" xref="S4.p4.3.m3.1.1.2.cmml">40</mn><mo lspace="0em" rspace="0em" id="S4.p4.3.m3.1.1.1" xref="S4.p4.3.m3.1.1.1.cmml">​</mo><mi id="S4.p4.3.m3.1.1.3" xref="S4.p4.3.m3.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.3.m3.1b"><apply id="S4.p4.3.m3.1.1.cmml" xref="S4.p4.3.m3.1.1"><times id="S4.p4.3.m3.1.1.1.cmml" xref="S4.p4.3.m3.1.1.1"></times><cn type="integer" id="S4.p4.3.m3.1.1.2.cmml" xref="S4.p4.3.m3.1.1.2">40</cn><ci id="S4.p4.3.m3.1.1.3.cmml" xref="S4.p4.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.3.m3.1c">40k</annotation></semantics></math> to <math id="S4.p4.4.m4.1" class="ltx_Math" alttext="130k" display="inline"><semantics id="S4.p4.4.m4.1a"><mrow id="S4.p4.4.m4.1.1" xref="S4.p4.4.m4.1.1.cmml"><mn id="S4.p4.4.m4.1.1.2" xref="S4.p4.4.m4.1.1.2.cmml">130</mn><mo lspace="0em" rspace="0em" id="S4.p4.4.m4.1.1.1" xref="S4.p4.4.m4.1.1.1.cmml">​</mo><mi id="S4.p4.4.m4.1.1.3" xref="S4.p4.4.m4.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.4.m4.1b"><apply id="S4.p4.4.m4.1.1.cmml" xref="S4.p4.4.m4.1.1"><times id="S4.p4.4.m4.1.1.1.cmml" xref="S4.p4.4.m4.1.1.1"></times><cn type="integer" id="S4.p4.4.m4.1.1.2.cmml" xref="S4.p4.4.m4.1.1.2">130</cn><ci id="S4.p4.4.m4.1.1.3.cmml" xref="S4.p4.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.4.m4.1c">130k</annotation></semantics></math>. However, no apparent simple relationship exists between the number of updates, the optimization step size, or the available training datasetas illustrated in figure <a href="#S4.F2" title="Figure 2 ‣ 4 Results ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. This suggests the requirement of different amounts of training depending upon the complexity and uniqueness of the languages. The fine-tuning freezing point, denoting the end at which specific model layers are frozen and not updated, seems to increase with the maximum number of updates for the Quechua, Bribri, and Guarani languages. However, this pattern does not hold for the Wa'ikhana language, which combines a lower freezing point with more updates. The mask channel values hover between <math id="S4.p4.5.m5.1" class="ltx_Math" alttext="0.25" display="inline"><semantics id="S4.p4.5.m5.1a"><mn id="S4.p4.5.m5.1.1" xref="S4.p4.5.m5.1.1.cmml">0.25</mn><annotation-xml encoding="MathML-Content" id="S4.p4.5.m5.1b"><cn type="float" id="S4.p4.5.m5.1.1.cmml" xref="S4.p4.5.m5.1.1">0.25</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.5.m5.1c">0.25</annotation></semantics></math> and <math id="S4.p4.6.m6.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.p4.6.m6.1a"><mn id="S4.p4.6.m6.1.1" xref="S4.p4.6.m6.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.p4.6.m6.1b"><cn type="float" id="S4.p4.6.m6.1.1.cmml" xref="S4.p4.6.m6.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.6.m6.1c">0.5</annotation></semantics></math>, implying the significance of masking specific inputs during training, potentially reducing overfitting. Finally, activation dropout rates are consistently low across the models, between <math id="S4.p4.7.m7.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.p4.7.m7.1a"><mn id="S4.p4.7.m7.1.1" xref="S4.p4.7.m7.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.p4.7.m7.1b"><cn type="float" id="S4.p4.7.m7.1.1.cmml" xref="S4.p4.7.m7.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.7.m7.1c">0.1</annotation></semantics></math> and <math id="S4.p4.8.m8.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S4.p4.8.m8.1a"><mn id="S4.p4.8.m8.1.1" xref="S4.p4.8.m8.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S4.p4.8.m8.1b"><cn type="float" id="S4.p4.8.m8.1.1.cmml" xref="S4.p4.8.m8.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.8.m8.1c">0.2</annotation></semantics></math>, suggesting a regularization strategy to prevent overfitting while maintaining the capability to learn complex patterns.
<br class="ltx_break"></p>
</div>
<div id="S4.p5" class="ltx_para ltx_noindent">
<p id="S4.p5.1" class="ltx_p">Specific hyperparameters did not correlate directly with lower WER or Loss values. This suggests that the optimal hyperparameters are highly dependent on language-specific characteristics. Nonetheless, it is worth noting that despite similar learning rates, mask channel probabilities, and activation dropout rates, the Guarani language model achieved notably lower WER and Loss values, hinting at the influence of factors like dataset quality, model architecture, or inherent language characteristics.
<br class="ltx_break"></p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.12.13.1" class="ltx_tr">
<th id="S4.T4.12.13.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_t"><span id="S4.T4.12.13.1.1.1" class="ltx_text ltx_font_bold">Parameter</span></th>
<th id="S4.T4.12.13.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.12.13.1.2.1" class="ltx_text ltx_font_bold">S1</span></th>
<th id="S4.T4.12.13.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T4.12.13.1.3.1" class="ltx_text ltx_font_bold">ST</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.2.2" class="ltx_tr">
<td id="S4.T4.2.2.3" class="ltx_td ltx_align_left ltx_border_l ltx_border_t">Freeze fine-tune updates</td>
<td id="S4.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T4.1.1.1.m1.1" class="ltx_Math" alttext="0.32" display="inline"><semantics id="S4.T4.1.1.1.m1.1a"><mn id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml">0.32</mn><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><cn type="float" id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1">0.32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">0.32</annotation></semantics></math></td>
<td id="S4.T4.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S4.T4.2.2.2.m1.1" class="ltx_Math" alttext="0.41" display="inline"><semantics id="S4.T4.2.2.2.m1.1a"><mn id="S4.T4.2.2.2.m1.1.1" xref="S4.T4.2.2.2.m1.1.1.cmml">0.41</mn><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.m1.1b"><cn type="float" id="S4.T4.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1">0.41</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.m1.1c">0.41</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.4.4" class="ltx_tr">
<td id="S4.T4.4.4.3" class="ltx_td ltx_align_left ltx_border_l">Activation dropout</td>
<td id="S4.T4.3.3.1" class="ltx_td ltx_align_center"><math id="S4.T4.3.3.1.m1.1" class="ltx_Math" alttext="0.35" display="inline"><semantics id="S4.T4.3.3.1.m1.1a"><mn id="S4.T4.3.3.1.m1.1.1" xref="S4.T4.3.3.1.m1.1.1.cmml">0.35</mn><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.1.m1.1b"><cn type="float" id="S4.T4.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.1.m1.1.1">0.35</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.1.m1.1c">0.35</annotation></semantics></math></td>
<td id="S4.T4.4.4.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.4.4.2.m1.1" class="ltx_Math" alttext="0.37" display="inline"><semantics id="S4.T4.4.4.2.m1.1a"><mn id="S4.T4.4.4.2.m1.1.1" xref="S4.T4.4.4.2.m1.1.1.cmml">0.37</mn><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.2.m1.1b"><cn type="float" id="S4.T4.4.4.2.m1.1.1.cmml" xref="S4.T4.4.4.2.m1.1.1">0.37</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.2.m1.1c">0.37</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.6.6" class="ltx_tr">
<td id="S4.T4.6.6.3" class="ltx_td ltx_align_left ltx_border_l">Mask prob</td>
<td id="S4.T4.5.5.1" class="ltx_td ltx_align_center"><math id="S4.T4.5.5.1.m1.1" class="ltx_Math" alttext="0.54" display="inline"><semantics id="S4.T4.5.5.1.m1.1a"><mn id="S4.T4.5.5.1.m1.1.1" xref="S4.T4.5.5.1.m1.1.1.cmml">0.54</mn><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.1.m1.1b"><cn type="float" id="S4.T4.5.5.1.m1.1.1.cmml" xref="S4.T4.5.5.1.m1.1.1">0.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.1.m1.1c">0.54</annotation></semantics></math></td>
<td id="S4.T4.6.6.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.6.6.2.m1.1" class="ltx_Math" alttext="0.29" display="inline"><semantics id="S4.T4.6.6.2.m1.1a"><mn id="S4.T4.6.6.2.m1.1.1" xref="S4.T4.6.6.2.m1.1.1.cmml">0.29</mn><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.2.m1.1b"><cn type="float" id="S4.T4.6.6.2.m1.1.1.cmml" xref="S4.T4.6.6.2.m1.1.1">0.29</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.2.m1.1c">0.29</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.8.8" class="ltx_tr">
<td id="S4.T4.8.8.3" class="ltx_td ltx_align_left ltx_border_l">Mask channel prob</td>
<td id="S4.T4.7.7.1" class="ltx_td ltx_align_center"><math id="S4.T4.7.7.1.m1.1" class="ltx_Math" alttext="0.54" display="inline"><semantics id="S4.T4.7.7.1.m1.1a"><mn id="S4.T4.7.7.1.m1.1.1" xref="S4.T4.7.7.1.m1.1.1.cmml">0.54</mn><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.1.m1.1b"><cn type="float" id="S4.T4.7.7.1.m1.1.1.cmml" xref="S4.T4.7.7.1.m1.1.1">0.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.1.m1.1c">0.54</annotation></semantics></math></td>
<td id="S4.T4.8.8.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.8.8.2.m1.1" class="ltx_Math" alttext="0.28" display="inline"><semantics id="S4.T4.8.8.2.m1.1a"><mn id="S4.T4.8.8.2.m1.1.1" xref="S4.T4.8.8.2.m1.1.1.cmml">0.28</mn><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.2.m1.1b"><cn type="float" id="S4.T4.8.8.2.m1.1.1.cmml" xref="S4.T4.8.8.2.m1.1.1">0.28</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.2.m1.1c">0.28</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.10.10" class="ltx_tr">
<td id="S4.T4.10.10.3" class="ltx_td ltx_align_left ltx_border_l">Learning Rate (lr)</td>
<td id="S4.T4.9.9.1" class="ltx_td ltx_align_center"><math id="S4.T4.9.9.1.m1.1" class="ltx_Math" alttext="0.57" display="inline"><semantics id="S4.T4.9.9.1.m1.1a"><mn id="S4.T4.9.9.1.m1.1.1" xref="S4.T4.9.9.1.m1.1.1.cmml">0.57</mn><annotation-xml encoding="MathML-Content" id="S4.T4.9.9.1.m1.1b"><cn type="float" id="S4.T4.9.9.1.m1.1.1.cmml" xref="S4.T4.9.9.1.m1.1.1">0.57</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.9.1.m1.1c">0.57</annotation></semantics></math></td>
<td id="S4.T4.10.10.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S4.T4.10.10.2.m1.1" class="ltx_Math" alttext="0.26" display="inline"><semantics id="S4.T4.10.10.2.m1.1a"><mn id="S4.T4.10.10.2.m1.1.1" xref="S4.T4.10.10.2.m1.1.1.cmml">0.26</mn><annotation-xml encoding="MathML-Content" id="S4.T4.10.10.2.m1.1b"><cn type="float" id="S4.T4.10.10.2.m1.1.1.cmml" xref="S4.T4.10.10.2.m1.1.1">0.26</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.10.2.m1.1c">0.26</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.12.12" class="ltx_tr">
<td id="S4.T4.12.12.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_l">Max Update</td>
<td id="S4.T4.11.11.1" class="ltx_td ltx_align_center ltx_border_b"><math id="S4.T4.11.11.1.m1.1" class="ltx_Math" alttext="\sim 0" display="inline"><semantics id="S4.T4.11.11.1.m1.1a"><mrow id="S4.T4.11.11.1.m1.1.1" xref="S4.T4.11.11.1.m1.1.1.cmml"><mi id="S4.T4.11.11.1.m1.1.1.2" xref="S4.T4.11.11.1.m1.1.1.2.cmml"></mi><mo id="S4.T4.11.11.1.m1.1.1.1" xref="S4.T4.11.11.1.m1.1.1.1.cmml">∼</mo><mn id="S4.T4.11.11.1.m1.1.1.3" xref="S4.T4.11.11.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.11.11.1.m1.1b"><apply id="S4.T4.11.11.1.m1.1.1.cmml" xref="S4.T4.11.11.1.m1.1.1"><csymbol cd="latexml" id="S4.T4.11.11.1.m1.1.1.1.cmml" xref="S4.T4.11.11.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S4.T4.11.11.1.m1.1.1.2.cmml" xref="S4.T4.11.11.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T4.11.11.1.m1.1.1.3.cmml" xref="S4.T4.11.11.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.11.1.m1.1c">\sim 0</annotation></semantics></math></td>
<td id="S4.T4.12.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S4.T4.12.12.2.m1.1" class="ltx_Math" alttext="0.13" display="inline"><semantics id="S4.T4.12.12.2.m1.1a"><mn id="S4.T4.12.12.2.m1.1.1" xref="S4.T4.12.12.2.m1.1.1.cmml">0.13</mn><annotation-xml encoding="MathML-Content" id="S4.T4.12.12.2.m1.1b"><cn type="float" id="S4.T4.12.12.2.m1.1.1.cmml" xref="S4.T4.12.12.2.m1.1.1">0.13</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.12.2.m1.1c">0.13</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.14.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.15.2" class="ltx_text" style="font-size:90%;">Sensitivity analysis results using First-Order (S1) Sobol and Global (ST) indices for the different fine-tuning hyperparameters. Parameters have been ordered by the ST importance.</span></figcaption>
</figure>
<div id="S4.p6" class="ltx_para ltx_noindent">
<p id="S4.p6.1" class="ltx_p">Table <a href="#S4.T4" title="Table 4 ‣ 4 Results ‣ ASR advancements for indigenous languages: Quechua, Guarani, Bribri, Kotiria, and Wa’ikhana" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents the outcomes of the Sobol sensitivity analysis, offering insights into the relative significance of each hyperparameter in influencing the WER of the language model. This analysis delves into the influence of six key hyperparameters: Learning Rate, Max number of Updates, Freeze fine-tune updates, Mask prob, Mask channel prob, and Activation dropout, on the model's WER. First-Order Sensitivity (S1) index measures the individual contribution of the parameter to the total output variance, while the Total Sensitivity (ST) index reflects the total contribution of a parameter, including its interactions with the other hyperparameters to the final output. Interestingly, hyperparameters with the most substantial individual influence on the WER (S1), e.g. Learning Rate (ST=0.57) or masked channel probability (S1=0.54), do not have so high an impact when considering the interactions with the other hyperparameters (ST=0.26 and ST=0.28 correspondently). Notably, the hyperparameter with higher ST is the freeze fine-tuning updates, suggesting that a bad choice could lead to <span id="S4.p6.1.1" class="ltx_text ltx_font_italic">forget</span> the info in the pre-trained layers or to not <span id="S4.p6.1.2" class="ltx_text ltx_font_italic">adapt</span> the pretrained neural network to the current domain. On the other hand, unexpectedly, the maximum number of updates during training seems not so sensible, although it is usually a parameter to which the research community shows more attention. Finally, activation dropout is the second most important contribution to the output variance on the ST, which is somehow expected as it is a sensible tunning that avoids overfitting but which, in turn, can make training difficult when not properly adjusted.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions and future work</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">In this work, we have fine-tuned and reported the very first ASR models for the Wa'ikhana and Kotiria languages and additionally established new benchmarks within the dataset of the Americas NLP Challenge 2022 for the Guarani, Quechua and Bribri, marking a significant step forward in this field. These results represent an important contribution to the study of ASR in indigenous languages, where only a few dozen studies are reported for these languages. Besides, we publish our best models in a repository and the full hyperparameter experiments in the SI. 
<br class="ltx_break"></p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p">We show that pre-trained models are very promising when fine-tuning them to some unknown domain with a very low amount of data but that bigger architectures do not always achieve better results. This may be due to the fact that when the number of data is very small and also very far from the pre-trained domain, it is more difficult to converge to an optimal solution if the number of trainable parameters is too large. This would imply that for some corner cases and minority languages, the race to use architectures with an increasing number of parameters may not be the most effective. Surprisingly, we did not find clear evidence between the number of hours available for each language and the accuracy of the fine-tuned models. This may be related to the phonemic distance between the pre-trained languages and the fine-tuned domains, which may have made the quantized latent pre-trained representations unsuitable for all the target languages. 
<br class="ltx_break"></p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p">The application of Sobol Sensitivity Analysis has allowed us to identify critical hyperparameters that impact language model performance in ASR tasks. These insights inform future hyperparameter tuning efforts, enhancing the accuracy and efficiency of ASR systems for under-resourced languages. We unveil that when considering internal correlations, the number of epochs where the pre-trained layers of the models are frozen is significantly more important than the total number of trained epochs. This indicates that when low amount of data is available for fine-tuning, the greatest effort has to be made inefficiently adjusting the weights of the neural network in the last layers rather than in adjusting its weights across the architecture. The second most important factor unveiled by Sobol analysis is the dropout rate and it shows that when the number of trainable parameters is so large and the amount of data is so scarce, the risk of overtraining is very high. This comprehensive evaluation of hyperparameters provides a valuable tool for optimizing ASR models, particularly crucial for languages with limited resources and data availability. 
<br class="ltx_break"></p>
</div>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.1" class="ltx_p">To round off, we hope that this work paves the way for new research avenues in ASR of indigenous languages and minority domains in general. Future research could explore advanced methods, such as automated machine learning (AutoML), for a more exhaustive exploration of hyperparameter spaces, potentially resulting in more optimized models. Also, advanced regularization techniques could mitigate model complexity and overfitting, especially in languages with limited data. Collecting more data for under-resourced languages is important, but the emphasis should be on capturing linguistic intricacies, dialectal variations, and cultural contexts to train more robust and culturally sensitive models. Furthermore, exploring the potential benefits of transfer learning from high-resource languages to less-resourced languages is an avenue worth pursuing. Cross-linguistic knowledge transfer could help mitigate the challenges posed by data scarcity and enhance model performance for underrepresented languages. These and other possible tasks will help to democratize access to AI speech models for the thousands of languages across the Earth. 
<br class="ltx_break"></p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Data and models accessibility</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The data utilized for fine-tuning, provided by the AmericasNLP challenge, is accessible online <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>. The results obtained by performing experiments with different hyperparameters and configurations are available in the Supplementary Information (SI). The fine-tuned models for each language, including Quechua <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, Bribri <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>, Kotiria <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>, Guarani <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>, and Wa'ikhana <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>, are stored in their respective repositories on Mendeley Data. Scripts prepared for downloading the fine-tuned models and able to perform inference are now available in <a target="_blank" href="https://github.com/monirome/asr-indigenous-languages" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/monirome/asr-indigenous-languages</a>.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgements</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">The authors gratefully acknowledge the Universidad Politécnica de Madrid for providing computing resources on the Magerit Supercomputer.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Brian C. Thiede and Clark Gray.

</span>
<span class="ltx_bibblock">Characterizing the indigenous forest peoples of latin america:
Results from census data.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">World Development</span>, 125:104685, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
UNESCO.

</span>
<span class="ltx_bibblock">How can latin american and caribbean indigenous languages be
preserved?, 2021.

</span>
<span class="ltx_bibblock">Last accessed 02 July 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Norman A McQuown.

</span>
<span class="ltx_bibblock">The indigenous languages of latin america.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">American Anthropologist</span>, 57(3):501–570, 1955.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Susan Chiblow and Paul J. Meighan.

</span>
<span class="ltx_bibblock">Language is land, land is language: The importance of indigenous
languages.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Human Geography</span>, 15(2):206–210, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
UNESCO.

</span>
<span class="ltx_bibblock">Indigenous languages: gateways to the world, 2022.

</span>
<span class="ltx_bibblock">Last accessed 02 July 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Global predictors of language endangerment and the future of linguistic
diversity.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Nature Ecology &amp; Evolution</span>, 6:163–173, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Jenanne Ferguson and Marissa Weaselboy.

</span>
<span class="ltx_bibblock">Indigenous sustainable relations: considering land in language and
language in land.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Current Opinion in Environmental Sustainability</span>, 43:1–7, 2020.

</span>
<span class="ltx_bibblock">Indigenous Conceptualizations of ‘Sustainability’.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Manuel Mager, Katharina Kann, Abteen Ebrahimi, Félix Oncevay, Rodolfo
Zevallos, Adam Wiemerslage, Pavel Denisov, John Ortega, Kristine Stenzel,
Aldo Alvarez, Luis Chiruzzo, Rolando Coto-Solano, Hilaria Cruz, Sofía
Flores-Solórzano, Iván Meza, and Thang Palmer, Alexis abd Vu.

</span>
<span class="ltx_bibblock">La modelización de la morfología verbal bribri, 20223.

</span>
<span class="ltx_bibblock">Last accessed 12 August 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Adolfo Constenla Umaña.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Chibchan languages</span>, pages 391–440.

</span>
<span class="ltx_bibblock">De Gruyter Mouton, Berlin, Boston, 2012.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Isaac Feldman and Rolando Coto-Solano.

</span>
<span class="ltx_bibblock">Neural machine translation models with back-translation for the
extremely low-resource indigenous language Bribri.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of the 28th International Conference on
Computational Linguistics</span>. International Committee on Computational
Linguistics, December 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Katharina Kann, Abteen Ebrahimi, Manuel Mager, Arturo Oncevay, John E Ortega,
Annette Rios, Angela Fan, Ximena Gutierrez-Vasques, Luis Chiruzzo, Gustavo A
Giménez-Lugo, et al.

</span>
<span class="ltx_bibblock">Americasnli: Machine translation and natural language inference
systems for indigenous languages of the americas.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Frontiers in Artificial Intelligence</span>, 5:266, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
W.F.H. Adelaar.

</span>
<span class="ltx_bibblock">Guaraní.

</span>
<span class="ltx_bibblock">In Keith Brown, editor, <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Encyclopedia of Language &amp; Linguistics
(Second Edition)</span>, pages 165–166. Elsevier, Oxford, second edition edition,
2006.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
William Costa.

</span>
<span class="ltx_bibblock">'culture is language': why an indigenous tongue is thriving in
paraguay, 2020.

</span>
<span class="ltx_bibblock">Last accessed 10 July 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
K. Stenzel.

</span>
<span class="ltx_bibblock">Kotiria 'differential object marking' in cross-linguistic
perspective.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Amerindia</span>, 32:153–181, 2008.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Endangered language project.

</span>
<span class="ltx_bibblock">Endangered language project catalogue, 2023.

</span>
<span class="ltx_bibblock">Last accessed 12 July 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Mily Crevels.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Language endangerment in South America: The clock is ticking</span>,
pages 167–234.

</span>
<span class="ltx_bibblock">De Gruyter Mouton, Berlin, Boston, 2012.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Ethnologue.

</span>
<span class="ltx_bibblock">Languages of the world, 2023.

</span>
<span class="ltx_bibblock">Last accessed 12 July 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
UNESCO.

</span>
<span class="ltx_bibblock">World atlas of languages, 2023.

</span>
<span class="ltx_bibblock">Last accessed 12 July 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Adrian J. Pearce and Paul Heggarty.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">``Mining the Data'' on the Huancayo-Huancavelica Quechua
Frontier</span>, pages 87–109.

</span>
<span class="ltx_bibblock">Palgrave Macmillan US, 2011.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Cristián Lagos, Marco Espinoza, and Darío. Rojas.

</span>
<span class="ltx_bibblock">Mapudungun according to its speakers: Mapuche intellectuals and the
influence of standard language ideology.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Current Issues in Language Planning</span>, 14:105–118, 2013.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Tom Ko, Vijayaditya Peddinti, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Audio augmentation for speech recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Sixteenth annual conference of the international speech
communication association</span>, 2015.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Tom Ko, Vijayaditya Peddinti, Daniel Povey, Michael L Seltzer, and Sanjeev
Khudanpur.

</span>
<span class="ltx_bibblock">A study on data augmentation of reverberant speech for robust speech
recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">2017 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP)</span>, pages 5220–5224. IEEE, 2017.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Daniel S Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D
Cubuk, and Quoc V Le.

</span>
<span class="ltx_bibblock">Specaugment: A simple data augmentation method for automatic speech
recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1904.08779</span>, 2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Gabriel Synnaeve, Qiantong Xu, Jacob Kahn, Tatiana Likhomanenko, Edouard Grave,
Vineel Pratap, Anuroop Sriram, Vitaliy Liptchinsky, and Ronan Collobert.

</span>
<span class="ltx_bibblock">End-to-end asr: from supervised to semi-supervised learning with
modern architectures.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1911.08460</span>, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Qiantong Xu, Tatiana Likhomanenko, Jacob Kahn, Awni Hannun, Gabriel Synnaeve,
and Ronan Collobert.

</span>
<span class="ltx_bibblock">Iterative pseudo-labeling for speech recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2005.09267</span>, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, and Michael Auli.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech
representations.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2006.11477, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Cheng Yi, Jianzong Wang, Ning Cheng, Shiyu Zhou, and Bo Xu.

</span>
<span class="ltx_bibblock">Applying wav2vec2.0 to speech recognition in various low-resource
languages.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/2012.12121, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Alexei Baevski, Wei-Ning Hsu, Alexis Conneau, and Michael Auli.

</span>
<span class="ltx_bibblock">Unsupervised speech recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
34:27826–27839, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Dong Wang and Thomas Fang Zheng.

</span>
<span class="ltx_bibblock">Transfer learning for speech and language processing.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">2015 Asia-Pacific Signal and Information Processing
Association Annual Summit and Conference (APSIPA)</span>, pages 1225–1237. IEEE,
2015.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Julius Kunze, Louis Kirsch, Ilia Kurenkov, Andreas Krug, Jens Johannsmeier, and
Sebastian Stober.

</span>
<span class="ltx_bibblock">Transfer learning for speech recognition on a budget.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1706.00290</span>, 2017.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Jiangyan Yi, Jianhua Tao, Zhengqi Wen, and Ye Bai.

</span>
<span class="ltx_bibblock">Language-adversarial transfer learning for low-resource speech
recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language
Processing</span>, 27(3):621–630, 2018.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Abteen Ebrahimi, Manuel Mager, Adam Wiemerslage, Pavel Denisov, Arturo Oncevay,
Danni Liu, Sai Koneru, Enes Yavuz Ugan, Zhaolin Li, Jan Niehues, et al.

</span>
<span class="ltx_bibblock">Findings of the second americasnlp competition on speech-to-text
translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">NeurIPS 2022 Competition Track</span>, pages 217–232. PMLR, 2022.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Manuel Mager, Ximena Gutierrez-Vasques, Gerardo Sierra, and Ivan Meza.

</span>
<span class="ltx_bibblock">Challenges of language technologies for the indigenous languages of
the americas, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Manuel Mager, Arturo Oncevay, Abteen Ebrahimi, John Ortega, Annette Rios
Gonzales, Angela Fan, Ximena Gutierrez-Vasques, Luis Chiruzzo, Gustavo
Giménez-Lugo, Ricardo Ramos, et al.

</span>
<span class="ltx_bibblock">Findings of the americasnlp 2021 shared task on open machine
translation for indigenous languages of the americas.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Proceedings of the First Workshop on Natural Language
Processing for Indigenous Languages of the Americas</span>, pages 202–217, 2021.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Katharina Kann, Abteen Ebrahimi, Manuel Mager, Arturo Oncevay, John E Ortega,
Annette Rios, Angela Fan, Ximena Gutierrez-Vasques, Luis Chiruzzo, Gustavo A
Giménez-Lugo, et al.

</span>
<span class="ltx_bibblock">Americasnli: Machine translation and natural language inference
systems for indigenous languages of the americas.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Frontiers in Artificial Intelligence</span>, 5:266, 2022.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Marvin Matías Agüero Torales et al.

</span>
<span class="ltx_bibblock">Machine learning approaches for topic and sentiment analysis in
multilingual opinions and low-resource languages: From english to guarani.

</span>
<span class="ltx_bibblock">2022.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Mike Gasser.

</span>
<span class="ltx_bibblock">Machine translation and the future of indigenous languages.

</span>
<span class="ltx_bibblock">In <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">I Congreso Internacional de Lenguas y Literaturas
Indoamericanas</span>, 2006.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Robert Jimerson, Zoey Liu, and Emily Prud'hommeaux.

</span>
<span class="ltx_bibblock">An (unhelpful) guide to selecting the best ASR architecture for
your under-resourced language.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for
Computational Linguistics (Volume 2: Short Papers)</span>, pages 1008–1016,
Toronto, Canada, July 2023. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Sajal Sasmal and Yang Saring.

</span>
<span class="ltx_bibblock">Robust automatic continuous speech recognition for'adi', a
zero-resource indigenous language of arunachal pradesh.

</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Sādhanā</span>, 47(4):271, 2022.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Rolando Coto-Solano, Sally Akevai Nicholas, Samiha Datta, Victoria Quint,
Piripi Wills, Emma Ngakuravaru Powell, Liam Koka‘ua, Syed Tanveer, and
Isaac Feldman.

</span>
<span class="ltx_bibblock">Development of automatic speech recognition for the documentation of
cook islands māori.

</span>
<span class="ltx_bibblock">2022.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Hernan Faustino Chacca Chuctaya, Rolfy Nixon Montufar Mercado, and Jeyson
Jesus Gonzales Gaona.

</span>
<span class="ltx_bibblock">Isolated automatic speech recognition of quechua numbers using mfcc,
dtw and knn.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Int. J. Adv. Comput. Sci. Appl</span>, 9(10):24–29, 2018.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Oliver Adams, Matthew Wiesner, Shinji Watanabe, and David Yarowsky.

</span>
<span class="ltx_bibblock">Massively multilingual adversarial speech recognition.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1904.02210</span>, 2019.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Rodolfo Zevallos, Johanna Cordova, and Luis Camacho.

</span>
<span class="ltx_bibblock">Automatic speech recognition of quechua language using hmm toolkit.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">Annual international symposium on information management and
big data</span>, pages 61–68. Springer, 2019.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Rodolfo Zevallos, Nuria Bel, Guillermo Cámbara, Mireia Farrús, and Jordi
Luque.

</span>
<span class="ltx_bibblock">Data augmentation for low-resource quechua asr improvement, 2022.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Diego Manuel Maldonado, Rodrigo Villalba Barrientos, and Diego P Pinto-Roa.

</span>
<span class="ltx_bibblock">Eñe’  e: Sistema de reconocimiento automático del habla en
guaraní.

</span>
<span class="ltx_bibblock">In <span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">Simposio Argentino de Inteligencia Artificial (ASAI
2016)-JAIIO 45 (Tres de Febrero, 2016).</span>, 2016.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Kay Peterson, Audrey Tong, and Yan Yu.

</span>
<span class="ltx_bibblock">Openasr20: An open challenge for automatic speech recognition of
conversational telephone speech in low-resource languages.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Interspeech</span>, pages 4324–4328, 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Kay Peterson, Audrey Tong, and Yan Yu.

</span>
<span class="ltx_bibblock">Openasr21: The second open challenge for automatic speech recognition
of low-resource languages.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Proc. Interspeech 2022</span>, pages 4895–4899, 2022.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Zhiqiang Lv, Jinghao Yan, Pengfei Hu, Jian Kang, Jing Zhao, Guixin Shi, Guan-Bo
Wang, Ambyera Han, Shen Huang, and Wei-Qiang Zhang.

</span>
<span class="ltx_bibblock">The tnt team system descriptions for iarpa openasr20.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Jing Zhao and Wei-Qiang Zhang.

</span>
<span class="ltx_bibblock">Improving automatic speech recognition performance for low-resource
languages with self-supervised models.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">IEEE Journal of Selected Topics in Signal Processing</span>,
16(6):1227–1241, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Rolando Coto-Solano and Flores Solórzano Sofía.

</span>
<span class="ltx_bibblock">Alineación forzada sin entrenamiento para la anotación automática
de corpus orales de las lenguas indígenas de costa rica.

</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">Káñina</span>, 40(4):175–199, 2017.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Rolando Coto-Solano.

</span>
<span class="ltx_bibblock">Explicit tone transcription improves ASR performance in extremely
low-resource languages: A case study in Bribri.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">Proceedings of the First Workshop on Natural Language
Processing for Indigenous Languages of the Americas</span>, pages 173–184, Online,
June 2021. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Chih-Chen Chen, William Chen, Rodolfo Zevallos, and John Ortega.

</span>
<span class="ltx_bibblock">Evaluating self-supervised speech representations for indigenous
american languages.

</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2310.03639</span>, 2023.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Rolando Coto-Solano.

</span>
<span class="ltx_bibblock">Evaluating word embeddings in extremely under-resourced languages: A
case study in Bribri.

</span>
<span class="ltx_bibblock">In <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Proceedings of the 29th International Conference on
Computational Linguistics</span>, pages 4455–4467, Gyeongju, Republic of Korea,
October 2022. International Committee on Computational Linguistics.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Emily Prud’hommeaux, Robbie Jimerson, Richard Hatcher, and Karin Michelson.

</span>
<span class="ltx_bibblock">Automatic speech recognition for supporting endangered language
documentation, 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Olga Krasnoukhova.

</span>
<span class="ltx_bibblock">Attributive modification in south american indigenous languages.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Linguistics</span>, 60(3):745–807, 2022.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer,
and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1911.02116, 2019.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Cheng Yi, Jianzong Wang, Ning Cheng, Shiyu Zhou, and Bo Xu.

</span>
<span class="ltx_bibblock">Transfer ability of monolingual wav2vec2.0 for low-resource speech
recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">2021 International Joint Conference on Neural Networks
(IJCNN)</span>, pages 1–6, 2021.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Krishna D. N, Pinyi Wang, and Bruno Bozza.

</span>
<span class="ltx_bibblock">Using Large Self-Supervised Models for Low-Resource Speech
Recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">Proc. Interspeech 2021</span>, pages 2436–2440, 2021.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Iván G Torre, Mónica Romero, and Aitor Álvarez.

</span>
<span class="ltx_bibblock">Improving aphasic speech recognition by using novel semi-supervised
learning methods on aphasiabank for english and spanish.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">Applied Sciences</span>, 11(19):8872, 2021.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Jiyang Tang, William Chen, Xuankai Chang, Shinji Watanabe, and Brian
MacWhinney.

</span>
<span class="ltx_bibblock">A new benchmark of aphasia speech recognition and detection based on
e-branchformer and multi-task learning, 2023.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and
Ilya Sutskever.

</span>
<span class="ltx_bibblock">Robust speech recognition via large-scale weak supervision, 2022.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech
representations.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>,
33:12449–12460, 2020.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman
Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei
Baevski, Alexis Conneau, and Michael Auli.

</span>
<span class="ltx_bibblock">Xls-r: Self-supervised cross-lingual speech representation learning
at scale, 2021.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler,
Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor
Weber.

</span>
<span class="ltx_bibblock">Common voice: A massively-multilingual speech corpus.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1912.06670</span>, 2019.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Mark JF Gales, Kate M Knill, Anton Ragni, and Shakti P Rath.

</span>
<span class="ltx_bibblock">Speech recognition and keyword spotting for low-resource languages:
Babel project research at cued.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Fourth International workshop on spoken language technologies
for under-resourced languages (SLTU-2014)</span>, pages 16–23. International
Speech Communication Association (ISCA), 2014.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, and Ronan
Collobert.

</span>
<span class="ltx_bibblock">Mls: A large-scale multilingual dataset for speech research.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.03411</span>, 2020.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Changhan Wang, Morgane Riviere, Ann Lee, Anne Wu, Chaitanya Talnikar, Daniel
Haziza, Mary Williamson, Juan Pino, and Emmanuel Dupoux.

</span>
<span class="ltx_bibblock">VoxPopuli: A large-scale multilingual speech corpus for
representation learning, semi-supervised learning and interpretation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for
Computational Linguistics and the 11th International Joint Conference on
Natural Language Processing (Volume 1: Long Papers)</span>, pages 993–1003,
Online, August 2021. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Jörgen Valk and Tanel Alumäe.

</span>
<span class="ltx_bibblock">Voxlingua107: a dataset for spoken language recognition, 2020.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Corpus oral pandialectal de la lengua bribri.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://bribri.net" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://bribri.net</a>, 2017.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Grammar and multilingual practices through the lens of everyday interaction in
two endangered languages in the east tukano family.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://hdl.handle.net/2196/00-0000-0000-0010-7D1A-A" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://hdl.handle.net/2196/00-0000-0000-0010-7D1A-A</a>, 2017.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Kotiria linguistic and cultural archive. endangered languages archive.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://hdl.handle.net/2196/00-0000-0000-0002-05B0-5" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://hdl.handle.net/2196/00-0000-0000-0002-05B0-5</a>, 2007.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Wa’ikhana linguistic and cultural archive. endangered languages archiv.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://hdl.handle.net/2196/00-0000-0000-000E-692D-2" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://hdl.handle.net/2196/00-0000-0000-000E-692D-2</a>, 2007.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Siminchikkunarayku.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.siminchikkunarayku.pe/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.siminchikkunarayku.pe/</a>.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Universidad de Costa Rica.

</span>
<span class="ltx_bibblock">Portal de la lengua bribri se'ie), 2021.

</span>
<span class="ltx_bibblock">Last accessed 12 September 2023.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
live.bible.is.

</span>
<span class="ltx_bibblock">Last accessed 12 September 2023.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Matthew Brown and Karen Tucker.

</span>
<span class="ltx_bibblock">Data from quipu project (12-2018), 2020.

</span>
<span class="ltx_bibblock">Last accessed 12 September 2023.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Tom Ko, Vijayaditya Peddinti, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Audio augmentation for speech recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">Proc. Interspeech 2015</span>, pages 3586–3589, 2015.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Kenneth Heafield.

</span>
<span class="ltx_bibblock">Kenlm: Faster and smaller language model queries.

</span>
<span class="ltx_bibblock">In <span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">Proceedings of the sixth workshop on statistical machine
translation</span>, pages 187–197, 2011.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas.

</span>
<span class="ltx_bibblock">Taking the human out of the loop: A review of bayesian optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib79.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, 104(1):148–175, 2015.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama.

</span>
<span class="ltx_bibblock">Optuna: A next-generation hyperparameter optimization framework.

</span>
<span class="ltx_bibblock">In <span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining</span>, 2019.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Ilya M Sobol.

</span>
<span class="ltx_bibblock">Global sensitivity indices for nonlinear mathematical models and
their monte carlo estimates.

</span>
<span class="ltx_bibblock"><span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">Mathematics and computers in simulation</span>, 55(1-3):271–280,
2001.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Ruy Freitas Reis, Bárbara de Melo Quintela, Joventino de Oliveira Campos,
Johnny Moreira Gomes, Bernardo Martins Rocha, Marcelo Lobosco, and
Rodrigo Weber Dos Santos.

</span>
<span class="ltx_bibblock">Characterization of the covid-19 pandemic and the impact of
uncertainties, mitigation strategies, and underreporting of cases in south
korea, italy, and brazil.

</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">Chaos, Solitons &amp; Fractals</span>, 136:109888, 2020.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Kezia Megagita Gerby Langie, Kyungjae Tak, Changsoo Kim, Hee Won Lee, Kwangho
Park, Dongjin Kim, Wonsang Jung, Chan Woo Lee, Hyung-Suk Oh, Dong Ki Lee,
et al.

</span>
<span class="ltx_bibblock">Toward economical application of carbon capture and utilization
technology with near-zero carbon emission.

</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">Nature Communications</span>, 13(1):7482, 2022.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Kevin Schneider, Wopke Van der Werf, Martina Cendoya, Monique Mourits, Juan A
Navas-Cortés, Antonio Vicent, and Alfons Oude Lansink.

</span>
<span class="ltx_bibblock">Impact of xylella fastidiosa subspecies pauca in european olives.

</span>
<span class="ltx_bibblock"><span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">Proceedings of the National Academy of Sciences</span>,
117(17):9250–9259, 2020.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Pantelis Linardatos, Vasilis Papastefanopoulos, and Sotiris Kotsiantis.

</span>
<span class="ltx_bibblock">Explainable ai: A review of machine learning interpretability
methods.

</span>
<span class="ltx_bibblock"><span id="bib.bib85.1.1" class="ltx_text ltx_font_italic">Entropy</span>, 23(1):18, 2020.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Anestis Antoniadis, Sophie Lambert-Lacroix, and Jean-Michel Poggi.

</span>
<span class="ltx_bibblock">Random forests for global sensitivity analysis: A selective review.

</span>
<span class="ltx_bibblock"><span id="bib.bib86.1.1" class="ltx_text ltx_font_italic">Reliability Engineering &amp; System Safety</span>, 206:107312, 2021.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Zehui Wang, Mingxuan Li, Fengsheng Ren, Binjian Ma, Huizhu Yang, and Yonggang
Zhu.

</span>
<span class="ltx_bibblock">Sobol sensitivity analysis and multi-objective optimization of
manifold microchannel heat sink considering entropy generation minimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib87.1.1" class="ltx_text ltx_font_italic">International Journal of Heat and Mass Transfer</span>, 208:124046,
2023.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
I.M Sobol.

</span>
<span class="ltx_bibblock">Global sensitivity indices for nonlinear mathematical models and
their monte carlo estimates.

</span>
<span class="ltx_bibblock"><span id="bib.bib88.1.1" class="ltx_text ltx_font_italic">Mathematics and Computers in Simulation</span>, 55(1):271–280, 2001.

</span>
<span class="ltx_bibblock">The Second IMACS Seminar on Monte Carlo Methods.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
AmericasNLP Organizers.

</span>
<span class="ltx_bibblock">Data for fine-tuning in americasnlp 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/AmericasNLP/americasnlp2022/tree/master" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/AmericasNLP/americasnlp2022/tree/master</a>,
2022.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Monica Romero.

</span>
<span class="ltx_bibblock">Asr indigenous language quechua, 2023.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Monica Romero.

</span>
<span class="ltx_bibblock">Asr indigenous language bribri, 2023.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Monica Romero.

</span>
<span class="ltx_bibblock">Asr indigenous language kotiria, 2023.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Monica Romero.

</span>
<span class="ltx_bibblock">Asr indigenous language guarani, 2023.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
Monica Romero.

</span>
<span class="ltx_bibblock">Asr indigenous language wa'ikhana, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.08367" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.08368" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.08368">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.08368" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.08369" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 19:14:53 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
