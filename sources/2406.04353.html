<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.04353] Introducing the Brand New QiandaoEar22 Dataset for Specific Ship Identification Using Ship-Radiated Noise This work was funded jointly by Natural Science Foundation of Shanghai (Grant No. 22ZR1475700), Youth Innovation Promotion Association CAS (Grant No. 2021022), and Young Talent Cultivation Program of Shanghai Branch of CAS.</title><meta property="og:description" content="Target identification of ship-radiated noise is a crucial area in underwater target recognition. However, there is currently a lack of multi-target ship datasets that accurately represent real-world underwater acoustic…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Introducing the Brand New QiandaoEar22 Dataset for Specific Ship Identification Using Ship-Radiated Noise This work was funded jointly by Natural Science Foundation of Shanghai (Grant No. 22ZR1475700), Youth Innovation Promotion Association CAS (Grant No. 2021022), and Young Talent Cultivation Program of Shanghai Branch of CAS.">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Introducing the Brand New QiandaoEar22 Dataset for Specific Ship Identification Using Ship-Radiated Noise This work was funded jointly by Natural Science Foundation of Shanghai (Grant No. 22ZR1475700), Youth Innovation Promotion Association CAS (Grant No. 2021022), and Young Talent Cultivation Program of Shanghai Branch of CAS.">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.04353">

<!--Generated on Sat Jul  6 01:34:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Ship-radiated noise dataset,  Underwater acoustic target recognition,  Underwater acoustics
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Introducing the Brand New QiandaoEar22 Dataset for Specific Ship Identification Using Ship-Radiated Noise
<br class="ltx_break"><span id="id1.id1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>This work was funded jointly by Natural Science Foundation of Shanghai (Grant No. 22ZR1475700), Youth Innovation Promotion Association CAS (Grant No. 2021022), and Young Talent Cultivation Program of Shanghai Branch of CAS.</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">1<sup id="id2.1.id1" class="ltx_sup">st</sup> Xiaoyang Du
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.2.id1" class="ltx_text ltx_font_italic">Shanghai Acoustics Laboratory,
<br class="ltx_break">Chinese Academy of Sciences
<br class="ltx_break">University of Chinese Academy of Sciences
<br class="ltx_break"></span>Shanghai, China 
<br class="ltx_break">duxiaoyang22@mails.ucas.ac.cn
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">2<sup id="id4.1.id1" class="ltx_sup">nd</sup> Feng Hong
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.2.id1" class="ltx_text ltx_font_italic">Shanghai Acoustics Laboratory,
<br class="ltx_break">Chinese Academy of Sciences
<br class="ltx_break"></span>Shanghai, China 
<br class="ltx_break">hongfeng@mail.ioa.ac.cn
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">Target identification of ship-radiated noise is a crucial area in underwater target recognition. However, there is currently a lack of multi-target ship datasets that accurately represent real-world underwater acoustic conditions. To ntackle this issue, we release QiandaoEar22 —an underwater acoustic multi-target dataset, which can be download on https://ieee-dataport.org/documents/qiandaoear22. This dataset encompasses 9 hours and 28 minutes of real-world ship-radiated noise data and 21 hours and 58 minutes of background noise data. We demonstrate the availability of QiandaoEar22 by conducting an experiment of identifying specific ship from the multiple targets. Taking different features as the input and six deep learning networks as classifier, we evaluate the baseline performance of different methods. The experimental results reveal that identifying the specific target of UUV from others can achieve the optimal recognition accuracy of 97.78%, and we find using spectrum and MFCC as feature inputs and DenseNet as the classifier can achieve better recognition performance. Our work not only establishes a benchmark for the dataset but helps the further development of innovative methods for the tasks of underwater acoustic target detection (UATD) and underwater acoustic target recognition(UATR).</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Ship-radiated noise dataset, Underwater acoustic target recognition, Underwater acoustics

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The importance of underwater acoustic target has been emphasized since American inventor Fessenden’s creation of sonar in 1913. However, publicly available datasets for underwater acoustic target research are scarce. Some small scale datasets have been created, including those from cargo ships, navy vessels, and personal watercraft. While some recent datasets like ShipsEar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and Deepship <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> are available, they primarily consist of single target ship-radiated noise data in simple environments, lacking the complexity of multiple target scenarios which often encounter in real-world conditions.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this paper, an underwater acoustic multi-target dataset named QiandaoEar22, is constructed through the experiment conducted in Qiandao Lake in 2022. Then, an experimental task is demonstrated to identify the specific ship from the multiple targets, which could be a reference when using this dataset for other potential purposes.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">The QiandaoEar22 dataset</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The data collection was performed from June 24 to 28, 2022, at the Xin’ anjiang Experimental Site of the Institute of Acoustics, Chinese Academy of Sciences (CAS), situated in the Qiandaohu town, Zhejiang, China. The coordinates of our sampling locations were 118.974532°E, 29.557795°N, and 118.947097°E, 29.548708°N, respectively. During the experiments, a DigitalHyd SR-1 hydrophone was anchored at the center of the deployment area using a counterweight and a buoy. The water depth was 30 to 50 meters, while the hydrophone was positioned at a depth of 10 to 15 meters. The experimental equipment was deployed near the channel to capture a broader range of radiated noise from the ships.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2406.04353/assets/distribution.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="88" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Duration of the recorded data for different targets</figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The recorded targets include large tour boats, cargo ships, sanitation vessels, small boats, research ships, and other targets such as helicopters and cars which noise were produced in the air but spread into underwater. The section of each audio segment are recorded according to the spectral characteristics. We label each data based on auditory sensation, distance, and their types. Among these tags, the auditory sensation is a subjective indicator which means the sound intensity of what the human ears hear, which can be strong,middle or weak. After labeling, the segmented data has the length of 3 seconds.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The ship-radiated noise dataset consists of 10,611 records in WAV format with a total of 143 recordings containing single or multiple ship targets. As shown in Fig. <a href="#S2.F1" title="Figure 1 ‣ II The QiandaoEar22 dataset ‣ Introducing the Brand New QiandaoEar22 Dataset for Specific Ship Identification Using Ship-Radiated Noise This work was funded jointly by Natural Science Foundation of Shanghai (Grant No. 22ZR1475700), Youth Innovation Promotion Association CAS (Grant No. 2021022), and Young Talent Cultivation Program of Shanghai Branch of CAS." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our dataset contains 20 categories of targets. Additionally, in order to ensure the integrity of the constructed dataset, we collect some background noise data during nighttime and idle periods. Ultimately, our dataset obtains a total of 9 hours and 28 minutes of real-world ship-radiated noise data and 21 hours and 58 minutes background data, which can be download on https://ieee-dataport.org/documents/qiandaoear22.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Experimental task: Identifying a specific type of ship signals from multiple targets</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To demonstrate the use of the dataset, we design an experimental task to identify a specific type of ship signals from the multi-target ship-radiated noise signals. The ship types can be speedboat, KaiYuan, and UUV, which is shown in Fig. <a href="#S3.F2" title="Figure 2 ‣ III Experimental task: Identifying a specific type of ship signals from multiple targets ‣ Introducing the Brand New QiandaoEar22 Dataset for Specific Ship Identification Using Ship-Radiated Noise This work was funded jointly by Natural Science Foundation of Shanghai (Grant No. 22ZR1475700), Youth Innovation Promotion Association CAS (Grant No. 2021022), and Young Talent Cultivation Program of Shanghai Branch of CAS." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We take different features as the input and several deep learning networks as classifier to evaluate the baseline performance of different methods.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04353/assets/speedboat.png" id="S3.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="78" height="50" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S3.F2.sf1.3.2" class="ltx_text" style="font-size:80%;">SpeedBoat</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04353/assets/kaiyuan.png" id="S3.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="78" height="50" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S3.F2.sf2.3.2" class="ltx_text" style="font-size:80%;">KaiYuan</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.04353/assets/uuv.jpg" id="S3.F2.sf3.g1" class="ltx_graphics ltx_img_landscape" width="78" height="50" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S3.F2.sf3.3.2" class="ltx_text" style="font-size:80%;">UUV</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Target ships</figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">To compare the performance of different networks, we calculate the average performance for different 2D features using the same network, shown in Fig. <a href="#S4.F3" title="Figure 3 ‣ IV Conclusion ‣ Introducing the Brand New QiandaoEar22 Dataset for Specific Ship Identification Using Ship-Radiated Noise This work was funded jointly by Natural Science Foundation of Shanghai (Grant No. 22ZR1475700), Youth Innovation Promotion Association CAS (Grant No. 2021022), and Young Talent Cultivation Program of Shanghai Branch of CAS." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Taking the UUV experiment as an example, DenseNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> performs best, followed by ResNet, CRNN, CNN, ECAPA-TDNN, and BiLSTM. The best average recognition accuracy can reach 97.78%, with only 4.34% of the data containing UUV targets being falsely recognized. To summarize, empirically, the DenseNet can be an exceptional choice when selecting a classifier to identify a specific type of ship signals from multiple targets using 2D features.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Then, we average the results obtained for each feature to find the superior features. According to the result shown in Table <a href="#S4.T1" title="TABLE I ‣ IV Conclusion ‣ Introducing the Brand New QiandaoEar22 Dataset for Specific Ship Identification Using Ship-Radiated Noise This work was funded jointly by Natural Science Foundation of Shanghai (Grant No. 22ZR1475700), Youth Innovation Promotion Association CAS (Grant No. 2021022), and Young Talent Cultivation Program of Shanghai Branch of CAS." class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, the spectrum and MFCC perform the best among 1D and 2D features separately, with both achieving accuracies of over 95%. The spectrum of ship-radiated noise consists of continuous, line, and modulation spectra, providing essential information about ship operations, engine status, and underwater environments. The reason why MFCC performs well may because it is designed based on human auditory perception and process signals through Mel filters. These characteristics better capture features at different frequencies in ship-radiated noise.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">Based on the above experimental task results, in underwater target recognition task of identifying a specific type of ship signals from multiple targets, using spectrum and MFCC as feature inputs and DenseNet as classifier can achieve better recognition performance. Empirically, similar choices in practical applications have indeed yielded better classification results, consistent with our experimental findings.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<figure id="S4.F3" class="ltx_figure"><img src="/html/2406.04353/assets/2D_result.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="94" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Average experimental results of deep learning methods for 2D feature classification</figcaption>
</figure>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Avearge results of the same feature (%)</figcaption>
<table id="S4.T1.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.3.1" class="ltx_tr">
<td id="S4.T1.3.1.1" class="ltx_td ltx_align_center">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;"> </span><span id="S4.T1.3.1.1.1" class="ltx_text" style="font-size:70%;">
feature</span>
</td>
<td id="S4.T1.3.1.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.1.2.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
<td id="S4.T1.3.1.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.1.3.1" class="ltx_text" style="font-size:70%;">recall</span></td>
<td id="S4.T1.3.1.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.1.4.1" class="ltx_text" style="font-size:70%;">precision</span></td>
<td id="S4.T1.3.1.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.1.5.1" class="ltx_text" style="font-size:70%;">F1 score</span></td>
<td id="S4.T1.3.1.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.1.6.1" class="ltx_text" style="font-size:70%;">FNR</span></td>
<td id="S4.T1.3.1.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.1.7.1" class="ltx_text" style="font-size:70%;">FPR</span></td>
</tr>
<tr id="S4.T1.3.2" class="ltx_tr">
<td id="S4.T1.3.2.1" class="ltx_td ltx_align_center">
<span class="ltx_rule" style="width:100%;height:0.5pt;background:black;display:inline-block;"> </span><span id="S4.T1.3.2.1.1" class="ltx_text" style="font-size:70%;">
Spectrum</span>
</td>
<td id="S4.T1.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.2.2.1" class="ltx_text" style="font-size:70%;">96.73</span></td>
<td id="S4.T1.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.2.3.1" class="ltx_text" style="font-size:70%;">96.43</span></td>
<td id="S4.T1.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.2.4.1" class="ltx_text" style="font-size:70%;">96.30</span></td>
<td id="S4.T1.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.2.5.1" class="ltx_text" style="font-size:70%;">96.35</span></td>
<td id="S4.T1.3.2.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.2.6.1" class="ltx_text" style="font-size:70%;">3.49</span></td>
<td id="S4.T1.3.2.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.2.7.1" class="ltx_text" style="font-size:70%;">3.65</span></td>
</tr>
<tr id="S4.T1.3.3" class="ltx_tr">
<td id="S4.T1.3.3.1" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.1.1" class="ltx_text" style="font-size:70%;">MFCC</span></td>
<td id="S4.T1.3.3.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.2.1" class="ltx_text" style="font-size:70%;">95.47</span></td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.3.1" class="ltx_text" style="font-size:70%;">94.92</span></td>
<td id="S4.T1.3.3.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.4.1" class="ltx_text" style="font-size:70%;">95.06</span></td>
<td id="S4.T1.3.3.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.5.1" class="ltx_text" style="font-size:70%;">94.95</span></td>
<td id="S4.T1.3.3.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.6.1" class="ltx_text" style="font-size:70%;">5.36</span></td>
<td id="S4.T1.3.3.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.3.7.1" class="ltx_text" style="font-size:70%;">4.54</span></td>
</tr>
<tr id="S4.T1.3.4" class="ltx_tr">
<td id="S4.T1.3.4.1" class="ltx_td ltx_align_center"><span id="S4.T1.3.4.1.1" class="ltx_text" style="font-size:70%;">Log Mel</span></td>
<td id="S4.T1.3.4.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.4.2.1" class="ltx_text" style="font-size:70%;">94.24</span></td>
<td id="S4.T1.3.4.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.4.3.1" class="ltx_text" style="font-size:70%;">93.24</span></td>
<td id="S4.T1.3.4.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.4.4.1" class="ltx_text" style="font-size:70%;">93.89</span></td>
<td id="S4.T1.3.4.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.4.5.1" class="ltx_text" style="font-size:70%;">93.48</span></td>
<td id="S4.T1.3.4.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.4.6.1" class="ltx_text" style="font-size:70%;">7.43</span></td>
<td id="S4.T1.3.4.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.4.7.1" class="ltx_text" style="font-size:70%;">6.09</span></td>
</tr>
<tr id="S4.T1.3.5" class="ltx_tr">
<td id="S4.T1.3.5.1" class="ltx_td ltx_align_center"><span id="S4.T1.3.5.1.1" class="ltx_text" style="font-size:70%;">PSD</span></td>
<td id="S4.T1.3.5.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.5.2.1" class="ltx_text" style="font-size:70%;">93.73</span></td>
<td id="S4.T1.3.5.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.5.3.1" class="ltx_text" style="font-size:70%;">92.40</span></td>
<td id="S4.T1.3.5.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.5.4.1" class="ltx_text" style="font-size:70%;">93.55</span></td>
<td id="S4.T1.3.5.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.5.5.1" class="ltx_text" style="font-size:70%;">92.87</span></td>
<td id="S4.T1.3.5.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.5.6.1" class="ltx_text" style="font-size:70%;">7.84</span></td>
<td id="S4.T1.3.5.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.5.7.1" class="ltx_text" style="font-size:70%;">7.35</span></td>
</tr>
<tr id="S4.T1.3.6" class="ltx_tr">
<td id="S4.T1.3.6.1" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.1.1" class="ltx_text" style="font-size:70%;">GFCC</span></td>
<td id="S4.T1.3.6.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.2.1" class="ltx_text" style="font-size:70%;">92.77</span></td>
<td id="S4.T1.3.6.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.3.1" class="ltx_text" style="font-size:70%;">91.43</span></td>
<td id="S4.T1.3.6.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.4.1" class="ltx_text" style="font-size:70%;">92.25</span></td>
<td id="S4.T1.3.6.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.5.1" class="ltx_text" style="font-size:70%;">91.75</span></td>
<td id="S4.T1.3.6.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.6.1" class="ltx_text" style="font-size:70%;">10.23</span></td>
<td id="S4.T1.3.6.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.6.7.1" class="ltx_text" style="font-size:70%;">6.66</span></td>
</tr>
<tr id="S4.T1.3.7" class="ltx_tr">
<td id="S4.T1.3.7.1" class="ltx_td ltx_align_center"><span id="S4.T1.3.7.1.1" class="ltx_text" style="font-size:70%;">PNCC</span></td>
<td id="S4.T1.3.7.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.7.2.1" class="ltx_text" style="font-size:70%;">92.56</span></td>
<td id="S4.T1.3.7.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.7.3.1" class="ltx_text" style="font-size:70%;">91.25</span></td>
<td id="S4.T1.3.7.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.7.4.1" class="ltx_text" style="font-size:70%;">91.96</span></td>
<td id="S4.T1.3.7.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.7.5.1" class="ltx_text" style="font-size:70%;">91.54</span></td>
<td id="S4.T1.3.7.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.7.6.1" class="ltx_text" style="font-size:70%;">10.16</span></td>
<td id="S4.T1.3.7.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.7.7.1" class="ltx_text" style="font-size:70%;">7.25</span></td>
</tr>
<tr id="S4.T1.3.8" class="ltx_tr">
<td id="S4.T1.3.8.1" class="ltx_td ltx_align_center"><span id="S4.T1.3.8.1.1" class="ltx_text" style="font-size:70%;">DEMON</span></td>
<td id="S4.T1.3.8.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.8.2.1" class="ltx_text" style="font-size:70%;">89.61</span></td>
<td id="S4.T1.3.8.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.8.3.1" class="ltx_text" style="font-size:70%;">85.46</span></td>
<td id="S4.T1.3.8.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.8.4.1" class="ltx_text" style="font-size:70%;">87.62</span></td>
<td id="S4.T1.3.8.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.8.5.1" class="ltx_text" style="font-size:70%;">86.29</span></td>
<td id="S4.T1.3.8.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.8.6.1" class="ltx_text" style="font-size:70%;">17.02</span></td>
<td id="S4.T1.3.8.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.8.7.1" class="ltx_text" style="font-size:70%;">11.92</span></td>
</tr>
<tr id="S4.T1.3.9" class="ltx_tr">
<td id="S4.T1.3.9.1" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.1.1" class="ltx_text" style="font-size:70%;">LOFAR</span></td>
<td id="S4.T1.3.9.2" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.2.1" class="ltx_text" style="font-size:70%;">87.22</span></td>
<td id="S4.T1.3.9.3" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.3.1" class="ltx_text" style="font-size:70%;">83.72</span></td>
<td id="S4.T1.3.9.4" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.4.1" class="ltx_text" style="font-size:70%;">86.89</span></td>
<td id="S4.T1.3.9.5" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.5.1" class="ltx_text" style="font-size:70%;">84.83</span></td>
<td id="S4.T1.3.9.6" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.6.1" class="ltx_text" style="font-size:70%;">20.99</span></td>
<td id="S4.T1.3.9.7" class="ltx_td ltx_align_center"><span id="S4.T1.3.9.7.1" class="ltx_text" style="font-size:70%;">11.58</span></td>
</tr>
<tr id="S4.T1.3.10" class="ltx_tr">
<td id="S4.T1.3.10.1" class="ltx_td ltx_align_center"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;"> </span></td>
<td id="S4.T1.3.10.2" class="ltx_td"></td>
<td id="S4.T1.3.10.3" class="ltx_td"></td>
<td id="S4.T1.3.10.4" class="ltx_td"></td>
<td id="S4.T1.3.10.5" class="ltx_td"></td>
<td id="S4.T1.3.10.6" class="ltx_td"></td>
<td id="S4.T1.3.10.7" class="ltx_td"></td>
</tr>
</table>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper, we introduced QiandaoEar22, an underwater acoustic multi-target dataset constructed through the experiment collection in Qiandao Lake in 2022 and executed an experimental task to identify specific ships from the multiple targets to demonstrate the use of the dataset. We set speedboat, KaiYuan, and UUV as the research object and extracted different features and deep learning networks for classification. The best recognition accuracy of UUV target is 97.78%, and we found using spectrum and MFCC as feature inputs and DenseNet as classifier can achieve excellent recognition performance. Our work established a benchmark for algorithm evaluation and may help the innovation development of UATD and UATR systems.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
D. Santos-Domínguez, S. Torres-Guijarro, A. Cardenal-López, and
A. Pena-Gimenez, “Shipsear: An underwater vessel noise database,”
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Applied Acoustics</em>, vol. 113, pp. 64–69, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
M. Irfan, Z. Jiangbin, S. Ali, M. Iqbal, Z. Masood, and U. Hamid, “Deepship:
An underwater acoustic benchmark dataset and a separable convolution based
autoencoder for classification,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em>,
vol. 183, p. 115270, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
D. Yu, J. Yang, Y. Zhang, and S. Yu, “Additive densenet: Dense connections
based on simple addition operations,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Journal of Intelligent &amp; Fuzzy
Systems</em>, vol. 40, no. 3, pp. 5015–5025, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.04352" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.04353" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.04353">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.04353" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.04354" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Jul  6 01:34:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
