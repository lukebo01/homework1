<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.12621] Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech</title><meta property="og:description" content="Direct dependency parsing of the speech signal –as opposed to parsing speech transcriptions– has recently been proposed as a task (Pupier et al., 2022), as a way of incorporating prosodic information in the parsing sys…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.12621">

<!--Generated on Sat Jul  6 00:11:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Growing Trees on Sounds: Assessing Strategies 
<br class="ltx_break">for End-to-End Dependency Parsing of Speech</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Adrien Pupier, Maximin Coavoux, Jérôme Goulian, Benjamin Lecouteux 
<br class="ltx_break">Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, 38000 Grenoble, France
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">first.last@univ-grenoble-alpes.fr</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Direct dependency parsing of the speech signal –as opposed to parsing speech transcriptions– has recently been proposed as a task <cite class="ltx_cite ltx_citemacro_citep">(Pupier et al., <a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite>, as a way of incorporating prosodic information in the parsing system and bypassing the limitations of a pipeline approach that would consist of using first an Automatic Speech Recognition (ASR) system and then a syntactic parser.
In this article, we report on a set of experiments aiming at assessing the performance of two parsing paradigms (graph-based parsing and sequence labeling based parsing) on speech parsing.
We perform this evaluation on a large treebank of spoken French, featuring
realistic spontaneous conversations.
Our findings show that (i) the graph-based approach obtain better results across the board (ii) parsing directly from speech outperforms a pipeline approach, despite having 30% fewer parameters.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.1" class="ltx_block ltx_align_bottom">
<p id="p1.1.1" class="ltx_p"><span id="p1.1.1.1" class="ltx_text ltx_font_bold">Growing Trees on Sounds: Assessing Strategies 
<br class="ltx_break">for End-to-End Dependency Parsing of Speech</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.1.2" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.1.2.1" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.1.1" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.1.2.1.1.1.1" class="ltx_tr">
<span id="p1.1.2.1.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Adrien Pupier, Maximin Coavoux, Jérôme Goulian, Benjamin Lecouteux</span></span></span>
<span id="p1.1.2.1.1.2.2" class="ltx_tr">
<span id="p1.1.2.1.1.2.2.1" class="ltx_td ltx_align_center">Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, 38000 Grenoble, France</span></span>
<span id="p1.1.2.1.1.3.3" class="ltx_tr">
<span id="p1.1.2.1.1.3.3.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.3.3.1.1" class="ltx_text ltx_font_typewriter">first.last@univ-grenoble-alpes.fr</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<figure id="S0.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S0.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.12621/assets/figures/speech_fig_trimmed.jpg" id="S0.F1.sf1.g1" class="ltx_graphics ltx_img_square" width="598" height="713" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>The two models based on audio features, blue arrow is <span id="S0.F1.sf1.3.1" class="ltx_text ltx_font_bold ltx_font_smallcaps" style="color:#0000FF;">audio</span>, red arrow is <span id="S0.F1.sf1.4.2" class="ltx_text ltx_font_bold ltx_font_smallcaps" style="color:#FF0000;">oracle</span>.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S0.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.12621/assets/figures/text_fig_trimmed.jpg" id="S0.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="598" height="730" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>The two baseline models based on a pretrained language model, blue arrow is <span id="S0.F1.sf2.3.1" class="ltx_text ltx_font_bold ltx_font_smallcaps" style="color:#0000FF;">pipeline</span> (predicted transcription), read arrow is <span id="S0.F1.sf2.4.2" class="ltx_text ltx_font_bold ltx_font_smallcaps" style="color:#FF0000;">text</span> (gold transcriptions).</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of architectures with the 4 settings described in Section <a href="#S4" title="4 Experiments ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Dependency parsing is a central task in natural language processing (NLP).
In the NLP community, it has mostly been addressed on textual data, either natively written texts or sometimes speech transcriptions.
Yet, speech is the main form of communication between humans, as well as arguably one of the most realistic types of linguistic data, which motivates the design of NLP systems able to deal directly with speech, both for applicative purposes and to construct corpora annotated with linguistic information.
When parsing speech <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">transcriptions</span>, most prior work has focused on disfluency detection and removal <cite class="ltx_cite ltx_citemacro_citep">(Charniak and Johnson, <a href="#bib.bib6" title="" class="ltx_ref">2001</a>; Johnson and Charniak, <a href="#bib.bib20" title="" class="ltx_ref">2004</a>; Rasooli and Tetreault, <a href="#bib.bib27" title="" class="ltx_ref">2013</a>; Honnibal and Johnson, <a href="#bib.bib16" title="" class="ltx_ref">2014</a>; Jamshid Lou et al., <a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite>, in an effort to ‘normalize’ the transcriptions and make them suitable input for NLP systems trained on written language.
Using only transcriptions as input is a natural choice from an NLP perspective: it makes it possible to use off-the-shelf NLP parsers ‘as is’.
However, predicted transcriptions can be very noisy, in particular for speech from spontaneous conversations. Furthermore, transcriptions are abstractions that contain much less information than the speech signal. The prosody, and the pauses in the speech utterances are very important clues for parsing <cite class="ltx_cite ltx_citemacro_citep">(Price et al., <a href="#bib.bib25" title="" class="ltx_ref">1991</a>)</cite> that are completely absent from transcriptions.
Hence, we address speech parsing using only the speech signal as input.
With the popularization of self-supervised method and modern neural network architecture (pretrained transformers), both speech and text domains now use similar techniques <cite class="ltx_cite ltx_citemacro_citep">(Chrupała, <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>.
This convergence of methodology has raised interest in other applications of speech models to go beyond ‘simple’ speech recognition.
Thus, addressing classical NLP tasks directly on speech is a natural step and design NLP tools able to deal with spontaneous speech, arguably the most realistic type of linguistic production. In short, Our contributions are the following:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">we introduce a graph-based end-to-end dependency parsing algorithm for speech;</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">we evaluate the parser on Orféo, a large treebank of spoken French that features spontaneous speech, and compare its performance to pipeline systems and to a parsing-as-tagging parser;</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">we release our code at <a target="_blank" href="https://github.com/Pupiera/Growing_tree_on_sound" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Pupiera/Growing_tree_on_sound</a>.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The code is also archived at <a target="_blank" href="https://doi.org/10.5281/zenodo.11474162" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.11474162</a>.</span></span></span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Parsers and pre-trained models</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We define speech parsing as the task of predicting a dependency tree from an audio signal corresponding to a spoken utterance.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>For the sake of simplicity, we will use the term ‘sentence’ in the rest of the article, even though the very definition of a sentence is debatable in the spoken domain.</span></span></span></p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Our parser is composed of 2 modules (Figure <a href="#S0.F1.sf1" title="In Figure 1 ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>): (i) an acoustic module that is used to predict transcriptions and a segmentation of the signal in words and (ii) a parsing module that uses the segmentation to construct audio word embeddings and predict trees.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Word level representations from speech</h3>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">To extract representations from the raw speech, we use a pre-trained wav2vec2 model trained on seven thousand hours of French speech: <span id="S2.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">LeBenchmark7K<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span id="footnote3.1.1.1" class="ltx_text ltx_font_serif">3</span></span><a target="_blank" href="https://huggingface.co/LeBenchmark/wav2vec2-FR-7K-large" title="" class="ltx_ref ltx_url">https://huggingface.co/LeBenchmark/wav2vec2-FR-7K-large</a></span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Parcollet et al. (<a href="#bib.bib24" title="" class="ltx_ref">2024</a>)</cite>.
Parsing requires word-level representations. We use the methodology of <cite class="ltx_cite ltx_citemacro_citet">Pupier et al. (<a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite> to construct audio word embeddings from the implicit frame level segmentation provided by the CTC speech recognition algorithm <cite class="ltx_cite ltx_citemacro_cite">Graves et al. (<a href="#bib.bib14" title="" class="ltx_ref">2006</a>)</cite>.
The method consists in combining the frame vectors corresponding to a single predicted word with an LSTM.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Graph-based parsing</h3>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">We use the audio word embeddings –whose construction is described above– as input to our implementation of a classical graph-based biaffine parser <cite class="ltx_cite ltx_citemacro_citep">(Dozat and Manning, <a href="#bib.bib11" title="" class="ltx_ref">2016</a>)</cite>: (i) compute a score every possible arc with a biaffine classifier and (ii) find the best scoring tree with a maximum spanning tree algorithm.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Sequence labeling</h3>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">The sequence labeling parser follows <cite class="ltx_cite ltx_citemacro_citet">Pupier et al. (<a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite> and is based on the <span id="S2.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">dep2label</span> approach <cite class="ltx_cite ltx_citemacro_cite">Gómez-Rodríguez et al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>); Strzyz et al. (<a href="#bib.bib30" title="" class="ltx_ref">2020</a>)</cite>, specifically
the <span id="S2.SS0.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_typewriter">relative POS-based encoding</span> <cite class="ltx_cite ltx_citemacro_cite">Strzyz et al. (<a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite>.
This method reduces the parsing problem to a sequence labeling problem.
The head of each token is encoded in a label of the form <math id="S2.SS0.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.1.m1.1a"><mo id="S2.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.1.m1.1b"><csymbol cd="latexml" id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.1.m1.1c">\pm</annotation></semantics></math>Integer@POS.
The integer stands for the relative position of the head considering only words of the POS category.
Eg., <span id="S2.SS0.SSS0.Px3.p1.1.3" class="ltx_text ltx_font_typewriter">-3@NOUN</span> means that the head of the current word is the third noun before it.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We use the CEFC-Orféo treebank <cite class="ltx_cite ltx_citemacro_cite">Benzitoun et al. (<a href="#bib.bib4" title="" class="ltx_ref">2016</a>)</cite>, a dependency-annotated French corpus composed of multiple subcorpora <cite class="ltx_cite ltx_citemacro_citep">(CLESTHIA, <a href="#bib.bib8" title="" class="ltx_ref">2018</a>; ICAR, <a href="#bib.bib18" title="" class="ltx_ref">2017</a>; ATILF, <a href="#bib.bib3" title="" class="ltx_ref">2020</a>; Mathieu et al., <a href="#bib.bib23" title="" class="ltx_ref">(2012-2020</a>; André, <a href="#bib.bib1" title="" class="ltx_ref">2016</a>; Carruthers, <a href="#bib.bib5" title="" class="ltx_ref">2013</a>; Cresti et al., <a href="#bib.bib9" title="" class="ltx_ref">2004</a>; DELIC et al., <a href="#bib.bib10" title="" class="ltx_ref">2004</a>; Francard et al., <a href="#bib.bib12" title="" class="ltx_ref">2009</a>; Kawaguchi et al., <a href="#bib.bib21" title="" class="ltx_ref">2006</a>; Husianycia, <a href="#bib.bib17" title="" class="ltx_ref">2011</a>)</cite>, and released with the audio recordings.
The treebank consists of various types of interactions, all of which feature spontaneous discussions, except for the French Oral Narrative corpus (audiobooks).
Orféo features many types of speech situations (eg. commercial interactions, interviews, informal discussions between friends) and is the largest French spoken corpus annotated in dependency syntax.
The annotation scheme has been designed specifically for Orféo <cite class="ltx_cite ltx_citemacro_cite">Benzitoun et al. (<a href="#bib.bib4" title="" class="ltx_ref">2016</a>)</cite> and differs from the Universal Dependency framework in many regards (in particular: its POS tagset is finer-grained, whereas the syntactic function tagset has only 14 relations).
The syntactic annotations of Orféo were done manually for 5% of the corpus and automatically for the rest of the corpus.
The train/dev/test split we use makes sure that the test section only contains gold annotations.
Nevertheless, the subcorpora with gold syntactic annotations correspond to low-quality recordings, which makes them a very challenging benchmark.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:162.8pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-48.2pt,18.0pt) scale(0.818020909336293,0.818020909336293) ;">
<table id="S4.T1.5.5" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.5.5.5" class="ltx_tr">
<td id="S4.T1.5.5.5.6" class="ltx_td ltx_align_left ltx_border_tt">Model</td>
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_right ltx_border_tt">WER<math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T1.2.2.2.2" class="ltx_td ltx_align_right ltx_border_tt">CER<math id="S4.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T1.2.2.2.2.m1.1.1" xref="S4.T1.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_right ltx_border_tt">POS<math id="S4.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T1.3.3.3.3.m1.1.1" xref="S4.T1.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.4.4.4.4" class="ltx_td ltx_align_right ltx_border_tt">UAS<math id="S4.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.4.4.4.4.m1.1a"><mo stretchy="false" id="S4.T1.4.4.4.4.m1.1.1" xref="S4.T1.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.m1.1b"><ci id="S4.T1.4.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.5.5.5.5" class="ltx_td ltx_align_right ltx_border_tt">LAS<math id="S4.T1.5.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.5.5.5.5.m1.1a"><mo stretchy="false" id="S4.T1.5.5.5.5.m1.1.1" xref="S4.T1.5.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.5.m1.1b"><ci id="S4.T1.5.5.5.5.m1.1.1.cmml" xref="S4.T1.5.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.5.5.5.7" class="ltx_td ltx_align_left ltx_border_tt">Parameters</td>
<td id="S4.T1.5.5.5.8" class="ltx_td ltx_align_left ltx_border_tt">Pre-training</td>
</tr>
<tr id="S4.T1.5.5.6.1" class="ltx_tr">
<td id="S4.T1.5.5.6.1.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T1.5.5.6.1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> <span id="S4.T1.5.5.6.1.1.2" class="ltx_text ltx_font_smallcaps">seq2label</span>
</td>
<td id="S4.T1.5.5.6.1.2" class="ltx_td ltx_align_right ltx_border_t">35.9</td>
<td id="S4.T1.5.5.6.1.3" class="ltx_td ltx_align_right ltx_border_t">22.3</td>
<td id="S4.T1.5.5.6.1.4" class="ltx_td ltx_align_right ltx_border_t">73.0</td>
<td id="S4.T1.5.5.6.1.5" class="ltx_td ltx_align_right ltx_border_t">65.7</td>
<td id="S4.T1.5.5.6.1.6" class="ltx_td ltx_align_right ltx_border_t">60.4</td>
<td id="S4.T1.5.5.6.1.7" class="ltx_td ltx_align_left ltx_border_t">315M + 34.9M</td>
<td id="S4.T1.5.5.6.1.8" class="ltx_td ltx_align_left ltx_border_t">Wav2vec2</td>
</tr>
<tr id="S4.T1.5.5.7.2" class="ltx_tr">
<td id="S4.T1.5.5.7.2.1" class="ltx_td ltx_align_left">
<span id="S4.T1.5.5.7.2.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> <span id="S4.T1.5.5.7.2.1.2" class="ltx_text ltx_font_smallcaps">graph</span>
</td>
<td id="S4.T1.5.5.7.2.2" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.7.2.2.1" class="ltx_text ltx_font_bold">35.6</span></td>
<td id="S4.T1.5.5.7.2.3" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.7.2.3.1" class="ltx_text ltx_font_bold">22.1</span></td>
<td id="S4.T1.5.5.7.2.4" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.7.2.4.1" class="ltx_text ltx_font_bold">73.1</span></td>
<td id="S4.T1.5.5.7.2.5" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.7.2.5.1" class="ltx_text ltx_font_bold">66.0</span></td>
<td id="S4.T1.5.5.7.2.6" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.7.2.6.1" class="ltx_text ltx_font_bold">60.9</span></td>
<td id="S4.T1.5.5.7.2.7" class="ltx_td ltx_align_left">315M + 34.9M</td>
<td id="S4.T1.5.5.7.2.8" class="ltx_td ltx_align_left">Wav2vec2</td>
</tr>
<tr id="S4.T1.5.5.8.3" class="ltx_tr">
<td id="S4.T1.5.5.8.3.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T1.5.5.8.3.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span> <span id="S4.T1.5.5.8.3.1.2" class="ltx_text ltx_font_smallcaps">seq2label</span>
</td>
<td id="S4.T1.5.5.8.3.2" class="ltx_td ltx_align_right ltx_border_t">36.3</td>
<td id="S4.T1.5.5.8.3.3" class="ltx_td ltx_align_right ltx_border_t">22.2</td>
<td id="S4.T1.5.5.8.3.4" class="ltx_td ltx_align_right ltx_border_t">75.6</td>
<td id="S4.T1.5.5.8.3.5" class="ltx_td ltx_align_right ltx_border_t">68.7</td>
<td id="S4.T1.5.5.8.3.6" class="ltx_td ltx_align_right ltx_border_t">62.7</td>
<td id="S4.T1.5.5.8.3.7" class="ltx_td ltx_align_left ltx_border_t">315M + 34.9M</td>
<td id="S4.T1.5.5.8.3.8" class="ltx_td ltx_align_left ltx_border_t">Wav2vec2</td>
</tr>
<tr id="S4.T1.5.5.9.4" class="ltx_tr">
<td id="S4.T1.5.5.9.4.1" class="ltx_td ltx_align_left">
<span id="S4.T1.5.5.9.4.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span> <span id="S4.T1.5.5.9.4.1.2" class="ltx_text ltx_font_smallcaps">graph</span>
</td>
<td id="S4.T1.5.5.9.4.2" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.9.4.2.1" class="ltx_text ltx_font_bold">35.6</span></td>
<td id="S4.T1.5.5.9.4.3" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.9.4.3.1" class="ltx_text ltx_font_bold">22.2</span></td>
<td id="S4.T1.5.5.9.4.4" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.9.4.4.1" class="ltx_text ltx_font_bold">77.4</span></td>
<td id="S4.T1.5.5.9.4.5" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.9.4.5.1" class="ltx_text ltx_font_bold">73.3</span></td>
<td id="S4.T1.5.5.9.4.6" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.9.4.6.1" class="ltx_text ltx_font_bold">67.5</span></td>
<td id="S4.T1.5.5.9.4.7" class="ltx_td ltx_align_left">315M + 34.9M</td>
<td id="S4.T1.5.5.9.4.8" class="ltx_td ltx_align_left">Wav2vec2</td>
</tr>
<tr id="S4.T1.5.5.10.5" class="ltx_tr">
<td id="S4.T1.5.5.10.5.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T1.5.5.10.5.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> <span id="S4.T1.5.5.10.5.1.2" class="ltx_text ltx_font_smallcaps">seq2label</span>
</td>
<td id="S4.T1.5.5.10.5.2" class="ltx_td ltx_align_right ltx_border_t">35.6</td>
<td id="S4.T1.5.5.10.5.3" class="ltx_td ltx_align_right ltx_border_t">22.0</td>
<td id="S4.T1.5.5.10.5.4" class="ltx_td ltx_align_right ltx_border_t">70.8</td>
<td id="S4.T1.5.5.10.5.5" class="ltx_td ltx_align_right ltx_border_t">63.8</td>
<td id="S4.T1.5.5.10.5.6" class="ltx_td ltx_align_right ltx_border_t">58.4</td>
<td id="S4.T1.5.5.10.5.7" class="ltx_td ltx_align_left ltx_border_t">314M + 110M + 39.2M</td>
<td id="S4.T1.5.5.10.5.8" class="ltx_td ltx_align_left ltx_border_t">Wav2vec2 + CamemBERT</td>
</tr>
<tr id="S4.T1.5.5.11.6" class="ltx_tr">
<td id="S4.T1.5.5.11.6.1" class="ltx_td ltx_align_left">
<span id="S4.T1.5.5.11.6.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> <span id="S4.T1.5.5.11.6.1.2" class="ltx_text ltx_font_smallcaps">graph</span>
</td>
<td id="S4.T1.5.5.11.6.2" class="ltx_td ltx_align_right">35.6</td>
<td id="S4.T1.5.5.11.6.3" class="ltx_td ltx_align_right">22.0</td>
<td id="S4.T1.5.5.11.6.4" class="ltx_td ltx_align_right">69.3</td>
<td id="S4.T1.5.5.11.6.5" class="ltx_td ltx_align_right">60.5</td>
<td id="S4.T1.5.5.11.6.6" class="ltx_td ltx_align_right">53.1</td>
<td id="S4.T1.5.5.11.6.7" class="ltx_td ltx_align_left">314M + 110M + 41.4M</td>
<td id="S4.T1.5.5.11.6.8" class="ltx_td ltx_align_left">Wav2vec2 + CamemBERT</td>
</tr>
<tr id="S4.T1.5.5.12.7" class="ltx_tr">
<td id="S4.T1.5.5.12.7.1" class="ltx_td ltx_align_left">
<span id="S4.T1.5.5.12.7.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> <span id="S4.T1.5.5.12.7.1.2" class="ltx_text ltx_font_smallcaps">hops</span>
</td>
<td id="S4.T1.5.5.12.7.2" class="ltx_td ltx_align_right">35.6</td>
<td id="S4.T1.5.5.12.7.3" class="ltx_td ltx_align_right">22.0</td>
<td id="S4.T1.5.5.12.7.4" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.12.7.4.1" class="ltx_text ltx_font_bold">72.4</span></td>
<td id="S4.T1.5.5.12.7.5" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.12.7.5.1" class="ltx_text ltx_font_bold">65.8</span></td>
<td id="S4.T1.5.5.12.7.6" class="ltx_td ltx_align_right"><span id="S4.T1.5.5.12.7.6.1" class="ltx_text ltx_font_bold">61.0</span></td>
<td id="S4.T1.5.5.12.7.7" class="ltx_td ltx_align_left">314M + 110M + 100M</td>
<td id="S4.T1.5.5.12.7.8" class="ltx_td ltx_align_left">Wav2vec2 + CamemBERT</td>
</tr>
<tr id="S4.T1.5.5.13.8" class="ltx_tr">
<td id="S4.T1.5.5.13.8.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T1.5.5.13.8.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> <span id="S4.T1.5.5.13.8.1.2" class="ltx_text ltx_font_smallcaps">seq2label</span>
</td>
<td id="S4.T1.5.5.13.8.2" class="ltx_td ltx_align_right ltx_border_t">0</td>
<td id="S4.T1.5.5.13.8.3" class="ltx_td ltx_align_right ltx_border_t">0</td>
<td id="S4.T1.5.5.13.8.4" class="ltx_td ltx_align_right ltx_border_t">96.9</td>
<td id="S4.T1.5.5.13.8.5" class="ltx_td ltx_align_right ltx_border_t">88.8</td>
<td id="S4.T1.5.5.13.8.6" class="ltx_td ltx_align_right ltx_border_t">85.7</td>
<td id="S4.T1.5.5.13.8.7" class="ltx_td ltx_align_left ltx_border_t">110M + 39.2M</td>
<td id="S4.T1.5.5.13.8.8" class="ltx_td ltx_align_left ltx_border_t">CamemBERT</td>
</tr>
<tr id="S4.T1.5.5.14.9" class="ltx_tr">
<td id="S4.T1.5.5.14.9.1" class="ltx_td ltx_align_left">
<span id="S4.T1.5.5.14.9.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> <span id="S4.T1.5.5.14.9.1.2" class="ltx_text ltx_font_smallcaps">graph</span>
</td>
<td id="S4.T1.5.5.14.9.2" class="ltx_td ltx_align_right">0</td>
<td id="S4.T1.5.5.14.9.3" class="ltx_td ltx_align_right">0</td>
<td id="S4.T1.5.5.14.9.4" class="ltx_td ltx_align_right">95.1</td>
<td id="S4.T1.5.5.14.9.5" class="ltx_td ltx_align_right">87.4</td>
<td id="S4.T1.5.5.14.9.6" class="ltx_td ltx_align_right">84.0</td>
<td id="S4.T1.5.5.14.9.7" class="ltx_td ltx_align_left">110M + 41.4M</td>
<td id="S4.T1.5.5.14.9.8" class="ltx_td ltx_align_left">CamemBERT</td>
</tr>
<tr id="S4.T1.5.5.15.10" class="ltx_tr">
<td id="S4.T1.5.5.15.10.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S4.T1.5.5.15.10.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> <span id="S4.T1.5.5.15.10.1.2" class="ltx_text ltx_font_smallcaps">hops</span>
</td>
<td id="S4.T1.5.5.15.10.2" class="ltx_td ltx_align_right ltx_border_bb">0</td>
<td id="S4.T1.5.5.15.10.3" class="ltx_td ltx_align_right ltx_border_bb">0</td>
<td id="S4.T1.5.5.15.10.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.5.5.15.10.4.1" class="ltx_text ltx_font_bold">98.2</span></td>
<td id="S4.T1.5.5.15.10.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.5.5.15.10.5.1" class="ltx_text ltx_font_bold">90.3</span></td>
<td id="S4.T1.5.5.15.10.6" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.5.5.15.10.6.1" class="ltx_text ltx_font_bold">87.7</span></td>
<td id="S4.T1.5.5.15.10.7" class="ltx_td ltx_align_left ltx_border_bb">110M + 100M</td>
<td id="S4.T1.5.5.15.10.8" class="ltx_td ltx_align_left ltx_border_bb">CamemBERT</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Evaluation on the full Orféo test set with the settings described in Section <a href="#S4" title="4 Experiments ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:162.8pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-48.2pt,18.0pt) scale(0.818020909336293,0.818020909336293) ;">
<table id="S4.T2.5.5" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.5.5.5" class="ltx_tr">
<td id="S4.T2.5.5.5.6" class="ltx_td ltx_align_left ltx_border_tt">Model</td>
<td id="S4.T2.1.1.1.1" class="ltx_td ltx_align_right ltx_border_tt">WER<math id="S4.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T2.2.2.2.2" class="ltx_td ltx_align_right ltx_border_tt">CER<math id="S4.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_right ltx_border_tt">POS<math id="S4.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T2.3.3.3.3.m1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><ci id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T2.4.4.4.4" class="ltx_td ltx_align_right ltx_border_tt">UAS<math id="S4.T2.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.4.4.4.4.m1.1a"><mo stretchy="false" id="S4.T2.4.4.4.4.m1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.m1.1b"><ci id="S4.T2.4.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T2.5.5.5.5" class="ltx_td ltx_align_right ltx_border_tt">LAS<math id="S4.T2.5.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.5.5.5.5.m1.1a"><mo stretchy="false" id="S4.T2.5.5.5.5.m1.1.1" xref="S4.T2.5.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.5.m1.1b"><ci id="S4.T2.5.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T2.5.5.5.7" class="ltx_td ltx_align_left ltx_border_tt">Parameters</td>
<td id="S4.T2.5.5.5.8" class="ltx_td ltx_align_left ltx_border_tt">Pre-training</td>
</tr>
<tr id="S4.T2.5.5.6.1" class="ltx_tr">
<td id="S4.T2.5.5.6.1.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T2.5.5.6.1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> <span id="S4.T2.5.5.6.1.1.2" class="ltx_text ltx_font_smallcaps">seq2label</span>
</td>
<td id="S4.T2.5.5.6.1.2" class="ltx_td ltx_align_right ltx_border_t">31.0</td>
<td id="S4.T2.5.5.6.1.3" class="ltx_td ltx_align_right ltx_border_t">18.4</td>
<td id="S4.T2.5.5.6.1.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T2.5.5.6.1.4.1" class="ltx_text ltx_font_bold">77.1</span></td>
<td id="S4.T2.5.5.6.1.5" class="ltx_td ltx_align_right ltx_border_t">70.2</td>
<td id="S4.T2.5.5.6.1.6" class="ltx_td ltx_align_right ltx_border_t">65.2</td>
<td id="S4.T2.5.5.6.1.7" class="ltx_td ltx_align_left ltx_border_t">315M + 34.9M</td>
<td id="S4.T2.5.5.6.1.8" class="ltx_td ltx_align_left ltx_border_t">Wav2vec2</td>
</tr>
<tr id="S4.T2.5.5.7.2" class="ltx_tr">
<td id="S4.T2.5.5.7.2.1" class="ltx_td ltx_align_left">
<span id="S4.T2.5.5.7.2.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> <span id="S4.T2.5.5.7.2.1.2" class="ltx_text ltx_font_smallcaps">graph</span>
</td>
<td id="S4.T2.5.5.7.2.2" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.7.2.2.1" class="ltx_text ltx_font_bold">30.6</span></td>
<td id="S4.T2.5.5.7.2.3" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.7.2.3.1" class="ltx_text ltx_font_bold">18.2</span></td>
<td id="S4.T2.5.5.7.2.4" class="ltx_td ltx_align_right">77.0</td>
<td id="S4.T2.5.5.7.2.5" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.7.2.5.1" class="ltx_text ltx_font_bold">70.9</span></td>
<td id="S4.T2.5.5.7.2.6" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.7.2.6.1" class="ltx_text ltx_font_bold">66.2</span></td>
<td id="S4.T2.5.5.7.2.7" class="ltx_td ltx_align_left">315M + 34.9M</td>
<td id="S4.T2.5.5.7.2.8" class="ltx_td ltx_align_left">Wav2vec2</td>
</tr>
<tr id="S4.T2.5.5.8.3" class="ltx_tr">
<td id="S4.T2.5.5.8.3.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T2.5.5.8.3.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span> <span id="S4.T2.5.5.8.3.1.2" class="ltx_text ltx_font_smallcaps">seq2label</span>
</td>
<td id="S4.T2.5.5.8.3.2" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T2.5.5.8.3.2.1" class="ltx_text ltx_font_bold">30.9</span></td>
<td id="S4.T2.5.5.8.3.3" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T2.5.5.8.3.3.1" class="ltx_text ltx_font_bold">18.6</span></td>
<td id="S4.T2.5.5.8.3.4" class="ltx_td ltx_align_right ltx_border_t">78.3</td>
<td id="S4.T2.5.5.8.3.5" class="ltx_td ltx_align_right ltx_border_t">71.9</td>
<td id="S4.T2.5.5.8.3.6" class="ltx_td ltx_align_right ltx_border_t">66.2</td>
<td id="S4.T2.5.5.8.3.7" class="ltx_td ltx_align_left ltx_border_t">315M + 34.9M</td>
<td id="S4.T2.5.5.8.3.8" class="ltx_td ltx_align_left ltx_border_t">Wav2vec2</td>
</tr>
<tr id="S4.T2.5.5.9.4" class="ltx_tr">
<td id="S4.T2.5.5.9.4.1" class="ltx_td ltx_align_left">
<span id="S4.T2.5.5.9.4.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span> <span id="S4.T2.5.5.9.4.1.2" class="ltx_text ltx_font_smallcaps">graph</span>
</td>
<td id="S4.T2.5.5.9.4.2" class="ltx_td ltx_align_right">31.4</td>
<td id="S4.T2.5.5.9.4.3" class="ltx_td ltx_align_right">19.2</td>
<td id="S4.T2.5.5.9.4.4" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.9.4.4.1" class="ltx_text ltx_font_bold">79.8</span></td>
<td id="S4.T2.5.5.9.4.5" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.9.4.5.1" class="ltx_text ltx_font_bold">76.0</span></td>
<td id="S4.T2.5.5.9.4.6" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.9.4.6.1" class="ltx_text ltx_font_bold">70.4</span></td>
<td id="S4.T2.5.5.9.4.7" class="ltx_td ltx_align_left">315M + 34.9M</td>
<td id="S4.T2.5.5.9.4.8" class="ltx_td ltx_align_left">Wav2vec2</td>
</tr>
<tr id="S4.T2.5.5.10.5" class="ltx_tr">
<td id="S4.T2.5.5.10.5.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T2.5.5.10.5.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> <span id="S4.T2.5.5.10.5.1.2" class="ltx_text ltx_font_smallcaps">seq2label</span>
</td>
<td id="S4.T2.5.5.10.5.2" class="ltx_td ltx_align_right ltx_border_t">30.5</td>
<td id="S4.T2.5.5.10.5.3" class="ltx_td ltx_align_right ltx_border_t">18.2</td>
<td id="S4.T2.5.5.10.5.4" class="ltx_td ltx_align_right ltx_border_t">74.7</td>
<td id="S4.T2.5.5.10.5.5" class="ltx_td ltx_align_right ltx_border_t">67.7</td>
<td id="S4.T2.5.5.10.5.6" class="ltx_td ltx_align_right ltx_border_t">62.4</td>
<td id="S4.T2.5.5.10.5.7" class="ltx_td ltx_align_left ltx_border_t">314M + 110M + 39.2M</td>
<td id="S4.T2.5.5.10.5.8" class="ltx_td ltx_align_left ltx_border_t">Wav2vec2 + CamemBERT</td>
</tr>
<tr id="S4.T2.5.5.11.6" class="ltx_tr">
<td id="S4.T2.5.5.11.6.1" class="ltx_td ltx_align_left">
<span id="S4.T2.5.5.11.6.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> <span id="S4.T2.5.5.11.6.1.2" class="ltx_text ltx_font_smallcaps">graph</span>
</td>
<td id="S4.T2.5.5.11.6.2" class="ltx_td ltx_align_right">30.5</td>
<td id="S4.T2.5.5.11.6.3" class="ltx_td ltx_align_right">18.2</td>
<td id="S4.T2.5.5.11.6.4" class="ltx_td ltx_align_right">73.5</td>
<td id="S4.T2.5.5.11.6.5" class="ltx_td ltx_align_right">64.2</td>
<td id="S4.T2.5.5.11.6.6" class="ltx_td ltx_align_right">57.3</td>
<td id="S4.T2.5.5.11.6.7" class="ltx_td ltx_align_left">314M + 110M + 41.4M</td>
<td id="S4.T2.5.5.11.6.8" class="ltx_td ltx_align_left">Wav2vec2 + CamemBERT</td>
</tr>
<tr id="S4.T2.5.5.12.7" class="ltx_tr">
<td id="S4.T2.5.5.12.7.1" class="ltx_td ltx_align_left">
<span id="S4.T2.5.5.12.7.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> <span id="S4.T2.5.5.12.7.1.2" class="ltx_text ltx_font_smallcaps">hops</span>
</td>
<td id="S4.T2.5.5.12.7.2" class="ltx_td ltx_align_right">30.5</td>
<td id="S4.T2.5.5.12.7.3" class="ltx_td ltx_align_right">18.2</td>
<td id="S4.T2.5.5.12.7.4" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.12.7.4.1" class="ltx_text ltx_font_bold">76.3</span></td>
<td id="S4.T2.5.5.12.7.5" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.12.7.5.1" class="ltx_text ltx_font_bold">69.4</span></td>
<td id="S4.T2.5.5.12.7.6" class="ltx_td ltx_align_right"><span id="S4.T2.5.5.12.7.6.1" class="ltx_text ltx_font_bold">64.6</span></td>
<td id="S4.T2.5.5.12.7.7" class="ltx_td ltx_align_left">314M + 110M + 100M</td>
<td id="S4.T2.5.5.12.7.8" class="ltx_td ltx_align_left">Wav2vec2 + CamemBERT</td>
</tr>
<tr id="S4.T2.5.5.13.8" class="ltx_tr">
<td id="S4.T2.5.5.13.8.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T2.5.5.13.8.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> <span id="S4.T2.5.5.13.8.1.2" class="ltx_text ltx_font_smallcaps">seq2label</span>
</td>
<td id="S4.T2.5.5.13.8.2" class="ltx_td ltx_align_right ltx_border_t">0</td>
<td id="S4.T2.5.5.13.8.3" class="ltx_td ltx_align_right ltx_border_t">0</td>
<td id="S4.T2.5.5.13.8.4" class="ltx_td ltx_align_right ltx_border_t">94.5</td>
<td id="S4.T2.5.5.13.8.5" class="ltx_td ltx_align_right ltx_border_t">86.7</td>
<td id="S4.T2.5.5.13.8.6" class="ltx_td ltx_align_right ltx_border_t">83.1</td>
<td id="S4.T2.5.5.13.8.7" class="ltx_td ltx_align_left ltx_border_t">110M + 39.2M</td>
<td id="S4.T2.5.5.13.8.8" class="ltx_td ltx_align_left ltx_border_t">CamemBERT</td>
</tr>
<tr id="S4.T2.5.5.14.9" class="ltx_tr">
<td id="S4.T2.5.5.14.9.1" class="ltx_td ltx_align_left">
<span id="S4.T2.5.5.14.9.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> <span id="S4.T2.5.5.14.9.1.2" class="ltx_text ltx_font_smallcaps">graph</span>
</td>
<td id="S4.T2.5.5.14.9.2" class="ltx_td ltx_align_right">0</td>
<td id="S4.T2.5.5.14.9.3" class="ltx_td ltx_align_right">0</td>
<td id="S4.T2.5.5.14.9.4" class="ltx_td ltx_align_right">96.8</td>
<td id="S4.T2.5.5.14.9.5" class="ltx_td ltx_align_right">88.3</td>
<td id="S4.T2.5.5.14.9.6" class="ltx_td ltx_align_right">84.5</td>
<td id="S4.T2.5.5.14.9.7" class="ltx_td ltx_align_left">110M + 41.4M</td>
<td id="S4.T2.5.5.14.9.8" class="ltx_td ltx_align_left">CamemBERT</td>
</tr>
<tr id="S4.T2.5.5.15.10" class="ltx_tr">
<td id="S4.T2.5.5.15.10.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S4.T2.5.5.15.10.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> <span id="S4.T2.5.5.15.10.1.2" class="ltx_text ltx_font_smallcaps">hops</span>
</td>
<td id="S4.T2.5.5.15.10.2" class="ltx_td ltx_align_right ltx_border_bb">0</td>
<td id="S4.T2.5.5.15.10.3" class="ltx_td ltx_align_right ltx_border_bb">0</td>
<td id="S4.T2.5.5.15.10.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T2.5.5.15.10.4.1" class="ltx_text ltx_font_bold">98.2</span></td>
<td id="S4.T2.5.5.15.10.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T2.5.5.15.10.5.1" class="ltx_text ltx_font_bold">90.3</span></td>
<td id="S4.T2.5.5.15.10.6" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T2.5.5.15.10.6.1" class="ltx_text ltx_font_bold">87.1</span></td>
<td id="S4.T2.5.5.15.10.7" class="ltx_td ltx_align_left ltx_border_bb">110M + 100M</td>
<td id="S4.T2.5.5.15.10.8" class="ltx_td ltx_align_left ltx_border_bb">CamemBERT</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Evaluation on the Valibel corpus (a subset of the test set).</figcaption>
</figure>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Experimental settings</h3>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">Our experiments aim at: (i) comparing our graph-based parser to the seq2label model,
(ii) comparing to pipeline approaches with text-based parsers, and
(iii) assessing the robustness of word representations with control experiments: using word boundaries (provided in the corpus) as input for the audio models and gold transcriptions for the text-based model. We compare the following settings (illustrated in Figure <a href="#S0.F1" title="Figure 1 ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>):</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span>: Access to <span id="S4.I1.i1.p1.1.2" class="ltx_text ltx_font_bold">raw audio</span> only, the model creates word-level representation from the acoustic model as described in Section <a href="#S2" title="2 Parsers and pre-trained models ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span>: Access to <span id="S4.I1.i2.p1.1.2" class="ltx_text ltx_font_bold">raw audio</span> and <span id="S4.I1.i2.p1.1.3" class="ltx_text ltx_font_bold">silver<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_medium">4</span></span><span id="footnote4.5" class="ltx_text ltx_font_medium">The corpus contained word-level timestamps that have been automatically constructed through forced alignment.</span></span></span></span></span> <span id="S4.I1.i2.p1.1.4" class="ltx_text ltx_font_bold">word-level timestamps</span>, making it easier to create word representations and mitigating the impact of the quality of the speech recognition on parsing.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span>: Access to <span id="S4.I1.i3.p1.1.2" class="ltx_text ltx_font_bold">predicted transcriptions</span> from the acoustic model only, then a language model uses the transcriptions as input for parsing.
The training trees are modified to take into account any deletion and insertion of words.
However, as for the speech approach, deletion or insertion penalizes the global score of the model since the model is evaluated against the gold transcriptions and not the modified one.
The drawback of this approach is that no information about prosody or pauses is available.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span>: Access to <span id="S4.I1.i4.p1.1.2" class="ltx_text ltx_font_bold">gold transcriptions</span>: this unrealistic setting provides an upper bound performance in the ideal case (perfect ASR).</p>
</div>
</li>
</ul>
<p id="S4.SS0.SSS0.Px1.p1.2" class="ltx_p">Both <span id="S4.SS0.SSS0.Px1.p1.2.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> and <span id="S4.SS0.SSS0.Px1.p1.2.2" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> settings use a French BERT model: <span id="S4.SS0.SSS0.Px1.p1.2.3" class="ltx_text ltx_font_typewriter">camembert-base<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span id="footnote5.1.1.1" class="ltx_text ltx_font_serif">5</span></span><a target="_blank" href="https://huggingface.co/almanach/camembert-base" title="" class="ltx_ref ltx_url">https://huggingface.co/almanach/camembert-base</a></span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Martin et al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite> to extract contextualized word embeddings.
For <span id="S4.SS0.SSS0.Px1.p1.2.4" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> and <span id="S4.SS0.SSS0.Px1.p1.2.5" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> settings, on top of our implementations, we use <span id="S4.SS0.SSS0.Px1.p1.2.6" class="ltx_text ltx_font_typewriter">hops</span> <cite class="ltx_cite ltx_citemacro_cite">Grobol and Crabbé (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>, an external state-of-the-art graph-based parser. The <span id="S4.SS0.SSS0.Px1.p1.2.7" class="ltx_text ltx_font_typewriter">hops</span> parser uses a character-bi-LSTM in addition to BERT to produce word embeddings, whereas our implementation does not (in an effort to make both versions of our parser, text-based and audio-based, as similar as possible).</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.5" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:92pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(47.1pt,-10.0pt) scale(1.27759502976559,1.27759502976559) ;">
<table id="S4.T3.5.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.5.5.5" class="ltx_tr">
<th id="S4.T3.5.5.5.6" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">WER<math id="S4.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T3.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">CER<math id="S4.T3.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T3.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T3.3.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">POS<math id="S4.T3.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T3.3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.m1.1b"><ci id="S4.T3.3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S4.T3.4.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">UAS<math id="S4.T3.4.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.4.4.4.4.m1.1a"><mo stretchy="false" id="S4.T3.4.4.4.4.m1.1.1" xref="S4.T3.4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.4.m1.1b"><ci id="S4.T3.4.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S4.T3.5.5.5.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">LAS<math id="S4.T3.5.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.5.5.5.5.m1.1a"><mo stretchy="false" id="S4.T3.5.5.5.5.m1.1.1" xref="S4.T3.5.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.5.m1.1b"><ci id="S4.T3.5.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.5.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S4.T3.5.5.5.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Parameters</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.5.5.6.1" class="ltx_tr">
<th id="S4.T3.5.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Graph-tiny</th>
<td id="S4.T3.5.5.6.1.2" class="ltx_td ltx_align_left ltx_border_t">35.74</td>
<td id="S4.T3.5.5.6.1.3" class="ltx_td ltx_align_left ltx_border_t">22.32</td>
<td id="S4.T3.5.5.6.1.4" class="ltx_td ltx_align_left ltx_border_t">72.97</td>
<td id="S4.T3.5.5.6.1.5" class="ltx_td ltx_align_left ltx_border_t">65.86</td>
<td id="S4.T3.5.5.6.1.6" class="ltx_td ltx_align_left ltx_border_t">60.79</td>
<td id="S4.T3.5.5.6.1.7" class="ltx_td ltx_align_left ltx_border_t">314M + 11.7M</td>
</tr>
<tr id="S4.T3.5.5.7.2" class="ltx_tr">
<th id="S4.T3.5.5.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Graph-base</th>
<td id="S4.T3.5.5.7.2.2" class="ltx_td ltx_align_left">35.63</td>
<td id="S4.T3.5.5.7.2.3" class="ltx_td ltx_align_left">22.10</td>
<td id="S4.T3.5.5.7.2.4" class="ltx_td ltx_align_left">73.13</td>
<td id="S4.T3.5.5.7.2.5" class="ltx_td ltx_align_left">66.05</td>
<td id="S4.T3.5.5.7.2.6" class="ltx_td ltx_align_left">60.90</td>
<td id="S4.T3.5.5.7.2.7" class="ltx_td ltx_align_left">314M + 34.9M</td>
</tr>
<tr id="S4.T3.5.5.8.3" class="ltx_tr">
<th id="S4.T3.5.5.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Graph-large</th>
<td id="S4.T3.5.5.8.3.2" class="ltx_td ltx_align_left ltx_border_bb">35.60</td>
<td id="S4.T3.5.5.8.3.3" class="ltx_td ltx_align_left ltx_border_bb">22.02</td>
<td id="S4.T3.5.5.8.3.4" class="ltx_td ltx_align_left ltx_border_bb">73.17</td>
<td id="S4.T3.5.5.8.3.5" class="ltx_td ltx_align_left ltx_border_bb">65.96</td>
<td id="S4.T3.5.5.8.3.6" class="ltx_td ltx_align_left ltx_border_bb">60.67</td>
<td id="S4.T3.5.5.8.3.7" class="ltx_td ltx_align_left ltx_border_bb">314M + 67.6M</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of parsing metrics with the graph-based architecture and different number of parameters.</figcaption>
</figure>
<div id="S4.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p2.1" class="ltx_p">Each parsing method for each modality is trained with the same number of epochs, the same hyperparameters (see Table <a href="#A1.T4" title="Table 4 ‣ Appendix A Training Details ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#A1.T5" title="Table 5 ‣ Appendix A Training Details ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> of Appendix <a href="#A1" title="Appendix A Training Details ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>), and approximately the same number of parameters.
We select the best checkpoint on the development set in each setting for the final evaluation.
Our implementations use speechbrain <cite class="ltx_cite ltx_citemacro_cite">Ravanelli et al. (<a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Metrics</h3>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">We use classical evaluation measures: <span id="S4.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Word Error Rate</span> (<span id="S4.SS0.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_typewriter">WER</span>) and <span id="S4.SS0.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_italic">Character Error Rate</span> (<span id="S4.SS0.SSS0.Px2.p1.1.4" class="ltx_text ltx_font_typewriter">CER</span>) for speech recognition, <span id="S4.SS0.SSS0.Px2.p1.1.5" class="ltx_text ltx_font_italic">POS accuracy</span> (<span id="S4.SS0.SSS0.Px2.p1.1.6" class="ltx_text ltx_font_typewriter">POS</span>), <span id="S4.SS0.SSS0.Px2.p1.1.7" class="ltx_text ltx_font_italic">Unlabeled Attachment Score</span> (<span id="S4.SS0.SSS0.Px2.p1.1.8" class="ltx_text ltx_font_typewriter">UAS</span>), and <span id="S4.SS0.SSS0.Px2.p1.1.9" class="ltx_text ltx_font_italic">Labeled Attachment Score</span> (<span id="S4.SS0.SSS0.Px2.p1.1.10" class="ltx_text ltx_font_typewriter">LAS</span>) for dependency parsing.</p>
</div>
<div id="S4.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p2.1" class="ltx_p">We report results in Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for the full corpus, and in Table <a href="#S4.T2" title="Table 2 ‣ 4 Experiments ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> for a sub-corpus of the test set (Valibel) for which speech recognition is easier.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px3" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Evaluation</h3>

<div id="S4.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p1.1" class="ltx_p">To evaluate our architecture, we use a modified version of the evaluation script provided by the CoNLL 2018 Shared Task.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://universaldependencies.org/conll18/evaluation.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://universaldependencies.org/conll18/evaluation.html</a></span></span></span>
The main limitation of this evaluation protocol is that it requires the two sequences to be exactly the same, which is not the case when speech recognition is involved.
Thus, we modify this evaluation script to work even when the two sequences to evaluate are not of the same length.
However, the modified script requires an alignement between the 2 sequences.
For our purpose, we use an alignment based on edit distance, i.e. the same alignment strategy already used to compute WER.</p>
</div>
<div id="S4.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p2.1" class="ltx_p">The modified script work by following this simple set of rules, depending on the edit operations:</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p">for word deletions: the predicted sequence is shorter, thus add a dummy token in the output sequence at the correct index to realign the sequences;</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">for word additions: the predicted sequence is longer, thus add a dummy token in the gold sequence at the correct index to realign the sequence;</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p">for word substitutions: do nothing;</p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p id="S4.I2.i4.p1.1" class="ltx_p">The syntactic information of the inserted token must differ from that of the corresponding word in the other sequence. Thus every insertion and deletion are considered parsing errors.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS0.SSS0.Px4" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Results: Speech recognition effect on parsing quality</h3>

<div id="S4.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px4.p1.1" class="ltx_p">In Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we observe that both graph-based and seq2label-based approaches give similar results when using no additional information, which shows that the limiting factor of the model is the speech recognition, rather than the parsing.</p>
</div>
<div id="S4.SS0.SSS0.Px4.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px4.p2.1" class="ltx_p">It is important to note that due to the nature of the speech corpus (spontaneous discussions), the <span id="S4.SS0.SSS0.Px4.p2.1.1" class="ltx_text ltx_font_typewriter">WER</span> is higher than what is typically expected on ASR benchmarks (usually containing ‘read’ speech).
As a matter of fact, the ASR module used in our model reaches around 8 <span id="S4.SS0.SSS0.Px4.p2.1.2" class="ltx_text ltx_font_typewriter">WER</span> when trained and evaluated on CommonVoice5.1 <cite class="ltx_cite ltx_citemacro_cite">Ardila et al. (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S4.SS0.SSS0.Px4.p3" class="ltx_para">
<p id="S4.SS0.SSS0.Px4.p3.1" class="ltx_p">Further evidence of the limitation caused by the speech recognition module is shown in Table <a href="#S4.T3" title="Table 3 ‣ Experimental settings ‣ 4 Experiments ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>: changing the number of parameters of the graph-based parser does not significantly alter performance.
Additionally, in Table <a href="#S4.T2" title="Table 2 ‣ 4 Experiments ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we observe a clear improvement in all the parsing metrics when evaluating on a test corpus with better speech recognition performance.
The model’s speech recognition ability directly affects the number of predicted tokens (some words may be deleted or added), which in turn impacts parsing.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px5" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Results: Difference between sequence labeling approach and graph-based approach</h3>

<div id="S4.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px5.p1.1" class="ltx_p">It is somewhat surprising that on the text modality (<span id="S4.SS0.SSS0.Px5.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span>), the sequence labeling parser outperforms the graph-based approach, since this is not the case on the other modality (<span id="S4.SS0.SSS0.Px5.p1.1.2" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span>).
However, it does not outperform a larger graph-based model with an additional character-bi-LSTM such as <span id="S4.SS0.SSS0.Px5.p1.1.3" class="ltx_text ltx_font_typewriter">hops</span>. The character bi-LSTM may mitigate the impact of out-of-vocabulary words produced by misspelling errors from the ASR.</p>
</div>
<div id="S4.SS0.SSS0.Px5.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px5.p2.1" class="ltx_p">A hypothesis about the graph-based model performance on <span id="S4.SS0.SSS0.Px5.p2.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> and the <span id="S4.SS0.SSS0.Px5.p2.1.2" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span> settings may be that it is able to extract more relevant syntactic information from the signal due to its global decoding than simpler approaches such as sequence labeling.</p>
</div>
<div id="S4.SS0.SSS0.Px5.p3" class="ltx_para">
<p id="S4.SS0.SSS0.Px5.p3.1" class="ltx_p">The largest gap between the two parsing approaches occur when more information about speech segmentation is given to the models (<span id="S4.SS0.SSS0.Px5.p3.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span>), reducing the overall influence of the speech recognition task on parsing.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px6" class="ltx_paragraph">
<h3 class="ltx_title ltx_title_paragraph">Transcribe then parse or directly parse ?</h3>

<div id="S4.SS0.SSS0.Px6.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px6.p1.1" class="ltx_p">The <span id="S4.SS0.SSS0.Px6.p1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> approach with <span id="S4.SS0.SSS0.Px6.p1.1.2" class="ltx_text ltx_font_typewriter">hops</span> does reach a similar performance as the <span id="S4.SS0.SSS0.Px6.p1.1.3" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> model with our graph-based parser.
However, <span id="S4.SS0.SSS0.Px6.p1.1.4" class="ltx_text ltx_font_typewriter">hops</span> is a more complex model not fully comparable to our graph-based parser. Moreover, it has 50% as many parameters as the model working directly on audio, requires 2 pretrained models, and is thus more expensive to train.</p>
</div>
<div id="S4.SS0.SSS0.Px6.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px6.p2.1" class="ltx_p">Lastly, Table <a href="#S4.T2" title="Table 2 ‣ 4 Experiments ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that the <span id="S4.SS0.SSS0.Px6.p2.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> approach outperforms the <span id="S4.SS0.SSS0.Px6.p2.1.2" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> approach when the quality of the speech recognition improves.
This result suggests that parsing benefits from <span id="S4.SS0.SSS0.Px6.p2.1.3" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> as soon as ASR reaches reasonable quality.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We introduced a graph-based speech parser that takes only the raw audio signal as input and assessed its performance in various settings and in several control experiments.
We show that a simple graph-based approach with wav2vec2 audio features is on a par with or outmatches a more complex pipeline approach that requires two pretrained models.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">From control experiments (<span id="S5.p2.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span>), we show that acquiring good quality word representations directly from speech is the main challenge for speech parsing.
We will focus future work on improving the quality of word segmentation on the speech signal.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We only evaluate our parsers on French, due to the availability of a large treebank, hence our conclusions should be interpreted with this restricted scope.
We plan to extend to other languages and treebanks in future work.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">We did not do a full grid search for hyperparameter tuning, due to computational resource limitations and environmental considerations, although we dedicated approximately the same computation budget to each model in a dedicated setting.
However, we acknowledge that not doing a full hyperparameter search may have affected the final performance of the parsers.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">This work is part of the PROPICTO project (French
acronym standing for PRojection du langage
Oral vers des unités PICTOgraphiques), funded by the Swiss National Science Foundation (N°197864) and the French National Research Agency (ANR-20-CE93-0005).
MC gratefully acknowledges the support of the French National Research Agency (grant ANR-23-CE23-0017-01).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">André (2016)</span>
<span class="ltx_bibblock">
Virginie André. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://fleuron.atilf.fr/index.php?lg=fr" title="" class="ltx_ref ltx_href">Fleuron: Français
langue Étrangère universitaire–ressources et outils numériques</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ardila et al. (2020)</span>
<span class="ltx_bibblock">
Rosana Ardila, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael
Henretty, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber.
2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2020.lrec-1.520" title="" class="ltx_ref ltx_href">Common voice: A
massively-multilingual speech corpus</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation
Conference</em>, pages 4218–4222, Marseille, France. European Language Resources
Association.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ATILF (2020)</span>
<span class="ltx_bibblock">
ATILF. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://hdl.handle.net/11403/tcof/v2.1" title="" class="ltx_ref ltx_href">Tcof : Traitement de
corpus oraux en français</a>.

</span>
<span class="ltx_bibblock">ORTOLANG (Open Resources and TOols for LANGuage)
–www.ortolang.fr.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benzitoun et al. (2016)</span>
<span class="ltx_bibblock">
Christophe Benzitoun, Jeanne-Marie Debaisieux, and Henri-José Deulofeu.
2016.

</span>
<span class="ltx_bibblock">Le projet orféo: un corpus d’étude pour le français
contemporain.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Corpus</em>, (15).

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carruthers (2013)</span>
<span class="ltx_bibblock">
Janice Carruthers. 2013.

</span>
<span class="ltx_bibblock">French oral narrative corpus.

</span>
<span class="ltx_bibblock">Commissioning Body / Publisher: Oxford Text Archive.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Charniak and Johnson (2001)</span>
<span class="ltx_bibblock">
Eugene Charniak and Mark Johnson. 2001.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/N01-1016" title="" class="ltx_ref ltx_href">Edit detection and parsing
for transcribed speech</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Second Meeting of the North American Chapter of the
Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chrupała (2023)</span>
<span class="ltx_bibblock">
Grzegorz Chrupała. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-acl.495" title="" class="ltx_ref ltx_href">Putting
natural in natural language processing</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
ACL 2023</em>, pages 7820–7827, Toronto, Canada. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">CLESTHIA (2018)</span>
<span class="ltx_bibblock">
CLESTHIA. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://hdl.handle.net/11403/cfpp2000/v1" title="" class="ltx_ref ltx_href">Cfpp2000</a>.

</span>
<span class="ltx_bibblock">ORTOLANG (Open Resources and TOols for LANGuage)
–www.ortolang.fr.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cresti et al. (2004)</span>
<span class="ltx_bibblock">
Emanuela Cresti, Fernanda Bacelar do Nascimento, Antonio Moreno Sandoval, Jean
Veronis, Philippe Martin, and Khalid Choukri. 2004.

</span>
<span class="ltx_bibblock">The c-oral-rom corpus. a multilingual resource of spontaneous speech
for romance languages.

</span>
<span class="ltx_bibblock">pages 26–28.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DELIC et al. (2004)</span>
<span class="ltx_bibblock">
Equipe DELIC, Sandra Teston-Bonnard, and Jean Véronis. 2004.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://halshs.archives-ouvertes.fr/halshs-01388193" title="" class="ltx_ref ltx_href">Présentation du corpus de référence du français parlé</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Recherches sur le français parlé</em>, 18:11–42.

</span>
<span class="ltx_bibblock">Equipe DELIC.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dozat and Manning (2016)</span>
<span class="ltx_bibblock">
Timothy Dozat and Christopher D Manning. 2016.

</span>
<span class="ltx_bibblock">Deep biaffine attention for neural dependency parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Francard et al. (2009)</span>
<span class="ltx_bibblock">
Michel Francard, Philippe Hambye, Anne-Catherine Simon, and Anne Dister. 2009.

</span>
<span class="ltx_bibblock">Du corpus à la banque de données.: Du son, des textes et des
métadonnées. l’évolution de banque de données textuelles
orales valibel (1989-2009).

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Cahiers de l’Institut de linguistique de Louvain-CILL</em>,
33(2):113.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gómez-Rodríguez et al. (2020)</span>
<span class="ltx_bibblock">
Carlos Gómez-Rodríguez, Michalina Strzyz, and David Vilares. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.coling-main.336" title="" class="ltx_ref ltx_href">A unifying
theory of transition-based and sequence labeling parsing</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on
Computational Linguistics</em>, pages 3776–3793, Barcelona, Spain (Online).
International Committee on Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. (2006)</span>
<span class="ltx_bibblock">
Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen
Schmidhuber. 2006.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/1143844.1143891" title="" class="ltx_ref ltx_href">Connectionist
temporal classification: Labelling unsegmented sequence data with recurrent
neural networks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd International Conference on Machine
Learning</em>, ICML ’06, page 369–376, New York, NY, USA. Association for
Computing Machinery.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grobol and Crabbé (2021)</span>
<span class="ltx_bibblock">
Loïc Grobol and Benoit Crabbé. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.jeptalnrecital-taln.9" title="" class="ltx_ref ltx_href">Analyse
en dépendances du français avec des plongements contextualisés
(French dependency parsing with contextualized embeddings)</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Actes de la 28e Conférence sur le Traitement Automatique
des Langues Naturelles. Volume 1 : conférence principale</em>, pages
106–114, Lille, France. ATALA.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honnibal and Johnson (2014)</span>
<span class="ltx_bibblock">
Matthew Honnibal and Mark Johnson. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00171" title="" class="ltx_ref ltx_href">Joint incremental
disfluency detection and dependency parsing</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
2:131–142.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Husianycia (2011)</span>
<span class="ltx_bibblock">
Magali Husianycia. 2011.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://hal.univ-lorraine.fr/tel-01749085" title="" class="ltx_ref ltx_href"><em id="bib.bib17.1.1.1" class="ltx_emph ltx_font_italic">Caractérisation de types de discours dans des situations de
travail</em></a>.

</span>
<span class="ltx_bibblock">Theses, Université Nancy 2.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ICAR (2017)</span>
<span class="ltx_bibblock">
ICAR. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://hdl.handle.net/11403/clapi/v1" title="" class="ltx_ref ltx_href">Clapi</a>.

</span>
<span class="ltx_bibblock">ORTOLANG (Open Resources and TOols for LANGuage)
–www.ortolang.fr.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jamshid Lou et al. (2019)</span>
<span class="ltx_bibblock">
Paria Jamshid Lou, Yufei Wang, and Mark Johnson. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1282" title="" class="ltx_ref ltx_href">Neural constituency
parsing of speech transcripts</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 2756–2765,
Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson and Charniak (2004)</span>
<span class="ltx_bibblock">
Mark Johnson and Eugene Charniak. 2004.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/1218955.1218960" title="" class="ltx_ref ltx_href">A TAG-based
noisy-channel model of speech repairs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 42nd Annual Meeting of the Association
for Computational Linguistics (ACL-04)</em>, pages 33–39, Barcelona, Spain.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kawaguchi et al. (2006)</span>
<span class="ltx_bibblock">
Yuji Kawaguchi, Susumu Zaima, and Toshihiro Takagaki, editors. 2006.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.jbe-platform.com/content/books/9789027292766" title="" class="ltx_ref ltx_href"><em id="bib.bib21.1.1.1" class="ltx_emph ltx_font_italic">Spoken Language Corpus and Linguistic Informatics</em></a>.

</span>
<span class="ltx_bibblock">John Benjamins.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martin et al. (2020)</span>
<span class="ltx_bibblock">
Louis Martin, Benjamin Muller, Pedro Javier Ortiz Suárez, Yoann Dupont,
Laurent Romary, Éric de la Clergerie, Djamé Seddah, and Benoît
Sagot. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.645" title="" class="ltx_ref ltx_href">CamemBERT:
a tasty French language model</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 7203–7219, Online. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathieu et al. ((2012-2020)</span>
<span class="ltx_bibblock">
Avanzi Mathieu, Béguelin Marie-José, Corminboeuf Gilles, Diémoz Federica,
and Johnsen Laure Anne. (2012-2020).

</span>
<span class="ltx_bibblock"><a href="www.unine.ch/ofrom" title="" class="ltx_ref ltx_href">Corpus ofrom – corpus oral de français
de suisse romande</a>.

</span>
<span class="ltx_bibblock">Université de Neuchâtel.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parcollet et al. (2024)</span>
<span class="ltx_bibblock">
Titouan Parcollet, Ha Nguyen, Solène Evain, Marcely Zanon Boito, Adrien
Pupier, Salima Mdhaffar, Hang Le, Sina Alisamir, Natalia Tomashenko, Marco
Dinarelli, Shucong Zhang, Alexandre Allauzen, Maximin Coavoux, Yannick
Estève, Mickael Rouvier, Jerôme Goulian, Benjamin Lecouteux, François
Portet, Solange Rossato, Fabien Ringeval, Didier Schwab, and Laurent
Besacier. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.csl.2024.101622" title="" class="ltx_ref ltx_href">Lebenchmark 2.0: A standardized, replicable and enhanced framework for
self-supervised representations of french speech</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, 86:101622.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Price et al. (1991)</span>
<span class="ltx_bibblock">
Patti J Price, Mari Ostendorf, Stefanie Shattuck-Hufnagel, and Cynthia Fong.
1991.

</span>
<span class="ltx_bibblock">The use of prosody in syntactic disambiguation.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">the Journal of the Acoustical Society of America</em>,
90(6):2956–2970.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pupier et al. (2022)</span>
<span class="ltx_bibblock">
Adrien Pupier, Maximin Coavoux, Benjamin Lecouteux, and Jerome Goulian. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.21437/Interspeech.2022-381" title="" class="ltx_ref ltx_href">End-to-End
Dependency Parsing of Spoken French</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2022</em>, pages 1816–1820.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rasooli and Tetreault (2013)</span>
<span class="ltx_bibblock">
Mohammad Sadegh Rasooli and Joel Tetreault. 2013.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/D13-1013" title="" class="ltx_ref ltx_href">Joint parsing and
disfluency detection in linear time</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2013 Conference on Empirical Methods in
Natural Language Processing</em>, pages 124–129, Seattle, Washington, USA.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ravanelli et al. (2021)</span>
<span class="ltx_bibblock">
Mirco Ravanelli, Titouan Parcollet, Peter Plantinga, Aku Rouhe, Samuele
Cornell, Loren Lugosch, Cem Subakan, Nauman Dawalatabad, Abdelwahab Heba,
Jianyuan Zhong, Ju-Chieh Chou, Sung-Lin Yeh, Szu-Wei Fu, Chien-Feng Liao,
Elena Rastorgueva, François Grondin, William Aris, Hwidong Na, Yan Gao,
Renato De Mori, and Yoshua Bengio. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2106.04624" title="" class="ltx_ref ltx_href">SpeechBrain: A
general-purpose speech toolkit</a>.

</span>
<span class="ltx_bibblock">ArXiv:2106.04624.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strzyz et al. (2019)</span>
<span class="ltx_bibblock">
Michalina Strzyz, David Vilares, and Carlos Gómez-Rodríguez. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1077" title="" class="ltx_ref ltx_href">Viable dependency
parsing as sequence labeling</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 717–723, Minneapolis,
Minnesota. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strzyz et al. (2020)</span>
<span class="ltx_bibblock">
Michalina Strzyz, David Vilares, and Carlos Gómez-Rodríguez. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.coling-main.223" title="" class="ltx_ref ltx_href">Bracketing
encodings for 2-planar dependency parsing</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on
Computational Linguistics</em>, pages 2472–2484, Barcelona, Spain (Online).
International Committee on Computational Linguistics.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Training Details</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Table <a href="#A1.T4" title="Table 4 ‣ Appendix A Training Details ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#A1.T5" title="Table 5 ‣ Appendix A Training Details ‣ Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> describe in more detail the hyperparameters used for each parser for the different sets of modalities.</p>
</div>
<figure id="A1.T4" class="ltx_table">
<table id="A1.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T4.1.1.1" class="ltx_tr">
<th id="A1.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Parser</th>
<td id="A1.T4.1.1.1.2" class="ltx_td ltx_align_center">SEQ</td>
<td id="A1.T4.1.1.1.3" class="ltx_td ltx_align_center"><span id="A1.T4.1.1.1.3.1" class="ltx_text ltx_font_smallcaps">graph</span></td>
</tr>
<tr id="A1.T4.1.2.2" class="ltx_tr">
<th id="A1.T4.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Epoch</th>
<td id="A1.T4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">30</td>
<td id="A1.T4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">30</td>
</tr>
<tr id="A1.T4.1.3.3" class="ltx_tr">
<th id="A1.T4.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Batch size</th>
<td id="A1.T4.1.3.3.2" class="ltx_td ltx_align_center">8</td>
<td id="A1.T4.1.3.3.3" class="ltx_td ltx_align_center">8</td>
</tr>
<tr id="A1.T4.1.4.4" class="ltx_tr">
<th id="A1.T4.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3">Tuning parameters</th>
</tr>
<tr id="A1.T4.1.5.5" class="ltx_tr">
<th id="A1.T4.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Learning rate</th>
<td id="A1.T4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_t">0.0001</td>
<td id="A1.T4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_t">0.0001</td>
</tr>
<tr id="A1.T4.1.6.6" class="ltx_tr">
<th id="A1.T4.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Optimizer</th>
<td id="A1.T4.1.6.6.2" class="ltx_td ltx_align_center">AdaDelta</td>
<td id="A1.T4.1.6.6.3" class="ltx_td ltx_align_center">AdaDelta</td>
</tr>
<tr id="A1.T4.1.7.7" class="ltx_tr">
<th id="A1.T4.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Model name</th>
<td id="A1.T4.1.7.7.2" class="ltx_td ltx_align_center" colspan="2">LeBenchmark7K</td>
</tr>
<tr id="A1.T4.1.8.8" class="ltx_tr">
<th id="A1.T4.1.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3">Encoder</th>
</tr>
<tr id="A1.T4.1.9.9" class="ltx_tr">
<th id="A1.T4.1.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Encoder layer</th>
<td id="A1.T4.1.9.9.2" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="A1.T4.1.9.9.3" class="ltx_td ltx_align_center ltx_border_t">3</td>
</tr>
<tr id="A1.T4.1.10.10" class="ltx_tr">
<th id="A1.T4.1.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Dropout</th>
<td id="A1.T4.1.10.10.2" class="ltx_td ltx_align_center">0.15</td>
<td id="A1.T4.1.10.10.3" class="ltx_td ltx_align_center">0.15</td>
</tr>
<tr id="A1.T4.1.11.11" class="ltx_tr">
<th id="A1.T4.1.11.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Encoder Dim</th>
<td id="A1.T4.1.11.11.2" class="ltx_td ltx_align_center">1024</td>
<td id="A1.T4.1.11.11.3" class="ltx_td ltx_align_center">1024</td>
</tr>
<tr id="A1.T4.1.12.12" class="ltx_tr">
<th id="A1.T4.1.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Activation</th>
<td id="A1.T4.1.12.12.2" class="ltx_td ltx_align_center">LeakyReLU</td>
<td id="A1.T4.1.12.12.3" class="ltx_td ltx_align_center">LeakyRelu</td>
</tr>
<tr id="A1.T4.1.13.13" class="ltx_tr">
<th id="A1.T4.1.13.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3">Fusion LSTM</th>
</tr>
<tr id="A1.T4.1.14.14" class="ltx_tr">
<th id="A1.T4.1.14.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Layer</th>
<td id="A1.T4.1.14.14.2" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="A1.T4.1.14.14.3" class="ltx_td ltx_align_center ltx_border_t">2</td>
</tr>
<tr id="A1.T4.1.15.15" class="ltx_tr">
<th id="A1.T4.1.15.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Dim</th>
<td id="A1.T4.1.15.15.2" class="ltx_td ltx_align_center">500</td>
<td id="A1.T4.1.15.15.3" class="ltx_td ltx_align_center">500</td>
</tr>
<tr id="A1.T4.1.16.16" class="ltx_tr">
<th id="A1.T4.1.16.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Bidirectional</th>
<td id="A1.T4.1.16.16.2" class="ltx_td ltx_align_center">False</td>
<td id="A1.T4.1.16.16.3" class="ltx_td ltx_align_center">False</td>
</tr>
<tr id="A1.T4.1.17.17" class="ltx_tr">
<th id="A1.T4.1.17.17.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Bias</th>
<td id="A1.T4.1.17.17.2" class="ltx_td ltx_align_center">True</td>
<td id="A1.T4.1.17.17.3" class="ltx_td ltx_align_center">True</td>
</tr>
<tr id="A1.T4.1.18.18" class="ltx_tr">
<th id="A1.T4.1.18.18.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3">LSTM parser</th>
</tr>
<tr id="A1.T4.1.19.19" class="ltx_tr">
<th id="A1.T4.1.19.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Layer</th>
<td id="A1.T4.1.19.19.2" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="A1.T4.1.19.19.3" class="ltx_td ltx_align_center ltx_border_t">3</td>
</tr>
<tr id="A1.T4.1.20.20" class="ltx_tr">
<th id="A1.T4.1.20.20.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Dim</th>
<td id="A1.T4.1.20.20.2" class="ltx_td ltx_align_center">800</td>
<td id="A1.T4.1.20.20.3" class="ltx_td ltx_align_center">768</td>
</tr>
<tr id="A1.T4.1.21.21" class="ltx_tr">
<th id="A1.T4.1.21.21.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Bidirectional</th>
<td id="A1.T4.1.21.21.2" class="ltx_td ltx_align_center">True</td>
<td id="A1.T4.1.21.21.3" class="ltx_td ltx_align_center">True</td>
</tr>
<tr id="A1.T4.1.22.22" class="ltx_tr">
<th id="A1.T4.1.22.22.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3">Labeler (<span id="A1.T4.1.22.22.1.1" class="ltx_text ltx_font_smallcaps">seq2label</span>)</th>
</tr>
<tr id="A1.T4.1.23.23" class="ltx_tr">
<th id="A1.T4.1.23.23.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T4.1.23.23.2" class="ltx_td ltx_align_center ltx_border_t">1600</td>
<td id="A1.T4.1.23.23.3" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="A1.T4.1.24.24" class="ltx_tr">
<th id="A1.T4.1.24.24.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Layer</th>
<td id="A1.T4.1.24.24.2" class="ltx_td ltx_align_center">1</td>
<td id="A1.T4.1.24.24.3" class="ltx_td"></td>
</tr>
<tr id="A1.T4.1.25.25" class="ltx_tr">
<th id="A1.T4.1.25.25.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim arc</th>
<td id="A1.T4.1.25.25.2" class="ltx_td ltx_align_center">846</td>
<td id="A1.T4.1.25.25.3" class="ltx_td"></td>
</tr>
<tr id="A1.T4.1.26.26" class="ltx_tr">
<th id="A1.T4.1.26.26.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim POS</th>
<td id="A1.T4.1.26.26.2" class="ltx_td ltx_align_center">23</td>
<td id="A1.T4.1.26.26.3" class="ltx_td"></td>
</tr>
<tr id="A1.T4.1.27.27" class="ltx_tr">
<th id="A1.T4.1.27.27.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim label</th>
<td id="A1.T4.1.27.27.2" class="ltx_td ltx_align_center">19</td>
<td id="A1.T4.1.27.27.3" class="ltx_td"></td>
</tr>
<tr id="A1.T4.1.28.28" class="ltx_tr">
<th id="A1.T4.1.28.28.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3">Arc MLP (<span id="A1.T4.1.28.28.1.1" class="ltx_text ltx_font_smallcaps">graph</span>)</th>
</tr>
<tr id="A1.T4.1.29.29" class="ltx_tr">
<th id="A1.T4.1.29.29.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T4.1.29.29.2" class="ltx_td ltx_border_t"></td>
<td id="A1.T4.1.29.29.3" class="ltx_td ltx_align_center ltx_border_t">768</td>
</tr>
<tr id="A1.T4.1.30.30" class="ltx_tr">
<th id="A1.T4.1.30.30.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Layer</th>
<td id="A1.T4.1.30.30.2" class="ltx_td"></td>
<td id="A1.T4.1.30.30.3" class="ltx_td ltx_align_center">1</td>
</tr>
<tr id="A1.T4.1.31.31" class="ltx_tr">
<th id="A1.T4.1.31.31.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim</th>
<td id="A1.T4.1.31.31.2" class="ltx_td"></td>
<td id="A1.T4.1.31.31.3" class="ltx_td ltx_align_center">768</td>
</tr>
<tr id="A1.T4.1.32.32" class="ltx_tr">
<th id="A1.T4.1.32.32.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3">Label MLP (<span id="A1.T4.1.32.32.1.1" class="ltx_text ltx_font_smallcaps">graph</span>)</th>
</tr>
<tr id="A1.T4.1.33.33" class="ltx_tr">
<th id="A1.T4.1.33.33.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T4.1.33.33.2" class="ltx_td ltx_border_t"></td>
<td id="A1.T4.1.33.33.3" class="ltx_td ltx_align_center ltx_border_t">768</td>
</tr>
<tr id="A1.T4.1.34.34" class="ltx_tr">
<th id="A1.T4.1.34.34.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Layer</th>
<td id="A1.T4.1.34.34.2" class="ltx_td"></td>
<td id="A1.T4.1.34.34.3" class="ltx_td ltx_align_center">1</td>
</tr>
<tr id="A1.T4.1.35.35" class="ltx_tr">
<th id="A1.T4.1.35.35.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Head dim</th>
<td id="A1.T4.1.35.35.2" class="ltx_td"></td>
<td id="A1.T4.1.35.35.3" class="ltx_td ltx_align_center">768</td>
</tr>
<tr id="A1.T4.1.36.36" class="ltx_tr">
<th id="A1.T4.1.36.36.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="3">POS MLP (<span id="A1.T4.1.36.36.1.1" class="ltx_text ltx_font_smallcaps">graph</span>)</th>
</tr>
<tr id="A1.T4.1.37.37" class="ltx_tr">
<th id="A1.T4.1.37.37.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T4.1.37.37.2" class="ltx_td ltx_border_t"></td>
<td id="A1.T4.1.37.37.3" class="ltx_td ltx_align_center ltx_border_t">768</td>
</tr>
<tr id="A1.T4.1.38.38" class="ltx_tr">
<th id="A1.T4.1.38.38.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim</th>
<td id="A1.T4.1.38.38.2" class="ltx_td"></td>
<td id="A1.T4.1.38.38.3" class="ltx_td ltx_align_center">24</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="A1.T4.6.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">audio</span> and <span id="A1.T4.7.2" class="ltx_text ltx_font_bold ltx_font_smallcaps">oracle</span> <span id="A1.T4.8.3" class="ltx_text ltx_font_smallcaps">seq2label</span> and <span id="A1.T4.9.4" class="ltx_text ltx_font_smallcaps">graph</span> hyperparameters.</figcaption>
</figure>
<figure id="A1.T5" class="ltx_table">
<table id="A1.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T5.1.1.1" class="ltx_tr">
<th id="A1.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Parser</th>
<td id="A1.T5.1.1.1.2" class="ltx_td ltx_align_center"><span id="A1.T5.1.1.1.2.1" class="ltx_text ltx_font_smallcaps">seq2label</span></td>
<td id="A1.T5.1.1.1.3" class="ltx_td ltx_align_center"><span id="A1.T5.1.1.1.3.1" class="ltx_text ltx_font_smallcaps">graph</span></td>
<td id="A1.T5.1.1.1.4" class="ltx_td ltx_align_center"><span id="A1.T5.1.1.1.4.1" class="ltx_text ltx_font_smallcaps">hops</span></td>
</tr>
<tr id="A1.T5.1.2.2" class="ltx_tr">
<th id="A1.T5.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Epoch</th>
<td id="A1.T5.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">40</td>
<td id="A1.T5.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">40</td>
<td id="A1.T5.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">40</td>
</tr>
<tr id="A1.T5.1.3.3" class="ltx_tr">
<th id="A1.T5.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Batch size</th>
<td id="A1.T5.1.3.3.2" class="ltx_td ltx_align_center">32</td>
<td id="A1.T5.1.3.3.3" class="ltx_td ltx_align_center">32</td>
<td id="A1.T5.1.3.3.4" class="ltx_td ltx_align_center">32</td>
</tr>
<tr id="A1.T5.1.4.4" class="ltx_tr">
<th id="A1.T5.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">Tuning parameters</th>
</tr>
<tr id="A1.T5.1.5.5" class="ltx_tr">
<th id="A1.T5.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Learning rate</th>
<td id="A1.T5.1.5.5.2" class="ltx_td ltx_align_center ltx_border_t">0.001</td>
<td id="A1.T5.1.5.5.3" class="ltx_td ltx_align_center ltx_border_t">0.001</td>
<td id="A1.T5.1.5.5.4" class="ltx_td ltx_align_center ltx_border_t">0.00003</td>
</tr>
<tr id="A1.T5.1.6.6" class="ltx_tr">
<th id="A1.T5.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">optimizer</th>
<td id="A1.T5.1.6.6.2" class="ltx_td ltx_align_center">Adam</td>
<td id="A1.T5.1.6.6.3" class="ltx_td ltx_align_center">Adam</td>
<td id="A1.T5.1.6.6.4" class="ltx_td ltx_align_center">Adam</td>
</tr>
<tr id="A1.T5.1.7.7" class="ltx_tr">
<th id="A1.T5.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Embedding</th>
<td id="A1.T5.1.7.7.2" class="ltx_td ltx_align_center">Last layer</td>
<td id="A1.T5.1.7.7.3" class="ltx_td ltx_align_center">Last layer</td>
<td id="A1.T5.1.7.7.4" class="ltx_td ltx_align_center">Mean First 12 layers</td>
</tr>
<tr id="A1.T5.1.8.8" class="ltx_tr">
<th id="A1.T5.1.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Embedding dim</th>
<td id="A1.T5.1.8.8.2" class="ltx_td ltx_align_center">768</td>
<td id="A1.T5.1.8.8.3" class="ltx_td ltx_align_center">768</td>
<td id="A1.T5.1.8.8.4" class="ltx_td ltx_align_center">768</td>
</tr>
<tr id="A1.T5.1.9.9" class="ltx_tr">
<th id="A1.T5.1.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">BERT</th>
<td id="A1.T5.1.9.9.2" class="ltx_td ltx_align_center" colspan="3">camembert_base</td>
</tr>
<tr id="A1.T5.1.10.10" class="ltx_tr">
<th id="A1.T5.1.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">Char Bi-LSTM <span id="A1.T5.1.10.10.1.1" class="ltx_text ltx_font_smallcaps">hops</span>
</th>
</tr>
<tr id="A1.T5.1.11.11" class="ltx_tr">
<th id="A1.T5.1.11.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Embedding dim</th>
<td id="A1.T5.1.11.11.2" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.11.11.3" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.11.11.4" class="ltx_td ltx_align_center ltx_border_t">128</td>
</tr>
<tr id="A1.T5.1.12.12" class="ltx_tr">
<th id="A1.T5.1.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">Word Embedding <span id="A1.T5.1.12.12.1.1" class="ltx_text ltx_font_smallcaps">hops</span>
</th>
</tr>
<tr id="A1.T5.1.13.13" class="ltx_tr">
<th id="A1.T5.1.13.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Embedding dim</th>
<td id="A1.T5.1.13.13.2" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.13.13.3" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.13.13.4" class="ltx_td ltx_align_center ltx_border_t">256</td>
</tr>
<tr id="A1.T5.1.14.14" class="ltx_tr">
<th id="A1.T5.1.14.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">LSTM parser</th>
</tr>
<tr id="A1.T5.1.15.15" class="ltx_tr">
<th id="A1.T5.1.15.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T5.1.15.15.2" class="ltx_td ltx_align_center ltx_border_t">768</td>
<td id="A1.T5.1.15.15.3" class="ltx_td ltx_align_center ltx_border_t">768</td>
<td id="A1.T5.1.15.15.4" class="ltx_td ltx_align_center ltx_border_t">512</td>
</tr>
<tr id="A1.T5.1.16.16" class="ltx_tr">
<th id="A1.T5.1.16.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Layers</th>
<td id="A1.T5.1.16.16.2" class="ltx_td ltx_align_center">3</td>
<td id="A1.T5.1.16.16.3" class="ltx_td ltx_align_center">2</td>
<td id="A1.T5.1.16.16.4" class="ltx_td ltx_align_center">3</td>
</tr>
<tr id="A1.T5.1.17.17" class="ltx_tr">
<th id="A1.T5.1.17.17.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Bidirectional</th>
<td id="A1.T5.1.17.17.2" class="ltx_td ltx_align_center">True</td>
<td id="A1.T5.1.17.17.3" class="ltx_td ltx_align_center">True</td>
<td id="A1.T5.1.17.17.4" class="ltx_td ltx_align_center">True</td>
</tr>
<tr id="A1.T5.1.18.18" class="ltx_tr">
<th id="A1.T5.1.18.18.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">Labeler (<span id="A1.T5.1.18.18.1.1" class="ltx_text ltx_font_smallcaps">seq2label</span>)</th>
</tr>
<tr id="A1.T5.1.19.19" class="ltx_tr">
<th id="A1.T5.1.19.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T5.1.19.19.2" class="ltx_td ltx_align_center ltx_border_t">1536</td>
<td id="A1.T5.1.19.19.3" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.19.19.4" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="A1.T5.1.20.20" class="ltx_tr">
<th id="A1.T5.1.20.20.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Layer</th>
<td id="A1.T5.1.20.20.2" class="ltx_td ltx_align_center">1</td>
<td id="A1.T5.1.20.20.3" class="ltx_td"></td>
<td id="A1.T5.1.20.20.4" class="ltx_td"></td>
</tr>
<tr id="A1.T5.1.21.21" class="ltx_tr">
<th id="A1.T5.1.21.21.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim arc</th>
<td id="A1.T5.1.21.21.2" class="ltx_td ltx_align_center">846</td>
<td id="A1.T5.1.21.21.3" class="ltx_td"></td>
<td id="A1.T5.1.21.21.4" class="ltx_td"></td>
</tr>
<tr id="A1.T5.1.22.22" class="ltx_tr">
<th id="A1.T5.1.22.22.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim POS</th>
<td id="A1.T5.1.22.22.2" class="ltx_td ltx_align_center">23</td>
<td id="A1.T5.1.22.22.3" class="ltx_td"></td>
<td id="A1.T5.1.22.22.4" class="ltx_td"></td>
</tr>
<tr id="A1.T5.1.23.23" class="ltx_tr">
<th id="A1.T5.1.23.23.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim label</th>
<td id="A1.T5.1.23.23.2" class="ltx_td ltx_align_center">19</td>
<td id="A1.T5.1.23.23.3" class="ltx_td"></td>
<td id="A1.T5.1.23.23.4" class="ltx_td"></td>
</tr>
<tr id="A1.T5.1.24.24" class="ltx_tr">
<th id="A1.T5.1.24.24.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">Arc MLP (<span id="A1.T5.1.24.24.1.1" class="ltx_text ltx_font_smallcaps">graph</span> and <span id="A1.T5.1.24.24.1.2" class="ltx_text ltx_font_smallcaps">hops</span>)</th>
</tr>
<tr id="A1.T5.1.25.25" class="ltx_tr">
<th id="A1.T5.1.25.25.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T5.1.25.25.2" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.25.25.3" class="ltx_td ltx_align_center ltx_border_t">768</td>
<td id="A1.T5.1.25.25.4" class="ltx_td ltx_align_center ltx_border_t">1024</td>
</tr>
<tr id="A1.T5.1.26.26" class="ltx_tr">
<th id="A1.T5.1.26.26.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Layer</th>
<td id="A1.T5.1.26.26.2" class="ltx_td"></td>
<td id="A1.T5.1.26.26.3" class="ltx_td ltx_align_center">1</td>
<td id="A1.T5.1.26.26.4" class="ltx_td ltx_align_center">2</td>
</tr>
<tr id="A1.T5.1.27.27" class="ltx_tr">
<th id="A1.T5.1.27.27.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim</th>
<td id="A1.T5.1.27.27.2" class="ltx_td"></td>
<td id="A1.T5.1.27.27.3" class="ltx_td ltx_align_center">768</td>
<td id="A1.T5.1.27.27.4" class="ltx_td ltx_align_center">768</td>
</tr>
<tr id="A1.T5.1.28.28" class="ltx_tr">
<th id="A1.T5.1.28.28.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">Label MLP (<span id="A1.T5.1.28.28.1.1" class="ltx_text ltx_font_smallcaps">graph</span>)</th>
</tr>
<tr id="A1.T5.1.29.29" class="ltx_tr">
<th id="A1.T5.1.29.29.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T5.1.29.29.2" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.29.29.3" class="ltx_td ltx_align_center ltx_border_t">768</td>
<td id="A1.T5.1.29.29.4" class="ltx_td ltx_align_center ltx_border_t">1024</td>
</tr>
<tr id="A1.T5.1.30.30" class="ltx_tr">
<th id="A1.T5.1.30.30.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Layer</th>
<td id="A1.T5.1.30.30.2" class="ltx_td"></td>
<td id="A1.T5.1.30.30.3" class="ltx_td ltx_align_center">1</td>
<td id="A1.T5.1.30.30.4" class="ltx_td ltx_align_center">2</td>
</tr>
<tr id="A1.T5.1.31.31" class="ltx_tr">
<th id="A1.T5.1.31.31.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Head dim</th>
<td id="A1.T5.1.31.31.2" class="ltx_td"></td>
<td id="A1.T5.1.31.31.3" class="ltx_td ltx_align_center">768</td>
<td id="A1.T5.1.31.31.4" class="ltx_td ltx_align_center">768</td>
</tr>
<tr id="A1.T5.1.32.32" class="ltx_tr">
<th id="A1.T5.1.32.32.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">POS MLP (<span id="A1.T5.1.32.32.1.1" class="ltx_text ltx_font_smallcaps">graph</span>)</th>
</tr>
<tr id="A1.T5.1.33.33" class="ltx_tr">
<th id="A1.T5.1.33.33.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Dim</th>
<td id="A1.T5.1.33.33.2" class="ltx_td ltx_border_t"></td>
<td id="A1.T5.1.33.33.3" class="ltx_td ltx_align_center ltx_border_t">768</td>
<td id="A1.T5.1.33.33.4" class="ltx_td ltx_align_center ltx_border_t">1024</td>
</tr>
<tr id="A1.T5.1.34.34" class="ltx_tr">
<th id="A1.T5.1.34.34.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Linear head dim</th>
<td id="A1.T5.1.34.34.2" class="ltx_td"></td>
<td id="A1.T5.1.34.34.3" class="ltx_td ltx_align_center">24</td>
<td id="A1.T5.1.34.34.4" class="ltx_td ltx_align_center">24</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span><span id="A1.T5.7.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> and <span id="A1.T5.8.2" class="ltx_text ltx_font_bold ltx_font_smallcaps">text</span> <span id="A1.T5.9.3" class="ltx_text ltx_font_smallcaps">seq2label</span>, <span id="A1.T5.10.4" class="ltx_text ltx_font_smallcaps">graph</span> and <span id="A1.T5.11.5" class="ltx_text ltx_font_bold ltx_font_smallcaps">pipeline</span> hyperparameters.</figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.12620" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.12621" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.12621">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.12621" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.12622" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Jul  6 00:11:10 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
