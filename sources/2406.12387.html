<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.12387] Performant ASR Models for Medical Entities in Accented Speech</title><meta property="og:description" content="Recent strides in automatic speech recognition (ASR) have accelerated their application in the medical domain where their performance on accented medical named entities (NE) such as drug names, diagnoses, and lab resul…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Performant ASR Models for Medical Entities in Accented Speech">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Performant ASR Models for Medical Entities in Accented Speech">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.12387">

<!--Generated on Fri Jul  5 18:43:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.2" class="ltx_ERROR undefined">\name</span>
<p id="p1.3" class="ltx_p">[affiliation=  †1,6,*]TejumadeAfonja
<span id="p1.3.1" class="ltx_ERROR undefined">\name</span>[affiliation=  †2,*]TobiOlatunji
<span id="p1.3.2" class="ltx_ERROR undefined">\name</span>[affiliation=3,*]SewadeOgun
<span id="p1.3.3" class="ltx_ERROR undefined">\name</span>[affiliation=4,*]
<br class="ltx_break">Naome A.Etori
<span id="p1.3.4" class="ltx_ERROR undefined">\name</span>[affiliation=2,*]AbrahamOwodunni
<span id="p1.3.5" class="ltx_ERROR undefined">\name</span>[affiliation=5,*]MoshoodYekini




</p>
</div>
<h1 class="ltx_title ltx_title_document">Performant ASR Models for Medical Entities in Accented Speech</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id10.id1" class="ltx_p">Recent strides in automatic speech recognition (ASR) have accelerated their application in the medical domain where their performance on accented medical named entities (NE) such as drug names, diagnoses, and lab results, is largely unknown. We rigorously evaluate multiple ASR models on a clinical English dataset of 93 African accents. Our analysis reveals that despite some models achieving low overall word error rates (WER), errors in clinical entities are higher, potentially posing substantial risks to patient safety. To empirically demonstrate this, we extract clinical entities from transcripts, develop a novel algorithm to align ASR predictions with these entities, and compute medical NE Recall, medical WER, and character error rate. Our results show that fine-tuning on accented clinical speech improves medical WER by a wide margin (25-34 % relative), improving their practical applicability in healthcare environments.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>speech recognition, medical documentation, medical named-entity recognition, African-accented speech 
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent years, significant advances have been made in accented speech recognition with state-of-the-art (SOTA) automatic speech recognition (ASR) models proficiently transcribing diverse linguistic interactions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. However, the effectiveness of these models in clinical or medical settings,<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We use the terms ‘clinical’ and ‘medical’ interchangeably to encompass all aspects related to the practice of medicine and patient care.</span></span></span> where nuanced communication is paramount, remains a challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. This becomes particularly evident when clinicians with non-western accents document critical medical information using ASR technology. While these SOTA models achieve low word error rates (WER) on general speech, they commonly struggle with accurately transcribing clinical named entities (NE), e.g., see Table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The domain-specific nature of clinical documentation introduces a vulnerability that could have severe consequences for patient well-being – minor inaccuracies in essential elements like drug names, diagnoses, lab results, and lesion measurements (for example, writing <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">renal</span> instead of <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">adrenal</span>, or <span id="S1.p1.1.3" class="ltx_text ltx_font_italic">hyper-</span> instead of <span id="S1.p1.1.4" class="ltx_text ltx_font_italic">hypo-</span>) could potentially risk patient safety and expose clinicians to avoidable litigation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
To empirically expose this problem, we analyze the performance of several SOTA open-source and commercial ASR models on medical NEs (MNEs). Our investigation reveals that current SOTA general-purpose multilingual ASR models while excelling in cross-domain scenarios, exhibit sub-optimal Recall rates for MNEs in accented speech. This limitation diminishes the practical utility of these models in healthcare settings, underscoring the need for specialized solutions.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Our contributions are as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We benchmark 19 open-source and commercial ASR models on African accented clinical speech highlighting the deficiencies of existing architectures in accurately recognizing accented MNEs.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We introduce metrics for evaluating medical NER performance in the context of accented speech, including medical named entity Recall, medical WER (M-WER), and medical character error rate (M-CER).</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We develop a novel fuzzy string matching algorithm to better align ASR-predicted noisy NEs to ground truth NEs for more nuanced analysis.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We demonstrate that supervised fine-tuning substantially enhances accented medical NER, making ASR models more applicable and reliable in real-world clinical scenarios.
</p>
</div>
</li>
</ol>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Predicted sentences from selected ASR models compared to the reference sentence.
</figcaption>
<table id="S1.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.1.1.1" class="ltx_tr">
<th id="S1.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S1.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S1.T1.1.1.1.2.1" class="ltx_text" style="font-size:90%;">Sentence</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.1.2.1" class="ltx_tr">
<th id="S1.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S1.T1.1.2.1.1.1" class="ltx_text" style="font-size:90%;">Reference sentence</span></th>
<td id="S1.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.1.2.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">lungs clear</span><span id="S1.T1.1.2.1.2.2" class="ltx_text" style="font-size:90%;"> but dim scattered </span><span id="S1.T1.1.2.1.2.3" class="ltx_text ltx_font_bold" style="font-size:90%;">rhonchi</span><span id="S1.T1.1.2.1.2.4" class="ltx_text" style="font-size:90%;"> nonproductive </span><span id="S1.T1.1.2.1.2.5" class="ltx_text ltx_font_bold" style="font-size:90%;">cough</span><span id="S1.T1.1.2.1.2.6" class="ltx_text" style="font-size:90%;">.</span>
</td>
</tr>
<tr id="S1.T1.1.3.2" class="ltx_tr">
<th id="S1.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S1.T1.1.3.2.1.1" class="ltx_text" style="font-size:90%;">Xlsr-53-en</span></th>
<td id="S1.T1.1.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.1.3.2.2.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">longscler</span><span id="S1.T1.1.3.2.2.2" class="ltx_text" style="font-size:90%;"> bout deim scattered </span><span id="S1.T1.1.3.2.2.3" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">rong i</span><span id="S1.T1.1.3.2.2.4" class="ltx_text" style="font-size:90%;"> non-productive hol</span>
</td>
</tr>
<tr id="S1.T1.1.4.3" class="ltx_tr">
<th id="S1.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S1.T1.1.4.3.1.1" class="ltx_text" style="font-size:90%;">Whisper-medium</span></th>
<td id="S1.T1.1.4.3.2" class="ltx_td ltx_align_left">
<span id="S1.T1.1.4.3.2.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">non-scler,</span><span id="S1.T1.1.4.3.2.2" class="ltx_text" style="font-size:90%;"> but dim-scattered </span><span id="S1.T1.1.4.3.2.3" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">ronchi</span><span id="S1.T1.1.4.3.2.4" class="ltx_text" style="font-size:90%;">, non-productive hub.</span>
</td>
</tr>
<tr id="S1.T1.1.5.4" class="ltx_tr">
<th id="S1.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S1.T1.1.5.4.1.1" class="ltx_text" style="font-size:90%;">GCP [Medical]</span></th>
<td id="S1.T1.1.5.4.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S1.T1.1.5.4.2.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">lungs , clear</span><span id="S1.T1.1.5.4.2.2" class="ltx_text" style="font-size:90%;"> . budan scattered </span><span id="S1.T1.1.5.4.2.3" class="ltx_text ltx_font_bold" style="font-size:90%;">rhonchi</span><span id="S1.T1.1.5.4.2.4" class="ltx_text" style="font-size:90%;"> . nonproductive</span>
</td>
</tr>
<tr id="S1.T1.1.6.5" class="ltx_tr">
<th id="S1.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S1.T1.1.6.5.1.1" class="ltx_text" style="font-size:90%;">AWS [Medical] (Primary Care)</span></th>
<td id="S1.T1.1.6.5.2" class="ltx_td ltx_align_left">
<span id="S1.T1.1.6.5.2.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">last clear</span><span id="S1.T1.1.6.5.2.2" class="ltx_text" style="font-size:90%;"> but deems scattered </span><span id="S1.T1.1.6.5.2.3" class="ltx_text ltx_font_bold" style="font-size:90%;">rhonchi</span><span id="S1.T1.1.6.5.2.4" class="ltx_text" style="font-size:90%;"> nonproductive.</span>
</td>
</tr>
<tr id="S1.T1.1.7.6" class="ltx_tr">
<th id="S1.T1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S1.T1.1.7.6.1.1" class="ltx_text" style="font-size:90%;">Whisper-medium-clinical</span></th>
<td id="S1.T1.1.7.6.2" class="ltx_td ltx_align_left ltx_border_b">
<span id="S1.T1.1.7.6.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">lungs clear</span><span id="S1.T1.1.7.6.2.2" class="ltx_text" style="font-size:90%;"> but dim scattered </span><span id="S1.T1.1.7.6.2.3" class="ltx_text ltx_font_bold" style="font-size:90%;">rhonchi</span><span id="S1.T1.1.7.6.2.4" class="ltx_text" style="font-size:90%;"> nonproductive </span><span id="S1.T1.1.7.6.2.5" class="ltx_text ltx_font_bold" style="font-size:90%;">cough</span><span id="S1.T1.1.7.6.2.6" class="ltx_text" style="font-size:90%;">.</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Recently, authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> highlighted the challenges faced by popular ASR models in recognizing African named entities like persons, locations, and organizations from accented speech.
They improved entity WER through data augmentation techniques.
In the medical domain, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> relied on large language models for correcting medical ASR transcription errors. The work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> also used a sequence-to-sequence model to correct clinical ASR errors.
Accurately detecting and classifying medical named entities from text has been explored in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> where <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> identified five key MNEs, and employed deep learning and multi-task learning approaches to extract crucial information from clinical narratives. Also, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> developed an ensemble of deep contextual models trained on clinical corpora from PubMed to enhance clinical NE recognition. The work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> separately benchmarked clinical speech recognition and entity extraction. Additionally, a production-scalable BiLSTM-CNN-Char framework with pre-trained embedding was designed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, which was shown to achieve better performance in speed and prediction compared to the SOTA models and commercial clinical NE recognition solutions. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> proposed a clinical task-specific prompting framework that adopts entity definitions, annotation guidelines and samples, and error analysis-based instructions.
However, research benchmarking SOTA ASR models on accented medical NE transcription or recognition is still lacking.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Approach</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We investigated this problem by evaluating 19 open-source and commercial ASR systems on a dataset of
African-accented clinical speech. A schematic is shown in Figure <a href="#S3.F1" title="Figure 1 ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The dataset, medical NE extraction approach, ASR models, and evaluation methods are described below.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2406.12387/assets/images/AfriNames-Page-3.drawio-5.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="302" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Methodology: Ground truth transcripts are passed to a commercial medical NER model, and audios are passed through multiple ASR models. Predicted medical entities are extracted using the MedTextAlign algorithm. Metrics are computed over silver NEs</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">For this analysis, we leveraged AfriSpeech-200 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, a 200-hour Pan-African accented English speech corpus for clinical and general domain ASR with 120 accents, and over 2,300 unique speakers from over 10 African countries. The dataset statistics and NE categories are shown in Table <a href="#S3.T2" title="Table 2 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Our evaluation focuses on the clinical domain test subset. After filtering out texts lacking sufficient medical context, we retained a total of 2,844 samples, encompassing 93 different accents.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Dataset splits showing the number of speakers, the number of clips, speech duration, and medical named entity category counts in train/dev/test splits.</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">Item</th>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">Train</td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">Dev</td>
<td id="S3.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">Test</td>
</tr>
<tr id="S3.T2.1.2.2" class="ltx_tr">
<th id="S3.T2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">Number of speakers</th>
<td id="S3.T2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">1466</td>
<td id="S3.T2.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">247</td>
<td id="S3.T2.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">750</td>
</tr>
<tr id="S3.T2.1.3.3" class="ltx_tr">
<th id="S3.T2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">Duration (in hours)</th>
<td id="S3.T2.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">173.4</td>
<td id="S3.T2.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">8.74</td>
<td id="S3.T2.1.3.3.4" class="ltx_td ltx_align_center" style="padding-left:5.4pt;padding-right:5.4pt;">18.77</td>
</tr>
<tr id="S3.T2.1.4.4" class="ltx_tr">
<th id="S3.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">Number of accents</th>
<td id="S3.T2.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">71</td>
<td id="S3.T2.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">45</td>
<td id="S3.T2.1.4.4.4" class="ltx_td ltx_align_center" style="padding-left:5.4pt;padding-right:5.4pt;">108</td>
</tr>
<tr id="S3.T2.1.5.5" class="ltx_tr">
<th id="S3.T2.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">Number of clips/speaker</th>
<td id="S3.T2.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">39.56</td>
<td id="S3.T2.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">13.08</td>
<td id="S3.T2.1.5.5.4" class="ltx_td ltx_align_center" style="padding-left:5.4pt;padding-right:5.4pt;">8.46</td>
</tr>
<tr id="S3.T2.1.6.6" class="ltx_tr">
<th id="S3.T2.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">Number of speakers/accent</th>
<td id="S3.T2.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">20.65</td>
<td id="S3.T2.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">5.49</td>
<td id="S3.T2.1.6.6.4" class="ltx_td ltx_align_center" style="padding-left:5.4pt;padding-right:5.4pt;">6.94</td>
</tr>
<tr id="S3.T2.1.7.7" class="ltx_tr">
<th id="S3.T2.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;"># clinical domain clips (61.80 %)</th>
<td id="S3.T2.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">36318</td>
<td id="S3.T2.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">1824</td>
<td id="S3.T2.1.7.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">3623</td>
</tr>
<tr id="S3.T2.1.8.8" class="ltx_tr">
<th id="S3.T2.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;"># general domain clips (38.20 %)</th>
<td id="S3.T2.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">21682</td>
<td id="S3.T2.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">1407</td>
<td id="S3.T2.1.8.8.4" class="ltx_td ltx_align_center" style="padding-left:5.4pt;padding-right:5.4pt;">2723</td>
</tr>
<tr id="S3.T2.1.9.9" class="ltx_tr">
<th id="S3.T2.1.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;" colspan="4">Medical named entity category count</th>
</tr>
<tr id="S3.T2.1.10.10" class="ltx_tr">
<th id="S3.T2.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">Medication (<span id="S3.T2.1.10.10.1.1" class="ltx_text ltx_font_typewriter">MED</span>)</th>
<td id="S3.T2.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">4164</td>
<td id="S3.T2.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">132</td>
<td id="S3.T2.1.10.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:5.4pt;padding-right:5.4pt;">276</td>
</tr>
<tr id="S3.T2.1.11.11" class="ltx_tr">
<th id="S3.T2.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">Medical condition (<span id="S3.T2.1.11.11.1.1" class="ltx_text ltx_font_typewriter">COND</span>)</th>
<td id="S3.T2.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">18804</td>
<td id="S3.T2.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">901</td>
<td id="S3.T2.1.11.11.4" class="ltx_td ltx_align_center" style="padding-left:5.4pt;padding-right:5.4pt;">1414</td>
</tr>
<tr id="S3.T2.1.12.12" class="ltx_tr">
<th id="S3.T2.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">Anatomy (<span id="S3.T2.1.12.12.1.1" class="ltx_text ltx_font_typewriter">ANA</span>)</th>
<td id="S3.T2.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">13650</td>
<td id="S3.T2.1.12.12.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">645</td>
<td id="S3.T2.1.12.12.4" class="ltx_td ltx_align_center" style="padding-left:5.4pt;padding-right:5.4pt;">927</td>
</tr>
<tr id="S3.T2.1.13.13" class="ltx_tr">
<th id="S3.T2.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">Test treatment procedure (<span id="S3.T2.1.13.13.1.1" class="ltx_text ltx_font_typewriter">TTP</span>)</th>
<td id="S3.T2.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">10713</td>
<td id="S3.T2.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">428</td>
<td id="S3.T2.1.13.13.4" class="ltx_td ltx_align_center" style="padding-left:5.4pt;padding-right:5.4pt;">893</td>
</tr>
<tr id="S3.T2.1.14.14" class="ltx_tr">
<th id="S3.T2.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">Protected health information (<span id="S3.T2.1.14.14.1.1" class="ltx_text ltx_font_typewriter">PHI</span>)</th>
<td id="S3.T2.1.14.14.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">3449</td>
<td id="S3.T2.1.14.14.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-left:5.4pt;padding-right:5.4pt;">105</td>
<td id="S3.T2.1.14.14.4" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:5.4pt;padding-right:5.4pt;">253</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Output from the Wavlm-libri-clean-100h-base model, entities matched exactly are highlighted in bold, while near matches identified through our MedTextAlign strategy are underlined.</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<th id="S3.T3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S3.T3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.1.1.1" class="ltx_p" style="width:433.6pt;">Reference</span>
</span>
</th>
<th id="S3.T3.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S3.T3.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.1.1.2.1.1" class="ltx_p" style="width:433.6pt;">Prediction</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.1.2.1" class="ltx_tr">
<td id="S3.T3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.2.1.1.1.1" class="ltx_p" style="width:433.6pt;">unlike <span id="S3.T3.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">quinidine</span>, <span id="S3.T3.1.2.1.1.1.1.2" class="ltx_text ltx_font_bold">disopyramide</span> does not increase the plasma concentration of <span id="S3.T3.1.2.1.1.1.1.3" class="ltx_text ltx_font_bold">digoxin</span> in patients</span>
</span>
</td>
<td id="S3.T3.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T3.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.2.1.2.1.1" class="ltx_p" style="width:433.6pt;">anlike <span id="S3.T3.1.2.1.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">quinidan</span>, <span id="S3.T3.1.2.1.2.1.1.2" class="ltx_text ltx_framed ltx_framed_underline">disopiramid</span> dos not incruse the plasma concentration of <span id="S3.T3.1.2.1.2.1.1.3" class="ltx_text ltx_framed ltx_framed_underline">dikod sin</span> in pesion</span>
</span>
</td>
</tr>
<tr id="S3.T3.1.3.2" class="ltx_tr">
<td id="S3.T3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t">
<span id="S3.T3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.3.2.1.1.1" class="ltx_p" style="width:433.6pt;">except for <span id="S3.T3.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold">ketamine</span>, the following agents have no <span id="S3.T3.1.3.2.1.1.1.2" class="ltx_text ltx_font_bold">analgesic properties</span> and do not cause <span id="S3.T3.1.3.2.1.1.1.3" class="ltx_text ltx_font_bold">paralysis</span> or <span id="S3.T3.1.3.2.1.1.1.4" class="ltx_text ltx_font_bold">muscle relaxation</span></span>
</span>
</td>
<td id="S3.T3.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T3.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.1.3.2.2.1.1" class="ltx_p" style="width:433.6pt;">except for <span id="S3.T3.1.3.2.2.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">ketami</span>, befullin agents have no <span id="S3.T3.1.3.2.2.1.1.2" class="ltx_text ltx_framed ltx_framed_underline">anagesic propatis</span> and do not cose <span id="S3.T3.1.3.2.2.1.1.3" class="ltx_text ltx_font_bold">paralysis</span> o <span id="S3.T3.1.3.2.2.1.1.4" class="ltx_text ltx_framed ltx_framed_underline">mozul relaxition</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance evaluation of benchmarked models on AfriSpeech-200 clinical domain test dataset. We report WER comparing transcript and prediction, alongside specific metrics including the medical WER (M-WER), the medical CER (M-CER), and the Recall for the different entities, medication (<span id="S3.T4.7.1" class="ltx_text ltx_font_typewriter">MED</span>), anatomy (<span id="S3.T4.8.2" class="ltx_text ltx_font_typewriter">ANA</span>), medical condition (<span id="S3.T4.9.3" class="ltx_text ltx_font_typewriter">COND</span>), test treatment procedure (<span id="S3.T4.10.4" class="ltx_text ltx_font_typewriter">TTP</span>), and protected health information (<span id="S3.T4.11.5" class="ltx_text ltx_font_typewriter">PHI</span>).</figcaption>
<table id="S3.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T4.1.1" class="ltx_tr">
<td id="S3.T4.1.1.2" class="ltx_td ltx_border_r ltx_border_t" colspan="2"></td>
<td id="S3.T4.1.1.3" class="ltx_td ltx_border_r ltx_border_t" colspan="2"></td>
<td id="S3.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5">
<span id="S3.T4.1.1.1.1" class="ltx_text" style="font-size:90%;">Recall(</span><math id="S3.T4.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T4.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S3.T4.1.1.1.m1.1.1" xref="S3.T4.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.m1.1b"><ci id="S3.T4.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.m1.1c">\uparrow</annotation></semantics></math><span id="S3.T4.1.1.1.2" class="ltx_text" style="font-size:90%;">)</span>
</td>
</tr>
<tr id="S3.T4.1.2.1" class="ltx_tr">
<td id="S3.T4.1.2.1.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.2.1.1.1" class="ltx_text" style="font-size:90%;">Models</span></td>
<td id="S3.T4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.2.1.2.1" class="ltx_text" style="font-size:90%;">WER</span></td>
<td id="S3.T4.1.2.1.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.2.1.3.1" class="ltx_text" style="font-size:90%;">M-WER</span></td>
<td id="S3.T4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.2.1.4.1" class="ltx_text" style="font-size:90%;">M-CER</span></td>
<td id="S3.T4.1.2.1.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.2.1.5.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">MED</span></td>
<td id="S3.T4.1.2.1.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.2.1.6.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">ANA</span></td>
<td id="S3.T4.1.2.1.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.2.1.7.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">COND</span></td>
<td id="S3.T4.1.2.1.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.2.1.8.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">TTP</span></td>
<td id="S3.T4.1.2.1.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.2.1.9.1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">PHI</span></td>
</tr>
<tr id="S3.T4.1.3.2" class="ltx_tr">
<td id="S3.T4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T4.1.3.2.1.1" class="ltx_text" style="font-size:90%;">Pretrained</span></td>
<td id="S3.T4.1.3.2.2" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.3.2.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.3.2.4" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.3.2.5" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.3.2.6" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.3.2.7" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.3.2.8" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.3.2.9" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T4.1.4.3" class="ltx_tr">
<td id="S3.T4.1.4.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T4.1.4.3.1.1" class="ltx_text" style="font-size:90%;">Wavlm-libri-clean-100h-base</span></td>
<td id="S3.T4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T4.1.4.3.2.1" class="ltx_text" style="font-size:90%;">0.902</span></td>
<td id="S3.T4.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.4.3.3.1" class="ltx_text" style="font-size:90%;">0.944</span></td>
<td id="S3.T4.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T4.1.4.3.4.1" class="ltx_text" style="font-size:90%;">0.504</span></td>
<td id="S3.T4.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.4.3.5.1" class="ltx_text" style="font-size:90%;">0.019</span></td>
<td id="S3.T4.1.4.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.4.3.6.1" class="ltx_text" style="font-size:90%;">0.069</span></td>
<td id="S3.T4.1.4.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.4.3.7.1" class="ltx_text" style="font-size:90%;">0.063</span></td>
<td id="S3.T4.1.4.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.4.3.8.1" class="ltx_text" style="font-size:90%;">0.056</span></td>
<td id="S3.T4.1.4.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.4.3.9.1" class="ltx_text" style="font-size:90%;">0.034</span></td>
</tr>
<tr id="S3.T4.1.5.4" class="ltx_tr">
<td id="S3.T4.1.5.4.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.5.4.1.1" class="ltx_text" style="font-size:90%;">Wavlm-libri-clean-100h-large</span></td>
<td id="S3.T4.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.5.4.2.1" class="ltx_text" style="font-size:90%;">0.784</span></td>
<td id="S3.T4.1.5.4.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.5.4.3.1" class="ltx_text" style="font-size:90%;">0.852</span></td>
<td id="S3.T4.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.5.4.4.1" class="ltx_text" style="font-size:90%;">0.307</span></td>
<td id="S3.T4.1.5.4.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.5.4.5.1" class="ltx_text" style="font-size:90%;">0.029</span></td>
<td id="S3.T4.1.5.4.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.5.4.6.1" class="ltx_text" style="font-size:90%;">0.177</span></td>
<td id="S3.T4.1.5.4.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.5.4.7.1" class="ltx_text" style="font-size:90%;">0.142</span></td>
<td id="S3.T4.1.5.4.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.5.4.8.1" class="ltx_text" style="font-size:90%;">0.110</span></td>
<td id="S3.T4.1.5.4.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.5.4.9.1" class="ltx_text" style="font-size:90%;">0.043</span></td>
</tr>
<tr id="S3.T4.1.6.5" class="ltx_tr">
<td id="S3.T4.1.6.5.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.6.5.1.1" class="ltx_text" style="font-size:90%;">Hubert-large-ls960-ft</span></td>
<td id="S3.T4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.6.5.2.1" class="ltx_text" style="font-size:90%;">0.712</span></td>
<td id="S3.T4.1.6.5.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.6.5.3.1" class="ltx_text" style="font-size:90%;">0.758</span></td>
<td id="S3.T4.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.6.5.4.1" class="ltx_text" style="font-size:90%;">0.279</span></td>
<td id="S3.T4.1.6.5.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.6.5.5.1" class="ltx_text" style="font-size:90%;">0.070</span></td>
<td id="S3.T4.1.6.5.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.6.5.6.1" class="ltx_text" style="font-size:90%;">0.282</span></td>
<td id="S3.T4.1.6.5.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.6.5.7.1" class="ltx_text" style="font-size:90%;">0.258</span></td>
<td id="S3.T4.1.6.5.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.6.5.8.1" class="ltx_text" style="font-size:90%;">0.168</span></td>
<td id="S3.T4.1.6.5.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.6.5.9.1" class="ltx_text" style="font-size:90%;">0.069</span></td>
</tr>
<tr id="S3.T4.1.7.6" class="ltx_tr">
<td id="S3.T4.1.7.6.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.7.6.1.1" class="ltx_text" style="font-size:90%;">Hubert-xlarge-ls960-ft</span></td>
<td id="S3.T4.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.7.6.2.1" class="ltx_text" style="font-size:90%;">0.722</span></td>
<td id="S3.T4.1.7.6.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.7.6.3.1" class="ltx_text" style="font-size:90%;">0.770</span></td>
<td id="S3.T4.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.7.6.4.1" class="ltx_text" style="font-size:90%;">0.275</span></td>
<td id="S3.T4.1.7.6.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.7.6.5.1" class="ltx_text" style="font-size:90%;">0.067</span></td>
<td id="S3.T4.1.7.6.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.7.6.6.1" class="ltx_text" style="font-size:90%;">0.284</span></td>
<td id="S3.T4.1.7.6.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.7.6.7.1" class="ltx_text" style="font-size:90%;">0.262</span></td>
<td id="S3.T4.1.7.6.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.7.6.8.1" class="ltx_text" style="font-size:90%;">0.166</span></td>
<td id="S3.T4.1.7.6.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.7.6.9.1" class="ltx_text" style="font-size:90%;">0.075</span></td>
</tr>
<tr id="S3.T4.1.8.7" class="ltx_tr">
<td id="S3.T4.1.8.7.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.8.7.1.1" class="ltx_text" style="font-size:90%;">Wav2vec2-large-robust-ft-swbd-300h</span></td>
<td id="S3.T4.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.8.7.2.1" class="ltx_text" style="font-size:90%;">0.907</span></td>
<td id="S3.T4.1.8.7.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.8.7.3.1" class="ltx_text" style="font-size:90%;">0.919</span></td>
<td id="S3.T4.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.8.7.4.1" class="ltx_text" style="font-size:90%;">0.367</span></td>
<td id="S3.T4.1.8.7.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.8.7.5.1" class="ltx_text" style="font-size:90%;">0.040</span></td>
<td id="S3.T4.1.8.7.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.8.7.6.1" class="ltx_text" style="font-size:90%;">0.129</span></td>
<td id="S3.T4.1.8.7.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.8.7.7.1" class="ltx_text" style="font-size:90%;">0.139</span></td>
<td id="S3.T4.1.8.7.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.8.7.8.1" class="ltx_text" style="font-size:90%;">0.112</span></td>
<td id="S3.T4.1.8.7.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.8.7.9.1" class="ltx_text" style="font-size:90%;">0.051</span></td>
</tr>
<tr id="S3.T4.1.9.8" class="ltx_tr">
<td id="S3.T4.1.9.8.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.9.8.1.1" class="ltx_text" style="font-size:90%;">Wav2vec2-large-960h</span></td>
<td id="S3.T4.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.9.8.2.1" class="ltx_text" style="font-size:90%;">0.796</span></td>
<td id="S3.T4.1.9.8.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.9.8.3.1" class="ltx_text" style="font-size:90%;">0.846</span></td>
<td id="S3.T4.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.9.8.4.1" class="ltx_text" style="font-size:90%;">0.345</span></td>
<td id="S3.T4.1.9.8.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.9.8.5.1" class="ltx_text" style="font-size:90%;">0.032</span></td>
<td id="S3.T4.1.9.8.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.9.8.6.1" class="ltx_text" style="font-size:90%;">0.189</span></td>
<td id="S3.T4.1.9.8.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.9.8.7.1" class="ltx_text" style="font-size:90%;">0.171</span></td>
<td id="S3.T4.1.9.8.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.9.8.8.1" class="ltx_text" style="font-size:90%;">0.109</span></td>
<td id="S3.T4.1.9.8.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.9.8.9.1" class="ltx_text" style="font-size:90%;">0.049</span></td>
</tr>
<tr id="S3.T4.1.10.9" class="ltx_tr">
<td id="S3.T4.1.10.9.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.10.9.1.1" class="ltx_text" style="font-size:90%;">Wav2vec2-large-960h-lv60-self</span></td>
<td id="S3.T4.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.10.9.2.1" class="ltx_text" style="font-size:90%;">0.694</span></td>
<td id="S3.T4.1.10.9.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.10.9.3.1" class="ltx_text" style="font-size:90%;">0.753</span></td>
<td id="S3.T4.1.10.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.10.9.4.1" class="ltx_text" style="font-size:90%;">0.277</span></td>
<td id="S3.T4.1.10.9.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.10.9.5.1" class="ltx_text" style="font-size:90%;">0.064</span></td>
<td id="S3.T4.1.10.9.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.10.9.6.1" class="ltx_text" style="font-size:90%;">0.309</span></td>
<td id="S3.T4.1.10.9.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.10.9.7.1" class="ltx_text" style="font-size:90%;">0.254</span></td>
<td id="S3.T4.1.10.9.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.10.9.8.1" class="ltx_text" style="font-size:90%;">0.173</span></td>
<td id="S3.T4.1.10.9.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.10.9.9.1" class="ltx_text" style="font-size:90%;">0.087</span></td>
</tr>
<tr id="S3.T4.1.11.10" class="ltx_tr">
<td id="S3.T4.1.11.10.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.11.10.1.1" class="ltx_text" style="font-size:90%;">Wav2vec2-xls-r-1b-english</span></td>
<td id="S3.T4.1.11.10.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.11.10.2.1" class="ltx_text" style="font-size:90%;">0.666</span></td>
<td id="S3.T4.1.11.10.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.11.10.3.1" class="ltx_text" style="font-size:90%;">0.729</span></td>
<td id="S3.T4.1.11.10.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.11.10.4.1" class="ltx_text" style="font-size:90%;">0.266</span></td>
<td id="S3.T4.1.11.10.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.11.10.5.1" class="ltx_text" style="font-size:90%;">0.081</span></td>
<td id="S3.T4.1.11.10.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.11.10.6.1" class="ltx_text" style="font-size:90%;">0.251</span></td>
<td id="S3.T4.1.11.10.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.11.10.7.1" class="ltx_text" style="font-size:90%;">0.249</span></td>
<td id="S3.T4.1.11.10.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.11.10.8.1" class="ltx_text" style="font-size:90%;">0.227</span></td>
<td id="S3.T4.1.11.10.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.11.10.9.1" class="ltx_text" style="font-size:90%;">0.138</span></td>
</tr>
<tr id="S3.T4.1.12.11" class="ltx_tr">
<td id="S3.T4.1.12.11.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.12.11.1.1" class="ltx_text" style="font-size:90%;">Wav2vec2-large-xlsr-53-english</span></td>
<td id="S3.T4.1.12.11.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.12.11.2.1" class="ltx_text" style="font-size:90%;">0.646</span></td>
<td id="S3.T4.1.12.11.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.12.11.3.1" class="ltx_text" style="font-size:90%;">0.710</span></td>
<td id="S3.T4.1.12.11.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.12.11.4.1" class="ltx_text" style="font-size:90%;">0.272</span></td>
<td id="S3.T4.1.12.11.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.12.11.5.1" class="ltx_text" style="font-size:90%;">0.072</span></td>
<td id="S3.T4.1.12.11.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.12.11.6.1" class="ltx_text" style="font-size:90%;">0.261</span></td>
<td id="S3.T4.1.12.11.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.12.11.7.1" class="ltx_text" style="font-size:90%;">0.256</span></td>
<td id="S3.T4.1.12.11.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.12.11.8.1" class="ltx_text" style="font-size:90%;">0.201</span></td>
<td id="S3.T4.1.12.11.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.12.11.9.1" class="ltx_text" style="font-size:90%;">0.095</span></td>
</tr>
<tr id="S3.T4.1.13.12" class="ltx_tr">
<td id="S3.T4.1.13.12.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.13.12.1.1" class="ltx_text" style="font-size:90%;">Whisper-small-en</span></td>
<td id="S3.T4.1.13.12.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.13.12.2.1" class="ltx_text" style="font-size:90%;">0.486</span></td>
<td id="S3.T4.1.13.12.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.13.12.3.1" class="ltx_text" style="font-size:90%;">0.566</span></td>
<td id="S3.T4.1.13.12.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.13.12.4.1" class="ltx_text" style="font-size:90%;">0.225</span></td>
<td id="S3.T4.1.13.12.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.13.12.5.1" class="ltx_text" style="font-size:90%;">0.215</span></td>
<td id="S3.T4.1.13.12.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.13.12.6.1" class="ltx_text" style="font-size:90%;">0.571</span></td>
<td id="S3.T4.1.13.12.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.13.12.7.1" class="ltx_text" style="font-size:90%;">0.536</span></td>
<td id="S3.T4.1.13.12.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.13.12.8.1" class="ltx_text" style="font-size:90%;">0.475</span></td>
<td id="S3.T4.1.13.12.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.13.12.9.1" class="ltx_text" style="font-size:90%;">0.300</span></td>
</tr>
<tr id="S3.T4.1.14.13" class="ltx_tr">
<td id="S3.T4.1.14.13.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.14.13.1.1" class="ltx_text" style="font-size:90%;">Whisper-small</span></td>
<td id="S3.T4.1.14.13.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.14.13.2.1" class="ltx_text" style="font-size:90%;">0.451</span></td>
<td id="S3.T4.1.14.13.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.14.13.3.1" class="ltx_text" style="font-size:90%;">0.567</span></td>
<td id="S3.T4.1.14.13.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.14.13.4.1" class="ltx_text" style="font-size:90%;">0.216</span></td>
<td id="S3.T4.1.14.13.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.14.13.5.1" class="ltx_text" style="font-size:90%;">0.235</span></td>
<td id="S3.T4.1.14.13.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.14.13.6.1" class="ltx_text" style="font-size:90%;">0.566</span></td>
<td id="S3.T4.1.14.13.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.14.13.7.1" class="ltx_text" style="font-size:90%;">0.541</span></td>
<td id="S3.T4.1.14.13.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.14.13.8.1" class="ltx_text" style="font-size:90%;">0.486</span></td>
<td id="S3.T4.1.14.13.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.14.13.9.1" class="ltx_text" style="font-size:90%;">0.301</span></td>
</tr>
<tr id="S3.T4.1.15.14" class="ltx_tr">
<td id="S3.T4.1.15.14.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.15.14.1.1" class="ltx_text" style="font-size:90%;">Whisper-medium-en</span></td>
<td id="S3.T4.1.15.14.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.15.14.2.1" class="ltx_text" style="font-size:90%;">0.415</span></td>
<td id="S3.T4.1.15.14.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.15.14.3.1" class="ltx_text" style="font-size:90%;">0.504</span></td>
<td id="S3.T4.1.15.14.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.15.14.4.1" class="ltx_text" style="font-size:90%;">0.188</span></td>
<td id="S3.T4.1.15.14.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.15.14.5.1" class="ltx_text" style="font-size:90%;">0.330</span></td>
<td id="S3.T4.1.15.14.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.15.14.6.1" class="ltx_text" style="font-size:90%;">0.636</span></td>
<td id="S3.T4.1.15.14.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.15.14.7.1" class="ltx_text" style="font-size:90%;">0.601</span></td>
<td id="S3.T4.1.15.14.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.15.14.8.1" class="ltx_text" style="font-size:90%;">0.532</span></td>
<td id="S3.T4.1.15.14.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.15.14.9.1" class="ltx_text" style="font-size:90%;">0.300</span></td>
</tr>
<tr id="S3.T4.1.16.15" class="ltx_tr">
<td id="S3.T4.1.16.15.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.16.15.1.1" class="ltx_text" style="font-size:90%;">Whisper-medium</span></td>
<td id="S3.T4.1.16.15.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.16.15.2.1" class="ltx_text" style="font-size:90%;">0.392</span></td>
<td id="S3.T4.1.16.15.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.16.15.3.1" class="ltx_text" style="font-size:90%;">0.487</span></td>
<td id="S3.T4.1.16.15.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.16.15.4.1" class="ltx_text" style="font-size:90%;">0.174</span></td>
<td id="S3.T4.1.16.15.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.16.15.5.1" class="ltx_text" style="font-size:90%;">0.343</span></td>
<td id="S3.T4.1.16.15.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.16.15.6.1" class="ltx_text" style="font-size:90%;">0.680</span></td>
<td id="S3.T4.1.16.15.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.16.15.7.1" class="ltx_text" style="font-size:90%;">0.627</span></td>
<td id="S3.T4.1.16.15.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.16.15.8.1" class="ltx_text" style="font-size:90%;">0.568</span></td>
<td id="S3.T4.1.16.15.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.16.15.9.1" class="ltx_text" style="font-size:90%;">0.335</span></td>
</tr>
<tr id="S3.T4.1.17.16" class="ltx_tr">
<td id="S3.T4.1.17.16.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.17.16.1.1" class="ltx_text" style="font-size:90%;">Whisper-large</span></td>
<td id="S3.T4.1.17.16.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.17.16.2.1" class="ltx_text" style="font-size:90%;">0.373</span></td>
<td id="S3.T4.1.17.16.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.17.16.3.1" class="ltx_text" style="font-size:90%;">0.454</span></td>
<td id="S3.T4.1.17.16.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.17.16.4.1" class="ltx_text" style="font-size:90%;">0.154</span></td>
<td id="S3.T4.1.17.16.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.17.16.5.1" class="ltx_text" style="font-size:90%;">0.425</span></td>
<td id="S3.T4.1.17.16.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.17.16.6.1" class="ltx_text" style="font-size:90%;">0.717</span></td>
<td id="S3.T4.1.17.16.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.17.16.7.1" class="ltx_text" style="font-size:90%;">0.667</span></td>
<td id="S3.T4.1.17.16.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.17.16.8.1" class="ltx_text" style="font-size:90%;">0.597</span></td>
<td id="S3.T4.1.17.16.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.17.16.9.1" class="ltx_text" style="font-size:90%;">0.331</span></td>
</tr>
<tr id="S3.T4.1.18.17" class="ltx_tr">
<td id="S3.T4.1.18.17.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T4.1.18.17.1.1" class="ltx_text" style="font-size:90%;">Commercial</span></td>
<td id="S3.T4.1.18.17.2" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.18.17.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.18.17.4" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.18.17.5" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.18.17.6" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.18.17.7" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.18.17.8" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.18.17.9" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T4.1.19.18" class="ltx_tr">
<td id="S3.T4.1.19.18.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T4.1.19.18.1.1" class="ltx_text" style="font-size:90%;">Azure</span></td>
<td id="S3.T4.1.19.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T4.1.19.18.2.1" class="ltx_text" style="font-size:90%;">0.442</span></td>
<td id="S3.T4.1.19.18.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.19.18.3.1" class="ltx_text" style="font-size:90%;">0.491</span></td>
<td id="S3.T4.1.19.18.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T4.1.19.18.4.1" class="ltx_text" style="font-size:90%;">0.216</span></td>
<td id="S3.T4.1.19.18.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.19.18.5.1" class="ltx_text" style="font-size:90%;">0.611</span></td>
<td id="S3.T4.1.19.18.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.19.18.6.1" class="ltx_text" style="font-size:90%;">0.660</span></td>
<td id="S3.T4.1.19.18.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.19.18.7.1" class="ltx_text" style="font-size:90%;">0.623</span></td>
<td id="S3.T4.1.19.18.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.19.18.8.1" class="ltx_text" style="font-size:90%;">0.515</span></td>
<td id="S3.T4.1.19.18.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.19.18.9.1" class="ltx_text" style="font-size:90%;">0.261</span></td>
</tr>
<tr id="S3.T4.1.20.19" class="ltx_tr">
<td id="S3.T4.1.20.19.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.20.19.1.1" class="ltx_text" style="font-size:90%;">AWS</span></td>
<td id="S3.T4.1.20.19.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.20.19.2.1" class="ltx_text" style="font-size:90%;">0.540</span></td>
<td id="S3.T4.1.20.19.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.20.19.3.1" class="ltx_text" style="font-size:90%;">0.660</span></td>
<td id="S3.T4.1.20.19.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.20.19.4.1" class="ltx_text" style="font-size:90%;">0.249</span></td>
<td id="S3.T4.1.20.19.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.20.19.5.1" class="ltx_text" style="font-size:90%;">0.212</span></td>
<td id="S3.T4.1.20.19.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.20.19.6.1" class="ltx_text" style="font-size:90%;">0.523</span></td>
<td id="S3.T4.1.20.19.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.20.19.7.1" class="ltx_text" style="font-size:90%;">0.485</span></td>
<td id="S3.T4.1.20.19.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.20.19.8.1" class="ltx_text" style="font-size:90%;">0.382</span></td>
<td id="S3.T4.1.20.19.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.20.19.9.1" class="ltx_text" style="font-size:90%;">0.246</span></td>
</tr>
<tr id="S3.T4.1.21.20" class="ltx_tr">
<td id="S3.T4.1.21.20.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.21.20.1.1" class="ltx_text" style="font-size:90%;">AWS [Medical] (Primary Care)</span></td>
<td id="S3.T4.1.21.20.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.21.20.2.1" class="ltx_text" style="font-size:90%;">0.516</span></td>
<td id="S3.T4.1.21.20.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.21.20.3.1" class="ltx_text" style="font-size:90%;">0.553</span></td>
<td id="S3.T4.1.21.20.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.21.20.4.1" class="ltx_text" style="font-size:90%;">0.218</span></td>
<td id="S3.T4.1.21.20.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.21.20.5.1" class="ltx_text" style="font-size:90%;">0.572</span></td>
<td id="S3.T4.1.21.20.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.21.20.6.1" class="ltx_text" style="font-size:90%;">0.644</span></td>
<td id="S3.T4.1.21.20.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.21.20.7.1" class="ltx_text" style="font-size:90%;">0.567</span></td>
<td id="S3.T4.1.21.20.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.21.20.8.1" class="ltx_text" style="font-size:90%;">0.494</span></td>
<td id="S3.T4.1.21.20.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.21.20.9.1" class="ltx_text" style="font-size:90%;">0.204</span></td>
</tr>
<tr id="S3.T4.1.22.21" class="ltx_tr">
<td id="S3.T4.1.22.21.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.22.21.1.1" class="ltx_text" style="font-size:90%;">GCP</span></td>
<td id="S3.T4.1.22.21.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.22.21.2.1" class="ltx_text" style="font-size:90%;">0.622</span></td>
<td id="S3.T4.1.22.21.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.22.21.3.1" class="ltx_text" style="font-size:90%;">0.634</span></td>
<td id="S3.T4.1.22.21.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.22.21.4.1" class="ltx_text" style="font-size:90%;">0.391</span></td>
<td id="S3.T4.1.22.21.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.22.21.5.1" class="ltx_text" style="font-size:90%;">0.386</span></td>
<td id="S3.T4.1.22.21.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.22.21.6.1" class="ltx_text" style="font-size:90%;">0.425</span></td>
<td id="S3.T4.1.22.21.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.22.21.7.1" class="ltx_text" style="font-size:90%;">0.380</span></td>
<td id="S3.T4.1.22.21.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.22.21.8.1" class="ltx_text" style="font-size:90%;">0.332</span></td>
<td id="S3.T4.1.22.21.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.22.21.9.1" class="ltx_text" style="font-size:90%;">0.177</span></td>
</tr>
<tr id="S3.T4.1.23.22" class="ltx_tr">
<td id="S3.T4.1.23.22.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.23.22.1.1" class="ltx_text" style="font-size:90%;">GCP [Medical]</span></td>
<td id="S3.T4.1.23.22.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.23.22.2.1" class="ltx_text" style="font-size:90%;">0.527</span></td>
<td id="S3.T4.1.23.22.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.23.22.3.1" class="ltx_text" style="font-size:90%;">0.434</span></td>
<td id="S3.T4.1.23.22.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.23.22.4.1" class="ltx_text" style="font-size:90%;">0.211</span></td>
<td id="S3.T4.1.23.22.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.23.22.5.1" class="ltx_text" style="font-size:90%;">0.568</span></td>
<td id="S3.T4.1.23.22.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.23.22.6.1" class="ltx_text" style="font-size:90%;">0.701</span></td>
<td id="S3.T4.1.23.22.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.23.22.7.1" class="ltx_text" style="font-size:90%;">0.565</span></td>
<td id="S3.T4.1.23.22.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.23.22.8.1" class="ltx_text" style="font-size:90%;">0.513</span></td>
<td id="S3.T4.1.23.22.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.23.22.9.1" class="ltx_text" style="font-size:90%;">0.184</span></td>
</tr>
<tr id="S3.T4.1.24.23" class="ltx_tr">
<td id="S3.T4.1.24.23.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T4.1.24.23.1.1" class="ltx_text" style="font-size:90%;">Fine-tuned on AfriSpeech-200</span></td>
<td id="S3.T4.1.24.23.2" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.24.23.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.24.23.4" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.24.23.5" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.24.23.6" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.24.23.7" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.24.23.8" class="ltx_td ltx_border_t"></td>
<td id="S3.T4.1.24.23.9" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T4.1.25.24" class="ltx_tr">
<td id="S3.T4.1.25.24.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T4.1.25.24.1.1" class="ltx_text" style="font-size:90%;">Wav2vec2-large-xlsr-53-english-general</span></td>
<td id="S3.T4.1.25.24.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T4.1.25.24.2.1" class="ltx_text" style="font-size:90%;">0.473</span></td>
<td id="S3.T4.1.25.24.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.25.24.3.1" class="ltx_text" style="font-size:90%;">0.680</span></td>
<td id="S3.T4.1.25.24.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T4.1.25.24.4.1" class="ltx_text" style="font-size:90%;">0.235</span></td>
<td id="S3.T4.1.25.24.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.25.24.5.1" class="ltx_text" style="font-size:90%;">0.144</span></td>
<td id="S3.T4.1.25.24.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.25.24.6.1" class="ltx_text" style="font-size:90%;">0.294</span></td>
<td id="S3.T4.1.25.24.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.25.24.7.1" class="ltx_text" style="font-size:90%;">0.300</span></td>
<td id="S3.T4.1.25.24.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.25.24.8.1" class="ltx_text" style="font-size:90%;">0.297</span></td>
<td id="S3.T4.1.25.24.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.1.25.24.9.1" class="ltx_text" style="font-size:90%;">0.300</span></td>
</tr>
<tr id="S3.T4.1.26.25" class="ltx_tr">
<td id="S3.T4.1.26.25.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.26.25.1.1" class="ltx_text" style="font-size:90%;">Wav2vec2-large-xlsr-53-english-both</span></td>
<td id="S3.T4.1.26.25.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.26.25.2.1" class="ltx_text" style="font-size:90%;">0.308</span></td>
<td id="S3.T4.1.26.25.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.26.25.3.1" class="ltx_text" style="font-size:90%;">0.467</span></td>
<td id="S3.T4.1.26.25.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.26.25.4.1" class="ltx_text" style="font-size:90%;">0.135</span></td>
<td id="S3.T4.1.26.25.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.26.25.5.1" class="ltx_text" style="font-size:90%;">0.451</span></td>
<td id="S3.T4.1.26.25.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.26.25.6.1" class="ltx_text" style="font-size:90%;">0.658</span></td>
<td id="S3.T4.1.26.25.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.26.25.7.1" class="ltx_text" style="font-size:90%;">0.576</span></td>
<td id="S3.T4.1.26.25.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.26.25.8.1" class="ltx_text" style="font-size:90%;">0.567</span></td>
<td id="S3.T4.1.26.25.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.26.25.9.1" class="ltx_text" style="font-size:90%;">0.356</span></td>
</tr>
<tr id="S3.T4.1.27.26" class="ltx_tr">
<td id="S3.T4.1.27.26.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.27.26.1.1" class="ltx_text" style="font-size:90%;">Wav2vec2-large-xlsr-53-english-clinical</span></td>
<td id="S3.T4.1.27.26.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.27.26.2.1" class="ltx_text" style="font-size:90%;">0.307</span></td>
<td id="S3.T4.1.27.26.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.27.26.3.1" class="ltx_text" style="font-size:90%;">0.465</span></td>
<td id="S3.T4.1.27.26.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.27.26.4.1" class="ltx_text" style="font-size:90%;">0.133</span></td>
<td id="S3.T4.1.27.26.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.27.26.5.1" class="ltx_text" style="font-size:90%;">0.496</span></td>
<td id="S3.T4.1.27.26.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.27.26.6.1" class="ltx_text" style="font-size:90%;">0.689</span></td>
<td id="S3.T4.1.27.26.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.27.26.7.1" class="ltx_text" style="font-size:90%;">0.584</span></td>
<td id="S3.T4.1.27.26.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.27.26.8.1" class="ltx_text" style="font-size:90%;">0.588</span></td>
<td id="S3.T4.1.27.26.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.27.26.9.1" class="ltx_text" style="font-size:90%;">0.291</span></td>
</tr>
<tr id="S3.T4.1.28.27" class="ltx_tr">
<td id="S3.T4.1.28.27.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.28.27.1.1" class="ltx_text" style="font-size:90%;">Whisper-medium-general</span></td>
<td id="S3.T4.1.28.27.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.28.27.2.1" class="ltx_text" style="font-size:90%;">0.532</span></td>
<td id="S3.T4.1.28.27.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.28.27.3.1" class="ltx_text" style="font-size:90%;">0.711</span></td>
<td id="S3.T4.1.28.27.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.28.27.4.1" class="ltx_text" style="font-size:90%;">0.347</span></td>
<td id="S3.T4.1.28.27.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.28.27.5.1" class="ltx_text" style="font-size:90%;">0.114</span></td>
<td id="S3.T4.1.28.27.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.28.27.6.1" class="ltx_text" style="font-size:90%;">0.314</span></td>
<td id="S3.T4.1.28.27.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.28.27.7.1" class="ltx_text" style="font-size:90%;">0.279</span></td>
<td id="S3.T4.1.28.27.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.28.27.8.1" class="ltx_text" style="font-size:90%;">0.282</span></td>
<td id="S3.T4.1.28.27.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.28.27.9.1" class="ltx_text" style="font-size:90%;">0.325</span></td>
</tr>
<tr id="S3.T4.1.29.28" class="ltx_tr">
<td id="S3.T4.1.29.28.1" class="ltx_td ltx_align_left"><span id="S3.T4.1.29.28.1.1" class="ltx_text" style="font-size:90%;">Whisper-medium-clinical</span></td>
<td id="S3.T4.1.29.28.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.29.28.2.1" class="ltx_text" style="font-size:90%;">0.264</span></td>
<td id="S3.T4.1.29.28.3" class="ltx_td ltx_align_center"><span id="S3.T4.1.29.28.3.1" class="ltx_text" style="font-size:90%;">0.388</span></td>
<td id="S3.T4.1.29.28.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T4.1.29.28.4.1" class="ltx_text" style="font-size:90%;">0.136</span></td>
<td id="S3.T4.1.29.28.5" class="ltx_td ltx_align_center"><span id="S3.T4.1.29.28.5.1" class="ltx_text" style="font-size:90%;">0.659</span></td>
<td id="S3.T4.1.29.28.6" class="ltx_td ltx_align_center"><span id="S3.T4.1.29.28.6.1" class="ltx_text" style="font-size:90%;">0.806</span></td>
<td id="S3.T4.1.29.28.7" class="ltx_td ltx_align_center"><span id="S3.T4.1.29.28.7.1" class="ltx_text" style="font-size:90%;">0.712</span></td>
<td id="S3.T4.1.29.28.8" class="ltx_td ltx_align_center"><span id="S3.T4.1.29.28.8.1" class="ltx_text" style="font-size:90%;">0.706</span></td>
<td id="S3.T4.1.29.28.9" class="ltx_td ltx_align_center"><span id="S3.T4.1.29.28.9.1" class="ltx_text" style="font-size:90%;">0.405</span></td>
</tr>
<tr id="S3.T4.1.30.29" class="ltx_tr">
<td id="S3.T4.1.30.29.1" class="ltx_td ltx_align_left ltx_border_b"><span id="S3.T4.1.30.29.1.1" class="ltx_text" style="font-size:90%;">Whisper-medium-both</span></td>
<td id="S3.T4.1.30.29.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T4.1.30.29.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.241</span></td>
<td id="S3.T4.1.30.29.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T4.1.30.29.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.365</span></td>
<td id="S3.T4.1.30.29.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T4.1.30.29.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.118</span></td>
<td id="S3.T4.1.30.29.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T4.1.30.29.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.731</span></td>
<td id="S3.T4.1.30.29.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T4.1.30.29.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.822</span></td>
<td id="S3.T4.1.30.29.7" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T4.1.30.29.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.725</span></td>
<td id="S3.T4.1.30.29.8" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T4.1.30.29.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.726</span></td>
<td id="S3.T4.1.30.29.9" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T4.1.30.29.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.490</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>ASR Models</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We evaluated several open-source and commercial (general-purpose and medical) ASR systems covering multiple SOTA ASR architectures shown in Table <a href="#S3.T4" title="Table 4 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
In addition, we selected two models for fine-tuning based on the model performance reported in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and our computational constraints.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Named Entity Extraction</h3>

<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Extracting Ground Truth Entities</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Since the dataset was not annotated with MNEs, we leveraged a commercially available medical NER model, Amazon Comprehend Medical <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>,<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Amazon Comprehend Medical at <a target="_blank" href="https://aws.amazon.com/comprehend/medical/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aws.amazon.com/comprehend/medical/</a></span></span></span> to automatically extract medical NEs from ground truth transcripts. This service has been publicly benchmarked against other NER systems by GigaOm<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>GigaOm Clinical NLP Benchmark at <a target="_blank" href="https://gigaom.com/report/healthcare-natural-language-processing/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://gigaom.com/report/healthcare-natural-language-processing/</a></span></span></span> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, and has good accuracy in predicting
multiple medical NE categories. We call these silver annotations as these are not human annotations.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Selected Named Entities</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">We focused on five key medical named entity categories: medication (<span id="S3.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_typewriter">MED</span>), medical condition (<span id="S3.SS3.SSS2.p1.1.2" class="ltx_text ltx_font_typewriter">COND</span>), anatomy (<span id="S3.SS3.SSS2.p1.1.3" class="ltx_text ltx_font_typewriter">ANA</span>), test treatment procedure (<span id="S3.SS3.SSS2.p1.1.4" class="ltx_text ltx_font_typewriter">TTP</span>), and protected health information (<span id="S3.SS3.SSS2.p1.1.5" class="ltx_text ltx_font_typewriter">PHI</span>). These categories cover a wide range of entities, including medication names, dosages, diagnoses, signs, symptoms, and protected health information such as names, addresses, ID numbers, etc. The distribution of entities across these categories for each dataset split is detailed in Table <a href="#S3.T2" title="Table 2 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>MedTextAlign: Extracting Predicted Named Entities</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">To evaluate predicted MNEs, a naive method is to use an NER model to identify the ASR-predicted MNEs. However, given that the ASR predictions are noisy, often having different lengths and spellings than ground-truth NEs, and single-word to multi-word entity mismatches exist, these issues pose a challenge for most NER models, making them inadequate. For example, ``analgesic properties'' is misspelled as ``anagesic propatis'', ``digoxin'' wrongly transcribed as ``dikod sin'', and ``spironolactone'' as ``spiro no lactone''. An alignment algorithm was thus needed to better match ground-truth MNEs. Therefore, we developed MedTextAlign, a
solution that
uses a fuzzy string-matching algorithm to better align the predicted to the ground truth (silver) MNEs.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.1" class="ltx_p">MedTextAlign first tokenizes the predicted transcript, creates a candidate list of unigrams, bigrams, and trigrams from the predicted transcript, then leverages a fuzzy string matching algorithm<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We used the python SequenceMatcher ratio() method at <a target="_blank" href="https://docs.python.org/3/library/difflib.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://docs.python.org/3/library/difflib.html</a> and set the cut-off threshold to 0.5.</span></span></span> to compare with each MNE from the ground truth transcript to find the closest match. The fuzzy match, akin to measuring the longest common character subsequence (e.g., in ROUGE-L <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>), produces a score between 0 and 1 for each string pair, with 1 indicating a perfect match, enabling effective matching of nearly correct spellings in the transcript, e.g., matching wrongly spelled ``quinidan'' or ``disopiramid'' (see Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p id="S3.SS3.SSS3.p3.1" class="ltx_p">Although not perfect, this strategy proved to be very effective. In Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we underline approximate entity matches and put in bold-face exact matches given by the Wavlm-libri-clean-100h-base model.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Evaluation Metrics</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Given the challenges with ASR alignment, conventional ASR or NER metrics fail to effectively measure the model's ability to transcribe medical entities. Consequently, to comprehensively assess the performance of these ASR models, we opted for a broad range of metrics that cover various evaluation dimensions.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Recall: An information retrieval metric that computes the proportion of recovered correct (exact match) entities in the prediction. Precision and F1 score were not computed because they are overly sensitive to ASR noise or errors. Higher Recall is better.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Word error rate (WER): a word-level metric that evaluates insertions, deletions, and substitutions in the predicted sequence. Lower is better.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Medical WER (M-WER): WER computed between the ground truth MNEs and their aligned MNEs in the prediction alone. This isolates WER on MNEs of interest while ignoring all other words. All ground truth MNEs in each sample are concatenated with intervening spaces. The MNEs recovered by MedTextAlign are also concatenated in the same way. WER is then calculated between resulting sequences. Lower is better.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Medical CER (M-CER): Similar to medical WER, but at the character level. M-CER measures the severity of ASR misspellings. Lower is better.</p>
</div>
</li>
</ol>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Benchmarking</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We compared SOTA open-source pre-trained ASR models: Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, Wav2vec2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, XLSR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, Hubert <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, WavLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, alongside commercial clinical and non-clinical ASR systems; Azure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, AWS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, and GCP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. For all open-source pre-trained ASR models, we refer readers to read their respective papers for details on pretraining corpora, model architecture, and hyperparameters. In addition, we used the Hugging Face transformer library <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> for inference. For each model, we show results on the AfriSpeech clinical domain test set in Table <a href="#S3.T4" title="Table 4 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Fine-tuning</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For the fine-tuning experiments,
we fine-tuned
the ASR models on three domains: (1) <em id="S4.SS2.p1.1.1" class="ltx_emph ltx_font_italic">general</em> domain (21,682 clips), (2) <em id="S4.SS2.p1.1.2" class="ltx_emph ltx_font_italic">clinical</em> domain (36,318 clips), and (3) <em id="S4.SS2.p1.1.3" class="ltx_emph ltx_font_italic">both</em> domains (58,000 clips). We fine-tuned the models using each domain's training set and tested on the clinical domain test set to investigate the effect of out-of-domain accented data on model performance. Additionally, based on the benchmark results in Table <a href="#S3.T4" title="Table 4 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and GPU memory constraints, two top performing open-source model architectures, Whisper-medium <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and Wav2vec-large-xlsr-53 (XLSR-53) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, were selected for fine-tuning.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">XLSR-53 (378.9 M parameters) is an encoder-decoder architecture with a convolution-based feature extractor pre-trained using a self-supervised objective. Whisper-medium (789.9 M parameters) is a decoder-only multi-task architecture trained on over 680,000 hours of multilingual and multitask data using a weak supervision objective.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.2" class="ltx_p">Each model was fine-tuned using mixed-precision training, with the AdamW optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, a batch size of 16 for 10 epochs, using a linear learning rate decay after a warmup over the first 10 % of iterations. Learning rates of <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="1\mathrm{e}{-4}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mrow id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mrow id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml"><mn id="S4.SS2.p3.1.m1.1.1.2.2" xref="S4.SS2.p3.1.m1.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.1.m1.1.1.2.1" xref="S4.SS2.p3.1.m1.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS2.p3.1.m1.1.1.2.3" xref="S4.SS2.p3.1.m1.1.1.2.3.cmml">e</mi></mrow><mo id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.cmml">−</mo><mn id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><minus id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1"></minus><apply id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2"><times id="S4.SS2.p3.1.m1.1.1.2.1.cmml" xref="S4.SS2.p3.1.m1.1.1.2.1"></times><cn type="integer" id="S4.SS2.p3.1.m1.1.1.2.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2.2">1</cn><ci id="S4.SS2.p3.1.m1.1.1.2.3.cmml" xref="S4.SS2.p3.1.m1.1.1.2.3">e</ci></apply><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">1\mathrm{e}{-4}</annotation></semantics></math> and <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="2.5\mathrm{e}{-4}" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mrow id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml"><mn id="S4.SS2.p3.2.m2.1.1.2.2" xref="S4.SS2.p3.2.m2.1.1.2.2.cmml">2.5</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p3.2.m2.1.1.2.1" xref="S4.SS2.p3.2.m2.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.SS2.p3.2.m2.1.1.2.3" xref="S4.SS2.p3.2.m2.1.1.2.3.cmml">e</mi></mrow><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">−</mo><mn id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><minus id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1"></minus><apply id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2"><times id="S4.SS2.p3.2.m2.1.1.2.1.cmml" xref="S4.SS2.p3.2.m2.1.1.2.1"></times><cn type="float" id="S4.SS2.p3.2.m2.1.1.2.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2.2">2.5</cn><ci id="S4.SS2.p3.2.m2.1.1.2.3.cmml" xref="S4.SS2.p3.2.m2.1.1.2.3">e</ci></apply><cn type="integer" id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">2.5\mathrm{e}{-4}</annotation></semantics></math> were used for the XLSR-53 and Whisper models respectively. The XLSR-53 models were trained on a single Tesla T4 GPU with 16GB GPU memory while Whisper was trained on a RTX8000 GPU with 48GB GPU memory. In general, fine-tuning took between 24-48 hours for each model.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results and Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Benchmarking results on 19 open-source and commercial ASR systems, as well as our fine-tuning experiments, are presented in Table <a href="#S3.T4" title="Table 4 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Large multilingual models with web-scale training data generalize better</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The overarching trend favors ASR models like Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> that were trained on vast amounts of multilingual web-scale speech data. Their data diversity and pretraining objective confer better generalization capabilities to accented speech and the clinical domain, as evidenced by their lower WER and higher Recall on MNEs, outperforming ASR models trained on monolingual data by a wide margin.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>WER vs medical WER</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">As consistently observed across all pre-trained model families, M-WER was
relatively worse overall by 4-51 % than WER, empirically validating the performance gap on medical NEs. The only exception was GCP [Medical] where its M-WER was better,
demonstrating a trade-off in domain-specific fine-tuning.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Relative Performance across Entity Categories</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Although Whisper-large outperformed other open- and closed-source models on WER, its MNE Recall was still poor overall with 42 % for medications (<span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">MED</span>), 33 % for protected health information (<span id="S5.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">PHI</span>), 59 % for test treatment procedure (<span id="S5.SS3.p1.1.3" class="ltx_text ltx_font_typewriter">TTP</span>), and 67 % for medical conditions (<span id="S5.SS3.p1.1.4" class="ltx_text ltx_font_typewriter">COND</span>), falling far below its practical applicability in real-world clinical scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> due to the extent of required editing. Also, its 71 % Recall for anatomy (<span id="S5.SS3.p1.1.5" class="ltx_text ltx_font_typewriter">ANA</span>) may have resulted from the relative abundance of body parts like leg, brain, heart, liver, etc., in web-scale text.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Medical CER: Exact vs Approximate Match</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">As seen in Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Approach ‣ Performant ASR Models for Medical Entities in Accented Speech" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, medical WER sometimes unfairly penalized even the most minuscule ASR errors, e.g., quinidan vs quinidine, especially with multi-word entities, e.g., ``muscle relaxation'' vs ``mozul relaxition'', treating minor and severe ASR errors alike, a phenomenon that was not investigated in most prior works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. M-CER is complimentary in this regard, allowing us to better evaluate the severity of ASR misspellings. Also, lower M-CER helps to select the better of two ASR models with comparable WERs, like GCP [Medical] and AWS [Medical].</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Fine-tuning Results on General vs Clinical Domain</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">The fine-tuned models significantly improved on MNE Recall, WER, medical WER, and medical CER, as the models were better adapted to accented speech in the clinical domain. However, this is not a silver bullet. Our results show that fine-tuning the ASR models on the general domain accented speech alone, in fact, worsens the WER, M-WER, M-CER, and Recall on clinical speech. XLSR-53 fine-tuned on the clinical subset reduced WER by
35 %, M-WER by
31 %, and M-CER by
43 % relative to the general domain. Fine-tuning Whisper-medium on both domains
yielded the best results overall, improving WER by
54 %, M-WER by
48 %, and M-CER by
65 % relative to finetuning on the general domain only, suggesting that the ASR models still benefit from exposure to general-domain accented speech.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">ASR models, while beneficial, can risk patient safety and expose clinicians to liability through minor errors like mistranscribed drug names, doses, or diagnoses. Verification steps and spell-checkers can be integrated into the workflow to mitigate potential errors. Using automatically generated named entities instead of human annotation also introduces errors in entity identification. Automated systems can serve as initial annotation agents, with their outputs refined by domain experts. Lastly, the AfriSpeech-200 dataset often includes medical abbreviations (e.g., "Pt" for "Patient"), therefore, transcripts should be normalized for more accurate benchmarking.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This work highlights a noticeable disparity between general and medical WER for many SOTA ASR models, pointing to challenges in accurately recognizing accented medical named entities. Fine-tuning these models with domain-specific data was beneficial in addressing some of these issues, indicating that tailored fine-tuning can enhance ASR performance in healthcare.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Acknowledgements</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">We appreciate the invaluable support from Intron Health for contributing the dataset and compute for experiments. Tejumade Afonja is partially supported by ELSA – European Lighthouse on Secure and Safe AI funded by the European Union under grant agreement No. 101070617.
We appreciate the support provided by the BioRAMP researchers, whose collaboration and insights have been fundamental to our research.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever,
``Robust speech recognition via large-scale weak supervision,'' in
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.   PMLR, 2023, pp. 28 492–28 518.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
W.-N. Hsu, B. Bolte, Y.-H. H. Tsai, K. Lakhotia, R. Salakhutdinov, and
A. Mohamed, ``HuBERT: Self-supervised speech representation learning by
masked prediction of hidden units,'' <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio,
Speech, and Language Processing</em>, vol. 29, pp. 3451–3460, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Baevski, Y. Zhou, A. Mohamed, and M. Auli, ``wav2vec 2.0: A framework for
self-supervised learning of speech representations,'' <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Advances in
neural information processing systems</em>, vol. 33, pp. 12 449–12 460, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T. Olatunji, T. Afonja, A. Yadavalli, C. C. Emezue, S. Singh, B. F. Dossou,
J. Osuchukwu, S. Osei, A. L. Tonja, N. Etori <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
``AfriSpeech-200: Pan-African accented speech dataset for clinical and
general domain ASR,'' <em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">Transactions of the Association for
Computational Linguistics</em>, vol. 11, pp. 1669–1685, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S. Ajami, ``Use of speech-to-text technology for documentation by healthcare
providers,'' <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">The National medical journal of India</em>, vol. 29, no. 3, p.
148, 2016.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T. Olatunji, T. Afonja, B. F. P. Dossou, A. L. Tonja, C. C. Emezue, A. M.
Rufai, and S. Singh, ``AfriNames: Most ASR Models "Butcher" African
Names,'' in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2023, pp. 5077–5081.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Adedeji, S. Joshi, and B. Doohan, ``The sound of healthcare: Improving
medical transcription ASR accuracy with large language models,'' 2024.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Jiang and C. Poellabauer, ``A sequence-to-sequence based error correction
model for medical automatic speech recognition,'' in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">International
Conference on Bioinformatics and Biomedicine (BIBM)</em>.   IEEE, 2021, pp. 3029–3035.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
P. Bhatia, B. Celikkaya, M. Khalilia, and S. Senthivel, ``Comprehend Medical:
A named entity recognition and relationship extraction web service,'' in
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">International Conference On Machine Learning And Applications
(ICMLA)</em>.   IEEE, 2019, pp. 1844–1851.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y. Zhou, C. Ju, J. H. Caufield, K. Shih, C. Chen, Y. Sun, K.-W. Chang, P. Ping,
and W. Wang, ``Clinical named entity recognition using contextualized token
representations,'' <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.12608</em>, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H. Suominen, L. Zhou, L. Hanlen, G. Ferraro <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Benchmarking
clinical speech recognition and information extraction: new data, methods,
and evaluations,'' <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">JMIR medical informatics</em>, vol. 3, no. 2, p. e4321,
2015.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
V. Kocaman and D. Talby, ``Accurate clinical and biomedical named entity
recognition at scale,'' <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Software Impacts</em>, vol. 13, p. 100373, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y. Hu, Q. Chen, J. Du, X. Peng, V. K. Keloth, X. Zuo, Y. Zhou, Z. Li, X. Jiang,
Z. Lu <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Improving large language models for clinical named
entity recognition via prompt engineering,'' <em id="bib.bib13.2.2" class="ltx_emph ltx_font_italic">Journal of the American
Medical Informatics Association</em>, p. ocad259, 2024.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
C.-Y. Lin, ``ROUGE: A package for automatic evaluation of summaries,'' in
<em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Text Summarization Branches Out</em>.   Barcelona, Spain: Association for Computational Linguistics, Jul.
2004, pp. 74–81. [Online]. Available:
<a target="_blank" href="https://aclanthology.org/W04-1013" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/W04-1013</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A. Babu, C. Wang, A. Tjandra, K. Lakhotia, Q. Xu, N. Goyal, K. Singh, P. von
Platen, Y. Saraf, J. M. Pino, A. Baevski, A. Conneau, and M. Auli, ``XLS-R:
Self-supervised cross-lingual speech representation learning at scale,'' in
<em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
S. Chen, C. Wang, Z. Chen, Y. Wu, S. Liu, Z. Chen, J. Li, N. Kanda,
T. Yoshioka, X. Xiao <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``WavLM: Large-scale self-supervised
pre-training for full stack speech processing,'' <em id="bib.bib16.2.2" class="ltx_emph ltx_font_italic">IEEE Journal of
Selected Topics in Signal Processing</em>, vol. 16, no. 6, pp. 1505–1518, 2022.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
``Cloud computing services: Microsoft Azure. Cloud Computing Services |
Microsoft Azure. (n.d.).'' <a target="_blank" href="https://azure.microsoft.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://azure.microsoft.com/</a>, accessed:
2024-03-01.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
``Cloud Computing Services - Amazon Web Services (AWS),''
<a target="_blank" href="https://aws.amazon.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aws.amazon.com</a>, accessed: 2024-03-01.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
``Cloud Computing Services | Google Cloud,'' <a target="_blank" href="https://cloud.google.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cloud.google.com/</a>,
accessed: 2024-03-01.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi, P. Cistac,
T. Rault, R. Louf, M. Funtowicz, J. Davison, S. Shleifer, P. von Platen,
C. Ma, Y. Jernite, J. Plu, C. Xu, T. L. Scao, S. Gugger, M. Drame, Q. Lhoest,
and A. M. Rush, ``Transformers: State-of-the-art natural language
processing,'' in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing: System Demonstrations</em>.   Online: Association for Computational
Linguistics, Oct. 2020, pp. 38–45. [Online]. Available:
<a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-demos.6" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-demos.6</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Grosman, ``Fine-tuned XLSR-53 large model for speech recognition in
English,''
<a target="_blank" href="https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english</a>,
2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
I. Loshchilov and F. Hutter, ``Decoupled weight decay regularization,'' in
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2018.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
E. Luchies, M. Spruit, and M. Askari, ``Speech technology in Dutch health
care: A qualitative study.'' in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">HEALTHINF</em>, 2018, pp. 339–348.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.12386" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.12387" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.12387">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.12387" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.12388" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 18:43:48 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
