<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.10904] Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition</title><meta property="og:description" content="Human communication is multi-modal; e.g., face-to-face interaction involves auditory signals (speech) and visual signals (face movements and hand gestures). Hence, it is essential to exploit multiple modalities when de…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.10904">

<!--Generated on Sun May  5 22:41:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marah Halawa<sup id="id1.1.id1" class="ltx_sup">1,4</sup> , Florian Blume<sup id="id2.2.id2" class="ltx_sup">1,4</sup><span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span> , Pia Bideau<sup id="id3.3.id3" class="ltx_sup">2</sup>, Martin Maier<sup id="id4.4.id4" class="ltx_sup">3,4</sup>
<br class="ltx_break">Rasha Abdel Rahman<sup id="id5.5.id5" class="ltx_sup">3,4</sup>, Olaf Hellwich<sup id="id6.6.id6" class="ltx_sup">1,4</sup>
<br class="ltx_break"><sup id="id7.7.id7" class="ltx_sup">1</sup>Technische Universität Berlin, <sup id="id8.8.id8" class="ltx_sup">2</sup>Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 
<br class="ltx_break"><sup id="id9.9.id9" class="ltx_sup">3</sup>Humboldt-Universität zu Berlin,
<sup id="id10.10.id10" class="ltx_sup">4</sup>Science of Intelligence, Research Cluster of Excellence, Berlin
<br class="ltx_break"><span id="id11.11.id11" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{marah.halawa, florian.blume, olaf.hellwich}@tu-berlin.de
<br class="ltx_break">{pia.bideau}@inria.fr, {martin.maier, rasha.abdel.rahman}@hu-berlin.de</span>
</span><span class="ltx_author_notes">equal contribution</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id12.id1" class="ltx_p">Human communication is multi-modal; <em id="id12.id1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="id12.id1.2" class="ltx_text"></span>, face-to-face interaction involves auditory signals (speech) and visual signals (face movements and hand gestures). Hence, it is essential to exploit multiple modalities when designing machine learning-based facial expression recognition systems. In addition, given the ever-growing quantities of video data that capture human facial expressions, such systems should utilize raw unlabeled videos without requiring expensive annotations. Therefore, in this work, we employ a multi-task multi-modal self-supervised learning method for facial expression recognition from in-the-wild video data. Our model combines three self-supervised objective functions: First, a multi-modal contrastive loss, that pulls diverse data modalities of the same video together in the representation space. Second, a multi-modal clustering loss that preserves the semantic structure of input data in the representation space. Finally, a multi-modal data reconstruction loss. We conduct a comprehensive study on this multi-modal multi-task self-supervised learning method on three facial expression recognition benchmarks. To that end, we examine the performance of learning through different combinations of self-supervised tasks on the facial expression recognition downstream task. Our model <span id="id12.id1.3" class="ltx_text ltx_font_bold">ConCluGen</span> outperforms several multi-modal self-supervised and fully supervised baselines on the <span title="" class="ltx_glossaryref">CMU-MOSEI</span> dataset. Our results generally show that multi-modal self-supervision tasks offer large performance gains for challenging tasks such as facial expression recognition, while also reducing the amount of manual annotations required. We release our pre-trained models as well as source code publicly <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/tub-cv-group/conclugen</span></span></span>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span title="" class="ltx_glossaryref">Facial expression recognition (FER)</span> is a fundamental task for successful everyday human social interaction, and human-computer interaction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite>. Rooted in the context-sensitive and top-down manner of human perception, how we perceive an expression can change with (affective) context and prior knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>, <a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, and other various other factors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>]</cite>. The same facial expression can be perceived differently depending on the situation and context <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>. A recent review from <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Maier et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>]</cite> highlights that to develop <span title="" class="ltx_glossaryref">FER</span> systems that align with human perception, we should consider contextual cues along with social knowledge. From a human perspective, context is inherently multi-modal, not just what is visually perceptible, as often previously treated in computer vision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>, <a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Over the last decade, deep learning aproaches have advanced the field of artificial intelligence by utilizing the massive amounts of data generated daily, <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.p2.1.2" class="ltx_text"></span> on the internet. Large quantities of such data are multimodal, such as videos. Even though real-world (in the wild) video data helps train deeper machine-learning models, it also presents multiple challenges. Such data is usually imbalanced, noisy, and, most importantly, unlabeled. Therefore, research in deep learning and computer vision directs attention toward self-supervised learning algorithms, that aim to learn rich data representations without the need for manual labeling processes. Self-supervised learning is a form of unsupervised representation learning where the labels are extracted from the data itself, enabling label-efficient feature learning. Subsequently, the resulting models after the self-supervised learning phase can be used or adapted to downstream tasks, such as facial expression recognition. Given the growing amounts of video data that capture human facial expressions, self-supervision may allow for learning data representations from raw unlabeled video samples.
Nevertheless, as mentioned above, <span title="" class="ltx_glossaryref">FER</span> is a challenging task that requires the integration of multi-modal contexts to align with human-level perception, since people their feelings across different modalities (visually, orally, and in other ways). Thus, not only is it essential to include these multiple modalities in learning algorithmss, but we also need to effectively model the interactions across these modalities to enhance <span title="" class="ltx_glossaryref">FER</span>. In this work, we introduce a multi-task multi-modal self-supervised approach for <span title="" class="ltx_glossaryref">FER</span>. Employing multiple tasks for self-supervision allows for learning more informative data representations, as each task enhances a certain property in the learned features, and integrating these tasks allows for capturing these complementary properties in the resulting embedding space.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Contributions</span>. The main contributions in this paper are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">To the best of our knowledge we are the first to employ multi-task multi-modal self-supervised methods for <span title="" class="ltx_glossaryref">FER</span>.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Our multi-modal multi-task self-supervised model <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">ConCluGen</span> (see <a href="#S3.F1" title="In 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>) outperforms multiple self-supervised and fully supervised models on <span title="" class="ltx_glossaryref">FER</span>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We provide a comprehensive study on multiple self-supervised learning methods for <span title="" class="ltx_glossaryref">FER</span>.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We make all self-supervised models (multi-modal and uni-modal) presented in this study publicly available to the research community as baselines for future studies.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Self-Supervised Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Over the last years, self-supervised learning methods advanced the research in different fields <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">43</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>, <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite>, especially in computer vision applications where the amount of unlabeled data is increased rapidly due to social media, <em id="S2.SS1.p1.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S2.SS1.p1.1.2" class="ltx_text"></span> YouTube videos, TikTok, and TV-series. The reason is that with self-supervised learning methods, we can learn robust feature representation for the input data without the need for annotations. Such approaches generate the labels for the pretext task automatically from the data itself <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite>. Different types of self-supervised methods have been developed: Some are predictive (also called generative) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite>, <em id="S2.SS1.p1.1.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S2.SS1.p1.1.4" class="ltx_text"></span> anticipate and/or generate some parts of the data from another part of the data. The others are contrastive, which aim to anticipate the relations between data samples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>. Some utilize one modality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite>, while others draw on multiple modalities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite>. In this paper, we examine different self-supervised approaches and show that especially for complex computer vision applications, such as <span title="" class="ltx_glossaryref">FER</span>, models can benefit from utilizing multi-modal data in the self-supervised learning techniques.
<br class="ltx_break"></p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Instance-Level Contrastive Learning.</span>
Instance-level contrastive learning has been used in multiple domains to improve learned representations from unlabeled data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite>. The main goal of such algorithms is to pull representations of similar objects together and push dissimilar objects far away from each other. Despite recent achievements of instance-level contrastive methods in multiple domains, they still suffer from downsides such as class collision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite>. In downstream classification tasks, instance-level contrastive learning methods lose semantic similarity between images from the same class. To mitigate this effect, some research used graph-based methods with weak supervision to pull similar instances closer to each other <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite>. Others used domain knowledge to create semantically aware positive and negative sets for contrastive learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite>. Moreover, some research focuses on introducing special augmentation techniques that can directly improve a specific downstream task performance rather than focusing on the generality of the self-supervised pre-trained model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite>. Additionally, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Doersch and Zisserman</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite> study multi-task self-supervised learning for visual representation learning. They jointly learn four simple but diverse self-supervised methods (motion segmentation, colorization, Exemplar task, and relative position).
In this paper, we study different self-supervised methods for <span title="" class="ltx_glossaryref">FER</span>. We also study multi-task self-supervised learning, but in different combinations compared to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>. We also focus more on multi-modality in multi-task self-supervised learning. 
<br class="ltx_break"></p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Multi-Modal Self-Supervised Learning.</span>
Self-supervised learning techniques have also advanced multi-modal learning. In such an environment, the model can draw on different data modalities to learn robust representation. Some research applies contrastive techniques in a multi-modal setting for multiple modalities together <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite>, or from two modalities as in CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite> that was first employed for text and audio representation learning, or to learn from visual and audio <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">42</span></a>]</cite>. Moreover, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Taleb et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite> applied a multi-modal self-supervised approach on genetic modalities, and <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Franceschini et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite> utilize facial landmarks as an additional modality for <span title="" class="ltx_glossaryref">FER</span> in videos. Additionally, a body of research work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>, <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> supports multi-modal contrastive learning with multi-modal clustering to ensure that semantically similar modalities are represented close to each other in the embedding space. In this paper, we follow the same direction in our ConCluGen and ConClu models (<a href="#S3.SS6" title="3.6 Multi-Task Self-Supervised Learning ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.6</span></a>). To the best of our knowledge, we are the first to apply such a technique for <span title="" class="ltx_glossaryref">FER</span>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Facial Expression Recognition</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p"><span title="" class="ltx_glossaryref">FER</span> is a challenging task in computer vision for multiple reasons, such as overlapping with other facial features such as identity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite>, and overlapping between multiple expression labels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>. Some research focuses on disentangling expression features from other facial features in the input images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite>. Other research focuses on learning a multi-modal representation for the <span title="" class="ltx_glossaryref">FER</span>. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Siriwardhana et al.</span></a></cite> introduced a multi-modal deep learning model for <span title="" class="ltx_glossaryref">FER</span> with a mechanism for the late fusion of multi-modal SSL features. The proposed technique is based on transformers and attention mechanisms. Our model differs from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> in that we learn a joint representation space for all input modalities. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>, the authors used a pairwise contrastive objective function inspired by CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite> to learn unsupervised multi-modal representations from video data paired with text, audio, and facial landmarks. Our model is different from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite> in that we preserve the semantic similarity between all modalities by learning a multi-modal clustering objective that regularizes the pairwise multi-modal contrastive objective.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Other works focus on the late fusion techniques to fuse different representations from different input modalities efficiently into one multi-modal representation that is free of redundant information. The latter is less prone to overfitting in the prediction task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite>. To the best of our knowledge, we are the first to study multi-task multi-modal self-supervised learning for <span title="" class="ltx_glossaryref">FER</span>. In this work, we study the combination of multiple self-supervised losses, including multi-modal contrastive learning with clustering, instance-based contrastive learning, and generative self-supervised learning.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2404.10904/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="176" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.4.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.5.2" class="ltx_text" style="font-size:90%;">Overview of the architecture of the multi-task multi-modal self-supervised method. The backbone feature extractors process the input modalities in blocks, which we average over the time domain. The resulting temporal features are stored on disk, <em id="S3.F1.5.2.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.F1.5.2.2" class="ltx_text"></span> the backbones are fully fixed. The 3-layer <span title="" class="ltx_glossaryref">representation head</span> produces the representations we want to use in downstream training. The three losses are: (a) A reconstruction loss which reconstructs the features of each modality individually. (b) The multi-modal contrastive loss encourages the representations from the projection head for modalities belonging to the same input to be represented closer to each other. (c) The multi-modal clustering loss which drives the modalities of a sample towards the centroids computed by k-means clustering. The latter uses the mean of the modalities to compute these centroids.</span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we will explain the self-supervised pre-training techniques that we adopt in this work. Then we will explain our multi-task multimodal self-supervised model.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Formulation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.24" class="ltx_p">Each input is an utterance that consists of a segment of a video as a sequence of frames <math id="S3.SS1.p1.1.m1.3" class="ltx_Math" alttext="V=\left(\mathbf{v_{1}},\dotsc,\mathbf{v_{n}}\right)" display="inline"><semantics id="S3.SS1.p1.1.m1.3a"><mrow id="S3.SS1.p1.1.m1.3.3" xref="S3.SS1.p1.1.m1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.3.3.4" xref="S3.SS1.p1.1.m1.3.3.4.cmml">V</mi><mo id="S3.SS1.p1.1.m1.3.3.3" xref="S3.SS1.p1.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.3.3.2.2" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml"><mo id="S3.SS1.p1.1.m1.3.3.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">(</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml">𝐯</mi><mn id="S3.SS1.p1.1.m1.2.2.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.cmml">𝟏</mn></msub><mo id="S3.SS1.p1.1.m1.3.3.2.2.4" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.p1.1.m1.3.3.2.2.5" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p1.1.m1.3.3.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.1.m1.3.3.2.2.2.2" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml">𝐯</mi><mi id="S3.SS1.p1.1.m1.3.3.2.2.2.3" xref="S3.SS1.p1.1.m1.3.3.2.2.2.3.cmml">𝐧</mi></msub><mo id="S3.SS1.p1.1.m1.3.3.2.2.6" xref="S3.SS1.p1.1.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.3b"><apply id="S3.SS1.p1.1.m1.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3"><eq id="S3.SS1.p1.1.m1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3.3"></eq><ci id="S3.SS1.p1.1.m1.3.3.4.cmml" xref="S3.SS1.p1.1.m1.3.3.4">𝑉</ci><vector id="S3.SS1.p1.1.m1.3.3.2.3.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2"><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2">𝐯</ci><cn type="integer" id="S3.SS1.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">…</ci><apply id="S3.SS1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.2">𝐯</ci><ci id="S3.SS1.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.3.3.2.2.2.3">𝐧</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.3c">V=\left(\mathbf{v_{1}},\dotsc,\mathbf{v_{n}}\right)</annotation></semantics></math>, a corresponding audio spectrum <math id="S3.SS1.p1.2.m2.3" class="ltx_Math" alttext="A=\left(\mathbf{a_{1}},\dotsc,\mathbf{a_{m}}\right)" display="inline"><semantics id="S3.SS1.p1.2.m2.3a"><mrow id="S3.SS1.p1.2.m2.3.3" xref="S3.SS1.p1.2.m2.3.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.4" xref="S3.SS1.p1.2.m2.3.3.4.cmml">A</mi><mo id="S3.SS1.p1.2.m2.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.2.m2.3.3.2.2" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml"><mo id="S3.SS1.p1.2.m2.3.3.2.2.3" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml">(</mo><msub id="S3.SS1.p1.2.m2.2.2.1.1.1" xref="S3.SS1.p1.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.2.2.1.1.1.2" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2.cmml">𝐚</mi><mn id="S3.SS1.p1.2.m2.2.2.1.1.1.3" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml">𝟏</mn></msub><mo id="S3.SS1.p1.2.m2.3.3.2.2.4" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">…</mi><mo id="S3.SS1.p1.2.m2.3.3.2.2.5" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p1.2.m2.3.3.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.2.m2.3.3.2.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2.cmml">𝐚</mi><mi id="S3.SS1.p1.2.m2.3.3.2.2.2.3" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml">𝐦</mi></msub><mo id="S3.SS1.p1.2.m2.3.3.2.2.6" xref="S3.SS1.p1.2.m2.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.3b"><apply id="S3.SS1.p1.2.m2.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3"><eq id="S3.SS1.p1.2.m2.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3"></eq><ci id="S3.SS1.p1.2.m2.3.3.4.cmml" xref="S3.SS1.p1.2.m2.3.3.4">𝐴</ci><vector id="S3.SS1.p1.2.m2.3.3.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2"><apply id="S3.SS1.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.2">𝐚</ci><cn type="integer" id="S3.SS1.p1.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">…</ci><apply id="S3.SS1.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.2">𝐚</ci><ci id="S3.SS1.p1.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2.3">𝐦</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.3c">A=\left(\mathbf{a_{1}},\dotsc,\mathbf{a_{m}}\right)</annotation></semantics></math>, and a corresponding text subtitle <math id="S3.SS1.p1.3.m3.3" class="ltx_Math" alttext="T=\left(\mathbf{t_{1}},\dotsc,\mathbf{t_{k}}\right)" display="inline"><semantics id="S3.SS1.p1.3.m3.3a"><mrow id="S3.SS1.p1.3.m3.3.3" xref="S3.SS1.p1.3.m3.3.3.cmml"><mi id="S3.SS1.p1.3.m3.3.3.4" xref="S3.SS1.p1.3.m3.3.3.4.cmml">T</mi><mo id="S3.SS1.p1.3.m3.3.3.3" xref="S3.SS1.p1.3.m3.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.3.m3.3.3.2.2" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml"><mo id="S3.SS1.p1.3.m3.3.3.2.2.3" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml">(</mo><msub id="S3.SS1.p1.3.m3.2.2.1.1.1" xref="S3.SS1.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.3.m3.2.2.1.1.1.2" xref="S3.SS1.p1.3.m3.2.2.1.1.1.2.cmml">𝐭</mi><mn id="S3.SS1.p1.3.m3.2.2.1.1.1.3" xref="S3.SS1.p1.3.m3.2.2.1.1.1.3.cmml">𝟏</mn></msub><mo id="S3.SS1.p1.3.m3.3.3.2.2.4" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">…</mi><mo id="S3.SS1.p1.3.m3.3.3.2.2.5" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p1.3.m3.3.3.2.2.2" xref="S3.SS1.p1.3.m3.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.3.m3.3.3.2.2.2.2" xref="S3.SS1.p1.3.m3.3.3.2.2.2.2.cmml">𝐭</mi><mi id="S3.SS1.p1.3.m3.3.3.2.2.2.3" xref="S3.SS1.p1.3.m3.3.3.2.2.2.3.cmml">𝐤</mi></msub><mo id="S3.SS1.p1.3.m3.3.3.2.2.6" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.3b"><apply id="S3.SS1.p1.3.m3.3.3.cmml" xref="S3.SS1.p1.3.m3.3.3"><eq id="S3.SS1.p1.3.m3.3.3.3.cmml" xref="S3.SS1.p1.3.m3.3.3.3"></eq><ci id="S3.SS1.p1.3.m3.3.3.4.cmml" xref="S3.SS1.p1.3.m3.3.3.4">𝑇</ci><vector id="S3.SS1.p1.3.m3.3.3.2.3.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2"><apply id="S3.SS1.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1.1.2">𝐭</ci><cn type="integer" id="S3.SS1.p1.3.m3.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">…</ci><apply id="S3.SS1.p1.3.m3.3.3.2.2.2.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2.2">𝐭</ci><ci id="S3.SS1.p1.3.m3.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2.3">𝐤</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.3c">T=\left(\mathbf{t_{1}},\dotsc,\mathbf{t_{k}}\right)</annotation></semantics></math>. The task is first to learn a rich representation for the input in an unsupervised manner, then predict the facial expression class of the corresponding input video. Due to the unsupervised nature of our approach, we can build a <span title="" class="ltx_glossaryref">FER</span> model without the need for a huge dataset. We evaluate the following self-supervised methods on both multi-label and single-label <span title="" class="ltx_glossaryref">FER</span> using three datasets. Note that that both pretext and downstream tasks are independent. Each input instance <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">I</annotation></semantics></math> is represented by a triple input <math id="S3.SS1.p1.5.m5.3" class="ltx_Math" alttext="(\mathbf{v_{i}},\mathbf{t_{i}},\mathbf{a_{i}})" display="inline"><semantics id="S3.SS1.p1.5.m5.3a"><mrow id="S3.SS1.p1.5.m5.3.3.3" xref="S3.SS1.p1.5.m5.3.3.4.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m5.3.3.3.4" xref="S3.SS1.p1.5.m5.3.3.4.cmml">(</mo><msub id="S3.SS1.p1.5.m5.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.1.1.2" xref="S3.SS1.p1.5.m5.1.1.1.1.2.cmml">𝐯</mi><mi id="S3.SS1.p1.5.m5.1.1.1.1.3" xref="S3.SS1.p1.5.m5.1.1.1.1.3.cmml">𝐢</mi></msub><mo id="S3.SS1.p1.5.m5.3.3.3.5" xref="S3.SS1.p1.5.m5.3.3.4.cmml">,</mo><msub id="S3.SS1.p1.5.m5.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.cmml">𝐭</mi><mi id="S3.SS1.p1.5.m5.2.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.2.2.3.cmml">𝐢</mi></msub><mo id="S3.SS1.p1.5.m5.3.3.3.6" xref="S3.SS1.p1.5.m5.3.3.4.cmml">,</mo><msub id="S3.SS1.p1.5.m5.3.3.3.3" xref="S3.SS1.p1.5.m5.3.3.3.3.cmml"><mi id="S3.SS1.p1.5.m5.3.3.3.3.2" xref="S3.SS1.p1.5.m5.3.3.3.3.2.cmml">𝐚</mi><mi id="S3.SS1.p1.5.m5.3.3.3.3.3" xref="S3.SS1.p1.5.m5.3.3.3.3.3.cmml">𝐢</mi></msub><mo stretchy="false" id="S3.SS1.p1.5.m5.3.3.3.7" xref="S3.SS1.p1.5.m5.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.3b"><vector id="S3.SS1.p1.5.m5.3.3.4.cmml" xref="S3.SS1.p1.5.m5.3.3.3"><apply id="S3.SS1.p1.5.m5.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.2">𝐯</ci><ci id="S3.SS1.p1.5.m5.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3">𝐢</ci></apply><apply id="S3.SS1.p1.5.m5.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.2.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2">𝐭</ci><ci id="S3.SS1.p1.5.m5.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.3">𝐢</ci></apply><apply id="S3.SS1.p1.5.m5.3.3.3.3.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.3.3.3.3.1.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.3.3.3.3.2.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3.2">𝐚</ci><ci id="S3.SS1.p1.5.m5.3.3.3.3.3.cmml" xref="S3.SS1.p1.5.m5.3.3.3.3.3">𝐢</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.3c">(\mathbf{v_{i}},\mathbf{t_{i}},\mathbf{a_{i}})</annotation></semantics></math> where <math id="S3.SS1.p1.6.m6.2" class="ltx_Math" alttext="i\in\left\{0,N\right\}" display="inline"><semantics id="S3.SS1.p1.6.m6.2a"><mrow id="S3.SS1.p1.6.m6.2.3" xref="S3.SS1.p1.6.m6.2.3.cmml"><mi id="S3.SS1.p1.6.m6.2.3.2" xref="S3.SS1.p1.6.m6.2.3.2.cmml">i</mi><mo id="S3.SS1.p1.6.m6.2.3.1" xref="S3.SS1.p1.6.m6.2.3.1.cmml">∈</mo><mrow id="S3.SS1.p1.6.m6.2.3.3.2" xref="S3.SS1.p1.6.m6.2.3.3.1.cmml"><mo id="S3.SS1.p1.6.m6.2.3.3.2.1" xref="S3.SS1.p1.6.m6.2.3.3.1.cmml">{</mo><mn id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">0</mn><mo id="S3.SS1.p1.6.m6.2.3.3.2.2" xref="S3.SS1.p1.6.m6.2.3.3.1.cmml">,</mo><mi id="S3.SS1.p1.6.m6.2.2" xref="S3.SS1.p1.6.m6.2.2.cmml">N</mi><mo id="S3.SS1.p1.6.m6.2.3.3.2.3" xref="S3.SS1.p1.6.m6.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.2b"><apply id="S3.SS1.p1.6.m6.2.3.cmml" xref="S3.SS1.p1.6.m6.2.3"><in id="S3.SS1.p1.6.m6.2.3.1.cmml" xref="S3.SS1.p1.6.m6.2.3.1"></in><ci id="S3.SS1.p1.6.m6.2.3.2.cmml" xref="S3.SS1.p1.6.m6.2.3.2">𝑖</ci><set id="S3.SS1.p1.6.m6.2.3.3.1.cmml" xref="S3.SS1.p1.6.m6.2.3.3.2"><cn type="integer" id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">0</cn><ci id="S3.SS1.p1.6.m6.2.2.cmml" xref="S3.SS1.p1.6.m6.2.2">𝑁</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.2c">i\in\left\{0,N\right\}</annotation></semantics></math> and <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">N</annotation></semantics></math> is the total number of input samples. We learn a representation for each modality by mapping each input modality to a lower dimensional space using three separate encoders as follows: A video encoder <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="F_{v}(\mathbf{v})\Rightarrow\mathbf{D_{v}}" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mrow id="S3.SS1.p1.8.m8.1.2" xref="S3.SS1.p1.8.m8.1.2.cmml"><mrow id="S3.SS1.p1.8.m8.1.2.2" xref="S3.SS1.p1.8.m8.1.2.2.cmml"><msub id="S3.SS1.p1.8.m8.1.2.2.2" xref="S3.SS1.p1.8.m8.1.2.2.2.cmml"><mi id="S3.SS1.p1.8.m8.1.2.2.2.2" xref="S3.SS1.p1.8.m8.1.2.2.2.2.cmml">F</mi><mi id="S3.SS1.p1.8.m8.1.2.2.2.3" xref="S3.SS1.p1.8.m8.1.2.2.2.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.8.m8.1.2.2.1" xref="S3.SS1.p1.8.m8.1.2.2.1.cmml">​</mo><mrow id="S3.SS1.p1.8.m8.1.2.2.3.2" xref="S3.SS1.p1.8.m8.1.2.2.cmml"><mo stretchy="false" id="S3.SS1.p1.8.m8.1.2.2.3.2.1" xref="S3.SS1.p1.8.m8.1.2.2.cmml">(</mo><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">𝐯</mi><mo stretchy="false" id="S3.SS1.p1.8.m8.1.2.2.3.2.2" xref="S3.SS1.p1.8.m8.1.2.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.8.m8.1.2.1" xref="S3.SS1.p1.8.m8.1.2.1.cmml">⇒</mo><msub id="S3.SS1.p1.8.m8.1.2.3" xref="S3.SS1.p1.8.m8.1.2.3.cmml"><mi id="S3.SS1.p1.8.m8.1.2.3.2" xref="S3.SS1.p1.8.m8.1.2.3.2.cmml">𝐃</mi><mi id="S3.SS1.p1.8.m8.1.2.3.3" xref="S3.SS1.p1.8.m8.1.2.3.3.cmml">𝐯</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.2.cmml" xref="S3.SS1.p1.8.m8.1.2"><ci id="S3.SS1.p1.8.m8.1.2.1.cmml" xref="S3.SS1.p1.8.m8.1.2.1">⇒</ci><apply id="S3.SS1.p1.8.m8.1.2.2.cmml" xref="S3.SS1.p1.8.m8.1.2.2"><times id="S3.SS1.p1.8.m8.1.2.2.1.cmml" xref="S3.SS1.p1.8.m8.1.2.2.1"></times><apply id="S3.SS1.p1.8.m8.1.2.2.2.cmml" xref="S3.SS1.p1.8.m8.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.2.2.2.1.cmml" xref="S3.SS1.p1.8.m8.1.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.2.2.2.2.cmml" xref="S3.SS1.p1.8.m8.1.2.2.2.2">𝐹</ci><ci id="S3.SS1.p1.8.m8.1.2.2.2.3.cmml" xref="S3.SS1.p1.8.m8.1.2.2.2.3">𝑣</ci></apply><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">𝐯</ci></apply><apply id="S3.SS1.p1.8.m8.1.2.3.cmml" xref="S3.SS1.p1.8.m8.1.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.2.3.1.cmml" xref="S3.SS1.p1.8.m8.1.2.3">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.2.3.2.cmml" xref="S3.SS1.p1.8.m8.1.2.3.2">𝐃</ci><ci id="S3.SS1.p1.8.m8.1.2.3.3.cmml" xref="S3.SS1.p1.8.m8.1.2.3.3">𝐯</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">F_{v}(\mathbf{v})\Rightarrow\mathbf{D_{v}}</annotation></semantics></math> that maps each video frame sequence to lower dimensional <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="\mathbf{D_{v}}" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><msub id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml">𝐯</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">𝐃</ci><ci id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3">𝐯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">\mathbf{D_{v}}</annotation></semantics></math>. A text encoder <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="F_{t}(\mathbf{t})\Rightarrow\mathbf{D_{t}}" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mrow id="S3.SS1.p1.10.m10.1.2" xref="S3.SS1.p1.10.m10.1.2.cmml"><mrow id="S3.SS1.p1.10.m10.1.2.2" xref="S3.SS1.p1.10.m10.1.2.2.cmml"><msub id="S3.SS1.p1.10.m10.1.2.2.2" xref="S3.SS1.p1.10.m10.1.2.2.2.cmml"><mi id="S3.SS1.p1.10.m10.1.2.2.2.2" xref="S3.SS1.p1.10.m10.1.2.2.2.2.cmml">F</mi><mi id="S3.SS1.p1.10.m10.1.2.2.2.3" xref="S3.SS1.p1.10.m10.1.2.2.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.10.m10.1.2.2.1" xref="S3.SS1.p1.10.m10.1.2.2.1.cmml">​</mo><mrow id="S3.SS1.p1.10.m10.1.2.2.3.2" xref="S3.SS1.p1.10.m10.1.2.2.cmml"><mo stretchy="false" id="S3.SS1.p1.10.m10.1.2.2.3.2.1" xref="S3.SS1.p1.10.m10.1.2.2.cmml">(</mo><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">𝐭</mi><mo stretchy="false" id="S3.SS1.p1.10.m10.1.2.2.3.2.2" xref="S3.SS1.p1.10.m10.1.2.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.10.m10.1.2.1" xref="S3.SS1.p1.10.m10.1.2.1.cmml">⇒</mo><msub id="S3.SS1.p1.10.m10.1.2.3" xref="S3.SS1.p1.10.m10.1.2.3.cmml"><mi id="S3.SS1.p1.10.m10.1.2.3.2" xref="S3.SS1.p1.10.m10.1.2.3.2.cmml">𝐃</mi><mi id="S3.SS1.p1.10.m10.1.2.3.3" xref="S3.SS1.p1.10.m10.1.2.3.3.cmml">𝐭</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.2.cmml" xref="S3.SS1.p1.10.m10.1.2"><ci id="S3.SS1.p1.10.m10.1.2.1.cmml" xref="S3.SS1.p1.10.m10.1.2.1">⇒</ci><apply id="S3.SS1.p1.10.m10.1.2.2.cmml" xref="S3.SS1.p1.10.m10.1.2.2"><times id="S3.SS1.p1.10.m10.1.2.2.1.cmml" xref="S3.SS1.p1.10.m10.1.2.2.1"></times><apply id="S3.SS1.p1.10.m10.1.2.2.2.cmml" xref="S3.SS1.p1.10.m10.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.2.2.2.1.cmml" xref="S3.SS1.p1.10.m10.1.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.10.m10.1.2.2.2.2.cmml" xref="S3.SS1.p1.10.m10.1.2.2.2.2">𝐹</ci><ci id="S3.SS1.p1.10.m10.1.2.2.2.3.cmml" xref="S3.SS1.p1.10.m10.1.2.2.2.3">𝑡</ci></apply><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">𝐭</ci></apply><apply id="S3.SS1.p1.10.m10.1.2.3.cmml" xref="S3.SS1.p1.10.m10.1.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.2.3.1.cmml" xref="S3.SS1.p1.10.m10.1.2.3">subscript</csymbol><ci id="S3.SS1.p1.10.m10.1.2.3.2.cmml" xref="S3.SS1.p1.10.m10.1.2.3.2">𝐃</ci><ci id="S3.SS1.p1.10.m10.1.2.3.3.cmml" xref="S3.SS1.p1.10.m10.1.2.3.3">𝐭</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">F_{t}(\mathbf{t})\Rightarrow\mathbf{D_{t}}</annotation></semantics></math> that maps each text subtitle sequence to lower dimensional <math id="S3.SS1.p1.11.m11.1" class="ltx_Math" alttext="\mathbf{D_{t}}" display="inline"><semantics id="S3.SS1.p1.11.m11.1a"><msub id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml"><mi id="S3.SS1.p1.11.m11.1.1.2" xref="S3.SS1.p1.11.m11.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.11.m11.1.1.3" xref="S3.SS1.p1.11.m11.1.1.3.cmml">𝐭</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b"><apply id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.1.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m11.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.2">𝐃</ci><ci id="S3.SS1.p1.11.m11.1.1.3.cmml" xref="S3.SS1.p1.11.m11.1.1.3">𝐭</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">\mathbf{D_{t}}</annotation></semantics></math>. Finally, an audio encoder <math id="S3.SS1.p1.12.m12.1" class="ltx_Math" alttext="F_{a}(\mathbf{a})\Rightarrow\mathbf{D_{a}}" display="inline"><semantics id="S3.SS1.p1.12.m12.1a"><mrow id="S3.SS1.p1.12.m12.1.2" xref="S3.SS1.p1.12.m12.1.2.cmml"><mrow id="S3.SS1.p1.12.m12.1.2.2" xref="S3.SS1.p1.12.m12.1.2.2.cmml"><msub id="S3.SS1.p1.12.m12.1.2.2.2" xref="S3.SS1.p1.12.m12.1.2.2.2.cmml"><mi id="S3.SS1.p1.12.m12.1.2.2.2.2" xref="S3.SS1.p1.12.m12.1.2.2.2.2.cmml">F</mi><mi id="S3.SS1.p1.12.m12.1.2.2.2.3" xref="S3.SS1.p1.12.m12.1.2.2.2.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.12.m12.1.2.2.1" xref="S3.SS1.p1.12.m12.1.2.2.1.cmml">​</mo><mrow id="S3.SS1.p1.12.m12.1.2.2.3.2" xref="S3.SS1.p1.12.m12.1.2.2.cmml"><mo stretchy="false" id="S3.SS1.p1.12.m12.1.2.2.3.2.1" xref="S3.SS1.p1.12.m12.1.2.2.cmml">(</mo><mi id="S3.SS1.p1.12.m12.1.1" xref="S3.SS1.p1.12.m12.1.1.cmml">𝐚</mi><mo stretchy="false" id="S3.SS1.p1.12.m12.1.2.2.3.2.2" xref="S3.SS1.p1.12.m12.1.2.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.12.m12.1.2.1" xref="S3.SS1.p1.12.m12.1.2.1.cmml">⇒</mo><msub id="S3.SS1.p1.12.m12.1.2.3" xref="S3.SS1.p1.12.m12.1.2.3.cmml"><mi id="S3.SS1.p1.12.m12.1.2.3.2" xref="S3.SS1.p1.12.m12.1.2.3.2.cmml">𝐃</mi><mi id="S3.SS1.p1.12.m12.1.2.3.3" xref="S3.SS1.p1.12.m12.1.2.3.3.cmml">𝐚</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m12.1b"><apply id="S3.SS1.p1.12.m12.1.2.cmml" xref="S3.SS1.p1.12.m12.1.2"><ci id="S3.SS1.p1.12.m12.1.2.1.cmml" xref="S3.SS1.p1.12.m12.1.2.1">⇒</ci><apply id="S3.SS1.p1.12.m12.1.2.2.cmml" xref="S3.SS1.p1.12.m12.1.2.2"><times id="S3.SS1.p1.12.m12.1.2.2.1.cmml" xref="S3.SS1.p1.12.m12.1.2.2.1"></times><apply id="S3.SS1.p1.12.m12.1.2.2.2.cmml" xref="S3.SS1.p1.12.m12.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m12.1.2.2.2.1.cmml" xref="S3.SS1.p1.12.m12.1.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.12.m12.1.2.2.2.2.cmml" xref="S3.SS1.p1.12.m12.1.2.2.2.2">𝐹</ci><ci id="S3.SS1.p1.12.m12.1.2.2.2.3.cmml" xref="S3.SS1.p1.12.m12.1.2.2.2.3">𝑎</ci></apply><ci id="S3.SS1.p1.12.m12.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1">𝐚</ci></apply><apply id="S3.SS1.p1.12.m12.1.2.3.cmml" xref="S3.SS1.p1.12.m12.1.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m12.1.2.3.1.cmml" xref="S3.SS1.p1.12.m12.1.2.3">subscript</csymbol><ci id="S3.SS1.p1.12.m12.1.2.3.2.cmml" xref="S3.SS1.p1.12.m12.1.2.3.2">𝐃</ci><ci id="S3.SS1.p1.12.m12.1.2.3.3.cmml" xref="S3.SS1.p1.12.m12.1.2.3.3">𝐚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m12.1c">F_{a}(\mathbf{a})\Rightarrow\mathbf{D_{a}}</annotation></semantics></math> that maps each audio spectrum sequence to lower dimensional <math id="S3.SS1.p1.13.m13.1" class="ltx_Math" alttext="\mathbf{D_{a}}" display="inline"><semantics id="S3.SS1.p1.13.m13.1a"><msub id="S3.SS1.p1.13.m13.1.1" xref="S3.SS1.p1.13.m13.1.1.cmml"><mi id="S3.SS1.p1.13.m13.1.1.2" xref="S3.SS1.p1.13.m13.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.13.m13.1.1.3" xref="S3.SS1.p1.13.m13.1.1.3.cmml">𝐚</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m13.1b"><apply id="S3.SS1.p1.13.m13.1.1.cmml" xref="S3.SS1.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m13.1.1.1.cmml" xref="S3.SS1.p1.13.m13.1.1">subscript</csymbol><ci id="S3.SS1.p1.13.m13.1.1.2.cmml" xref="S3.SS1.p1.13.m13.1.1.2">𝐃</ci><ci id="S3.SS1.p1.13.m13.1.1.3.cmml" xref="S3.SS1.p1.13.m13.1.1.3">𝐚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m13.1c">\mathbf{D_{a}}</annotation></semantics></math>. To learn contrastive representations, we map <math id="S3.SS1.p1.14.m14.1" class="ltx_Math" alttext="\mathbf{D_{v}}" display="inline"><semantics id="S3.SS1.p1.14.m14.1a"><msub id="S3.SS1.p1.14.m14.1.1" xref="S3.SS1.p1.14.m14.1.1.cmml"><mi id="S3.SS1.p1.14.m14.1.1.2" xref="S3.SS1.p1.14.m14.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.14.m14.1.1.3" xref="S3.SS1.p1.14.m14.1.1.3.cmml">𝐯</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m14.1b"><apply id="S3.SS1.p1.14.m14.1.1.cmml" xref="S3.SS1.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.14.m14.1.1.1.cmml" xref="S3.SS1.p1.14.m14.1.1">subscript</csymbol><ci id="S3.SS1.p1.14.m14.1.1.2.cmml" xref="S3.SS1.p1.14.m14.1.1.2">𝐃</ci><ci id="S3.SS1.p1.14.m14.1.1.3.cmml" xref="S3.SS1.p1.14.m14.1.1.3">𝐯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m14.1c">\mathbf{D_{v}}</annotation></semantics></math>, <math id="S3.SS1.p1.15.m15.1" class="ltx_Math" alttext="\mathbf{D_{t}}" display="inline"><semantics id="S3.SS1.p1.15.m15.1a"><msub id="S3.SS1.p1.15.m15.1.1" xref="S3.SS1.p1.15.m15.1.1.cmml"><mi id="S3.SS1.p1.15.m15.1.1.2" xref="S3.SS1.p1.15.m15.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.15.m15.1.1.3" xref="S3.SS1.p1.15.m15.1.1.3.cmml">𝐭</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m15.1b"><apply id="S3.SS1.p1.15.m15.1.1.cmml" xref="S3.SS1.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.15.m15.1.1.1.cmml" xref="S3.SS1.p1.15.m15.1.1">subscript</csymbol><ci id="S3.SS1.p1.15.m15.1.1.2.cmml" xref="S3.SS1.p1.15.m15.1.1.2">𝐃</ci><ci id="S3.SS1.p1.15.m15.1.1.3.cmml" xref="S3.SS1.p1.15.m15.1.1.3">𝐭</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m15.1c">\mathbf{D_{t}}</annotation></semantics></math>, and <math id="S3.SS1.p1.16.m16.1" class="ltx_Math" alttext="\mathbf{D_{a}}" display="inline"><semantics id="S3.SS1.p1.16.m16.1a"><msub id="S3.SS1.p1.16.m16.1.1" xref="S3.SS1.p1.16.m16.1.1.cmml"><mi id="S3.SS1.p1.16.m16.1.1.2" xref="S3.SS1.p1.16.m16.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.16.m16.1.1.3" xref="S3.SS1.p1.16.m16.1.1.3.cmml">𝐚</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.16.m16.1b"><apply id="S3.SS1.p1.16.m16.1.1.cmml" xref="S3.SS1.p1.16.m16.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.16.m16.1.1.1.cmml" xref="S3.SS1.p1.16.m16.1.1">subscript</csymbol><ci id="S3.SS1.p1.16.m16.1.1.2.cmml" xref="S3.SS1.p1.16.m16.1.1.2">𝐃</ci><ci id="S3.SS1.p1.16.m16.1.1.3.cmml" xref="S3.SS1.p1.16.m16.1.1.3">𝐚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.16.m16.1c">\mathbf{D_{a}}</annotation></semantics></math> representations into three separate projection heads (one for each modality), each consisting of two linear layers, as follows: <math id="S3.SS1.p1.17.m17.1" class="ltx_Math" alttext="J_{\mathbf{v}}(\mathbf{D_{v}})\Rightarrow\mathbf{P_{v}}" display="inline"><semantics id="S3.SS1.p1.17.m17.1a"><mrow id="S3.SS1.p1.17.m17.1.1" xref="S3.SS1.p1.17.m17.1.1.cmml"><mrow id="S3.SS1.p1.17.m17.1.1.1" xref="S3.SS1.p1.17.m17.1.1.1.cmml"><msub id="S3.SS1.p1.17.m17.1.1.1.3" xref="S3.SS1.p1.17.m17.1.1.1.3.cmml"><mi id="S3.SS1.p1.17.m17.1.1.1.3.2" xref="S3.SS1.p1.17.m17.1.1.1.3.2.cmml">J</mi><mi id="S3.SS1.p1.17.m17.1.1.1.3.3" xref="S3.SS1.p1.17.m17.1.1.1.3.3.cmml">𝐯</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.17.m17.1.1.1.2" xref="S3.SS1.p1.17.m17.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.17.m17.1.1.1.1.1" xref="S3.SS1.p1.17.m17.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.17.m17.1.1.1.1.1.2" xref="S3.SS1.p1.17.m17.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p1.17.m17.1.1.1.1.1.1" xref="S3.SS1.p1.17.m17.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.17.m17.1.1.1.1.1.1.2" xref="S3.SS1.p1.17.m17.1.1.1.1.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.17.m17.1.1.1.1.1.1.3" xref="S3.SS1.p1.17.m17.1.1.1.1.1.1.3.cmml">𝐯</mi></msub><mo stretchy="false" id="S3.SS1.p1.17.m17.1.1.1.1.1.3" xref="S3.SS1.p1.17.m17.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.17.m17.1.1.2" xref="S3.SS1.p1.17.m17.1.1.2.cmml">⇒</mo><msub id="S3.SS1.p1.17.m17.1.1.3" xref="S3.SS1.p1.17.m17.1.1.3.cmml"><mi id="S3.SS1.p1.17.m17.1.1.3.2" xref="S3.SS1.p1.17.m17.1.1.3.2.cmml">𝐏</mi><mi id="S3.SS1.p1.17.m17.1.1.3.3" xref="S3.SS1.p1.17.m17.1.1.3.3.cmml">𝐯</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.17.m17.1b"><apply id="S3.SS1.p1.17.m17.1.1.cmml" xref="S3.SS1.p1.17.m17.1.1"><ci id="S3.SS1.p1.17.m17.1.1.2.cmml" xref="S3.SS1.p1.17.m17.1.1.2">⇒</ci><apply id="S3.SS1.p1.17.m17.1.1.1.cmml" xref="S3.SS1.p1.17.m17.1.1.1"><times id="S3.SS1.p1.17.m17.1.1.1.2.cmml" xref="S3.SS1.p1.17.m17.1.1.1.2"></times><apply id="S3.SS1.p1.17.m17.1.1.1.3.cmml" xref="S3.SS1.p1.17.m17.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.17.m17.1.1.1.3.1.cmml" xref="S3.SS1.p1.17.m17.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.17.m17.1.1.1.3.2.cmml" xref="S3.SS1.p1.17.m17.1.1.1.3.2">𝐽</ci><ci id="S3.SS1.p1.17.m17.1.1.1.3.3.cmml" xref="S3.SS1.p1.17.m17.1.1.1.3.3">𝐯</ci></apply><apply id="S3.SS1.p1.17.m17.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.17.m17.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.17.m17.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.17.m17.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.17.m17.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.17.m17.1.1.1.1.1.1.2">𝐃</ci><ci id="S3.SS1.p1.17.m17.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.17.m17.1.1.1.1.1.1.3">𝐯</ci></apply></apply><apply id="S3.SS1.p1.17.m17.1.1.3.cmml" xref="S3.SS1.p1.17.m17.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.17.m17.1.1.3.1.cmml" xref="S3.SS1.p1.17.m17.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.17.m17.1.1.3.2.cmml" xref="S3.SS1.p1.17.m17.1.1.3.2">𝐏</ci><ci id="S3.SS1.p1.17.m17.1.1.3.3.cmml" xref="S3.SS1.p1.17.m17.1.1.3.3">𝐯</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.17.m17.1c">J_{\mathbf{v}}(\mathbf{D_{v}})\Rightarrow\mathbf{P_{v}}</annotation></semantics></math>, <math id="S3.SS1.p1.18.m18.1" class="ltx_Math" alttext="J_{\mathbf{t}}(\mathbf{D_{t}})\Rightarrow\mathbf{P_{t}}" display="inline"><semantics id="S3.SS1.p1.18.m18.1a"><mrow id="S3.SS1.p1.18.m18.1.1" xref="S3.SS1.p1.18.m18.1.1.cmml"><mrow id="S3.SS1.p1.18.m18.1.1.1" xref="S3.SS1.p1.18.m18.1.1.1.cmml"><msub id="S3.SS1.p1.18.m18.1.1.1.3" xref="S3.SS1.p1.18.m18.1.1.1.3.cmml"><mi id="S3.SS1.p1.18.m18.1.1.1.3.2" xref="S3.SS1.p1.18.m18.1.1.1.3.2.cmml">J</mi><mi id="S3.SS1.p1.18.m18.1.1.1.3.3" xref="S3.SS1.p1.18.m18.1.1.1.3.3.cmml">𝐭</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.18.m18.1.1.1.2" xref="S3.SS1.p1.18.m18.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.18.m18.1.1.1.1.1" xref="S3.SS1.p1.18.m18.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.18.m18.1.1.1.1.1.2" xref="S3.SS1.p1.18.m18.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p1.18.m18.1.1.1.1.1.1" xref="S3.SS1.p1.18.m18.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.18.m18.1.1.1.1.1.1.2" xref="S3.SS1.p1.18.m18.1.1.1.1.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.18.m18.1.1.1.1.1.1.3" xref="S3.SS1.p1.18.m18.1.1.1.1.1.1.3.cmml">𝐭</mi></msub><mo stretchy="false" id="S3.SS1.p1.18.m18.1.1.1.1.1.3" xref="S3.SS1.p1.18.m18.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.18.m18.1.1.2" xref="S3.SS1.p1.18.m18.1.1.2.cmml">⇒</mo><msub id="S3.SS1.p1.18.m18.1.1.3" xref="S3.SS1.p1.18.m18.1.1.3.cmml"><mi id="S3.SS1.p1.18.m18.1.1.3.2" xref="S3.SS1.p1.18.m18.1.1.3.2.cmml">𝐏</mi><mi id="S3.SS1.p1.18.m18.1.1.3.3" xref="S3.SS1.p1.18.m18.1.1.3.3.cmml">𝐭</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.18.m18.1b"><apply id="S3.SS1.p1.18.m18.1.1.cmml" xref="S3.SS1.p1.18.m18.1.1"><ci id="S3.SS1.p1.18.m18.1.1.2.cmml" xref="S3.SS1.p1.18.m18.1.1.2">⇒</ci><apply id="S3.SS1.p1.18.m18.1.1.1.cmml" xref="S3.SS1.p1.18.m18.1.1.1"><times id="S3.SS1.p1.18.m18.1.1.1.2.cmml" xref="S3.SS1.p1.18.m18.1.1.1.2"></times><apply id="S3.SS1.p1.18.m18.1.1.1.3.cmml" xref="S3.SS1.p1.18.m18.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.18.m18.1.1.1.3.1.cmml" xref="S3.SS1.p1.18.m18.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.18.m18.1.1.1.3.2.cmml" xref="S3.SS1.p1.18.m18.1.1.1.3.2">𝐽</ci><ci id="S3.SS1.p1.18.m18.1.1.1.3.3.cmml" xref="S3.SS1.p1.18.m18.1.1.1.3.3">𝐭</ci></apply><apply id="S3.SS1.p1.18.m18.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.18.m18.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.18.m18.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.18.m18.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.18.m18.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.18.m18.1.1.1.1.1.1.2">𝐃</ci><ci id="S3.SS1.p1.18.m18.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.18.m18.1.1.1.1.1.1.3">𝐭</ci></apply></apply><apply id="S3.SS1.p1.18.m18.1.1.3.cmml" xref="S3.SS1.p1.18.m18.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.18.m18.1.1.3.1.cmml" xref="S3.SS1.p1.18.m18.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.18.m18.1.1.3.2.cmml" xref="S3.SS1.p1.18.m18.1.1.3.2">𝐏</ci><ci id="S3.SS1.p1.18.m18.1.1.3.3.cmml" xref="S3.SS1.p1.18.m18.1.1.3.3">𝐭</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.18.m18.1c">J_{\mathbf{t}}(\mathbf{D_{t}})\Rightarrow\mathbf{P_{t}}</annotation></semantics></math>, and <math id="S3.SS1.p1.19.m19.1" class="ltx_Math" alttext="J_{\mathbf{a}}(\mathbf{D_{a}})\Rightarrow\mathbf{P_{a}}" display="inline"><semantics id="S3.SS1.p1.19.m19.1a"><mrow id="S3.SS1.p1.19.m19.1.1" xref="S3.SS1.p1.19.m19.1.1.cmml"><mrow id="S3.SS1.p1.19.m19.1.1.1" xref="S3.SS1.p1.19.m19.1.1.1.cmml"><msub id="S3.SS1.p1.19.m19.1.1.1.3" xref="S3.SS1.p1.19.m19.1.1.1.3.cmml"><mi id="S3.SS1.p1.19.m19.1.1.1.3.2" xref="S3.SS1.p1.19.m19.1.1.1.3.2.cmml">J</mi><mi id="S3.SS1.p1.19.m19.1.1.1.3.3" xref="S3.SS1.p1.19.m19.1.1.1.3.3.cmml">𝐚</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.19.m19.1.1.1.2" xref="S3.SS1.p1.19.m19.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.19.m19.1.1.1.1.1" xref="S3.SS1.p1.19.m19.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.19.m19.1.1.1.1.1.2" xref="S3.SS1.p1.19.m19.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p1.19.m19.1.1.1.1.1.1" xref="S3.SS1.p1.19.m19.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.19.m19.1.1.1.1.1.1.2" xref="S3.SS1.p1.19.m19.1.1.1.1.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.19.m19.1.1.1.1.1.1.3" xref="S3.SS1.p1.19.m19.1.1.1.1.1.1.3.cmml">𝐚</mi></msub><mo stretchy="false" id="S3.SS1.p1.19.m19.1.1.1.1.1.3" xref="S3.SS1.p1.19.m19.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.19.m19.1.1.2" xref="S3.SS1.p1.19.m19.1.1.2.cmml">⇒</mo><msub id="S3.SS1.p1.19.m19.1.1.3" xref="S3.SS1.p1.19.m19.1.1.3.cmml"><mi id="S3.SS1.p1.19.m19.1.1.3.2" xref="S3.SS1.p1.19.m19.1.1.3.2.cmml">𝐏</mi><mi id="S3.SS1.p1.19.m19.1.1.3.3" xref="S3.SS1.p1.19.m19.1.1.3.3.cmml">𝐚</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.19.m19.1b"><apply id="S3.SS1.p1.19.m19.1.1.cmml" xref="S3.SS1.p1.19.m19.1.1"><ci id="S3.SS1.p1.19.m19.1.1.2.cmml" xref="S3.SS1.p1.19.m19.1.1.2">⇒</ci><apply id="S3.SS1.p1.19.m19.1.1.1.cmml" xref="S3.SS1.p1.19.m19.1.1.1"><times id="S3.SS1.p1.19.m19.1.1.1.2.cmml" xref="S3.SS1.p1.19.m19.1.1.1.2"></times><apply id="S3.SS1.p1.19.m19.1.1.1.3.cmml" xref="S3.SS1.p1.19.m19.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.19.m19.1.1.1.3.1.cmml" xref="S3.SS1.p1.19.m19.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.19.m19.1.1.1.3.2.cmml" xref="S3.SS1.p1.19.m19.1.1.1.3.2">𝐽</ci><ci id="S3.SS1.p1.19.m19.1.1.1.3.3.cmml" xref="S3.SS1.p1.19.m19.1.1.1.3.3">𝐚</ci></apply><apply id="S3.SS1.p1.19.m19.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.19.m19.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.19.m19.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.19.m19.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.19.m19.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.19.m19.1.1.1.1.1.1.2">𝐃</ci><ci id="S3.SS1.p1.19.m19.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.19.m19.1.1.1.1.1.1.3">𝐚</ci></apply></apply><apply id="S3.SS1.p1.19.m19.1.1.3.cmml" xref="S3.SS1.p1.19.m19.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.19.m19.1.1.3.1.cmml" xref="S3.SS1.p1.19.m19.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.19.m19.1.1.3.2.cmml" xref="S3.SS1.p1.19.m19.1.1.3.2">𝐏</ci><ci id="S3.SS1.p1.19.m19.1.1.3.3.cmml" xref="S3.SS1.p1.19.m19.1.1.3.3">𝐚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.19.m19.1c">J_{\mathbf{a}}(\mathbf{D_{a}})\Rightarrow\mathbf{P_{a}}</annotation></semantics></math>. After that, to learn the multi-modal clustering, we map the output of the projection heads to one layer clustering head <math id="S3.SS1.p1.20.m20.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS1.p1.20.m20.1a"><mi id="S3.SS1.p1.20.m20.1.1" xref="S3.SS1.p1.20.m20.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.20.m20.1b"><ci id="S3.SS1.p1.20.m20.1.1.cmml" xref="S3.SS1.p1.20.m20.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.20.m20.1c">G</annotation></semantics></math> (see <a href="#S3.F1" title="In 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>), where <math id="S3.SS1.p1.21.m21.1" class="ltx_Math" alttext="G(\mathbf{D_{v}})\Rightarrow\mathbf{g_{v}}" display="inline"><semantics id="S3.SS1.p1.21.m21.1a"><mrow id="S3.SS1.p1.21.m21.1.1" xref="S3.SS1.p1.21.m21.1.1.cmml"><mrow id="S3.SS1.p1.21.m21.1.1.1" xref="S3.SS1.p1.21.m21.1.1.1.cmml"><mi id="S3.SS1.p1.21.m21.1.1.1.3" xref="S3.SS1.p1.21.m21.1.1.1.3.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.21.m21.1.1.1.2" xref="S3.SS1.p1.21.m21.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.21.m21.1.1.1.1.1" xref="S3.SS1.p1.21.m21.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.21.m21.1.1.1.1.1.2" xref="S3.SS1.p1.21.m21.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p1.21.m21.1.1.1.1.1.1" xref="S3.SS1.p1.21.m21.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.21.m21.1.1.1.1.1.1.2" xref="S3.SS1.p1.21.m21.1.1.1.1.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.21.m21.1.1.1.1.1.1.3" xref="S3.SS1.p1.21.m21.1.1.1.1.1.1.3.cmml">𝐯</mi></msub><mo stretchy="false" id="S3.SS1.p1.21.m21.1.1.1.1.1.3" xref="S3.SS1.p1.21.m21.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.21.m21.1.1.2" xref="S3.SS1.p1.21.m21.1.1.2.cmml">⇒</mo><msub id="S3.SS1.p1.21.m21.1.1.3" xref="S3.SS1.p1.21.m21.1.1.3.cmml"><mi id="S3.SS1.p1.21.m21.1.1.3.2" xref="S3.SS1.p1.21.m21.1.1.3.2.cmml">𝐠</mi><mi id="S3.SS1.p1.21.m21.1.1.3.3" xref="S3.SS1.p1.21.m21.1.1.3.3.cmml">𝐯</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.21.m21.1b"><apply id="S3.SS1.p1.21.m21.1.1.cmml" xref="S3.SS1.p1.21.m21.1.1"><ci id="S3.SS1.p1.21.m21.1.1.2.cmml" xref="S3.SS1.p1.21.m21.1.1.2">⇒</ci><apply id="S3.SS1.p1.21.m21.1.1.1.cmml" xref="S3.SS1.p1.21.m21.1.1.1"><times id="S3.SS1.p1.21.m21.1.1.1.2.cmml" xref="S3.SS1.p1.21.m21.1.1.1.2"></times><ci id="S3.SS1.p1.21.m21.1.1.1.3.cmml" xref="S3.SS1.p1.21.m21.1.1.1.3">𝐺</ci><apply id="S3.SS1.p1.21.m21.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.21.m21.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.21.m21.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.21.m21.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.21.m21.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.21.m21.1.1.1.1.1.1.2">𝐃</ci><ci id="S3.SS1.p1.21.m21.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.21.m21.1.1.1.1.1.1.3">𝐯</ci></apply></apply><apply id="S3.SS1.p1.21.m21.1.1.3.cmml" xref="S3.SS1.p1.21.m21.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.21.m21.1.1.3.1.cmml" xref="S3.SS1.p1.21.m21.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.21.m21.1.1.3.2.cmml" xref="S3.SS1.p1.21.m21.1.1.3.2">𝐠</ci><ci id="S3.SS1.p1.21.m21.1.1.3.3.cmml" xref="S3.SS1.p1.21.m21.1.1.3.3">𝐯</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.21.m21.1c">G(\mathbf{D_{v}})\Rightarrow\mathbf{g_{v}}</annotation></semantics></math>, <math id="S3.SS1.p1.22.m22.1" class="ltx_Math" alttext="G(\mathbf{D_{t}})\Rightarrow\mathbf{g_{t}}" display="inline"><semantics id="S3.SS1.p1.22.m22.1a"><mrow id="S3.SS1.p1.22.m22.1.1" xref="S3.SS1.p1.22.m22.1.1.cmml"><mrow id="S3.SS1.p1.22.m22.1.1.1" xref="S3.SS1.p1.22.m22.1.1.1.cmml"><mi id="S3.SS1.p1.22.m22.1.1.1.3" xref="S3.SS1.p1.22.m22.1.1.1.3.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.22.m22.1.1.1.2" xref="S3.SS1.p1.22.m22.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.22.m22.1.1.1.1.1" xref="S3.SS1.p1.22.m22.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.22.m22.1.1.1.1.1.2" xref="S3.SS1.p1.22.m22.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p1.22.m22.1.1.1.1.1.1" xref="S3.SS1.p1.22.m22.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.22.m22.1.1.1.1.1.1.2" xref="S3.SS1.p1.22.m22.1.1.1.1.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.22.m22.1.1.1.1.1.1.3" xref="S3.SS1.p1.22.m22.1.1.1.1.1.1.3.cmml">𝐭</mi></msub><mo stretchy="false" id="S3.SS1.p1.22.m22.1.1.1.1.1.3" xref="S3.SS1.p1.22.m22.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.22.m22.1.1.2" xref="S3.SS1.p1.22.m22.1.1.2.cmml">⇒</mo><msub id="S3.SS1.p1.22.m22.1.1.3" xref="S3.SS1.p1.22.m22.1.1.3.cmml"><mi id="S3.SS1.p1.22.m22.1.1.3.2" xref="S3.SS1.p1.22.m22.1.1.3.2.cmml">𝐠</mi><mi id="S3.SS1.p1.22.m22.1.1.3.3" xref="S3.SS1.p1.22.m22.1.1.3.3.cmml">𝐭</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.22.m22.1b"><apply id="S3.SS1.p1.22.m22.1.1.cmml" xref="S3.SS1.p1.22.m22.1.1"><ci id="S3.SS1.p1.22.m22.1.1.2.cmml" xref="S3.SS1.p1.22.m22.1.1.2">⇒</ci><apply id="S3.SS1.p1.22.m22.1.1.1.cmml" xref="S3.SS1.p1.22.m22.1.1.1"><times id="S3.SS1.p1.22.m22.1.1.1.2.cmml" xref="S3.SS1.p1.22.m22.1.1.1.2"></times><ci id="S3.SS1.p1.22.m22.1.1.1.3.cmml" xref="S3.SS1.p1.22.m22.1.1.1.3">𝐺</ci><apply id="S3.SS1.p1.22.m22.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.22.m22.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.22.m22.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.22.m22.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.22.m22.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.22.m22.1.1.1.1.1.1.2">𝐃</ci><ci id="S3.SS1.p1.22.m22.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.22.m22.1.1.1.1.1.1.3">𝐭</ci></apply></apply><apply id="S3.SS1.p1.22.m22.1.1.3.cmml" xref="S3.SS1.p1.22.m22.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.22.m22.1.1.3.1.cmml" xref="S3.SS1.p1.22.m22.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.22.m22.1.1.3.2.cmml" xref="S3.SS1.p1.22.m22.1.1.3.2">𝐠</ci><ci id="S3.SS1.p1.22.m22.1.1.3.3.cmml" xref="S3.SS1.p1.22.m22.1.1.3.3">𝐭</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.22.m22.1c">G(\mathbf{D_{t}})\Rightarrow\mathbf{g_{t}}</annotation></semantics></math>, and <math id="S3.SS1.p1.23.m23.1" class="ltx_Math" alttext="G(\mathbf{D_{a}})\Rightarrow\mathbf{g_{a}}" display="inline"><semantics id="S3.SS1.p1.23.m23.1a"><mrow id="S3.SS1.p1.23.m23.1.1" xref="S3.SS1.p1.23.m23.1.1.cmml"><mrow id="S3.SS1.p1.23.m23.1.1.1" xref="S3.SS1.p1.23.m23.1.1.1.cmml"><mi id="S3.SS1.p1.23.m23.1.1.1.3" xref="S3.SS1.p1.23.m23.1.1.1.3.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.23.m23.1.1.1.2" xref="S3.SS1.p1.23.m23.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.23.m23.1.1.1.1.1" xref="S3.SS1.p1.23.m23.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.23.m23.1.1.1.1.1.2" xref="S3.SS1.p1.23.m23.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p1.23.m23.1.1.1.1.1.1" xref="S3.SS1.p1.23.m23.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.23.m23.1.1.1.1.1.1.2" xref="S3.SS1.p1.23.m23.1.1.1.1.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.p1.23.m23.1.1.1.1.1.1.3" xref="S3.SS1.p1.23.m23.1.1.1.1.1.1.3.cmml">𝐚</mi></msub><mo stretchy="false" id="S3.SS1.p1.23.m23.1.1.1.1.1.3" xref="S3.SS1.p1.23.m23.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.23.m23.1.1.2" xref="S3.SS1.p1.23.m23.1.1.2.cmml">⇒</mo><msub id="S3.SS1.p1.23.m23.1.1.3" xref="S3.SS1.p1.23.m23.1.1.3.cmml"><mi id="S3.SS1.p1.23.m23.1.1.3.2" xref="S3.SS1.p1.23.m23.1.1.3.2.cmml">𝐠</mi><mi id="S3.SS1.p1.23.m23.1.1.3.3" xref="S3.SS1.p1.23.m23.1.1.3.3.cmml">𝐚</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.23.m23.1b"><apply id="S3.SS1.p1.23.m23.1.1.cmml" xref="S3.SS1.p1.23.m23.1.1"><ci id="S3.SS1.p1.23.m23.1.1.2.cmml" xref="S3.SS1.p1.23.m23.1.1.2">⇒</ci><apply id="S3.SS1.p1.23.m23.1.1.1.cmml" xref="S3.SS1.p1.23.m23.1.1.1"><times id="S3.SS1.p1.23.m23.1.1.1.2.cmml" xref="S3.SS1.p1.23.m23.1.1.1.2"></times><ci id="S3.SS1.p1.23.m23.1.1.1.3.cmml" xref="S3.SS1.p1.23.m23.1.1.1.3">𝐺</ci><apply id="S3.SS1.p1.23.m23.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.23.m23.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.23.m23.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.23.m23.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.23.m23.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.23.m23.1.1.1.1.1.1.2">𝐃</ci><ci id="S3.SS1.p1.23.m23.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.23.m23.1.1.1.1.1.1.3">𝐚</ci></apply></apply><apply id="S3.SS1.p1.23.m23.1.1.3.cmml" xref="S3.SS1.p1.23.m23.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.23.m23.1.1.3.1.cmml" xref="S3.SS1.p1.23.m23.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.23.m23.1.1.3.2.cmml" xref="S3.SS1.p1.23.m23.1.1.3.2">𝐠</ci><ci id="S3.SS1.p1.23.m23.1.1.3.3.cmml" xref="S3.SS1.p1.23.m23.1.1.3.3">𝐚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.23.m23.1c">G(\mathbf{D_{a}})\Rightarrow\mathbf{g_{a}}</annotation></semantics></math>. <a href="#S3.F1" title="In 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a> depicts an overview of this architecture. We named the encoders <math id="S3.SS1.p1.24.m24.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS1.p1.24.m24.1a"><mi id="S3.SS1.p1.24.m24.1.1" xref="S3.SS1.p1.24.m24.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.24.m24.1b"><ci id="S3.SS1.p1.24.m24.1.1.cmml" xref="S3.SS1.p1.24.m24.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.24.m24.1c">F</annotation></semantics></math> <span id="S3.SS1.p1.24.1" class="ltx_text ltx_font_italic">Representation Head</span> here.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.2" class="ltx_p">Note that the feature extraction networks in <a href="#S3.F1" title="In 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a> are fully fixed since we focus on improving the representations obtained from <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">F</annotation></semantics></math>. This means that in the previous paragraphs, <math id="S3.SS1.p2.2.m2.3" class="ltx_Math" alttext="(\mathbf{v_{i}},\mathbf{t_{i}},\mathbf{a_{i}})" display="inline"><semantics id="S3.SS1.p2.2.m2.3a"><mrow id="S3.SS1.p2.2.m2.3.3.3" xref="S3.SS1.p2.2.m2.3.3.4.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.3.3.3.4" xref="S3.SS1.p2.2.m2.3.3.4.cmml">(</mo><msub id="S3.SS1.p2.2.m2.1.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.1.1.2" xref="S3.SS1.p2.2.m2.1.1.1.1.2.cmml">𝐯</mi><mi id="S3.SS1.p2.2.m2.1.1.1.1.3" xref="S3.SS1.p2.2.m2.1.1.1.1.3.cmml">𝐢</mi></msub><mo id="S3.SS1.p2.2.m2.3.3.3.5" xref="S3.SS1.p2.2.m2.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.2.m2.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.2.2.cmml"><mi id="S3.SS1.p2.2.m2.2.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.2.2.2.cmml">𝐭</mi><mi id="S3.SS1.p2.2.m2.2.2.2.2.3" xref="S3.SS1.p2.2.m2.2.2.2.2.3.cmml">𝐢</mi></msub><mo id="S3.SS1.p2.2.m2.3.3.3.6" xref="S3.SS1.p2.2.m2.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.2.m2.3.3.3.3" xref="S3.SS1.p2.2.m2.3.3.3.3.cmml"><mi id="S3.SS1.p2.2.m2.3.3.3.3.2" xref="S3.SS1.p2.2.m2.3.3.3.3.2.cmml">𝐚</mi><mi id="S3.SS1.p2.2.m2.3.3.3.3.3" xref="S3.SS1.p2.2.m2.3.3.3.3.3.cmml">𝐢</mi></msub><mo stretchy="false" id="S3.SS1.p2.2.m2.3.3.3.7" xref="S3.SS1.p2.2.m2.3.3.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.3b"><vector id="S3.SS1.p2.2.m2.3.3.4.cmml" xref="S3.SS1.p2.2.m2.3.3.3"><apply id="S3.SS1.p2.2.m2.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.2">𝐯</ci><ci id="S3.SS1.p2.2.m2.1.1.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.3">𝐢</ci></apply><apply id="S3.SS1.p2.2.m2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2.2">𝐭</ci><ci id="S3.SS1.p2.2.m2.2.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2.3">𝐢</ci></apply><apply id="S3.SS1.p2.2.m2.3.3.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.3.3.3.1.cmml" xref="S3.SS1.p2.2.m2.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.2.m2.3.3.3.3.2.cmml" xref="S3.SS1.p2.2.m2.3.3.3.3.2">𝐚</ci><ci id="S3.SS1.p2.2.m2.3.3.3.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3.3.3.3">𝐢</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.3c">(\mathbf{v_{i}},\mathbf{t_{i}},\mathbf{a_{i}})</annotation></semantics></math> are not the raw data, but the fixed output features extracted from 2D and 3D ResNet (<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite>), DistilBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite>, and DAVENet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite> respectively.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Instance-Level (Visual Only) Contrastive Learning</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.7" class="ltx_p">Instance-level contrastive learning methods are self-supervised methods that learn a representation of unlabeled data by discriminating between pairs of instances. They represent similar instances closer to each other in the embedding space, and dissimilar instances far apart. The quality of instance-level contrastive learning methods is influenced by the quality of data augmentations. This is the case because positive pairs for each instance are the augmented version of that instance, and the negative pairs are other instances in the training batch. To implement an instance-level contrastive learning method for video data, we follow the spatial augmentation process in the work of <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Qian et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite> that is consistent along the temporal dimension. Thus we will preserve the motion signal across frames, by generating random spatial augmentations across videos not across frames. We applied the following augmentations: random cropping with resizing, random horizontal flipping, color jitter, random grayscale, and Gaussian blur. Finally, we apply InfoNCE loss given as follows:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.5" class="ltx_Math" alttext="\ell_{\text{NCE}}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{\exp(sim(\mathbf{P}_{\textbf{v}}^{i},\mathbf{P}_{\textbf{v}}^{{}^{\prime}i})/\tau)}{\sum^{2K}_{k=1}\mathbbold{1}_{[k\neq i]}\exp(sim(\mathbf{P}_{\textbf{{v}}}^{i},\mathbf{P}_{\textbf{v}}^{k})/\tau)}" display="block"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.6" xref="S3.E1.m1.5.6.cmml"><msub id="S3.E1.m1.5.6.2" xref="S3.E1.m1.5.6.2.cmml"><mi mathvariant="normal" id="S3.E1.m1.5.6.2.2" xref="S3.E1.m1.5.6.2.2.cmml">ℓ</mi><mtext id="S3.E1.m1.5.6.2.3" xref="S3.E1.m1.5.6.2.3a.cmml">NCE</mtext></msub><mo id="S3.E1.m1.5.6.1" xref="S3.E1.m1.5.6.1.cmml">=</mo><mrow id="S3.E1.m1.5.6.3" xref="S3.E1.m1.5.6.3.cmml"><mo id="S3.E1.m1.5.6.3a" xref="S3.E1.m1.5.6.3.cmml">−</mo><mrow id="S3.E1.m1.5.6.3.2" xref="S3.E1.m1.5.6.3.2.cmml"><mfrac id="S3.E1.m1.5.6.3.2.2" xref="S3.E1.m1.5.6.3.2.2.cmml"><mn id="S3.E1.m1.5.6.3.2.2.2" xref="S3.E1.m1.5.6.3.2.2.2.cmml">1</mn><mi id="S3.E1.m1.5.6.3.2.2.3" xref="S3.E1.m1.5.6.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.6.3.2.1" xref="S3.E1.m1.5.6.3.2.1.cmml">​</mo><mrow id="S3.E1.m1.5.6.3.2.3" xref="S3.E1.m1.5.6.3.2.3.cmml"><munderover id="S3.E1.m1.5.6.3.2.3.1" xref="S3.E1.m1.5.6.3.2.3.1.cmml"><mo movablelimits="false" id="S3.E1.m1.5.6.3.2.3.1.2.2" xref="S3.E1.m1.5.6.3.2.3.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.5.6.3.2.3.1.2.3" xref="S3.E1.m1.5.6.3.2.3.1.2.3.cmml"><mi id="S3.E1.m1.5.6.3.2.3.1.2.3.2" xref="S3.E1.m1.5.6.3.2.3.1.2.3.2.cmml">i</mi><mo id="S3.E1.m1.5.6.3.2.3.1.2.3.1" xref="S3.E1.m1.5.6.3.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.5.6.3.2.3.1.2.3.3" xref="S3.E1.m1.5.6.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.5.6.3.2.3.1.3" xref="S3.E1.m1.5.6.3.2.3.1.3.cmml">N</mi></munderover><mrow id="S3.E1.m1.5.6.3.2.3.2" xref="S3.E1.m1.5.6.3.2.3.2.cmml"><mi id="S3.E1.m1.5.6.3.2.3.2.1" xref="S3.E1.m1.5.6.3.2.3.2.1.cmml">log</mi><mo lspace="0.167em" id="S3.E1.m1.5.6.3.2.3.2a" xref="S3.E1.m1.5.6.3.2.3.2.cmml">⁡</mo><mfrac id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml"><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">exp</mi><mo id="S3.E1.m1.2.2.2.2a" xref="S3.E1.m1.2.2.2.3.cmml">⁡</mo><mrow id="S3.E1.m1.2.2.2.2.1" xref="S3.E1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.3.cmml">(</mo><mrow id="S3.E1.m1.2.2.2.2.1.1" xref="S3.E1.m1.2.2.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.2.2.1.1.2" xref="S3.E1.m1.2.2.2.2.1.1.2.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.2.4" xref="S3.E1.m1.2.2.2.2.1.1.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.1.1.2.3" xref="S3.E1.m1.2.2.2.2.1.1.2.3.cmml">​</mo><mi id="S3.E1.m1.2.2.2.2.1.1.2.5" xref="S3.E1.m1.2.2.2.2.1.1.2.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.1.1.2.3a" xref="S3.E1.m1.2.2.2.2.1.1.2.3.cmml">​</mo><mi id="S3.E1.m1.2.2.2.2.1.1.2.6" xref="S3.E1.m1.2.2.2.2.1.1.2.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.1.1.2.3b" xref="S3.E1.m1.2.2.2.2.1.1.2.3.cmml">​</mo><mrow id="S3.E1.m1.2.2.2.2.1.1.2.2.2" xref="S3.E1.m1.2.2.2.2.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.2.2.1.1.2.2.2.3" xref="S3.E1.m1.2.2.2.2.1.1.2.2.3.cmml">(</mo><msubsup id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.2.cmml">𝐏</mi><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3a.cmml">v</mtext><mi id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.E1.m1.2.2.2.2.1.1.2.2.2.4" xref="S3.E1.m1.2.2.2.2.1.1.2.2.3.cmml">,</mo><msubsup id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.2.cmml">𝐏</mi><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.3a.cmml">v</mtext><mmultiscripts id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.cmml"><mi id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.2.cmml">i</mi><mprescripts id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3a" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.cmml"></mprescripts><mrow id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3b" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.cmml"></mrow><mo id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.3.cmml">′</mo></mmultiscripts></msubsup><mo stretchy="false" id="S3.E1.m1.2.2.2.2.1.1.2.2.2.5" xref="S3.E1.m1.2.2.2.2.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.2.2.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.3.cmml">/</mo><mi id="S3.E1.m1.2.2.2.2.1.1.4" xref="S3.E1.m1.2.2.2.2.1.1.4.cmml">τ</mi></mrow><mo stretchy="false" id="S3.E1.m1.2.2.2.2.1.3" xref="S3.E1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S3.E1.m1.5.5.5" xref="S3.E1.m1.5.5.5.cmml"><msubsup id="S3.E1.m1.5.5.5.4" xref="S3.E1.m1.5.5.5.4.cmml"><mo id="S3.E1.m1.5.5.5.4.2.2" xref="S3.E1.m1.5.5.5.4.2.2.cmml">∑</mo><mrow id="S3.E1.m1.5.5.5.4.3" xref="S3.E1.m1.5.5.5.4.3.cmml"><mi id="S3.E1.m1.5.5.5.4.3.2" xref="S3.E1.m1.5.5.5.4.3.2.cmml">k</mi><mo id="S3.E1.m1.5.5.5.4.3.1" xref="S3.E1.m1.5.5.5.4.3.1.cmml">=</mo><mn id="S3.E1.m1.5.5.5.4.3.3" xref="S3.E1.m1.5.5.5.4.3.3.cmml">1</mn></mrow><mrow id="S3.E1.m1.5.5.5.4.2.3" xref="S3.E1.m1.5.5.5.4.2.3.cmml"><mn id="S3.E1.m1.5.5.5.4.2.3.2" xref="S3.E1.m1.5.5.5.4.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.4.2.3.1" xref="S3.E1.m1.5.5.5.4.2.3.1.cmml">​</mo><mi id="S3.E1.m1.5.5.5.4.2.3.3" xref="S3.E1.m1.5.5.5.4.2.3.3.cmml">K</mi></mrow></msubsup><mrow id="S3.E1.m1.5.5.5.3" xref="S3.E1.m1.5.5.5.3.cmml"><msub id="S3.E1.m1.5.5.5.3.3" xref="S3.E1.m1.5.5.5.3.3.cmml"><mn id="S3.E1.m1.5.5.5.3.3.2" xref="S3.E1.m1.5.5.5.3.3.2.cmml">𝟙</mn><mrow id="S3.E1.m1.3.3.3.1.1.1" xref="S3.E1.m1.3.3.3.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.1.2" xref="S3.E1.m1.3.3.3.1.1.2.1.cmml">[</mo><mrow id="S3.E1.m1.3.3.3.1.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.3.1.1.1.1.2.cmml">𝕜</mi><mo id="S3.E1.m1.3.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.3.1.1.1.1.1.cmml">≠</mo><mi id="S3.E1.m1.3.3.3.1.1.1.1.3" xref="S3.E1.m1.3.3.3.1.1.1.1.3.cmml">𝕚</mi></mrow><mo stretchy="false" id="S3.E1.m1.3.3.3.1.1.1.3" xref="S3.E1.m1.3.3.3.1.1.2.1.cmml">]</mo></mrow></msub><mo lspace="0.167em" rspace="0em" id="S3.E1.m1.5.5.5.3.2" xref="S3.E1.m1.5.5.5.3.2.cmml">​</mo><mrow id="S3.E1.m1.5.5.5.3.1.1" xref="S3.E1.m1.5.5.5.3.1.2.cmml"><mi id="S3.E1.m1.4.4.4.2" xref="S3.E1.m1.4.4.4.2.cmml">exp</mi><mo id="S3.E1.m1.5.5.5.3.1.1a" xref="S3.E1.m1.5.5.5.3.1.2.cmml">⁡</mo><mrow id="S3.E1.m1.5.5.5.3.1.1.1" xref="S3.E1.m1.5.5.5.3.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.5.3.1.1.1.2" xref="S3.E1.m1.5.5.5.3.1.2.cmml">(</mo><mrow id="S3.E1.m1.5.5.5.3.1.1.1.1" xref="S3.E1.m1.5.5.5.3.1.1.1.1.cmml"><mrow id="S3.E1.m1.5.5.5.3.1.1.1.1.2" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.cmml"><mi id="S3.E1.m1.5.5.5.3.1.1.1.1.2.4" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.4.cmml">𝕤</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.3" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.3.cmml">​</mo><mi id="S3.E1.m1.5.5.5.3.1.1.1.1.2.5" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.5.cmml">𝕚</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.3a" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.3.cmml">​</mo><mi id="S3.E1.m1.5.5.5.3.1.1.1.1.2.6" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.6.cmml">𝕞</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.3b" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.3.cmml">​</mo><mrow id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.3" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.3.cmml">(</mo><msubsup id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.2.cmml">𝐏</mi><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.3a.cmml">v</mtext><mi id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.3.cmml">𝕚</mi></msubsup><mo id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.4" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.3.cmml">,</mo><msubsup id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.2" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.2.cmml">𝐏</mi><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.3" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.3a.cmml">v</mtext><mi id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.3" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.3.cmml">𝕜</mi></msubsup><mo stretchy="false" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.5" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.5.5.5.3.1.1.1.1.3" xref="S3.E1.m1.5.5.5.3.1.1.1.1.3.cmml">/</mo><mi id="S3.E1.m1.5.5.5.3.1.1.1.1.4" xref="S3.E1.m1.5.5.5.3.1.1.1.1.4.cmml">τ</mi></mrow><mo stretchy="false" id="S3.E1.m1.5.5.5.3.1.1.1.3" xref="S3.E1.m1.5.5.5.3.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.6.cmml" xref="S3.E1.m1.5.6"><eq id="S3.E1.m1.5.6.1.cmml" xref="S3.E1.m1.5.6.1"></eq><apply id="S3.E1.m1.5.6.2.cmml" xref="S3.E1.m1.5.6.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.6.2.1.cmml" xref="S3.E1.m1.5.6.2">subscript</csymbol><ci id="S3.E1.m1.5.6.2.2.cmml" xref="S3.E1.m1.5.6.2.2">ℓ</ci><ci id="S3.E1.m1.5.6.2.3a.cmml" xref="S3.E1.m1.5.6.2.3"><mtext mathsize="70%" id="S3.E1.m1.5.6.2.3.cmml" xref="S3.E1.m1.5.6.2.3">NCE</mtext></ci></apply><apply id="S3.E1.m1.5.6.3.cmml" xref="S3.E1.m1.5.6.3"><minus id="S3.E1.m1.5.6.3.1.cmml" xref="S3.E1.m1.5.6.3"></minus><apply id="S3.E1.m1.5.6.3.2.cmml" xref="S3.E1.m1.5.6.3.2"><times id="S3.E1.m1.5.6.3.2.1.cmml" xref="S3.E1.m1.5.6.3.2.1"></times><apply id="S3.E1.m1.5.6.3.2.2.cmml" xref="S3.E1.m1.5.6.3.2.2"><divide id="S3.E1.m1.5.6.3.2.2.1.cmml" xref="S3.E1.m1.5.6.3.2.2"></divide><cn type="integer" id="S3.E1.m1.5.6.3.2.2.2.cmml" xref="S3.E1.m1.5.6.3.2.2.2">1</cn><ci id="S3.E1.m1.5.6.3.2.2.3.cmml" xref="S3.E1.m1.5.6.3.2.2.3">𝑁</ci></apply><apply id="S3.E1.m1.5.6.3.2.3.cmml" xref="S3.E1.m1.5.6.3.2.3"><apply id="S3.E1.m1.5.6.3.2.3.1.cmml" xref="S3.E1.m1.5.6.3.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.6.3.2.3.1.1.cmml" xref="S3.E1.m1.5.6.3.2.3.1">superscript</csymbol><apply id="S3.E1.m1.5.6.3.2.3.1.2.cmml" xref="S3.E1.m1.5.6.3.2.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.6.3.2.3.1.2.1.cmml" xref="S3.E1.m1.5.6.3.2.3.1">subscript</csymbol><sum id="S3.E1.m1.5.6.3.2.3.1.2.2.cmml" xref="S3.E1.m1.5.6.3.2.3.1.2.2"></sum><apply id="S3.E1.m1.5.6.3.2.3.1.2.3.cmml" xref="S3.E1.m1.5.6.3.2.3.1.2.3"><eq id="S3.E1.m1.5.6.3.2.3.1.2.3.1.cmml" xref="S3.E1.m1.5.6.3.2.3.1.2.3.1"></eq><ci id="S3.E1.m1.5.6.3.2.3.1.2.3.2.cmml" xref="S3.E1.m1.5.6.3.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E1.m1.5.6.3.2.3.1.2.3.3.cmml" xref="S3.E1.m1.5.6.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.5.6.3.2.3.1.3.cmml" xref="S3.E1.m1.5.6.3.2.3.1.3">𝑁</ci></apply><apply id="S3.E1.m1.5.6.3.2.3.2.cmml" xref="S3.E1.m1.5.6.3.2.3.2"><log id="S3.E1.m1.5.6.3.2.3.2.1.cmml" xref="S3.E1.m1.5.6.3.2.3.2.1"></log><apply id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5"><divide id="S3.E1.m1.5.5.6.cmml" xref="S3.E1.m1.5.5"></divide><apply id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2"><exp id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"></exp><apply id="S3.E1.m1.2.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1"><divide id="S3.E1.m1.2.2.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.3"></divide><apply id="S3.E1.m1.2.2.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2"><times id="S3.E1.m1.2.2.2.2.1.1.2.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.3"></times><ci id="S3.E1.m1.2.2.2.2.1.1.2.4.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.4">𝑠</ci><ci id="S3.E1.m1.2.2.2.2.1.1.2.5.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.5">𝑖</ci><ci id="S3.E1.m1.2.2.2.2.1.1.2.6.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.6">𝑚</ci><interval closure="open" id="S3.E1.m1.2.2.2.2.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2"><apply id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.2">𝐏</ci><ci id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3a.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.2.3">v</mtext></ci></apply><ci id="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2">superscript</csymbol><apply id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.2">𝐏</ci><ci id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.2.3">v</mtext></ci></apply><apply id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3">superscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.2">𝑖</ci><ci id="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.2.2.2.2.3.3">′</ci></apply></apply></interval></apply><ci id="S3.E1.m1.2.2.2.2.1.1.4.cmml" xref="S3.E1.m1.2.2.2.2.1.1.4">𝜏</ci></apply></apply><apply id="S3.E1.m1.5.5.5.cmml" xref="S3.E1.m1.5.5.5"><apply id="S3.E1.m1.5.5.5.4.cmml" xref="S3.E1.m1.5.5.5.4"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.4.1.cmml" xref="S3.E1.m1.5.5.5.4">subscript</csymbol><apply id="S3.E1.m1.5.5.5.4.2.cmml" xref="S3.E1.m1.5.5.5.4"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.4.2.1.cmml" xref="S3.E1.m1.5.5.5.4">superscript</csymbol><sum id="S3.E1.m1.5.5.5.4.2.2.cmml" xref="S3.E1.m1.5.5.5.4.2.2"></sum><apply id="S3.E1.m1.5.5.5.4.2.3.cmml" xref="S3.E1.m1.5.5.5.4.2.3"><times id="S3.E1.m1.5.5.5.4.2.3.1.cmml" xref="S3.E1.m1.5.5.5.4.2.3.1"></times><cn type="integer" id="S3.E1.m1.5.5.5.4.2.3.2.cmml" xref="S3.E1.m1.5.5.5.4.2.3.2">2</cn><ci id="S3.E1.m1.5.5.5.4.2.3.3.cmml" xref="S3.E1.m1.5.5.5.4.2.3.3">𝐾</ci></apply></apply><apply id="S3.E1.m1.5.5.5.4.3.cmml" xref="S3.E1.m1.5.5.5.4.3"><eq id="S3.E1.m1.5.5.5.4.3.1.cmml" xref="S3.E1.m1.5.5.5.4.3.1"></eq><ci id="S3.E1.m1.5.5.5.4.3.2.cmml" xref="S3.E1.m1.5.5.5.4.3.2">𝑘</ci><cn type="integer" id="S3.E1.m1.5.5.5.4.3.3.cmml" xref="S3.E1.m1.5.5.5.4.3.3">1</cn></apply></apply><apply id="S3.E1.m1.5.5.5.3.cmml" xref="S3.E1.m1.5.5.5.3"><times id="S3.E1.m1.5.5.5.3.2.cmml" xref="S3.E1.m1.5.5.5.3.2"></times><apply id="S3.E1.m1.5.5.5.3.3.cmml" xref="S3.E1.m1.5.5.5.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.3.3.1.cmml" xref="S3.E1.m1.5.5.5.3.3">subscript</csymbol><cn type="integer" id="S3.E1.m1.5.5.5.3.3.2.cmml" xref="S3.E1.m1.5.5.5.3.3.2">1</cn><apply id="S3.E1.m1.3.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.3.3.3.1.1.2.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.3.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1"><neq id="S3.E1.m1.3.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.1"></neq><ci id="S3.E1.m1.3.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.2">𝕜</ci><ci id="S3.E1.m1.3.3.3.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.1.1.1.1.3">𝕚</ci></apply></apply></apply><apply id="S3.E1.m1.5.5.5.3.1.2.cmml" xref="S3.E1.m1.5.5.5.3.1.1"><exp id="S3.E1.m1.4.4.4.2.cmml" xref="S3.E1.m1.4.4.4.2"></exp><apply id="S3.E1.m1.5.5.5.3.1.1.1.1.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1"><divide id="S3.E1.m1.5.5.5.3.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.3"></divide><apply id="S3.E1.m1.5.5.5.3.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2"><times id="S3.E1.m1.5.5.5.3.1.1.1.1.2.3.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.3"></times><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.2.4.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.4">𝕤</ci><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.2.5.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.5">𝕚</ci><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.2.6.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.6">𝕞</ci><interval closure="open" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2"><apply id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.2">𝐏</ci><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.3a.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.2.3">v</mtext></ci></apply><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.1.1.1.1.3">𝕚</ci></apply><apply id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2">superscript</csymbol><apply id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.2">𝐏</ci><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.3a.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.2.3">v</mtext></ci></apply><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.2.2.2.2.3">𝕜</ci></apply></interval></apply><ci id="S3.E1.m1.5.5.5.3.1.1.1.1.4.cmml" xref="S3.E1.m1.5.5.5.3.1.1.1.1.4">𝜏</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">\ell_{\text{NCE}}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{\exp(sim(\mathbf{P}_{\textbf{v}}^{i},\mathbf{P}_{\textbf{v}}^{{}^{\prime}i})/\tau)}{\sum^{2K}_{k=1}\mathbbold{1}_{[k\neq i]}\exp(sim(\mathbf{P}_{\textbf{{v}}}^{i},\mathbf{P}_{\textbf{v}}^{k})/\tau)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.6" class="ltx_p">where <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\tau</annotation></semantics></math> is the positive temperature parameter, <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{P_{v}}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">𝐯</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝐏</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">𝐯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathbf{P_{v}}</annotation></semantics></math> is the representation of video frames, and <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="sim" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.3.m3.1.1.1a" xref="S3.SS2.p1.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.p1.3.m3.1.1.4" xref="S3.SS2.p1.3.m3.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><times id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1"></times><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">𝑠</ci><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">𝑖</ci><ci id="S3.SS2.p1.3.m3.1.1.4.cmml" xref="S3.SS2.p1.3.m3.1.1.4">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">sim</annotation></semantics></math> is a similarity function. By minimizing <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\ell_{\text{NCE}}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><msub id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">ℓ</mi><mtext id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3a.cmml">NCE</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">ℓ</ci><ci id="S3.SS2.p1.4.m4.1.1.3a.cmml" xref="S3.SS2.p1.4.m4.1.1.3"><mtext mathsize="70%" id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">NCE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\ell_{\text{NCE}}</annotation></semantics></math> we are minimizing the distance between the instance <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{P_{v}}" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><msub id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">𝐏</mi><mi id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">𝐯</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">𝐏</ci><ci id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3">𝐯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">\mathbf{P_{v}}</annotation></semantics></math>, and its augmented versions <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="\mathbf{P_{v}}^{{}^{\prime}}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mmultiscripts id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2.2" xref="S3.SS2.p1.6.m6.1.1.2.2.cmml">𝐏</mi><mi id="S3.SS2.p1.6.m6.1.1.2.3" xref="S3.SS2.p1.6.m6.1.1.2.3.cmml">𝐯</mi><mrow id="S3.SS2.p1.6.m6.1.1a" xref="S3.SS2.p1.6.m6.1.1.cmml"></mrow><mrow id="S3.SS2.p1.6.m6.1.1b" xref="S3.SS2.p1.6.m6.1.1.cmml"></mrow><msup id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml"><mi id="S3.SS2.p1.6.m6.1.1.3a" xref="S3.SS2.p1.6.m6.1.1.3.cmml"></mi><mo id="S3.SS2.p1.6.m6.1.1.3.1" xref="S3.SS2.p1.6.m6.1.1.3.1.cmml">′</mo></msup></mmultiscripts><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">superscript</csymbol><apply id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.2.1.cmml" xref="S3.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2.2">𝐏</ci><ci id="S3.SS2.p1.6.m6.1.1.2.3.cmml" xref="S3.SS2.p1.6.m6.1.1.2.3">𝐯</ci></apply><apply id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3"><ci id="S3.SS2.p1.6.m6.1.1.3.1.cmml" xref="S3.SS2.p1.6.m6.1.1.3.1">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\mathbf{P_{v}}^{{}^{\prime}}</annotation></semantics></math>, and maximize the distance between other instances.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Multi-Modal Contrastive Learning</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">To train a network that can project all modality inputs to the same embedding space, we learn a Masked Margin Softmax (MMS) loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite> between each input modality. Masked Margin Softmax (MMS) loss maximizes the similarity of correctly paired modalities and minimizes the similarity of incorrectly paired modalities. In the case of two modalities, text, and video frames. We calculate MMS loss as follows:</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="L_{MMS_{vw}}=L_{wv}+L_{vw}" display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><msub id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.2.2" xref="S3.E2.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E2.m1.1.1.2.3" xref="S3.E2.m1.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.2.3.2" xref="S3.E2.m1.1.1.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.2.3.1" xref="S3.E2.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.2.3.3" xref="S3.E2.m1.1.1.2.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.2.3.1a" xref="S3.E2.m1.1.1.2.3.1.cmml">​</mo><msub id="S3.E2.m1.1.1.2.3.4" xref="S3.E2.m1.1.1.2.3.4.cmml"><mi id="S3.E2.m1.1.1.2.3.4.2" xref="S3.E2.m1.1.1.2.3.4.2.cmml">S</mi><mrow id="S3.E2.m1.1.1.2.3.4.3" xref="S3.E2.m1.1.1.2.3.4.3.cmml"><mi id="S3.E2.m1.1.1.2.3.4.3.2" xref="S3.E2.m1.1.1.2.3.4.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.2.3.4.3.1" xref="S3.E2.m1.1.1.2.3.4.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.2.3.4.3.3" xref="S3.E2.m1.1.1.2.3.4.3.3.cmml">w</mi></mrow></msub></mrow></msub><mo id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><msub id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.3.2.2" xref="S3.E2.m1.1.1.3.2.2.cmml">L</mi><mrow id="S3.E2.m1.1.1.3.2.3" xref="S3.E2.m1.1.1.3.2.3.cmml"><mi id="S3.E2.m1.1.1.3.2.3.2" xref="S3.E2.m1.1.1.3.2.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.2.3.1" xref="S3.E2.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.3.2.3.3" xref="S3.E2.m1.1.1.3.2.3.3.cmml">v</mi></mrow></msub><mo id="S3.E2.m1.1.1.3.1" xref="S3.E2.m1.1.1.3.1.cmml">+</mo><msub id="S3.E2.m1.1.1.3.3" xref="S3.E2.m1.1.1.3.3.cmml"><mi id="S3.E2.m1.1.1.3.3.2" xref="S3.E2.m1.1.1.3.3.2.cmml">L</mi><mrow id="S3.E2.m1.1.1.3.3.3" xref="S3.E2.m1.1.1.3.3.3.cmml"><mi id="S3.E2.m1.1.1.3.3.3.2" xref="S3.E2.m1.1.1.3.3.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.3.3.1" xref="S3.E2.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.3.3.3.3" xref="S3.E2.m1.1.1.3.3.3.3.cmml">w</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"></eq><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.2.2">𝐿</ci><apply id="S3.E2.m1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.2.3"><times id="S3.E2.m1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.2.3.1"></times><ci id="S3.E2.m1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.2.3.2">𝑀</ci><ci id="S3.E2.m1.1.1.2.3.3.cmml" xref="S3.E2.m1.1.1.2.3.3">𝑀</ci><apply id="S3.E2.m1.1.1.2.3.4.cmml" xref="S3.E2.m1.1.1.2.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.3.4.1.cmml" xref="S3.E2.m1.1.1.2.3.4">subscript</csymbol><ci id="S3.E2.m1.1.1.2.3.4.2.cmml" xref="S3.E2.m1.1.1.2.3.4.2">𝑆</ci><apply id="S3.E2.m1.1.1.2.3.4.3.cmml" xref="S3.E2.m1.1.1.2.3.4.3"><times id="S3.E2.m1.1.1.2.3.4.3.1.cmml" xref="S3.E2.m1.1.1.2.3.4.3.1"></times><ci id="S3.E2.m1.1.1.2.3.4.3.2.cmml" xref="S3.E2.m1.1.1.2.3.4.3.2">𝑣</ci><ci id="S3.E2.m1.1.1.2.3.4.3.3.cmml" xref="S3.E2.m1.1.1.2.3.4.3.3">𝑤</ci></apply></apply></apply></apply><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><plus id="S3.E2.m1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.3.1"></plus><apply id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.3.2.2">𝐿</ci><apply id="S3.E2.m1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.3.2.3"><times id="S3.E2.m1.1.1.3.2.3.1.cmml" xref="S3.E2.m1.1.1.3.2.3.1"></times><ci id="S3.E2.m1.1.1.3.2.3.2.cmml" xref="S3.E2.m1.1.1.3.2.3.2">𝑤</ci><ci id="S3.E2.m1.1.1.3.2.3.3.cmml" xref="S3.E2.m1.1.1.3.2.3.3">𝑣</ci></apply></apply><apply id="S3.E2.m1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.3.3.2">𝐿</ci><apply id="S3.E2.m1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.3.3.3"><times id="S3.E2.m1.1.1.3.3.3.1.cmml" xref="S3.E2.m1.1.1.3.3.3.1"></times><ci id="S3.E2.m1.1.1.3.3.3.2.cmml" xref="S3.E2.m1.1.1.3.3.3.2">𝑣</ci><ci id="S3.E2.m1.1.1.3.3.3.3.cmml" xref="S3.E2.m1.1.1.3.3.3.3">𝑤</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">L_{MMS_{vw}}=L_{wv}+L_{vw}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="L_{vw}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{{\rm e}^{\mathbf{P_{v_{i}}}\cdot\mathbf{P_{w_{i}}}-\delta}}{\rm e^{\mathbf{P_{v_{i}}}\cdot\mathbf{P_{w_{i}}}}\sum^{N}_{j=1,j\neq i}\rm e^{\mathbf{P_{v_{j}}}\cdot\mathbf{P_{w_{i}}}}}" display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.3" xref="S3.E3.m1.2.3.cmml"><msub id="S3.E3.m1.2.3.2" xref="S3.E3.m1.2.3.2.cmml"><mi id="S3.E3.m1.2.3.2.2" xref="S3.E3.m1.2.3.2.2.cmml">L</mi><mrow id="S3.E3.m1.2.3.2.3" xref="S3.E3.m1.2.3.2.3.cmml"><mi id="S3.E3.m1.2.3.2.3.2" xref="S3.E3.m1.2.3.2.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.3.2.3.1" xref="S3.E3.m1.2.3.2.3.1.cmml">​</mo><mi id="S3.E3.m1.2.3.2.3.3" xref="S3.E3.m1.2.3.2.3.3.cmml">w</mi></mrow></msub><mo id="S3.E3.m1.2.3.1" xref="S3.E3.m1.2.3.1.cmml">=</mo><mrow id="S3.E3.m1.2.3.3" xref="S3.E3.m1.2.3.3.cmml"><mo id="S3.E3.m1.2.3.3a" xref="S3.E3.m1.2.3.3.cmml">−</mo><mrow id="S3.E3.m1.2.3.3.2" xref="S3.E3.m1.2.3.3.2.cmml"><mfrac id="S3.E3.m1.2.3.3.2.2" xref="S3.E3.m1.2.3.3.2.2.cmml"><mn id="S3.E3.m1.2.3.3.2.2.2" xref="S3.E3.m1.2.3.3.2.2.2.cmml">1</mn><mi id="S3.E3.m1.2.3.3.2.2.3" xref="S3.E3.m1.2.3.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.3.3.2.1" xref="S3.E3.m1.2.3.3.2.1.cmml">​</mo><mrow id="S3.E3.m1.2.3.3.2.3" xref="S3.E3.m1.2.3.3.2.3.cmml"><munderover id="S3.E3.m1.2.3.3.2.3.1" xref="S3.E3.m1.2.3.3.2.3.1.cmml"><mo movablelimits="false" id="S3.E3.m1.2.3.3.2.3.1.2.2" xref="S3.E3.m1.2.3.3.2.3.1.2.2.cmml">∑</mo><mrow id="S3.E3.m1.2.3.3.2.3.1.2.3" xref="S3.E3.m1.2.3.3.2.3.1.2.3.cmml"><mi id="S3.E3.m1.2.3.3.2.3.1.2.3.2" xref="S3.E3.m1.2.3.3.2.3.1.2.3.2.cmml">i</mi><mo id="S3.E3.m1.2.3.3.2.3.1.2.3.1" xref="S3.E3.m1.2.3.3.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E3.m1.2.3.3.2.3.1.2.3.3" xref="S3.E3.m1.2.3.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.2.3.3.2.3.1.3" xref="S3.E3.m1.2.3.3.2.3.1.3.cmml">N</mi></munderover><mrow id="S3.E3.m1.2.3.3.2.3.2" xref="S3.E3.m1.2.3.3.2.3.2.cmml"><mi id="S3.E3.m1.2.3.3.2.3.2.1" xref="S3.E3.m1.2.3.3.2.3.2.1.cmml">log</mi><mo lspace="0.167em" id="S3.E3.m1.2.3.3.2.3.2a" xref="S3.E3.m1.2.3.3.2.3.2.cmml">⁡</mo><mfrac id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msup id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml"><mi mathvariant="normal" id="S3.E3.m1.2.2.4.2" xref="S3.E3.m1.2.2.4.2.cmml">e</mi><mrow id="S3.E3.m1.2.2.4.3" xref="S3.E3.m1.2.2.4.3.cmml"><mrow id="S3.E3.m1.2.2.4.3.2" xref="S3.E3.m1.2.2.4.3.2.cmml"><msub id="S3.E3.m1.2.2.4.3.2.2" xref="S3.E3.m1.2.2.4.3.2.2.cmml"><mi id="S3.E3.m1.2.2.4.3.2.2.2" xref="S3.E3.m1.2.2.4.3.2.2.2.cmml">𝐏</mi><msub id="S3.E3.m1.2.2.4.3.2.2.3" xref="S3.E3.m1.2.2.4.3.2.2.3.cmml"><mi id="S3.E3.m1.2.2.4.3.2.2.3.2" xref="S3.E3.m1.2.2.4.3.2.2.3.2.cmml">𝐯</mi><mi id="S3.E3.m1.2.2.4.3.2.2.3.3" xref="S3.E3.m1.2.2.4.3.2.2.3.3.cmml">𝐢</mi></msub></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.2.2.4.3.2.1" xref="S3.E3.m1.2.2.4.3.2.1.cmml">⋅</mo><msub id="S3.E3.m1.2.2.4.3.2.3" xref="S3.E3.m1.2.2.4.3.2.3.cmml"><mi id="S3.E3.m1.2.2.4.3.2.3.2" xref="S3.E3.m1.2.2.4.3.2.3.2.cmml">𝐏</mi><msub id="S3.E3.m1.2.2.4.3.2.3.3" xref="S3.E3.m1.2.2.4.3.2.3.3.cmml"><mi id="S3.E3.m1.2.2.4.3.2.3.3.2" xref="S3.E3.m1.2.2.4.3.2.3.3.2.cmml">𝐰</mi><mi id="S3.E3.m1.2.2.4.3.2.3.3.3" xref="S3.E3.m1.2.2.4.3.2.3.3.3.cmml">𝐢</mi></msub></msub></mrow><mo id="S3.E3.m1.2.2.4.3.1" xref="S3.E3.m1.2.2.4.3.1.cmml">−</mo><mi id="S3.E3.m1.2.2.4.3.3" xref="S3.E3.m1.2.2.4.3.3.cmml">δ</mi></mrow></msup><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><msup id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.4.cmml"><mi mathvariant="normal" id="S3.E3.m1.2.2.2.4.2" xref="S3.E3.m1.2.2.2.4.2.cmml">e</mi><mrow id="S3.E3.m1.2.2.2.4.3" xref="S3.E3.m1.2.2.2.4.3.cmml"><msub id="S3.E3.m1.2.2.2.4.3.2" xref="S3.E3.m1.2.2.2.4.3.2.cmml"><mi id="S3.E3.m1.2.2.2.4.3.2.2" xref="S3.E3.m1.2.2.2.4.3.2.2.cmml">𝐏</mi><msub id="S3.E3.m1.2.2.2.4.3.2.3" xref="S3.E3.m1.2.2.2.4.3.2.3.cmml"><mi id="S3.E3.m1.2.2.2.4.3.2.3.2" xref="S3.E3.m1.2.2.2.4.3.2.3.2.cmml">𝐯</mi><mi id="S3.E3.m1.2.2.2.4.3.2.3.3" xref="S3.E3.m1.2.2.2.4.3.2.3.3.cmml">𝐢</mi></msub></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.2.2.2.4.3.1" xref="S3.E3.m1.2.2.2.4.3.1.cmml">⋅</mo><msub id="S3.E3.m1.2.2.2.4.3.3" xref="S3.E3.m1.2.2.2.4.3.3.cmml"><mi id="S3.E3.m1.2.2.2.4.3.3.2" xref="S3.E3.m1.2.2.2.4.3.3.2.cmml">𝐏</mi><msub id="S3.E3.m1.2.2.2.4.3.3.3" xref="S3.E3.m1.2.2.2.4.3.3.3.cmml"><mi id="S3.E3.m1.2.2.2.4.3.3.3.2" xref="S3.E3.m1.2.2.2.4.3.3.3.2.cmml">𝐰</mi><mi id="S3.E3.m1.2.2.2.4.3.3.3.3" xref="S3.E3.m1.2.2.2.4.3.3.3.3.cmml">𝐢</mi></msub></msub></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml">​</mo><mrow id="S3.E3.m1.2.2.2.5" xref="S3.E3.m1.2.2.2.5.cmml"><msubsup id="S3.E3.m1.2.2.2.5.1" xref="S3.E3.m1.2.2.2.5.1.cmml"><mo id="S3.E3.m1.2.2.2.5.1.2.2" xref="S3.E3.m1.2.2.2.5.1.2.2.cmml">∑</mo><mrow id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.3.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.2.cmml">j</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml">=</mo><mn id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.E3.m1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.3a.cmml">,</mo><mrow id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.E3.m1.2.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.2.cmml">j</mi><mo id="S3.E3.m1.2.2.2.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.2.2.2.1.cmml">≠</mo><mi mathvariant="normal" id="S3.E3.m1.2.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.2.3.cmml">i</mi></mrow></mrow><mi mathvariant="normal" id="S3.E3.m1.2.2.2.5.1.2.3" xref="S3.E3.m1.2.2.2.5.1.2.3.cmml">N</mi></msubsup><msup id="S3.E3.m1.2.2.2.5.2" xref="S3.E3.m1.2.2.2.5.2.cmml"><mi mathvariant="normal" id="S3.E3.m1.2.2.2.5.2.2" xref="S3.E3.m1.2.2.2.5.2.2.cmml">e</mi><mrow id="S3.E3.m1.2.2.2.5.2.3" xref="S3.E3.m1.2.2.2.5.2.3.cmml"><msub id="S3.E3.m1.2.2.2.5.2.3.2" xref="S3.E3.m1.2.2.2.5.2.3.2.cmml"><mi id="S3.E3.m1.2.2.2.5.2.3.2.2" xref="S3.E3.m1.2.2.2.5.2.3.2.2.cmml">𝐏</mi><msub id="S3.E3.m1.2.2.2.5.2.3.2.3" xref="S3.E3.m1.2.2.2.5.2.3.2.3.cmml"><mi id="S3.E3.m1.2.2.2.5.2.3.2.3.2" xref="S3.E3.m1.2.2.2.5.2.3.2.3.2.cmml">𝐯</mi><mi id="S3.E3.m1.2.2.2.5.2.3.2.3.3" xref="S3.E3.m1.2.2.2.5.2.3.2.3.3.cmml">𝐣</mi></msub></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E3.m1.2.2.2.5.2.3.1" xref="S3.E3.m1.2.2.2.5.2.3.1.cmml">⋅</mo><msub id="S3.E3.m1.2.2.2.5.2.3.3" xref="S3.E3.m1.2.2.2.5.2.3.3.cmml"><mi id="S3.E3.m1.2.2.2.5.2.3.3.2" xref="S3.E3.m1.2.2.2.5.2.3.3.2.cmml">𝐏</mi><msub id="S3.E3.m1.2.2.2.5.2.3.3.3" xref="S3.E3.m1.2.2.2.5.2.3.3.3.cmml"><mi id="S3.E3.m1.2.2.2.5.2.3.3.3.2" xref="S3.E3.m1.2.2.2.5.2.3.3.3.2.cmml">𝐰</mi><mi id="S3.E3.m1.2.2.2.5.2.3.3.3.3" xref="S3.E3.m1.2.2.2.5.2.3.3.3.3.cmml">𝐢</mi></msub></msub></mrow></msup></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.3.cmml" xref="S3.E3.m1.2.3"><eq id="S3.E3.m1.2.3.1.cmml" xref="S3.E3.m1.2.3.1"></eq><apply id="S3.E3.m1.2.3.2.cmml" xref="S3.E3.m1.2.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.3.2.1.cmml" xref="S3.E3.m1.2.3.2">subscript</csymbol><ci id="S3.E3.m1.2.3.2.2.cmml" xref="S3.E3.m1.2.3.2.2">𝐿</ci><apply id="S3.E3.m1.2.3.2.3.cmml" xref="S3.E3.m1.2.3.2.3"><times id="S3.E3.m1.2.3.2.3.1.cmml" xref="S3.E3.m1.2.3.2.3.1"></times><ci id="S3.E3.m1.2.3.2.3.2.cmml" xref="S3.E3.m1.2.3.2.3.2">𝑣</ci><ci id="S3.E3.m1.2.3.2.3.3.cmml" xref="S3.E3.m1.2.3.2.3.3">𝑤</ci></apply></apply><apply id="S3.E3.m1.2.3.3.cmml" xref="S3.E3.m1.2.3.3"><minus id="S3.E3.m1.2.3.3.1.cmml" xref="S3.E3.m1.2.3.3"></minus><apply id="S3.E3.m1.2.3.3.2.cmml" xref="S3.E3.m1.2.3.3.2"><times id="S3.E3.m1.2.3.3.2.1.cmml" xref="S3.E3.m1.2.3.3.2.1"></times><apply id="S3.E3.m1.2.3.3.2.2.cmml" xref="S3.E3.m1.2.3.3.2.2"><divide id="S3.E3.m1.2.3.3.2.2.1.cmml" xref="S3.E3.m1.2.3.3.2.2"></divide><cn type="integer" id="S3.E3.m1.2.3.3.2.2.2.cmml" xref="S3.E3.m1.2.3.3.2.2.2">1</cn><ci id="S3.E3.m1.2.3.3.2.2.3.cmml" xref="S3.E3.m1.2.3.3.2.2.3">𝑁</ci></apply><apply id="S3.E3.m1.2.3.3.2.3.cmml" xref="S3.E3.m1.2.3.3.2.3"><apply id="S3.E3.m1.2.3.3.2.3.1.cmml" xref="S3.E3.m1.2.3.3.2.3.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.3.3.2.3.1.1.cmml" xref="S3.E3.m1.2.3.3.2.3.1">superscript</csymbol><apply id="S3.E3.m1.2.3.3.2.3.1.2.cmml" xref="S3.E3.m1.2.3.3.2.3.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.3.3.2.3.1.2.1.cmml" xref="S3.E3.m1.2.3.3.2.3.1">subscript</csymbol><sum id="S3.E3.m1.2.3.3.2.3.1.2.2.cmml" xref="S3.E3.m1.2.3.3.2.3.1.2.2"></sum><apply id="S3.E3.m1.2.3.3.2.3.1.2.3.cmml" xref="S3.E3.m1.2.3.3.2.3.1.2.3"><eq id="S3.E3.m1.2.3.3.2.3.1.2.3.1.cmml" xref="S3.E3.m1.2.3.3.2.3.1.2.3.1"></eq><ci id="S3.E3.m1.2.3.3.2.3.1.2.3.2.cmml" xref="S3.E3.m1.2.3.3.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E3.m1.2.3.3.2.3.1.2.3.3.cmml" xref="S3.E3.m1.2.3.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.2.3.3.2.3.1.3.cmml" xref="S3.E3.m1.2.3.3.2.3.1.3">𝑁</ci></apply><apply id="S3.E3.m1.2.3.3.2.3.2.cmml" xref="S3.E3.m1.2.3.3.2.3.2"><log id="S3.E3.m1.2.3.3.2.3.2.1.cmml" xref="S3.E3.m1.2.3.3.2.3.2.1"></log><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><divide id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2"></divide><apply id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.4">superscript</csymbol><ci id="S3.E3.m1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.4.2">e</ci><apply id="S3.E3.m1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.4.3"><minus id="S3.E3.m1.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.4.3.1"></minus><apply id="S3.E3.m1.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.4.3.2"><ci id="S3.E3.m1.2.2.4.3.2.1.cmml" xref="S3.E3.m1.2.2.4.3.2.1">⋅</ci><apply id="S3.E3.m1.2.2.4.3.2.2.cmml" xref="S3.E3.m1.2.2.4.3.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.3.2.2.1.cmml" xref="S3.E3.m1.2.2.4.3.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.4.3.2.2.2.cmml" xref="S3.E3.m1.2.2.4.3.2.2.2">𝐏</ci><apply id="S3.E3.m1.2.2.4.3.2.2.3.cmml" xref="S3.E3.m1.2.2.4.3.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.3.2.2.3.1.cmml" xref="S3.E3.m1.2.2.4.3.2.2.3">subscript</csymbol><ci id="S3.E3.m1.2.2.4.3.2.2.3.2.cmml" xref="S3.E3.m1.2.2.4.3.2.2.3.2">𝐯</ci><ci id="S3.E3.m1.2.2.4.3.2.2.3.3.cmml" xref="S3.E3.m1.2.2.4.3.2.2.3.3">𝐢</ci></apply></apply><apply id="S3.E3.m1.2.2.4.3.2.3.cmml" xref="S3.E3.m1.2.2.4.3.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.3.2.3.1.cmml" xref="S3.E3.m1.2.2.4.3.2.3">subscript</csymbol><ci id="S3.E3.m1.2.2.4.3.2.3.2.cmml" xref="S3.E3.m1.2.2.4.3.2.3.2">𝐏</ci><apply id="S3.E3.m1.2.2.4.3.2.3.3.cmml" xref="S3.E3.m1.2.2.4.3.2.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.3.2.3.3.1.cmml" xref="S3.E3.m1.2.2.4.3.2.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.4.3.2.3.3.2.cmml" xref="S3.E3.m1.2.2.4.3.2.3.3.2">𝐰</ci><ci id="S3.E3.m1.2.2.4.3.2.3.3.3.cmml" xref="S3.E3.m1.2.2.4.3.2.3.3.3">𝐢</ci></apply></apply></apply><ci id="S3.E3.m1.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.4.3.3">𝛿</ci></apply></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><times id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></times><apply id="S3.E3.m1.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.4.1.cmml" xref="S3.E3.m1.2.2.2.4">superscript</csymbol><ci id="S3.E3.m1.2.2.2.4.2.cmml" xref="S3.E3.m1.2.2.2.4.2">e</ci><apply id="S3.E3.m1.2.2.2.4.3.cmml" xref="S3.E3.m1.2.2.2.4.3"><ci id="S3.E3.m1.2.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.2.4.3.1">⋅</ci><apply id="S3.E3.m1.2.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.2.4.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.4.3.2.1.cmml" xref="S3.E3.m1.2.2.2.4.3.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.4.3.2.2.cmml" xref="S3.E3.m1.2.2.2.4.3.2.2">𝐏</ci><apply id="S3.E3.m1.2.2.2.4.3.2.3.cmml" xref="S3.E3.m1.2.2.2.4.3.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.4.3.2.3.1.cmml" xref="S3.E3.m1.2.2.2.4.3.2.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.4.3.2.3.2.cmml" xref="S3.E3.m1.2.2.2.4.3.2.3.2">𝐯</ci><ci id="S3.E3.m1.2.2.2.4.3.2.3.3.cmml" xref="S3.E3.m1.2.2.2.4.3.2.3.3">𝐢</ci></apply></apply><apply id="S3.E3.m1.2.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.2.4.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.4.3.3.1.cmml" xref="S3.E3.m1.2.2.2.4.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.4.3.3.2.cmml" xref="S3.E3.m1.2.2.2.4.3.3.2">𝐏</ci><apply id="S3.E3.m1.2.2.2.4.3.3.3.cmml" xref="S3.E3.m1.2.2.2.4.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.4.3.3.3.1.cmml" xref="S3.E3.m1.2.2.2.4.3.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.4.3.3.3.2.cmml" xref="S3.E3.m1.2.2.2.4.3.3.3.2">𝐰</ci><ci id="S3.E3.m1.2.2.2.4.3.3.3.3.cmml" xref="S3.E3.m1.2.2.2.4.3.3.3.3">𝐢</ci></apply></apply></apply></apply><apply id="S3.E3.m1.2.2.2.5.cmml" xref="S3.E3.m1.2.2.2.5"><apply id="S3.E3.m1.2.2.2.5.1.cmml" xref="S3.E3.m1.2.2.2.5.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.5.1.1.cmml" xref="S3.E3.m1.2.2.2.5.1">subscript</csymbol><apply id="S3.E3.m1.2.2.2.5.1.2.cmml" xref="S3.E3.m1.2.2.2.5.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.5.1.2.1.cmml" xref="S3.E3.m1.2.2.2.5.1">superscript</csymbol><sum id="S3.E3.m1.2.2.2.5.1.2.2.cmml" xref="S3.E3.m1.2.2.2.5.1.2.2"></sum><ci id="S3.E3.m1.2.2.2.5.1.2.3.cmml" xref="S3.E3.m1.2.2.2.5.1.2.3">N</ci></apply><apply id="S3.E3.m1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.3a.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"></eq><ci id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2">j</ci><cn type="integer" id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.E3.m1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2"><neq id="S3.E3.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.1"></neq><ci id="S3.E3.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.2">j</ci><ci id="S3.E3.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.3">i</ci></apply></apply></apply><apply id="S3.E3.m1.2.2.2.5.2.cmml" xref="S3.E3.m1.2.2.2.5.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.5.2.1.cmml" xref="S3.E3.m1.2.2.2.5.2">superscript</csymbol><ci id="S3.E3.m1.2.2.2.5.2.2.cmml" xref="S3.E3.m1.2.2.2.5.2.2">e</ci><apply id="S3.E3.m1.2.2.2.5.2.3.cmml" xref="S3.E3.m1.2.2.2.5.2.3"><ci id="S3.E3.m1.2.2.2.5.2.3.1.cmml" xref="S3.E3.m1.2.2.2.5.2.3.1">⋅</ci><apply id="S3.E3.m1.2.2.2.5.2.3.2.cmml" xref="S3.E3.m1.2.2.2.5.2.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.5.2.3.2.1.cmml" xref="S3.E3.m1.2.2.2.5.2.3.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.5.2.3.2.2.cmml" xref="S3.E3.m1.2.2.2.5.2.3.2.2">𝐏</ci><apply id="S3.E3.m1.2.2.2.5.2.3.2.3.cmml" xref="S3.E3.m1.2.2.2.5.2.3.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.5.2.3.2.3.1.cmml" xref="S3.E3.m1.2.2.2.5.2.3.2.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.5.2.3.2.3.2.cmml" xref="S3.E3.m1.2.2.2.5.2.3.2.3.2">𝐯</ci><ci id="S3.E3.m1.2.2.2.5.2.3.2.3.3.cmml" xref="S3.E3.m1.2.2.2.5.2.3.2.3.3">𝐣</ci></apply></apply><apply id="S3.E3.m1.2.2.2.5.2.3.3.cmml" xref="S3.E3.m1.2.2.2.5.2.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.5.2.3.3.1.cmml" xref="S3.E3.m1.2.2.2.5.2.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.5.2.3.3.2.cmml" xref="S3.E3.m1.2.2.2.5.2.3.3.2">𝐏</ci><apply id="S3.E3.m1.2.2.2.5.2.3.3.3.cmml" xref="S3.E3.m1.2.2.2.5.2.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.5.2.3.3.3.1.cmml" xref="S3.E3.m1.2.2.2.5.2.3.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.2.5.2.3.3.3.2.cmml" xref="S3.E3.m1.2.2.2.5.2.3.3.3.2">𝐰</ci><ci id="S3.E3.m1.2.2.2.5.2.3.3.3.3.cmml" xref="S3.E3.m1.2.2.2.5.2.3.3.3.3">𝐢</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">L_{vw}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{{\rm e}^{\mathbf{P_{v_{i}}}\cdot\mathbf{P_{w_{i}}}-\delta}}{\rm e^{\mathbf{P_{v_{i}}}\cdot\mathbf{P_{w_{i}}}}\sum^{N}_{j=1,j\neq i}\rm e^{\mathbf{P_{v_{j}}}\cdot\mathbf{P_{w_{i}}}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.2" class="ltx_Math" alttext="L_{wv}=-\frac{1}{N}\sum_{j=1}^{N}\log\frac{{\rm e}^{\mathbf{P_{v_{j}}}\cdot\mathbf{P_{w_{j}}}-\delta}}{\rm e^{\mathbf{P_{v_{j}}}\cdot\mathbf{P_{w_{j}}}}\sum^{N}_{i=1,j\neq i}\rm e^{\mathbf{P_{v_{i}}}\cdot\mathbf{P_{w_{j}}}}}" display="block"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.3" xref="S3.E4.m1.2.3.cmml"><msub id="S3.E4.m1.2.3.2" xref="S3.E4.m1.2.3.2.cmml"><mi id="S3.E4.m1.2.3.2.2" xref="S3.E4.m1.2.3.2.2.cmml">L</mi><mrow id="S3.E4.m1.2.3.2.3" xref="S3.E4.m1.2.3.2.3.cmml"><mi id="S3.E4.m1.2.3.2.3.2" xref="S3.E4.m1.2.3.2.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.3.2.3.1" xref="S3.E4.m1.2.3.2.3.1.cmml">​</mo><mi id="S3.E4.m1.2.3.2.3.3" xref="S3.E4.m1.2.3.2.3.3.cmml">v</mi></mrow></msub><mo id="S3.E4.m1.2.3.1" xref="S3.E4.m1.2.3.1.cmml">=</mo><mrow id="S3.E4.m1.2.3.3" xref="S3.E4.m1.2.3.3.cmml"><mo id="S3.E4.m1.2.3.3a" xref="S3.E4.m1.2.3.3.cmml">−</mo><mrow id="S3.E4.m1.2.3.3.2" xref="S3.E4.m1.2.3.3.2.cmml"><mfrac id="S3.E4.m1.2.3.3.2.2" xref="S3.E4.m1.2.3.3.2.2.cmml"><mn id="S3.E4.m1.2.3.3.2.2.2" xref="S3.E4.m1.2.3.3.2.2.2.cmml">1</mn><mi id="S3.E4.m1.2.3.3.2.2.3" xref="S3.E4.m1.2.3.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.3.3.2.1" xref="S3.E4.m1.2.3.3.2.1.cmml">​</mo><mrow id="S3.E4.m1.2.3.3.2.3" xref="S3.E4.m1.2.3.3.2.3.cmml"><munderover id="S3.E4.m1.2.3.3.2.3.1" xref="S3.E4.m1.2.3.3.2.3.1.cmml"><mo movablelimits="false" id="S3.E4.m1.2.3.3.2.3.1.2.2" xref="S3.E4.m1.2.3.3.2.3.1.2.2.cmml">∑</mo><mrow id="S3.E4.m1.2.3.3.2.3.1.2.3" xref="S3.E4.m1.2.3.3.2.3.1.2.3.cmml"><mi id="S3.E4.m1.2.3.3.2.3.1.2.3.2" xref="S3.E4.m1.2.3.3.2.3.1.2.3.2.cmml">j</mi><mo id="S3.E4.m1.2.3.3.2.3.1.2.3.1" xref="S3.E4.m1.2.3.3.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E4.m1.2.3.3.2.3.1.2.3.3" xref="S3.E4.m1.2.3.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.2.3.3.2.3.1.3" xref="S3.E4.m1.2.3.3.2.3.1.3.cmml">N</mi></munderover><mrow id="S3.E4.m1.2.3.3.2.3.2" xref="S3.E4.m1.2.3.3.2.3.2.cmml"><mi id="S3.E4.m1.2.3.3.2.3.2.1" xref="S3.E4.m1.2.3.3.2.3.2.1.cmml">log</mi><mo lspace="0.167em" id="S3.E4.m1.2.3.3.2.3.2a" xref="S3.E4.m1.2.3.3.2.3.2.cmml">⁡</mo><mfrac id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><msup id="S3.E4.m1.2.2.4" xref="S3.E4.m1.2.2.4.cmml"><mi mathvariant="normal" id="S3.E4.m1.2.2.4.2" xref="S3.E4.m1.2.2.4.2.cmml">e</mi><mrow id="S3.E4.m1.2.2.4.3" xref="S3.E4.m1.2.2.4.3.cmml"><mrow id="S3.E4.m1.2.2.4.3.2" xref="S3.E4.m1.2.2.4.3.2.cmml"><msub id="S3.E4.m1.2.2.4.3.2.2" xref="S3.E4.m1.2.2.4.3.2.2.cmml"><mi id="S3.E4.m1.2.2.4.3.2.2.2" xref="S3.E4.m1.2.2.4.3.2.2.2.cmml">𝐏</mi><msub id="S3.E4.m1.2.2.4.3.2.2.3" xref="S3.E4.m1.2.2.4.3.2.2.3.cmml"><mi id="S3.E4.m1.2.2.4.3.2.2.3.2" xref="S3.E4.m1.2.2.4.3.2.2.3.2.cmml">𝐯</mi><mi id="S3.E4.m1.2.2.4.3.2.2.3.3" xref="S3.E4.m1.2.2.4.3.2.2.3.3.cmml">𝐣</mi></msub></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.2.2.4.3.2.1" xref="S3.E4.m1.2.2.4.3.2.1.cmml">⋅</mo><msub id="S3.E4.m1.2.2.4.3.2.3" xref="S3.E4.m1.2.2.4.3.2.3.cmml"><mi id="S3.E4.m1.2.2.4.3.2.3.2" xref="S3.E4.m1.2.2.4.3.2.3.2.cmml">𝐏</mi><msub id="S3.E4.m1.2.2.4.3.2.3.3" xref="S3.E4.m1.2.2.4.3.2.3.3.cmml"><mi id="S3.E4.m1.2.2.4.3.2.3.3.2" xref="S3.E4.m1.2.2.4.3.2.3.3.2.cmml">𝐰</mi><mi id="S3.E4.m1.2.2.4.3.2.3.3.3" xref="S3.E4.m1.2.2.4.3.2.3.3.3.cmml">𝐣</mi></msub></msub></mrow><mo id="S3.E4.m1.2.2.4.3.1" xref="S3.E4.m1.2.2.4.3.1.cmml">−</mo><mi id="S3.E4.m1.2.2.4.3.3" xref="S3.E4.m1.2.2.4.3.3.cmml">δ</mi></mrow></msup><mrow id="S3.E4.m1.2.2.2" xref="S3.E4.m1.2.2.2.cmml"><msup id="S3.E4.m1.2.2.2.4" xref="S3.E4.m1.2.2.2.4.cmml"><mi mathvariant="normal" id="S3.E4.m1.2.2.2.4.2" xref="S3.E4.m1.2.2.2.4.2.cmml">e</mi><mrow id="S3.E4.m1.2.2.2.4.3" xref="S3.E4.m1.2.2.2.4.3.cmml"><msub id="S3.E4.m1.2.2.2.4.3.2" xref="S3.E4.m1.2.2.2.4.3.2.cmml"><mi id="S3.E4.m1.2.2.2.4.3.2.2" xref="S3.E4.m1.2.2.2.4.3.2.2.cmml">𝐏</mi><msub id="S3.E4.m1.2.2.2.4.3.2.3" xref="S3.E4.m1.2.2.2.4.3.2.3.cmml"><mi id="S3.E4.m1.2.2.2.4.3.2.3.2" xref="S3.E4.m1.2.2.2.4.3.2.3.2.cmml">𝐯</mi><mi id="S3.E4.m1.2.2.2.4.3.2.3.3" xref="S3.E4.m1.2.2.2.4.3.2.3.3.cmml">𝐣</mi></msub></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.2.2.2.4.3.1" xref="S3.E4.m1.2.2.2.4.3.1.cmml">⋅</mo><msub id="S3.E4.m1.2.2.2.4.3.3" xref="S3.E4.m1.2.2.2.4.3.3.cmml"><mi id="S3.E4.m1.2.2.2.4.3.3.2" xref="S3.E4.m1.2.2.2.4.3.3.2.cmml">𝐏</mi><msub id="S3.E4.m1.2.2.2.4.3.3.3" xref="S3.E4.m1.2.2.2.4.3.3.3.cmml"><mi id="S3.E4.m1.2.2.2.4.3.3.3.2" xref="S3.E4.m1.2.2.2.4.3.3.3.2.cmml">𝐰</mi><mi id="S3.E4.m1.2.2.2.4.3.3.3.3" xref="S3.E4.m1.2.2.2.4.3.3.3.3.cmml">𝐣</mi></msub></msub></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.3" xref="S3.E4.m1.2.2.2.3.cmml">​</mo><mrow id="S3.E4.m1.2.2.2.5" xref="S3.E4.m1.2.2.2.5.cmml"><msubsup id="S3.E4.m1.2.2.2.5.1" xref="S3.E4.m1.2.2.2.5.1.cmml"><mo id="S3.E4.m1.2.2.2.5.1.2.2" xref="S3.E4.m1.2.2.2.5.1.2.2.cmml">∑</mo><mrow id="S3.E4.m1.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.3.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml">i</mi><mo id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">=</mo><mn id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.E4.m1.2.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.2.3a.cmml">,</mo><mrow id="S3.E4.m1.2.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.E4.m1.2.2.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.2.2.cmml">j</mi><mo id="S3.E4.m1.2.2.2.2.2.2.2.1" xref="S3.E4.m1.2.2.2.2.2.2.2.1.cmml">≠</mo><mi mathvariant="normal" id="S3.E4.m1.2.2.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.2.2.2.3.cmml">i</mi></mrow></mrow><mi mathvariant="normal" id="S3.E4.m1.2.2.2.5.1.2.3" xref="S3.E4.m1.2.2.2.5.1.2.3.cmml">N</mi></msubsup><msup id="S3.E4.m1.2.2.2.5.2" xref="S3.E4.m1.2.2.2.5.2.cmml"><mi mathvariant="normal" id="S3.E4.m1.2.2.2.5.2.2" xref="S3.E4.m1.2.2.2.5.2.2.cmml">e</mi><mrow id="S3.E4.m1.2.2.2.5.2.3" xref="S3.E4.m1.2.2.2.5.2.3.cmml"><msub id="S3.E4.m1.2.2.2.5.2.3.2" xref="S3.E4.m1.2.2.2.5.2.3.2.cmml"><mi id="S3.E4.m1.2.2.2.5.2.3.2.2" xref="S3.E4.m1.2.2.2.5.2.3.2.2.cmml">𝐏</mi><msub id="S3.E4.m1.2.2.2.5.2.3.2.3" xref="S3.E4.m1.2.2.2.5.2.3.2.3.cmml"><mi id="S3.E4.m1.2.2.2.5.2.3.2.3.2" xref="S3.E4.m1.2.2.2.5.2.3.2.3.2.cmml">𝐯</mi><mi id="S3.E4.m1.2.2.2.5.2.3.2.3.3" xref="S3.E4.m1.2.2.2.5.2.3.2.3.3.cmml">𝐢</mi></msub></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.2.2.2.5.2.3.1" xref="S3.E4.m1.2.2.2.5.2.3.1.cmml">⋅</mo><msub id="S3.E4.m1.2.2.2.5.2.3.3" xref="S3.E4.m1.2.2.2.5.2.3.3.cmml"><mi id="S3.E4.m1.2.2.2.5.2.3.3.2" xref="S3.E4.m1.2.2.2.5.2.3.3.2.cmml">𝐏</mi><msub id="S3.E4.m1.2.2.2.5.2.3.3.3" xref="S3.E4.m1.2.2.2.5.2.3.3.3.cmml"><mi id="S3.E4.m1.2.2.2.5.2.3.3.3.2" xref="S3.E4.m1.2.2.2.5.2.3.3.3.2.cmml">𝐰</mi><mi id="S3.E4.m1.2.2.2.5.2.3.3.3.3" xref="S3.E4.m1.2.2.2.5.2.3.3.3.3.cmml">𝐣</mi></msub></msub></mrow></msup></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.3.cmml" xref="S3.E4.m1.2.3"><eq id="S3.E4.m1.2.3.1.cmml" xref="S3.E4.m1.2.3.1"></eq><apply id="S3.E4.m1.2.3.2.cmml" xref="S3.E4.m1.2.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.3.2.1.cmml" xref="S3.E4.m1.2.3.2">subscript</csymbol><ci id="S3.E4.m1.2.3.2.2.cmml" xref="S3.E4.m1.2.3.2.2">𝐿</ci><apply id="S3.E4.m1.2.3.2.3.cmml" xref="S3.E4.m1.2.3.2.3"><times id="S3.E4.m1.2.3.2.3.1.cmml" xref="S3.E4.m1.2.3.2.3.1"></times><ci id="S3.E4.m1.2.3.2.3.2.cmml" xref="S3.E4.m1.2.3.2.3.2">𝑤</ci><ci id="S3.E4.m1.2.3.2.3.3.cmml" xref="S3.E4.m1.2.3.2.3.3">𝑣</ci></apply></apply><apply id="S3.E4.m1.2.3.3.cmml" xref="S3.E4.m1.2.3.3"><minus id="S3.E4.m1.2.3.3.1.cmml" xref="S3.E4.m1.2.3.3"></minus><apply id="S3.E4.m1.2.3.3.2.cmml" xref="S3.E4.m1.2.3.3.2"><times id="S3.E4.m1.2.3.3.2.1.cmml" xref="S3.E4.m1.2.3.3.2.1"></times><apply id="S3.E4.m1.2.3.3.2.2.cmml" xref="S3.E4.m1.2.3.3.2.2"><divide id="S3.E4.m1.2.3.3.2.2.1.cmml" xref="S3.E4.m1.2.3.3.2.2"></divide><cn type="integer" id="S3.E4.m1.2.3.3.2.2.2.cmml" xref="S3.E4.m1.2.3.3.2.2.2">1</cn><ci id="S3.E4.m1.2.3.3.2.2.3.cmml" xref="S3.E4.m1.2.3.3.2.2.3">𝑁</ci></apply><apply id="S3.E4.m1.2.3.3.2.3.cmml" xref="S3.E4.m1.2.3.3.2.3"><apply id="S3.E4.m1.2.3.3.2.3.1.cmml" xref="S3.E4.m1.2.3.3.2.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.3.3.2.3.1.1.cmml" xref="S3.E4.m1.2.3.3.2.3.1">superscript</csymbol><apply id="S3.E4.m1.2.3.3.2.3.1.2.cmml" xref="S3.E4.m1.2.3.3.2.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.3.3.2.3.1.2.1.cmml" xref="S3.E4.m1.2.3.3.2.3.1">subscript</csymbol><sum id="S3.E4.m1.2.3.3.2.3.1.2.2.cmml" xref="S3.E4.m1.2.3.3.2.3.1.2.2"></sum><apply id="S3.E4.m1.2.3.3.2.3.1.2.3.cmml" xref="S3.E4.m1.2.3.3.2.3.1.2.3"><eq id="S3.E4.m1.2.3.3.2.3.1.2.3.1.cmml" xref="S3.E4.m1.2.3.3.2.3.1.2.3.1"></eq><ci id="S3.E4.m1.2.3.3.2.3.1.2.3.2.cmml" xref="S3.E4.m1.2.3.3.2.3.1.2.3.2">𝑗</ci><cn type="integer" id="S3.E4.m1.2.3.3.2.3.1.2.3.3.cmml" xref="S3.E4.m1.2.3.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.2.3.3.2.3.1.3.cmml" xref="S3.E4.m1.2.3.3.2.3.1.3">𝑁</ci></apply><apply id="S3.E4.m1.2.3.3.2.3.2.cmml" xref="S3.E4.m1.2.3.3.2.3.2"><log id="S3.E4.m1.2.3.3.2.3.2.1.cmml" xref="S3.E4.m1.2.3.3.2.3.2.1"></log><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><divide id="S3.E4.m1.2.2.3.cmml" xref="S3.E4.m1.2.2"></divide><apply id="S3.E4.m1.2.2.4.cmml" xref="S3.E4.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.4.1.cmml" xref="S3.E4.m1.2.2.4">superscript</csymbol><ci id="S3.E4.m1.2.2.4.2.cmml" xref="S3.E4.m1.2.2.4.2">e</ci><apply id="S3.E4.m1.2.2.4.3.cmml" xref="S3.E4.m1.2.2.4.3"><minus id="S3.E4.m1.2.2.4.3.1.cmml" xref="S3.E4.m1.2.2.4.3.1"></minus><apply id="S3.E4.m1.2.2.4.3.2.cmml" xref="S3.E4.m1.2.2.4.3.2"><ci id="S3.E4.m1.2.2.4.3.2.1.cmml" xref="S3.E4.m1.2.2.4.3.2.1">⋅</ci><apply id="S3.E4.m1.2.2.4.3.2.2.cmml" xref="S3.E4.m1.2.2.4.3.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.4.3.2.2.1.cmml" xref="S3.E4.m1.2.2.4.3.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.4.3.2.2.2.cmml" xref="S3.E4.m1.2.2.4.3.2.2.2">𝐏</ci><apply id="S3.E4.m1.2.2.4.3.2.2.3.cmml" xref="S3.E4.m1.2.2.4.3.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.4.3.2.2.3.1.cmml" xref="S3.E4.m1.2.2.4.3.2.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.4.3.2.2.3.2.cmml" xref="S3.E4.m1.2.2.4.3.2.2.3.2">𝐯</ci><ci id="S3.E4.m1.2.2.4.3.2.2.3.3.cmml" xref="S3.E4.m1.2.2.4.3.2.2.3.3">𝐣</ci></apply></apply><apply id="S3.E4.m1.2.2.4.3.2.3.cmml" xref="S3.E4.m1.2.2.4.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.4.3.2.3.1.cmml" xref="S3.E4.m1.2.2.4.3.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.4.3.2.3.2.cmml" xref="S3.E4.m1.2.2.4.3.2.3.2">𝐏</ci><apply id="S3.E4.m1.2.2.4.3.2.3.3.cmml" xref="S3.E4.m1.2.2.4.3.2.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.4.3.2.3.3.1.cmml" xref="S3.E4.m1.2.2.4.3.2.3.3">subscript</csymbol><ci id="S3.E4.m1.2.2.4.3.2.3.3.2.cmml" xref="S3.E4.m1.2.2.4.3.2.3.3.2">𝐰</ci><ci id="S3.E4.m1.2.2.4.3.2.3.3.3.cmml" xref="S3.E4.m1.2.2.4.3.2.3.3.3">𝐣</ci></apply></apply></apply><ci id="S3.E4.m1.2.2.4.3.3.cmml" xref="S3.E4.m1.2.2.4.3.3">𝛿</ci></apply></apply><apply id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.2"><times id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.3"></times><apply id="S3.E4.m1.2.2.2.4.cmml" xref="S3.E4.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.4.1.cmml" xref="S3.E4.m1.2.2.2.4">superscript</csymbol><ci id="S3.E4.m1.2.2.2.4.2.cmml" xref="S3.E4.m1.2.2.2.4.2">e</ci><apply id="S3.E4.m1.2.2.2.4.3.cmml" xref="S3.E4.m1.2.2.2.4.3"><ci id="S3.E4.m1.2.2.2.4.3.1.cmml" xref="S3.E4.m1.2.2.2.4.3.1">⋅</ci><apply id="S3.E4.m1.2.2.2.4.3.2.cmml" xref="S3.E4.m1.2.2.2.4.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.4.3.2.1.cmml" xref="S3.E4.m1.2.2.2.4.3.2">subscript</csymbol><ci id="S3.E4.m1.2.2.2.4.3.2.2.cmml" xref="S3.E4.m1.2.2.2.4.3.2.2">𝐏</ci><apply id="S3.E4.m1.2.2.2.4.3.2.3.cmml" xref="S3.E4.m1.2.2.2.4.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.4.3.2.3.1.cmml" xref="S3.E4.m1.2.2.2.4.3.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.4.3.2.3.2.cmml" xref="S3.E4.m1.2.2.2.4.3.2.3.2">𝐯</ci><ci id="S3.E4.m1.2.2.2.4.3.2.3.3.cmml" xref="S3.E4.m1.2.2.2.4.3.2.3.3">𝐣</ci></apply></apply><apply id="S3.E4.m1.2.2.2.4.3.3.cmml" xref="S3.E4.m1.2.2.2.4.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.4.3.3.1.cmml" xref="S3.E4.m1.2.2.2.4.3.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.4.3.3.2.cmml" xref="S3.E4.m1.2.2.2.4.3.3.2">𝐏</ci><apply id="S3.E4.m1.2.2.2.4.3.3.3.cmml" xref="S3.E4.m1.2.2.2.4.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.4.3.3.3.1.cmml" xref="S3.E4.m1.2.2.2.4.3.3.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.4.3.3.3.2.cmml" xref="S3.E4.m1.2.2.2.4.3.3.3.2">𝐰</ci><ci id="S3.E4.m1.2.2.2.4.3.3.3.3.cmml" xref="S3.E4.m1.2.2.2.4.3.3.3.3">𝐣</ci></apply></apply></apply></apply><apply id="S3.E4.m1.2.2.2.5.cmml" xref="S3.E4.m1.2.2.2.5"><apply id="S3.E4.m1.2.2.2.5.1.cmml" xref="S3.E4.m1.2.2.2.5.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.5.1.1.cmml" xref="S3.E4.m1.2.2.2.5.1">subscript</csymbol><apply id="S3.E4.m1.2.2.2.5.1.2.cmml" xref="S3.E4.m1.2.2.2.5.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.5.1.2.1.cmml" xref="S3.E4.m1.2.2.2.5.1">superscript</csymbol><sum id="S3.E4.m1.2.2.2.5.1.2.2.cmml" xref="S3.E4.m1.2.2.2.5.1.2.2"></sum><ci id="S3.E4.m1.2.2.2.5.1.2.3.cmml" xref="S3.E4.m1.2.2.2.5.1.2.3">N</ci></apply><apply id="S3.E4.m1.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.2.3a.cmml" xref="S3.E4.m1.2.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"></eq><ci id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.2">i</ci><cn type="integer" id="S3.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.E4.m1.2.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2"><neq id="S3.E4.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2.1"></neq><ci id="S3.E4.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2.2">j</ci><ci id="S3.E4.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2.3">i</ci></apply></apply></apply><apply id="S3.E4.m1.2.2.2.5.2.cmml" xref="S3.E4.m1.2.2.2.5.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.5.2.1.cmml" xref="S3.E4.m1.2.2.2.5.2">superscript</csymbol><ci id="S3.E4.m1.2.2.2.5.2.2.cmml" xref="S3.E4.m1.2.2.2.5.2.2">e</ci><apply id="S3.E4.m1.2.2.2.5.2.3.cmml" xref="S3.E4.m1.2.2.2.5.2.3"><ci id="S3.E4.m1.2.2.2.5.2.3.1.cmml" xref="S3.E4.m1.2.2.2.5.2.3.1">⋅</ci><apply id="S3.E4.m1.2.2.2.5.2.3.2.cmml" xref="S3.E4.m1.2.2.2.5.2.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.5.2.3.2.1.cmml" xref="S3.E4.m1.2.2.2.5.2.3.2">subscript</csymbol><ci id="S3.E4.m1.2.2.2.5.2.3.2.2.cmml" xref="S3.E4.m1.2.2.2.5.2.3.2.2">𝐏</ci><apply id="S3.E4.m1.2.2.2.5.2.3.2.3.cmml" xref="S3.E4.m1.2.2.2.5.2.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.5.2.3.2.3.1.cmml" xref="S3.E4.m1.2.2.2.5.2.3.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.5.2.3.2.3.2.cmml" xref="S3.E4.m1.2.2.2.5.2.3.2.3.2">𝐯</ci><ci id="S3.E4.m1.2.2.2.5.2.3.2.3.3.cmml" xref="S3.E4.m1.2.2.2.5.2.3.2.3.3">𝐢</ci></apply></apply><apply id="S3.E4.m1.2.2.2.5.2.3.3.cmml" xref="S3.E4.m1.2.2.2.5.2.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.5.2.3.3.1.cmml" xref="S3.E4.m1.2.2.2.5.2.3.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.5.2.3.3.2.cmml" xref="S3.E4.m1.2.2.2.5.2.3.3.2">𝐏</ci><apply id="S3.E4.m1.2.2.2.5.2.3.3.3.cmml" xref="S3.E4.m1.2.2.2.5.2.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.5.2.3.3.3.1.cmml" xref="S3.E4.m1.2.2.2.5.2.3.3.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.5.2.3.3.3.2.cmml" xref="S3.E4.m1.2.2.2.5.2.3.3.3.2">𝐰</ci><ci id="S3.E4.m1.2.2.2.5.2.3.3.3.3.cmml" xref="S3.E4.m1.2.2.2.5.2.3.3.3.3">𝐣</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">L_{wv}=-\frac{1}{N}\sum_{j=1}^{N}\log\frac{{\rm e}^{\mathbf{P_{v_{j}}}\cdot\mathbf{P_{w_{j}}}-\delta}}{\rm e^{\mathbf{P_{v_{j}}}\cdot\mathbf{P_{w_{j}}}}\sum^{N}_{i=1,j\neq i}\rm e^{\mathbf{P_{v_{i}}}\cdot\mathbf{P_{w_{j}}}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p">In the case of three modalities input, we calculate the MMS loss for each modality pair, and the final loss is the sum of all MMS losses between paired modalities.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="L_{MMS}=L_{MMS_{vh}}+L_{MMS_{vw}}+L_{MMS_{hw}}" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><msub id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.2.2" xref="S3.E5.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E5.m1.1.1.2.3" xref="S3.E5.m1.1.1.2.3.cmml"><mi id="S3.E5.m1.1.1.2.3.2" xref="S3.E5.m1.1.1.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.2.3.1" xref="S3.E5.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.2.3.3" xref="S3.E5.m1.1.1.2.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.2.3.1a" xref="S3.E5.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.2.3.4" xref="S3.E5.m1.1.1.2.3.4.cmml">S</mi></mrow></msub><mo id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.3.2" xref="S3.E5.m1.1.1.3.2.cmml"><mi id="S3.E5.m1.1.1.3.2.2" xref="S3.E5.m1.1.1.3.2.2.cmml">L</mi><mrow id="S3.E5.m1.1.1.3.2.3" xref="S3.E5.m1.1.1.3.2.3.cmml"><mi id="S3.E5.m1.1.1.3.2.3.2" xref="S3.E5.m1.1.1.3.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.3.1" xref="S3.E5.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.2.3.3" xref="S3.E5.m1.1.1.3.2.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.3.1a" xref="S3.E5.m1.1.1.3.2.3.1.cmml">​</mo><msub id="S3.E5.m1.1.1.3.2.3.4" xref="S3.E5.m1.1.1.3.2.3.4.cmml"><mi id="S3.E5.m1.1.1.3.2.3.4.2" xref="S3.E5.m1.1.1.3.2.3.4.2.cmml">S</mi><mrow id="S3.E5.m1.1.1.3.2.3.4.3" xref="S3.E5.m1.1.1.3.2.3.4.3.cmml"><mi id="S3.E5.m1.1.1.3.2.3.4.3.2" xref="S3.E5.m1.1.1.3.2.3.4.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.3.4.3.1" xref="S3.E5.m1.1.1.3.2.3.4.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.2.3.4.3.3" xref="S3.E5.m1.1.1.3.2.3.4.3.3.cmml">h</mi></mrow></msub></mrow></msub><mo id="S3.E5.m1.1.1.3.1" xref="S3.E5.m1.1.1.3.1.cmml">+</mo><msub id="S3.E5.m1.1.1.3.3" xref="S3.E5.m1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.3.3.2" xref="S3.E5.m1.1.1.3.3.2.cmml">L</mi><mrow id="S3.E5.m1.1.1.3.3.3" xref="S3.E5.m1.1.1.3.3.3.cmml"><mi id="S3.E5.m1.1.1.3.3.3.2" xref="S3.E5.m1.1.1.3.3.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.1" xref="S3.E5.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3" xref="S3.E5.m1.1.1.3.3.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.1a" xref="S3.E5.m1.1.1.3.3.3.1.cmml">​</mo><msub id="S3.E5.m1.1.1.3.3.3.4" xref="S3.E5.m1.1.1.3.3.3.4.cmml"><mi id="S3.E5.m1.1.1.3.3.3.4.2" xref="S3.E5.m1.1.1.3.3.3.4.2.cmml">S</mi><mrow id="S3.E5.m1.1.1.3.3.3.4.3" xref="S3.E5.m1.1.1.3.3.3.4.3.cmml"><mi id="S3.E5.m1.1.1.3.3.3.4.3.2" xref="S3.E5.m1.1.1.3.3.3.4.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.4.3.1" xref="S3.E5.m1.1.1.3.3.3.4.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.4.3.3" xref="S3.E5.m1.1.1.3.3.3.4.3.3.cmml">w</mi></mrow></msub></mrow></msub><mo id="S3.E5.m1.1.1.3.1a" xref="S3.E5.m1.1.1.3.1.cmml">+</mo><msub id="S3.E5.m1.1.1.3.4" xref="S3.E5.m1.1.1.3.4.cmml"><mi id="S3.E5.m1.1.1.3.4.2" xref="S3.E5.m1.1.1.3.4.2.cmml">L</mi><mrow id="S3.E5.m1.1.1.3.4.3" xref="S3.E5.m1.1.1.3.4.3.cmml"><mi id="S3.E5.m1.1.1.3.4.3.2" xref="S3.E5.m1.1.1.3.4.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.4.3.1" xref="S3.E5.m1.1.1.3.4.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.4.3.3" xref="S3.E5.m1.1.1.3.4.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.4.3.1a" xref="S3.E5.m1.1.1.3.4.3.1.cmml">​</mo><msub id="S3.E5.m1.1.1.3.4.3.4" xref="S3.E5.m1.1.1.3.4.3.4.cmml"><mi id="S3.E5.m1.1.1.3.4.3.4.2" xref="S3.E5.m1.1.1.3.4.3.4.2.cmml">S</mi><mrow id="S3.E5.m1.1.1.3.4.3.4.3" xref="S3.E5.m1.1.1.3.4.3.4.3.cmml"><mi id="S3.E5.m1.1.1.3.4.3.4.3.2" xref="S3.E5.m1.1.1.3.4.3.4.3.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.4.3.4.3.1" xref="S3.E5.m1.1.1.3.4.3.4.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.4.3.4.3.3" xref="S3.E5.m1.1.1.3.4.3.4.3.3.cmml">w</mi></mrow></msub></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"></eq><apply id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.2.2">𝐿</ci><apply id="S3.E5.m1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.2.3"><times id="S3.E5.m1.1.1.2.3.1.cmml" xref="S3.E5.m1.1.1.2.3.1"></times><ci id="S3.E5.m1.1.1.2.3.2.cmml" xref="S3.E5.m1.1.1.2.3.2">𝑀</ci><ci id="S3.E5.m1.1.1.2.3.3.cmml" xref="S3.E5.m1.1.1.2.3.3">𝑀</ci><ci id="S3.E5.m1.1.1.2.3.4.cmml" xref="S3.E5.m1.1.1.2.3.4">𝑆</ci></apply></apply><apply id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"><plus id="S3.E5.m1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.3.1"></plus><apply id="S3.E5.m1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2">𝐿</ci><apply id="S3.E5.m1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.3.2.3"><times id="S3.E5.m1.1.1.3.2.3.1.cmml" xref="S3.E5.m1.1.1.3.2.3.1"></times><ci id="S3.E5.m1.1.1.3.2.3.2.cmml" xref="S3.E5.m1.1.1.3.2.3.2">𝑀</ci><ci id="S3.E5.m1.1.1.3.2.3.3.cmml" xref="S3.E5.m1.1.1.3.2.3.3">𝑀</ci><apply id="S3.E5.m1.1.1.3.2.3.4.cmml" xref="S3.E5.m1.1.1.3.2.3.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.3.4.1.cmml" xref="S3.E5.m1.1.1.3.2.3.4">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.3.4.2.cmml" xref="S3.E5.m1.1.1.3.2.3.4.2">𝑆</ci><apply id="S3.E5.m1.1.1.3.2.3.4.3.cmml" xref="S3.E5.m1.1.1.3.2.3.4.3"><times id="S3.E5.m1.1.1.3.2.3.4.3.1.cmml" xref="S3.E5.m1.1.1.3.2.3.4.3.1"></times><ci id="S3.E5.m1.1.1.3.2.3.4.3.2.cmml" xref="S3.E5.m1.1.1.3.2.3.4.3.2">𝑣</ci><ci id="S3.E5.m1.1.1.3.2.3.4.3.3.cmml" xref="S3.E5.m1.1.1.3.2.3.4.3.3">ℎ</ci></apply></apply></apply></apply><apply id="S3.E5.m1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.2">𝐿</ci><apply id="S3.E5.m1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3"><times id="S3.E5.m1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3.3.1"></times><ci id="S3.E5.m1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.3.2">𝑀</ci><ci id="S3.E5.m1.1.1.3.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3.3">𝑀</ci><apply id="S3.E5.m1.1.1.3.3.3.4.cmml" xref="S3.E5.m1.1.1.3.3.3.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.3.4.1.cmml" xref="S3.E5.m1.1.1.3.3.3.4">subscript</csymbol><ci id="S3.E5.m1.1.1.3.3.3.4.2.cmml" xref="S3.E5.m1.1.1.3.3.3.4.2">𝑆</ci><apply id="S3.E5.m1.1.1.3.3.3.4.3.cmml" xref="S3.E5.m1.1.1.3.3.3.4.3"><times id="S3.E5.m1.1.1.3.3.3.4.3.1.cmml" xref="S3.E5.m1.1.1.3.3.3.4.3.1"></times><ci id="S3.E5.m1.1.1.3.3.3.4.3.2.cmml" xref="S3.E5.m1.1.1.3.3.3.4.3.2">𝑣</ci><ci id="S3.E5.m1.1.1.3.3.3.4.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3.4.3.3">𝑤</ci></apply></apply></apply></apply><apply id="S3.E5.m1.1.1.3.4.cmml" xref="S3.E5.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.4.1.cmml" xref="S3.E5.m1.1.1.3.4">subscript</csymbol><ci id="S3.E5.m1.1.1.3.4.2.cmml" xref="S3.E5.m1.1.1.3.4.2">𝐿</ci><apply id="S3.E5.m1.1.1.3.4.3.cmml" xref="S3.E5.m1.1.1.3.4.3"><times id="S3.E5.m1.1.1.3.4.3.1.cmml" xref="S3.E5.m1.1.1.3.4.3.1"></times><ci id="S3.E5.m1.1.1.3.4.3.2.cmml" xref="S3.E5.m1.1.1.3.4.3.2">𝑀</ci><ci id="S3.E5.m1.1.1.3.4.3.3.cmml" xref="S3.E5.m1.1.1.3.4.3.3">𝑀</ci><apply id="S3.E5.m1.1.1.3.4.3.4.cmml" xref="S3.E5.m1.1.1.3.4.3.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.4.3.4.1.cmml" xref="S3.E5.m1.1.1.3.4.3.4">subscript</csymbol><ci id="S3.E5.m1.1.1.3.4.3.4.2.cmml" xref="S3.E5.m1.1.1.3.4.3.4.2">𝑆</ci><apply id="S3.E5.m1.1.1.3.4.3.4.3.cmml" xref="S3.E5.m1.1.1.3.4.3.4.3"><times id="S3.E5.m1.1.1.3.4.3.4.3.1.cmml" xref="S3.E5.m1.1.1.3.4.3.4.3.1"></times><ci id="S3.E5.m1.1.1.3.4.3.4.3.2.cmml" xref="S3.E5.m1.1.1.3.4.3.4.3.2">ℎ</ci><ci id="S3.E5.m1.1.1.3.4.3.4.3.3.cmml" xref="S3.E5.m1.1.1.3.4.3.4.3.3">𝑤</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">L_{MMS}=L_{MMS_{vh}}+L_{MMS_{vw}}+L_{MMS_{hw}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Generative Self-Supervised Learning</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.4" class="ltx_p">In this work, we study the impact of the reconstruction objective function on the learned representation from unlabeled data. Either as the only objective function in the proxy task or as a part of multi-task self-supervised training. Since the training data is multi-modal, we follow a similar direction as <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Chen et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite> and perform the reconstruction for each modality individually. The final reconstruction loss is the sum of the reconstruction losses of all modalities. Thus we have 3 encoder-decoder models, <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="Q_{f}" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">Q</mi><mi id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">𝑄</ci><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">Q_{f}</annotation></semantics></math>, <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="Q_{w}" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><msub id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">Q</mi><mi id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml">w</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">𝑄</ci><ci id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">Q_{w}</annotation></semantics></math>, and <math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="Q_{h}" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><msub id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml"><mi id="S3.SS4.p1.3.m3.1.1.2" xref="S3.SS4.p1.3.m3.1.1.2.cmml">Q</mi><mi id="S3.SS4.p1.3.m3.1.1.3" xref="S3.SS4.p1.3.m3.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><apply id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.3.m3.1.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p1.3.m3.1.1.2.cmml" xref="S3.SS4.p1.3.m3.1.1.2">𝑄</ci><ci id="S3.SS4.p1.3.m3.1.1.3.cmml" xref="S3.SS4.p1.3.m3.1.1.3">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">Q_{h}</annotation></semantics></math> for video, text, and audio respectively. Each decoder receives a feature representation <math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{D}" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><mi id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">𝐃</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><ci id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">𝐃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">\mathbf{D}</annotation></semantics></math> from the related reconstruction head. In the following you can see the reconstruction loss for the visual modality:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.2" class="ltx_Math" alttext="L_{Rec_{\mathbf{v}}}=\text{MSE}(v,Q_{v}(\mathbf{D_{v}}))" display="block"><semantics id="S3.E6.m1.2a"><mrow id="S3.E6.m1.2.2" xref="S3.E6.m1.2.2.cmml"><msub id="S3.E6.m1.2.2.3" xref="S3.E6.m1.2.2.3.cmml"><mi id="S3.E6.m1.2.2.3.2" xref="S3.E6.m1.2.2.3.2.cmml">L</mi><mrow id="S3.E6.m1.2.2.3.3" xref="S3.E6.m1.2.2.3.3.cmml"><mi id="S3.E6.m1.2.2.3.3.2" xref="S3.E6.m1.2.2.3.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.3.3.1" xref="S3.E6.m1.2.2.3.3.1.cmml">​</mo><mi id="S3.E6.m1.2.2.3.3.3" xref="S3.E6.m1.2.2.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.3.3.1a" xref="S3.E6.m1.2.2.3.3.1.cmml">​</mo><msub id="S3.E6.m1.2.2.3.3.4" xref="S3.E6.m1.2.2.3.3.4.cmml"><mi id="S3.E6.m1.2.2.3.3.4.2" xref="S3.E6.m1.2.2.3.3.4.2.cmml">c</mi><mi id="S3.E6.m1.2.2.3.3.4.3" xref="S3.E6.m1.2.2.3.3.4.3.cmml">𝐯</mi></msub></mrow></msub><mo id="S3.E6.m1.2.2.2" xref="S3.E6.m1.2.2.2.cmml">=</mo><mrow id="S3.E6.m1.2.2.1" xref="S3.E6.m1.2.2.1.cmml"><mtext id="S3.E6.m1.2.2.1.3" xref="S3.E6.m1.2.2.1.3a.cmml">MSE</mtext><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.2" xref="S3.E6.m1.2.2.1.2.cmml">​</mo><mrow id="S3.E6.m1.2.2.1.1.1" xref="S3.E6.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.2" xref="S3.E6.m1.2.2.1.1.2.cmml">(</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">v</mi><mo id="S3.E6.m1.2.2.1.1.1.3" xref="S3.E6.m1.2.2.1.1.2.cmml">,</mo><mrow id="S3.E6.m1.2.2.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.cmml"><msub id="S3.E6.m1.2.2.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.3.2" xref="S3.E6.m1.2.2.1.1.1.1.3.2.cmml">Q</mi><mi id="S3.E6.m1.2.2.1.1.1.1.3.3" xref="S3.E6.m1.2.2.1.1.1.1.3.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S3.E6.m1.2.2.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E6.m1.2.2.1.1.1.1.1.1.1" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.cmml">𝐃</mi><mi id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.cmml">𝐯</mi></msub><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.1.1.1.3" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E6.m1.2.2.1.1.1.4" xref="S3.E6.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.2b"><apply id="S3.E6.m1.2.2.cmml" xref="S3.E6.m1.2.2"><eq id="S3.E6.m1.2.2.2.cmml" xref="S3.E6.m1.2.2.2"></eq><apply id="S3.E6.m1.2.2.3.cmml" xref="S3.E6.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.3.1.cmml" xref="S3.E6.m1.2.2.3">subscript</csymbol><ci id="S3.E6.m1.2.2.3.2.cmml" xref="S3.E6.m1.2.2.3.2">𝐿</ci><apply id="S3.E6.m1.2.2.3.3.cmml" xref="S3.E6.m1.2.2.3.3"><times id="S3.E6.m1.2.2.3.3.1.cmml" xref="S3.E6.m1.2.2.3.3.1"></times><ci id="S3.E6.m1.2.2.3.3.2.cmml" xref="S3.E6.m1.2.2.3.3.2">𝑅</ci><ci id="S3.E6.m1.2.2.3.3.3.cmml" xref="S3.E6.m1.2.2.3.3.3">𝑒</ci><apply id="S3.E6.m1.2.2.3.3.4.cmml" xref="S3.E6.m1.2.2.3.3.4"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.3.3.4.1.cmml" xref="S3.E6.m1.2.2.3.3.4">subscript</csymbol><ci id="S3.E6.m1.2.2.3.3.4.2.cmml" xref="S3.E6.m1.2.2.3.3.4.2">𝑐</ci><ci id="S3.E6.m1.2.2.3.3.4.3.cmml" xref="S3.E6.m1.2.2.3.3.4.3">𝐯</ci></apply></apply></apply><apply id="S3.E6.m1.2.2.1.cmml" xref="S3.E6.m1.2.2.1"><times id="S3.E6.m1.2.2.1.2.cmml" xref="S3.E6.m1.2.2.1.2"></times><ci id="S3.E6.m1.2.2.1.3a.cmml" xref="S3.E6.m1.2.2.1.3"><mtext id="S3.E6.m1.2.2.1.3.cmml" xref="S3.E6.m1.2.2.1.3">MSE</mtext></ci><interval closure="open" id="S3.E6.m1.2.2.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1"><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">𝑣</ci><apply id="S3.E6.m1.2.2.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1"><times id="S3.E6.m1.2.2.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.2"></times><apply id="S3.E6.m1.2.2.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.2">𝑄</ci><ci id="S3.E6.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.3.3">𝑣</ci></apply><apply id="S3.E6.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.2">𝐃</ci><ci id="S3.E6.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.1.1.1.1.1.3">𝐯</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.2c">L_{Rec_{\mathbf{v}}}=\text{MSE}(v,Q_{v}(\mathbf{D_{v}}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p1.5" class="ltx_p">The reconstruction loss is the mean-squared error (MSE) between the output features from the encoder-decoder model and the input features. Such loss penalizes the network for creating outputs (in this case features) different from the input features. The final reconstruction loss over the 3 modalities is given as:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="L_{Rec}=L_{Rec_{v}}+L_{Rec_{h}}+L_{Rec_{w}}" display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml"><msub id="S3.E7.m1.1.1.2" xref="S3.E7.m1.1.1.2.cmml"><mi id="S3.E7.m1.1.1.2.2" xref="S3.E7.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E7.m1.1.1.2.3" xref="S3.E7.m1.1.1.2.3.cmml"><mi id="S3.E7.m1.1.1.2.3.2" xref="S3.E7.m1.1.1.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.2.3.1" xref="S3.E7.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.2.3.3" xref="S3.E7.m1.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.2.3.1a" xref="S3.E7.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.2.3.4" xref="S3.E7.m1.1.1.2.3.4.cmml">c</mi></mrow></msub><mo id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml">=</mo><mrow id="S3.E7.m1.1.1.3" xref="S3.E7.m1.1.1.3.cmml"><msub id="S3.E7.m1.1.1.3.2" xref="S3.E7.m1.1.1.3.2.cmml"><mi id="S3.E7.m1.1.1.3.2.2" xref="S3.E7.m1.1.1.3.2.2.cmml">L</mi><mrow id="S3.E7.m1.1.1.3.2.3" xref="S3.E7.m1.1.1.3.2.3.cmml"><mi id="S3.E7.m1.1.1.3.2.3.2" xref="S3.E7.m1.1.1.3.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.2.3.1" xref="S3.E7.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.3.2.3.3" xref="S3.E7.m1.1.1.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.2.3.1a" xref="S3.E7.m1.1.1.3.2.3.1.cmml">​</mo><msub id="S3.E7.m1.1.1.3.2.3.4" xref="S3.E7.m1.1.1.3.2.3.4.cmml"><mi id="S3.E7.m1.1.1.3.2.3.4.2" xref="S3.E7.m1.1.1.3.2.3.4.2.cmml">c</mi><mi id="S3.E7.m1.1.1.3.2.3.4.3" xref="S3.E7.m1.1.1.3.2.3.4.3.cmml">v</mi></msub></mrow></msub><mo id="S3.E7.m1.1.1.3.1" xref="S3.E7.m1.1.1.3.1.cmml">+</mo><msub id="S3.E7.m1.1.1.3.3" xref="S3.E7.m1.1.1.3.3.cmml"><mi id="S3.E7.m1.1.1.3.3.2" xref="S3.E7.m1.1.1.3.3.2.cmml">L</mi><mrow id="S3.E7.m1.1.1.3.3.3" xref="S3.E7.m1.1.1.3.3.3.cmml"><mi id="S3.E7.m1.1.1.3.3.3.2" xref="S3.E7.m1.1.1.3.3.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.3.3.1" xref="S3.E7.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.3.3.3.3" xref="S3.E7.m1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.3.3.1a" xref="S3.E7.m1.1.1.3.3.3.1.cmml">​</mo><msub id="S3.E7.m1.1.1.3.3.3.4" xref="S3.E7.m1.1.1.3.3.3.4.cmml"><mi id="S3.E7.m1.1.1.3.3.3.4.2" xref="S3.E7.m1.1.1.3.3.3.4.2.cmml">c</mi><mi id="S3.E7.m1.1.1.3.3.3.4.3" xref="S3.E7.m1.1.1.3.3.3.4.3.cmml">h</mi></msub></mrow></msub><mo id="S3.E7.m1.1.1.3.1a" xref="S3.E7.m1.1.1.3.1.cmml">+</mo><msub id="S3.E7.m1.1.1.3.4" xref="S3.E7.m1.1.1.3.4.cmml"><mi id="S3.E7.m1.1.1.3.4.2" xref="S3.E7.m1.1.1.3.4.2.cmml">L</mi><mrow id="S3.E7.m1.1.1.3.4.3" xref="S3.E7.m1.1.1.3.4.3.cmml"><mi id="S3.E7.m1.1.1.3.4.3.2" xref="S3.E7.m1.1.1.3.4.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.4.3.1" xref="S3.E7.m1.1.1.3.4.3.1.cmml">​</mo><mi id="S3.E7.m1.1.1.3.4.3.3" xref="S3.E7.m1.1.1.3.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.4.3.1a" xref="S3.E7.m1.1.1.3.4.3.1.cmml">​</mo><msub id="S3.E7.m1.1.1.3.4.3.4" xref="S3.E7.m1.1.1.3.4.3.4.cmml"><mi id="S3.E7.m1.1.1.3.4.3.4.2" xref="S3.E7.m1.1.1.3.4.3.4.2.cmml">c</mi><mi id="S3.E7.m1.1.1.3.4.3.4.3" xref="S3.E7.m1.1.1.3.4.3.4.3.cmml">w</mi></msub></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"><eq id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"></eq><apply id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.2.2">𝐿</ci><apply id="S3.E7.m1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.2.3"><times id="S3.E7.m1.1.1.2.3.1.cmml" xref="S3.E7.m1.1.1.2.3.1"></times><ci id="S3.E7.m1.1.1.2.3.2.cmml" xref="S3.E7.m1.1.1.2.3.2">𝑅</ci><ci id="S3.E7.m1.1.1.2.3.3.cmml" xref="S3.E7.m1.1.1.2.3.3">𝑒</ci><ci id="S3.E7.m1.1.1.2.3.4.cmml" xref="S3.E7.m1.1.1.2.3.4">𝑐</ci></apply></apply><apply id="S3.E7.m1.1.1.3.cmml" xref="S3.E7.m1.1.1.3"><plus id="S3.E7.m1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.3.1"></plus><apply id="S3.E7.m1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.3.2">subscript</csymbol><ci id="S3.E7.m1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.3.2.2">𝐿</ci><apply id="S3.E7.m1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.3.2.3"><times id="S3.E7.m1.1.1.3.2.3.1.cmml" xref="S3.E7.m1.1.1.3.2.3.1"></times><ci id="S3.E7.m1.1.1.3.2.3.2.cmml" xref="S3.E7.m1.1.1.3.2.3.2">𝑅</ci><ci id="S3.E7.m1.1.1.3.2.3.3.cmml" xref="S3.E7.m1.1.1.3.2.3.3">𝑒</ci><apply id="S3.E7.m1.1.1.3.2.3.4.cmml" xref="S3.E7.m1.1.1.3.2.3.4"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.2.3.4.1.cmml" xref="S3.E7.m1.1.1.3.2.3.4">subscript</csymbol><ci id="S3.E7.m1.1.1.3.2.3.4.2.cmml" xref="S3.E7.m1.1.1.3.2.3.4.2">𝑐</ci><ci id="S3.E7.m1.1.1.3.2.3.4.3.cmml" xref="S3.E7.m1.1.1.3.2.3.4.3">𝑣</ci></apply></apply></apply><apply id="S3.E7.m1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.3.3">subscript</csymbol><ci id="S3.E7.m1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.3.3.2">𝐿</ci><apply id="S3.E7.m1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.3.3.3"><times id="S3.E7.m1.1.1.3.3.3.1.cmml" xref="S3.E7.m1.1.1.3.3.3.1"></times><ci id="S3.E7.m1.1.1.3.3.3.2.cmml" xref="S3.E7.m1.1.1.3.3.3.2">𝑅</ci><ci id="S3.E7.m1.1.1.3.3.3.3.cmml" xref="S3.E7.m1.1.1.3.3.3.3">𝑒</ci><apply id="S3.E7.m1.1.1.3.3.3.4.cmml" xref="S3.E7.m1.1.1.3.3.3.4"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.3.3.4.1.cmml" xref="S3.E7.m1.1.1.3.3.3.4">subscript</csymbol><ci id="S3.E7.m1.1.1.3.3.3.4.2.cmml" xref="S3.E7.m1.1.1.3.3.3.4.2">𝑐</ci><ci id="S3.E7.m1.1.1.3.3.3.4.3.cmml" xref="S3.E7.m1.1.1.3.3.3.4.3">ℎ</ci></apply></apply></apply><apply id="S3.E7.m1.1.1.3.4.cmml" xref="S3.E7.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.4.1.cmml" xref="S3.E7.m1.1.1.3.4">subscript</csymbol><ci id="S3.E7.m1.1.1.3.4.2.cmml" xref="S3.E7.m1.1.1.3.4.2">𝐿</ci><apply id="S3.E7.m1.1.1.3.4.3.cmml" xref="S3.E7.m1.1.1.3.4.3"><times id="S3.E7.m1.1.1.3.4.3.1.cmml" xref="S3.E7.m1.1.1.3.4.3.1"></times><ci id="S3.E7.m1.1.1.3.4.3.2.cmml" xref="S3.E7.m1.1.1.3.4.3.2">𝑅</ci><ci id="S3.E7.m1.1.1.3.4.3.3.cmml" xref="S3.E7.m1.1.1.3.4.3.3">𝑒</ci><apply id="S3.E7.m1.1.1.3.4.3.4.cmml" xref="S3.E7.m1.1.1.3.4.3.4"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.4.3.4.1.cmml" xref="S3.E7.m1.1.1.3.4.3.4">subscript</csymbol><ci id="S3.E7.m1.1.1.3.4.3.4.2.cmml" xref="S3.E7.m1.1.1.3.4.3.4.2">𝑐</ci><ci id="S3.E7.m1.1.1.3.4.3.4.3.cmml" xref="S3.E7.m1.1.1.3.4.3.4.3">𝑤</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">L_{Rec}=L_{Rec_{v}}+L_{Rec_{h}}+L_{Rec_{w}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Multi-Modal Contrastive Learning with Clustering</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">This method learns a multi-modal representation utilizing the multi-modal contrastive objective function from <a href="#S3.SS3" title="3.3 Multi-Modal Contrastive Learning ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.3</span></a> that encourages modalities of the same instance represented closer to each other in the feature space. Moreover, it preserves the similarity between different instances by learning a multi-modal clustering objective function beside the multi-modal contrastive object function. The objective function that guides the multi-modal learning process consists of two losses: The first one is the multi-modal contrastive loss <a href="#S3.E5" title="In 3.3 Multi-Modal Contrastive Learning ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">5</span></a>, the second one is the multi-modal clustering loss that will be elaborated below.
<br class="ltx_break"></p>
</div>
<div id="S3.SS5.p2" class="ltx_para ltx_noindent">
<p id="S3.SS5.p2.1" class="ltx_p"><span id="S3.SS5.p2.1.1" class="ltx_text ltx_font_bold">Multi-modal clustering representation learning.</span> 
<br class="ltx_break">To preserve the similarity between different modalities of similar instances, we formulate a clustering objective function that minimizes the distance between similar modalities. To create the clustering centroids we follow a similar direction of recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite> that creates a multi-modal centroid over joint multi-modal representations instead of creating a separate centroid for each modality. Thus, by using the clustering loss, we encourage the audio, visual, and text embeddings of similar videos (that share similar semantic information) to be represented closer to each other in the feature space.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.4" class="ltx_p">As shown in <a href="#S3.E8" title="In 3.5 Multi-Modal Contrastive Learning with Clustering ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">8</span></a>, we compute the multi-modal representation <math id="S3.SS5.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{R_{i}}" display="inline"><semantics id="S3.SS5.p3.1.m1.1a"><msub id="S3.SS5.p3.1.m1.1.1" xref="S3.SS5.p3.1.m1.1.1.cmml"><mi id="S3.SS5.p3.1.m1.1.1.2" xref="S3.SS5.p3.1.m1.1.1.2.cmml">𝐑</mi><mi id="S3.SS5.p3.1.m1.1.1.3" xref="S3.SS5.p3.1.m1.1.1.3.cmml">𝐢</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.1.m1.1b"><apply id="S3.SS5.p3.1.m1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.1.m1.1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.p3.1.m1.1.1.2.cmml" xref="S3.SS5.p3.1.m1.1.1.2">𝐑</ci><ci id="S3.SS5.p3.1.m1.1.1.3.cmml" xref="S3.SS5.p3.1.m1.1.1.3">𝐢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.1.m1.1c">\mathbf{R_{i}}</annotation></semantics></math> of each instance as the mean over the representations of each modality associated with that instance. As illustrated in <a href="#S3.F1" title="In 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>, the clustering loss is performed over the output of the <span id="S3.SS5.p3.4.1" class="ltx_text ltx_font_italic">Clustering Head</span> which is <math id="S3.SS5.p3.2.m2.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.SS5.p3.2.m2.1a"><mi id="S3.SS5.p3.2.m2.1.1" xref="S3.SS5.p3.2.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.2.m2.1b"><ci id="S3.SS5.p3.2.m2.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.2.m2.1c">G</annotation></semantics></math> (see <a href="#S3.SS1" title="3.1 Problem Formulation ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.1</span></a>). Assuming we have three modalities (video, text, and audio) as input then the multi-modal representation <math id="S3.SS5.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{R}" display="inline"><semantics id="S3.SS5.p3.3.m3.1a"><mi id="S3.SS5.p3.3.m3.1.1" xref="S3.SS5.p3.3.m3.1.1.cmml">𝐑</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.3.m3.1b"><ci id="S3.SS5.p3.3.m3.1.1.cmml" xref="S3.SS5.p3.3.m3.1.1">𝐑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.3.m3.1c">\mathbf{R}</annotation></semantics></math> for each instance <math id="S3.SS5.p3.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS5.p3.4.m4.1a"><mi id="S3.SS5.p3.4.m4.1.1" xref="S3.SS5.p3.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.4.m4.1b"><ci id="S3.SS5.p3.4.m4.1.1.cmml" xref="S3.SS5.p3.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.4.m4.1c">i</annotation></semantics></math> is calculated as follows: 
<br class="ltx_break"></p>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.4" class="ltx_Math" alttext="R_{i}(\mathbf{g}_{\mathbf{v}}^{i},\mathbf{g}_{\mathbf{t}}^{i},\mathbf{g}_{\mathbf{a}}^{i})=(\mathbf{g}_{\mathbf{v}}^{i}+\mathbf{g}_{\mathbf{t}}^{i}+\mathbf{g}_{\mathbf{a}}^{i})/3" display="block"><semantics id="S3.E8.m1.4a"><mrow id="S3.E8.m1.4.4" xref="S3.E8.m1.4.4.cmml"><mrow id="S3.E8.m1.3.3.3" xref="S3.E8.m1.3.3.3.cmml"><msub id="S3.E8.m1.3.3.3.5" xref="S3.E8.m1.3.3.3.5.cmml"><mi id="S3.E8.m1.3.3.3.5.2" xref="S3.E8.m1.3.3.3.5.2.cmml">R</mi><mi id="S3.E8.m1.3.3.3.5.3" xref="S3.E8.m1.3.3.3.5.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.3.3.3.4" xref="S3.E8.m1.3.3.3.4.cmml">​</mo><mrow id="S3.E8.m1.3.3.3.3.3" xref="S3.E8.m1.3.3.3.3.4.cmml"><mo stretchy="false" id="S3.E8.m1.3.3.3.3.3.4" xref="S3.E8.m1.3.3.3.3.4.cmml">(</mo><msubsup id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.1.1.2.2.cmml">𝐠</mi><mi id="S3.E8.m1.1.1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.1.1.2.3.cmml">𝐯</mi><mi id="S3.E8.m1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.E8.m1.3.3.3.3.3.5" xref="S3.E8.m1.3.3.3.3.4.cmml">,</mo><msubsup id="S3.E8.m1.2.2.2.2.2.2" xref="S3.E8.m1.2.2.2.2.2.2.cmml"><mi id="S3.E8.m1.2.2.2.2.2.2.2.2" xref="S3.E8.m1.2.2.2.2.2.2.2.2.cmml">𝐠</mi><mi id="S3.E8.m1.2.2.2.2.2.2.2.3" xref="S3.E8.m1.2.2.2.2.2.2.2.3.cmml">𝐭</mi><mi id="S3.E8.m1.2.2.2.2.2.2.3" xref="S3.E8.m1.2.2.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.E8.m1.3.3.3.3.3.6" xref="S3.E8.m1.3.3.3.3.4.cmml">,</mo><msubsup id="S3.E8.m1.3.3.3.3.3.3" xref="S3.E8.m1.3.3.3.3.3.3.cmml"><mi id="S3.E8.m1.3.3.3.3.3.3.2.2" xref="S3.E8.m1.3.3.3.3.3.3.2.2.cmml">𝐠</mi><mi id="S3.E8.m1.3.3.3.3.3.3.2.3" xref="S3.E8.m1.3.3.3.3.3.3.2.3.cmml">𝐚</mi><mi id="S3.E8.m1.3.3.3.3.3.3.3" xref="S3.E8.m1.3.3.3.3.3.3.3.cmml">i</mi></msubsup><mo stretchy="false" id="S3.E8.m1.3.3.3.3.3.7" xref="S3.E8.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.4.4.5" xref="S3.E8.m1.4.4.5.cmml">=</mo><mrow id="S3.E8.m1.4.4.4" xref="S3.E8.m1.4.4.4.cmml"><mrow id="S3.E8.m1.4.4.4.1.1" xref="S3.E8.m1.4.4.4.1.1.1.cmml"><mo stretchy="false" id="S3.E8.m1.4.4.4.1.1.2" xref="S3.E8.m1.4.4.4.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.4.4.4.1.1.1" xref="S3.E8.m1.4.4.4.1.1.1.cmml"><msubsup id="S3.E8.m1.4.4.4.1.1.1.2" xref="S3.E8.m1.4.4.4.1.1.1.2.cmml"><mi id="S3.E8.m1.4.4.4.1.1.1.2.2.2" xref="S3.E8.m1.4.4.4.1.1.1.2.2.2.cmml">𝐠</mi><mi id="S3.E8.m1.4.4.4.1.1.1.2.2.3" xref="S3.E8.m1.4.4.4.1.1.1.2.2.3.cmml">𝐯</mi><mi id="S3.E8.m1.4.4.4.1.1.1.2.3" xref="S3.E8.m1.4.4.4.1.1.1.2.3.cmml">i</mi></msubsup><mo id="S3.E8.m1.4.4.4.1.1.1.1" xref="S3.E8.m1.4.4.4.1.1.1.1.cmml">+</mo><msubsup id="S3.E8.m1.4.4.4.1.1.1.3" xref="S3.E8.m1.4.4.4.1.1.1.3.cmml"><mi id="S3.E8.m1.4.4.4.1.1.1.3.2.2" xref="S3.E8.m1.4.4.4.1.1.1.3.2.2.cmml">𝐠</mi><mi id="S3.E8.m1.4.4.4.1.1.1.3.2.3" xref="S3.E8.m1.4.4.4.1.1.1.3.2.3.cmml">𝐭</mi><mi id="S3.E8.m1.4.4.4.1.1.1.3.3" xref="S3.E8.m1.4.4.4.1.1.1.3.3.cmml">i</mi></msubsup><mo id="S3.E8.m1.4.4.4.1.1.1.1a" xref="S3.E8.m1.4.4.4.1.1.1.1.cmml">+</mo><msubsup id="S3.E8.m1.4.4.4.1.1.1.4" xref="S3.E8.m1.4.4.4.1.1.1.4.cmml"><mi id="S3.E8.m1.4.4.4.1.1.1.4.2.2" xref="S3.E8.m1.4.4.4.1.1.1.4.2.2.cmml">𝐠</mi><mi id="S3.E8.m1.4.4.4.1.1.1.4.2.3" xref="S3.E8.m1.4.4.4.1.1.1.4.2.3.cmml">𝐚</mi><mi id="S3.E8.m1.4.4.4.1.1.1.4.3" xref="S3.E8.m1.4.4.4.1.1.1.4.3.cmml">i</mi></msubsup></mrow><mo stretchy="false" id="S3.E8.m1.4.4.4.1.1.3" xref="S3.E8.m1.4.4.4.1.1.1.cmml">)</mo></mrow><mo id="S3.E8.m1.4.4.4.2" xref="S3.E8.m1.4.4.4.2.cmml">/</mo><mn id="S3.E8.m1.4.4.4.3" xref="S3.E8.m1.4.4.4.3.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.4b"><apply id="S3.E8.m1.4.4.cmml" xref="S3.E8.m1.4.4"><eq id="S3.E8.m1.4.4.5.cmml" xref="S3.E8.m1.4.4.5"></eq><apply id="S3.E8.m1.3.3.3.cmml" xref="S3.E8.m1.3.3.3"><times id="S3.E8.m1.3.3.3.4.cmml" xref="S3.E8.m1.3.3.3.4"></times><apply id="S3.E8.m1.3.3.3.5.cmml" xref="S3.E8.m1.3.3.3.5"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.3.5.1.cmml" xref="S3.E8.m1.3.3.3.5">subscript</csymbol><ci id="S3.E8.m1.3.3.3.5.2.cmml" xref="S3.E8.m1.3.3.3.5.2">𝑅</ci><ci id="S3.E8.m1.3.3.3.5.3.cmml" xref="S3.E8.m1.3.3.3.5.3">𝑖</ci></apply><vector id="S3.E8.m1.3.3.3.3.4.cmml" xref="S3.E8.m1.3.3.3.3.3"><apply id="S3.E8.m1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E8.m1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2.2">𝐠</ci><ci id="S3.E8.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2.3">𝐯</ci></apply><ci id="S3.E8.m1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E8.m1.2.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E8.m1.2.2.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E8.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2.2.2.2.2">𝐠</ci><ci id="S3.E8.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.2.2.2.2.3">𝐭</ci></apply><ci id="S3.E8.m1.2.2.2.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.2.2.2.3">𝑖</ci></apply><apply id="S3.E8.m1.3.3.3.3.3.3.cmml" xref="S3.E8.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.3.3.3.3.1.cmml" xref="S3.E8.m1.3.3.3.3.3.3">superscript</csymbol><apply id="S3.E8.m1.3.3.3.3.3.3.2.cmml" xref="S3.E8.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.3.3.3.3.2.1.cmml" xref="S3.E8.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S3.E8.m1.3.3.3.3.3.3.2.2.cmml" xref="S3.E8.m1.3.3.3.3.3.3.2.2">𝐠</ci><ci id="S3.E8.m1.3.3.3.3.3.3.2.3.cmml" xref="S3.E8.m1.3.3.3.3.3.3.2.3">𝐚</ci></apply><ci id="S3.E8.m1.3.3.3.3.3.3.3.cmml" xref="S3.E8.m1.3.3.3.3.3.3.3">𝑖</ci></apply></vector></apply><apply id="S3.E8.m1.4.4.4.cmml" xref="S3.E8.m1.4.4.4"><divide id="S3.E8.m1.4.4.4.2.cmml" xref="S3.E8.m1.4.4.4.2"></divide><apply id="S3.E8.m1.4.4.4.1.1.1.cmml" xref="S3.E8.m1.4.4.4.1.1"><plus id="S3.E8.m1.4.4.4.1.1.1.1.cmml" xref="S3.E8.m1.4.4.4.1.1.1.1"></plus><apply id="S3.E8.m1.4.4.4.1.1.1.2.cmml" xref="S3.E8.m1.4.4.4.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.4.1.1.1.2.1.cmml" xref="S3.E8.m1.4.4.4.1.1.1.2">superscript</csymbol><apply id="S3.E8.m1.4.4.4.1.1.1.2.2.cmml" xref="S3.E8.m1.4.4.4.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.4.1.1.1.2.2.1.cmml" xref="S3.E8.m1.4.4.4.1.1.1.2">subscript</csymbol><ci id="S3.E8.m1.4.4.4.1.1.1.2.2.2.cmml" xref="S3.E8.m1.4.4.4.1.1.1.2.2.2">𝐠</ci><ci id="S3.E8.m1.4.4.4.1.1.1.2.2.3.cmml" xref="S3.E8.m1.4.4.4.1.1.1.2.2.3">𝐯</ci></apply><ci id="S3.E8.m1.4.4.4.1.1.1.2.3.cmml" xref="S3.E8.m1.4.4.4.1.1.1.2.3">𝑖</ci></apply><apply id="S3.E8.m1.4.4.4.1.1.1.3.cmml" xref="S3.E8.m1.4.4.4.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.4.1.1.1.3.1.cmml" xref="S3.E8.m1.4.4.4.1.1.1.3">superscript</csymbol><apply id="S3.E8.m1.4.4.4.1.1.1.3.2.cmml" xref="S3.E8.m1.4.4.4.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.4.1.1.1.3.2.1.cmml" xref="S3.E8.m1.4.4.4.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.4.4.4.1.1.1.3.2.2.cmml" xref="S3.E8.m1.4.4.4.1.1.1.3.2.2">𝐠</ci><ci id="S3.E8.m1.4.4.4.1.1.1.3.2.3.cmml" xref="S3.E8.m1.4.4.4.1.1.1.3.2.3">𝐭</ci></apply><ci id="S3.E8.m1.4.4.4.1.1.1.3.3.cmml" xref="S3.E8.m1.4.4.4.1.1.1.3.3">𝑖</ci></apply><apply id="S3.E8.m1.4.4.4.1.1.1.4.cmml" xref="S3.E8.m1.4.4.4.1.1.1.4"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.4.1.1.1.4.1.cmml" xref="S3.E8.m1.4.4.4.1.1.1.4">superscript</csymbol><apply id="S3.E8.m1.4.4.4.1.1.1.4.2.cmml" xref="S3.E8.m1.4.4.4.1.1.1.4"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.4.1.1.1.4.2.1.cmml" xref="S3.E8.m1.4.4.4.1.1.1.4">subscript</csymbol><ci id="S3.E8.m1.4.4.4.1.1.1.4.2.2.cmml" xref="S3.E8.m1.4.4.4.1.1.1.4.2.2">𝐠</ci><ci id="S3.E8.m1.4.4.4.1.1.1.4.2.3.cmml" xref="S3.E8.m1.4.4.4.1.1.1.4.2.3">𝐚</ci></apply><ci id="S3.E8.m1.4.4.4.1.1.1.4.3.cmml" xref="S3.E8.m1.4.4.4.1.1.1.4.3">𝑖</ci></apply></apply><cn type="integer" id="S3.E8.m1.4.4.4.3.cmml" xref="S3.E8.m1.4.4.4.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.4c">R_{i}(\mathbf{g}_{\mathbf{v}}^{i},\mathbf{g}_{\mathbf{t}}^{i},\mathbf{g}_{\mathbf{a}}^{i})=(\mathbf{g}_{\mathbf{v}}^{i}+\mathbf{g}_{\mathbf{t}}^{i}+\mathbf{g}_{\mathbf{a}}^{i})/3</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS5.p5" class="ltx_para">
<p id="S3.SS5.p5.3" class="ltx_p">After estimating the cluster centroids <math id="S3.SS5.p5.1.m1.3" class="ltx_Math" alttext="(\mathbf{C}_{1},\dotsc,\mathbf{C}_{k})" display="inline"><semantics id="S3.SS5.p5.1.m1.3a"><mrow id="S3.SS5.p5.1.m1.3.3.2" xref="S3.SS5.p5.1.m1.3.3.3.cmml"><mo stretchy="false" id="S3.SS5.p5.1.m1.3.3.2.3" xref="S3.SS5.p5.1.m1.3.3.3.cmml">(</mo><msub id="S3.SS5.p5.1.m1.2.2.1.1" xref="S3.SS5.p5.1.m1.2.2.1.1.cmml"><mi id="S3.SS5.p5.1.m1.2.2.1.1.2" xref="S3.SS5.p5.1.m1.2.2.1.1.2.cmml">𝐂</mi><mn id="S3.SS5.p5.1.m1.2.2.1.1.3" xref="S3.SS5.p5.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS5.p5.1.m1.3.3.2.4" xref="S3.SS5.p5.1.m1.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS5.p5.1.m1.1.1" xref="S3.SS5.p5.1.m1.1.1.cmml">…</mi><mo id="S3.SS5.p5.1.m1.3.3.2.5" xref="S3.SS5.p5.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS5.p5.1.m1.3.3.2.2" xref="S3.SS5.p5.1.m1.3.3.2.2.cmml"><mi id="S3.SS5.p5.1.m1.3.3.2.2.2" xref="S3.SS5.p5.1.m1.3.3.2.2.2.cmml">𝐂</mi><mi id="S3.SS5.p5.1.m1.3.3.2.2.3" xref="S3.SS5.p5.1.m1.3.3.2.2.3.cmml">k</mi></msub><mo stretchy="false" id="S3.SS5.p5.1.m1.3.3.2.6" xref="S3.SS5.p5.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p5.1.m1.3b"><vector id="S3.SS5.p5.1.m1.3.3.3.cmml" xref="S3.SS5.p5.1.m1.3.3.2"><apply id="S3.SS5.p5.1.m1.2.2.1.1.cmml" xref="S3.SS5.p5.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p5.1.m1.2.2.1.1.1.cmml" xref="S3.SS5.p5.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS5.p5.1.m1.2.2.1.1.2.cmml" xref="S3.SS5.p5.1.m1.2.2.1.1.2">𝐂</ci><cn type="integer" id="S3.SS5.p5.1.m1.2.2.1.1.3.cmml" xref="S3.SS5.p5.1.m1.2.2.1.1.3">1</cn></apply><ci id="S3.SS5.p5.1.m1.1.1.cmml" xref="S3.SS5.p5.1.m1.1.1">…</ci><apply id="S3.SS5.p5.1.m1.3.3.2.2.cmml" xref="S3.SS5.p5.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.p5.1.m1.3.3.2.2.1.cmml" xref="S3.SS5.p5.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS5.p5.1.m1.3.3.2.2.2.cmml" xref="S3.SS5.p5.1.m1.3.3.2.2.2">𝐂</ci><ci id="S3.SS5.p5.1.m1.3.3.2.2.3.cmml" xref="S3.SS5.p5.1.m1.3.3.2.2.3">𝑘</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p5.1.m1.3c">(\mathbf{C}_{1},\dotsc,\mathbf{C}_{k})</annotation></semantics></math>, where <math id="S3.SS5.p5.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS5.p5.2.m2.1a"><mi id="S3.SS5.p5.2.m2.1.1" xref="S3.SS5.p5.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p5.2.m2.1b"><ci id="S3.SS5.p5.2.m2.1.1.cmml" xref="S3.SS5.p5.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p5.2.m2.1c">k</annotation></semantics></math> is the number of clusters, we estimate the multi-modal centroids using K-means over the multi-modal representations <math id="S3.SS5.p5.3.m3.1" class="ltx_Math" alttext="\mathbf{R}" display="inline"><semantics id="S3.SS5.p5.3.m3.1a"><mi id="S3.SS5.p5.3.m3.1.1" xref="S3.SS5.p5.3.m3.1.1.cmml">𝐑</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p5.3.m3.1b"><ci id="S3.SS5.p5.3.m3.1.1.cmml" xref="S3.SS5.p5.3.m3.1.1">𝐑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p5.3.m3.1c">\mathbf{R}</annotation></semantics></math> by minimizing the following equation:</p>
</div>
<div id="S3.SS5.p6" class="ltx_para">
<table id="S3.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E9.m1.2" class="ltx_Math" alttext="\sum_{j=1}^{k}\sum_{i=1}^{n}\left|\mathbf{R}_{i}^{(j)}-\mathbf{C}_{j}\right|" display="block"><semantics id="S3.E9.m1.2a"><mrow id="S3.E9.m1.2.2" xref="S3.E9.m1.2.2.cmml"><munderover id="S3.E9.m1.2.2.2" xref="S3.E9.m1.2.2.2.cmml"><mo movablelimits="false" id="S3.E9.m1.2.2.2.2.2" xref="S3.E9.m1.2.2.2.2.2.cmml">∑</mo><mrow id="S3.E9.m1.2.2.2.2.3" xref="S3.E9.m1.2.2.2.2.3.cmml"><mi id="S3.E9.m1.2.2.2.2.3.2" xref="S3.E9.m1.2.2.2.2.3.2.cmml">j</mi><mo id="S3.E9.m1.2.2.2.2.3.1" xref="S3.E9.m1.2.2.2.2.3.1.cmml">=</mo><mn id="S3.E9.m1.2.2.2.2.3.3" xref="S3.E9.m1.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E9.m1.2.2.2.3" xref="S3.E9.m1.2.2.2.3.cmml">k</mi></munderover><mrow id="S3.E9.m1.2.2.1" xref="S3.E9.m1.2.2.1.cmml"><munderover id="S3.E9.m1.2.2.1.2" xref="S3.E9.m1.2.2.1.2.cmml"><mo lspace="0.167em" movablelimits="false" rspace="0em" id="S3.E9.m1.2.2.1.2.2.2" xref="S3.E9.m1.2.2.1.2.2.2.cmml">∑</mo><mrow id="S3.E9.m1.2.2.1.2.2.3" xref="S3.E9.m1.2.2.1.2.2.3.cmml"><mi id="S3.E9.m1.2.2.1.2.2.3.2" xref="S3.E9.m1.2.2.1.2.2.3.2.cmml">i</mi><mo id="S3.E9.m1.2.2.1.2.2.3.1" xref="S3.E9.m1.2.2.1.2.2.3.1.cmml">=</mo><mn id="S3.E9.m1.2.2.1.2.2.3.3" xref="S3.E9.m1.2.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E9.m1.2.2.1.2.3" xref="S3.E9.m1.2.2.1.2.3.cmml">n</mi></munderover><mrow id="S3.E9.m1.2.2.1.1.1" xref="S3.E9.m1.2.2.1.1.2.cmml"><mo id="S3.E9.m1.2.2.1.1.1.2" xref="S3.E9.m1.2.2.1.1.2.1.cmml">|</mo><mrow id="S3.E9.m1.2.2.1.1.1.1" xref="S3.E9.m1.2.2.1.1.1.1.cmml"><msubsup id="S3.E9.m1.2.2.1.1.1.1.2" xref="S3.E9.m1.2.2.1.1.1.1.2.cmml"><mi id="S3.E9.m1.2.2.1.1.1.1.2.2.2" xref="S3.E9.m1.2.2.1.1.1.1.2.2.2.cmml">𝐑</mi><mi id="S3.E9.m1.2.2.1.1.1.1.2.2.3" xref="S3.E9.m1.2.2.1.1.1.1.2.2.3.cmml">i</mi><mrow id="S3.E9.m1.1.1.1.3" xref="S3.E9.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E9.m1.1.1.1.3.1" xref="S3.E9.m1.2.2.1.1.1.1.2.cmml">(</mo><mi id="S3.E9.m1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml">j</mi><mo stretchy="false" id="S3.E9.m1.1.1.1.3.2" xref="S3.E9.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></msubsup><mo id="S3.E9.m1.2.2.1.1.1.1.1" xref="S3.E9.m1.2.2.1.1.1.1.1.cmml">−</mo><msub id="S3.E9.m1.2.2.1.1.1.1.3" xref="S3.E9.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E9.m1.2.2.1.1.1.1.3.2" xref="S3.E9.m1.2.2.1.1.1.1.3.2.cmml">𝐂</mi><mi id="S3.E9.m1.2.2.1.1.1.1.3.3" xref="S3.E9.m1.2.2.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo id="S3.E9.m1.2.2.1.1.1.3" xref="S3.E9.m1.2.2.1.1.2.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.2b"><apply id="S3.E9.m1.2.2.cmml" xref="S3.E9.m1.2.2"><apply id="S3.E9.m1.2.2.2.cmml" xref="S3.E9.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.2.1.cmml" xref="S3.E9.m1.2.2.2">superscript</csymbol><apply id="S3.E9.m1.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.2.2.1.cmml" xref="S3.E9.m1.2.2.2">subscript</csymbol><sum id="S3.E9.m1.2.2.2.2.2.cmml" xref="S3.E9.m1.2.2.2.2.2"></sum><apply id="S3.E9.m1.2.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.2.3"><eq id="S3.E9.m1.2.2.2.2.3.1.cmml" xref="S3.E9.m1.2.2.2.2.3.1"></eq><ci id="S3.E9.m1.2.2.2.2.3.2.cmml" xref="S3.E9.m1.2.2.2.2.3.2">𝑗</ci><cn type="integer" id="S3.E9.m1.2.2.2.2.3.3.cmml" xref="S3.E9.m1.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.E9.m1.2.2.2.3.cmml" xref="S3.E9.m1.2.2.2.3">𝑘</ci></apply><apply id="S3.E9.m1.2.2.1.cmml" xref="S3.E9.m1.2.2.1"><apply id="S3.E9.m1.2.2.1.2.cmml" xref="S3.E9.m1.2.2.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.2.1.cmml" xref="S3.E9.m1.2.2.1.2">superscript</csymbol><apply id="S3.E9.m1.2.2.1.2.2.cmml" xref="S3.E9.m1.2.2.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.2.2.1.cmml" xref="S3.E9.m1.2.2.1.2">subscript</csymbol><sum id="S3.E9.m1.2.2.1.2.2.2.cmml" xref="S3.E9.m1.2.2.1.2.2.2"></sum><apply id="S3.E9.m1.2.2.1.2.2.3.cmml" xref="S3.E9.m1.2.2.1.2.2.3"><eq id="S3.E9.m1.2.2.1.2.2.3.1.cmml" xref="S3.E9.m1.2.2.1.2.2.3.1"></eq><ci id="S3.E9.m1.2.2.1.2.2.3.2.cmml" xref="S3.E9.m1.2.2.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.E9.m1.2.2.1.2.2.3.3.cmml" xref="S3.E9.m1.2.2.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E9.m1.2.2.1.2.3.cmml" xref="S3.E9.m1.2.2.1.2.3">𝑛</ci></apply><apply id="S3.E9.m1.2.2.1.1.2.cmml" xref="S3.E9.m1.2.2.1.1.1"><abs id="S3.E9.m1.2.2.1.1.2.1.cmml" xref="S3.E9.m1.2.2.1.1.1.2"></abs><apply id="S3.E9.m1.2.2.1.1.1.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1"><minus id="S3.E9.m1.2.2.1.1.1.1.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.1"></minus><apply id="S3.E9.m1.2.2.1.1.1.1.2.cmml" xref="S3.E9.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.2">superscript</csymbol><apply id="S3.E9.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.E9.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.1.1.1.2.2.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.2">subscript</csymbol><ci id="S3.E9.m1.2.2.1.1.1.1.2.2.2.cmml" xref="S3.E9.m1.2.2.1.1.1.1.2.2.2">𝐑</ci><ci id="S3.E9.m1.2.2.1.1.1.1.2.2.3.cmml" xref="S3.E9.m1.2.2.1.1.1.1.2.2.3">𝑖</ci></apply><ci id="S3.E9.m1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1">𝑗</ci></apply><apply id="S3.E9.m1.2.2.1.1.1.1.3.cmml" xref="S3.E9.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E9.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E9.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E9.m1.2.2.1.1.1.1.3.2">𝐂</ci><ci id="S3.E9.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E9.m1.2.2.1.1.1.1.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.2c">\sum_{j=1}^{k}\sum_{i=1}^{n}\left|\mathbf{R}_{i}^{(j)}-\mathbf{C}_{j}\right|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S3.SS5.p6.4" class="ltx_p">where <math id="S3.SS5.p6.1.m1.1" class="ltx_Math" alttext="\mathbf{R}_{i}^{(j)}" display="inline"><semantics id="S3.SS5.p6.1.m1.1a"><msubsup id="S3.SS5.p6.1.m1.1.2" xref="S3.SS5.p6.1.m1.1.2.cmml"><mi id="S3.SS5.p6.1.m1.1.2.2.2" xref="S3.SS5.p6.1.m1.1.2.2.2.cmml">𝐑</mi><mi id="S3.SS5.p6.1.m1.1.2.2.3" xref="S3.SS5.p6.1.m1.1.2.2.3.cmml">i</mi><mrow id="S3.SS5.p6.1.m1.1.1.1.3" xref="S3.SS5.p6.1.m1.1.2.cmml"><mo stretchy="false" id="S3.SS5.p6.1.m1.1.1.1.3.1" xref="S3.SS5.p6.1.m1.1.2.cmml">(</mo><mi id="S3.SS5.p6.1.m1.1.1.1.1" xref="S3.SS5.p6.1.m1.1.1.1.1.cmml">j</mi><mo stretchy="false" id="S3.SS5.p6.1.m1.1.1.1.3.2" xref="S3.SS5.p6.1.m1.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.p6.1.m1.1b"><apply id="S3.SS5.p6.1.m1.1.2.cmml" xref="S3.SS5.p6.1.m1.1.2"><csymbol cd="ambiguous" id="S3.SS5.p6.1.m1.1.2.1.cmml" xref="S3.SS5.p6.1.m1.1.2">superscript</csymbol><apply id="S3.SS5.p6.1.m1.1.2.2.cmml" xref="S3.SS5.p6.1.m1.1.2"><csymbol cd="ambiguous" id="S3.SS5.p6.1.m1.1.2.2.1.cmml" xref="S3.SS5.p6.1.m1.1.2">subscript</csymbol><ci id="S3.SS5.p6.1.m1.1.2.2.2.cmml" xref="S3.SS5.p6.1.m1.1.2.2.2">𝐑</ci><ci id="S3.SS5.p6.1.m1.1.2.2.3.cmml" xref="S3.SS5.p6.1.m1.1.2.2.3">𝑖</ci></apply><ci id="S3.SS5.p6.1.m1.1.1.1.1.cmml" xref="S3.SS5.p6.1.m1.1.1.1.1">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p6.1.m1.1c">\mathbf{R}_{i}^{(j)}</annotation></semantics></math> is the multimodal representation that belongs to cluster j with centroid <math id="S3.SS5.p6.2.m2.1" class="ltx_Math" alttext="\mathbf{C}j" display="inline"><semantics id="S3.SS5.p6.2.m2.1a"><mrow id="S3.SS5.p6.2.m2.1.1" xref="S3.SS5.p6.2.m2.1.1.cmml"><mi id="S3.SS5.p6.2.m2.1.1.2" xref="S3.SS5.p6.2.m2.1.1.2.cmml">𝐂</mi><mo lspace="0em" rspace="0em" id="S3.SS5.p6.2.m2.1.1.1" xref="S3.SS5.p6.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS5.p6.2.m2.1.1.3" xref="S3.SS5.p6.2.m2.1.1.3.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p6.2.m2.1b"><apply id="S3.SS5.p6.2.m2.1.1.cmml" xref="S3.SS5.p6.2.m2.1.1"><times id="S3.SS5.p6.2.m2.1.1.1.cmml" xref="S3.SS5.p6.2.m2.1.1.1"></times><ci id="S3.SS5.p6.2.m2.1.1.2.cmml" xref="S3.SS5.p6.2.m2.1.1.2">𝐂</ci><ci id="S3.SS5.p6.2.m2.1.1.3.cmml" xref="S3.SS5.p6.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p6.2.m2.1c">\mathbf{C}j</annotation></semantics></math>. Finally, we learn the Multi-modal clustering loss that minimizes the distance between the multi-modal representations <math id="S3.SS5.p6.3.m3.5" class="ltx_Math" alttext="(\mathbf{R}_{1}^{(1)},\dotsc,\mathbf{R}_{n}^{(k)})" display="inline"><semantics id="S3.SS5.p6.3.m3.5a"><mrow id="S3.SS5.p6.3.m3.5.5.2" xref="S3.SS5.p6.3.m3.5.5.3.cmml"><mo stretchy="false" id="S3.SS5.p6.3.m3.5.5.2.3" xref="S3.SS5.p6.3.m3.5.5.3.cmml">(</mo><msubsup id="S3.SS5.p6.3.m3.4.4.1.1" xref="S3.SS5.p6.3.m3.4.4.1.1.cmml"><mi id="S3.SS5.p6.3.m3.4.4.1.1.2.2" xref="S3.SS5.p6.3.m3.4.4.1.1.2.2.cmml">𝐑</mi><mn id="S3.SS5.p6.3.m3.4.4.1.1.2.3" xref="S3.SS5.p6.3.m3.4.4.1.1.2.3.cmml">1</mn><mrow id="S3.SS5.p6.3.m3.1.1.1.3" xref="S3.SS5.p6.3.m3.4.4.1.1.cmml"><mo stretchy="false" id="S3.SS5.p6.3.m3.1.1.1.3.1" xref="S3.SS5.p6.3.m3.4.4.1.1.cmml">(</mo><mn id="S3.SS5.p6.3.m3.1.1.1.1" xref="S3.SS5.p6.3.m3.1.1.1.1.cmml">1</mn><mo stretchy="false" id="S3.SS5.p6.3.m3.1.1.1.3.2" xref="S3.SS5.p6.3.m3.4.4.1.1.cmml">)</mo></mrow></msubsup><mo id="S3.SS5.p6.3.m3.5.5.2.4" xref="S3.SS5.p6.3.m3.5.5.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS5.p6.3.m3.3.3" xref="S3.SS5.p6.3.m3.3.3.cmml">…</mi><mo id="S3.SS5.p6.3.m3.5.5.2.5" xref="S3.SS5.p6.3.m3.5.5.3.cmml">,</mo><msubsup id="S3.SS5.p6.3.m3.5.5.2.2" xref="S3.SS5.p6.3.m3.5.5.2.2.cmml"><mi id="S3.SS5.p6.3.m3.5.5.2.2.2.2" xref="S3.SS5.p6.3.m3.5.5.2.2.2.2.cmml">𝐑</mi><mi id="S3.SS5.p6.3.m3.5.5.2.2.2.3" xref="S3.SS5.p6.3.m3.5.5.2.2.2.3.cmml">n</mi><mrow id="S3.SS5.p6.3.m3.2.2.1.3" xref="S3.SS5.p6.3.m3.5.5.2.2.cmml"><mo stretchy="false" id="S3.SS5.p6.3.m3.2.2.1.3.1" xref="S3.SS5.p6.3.m3.5.5.2.2.cmml">(</mo><mi id="S3.SS5.p6.3.m3.2.2.1.1" xref="S3.SS5.p6.3.m3.2.2.1.1.cmml">k</mi><mo stretchy="false" id="S3.SS5.p6.3.m3.2.2.1.3.2" xref="S3.SS5.p6.3.m3.5.5.2.2.cmml">)</mo></mrow></msubsup><mo stretchy="false" id="S3.SS5.p6.3.m3.5.5.2.6" xref="S3.SS5.p6.3.m3.5.5.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p6.3.m3.5b"><vector id="S3.SS5.p6.3.m3.5.5.3.cmml" xref="S3.SS5.p6.3.m3.5.5.2"><apply id="S3.SS5.p6.3.m3.4.4.1.1.cmml" xref="S3.SS5.p6.3.m3.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS5.p6.3.m3.4.4.1.1.1.cmml" xref="S3.SS5.p6.3.m3.4.4.1.1">superscript</csymbol><apply id="S3.SS5.p6.3.m3.4.4.1.1.2.cmml" xref="S3.SS5.p6.3.m3.4.4.1.1"><csymbol cd="ambiguous" id="S3.SS5.p6.3.m3.4.4.1.1.2.1.cmml" xref="S3.SS5.p6.3.m3.4.4.1.1">subscript</csymbol><ci id="S3.SS5.p6.3.m3.4.4.1.1.2.2.cmml" xref="S3.SS5.p6.3.m3.4.4.1.1.2.2">𝐑</ci><cn type="integer" id="S3.SS5.p6.3.m3.4.4.1.1.2.3.cmml" xref="S3.SS5.p6.3.m3.4.4.1.1.2.3">1</cn></apply><cn type="integer" id="S3.SS5.p6.3.m3.1.1.1.1.cmml" xref="S3.SS5.p6.3.m3.1.1.1.1">1</cn></apply><ci id="S3.SS5.p6.3.m3.3.3.cmml" xref="S3.SS5.p6.3.m3.3.3">…</ci><apply id="S3.SS5.p6.3.m3.5.5.2.2.cmml" xref="S3.SS5.p6.3.m3.5.5.2.2"><csymbol cd="ambiguous" id="S3.SS5.p6.3.m3.5.5.2.2.1.cmml" xref="S3.SS5.p6.3.m3.5.5.2.2">superscript</csymbol><apply id="S3.SS5.p6.3.m3.5.5.2.2.2.cmml" xref="S3.SS5.p6.3.m3.5.5.2.2"><csymbol cd="ambiguous" id="S3.SS5.p6.3.m3.5.5.2.2.2.1.cmml" xref="S3.SS5.p6.3.m3.5.5.2.2">subscript</csymbol><ci id="S3.SS5.p6.3.m3.5.5.2.2.2.2.cmml" xref="S3.SS5.p6.3.m3.5.5.2.2.2.2">𝐑</ci><ci id="S3.SS5.p6.3.m3.5.5.2.2.2.3.cmml" xref="S3.SS5.p6.3.m3.5.5.2.2.2.3">𝑛</ci></apply><ci id="S3.SS5.p6.3.m3.2.2.1.1.cmml" xref="S3.SS5.p6.3.m3.2.2.1.1">𝑘</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p6.3.m3.5c">(\mathbf{R}_{1}^{(1)},\dotsc,\mathbf{R}_{n}^{(k)})</annotation></semantics></math> and the cluster centroids <math id="S3.SS5.p6.4.m4.3" class="ltx_Math" alttext="(\mathbf{C}_{1},\dotsc,\mathbf{C}_{k})" display="inline"><semantics id="S3.SS5.p6.4.m4.3a"><mrow id="S3.SS5.p6.4.m4.3.3.2" xref="S3.SS5.p6.4.m4.3.3.3.cmml"><mo stretchy="false" id="S3.SS5.p6.4.m4.3.3.2.3" xref="S3.SS5.p6.4.m4.3.3.3.cmml">(</mo><msub id="S3.SS5.p6.4.m4.2.2.1.1" xref="S3.SS5.p6.4.m4.2.2.1.1.cmml"><mi id="S3.SS5.p6.4.m4.2.2.1.1.2" xref="S3.SS5.p6.4.m4.2.2.1.1.2.cmml">𝐂</mi><mn id="S3.SS5.p6.4.m4.2.2.1.1.3" xref="S3.SS5.p6.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS5.p6.4.m4.3.3.2.4" xref="S3.SS5.p6.4.m4.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS5.p6.4.m4.1.1" xref="S3.SS5.p6.4.m4.1.1.cmml">…</mi><mo id="S3.SS5.p6.4.m4.3.3.2.5" xref="S3.SS5.p6.4.m4.3.3.3.cmml">,</mo><msub id="S3.SS5.p6.4.m4.3.3.2.2" xref="S3.SS5.p6.4.m4.3.3.2.2.cmml"><mi id="S3.SS5.p6.4.m4.3.3.2.2.2" xref="S3.SS5.p6.4.m4.3.3.2.2.2.cmml">𝐂</mi><mi id="S3.SS5.p6.4.m4.3.3.2.2.3" xref="S3.SS5.p6.4.m4.3.3.2.2.3.cmml">k</mi></msub><mo stretchy="false" id="S3.SS5.p6.4.m4.3.3.2.6" xref="S3.SS5.p6.4.m4.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p6.4.m4.3b"><vector id="S3.SS5.p6.4.m4.3.3.3.cmml" xref="S3.SS5.p6.4.m4.3.3.2"><apply id="S3.SS5.p6.4.m4.2.2.1.1.cmml" xref="S3.SS5.p6.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p6.4.m4.2.2.1.1.1.cmml" xref="S3.SS5.p6.4.m4.2.2.1.1">subscript</csymbol><ci id="S3.SS5.p6.4.m4.2.2.1.1.2.cmml" xref="S3.SS5.p6.4.m4.2.2.1.1.2">𝐂</ci><cn type="integer" id="S3.SS5.p6.4.m4.2.2.1.1.3.cmml" xref="S3.SS5.p6.4.m4.2.2.1.1.3">1</cn></apply><ci id="S3.SS5.p6.4.m4.1.1.cmml" xref="S3.SS5.p6.4.m4.1.1">…</ci><apply id="S3.SS5.p6.4.m4.3.3.2.2.cmml" xref="S3.SS5.p6.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.p6.4.m4.3.3.2.2.1.cmml" xref="S3.SS5.p6.4.m4.3.3.2.2">subscript</csymbol><ci id="S3.SS5.p6.4.m4.3.3.2.2.2.cmml" xref="S3.SS5.p6.4.m4.3.3.2.2.2">𝐂</ci><ci id="S3.SS5.p6.4.m4.3.3.2.2.3.cmml" xref="S3.SS5.p6.4.m4.3.3.2.2.3">𝑘</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p6.4.m4.3c">(\mathbf{C}_{1},\dotsc,\mathbf{C}_{k})</annotation></semantics></math>. This loss updates all modality encoders to encourage modality embeddings to be presented closer to each other in the feature space. The multi-modal clustering loss encourages the multi-modal representations that belong to the same cluster to be closer to their centroid thus preserving the similarity between multimodal representations.</p>
<table id="S3.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E10.m1.1" class="ltx_Math" alttext="\ell_{\text{Clu}}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{{\rm e}^{\mathbf{R}_{i}^{j}\cdot\mathbf{C}_{j}-\delta}}{\sum^{K}_{k=1}\rm e^{\mathbf{R}_{i}^{j}\cdot\mathbf{C}_{k}}}" display="block"><semantics id="S3.E10.m1.1a"><mrow id="S3.E10.m1.1.1" xref="S3.E10.m1.1.1.cmml"><msub id="S3.E10.m1.1.1.2" xref="S3.E10.m1.1.1.2.cmml"><mi mathvariant="normal" id="S3.E10.m1.1.1.2.2" xref="S3.E10.m1.1.1.2.2.cmml">ℓ</mi><mtext id="S3.E10.m1.1.1.2.3" xref="S3.E10.m1.1.1.2.3a.cmml">Clu</mtext></msub><mo id="S3.E10.m1.1.1.1" xref="S3.E10.m1.1.1.1.cmml">=</mo><mrow id="S3.E10.m1.1.1.3" xref="S3.E10.m1.1.1.3.cmml"><mo id="S3.E10.m1.1.1.3a" xref="S3.E10.m1.1.1.3.cmml">−</mo><mrow id="S3.E10.m1.1.1.3.2" xref="S3.E10.m1.1.1.3.2.cmml"><mfrac id="S3.E10.m1.1.1.3.2.2" xref="S3.E10.m1.1.1.3.2.2.cmml"><mn id="S3.E10.m1.1.1.3.2.2.2" xref="S3.E10.m1.1.1.3.2.2.2.cmml">1</mn><mi id="S3.E10.m1.1.1.3.2.2.3" xref="S3.E10.m1.1.1.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E10.m1.1.1.3.2.1" xref="S3.E10.m1.1.1.3.2.1.cmml">​</mo><mrow id="S3.E10.m1.1.1.3.2.3" xref="S3.E10.m1.1.1.3.2.3.cmml"><munderover id="S3.E10.m1.1.1.3.2.3.1" xref="S3.E10.m1.1.1.3.2.3.1.cmml"><mo movablelimits="false" id="S3.E10.m1.1.1.3.2.3.1.2.2" xref="S3.E10.m1.1.1.3.2.3.1.2.2.cmml">∑</mo><mrow id="S3.E10.m1.1.1.3.2.3.1.2.3" xref="S3.E10.m1.1.1.3.2.3.1.2.3.cmml"><mi id="S3.E10.m1.1.1.3.2.3.1.2.3.2" xref="S3.E10.m1.1.1.3.2.3.1.2.3.2.cmml">i</mi><mo id="S3.E10.m1.1.1.3.2.3.1.2.3.1" xref="S3.E10.m1.1.1.3.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E10.m1.1.1.3.2.3.1.2.3.3" xref="S3.E10.m1.1.1.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E10.m1.1.1.3.2.3.1.3" xref="S3.E10.m1.1.1.3.2.3.1.3.cmml">N</mi></munderover><mrow id="S3.E10.m1.1.1.3.2.3.2" xref="S3.E10.m1.1.1.3.2.3.2.cmml"><mi id="S3.E10.m1.1.1.3.2.3.2.1" xref="S3.E10.m1.1.1.3.2.3.2.1.cmml">log</mi><mo lspace="0.167em" id="S3.E10.m1.1.1.3.2.3.2a" xref="S3.E10.m1.1.1.3.2.3.2.cmml">⁡</mo><mfrac id="S3.E10.m1.1.1.3.2.3.2.2" xref="S3.E10.m1.1.1.3.2.3.2.2.cmml"><msup id="S3.E10.m1.1.1.3.2.3.2.2.2" xref="S3.E10.m1.1.1.3.2.3.2.2.2.cmml"><mi mathvariant="normal" id="S3.E10.m1.1.1.3.2.3.2.2.2.2" xref="S3.E10.m1.1.1.3.2.3.2.2.2.2.cmml">e</mi><mrow id="S3.E10.m1.1.1.3.2.3.2.2.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.cmml"><mrow id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.cmml"><msubsup id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.cmml"><mi id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.2" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.2.cmml">𝐑</mi><mi id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.3.cmml">i</mi><mi id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.3.cmml">j</mi></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.1" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.1.cmml">⋅</mo><msub id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.cmml"><mi id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.2" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.2.cmml">𝐂</mi><mi id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.3" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.3.cmml">j</mi></msub></mrow><mo id="S3.E10.m1.1.1.3.2.3.2.2.2.3.1" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.1.cmml">−</mo><mi id="S3.E10.m1.1.1.3.2.3.2.2.2.3.3" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.3.cmml">δ</mi></mrow></msup><mrow id="S3.E10.m1.1.1.3.2.3.2.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.cmml"><msubsup id="S3.E10.m1.1.1.3.2.3.2.2.3.1" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.cmml"><mo id="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.2" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.2.cmml">∑</mo><mrow id="S3.E10.m1.1.1.3.2.3.2.2.3.1.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.cmml"><mi id="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.2" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.2.cmml">k</mi><mo id="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.1" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.1.cmml">=</mo><mn id="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.3.cmml">1</mn></mrow><mi id="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.3.cmml">K</mi></msubsup><msup id="S3.E10.m1.1.1.3.2.3.2.2.3.2" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.cmml"><mi mathvariant="normal" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.2" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.2.cmml">e</mi><mrow id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.cmml"><msubsup id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.cmml"><mi id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.2" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.2.cmml">𝐑</mi><mi mathvariant="normal" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.3.cmml">i</mi><mi mathvariant="normal" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.3.cmml">j</mi></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.1" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.1.cmml">⋅</mo><msub id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.cmml"><mi id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.2" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.2.cmml">𝐂</mi><mi mathvariant="normal" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.3" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.3.cmml">k</mi></msub></mrow></msup></mrow></mfrac></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E10.m1.1b"><apply id="S3.E10.m1.1.1.cmml" xref="S3.E10.m1.1.1"><eq id="S3.E10.m1.1.1.1.cmml" xref="S3.E10.m1.1.1.1"></eq><apply id="S3.E10.m1.1.1.2.cmml" xref="S3.E10.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.2.1.cmml" xref="S3.E10.m1.1.1.2">subscript</csymbol><ci id="S3.E10.m1.1.1.2.2.cmml" xref="S3.E10.m1.1.1.2.2">ℓ</ci><ci id="S3.E10.m1.1.1.2.3a.cmml" xref="S3.E10.m1.1.1.2.3"><mtext mathsize="70%" id="S3.E10.m1.1.1.2.3.cmml" xref="S3.E10.m1.1.1.2.3">Clu</mtext></ci></apply><apply id="S3.E10.m1.1.1.3.cmml" xref="S3.E10.m1.1.1.3"><minus id="S3.E10.m1.1.1.3.1.cmml" xref="S3.E10.m1.1.1.3"></minus><apply id="S3.E10.m1.1.1.3.2.cmml" xref="S3.E10.m1.1.1.3.2"><times id="S3.E10.m1.1.1.3.2.1.cmml" xref="S3.E10.m1.1.1.3.2.1"></times><apply id="S3.E10.m1.1.1.3.2.2.cmml" xref="S3.E10.m1.1.1.3.2.2"><divide id="S3.E10.m1.1.1.3.2.2.1.cmml" xref="S3.E10.m1.1.1.3.2.2"></divide><cn type="integer" id="S3.E10.m1.1.1.3.2.2.2.cmml" xref="S3.E10.m1.1.1.3.2.2.2">1</cn><ci id="S3.E10.m1.1.1.3.2.2.3.cmml" xref="S3.E10.m1.1.1.3.2.2.3">𝑁</ci></apply><apply id="S3.E10.m1.1.1.3.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3"><apply id="S3.E10.m1.1.1.3.2.3.1.cmml" xref="S3.E10.m1.1.1.3.2.3.1"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.1.1.cmml" xref="S3.E10.m1.1.1.3.2.3.1">superscript</csymbol><apply id="S3.E10.m1.1.1.3.2.3.1.2.cmml" xref="S3.E10.m1.1.1.3.2.3.1"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.1.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.1">subscript</csymbol><sum id="S3.E10.m1.1.1.3.2.3.1.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.1.2.2"></sum><apply id="S3.E10.m1.1.1.3.2.3.1.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.1.2.3"><eq id="S3.E10.m1.1.1.3.2.3.1.2.3.1.cmml" xref="S3.E10.m1.1.1.3.2.3.1.2.3.1"></eq><ci id="S3.E10.m1.1.1.3.2.3.1.2.3.2.cmml" xref="S3.E10.m1.1.1.3.2.3.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E10.m1.1.1.3.2.3.1.2.3.3.cmml" xref="S3.E10.m1.1.1.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E10.m1.1.1.3.2.3.1.3.cmml" xref="S3.E10.m1.1.1.3.2.3.1.3">𝑁</ci></apply><apply id="S3.E10.m1.1.1.3.2.3.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2"><log id="S3.E10.m1.1.1.3.2.3.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.1"></log><apply id="S3.E10.m1.1.1.3.2.3.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2"><divide id="S3.E10.m1.1.1.3.2.3.2.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2"></divide><apply id="S3.E10.m1.1.1.3.2.3.2.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2">superscript</csymbol><ci id="S3.E10.m1.1.1.3.2.3.2.2.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.2">e</ci><apply id="S3.E10.m1.1.1.3.2.3.2.2.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3"><minus id="S3.E10.m1.1.1.3.2.3.2.2.2.3.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.1"></minus><apply id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2"><ci id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.1">⋅</ci><apply id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2">superscript</csymbol><apply id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2">subscript</csymbol><ci id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.2">𝐑</ci><ci id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.2.3">𝑖</ci></apply><ci id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.2.3">𝑗</ci></apply><apply id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3">subscript</csymbol><ci id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.2">𝐂</ci><ci id="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.2.3.3">𝑗</ci></apply></apply><ci id="S3.E10.m1.1.1.3.2.3.2.2.2.3.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.2.3.3">𝛿</ci></apply></apply><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3"><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.3.1.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1">subscript</csymbol><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1">superscript</csymbol><sum id="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.2"></sum><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.2.3">𝐾</ci></apply><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.3"><eq id="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.1"></eq><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.2">𝑘</ci><cn type="integer" id="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.1.3.3">1</cn></apply></apply><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2">superscript</csymbol><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.2">e</ci><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3"><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.1">⋅</ci><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2">superscript</csymbol><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2">subscript</csymbol><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.2">𝐑</ci><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.2.3">i</ci></apply><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.2.3">j</ci></apply><apply id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.1.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3">subscript</csymbol><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.2.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.2">𝐂</ci><ci id="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.3.cmml" xref="S3.E10.m1.1.1.3.2.3.2.2.3.2.3.3.3">k</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E10.m1.1c">\ell_{\text{Clu}}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{{\rm e}^{\mathbf{R}_{i}^{j}\cdot\mathbf{C}_{j}-\delta}}{\sum^{K}_{k=1}\rm e^{\mathbf{R}_{i}^{j}\cdot\mathbf{C}_{k}}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Multi-Task Self-Supervised Learning</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">In this section, we analyze the ability to learn rich multi-modal representations in a multi-task self-supervised learning fashion. Here we will learn multiple self-supervised tasks simultaneously without supervision, only by leveraging the structure of the multi-modal data. The intuition behind multi-task self-supervised learning is to make the most of the structure of the large unlabeled datasets which leads to rich and better generalized representation learning.
In this study, we investigate the following multi-modal task combination:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">ConCluGen</span>: In this model, we jointly learn three self-supervised tasks. The first is multi-modal contrastive learning. The second is online multi-modal clustering. The third is multi-modal reconstruction. The objective function that guides the learning process in ConCluGen model is as follows:
<br class="ltx_break"></p>
<table id="S3.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E11.m1.1" class="ltx_Math" alttext="L_{ConCluGen}=L_{MMS}+L_{Clu}+L_{Rec}" display="block"><semantics id="S3.E11.m1.1a"><mrow id="S3.E11.m1.1.1" xref="S3.E11.m1.1.1.cmml"><msub id="S3.E11.m1.1.1.2" xref="S3.E11.m1.1.1.2.cmml"><mi id="S3.E11.m1.1.1.2.2" xref="S3.E11.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E11.m1.1.1.2.3" xref="S3.E11.m1.1.1.2.3.cmml"><mi id="S3.E11.m1.1.1.2.3.2" xref="S3.E11.m1.1.1.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.3.1" xref="S3.E11.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3.3" xref="S3.E11.m1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.3.1a" xref="S3.E11.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3.4" xref="S3.E11.m1.1.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.3.1b" xref="S3.E11.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3.5" xref="S3.E11.m1.1.1.2.3.5.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.3.1c" xref="S3.E11.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3.6" xref="S3.E11.m1.1.1.2.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.3.1d" xref="S3.E11.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3.7" xref="S3.E11.m1.1.1.2.3.7.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.3.1e" xref="S3.E11.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3.8" xref="S3.E11.m1.1.1.2.3.8.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.3.1f" xref="S3.E11.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3.9" xref="S3.E11.m1.1.1.2.3.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.2.3.1g" xref="S3.E11.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.2.3.10" xref="S3.E11.m1.1.1.2.3.10.cmml">n</mi></mrow></msub><mo id="S3.E11.m1.1.1.1" xref="S3.E11.m1.1.1.1.cmml">=</mo><mrow id="S3.E11.m1.1.1.3" xref="S3.E11.m1.1.1.3.cmml"><msub id="S3.E11.m1.1.1.3.2" xref="S3.E11.m1.1.1.3.2.cmml"><mi id="S3.E11.m1.1.1.3.2.2" xref="S3.E11.m1.1.1.3.2.2.cmml">L</mi><mrow id="S3.E11.m1.1.1.3.2.3" xref="S3.E11.m1.1.1.3.2.3.cmml"><mi id="S3.E11.m1.1.1.3.2.3.2" xref="S3.E11.m1.1.1.3.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.3.2.3.1" xref="S3.E11.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.3.2.3.3" xref="S3.E11.m1.1.1.3.2.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.3.2.3.1a" xref="S3.E11.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.3.2.3.4" xref="S3.E11.m1.1.1.3.2.3.4.cmml">S</mi></mrow></msub><mo id="S3.E11.m1.1.1.3.1" xref="S3.E11.m1.1.1.3.1.cmml">+</mo><msub id="S3.E11.m1.1.1.3.3" xref="S3.E11.m1.1.1.3.3.cmml"><mi id="S3.E11.m1.1.1.3.3.2" xref="S3.E11.m1.1.1.3.3.2.cmml">L</mi><mrow id="S3.E11.m1.1.1.3.3.3" xref="S3.E11.m1.1.1.3.3.3.cmml"><mi id="S3.E11.m1.1.1.3.3.3.2" xref="S3.E11.m1.1.1.3.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.3.3.3.1" xref="S3.E11.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.3.3.3.3" xref="S3.E11.m1.1.1.3.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.3.3.3.1a" xref="S3.E11.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.3.3.3.4" xref="S3.E11.m1.1.1.3.3.3.4.cmml">u</mi></mrow></msub><mo id="S3.E11.m1.1.1.3.1a" xref="S3.E11.m1.1.1.3.1.cmml">+</mo><msub id="S3.E11.m1.1.1.3.4" xref="S3.E11.m1.1.1.3.4.cmml"><mi id="S3.E11.m1.1.1.3.4.2" xref="S3.E11.m1.1.1.3.4.2.cmml">L</mi><mrow id="S3.E11.m1.1.1.3.4.3" xref="S3.E11.m1.1.1.3.4.3.cmml"><mi id="S3.E11.m1.1.1.3.4.3.2" xref="S3.E11.m1.1.1.3.4.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.3.4.3.1" xref="S3.E11.m1.1.1.3.4.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.3.4.3.3" xref="S3.E11.m1.1.1.3.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E11.m1.1.1.3.4.3.1a" xref="S3.E11.m1.1.1.3.4.3.1.cmml">​</mo><mi id="S3.E11.m1.1.1.3.4.3.4" xref="S3.E11.m1.1.1.3.4.3.4.cmml">c</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E11.m1.1b"><apply id="S3.E11.m1.1.1.cmml" xref="S3.E11.m1.1.1"><eq id="S3.E11.m1.1.1.1.cmml" xref="S3.E11.m1.1.1.1"></eq><apply id="S3.E11.m1.1.1.2.cmml" xref="S3.E11.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.2.1.cmml" xref="S3.E11.m1.1.1.2">subscript</csymbol><ci id="S3.E11.m1.1.1.2.2.cmml" xref="S3.E11.m1.1.1.2.2">𝐿</ci><apply id="S3.E11.m1.1.1.2.3.cmml" xref="S3.E11.m1.1.1.2.3"><times id="S3.E11.m1.1.1.2.3.1.cmml" xref="S3.E11.m1.1.1.2.3.1"></times><ci id="S3.E11.m1.1.1.2.3.2.cmml" xref="S3.E11.m1.1.1.2.3.2">𝐶</ci><ci id="S3.E11.m1.1.1.2.3.3.cmml" xref="S3.E11.m1.1.1.2.3.3">𝑜</ci><ci id="S3.E11.m1.1.1.2.3.4.cmml" xref="S3.E11.m1.1.1.2.3.4">𝑛</ci><ci id="S3.E11.m1.1.1.2.3.5.cmml" xref="S3.E11.m1.1.1.2.3.5">𝐶</ci><ci id="S3.E11.m1.1.1.2.3.6.cmml" xref="S3.E11.m1.1.1.2.3.6">𝑙</ci><ci id="S3.E11.m1.1.1.2.3.7.cmml" xref="S3.E11.m1.1.1.2.3.7">𝑢</ci><ci id="S3.E11.m1.1.1.2.3.8.cmml" xref="S3.E11.m1.1.1.2.3.8">𝐺</ci><ci id="S3.E11.m1.1.1.2.3.9.cmml" xref="S3.E11.m1.1.1.2.3.9">𝑒</ci><ci id="S3.E11.m1.1.1.2.3.10.cmml" xref="S3.E11.m1.1.1.2.3.10">𝑛</ci></apply></apply><apply id="S3.E11.m1.1.1.3.cmml" xref="S3.E11.m1.1.1.3"><plus id="S3.E11.m1.1.1.3.1.cmml" xref="S3.E11.m1.1.1.3.1"></plus><apply id="S3.E11.m1.1.1.3.2.cmml" xref="S3.E11.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.3.2.1.cmml" xref="S3.E11.m1.1.1.3.2">subscript</csymbol><ci id="S3.E11.m1.1.1.3.2.2.cmml" xref="S3.E11.m1.1.1.3.2.2">𝐿</ci><apply id="S3.E11.m1.1.1.3.2.3.cmml" xref="S3.E11.m1.1.1.3.2.3"><times id="S3.E11.m1.1.1.3.2.3.1.cmml" xref="S3.E11.m1.1.1.3.2.3.1"></times><ci id="S3.E11.m1.1.1.3.2.3.2.cmml" xref="S3.E11.m1.1.1.3.2.3.2">𝑀</ci><ci id="S3.E11.m1.1.1.3.2.3.3.cmml" xref="S3.E11.m1.1.1.3.2.3.3">𝑀</ci><ci id="S3.E11.m1.1.1.3.2.3.4.cmml" xref="S3.E11.m1.1.1.3.2.3.4">𝑆</ci></apply></apply><apply id="S3.E11.m1.1.1.3.3.cmml" xref="S3.E11.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.3.3.1.cmml" xref="S3.E11.m1.1.1.3.3">subscript</csymbol><ci id="S3.E11.m1.1.1.3.3.2.cmml" xref="S3.E11.m1.1.1.3.3.2">𝐿</ci><apply id="S3.E11.m1.1.1.3.3.3.cmml" xref="S3.E11.m1.1.1.3.3.3"><times id="S3.E11.m1.1.1.3.3.3.1.cmml" xref="S3.E11.m1.1.1.3.3.3.1"></times><ci id="S3.E11.m1.1.1.3.3.3.2.cmml" xref="S3.E11.m1.1.1.3.3.3.2">𝐶</ci><ci id="S3.E11.m1.1.1.3.3.3.3.cmml" xref="S3.E11.m1.1.1.3.3.3.3">𝑙</ci><ci id="S3.E11.m1.1.1.3.3.3.4.cmml" xref="S3.E11.m1.1.1.3.3.3.4">𝑢</ci></apply></apply><apply id="S3.E11.m1.1.1.3.4.cmml" xref="S3.E11.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E11.m1.1.1.3.4.1.cmml" xref="S3.E11.m1.1.1.3.4">subscript</csymbol><ci id="S3.E11.m1.1.1.3.4.2.cmml" xref="S3.E11.m1.1.1.3.4.2">𝐿</ci><apply id="S3.E11.m1.1.1.3.4.3.cmml" xref="S3.E11.m1.1.1.3.4.3"><times id="S3.E11.m1.1.1.3.4.3.1.cmml" xref="S3.E11.m1.1.1.3.4.3.1"></times><ci id="S3.E11.m1.1.1.3.4.3.2.cmml" xref="S3.E11.m1.1.1.3.4.3.2">𝑅</ci><ci id="S3.E11.m1.1.1.3.4.3.3.cmml" xref="S3.E11.m1.1.1.3.4.3.3">𝑒</ci><ci id="S3.E11.m1.1.1.3.4.3.4.cmml" xref="S3.E11.m1.1.1.3.4.3.4">𝑐</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E11.m1.1c">L_{ConCluGen}=L_{MMS}+L_{Clu}+L_{Rec}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">ConClu</span>: In this model, we jointly learn two self-supervised tasks. First is multi-modal contrastive learning. The second is online multi-modal clustering. The objective function that guides the learning process in ConClu model is as follows:
<br class="ltx_break"></p>
<table id="S3.E12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E12.m1.1" class="ltx_Math" alttext="L_{ConClu}=L_{MMS}+L_{Clu}" display="block"><semantics id="S3.E12.m1.1a"><mrow id="S3.E12.m1.1.1" xref="S3.E12.m1.1.1.cmml"><msub id="S3.E12.m1.1.1.2" xref="S3.E12.m1.1.1.2.cmml"><mi id="S3.E12.m1.1.1.2.2" xref="S3.E12.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E12.m1.1.1.2.3" xref="S3.E12.m1.1.1.2.3.cmml"><mi id="S3.E12.m1.1.1.2.3.2" xref="S3.E12.m1.1.1.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.2.3.1" xref="S3.E12.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.2.3.3" xref="S3.E12.m1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.2.3.1a" xref="S3.E12.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.2.3.4" xref="S3.E12.m1.1.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.2.3.1b" xref="S3.E12.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.2.3.5" xref="S3.E12.m1.1.1.2.3.5.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.2.3.1c" xref="S3.E12.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.2.3.6" xref="S3.E12.m1.1.1.2.3.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.2.3.1d" xref="S3.E12.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.2.3.7" xref="S3.E12.m1.1.1.2.3.7.cmml">u</mi></mrow></msub><mo id="S3.E12.m1.1.1.1" xref="S3.E12.m1.1.1.1.cmml">=</mo><mrow id="S3.E12.m1.1.1.3" xref="S3.E12.m1.1.1.3.cmml"><msub id="S3.E12.m1.1.1.3.2" xref="S3.E12.m1.1.1.3.2.cmml"><mi id="S3.E12.m1.1.1.3.2.2" xref="S3.E12.m1.1.1.3.2.2.cmml">L</mi><mrow id="S3.E12.m1.1.1.3.2.3" xref="S3.E12.m1.1.1.3.2.3.cmml"><mi id="S3.E12.m1.1.1.3.2.3.2" xref="S3.E12.m1.1.1.3.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.3.2.3.1" xref="S3.E12.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.3.2.3.3" xref="S3.E12.m1.1.1.3.2.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.3.2.3.1a" xref="S3.E12.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.3.2.3.4" xref="S3.E12.m1.1.1.3.2.3.4.cmml">S</mi></mrow></msub><mo id="S3.E12.m1.1.1.3.1" xref="S3.E12.m1.1.1.3.1.cmml">+</mo><msub id="S3.E12.m1.1.1.3.3" xref="S3.E12.m1.1.1.3.3.cmml"><mi id="S3.E12.m1.1.1.3.3.2" xref="S3.E12.m1.1.1.3.3.2.cmml">L</mi><mrow id="S3.E12.m1.1.1.3.3.3" xref="S3.E12.m1.1.1.3.3.3.cmml"><mi id="S3.E12.m1.1.1.3.3.3.2" xref="S3.E12.m1.1.1.3.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.3.3.3.1" xref="S3.E12.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.3.3.3.3" xref="S3.E12.m1.1.1.3.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E12.m1.1.1.3.3.3.1a" xref="S3.E12.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E12.m1.1.1.3.3.3.4" xref="S3.E12.m1.1.1.3.3.3.4.cmml">u</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E12.m1.1b"><apply id="S3.E12.m1.1.1.cmml" xref="S3.E12.m1.1.1"><eq id="S3.E12.m1.1.1.1.cmml" xref="S3.E12.m1.1.1.1"></eq><apply id="S3.E12.m1.1.1.2.cmml" xref="S3.E12.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E12.m1.1.1.2.1.cmml" xref="S3.E12.m1.1.1.2">subscript</csymbol><ci id="S3.E12.m1.1.1.2.2.cmml" xref="S3.E12.m1.1.1.2.2">𝐿</ci><apply id="S3.E12.m1.1.1.2.3.cmml" xref="S3.E12.m1.1.1.2.3"><times id="S3.E12.m1.1.1.2.3.1.cmml" xref="S3.E12.m1.1.1.2.3.1"></times><ci id="S3.E12.m1.1.1.2.3.2.cmml" xref="S3.E12.m1.1.1.2.3.2">𝐶</ci><ci id="S3.E12.m1.1.1.2.3.3.cmml" xref="S3.E12.m1.1.1.2.3.3">𝑜</ci><ci id="S3.E12.m1.1.1.2.3.4.cmml" xref="S3.E12.m1.1.1.2.3.4">𝑛</ci><ci id="S3.E12.m1.1.1.2.3.5.cmml" xref="S3.E12.m1.1.1.2.3.5">𝐶</ci><ci id="S3.E12.m1.1.1.2.3.6.cmml" xref="S3.E12.m1.1.1.2.3.6">𝑙</ci><ci id="S3.E12.m1.1.1.2.3.7.cmml" xref="S3.E12.m1.1.1.2.3.7">𝑢</ci></apply></apply><apply id="S3.E12.m1.1.1.3.cmml" xref="S3.E12.m1.1.1.3"><plus id="S3.E12.m1.1.1.3.1.cmml" xref="S3.E12.m1.1.1.3.1"></plus><apply id="S3.E12.m1.1.1.3.2.cmml" xref="S3.E12.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E12.m1.1.1.3.2.1.cmml" xref="S3.E12.m1.1.1.3.2">subscript</csymbol><ci id="S3.E12.m1.1.1.3.2.2.cmml" xref="S3.E12.m1.1.1.3.2.2">𝐿</ci><apply id="S3.E12.m1.1.1.3.2.3.cmml" xref="S3.E12.m1.1.1.3.2.3"><times id="S3.E12.m1.1.1.3.2.3.1.cmml" xref="S3.E12.m1.1.1.3.2.3.1"></times><ci id="S3.E12.m1.1.1.3.2.3.2.cmml" xref="S3.E12.m1.1.1.3.2.3.2">𝑀</ci><ci id="S3.E12.m1.1.1.3.2.3.3.cmml" xref="S3.E12.m1.1.1.3.2.3.3">𝑀</ci><ci id="S3.E12.m1.1.1.3.2.3.4.cmml" xref="S3.E12.m1.1.1.3.2.3.4">𝑆</ci></apply></apply><apply id="S3.E12.m1.1.1.3.3.cmml" xref="S3.E12.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E12.m1.1.1.3.3.1.cmml" xref="S3.E12.m1.1.1.3.3">subscript</csymbol><ci id="S3.E12.m1.1.1.3.3.2.cmml" xref="S3.E12.m1.1.1.3.3.2">𝐿</ci><apply id="S3.E12.m1.1.1.3.3.3.cmml" xref="S3.E12.m1.1.1.3.3.3"><times id="S3.E12.m1.1.1.3.3.3.1.cmml" xref="S3.E12.m1.1.1.3.3.3.1"></times><ci id="S3.E12.m1.1.1.3.3.3.2.cmml" xref="S3.E12.m1.1.1.3.3.3.2">𝐶</ci><ci id="S3.E12.m1.1.1.3.3.3.3.cmml" xref="S3.E12.m1.1.1.3.3.3.3">𝑙</ci><ci id="S3.E12.m1.1.1.3.3.3.4.cmml" xref="S3.E12.m1.1.1.3.3.3.4">𝑢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E12.m1.1c">L_{ConClu}=L_{MMS}+L_{Clu}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(12)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">ConGen</span>: In this model, we jointly learn two self-supervised tasks. First is multi-modal contrastive learning. The second is multi-modal reconstruction. The objective function that guides the learning process in ConGen model is as follows:
<br class="ltx_break"></p>
<table id="S3.E13" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E13.m1.1" class="ltx_Math" alttext="L_{ConGen}=L_{MMS}+L_{Rec}" display="block"><semantics id="S3.E13.m1.1a"><mrow id="S3.E13.m1.1.1" xref="S3.E13.m1.1.1.cmml"><msub id="S3.E13.m1.1.1.2" xref="S3.E13.m1.1.1.2.cmml"><mi id="S3.E13.m1.1.1.2.2" xref="S3.E13.m1.1.1.2.2.cmml">L</mi><mrow id="S3.E13.m1.1.1.2.3" xref="S3.E13.m1.1.1.2.3.cmml"><mi id="S3.E13.m1.1.1.2.3.2" xref="S3.E13.m1.1.1.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.2.3.1" xref="S3.E13.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.2.3.3" xref="S3.E13.m1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.2.3.1a" xref="S3.E13.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.2.3.4" xref="S3.E13.m1.1.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.2.3.1b" xref="S3.E13.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.2.3.5" xref="S3.E13.m1.1.1.2.3.5.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.2.3.1c" xref="S3.E13.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.2.3.6" xref="S3.E13.m1.1.1.2.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.2.3.1d" xref="S3.E13.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.2.3.7" xref="S3.E13.m1.1.1.2.3.7.cmml">n</mi></mrow></msub><mo id="S3.E13.m1.1.1.1" xref="S3.E13.m1.1.1.1.cmml">=</mo><mrow id="S3.E13.m1.1.1.3" xref="S3.E13.m1.1.1.3.cmml"><msub id="S3.E13.m1.1.1.3.2" xref="S3.E13.m1.1.1.3.2.cmml"><mi id="S3.E13.m1.1.1.3.2.2" xref="S3.E13.m1.1.1.3.2.2.cmml">L</mi><mrow id="S3.E13.m1.1.1.3.2.3" xref="S3.E13.m1.1.1.3.2.3.cmml"><mi id="S3.E13.m1.1.1.3.2.3.2" xref="S3.E13.m1.1.1.3.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.2.3.1" xref="S3.E13.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.2.3.3" xref="S3.E13.m1.1.1.3.2.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.2.3.1a" xref="S3.E13.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.2.3.4" xref="S3.E13.m1.1.1.3.2.3.4.cmml">S</mi></mrow></msub><mo id="S3.E13.m1.1.1.3.1" xref="S3.E13.m1.1.1.3.1.cmml">+</mo><msub id="S3.E13.m1.1.1.3.3" xref="S3.E13.m1.1.1.3.3.cmml"><mi id="S3.E13.m1.1.1.3.3.2" xref="S3.E13.m1.1.1.3.3.2.cmml">L</mi><mrow id="S3.E13.m1.1.1.3.3.3" xref="S3.E13.m1.1.1.3.3.3.cmml"><mi id="S3.E13.m1.1.1.3.3.3.2" xref="S3.E13.m1.1.1.3.3.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.3.1" xref="S3.E13.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.3.3" xref="S3.E13.m1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E13.m1.1.1.3.3.3.1a" xref="S3.E13.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E13.m1.1.1.3.3.3.4" xref="S3.E13.m1.1.1.3.3.3.4.cmml">c</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E13.m1.1b"><apply id="S3.E13.m1.1.1.cmml" xref="S3.E13.m1.1.1"><eq id="S3.E13.m1.1.1.1.cmml" xref="S3.E13.m1.1.1.1"></eq><apply id="S3.E13.m1.1.1.2.cmml" xref="S3.E13.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E13.m1.1.1.2.1.cmml" xref="S3.E13.m1.1.1.2">subscript</csymbol><ci id="S3.E13.m1.1.1.2.2.cmml" xref="S3.E13.m1.1.1.2.2">𝐿</ci><apply id="S3.E13.m1.1.1.2.3.cmml" xref="S3.E13.m1.1.1.2.3"><times id="S3.E13.m1.1.1.2.3.1.cmml" xref="S3.E13.m1.1.1.2.3.1"></times><ci id="S3.E13.m1.1.1.2.3.2.cmml" xref="S3.E13.m1.1.1.2.3.2">𝐶</ci><ci id="S3.E13.m1.1.1.2.3.3.cmml" xref="S3.E13.m1.1.1.2.3.3">𝑜</ci><ci id="S3.E13.m1.1.1.2.3.4.cmml" xref="S3.E13.m1.1.1.2.3.4">𝑛</ci><ci id="S3.E13.m1.1.1.2.3.5.cmml" xref="S3.E13.m1.1.1.2.3.5">𝐺</ci><ci id="S3.E13.m1.1.1.2.3.6.cmml" xref="S3.E13.m1.1.1.2.3.6">𝑒</ci><ci id="S3.E13.m1.1.1.2.3.7.cmml" xref="S3.E13.m1.1.1.2.3.7">𝑛</ci></apply></apply><apply id="S3.E13.m1.1.1.3.cmml" xref="S3.E13.m1.1.1.3"><plus id="S3.E13.m1.1.1.3.1.cmml" xref="S3.E13.m1.1.1.3.1"></plus><apply id="S3.E13.m1.1.1.3.2.cmml" xref="S3.E13.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E13.m1.1.1.3.2.1.cmml" xref="S3.E13.m1.1.1.3.2">subscript</csymbol><ci id="S3.E13.m1.1.1.3.2.2.cmml" xref="S3.E13.m1.1.1.3.2.2">𝐿</ci><apply id="S3.E13.m1.1.1.3.2.3.cmml" xref="S3.E13.m1.1.1.3.2.3"><times id="S3.E13.m1.1.1.3.2.3.1.cmml" xref="S3.E13.m1.1.1.3.2.3.1"></times><ci id="S3.E13.m1.1.1.3.2.3.2.cmml" xref="S3.E13.m1.1.1.3.2.3.2">𝑀</ci><ci id="S3.E13.m1.1.1.3.2.3.3.cmml" xref="S3.E13.m1.1.1.3.2.3.3">𝑀</ci><ci id="S3.E13.m1.1.1.3.2.3.4.cmml" xref="S3.E13.m1.1.1.3.2.3.4">𝑆</ci></apply></apply><apply id="S3.E13.m1.1.1.3.3.cmml" xref="S3.E13.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E13.m1.1.1.3.3.1.cmml" xref="S3.E13.m1.1.1.3.3">subscript</csymbol><ci id="S3.E13.m1.1.1.3.3.2.cmml" xref="S3.E13.m1.1.1.3.3.2">𝐿</ci><apply id="S3.E13.m1.1.1.3.3.3.cmml" xref="S3.E13.m1.1.1.3.3.3"><times id="S3.E13.m1.1.1.3.3.3.1.cmml" xref="S3.E13.m1.1.1.3.3.3.1"></times><ci id="S3.E13.m1.1.1.3.3.3.2.cmml" xref="S3.E13.m1.1.1.3.3.3.2">𝑅</ci><ci id="S3.E13.m1.1.1.3.3.3.3.cmml" xref="S3.E13.m1.1.1.3.3.3.3">𝑒</ci><ci id="S3.E13.m1.1.1.3.3.3.4.cmml" xref="S3.E13.m1.1.1.3.3.3.4">𝑐</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E13.m1.1c">L_{ConGen}=L_{MMS}+L_{Rec}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(13)</span></td>
</tr></tbody>
</table>
</div>
</li>
</ol>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Analysis</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we evaluate the previously detailed self-supervised methods on three facial expression recognition datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> . First, we present the
datasets used to evaluate our work. Then, we clarify the evaluation metrics (See the Appendix for implementation details). Finally, we analyze and discuss our results.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span title="" class="ltx_glossaryref ltx_font_bold">VoxCeleb2</span><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">.</span> We pretrain all methods on the large-scale face dataset <span title="" class="ltx_glossaryref">VoxCeleb2</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite>, which is <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">not</span> annotated for <span title="" class="ltx_glossaryref">FER</span>. <span title="" class="ltx_glossaryref">VoxCeleb2</span> consists of 145,000 videos of celebrities and also contains audio and subtitles. Since the videos are already focused on the face, we did not perform any cropping.
<br class="ltx_break">For downstream task, we evaluate the <span title="" class="ltx_glossaryref">CAER</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite>, <span title="" class="ltx_glossaryref">MELD</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> and <span title="" class="ltx_glossaryref">CMU-MOSEI</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> datasets. We employed a Pytorch MTCNN implementation<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://github.com/timesler/facenet-pytorch</span></span></span> to crop out the faces (see appendix for details).
<br class="ltx_break"><span title="" class="ltx_glossaryref ltx_font_bold">CAER</span><span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_bold">.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite> consists of 13,000 videos, containing audio, of the TV series Friends. We automatically inferred subtitles from the audio data. Multiple speakers can be visible within one scene. The annotation labels are the 7 basic Ekman expressions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>.
<br class="ltx_break"><span title="" class="ltx_glossaryref ltx_font_bold">MELD</span><span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_bold">.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> is a multi-modal dataset providing frames, audio, and subtitles and is also based on the TV series Friends, similarly to <span title="" class="ltx_glossaryref">CAER</span>. Its 13,000 videos feature single individuals only, cuts in a scene result in a different sample in this dataset. It provides 7 expression labels.
<br class="ltx_break"><span title="" class="ltx_glossaryref ltx_font_bold">CMU-MOSEI</span><span id="S4.SS1.p1.1.5" class="ltx_text ltx_font_bold">.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> contains 3,000 videos from YouTube in which people talk mostly directly into the camera. In contrast to <span title="" class="ltx_glossaryref">CAER</span> and <span title="" class="ltx_glossaryref">MELD</span>, <span title="" class="ltx_glossaryref">CMU-MOSEI</span> offers smooth multi-label annotations for 6 emotions on a Likert scale from 0 to 3. We discretize the labels by setting every value greater than 0 to 1.
<br class="ltx_break"><span id="S4.SS1.p1.1.6" class="ltx_text ltx_font_bold">Evaluation Metrics.</span> For the downstream task we measure <span title="" class="ltx_glossaryref">accuracy (Acc.)</span>, <span title="" class="ltx_glossaryref">F1 score (F1)</span>, precision and recall, all weighted by the class occurences. <span title="" class="ltx_glossaryref">CAER</span>, <span title="" class="ltx_glossaryref">MELD</span> and <span title="" class="ltx_glossaryref">CMU-MOSEI</span> are heavily imbalanced which makes weighting necessary.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evaluation Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In this section, we start with evaluating our model ConCluGen that we pretrained on <span title="" class="ltx_glossaryref">VoxCeleb2</span> dataset against FER benchmarks and baselines. Then we conduct a detailed study to analyze the efficiency of the features obtained from the self-supervised methods mentioned above.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Benchmarking Against SOTA</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">In this section we are comparing the multi-task multi-modal self-supervised learning model <span id="S4.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_bold">ConCluGen</span> that is pre-trained on VoxCeleb, to other multi-modal self-supervised benchmarks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>. Results in <a href="#S4.T1" title="In 4.2.1 Benchmarking Against SOTA ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a> show that ConCluGen model pretrained on VoxCeleb and finetuned on <span title="" class="ltx_glossaryref">CMU-MOSEI</span> dataset is outperforming CAE-LR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>, which is a self-supervised model that is trained on <span title="" class="ltx_glossaryref">CMU-MOSEI</span> dataset. It is also on par with <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Franceschini et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite> model performance, which uses more modalities (facial landmarks) than ConCluGen model for pretraining. It is worth mentioning that both CAE-LR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>, and <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Franceschini et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite> are pretrained on <span title="" class="ltx_glossaryref">CMU-MOSEI</span> and evaluate the downstream task on this dataset as well. However, ConCluGen model in <a href="#S4.T1" title="In 4.2.1 Benchmarking Against SOTA ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a> is pretrained on <span title="" class="ltx_glossaryref">VoxCeleb2</span>, and only finetuned on <span title="" class="ltx_glossaryref">CMU-MOSEI</span>.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">Moreover, our ConCluGen model, both with fintuning on the <span title="" class="ltx_glossaryref">CMU-MOSEI</span> dataset on <a href="#S4.T1" title="In 4.2.1 Benchmarking Against SOTA ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a> and without (<em id="S4.SS2.SSS1.p2.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS2.SSS1.p2.1.2" class="ltx_text"></span> simple linear evaluation), are outperforming SSE-FT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite>. SSE-FT is an independently pre-trained SSL model for vision, audio, and text modalities. They perform late fusion using an attention mechanism. Finally, they evaluate the model on <span title="" class="ltx_glossaryref">CMU-MOSEI</span> dataset without finetuning.</p>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.SSS1.p3.1" class="ltx_p">Finally, results in <a href="#S4.T1" title="In 4.2.1 Benchmarking Against SOTA ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a> show that ConCluGen model outperforms multiple fully supervised benchmarks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>]</cite> and is on the par with <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite> on <span title="" class="ltx_glossaryref">CMU-MOSEI</span>.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.2.1.1" class="ltx_tr">
<th id="S4.T1.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Method</th>
<th id="S4.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt">Year</th>
<td id="S4.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Mod.</td>
<td id="S4.T1.2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span title="" class="ltx_glossaryref">Acc.</span></td>
</tr>
<tr id="S4.T1.2.2.2" class="ltx_tr">
<th id="S4.T1.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">Self-Supervised Baselines</th>
</tr>
<tr id="S4.T1.2.3.3" class="ltx_tr">
<th id="S4.T1.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">SSE-FT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite>
</th>
<th id="S4.T1.2.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">2020</th>
<td id="S4.T1.2.3.3.3" class="ltx_td ltx_align_center ltx_border_t">VAT</td>
<td id="S4.T1.2.3.3.4" class="ltx_td ltx_align_center ltx_border_t">55.7</td>
</tr>
<tr id="S4.T1.2.4.4" class="ltx_tr">
<th id="S4.T1.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">CAE-LR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>
</th>
<th id="S4.T1.2.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2021</th>
<td id="S4.T1.2.4.4.3" class="ltx_td ltx_align_center">VAT</td>
<td id="S4.T1.2.4.4.4" class="ltx_td ltx_align_center">61.03</td>
</tr>
<tr id="S4.T1.2.5.5" class="ltx_tr">
<th id="S4.T1.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Franceschini et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>
</th>
<th id="S4.T1.2.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2022</th>
<td id="S4.T1.2.5.5.3" class="ltx_td ltx_align_center">VATK</td>
<td id="S4.T1.2.5.5.4" class="ltx_td ltx_align_center">66.70</td>
</tr>
<tr id="S4.T1.2.6.6" class="ltx_tr">
<th id="S4.T1.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConCluGen (ours)</th>
<th id="S4.T1.2.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2024</th>
<td id="S4.T1.2.6.6.3" class="ltx_td ltx_align_center">VAT</td>
<td id="S4.T1.2.6.6.4" class="ltx_td ltx_align_center">66.48</td>
</tr>
<tr id="S4.T1.2.7.7" class="ltx_tr">
<th id="S4.T1.2.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4">Fully Supervised Baselines</th>
</tr>
<tr id="S4.T1.2.8.8" class="ltx_tr">
<th id="S4.T1.2.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">CMIB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite>
</th>
<th id="S4.T1.2.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">2022</th>
<td id="S4.T1.2.8.8.3" class="ltx_td ltx_align_center ltx_border_t">VAT</td>
<td id="S4.T1.2.8.8.4" class="ltx_td ltx_align_center ltx_border_t">48.2</td>
</tr>
<tr id="S4.T1.2.9.9" class="ltx_tr">
<th id="S4.T1.2.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Huynh et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite>
</th>
<th id="S4.T1.2.9.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2021</th>
<td id="S4.T1.2.9.9.3" class="ltx_td ltx_align_center">VAT</td>
<td id="S4.T1.2.9.9.4" class="ltx_td ltx_align_center">57.70</td>
</tr>
<tr id="S4.T1.2.10.10" class="ltx_tr">
<th id="S4.T1.2.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Graph-MFN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>
</th>
<th id="S4.T1.2.10.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2018</th>
<td id="S4.T1.2.10.10.3" class="ltx_td ltx_align_center">VAT</td>
<td id="S4.T1.2.10.10.4" class="ltx_td ltx_align_center">62.35</td>
</tr>
<tr id="S4.T1.2.11.11" class="ltx_tr">
<th id="S4.T1.2.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">CIA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>
</th>
<th id="S4.T1.2.11.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2019</th>
<td id="S4.T1.2.11.11.3" class="ltx_td ltx_align_center">VAT</td>
<td id="S4.T1.2.11.11.4" class="ltx_td ltx_align_center">62.88</td>
</tr>
<tr id="S4.T1.2.12.12" class="ltx_tr">
<th id="S4.T1.2.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">MESM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>]</cite>
</th>
<th id="S4.T1.2.12.12.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2021</th>
<td id="S4.T1.2.12.12.3" class="ltx_td ltx_align_center">VAT</td>
<td id="S4.T1.2.12.12.4" class="ltx_td ltx_align_center">66.80</td>
</tr>
<tr id="S4.T1.2.13.13" class="ltx_tr">
<th id="S4.T1.2.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Khare et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite>
</th>
<th id="S4.T1.2.13.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2021</th>
<td id="S4.T1.2.13.13.3" class="ltx_td ltx_align_center">VAT</td>
<td id="S4.T1.2.13.13.4" class="ltx_td ltx_align_center">66.90</td>
</tr>
<tr id="S4.T1.2.14.14" class="ltx_tr">
<th id="S4.T1.2.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Wen et al.</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>]</cite>
</th>
<th id="S4.T1.2.14.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">2021</th>
<td id="S4.T1.2.14.14.3" class="ltx_td ltx_align_center">VAT</td>
<td id="S4.T1.2.14.14.4" class="ltx_td ltx_align_center">82.08</td>
</tr>
<tr id="S4.T1.2.15.15" class="ltx_tr">
<th id="S4.T1.2.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">
<cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">Shenoy and Sardana</span></a></cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>
</th>
<th id="S4.T1.2.15.15.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">2020</th>
<td id="S4.T1.2.15.15.3" class="ltx_td ltx_align_center ltx_border_bb">VAT</td>
<td id="S4.T1.2.15.15.4" class="ltx_td ltx_align_center ltx_border_bb">82.77</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.8.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.9.2" class="ltx_text" style="font-size:90%;">Benchmark evaluations of our model against SOTA methods for CMU-MOSEI dataset. Modalities (<span id="S4.T1.9.2.1" class="ltx_text ltx_font_italic">Mod.</span>) are <span id="S4.T1.9.2.2" class="ltx_text ltx_font_bold">V</span>ideo, <span id="S4.T1.9.2.3" class="ltx_text ltx_font_bold">A</span>udio, <span id="S4.T1.9.2.4" class="ltx_text ltx_font_bold">T</span>ext, (facial) <span id="S4.T1.9.2.5" class="ltx_text ltx_font_bold">K</span>eypoints.</span></figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:233.3pt;height:61.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.6pt,5.4pt) scale(0.85,0.85) ;">
<table id="S4.T2.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.2.1.1.1" class="ltx_tr">
<th id="S4.T2.2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Method</th>
<th id="S4.T2.2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">CMU-MOSEI</th>
<th id="S4.T2.2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">CAER</th>
<th id="S4.T2.2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">MELD</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.2.1.2.1" class="ltx_tr">
<th id="S4.T2.2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Supervised baseline</th>
<td id="S4.T2.2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">57.88</td>
<td id="S4.T2.2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">34.43</td>
<td id="S4.T2.2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">55.97</td>
</tr>
<tr id="S4.T2.2.1.3.2" class="ltx_tr">
<th id="S4.T2.2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConCluGen <span id="S4.T2.2.1.3.2.1.1" class="ltx_text" style="font-size:90%;">(linear eval.)</span>
</th>
<td id="S4.T2.2.1.3.2.2" class="ltx_td ltx_align_center">60.0</td>
<td id="S4.T2.2.1.3.2.3" class="ltx_td ltx_align_center">37.5</td>
<td id="S4.T2.2.1.3.2.4" class="ltx_td ltx_align_center">56.6</td>
</tr>
<tr id="S4.T2.2.1.4.3" class="ltx_tr">
<th id="S4.T2.2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">ConCluGen <span id="S4.T2.2.1.4.3.1.1" class="ltx_text" style="font-size:90%;">(finetuned)</span>
</th>
<td id="S4.T2.2.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb">66.48</td>
<td id="S4.T2.2.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb">50.75</td>
<td id="S4.T2.2.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb">60.03</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.4.2" class="ltx_text" style="font-size:90%;">Comparison of the proposed method and baselines.</span></figcaption>
</figure>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Supervised Baselines</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">The supervised baseline shown in <a href="#S4.T2" title="In 4.2.1 Benchmarking Against SOTA ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2</span></a> consists of the same multi-model architecture as the ConCluGen model, but with a fully-supervised objective function on the target dataset. Results in <a href="#S4.T2" title="In 4.2.1 Benchmarking Against SOTA ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2</span></a> show that both the linear evaluation and the finetuning approach outperform the fully supervised baseline for the three datasets. That highlights the efficiency of the multi-modal self-supervised learning method.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.2.1.1" class="ltx_tr">
<th id="S4.T3.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Method</th>
<td id="S4.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span title="" class="ltx_glossaryref">Acc.</span></td>
<td id="S4.T3.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">F1</td>
<td id="S4.T3.2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Prec.</td>
<td id="S4.T3.2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">Recall</td>
</tr>
<tr id="S4.T3.2.2.2" class="ltx_tr">
<th id="S4.T3.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ConCluGen</th>
<td id="S4.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">60.4</td>
<td id="S4.T3.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">49.6</td>
<td id="S4.T3.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">41.7</td>
<td id="S4.T3.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">70.3</td>
</tr>
<tr id="S4.T3.2.3.3" class="ltx_tr">
<th id="S4.T3.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConClu</th>
<td id="S4.T3.2.3.3.2" class="ltx_td ltx_align_center">57.4</td>
<td id="S4.T3.2.3.3.3" class="ltx_td ltx_align_center">43.9</td>
<td id="S4.T3.2.3.3.4" class="ltx_td ltx_align_center">44.9</td>
<td id="S4.T3.2.3.3.5" class="ltx_td ltx_align_center">60.5</td>
</tr>
<tr id="S4.T3.2.4.4" class="ltx_tr">
<th id="S4.T3.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConGen</th>
<td id="S4.T3.2.4.4.2" class="ltx_td ltx_align_center">53.3</td>
<td id="S4.T3.2.4.4.3" class="ltx_td ltx_align_center">39.2</td>
<td id="S4.T3.2.4.4.4" class="ltx_td ltx_align_center">45.8</td>
<td id="S4.T3.2.4.4.5" class="ltx_td ltx_align_center">58.4</td>
</tr>
<tr id="S4.T3.2.5.5" class="ltx_tr">
<th id="S4.T3.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Multi-Cont</th>
<td id="S4.T3.2.5.5.2" class="ltx_td ltx_align_center">56.4</td>
<td id="S4.T3.2.5.5.3" class="ltx_td ltx_align_center">44.4</td>
<td id="S4.T3.2.5.5.4" class="ltx_td ltx_align_center">43.9</td>
<td id="S4.T3.2.5.5.5" class="ltx_td ltx_align_center">63.1</td>
</tr>
<tr id="S4.T3.2.6.6" class="ltx_tr">
<th id="S4.T3.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Instance-Cont</th>
<td id="S4.T3.2.6.6.2" class="ltx_td ltx_align_center">41.2</td>
<td id="S4.T3.2.6.6.3" class="ltx_td ltx_align_center">43.3</td>
<td id="S4.T3.2.6.6.4" class="ltx_td ltx_align_center">35.1</td>
<td id="S4.T3.2.6.6.5" class="ltx_td ltx_align_center">77.1</td>
</tr>
<tr id="S4.T3.2.7.7" class="ltx_tr">
<th id="S4.T3.2.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Generative</th>
<td id="S4.T3.2.7.7.2" class="ltx_td ltx_align_center ltx_border_t">46.9</td>
<td id="S4.T3.2.7.7.3" class="ltx_td ltx_align_center ltx_border_t">49.2</td>
<td id="S4.T3.2.7.7.4" class="ltx_td ltx_align_center ltx_border_t">38</td>
<td id="S4.T3.2.7.7.5" class="ltx_td ltx_align_center ltx_border_t">87.8</td>
</tr>
<tr id="S4.T3.2.8.8" class="ltx_tr">
<th id="S4.T3.2.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ConCluGen/(vision)</th>
<td id="S4.T3.2.8.8.2" class="ltx_td ltx_align_center ltx_border_t">52.4</td>
<td id="S4.T3.2.8.8.3" class="ltx_td ltx_align_center ltx_border_t">40.4</td>
<td id="S4.T3.2.8.8.4" class="ltx_td ltx_align_center ltx_border_t">38.2</td>
<td id="S4.T3.2.8.8.5" class="ltx_td ltx_align_center ltx_border_t">57.3</td>
</tr>
<tr id="S4.T3.2.9.9" class="ltx_tr">
<th id="S4.T3.2.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Multi-Cont <span id="S4.T3.2.9.9.1.1" class="ltx_text" style="font-size:50%;">Wout/text</span>
</th>
<td id="S4.T3.2.9.9.2" class="ltx_td ltx_align_center">42.5</td>
<td id="S4.T3.2.9.9.3" class="ltx_td ltx_align_center">27.3</td>
<td id="S4.T3.2.9.9.4" class="ltx_td ltx_align_center">35.3</td>
<td id="S4.T3.2.9.9.5" class="ltx_td ltx_align_center">53.1</td>
</tr>
<tr id="S4.T3.2.10.10" class="ltx_tr">
<th id="S4.T3.2.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Multi-Cont <span id="S4.T3.2.10.10.1.1" class="ltx_text" style="font-size:50%;">Wout/audio</span>
</th>
<td id="S4.T3.2.10.10.2" class="ltx_td ltx_align_center ltx_border_bb">53.4</td>
<td id="S4.T3.2.10.10.3" class="ltx_td ltx_align_center ltx_border_bb">47.4</td>
<td id="S4.T3.2.10.10.4" class="ltx_td ltx_align_center ltx_border_bb">41.3</td>
<td id="S4.T3.2.10.10.5" class="ltx_td ltx_align_center ltx_border_bb">75.9</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.3.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.4.2" class="ltx_text" style="font-size:90%;">Results of different combinations of self-supervised methods on CMU-MOSEI dataset. All metrics are weighted.</span></figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.2.1.1" class="ltx_tr">
<th id="S4.T4.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Method</th>
<td id="S4.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span title="" class="ltx_glossaryref">Acc.</span></td>
<td id="S4.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">F1</td>
<td id="S4.T4.2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Prec.</td>
<td id="S4.T4.2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">Recall</td>
</tr>
<tr id="S4.T4.2.2.2" class="ltx_tr">
<th id="S4.T4.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ConCluGen</th>
<td id="S4.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">56.6</td>
<td id="S4.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">53.1</td>
<td id="S4.T4.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">58.5</td>
<td id="S4.T4.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">56.6</td>
</tr>
<tr id="S4.T4.2.3.3" class="ltx_tr">
<th id="S4.T4.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConClu</th>
<td id="S4.T4.2.3.3.2" class="ltx_td ltx_align_center">58</td>
<td id="S4.T4.2.3.3.3" class="ltx_td ltx_align_center">54.7</td>
<td id="S4.T4.2.3.3.4" class="ltx_td ltx_align_center">57.6</td>
<td id="S4.T4.2.3.3.5" class="ltx_td ltx_align_center">58</td>
</tr>
<tr id="S4.T4.2.4.4" class="ltx_tr">
<th id="S4.T4.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConGen</th>
<td id="S4.T4.2.4.4.2" class="ltx_td ltx_align_center">57.4</td>
<td id="S4.T4.2.4.4.3" class="ltx_td ltx_align_center">52.7</td>
<td id="S4.T4.2.4.4.4" class="ltx_td ltx_align_center">57.1</td>
<td id="S4.T4.2.4.4.5" class="ltx_td ltx_align_center">57.4</td>
</tr>
<tr id="S4.T4.2.5.5" class="ltx_tr">
<th id="S4.T4.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Multi-Cont</th>
<td id="S4.T4.2.5.5.2" class="ltx_td ltx_align_center">57.2</td>
<td id="S4.T4.2.5.5.3" class="ltx_td ltx_align_center">54.1</td>
<td id="S4.T4.2.5.5.4" class="ltx_td ltx_align_center">57.6</td>
<td id="S4.T4.2.5.5.5" class="ltx_td ltx_align_center">57.2</td>
</tr>
<tr id="S4.T4.2.6.6" class="ltx_tr">
<th id="S4.T4.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Instance-Cont</th>
<td id="S4.T4.2.6.6.2" class="ltx_td ltx_align_center">46.3</td>
<td id="S4.T4.2.6.6.3" class="ltx_td ltx_align_center">32.1</td>
<td id="S4.T4.2.6.6.4" class="ltx_td ltx_align_center">25.3</td>
<td id="S4.T4.2.6.6.5" class="ltx_td ltx_align_center">46.3</td>
</tr>
<tr id="S4.T4.2.7.7" class="ltx_tr">
<th id="S4.T4.2.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Generative</th>
<td id="S4.T4.2.7.7.2" class="ltx_td ltx_align_center ltx_border_t">52.1</td>
<td id="S4.T4.2.7.7.3" class="ltx_td ltx_align_center ltx_border_t">40.9</td>
<td id="S4.T4.2.7.7.4" class="ltx_td ltx_align_center ltx_border_t">37.5</td>
<td id="S4.T4.2.7.7.5" class="ltx_td ltx_align_center ltx_border_t">52.1</td>
</tr>
<tr id="S4.T4.2.8.8" class="ltx_tr">
<th id="S4.T4.2.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ConCluGen/(vision)</th>
<td id="S4.T4.2.8.8.2" class="ltx_td ltx_align_center ltx_border_t">31.0</td>
<td id="S4.T4.2.8.8.3" class="ltx_td ltx_align_center ltx_border_t">26.3</td>
<td id="S4.T4.2.8.8.4" class="ltx_td ltx_align_center ltx_border_t">28.7</td>
<td id="S4.T4.2.8.8.5" class="ltx_td ltx_align_center ltx_border_t">31</td>
</tr>
<tr id="S4.T4.2.9.9" class="ltx_tr">
<th id="S4.T4.2.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Multi-Cont <span id="S4.T4.2.9.9.1.1" class="ltx_text" style="font-size:50%;">Wout/text</span>
</th>
<td id="S4.T4.2.9.9.2" class="ltx_td ltx_align_center">48.1</td>
<td id="S4.T4.2.9.9.3" class="ltx_td ltx_align_center">31.4</td>
<td id="S4.T4.2.9.9.4" class="ltx_td ltx_align_center">24.3</td>
<td id="S4.T4.2.9.9.5" class="ltx_td ltx_align_center">48.1</td>
</tr>
<tr id="S4.T4.2.10.10" class="ltx_tr">
<th id="S4.T4.2.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Multi-Cont <span id="S4.T4.2.10.10.1.1" class="ltx_text" style="font-size:50%;">Wout/audio</span>
</th>
<td id="S4.T4.2.10.10.2" class="ltx_td ltx_align_center ltx_border_bb">54.3</td>
<td id="S4.T4.2.10.10.3" class="ltx_td ltx_align_center ltx_border_bb">46.9</td>
<td id="S4.T4.2.10.10.4" class="ltx_td ltx_align_center ltx_border_bb">58.2</td>
<td id="S4.T4.2.10.10.5" class="ltx_td ltx_align_center ltx_border_bb">54.3</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.4.2" class="ltx_text" style="font-size:90%;">Results of different combinations of self-supervised methods on MELD dataset. All metrics are weighted.</span></figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.2.1.1" class="ltx_tr">
<th id="S4.T5.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Method</th>
<td id="S4.T5.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span title="" class="ltx_glossaryref">Acc.</span></td>
<td id="S4.T5.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">F1</td>
<td id="S4.T5.2.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">Prec.</td>
<td id="S4.T5.2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">Recall</td>
</tr>
<tr id="S4.T5.2.2.2" class="ltx_tr">
<th id="S4.T5.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ConCluGen</th>
<td id="S4.T5.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">37.5</td>
<td id="S4.T5.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">26.1</td>
<td id="S4.T5.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">34.8</td>
<td id="S4.T5.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">37.5</td>
</tr>
<tr id="S4.T5.2.3.3" class="ltx_tr">
<th id="S4.T5.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConClu</th>
<td id="S4.T5.2.3.3.2" class="ltx_td ltx_align_center">36.6</td>
<td id="S4.T5.2.3.3.3" class="ltx_td ltx_align_center">24</td>
<td id="S4.T5.2.3.3.4" class="ltx_td ltx_align_center">29.4</td>
<td id="S4.T5.2.3.3.5" class="ltx_td ltx_align_center">36.6</td>
</tr>
<tr id="S4.T5.2.4.4" class="ltx_tr">
<th id="S4.T5.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">ConGen</th>
<td id="S4.T5.2.4.4.2" class="ltx_td ltx_align_center">35.8</td>
<td id="S4.T5.2.4.4.3" class="ltx_td ltx_align_center">22.5</td>
<td id="S4.T5.2.4.4.4" class="ltx_td ltx_align_center">32.3</td>
<td id="S4.T5.2.4.4.5" class="ltx_td ltx_align_center">35.8</td>
</tr>
<tr id="S4.T5.2.5.5" class="ltx_tr">
<th id="S4.T5.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Multi-Cont</th>
<td id="S4.T5.2.5.5.2" class="ltx_td ltx_align_center">34.6</td>
<td id="S4.T5.2.5.5.3" class="ltx_td ltx_align_center">22.3</td>
<td id="S4.T5.2.5.5.4" class="ltx_td ltx_align_center">30.7</td>
<td id="S4.T5.2.5.5.5" class="ltx_td ltx_align_center">34.6</td>
</tr>
<tr id="S4.T5.2.6.6" class="ltx_tr">
<th id="S4.T5.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Instance-Cont</th>
<td id="S4.T5.2.6.6.2" class="ltx_td ltx_align_center">34.6</td>
<td id="S4.T5.2.6.6.3" class="ltx_td ltx_align_center">17.8</td>
<td id="S4.T5.2.6.6.4" class="ltx_td ltx_align_center">12</td>
<td id="S4.T5.2.6.6.5" class="ltx_td ltx_align_center">34.6</td>
</tr>
<tr id="S4.T5.2.7.7" class="ltx_tr">
<th id="S4.T5.2.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Generative</th>
<td id="S4.T5.2.7.7.2" class="ltx_td ltx_align_center ltx_border_t">37.3</td>
<td id="S4.T5.2.7.7.3" class="ltx_td ltx_align_center ltx_border_t">23.9</td>
<td id="S4.T5.2.7.7.4" class="ltx_td ltx_align_center ltx_border_t">45.3</td>
<td id="S4.T5.2.7.7.5" class="ltx_td ltx_align_center ltx_border_t">37.3</td>
</tr>
<tr id="S4.T5.2.8.8" class="ltx_tr">
<th id="S4.T5.2.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ConCluGen/(vision)</th>
<td id="S4.T5.2.8.8.2" class="ltx_td ltx_align_center ltx_border_t">36.1</td>
<td id="S4.T5.2.8.8.3" class="ltx_td ltx_align_center ltx_border_t">21.9</td>
<td id="S4.T5.2.8.8.4" class="ltx_td ltx_align_center ltx_border_t">32.5</td>
<td id="S4.T5.2.8.8.5" class="ltx_td ltx_align_center ltx_border_t">36.1</td>
</tr>
<tr id="S4.T5.2.9.9" class="ltx_tr">
<th id="S4.T5.2.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Multi-Cont <span id="S4.T5.2.9.9.1.1" class="ltx_text" style="font-size:50%;">Wout/text</span>
</th>
<td id="S4.T5.2.9.9.2" class="ltx_td ltx_align_center">23.2</td>
<td id="S4.T5.2.9.9.3" class="ltx_td ltx_align_center">16.8</td>
<td id="S4.T5.2.9.9.4" class="ltx_td ltx_align_center">13.9</td>
<td id="S4.T5.2.9.9.5" class="ltx_td ltx_align_center">23.2</td>
</tr>
<tr id="S4.T5.2.10.10" class="ltx_tr">
<th id="S4.T5.2.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Multi-Cont <span id="S4.T5.2.10.10.1.1" class="ltx_text" style="font-size:50%;">Wout/audio</span>
</th>
<td id="S4.T5.2.10.10.2" class="ltx_td ltx_align_center ltx_border_bb">35.1</td>
<td id="S4.T5.2.10.10.3" class="ltx_td ltx_align_center ltx_border_bb">19.3</td>
<td id="S4.T5.2.10.10.4" class="ltx_td ltx_align_center ltx_border_bb">24</td>
<td id="S4.T5.2.10.10.5" class="ltx_td ltx_align_center ltx_border_bb">35.1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.4.2" class="ltx_text" style="font-size:90%;">Results of different combinations of self-supervised methods on CAER dataset. All metrics are weighted.</span></figcaption>
</figure>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Evaluation of Self-Supervised Tasks</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">We start with a comparison between individual self-supervised tasks, then we evaluate different permutations of combining different self-supervised tasks, all for facial expression recognition. 
<br class="ltx_break"></p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.1" class="ltx_p"><span id="S4.SS2.SSS3.p2.1.1" class="ltx_text ltx_font_bold">Instance-level contrastive learning vs. multi-modal contrastive learning.
<br class="ltx_break"></span>Results in <a href="#S4.T3" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S4.T4" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, and <a href="#S4.T5" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a> show that the multi-modal contrastive learning method <span id="S4.SS2.SSS3.p2.1.2" class="ltx_text ltx_font_bold">Multi-Cont</span> ( <a href="#S3.SS3" title="3.3 Multi-Modal Contrastive Learning ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.3</span></a>) outperforms the instance level contrastive learning <span id="S4.SS2.SSS3.p2.1.3" class="ltx_text ltx_font_bold">Instance-Cont</span> (<a href="#S3.SS2" title="3.2 Instance-Level (Visual Only) Contrastive Learning ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>).
Thus the self-supervised multi-modal contrastive method can learn better representations than the instance-level contrastive method (uni-modal). The confusion matrices for the <span title="" class="ltx_glossaryref">MELD</span> dataset in <a href="#S4.F2" title="In 4.2.3 Evaluation of Self-Supervised Tasks ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a> indicate the quality of the classification performance of Multi-Cont model <a href="#S4.F2.sf3" title="In Figure 2 ‣ 4.2.3 Evaluation of Self-Supervised Tasks ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2(c)</span></a> across different emotion classes over Instance-Cont model <a href="#S4.F2.sf4" title="In Figure 2 ‣ 4.2.3 Evaluation of Self-Supervised Tasks ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2(d)</span></a>. See the Appendix for the confusion matrices of the <span title="" class="ltx_glossaryref">CAER</span> dataset.
Moreover, we conduct an experiment to evaluate which modality is more informative to be learned along with the visual modality. Results in <a href="#S4.T3" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S4.T4" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, and <a href="#S4.T5" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a> consistently show that the model can benefit more from text modality.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.10904/assets/x2.png" id="S4.F2.sf1.g1" class="ltx_graphics ltx_img_portrait" width="528" height="683" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">ConCluGen Model.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.10904/assets/x3.png" id="S4.F2.sf2.g1" class="ltx_graphics ltx_img_portrait" width="528" height="683" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F2.sf2.3.2" class="ltx_text" style="font-size:90%;">ConClu Model.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.10904/assets/x4.png" id="S4.F2.sf3.g1" class="ltx_graphics ltx_img_portrait" width="528" height="683" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F2.sf3.3.2" class="ltx_text" style="font-size:90%;">Multi-Cont Model.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F2.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.10904/assets/x5.png" id="S4.F2.sf4.g1" class="ltx_graphics ltx_img_portrait" width="528" height="683" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F2.sf4.3.2" class="ltx_text" style="font-size:90%;">Instance-Cont Model.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;">Confusion metrics for MELD dataset over different self-supervised models.</span></figcaption>
</figure>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<p id="S4.SS2.SSS3.p3.1" class="ltx_p"><span id="S4.SS2.SSS3.p3.1.1" class="ltx_text ltx_font_bold">Contrastive learning with clustering.
<br class="ltx_break"></span>Results on <a href="#S4.T4" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, and <a href="#S4.T5" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a> show that learning online multi-modal clustering task along with multi-modal contrastive task during the pre-training phase, such as in <span id="S4.SS2.SSS3.p3.1.2" class="ltx_text ltx_font_bold">ConClu</span> model (<a href="#S3.SS5" title="3.5 Multi-Modal Contrastive Learning with Clustering ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.5</span></a>), improves the results on the downstream task of <span title="" class="ltx_glossaryref">FER</span> for both <span title="" class="ltx_glossaryref">MELD</span> and <span title="" class="ltx_glossaryref">CAER</span>. <a href="#S4.T3" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a> shows that the results are comparable between both models on <span title="" class="ltx_glossaryref">CMU-MOSEI</span> dataset. The hypothesis behind such a model is that by supporting the contrastive method with distance-based clustering, we can better capture semantic structures from the data. <a href="#S4.F2.sf2" title="In Figure 2 ‣ 4.2.3 Evaluation of Self-Supervised Tasks ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2(b)</span></a> shows how the quality of the classification in ConClu model enhanced over emotion classes on <span title="" class="ltx_glossaryref">MELD</span> dataset over Multi-Cont model (<a href="#S4.F2.sf3" title="In Figure 2 ‣ 4.2.3 Evaluation of Self-Supervised Tasks ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2(c)</span></a>).
<br class="ltx_break"></p>
</div>
<div id="S4.SS2.SSS3.p4" class="ltx_para">
<p id="S4.SS2.SSS3.p4.1" class="ltx_p"><span id="S4.SS2.SSS3.p4.1.1" class="ltx_text ltx_font_bold">Generative self-supervised learning vs. contrastive self-supervised learning.
<br class="ltx_break"></span>To answer this question we compare the generative multi-modal model <span id="S4.SS2.SSS3.p4.1.2" class="ltx_text ltx_font_bold">Generative</span> (<a href="#S3.SS4" title="3.4 Generative Self-Supervised Learning ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.4</span></a>) that reconstructs each modality representation separately, to both multi-modal contrastive learning method <span id="S4.SS2.SSS3.p4.1.3" class="ltx_text ltx_font_bold">Multi-Cont</span> and instance-level contrastive <span id="S4.SS2.SSS3.p4.1.4" class="ltx_text ltx_font_bold">Instance-Cont</span>. Results on <span title="" class="ltx_glossaryref">CMU-MOSEI</span> and <span title="" class="ltx_glossaryref">CAER</span> datasets in <a href="#S4.T3" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S4.T5" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a> show that the generative loss is a robust objective function as a proxy task for <span title="" class="ltx_glossaryref">FER</span>. On the other hand, results for <span title="" class="ltx_glossaryref">MELD</span> dataset in <a href="#S4.T4" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a> show that the <span id="S4.SS2.SSS3.p4.1.5" class="ltx_text ltx_font_bold">Generative</span> model is outperforming <span id="S4.SS2.SSS3.p4.1.6" class="ltx_text ltx_font_bold">Instance-Cont</span> but not the <span id="S4.SS2.SSS3.p4.1.7" class="ltx_text ltx_font_bold">Multi-Cont</span> model.</p>
</div>
<div id="S4.SS2.SSS3.p5" class="ltx_para">
<p id="S4.SS2.SSS3.p5.1" class="ltx_p"><span id="S4.SS2.SSS3.p5.1.1" class="ltx_text ltx_font_bold">Multi-task multi-modal self-supervised learning.
<br class="ltx_break"></span>In the previous section, results showed how powerful the generative objective function is as a proxy task compared to contrastive objective functions on some datasets. On the other hand, results in <a href="#S4.T3" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S4.T4" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, <a href="#S4.T5" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a>, show that for all datasets, minimizing a reconstruction loss along with a multi-modal contrastive loss <span id="S4.SS2.SSS3.p5.1.2" class="ltx_text ltx_font_bold">ConGen</span> leads to models that underperform the model that we pre-trained using only the multi-modal contrastive objective function. 
<br class="ltx_break">Finally, we evaluate the model that learns using the multi-task multi-modal self-supervised objective function <span id="S4.SS2.SSS3.p5.1.3" class="ltx_text ltx_font_bold">ConCluGen</span> <a href="#S3.SS6" title="3.6 Multi-Task Self-Supervised Learning ‣ 3 Methodology ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">3.6</span></a>. Results in <a href="#S4.T3" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, and <a href="#S4.T5" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a>, show that for all datasets except for <span title="" class="ltx_glossaryref">MELD</span> <a href="#S4.T4" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, ConCluGen model is outperforming all other models. 
<br class="ltx_break"></p>
</div>
<div id="S4.SS2.SSS3.p6" class="ltx_para">
<p id="S4.SS2.SSS3.p6.1" class="ltx_p"><span id="S4.SS2.SSS3.p6.1.1" class="ltx_text ltx_font_bold">How informative is the individual modality representation when learning the multi-modal multi-task self-supervised model ConCluGen?
<br class="ltx_break"></span>To answer this question we evaluate the results using only the visual representation from the multi-modal multi-task model <span id="S4.SS2.SSS3.p6.1.2" class="ltx_text ltx_font_bold">ConCluGen</span> to the results of <span id="S4.SS2.SSS3.p6.1.3" class="ltx_text ltx_font_bold">Instance-Cont</span> model that only utilizes the vision modality during pretraining. <a href="#S4.T5" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a>, and <a href="#S4.T3" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, show that <span id="S4.SS2.SSS3.p6.1.4" class="ltx_text ltx_font_bold">ConCluGen/(vision)</span> is outperforming the model that we pre-trained using the instance level contrastive method. On the other hand, results in <a href="#S4.T4" title="In 4.2.2 Supervised Baselines ‣ 4.2 Evaluation Results ‣ 4 Experiments and Analysis ‣ Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a> show that we need to utilize the three modalities that are learned by <span id="S4.SS2.SSS3.p6.1.5" class="ltx_text ltx_font_bold">ConCluGen</span> model, to outperform the <span id="S4.SS2.SSS3.p6.1.6" class="ltx_text ltx_font_bold">Instance-Cont</span> model.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we employed a multi-task multi-modal self-supervised method for facial expression recognition on three different in-the-wild datasets. Our <span id="S5.p1.1.1" class="ltx_text ltx_font_bold">ConCluGen</span> model outperforms several multi-modal self-supervised as well as supervised baseline models. We conduct an extensive experimental study to evaluate the performance of pre-trained models with multiple self-supervised tasks.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">First, we assess the gains obtained by including multiple data modalities in the self-supervised algorithm, by evaluating the performance of the model pre-trained with a multi-modal contrastive method against a model pre-trained using a contrastive method with the visual modality only, following instance-based state-of-the-art self-supervised algorithms. We found that the multi-modal contrastive method learns more informative representations than the instance-based contrastive (uni-modal method), <em id="S5.p2.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S5.p2.1.2" class="ltx_text"></span> the resulting model from the multi-modal method outperforms the uni-modal model on the facial expression recognition task. In another related experiment, we discarded the other data modalities from the multi-modal model, and only kept the visual modality part of the model. In this experiment, we found that even only the visual part of the multi-modal still outperforms the instance-based uni-modal model which was trained on the visual modality only. These experiments illustrate the gains obtained when including other data modalities in the self-supervised pre-training stage; the resulting features contain more information about the data - facial expressions in our case. In addition, another noteworthy observation here is that the text modality seems to enrich the resulting representations with more information about facial expressions than the audio modality.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Moreover, in another set of experiments, we evaluate the performance gains when pretraining a model with a self-supervised task that combines both a multi-modal contrastive loss and a multi-modal clustering loss simultaneously. Here, we found that combining a contrastive loss with a distance-based clustering loss encourages the model to learn more semantic structure from the data. This effect is demonstrated clearly in the improved downstream <span title="" class="ltx_glossaryref">FER</span> performance. We believe that employing a clustering loss in combination with a contrastive loss mitigates the issue of class collision that contrastive learning methods alone could encounter <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>]</cite>, as explained earlier.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">Finally, it is noteworthy that performing the self-supervised pre-training phase in a multi-task fashion captures more semantically meaningful representations than performing each task alone. In other words, for a challenging downstream task, such as facial expression recognition in the wild, the representations learned by each individual self-supervised task alone do not seem sufficient, as demonstrated by the superior performance of <span id="S5.p4.1.1" class="ltx_text ltx_font_bold">ConCluGen</span> against all other self-supervised models.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">In future work, we would like to expand the multi-task multi-modal method for more modalities such as facial landmarks. Additionally, we aim to evaluate our multi-task multi-modal <span id="S5.p5.1.1" class="ltx_text ltx_font_bold">ConCluGen</span> on different downstream tasks, such as facial action unit detection, face detection, and sentiment analysis. The code and the pre-trained models implemented in this work are publicly available for the research community as baselines for future studies <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://github.com/tub-cv-group/conclugen</span></span></span>.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany’s Excellence Strategy – EXC 2002/1 “Science of Intelligence” – project number 390523135. In addition, this work has been partially supported by MIAI@Grenoble Alpes, (ANR-19-P3IA-0003)</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:90%;">Abdat et al. [2011]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:90%;">
F. Abdat, C. Maaoui, and A. Pruski.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.8.1" class="ltx_text" style="font-size:90%;">Human-computer interaction using emotion recognition from facial expression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib1.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2011 UKSim 5th European Symposium on Computer Modeling and Simulation</em><span id="bib.bib1.11.3" class="ltx_text" style="font-size:90%;">, pages 196–201, 2011.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Alwassel et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">
Humam Alwassel, Dhruv Mahajan, Bruno Korbar, Lorenzo Torresani, Bernard Ghanem, and Du Tran.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">Self-supervised learning by cross-modal audio-video clustering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib2.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 34th International Conference on Neural Information Processing Systems</em><span id="bib.bib2.11.3" class="ltx_text" style="font-size:90%;">, Red Hook, NY, USA, 2020. Curran Associates Inc.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.4.4.1" class="ltx_text" style="font-size:90%;">Andonian [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.6.1" class="ltx_text" style="font-size:90%;">
Alex Andonian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:90%;">Pretorched-x.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/alexandonian/pretorched-x" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/alexandonian/pretorched-x</a><span id="bib.bib3.8.1" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:90%;">Asano et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:90%;">
Yuki Markus Asano, Mandela Patrick, Christian Rupprecht 0001, and Andrea Vedaldi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:90%;">Labelling unlabelled videos from scratch with multi-modal self-supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib4.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em><span id="bib.bib4.11.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Aviezer et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">
Hillel Aviezer, Noga Ensenberg, and Ran R Hassin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">The inherently contextualized nature of facial emotion perception.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib5.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Current Opinion in Psychology</em><span id="bib.bib5.10.2" class="ltx_text" style="font-size:90%;">, 17:47–54, 2017.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Bagher Zadeh et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:90%;">
AmirAli Bagher Zadeh, Paul Pu Liang, Soujanya Poria, Erik Cambria, and Louis-Philippe Morency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:90%;">Multimodal language analysis in the wild: CMU-MOSEI dataset and interpretable dynamic fusion graph.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib6.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em><span id="bib.bib6.11.3" class="ltx_text" style="font-size:90%;">, pages 2236–2246, Melbourne, Australia, 2018. Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Baum et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:90%;">
Julia Baum, Milena Rabovsky, Sebastian Benjamin Rose, and Rasha Abdel Rahman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text" style="font-size:90%;">Clear judgments based on unclear evidence: Person evaluation is strongly influenced by untrustworthy gossip.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib7.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Emotion</em><span id="bib.bib7.10.2" class="ltx_text" style="font-size:90%;">, 20(2):248–260, 2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Chauhan et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:90%;">
Dushyant Singh Chauhan, Md. Shad Akhtar, Asif Ekbal, and Pushpak Bhattacharyya.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:90%;">Context-aware interactive attention for multi-modal sentiment and emotion analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib8.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Conference on Empirical Methods in Natural Language Processing</em><span id="bib.bib8.11.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Chen et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:90%;">
Brian Chen, Andrew Rouditchenko, Kevin Duarte, Hilde Kuehne, Samuel Thomas, Angie Boggust, Rameswar Panda, Brian Kingsbury, Rogério Schmidt Feris, David F. Harwath, James R. Glass, Michael Picheny, and Shih-Fu Chang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text" style="font-size:90%;">Multimodal clustering networks for self-supervised learning from unlabeled videos.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib9.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</em><span id="bib.bib9.10.2" class="ltx_text" style="font-size:90%;">, pages 7992–8001, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Chen et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:90%;">
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:90%;">A simple framework for contrastive learning of visual representations.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib10.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2002.05709</em><span id="bib.bib10.10.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Chung et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:90%;">
J. S. Chung, A. Nagrani, and A. Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:90%;">VoxCeleb2: Deep speaker recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib11.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">INTERSPEECH</em><span id="bib.bib11.11.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:90%;">Dai et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">
Wenliang Dai, Samuel Cahyawijaya, Zihan Liu, and Pascale Fung.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:90%;">Multimodal end-to-end sparse model for emotion recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib12.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021</em><span id="bib.bib12.11.3" class="ltx_text" style="font-size:90%;">, pages 5305–5316. Association for Computational Linguistics, 2021.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:90%;">Deng et al. [2009]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.8.1" class="ltx_text" style="font-size:90%;">ImageNet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib13.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2009 IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib13.11.3" class="ltx_text" style="font-size:90%;">, pages 248–255, 2009.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:90%;">Devlin et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">BERT: Pre-training of deep bidirectional transformers for language understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib14.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em><span id="bib.bib14.11.3" class="ltx_text" style="font-size:90%;">, pages 4171–4186, Minneapolis, Minnesota, 2019. Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.4.4.1" class="ltx_text" style="font-size:90%;">Doersch and Zisserman [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.6.1" class="ltx_text" style="font-size:90%;">
Carl Doersch and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">Multi-task self-supervised visual learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib15.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">2017 IEEE International Conference on Computer Vision (ICCV)</em><span id="bib.bib15.9.2" class="ltx_text" style="font-size:90%;">, pages 2070–2079, 2017.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:90%;">Eiserbeck et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">
Anna Eiserbeck, Martin Maier, Julia Baum, and Rasha Abdel Rahman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:90%;">Deepfake smiles matter less—the psychological and neural impact of presumed AI-generated faces.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib16.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Scientific Reports</em><span id="bib.bib16.10.2" class="ltx_text" style="font-size:90%;">, 13(1):16111, 2023.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.4.4.1" class="ltx_text" style="font-size:90%;">Ekman [1971]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.6.1" class="ltx_text" style="font-size:90%;">
Paul Ekman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:90%;">Universals and cultural differences in facial expressions of emotion.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib17.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Nebraska Symposium on Motivation</em><span id="bib.bib17.9.2" class="ltx_text" style="font-size:90%;">, 19:207–283, 1971.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.4.4.1" class="ltx_text" style="font-size:90%;">Feldman Barrett and Kensinger [2010]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.6.1" class="ltx_text" style="font-size:90%;">
Lisa Feldman Barrett and E. Kensinger.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">Context Is Routinely Encoded During Emotion Perception.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib18.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Psychological science</em><span id="bib.bib18.9.2" class="ltx_text" style="font-size:90%;">, 2010.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">Franceschini et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">
R. Franceschini, E. Fini, C. Beyan, A. Conti, F. Arrigoni, and E. Ricci.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:90%;">Multimodal emotion recognition with modality-pairwise unsupervised contrastive loss.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib19.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2022 26th International Conference on Pattern Recognition (ICPR)</em><span id="bib.bib19.11.3" class="ltx_text" style="font-size:90%;">, pages 2589–2596, Los Alamitos, CA, USA, 2022. IEEE Computer Society.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:90%;">Gidaris et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:90%;">Unsupervised representation learning by predicting image rotations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib20.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings</em><span id="bib.bib20.11.3" class="ltx_text" style="font-size:90%;">. OpenReview.net, 2018.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Halawa et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:90%;">
Marah Halawa, Manuel Wöllhaf, Eduardo Vellasques, Urko Sánchez Sanz, and Olaf Hellwich.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:90%;">Learning disentangled expression representations from facial images.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib21.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2008.07001</em><span id="bib.bib21.10.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Halawa et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:90%;">
Marah Halawa, Olaf Hellwich, and Pia Bideau.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:90%;">Action-based contrastive learning for trajectory prediction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib22.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Vision – ECCV 2022</em><span id="bib.bib22.11.3" class="ltx_text" style="font-size:90%;">, pages 143–159, Cham, 2022. Springer Nature Switzerland.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Harwath et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:90%;">
David F. Harwath, Adrià Recasens, Dídac Surís, Galen Chuang, Antonio Torralba, and James R. Glass.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:90%;">Jointly discovering visual objects and spoken words from raw sensory input.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib23.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Journal of Computer Vision</em><span id="bib.bib23.10.2" class="ltx_text" style="font-size:90%;">, 128:620 – 641, 2018.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:90%;">He et al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:90%;">
Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib24.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib24.10.2" class="ltx_text" style="font-size:90%;">, pages 770–778, 2015.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:90%;">Huynh et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:90%;">
Van Thong Huynh, Hyung-Jeong Yang, Guee-Sang Lee, and Soo-Hyung Kim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:90%;">End-to-end learning for multimodal emotion recognition in video with adaptive loss.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib25.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE MultiMedia</em><span id="bib.bib25.10.2" class="ltx_text" style="font-size:90%;">, 28(2):59–66, 2021.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Ilharco et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:90%;">
Gabriel Ilharco, Yuan Zhang, and Jason Baldridge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:90%;">Large-scale representation learning from visually grounded untranscribed speech.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib26.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</em><span id="bib.bib26.11.3" class="ltx_text" style="font-size:90%;">, pages 55–65, Hong Kong, China, 2019. Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Kay et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:90%;">
Will Kay, João Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, Mustafa Suleyman, and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text" style="font-size:90%;">The kinetics human action video dataset.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib27.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib27.10.2" class="ltx_text" style="font-size:90%;">, abs/1705.06950, 2017.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Khare et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:90%;">
Aparna Khare, Srinivas Parthasarathy, and Shiva Sundaram.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:90%;">Self-supervised learning with cross-modal transformers for emotion recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib28.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 IEEE Spoken Language Technology Workshop (SLT)</em><span id="bib.bib28.10.2" class="ltx_text" style="font-size:90%;">, pages 381–388, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Kim et al. [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:90%;">
Vladislav Kim, Nikolaos Adaloglou, Marc Osterland, Flavio M. Morelli, Marah Halawa, Tim König, David Gnutt, and Paula A. Marin Zapata.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:90%;">Self-supervision advances morphological profiling by unlocking powerful image representations.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib29.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">bioRxiv</em><span id="bib.bib29.10.2" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.4.4.1" class="ltx_text" style="font-size:90%;">Koromilas and Giannakopoulos [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.6.1" class="ltx_text" style="font-size:90%;">
Panagiotis Koromilas and Theodoros Giannakopoulos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:90%;">Unsupervised multimodal language representations using convolutional autoencoders.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib30.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib30.9.2" class="ltx_text" style="font-size:90%;">, abs/2110.03007, 2021.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Kosti et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:90%;">
Ronak Kosti, Jose Alvarez, Adria Recasens, and Agata Lapedriza.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:90%;">Context Based Emotion Recognition using EMOTIC Dataset.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib31.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</em><span id="bib.bib31.10.2" class="ltx_text" style="font-size:90%;">, pages 1–1, 2019.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Larsson et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:90%;">
Gustav Larsson, Michael Maire, and Gregory Shakhnarovich.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text" style="font-size:90%;">Colorization as a proxy task for visual understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib32.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib32.11.3" class="ltx_text" style="font-size:90%;">. IEEE, 2017.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text" style="font-size:90%;">Lee et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text" style="font-size:90%;">
Jiyoung Lee, Seungryong Kim, Sunok Kim, Jungin Park, and Kwanghoon Sohn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.8.1" class="ltx_text" style="font-size:90%;">Context-Aware Emotion Recognition Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib33.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</em><span id="bib.bib33.11.3" class="ltx_text" style="font-size:90%;">, pages 10142–10151, 2019.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.4.4.1" class="ltx_text" style="font-size:90%;">Li and Deng [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.6.1" class="ltx_text" style="font-size:90%;">
Shan Li and Weihong Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text" style="font-size:90%;">Deep facial expression recognition: A survey.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib34.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Affective Computing</em><span id="bib.bib34.9.2" class="ltx_text" style="font-size:90%;">, 13(3):1195–1215, 2022.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:90%;">Liu et al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:90%;">
Yu Liu, Fangyin Wei, Jing Shao, Lu Sheng, Junjie Yan, and Xiaogang Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text" style="font-size:90%;">Exploring disentangled feature representation beyond face identification.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib35.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib35.10.2" class="ltx_text" style="font-size:90%;">, pages 2080–2089, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.4.4.1" class="ltx_text" style="font-size:90%;">Loshchilov and Hutter [2017a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.6.1" class="ltx_text" style="font-size:90%;">
I. Loshchilov and F. Hutter.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text" style="font-size:90%;">Decoupled Weight Decay Regularization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib36.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib36.10.3" class="ltx_text" style="font-size:90%;">, 2017a.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.4.4.1" class="ltx_text" style="font-size:90%;">Loshchilov and Hutter [2017b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.6.1" class="ltx_text" style="font-size:90%;">
Ilya Loshchilov and Frank Hutter.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:90%;">SGDR: stochastic gradient descent with warm restarts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib37.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings</em><span id="bib.bib37.10.3" class="ltx_text" style="font-size:90%;">. OpenReview.net, 2017b.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text" style="font-size:90%;">Mai et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text" style="font-size:90%;">
Sijie Mai, Ying Zeng, and Haifeng Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.8.1" class="ltx_text" style="font-size:90%;">Multimodal information bottleneck: Learning minimal sufficient unimodal and multimodal representations.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib38.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Multimedia</em><span id="bib.bib38.10.2" class="ltx_text" style="font-size:90%;">, pages 1–1, 2022.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">Maier et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text" style="font-size:90%;">
Martin Maier, Florian Blume, Pia Bideau, Olaf Hellwich, and Rasha Abdel Rahman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text" style="font-size:90%;">Knowledge-augmented face perception: Prospects for the Bayesian brain-framework to align AI and human vision.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib39.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Consciousness and Cognition</em><span id="bib.bib39.10.2" class="ltx_text" style="font-size:90%;">, 101:103301, 2022.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:90%;">Mikolov et al. [2013]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text" style="font-size:90%;">
Tomas Mikolov, Kai Chen, Gregory S. Corrado, and Jeffrey Dean.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text" style="font-size:90%;">Efficient estimation of word representations in vector space.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib40.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib40.11.3" class="ltx_text" style="font-size:90%;">, 2013.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.4.4.1" class="ltx_text" style="font-size:90%;">Noroozi and Favaro [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.6.1" class="ltx_text" style="font-size:90%;">
Mehdi Noroozi and Paolo Favaro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text" style="font-size:90%;">Unsupervised learning of visual representations by solving jigsaw puzzles.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib41.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Vision – ECCV 2016</em><span id="bib.bib41.10.3" class="ltx_text" style="font-size:90%;">, pages 69–84, Cham, 2016. Springer International Publishing.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.4.4.1" class="ltx_text" style="font-size:90%;">Owens and Efros [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.6.1" class="ltx_text" style="font-size:90%;">
Andrew Owens and Alexei A. Efros.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text" style="font-size:90%;">Audio-visual scene analysis with self-supervised multisensory features.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib42.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</em><span id="bib.bib42.10.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text" style="font-size:90%;">Pathak et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text" style="font-size:90%;">
Deepak Pathak, Dhiraj Gandhi, and Abhinav Gupta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text" style="font-size:90%;">Self-supervised exploration via disagreement.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib43.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICML</em><span id="bib.bib43.11.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text" style="font-size:90%;">Poria et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:90%;">
Soujanya Poria, Devamanyu Hazarika, Navonil Majumder, Gautam Naik, Erik Cambria, and Rada Mihalcea.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text" style="font-size:90%;">MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib44.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em><span id="bib.bib44.10.2" class="ltx_text" style="font-size:90%;">, pages 527–536, 2019.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:90%;">Qian et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text" style="font-size:90%;">
R. Qian, T. Meng, B. Gong, M. Yang, H. Wang, S. Belongie, and Y. Cui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text" style="font-size:90%;">Spatiotemporal contrastive video representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib45.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib45.11.3" class="ltx_text" style="font-size:90%;">, pages 6960–6970, Los Alamitos, CA, USA, 2021. IEEE Computer Society.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:90%;">Radford et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:90%;">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text" style="font-size:90%;">Learning transferable visual models from natural language supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib46.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event</em><span id="bib.bib46.11.3" class="ltx_text" style="font-size:90%;">, pages 8748–8763. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.4.4.1" class="ltx_text" style="font-size:90%;">Russell [1997]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.6.1" class="ltx_text" style="font-size:90%;">
James A. Russell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text" style="font-size:90%;">Reading emotions from and into faces: Resurrecting a dimensional-contextual perspective.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib47.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">The Psychology of Facial Expression</em><span id="bib.bib47.10.3" class="ltx_text" style="font-size:90%;">, pages 295–320. Cambridge University Press, Cambridge, 1997.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text" style="font-size:90%;">Sanh et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text" style="font-size:90%;">
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.8.1" class="ltx_text" style="font-size:90%;">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib48.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ArXiv</em><span id="bib.bib48.10.2" class="ltx_text" style="font-size:90%;">, abs/1910.01108, 2019.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:90%;">Schiappa et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text" style="font-size:90%;">
Madeline Chantry Schiappa, Yogesh Singh Rawat, and Mubarak Shah.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.8.1" class="ltx_text" style="font-size:90%;">Self-supervised learning for videos: A survey.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib49.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Computing Surveys</em><span id="bib.bib49.10.2" class="ltx_text" style="font-size:90%;">, 55:1 – 37, 2022.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.4.4.1" class="ltx_text" style="font-size:90%;">Shenoy and Sardana [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.6.1" class="ltx_text" style="font-size:90%;">
Aman Shenoy and Ashish Sardana.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.7.1" class="ltx_text" style="font-size:90%;">Multilogue-net: A context-aware RNN for multi-modal emotion detection and sentiment analysis in conversation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib50.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</em><span id="bib.bib50.10.3" class="ltx_text" style="font-size:90%;">, pages 19–28, Seattle, USA, 2020. Association for Computational Linguistics.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text" style="font-size:90%;">Shu et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.7.1" class="ltx_text" style="font-size:90%;">
Yuxuan Shu, Xiao Gu, Guangyao Yang, and Benny P. L. Lo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.8.1" class="ltx_text" style="font-size:90%;">Revisiting self-supervised contrastive learning for facial expression recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib51.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">British Machine Vision Conference</em><span id="bib.bib51.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text" style="font-size:90%;">Siriwardhana et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.7.1" class="ltx_text" style="font-size:90%;">
Shamane Siriwardhana, Tharindu Kaluarachchi, Mark Billinghurst, and Suranga Nanayakkara.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.8.1" class="ltx_text" style="font-size:90%;">Multimodal emotion recognition with transformer-based self supervised feature fusion.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib52.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Access</em><span id="bib.bib52.10.2" class="ltx_text" style="font-size:90%;">, 8:176274–176285, 2020.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.5.5.1" class="ltx_text" style="font-size:90%;">Suess et al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.7.1" class="ltx_text" style="font-size:90%;">
Franziska Suess, Milena Rabovsky, and Rasha Abdel Rahman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.8.1" class="ltx_text" style="font-size:90%;">Perceiving emotions in neutral faces: Expression processing is biased by affective person knowledge.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib53.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Social Cognitive and Affective Neuroscience</em><span id="bib.bib53.10.2" class="ltx_text" style="font-size:90%;">, 10(4):531–536, 2015.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.5.5.1" class="ltx_text" style="font-size:90%;">Sun et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.7.1" class="ltx_text" style="font-size:90%;">
Chen Sun, Austin Myers, Carl Vondrick, Kevin P. Murphy, and Cordelia Schmid.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.8.1" class="ltx_text" style="font-size:90%;">Videobert: A joint model for video and language representation learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib54.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</em><span id="bib.bib54.10.2" class="ltx_text" style="font-size:90%;">, pages 7463–7472, 2019.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.5.5.1" class="ltx_text" style="font-size:90%;">Taleb et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.7.1" class="ltx_text" style="font-size:90%;">
Aiham Taleb, Matthias Kirchler, Remo Monti, and Christoph Lippert.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.8.1" class="ltx_text" style="font-size:90%;">Contig: Self-supervised multimodal contrastive learning for medical imaging with genetics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib55.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib55.11.3" class="ltx_text" style="font-size:90%;">, pages 20908–20921, 2022.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.5.5.1" class="ltx_text" style="font-size:90%;">Tian et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.7.1" class="ltx_text" style="font-size:90%;">
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.8.1" class="ltx_text" style="font-size:90%;">Contrastive multiview coding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib56.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Vision – ECCV 2020</em><span id="bib.bib56.11.3" class="ltx_text" style="font-size:90%;">, pages 776–794, Cham, 2020. Springer International Publishing.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.5.5.1" class="ltx_text" style="font-size:90%;">Wen et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.7.1" class="ltx_text" style="font-size:90%;">
Huanglu Wen, Shaodi You, and Ying Fu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.8.1" class="ltx_text" style="font-size:90%;">Cross-modal dynamic convolution for multi-modal emotion recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib57.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of Visual Communication and Image Representation</em><span id="bib.bib57.10.2" class="ltx_text" style="font-size:90%;">, 78:103178, 2021.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.4.4.1" class="ltx_text" style="font-size:90%;">Wieser and Brosch [2012]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.6.1" class="ltx_text" style="font-size:90%;">
Matthias J. Wieser and Tobias Brosch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.7.1" class="ltx_text" style="font-size:90%;">Faces in Context: A Review and Systematization of Contextual Influences on Affective Face Processing.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib58.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Frontiers in Psychology</em><span id="bib.bib58.9.2" class="ltx_text" style="font-size:90%;">, 3, 2012.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.5.5.1" class="ltx_text" style="font-size:90%;">Zhang et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.7.1" class="ltx_text" style="font-size:90%;">
Mengmi Zhang, Claire Tseng, and Gabriel Kreiman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.8.1" class="ltx_text" style="font-size:90%;">Putting Visual Object Recognition in Context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib59.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib59.11.3" class="ltx_text" style="font-size:90%;">, pages 12982–12991, Seattle, WA, USA, 2020. IEEE.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.5.5.1" class="ltx_text" style="font-size:90%;">Zheng et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.7.1" class="ltx_text" style="font-size:90%;">
Mingkai Zheng, Fei Wang, Shan You, Chen Qian, Changshui Zhang, Xiaogang Wang, and Chang Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.8.1" class="ltx_text" style="font-size:90%;">Weakly supervised contrastive learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib60.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</em><span id="bib.bib60.11.3" class="ltx_text" style="font-size:90%;">, pages 10022–10031, 2021.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para ltx_noindent">
<span id="p1.1" class="ltx_ERROR undefined">\thetitle</span>
<br class="ltx_break ltx_centering">
<p id="p1.2" class="ltx_p ltx_align_center"><span id="p1.2.1" class="ltx_text" style="font-size:144%;">Supplementary Material 
<br class="ltx_break"></span></p>
</div>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">6 </span>Implementation Details</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text" style="font-size:144%;">We extract features from the input modalities using pretrained fixed feature extractors. The frames for the 2D ResNet-152 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p1.1.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a><span id="S6.p1.1.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S6.p1.1.4" class="ltx_text" style="font-size:144%;"> (ImageNet </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p1.1.5.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a><span id="S6.p1.1.6.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S6.p1.1.7" class="ltx_text" style="font-size:144%;">) are subsampled to 1fps and for the 3D ResNet-101 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p1.1.8.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a><span id="S6.p1.1.9.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S6.p1.1.10" class="ltx_text" style="font-size:144%;"> (Kinetics </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p1.1.11.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a><span id="S6.p1.1.12.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S6.p1.1.13" class="ltx_text" style="font-size:144%;">) to 16fps. The audio is transformed into Mel spectrograms before processing with a DAVENet </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p1.1.14.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a><span id="S6.p1.1.15.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S6.p1.1.16" class="ltx_text" style="font-size:144%;"> pretrained on affective audio. For text, we take the last hidden layer of a DistillBERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p1.1.17.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a><span id="S6.p1.1.18.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S6.p1.1.19" class="ltx_text" style="font-size:144%;"> that was trained for sentiment analysis. To obtain a fixed-size feature vector per modality, we process the inputs sequentially and average the resulting vectors over time. The 2D and 3D frame features are concatenated after averaging. The result is stored on disk, </span><em id="S6.p1.1.20" class="ltx_emph ltx_font_italic" style="font-size:144%;">i.e</em><span id="S6.p1.1.21" class="ltx_text" style="font-size:144%;">.</span><span id="S6.p1.1.22" class="ltx_text"></span><span id="S6.p1.1.23" class="ltx_text" style="font-size:144%;"> no finetuning of the backbone feature extractors happens. We use AdamW optimizer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p1.1.24.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a><span id="S6.p1.1.25.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S6.p1.1.26" class="ltx_text" style="font-size:144%;"> for both pertaining and downstream training, in combination with cosine annealing with warm restarts </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S6.p1.1.27.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a><span id="S6.p1.1.28.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S6.p1.1.29" class="ltx_text" style="font-size:144%;"> as learning rate scheduling. Our batch size is 4096 and the image size is 180 by 180 pixels (cropped or resized). The size of the representations is 4096. More details are given in the supplementary material. We used the following learning rates in our experiments:</span></p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Pretraining:</span><span id="S6.p2.1.2" class="ltx_text" style="font-size:144%;"></span></p>
</div>
<div id="S6.p3" class="ltx_para">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p"><span id="S6.I1.i1.p1.1.1" class="ltx_text" style="font-size:144%;">ConCluGen: lr=0.00009, weight decay=0.00032</span></p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p"><span id="S6.I1.i2.p1.1.1" class="ltx_text" style="font-size:144%;">ConClu: lr=0.00009, weight decay=0.00032</span></p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p"><span id="S6.I1.i3.p1.1.1" class="ltx_text" style="font-size:144%;">ConGen: lr=0.00036, weight decay=0.00032</span></p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p id="S6.I1.i4.p1.1" class="ltx_p"><span id="S6.I1.i4.p1.1.1" class="ltx_text" style="font-size:144%;">Multi-Cont: lr=0.00036, weight decay=</span></p>
</div>
</li>
<li id="S6.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i5.p1" class="ltx_para">
<p id="S6.I1.i5.p1.1" class="ltx_p"><span id="S6.I1.i5.p1.1.1" class="ltx_text" style="font-size:144%;">Instance-Cont: lr=0.00036, weight decay=00032</span></p>
</div>
</li>
<li id="S6.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i6.p1" class="ltx_para">
<p id="S6.I1.i6.p1.1" class="ltx_p"><span id="S6.I1.i6.p1.1.1" class="ltx_text" style="font-size:144%;">Generative: lr=0.00036, weight decay=0.00032</span></p>
</div>
</li>
</ul>
</div>
<div id="S6.p4" class="ltx_para ltx_noindent">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Downstream:</span><span id="S6.p4.1.2" class="ltx_text" style="font-size:144%;"> (We chose common hyperparameters that worked well for all methods)</span></p>
</div>
<div id="S6.p5" class="ltx_para">
<ul id="S6.I2" class="ltx_itemize">
<li id="S6.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i1.p1" class="ltx_para">
<p id="S6.I2.i1.p1.1" class="ltx_p"><span id="S6.I2.i1.p1.1.1" class="ltx_text" style="font-size:144%;">CAER: lr=0.0061, weight decay=0.08216</span></p>
</div>
</li>
<li id="S6.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i2.p1" class="ltx_para">
<p id="S6.I2.i2.p1.1" class="ltx_p"><span id="S6.I2.i2.p1.1.1" class="ltx_text" style="font-size:144%;">MELD: lr=0.00967, weight decay=0.00004</span></p>
</div>
</li>
<li id="S6.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I2.i3.p1" class="ltx_para">
<p id="S6.I2.i3.p1.1" class="ltx_p"><span id="S6.I2.i3.p1.1.1" class="ltx_text" style="font-size:144%;">MOSEI: lr=0.00996, weight decay=0.00007</span></p>
</div>
</li>
</ul>
</div>
<div id="S6.p6" class="ltx_para">
<p id="S6.p6.1" class="ltx_p"><span id="S6.p6.1.1" class="ltx_text" style="font-size:144%;">For the K-means clustering, we choose a queue size of 4 (</span><em id="S6.p6.1.2" class="ltx_emph ltx_font_italic" style="font-size:144%;">i.e</em><span id="S6.p6.1.3" class="ltx_text" style="font-size:144%;">.</span><span id="S6.p6.1.4" class="ltx_text"></span><span id="S6.p6.1.5" class="ltx_text" style="font-size:144%;"> 4 batches were considered in the clustering), 8 clusters and started the clustering in epoch 12.</span></p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">7 </span>Confusion Matrices for <span title="" class="ltx_glossaryref">CAER</span>
</h2>

<figure id="S7.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S7.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.10904/assets/x6.png" id="S7.F3.sf1.g1" class="ltx_graphics ltx_img_portrait" width="528" height="683" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S7.F3.sf1.4.1.1" class="ltx_text" style="font-size:63%;">(a)</span> </span><span id="S7.F3.sf1.5.2" class="ltx_text" style="font-size:63%;">ConCluGen Model.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S7.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.10904/assets/x7.png" id="S7.F3.sf2.g1" class="ltx_graphics ltx_img_portrait" width="528" height="683" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S7.F3.sf2.4.1.1" class="ltx_text" style="font-size:63%;">(b)</span> </span><span id="S7.F3.sf2.5.2" class="ltx_text" style="font-size:63%;">ConClu Model.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S7.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="" id="S7.F3.sf3.g1" class="ltx_graphics ltx_missing ltx_missing_image" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S7.F3.sf3.4.1.1" class="ltx_text" style="font-size:63%;">(c)</span> </span><span id="S7.F3.sf3.5.2" class="ltx_text" style="font-size:63%;">Multi-Cont Model.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S7.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2404.10904/assets/x9.png" id="S7.F3.sf4.g1" class="ltx_graphics ltx_img_portrait" width="528" height="683" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S7.F3.sf4.4.1.1" class="ltx_text" style="font-size:63%;">(d)</span> </span><span id="S7.F3.sf4.5.2" class="ltx_text" style="font-size:63%;">Instance-Cont Model.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S7.F3.4.1.1" class="ltx_text" style="font-size:63%;">Figure 3</span>: </span><span id="S7.F3.5.2" class="ltx_text" style="font-size:63%;">Confusion metrics for CAER dataset over different models.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.10902" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.10904" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.10904">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.10904" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.10905" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 22:41:06 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
