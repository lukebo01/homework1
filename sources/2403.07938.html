<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.07938] Text-to-Audio Generation Synchronized with Videos</title><meta property="og:description" content="In recent times, the focus on text-to-audio (TTA) generation has intensified, as researchers strive to synthesize audio from textual descriptions.
However, most existing methods, though leveraging latent diffusion mode…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Text-to-Audio Generation Synchronized with Videos">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Text-to-Audio Generation Synchronized with Videos">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.07938">

<!--Generated on Fri Apr  5 14:08:14 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Machine Learning,  ICML">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Text-to-Audio Generation Synchronized with Videos</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shentong Mo
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jing Shi
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yapeng Tian
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">In recent times, the focus on text-to-audio (TTA) generation has intensified, as researchers strive to synthesize audio from textual descriptions.
However, most existing methods, though leveraging latent diffusion models to learn the correlation between audio and text embeddings, fall short when it comes to maintaining a seamless synchronization between the produced audio and its video.
This often results in discernible audio-visual mismatches.
To bridge this gap, we introduce a groundbreaking benchmark for Text-to-Audio generation that aligns with Videos, named <span id="id1.id1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span>.
This benchmark distinguishes itself with three novel metrics dedicated to evaluating visual alignment and temporal consistency.
To complement this, we also present a simple yet effective video-aligned TTA generation model, namely <span id="id1.id1.2" class="ltx_text ltx_font_smallcaps">T2AV</span>.
Moving beyond traditional methods, <span id="id1.id1.3" class="ltx_text ltx_font_smallcaps">T2AV</span> refines the latent diffusion approach by integrating visual-aligned text embeddings as its conditional foundation.
It employs a temporal multi-head attention transformer to extract and understand temporal nuances from video data, a feat amplified by our Audio-Visual ControlNet that adeptly merges temporal visual representations with text embeddings.
Further enhancing this integration, we weave in a contrastive learning objective, designed to ensure that the visual-aligned text embeddings resonate closely with the audio features.
Extensive evaluations on the AudioCaps and <span id="id1.id1.4" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> demonstrate that our <span id="id1.id1.5" class="ltx_text ltx_font_smallcaps">T2AV</span> sets a new standard for video-aligned TTA generation in ensuring visual alignment and temporal consistency.</p>
</div>
<div class="ltx_keywords">Machine Learning, ICML
</div>
<div id="p2" class="ltx_para">
<br class="ltx_break">
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The realm of audio signal processing is continually expanding, and one of its most promising offshoots is text-to-audio (TTA) generation.
This avenue seeks to address a compelling query: <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">is it feasible to craft high-dimensional audio signals that are not only sonically rich but also contextually attuned to their textual precursors? </span>
Recent times have witnessed a surge of investigative endeavors into this realm, with researchers exploring the power of denoising diffusion probabilistic models (DDPMs) as evidenced by innovations like DiffSound <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite> and AudioGen <cite class="ltx_cite ltx_citemacro_citep">(Kreuk et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>.
Building on this momentum, AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> set a new trajectory by synergizing latent diffusion models with the contrastive prowess of language-audio pre-training (CLAP) <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>, rooting their strategy in the bedrock of text embeddings.
The resultant audio landscapes were not just audibly impressive but also contextually tethered to their textual origins.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2403.07938/assets/figs/title_image.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="362" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.6.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.7.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Comparison of our <span id="S1.F1.7.2.1" class="ltx_text ltx_font_medium ltx_font_smallcaps">T2AV</span> with state-of-the-art methods<span id="S1.F1.7.2.2" class="ltx_text ltx_font_medium"> on the proposed <span id="S1.F1.7.2.2.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> in terms of FAD, FAVD, FATD, and FA(VT)D for video-aligned text-to-audio generation.
Our method significantly outperforms previous baselines in terms of all metrics (lower is better).</span></span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Although these methods achieve impressive performance in generating plausible sounds, they ignored the synchronization between generated audio and visual content in videos, resulting in misaligned audio and video frames.
For instance, the model might generate a train horn sound for ten seconds, even when no train is visible in the frame.
The main challenge is that sounds are naturally aligned with frames in natural videos.
This inspires us to learn video-aligned semantics for each text prompt from the video to guide text-to-audio generation.
To address the problem, our key idea is to capture video-aligned text representations for updating text embeddings as the condition, which differs from existing DDPMs and LDMs on TTA generation.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To address this challenge, we present the <span id="S1.p3.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> benchmark for Text-to-Audio generation aligned with Videos to ensure synchronization with video content.
Meanwhile, inspired by Frechet Inception Distance in the image domain, we present three novel metrics including Frechet Audio-Visual Distance, Frechet Audio-Visual Distance, and Frechet Audio-(Video-Text) Distance for the evaluation of the quality of our generated audio regarding visual alignment and temporal consistency.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Beyond this benchmark, we also introduce <span id="S1.p4.1.1" class="ltx_text ltx_font_smallcaps">T2AV</span>, a simple yet effective method based on a latent diffusion model that can learn visual-aligned text semantics as guidance for video-aligned TTA generation.
Specifically, our <span id="S1.p4.1.2" class="ltx_text ltx_font_smallcaps">T2AV</span> leverages visual-aligned contrastive language-audio pre-training to capture the alignment between the textual and visual features at spatial and temporal levels corresponding to the paired audio.
Then, we introduce Audio-Visual ControlNet based on a temporal multi-head attention transformer to extract text embeddings with visual-aligned semantics as the condition for latent diffusion models.
Compared to previous TTA baselines, our new framework can support a flexible number of condition operators in Audio-Visual ControlNet and shows the effectiveness of learning video-aligned semantics for generating high-fidelity audio given input captions</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Empirical experiments on AudioCaps benchmarks and our <span id="S1.p5.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> comprehensively demonstrate the state-of-the-art performance against previous text-to-audio generation baselines.
In addition, qualitative visualizations of target-generated video results showcase the effectiveness of our <span id="S1.p5.1.2" class="ltx_text ltx_font_smallcaps">T2AV</span> in generating high-fidelity audio aligned with videos.
Extensive ablation studies also validate the importance of visual-aligned language-audio pre-training and Audio-Visual ControlNet in learning temporal-aware representations for maintaining visual alignment and temporal consistency.
We also demonstrate the importance of the training data scale and latent diffusion tuning in video-aligned text-to-audio generation.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In summation, our contributions can be summarized as:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We present a novel benchmark for Text-to-Audio generation aligned with Video, namely <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span>, complemented by three new metrics focusing on visual coherence and temporal synchronicity.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We introduce a simple yet effective approach called <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_smallcaps">T2AV</span>, a new latent diffusion model that symbiotically integrates temporal video representations conditioned by the proposed Audio-Visual ControlNet.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Extensive experiments comprehensively demonstrate
the state-of-the-art superiority of our <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_smallcaps">T2AV</span> over previous baselines on text-to-audio generation outputs with visual alignment and temporal consistency.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Diffusion Models.</span>
Diffusion models have been demonstrated to be effective in many generative tasks, such as image generation <cite class="ltx_cite ltx_citemacro_citep">(Saharia et al., <a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite>, image restoration <cite class="ltx_cite ltx_citemacro_citep">(Saharia et al., <a href="#bib.bib40" title="" class="ltx_ref">2021</a>)</cite>, speech generation <cite class="ltx_cite ltx_citemacro_citep">(Kong et al., <a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite>, and video generation <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>.
Typically, denoising diffusion probabilistic models (DDPMs) <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a href="#bib.bib7" title="" class="ltx_ref">2020</a>; Song et al., <a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite> utilized a forward noising process that gradually adds Gaussian noise to images and trained a reverse process that inverts the forward process.
Unlike them, we apply latent diffusion models (LDMs) on audio embeddings to generate visually aligned and temporally consistent sounds based on text descriptions.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Audio-Visual Learning.</span>
Audio-visual learning has been explored in many previous works <cite class="ltx_cite ltx_citemacro_citep">(Aytar et al., <a href="#bib.bib2" title="" class="ltx_ref">2016</a>; Owens et al., <a href="#bib.bib37" title="" class="ltx_ref">2016</a>; Arandjelovic &amp; Zisserman, <a href="#bib.bib1" title="" class="ltx_ref">2017</a>; Korbar et al., <a href="#bib.bib14" title="" class="ltx_ref">2018</a>; Senocak et al., <a href="#bib.bib42" title="" class="ltx_ref">2018</a>; Zhao et al., <a href="#bib.bib52" title="" class="ltx_ref">2018</a>, <a href="#bib.bib53" title="" class="ltx_ref">2019</a>; Gan et al., <a href="#bib.bib5" title="" class="ltx_ref">2020</a>; Morgado et al., <a href="#bib.bib34" title="" class="ltx_ref">2020</a>, <a href="#bib.bib35" title="" class="ltx_ref">2021a</a>, <a href="#bib.bib36" title="" class="ltx_ref">2021b</a>; Mo &amp; Tian, <a href="#bib.bib28" title="" class="ltx_ref">2022b</a>; Mo &amp; Morgado, <a href="#bib.bib23" title="" class="ltx_ref">2022c</a>; Mo et al., <a href="#bib.bib32" title="" class="ltx_ref">2023b</a>; Mo &amp; Morgado, <a href="#bib.bib25" title="" class="ltx_ref">2023b</a>, <a href="#bib.bib24" title="" class="ltx_ref">a</a>; Mo et al., <a href="#bib.bib31" title="" class="ltx_ref">2023a</a>; Pian et al., <a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite> to capture the audio-visual alignment between two distinct modalities in videos.
Such cross-modal correspondences are beneficial for many audio-visual tasks, such as audio-event localization <cite class="ltx_cite ltx_citemacro_citep">(Tian et al., <a href="#bib.bib44" title="" class="ltx_ref">2018</a>; Wu et al., <a href="#bib.bib48" title="" class="ltx_ref">2019</a>; Lin et al., <a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite>, audio-visual parsing <cite class="ltx_cite ltx_citemacro_citep">(Tian et al., <a href="#bib.bib45" title="" class="ltx_ref">2020</a>; Wu &amp; Yang, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>; Lin et al., <a href="#bib.bib17" title="" class="ltx_ref">2021</a>; Mo &amp; Tian, <a href="#bib.bib27" title="" class="ltx_ref">2022a</a>)</cite>, audio-visual spatialization &amp; localization <cite class="ltx_cite ltx_citemacro_citep">(Morgado et al., <a href="#bib.bib33" title="" class="ltx_ref">2018</a>, <a href="#bib.bib34" title="" class="ltx_ref">2020</a>; Mo &amp; Morgado, <a href="#bib.bib21" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib22" title="" class="ltx_ref">b</a>; Mo &amp; Tian, <a href="#bib.bib29" title="" class="ltx_ref">2023a</a>, <a href="#bib.bib30" title="" class="ltx_ref">b</a>; Mo &amp; Raj, <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite>, and visual-to-sound generation <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib54" title="" class="ltx_ref">2018</a>; Iashin &amp; Rahtu, <a href="#bib.bib11" title="" class="ltx_ref">2021b</a>; Du et al., <a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite>. While the task of visual-to-sound generation is relevant to our problem, our primary focus is on learning discriminative cross-modal representations for visual-guided text-to-sound generation, a more challenging endeavor than the aforementioned tasks.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.T1.st1" class="ltx_table ltx_figure_panel ltx_align_center">
<div id="S2.T1.st1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:261.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(127.4pt,-76.9pt) scale(2.42396006371722,2.42396006371722) ;">
<table id="S2.T1.st1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.st1.1.1.1" class="ltx_tr">
<th id="S2.T1.st1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st1.1.1.1.2.1" class="ltx_text ltx_font_bold">True Pairs</span></th>
<th id="S2.T1.st1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st1.1.1.1.3.1" class="ltx_text ltx_font_bold">False Pairs</span></th>
<th id="S2.T1.st1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st1.1.1.1.1.1" class="ltx_text ltx_font_bold">FAVD (<math id="S2.T1.st1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S2.T1.st1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S2.T1.st1.1.1.1.1.1.m1.1.1" xref="S2.T1.st1.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S2.T1.st1.1.1.1.1.1.m1.1b"><ci id="S2.T1.st1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.st1.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.st1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.st1.1.1.2.1" class="ltx_tr" style="background-color:#000000;">
<td id="S2.T1.st1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st1.1.1.2.1.1.1" class="ltx_text" style="background-color:#000000;">500</span></td>
<td id="S2.T1.st1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st1.1.1.2.1.2.1" class="ltx_text" style="background-color:#000000;">0</span></td>
<td id="S2.T1.st1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st1.1.1.2.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">12.85</span></td>
</tr>
<tr id="S2.T1.st1.1.1.3.2" class="ltx_tr">
<td id="S2.T1.st1.1.1.3.2.1" class="ltx_td ltx_align_center">0</td>
<td id="S2.T1.st1.1.1.3.2.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st1.1.1.3.2.3" class="ltx_td ltx_align_center">58.62</td>
</tr>
<tr id="S2.T1.st1.1.1.4.3" class="ltx_tr">
<td id="S2.T1.st1.1.1.4.3.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st1.1.1.4.3.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st1.1.1.4.3.3" class="ltx_td ltx_align_center">36.72</td>
</tr>
<tr id="S2.T1.st1.1.1.5.4" class="ltx_tr">
<td id="S2.T1.st1.1.1.5.4.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st1.1.1.5.4.2" class="ltx_td ltx_align_center">1000</td>
<td id="S2.T1.st1.1.1.5.4.3" class="ltx_td ltx_align_center">49.51</td>
</tr>
<tr id="S2.T1.st1.1.1.6.5" class="ltx_tr">
<td id="S2.T1.st1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_bb">1000</td>
<td id="S2.T1.st1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb">500</td>
<td id="S2.T1.st1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">29.18</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.st1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S2.T1.st1.4.2" class="ltx_text" style="font-size:90%;">FAVD.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.T1.st2" class="ltx_table ltx_figure_panel ltx_align_center">
<div id="S2.T1.st2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:261.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(127.4pt,-76.9pt) scale(2.42396027047494,2.42396027047494) ;">
<table id="S2.T1.st2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.st2.1.1.1" class="ltx_tr">
<th id="S2.T1.st2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st2.1.1.1.2.1" class="ltx_text ltx_font_bold">True Pairs</span></th>
<th id="S2.T1.st2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st2.1.1.1.3.1" class="ltx_text ltx_font_bold">False Pairs</span></th>
<th id="S2.T1.st2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st2.1.1.1.1.1" class="ltx_text ltx_font_bold">FATD (<math id="S2.T1.st2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S2.T1.st2.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S2.T1.st2.1.1.1.1.1.m1.1.1" xref="S2.T1.st2.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S2.T1.st2.1.1.1.1.1.m1.1b"><ci id="S2.T1.st2.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.st2.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.st2.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.st2.1.1.2.1" class="ltx_tr" style="background-color:#000000;">
<td id="S2.T1.st2.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st2.1.1.2.1.1.1" class="ltx_text" style="background-color:#000000;">500</span></td>
<td id="S2.T1.st2.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st2.1.1.2.1.2.1" class="ltx_text" style="background-color:#000000;">0</span></td>
<td id="S2.T1.st2.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st2.1.1.2.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">5.27</span></td>
</tr>
<tr id="S2.T1.st2.1.1.3.2" class="ltx_tr">
<td id="S2.T1.st2.1.1.3.2.1" class="ltx_td ltx_align_center">0</td>
<td id="S2.T1.st2.1.1.3.2.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st2.1.1.3.2.3" class="ltx_td ltx_align_center">38.39</td>
</tr>
<tr id="S2.T1.st2.1.1.4.3" class="ltx_tr">
<td id="S2.T1.st2.1.1.4.3.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st2.1.1.4.3.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st2.1.1.4.3.3" class="ltx_td ltx_align_center">22.58</td>
</tr>
<tr id="S2.T1.st2.1.1.5.4" class="ltx_tr">
<td id="S2.T1.st2.1.1.5.4.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st2.1.1.5.4.2" class="ltx_td ltx_align_center">1000</td>
<td id="S2.T1.st2.1.1.5.4.3" class="ltx_td ltx_align_center">30.39</td>
</tr>
<tr id="S2.T1.st2.1.1.6.5" class="ltx_tr">
<td id="S2.T1.st2.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_bb">1000</td>
<td id="S2.T1.st2.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb">500</td>
<td id="S2.T1.st2.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">16.72</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.st2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S2.T1.st2.4.2" class="ltx_text" style="font-size:90%;">FATD</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.T1.st3" class="ltx_table ltx_figure_panel ltx_align_center">
<div id="S2.T1.st3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:240.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(119.3pt,-66.1pt) scale(2.22368967258981,2.22368967258981) ;">
<table id="S2.T1.st3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.st3.1.1.1" class="ltx_tr">
<th id="S2.T1.st3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st3.1.1.1.2.1" class="ltx_text ltx_font_bold">True Pairs</span></th>
<th id="S2.T1.st3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st3.1.1.1.3.1" class="ltx_text ltx_font_bold">False Pairs</span></th>
<th id="S2.T1.st3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.st3.1.1.1.1.1" class="ltx_text ltx_font_bold">FA(VT)D (<math id="S2.T1.st3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S2.T1.st3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S2.T1.st3.1.1.1.1.1.m1.1.1" xref="S2.T1.st3.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S2.T1.st3.1.1.1.1.1.m1.1b"><ci id="S2.T1.st3.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.st3.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.st3.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.st3.1.1.2.1" class="ltx_tr" style="background-color:#000000;">
<td id="S2.T1.st3.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st3.1.1.2.1.1.1" class="ltx_text" style="background-color:#000000;">500</span></td>
<td id="S2.T1.st3.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st3.1.1.2.1.2.1" class="ltx_text" style="background-color:#000000;">0</span></td>
<td id="S2.T1.st3.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.st3.1.1.2.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">8.75</span></td>
</tr>
<tr id="S2.T1.st3.1.1.3.2" class="ltx_tr">
<td id="S2.T1.st3.1.1.3.2.1" class="ltx_td ltx_align_center">0</td>
<td id="S2.T1.st3.1.1.3.2.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st3.1.1.3.2.3" class="ltx_td ltx_align_center">42.19</td>
</tr>
<tr id="S2.T1.st3.1.1.4.3" class="ltx_tr">
<td id="S2.T1.st3.1.1.4.3.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st3.1.1.4.3.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st3.1.1.4.3.3" class="ltx_td ltx_align_center">26.47</td>
</tr>
<tr id="S2.T1.st3.1.1.5.4" class="ltx_tr">
<td id="S2.T1.st3.1.1.5.4.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T1.st3.1.1.5.4.2" class="ltx_td ltx_align_center">1000</td>
<td id="S2.T1.st3.1.1.5.4.3" class="ltx_td ltx_align_center">33.98</td>
</tr>
<tr id="S2.T1.st3.1.1.6.5" class="ltx_tr">
<td id="S2.T1.st3.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_bb">1000</td>
<td id="S2.T1.st3.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb">500</td>
<td id="S2.T1.st3.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">21.33</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.st3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S2.T1.st3.4.2" class="ltx_text" style="font-size:90%;">FA(VT)D</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.4.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Visual alignment validation<span id="S2.T1.5.2.1" class="ltx_text ltx_font_medium"> of all metrics in our <span id="S2.T1.5.2.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span>.</span></span></figcaption>
</figure>
<figure id="S2.T2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.T2.st1" class="ltx_table ltx_figure_panel ltx_align_center">
<div id="S2.T2.st1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:222.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(94.8pt,-57.3pt) scale(2.06038081062465,2.06038081062465) ;">
<table id="S2.T2.st1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T2.st1.1.1.1" class="ltx_tr">
<th id="S2.T2.st1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.st1.1.1.1.2.1" class="ltx_text ltx_font_bold">True Pairs</span></th>
<th id="S2.T2.st1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.st1.1.1.1.3.1" class="ltx_text ltx_font_bold">False Pairs</span></th>
<th id="S2.T2.st1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.st1.1.1.1.1.1" class="ltx_text ltx_font_bold">FAVD (<math id="S2.T2.st1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S2.T2.st1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S2.T2.st1.1.1.1.1.1.m1.1.1" xref="S2.T2.st1.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S2.T2.st1.1.1.1.1.1.m1.1b"><ci id="S2.T2.st1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T2.st1.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.st1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T2.st1.1.1.2.1" class="ltx_tr" style="background-color:#000000;">
<td id="S2.T2.st1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.st1.1.1.2.1.1.1" class="ltx_text" style="background-color:#000000;">500</span></td>
<td id="S2.T2.st1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.st1.1.1.2.1.2.1" class="ltx_text" style="background-color:#000000;">0</span></td>
<td id="S2.T2.st1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.st1.1.1.2.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">12.85</span></td>
</tr>
<tr id="S2.T2.st1.1.1.3.2" class="ltx_tr">
<td id="S2.T2.st1.1.1.3.2.1" class="ltx_td ltx_align_center">0</td>
<td id="S2.T2.st1.1.1.3.2.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T2.st1.1.1.3.2.3" class="ltx_td ltx_align_center">49.73</td>
</tr>
<tr id="S2.T2.st1.1.1.4.3" class="ltx_tr">
<td id="S2.T2.st1.1.1.4.3.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T2.st1.1.1.4.3.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T2.st1.1.1.4.3.3" class="ltx_td ltx_align_center">32.95</td>
</tr>
<tr id="S2.T2.st1.1.1.5.4" class="ltx_tr">
<td id="S2.T2.st1.1.1.5.4.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T2.st1.1.1.5.4.2" class="ltx_td ltx_align_center">1000</td>
<td id="S2.T2.st1.1.1.5.4.3" class="ltx_td ltx_align_center">39.06</td>
</tr>
<tr id="S2.T2.st1.1.1.6.5" class="ltx_tr">
<td id="S2.T2.st1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_bb">1000</td>
<td id="S2.T2.st1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb">500</td>
<td id="S2.T2.st1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">25.98</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.st1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S2.T2.st1.4.2" class="ltx_text" style="font-size:90%;">Random selection within the same classes.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.T2.st2" class="ltx_table ltx_figure_panel ltx_align_center">
<div id="S2.T2.st2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:222.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(94.8pt,-57.3pt) scale(2.06038081062465,2.06038081062465) ;">
<table id="S2.T2.st2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T2.st2.1.1.1" class="ltx_tr">
<th id="S2.T2.st2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.st2.1.1.1.2.1" class="ltx_text ltx_font_bold">True Pairs</span></th>
<th id="S2.T2.st2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.st2.1.1.1.3.1" class="ltx_text ltx_font_bold">False Pairs</span></th>
<th id="S2.T2.st2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.st2.1.1.1.1.1" class="ltx_text ltx_font_bold">FAVD (<math id="S2.T2.st2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S2.T2.st2.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S2.T2.st2.1.1.1.1.1.m1.1.1" xref="S2.T2.st2.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S2.T2.st2.1.1.1.1.1.m1.1b"><ci id="S2.T2.st2.1.1.1.1.1.m1.1.1.cmml" xref="S2.T2.st2.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.st2.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T2.st2.1.1.2.1" class="ltx_tr" style="background-color:#000000;">
<td id="S2.T2.st2.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.st2.1.1.2.1.1.1" class="ltx_text" style="background-color:#000000;">500</span></td>
<td id="S2.T2.st2.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.st2.1.1.2.1.2.1" class="ltx_text" style="background-color:#000000;">0</span></td>
<td id="S2.T2.st2.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.st2.1.1.2.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">12.85</span></td>
</tr>
<tr id="S2.T2.st2.1.1.3.2" class="ltx_tr">
<td id="S2.T2.st2.1.1.3.2.1" class="ltx_td ltx_align_center">0</td>
<td id="S2.T2.st2.1.1.3.2.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T2.st2.1.1.3.2.3" class="ltx_td ltx_align_center">56.21</td>
</tr>
<tr id="S2.T2.st2.1.1.4.3" class="ltx_tr">
<td id="S2.T2.st2.1.1.4.3.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T2.st2.1.1.4.3.2" class="ltx_td ltx_align_center">500</td>
<td id="S2.T2.st2.1.1.4.3.3" class="ltx_td ltx_align_center">35.36</td>
</tr>
<tr id="S2.T2.st2.1.1.5.4" class="ltx_tr">
<td id="S2.T2.st2.1.1.5.4.1" class="ltx_td ltx_align_center">500</td>
<td id="S2.T2.st2.1.1.5.4.2" class="ltx_td ltx_align_center">1000</td>
<td id="S2.T2.st2.1.1.5.4.3" class="ltx_td ltx_align_center">45.17</td>
</tr>
<tr id="S2.T2.st2.1.1.6.5" class="ltx_tr">
<td id="S2.T2.st2.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_bb">1000</td>
<td id="S2.T2.st2.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb">500</td>
<td id="S2.T2.st2.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb">27.59</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.st2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S2.T2.st2.4.2" class="ltx_text" style="font-size:90%;">Random shift audio within the same pairs.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.4.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S2.T2.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Temporal consistency validation<span id="S2.T2.5.2.1" class="ltx_text ltx_font_medium"> of Frechet Audio-Video Distance in our <span id="S2.T2.5.2.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span>.</span></span></figcaption>
</figure>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Text-to-Audio Generation.</span>
Text-to-audio (TTA) generation aims to develop the generative model in audio space to synthesize audio signals based on text prompts.
This task is attracting increased attention, with several works appearing in recent two years.
For instance, DiffSound <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite> employs a discrete diffusion process to convert audio codes from VQ-VAE into sounds. AudioGen <cite class="ltx_cite ltx_citemacro_citep">(Kreuk et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>, on the other hand, uses a two-stage process involving a neural audio compression model and an autoregressive Transformer. Additionally, Latent Diffusion Models, seen in text-to-audio systems, promise superior sound synthesis <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>; Huang et al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>)</cite>. These advanced TTA methods can now generate sounds that align with linguistic prompts with the help of cutting-edge generative models. However, a salient challenge emerges when audio is merged with video: temporal synchronization. The sounds, though of impressive quality, often don’t temporally match the visual scenes. To bridge this gap, in this work, we develop a novel TTA generation method with visual alignment based on LDMs by integrating temporal visual features with audio-visual ControlNet modules.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> &amp; Metrics</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we propose a new benchmark, namely <span id="S3.p1.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span>, for video-aligned text-to-audio generation that can achieve both visual alignment and temporal consistency.
Furthermore, we present three novel metrics for the evaluation of the quality of our generated audio.
Finally, we also perform simulation experiments to validate the effectiveness of the proposed metrics for assessing visual alignment and temporal consistency.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Benchmark Details</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In order to evaluate video-aligned text-to-audio generation, we develop a new dataset consisting of 500 video-text pairs.
Specifically, we downloaded all videos from 5,158 samples in the test set of VGGSound <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite>.
For each video, we use the class label with object and action tagging as the text caption, such as “cat hissing” and “female singing”.
Based on the current video-text pairs, we curate 500 pairs by keeping videos with single source objects, temporal matching, and non-noisy backgrounds.
With 500 video-text pairs, we extract audio clips with a length of ten seconds for each video according to the starting timestamp in the original annotated information from VGGSound <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2403.07938/assets/x1.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="187" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Illustration of the proposed framework for Text-to-audio generation aligned with videos (T2AV).<span id="S3.F2.4.2.1" class="ltx_text ltx_font_medium">
The Audio-Visual ControlNet aggregates temporal video features as the condition in the text-based latent diffusion models.
Then, a contrastive language-audio pretraining objective across each temporal location is applied to match visual-aligned text embeddings with audio features.
After visual-aligned CLAP pre-training, we directly extract text embeddings with Audio-Visual ControlNet as the condition for latent diffusion models to achieve Text-to-Audio generation with visual alignment and temporal consistency.
</span></span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Metrics Details</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Similar to Frechet inception distance (FID) to assess the quality of images and Frechet audio distance (FAD) for audio, we present three new metrics to evaluate the visual alignment and temporal consistency of generated audio in our video-aligned TTA generation.
1) <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">Frechet Audio-Visual Distance (FAVD)</span>: compares the distribution of generated audio with the distribution of a set of real videos.
Specifically, we calculate the distance between audio embeddings from VGGish <cite class="ltx_cite ltx_citemacro_citep">(Hershey et al., <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite> and video embeddings from C3D <cite class="ltx_cite ltx_citemacro_citep">(Tran et al., <a href="#bib.bib46" title="" class="ltx_ref">2015</a>)</cite>.
2) <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_bold">Frechet Audio-Text Distance (FATD)</span>: evaluates the distribution of generated audio with the distribution of a set of tagging texts, where we compute the distance between audio embeddings from VGGish <cite class="ltx_cite ltx_citemacro_citep">(Hershey et al., <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite> and text embeddings from word2vec <cite class="ltx_cite ltx_citemacro_citep">(Mikolov et al., <a href="#bib.bib20" title="" class="ltx_ref">2013</a>)</cite> using the tagging class label.
3) <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_bold">Frechet Audio-(Video-Text) Distance (FAVTD)</span>: compares the distribution of generated audio with the distribution of a set of both videos and tagging texts, where we compute the distance between audio embeddings from VGGish <cite class="ltx_cite ltx_citemacro_citep">(Hershey et al., <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite> and an averaged embeddings of video embeddings from VGGish <cite class="ltx_cite ltx_citemacro_citep">(Hershey et al., <a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite> and text embeddings from word2vec <cite class="ltx_cite ltx_citemacro_citep">(Mikolov et al., <a href="#bib.bib20" title="" class="ltx_ref">2013</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Metrics Validation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In order to demonstrate the efficiency of the proposed metrics for the evaluation of visual alignment and temporal consistency, we perform simulation experiments by computing the metrics from matching (true) video-text pairs and mismatching (false) pairs.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Visual Alignment.</span>
For visual alignment, we compute all metrics, including FAVD, FATD, FA(VT)D by using 500 matching (true) video-text pairs and 500 randomly selected mismatching (false) pairs in our <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span>, and 500 matching (true) video-text pairs randomly selected from AudioCaps <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>.
The quantitative results are reported in Table <a href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
With the increase in the number of false pairs with mismatching visual information, all metrics increase.
Adding 500 true pairs to [500, 500] cases further decreases all metrics.
These results validate the effectiveness of the proposed metrics in evaluating visual alignment.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold">Temporal Consistency.</span>
For temporal consistency, we conduct two sub-experiments to compare changes in FAVD scores. First, we randomly select 500 videos from the same classes in VGGSound <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite>.
Second, we perform random shift audio from the same pair in our <span id="S3.SS3.p3.1.2" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span>.
Table <a href="#S2.T2" title="Table 2 ‣ 2 Related Work ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the comparison results on our <span id="S3.SS3.p3.1.3" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> in terms of FAVD scores.
As can be seen, the FAVD score rises with the increase in the number of false pairs with mismatching temporal consistency, although they share the same visual information.
Adding 500 additional true pairs from VGGSound <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> to [500, 500] cases also decreases FAVD scores, which further shows the importance of the proposed metrics in assessing temporal consistency together with visual alignment.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Method</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Given video frames and a text prompt, our aim is to synthesize an audio aligned with textual and visual semantics.
We propose a novel TTA generation approach based on LDMs personalized with visual alignment, named DiffAVA, which consists of two main modules, Visual-aligned CLAP in Section <a href="#S4.SS2" title="4.2 Visual-aligned CLAP ‣ 4 Method ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> and Audio-Visual ControlNet in Section <a href="#S4.SS3" title="4.3 Audio-Visual ControlNet ‣ 4 Method ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Preliminaries</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In this section, we first describe the problem setup and notations and then revisit conditional latent diffusion models in AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> for TTA generation.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.11" class="ltx_p"><span id="S4.SS1.p2.11.1" class="ltx_text ltx_font_bold">Problem Setup and Notations.</span>
Given audio <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">a</annotation></semantics></math> and visual frames <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mi id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">v</annotation></semantics></math> from a video and a text prompt <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mi id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><ci id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">t</annotation></semantics></math>, the goal is to generate new audio aligned with textual and visual semantics.
For a video, we have the mel-spectrogram of audio denoted as <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{A}\in\mathbb{R}^{T\times F}" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mrow id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">𝐀</mi><mo id="S4.SS1.p2.4.m4.1.1.1" xref="S4.SS1.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3.cmml"><mi id="S4.SS1.p2.4.m4.1.1.3.2" xref="S4.SS1.p2.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p2.4.m4.1.1.3.3" xref="S4.SS1.p2.4.m4.1.1.3.3.cmml"><mi id="S4.SS1.p2.4.m4.1.1.3.3.2" xref="S4.SS1.p2.4.m4.1.1.3.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.4.m4.1.1.3.3.1" xref="S4.SS1.p2.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S4.SS1.p2.4.m4.1.1.3.3.3" xref="S4.SS1.p2.4.m4.1.1.3.3.3.cmml">F</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><in id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1.1"></in><ci id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">𝐀</ci><apply id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.4.m4.1.1.3.1.cmml" xref="S4.SS1.p2.4.m4.1.1.3">superscript</csymbol><ci id="S4.SS1.p2.4.m4.1.1.3.2.cmml" xref="S4.SS1.p2.4.m4.1.1.3.2">ℝ</ci><apply id="S4.SS1.p2.4.m4.1.1.3.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3.3"><times id="S4.SS1.p2.4.m4.1.1.3.3.1.cmml" xref="S4.SS1.p2.4.m4.1.1.3.3.1"></times><ci id="S4.SS1.p2.4.m4.1.1.3.3.2.cmml" xref="S4.SS1.p2.4.m4.1.1.3.3.2">𝑇</ci><ci id="S4.SS1.p2.4.m4.1.1.3.3.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3.3.3">𝐹</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">\mathbf{A}\in\mathbb{R}^{T\times F}</annotation></semantics></math>, and visual frames denoted as <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{V}\in\mathbb{R}^{T\times H\times W\times 3}" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mrow id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml"><mi id="S4.SS1.p2.5.m5.1.1.2" xref="S4.SS1.p2.5.m5.1.1.2.cmml">𝐕</mi><mo id="S4.SS1.p2.5.m5.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.cmml">∈</mo><msup id="S4.SS1.p2.5.m5.1.1.3" xref="S4.SS1.p2.5.m5.1.1.3.cmml"><mi id="S4.SS1.p2.5.m5.1.1.3.2" xref="S4.SS1.p2.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p2.5.m5.1.1.3.3" xref="S4.SS1.p2.5.m5.1.1.3.3.cmml"><mi id="S4.SS1.p2.5.m5.1.1.3.3.2" xref="S4.SS1.p2.5.m5.1.1.3.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.5.m5.1.1.3.3.1" xref="S4.SS1.p2.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S4.SS1.p2.5.m5.1.1.3.3.3" xref="S4.SS1.p2.5.m5.1.1.3.3.3.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.5.m5.1.1.3.3.1a" xref="S4.SS1.p2.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S4.SS1.p2.5.m5.1.1.3.3.4" xref="S4.SS1.p2.5.m5.1.1.3.3.4.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.5.m5.1.1.3.3.1b" xref="S4.SS1.p2.5.m5.1.1.3.3.1.cmml">×</mo><mn id="S4.SS1.p2.5.m5.1.1.3.3.5" xref="S4.SS1.p2.5.m5.1.1.3.3.5.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><apply id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1"><in id="S4.SS1.p2.5.m5.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1"></in><ci id="S4.SS1.p2.5.m5.1.1.2.cmml" xref="S4.SS1.p2.5.m5.1.1.2">𝐕</ci><apply id="S4.SS1.p2.5.m5.1.1.3.cmml" xref="S4.SS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.5.m5.1.1.3.1.cmml" xref="S4.SS1.p2.5.m5.1.1.3">superscript</csymbol><ci id="S4.SS1.p2.5.m5.1.1.3.2.cmml" xref="S4.SS1.p2.5.m5.1.1.3.2">ℝ</ci><apply id="S4.SS1.p2.5.m5.1.1.3.3.cmml" xref="S4.SS1.p2.5.m5.1.1.3.3"><times id="S4.SS1.p2.5.m5.1.1.3.3.1.cmml" xref="S4.SS1.p2.5.m5.1.1.3.3.1"></times><ci id="S4.SS1.p2.5.m5.1.1.3.3.2.cmml" xref="S4.SS1.p2.5.m5.1.1.3.3.2">𝑇</ci><ci id="S4.SS1.p2.5.m5.1.1.3.3.3.cmml" xref="S4.SS1.p2.5.m5.1.1.3.3.3">𝐻</ci><ci id="S4.SS1.p2.5.m5.1.1.3.3.4.cmml" xref="S4.SS1.p2.5.m5.1.1.3.3.4">𝑊</ci><cn type="integer" id="S4.SS1.p2.5.m5.1.1.3.3.5.cmml" xref="S4.SS1.p2.5.m5.1.1.3.3.5">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">\mathbf{V}\in\mathbb{R}^{T\times H\times W\times 3}</annotation></semantics></math>.
<math id="S4.SS1.p2.6.m6.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS1.p2.6.m6.1a"><mi id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><ci id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">T</annotation></semantics></math> and <math id="S4.SS1.p2.7.m7.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S4.SS1.p2.7.m7.1a"><mi id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><ci id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1">𝐹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m7.1c">F</annotation></semantics></math> denote the time and frequency, respectively.
We extract text features <math id="S4.SS1.p2.8.m8.1" class="ltx_Math" alttext="\mathbf{F}^{t}" display="inline"><semantics id="S4.SS1.p2.8.m8.1a"><msup id="S4.SS1.p2.8.m8.1.1" xref="S4.SS1.p2.8.m8.1.1.cmml"><mi id="S4.SS1.p2.8.m8.1.1.2" xref="S4.SS1.p2.8.m8.1.1.2.cmml">𝐅</mi><mi id="S4.SS1.p2.8.m8.1.1.3" xref="S4.SS1.p2.8.m8.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m8.1b"><apply id="S4.SS1.p2.8.m8.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.8.m8.1.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1">superscript</csymbol><ci id="S4.SS1.p2.8.m8.1.1.2.cmml" xref="S4.SS1.p2.8.m8.1.1.2">𝐅</ci><ci id="S4.SS1.p2.8.m8.1.1.3.cmml" xref="S4.SS1.p2.8.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m8.1c">\mathbf{F}^{t}</annotation></semantics></math> and audio features <math id="S4.SS1.p2.9.m9.1" class="ltx_Math" alttext="\mathbf{F}^{a}" display="inline"><semantics id="S4.SS1.p2.9.m9.1a"><msup id="S4.SS1.p2.9.m9.1.1" xref="S4.SS1.p2.9.m9.1.1.cmml"><mi id="S4.SS1.p2.9.m9.1.1.2" xref="S4.SS1.p2.9.m9.1.1.2.cmml">𝐅</mi><mi id="S4.SS1.p2.9.m9.1.1.3" xref="S4.SS1.p2.9.m9.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.9.m9.1b"><apply id="S4.SS1.p2.9.m9.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.9.m9.1.1.1.cmml" xref="S4.SS1.p2.9.m9.1.1">superscript</csymbol><ci id="S4.SS1.p2.9.m9.1.1.2.cmml" xref="S4.SS1.p2.9.m9.1.1.2">𝐅</ci><ci id="S4.SS1.p2.9.m9.1.1.3.cmml" xref="S4.SS1.p2.9.m9.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.9.m9.1c">\mathbf{F}^{a}</annotation></semantics></math> from pre-trained text encoder <math id="S4.SS1.p2.10.m10.1" class="ltx_Math" alttext="f_{t}(\cdot)" display="inline"><semantics id="S4.SS1.p2.10.m10.1a"><mrow id="S4.SS1.p2.10.m10.1.2" xref="S4.SS1.p2.10.m10.1.2.cmml"><msub id="S4.SS1.p2.10.m10.1.2.2" xref="S4.SS1.p2.10.m10.1.2.2.cmml"><mi id="S4.SS1.p2.10.m10.1.2.2.2" xref="S4.SS1.p2.10.m10.1.2.2.2.cmml">f</mi><mi id="S4.SS1.p2.10.m10.1.2.2.3" xref="S4.SS1.p2.10.m10.1.2.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p2.10.m10.1.2.1" xref="S4.SS1.p2.10.m10.1.2.1.cmml">​</mo><mrow id="S4.SS1.p2.10.m10.1.2.3.2" xref="S4.SS1.p2.10.m10.1.2.cmml"><mo stretchy="false" id="S4.SS1.p2.10.m10.1.2.3.2.1" xref="S4.SS1.p2.10.m10.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.SS1.p2.10.m10.1.1" xref="S4.SS1.p2.10.m10.1.1.cmml">⋅</mo><mo stretchy="false" id="S4.SS1.p2.10.m10.1.2.3.2.2" xref="S4.SS1.p2.10.m10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.10.m10.1b"><apply id="S4.SS1.p2.10.m10.1.2.cmml" xref="S4.SS1.p2.10.m10.1.2"><times id="S4.SS1.p2.10.m10.1.2.1.cmml" xref="S4.SS1.p2.10.m10.1.2.1"></times><apply id="S4.SS1.p2.10.m10.1.2.2.cmml" xref="S4.SS1.p2.10.m10.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.10.m10.1.2.2.1.cmml" xref="S4.SS1.p2.10.m10.1.2.2">subscript</csymbol><ci id="S4.SS1.p2.10.m10.1.2.2.2.cmml" xref="S4.SS1.p2.10.m10.1.2.2.2">𝑓</ci><ci id="S4.SS1.p2.10.m10.1.2.2.3.cmml" xref="S4.SS1.p2.10.m10.1.2.2.3">𝑡</ci></apply><ci id="S4.SS1.p2.10.m10.1.1.cmml" xref="S4.SS1.p2.10.m10.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.10.m10.1c">f_{t}(\cdot)</annotation></semantics></math> and pre-trained audio encoder <math id="S4.SS1.p2.11.m11.1" class="ltx_Math" alttext="f_{a}(\cdot)" display="inline"><semantics id="S4.SS1.p2.11.m11.1a"><mrow id="S4.SS1.p2.11.m11.1.2" xref="S4.SS1.p2.11.m11.1.2.cmml"><msub id="S4.SS1.p2.11.m11.1.2.2" xref="S4.SS1.p2.11.m11.1.2.2.cmml"><mi id="S4.SS1.p2.11.m11.1.2.2.2" xref="S4.SS1.p2.11.m11.1.2.2.2.cmml">f</mi><mi id="S4.SS1.p2.11.m11.1.2.2.3" xref="S4.SS1.p2.11.m11.1.2.2.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p2.11.m11.1.2.1" xref="S4.SS1.p2.11.m11.1.2.1.cmml">​</mo><mrow id="S4.SS1.p2.11.m11.1.2.3.2" xref="S4.SS1.p2.11.m11.1.2.cmml"><mo stretchy="false" id="S4.SS1.p2.11.m11.1.2.3.2.1" xref="S4.SS1.p2.11.m11.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.SS1.p2.11.m11.1.1" xref="S4.SS1.p2.11.m11.1.1.cmml">⋅</mo><mo stretchy="false" id="S4.SS1.p2.11.m11.1.2.3.2.2" xref="S4.SS1.p2.11.m11.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.11.m11.1b"><apply id="S4.SS1.p2.11.m11.1.2.cmml" xref="S4.SS1.p2.11.m11.1.2"><times id="S4.SS1.p2.11.m11.1.2.1.cmml" xref="S4.SS1.p2.11.m11.1.2.1"></times><apply id="S4.SS1.p2.11.m11.1.2.2.cmml" xref="S4.SS1.p2.11.m11.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.11.m11.1.2.2.1.cmml" xref="S4.SS1.p2.11.m11.1.2.2">subscript</csymbol><ci id="S4.SS1.p2.11.m11.1.2.2.2.cmml" xref="S4.SS1.p2.11.m11.1.2.2.2">𝑓</ci><ci id="S4.SS1.p2.11.m11.1.2.2.3.cmml" xref="S4.SS1.p2.11.m11.1.2.2.3">𝑎</ci></apply><ci id="S4.SS1.p2.11.m11.1.1.cmml" xref="S4.SS1.p2.11.m11.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.11.m11.1c">f_{a}(\cdot)</annotation></semantics></math> from CLAP <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:495.9pt;height:97.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.6pt,5.4pt) scale(0.9,0.9) ;">
<table id="S4.T3.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.7.7.7" class="ltx_tr">
<th id="S4.T3.7.7.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.7.8.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">FD (<math id="S4.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T3.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.2.2.2.2.1" class="ltx_text ltx_font_bold">IS (<math id="S4.T3.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T3.2.2.2.2.1.m1.1.1" xref="S4.T3.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th id="S4.T3.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.3.3.3.3.1" class="ltx_text ltx_font_bold">KL (<math id="S4.T3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T3.3.3.3.3.1.m1.1.1" xref="S4.T3.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.1.m1.1b"><ci id="S4.T3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T3.4.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.4.4.4.4.1" class="ltx_text ltx_font_bold">FAD (<math id="S4.T3.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T3.4.4.4.4.1.m1.1.1" xref="S4.T3.4.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.4.1.m1.1b"><ci id="S4.T3.4.4.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T3.5.5.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.5.5.5.5.1" class="ltx_text ltx_font_bold">FAVD (<math id="S4.T3.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.5.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T3.5.5.5.5.1.m1.1.1" xref="S4.T3.5.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.5.1.m1.1b"><ci id="S4.T3.5.5.5.5.1.m1.1.1.cmml" xref="S4.T3.5.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T3.6.6.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.6.6.6.6.1" class="ltx_text ltx_font_bold">FATD (<math id="S4.T3.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.6.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T3.6.6.6.6.1.m1.1.1" xref="S4.T3.6.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.6.1.m1.1b"><ci id="S4.T3.6.6.6.6.1.m1.1.1.cmml" xref="S4.T3.6.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T3.7.7.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.7.7.1" class="ltx_text ltx_font_bold">FA(VT)D (<math id="S4.T3.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.7.7.7.7.1.m1.1a"><mo stretchy="false" id="S4.T3.7.7.7.7.1.m1.1.1" xref="S4.T3.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.7.7.1.m1.1b"><ci id="S4.T3.7.7.7.7.1.m1.1.1.cmml" xref="S4.T3.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.7.7.8.1" class="ltx_tr">
<th id="S4.T3.7.7.8.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">SpecVQGAN <cite class="ltx_cite ltx_citemacro_citep">(Iashin &amp; Rahtu, <a href="#bib.bib10" title="" class="ltx_ref">2021a</a>)</cite>
</th>
<td id="S4.T3.7.7.8.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">47.72</td>
<td id="S4.T3.7.7.8.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">3.86</td>
<td id="S4.T3.7.7.8.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">7.53</td>
<td id="S4.T3.7.7.8.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">9.72</td>
<td id="S4.T3.7.7.8.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">38.12</td>
<td id="S4.T3.7.7.8.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">23.58</td>
<td id="S4.T3.7.7.8.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">29.16</td>
</tr>
<tr id="S4.T3.7.7.9.2" class="ltx_tr">
<th id="S4.T3.7.7.9.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">MMDiffusion <cite class="ltx_cite ltx_citemacro_citep">(Ruan et al., <a href="#bib.bib39" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S4.T3.7.7.9.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">46.38</td>
<td id="S4.T3.7.7.9.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">4.53</td>
<td id="S4.T3.7.7.9.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">6.92</td>
<td id="S4.T3.7.7.9.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">8.36</td>
<td id="S4.T3.7.7.9.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">36.15</td>
<td id="S4.T3.7.7.9.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">21.73</td>
<td id="S4.T3.7.7.9.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">28.75</td>
</tr>
<tr id="S4.T3.7.7.10.3" class="ltx_tr">
<th id="S4.T3.7.7.10.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">AudioGen <cite class="ltx_cite ltx_citemacro_citep">(Kreuk et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S4.T3.7.7.10.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">45.72</td>
<td id="S4.T3.7.7.10.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">4.61</td>
<td id="S4.T3.7.7.10.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">6.53</td>
<td id="S4.T3.7.7.10.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">7.82</td>
<td id="S4.T3.7.7.10.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">35.56</td>
<td id="S4.T3.7.7.10.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">21.36</td>
<td id="S4.T3.7.7.10.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">28.02</td>
</tr>
<tr id="S4.T3.7.7.11.4" class="ltx_tr">
<th id="S4.T3.7.7.11.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S4.T3.7.7.11.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">42.59</td>
<td id="S4.T3.7.7.11.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">4.82</td>
<td id="S4.T3.7.7.11.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">5.72</td>
<td id="S4.T3.7.7.11.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">6.25</td>
<td id="S4.T3.7.7.11.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">33.76</td>
<td id="S4.T3.7.7.11.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">19.52</td>
<td id="S4.T3.7.7.11.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">26.37</td>
</tr>
<tr id="S4.T3.7.7.12.5" class="ltx_tr" style="background-color:#000000;">
<th id="S4.T3.7.7.12.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.12.5.1.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">T2AV (ours)</span></th>
<td id="S4.T3.7.7.12.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.12.5.2.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">33.29</span></td>
<td id="S4.T3.7.7.12.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.12.5.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">8.02</span></td>
<td id="S4.T3.7.7.12.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.12.5.4.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">2.12</span></td>
<td id="S4.T3.7.7.12.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.12.5.5.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">4.05</span></td>
<td id="S4.T3.7.7.12.5.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.12.5.6.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">24.03</span></td>
<td id="S4.T3.7.7.12.5.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.12.5.7.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">13.16</span></td>
<td id="S4.T3.7.7.12.5.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T3.7.7.12.5.8.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">17.82</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.12.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.13.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Quantitative results of video-aligned text-to-audio generation on <span id="S4.T3.13.2.1" class="ltx_text ltx_font_medium ltx_font_smallcaps">T2AV-Bench</span>.<span id="S4.T3.13.2.2" class="ltx_text ltx_font_medium"> Our method significantly outperforms
previous baselines in terms of all metrics.</span></span></figcaption>
</figure>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.4" class="ltx_p"><span id="S4.SS1.p3.4.1" class="ltx_text ltx_font_bold">Revisit AudioLDM.</span>
To address the TTA generation problem, AudioLDM introduced a conditional latent diffusion model to estimate the noise <math id="S4.SS1.p3.1.m1.3" class="ltx_Math" alttext="\bm{\epsilon}(\bm{z}_{n},n,\mathbf{F}^{t})" display="inline"><semantics id="S4.SS1.p3.1.m1.3a"><mrow id="S4.SS1.p3.1.m1.3.3" xref="S4.SS1.p3.1.m1.3.3.cmml"><mi class="ltx_mathvariant_bold-italic" mathvariant="bold-italic" id="S4.SS1.p3.1.m1.3.3.4" xref="S4.SS1.p3.1.m1.3.3.4.cmml">ϵ</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p3.1.m1.3.3.3" xref="S4.SS1.p3.1.m1.3.3.3.cmml">​</mo><mrow id="S4.SS1.p3.1.m1.3.3.2.2" xref="S4.SS1.p3.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S4.SS1.p3.1.m1.3.3.2.2.3" xref="S4.SS1.p3.1.m1.3.3.2.3.cmml">(</mo><msub id="S4.SS1.p3.1.m1.2.2.1.1.1" xref="S4.SS1.p3.1.m1.2.2.1.1.1.cmml"><mi id="S4.SS1.p3.1.m1.2.2.1.1.1.2" xref="S4.SS1.p3.1.m1.2.2.1.1.1.2.cmml">𝒛</mi><mi id="S4.SS1.p3.1.m1.2.2.1.1.1.3" xref="S4.SS1.p3.1.m1.2.2.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS1.p3.1.m1.3.3.2.2.4" xref="S4.SS1.p3.1.m1.3.3.2.3.cmml">,</mo><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">n</mi><mo id="S4.SS1.p3.1.m1.3.3.2.2.5" xref="S4.SS1.p3.1.m1.3.3.2.3.cmml">,</mo><msup id="S4.SS1.p3.1.m1.3.3.2.2.2" xref="S4.SS1.p3.1.m1.3.3.2.2.2.cmml"><mi id="S4.SS1.p3.1.m1.3.3.2.2.2.2" xref="S4.SS1.p3.1.m1.3.3.2.2.2.2.cmml">𝐅</mi><mi id="S4.SS1.p3.1.m1.3.3.2.2.2.3" xref="S4.SS1.p3.1.m1.3.3.2.2.2.3.cmml">t</mi></msup><mo stretchy="false" id="S4.SS1.p3.1.m1.3.3.2.2.6" xref="S4.SS1.p3.1.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.3b"><apply id="S4.SS1.p3.1.m1.3.3.cmml" xref="S4.SS1.p3.1.m1.3.3"><times id="S4.SS1.p3.1.m1.3.3.3.cmml" xref="S4.SS1.p3.1.m1.3.3.3"></times><ci id="S4.SS1.p3.1.m1.3.3.4.cmml" xref="S4.SS1.p3.1.m1.3.3.4">bold-italic-ϵ</ci><vector id="S4.SS1.p3.1.m1.3.3.2.3.cmml" xref="S4.SS1.p3.1.m1.3.3.2.2"><apply id="S4.SS1.p3.1.m1.2.2.1.1.1.cmml" xref="S4.SS1.p3.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.2.2.1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.1.m1.2.2.1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.2.2.1.1.1.2">𝒛</ci><ci id="S4.SS1.p3.1.m1.2.2.1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.2.2.1.1.1.3">𝑛</ci></apply><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">𝑛</ci><apply id="S4.SS1.p3.1.m1.3.3.2.2.2.cmml" xref="S4.SS1.p3.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.3.3.2.2.2.1.cmml" xref="S4.SS1.p3.1.m1.3.3.2.2.2">superscript</csymbol><ci id="S4.SS1.p3.1.m1.3.3.2.2.2.2.cmml" xref="S4.SS1.p3.1.m1.3.3.2.2.2.2">𝐅</ci><ci id="S4.SS1.p3.1.m1.3.3.2.2.2.3.cmml" xref="S4.SS1.p3.1.m1.3.3.2.2.2.3">𝑡</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.3c">\bm{\epsilon}(\bm{z}_{n},n,\mathbf{F}^{t})</annotation></semantics></math> from the audio prior <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="\bm{z}_{0}\in\mathbb{R}^{C\times\frac{T}{r}\times\frac{F}{r}}" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mrow id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><msub id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2.2" xref="S4.SS1.p3.2.m2.1.1.2.2.cmml">𝒛</mi><mn id="S4.SS1.p3.2.m2.1.1.2.3" xref="S4.SS1.p3.2.m2.1.1.2.3.cmml">0</mn></msub><mo id="S4.SS1.p3.2.m2.1.1.1" xref="S4.SS1.p3.2.m2.1.1.1.cmml">∈</mo><msup id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3.cmml"><mi id="S4.SS1.p3.2.m2.1.1.3.2" xref="S4.SS1.p3.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p3.2.m2.1.1.3.3" xref="S4.SS1.p3.2.m2.1.1.3.3.cmml"><mi id="S4.SS1.p3.2.m2.1.1.3.3.2" xref="S4.SS1.p3.2.m2.1.1.3.3.2.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p3.2.m2.1.1.3.3.1" xref="S4.SS1.p3.2.m2.1.1.3.3.1.cmml">×</mo><mfrac id="S4.SS1.p3.2.m2.1.1.3.3.3" xref="S4.SS1.p3.2.m2.1.1.3.3.3.cmml"><mi id="S4.SS1.p3.2.m2.1.1.3.3.3.2" xref="S4.SS1.p3.2.m2.1.1.3.3.3.2.cmml">T</mi><mi id="S4.SS1.p3.2.m2.1.1.3.3.3.3" xref="S4.SS1.p3.2.m2.1.1.3.3.3.3.cmml">r</mi></mfrac><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p3.2.m2.1.1.3.3.1a" xref="S4.SS1.p3.2.m2.1.1.3.3.1.cmml">×</mo><mfrac id="S4.SS1.p3.2.m2.1.1.3.3.4" xref="S4.SS1.p3.2.m2.1.1.3.3.4.cmml"><mi id="S4.SS1.p3.2.m2.1.1.3.3.4.2" xref="S4.SS1.p3.2.m2.1.1.3.3.4.2.cmml">F</mi><mi id="S4.SS1.p3.2.m2.1.1.3.3.4.3" xref="S4.SS1.p3.2.m2.1.1.3.3.4.3.cmml">r</mi></mfrac></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><in id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1.1"></in><apply id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.1.1.2.1.cmml" xref="S4.SS1.p3.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS1.p3.2.m2.1.1.2.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2.2">𝒛</ci><cn type="integer" id="S4.SS1.p3.2.m2.1.1.2.3.cmml" xref="S4.SS1.p3.2.m2.1.1.2.3">0</cn></apply><apply id="S4.SS1.p3.2.m2.1.1.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.1.1.3.1.cmml" xref="S4.SS1.p3.2.m2.1.1.3">superscript</csymbol><ci id="S4.SS1.p3.2.m2.1.1.3.2.cmml" xref="S4.SS1.p3.2.m2.1.1.3.2">ℝ</ci><apply id="S4.SS1.p3.2.m2.1.1.3.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3"><times id="S4.SS1.p3.2.m2.1.1.3.3.1.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.1"></times><ci id="S4.SS1.p3.2.m2.1.1.3.3.2.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.2">𝐶</ci><apply id="S4.SS1.p3.2.m2.1.1.3.3.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.3"><divide id="S4.SS1.p3.2.m2.1.1.3.3.3.1.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.3"></divide><ci id="S4.SS1.p3.2.m2.1.1.3.3.3.2.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.3.2">𝑇</ci><ci id="S4.SS1.p3.2.m2.1.1.3.3.3.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.3.3">𝑟</ci></apply><apply id="S4.SS1.p3.2.m2.1.1.3.3.4.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.4"><divide id="S4.SS1.p3.2.m2.1.1.3.3.4.1.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.4"></divide><ci id="S4.SS1.p3.2.m2.1.1.3.3.4.2.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.4.2">𝐹</ci><ci id="S4.SS1.p3.2.m2.1.1.3.3.4.3.cmml" xref="S4.SS1.p3.2.m2.1.1.3.3.4.3">𝑟</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">\bm{z}_{0}\in\mathbb{R}^{C\times\frac{T}{r}\times\frac{F}{r}}</annotation></semantics></math> for the mel-spectrogram of audio, where <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mi id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><ci id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">C</annotation></semantics></math> and <math id="S4.SS1.p3.4.m4.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S4.SS1.p3.4.m4.1a"><mi id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><ci id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">r</annotation></semantics></math> denote the channel of latent representation and the compression level, separately.
For noise estimation, they used the reweighted training objective as</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.6" class="ltx_Math" alttext="\mathcal{L}_{n}(\theta)=\mathbb{E}_{\bm{z}_{0},\bm{\epsilon},n}\|\bm{\epsilon}-\bm{\epsilon}_{\theta}(\bm{z}_{n},n,\mathbf{F}^{a})\|" display="block"><semantics id="S4.E1.m1.6a"><mrow id="S4.E1.m1.6.6" xref="S4.E1.m1.6.6.cmml"><mrow id="S4.E1.m1.6.6.3" xref="S4.E1.m1.6.6.3.cmml"><msub id="S4.E1.m1.6.6.3.2" xref="S4.E1.m1.6.6.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.6.6.3.2.2" xref="S4.E1.m1.6.6.3.2.2.cmml">ℒ</mi><mi id="S4.E1.m1.6.6.3.2.3" xref="S4.E1.m1.6.6.3.2.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.6.6.3.1" xref="S4.E1.m1.6.6.3.1.cmml">​</mo><mrow id="S4.E1.m1.6.6.3.3.2" xref="S4.E1.m1.6.6.3.cmml"><mo stretchy="false" id="S4.E1.m1.6.6.3.3.2.1" xref="S4.E1.m1.6.6.3.cmml">(</mo><mi id="S4.E1.m1.4.4" xref="S4.E1.m1.4.4.cmml">θ</mi><mo stretchy="false" id="S4.E1.m1.6.6.3.3.2.2" xref="S4.E1.m1.6.6.3.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.6.6.2" xref="S4.E1.m1.6.6.2.cmml">=</mo><mrow id="S4.E1.m1.6.6.1" xref="S4.E1.m1.6.6.1.cmml"><msub id="S4.E1.m1.6.6.1.3" xref="S4.E1.m1.6.6.1.3.cmml"><mi id="S4.E1.m1.6.6.1.3.2" xref="S4.E1.m1.6.6.1.3.2.cmml">𝔼</mi><mrow id="S4.E1.m1.3.3.3.3" xref="S4.E1.m1.3.3.3.4.cmml"><msub id="S4.E1.m1.3.3.3.3.1" xref="S4.E1.m1.3.3.3.3.1.cmml"><mi id="S4.E1.m1.3.3.3.3.1.2" xref="S4.E1.m1.3.3.3.3.1.2.cmml">𝒛</mi><mn id="S4.E1.m1.3.3.3.3.1.3" xref="S4.E1.m1.3.3.3.3.1.3.cmml">0</mn></msub><mo id="S4.E1.m1.3.3.3.3.2" xref="S4.E1.m1.3.3.3.4.cmml">,</mo><mi class="ltx_mathvariant_bold-italic" mathvariant="bold-italic" id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml">ϵ</mi><mo id="S4.E1.m1.3.3.3.3.3" xref="S4.E1.m1.3.3.3.4.cmml">,</mo><mi id="S4.E1.m1.2.2.2.2" xref="S4.E1.m1.2.2.2.2.cmml">n</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.6.6.1.2" xref="S4.E1.m1.6.6.1.2.cmml">​</mo><mrow id="S4.E1.m1.6.6.1.1.1" xref="S4.E1.m1.6.6.1.1.2.cmml"><mo stretchy="false" id="S4.E1.m1.6.6.1.1.1.2" xref="S4.E1.m1.6.6.1.1.2.1.cmml">‖</mo><mrow id="S4.E1.m1.6.6.1.1.1.1" xref="S4.E1.m1.6.6.1.1.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" mathvariant="bold-italic" id="S4.E1.m1.6.6.1.1.1.1.4" xref="S4.E1.m1.6.6.1.1.1.1.4.cmml">ϵ</mi><mo id="S4.E1.m1.6.6.1.1.1.1.3" xref="S4.E1.m1.6.6.1.1.1.1.3.cmml">−</mo><mrow id="S4.E1.m1.6.6.1.1.1.1.2" xref="S4.E1.m1.6.6.1.1.1.1.2.cmml"><msub id="S4.E1.m1.6.6.1.1.1.1.2.4" xref="S4.E1.m1.6.6.1.1.1.1.2.4.cmml"><mi class="ltx_mathvariant_bold-italic" mathvariant="bold-italic" id="S4.E1.m1.6.6.1.1.1.1.2.4.2" xref="S4.E1.m1.6.6.1.1.1.1.2.4.2.cmml">ϵ</mi><mi id="S4.E1.m1.6.6.1.1.1.1.2.4.3" xref="S4.E1.m1.6.6.1.1.1.1.2.4.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.6.6.1.1.1.1.2.3" xref="S4.E1.m1.6.6.1.1.1.1.2.3.cmml">​</mo><mrow id="S4.E1.m1.6.6.1.1.1.1.2.2.2" xref="S4.E1.m1.6.6.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S4.E1.m1.6.6.1.1.1.1.2.2.2.3" xref="S4.E1.m1.6.6.1.1.1.1.2.2.3.cmml">(</mo><msub id="S4.E1.m1.6.6.1.1.1.1.1.1.1.1" xref="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.2.cmml">𝒛</mi><mi id="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S4.E1.m1.6.6.1.1.1.1.2.2.2.4" xref="S4.E1.m1.6.6.1.1.1.1.2.2.3.cmml">,</mo><mi id="S4.E1.m1.5.5" xref="S4.E1.m1.5.5.cmml">n</mi><mo id="S4.E1.m1.6.6.1.1.1.1.2.2.2.5" xref="S4.E1.m1.6.6.1.1.1.1.2.2.3.cmml">,</mo><msup id="S4.E1.m1.6.6.1.1.1.1.2.2.2.2" xref="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.cmml"><mi id="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.2" xref="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.2.cmml">𝐅</mi><mi id="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.3" xref="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.3.cmml">a</mi></msup><mo stretchy="false" id="S4.E1.m1.6.6.1.1.1.1.2.2.2.6" xref="S4.E1.m1.6.6.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.E1.m1.6.6.1.1.1.3" xref="S4.E1.m1.6.6.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.6b"><apply id="S4.E1.m1.6.6.cmml" xref="S4.E1.m1.6.6"><eq id="S4.E1.m1.6.6.2.cmml" xref="S4.E1.m1.6.6.2"></eq><apply id="S4.E1.m1.6.6.3.cmml" xref="S4.E1.m1.6.6.3"><times id="S4.E1.m1.6.6.3.1.cmml" xref="S4.E1.m1.6.6.3.1"></times><apply id="S4.E1.m1.6.6.3.2.cmml" xref="S4.E1.m1.6.6.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.3.2.1.cmml" xref="S4.E1.m1.6.6.3.2">subscript</csymbol><ci id="S4.E1.m1.6.6.3.2.2.cmml" xref="S4.E1.m1.6.6.3.2.2">ℒ</ci><ci id="S4.E1.m1.6.6.3.2.3.cmml" xref="S4.E1.m1.6.6.3.2.3">𝑛</ci></apply><ci id="S4.E1.m1.4.4.cmml" xref="S4.E1.m1.4.4">𝜃</ci></apply><apply id="S4.E1.m1.6.6.1.cmml" xref="S4.E1.m1.6.6.1"><times id="S4.E1.m1.6.6.1.2.cmml" xref="S4.E1.m1.6.6.1.2"></times><apply id="S4.E1.m1.6.6.1.3.cmml" xref="S4.E1.m1.6.6.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.1.3.1.cmml" xref="S4.E1.m1.6.6.1.3">subscript</csymbol><ci id="S4.E1.m1.6.6.1.3.2.cmml" xref="S4.E1.m1.6.6.1.3.2">𝔼</ci><list id="S4.E1.m1.3.3.3.4.cmml" xref="S4.E1.m1.3.3.3.3"><apply id="S4.E1.m1.3.3.3.3.1.cmml" xref="S4.E1.m1.3.3.3.3.1"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.3.3.1.1.cmml" xref="S4.E1.m1.3.3.3.3.1">subscript</csymbol><ci id="S4.E1.m1.3.3.3.3.1.2.cmml" xref="S4.E1.m1.3.3.3.3.1.2">𝒛</ci><cn type="integer" id="S4.E1.m1.3.3.3.3.1.3.cmml" xref="S4.E1.m1.3.3.3.3.1.3">0</cn></apply><ci id="S4.E1.m1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1">bold-italic-ϵ</ci><ci id="S4.E1.m1.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2">𝑛</ci></list></apply><apply id="S4.E1.m1.6.6.1.1.2.cmml" xref="S4.E1.m1.6.6.1.1.1"><csymbol cd="latexml" id="S4.E1.m1.6.6.1.1.2.1.cmml" xref="S4.E1.m1.6.6.1.1.1.2">norm</csymbol><apply id="S4.E1.m1.6.6.1.1.1.1.cmml" xref="S4.E1.m1.6.6.1.1.1.1"><minus id="S4.E1.m1.6.6.1.1.1.1.3.cmml" xref="S4.E1.m1.6.6.1.1.1.1.3"></minus><ci id="S4.E1.m1.6.6.1.1.1.1.4.cmml" xref="S4.E1.m1.6.6.1.1.1.1.4">bold-italic-ϵ</ci><apply id="S4.E1.m1.6.6.1.1.1.1.2.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2"><times id="S4.E1.m1.6.6.1.1.1.1.2.3.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.3"></times><apply id="S4.E1.m1.6.6.1.1.1.1.2.4.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.1.1.1.1.2.4.1.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.4">subscript</csymbol><ci id="S4.E1.m1.6.6.1.1.1.1.2.4.2.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.4.2">bold-italic-ϵ</ci><ci id="S4.E1.m1.6.6.1.1.1.1.2.4.3.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.4.3">𝜃</ci></apply><vector id="S4.E1.m1.6.6.1.1.1.1.2.2.3.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.2.2"><apply id="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.6.6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.6.6.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.2">𝒛</ci><ci id="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.6.6.1.1.1.1.1.1.1.1.3">𝑛</ci></apply><ci id="S4.E1.m1.5.5.cmml" xref="S4.E1.m1.5.5">𝑛</ci><apply id="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.1.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.2.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.2">𝐅</ci><ci id="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.3.cmml" xref="S4.E1.m1.6.6.1.1.1.1.2.2.2.2.3">𝑎</ci></apply></vector></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.6c">\mathcal{L}_{n}(\theta)=\mathbb{E}_{\bm{z}_{0},\bm{\epsilon},n}\|\bm{\epsilon}-\bm{\epsilon}_{\theta}(\bm{z}_{n},n,\mathbf{F}^{a})\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.SS1.p3.13" class="ltx_p">where <math id="S4.SS1.p3.5.m1.2" class="ltx_Math" alttext="\bm{\epsilon}\in\mathcal{N}(\bm{0},\bm{I})" display="inline"><semantics id="S4.SS1.p3.5.m1.2a"><mrow id="S4.SS1.p3.5.m1.2.3" xref="S4.SS1.p3.5.m1.2.3.cmml"><mi class="ltx_mathvariant_bold-italic" mathvariant="bold-italic" id="S4.SS1.p3.5.m1.2.3.2" xref="S4.SS1.p3.5.m1.2.3.2.cmml">ϵ</mi><mo id="S4.SS1.p3.5.m1.2.3.1" xref="S4.SS1.p3.5.m1.2.3.1.cmml">∈</mo><mrow id="S4.SS1.p3.5.m1.2.3.3" xref="S4.SS1.p3.5.m1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p3.5.m1.2.3.3.2" xref="S4.SS1.p3.5.m1.2.3.3.2.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p3.5.m1.2.3.3.1" xref="S4.SS1.p3.5.m1.2.3.3.1.cmml">​</mo><mrow id="S4.SS1.p3.5.m1.2.3.3.3.2" xref="S4.SS1.p3.5.m1.2.3.3.3.1.cmml"><mo stretchy="false" id="S4.SS1.p3.5.m1.2.3.3.3.2.1" xref="S4.SS1.p3.5.m1.2.3.3.3.1.cmml">(</mo><mn id="S4.SS1.p3.5.m1.1.1" xref="S4.SS1.p3.5.m1.1.1.cmml">𝟎</mn><mo id="S4.SS1.p3.5.m1.2.3.3.3.2.2" xref="S4.SS1.p3.5.m1.2.3.3.3.1.cmml">,</mo><mi id="S4.SS1.p3.5.m1.2.2" xref="S4.SS1.p3.5.m1.2.2.cmml">𝑰</mi><mo stretchy="false" id="S4.SS1.p3.5.m1.2.3.3.3.2.3" xref="S4.SS1.p3.5.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m1.2b"><apply id="S4.SS1.p3.5.m1.2.3.cmml" xref="S4.SS1.p3.5.m1.2.3"><in id="S4.SS1.p3.5.m1.2.3.1.cmml" xref="S4.SS1.p3.5.m1.2.3.1"></in><ci id="S4.SS1.p3.5.m1.2.3.2.cmml" xref="S4.SS1.p3.5.m1.2.3.2">bold-italic-ϵ</ci><apply id="S4.SS1.p3.5.m1.2.3.3.cmml" xref="S4.SS1.p3.5.m1.2.3.3"><times id="S4.SS1.p3.5.m1.2.3.3.1.cmml" xref="S4.SS1.p3.5.m1.2.3.3.1"></times><ci id="S4.SS1.p3.5.m1.2.3.3.2.cmml" xref="S4.SS1.p3.5.m1.2.3.3.2">𝒩</ci><interval closure="open" id="S4.SS1.p3.5.m1.2.3.3.3.1.cmml" xref="S4.SS1.p3.5.m1.2.3.3.3.2"><cn type="integer" id="S4.SS1.p3.5.m1.1.1.cmml" xref="S4.SS1.p3.5.m1.1.1">0</cn><ci id="S4.SS1.p3.5.m1.2.2.cmml" xref="S4.SS1.p3.5.m1.2.2">𝑰</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m1.2c">\bm{\epsilon}\in\mathcal{N}(\bm{0},\bm{I})</annotation></semantics></math> denote the added nosie.
At the final time step <math id="S4.SS1.p3.6.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS1.p3.6.m2.1a"><mi id="S4.SS1.p3.6.m2.1.1" xref="S4.SS1.p3.6.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m2.1b"><ci id="S4.SS1.p3.6.m2.1.1.cmml" xref="S4.SS1.p3.6.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m2.1c">N</annotation></semantics></math> of the forward pass, the input <math id="S4.SS1.p3.7.m3.2" class="ltx_Math" alttext="\bm{z}_{n}\in\mathcal{N}(\bm{0},\bm{I})" display="inline"><semantics id="S4.SS1.p3.7.m3.2a"><mrow id="S4.SS1.p3.7.m3.2.3" xref="S4.SS1.p3.7.m3.2.3.cmml"><msub id="S4.SS1.p3.7.m3.2.3.2" xref="S4.SS1.p3.7.m3.2.3.2.cmml"><mi id="S4.SS1.p3.7.m3.2.3.2.2" xref="S4.SS1.p3.7.m3.2.3.2.2.cmml">𝒛</mi><mi id="S4.SS1.p3.7.m3.2.3.2.3" xref="S4.SS1.p3.7.m3.2.3.2.3.cmml">n</mi></msub><mo id="S4.SS1.p3.7.m3.2.3.1" xref="S4.SS1.p3.7.m3.2.3.1.cmml">∈</mo><mrow id="S4.SS1.p3.7.m3.2.3.3" xref="S4.SS1.p3.7.m3.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.p3.7.m3.2.3.3.2" xref="S4.SS1.p3.7.m3.2.3.3.2.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p3.7.m3.2.3.3.1" xref="S4.SS1.p3.7.m3.2.3.3.1.cmml">​</mo><mrow id="S4.SS1.p3.7.m3.2.3.3.3.2" xref="S4.SS1.p3.7.m3.2.3.3.3.1.cmml"><mo stretchy="false" id="S4.SS1.p3.7.m3.2.3.3.3.2.1" xref="S4.SS1.p3.7.m3.2.3.3.3.1.cmml">(</mo><mn id="S4.SS1.p3.7.m3.1.1" xref="S4.SS1.p3.7.m3.1.1.cmml">𝟎</mn><mo id="S4.SS1.p3.7.m3.2.3.3.3.2.2" xref="S4.SS1.p3.7.m3.2.3.3.3.1.cmml">,</mo><mi id="S4.SS1.p3.7.m3.2.2" xref="S4.SS1.p3.7.m3.2.2.cmml">𝑰</mi><mo stretchy="false" id="S4.SS1.p3.7.m3.2.3.3.3.2.3" xref="S4.SS1.p3.7.m3.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.7.m3.2b"><apply id="S4.SS1.p3.7.m3.2.3.cmml" xref="S4.SS1.p3.7.m3.2.3"><in id="S4.SS1.p3.7.m3.2.3.1.cmml" xref="S4.SS1.p3.7.m3.2.3.1"></in><apply id="S4.SS1.p3.7.m3.2.3.2.cmml" xref="S4.SS1.p3.7.m3.2.3.2"><csymbol cd="ambiguous" id="S4.SS1.p3.7.m3.2.3.2.1.cmml" xref="S4.SS1.p3.7.m3.2.3.2">subscript</csymbol><ci id="S4.SS1.p3.7.m3.2.3.2.2.cmml" xref="S4.SS1.p3.7.m3.2.3.2.2">𝒛</ci><ci id="S4.SS1.p3.7.m3.2.3.2.3.cmml" xref="S4.SS1.p3.7.m3.2.3.2.3">𝑛</ci></apply><apply id="S4.SS1.p3.7.m3.2.3.3.cmml" xref="S4.SS1.p3.7.m3.2.3.3"><times id="S4.SS1.p3.7.m3.2.3.3.1.cmml" xref="S4.SS1.p3.7.m3.2.3.3.1"></times><ci id="S4.SS1.p3.7.m3.2.3.3.2.cmml" xref="S4.SS1.p3.7.m3.2.3.3.2">𝒩</ci><interval closure="open" id="S4.SS1.p3.7.m3.2.3.3.3.1.cmml" xref="S4.SS1.p3.7.m3.2.3.3.3.2"><cn type="integer" id="S4.SS1.p3.7.m3.1.1.cmml" xref="S4.SS1.p3.7.m3.1.1">0</cn><ci id="S4.SS1.p3.7.m3.2.2.cmml" xref="S4.SS1.p3.7.m3.2.2">𝑰</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.7.m3.2c">\bm{z}_{n}\in\mathcal{N}(\bm{0},\bm{I})</annotation></semantics></math> becomes an isotropic Gaussian noise.
During the training stage, they generated the audio prior <math id="S4.SS1.p3.8.m4.1" class="ltx_Math" alttext="\bm{z}_{0}" display="inline"><semantics id="S4.SS1.p3.8.m4.1a"><msub id="S4.SS1.p3.8.m4.1.1" xref="S4.SS1.p3.8.m4.1.1.cmml"><mi id="S4.SS1.p3.8.m4.1.1.2" xref="S4.SS1.p3.8.m4.1.1.2.cmml">𝒛</mi><mn id="S4.SS1.p3.8.m4.1.1.3" xref="S4.SS1.p3.8.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.8.m4.1b"><apply id="S4.SS1.p3.8.m4.1.1.cmml" xref="S4.SS1.p3.8.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.8.m4.1.1.1.cmml" xref="S4.SS1.p3.8.m4.1.1">subscript</csymbol><ci id="S4.SS1.p3.8.m4.1.1.2.cmml" xref="S4.SS1.p3.8.m4.1.1.2">𝒛</ci><cn type="integer" id="S4.SS1.p3.8.m4.1.1.3.cmml" xref="S4.SS1.p3.8.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.8.m4.1c">\bm{z}_{0}</annotation></semantics></math> from the cross-modal representation <math id="S4.SS1.p3.9.m5.1" class="ltx_Math" alttext="\mathbf{F}^{a}" display="inline"><semantics id="S4.SS1.p3.9.m5.1a"><msup id="S4.SS1.p3.9.m5.1.1" xref="S4.SS1.p3.9.m5.1.1.cmml"><mi id="S4.SS1.p3.9.m5.1.1.2" xref="S4.SS1.p3.9.m5.1.1.2.cmml">𝐅</mi><mi id="S4.SS1.p3.9.m5.1.1.3" xref="S4.SS1.p3.9.m5.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.9.m5.1b"><apply id="S4.SS1.p3.9.m5.1.1.cmml" xref="S4.SS1.p3.9.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.9.m5.1.1.1.cmml" xref="S4.SS1.p3.9.m5.1.1">superscript</csymbol><ci id="S4.SS1.p3.9.m5.1.1.2.cmml" xref="S4.SS1.p3.9.m5.1.1.2">𝐅</ci><ci id="S4.SS1.p3.9.m5.1.1.3.cmml" xref="S4.SS1.p3.9.m5.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.9.m5.1c">\mathbf{F}^{a}</annotation></semantics></math> of an audio <math id="S4.SS1.p3.10.m6.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S4.SS1.p3.10.m6.1a"><mi id="S4.SS1.p3.10.m6.1.1" xref="S4.SS1.p3.10.m6.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.10.m6.1b"><ci id="S4.SS1.p3.10.m6.1.1.cmml" xref="S4.SS1.p3.10.m6.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.10.m6.1c">a</annotation></semantics></math> in a video.
For TTA generation, the text embedding <math id="S4.SS1.p3.11.m7.1" class="ltx_Math" alttext="\mathbf{F}^{t}" display="inline"><semantics id="S4.SS1.p3.11.m7.1a"><msup id="S4.SS1.p3.11.m7.1.1" xref="S4.SS1.p3.11.m7.1.1.cmml"><mi id="S4.SS1.p3.11.m7.1.1.2" xref="S4.SS1.p3.11.m7.1.1.2.cmml">𝐅</mi><mi id="S4.SS1.p3.11.m7.1.1.3" xref="S4.SS1.p3.11.m7.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.11.m7.1b"><apply id="S4.SS1.p3.11.m7.1.1.cmml" xref="S4.SS1.p3.11.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.11.m7.1.1.1.cmml" xref="S4.SS1.p3.11.m7.1.1">superscript</csymbol><ci id="S4.SS1.p3.11.m7.1.1.2.cmml" xref="S4.SS1.p3.11.m7.1.1.2">𝐅</ci><ci id="S4.SS1.p3.11.m7.1.1.3.cmml" xref="S4.SS1.p3.11.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.11.m7.1c">\mathbf{F}^{t}</annotation></semantics></math> is used to predict the noise <math id="S4.SS1.p3.12.m8.3" class="ltx_Math" alttext="\bm{\epsilon}_{\theta}(\bm{z}_{n},n,\mathbf{F}^{t})" display="inline"><semantics id="S4.SS1.p3.12.m8.3a"><mrow id="S4.SS1.p3.12.m8.3.3" xref="S4.SS1.p3.12.m8.3.3.cmml"><msub id="S4.SS1.p3.12.m8.3.3.4" xref="S4.SS1.p3.12.m8.3.3.4.cmml"><mi class="ltx_mathvariant_bold-italic" mathvariant="bold-italic" id="S4.SS1.p3.12.m8.3.3.4.2" xref="S4.SS1.p3.12.m8.3.3.4.2.cmml">ϵ</mi><mi id="S4.SS1.p3.12.m8.3.3.4.3" xref="S4.SS1.p3.12.m8.3.3.4.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p3.12.m8.3.3.3" xref="S4.SS1.p3.12.m8.3.3.3.cmml">​</mo><mrow id="S4.SS1.p3.12.m8.3.3.2.2" xref="S4.SS1.p3.12.m8.3.3.2.3.cmml"><mo stretchy="false" id="S4.SS1.p3.12.m8.3.3.2.2.3" xref="S4.SS1.p3.12.m8.3.3.2.3.cmml">(</mo><msub id="S4.SS1.p3.12.m8.2.2.1.1.1" xref="S4.SS1.p3.12.m8.2.2.1.1.1.cmml"><mi id="S4.SS1.p3.12.m8.2.2.1.1.1.2" xref="S4.SS1.p3.12.m8.2.2.1.1.1.2.cmml">𝒛</mi><mi id="S4.SS1.p3.12.m8.2.2.1.1.1.3" xref="S4.SS1.p3.12.m8.2.2.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS1.p3.12.m8.3.3.2.2.4" xref="S4.SS1.p3.12.m8.3.3.2.3.cmml">,</mo><mi id="S4.SS1.p3.12.m8.1.1" xref="S4.SS1.p3.12.m8.1.1.cmml">n</mi><mo id="S4.SS1.p3.12.m8.3.3.2.2.5" xref="S4.SS1.p3.12.m8.3.3.2.3.cmml">,</mo><msup id="S4.SS1.p3.12.m8.3.3.2.2.2" xref="S4.SS1.p3.12.m8.3.3.2.2.2.cmml"><mi id="S4.SS1.p3.12.m8.3.3.2.2.2.2" xref="S4.SS1.p3.12.m8.3.3.2.2.2.2.cmml">𝐅</mi><mi id="S4.SS1.p3.12.m8.3.3.2.2.2.3" xref="S4.SS1.p3.12.m8.3.3.2.2.2.3.cmml">t</mi></msup><mo stretchy="false" id="S4.SS1.p3.12.m8.3.3.2.2.6" xref="S4.SS1.p3.12.m8.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.12.m8.3b"><apply id="S4.SS1.p3.12.m8.3.3.cmml" xref="S4.SS1.p3.12.m8.3.3"><times id="S4.SS1.p3.12.m8.3.3.3.cmml" xref="S4.SS1.p3.12.m8.3.3.3"></times><apply id="S4.SS1.p3.12.m8.3.3.4.cmml" xref="S4.SS1.p3.12.m8.3.3.4"><csymbol cd="ambiguous" id="S4.SS1.p3.12.m8.3.3.4.1.cmml" xref="S4.SS1.p3.12.m8.3.3.4">subscript</csymbol><ci id="S4.SS1.p3.12.m8.3.3.4.2.cmml" xref="S4.SS1.p3.12.m8.3.3.4.2">bold-italic-ϵ</ci><ci id="S4.SS1.p3.12.m8.3.3.4.3.cmml" xref="S4.SS1.p3.12.m8.3.3.4.3">𝜃</ci></apply><vector id="S4.SS1.p3.12.m8.3.3.2.3.cmml" xref="S4.SS1.p3.12.m8.3.3.2.2"><apply id="S4.SS1.p3.12.m8.2.2.1.1.1.cmml" xref="S4.SS1.p3.12.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.12.m8.2.2.1.1.1.1.cmml" xref="S4.SS1.p3.12.m8.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.12.m8.2.2.1.1.1.2.cmml" xref="S4.SS1.p3.12.m8.2.2.1.1.1.2">𝒛</ci><ci id="S4.SS1.p3.12.m8.2.2.1.1.1.3.cmml" xref="S4.SS1.p3.12.m8.2.2.1.1.1.3">𝑛</ci></apply><ci id="S4.SS1.p3.12.m8.1.1.cmml" xref="S4.SS1.p3.12.m8.1.1">𝑛</ci><apply id="S4.SS1.p3.12.m8.3.3.2.2.2.cmml" xref="S4.SS1.p3.12.m8.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.12.m8.3.3.2.2.2.1.cmml" xref="S4.SS1.p3.12.m8.3.3.2.2.2">superscript</csymbol><ci id="S4.SS1.p3.12.m8.3.3.2.2.2.2.cmml" xref="S4.SS1.p3.12.m8.3.3.2.2.2.2">𝐅</ci><ci id="S4.SS1.p3.12.m8.3.3.2.2.2.3.cmml" xref="S4.SS1.p3.12.m8.3.3.2.2.2.3">𝑡</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.12.m8.3c">\bm{\epsilon}_{\theta}(\bm{z}_{n},n,\mathbf{F}^{t})</annotation></semantics></math>, instead of <math id="S4.SS1.p3.13.m9.3" class="ltx_Math" alttext="\bm{\epsilon}_{\theta}(\bm{z}_{n},n,\mathbf{F}^{a})" display="inline"><semantics id="S4.SS1.p3.13.m9.3a"><mrow id="S4.SS1.p3.13.m9.3.3" xref="S4.SS1.p3.13.m9.3.3.cmml"><msub id="S4.SS1.p3.13.m9.3.3.4" xref="S4.SS1.p3.13.m9.3.3.4.cmml"><mi class="ltx_mathvariant_bold-italic" mathvariant="bold-italic" id="S4.SS1.p3.13.m9.3.3.4.2" xref="S4.SS1.p3.13.m9.3.3.4.2.cmml">ϵ</mi><mi id="S4.SS1.p3.13.m9.3.3.4.3" xref="S4.SS1.p3.13.m9.3.3.4.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p3.13.m9.3.3.3" xref="S4.SS1.p3.13.m9.3.3.3.cmml">​</mo><mrow id="S4.SS1.p3.13.m9.3.3.2.2" xref="S4.SS1.p3.13.m9.3.3.2.3.cmml"><mo stretchy="false" id="S4.SS1.p3.13.m9.3.3.2.2.3" xref="S4.SS1.p3.13.m9.3.3.2.3.cmml">(</mo><msub id="S4.SS1.p3.13.m9.2.2.1.1.1" xref="S4.SS1.p3.13.m9.2.2.1.1.1.cmml"><mi id="S4.SS1.p3.13.m9.2.2.1.1.1.2" xref="S4.SS1.p3.13.m9.2.2.1.1.1.2.cmml">𝒛</mi><mi id="S4.SS1.p3.13.m9.2.2.1.1.1.3" xref="S4.SS1.p3.13.m9.2.2.1.1.1.3.cmml">n</mi></msub><mo id="S4.SS1.p3.13.m9.3.3.2.2.4" xref="S4.SS1.p3.13.m9.3.3.2.3.cmml">,</mo><mi id="S4.SS1.p3.13.m9.1.1" xref="S4.SS1.p3.13.m9.1.1.cmml">n</mi><mo id="S4.SS1.p3.13.m9.3.3.2.2.5" xref="S4.SS1.p3.13.m9.3.3.2.3.cmml">,</mo><msup id="S4.SS1.p3.13.m9.3.3.2.2.2" xref="S4.SS1.p3.13.m9.3.3.2.2.2.cmml"><mi id="S4.SS1.p3.13.m9.3.3.2.2.2.2" xref="S4.SS1.p3.13.m9.3.3.2.2.2.2.cmml">𝐅</mi><mi id="S4.SS1.p3.13.m9.3.3.2.2.2.3" xref="S4.SS1.p3.13.m9.3.3.2.2.2.3.cmml">a</mi></msup><mo stretchy="false" id="S4.SS1.p3.13.m9.3.3.2.2.6" xref="S4.SS1.p3.13.m9.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.13.m9.3b"><apply id="S4.SS1.p3.13.m9.3.3.cmml" xref="S4.SS1.p3.13.m9.3.3"><times id="S4.SS1.p3.13.m9.3.3.3.cmml" xref="S4.SS1.p3.13.m9.3.3.3"></times><apply id="S4.SS1.p3.13.m9.3.3.4.cmml" xref="S4.SS1.p3.13.m9.3.3.4"><csymbol cd="ambiguous" id="S4.SS1.p3.13.m9.3.3.4.1.cmml" xref="S4.SS1.p3.13.m9.3.3.4">subscript</csymbol><ci id="S4.SS1.p3.13.m9.3.3.4.2.cmml" xref="S4.SS1.p3.13.m9.3.3.4.2">bold-italic-ϵ</ci><ci id="S4.SS1.p3.13.m9.3.3.4.3.cmml" xref="S4.SS1.p3.13.m9.3.3.4.3">𝜃</ci></apply><vector id="S4.SS1.p3.13.m9.3.3.2.3.cmml" xref="S4.SS1.p3.13.m9.3.3.2.2"><apply id="S4.SS1.p3.13.m9.2.2.1.1.1.cmml" xref="S4.SS1.p3.13.m9.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.13.m9.2.2.1.1.1.1.cmml" xref="S4.SS1.p3.13.m9.2.2.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.13.m9.2.2.1.1.1.2.cmml" xref="S4.SS1.p3.13.m9.2.2.1.1.1.2">𝒛</ci><ci id="S4.SS1.p3.13.m9.2.2.1.1.1.3.cmml" xref="S4.SS1.p3.13.m9.2.2.1.1.1.3">𝑛</ci></apply><ci id="S4.SS1.p3.13.m9.1.1.cmml" xref="S4.SS1.p3.13.m9.1.1">𝑛</ci><apply id="S4.SS1.p3.13.m9.3.3.2.2.2.cmml" xref="S4.SS1.p3.13.m9.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.13.m9.3.3.2.2.2.1.cmml" xref="S4.SS1.p3.13.m9.3.3.2.2.2">superscript</csymbol><ci id="S4.SS1.p3.13.m9.3.3.2.2.2.2.cmml" xref="S4.SS1.p3.13.m9.3.3.2.2.2.2">𝐅</ci><ci id="S4.SS1.p3.13.m9.3.3.2.2.2.3.cmml" xref="S4.SS1.p3.13.m9.3.3.2.2.2.3">𝑎</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.13.m9.3c">\bm{\epsilon}_{\theta}(\bm{z}_{n},n,\mathbf{F}^{a})</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Visual-aligned CLAP</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p">To align the textual and visual features at spatial and temporal levels corresponding to the paired sound, we apply a multi-head attention transformer to aggregate temporal information from video features <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\{\mathbf{F}^{v}_{i}\}_{i=1}^{T}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msubsup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mrow id="S4.SS2.p1.1.m1.1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p1.1.m1.1.1.1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.1.1.2.cmml">{</mo><msubsup id="S4.SS2.p1.1.m1.1.1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.2" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.2.cmml">𝐅</mi><mi id="S4.SS2.p1.1.m1.1.1.1.1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.3.cmml">i</mi><mi id="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.3" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.3.cmml">v</mi></msubsup><mo stretchy="false" id="S4.SS2.p1.1.m1.1.1.1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS2.p1.1.m1.1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.1.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.1.3.2.cmml">i</mi><mo id="S4.SS2.p1.1.m1.1.1.1.3.1" xref="S4.SS2.p1.1.m1.1.1.1.3.1.cmml">=</mo><mn id="S4.SS2.p1.1.m1.1.1.1.3.3" xref="S4.SS2.p1.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">T</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1">superscript</csymbol><apply id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1">subscript</csymbol><set id="S4.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1"><apply id="S4.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.2">𝐅</ci><ci id="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.2.3">𝑣</ci></apply><ci id="S4.SS2.p1.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S4.SS2.p1.1.m1.1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.1.3"><eq id="S4.SS2.p1.1.m1.1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.3.1"></eq><ci id="S4.SS2.p1.1.m1.1.1.1.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S4.SS2.p1.1.m1.1.1.1.3.3.cmml" xref="S4.SS2.p1.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\{\mathbf{F}^{v}_{i}\}_{i=1}^{T}</annotation></semantics></math>.
Then, we utilize a dual multi-modal residual network to fuse temporal visual representations with text embeddings <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{F}^{t}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msup id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">𝐅</mi><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">𝐅</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\mathbf{F}^{t}</annotation></semantics></math> for generating new visual-aligned text embedding <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="\hat{\mathbf{F}}^{t}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><msup id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mover accent="true" id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml"><mi id="S4.SS2.p1.3.m3.1.1.2.2" xref="S4.SS2.p1.3.m3.1.1.2.2.cmml">𝐅</mi><mo id="S4.SS2.p1.3.m3.1.1.2.1" xref="S4.SS2.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">superscript</csymbol><apply id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2"><ci id="S4.SS2.p1.3.m3.1.1.2.1.cmml" xref="S4.SS2.p1.3.m3.1.1.2.1">^</ci><ci id="S4.SS2.p1.3.m3.1.1.2.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2.2">𝐅</ci></apply><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">\hat{\mathbf{F}}^{t}</annotation></semantics></math>.
Based on contrastive language-audio pre-training (CLAP), we
apply visual-aligned CLAP between the textual features with the audio representation in the same mini-batch, which is defined as:</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.12" class="ltx_Math" alttext="\mathcal{L}=-\frac{1}{B}\sum_{b=1}^{B}\sum_{i=1}^{T}\log\frac{\exp\left(\frac{1}{\tau}\mathtt{sim}(\mathbf{F}^{a}_{b,i},\hat{\mathbf{F}}^{t}_{b,i})\right)}{\sum_{m=1}^{B}\exp\left(\frac{1}{\tau}\mathtt{sim}(\mathbf{F}^{a}_{b,i},\hat{\mathbf{F}}_{m,i}^{t})\right)}" display="block"><semantics id="S4.E2.m1.12a"><mrow id="S4.E2.m1.12.13" xref="S4.E2.m1.12.13.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.12.13.2" xref="S4.E2.m1.12.13.2.cmml">ℒ</mi><mo id="S4.E2.m1.12.13.1" xref="S4.E2.m1.12.13.1.cmml">=</mo><mrow id="S4.E2.m1.12.13.3" xref="S4.E2.m1.12.13.3.cmml"><mo id="S4.E2.m1.12.13.3a" xref="S4.E2.m1.12.13.3.cmml">−</mo><mrow id="S4.E2.m1.12.13.3.2" xref="S4.E2.m1.12.13.3.2.cmml"><mfrac id="S4.E2.m1.12.13.3.2.2" xref="S4.E2.m1.12.13.3.2.2.cmml"><mn id="S4.E2.m1.12.13.3.2.2.2" xref="S4.E2.m1.12.13.3.2.2.2.cmml">1</mn><mi id="S4.E2.m1.12.13.3.2.2.3" xref="S4.E2.m1.12.13.3.2.2.3.cmml">B</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E2.m1.12.13.3.2.1" xref="S4.E2.m1.12.13.3.2.1.cmml">​</mo><mrow id="S4.E2.m1.12.13.3.2.3" xref="S4.E2.m1.12.13.3.2.3.cmml"><munderover id="S4.E2.m1.12.13.3.2.3.1" xref="S4.E2.m1.12.13.3.2.3.1.cmml"><mo movablelimits="false" rspace="0em" id="S4.E2.m1.12.13.3.2.3.1.2.2" xref="S4.E2.m1.12.13.3.2.3.1.2.2.cmml">∑</mo><mrow id="S4.E2.m1.12.13.3.2.3.1.2.3" xref="S4.E2.m1.12.13.3.2.3.1.2.3.cmml"><mi id="S4.E2.m1.12.13.3.2.3.1.2.3.2" xref="S4.E2.m1.12.13.3.2.3.1.2.3.2.cmml">b</mi><mo id="S4.E2.m1.12.13.3.2.3.1.2.3.1" xref="S4.E2.m1.12.13.3.2.3.1.2.3.1.cmml">=</mo><mn id="S4.E2.m1.12.13.3.2.3.1.2.3.3" xref="S4.E2.m1.12.13.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E2.m1.12.13.3.2.3.1.3" xref="S4.E2.m1.12.13.3.2.3.1.3.cmml">B</mi></munderover><mrow id="S4.E2.m1.12.13.3.2.3.2" xref="S4.E2.m1.12.13.3.2.3.2.cmml"><munderover id="S4.E2.m1.12.13.3.2.3.2.1" xref="S4.E2.m1.12.13.3.2.3.2.1.cmml"><mo movablelimits="false" id="S4.E2.m1.12.13.3.2.3.2.1.2.2" xref="S4.E2.m1.12.13.3.2.3.2.1.2.2.cmml">∑</mo><mrow id="S4.E2.m1.12.13.3.2.3.2.1.2.3" xref="S4.E2.m1.12.13.3.2.3.2.1.2.3.cmml"><mi id="S4.E2.m1.12.13.3.2.3.2.1.2.3.2" xref="S4.E2.m1.12.13.3.2.3.2.1.2.3.2.cmml">i</mi><mo id="S4.E2.m1.12.13.3.2.3.2.1.2.3.1" xref="S4.E2.m1.12.13.3.2.3.2.1.2.3.1.cmml">=</mo><mn id="S4.E2.m1.12.13.3.2.3.2.1.2.3.3" xref="S4.E2.m1.12.13.3.2.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.E2.m1.12.13.3.2.3.2.1.3" xref="S4.E2.m1.12.13.3.2.3.2.1.3.cmml">T</mi></munderover><mrow id="S4.E2.m1.12.13.3.2.3.2.2" xref="S4.E2.m1.12.13.3.2.3.2.2.cmml"><mi id="S4.E2.m1.12.13.3.2.3.2.2.1" xref="S4.E2.m1.12.13.3.2.3.2.2.1.cmml">log</mi><mo lspace="0.167em" id="S4.E2.m1.12.13.3.2.3.2.2a" xref="S4.E2.m1.12.13.3.2.3.2.2.cmml">⁡</mo><mfrac id="S4.E2.m1.12.12" xref="S4.E2.m1.12.12.cmml"><mrow id="S4.E2.m1.6.6.6.6" xref="S4.E2.m1.6.6.6.7.cmml"><mi id="S4.E2.m1.5.5.5.5" xref="S4.E2.m1.5.5.5.5.cmml">exp</mi><mo id="S4.E2.m1.6.6.6.6a" xref="S4.E2.m1.6.6.6.7.cmml">⁡</mo><mrow id="S4.E2.m1.6.6.6.6.1" xref="S4.E2.m1.6.6.6.7.cmml"><mo id="S4.E2.m1.6.6.6.6.1.2" xref="S4.E2.m1.6.6.6.7.cmml">(</mo><mrow id="S4.E2.m1.6.6.6.6.1.1" xref="S4.E2.m1.6.6.6.6.1.1.cmml"><mfrac id="S4.E2.m1.6.6.6.6.1.1.4" xref="S4.E2.m1.6.6.6.6.1.1.4.cmml"><mn id="S4.E2.m1.6.6.6.6.1.1.4.2" xref="S4.E2.m1.6.6.6.6.1.1.4.2.cmml">1</mn><mi id="S4.E2.m1.6.6.6.6.1.1.4.3" xref="S4.E2.m1.6.6.6.6.1.1.4.3.cmml">τ</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E2.m1.6.6.6.6.1.1.3" xref="S4.E2.m1.6.6.6.6.1.1.3.cmml">​</mo><mi id="S4.E2.m1.6.6.6.6.1.1.5" xref="S4.E2.m1.6.6.6.6.1.1.5.cmml">𝚜𝚒𝚖</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.6.6.6.6.1.1.3a" xref="S4.E2.m1.6.6.6.6.1.1.3.cmml">​</mo><mrow id="S4.E2.m1.6.6.6.6.1.1.2.2" xref="S4.E2.m1.6.6.6.6.1.1.2.3.cmml"><mo stretchy="false" id="S4.E2.m1.6.6.6.6.1.1.2.2.3" xref="S4.E2.m1.6.6.6.6.1.1.2.3.cmml">(</mo><msubsup id="S4.E2.m1.6.6.6.6.1.1.1.1.1" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1.cmml"><mi id="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.2" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.2.cmml">𝐅</mi><mrow id="S4.E2.m1.2.2.2.2.2.4" xref="S4.E2.m1.2.2.2.2.2.3.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml">b</mi><mo id="S4.E2.m1.2.2.2.2.2.4.1" xref="S4.E2.m1.2.2.2.2.2.3.cmml">,</mo><mi id="S4.E2.m1.2.2.2.2.2.2" xref="S4.E2.m1.2.2.2.2.2.2.cmml">i</mi></mrow><mi id="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.3" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.3.cmml">a</mi></msubsup><mo id="S4.E2.m1.6.6.6.6.1.1.2.2.4" xref="S4.E2.m1.6.6.6.6.1.1.2.3.cmml">,</mo><msubsup id="S4.E2.m1.6.6.6.6.1.1.2.2.2" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.cmml"><mover accent="true" id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.cmml"><mi id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.2" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.2.cmml">𝐅</mi><mo id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.1" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.1.cmml">^</mo></mover><mrow id="S4.E2.m1.4.4.4.4.2.4" xref="S4.E2.m1.4.4.4.4.2.3.cmml"><mi id="S4.E2.m1.3.3.3.3.1.1" xref="S4.E2.m1.3.3.3.3.1.1.cmml">b</mi><mo id="S4.E2.m1.4.4.4.4.2.4.1" xref="S4.E2.m1.4.4.4.4.2.3.cmml">,</mo><mi id="S4.E2.m1.4.4.4.4.2.2" xref="S4.E2.m1.4.4.4.4.2.2.cmml">i</mi></mrow><mi id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.3" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="S4.E2.m1.6.6.6.6.1.1.2.2.5" xref="S4.E2.m1.6.6.6.6.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.6.6.6.6.1.3" xref="S4.E2.m1.6.6.6.7.cmml">)</mo></mrow></mrow><mrow id="S4.E2.m1.12.12.12" xref="S4.E2.m1.12.12.12.cmml"><msubsup id="S4.E2.m1.12.12.12.7" xref="S4.E2.m1.12.12.12.7.cmml"><mo id="S4.E2.m1.12.12.12.7.2.2" xref="S4.E2.m1.12.12.12.7.2.2.cmml">∑</mo><mrow id="S4.E2.m1.12.12.12.7.2.3" xref="S4.E2.m1.12.12.12.7.2.3.cmml"><mi id="S4.E2.m1.12.12.12.7.2.3.2" xref="S4.E2.m1.12.12.12.7.2.3.2.cmml">m</mi><mo id="S4.E2.m1.12.12.12.7.2.3.1" xref="S4.E2.m1.12.12.12.7.2.3.1.cmml">=</mo><mn id="S4.E2.m1.12.12.12.7.2.3.3" xref="S4.E2.m1.12.12.12.7.2.3.3.cmml">1</mn></mrow><mi id="S4.E2.m1.12.12.12.7.3" xref="S4.E2.m1.12.12.12.7.3.cmml">B</mi></msubsup><mrow id="S4.E2.m1.12.12.12.6.1" xref="S4.E2.m1.12.12.12.6.2.cmml"><mi id="S4.E2.m1.11.11.11.5" xref="S4.E2.m1.11.11.11.5.cmml">exp</mi><mo id="S4.E2.m1.12.12.12.6.1a" xref="S4.E2.m1.12.12.12.6.2.cmml">⁡</mo><mrow id="S4.E2.m1.12.12.12.6.1.1" xref="S4.E2.m1.12.12.12.6.2.cmml"><mo id="S4.E2.m1.12.12.12.6.1.1.2" xref="S4.E2.m1.12.12.12.6.2.cmml">(</mo><mrow id="S4.E2.m1.12.12.12.6.1.1.1" xref="S4.E2.m1.12.12.12.6.1.1.1.cmml"><mfrac id="S4.E2.m1.12.12.12.6.1.1.1.4" xref="S4.E2.m1.12.12.12.6.1.1.1.4.cmml"><mn id="S4.E2.m1.12.12.12.6.1.1.1.4.2" xref="S4.E2.m1.12.12.12.6.1.1.1.4.2.cmml">1</mn><mi id="S4.E2.m1.12.12.12.6.1.1.1.4.3" xref="S4.E2.m1.12.12.12.6.1.1.1.4.3.cmml">τ</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E2.m1.12.12.12.6.1.1.1.3" xref="S4.E2.m1.12.12.12.6.1.1.1.3.cmml">​</mo><mi id="S4.E2.m1.12.12.12.6.1.1.1.5" xref="S4.E2.m1.12.12.12.6.1.1.1.5.cmml">𝚜𝚒𝚖</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.12.12.12.6.1.1.1.3a" xref="S4.E2.m1.12.12.12.6.1.1.1.3.cmml">​</mo><mrow id="S4.E2.m1.12.12.12.6.1.1.1.2.2" xref="S4.E2.m1.12.12.12.6.1.1.1.2.3.cmml"><mo stretchy="false" id="S4.E2.m1.12.12.12.6.1.1.1.2.2.3" xref="S4.E2.m1.12.12.12.6.1.1.1.2.3.cmml">(</mo><msubsup id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.2" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.2.cmml">𝐅</mi><mrow id="S4.E2.m1.8.8.8.2.2.4" xref="S4.E2.m1.8.8.8.2.2.3.cmml"><mi id="S4.E2.m1.7.7.7.1.1.1" xref="S4.E2.m1.7.7.7.1.1.1.cmml">b</mi><mo id="S4.E2.m1.8.8.8.2.2.4.1" xref="S4.E2.m1.8.8.8.2.2.3.cmml">,</mo><mi id="S4.E2.m1.8.8.8.2.2.2" xref="S4.E2.m1.8.8.8.2.2.2.cmml">i</mi></mrow><mi id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.3" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.3.cmml">a</mi></msubsup><mo id="S4.E2.m1.12.12.12.6.1.1.1.2.2.4" xref="S4.E2.m1.12.12.12.6.1.1.1.2.3.cmml">,</mo><msubsup id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.cmml"><mover accent="true" id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.cmml"><mi id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.2" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.2.cmml">𝐅</mi><mo id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.1" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.1.cmml">^</mo></mover><mrow id="S4.E2.m1.10.10.10.4.2.4" xref="S4.E2.m1.10.10.10.4.2.3.cmml"><mi id="S4.E2.m1.9.9.9.3.1.1" xref="S4.E2.m1.9.9.9.3.1.1.cmml">m</mi><mo id="S4.E2.m1.10.10.10.4.2.4.1" xref="S4.E2.m1.10.10.10.4.2.3.cmml">,</mo><mi id="S4.E2.m1.10.10.10.4.2.2" xref="S4.E2.m1.10.10.10.4.2.2.cmml">i</mi></mrow><mi id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.3" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="S4.E2.m1.12.12.12.6.1.1.1.2.2.5" xref="S4.E2.m1.12.12.12.6.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.12.12.12.6.1.1.3" xref="S4.E2.m1.12.12.12.6.2.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.12b"><apply id="S4.E2.m1.12.13.cmml" xref="S4.E2.m1.12.13"><eq id="S4.E2.m1.12.13.1.cmml" xref="S4.E2.m1.12.13.1"></eq><ci id="S4.E2.m1.12.13.2.cmml" xref="S4.E2.m1.12.13.2">ℒ</ci><apply id="S4.E2.m1.12.13.3.cmml" xref="S4.E2.m1.12.13.3"><minus id="S4.E2.m1.12.13.3.1.cmml" xref="S4.E2.m1.12.13.3"></minus><apply id="S4.E2.m1.12.13.3.2.cmml" xref="S4.E2.m1.12.13.3.2"><times id="S4.E2.m1.12.13.3.2.1.cmml" xref="S4.E2.m1.12.13.3.2.1"></times><apply id="S4.E2.m1.12.13.3.2.2.cmml" xref="S4.E2.m1.12.13.3.2.2"><divide id="S4.E2.m1.12.13.3.2.2.1.cmml" xref="S4.E2.m1.12.13.3.2.2"></divide><cn type="integer" id="S4.E2.m1.12.13.3.2.2.2.cmml" xref="S4.E2.m1.12.13.3.2.2.2">1</cn><ci id="S4.E2.m1.12.13.3.2.2.3.cmml" xref="S4.E2.m1.12.13.3.2.2.3">𝐵</ci></apply><apply id="S4.E2.m1.12.13.3.2.3.cmml" xref="S4.E2.m1.12.13.3.2.3"><apply id="S4.E2.m1.12.13.3.2.3.1.cmml" xref="S4.E2.m1.12.13.3.2.3.1"><csymbol cd="ambiguous" id="S4.E2.m1.12.13.3.2.3.1.1.cmml" xref="S4.E2.m1.12.13.3.2.3.1">superscript</csymbol><apply id="S4.E2.m1.12.13.3.2.3.1.2.cmml" xref="S4.E2.m1.12.13.3.2.3.1"><csymbol cd="ambiguous" id="S4.E2.m1.12.13.3.2.3.1.2.1.cmml" xref="S4.E2.m1.12.13.3.2.3.1">subscript</csymbol><sum id="S4.E2.m1.12.13.3.2.3.1.2.2.cmml" xref="S4.E2.m1.12.13.3.2.3.1.2.2"></sum><apply id="S4.E2.m1.12.13.3.2.3.1.2.3.cmml" xref="S4.E2.m1.12.13.3.2.3.1.2.3"><eq id="S4.E2.m1.12.13.3.2.3.1.2.3.1.cmml" xref="S4.E2.m1.12.13.3.2.3.1.2.3.1"></eq><ci id="S4.E2.m1.12.13.3.2.3.1.2.3.2.cmml" xref="S4.E2.m1.12.13.3.2.3.1.2.3.2">𝑏</ci><cn type="integer" id="S4.E2.m1.12.13.3.2.3.1.2.3.3.cmml" xref="S4.E2.m1.12.13.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="S4.E2.m1.12.13.3.2.3.1.3.cmml" xref="S4.E2.m1.12.13.3.2.3.1.3">𝐵</ci></apply><apply id="S4.E2.m1.12.13.3.2.3.2.cmml" xref="S4.E2.m1.12.13.3.2.3.2"><apply id="S4.E2.m1.12.13.3.2.3.2.1.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1"><csymbol cd="ambiguous" id="S4.E2.m1.12.13.3.2.3.2.1.1.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1">superscript</csymbol><apply id="S4.E2.m1.12.13.3.2.3.2.1.2.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1"><csymbol cd="ambiguous" id="S4.E2.m1.12.13.3.2.3.2.1.2.1.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1">subscript</csymbol><sum id="S4.E2.m1.12.13.3.2.3.2.1.2.2.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1.2.2"></sum><apply id="S4.E2.m1.12.13.3.2.3.2.1.2.3.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1.2.3"><eq id="S4.E2.m1.12.13.3.2.3.2.1.2.3.1.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1.2.3.1"></eq><ci id="S4.E2.m1.12.13.3.2.3.2.1.2.3.2.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1.2.3.2">𝑖</ci><cn type="integer" id="S4.E2.m1.12.13.3.2.3.2.1.2.3.3.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1.2.3.3">1</cn></apply></apply><ci id="S4.E2.m1.12.13.3.2.3.2.1.3.cmml" xref="S4.E2.m1.12.13.3.2.3.2.1.3">𝑇</ci></apply><apply id="S4.E2.m1.12.13.3.2.3.2.2.cmml" xref="S4.E2.m1.12.13.3.2.3.2.2"><log id="S4.E2.m1.12.13.3.2.3.2.2.1.cmml" xref="S4.E2.m1.12.13.3.2.3.2.2.1"></log><apply id="S4.E2.m1.12.12.cmml" xref="S4.E2.m1.12.12"><divide id="S4.E2.m1.12.12.13.cmml" xref="S4.E2.m1.12.12"></divide><apply id="S4.E2.m1.6.6.6.7.cmml" xref="S4.E2.m1.6.6.6.6"><exp id="S4.E2.m1.5.5.5.5.cmml" xref="S4.E2.m1.5.5.5.5"></exp><apply id="S4.E2.m1.6.6.6.6.1.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1"><times id="S4.E2.m1.6.6.6.6.1.1.3.cmml" xref="S4.E2.m1.6.6.6.6.1.1.3"></times><apply id="S4.E2.m1.6.6.6.6.1.1.4.cmml" xref="S4.E2.m1.6.6.6.6.1.1.4"><divide id="S4.E2.m1.6.6.6.6.1.1.4.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.4"></divide><cn type="integer" id="S4.E2.m1.6.6.6.6.1.1.4.2.cmml" xref="S4.E2.m1.6.6.6.6.1.1.4.2">1</cn><ci id="S4.E2.m1.6.6.6.6.1.1.4.3.cmml" xref="S4.E2.m1.6.6.6.6.1.1.4.3">𝜏</ci></apply><ci id="S4.E2.m1.6.6.6.6.1.1.5.cmml" xref="S4.E2.m1.6.6.6.6.1.1.5">𝚜𝚒𝚖</ci><interval closure="open" id="S4.E2.m1.6.6.6.6.1.1.2.3.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2"><apply id="S4.E2.m1.6.6.6.6.1.1.1.1.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.6.6.1.1.1.1.1.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1">subscript</csymbol><apply id="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1">superscript</csymbol><ci id="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.2">𝐅</ci><ci id="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.6.6.6.6.1.1.1.1.1.2.3">𝑎</ci></apply><list id="S4.E2.m1.2.2.2.2.2.3.cmml" xref="S4.E2.m1.2.2.2.2.2.4"><ci id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1">𝑏</ci><ci id="S4.E2.m1.2.2.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2.2.2">𝑖</ci></list></apply><apply id="S4.E2.m1.6.6.6.6.1.1.2.2.2.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.6.6.1.1.2.2.2.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2">subscript</csymbol><apply id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2">superscript</csymbol><apply id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2"><ci id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.1.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.1">^</ci><ci id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.2.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.2.2">𝐅</ci></apply><ci id="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.3.cmml" xref="S4.E2.m1.6.6.6.6.1.1.2.2.2.2.3">𝑡</ci></apply><list id="S4.E2.m1.4.4.4.4.2.3.cmml" xref="S4.E2.m1.4.4.4.4.2.4"><ci id="S4.E2.m1.3.3.3.3.1.1.cmml" xref="S4.E2.m1.3.3.3.3.1.1">𝑏</ci><ci id="S4.E2.m1.4.4.4.4.2.2.cmml" xref="S4.E2.m1.4.4.4.4.2.2">𝑖</ci></list></apply></interval></apply></apply><apply id="S4.E2.m1.12.12.12.cmml" xref="S4.E2.m1.12.12.12"><apply id="S4.E2.m1.12.12.12.7.cmml" xref="S4.E2.m1.12.12.12.7"><csymbol cd="ambiguous" id="S4.E2.m1.12.12.12.7.1.cmml" xref="S4.E2.m1.12.12.12.7">superscript</csymbol><apply id="S4.E2.m1.12.12.12.7.2.cmml" xref="S4.E2.m1.12.12.12.7"><csymbol cd="ambiguous" id="S4.E2.m1.12.12.12.7.2.1.cmml" xref="S4.E2.m1.12.12.12.7">subscript</csymbol><sum id="S4.E2.m1.12.12.12.7.2.2.cmml" xref="S4.E2.m1.12.12.12.7.2.2"></sum><apply id="S4.E2.m1.12.12.12.7.2.3.cmml" xref="S4.E2.m1.12.12.12.7.2.3"><eq id="S4.E2.m1.12.12.12.7.2.3.1.cmml" xref="S4.E2.m1.12.12.12.7.2.3.1"></eq><ci id="S4.E2.m1.12.12.12.7.2.3.2.cmml" xref="S4.E2.m1.12.12.12.7.2.3.2">𝑚</ci><cn type="integer" id="S4.E2.m1.12.12.12.7.2.3.3.cmml" xref="S4.E2.m1.12.12.12.7.2.3.3">1</cn></apply></apply><ci id="S4.E2.m1.12.12.12.7.3.cmml" xref="S4.E2.m1.12.12.12.7.3">𝐵</ci></apply><apply id="S4.E2.m1.12.12.12.6.2.cmml" xref="S4.E2.m1.12.12.12.6.1"><exp id="S4.E2.m1.11.11.11.5.cmml" xref="S4.E2.m1.11.11.11.5"></exp><apply id="S4.E2.m1.12.12.12.6.1.1.1.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1"><times id="S4.E2.m1.12.12.12.6.1.1.1.3.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.3"></times><apply id="S4.E2.m1.12.12.12.6.1.1.1.4.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.4"><divide id="S4.E2.m1.12.12.12.6.1.1.1.4.1.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.4"></divide><cn type="integer" id="S4.E2.m1.12.12.12.6.1.1.1.4.2.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.4.2">1</cn><ci id="S4.E2.m1.12.12.12.6.1.1.1.4.3.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.4.3">𝜏</ci></apply><ci id="S4.E2.m1.12.12.12.6.1.1.1.5.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.5">𝚜𝚒𝚖</ci><interval closure="open" id="S4.E2.m1.12.12.12.6.1.1.1.2.3.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2"><apply id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1">superscript</csymbol><ci id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.2">𝐅</ci><ci id="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.1.1.1.2.3">𝑎</ci></apply><list id="S4.E2.m1.8.8.8.2.2.3.cmml" xref="S4.E2.m1.8.8.8.2.2.4"><ci id="S4.E2.m1.7.7.7.1.1.1.cmml" xref="S4.E2.m1.7.7.7.1.1.1">𝑏</ci><ci id="S4.E2.m1.8.8.8.2.2.2.cmml" xref="S4.E2.m1.8.8.8.2.2.2">𝑖</ci></list></apply><apply id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.1.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2">superscript</csymbol><apply id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.1.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2">subscript</csymbol><apply id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2"><ci id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.1.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.1">^</ci><ci id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.2.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.2.2.2">𝐅</ci></apply><list id="S4.E2.m1.10.10.10.4.2.3.cmml" xref="S4.E2.m1.10.10.10.4.2.4"><ci id="S4.E2.m1.9.9.9.3.1.1.cmml" xref="S4.E2.m1.9.9.9.3.1.1">𝑚</ci><ci id="S4.E2.m1.10.10.10.4.2.2.cmml" xref="S4.E2.m1.10.10.10.4.2.2">𝑖</ci></list></apply><ci id="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.3.cmml" xref="S4.E2.m1.12.12.12.6.1.1.1.2.2.2.3">𝑡</ci></apply></interval></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.12c">\mathcal{L}=-\frac{1}{B}\sum_{b=1}^{B}\sum_{i=1}^{T}\log\frac{\exp\left(\frac{1}{\tau}\mathtt{sim}(\mathbf{F}^{a}_{b,i},\hat{\mathbf{F}}^{t}_{b,i})\right)}{\sum_{m=1}^{B}\exp\left(\frac{1}{\tau}\mathtt{sim}(\mathbf{F}^{a}_{b,i},\hat{\mathbf{F}}_{m,i}^{t})\right)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.10" class="ltx_p">where the similarity <math id="S4.SS2.p1.4.m1.6" class="ltx_Math" alttext="\mathtt{sim}(\mathbf{F}^{a}_{b,i},\mathbf{F}^{v}_{b,i})" display="inline"><semantics id="S4.SS2.p1.4.m1.6a"><mrow id="S4.SS2.p1.4.m1.6.6" xref="S4.SS2.p1.4.m1.6.6.cmml"><mi id="S4.SS2.p1.4.m1.6.6.4" xref="S4.SS2.p1.4.m1.6.6.4.cmml">𝚜𝚒𝚖</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.4.m1.6.6.3" xref="S4.SS2.p1.4.m1.6.6.3.cmml">​</mo><mrow id="S4.SS2.p1.4.m1.6.6.2.2" xref="S4.SS2.p1.4.m1.6.6.2.3.cmml"><mo stretchy="false" id="S4.SS2.p1.4.m1.6.6.2.2.3" xref="S4.SS2.p1.4.m1.6.6.2.3.cmml">(</mo><msubsup id="S4.SS2.p1.4.m1.5.5.1.1.1" xref="S4.SS2.p1.4.m1.5.5.1.1.1.cmml"><mi id="S4.SS2.p1.4.m1.5.5.1.1.1.2.2" xref="S4.SS2.p1.4.m1.5.5.1.1.1.2.2.cmml">𝐅</mi><mrow id="S4.SS2.p1.4.m1.2.2.2.4" xref="S4.SS2.p1.4.m1.2.2.2.3.cmml"><mi id="S4.SS2.p1.4.m1.1.1.1.1" xref="S4.SS2.p1.4.m1.1.1.1.1.cmml">b</mi><mo id="S4.SS2.p1.4.m1.2.2.2.4.1" xref="S4.SS2.p1.4.m1.2.2.2.3.cmml">,</mo><mi id="S4.SS2.p1.4.m1.2.2.2.2" xref="S4.SS2.p1.4.m1.2.2.2.2.cmml">i</mi></mrow><mi id="S4.SS2.p1.4.m1.5.5.1.1.1.2.3" xref="S4.SS2.p1.4.m1.5.5.1.1.1.2.3.cmml">a</mi></msubsup><mo id="S4.SS2.p1.4.m1.6.6.2.2.4" xref="S4.SS2.p1.4.m1.6.6.2.3.cmml">,</mo><msubsup id="S4.SS2.p1.4.m1.6.6.2.2.2" xref="S4.SS2.p1.4.m1.6.6.2.2.2.cmml"><mi id="S4.SS2.p1.4.m1.6.6.2.2.2.2.2" xref="S4.SS2.p1.4.m1.6.6.2.2.2.2.2.cmml">𝐅</mi><mrow id="S4.SS2.p1.4.m1.4.4.2.4" xref="S4.SS2.p1.4.m1.4.4.2.3.cmml"><mi id="S4.SS2.p1.4.m1.3.3.1.1" xref="S4.SS2.p1.4.m1.3.3.1.1.cmml">b</mi><mo id="S4.SS2.p1.4.m1.4.4.2.4.1" xref="S4.SS2.p1.4.m1.4.4.2.3.cmml">,</mo><mi id="S4.SS2.p1.4.m1.4.4.2.2" xref="S4.SS2.p1.4.m1.4.4.2.2.cmml">i</mi></mrow><mi id="S4.SS2.p1.4.m1.6.6.2.2.2.2.3" xref="S4.SS2.p1.4.m1.6.6.2.2.2.2.3.cmml">v</mi></msubsup><mo stretchy="false" id="S4.SS2.p1.4.m1.6.6.2.2.5" xref="S4.SS2.p1.4.m1.6.6.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m1.6b"><apply id="S4.SS2.p1.4.m1.6.6.cmml" xref="S4.SS2.p1.4.m1.6.6"><times id="S4.SS2.p1.4.m1.6.6.3.cmml" xref="S4.SS2.p1.4.m1.6.6.3"></times><ci id="S4.SS2.p1.4.m1.6.6.4.cmml" xref="S4.SS2.p1.4.m1.6.6.4">𝚜𝚒𝚖</ci><interval closure="open" id="S4.SS2.p1.4.m1.6.6.2.3.cmml" xref="S4.SS2.p1.4.m1.6.6.2.2"><apply id="S4.SS2.p1.4.m1.5.5.1.1.1.cmml" xref="S4.SS2.p1.4.m1.5.5.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m1.5.5.1.1.1.1.cmml" xref="S4.SS2.p1.4.m1.5.5.1.1.1">subscript</csymbol><apply id="S4.SS2.p1.4.m1.5.5.1.1.1.2.cmml" xref="S4.SS2.p1.4.m1.5.5.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m1.5.5.1.1.1.2.1.cmml" xref="S4.SS2.p1.4.m1.5.5.1.1.1">superscript</csymbol><ci id="S4.SS2.p1.4.m1.5.5.1.1.1.2.2.cmml" xref="S4.SS2.p1.4.m1.5.5.1.1.1.2.2">𝐅</ci><ci id="S4.SS2.p1.4.m1.5.5.1.1.1.2.3.cmml" xref="S4.SS2.p1.4.m1.5.5.1.1.1.2.3">𝑎</ci></apply><list id="S4.SS2.p1.4.m1.2.2.2.3.cmml" xref="S4.SS2.p1.4.m1.2.2.2.4"><ci id="S4.SS2.p1.4.m1.1.1.1.1.cmml" xref="S4.SS2.p1.4.m1.1.1.1.1">𝑏</ci><ci id="S4.SS2.p1.4.m1.2.2.2.2.cmml" xref="S4.SS2.p1.4.m1.2.2.2.2">𝑖</ci></list></apply><apply id="S4.SS2.p1.4.m1.6.6.2.2.2.cmml" xref="S4.SS2.p1.4.m1.6.6.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m1.6.6.2.2.2.1.cmml" xref="S4.SS2.p1.4.m1.6.6.2.2.2">subscript</csymbol><apply id="S4.SS2.p1.4.m1.6.6.2.2.2.2.cmml" xref="S4.SS2.p1.4.m1.6.6.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m1.6.6.2.2.2.2.1.cmml" xref="S4.SS2.p1.4.m1.6.6.2.2.2">superscript</csymbol><ci id="S4.SS2.p1.4.m1.6.6.2.2.2.2.2.cmml" xref="S4.SS2.p1.4.m1.6.6.2.2.2.2.2">𝐅</ci><ci id="S4.SS2.p1.4.m1.6.6.2.2.2.2.3.cmml" xref="S4.SS2.p1.4.m1.6.6.2.2.2.2.3">𝑣</ci></apply><list id="S4.SS2.p1.4.m1.4.4.2.3.cmml" xref="S4.SS2.p1.4.m1.4.4.2.4"><ci id="S4.SS2.p1.4.m1.3.3.1.1.cmml" xref="S4.SS2.p1.4.m1.3.3.1.1">𝑏</ci><ci id="S4.SS2.p1.4.m1.4.4.2.2.cmml" xref="S4.SS2.p1.4.m1.4.4.2.2">𝑖</ci></list></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m1.6c">\mathtt{sim}(\mathbf{F}^{a}_{b,i},\mathbf{F}^{v}_{b,i})</annotation></semantics></math> denotes the temporal audio-textual cosine similarity of <math id="S4.SS2.p1.5.m2.2" class="ltx_Math" alttext="\mathbf{F}^{a}_{b,i}" display="inline"><semantics id="S4.SS2.p1.5.m2.2a"><msubsup id="S4.SS2.p1.5.m2.2.3" xref="S4.SS2.p1.5.m2.2.3.cmml"><mi id="S4.SS2.p1.5.m2.2.3.2.2" xref="S4.SS2.p1.5.m2.2.3.2.2.cmml">𝐅</mi><mrow id="S4.SS2.p1.5.m2.2.2.2.4" xref="S4.SS2.p1.5.m2.2.2.2.3.cmml"><mi id="S4.SS2.p1.5.m2.1.1.1.1" xref="S4.SS2.p1.5.m2.1.1.1.1.cmml">b</mi><mo id="S4.SS2.p1.5.m2.2.2.2.4.1" xref="S4.SS2.p1.5.m2.2.2.2.3.cmml">,</mo><mi id="S4.SS2.p1.5.m2.2.2.2.2" xref="S4.SS2.p1.5.m2.2.2.2.2.cmml">i</mi></mrow><mi id="S4.SS2.p1.5.m2.2.3.2.3" xref="S4.SS2.p1.5.m2.2.3.2.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m2.2b"><apply id="S4.SS2.p1.5.m2.2.3.cmml" xref="S4.SS2.p1.5.m2.2.3"><csymbol cd="ambiguous" id="S4.SS2.p1.5.m2.2.3.1.cmml" xref="S4.SS2.p1.5.m2.2.3">subscript</csymbol><apply id="S4.SS2.p1.5.m2.2.3.2.cmml" xref="S4.SS2.p1.5.m2.2.3"><csymbol cd="ambiguous" id="S4.SS2.p1.5.m2.2.3.2.1.cmml" xref="S4.SS2.p1.5.m2.2.3">superscript</csymbol><ci id="S4.SS2.p1.5.m2.2.3.2.2.cmml" xref="S4.SS2.p1.5.m2.2.3.2.2">𝐅</ci><ci id="S4.SS2.p1.5.m2.2.3.2.3.cmml" xref="S4.SS2.p1.5.m2.2.3.2.3">𝑎</ci></apply><list id="S4.SS2.p1.5.m2.2.2.2.3.cmml" xref="S4.SS2.p1.5.m2.2.2.2.4"><ci id="S4.SS2.p1.5.m2.1.1.1.1.cmml" xref="S4.SS2.p1.5.m2.1.1.1.1">𝑏</ci><ci id="S4.SS2.p1.5.m2.2.2.2.2.cmml" xref="S4.SS2.p1.5.m2.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m2.2c">\mathbf{F}^{a}_{b,i}</annotation></semantics></math> and <math id="S4.SS2.p1.6.m3.2" class="ltx_Math" alttext="\mathbf{F}^{v}_{b,i}" display="inline"><semantics id="S4.SS2.p1.6.m3.2a"><msubsup id="S4.SS2.p1.6.m3.2.3" xref="S4.SS2.p1.6.m3.2.3.cmml"><mi id="S4.SS2.p1.6.m3.2.3.2.2" xref="S4.SS2.p1.6.m3.2.3.2.2.cmml">𝐅</mi><mrow id="S4.SS2.p1.6.m3.2.2.2.4" xref="S4.SS2.p1.6.m3.2.2.2.3.cmml"><mi id="S4.SS2.p1.6.m3.1.1.1.1" xref="S4.SS2.p1.6.m3.1.1.1.1.cmml">b</mi><mo id="S4.SS2.p1.6.m3.2.2.2.4.1" xref="S4.SS2.p1.6.m3.2.2.2.3.cmml">,</mo><mi id="S4.SS2.p1.6.m3.2.2.2.2" xref="S4.SS2.p1.6.m3.2.2.2.2.cmml">i</mi></mrow><mi id="S4.SS2.p1.6.m3.2.3.2.3" xref="S4.SS2.p1.6.m3.2.3.2.3.cmml">v</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m3.2b"><apply id="S4.SS2.p1.6.m3.2.3.cmml" xref="S4.SS2.p1.6.m3.2.3"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m3.2.3.1.cmml" xref="S4.SS2.p1.6.m3.2.3">subscript</csymbol><apply id="S4.SS2.p1.6.m3.2.3.2.cmml" xref="S4.SS2.p1.6.m3.2.3"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m3.2.3.2.1.cmml" xref="S4.SS2.p1.6.m3.2.3">superscript</csymbol><ci id="S4.SS2.p1.6.m3.2.3.2.2.cmml" xref="S4.SS2.p1.6.m3.2.3.2.2">𝐅</ci><ci id="S4.SS2.p1.6.m3.2.3.2.3.cmml" xref="S4.SS2.p1.6.m3.2.3.2.3">𝑣</ci></apply><list id="S4.SS2.p1.6.m3.2.2.2.3.cmml" xref="S4.SS2.p1.6.m3.2.2.2.4"><ci id="S4.SS2.p1.6.m3.1.1.1.1.cmml" xref="S4.SS2.p1.6.m3.1.1.1.1">𝑏</ci><ci id="S4.SS2.p1.6.m3.2.2.2.2.cmml" xref="S4.SS2.p1.6.m3.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m3.2c">\mathbf{F}^{v}_{b,i}</annotation></semantics></math> across all temporal locations at <math id="S4.SS2.p1.7.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS2.p1.7.m4.1a"><mi id="S4.SS2.p1.7.m4.1.1" xref="S4.SS2.p1.7.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m4.1b"><ci id="S4.SS2.p1.7.m4.1.1.cmml" xref="S4.SS2.p1.7.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m4.1c">i</annotation></semantics></math>-th second.
<math id="S4.SS2.p1.8.m5.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.SS2.p1.8.m5.1a"><mi id="S4.SS2.p1.8.m5.1.1" xref="S4.SS2.p1.8.m5.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m5.1b"><ci id="S4.SS2.p1.8.m5.1.1.cmml" xref="S4.SS2.p1.8.m5.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m5.1c">B</annotation></semantics></math> is the batch size, <math id="S4.SS2.p1.9.m6.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS2.p1.9.m6.1a"><mi id="S4.SS2.p1.9.m6.1.1" xref="S4.SS2.p1.9.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m6.1b"><ci id="S4.SS2.p1.9.m6.1.1.cmml" xref="S4.SS2.p1.9.m6.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m6.1c">D</annotation></semantics></math> is the dimension size, and <math id="S4.SS2.p1.10.m7.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS2.p1.10.m7.1a"><mi id="S4.SS2.p1.10.m7.1.1" xref="S4.SS2.p1.10.m7.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m7.1b"><ci id="S4.SS2.p1.10.m7.1.1.cmml" xref="S4.SS2.p1.10.m7.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m7.1c">\tau</annotation></semantics></math> is a temperature hyper-parameter.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Audio-Visual ControlNet</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.2" class="ltx_p">With the benefit of visual-aligned CLAP pre-training, we use the pre-trained text encoder to extract text embeddings <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\hat{\mathbf{F}}^{t}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><msup id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mover accent="true" id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2.2" xref="S4.SS3.p1.1.m1.1.1.2.2.cmml">𝐅</mi><mo id="S4.SS3.p1.1.m1.1.1.2.1" xref="S4.SS3.p1.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">superscript</csymbol><apply id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2"><ci id="S4.SS3.p1.1.m1.1.1.2.1.cmml" xref="S4.SS3.p1.1.m1.1.1.2.1">^</ci><ci id="S4.SS3.p1.1.m1.1.1.2.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2.2">𝐅</ci></apply><ci id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\hat{\mathbf{F}}^{t}</annotation></semantics></math> with visual-aligned semantics as the condition for latent diffusion models.
In order to enhance the temporal consistency, we are inspired by ControlNet <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib51" title="" class="ltx_ref">2023</a>)</cite> for multimodal conditional text-to-image diffusion models and propose a novel Audio-Visual ControlNet module with temporal self-attention layers, as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Benchmark Details ‣ 3 T2AV-Bench &amp; Metrics ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Specifically, we apply temporal self-attention layers <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\phi(\cdot)" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.2" xref="S4.SS3.p1.2.m2.1.2.cmml"><mi id="S4.SS3.p1.2.m2.1.2.2" xref="S4.SS3.p1.2.m2.1.2.2.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.2.1" xref="S4.SS3.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S4.SS3.p1.2.m2.1.2.3.2" xref="S4.SS3.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S4.SS3.p1.2.m2.1.2.3.2.1" xref="S4.SS3.p1.2.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S4.SS3.p1.2.m2.1.2.3.2.2" xref="S4.SS3.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.2.cmml" xref="S4.SS3.p1.2.m2.1.2"><times id="S4.SS3.p1.2.m2.1.2.1.cmml" xref="S4.SS3.p1.2.m2.1.2.1"></times><ci id="S4.SS3.p1.2.m2.1.2.2.cmml" xref="S4.SS3.p1.2.m2.1.2.2">italic-ϕ</ci><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\phi(\cdot)</annotation></semantics></math> to aggregate temporal features from the raw output features of the pre-trained visual encoder as:</p>
<table id="S4.E3" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S4.E3X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E3X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\{\hat{\mathbf{F}}_{i}^{v}\}_{i=1}^{T}=\{\phi(\mathbf{F}_{i}^{v},\mathbf{F}^{v},\mathbf{F}^{v})\}_{i=1}^{T},\quad\mathbf{F}^{v}=\{\mathbf{F}_{i}^{v}\}_{i=1}^{T}" display="inline"><semantics id="S4.E3X.2.1.1.m1.2a"><mrow id="S4.E3X.2.1.1.m1.2.2.2" xref="S4.E3X.2.1.1.m1.2.2.3.cmml"><mrow id="S4.E3X.2.1.1.m1.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.cmml"><msubsup id="S4.E3X.2.1.1.m1.1.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.cmml"><mrow id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml">{</mo><msubsup id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">𝐅</mi><mo id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">v</mi></msubsup><mo stretchy="false" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.2.cmml">i</mi><mo id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.1.cmml">=</mo><mn id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.E3X.2.1.1.m1.1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.3.cmml">T</mi></msubsup><mo id="S4.E3X.2.1.1.m1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.3.cmml">=</mo><msubsup id="S4.E3X.2.1.1.m1.1.1.1.1.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.cmml"><mrow id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.2.cmml"><mo stretchy="false" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.2.cmml">{</mo><mrow id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.5" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.5.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.4" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.4.cmml">​</mo><mrow id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.4.cmml"><mo stretchy="false" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.4" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.4.cmml">(</mo><msubsup id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.2.cmml">𝐅</mi><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.3.cmml">v</mi></msubsup><mo id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.5" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.4.cmml">,</mo><msup id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.2.cmml">𝐅</mi><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.3.cmml">v</mi></msup><mo id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.6" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.4.cmml">,</mo><msup id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.2.cmml">𝐅</mi><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.3.cmml">v</mi></msup><mo stretchy="false" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.7" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.4.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.2.cmml">}</mo></mrow><mrow id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.cmml"><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.2" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.2.cmml">i</mi><mo id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.1" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.1.cmml">=</mo><mn id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.3.cmml">1</mn></mrow><mi id="S4.E3X.2.1.1.m1.1.1.1.1.2.3" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.3.cmml">T</mi></msubsup></mrow><mo rspace="1.167em" id="S4.E3X.2.1.1.m1.2.2.2.3" xref="S4.E3X.2.1.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.E3X.2.1.1.m1.2.2.2.2" xref="S4.E3X.2.1.1.m1.2.2.2.2.cmml"><msup id="S4.E3X.2.1.1.m1.2.2.2.2.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.3.cmml"><mi id="S4.E3X.2.1.1.m1.2.2.2.2.3.2" xref="S4.E3X.2.1.1.m1.2.2.2.2.3.2.cmml">𝐅</mi><mi id="S4.E3X.2.1.1.m1.2.2.2.2.3.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.3.3.cmml">v</mi></msup><mo id="S4.E3X.2.1.1.m1.2.2.2.2.2" xref="S4.E3X.2.1.1.m1.2.2.2.2.2.cmml">=</mo><msubsup id="S4.E3X.2.1.1.m1.2.2.2.2.1" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.cmml"><mrow id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.2" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.2.cmml">{</mo><msubsup id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.cmml"><mi id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.2" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.2.cmml">𝐅</mi><mi id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.3.cmml">i</mi><mi id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.3.cmml">v</mi></msubsup><mo stretchy="false" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.cmml"><mi id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.2" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.2.cmml">i</mi><mo id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.1" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.1.cmml">=</mo><mn id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.3.cmml">1</mn></mrow><mi id="S4.E3X.2.1.1.m1.2.2.2.2.1.3" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.3.cmml">T</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3X.2.1.1.m1.2b"><apply id="S4.E3X.2.1.1.m1.2.2.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.2.2.3a.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.E3X.2.1.1.m1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1"><eq id="S4.E3X.2.1.1.m1.1.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.3"></eq><apply id="S4.E3X.2.1.1.m1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1">superscript</csymbol><apply id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1">subscript</csymbol><set id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1"><apply id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2"><ci id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2">𝐅</ci></apply><ci id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3">𝑣</ci></apply></set><apply id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3"><eq id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.1"></eq><ci id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.E3X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.1.3">𝑇</ci></apply><apply id="S4.E3X.2.1.1.m1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2">superscript</csymbol><apply id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2">subscript</csymbol><set id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1"><apply id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1"><times id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.4.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.4"></times><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.5.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.5">italic-ϕ</ci><vector id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.4.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3"><apply id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1">superscript</csymbol><apply id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.2">𝐅</ci><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.1.1.1.3">𝑣</ci></apply><apply id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2">superscript</csymbol><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.2">𝐅</ci><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.2.2.2.3">𝑣</ci></apply><apply id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3">superscript</csymbol><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.2">𝐅</ci><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.1.1.1.3.3.3.3">𝑣</ci></apply></vector></apply></set><apply id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3"><eq id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.1.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.1"></eq><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.2.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.2">𝑖</ci><cn type="integer" id="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.1.3.3">1</cn></apply></apply><ci id="S4.E3X.2.1.1.m1.1.1.1.1.2.3.cmml" xref="S4.E3X.2.1.1.m1.1.1.1.1.2.3">𝑇</ci></apply></apply><apply id="S4.E3X.2.1.1.m1.2.2.2.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2"><eq id="S4.E3X.2.1.1.m1.2.2.2.2.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.2"></eq><apply id="S4.E3X.2.1.1.m1.2.2.2.2.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.2.2.2.2.3.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.3">superscript</csymbol><ci id="S4.E3X.2.1.1.m1.2.2.2.2.3.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.3.2">𝐅</ci><ci id="S4.E3X.2.1.1.m1.2.2.2.2.3.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.3.3">𝑣</ci></apply><apply id="S4.E3X.2.1.1.m1.2.2.2.2.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.2.2.2.2.1.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1">superscript</csymbol><apply id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1">subscript</csymbol><set id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1"><apply id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1">superscript</csymbol><apply id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.2">𝐅</ci><ci id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.1.1.1.3">𝑣</ci></apply></set><apply id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3"><eq id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.1.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.1"></eq><ci id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.2.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.2">𝑖</ci><cn type="integer" id="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.1.3.3">1</cn></apply></apply><ci id="S4.E3X.2.1.1.m1.2.2.2.2.1.3.cmml" xref="S4.E3X.2.1.1.m1.2.2.2.2.1.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3X.2.1.1.m1.2c">\displaystyle\{\hat{\mathbf{F}}_{i}^{v}\}_{i=1}^{T}=\{\phi(\mathbf{F}_{i}^{v},\mathbf{F}^{v},\mathbf{F}^{v})\}_{i=1}^{T},\quad\mathbf{F}^{v}=\{\mathbf{F}_{i}^{v}\}_{i=1}^{T}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(3)</span></td>
</tr>
</tbody>
</table>
<p id="S4.SS3.p1.3" class="ltx_p">The self-attention operator <math id="S4.SS3.p1.3.m1.1" class="ltx_Math" alttext="\phi(\cdot)" display="inline"><semantics id="S4.SS3.p1.3.m1.1a"><mrow id="S4.SS3.p1.3.m1.1.2" xref="S4.SS3.p1.3.m1.1.2.cmml"><mi id="S4.SS3.p1.3.m1.1.2.2" xref="S4.SS3.p1.3.m1.1.2.2.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m1.1.2.1" xref="S4.SS3.p1.3.m1.1.2.1.cmml">​</mo><mrow id="S4.SS3.p1.3.m1.1.2.3.2" xref="S4.SS3.p1.3.m1.1.2.cmml"><mo stretchy="false" id="S4.SS3.p1.3.m1.1.2.3.2.1" xref="S4.SS3.p1.3.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m1.1.1" xref="S4.SS3.p1.3.m1.1.1.cmml">⋅</mo><mo stretchy="false" id="S4.SS3.p1.3.m1.1.2.3.2.2" xref="S4.SS3.p1.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m1.1b"><apply id="S4.SS3.p1.3.m1.1.2.cmml" xref="S4.SS3.p1.3.m1.1.2"><times id="S4.SS3.p1.3.m1.1.2.1.cmml" xref="S4.SS3.p1.3.m1.1.2.1"></times><ci id="S4.SS3.p1.3.m1.1.2.2.cmml" xref="S4.SS3.p1.3.m1.1.2.2">italic-ϕ</ci><ci id="S4.SS3.p1.3.m1.1.1.cmml" xref="S4.SS3.p1.3.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m1.1c">\phi(\cdot)</annotation></semantics></math> is formulated as:</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.4" class="ltx_Math" alttext="\phi(\mathbf{F}_{i},\mathbf{F}^{v},\mathbf{F}^{v})=\mbox{Softmax}(\dfrac{\mathbf{F}_{i}(\mathbf{F}^{v})^{\top}}{\sqrt{D}})\mathbf{\mathbf{F}^{v}}" display="block"><semantics id="S4.E4.m1.4a"><mrow id="S4.E4.m1.4.4" xref="S4.E4.m1.4.4.cmml"><mrow id="S4.E4.m1.4.4.3" xref="S4.E4.m1.4.4.3.cmml"><mi id="S4.E4.m1.4.4.3.5" xref="S4.E4.m1.4.4.3.5.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.3.4" xref="S4.E4.m1.4.4.3.4.cmml">​</mo><mrow id="S4.E4.m1.4.4.3.3.3" xref="S4.E4.m1.4.4.3.3.4.cmml"><mo stretchy="false" id="S4.E4.m1.4.4.3.3.3.4" xref="S4.E4.m1.4.4.3.3.4.cmml">(</mo><msub id="S4.E4.m1.2.2.1.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.cmml"><mi id="S4.E4.m1.2.2.1.1.1.1.2" xref="S4.E4.m1.2.2.1.1.1.1.2.cmml">𝐅</mi><mi id="S4.E4.m1.2.2.1.1.1.1.3" xref="S4.E4.m1.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.E4.m1.4.4.3.3.3.5" xref="S4.E4.m1.4.4.3.3.4.cmml">,</mo><msup id="S4.E4.m1.3.3.2.2.2.2" xref="S4.E4.m1.3.3.2.2.2.2.cmml"><mi id="S4.E4.m1.3.3.2.2.2.2.2" xref="S4.E4.m1.3.3.2.2.2.2.2.cmml">𝐅</mi><mi id="S4.E4.m1.3.3.2.2.2.2.3" xref="S4.E4.m1.3.3.2.2.2.2.3.cmml">v</mi></msup><mo id="S4.E4.m1.4.4.3.3.3.6" xref="S4.E4.m1.4.4.3.3.4.cmml">,</mo><msup id="S4.E4.m1.4.4.3.3.3.3" xref="S4.E4.m1.4.4.3.3.3.3.cmml"><mi id="S4.E4.m1.4.4.3.3.3.3.2" xref="S4.E4.m1.4.4.3.3.3.3.2.cmml">𝐅</mi><mi id="S4.E4.m1.4.4.3.3.3.3.3" xref="S4.E4.m1.4.4.3.3.3.3.3.cmml">v</mi></msup><mo stretchy="false" id="S4.E4.m1.4.4.3.3.3.7" xref="S4.E4.m1.4.4.3.3.4.cmml">)</mo></mrow></mrow><mo id="S4.E4.m1.4.4.4" xref="S4.E4.m1.4.4.4.cmml">=</mo><mrow id="S4.E4.m1.4.4.5" xref="S4.E4.m1.4.4.5.cmml"><mtext id="S4.E4.m1.4.4.5.2" xref="S4.E4.m1.4.4.5.2a.cmml">Softmax</mtext><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.5.1" xref="S4.E4.m1.4.4.5.1.cmml">​</mo><mrow id="S4.E4.m1.4.4.5.3.2" xref="S4.E4.m1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.4.4.5.3.2.1" xref="S4.E4.m1.1.1.cmml">(</mo><mfrac id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.cmml"><msub id="S4.E4.m1.1.1.1.3" xref="S4.E4.m1.1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.3.2.cmml">𝐅</mi><mi id="S4.E4.m1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.E4.m1.1.1.1.2" xref="S4.E4.m1.1.1.1.2.cmml">​</mo><msup id="S4.E4.m1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.cmml"><mrow id="S4.E4.m1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.1.2.cmml">𝐅</mi><mi id="S4.E4.m1.1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.3.cmml">v</mi></msup><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E4.m1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.3.cmml">⊤</mo></msup></mrow><msqrt id="S4.E4.m1.1.1.3" xref="S4.E4.m1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.3.2" xref="S4.E4.m1.1.1.3.2.cmml">D</mi></msqrt></mfrac><mo stretchy="false" id="S4.E4.m1.4.4.5.3.2.2" xref="S4.E4.m1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E4.m1.4.4.5.1a" xref="S4.E4.m1.4.4.5.1.cmml">​</mo><msup id="S4.E4.m1.4.4.5.4" xref="S4.E4.m1.4.4.5.4.cmml"><mi id="S4.E4.m1.4.4.5.4.2" xref="S4.E4.m1.4.4.5.4.2.cmml">𝐅</mi><mi id="S4.E4.m1.4.4.5.4.3" xref="S4.E4.m1.4.4.5.4.3.cmml">𝐯</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.4b"><apply id="S4.E4.m1.4.4.cmml" xref="S4.E4.m1.4.4"><eq id="S4.E4.m1.4.4.4.cmml" xref="S4.E4.m1.4.4.4"></eq><apply id="S4.E4.m1.4.4.3.cmml" xref="S4.E4.m1.4.4.3"><times id="S4.E4.m1.4.4.3.4.cmml" xref="S4.E4.m1.4.4.3.4"></times><ci id="S4.E4.m1.4.4.3.5.cmml" xref="S4.E4.m1.4.4.3.5">italic-ϕ</ci><vector id="S4.E4.m1.4.4.3.3.4.cmml" xref="S4.E4.m1.4.4.3.3.3"><apply id="S4.E4.m1.2.2.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.2.2.1.1.1.1.2.cmml" xref="S4.E4.m1.2.2.1.1.1.1.2">𝐅</ci><ci id="S4.E4.m1.2.2.1.1.1.1.3.cmml" xref="S4.E4.m1.2.2.1.1.1.1.3">𝑖</ci></apply><apply id="S4.E4.m1.3.3.2.2.2.2.cmml" xref="S4.E4.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S4.E4.m1.3.3.2.2.2.2.1.cmml" xref="S4.E4.m1.3.3.2.2.2.2">superscript</csymbol><ci id="S4.E4.m1.3.3.2.2.2.2.2.cmml" xref="S4.E4.m1.3.3.2.2.2.2.2">𝐅</ci><ci id="S4.E4.m1.3.3.2.2.2.2.3.cmml" xref="S4.E4.m1.3.3.2.2.2.2.3">𝑣</ci></apply><apply id="S4.E4.m1.4.4.3.3.3.3.cmml" xref="S4.E4.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.3.3.3.3.1.cmml" xref="S4.E4.m1.4.4.3.3.3.3">superscript</csymbol><ci id="S4.E4.m1.4.4.3.3.3.3.2.cmml" xref="S4.E4.m1.4.4.3.3.3.3.2">𝐅</ci><ci id="S4.E4.m1.4.4.3.3.3.3.3.cmml" xref="S4.E4.m1.4.4.3.3.3.3.3">𝑣</ci></apply></vector></apply><apply id="S4.E4.m1.4.4.5.cmml" xref="S4.E4.m1.4.4.5"><times id="S4.E4.m1.4.4.5.1.cmml" xref="S4.E4.m1.4.4.5.1"></times><ci id="S4.E4.m1.4.4.5.2a.cmml" xref="S4.E4.m1.4.4.5.2"><mtext id="S4.E4.m1.4.4.5.2.cmml" xref="S4.E4.m1.4.4.5.2">Softmax</mtext></ci><apply id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.4.4.5.3.2"><divide id="S4.E4.m1.1.1.2.cmml" xref="S4.E4.m1.4.4.5.3.2"></divide><apply id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><times id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.2"></times><apply id="S4.E4.m1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.3.2">𝐅</ci><ci id="S4.E4.m1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.3.3">𝑖</ci></apply><apply id="S4.E4.m1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1">superscript</csymbol><apply id="S4.E4.m1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.2">𝐅</ci><ci id="S4.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1.3">𝑣</ci></apply><csymbol cd="latexml" id="S4.E4.m1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.3">top</csymbol></apply></apply><apply id="S4.E4.m1.1.1.3.cmml" xref="S4.E4.m1.1.1.3"><root id="S4.E4.m1.1.1.3a.cmml" xref="S4.E4.m1.1.1.3"></root><ci id="S4.E4.m1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.3.2">𝐷</ci></apply></apply><apply id="S4.E4.m1.4.4.5.4.cmml" xref="S4.E4.m1.4.4.5.4"><csymbol cd="ambiguous" id="S4.E4.m1.4.4.5.4.1.cmml" xref="S4.E4.m1.4.4.5.4">superscript</csymbol><ci id="S4.E4.m1.4.4.5.4.2.cmml" xref="S4.E4.m1.4.4.5.4.2">𝐅</ci><ci id="S4.E4.m1.4.4.5.4.3.cmml" xref="S4.E4.m1.4.4.5.4.3">𝐯</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.4c">\phi(\mathbf{F}_{i},\mathbf{F}^{v},\mathbf{F}^{v})=\mbox{Softmax}(\dfrac{\mathbf{F}_{i}(\mathbf{F}^{v})^{\top}}{\sqrt{D}})\mathbf{\mathbf{F}^{v}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.SS3.p1.6" class="ltx_p">where <math id="S4.SS3.p1.4.m1.1" class="ltx_math_unparsed" alttext="[\ ;\ ]" display="inline"><semantics id="S4.SS3.p1.4.m1.1a"><mrow id="S4.SS3.p1.4.m1.1b"><mo rspace="0.500em" stretchy="false" id="S4.SS3.p1.4.m1.1.1">[</mo><mo rspace="0.667em" id="S4.SS3.p1.4.m1.1.2">;</mo><mo stretchy="false" id="S4.SS3.p1.4.m1.1.3">]</mo></mrow><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m1.1c">[\ ;\ ]</annotation></semantics></math> denotes the concatenation operator.
<math id="S4.SS3.p1.5.m2.1" class="ltx_Math" alttext="\mathbf{F}_{i}^{v}\in\mathbb{R}^{1\times D}" display="inline"><semantics id="S4.SS3.p1.5.m2.1a"><mrow id="S4.SS3.p1.5.m2.1.1" xref="S4.SS3.p1.5.m2.1.1.cmml"><msubsup id="S4.SS3.p1.5.m2.1.1.2" xref="S4.SS3.p1.5.m2.1.1.2.cmml"><mi id="S4.SS3.p1.5.m2.1.1.2.2.2" xref="S4.SS3.p1.5.m2.1.1.2.2.2.cmml">𝐅</mi><mi id="S4.SS3.p1.5.m2.1.1.2.2.3" xref="S4.SS3.p1.5.m2.1.1.2.2.3.cmml">i</mi><mi id="S4.SS3.p1.5.m2.1.1.2.3" xref="S4.SS3.p1.5.m2.1.1.2.3.cmml">v</mi></msubsup><mo id="S4.SS3.p1.5.m2.1.1.1" xref="S4.SS3.p1.5.m2.1.1.1.cmml">∈</mo><msup id="S4.SS3.p1.5.m2.1.1.3" xref="S4.SS3.p1.5.m2.1.1.3.cmml"><mi id="S4.SS3.p1.5.m2.1.1.3.2" xref="S4.SS3.p1.5.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS3.p1.5.m2.1.1.3.3" xref="S4.SS3.p1.5.m2.1.1.3.3.cmml"><mn id="S4.SS3.p1.5.m2.1.1.3.3.2" xref="S4.SS3.p1.5.m2.1.1.3.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.5.m2.1.1.3.3.1" xref="S4.SS3.p1.5.m2.1.1.3.3.1.cmml">×</mo><mi id="S4.SS3.p1.5.m2.1.1.3.3.3" xref="S4.SS3.p1.5.m2.1.1.3.3.3.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m2.1b"><apply id="S4.SS3.p1.5.m2.1.1.cmml" xref="S4.SS3.p1.5.m2.1.1"><in id="S4.SS3.p1.5.m2.1.1.1.cmml" xref="S4.SS3.p1.5.m2.1.1.1"></in><apply id="S4.SS3.p1.5.m2.1.1.2.cmml" xref="S4.SS3.p1.5.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m2.1.1.2.1.cmml" xref="S4.SS3.p1.5.m2.1.1.2">superscript</csymbol><apply id="S4.SS3.p1.5.m2.1.1.2.2.cmml" xref="S4.SS3.p1.5.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m2.1.1.2.2.1.cmml" xref="S4.SS3.p1.5.m2.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.5.m2.1.1.2.2.2.cmml" xref="S4.SS3.p1.5.m2.1.1.2.2.2">𝐅</ci><ci id="S4.SS3.p1.5.m2.1.1.2.2.3.cmml" xref="S4.SS3.p1.5.m2.1.1.2.2.3">𝑖</ci></apply><ci id="S4.SS3.p1.5.m2.1.1.2.3.cmml" xref="S4.SS3.p1.5.m2.1.1.2.3">𝑣</ci></apply><apply id="S4.SS3.p1.5.m2.1.1.3.cmml" xref="S4.SS3.p1.5.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m2.1.1.3.1.cmml" xref="S4.SS3.p1.5.m2.1.1.3">superscript</csymbol><ci id="S4.SS3.p1.5.m2.1.1.3.2.cmml" xref="S4.SS3.p1.5.m2.1.1.3.2">ℝ</ci><apply id="S4.SS3.p1.5.m2.1.1.3.3.cmml" xref="S4.SS3.p1.5.m2.1.1.3.3"><times id="S4.SS3.p1.5.m2.1.1.3.3.1.cmml" xref="S4.SS3.p1.5.m2.1.1.3.3.1"></times><cn type="integer" id="S4.SS3.p1.5.m2.1.1.3.3.2.cmml" xref="S4.SS3.p1.5.m2.1.1.3.3.2">1</cn><ci id="S4.SS3.p1.5.m2.1.1.3.3.3.cmml" xref="S4.SS3.p1.5.m2.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m2.1c">\mathbf{F}_{i}^{v}\in\mathbb{R}^{1\times D}</annotation></semantics></math>, and <math id="S4.SS3.p1.6.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS3.p1.6.m3.1a"><mi id="S4.SS3.p1.6.m3.1.1" xref="S4.SS3.p1.6.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m3.1b"><ci id="S4.SS3.p1.6.m3.1.1.cmml" xref="S4.SS3.p1.6.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m3.1c">D</annotation></semantics></math> is the dimension of embeddings.
Note that our model supports to freezing of the parameters of latent diffusion models and directly uses the VAE and vocoder released from AudioLDM to achieve efficient and video-conditioned TTA generation.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:297.7pt;height:70.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-42.0pt,9.9pt) scale(0.78,0.78) ;">
<table id="S4.T4.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.4.4.4" class="ltx_tr">
<th id="S4.T4.4.4.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.4.4.4.5.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">IS (<math id="S4.T4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T4.1.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th id="S4.T4.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.2.2.2.2.1" class="ltx_text ltx_font_bold">KL (<math id="S4.T4.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T4.2.2.2.2.1.m1.1.1" xref="S4.T4.2.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.2.1.m1.1b"><ci id="S4.T4.2.2.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T4.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.3.3.3.3.1" class="ltx_text ltx_font_bold">FAD (<math id="S4.T4.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T4.3.3.3.3.1.m1.1.1" xref="S4.T4.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.3.1.m1.1b"><ci id="S4.T4.3.3.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T4.4.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.4.4.4.4.1" class="ltx_text ltx_font_bold">FD (<math id="S4.T4.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T4.4.4.4.4.1.m1.1.1" xref="S4.T4.4.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.4.1.m1.1b"><ci id="S4.T4.4.4.4.4.1.m1.1.1.cmml" xref="S4.T4.4.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.4.4.5.1" class="ltx_tr">
<th id="S4.T4.4.4.5.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">DiffSound <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite>
</th>
<td id="S4.T4.4.4.5.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">4.01</td>
<td id="S4.T4.4.4.5.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">2.52</td>
<td id="S4.T4.4.4.5.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">7.75</td>
<td id="S4.T4.4.4.5.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">47.68</td>
</tr>
<tr id="S4.T4.4.4.6.2" class="ltx_tr">
<th id="S4.T4.4.4.6.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">AudioGen <cite class="ltx_cite ltx_citemacro_citep">(Kreuk et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S4.T4.4.4.6.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">–</td>
<td id="S4.T4.4.4.6.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">2.09</td>
<td id="S4.T4.4.4.6.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">3.13</td>
<td id="S4.T4.4.4.6.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">–</td>
</tr>
<tr id="S4.T4.4.4.7.3" class="ltx_tr">
<th id="S4.T4.4.4.7.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;">AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>
</th>
<td id="S4.T4.4.4.7.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">6.90</td>
<td id="S4.T4.4.4.7.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">1.97</td>
<td id="S4.T4.4.4.7.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">2.43</td>
<td id="S4.T4.4.4.7.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">29.48</td>
</tr>
<tr id="S4.T4.4.4.8.4" class="ltx_tr" style="background-color:#000000;">
<th id="S4.T4.4.4.8.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.4.4.8.4.1.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">T2AV (ours)</span></th>
<td id="S4.T4.4.4.8.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.4.4.8.4.2.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">8.25</span></td>
<td id="S4.T4.4.4.8.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.4.4.8.4.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">1.32</span></td>
<td id="S4.T4.4.4.8.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.4.4.8.4.4.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">1.78</span></td>
<td id="S4.T4.4.4.8.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T4.4.4.8.4.5.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">25.38</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.7.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.8.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Quantitative results of text-to-audio generation on AudioCaps benchmark.<span id="S4.T4.8.2.1" class="ltx_text ltx_font_medium"> We achieve the best results in terms of all metrics on text-to-audio generation.</span></span></figcaption>
</figure>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2403.07938/assets/figs/vis_generation.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Qualitative comparisons with AudioLDM on video-aligned TTA generation.<span id="S4.F3.4.2.1" class="ltx_text ltx_font_medium">
The proposed T2AV produces more accurate and aligned audio for target videos.
</span></span></figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<div id="S4.T5.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:300.9pt;height:81pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.7pt,4.5pt) scale(0.9,0.9) ;">
<table id="S4.T5.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.7.7.7" class="ltx_tr">
<th id="S4.T5.7.7.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.7.8.1" class="ltx_text ltx_font_bold">VCLAP</span></th>
<th id="S4.T5.7.7.7.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.7.9.1" class="ltx_text ltx_font_bold">AVCN</span></th>
<th id="S4.T5.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">FD (<math id="S4.T5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T5.1.1.1.1.1.m1.1.1" xref="S4.T5.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.1.1.m1.1b"><ci id="S4.T5.1.1.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T5.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.2.2.2.2.1" class="ltx_text ltx_font_bold">IS (<math id="S4.T5.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T5.2.2.2.2.1.m1.1.1" xref="S4.T5.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.2.1.m1.1b"><ci id="S4.T5.2.2.2.2.1.m1.1.1.cmml" xref="S4.T5.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th id="S4.T5.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.3.3.3.3.1" class="ltx_text ltx_font_bold">KL (<math id="S4.T5.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T5.3.3.3.3.1.m1.1.1" xref="S4.T5.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.3.1.m1.1b"><ci id="S4.T5.3.3.3.3.1.m1.1.1.cmml" xref="S4.T5.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T5.4.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.4.4.4.4.1" class="ltx_text ltx_font_bold">FAD (<math id="S4.T5.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T5.4.4.4.4.1.m1.1.1" xref="S4.T5.4.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.4.4.1.m1.1b"><ci id="S4.T5.4.4.4.4.1.m1.1.1.cmml" xref="S4.T5.4.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T5.5.5.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.5.5.5.5.1" class="ltx_text ltx_font_bold">FAVD (<math id="S4.T5.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.5.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T5.5.5.5.5.1.m1.1.1" xref="S4.T5.5.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.5.5.1.m1.1b"><ci id="S4.T5.5.5.5.5.1.m1.1.1.cmml" xref="S4.T5.5.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T5.6.6.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.6.6.6.6.1" class="ltx_text ltx_font_bold">FATD (<math id="S4.T5.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.6.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T5.6.6.6.6.1.m1.1.1" xref="S4.T5.6.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.6.6.1.m1.1b"><ci id="S4.T5.6.6.6.6.1.m1.1.1.cmml" xref="S4.T5.6.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T5.7.7.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.7.7.1" class="ltx_text ltx_font_bold">FA(VT)D (<math id="S4.T5.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.7.7.7.7.1.m1.1a"><mo stretchy="false" id="S4.T5.7.7.7.7.1.m1.1.1" xref="S4.T5.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.7.7.7.7.1.m1.1b"><ci id="S4.T5.7.7.7.7.1.m1.1.1.cmml" xref="S4.T5.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.7.7.8.1" class="ltx_tr">
<td id="S4.T5.7.7.8.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">✗</td>
<td id="S4.T5.7.7.8.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">✗</td>
<td id="S4.T5.7.7.8.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">42.59</td>
<td id="S4.T5.7.7.8.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">4.82</td>
<td id="S4.T5.7.7.8.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">5.72</td>
<td id="S4.T5.7.7.8.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">6.25</td>
<td id="S4.T5.7.7.8.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">33.76</td>
<td id="S4.T5.7.7.8.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">19.52</td>
<td id="S4.T5.7.7.8.1.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">26.37</td>
</tr>
<tr id="S4.T5.7.7.9.2" class="ltx_tr">
<td id="S4.T5.7.7.9.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">✓</td>
<td id="S4.T5.7.7.9.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">✗</td>
<td id="S4.T5.7.7.9.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">37.28</td>
<td id="S4.T5.7.7.9.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">7.53</td>
<td id="S4.T5.7.7.9.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">3.45</td>
<td id="S4.T5.7.7.9.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">5.52</td>
<td id="S4.T5.7.7.9.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">29.63</td>
<td id="S4.T5.7.7.9.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">16.93</td>
<td id="S4.T5.7.7.9.2.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">23.02</td>
</tr>
<tr id="S4.T5.7.7.10.3" class="ltx_tr">
<td id="S4.T5.7.7.10.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">✗</td>
<td id="S4.T5.7.7.10.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">✓</td>
<td id="S4.T5.7.7.10.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">38.32</td>
<td id="S4.T5.7.7.10.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">6.85</td>
<td id="S4.T5.7.7.10.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">3.57</td>
<td id="S4.T5.7.7.10.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">5.65</td>
<td id="S4.T5.7.7.10.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">30.35</td>
<td id="S4.T5.7.7.10.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">18.05</td>
<td id="S4.T5.7.7.10.3.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">24.53</td>
</tr>
<tr id="S4.T5.7.7.11.4" class="ltx_tr" style="background-color:#000000;">
<td id="S4.T5.7.7.11.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.1.1" class="ltx_text" style="background-color:#000000;">✓</span></td>
<td id="S4.T5.7.7.11.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.2.1" class="ltx_text" style="background-color:#000000;">✓</span></td>
<td id="S4.T5.7.7.11.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">33.73</span></td>
<td id="S4.T5.7.7.11.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.4.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">8.31</span></td>
<td id="S4.T5.7.7.11.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.5.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">2.62</span></td>
<td id="S4.T5.7.7.11.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.6.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">4.26</span></td>
<td id="S4.T5.7.7.11.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.7.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">24.15</span></td>
<td id="S4.T5.7.7.11.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.8.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">13.65</span></td>
<td id="S4.T5.7.7.11.4.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T5.7.7.11.4.9.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">18.05</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.11.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.12.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Ablation studies on Visual-aligned CLAP (VCLAP) and Audio-Visual ControlNet (AVCN).<span id="S4.T5.12.2.1" class="ltx_text ltx_font_medium">
All models are trained on AudioCaps and VGGSound, and the parameters of latent diffusion models are also </span>trainable<span id="S4.T5.12.2.2" class="ltx_text ltx_font_medium">.</span></span></figcaption>
</figure>
<figure id="S4.T6" class="ltx_table">
<div id="S4.T6.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:320.5pt;height:76.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.3pt,6.8pt) scale(0.85,0.85) ;">
<table id="S4.T6.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.7.7.7" class="ltx_tr">
<th id="S4.T6.7.7.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.7.8.1" class="ltx_text ltx_font_bold">Condition Operators</span></th>
<th id="S4.T6.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.1.1.1.1.1" class="ltx_text ltx_font_bold">FD (<math id="S4.T6.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T6.1.1.1.1.1.m1.1.1" xref="S4.T6.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.1.1.m1.1b"><ci id="S4.T6.1.1.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T6.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.2.2.2.2.1" class="ltx_text ltx_font_bold">IS (<math id="S4.T6.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T6.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T6.2.2.2.2.1.m1.1.1" xref="S4.T6.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.2.2.1.m1.1b"><ci id="S4.T6.2.2.2.2.1.m1.1.1.cmml" xref="S4.T6.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th id="S4.T6.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.3.3.3.3.1" class="ltx_text ltx_font_bold">KL (<math id="S4.T6.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T6.3.3.3.3.1.m1.1.1" xref="S4.T6.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.3.3.1.m1.1b"><ci id="S4.T6.3.3.3.3.1.m1.1.1.cmml" xref="S4.T6.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T6.4.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.4.4.4.4.1" class="ltx_text ltx_font_bold">FAD (<math id="S4.T6.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T6.4.4.4.4.1.m1.1.1" xref="S4.T6.4.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.4.4.4.4.1.m1.1b"><ci id="S4.T6.4.4.4.4.1.m1.1.1.cmml" xref="S4.T6.4.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T6.5.5.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.5.5.5.5.1" class="ltx_text ltx_font_bold">FAVD (<math id="S4.T6.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.5.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T6.5.5.5.5.1.m1.1.1" xref="S4.T6.5.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.5.5.5.5.1.m1.1b"><ci id="S4.T6.5.5.5.5.1.m1.1.1.cmml" xref="S4.T6.5.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.5.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T6.6.6.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.6.6.6.6.1" class="ltx_text ltx_font_bold">FATD (<math id="S4.T6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.6.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T6.6.6.6.6.1.m1.1.1" xref="S4.T6.6.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.6.6.6.6.1.m1.1b"><ci id="S4.T6.6.6.6.6.1.m1.1.1.cmml" xref="S4.T6.6.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.6.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S4.T6.7.7.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.7.7.1" class="ltx_text ltx_font_bold">FA(VT)D (<math id="S4.T6.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.7.7.7.7.1.m1.1a"><mo stretchy="false" id="S4.T6.7.7.7.7.1.m1.1.1" xref="S4.T6.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.7.7.7.7.1.m1.1b"><ci id="S4.T6.7.7.7.7.1.m1.1.1.cmml" xref="S4.T6.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.7.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.7.7.8.1" class="ltx_tr">
<td id="S4.T6.7.7.8.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">LSTM</td>
<td id="S4.T6.7.7.8.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">40.78</td>
<td id="S4.T6.7.7.8.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">4.63</td>
<td id="S4.T6.7.7.8.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">4.86</td>
<td id="S4.T6.7.7.8.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">6.02</td>
<td id="S4.T6.7.7.8.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">30.57</td>
<td id="S4.T6.7.7.8.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">18.93</td>
<td id="S4.T6.7.7.8.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">24.85</td>
</tr>
<tr id="S4.T6.7.7.9.2" class="ltx_tr">
<td id="S4.T6.7.7.9.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">Cross-Attention</td>
<td id="S4.T6.7.7.9.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">38.73</td>
<td id="S4.T6.7.7.9.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">6.51</td>
<td id="S4.T6.7.7.9.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">3.83</td>
<td id="S4.T6.7.7.9.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">5.82</td>
<td id="S4.T6.7.7.9.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">30.73</td>
<td id="S4.T6.7.7.9.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">18.36</td>
<td id="S4.T6.7.7.9.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">24.92</td>
</tr>
<tr id="S4.T6.7.7.10.3" class="ltx_tr">
<td id="S4.T6.7.7.10.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">Addition</td>
<td id="S4.T6.7.7.10.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">37.56</td>
<td id="S4.T6.7.7.10.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">7.32</td>
<td id="S4.T6.7.7.10.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">3.67</td>
<td id="S4.T6.7.7.10.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">5.79</td>
<td id="S4.T6.7.7.10.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">29.85</td>
<td id="S4.T6.7.7.10.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">17.19</td>
<td id="S4.T6.7.7.10.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">23.29</td>
</tr>
<tr id="S4.T6.7.7.11.4" class="ltx_tr" style="background-color:#000000;">
<td id="S4.T6.7.7.11.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.11.4.1.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">Temporal Self-Attention</span></td>
<td id="S4.T6.7.7.11.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.11.4.2.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">36.98</span></td>
<td id="S4.T6.7.7.11.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.11.4.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">7.52</span></td>
<td id="S4.T6.7.7.11.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.11.4.4.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">3.52</span></td>
<td id="S4.T6.7.7.11.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.11.4.5.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">5.61</span></td>
<td id="S4.T6.7.7.11.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.11.4.6.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">28.65</span></td>
<td id="S4.T6.7.7.11.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.11.4.7.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">16.95</span></td>
<td id="S4.T6.7.7.11.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S4.T6.7.7.11.4.8.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">22.68</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.11.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.12.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Exploration studies on condition operators in Audio-Visual ControlNet.<span id="S4.T6.12.2.1" class="ltx_text ltx_font_medium"> All models are trained on AudioCaps and VGGSound, and the parameters of latent diffusion models are </span>frozen<span id="S4.T6.12.2.2" class="ltx_text ltx_font_medium">.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experimental setup</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_bold">Datasets.</span>
AudioCaps <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> dataset includes 45,423 ten-second audio clips collected from YouTube videos paired with captions for training and 2,240 samples for validation.
Since each audio clip in AudioCaps has 5 text captions, we use the same testing set in AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> with 886 instances by selecting one random caption as a text condition.
VGGSound <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> contains 200k YouTube video clips of
10 seconds long from 309 sound categories, such as such as animals, vehicles, human speech, dancing, musical instruments, etc.
The Look, Listen and Parse (LLP) Dataset <cite class="ltx_cite ltx_citemacro_citep">(Tian et al., <a href="#bib.bib45" title="" class="ltx_ref">2020</a>)</cite> includes 11,849 YouTube video clips of
10 seconds long from 25 different event classes, such as music, car, etc.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Evaluation Metrics.</span>
For comprehensive evaluation between generated audio and target audio, we apply Inception Score (IS), Kullback–Leibler (KL) divergence, Frechet Audio Distance (FAD), and Frechet Distance (FD) as evaluation metrics, following the previous work <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>.
IS is used to measure both audio quality and diversity, while KL is evaluated on paired audio.
FAD and FD calculate the similarity between generated audio and reference audio.
For video-aligned TTA generation, we use the proposed metrics, including FAVD, FATD, FA(VT)D for evaluation.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">Implementation.</span>
We initialize the weights from the audio and text encoder in AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> and fine-tune the parameters.
For the video encoder, we apply the pre-trained X-CLIP <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite> as the initialization weights.
The depth of multi-head self-attention layers in Audio-Visual ControlNet with a dimension of 768 is 4, and the number of heads is 8.
The model is trained for 50 epochs using a batch size of 128 and the Adam optimizer with a learning rate of <math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="1e-4" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mrow id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mrow id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml"><mn id="S5.SS1.p3.1.m1.1.1.2.2" xref="S5.SS1.p3.1.m1.1.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S5.SS1.p3.1.m1.1.1.2.1" xref="S5.SS1.p3.1.m1.1.1.2.1.cmml">​</mo><mi id="S5.SS1.p3.1.m1.1.1.2.3" xref="S5.SS1.p3.1.m1.1.1.2.3.cmml">e</mi></mrow><mo id="S5.SS1.p3.1.m1.1.1.1" xref="S5.SS1.p3.1.m1.1.1.1.cmml">−</mo><mn id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><minus id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1.1"></minus><apply id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2"><times id="S5.SS1.p3.1.m1.1.1.2.1.cmml" xref="S5.SS1.p3.1.m1.1.1.2.1"></times><cn type="integer" id="S5.SS1.p3.1.m1.1.1.2.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2.2">1</cn><ci id="S5.SS1.p3.1.m1.1.1.2.3.cmml" xref="S5.SS1.p3.1.m1.1.1.2.3">𝑒</ci></apply><cn type="integer" id="S5.SS1.p3.1.m1.1.1.3.cmml" xref="S5.SS1.p3.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">1e-4</annotation></semantics></math>.
We use the released weights from AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> for VAE and vocoder to generate the final audio samples.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Comparison to Prior Work</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In this work, we propose a novel and effective framework for text-to-audio generation.
In order to validate the effectiveness of the proposed T2AV, we comprehensively compare it to previous DDPM and LDM baselines:
1) SpecVQGAN <cite class="ltx_cite ltx_citemacro_citep">(Iashin &amp; Rahtu, <a href="#bib.bib10" title="" class="ltx_ref">2021a</a>)</cite> (2021’BMVC): a VQGAN approach based on a compact sampling space to generate a new spectrogram from the pre-trained spectrogram codebook.
2) DiffSound <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite> (2022’TASLP): a vector-quantized variational autoencoder (VQ-VAE) based DDPM framework by learning a discrete space from audio given natural language description with mask-based text generation.
3) MMDiffusion <cite class="ltx_cite ltx_citemacro_citep">(Ruan et al., <a href="#bib.bib39" title="" class="ltx_ref">2023</a>)</cite> (2023’CVPR): a strong multi-modal diffusion model with a sequential U-Net with two-coupled autoencoders for a joint audio-video denoising process.
4) AudioGen <cite class="ltx_cite ltx_citemacro_citep">(Kreuk et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> (2023’ICLR):
a recent DDPM approach using a transformer decoder to learn discrete representations from the audio waveform directly.
5) AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> (2023’ICML):
a strong LDM baseline to learn the continuous audio representations from a latent space in contrastive language-audio pre-training.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">For video-aligned text-to-audio generation, we report the quantitative comparison results on the <span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> in Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Preliminaries ‣ 4 Method ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
As can be seen, we achieve the best results regarding all metrics for video-aligned text-to-audio generation compared to previous DDPM and LDM approaches.
In particular, the proposed T2AV superiorly outperforms AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>, the current state-of-the-art text-to-audio generation baseline, by 9.30 FD &amp; 2.20 FAD, 9.73 FAVD &amp; 6.36 FATD, and 8.55 FA(VT)D on our benchmark.
Furthermore, we achieve significant performance gains compared to MMDiffusion <cite class="ltx_cite ltx_citemacro_citep">(Ruan et al., <a href="#bib.bib39" title="" class="ltx_ref">2023</a>)</cite>, the strong multi-modal joint diffusion baseline, which indicates the importance of extracting temporal visual semantics from visual representations as guidance for video-aligned text-to-audio generation.
Meanwhile, our achieves better results against
those DDPM baselines, such as DiffSound <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite> and AudioGen <cite class="ltx_cite ltx_citemacro_citep">(Kreuk et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>.
These significant improvements demonstrate the superiority of our approach in generating high-quality video-aligned audio from text captions.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">In addition, significant gains in TTA generation on the AudioCaps benchmark can be observed in Table <a href="#S4.T4" title="Table 4 ‣ 4.3 Audio-Visual ControlNet ‣ 4 Method ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
As can be seen, we achieve the best results in terms of IS and KL while performing competitively in other metrics.
In particular, the proposed significantly outperforms DiffSound <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite>, the first DDPM-based baseline on TTA generation, by 4.24 IS, and highly decreases other metrics by 1.20 KL, 5.97 FAD, and 22.30 FD.
Moreover, we achieve decent performance gains of 1.35 IS and a decrease of 4.10 FD, compared to AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>, the current state-of-the-art text-to-audio generation approach.
These results demonstrate the effectiveness of our approach in learning visual-aligned textual semantics for text-to-audio generation.</p>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">In order to qualitatively evaluate the quality of video-aligned TTA generation, we compare the proposed with AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.3 Audio-Visual ControlNet ‣ 4 Method ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
From comparisons, we observed that without explicit visual-aligned CLAP pre-training objectives, AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite>, the strong TTA generation baseline fails to discriminate the order of two sounding objects given in the input text, such as “Pigeons vocalize and birds chirp”.
Meanwhile, it is hard for AudioLDM <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> to generate sound temporally aligned with the original video.
For example, given the input text “A train horn blows as it passes by”, the strong baseline model generates the horn blowing sound across all ten seconds although no train appeared in the last several seconds.
In contrast, the generated audio from our method is more aligned with the visual semantics existing in the video.
These visualizations further showcase the superiority of our approach in video-aligned text-to-audio generation.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Experimental Analysis</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">In this section, we provide ablation studies to demonstrate the benefit of the Visual-aligned CLAP and Audio-Visual ControlNet modules.
We also conducted extensive experiments to explore the condition in Audio-Visual ControlNet, training data scale, and latent diffusion tuning.</p>
</div>
<figure id="S5.T7" class="ltx_table">
<div id="S5.T7.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:354.8pt;height:61.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-31.3pt,5.4pt) scale(0.85,0.85) ;">
<table id="S5.T7.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T7.7.7.7" class="ltx_tr">
<th id="S5.T7.7.7.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.7.8.1" class="ltx_text ltx_font_bold">Train Data</span></th>
<th id="S5.T7.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.1.1.1.1.1" class="ltx_text ltx_font_bold">FD (<math id="S5.T7.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T7.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T7.1.1.1.1.1.m1.1.1" xref="S5.T7.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.1.1.1.1.1.m1.1b"><ci id="S5.T7.1.1.1.1.1.m1.1.1.cmml" xref="S5.T7.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T7.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.2.2.2.2.1" class="ltx_text ltx_font_bold">IS (<math id="S5.T7.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T7.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T7.2.2.2.2.1.m1.1.1" xref="S5.T7.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T7.2.2.2.2.1.m1.1b"><ci id="S5.T7.2.2.2.2.1.m1.1.1.cmml" xref="S5.T7.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th id="S5.T7.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.3.3.3.3.1" class="ltx_text ltx_font_bold">KL (<math id="S5.T7.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T7.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S5.T7.3.3.3.3.1.m1.1.1" xref="S5.T7.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.3.3.3.3.1.m1.1b"><ci id="S5.T7.3.3.3.3.1.m1.1.1.cmml" xref="S5.T7.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T7.4.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.4.4.4.4.1" class="ltx_text ltx_font_bold">FAD (<math id="S5.T7.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T7.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S5.T7.4.4.4.4.1.m1.1.1" xref="S5.T7.4.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.4.4.4.4.1.m1.1b"><ci id="S5.T7.4.4.4.4.1.m1.1.1.cmml" xref="S5.T7.4.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T7.5.5.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.5.5.5.5.1" class="ltx_text ltx_font_bold">FAVD (<math id="S5.T7.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T7.5.5.5.5.1.m1.1a"><mo stretchy="false" id="S5.T7.5.5.5.5.1.m1.1.1" xref="S5.T7.5.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.5.5.5.5.1.m1.1b"><ci id="S5.T7.5.5.5.5.1.m1.1.1.cmml" xref="S5.T7.5.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.5.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T7.6.6.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.6.6.6.6.1" class="ltx_text ltx_font_bold">FATD (<math id="S5.T7.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T7.6.6.6.6.1.m1.1a"><mo stretchy="false" id="S5.T7.6.6.6.6.1.m1.1.1" xref="S5.T7.6.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.6.6.6.6.1.m1.1b"><ci id="S5.T7.6.6.6.6.1.m1.1.1.cmml" xref="S5.T7.6.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.6.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T7.7.7.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.7.7.1" class="ltx_text ltx_font_bold">FA(VT)D (<math id="S5.T7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T7.7.7.7.7.1.m1.1a"><mo stretchy="false" id="S5.T7.7.7.7.7.1.m1.1.1" xref="S5.T7.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T7.7.7.7.7.1.m1.1b"><ci id="S5.T7.7.7.7.7.1.m1.1.1.cmml" xref="S5.T7.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T7.7.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T7.7.7.8.1" class="ltx_tr">
<td id="S5.T7.7.7.8.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">AudioCaps</td>
<td id="S5.T7.7.7.8.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">36.98</td>
<td id="S5.T7.7.7.8.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">7.52</td>
<td id="S5.T7.7.7.8.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">3.52</td>
<td id="S5.T7.7.7.8.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">5.61</td>
<td id="S5.T7.7.7.8.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">28.65</td>
<td id="S5.T7.7.7.8.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">16.95</td>
<td id="S5.T7.7.7.8.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">22.68</td>
</tr>
<tr id="S5.T7.7.7.9.2" class="ltx_tr">
<td id="S5.T7.7.7.9.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">AudioCaps + VGGSound</td>
<td id="S5.T7.7.7.9.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">35.28</td>
<td id="S5.T7.7.7.9.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">8.72</td>
<td id="S5.T7.7.7.9.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">2.93</td>
<td id="S5.T7.7.7.9.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">4.78</td>
<td id="S5.T7.7.7.9.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">25.23</td>
<td id="S5.T7.7.7.9.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">14.71</td>
<td id="S5.T7.7.7.9.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">20.16</td>
</tr>
<tr id="S5.T7.7.7.10.3" class="ltx_tr" style="background-color:#000000;">
<td id="S5.T7.7.7.10.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.10.3.1.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">AudioCaps + VGGSound + LLP</span></td>
<td id="S5.T7.7.7.10.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.10.3.2.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">34.86</span></td>
<td id="S5.T7.7.7.10.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.10.3.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">9.26</span></td>
<td id="S5.T7.7.7.10.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.10.3.4.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">2.35</span></td>
<td id="S5.T7.7.7.10.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.10.3.5.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">4.21</span></td>
<td id="S5.T7.7.7.10.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.10.3.6.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">24.15</span></td>
<td id="S5.T7.7.7.10.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.10.3.7.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">13.32</span></td>
<td id="S5.T7.7.7.10.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T7.7.7.10.3.8.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">18.95</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T7.10.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S5.T7.11.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Exploration studies on the scale of training data.<span id="S5.T7.11.2.1" class="ltx_text ltx_font_medium">
The parameters of latent diffusion models are frozen.</span></span></figcaption>
</figure>
<figure id="S5.T8" class="ltx_table">
<div id="S5.T8.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:320.9pt;height:76.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.3pt,6.8pt) scale(0.85,0.85) ;">
<table id="S5.T8.7.7" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T8.7.7.7" class="ltx_tr">
<th id="S5.T8.7.7.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.7.8.1" class="ltx_text ltx_font_bold">Tuning</span></th>
<th id="S5.T8.7.7.7.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.7.9.1" class="ltx_text ltx_font_bold">Train Data</span></th>
<th id="S5.T8.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.1.1.1.1.1" class="ltx_text ltx_font_bold">FD (<math id="S5.T8.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T8.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T8.1.1.1.1.1.m1.1.1" xref="S5.T8.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T8.1.1.1.1.1.m1.1b"><ci id="S5.T8.1.1.1.1.1.m1.1.1.cmml" xref="S5.T8.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T8.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.2.2.2.2.1" class="ltx_text ltx_font_bold">IS (<math id="S5.T8.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T8.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T8.2.2.2.2.1.m1.1.1" xref="S5.T8.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T8.2.2.2.2.1.m1.1b"><ci id="S5.T8.2.2.2.2.1.m1.1.1.cmml" xref="S5.T8.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th id="S5.T8.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.3.3.3.3.1" class="ltx_text ltx_font_bold">KL (<math id="S5.T8.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T8.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S5.T8.3.3.3.3.1.m1.1.1" xref="S5.T8.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T8.3.3.3.3.1.m1.1b"><ci id="S5.T8.3.3.3.3.1.m1.1.1.cmml" xref="S5.T8.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T8.4.4.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.4.4.4.4.1" class="ltx_text ltx_font_bold">FAD (<math id="S5.T8.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T8.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S5.T8.4.4.4.4.1.m1.1.1" xref="S5.T8.4.4.4.4.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T8.4.4.4.4.1.m1.1b"><ci id="S5.T8.4.4.4.4.1.m1.1.1.cmml" xref="S5.T8.4.4.4.4.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T8.5.5.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.5.5.5.5.1" class="ltx_text ltx_font_bold">FAVD (<math id="S5.T8.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T8.5.5.5.5.1.m1.1a"><mo stretchy="false" id="S5.T8.5.5.5.5.1.m1.1.1" xref="S5.T8.5.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T8.5.5.5.5.1.m1.1b"><ci id="S5.T8.5.5.5.5.1.m1.1.1.cmml" xref="S5.T8.5.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.5.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T8.6.6.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.6.6.6.6.1" class="ltx_text ltx_font_bold">FATD (<math id="S5.T8.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T8.6.6.6.6.1.m1.1a"><mo stretchy="false" id="S5.T8.6.6.6.6.1.m1.1.1" xref="S5.T8.6.6.6.6.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T8.6.6.6.6.1.m1.1b"><ci id="S5.T8.6.6.6.6.1.m1.1.1.cmml" xref="S5.T8.6.6.6.6.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.6.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th id="S5.T8.7.7.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.7.7.1" class="ltx_text ltx_font_bold">FA(VT)D (<math id="S5.T8.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T8.7.7.7.7.1.m1.1a"><mo stretchy="false" id="S5.T8.7.7.7.7.1.m1.1.1" xref="S5.T8.7.7.7.7.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T8.7.7.7.7.1.m1.1b"><ci id="S5.T8.7.7.7.7.1.m1.1.1.cmml" xref="S5.T8.7.7.7.7.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T8.7.7.7.7.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T8.7.7.8.1" class="ltx_tr">
<td id="S5.T8.7.7.8.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">✗</td>
<td id="S5.T8.7.7.8.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">AC + VS</td>
<td id="S5.T8.7.7.8.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">35.28</td>
<td id="S5.T8.7.7.8.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">8.72</td>
<td id="S5.T8.7.7.8.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">2.93</td>
<td id="S5.T8.7.7.8.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">4.78</td>
<td id="S5.T8.7.7.8.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">25.23</td>
<td id="S5.T8.7.7.8.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">14.71</td>
<td id="S5.T8.7.7.8.1.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">20.16</td>
</tr>
<tr id="S5.T8.7.7.9.2" class="ltx_tr">
<td id="S5.T8.7.7.9.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">✓</td>
<td id="S5.T8.7.7.9.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;">AC + VS</td>
<td id="S5.T8.7.7.9.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.9.2.3.1" class="ltx_text ltx_font_bold">33.73</span></td>
<td id="S5.T8.7.7.9.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.9.2.4.1" class="ltx_text ltx_font_bold">8.31</span></td>
<td id="S5.T8.7.7.9.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.9.2.5.1" class="ltx_text ltx_font_bold">2.62</span></td>
<td id="S5.T8.7.7.9.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.9.2.6.1" class="ltx_text ltx_font_bold">4.26</span></td>
<td id="S5.T8.7.7.9.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.9.2.7.1" class="ltx_text ltx_font_bold">24.15</span></td>
<td id="S5.T8.7.7.9.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.9.2.8.1" class="ltx_text ltx_font_bold">13.65</span></td>
<td id="S5.T8.7.7.9.2.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.9.2.9.1" class="ltx_text ltx_font_bold">18.05</span></td>
</tr>
<tr id="S5.T8.7.7.10.3" class="ltx_tr">
<td id="S5.T8.7.7.10.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">✗</td>
<td id="S5.T8.7.7.10.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">AC + VS + LLP</td>
<td id="S5.T8.7.7.10.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">34.86</td>
<td id="S5.T8.7.7.10.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">9.26</td>
<td id="S5.T8.7.7.10.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">2.35</td>
<td id="S5.T8.7.7.10.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">4.21</td>
<td id="S5.T8.7.7.10.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">24.15</td>
<td id="S5.T8.7.7.10.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">13.32</td>
<td id="S5.T8.7.7.10.3.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:0.0pt;padding-right:0.0pt;">18.95</td>
</tr>
<tr id="S5.T8.7.7.11.4" class="ltx_tr" style="background-color:#000000;">
<td id="S5.T8.7.7.11.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.1.1" class="ltx_text" style="background-color:#000000;">✓</span></td>
<td id="S5.T8.7.7.11.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.2.1" class="ltx_text" style="background-color:#000000;">AC + VS + LLP</span></td>
<td id="S5.T8.7.7.11.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.3.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">33.29</span></td>
<td id="S5.T8.7.7.11.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.4.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">8.02</span></td>
<td id="S5.T8.7.7.11.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.5.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">2.12</span></td>
<td id="S5.T8.7.7.11.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.6.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">4.05</span></td>
<td id="S5.T8.7.7.11.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.7.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">24.03</span></td>
<td id="S5.T8.7.7.11.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.8.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">13.16</span></td>
<td id="S5.T8.7.7.11.4.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding-left:0.0pt;padding-right:0.0pt;"><span id="S5.T8.7.7.11.4.9.1" class="ltx_text ltx_font_bold" style="background-color:#000000;">17.82</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T8.10.1.1" class="ltx_text" style="font-size:90%;">Table 8</span>: </span><span id="S5.T8.11.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Exploration studies on the latent diffusion tuning.<span id="S5.T8.11.2.1" class="ltx_text ltx_font_medium"> AC and VS denote AudioCaps and VGGSound datasets, respectively.
All models are trained on
AC + VS or AC + VS + LLP, and the parameters of latent diffusion models are also trainable.</span></span></figcaption>
</figure>
<div id="S5.SS3.p2" class="ltx_para ltx_noindent">
<p id="S5.SS3.p2.1" class="ltx_p"><span id="S5.SS3.p2.1.1" class="ltx_text ltx_font_bold">Visual-aligned CLAP &amp; Audio-Visual ControlNet.</span>
In order to demonstrate the effectiveness of the introduced visual-aligned contrastive language-audio pre-training (VCLAP) and audio-visual ControlNet (AVCN), we ablate the necessity of each module and report the quantitative results on our <span id="S5.SS3.p2.1.2" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> in Table <a href="#S4.T5" title="Table 5 ‣ 4.3 Audio-Visual ControlNet ‣ 4 Method ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
We train our model on AudioCaps and VGGSound, and also tune the parameters of latent diffusion models for a comprehensive comparison.
As can be observed, adding VCLAP to the vanilla baseline highly decreases the performance by 5.31 FD &amp; 0.73 FAD, 4.13 FAVD &amp; 2.59 FATD, and 3.35 FA(VT)D, which validates the benefit of visual-aligned contrastive language-audio pre-training in extracting text representations with visual semantics for text-to-audio generation.
Meanwhile, introducing only AVCN in the baseline increases the video-aligned text-to-video generation performance regarding all metrics.
More importantly, incorporating VCLAP and AVCN into the baseline significantly reduces the results of 9.30 FD &amp; 2.20 FAD, 9.73 FAVD &amp; 6.36 FATD, and 8.55 FA(VT)D on our benchmark.
These improving results validate the importance of visual-aligned contrastive language-audio pre-training and audio-visual ControlNet in extracting temporal-aware semantics from videos as guidance for text-to-audio generation.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para ltx_noindent">
<p id="S5.SS3.p3.2" class="ltx_p"><span id="S5.SS3.p3.2.1" class="ltx_text ltx_font_bold">Condition in Audio-Visual ControlNet.</span>
Learning video-aligned textual representations with temporal-aware semantics as the condition in the proposed Audio-Visual ControlNet module is critical for generating high-quality audio from input captions.
To explore such effects more comprehensively, we varied the condition operator from <math id="S5.SS3.p3.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="S5.SS3.p3.1.m1.1a"><mo stretchy="false" id="S5.SS3.p3.1.m1.1.1" xref="S5.SS3.p3.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.1.m1.1b"><ci id="S5.SS3.p3.1.m1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.1.m1.1c">\{</annotation></semantics></math>LSTM, Cross-Attention, Addition, Temporal Self-Attention<math id="S5.SS3.p3.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S5.SS3.p3.2.m2.1a"><mo stretchy="false" id="S5.SS3.p3.2.m2.1.1" xref="S5.SS3.p3.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.2.m2.1b"><ci id="S5.SS3.p3.2.m2.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.2.m2.1c">\}</annotation></semantics></math>.
The comparison results of video-aligned text-to-audio generation performance are reported in Table <a href="#S4.T6" title="Table 6 ‣ 4.3 Audio-Visual ControlNet ‣ 4 Method ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
When using the vanilla LSTM as the condition operator, we achieve the worst results in terms of all metrics.
With a temporal self-attention operator to aggregate temporal-aware visual features as guidance, the proposed T2AV achieves the best video-aligned text-to-audio generation performance in terms of all metrics decreasing by 3.80 FD &amp; 0.41 FAD, 1.92 FAVD &amp; 1.98 FATD, and 2.17 FA(VT)D, which shows the importance of long-term temporal features in Audio-Visual ControlNet for generating high-fidelity audio aligned with videos.
Regarding the Cross-Attention operator, the performance of the proposed T2AV performs better than the vanilla LSTM decreasing by 2.05 FD &amp; 0.20 FAD, 0.16 FAVD &amp; 0.57 FATD, and 0.07 FA(VT)D when only global visual features are fed into latent diffusion models as guidance.
Interestingly, using a simple addition operator on top of temporal video features will continually improve the result against the vanilla LSTM by decreasing 3.22 FD &amp; 0.23 FAD, 0.72 FAVD &amp; 1.74 FATD, and 1.56 FA(VT)D since there might be some temporal consistency maintained in the original visual features from the video encoder by visual-aligned contrastive language-audio pre-training to boost the performance of video-aligned text-to-audio generation.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para ltx_noindent">
<p id="S5.SS3.p4.2" class="ltx_p"><span id="S5.SS3.p4.2.1" class="ltx_text ltx_font_bold">Training Data Scale.</span>
In order to show the scaling-up properties of our T2AV in large-scale training data, we ablated the training data from <math id="S5.SS3.p4.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="S5.SS3.p4.1.m1.1a"><mo stretchy="false" id="S5.SS3.p4.1.m1.1.1" xref="S5.SS3.p4.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.1.m1.1b"><ci id="S5.SS3.p4.1.m1.1.1.cmml" xref="S5.SS3.p4.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.1.m1.1c">\{</annotation></semantics></math>AudioCaps, AudioCaps+VGGSound, AudioCaps+VGGSound+LLP<math id="S5.SS3.p4.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S5.SS3.p4.2.m2.1a"><mo stretchy="false" id="S5.SS3.p4.2.m2.1.1" xref="S5.SS3.p4.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p4.2.m2.1b"><ci id="S5.SS3.p4.2.m2.1.1.cmml" xref="S5.SS3.p4.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p4.2.m2.1c">\}</annotation></semantics></math> and report the comparison results on our <span id="S5.SS3.p4.2.2" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> in Table <a href="#S5.T7" title="Table 7 ‣ 5.3 Experimental Analysis ‣ 5 Experiments ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
Note that all models are trained except for the parameters of latent diffusion models are frozen.
As can be seen, we achieve the worst results on our <span id="S5.SS3.p4.2.3" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> in terms of all metrics, when using only AudioCaps <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> for training.
By adding VGGSound <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> with 200k videos to AudioCaps in the training data, we achieve better video-aligned text-to-audio generation performance in terms of all metrics decreasing by 1.70 FD &amp; 0.83 FAD, 3.42 FAVD &amp; 2.24 FATD, and 2.52 FA(VT)D, which shows the importance of diverse categories in VGGSound in learning video-aligned representations for generating high-fidelity audio.
Furthermore, incorporating LLP <cite class="ltx_cite ltx_citemacro_citep">(Tian et al., <a href="#bib.bib45" title="" class="ltx_ref">2020</a>)</cite> into the previous two training datasets continually improves the performance by decreasing 2.12 FD &amp; 1.40 FAD, 4.50 FAVD &amp; 3.63 FATD, and 3.73 FA(VT)D, compared to the vanilla baseline trained on only AudioCaps.
This might be due to the rich temporal semantics in LLP training data as each video includes at least one-second audio or visual events, which also validates the importance of learning temporal semantics from the video encoder by visual-aligned contrastive language-audio pre-training in video-aligned text-to-audio generation.</p>
</div>
<div id="S5.SS3.p5" class="ltx_para ltx_noindent">
<p id="S5.SS3.p5.2" class="ltx_p"><span id="S5.SS3.p5.2.1" class="ltx_text ltx_font_bold">Latent Diffusion Tuning.</span>
Tuning the latent diffusion model to capture temporal-aware representations as the guidance also benefits generating high-quality videos from input captions.
In order to explore such effects more comprehensively on video-aligned text-to-audio generation, we ablated latent diffusion tuning and varied the training data from <math id="S5.SS3.p5.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="S5.SS3.p5.1.m1.1a"><mo stretchy="false" id="S5.SS3.p5.1.m1.1.1" xref="S5.SS3.p5.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p5.1.m1.1b"><ci id="S5.SS3.p5.1.m1.1.1.cmml" xref="S5.SS3.p5.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p5.1.m1.1c">\{</annotation></semantics></math>AC + VS, AC + VS + LLP<math id="S5.SS3.p5.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="S5.SS3.p5.2.m2.1a"><mo stretchy="false" id="S5.SS3.p5.2.m2.1.1" xref="S5.SS3.p5.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p5.2.m2.1b"><ci id="S5.SS3.p5.2.m2.1.1.cmml" xref="S5.SS3.p5.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p5.2.m2.1c">\}</annotation></semantics></math>, where AC and VS denote AudioCaps and VGGSound datasets, respectively.
The comparison results on our <span id="S5.SS3.p5.2.2" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> are shown in Table <a href="#S5.T8" title="Table 8 ‣ 5.3 Experimental Analysis ‣ 5 Experiments ‣ Text-to-Audio Generation Synchronized with Videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.
Adding latent diffusion model tuning to both training data settings improves video-aligned text-to-audio generation performance in terms of all metrics.
In particular, latent diffusion tuning improves the results by decreasing 1.55 FD &amp; 0.52 FAD, 1.08 FAVD &amp; 1.06 FATD, and 2.11 FA(VT)D on AC + VS, and by 1.57 FD &amp; 0.16 FAD, 0.12 FAVD &amp; 0.16 FATD, and 1.13 FA(VT)D on AC + VS + LLP.
These improvements demonstrate the importance of latent diffusion tuning in learning new temporal-aware semantics aligned with both text and videos using Audio-Visual ControlNet for generating high-fidelity audio aligned with videos from the input caption.
However, the performance gains of latent diffusion model tuning on AC + VS + LLP are less than latent diffusion model tuning on AC + VS, since there might be some similar videos with overlapping semantics from the video encoder by visual-aligned contrastive language-audio pre-training on AC + LLP or VS + LLP, which leads to confusion on generating audio aligned with different videos from similar input captions.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we present <span id="S6.p1.1.1" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span>, a new benchmark for TTA generation aligned with videos, and three novel metrics that evaluate visual alignment and temporal consistency.
We also propose a simple yet effective latent diffusion approach, named <span id="S6.p1.1.2" class="ltx_text ltx_font_smallcaps">T2AV</span>, that integrates temporal visual-aligned embeddings with Audio-Visual ControlNet as the condition.
We introduce a temporal multi-head self-attention transformer to aggregate temporal information from video features to fuse temporal visual embeddings in Audio-Visual ControlNet.
Empirical experiments on AudioCaps and our <span id="S6.p1.1.3" class="ltx_text ltx_font_smallcaps">T2AV-Bench</span> benchmarks demonstrate the state-of-the-art performance of our <span id="S6.p1.1.4" class="ltx_text ltx_font_smallcaps">T2AV</span> on visual-aligned text-to-audio generation.
Meanwhile, qualitative visualizations of videos paired with audio vividly showcase the effectiveness of our <span id="S6.p1.1.5" class="ltx_text ltx_font_smallcaps">T2AV</span> in capturing visual alignment and temporal consistency.
Furthermore, extensive ablation studies also validate the importance of visual-aligned CLAP and Audio-Visual ControlNet, training data scale, and latent diffusion tuning in video-aligned text-to-audio generation.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Impact Statement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The method under discussion creates audio that aligns with videos based on user-uploaded captions on the web.
This approach risks embedding internal biases in the data.
For instance, the model may struggle to accurately produce audio for less common yet vital sound categories in videos.
Addressing these potential shortcomings is crucial for the application in real-world scenarios.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arandjelovic &amp; Zisserman (2017)</span>
<span class="ltx_bibblock">
Arandjelovic, R. and Zisserman, A.

</span>
<span class="ltx_bibblock">Look, listen and learn.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</em>, pp.  609–617, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aytar et al. (2016)</span>
<span class="ltx_bibblock">
Aytar, Y., Vondrick, C., and Torralba, A.

</span>
<span class="ltx_bibblock">Soundnet: Learning sound representations from unlabeled video.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</em>, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020)</span>
<span class="ltx_bibblock">
Chen, H., Xie, W., Vedaldi, A., and Zisserman, A.

</span>
<span class="ltx_bibblock">Vggsound: A large-scale audio-visual dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp.  721–725. IEEE, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2023)</span>
<span class="ltx_bibblock">
Du, Y., Chen, Z., Salamon, J., Russell, B., and Owens, A.

</span>
<span class="ltx_bibblock">Conditional generation of audio from video via foley analogies.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  2426–2436, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gan et al. (2020)</span>
<span class="ltx_bibblock">
Gan, C., Huang, D., Zhao, H., Tenenbaum, J. B., and Torralba, A.

</span>
<span class="ltx_bibblock">Music gesture for visual sound separation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp.  10478–10487, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hershey et al. (2017)</span>
<span class="ltx_bibblock">
Hershey, S., Chaudhuri, S., Ellis, D. P. W., Gemmeke, J. F., Jansen, A., Moore, R. C., Plakal, M., Platt, D., Saurous, R. A., Seybold, B., Slaney, M., Weiss, R. J., and Wilson, K.

</span>
<span class="ltx_bibblock">Cnn architectures for large-scale audio classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et al. (2020)</span>
<span class="ltx_bibblock">
Ho, J., Jain, A., and Abbeel, P.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances In Neural Information Processing Systems (NeurIPS)</em>, pp.  6840–6851, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et al. (2022)</span>
<span class="ltx_bibblock">
Ho, J., Chan, W., Saharia, C., Whang, J., Gao, R., Gritsenko, A., Kingma, D. P., Poole, B., Norouzi, M., Fleet, D. J., and Salimans, T.

</span>
<span class="ltx_bibblock">Imagen video: High definition video generation with diffusion models.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.02303</em>, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023)</span>
<span class="ltx_bibblock">
Huang, R., Huang, J., Yang, D., Ren, Y., Liu, L., Li, M., Ye, Z., Liu, J., Yin, X., and Zhao, Z.

</span>
<span class="ltx_bibblock">Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.12661</em>, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iashin &amp; Rahtu (2021a)</span>
<span class="ltx_bibblock">
Iashin, V. and Rahtu, E.

</span>
<span class="ltx_bibblock">Taming visually guided sound generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of British Machine Vision Conference (BMVC)</em>, 2021a.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iashin &amp; Rahtu (2021b)</span>
<span class="ltx_bibblock">
Iashin, V. and Rahtu, E.

</span>
<span class="ltx_bibblock">Taming visually guided sound generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.08791</em>, 2021b.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2019)</span>
<span class="ltx_bibblock">
Kim, C. D., Kim, B., Lee, H., and Kim, G.

</span>
<span class="ltx_bibblock">AudioCaps: Generating captions for audios in the wild.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pp.  119–132, 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kong et al. (2021)</span>
<span class="ltx_bibblock">
Kong, Z., Ping, W., Huang, J., Zhao, K., and Catanzaro, B.

</span>
<span class="ltx_bibblock">Diffwave: A versatile diffusion model for audio synthesis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Korbar et al. (2018)</span>
<span class="ltx_bibblock">
Korbar, B., Tran, D., and Torresani, L.

</span>
<span class="ltx_bibblock">Cooperative learning of audio and video models from self-supervised synchronization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</em>, 2018.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kreuk et al. (2023)</span>
<span class="ltx_bibblock">
Kreuk, F., Synnaeve, G., Polyak, A., Singer, U., Défossez, A., Copet, J., Parikh, D., Taigman, Y., and Adi, Y.

</span>
<span class="ltx_bibblock">Audiogen: Textually guided audio generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of International Conference on Learning Representations (ICLR)</em>, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2019)</span>
<span class="ltx_bibblock">
Lin, Y.-B., Li, Y.-J., and Wang, Y.-C. F.

</span>
<span class="ltx_bibblock">Dual-modality seq2seq network for audio-visual event localization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp.  2002–2006. IEEE, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2021)</span>
<span class="ltx_bibblock">
Lin, Y.-B., Tseng, H.-Y., Lee, H.-Y., Lin, Y.-Y., and Yang, M.-H.

</span>
<span class="ltx_bibblock">Exploring cross-video and cross-modality signals for weakly-supervised audio-visual video parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Liu, H., Chen, Z., Yuan, Y., Mei, X., Liu, X., Mandic, D., Wang, W., and Plumbley, M. D.

</span>
<span class="ltx_bibblock">Audioldm: Text-to-audio generation with latent diffusion models.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.12503</em>, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2022)</span>
<span class="ltx_bibblock">
Ma, Y., Xu, G., Sun, X., Yan, M., Zhang, J., and Ji, R.

</span>
<span class="ltx_bibblock">X-clip: End-to-end multi-grained contrastive learning for video-text retrieval.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of ACM International Conference on Multimedia (ACMMM)</em>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mikolov et al. (2013)</span>
<span class="ltx_bibblock">
Mikolov, T., Chen, K., Corrado, G., and Dean, J.

</span>
<span class="ltx_bibblock">Efficient estimation of word representations in vector space.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of International Conference on Learning Representations (ICLR)</em>, 2013.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Morgado (2022a)</span>
<span class="ltx_bibblock">
Mo, S. and Morgado, P.

</span>
<span class="ltx_bibblock">Localizing visual sounds the easy way.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of European Conference on Computer Vision (ECCV)</em>, pp.  218–234, 2022a.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Morgado (2022b)</span>
<span class="ltx_bibblock">
Mo, S. and Morgado, P.

</span>
<span class="ltx_bibblock">A closer look at weakly-supervised audio-visual source localization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</em>, 2022b.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Morgado (2022c)</span>
<span class="ltx_bibblock">
Mo, S. and Morgado, P.

</span>
<span class="ltx_bibblock">Benchmarking weakly-supervised audio-visual sound localization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision (ECCV) Workshop</em>, 2022c.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Morgado (2023a)</span>
<span class="ltx_bibblock">
Mo, S. and Morgado, P.

</span>
<span class="ltx_bibblock">Unveiling the power of audio-visual early fusion transformers with dense interactions through masked modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.01017</em>, 2023a.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Morgado (2023b)</span>
<span class="ltx_bibblock">
Mo, S. and Morgado, P.

</span>
<span class="ltx_bibblock">A unified audio-visual learning framework for localization, separation, and recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.19458</em>, 2023b.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Raj (2023)</span>
<span class="ltx_bibblock">
Mo, S. and Raj, B.

</span>
<span class="ltx_bibblock">Weakly-supervised audio-visual segmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</em>, 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Tian (2022a)</span>
<span class="ltx_bibblock">
Mo, S. and Tian, Y.

</span>
<span class="ltx_bibblock">Multi-modal grouping network for weakly-supervised audio-visual video parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</em>, 2022a.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Tian (2022b)</span>
<span class="ltx_bibblock">
Mo, S. and Tian, Y.

</span>
<span class="ltx_bibblock">Semantic-aware multi-modal grouping for weakly-supervised audio-visual video parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision (ECCV) Workshop</em>, 2022b.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Tian (2023a)</span>
<span class="ltx_bibblock">
Mo, S. and Tian, Y.

</span>
<span class="ltx_bibblock">Audio-visual grouping network for sound localization from mixtures.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.17056</em>, 2023a.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo &amp; Tian (2023b)</span>
<span class="ltx_bibblock">
Mo, S. and Tian, Y.

</span>
<span class="ltx_bibblock">AV-SAM: Segment anything model meets audio-visual localization and segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.01836</em>, 2023b.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo et al. (2023a)</span>
<span class="ltx_bibblock">
Mo, S., Pian, W., and Tian, Y.

</span>
<span class="ltx_bibblock">Class-incremental grouping network for continual audio-visual learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023a.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo et al. (2023b)</span>
<span class="ltx_bibblock">
Mo, S., Shi, J., and Tian, Y.

</span>
<span class="ltx_bibblock">DiffAVA: Personalized text-to-audio generation with visual alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.12903</em>, 2023b.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Morgado et al. (2018)</span>
<span class="ltx_bibblock">
Morgado, P., Nvasconcelos, N., Langlois, T., and Wang, O.

</span>
<span class="ltx_bibblock">Self-supervised generation of spatial audio for 360°video.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</em>, 2018.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Morgado et al. (2020)</span>
<span class="ltx_bibblock">
Morgado, P., Li, Y., and Nvasconcelos, N.

</span>
<span class="ltx_bibblock">Learning representations from audio-visual spatial alignment.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of Advances in Neural Information Processing Systems (NeurIPS)</em>, pp.  4733–4744, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Morgado et al. (2021a)</span>
<span class="ltx_bibblock">
Morgado, P., Misra, I., and Vasconcelos, N.

</span>
<span class="ltx_bibblock">Robust audio-visual instance discrimination.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp.  12934–12945, 2021a.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Morgado et al. (2021b)</span>
<span class="ltx_bibblock">
Morgado, P., Vasconcelos, N., and Misra, I.

</span>
<span class="ltx_bibblock">Audio-visual instance discrimination with cross-modal agreement.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp.  12475–12486, June 2021b.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Owens et al. (2016)</span>
<span class="ltx_bibblock">
Owens, A., Wu, J., McDermott, J. H., Freeman, W. T., and Torralba, A.

</span>
<span class="ltx_bibblock">Ambient sound provides supervision for visual learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer Vision (ECCV)</em>, pp.  801–816, 2016.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pian et al. (2023)</span>
<span class="ltx_bibblock">
Pian, W., Mo, S., Guo, Y., and Tian, Y.

</span>
<span class="ltx_bibblock">Audio-visual class-incremental learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruan et al. (2023)</span>
<span class="ltx_bibblock">
Ruan, L., Ma, Y., Yang, H., He, H., Liu, B., Fu, J., Yuan, N. J., Jin, Q., and Guo, B.

</span>
<span class="ltx_bibblock">Mm-diffusion: Learning multi-modal diffusion models for joint audio and video generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saharia et al. (2021)</span>
<span class="ltx_bibblock">
Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D. J., and Norouzi, M.

</span>
<span class="ltx_bibblock">Image super-resolution via iterative refinement.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.07636</em>, 2021.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saharia et al. (2022)</span>
<span class="ltx_bibblock">
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., Ghasemipour, S. K. S., Ayan, B. K., Mahdavi, S. S., Lopes, R. G., Salimans, T., Ho, J., Fleet, D. J., and Norouzi, M.

</span>
<span class="ltx_bibblock">Photorealistic text-to-image diffusion models with deep language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.11487</em>, 2022.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Senocak et al. (2018)</span>
<span class="ltx_bibblock">
Senocak, A., Oh, T.-H., Kim, J., Yang, M.-H., and Kweon, I. S.

</span>
<span class="ltx_bibblock">Learning to localize sound source in visual scenes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp.  4358–4366, 2018.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. (2021)</span>
<span class="ltx_bibblock">
Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B.

</span>
<span class="ltx_bibblock">Score-based generative modeling through stochastic differential equations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. (2018)</span>
<span class="ltx_bibblock">
Tian, Y., Shi, J., Li, B., Duan, Z., and Xu, C.

</span>
<span class="ltx_bibblock">Audio-visual event localization in unconstrained videos.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of European Conference on Computer Vision (ECCV)</em>, 2018.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. (2020)</span>
<span class="ltx_bibblock">
Tian, Y., Li, D., and Xu, C.

</span>
<span class="ltx_bibblock">Unified multisensory perception: Weakly-supervised audio-visual video parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of European Conference on Computer Vision (ECCV)</em>, pp.  436–454, 2020.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tran et al. (2015)</span>
<span class="ltx_bibblock">
Tran, D., Bourdev, L., Fergus, R., Torresani, L., and Paluri, M.

</span>
<span class="ltx_bibblock">Learning spatiotemporal features with 3d convolutional networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</em>, 2015.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu &amp; Yang (2021)</span>
<span class="ltx_bibblock">
Wu, Y. and Yang, Y.

</span>
<span class="ltx_bibblock">Exploring heterogeneous clues for weakly-supervised audio-visual video parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp.  1326–1335, 2021.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2019)</span>
<span class="ltx_bibblock">
Wu, Y., Zhu, L., Yan, Y., and Yang, Y.

</span>
<span class="ltx_bibblock">Dual attention matching for audio-visual event localization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on computer vision</em>, pp.  6292–6300, 2019.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Wu, Y., Chen, K., Zhang, T., Hui, Y., Berg-Kirkpatrick, T., and Dubnov, S.

</span>
<span class="ltx_bibblock">Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP</em>, 2023.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2022)</span>
<span class="ltx_bibblock">
Yang, D., Yu, J., Wang, H., Wang, W., Weng, C., Zou, Y., and Yu, D.

</span>
<span class="ltx_bibblock">Diffsound: Discrete diffusion model for text-to-sound generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.09983</em>, 2022.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Zhang, L., Rao, A., and Agrawala, M.

</span>
<span class="ltx_bibblock">Adding conditional control to text-to-image diffusion models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</em>, 2023.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2018)</span>
<span class="ltx_bibblock">
Zhao, H., Gan, C., Rouditchenko, A., Vondrick, C., McDermott, J., and Torralba, A.

</span>
<span class="ltx_bibblock">The sound of pixels.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer Vision (ECCV)</em>, pp.  570–586, 2018.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2019)</span>
<span class="ltx_bibblock">
Zhao, H., Gan, C., Ma, W.-C., and Torralba, A.

</span>
<span class="ltx_bibblock">The sound of motions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, pp.  1735–1744, 2019.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2018)</span>
<span class="ltx_bibblock">
Zhou, Y., Wang, Z., Fang, C., Bui, T., and Berg, T. L.

</span>
<span class="ltx_bibblock">Visual to sound: Generating natural sound for videos in the wild.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  3550–3558, 2018.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.07937" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.07938" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.07938">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.07938" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.07939" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 14:08:14 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
