<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.02408] CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models</title><meta property="og:description" content="Effectively using Natural Language Processing (NLP) tools in under-resourced languages requires a thorough understanding of the language itself, familiarity with the latest models and training methodologies, and techni…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.02408">

<!--Generated on Sun May  5 18:53:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zaid Sheikh<sup id="id10.10.id1" class="ltx_sup">1</sup>, Antonios Anastasopoulos<sup id="id11.11.id2" class="ltx_sup">2</sup>, Shruti Rijhwani<sup id="id12.12.id3" class="ltx_sup">1</sup>,
<br class="ltx_break"><span id="id6.6.3" class="ltx_text ltx_font_bold">Lindia Tjuatja<sup id="id6.6.3.1" class="ltx_sup"><span id="id6.6.3.1.1" class="ltx_text ltx_font_medium">1</span></sup>, Robbie Jimerson<sup id="id6.6.3.2" class="ltx_sup"><span id="id6.6.3.2.1" class="ltx_text ltx_font_medium">3</span></sup>, Graham Neubig<sup id="id6.6.3.3" class="ltx_sup"><span id="id6.6.3.3.1" class="ltx_text ltx_font_medium">1</span></sup></span> 
<br class="ltx_break"><sup id="id13.13.id4" class="ltx_sup">1</sup>Carnegie Mellon University, <sup id="id14.14.id5" class="ltx_sup">2</sup>George Mason University, <sup id="id15.15.id6" class="ltx_sup">3</sup>Rochester Institute of Technology 
<br class="ltx_break"><span id="id16.16.id7" class="ltx_text ltx_font_typewriter">{zsheikh,gneubig}@cs.cmu.edu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id17.id1" class="ltx_p">Effectively using Natural Language Processing (NLP) tools in under-resourced languages requires a thorough understanding of the language itself, familiarity with the latest models and training methodologies, and technical expertise to deploy these models. This could present a significant obstacle for language community members and linguists to use NLP tools. This paper introduces the CMU Linguistic Annotation Backend (<a target="_blank" href="https://cmulab.dev" title="" class="ltx_ref ltx_href">CMULAB</a>), an open-source framework that simplifies model deployment and continuous human-in-the-loop fine-tuning of NLP models. CMULAB enables users to leverage the power of multilingual models to quickly adapt and extend existing tools for speech recognition, OCR, translation, and syntactic analysis to new languages, even with limited training data. We describe various tools and APIs that are currently available and how developers can easily add new models/functionality to the framework.
Code is available at <a target="_blank" href="https://github.com/neulab/cmulab" title="" class="ltx_ref ltx_href">github.com/neulab/cmulab</a> along with a live demo at <a target="_blank" href="https://cmulab.dev" title="" class="ltx_ref ltx_href">https://cmulab.dev</a><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>A short demo video is available at <a target="_blank" href="https://youtu.be/t67hDN_hly4" title="" class="ltx_ref ltx_href">youtu.be/t67hDN_hly4</a></span></span></span>.</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\addauthor</span>
<p id="p1.2" class="ltx_p">gnmagenta
<span id="p1.2.1" class="ltx_ERROR undefined">\addauthor</span>anorange
<span id="p1.2.2" class="ltx_ERROR undefined">\addauthor</span>ltblue


</p>
</div>
<div id="p2" class="ltx_para ltx_noindent">
<div id="p2.9" class="ltx_block ltx_align_bottom">
<p id="p2.9.10" class="ltx_p"><span id="p2.9.10.1" class="ltx_text ltx_font_bold">CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models</span></p>
<br class="ltx_break ltx_centering">
<p id="p2.9.9" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p2.9.9.9" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p2.9.9.9.9" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p2.3.3.3.3.3" class="ltx_tr">
<span id="p2.3.3.3.3.3.3" class="ltx_td ltx_align_center"><span id="p2.3.3.3.3.3.3.3" class="ltx_text ltx_font_bold">Zaid Sheikh<sup id="p2.3.3.3.3.3.3.3.1" class="ltx_sup"><span id="p2.3.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_medium">1</span></sup>, Antonios Anastasopoulos<sup id="p2.3.3.3.3.3.3.3.2" class="ltx_sup"><span id="p2.3.3.3.3.3.3.3.2.1" class="ltx_text ltx_font_medium">2</span></sup>, Shruti Rijhwani<sup id="p2.3.3.3.3.3.3.3.3" class="ltx_sup"><span id="p2.3.3.3.3.3.3.3.3.1" class="ltx_text ltx_font_medium">1</span></sup>,</span></span></span>
<span id="p2.6.6.6.6.6" class="ltx_tr">
<span id="p2.6.6.6.6.6.3" class="ltx_td ltx_align_center"><span id="p2.6.6.6.6.6.3.3" class="ltx_text ltx_font_bold">Lindia Tjuatja<sup id="p2.6.6.6.6.6.3.3.1" class="ltx_sup"><span id="p2.6.6.6.6.6.3.3.1.1" class="ltx_text ltx_font_medium">1</span></sup>, Robbie Jimerson<sup id="p2.6.6.6.6.6.3.3.2" class="ltx_sup"><span id="p2.6.6.6.6.6.3.3.2.1" class="ltx_text ltx_font_medium">3</span></sup>, Graham Neubig<sup id="p2.6.6.6.6.6.3.3.3" class="ltx_sup"><span id="p2.6.6.6.6.6.3.3.3.1" class="ltx_text ltx_font_medium">1</span></sup></span></span></span>
<span id="p2.9.9.9.9.9" class="ltx_tr">
<span id="p2.9.9.9.9.9.3" class="ltx_td ltx_align_center"><sup id="p2.9.9.9.9.9.3.1" class="ltx_sup">1</sup>Carnegie Mellon University, <sup id="p2.9.9.9.9.9.3.2" class="ltx_sup">2</sup>George Mason University, <sup id="p2.9.9.9.9.9.3.3" class="ltx_sup">3</sup>Rochester Institute of Technology</span></span>
<span id="p2.9.9.9.9.10.1" class="ltx_tr">
<span id="p2.9.9.9.9.10.1.1" class="ltx_td ltx_align_center"><span id="p2.9.9.9.9.10.1.1.1" class="ltx_text ltx_font_typewriter">{zsheikh,gneubig}@cs.cmu.edu</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With improved methodology and data availability, it is now possible for a skilled NLP practitioner to build somewhat accurate systems for many languages in the world, even those that have relatively few resources <cite class="ltx_cite ltx_citemacro_citep">(Hedderich et al., <a href="#bib.bib6" title="" class="ltx_ref">2021</a>; Ogueji et al., <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>.
At the same time, there is burgeoning interest from linguists and language community members to apply these state-of-the-art techniques to languages where these technologies are not widely accessible, for applications such as optical character recognition <cite class="ltx_cite ltx_citemacro_citep">(Nguyen et al., <a href="#bib.bib12" title="" class="ltx_ref">2021</a>; Rijhwani et al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, speech recognition <cite class="ltx_cite ltx_citemacro_citep">(Bartelds et al., <a href="#bib.bib2" title="" class="ltx_ref">2023</a>; Hou et al., <a href="#bib.bib7" title="" class="ltx_ref">2021</a>)</cite>, and machine translation <cite class="ltx_cite ltx_citemacro_citep">(Ranathunga et al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>; Haddow et al., <a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>.
However, herein lies a skill gap: despite this considerable interest, often the barrier of entry for building high-quality systems is high, because of the technological expertise that is typically necessary.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To address this issue, we present the CMU Linguistic Annotation Backend (CMULAB), an open-source web-based framework that allows users to quickly adapt/extend existing NLP tools to new languages and domains by leveraging massively multilingual neural network models.
This allows language community members, linguists, and other end-users to use these models as well as improve them by uploading corrected annotations and fine-tuning the models (<a href="#S2" title="2 Framework Overview ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 2</span></a>).</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Several NLP tasks are included out-of-the-box (<a href="#S3" title="3 Currently Supported NLP tasks ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 3</span></a>). These include</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Optical character recognition</span>, using the Google Cloud Vision OCR<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://cloud.google.com/vision/docs/ocr" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cloud.google.com/vision/docs/ocr</a></span></span></span> and the post-correction method of <cite class="ltx_cite ltx_citemacro_citet">Rijhwani et al. (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Speech recognition</span>, through Allosaurus, a pretrained universal phone recognizer for more than 2000 languages <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Speaker diarization</span>, through a model based on Resemblyzer<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/resemble-ai/Resemblyzer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/resemble-ai/Resemblyzer</a></span></span></span>, an open-source diarization tool based on neural speaker embeddings <cite class="ltx_cite ltx_citemacro_cite">Wan et al. (<a href="#bib.bib19" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Machine translation</span>, through the NLLB translation model that supports 200 languages <cite class="ltx_cite ltx_citemacro_cite">NLLB Team et al. (<a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p"><span id="S1.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Morphosyntactic analysis</span>, with GlossLM, a pre-trained model for interlinear glossing in many languages <cite class="ltx_cite ltx_citemacro_cite">Ginn et al. (<a href="#bib.bib4" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">End-users do not need to have any coding or technical expertise to use or fine-tune these models. In addition, the open-source and modular nature of the framework allows developers to easily integrate additional models or functionality. Developers also have direct access to the back-end models via well-defined REST APIs, allowing them to design custom interfaces or add additional features to popular annotation tools such as FLEx<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://software.sil.org/fieldworks/</span></span></span>, ELAN <cite class="ltx_cite ltx_citemacro_citep">(Wittenburg et al., <a href="#bib.bib20" title="" class="ltx_ref">2006</a>)</cite> or Inception <cite class="ltx_cite ltx_citemacro_citep">(Klie et al., <a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">CMULAB takes a step towards putting advanced language technologies in the hands of under-represented language communities and linguists, and in <a href="#S7" title="7 Case Study ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 7</span></a>, we discuss some of our initial case studies where CMULAB is being used to develop NLP models for endangered languages.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Framework Overview</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">When users interact with CMULAB, they will do so through a frontend, which can be either the <a target="_blank" href="https://cmulab.dev" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cmulab.dev</a> web site, a front-end plugin to annotation software such as ELAN, or (for developers) through REST APIs (<a href="#S5" title="5 Frontend implementation ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 5</span></a>).
Requests originating from this frontend are forwarded to a separate, high-powered backend server for processing (<a href="#S4" title="4 Backend implementation ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 4</span></a>).</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Out-of-the-box, CMULAB includes a selection of pre-trained multilingual base models that support a number of NLP tasks (<a href="#S3" title="3 Currently Supported NLP tasks ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 3</span></a>) over hundreds of languages.
All of these models support zero-shot application to new languages, so even for languages that are not covered in the training data, users can get first results on a new language within minutes.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Users also have the option to upload training data to fine-tune the models to further improve performance beyond what is available zero-shot.
After models are trained, users can interact with them through the interface. They have options to view the model details, run predictions, or delete the model if it is no longer needed. To foster collaboration, users also have the option of sharing their trained models with the community by marking them as public.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Languages supported</figcaption>
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Task</td>
<td id="S2.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Model</td>
<td id="S2.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">Supported Languages</td>
</tr>
<tr id="S2.T1.1.2.2" class="ltx_tr">
<td id="S2.T1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Phoneme recognition</td>
<td id="S2.T1.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Allosaurus</td>
<td id="S2.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">2000+</td>
</tr>
<tr id="S2.T1.1.3.3" class="ltx_tr">
<td id="S2.T1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r">Speaker Diarization</td>
<td id="S2.T1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r">Resemblyzer</td>
<td id="S2.T1.1.3.3.3" class="ltx_td ltx_align_center">Language-independent</td>
</tr>
<tr id="S2.T1.1.4.4" class="ltx_tr">
<td id="S2.T1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r">Automatic glossing</td>
<td id="S2.T1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r">lecslab/glosslm</td>
<td id="S2.T1.1.4.4.3" class="ltx_td ltx_align_center">1800</td>
</tr>
<tr id="S2.T1.1.5.5" class="ltx_tr">
<td id="S2.T1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r">OCR post-correction</td>
<td id="S2.T1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r">Google Vision API + post-correction model</td>
<td id="S2.T1.1.5.5.3" class="ltx_td ltx_align_center">200+ languages, 32 scripts</td>
</tr>
<tr id="S2.T1.1.6.6" class="ltx_tr">
<td id="S2.T1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Machine Translation</td>
<td id="S2.T1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">facebook/nllb-200-distilled-600M</td>
<td id="S2.T1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_bb">200</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Currently Supported NLP tasks</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">CMULAB supports a variety of NLP tasks with the goal of making linguistic documentation easier, including speaker segmentation and diarization, phoneme recognition, automatic glossing, machine translation and OCR post-correction. <a href="#S2.T1" title="Table 1 ‣ 2 Framework Overview ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a> provides an overview of the models used and the languages supported. These tasks are described in more detail in the following sections.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>OCR post-correction</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Pre-trained OCR software can struggle with low-resource languages, often producing inaccurate results with high error rates. Our OCR-post-correction tool <cite class="ltx_cite ltx_citemacro_citep">(Rijhwani et al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite> addresses this issue by automatically correcting errors, given a small amount of training data. The process begins with the user uploading a set of document images and receiving transcribed output from the Google Vision API. Alternatively, users may opt to utilize any other OCR tool for the initial transcription. In the event of errors in the output, users can manually correct a selection of files, which can then be uploaded to train a new post-correction model in step 2. This updated model can subsequently be utilized to correct additional first-pass OCR output in step 3. Steps 2 and 3 can be repeated multiple times to progressively improve the model’s performance.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Phoneme recognition</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">CMULAB’s phone transcription API is based on the Allosaurus <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite> pre-trained universal phone recognizer which supports more than 2000 languages. The API also allows users to fine-tune the Allosaurus pre-trained models by uploading a small amount of training data. Our ELAN extension (<a href="#S5" title="5 Frontend implementation ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">section 5</span></a>) takes advantage of these APIs to enable users to generate initial phoneme transcriptions, make corrections to a few examples, and upload them to fine-tune the Allosaurus model. This can be repeated multiple times to iteratively improve the models.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Speaker Diarization</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Our speaker diarization tool is based on the Resemblyzer python package. It uses a pre-trained neural speech encoder <cite class="ltx_cite ltx_citemacro_cite">Wan et al. (<a href="#bib.bib19" title="" class="ltx_ref">2018</a>)</cite>. In particular, the user needs to provide a minimal amount of speaker annotation (a few seconds per speaker), which are used to create an average speaker embedding. The rest of the audio is then diarized based on its similarity to these speaker embeddings. This approach strikes a good balance between performance (with competent accuracy fairly close to other state-of-the-art but also more complicated models) with minimal annotation requirements, while also being computationally efficient.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Machine translation</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">We also offer a translation service powered by Meta’s NLLB model <cite class="ltx_cite ltx_citemacro_citep">(NLLB Team et al., <a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite>, supporting over 200 languages. This service allows users to translate text quickly and easily. Users can also upload their own data to fine-tune the model for their specific needs, potentially improving translation accuracy for their domain or language pair.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Interlinear glossing</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Interlinear glossed text (IGT) is a widely-used format for linguistic annotation, and is an information-dense resource often created by linguists in language documentation and fieldwork settings. IGT is a multi-line format that presents (1) a transcription in the source language, (2) morpheme-aligned labels (glosses) indicating each morpheme’s meaning and/or grammatical function, and often (3) a translation in a widely spoken language, such as English. Creating IGT corpora is a time-intensive task, requiring complex morphological analysis and extensive knowledge of the language grammar. To assist linguists in this task, we provide easy access to GlossLM <cite class="ltx_cite ltx_citemacro_cite">Ginn et al. (<a href="#bib.bib4" title="" class="ltx_ref">2024</a>)</cite>, a model that continually pretrained ByT5 <cite class="ltx_cite ltx_citemacro_cite">Xue et al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite> on the task of generating the gloss labels given a transcription and optional translation across 1.8k languages.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2404.02408/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Architecture Diagram</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Backend implementation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">CMULAB’s web interface and REST APIs are powered by Django, a popular open-source, Python-based web framework. Backend NLP models and functionality are implemented as python packages that register themselves as CMULAB plugins, enabling automatic discovery. The core CMULAB framework efficiently manages input and output data, invokes registered functions, and routes them to the appropriate task queues. It also supports real-time log file collection and display, task cancellation and restart on user request, email notifications regarding task status and other features to help users monitor and manage their training jobs.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">When tasks are submitted, via the web interface or the REST APIs, they are categorized based on their expected resource requirements and placed into corresponding task queues. These task queues are implemented using Redis as the message broker. Multiple background workers constantly fetch and execute tasks from these queues. For horizontal scaling, these workers can be distributed across multiple compute nodes. Pre-built Docker images simplify spinning up new worker nodes on demand. Developers also have the option to deploy their model using a third-party framework and instruct CMULAB to forward requests to the external server.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Authentication is done using Django’s built-in authentication system. Third-party OAuth authentication is also supported. API access is enabled using token-based authentication.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Frontend implementation</h2>

<figure id="S5.F2" class="ltx_figure"><img src="/html/2404.02408/assets/cmulab_homepage_bold.png" id="S5.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="354" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>CMULAB Homepage</figcaption>
</figure>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2404.02408/assets/models_tab_bold_cropped.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="184" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>CMULAB Models page</figcaption>
</figure>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2404.02408/assets/mt_ui_bold2.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="266" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Machine Translation UI</figcaption>
</figure>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2404.02408/assets/ocr_interface_bold.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="344" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>CMULAB OCR post-correction tool</figcaption>
</figure>
<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The CMULAB web interface is designed with a focus on maximizing user-friendliness and intuitiveness. Django templates are used server-side for dynamic HTML generation while the client-side functionality is handled by React, a popular JavaScript framework. Bootstrap CSS is utilized for styling purposes.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Users can also interact with CMULAB through our extension for ELAN,<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://archive.mpi.nl/tla/elan</span></span></span>
a widely-used annotation tool for audio and video recordings. The CMULAB ELAN extension<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://github.com/neulab/cmulab_elan_extension</span></span></span> allows users to run speaker diarization on any audio file, generate phone transcriptions, as well as upload corrected transcriptions to fine-tune the model.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Data Collection and Security</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">All data collected by the main <a target="_blank" href="https://cmulab.dev" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://cmulab.dev</a> server is done under an IRB protocol with informed consent. Users can always delete their models and all associated data, including logs. By default, everything remains private. Even if users choose to share a model publicly, only the model itself becomes accessible, not the underlying training data or logs. We also transparently disclose any use of third-party services, such as Google Vision API. In addition, because all of the code is open-source, technically saavy users can set up their own instances on a private server if they wish.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Case Study</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">As described in <a href="#S3.SS1" title="3.1 OCR post-correction ‣ 3 Currently Supported NLP tasks ‣ CMULAB: An Open-Source Framework for Training and Deployment of Natural Language Processing Models" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">subsection 3.1</span></a>, CMULAB’s OCR post-correction tool allows users to train a model that can correct errors in the output of existing OCR tools. We evaluated its performance and usability using Seneca, a low-resource indigenous language from the Iroquoian family of languages. The data originates from the four books of the gospel translated into Seneca by Presbyterian missionary Asher Wright. Published in 1878 using a printing press at the Seneca Mission on the Buffalo Creek Reservation in Buffalo, New York, the document predates modern computing and was never digitized, remaining solely in PDF format. The initial output from Google Vision API for Seneca data yielded a high CER of 44.11%. We manually corrected 10 pages and uploaded them to CMULAB. These were used to train a new post-correction model. This achieved a significant reduction in CER, dropping the error rate to 18.53%.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Comparison to Other Tools</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Open-source packages such as Gradio <cite class="ltx_cite ltx_citemacro_citep">(Abid et al., <a href="#bib.bib1" title="" class="ltx_ref">2019</a>)</cite> and Streamlit<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://github.com/streamlit/streamlit</span></span></span> make it easy to quickly build web applications on top of ML models. These frameworks, combined with application packaging and deployment tools such as Replicate’s Cog<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>https://github.com/replicate/cog</span></span></span> or BentoML<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>https://github.com/bentoml/BentoML</span></span></span> allow NLP practitioners to quickly build new NLP tools. However, these frameworks require technical knowledge beyond that available to most linguists or language community members.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">On the other end of the spectrum are no-code or low-code open-source GUI frameworks such as H2O LLM Studio <cite class="ltx_cite ltx_citemacro_citep">(Candel et al., <a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite> and LLaMA Board<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>https://github.com/hiyouga/LLaMA-Factory</span></span></span> that help users fine-tune LLMs. Deploying them in a scalable manner can still require a lot of technical knowledge and computational resources. The Prompt2Model project <cite class="ltx_cite ltx_citemacro_citep">(Viswanathan et al., <a href="#bib.bib18" title="" class="ltx_ref">2023</a>)</cite> attempts to address this issue by taking a natural language task description and using it to train a special-purpose model that is conducive to deployment. However, these approaches, due to their reliance on LLMs, do not work well on low-resource languages.</p>
</div>
<div id="S8.p3" class="ltx_para">
<p id="S8.p3.1" class="ltx_p">CMULAB, on the other hand, focuses on simplifying the use of NLP tools for low-resource languages. To this end, it offers pre-trained multilingual models that support hundreds of languages, a user-friendly interface for non-technical users, and is fully open source with clear contribution paths for researchers and developers to add new features and functionality.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Conclusion and Future Work</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">CMULAB presents a significant step towards democratizing access to NLP tools and models, particularly for under-resourced languages. By offering pre-trained multilingual models, a user-friendly interface, and easy deployment options, CMULAB empowers language communities and linguists to leverage advanced NLP technologies without requiring extensive technical expertise.</p>
</div>
<div id="S9.p2" class="ltx_para">
<p id="S9.p2.1" class="ltx_p">While this project has already achieved substantial progress, we envision several avenues for future development. Integrating active learning algorithms could optimize data annotation by prioritizing the most informative data points. Additionally, incorporating model comparison and evaluation tools would allow users to assess and select the best models for their specific needs. We also plan to implement a detailed version history system for uploaded data, enabling users to track changes in model performance over time. Finally, we aim to introduce granular permissions and access control mechanisms to facilitate data sharing, joint data curation, and enhanced collaboration.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">While CMULAB offers a powerful, flexible, and accessible platform to democratize access to NLP tools and models, it is important to acknowledge some limitations. CMULAB allows fine-tuning of pre-trained models, but the degree of customization is limited since end-users cannot modify the underlying model architecture or training algorithms. Furthermore, the success of fine-tuning is highly dependent on the quality and quantity of user-provided training data. In addition, CMULAB currently supports a limited set of NLP tasks. While its focus on extensibility allows for easy integration of new functionalities, a certain level of programming skills and knowledge of NLP techniques is still required. This necessitates cooperation between language communities and NLP researchers to build these new tasks.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We thank numerous collaborators who contributed to usability testing of CMULAB. Daisy Rosenblum and Olivia Chen from the University of British Columbia evaluated our OCR post-correction tool on Kwak’wala data and provided comprehensive feedback. We are also grateful to Jonathan Amith from Gettysburg College, who extensively tested our ELAN plugin using Yoloxochitl Mixtec and Nahuatl recordings, providing valuable suggestions for improvement.
We also thank Alexis Michaud for his feedback and for suggesting the name CMULAB.
This material is based upon work supported in part by the National Science Foundation under Grants No. 1761548, 2040926, 2211951, and by the National Endowment for the Humanities under Grant #PR-276810-21.</p>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">The CMULAB framework has the potential to democratize NLP by lowering the entry barrier for researchers and domain specialists who lack extensive technical expertise. This could lead to a wider range of languages and domains being covered by NLP tools, fostering broader understanding and communication across cultures.</p>
</div>
<div id="Sx3.p2" class="ltx_para">
<p id="Sx3.p2.1" class="ltx_p">However, with the ease of access and modification of NLP models, several ethical considerations must be taken into account. Multilingual large language models have been shown to facilitate the transmission of biases across different cultures and languages. Bearing this in mind, we intend to introduce measures to detect and mitigate such biases.</p>
</div>
<div id="Sx3.p3" class="ltx_para">
<p id="Sx3.p3.1" class="ltx_p">In addition, since CMULAB allows users to upload corrections and annotations, privacy and security of the data is of utmost importance, especially when it involves sensitive or personal data. CMULAB prioritizes the protection of user data. All data uploaded to CMULAB remains private by default, and users have full control over its access and deletion. Informed consent is obtained from individuals whose data is used to train or fine-tune NLP models.</p>
</div>
<div id="Sx3.p4" class="ltx_para">
<p id="Sx3.p4.1" class="ltx_p">We also acknowledge the importance of respecting intellectual property rights, especially when working with data and models for under-resourced languages and encourage users to be mindful of existing intellectual property rights and to engage in open and collaborative practices that respect the ownership and control of language data.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abid et al. (2019)</span>
<span class="ltx_bibblock">
Abubakar Abid, Ali Abdalla, Ali Abid, Dawood Khan, Abdulrahman Alfozan, and James Zou. 2019.

</span>
<span class="ltx_bibblock">Gradio: Hassle-free sharing and testing of ml models in the wild.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.02569</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bartelds et al. (2023)</span>
<span class="ltx_bibblock">
Martijn Bartelds, Nay San, Bradley McDonnell, Dan Jurafsky, and Martijn Wieling. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.42" title="" class="ltx_ref ltx_href">Making more of little data: Improving low-resource automatic speech recognition using data augmentation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 715–729, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Candel et al. (2023)</span>
<span class="ltx_bibblock">
Arno Candel, Jon McKinney, Philipp Singer, Pascal Pfeiffer, Maximilian Jeblick, Chun Ming Lee, and Marcos Conde. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-demo.6" title="" class="ltx_ref ltx_href">H2O open ecosystem for state-of-the-art large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>, pages 82–89, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ginn et al. (2024)</span>
<span class="ltx_bibblock">
Michael Ginn, Lindia Tjuatja, Taiqi He, Enora Rice, Graham Neubig, Alexis Palmer, and Lori Levin. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2403.06399" title="" class="ltx_ref ltx_href">Glosslm: Multilingual pretraining for low-resource interlinear glossing</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haddow et al. (2021)</span>
<span class="ltx_bibblock">
Barry Haddow, Rachel Bawden, Antonio Valerio Miceli Barone, Jindvrich Helcl, and Alexandra Birch. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:237371890" title="" class="ltx_ref ltx_href">Survey of low-resource machine translation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Computational Linguistics</em>, 48:673–732.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hedderich et al. (2021)</span>
<span class="ltx_bibblock">
Michael A. Hedderich, Lukas Lange, Heike Adel, Jannik Strötgen, and Dietrich Klakow. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.201" title="" class="ltx_ref ltx_href">A survey on recent approaches for natural language processing in low-resource scenarios</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 2545–2568, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al. (2021)</span>
<span class="ltx_bibblock">
Wenxin Hou, Hanlin Zhu, Yidong Wang, Jindong Wang, Tao Qin, Renjun Xu, and Takahiro Shinozaki. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:235187234" title="" class="ltx_ref ltx_href">Exploiting adapters for cross-lingual low-resource speech recognition</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 30:317–329.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klie et al. (2018)</span>
<span class="ltx_bibblock">
Jan-Christoph Klie, Michael Bugert, Beto Boullosa, Richard Eckart de Castilho, and Iryna Gurevych. 2018.

</span>
<span class="ltx_bibblock">The inception platform: Machine-assisted and knowledge-oriented interactive annotation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">proceedings of the 27th international conference on computational linguistics: system demonstrations</em>, pages 5–9.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Xinjian Li, Siddharth Dalmia, Juncheng Li, Matthew Lee, Patrick Littell, Jiali Yao, Antonios Anastasopoulos, David R Mortensen, Graham Neubig, Alan W Black, and Metze Florian. 2020.

</span>
<span class="ltx_bibblock">Universal phone recognition with a multilingual allophone system.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 8249–8253. IEEE.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neubig and Hu (2018)</span>
<span class="ltx_bibblock">
Graham Neubig and Junjie Hu. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D18-1103" title="" class="ltx_ref ltx_href">Rapid adaptation of neural machine translation to new languages</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pages 875–880, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neubig et al. (2019)</span>
<span class="ltx_bibblock">
Graham Neubig, Patrick Littell, Chian-Yu Chen, Jean Lee, Zirui Li, Yu-Hsiang Lin, and Yuyan Zhang. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1812.05272" title="" class="ltx_ref ltx_href">Towards a general-purpose linguistic annotation backend</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Workshop on The Use of Computational Methods in the Study of Endangered Languages (Compute-EL)</em>, Honolulu, Hawaii.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al. (2021)</span>
<span class="ltx_bibblock">
Thi Tuyet Hai Nguyen, Adam Jatowt, Mickael Coustaty, and Antoine Doucet. 2021.

</span>
<span class="ltx_bibblock">Survey of post-ocr processing approaches.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>, 54(6):1–37.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NLLB Team et al. (2022)</span>
<span class="ltx_bibblock">
NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia-Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022.

</span>
<span class="ltx_bibblock">No language left behind: Scaling human-centered machine translation.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ogueji et al. (2021)</span>
<span class="ltx_bibblock">
Kelechi Ogueji, Yuxin Zhu, and Jimmy Lin. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.mrl-1.11" title="" class="ltx_ref ltx_href">Small data? no problem! exploring the viability of pretrained multilingual language models for low-resourced languages</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st Workshop on Multilingual Representation Learning</em>, pages 116–126, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranathunga et al. (2023)</span>
<span class="ltx_bibblock">
Surangika Ranathunga, En-Shiun Annie Lee, Marjana Prifti Skenduli, Ravi Shekhar, Mehreen Alam, and Rishemjit Kaur. 2023.

</span>
<span class="ltx_bibblock">Neural machine translation for low-resource languages: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, 55(11):1–37.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rijhwani et al. (2020)</span>
<span class="ltx_bibblock">
Shruti Rijhwani, Antonios Anastasopoulos, and Graham Neubig. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.478" title="" class="ltx_ref ltx_href">OCR Post Correction for Endangered Language Texts</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 5931–5942, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2022)</span>
<span class="ltx_bibblock">
NLLB Team, Marta R. Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, Anna Sun, Skyler Wang, Guillaume Wenzek, Al Youngblood, Bapi Akula, Loic Barrault, Gabriel Mejia Gonzalez, Prangthip Hansanti, John Hoffman, Semarley Jarrett, Kaushik Ram Sadagopan, Dirk Rowe, Shannon Spruit, Chau Tran, Pierre Andrews, Necip Fazil Ayan, Shruti Bhosale, Sergey Edunov, Angela Fan, Cynthia Gao, Vedanuj Goswami, Francisco Guzmán, Philipp Koehn, Alexandre Mourachko, Christophe Ropers, Safiyyah Saleem, Holger Schwenk, and Jeff Wang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2207.04672" title="" class="ltx_ref ltx_href">No language left behind: Scaling human-centered machine translation</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Viswanathan et al. (2023)</span>
<span class="ltx_bibblock">
Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Wu, and Graham Neubig. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2308.12261" title="" class="ltx_ref ltx_href">Prompt2model: Generating deployable models from natural language instructions</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan et al. (2018)</span>
<span class="ltx_bibblock">
Li Wan, Quan Wang, Alan Papir, and Ignacio Lopez Moreno. 2018.

</span>
<span class="ltx_bibblock">Generalized end-to-end loss for speaker verification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 4879–4883. IEEE.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wittenburg et al. (2006)</span>
<span class="ltx_bibblock">
Peter Wittenburg, Hennie Brugman, Albert Russel, Alex Klassmann, and Han Sloetjes. 2006.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2006/pdf/153_pdf.pdf" title="" class="ltx_ref ltx_href">ELAN: a professional framework for multimodality research</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC’06)</em>, Genoa, Italy. European Language Resources Association (ELRA).

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et al. (2022)</span>
<span class="ltx_bibblock">
Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, and Colin Raffel. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00461" title="" class="ltx_ref ltx_href">ByT5: Towards a token-free future with pre-trained byte-to-byte models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 10:291–306.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2020)</span>
<span class="ltx_bibblock">
Chongchong Yu, Meng Kang, Yunbing Chen, Jiajia Wu, and Xia Zhao. 2020.

</span>
<span class="ltx_bibblock">Acoustic modeling based on deep learning for low-resource speech recognition: An overview.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, 8:163829–163843.

</span>
</li>
</ul>
</section>
<div id="p3" class="ltx_para">
<p id="p3.1" class="ltx_p"></p>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.02407" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.02408" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.02408">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.02408" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.02409" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 18:53:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
