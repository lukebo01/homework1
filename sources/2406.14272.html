<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.14272] MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset</title><meta property="og:description" content="Recent studies in speech-driven 3D talking head generation have achieved convincing results in verbal articulations. However, generating accurate lip-syncs degrades when applied to input speech in other languages, poss…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.14272">

<!--Generated on Sat Jul  6 00:44:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.2" class="ltx_ERROR undefined">\name</span>
<p id="p1.3" class="ltx_p">[affiliation=1*]KimSung-Bin
<span id="p1.3.1" class="ltx_ERROR undefined">\name</span>[affiliation=2*]LeeChae-Yeon
<span id="p1.3.2" class="ltx_ERROR undefined">\name</span>[affiliation=1*]GihunSon
<span id="p1.3.3" class="ltx_ERROR undefined">\name</span>[affiliation=1]OhHyun-Binnewline
<span id="p1.3.4" class="ltx_ERROR undefined">\name</span>[affiliation=3]JanghoonJu
<span id="p1.3.5" class="ltx_ERROR undefined">\name</span>[affiliation=3]SuekyeongNam
<span id="p1.3.6" class="ltx_ERROR undefined">\name</span>[affiliation=1,2,4]Tae-HyunOh






































































 
 
 
 
 





























































































































































































































































</p>
</div>
<h1 class="ltx_title ltx_title_document">MultiTalk: Enhancing 3D Talking Head Generation 
<br class="ltx_break">Across Languages with Multilingual Video Dataset</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Recent studies in speech-driven 3D talking head generation have achieved convincing results in verbal articulations. However, generating accurate lip-syncs degrades when applied to input speech in other languages, possibly due to the lack of datasets covering a broad spectrum of facial movements across languages. In this work, we introduce a novel task to generate 3D talking heads from speeches of diverse languages. We collect a new multilingual 2D video dataset comprising over 420 hours of talking videos in 20 languages. With our proposed dataset, we present a multilingually enhanced model that incorporates language-specific style embeddings, enabling it to capture the unique mouth movements associated with each language. Additionally, we present a metric for assessing lip-sync accuracy in multilingual settings. We demonstrate that training a 3D talking head model with our proposed dataset significantly enhances its multilingual performance. Codes and datasets are available at <a target="_blank" href="https://multi-talk.github.io/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://multi-talk.github.io/</a>.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Speech-driven 3D talking head, Video dataset, Multilingual, Audio-visual speech recognition
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>These authors contributed equally.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Speech-driven 3D talking heads are key components in virtual avatars, enhancing realism and improving user engagement in diverse multimedia applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Recent advancements in deep learning have significantly advanced the field of 3D talking heads.
Earlier efforts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> have focused on enhancing lip synchronization, while more recent studies aim to enable the expression of various emotions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and non-verbal signals <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, or even to develop personalized models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">However, the multilingual capabilities of 3D talking heads have received less attention and remain underexplored.
Despite claims from previous studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> that their models are language-agnostic, we observe that Huang <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> cover only two languages, and the quality of the generated meshes
from prior works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>
degrades when input speech deviates from the English language family.
We hypothesize that this limitation stems from the scarcity of diverse 3D talking head datasets.
Existing datasets, such as VOCASET <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and BIWI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, are not only small in scale but also limited in expressiveness, diversity, and language scope (English-only).
Even a more sophisticated model, designed to handle diverse languages, may be constrained by the styles and motion characteristics of available datasets.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.14272/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="208" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S1.F1.2.1" class="ltx_text ltx_font_bold">Samples of our MultiTalk dataset.</span> Each 2D video is annotated with the language type and the pseudo transcript, and a subset of the videos further provides pseudo 3D mesh vertices.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To tackle this challenge, we introduce a novel task of generating 3D talking heads from speeches in diverse languages, <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">i.e</em>., multilingual 3D talking heads.
For this task, we collect the <span id="S1.p3.1.2" class="ltx_text ltx_font_bold">MultiTalk dataset</span>, comprising in-the-wild 2D talking videos across 20 different languages, paired with corresponding pseudo 3D meshes and transcripts (see Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
We design an automated data collection pipeline to parse short utterances of frontal talking videos in diverse languages from YouTube.
As these 2D videos lack 3D metadata, we leverage an off-the-shelf 3D reconstruction model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> to generate reliable and robust pseudo ground-truth 3D mesh vertices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> for the collected 2D videos.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To demonstrate the effectiveness of our dataset for multilingual 3D talking heads, we introduce a strong baseline model, <span id="S1.p4.1.1" class="ltx_text ltx_font_bold">MultiTalk</span>, by training on a subset of our dataset.
Inspired by previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, we start by training a vector-quantized autoencoder (VQ-VAE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to learn a discrete codebook, which encodes expressive 3D facial motions across various languages.
By utilizing this discrete codebook, we then train a temporal autoregressive model to synthesize sequences of 3D faces, conditioned on both the input speech and the learnable language embedding. This language embedding captures the stylistic nuances of facial motions specific to each language family.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We validate our baseline model against existing 3D talking head models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> trained on the English-only VOCASET dataset.
As this task is novel, we propose a new evaluation metric, Audio-Visual Lip Readability (AVLR), which assesses the lip-sync accuracy of 3D talking heads on multilingual speeches using a pre-trained Audio-Visual Speech Recognition (AVSR) model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
Through the experiments, we show that our model performs favorably across diverse languages compared to previous works.
Our main contributions are summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Proposing a new task, multilingual 3D talking head, accompanied by an evaluation metric to measure the lip synchronization accuracy on multilingual speech.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Collecting the MultiTalk dataset, featuring over 420 hours of 2D videos with paired 3D metadata in 20 different languages.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Introducing a strong baseline, MultiTalk, capable of generating accurate and expressive 3D faces from multilingual speech.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Learning multilingual 3D talking head</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we introduce our new multilingual video dataset in Sec. <a href="#S2.SS1" title="2.1 MultiTalk dataset ‣ 2 Learning multilingual 3D talking head ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a> and describe the proposed baseline model for multilingual 3D talking head generation in Sec. <a href="#S2.SS2" title="2.2 Speech-driven multilingual 3D talking head ‣ 2 Learning multilingual 3D talking head ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.</p>
</div>
<figure id="S2.T1" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S2.T1.3.1" class="ltx_text ltx_font_bold">Statistics of our MultiTalk dataset.</span> We present a 2D talking video dataset that is well-balanced across 20 languages (each accounting for 2.0-9.7%), accompanied by pseudo 3D mesh vertices and transcripts for each video.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S2.T1.1" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:114.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-115.0pt,60.7pt) scale(0.485205839738098,0.485205839738098) ;">
<table id="S2.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2406.14272/assets/x2.png" id="S2.T1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="246" alt="[Uncaptioned image]"></td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S2.T1.4" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:199.5pt;height:144.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(37.5pt,-27.1pt) scale(1.60172089834692,1.60172089834692) ;">
<table id="S2.T1.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.4.1.1.1" class="ltx_tr">
<th id="S2.T1.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2"><span id="S2.T1.4.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Statistics of our MultiTalk dataset</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.4.1.2.1" class="ltx_tr">
<th id="S2.T1.4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S2.T1.4.1.2.1.1.1" class="ltx_text" style="font-size:80%;">Num. of languages</span></th>
<td id="S2.T1.4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.4.1.2.1.2.1" class="ltx_text" style="font-size:80%;">20</span></td>
</tr>
<tr id="S2.T1.4.1.3.2" class="ltx_tr">
<th id="S2.T1.4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S2.T1.4.1.3.2.1.1" class="ltx_text" style="font-size:80%;">Num. of video clips</span></th>
<td id="S2.T1.4.1.3.2.2" class="ltx_td ltx_align_left"><span id="S2.T1.4.1.3.2.2.1" class="ltx_text" style="font-size:80%;">294k</span></td>
</tr>
<tr id="S2.T1.4.1.4.3" class="ltx_tr">
<th id="S2.T1.4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S2.T1.4.1.4.3.1.1" class="ltx_text" style="font-size:80%;">Total hours</span></th>
<td id="S2.T1.4.1.4.3.2" class="ltx_td ltx_align_left"><span id="S2.T1.4.1.4.3.2.1" class="ltx_text" style="font-size:80%;">423.2 h</span></td>
</tr>
<tr id="S2.T1.4.1.5.4" class="ltx_tr">
<th id="S2.T1.4.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S2.T1.4.1.5.4.1.1" class="ltx_text" style="font-size:80%;">Avg. duration</span></th>
<td id="S2.T1.4.1.5.4.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T1.4.1.5.4.2.1" class="ltx_text" style="font-size:80%;">5.2 sec.</span></td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>MultiTalk dataset</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We introduce the MultiTalk dataset, featuring over 420 hours of multilingual 2D talking videos across 20 languages.
Despite the abundance of 2D video datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, we aim to curate a dataset with more balanced statistics across a broader range of languages.
Each video in the MultiTalk dataset is annotated with the language type of a speech and a pseudo-transcript generated using Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, and a subset among the videos is annotated with pseudo 3D mesh vertices.
Samples and statistics of the MultiTalk dataset are shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Table <a href="#S2.T1" title="Table 1 ‣ 2 Learning multilingual 3D talking head ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, respectively.
We design an automated pipeline to obtain short utterances of talking videos in diverse languages, described as follows.</p>
</div>
<section id="S2.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Collecting 2D videos</h4>

<div id="S2.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px1.p1.1" class="ltx_p">We begin by designing various queries that incorporate keywords, such as ``nationality,'' ``interviews,'' and ``conversation.''
These queries are prompted to YouTube to retrieve in-the-wild human talking 2D videos in different languages and diverse scenarios.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Active speaker verification</h4>

<div id="S2.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px2.p1.1" class="ltx_p">The goal here is to trim a raw video into segments that only contain talking faces synchronized to speech, while removing clips with non-active speakers.
To achieve this, we leverage TalkNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, which performs audio-visual cross-attention to identify the visible person in speaking.
We set conservative thresholds to minimize false positives and ensure that only the cleaned video is left.
We further trim the video when gaps occur during speaking, resulting in short utterances.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Frontal face verification</h4>

<div id="S2.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px3.p1.1" class="ltx_p">The faces in the filtered videos do not always face the front, which can prevent the model from learning clear facial movements.
Thus, we measure the angle of yaw and pitch of the face using Mediapipe <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and filter out videos with abrupt angle changes (indicating abrupt head movements) or large yaw or pitch angles (side faces).
This process concludes the automated pipeline for collecting cleaned 2D frontal talking face videos with short utterances in diverse languages. We further leverage Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Referring to <a target="_blank" href="https://github.com/openai/whisper" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/openai/whisper</a>, Whisper’s performance on our target language yields a word error rate (WER) of 2.8% to 17.0%, which is quite accurate.</span></span></span> trained on each language, to annotate the pseudo-transcript for each video clip.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Lifting 2D video to 3D</h4>

<div id="S2.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S2.SS1.SSS0.Px4.p1.1" class="ltx_p">From the subset of collected 2D talking videos, we reconstruct 3D meshes that are synchronized with both the audio and facial movements of the video clips.
Similar to prior arts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> that demonstrate the effectiveness of pseudo-3D reconstructions for training 3D talking heads, we leverage SPECTRE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> to reconstruct accurate and robust pseudo 3D meshes from 2D talking videos.
Unlike existing datasets, <em id="S2.SS1.SSS0.Px4.p1.1.1" class="ltx_emph ltx_font_italic">e.g</em>., VOCASET <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, which are limited in small scale and English-only speeches, our newly annotated 3D mesh dataset encompasses expressive facial motions, paired with speeches that vary in diverse tones and pitches across a wide range of languages.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2406.14272/assets/x3.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="236" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S2.F2.2.1" class="ltx_text ltx_font_bold">Overall pipeline of MultiTalk.</span> In stage 1, a codebook of discrete motions is learned from 3D facial meshes speaking in diverse languages. In stage 2, the model learns to autoregressively generate a sequence of motion representations
from an input speech. These representations
are quantized by the codebook, thereby synthesizing speech-driven 3D talking head.
</figcaption>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Speech-driven multilingual 3D talking head</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Using the subset of the dataset we collected, as detailed in Sec. <a href="#S2.SS1" title="2.1 MultiTalk dataset ‣ 2 Learning multilingual 3D talking head ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, we aim to develop a model capable of generating accurate 3D talking head synchronized with input speech in various languages.
Despite the increased diversity of the dataset, naïvely dumping all data into the model could result in learning only average facial movements.
To address this, we break down the task into sub-problems and introduce a baseline model, MultiTalk.
MultiTalk undergoes a two-stage training process: first, learning a general facial motion prior through discrete codes, then training a speech-driven temporal autoregressive model to animate 3D faces with the learned discrete codes.
Echoing the success of previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, the disentanglement of the learning process allows the model to effectively construct rich discrete motion prior from the diverse talking faces of various languages, which is then leveraged in the second stage for synthesis.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.7" class="ltx_p">The task formulation is specified as follows: Let <math id="S2.SS2.p2.1.m1.3" class="ltx_Math" alttext="\mathbf{V}_{1:T}=(\mathbf{v}_{1},\dots,\mathbf{v}_{T})" display="inline"><semantics id="S2.SS2.p2.1.m1.3a"><mrow id="S2.SS2.p2.1.m1.3.3" xref="S2.SS2.p2.1.m1.3.3.cmml"><msub id="S2.SS2.p2.1.m1.3.3.4" xref="S2.SS2.p2.1.m1.3.3.4.cmml"><mi id="S2.SS2.p2.1.m1.3.3.4.2" xref="S2.SS2.p2.1.m1.3.3.4.2.cmml">𝐕</mi><mrow id="S2.SS2.p2.1.m1.3.3.4.3" xref="S2.SS2.p2.1.m1.3.3.4.3.cmml"><mn id="S2.SS2.p2.1.m1.3.3.4.3.2" xref="S2.SS2.p2.1.m1.3.3.4.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.p2.1.m1.3.3.4.3.1" xref="S2.SS2.p2.1.m1.3.3.4.3.1.cmml">:</mo><mi id="S2.SS2.p2.1.m1.3.3.4.3.3" xref="S2.SS2.p2.1.m1.3.3.4.3.3.cmml">T</mi></mrow></msub><mo id="S2.SS2.p2.1.m1.3.3.3" xref="S2.SS2.p2.1.m1.3.3.3.cmml">=</mo><mrow id="S2.SS2.p2.1.m1.3.3.2.2" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S2.SS2.p2.1.m1.3.3.2.2.3" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml">(</mo><msub id="S2.SS2.p2.1.m1.2.2.1.1.1" xref="S2.SS2.p2.1.m1.2.2.1.1.1.cmml"><mi id="S2.SS2.p2.1.m1.2.2.1.1.1.2" xref="S2.SS2.p2.1.m1.2.2.1.1.1.2.cmml">𝐯</mi><mn id="S2.SS2.p2.1.m1.2.2.1.1.1.3" xref="S2.SS2.p2.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.p2.1.m1.3.3.2.2.4" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">…</mi><mo id="S2.SS2.p2.1.m1.3.3.2.2.5" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml">,</mo><msub id="S2.SS2.p2.1.m1.3.3.2.2.2" xref="S2.SS2.p2.1.m1.3.3.2.2.2.cmml"><mi id="S2.SS2.p2.1.m1.3.3.2.2.2.2" xref="S2.SS2.p2.1.m1.3.3.2.2.2.2.cmml">𝐯</mi><mi id="S2.SS2.p2.1.m1.3.3.2.2.2.3" xref="S2.SS2.p2.1.m1.3.3.2.2.2.3.cmml">T</mi></msub><mo stretchy="false" id="S2.SS2.p2.1.m1.3.3.2.2.6" xref="S2.SS2.p2.1.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.3b"><apply id="S2.SS2.p2.1.m1.3.3.cmml" xref="S2.SS2.p2.1.m1.3.3"><eq id="S2.SS2.p2.1.m1.3.3.3.cmml" xref="S2.SS2.p2.1.m1.3.3.3"></eq><apply id="S2.SS2.p2.1.m1.3.3.4.cmml" xref="S2.SS2.p2.1.m1.3.3.4"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.3.3.4.1.cmml" xref="S2.SS2.p2.1.m1.3.3.4">subscript</csymbol><ci id="S2.SS2.p2.1.m1.3.3.4.2.cmml" xref="S2.SS2.p2.1.m1.3.3.4.2">𝐕</ci><apply id="S2.SS2.p2.1.m1.3.3.4.3.cmml" xref="S2.SS2.p2.1.m1.3.3.4.3"><ci id="S2.SS2.p2.1.m1.3.3.4.3.1.cmml" xref="S2.SS2.p2.1.m1.3.3.4.3.1">:</ci><cn type="integer" id="S2.SS2.p2.1.m1.3.3.4.3.2.cmml" xref="S2.SS2.p2.1.m1.3.3.4.3.2">1</cn><ci id="S2.SS2.p2.1.m1.3.3.4.3.3.cmml" xref="S2.SS2.p2.1.m1.3.3.4.3.3">𝑇</ci></apply></apply><vector id="S2.SS2.p2.1.m1.3.3.2.3.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2"><apply id="S2.SS2.p2.1.m1.2.2.1.1.1.cmml" xref="S2.SS2.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.2.2.1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.p2.1.m1.2.2.1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.2.2.1.1.1.2">𝐯</ci><cn type="integer" id="S2.SS2.p2.1.m1.2.2.1.1.1.3.cmml" xref="S2.SS2.p2.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">…</ci><apply id="S2.SS2.p2.1.m1.3.3.2.2.2.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.1.m1.3.3.2.2.2.1.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.p2.1.m1.3.3.2.2.2.2.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2.2.2">𝐯</ci><ci id="S2.SS2.p2.1.m1.3.3.2.2.2.3.cmml" xref="S2.SS2.p2.1.m1.3.3.2.2.2.3">𝑇</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.3c">\mathbf{V}_{1:T}=(\mathbf{v}_{1},\dots,\mathbf{v}_{T})</annotation></semantics></math> denote a temporal sequence of ground-truth facial motions, where each frame <math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{v}_{t}\in\mathbb{R}^{N\times 3}" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mrow id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml"><msub id="S2.SS2.p2.2.m2.1.1.2" xref="S2.SS2.p2.2.m2.1.1.2.cmml"><mi id="S2.SS2.p2.2.m2.1.1.2.2" xref="S2.SS2.p2.2.m2.1.1.2.2.cmml">𝐯</mi><mi id="S2.SS2.p2.2.m2.1.1.2.3" xref="S2.SS2.p2.2.m2.1.1.2.3.cmml">t</mi></msub><mo id="S2.SS2.p2.2.m2.1.1.1" xref="S2.SS2.p2.2.m2.1.1.1.cmml">∈</mo><msup id="S2.SS2.p2.2.m2.1.1.3" xref="S2.SS2.p2.2.m2.1.1.3.cmml"><mi id="S2.SS2.p2.2.m2.1.1.3.2" xref="S2.SS2.p2.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS2.p2.2.m2.1.1.3.3" xref="S2.SS2.p2.2.m2.1.1.3.3.cmml"><mi id="S2.SS2.p2.2.m2.1.1.3.3.2" xref="S2.SS2.p2.2.m2.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS2.p2.2.m2.1.1.3.3.1" xref="S2.SS2.p2.2.m2.1.1.3.3.1.cmml">×</mo><mn id="S2.SS2.p2.2.m2.1.1.3.3.3" xref="S2.SS2.p2.2.m2.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><apply id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1"><in id="S2.SS2.p2.2.m2.1.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1.1"></in><apply id="S2.SS2.p2.2.m2.1.1.2.cmml" xref="S2.SS2.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p2.2.m2.1.1.2.1.cmml" xref="S2.SS2.p2.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS2.p2.2.m2.1.1.2.2.cmml" xref="S2.SS2.p2.2.m2.1.1.2.2">𝐯</ci><ci id="S2.SS2.p2.2.m2.1.1.2.3.cmml" xref="S2.SS2.p2.2.m2.1.1.2.3">𝑡</ci></apply><apply id="S2.SS2.p2.2.m2.1.1.3.cmml" xref="S2.SS2.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p2.2.m2.1.1.3.1.cmml" xref="S2.SS2.p2.2.m2.1.1.3">superscript</csymbol><ci id="S2.SS2.p2.2.m2.1.1.3.2.cmml" xref="S2.SS2.p2.2.m2.1.1.3.2">ℝ</ci><apply id="S2.SS2.p2.2.m2.1.1.3.3.cmml" xref="S2.SS2.p2.2.m2.1.1.3.3"><times id="S2.SS2.p2.2.m2.1.1.3.3.1.cmml" xref="S2.SS2.p2.2.m2.1.1.3.3.1"></times><ci id="S2.SS2.p2.2.m2.1.1.3.3.2.cmml" xref="S2.SS2.p2.2.m2.1.1.3.3.2">𝑁</ci><cn type="integer" id="S2.SS2.p2.2.m2.1.1.3.3.3.cmml" xref="S2.SS2.p2.2.m2.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">\mathbf{v}_{t}\in\mathbb{R}^{N\times 3}</annotation></semantics></math> consisting <math id="S2.SS2.p2.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS2.p2.3.m3.1a"><mi id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><ci id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">N</annotation></semantics></math> vertices, represents the 3D facial movement.
Additionally, let <math id="S2.SS2.p2.4.m4.3" class="ltx_Math" alttext="\mathbf{S}_{1:T}=(\mathbf{s}_{1},\dots,\mathbf{s}_{T})" display="inline"><semantics id="S2.SS2.p2.4.m4.3a"><mrow id="S2.SS2.p2.4.m4.3.3" xref="S2.SS2.p2.4.m4.3.3.cmml"><msub id="S2.SS2.p2.4.m4.3.3.4" xref="S2.SS2.p2.4.m4.3.3.4.cmml"><mi id="S2.SS2.p2.4.m4.3.3.4.2" xref="S2.SS2.p2.4.m4.3.3.4.2.cmml">𝐒</mi><mrow id="S2.SS2.p2.4.m4.3.3.4.3" xref="S2.SS2.p2.4.m4.3.3.4.3.cmml"><mn id="S2.SS2.p2.4.m4.3.3.4.3.2" xref="S2.SS2.p2.4.m4.3.3.4.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.p2.4.m4.3.3.4.3.1" xref="S2.SS2.p2.4.m4.3.3.4.3.1.cmml">:</mo><mi id="S2.SS2.p2.4.m4.3.3.4.3.3" xref="S2.SS2.p2.4.m4.3.3.4.3.3.cmml">T</mi></mrow></msub><mo id="S2.SS2.p2.4.m4.3.3.3" xref="S2.SS2.p2.4.m4.3.3.3.cmml">=</mo><mrow id="S2.SS2.p2.4.m4.3.3.2.2" xref="S2.SS2.p2.4.m4.3.3.2.3.cmml"><mo stretchy="false" id="S2.SS2.p2.4.m4.3.3.2.2.3" xref="S2.SS2.p2.4.m4.3.3.2.3.cmml">(</mo><msub id="S2.SS2.p2.4.m4.2.2.1.1.1" xref="S2.SS2.p2.4.m4.2.2.1.1.1.cmml"><mi id="S2.SS2.p2.4.m4.2.2.1.1.1.2" xref="S2.SS2.p2.4.m4.2.2.1.1.1.2.cmml">𝐬</mi><mn id="S2.SS2.p2.4.m4.2.2.1.1.1.3" xref="S2.SS2.p2.4.m4.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.p2.4.m4.3.3.2.2.4" xref="S2.SS2.p2.4.m4.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml">…</mi><mo id="S2.SS2.p2.4.m4.3.3.2.2.5" xref="S2.SS2.p2.4.m4.3.3.2.3.cmml">,</mo><msub id="S2.SS2.p2.4.m4.3.3.2.2.2" xref="S2.SS2.p2.4.m4.3.3.2.2.2.cmml"><mi id="S2.SS2.p2.4.m4.3.3.2.2.2.2" xref="S2.SS2.p2.4.m4.3.3.2.2.2.2.cmml">𝐬</mi><mi id="S2.SS2.p2.4.m4.3.3.2.2.2.3" xref="S2.SS2.p2.4.m4.3.3.2.2.2.3.cmml">T</mi></msub><mo stretchy="false" id="S2.SS2.p2.4.m4.3.3.2.2.6" xref="S2.SS2.p2.4.m4.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.3b"><apply id="S2.SS2.p2.4.m4.3.3.cmml" xref="S2.SS2.p2.4.m4.3.3"><eq id="S2.SS2.p2.4.m4.3.3.3.cmml" xref="S2.SS2.p2.4.m4.3.3.3"></eq><apply id="S2.SS2.p2.4.m4.3.3.4.cmml" xref="S2.SS2.p2.4.m4.3.3.4"><csymbol cd="ambiguous" id="S2.SS2.p2.4.m4.3.3.4.1.cmml" xref="S2.SS2.p2.4.m4.3.3.4">subscript</csymbol><ci id="S2.SS2.p2.4.m4.3.3.4.2.cmml" xref="S2.SS2.p2.4.m4.3.3.4.2">𝐒</ci><apply id="S2.SS2.p2.4.m4.3.3.4.3.cmml" xref="S2.SS2.p2.4.m4.3.3.4.3"><ci id="S2.SS2.p2.4.m4.3.3.4.3.1.cmml" xref="S2.SS2.p2.4.m4.3.3.4.3.1">:</ci><cn type="integer" id="S2.SS2.p2.4.m4.3.3.4.3.2.cmml" xref="S2.SS2.p2.4.m4.3.3.4.3.2">1</cn><ci id="S2.SS2.p2.4.m4.3.3.4.3.3.cmml" xref="S2.SS2.p2.4.m4.3.3.4.3.3">𝑇</ci></apply></apply><vector id="S2.SS2.p2.4.m4.3.3.2.3.cmml" xref="S2.SS2.p2.4.m4.3.3.2.2"><apply id="S2.SS2.p2.4.m4.2.2.1.1.1.cmml" xref="S2.SS2.p2.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.4.m4.2.2.1.1.1.1.cmml" xref="S2.SS2.p2.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.p2.4.m4.2.2.1.1.1.2.cmml" xref="S2.SS2.p2.4.m4.2.2.1.1.1.2">𝐬</ci><cn type="integer" id="S2.SS2.p2.4.m4.2.2.1.1.1.3.cmml" xref="S2.SS2.p2.4.m4.2.2.1.1.1.3">1</cn></apply><ci id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1">…</ci><apply id="S2.SS2.p2.4.m4.3.3.2.2.2.cmml" xref="S2.SS2.p2.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.4.m4.3.3.2.2.2.1.cmml" xref="S2.SS2.p2.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.p2.4.m4.3.3.2.2.2.2.cmml" xref="S2.SS2.p2.4.m4.3.3.2.2.2.2">𝐬</ci><ci id="S2.SS2.p2.4.m4.3.3.2.2.2.3.cmml" xref="S2.SS2.p2.4.m4.3.3.2.2.2.3">𝑇</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.3c">\mathbf{S}_{1:T}=(\mathbf{s}_{1},\dots,\mathbf{s}_{T})</annotation></semantics></math> be a sequence of speech representations.
By conditioning on input speech <math id="S2.SS2.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{S}_{1:T}" display="inline"><semantics id="S2.SS2.p2.5.m5.1a"><msub id="S2.SS2.p2.5.m5.1.1" xref="S2.SS2.p2.5.m5.1.1.cmml"><mi id="S2.SS2.p2.5.m5.1.1.2" xref="S2.SS2.p2.5.m5.1.1.2.cmml">𝐒</mi><mrow id="S2.SS2.p2.5.m5.1.1.3" xref="S2.SS2.p2.5.m5.1.1.3.cmml"><mn id="S2.SS2.p2.5.m5.1.1.3.2" xref="S2.SS2.p2.5.m5.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.p2.5.m5.1.1.3.1" xref="S2.SS2.p2.5.m5.1.1.3.1.cmml">:</mo><mi id="S2.SS2.p2.5.m5.1.1.3.3" xref="S2.SS2.p2.5.m5.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.5.m5.1b"><apply id="S2.SS2.p2.5.m5.1.1.cmml" xref="S2.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.5.m5.1.1.1.cmml" xref="S2.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.p2.5.m5.1.1.2.cmml" xref="S2.SS2.p2.5.m5.1.1.2">𝐒</ci><apply id="S2.SS2.p2.5.m5.1.1.3.cmml" xref="S2.SS2.p2.5.m5.1.1.3"><ci id="S2.SS2.p2.5.m5.1.1.3.1.cmml" xref="S2.SS2.p2.5.m5.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.p2.5.m5.1.1.3.2.cmml" xref="S2.SS2.p2.5.m5.1.1.3.2">1</cn><ci id="S2.SS2.p2.5.m5.1.1.3.3.cmml" xref="S2.SS2.p2.5.m5.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.5.m5.1c">\mathbf{S}_{1:T}</annotation></semantics></math>, the goal in this task is to sequentially predict facial movements <math id="S2.SS2.p2.6.m6.1" class="ltx_Math" alttext="\mathbf{\hat{V}}_{1:T}" display="inline"><semantics id="S2.SS2.p2.6.m6.1a"><msub id="S2.SS2.p2.6.m6.1.1" xref="S2.SS2.p2.6.m6.1.1.cmml"><mover accent="true" id="S2.SS2.p2.6.m6.1.1.2" xref="S2.SS2.p2.6.m6.1.1.2.cmml"><mi id="S2.SS2.p2.6.m6.1.1.2.2" xref="S2.SS2.p2.6.m6.1.1.2.2.cmml">𝐕</mi><mo id="S2.SS2.p2.6.m6.1.1.2.1" xref="S2.SS2.p2.6.m6.1.1.2.1.cmml">^</mo></mover><mrow id="S2.SS2.p2.6.m6.1.1.3" xref="S2.SS2.p2.6.m6.1.1.3.cmml"><mn id="S2.SS2.p2.6.m6.1.1.3.2" xref="S2.SS2.p2.6.m6.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.p2.6.m6.1.1.3.1" xref="S2.SS2.p2.6.m6.1.1.3.1.cmml">:</mo><mi id="S2.SS2.p2.6.m6.1.1.3.3" xref="S2.SS2.p2.6.m6.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.6.m6.1b"><apply id="S2.SS2.p2.6.m6.1.1.cmml" xref="S2.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.6.m6.1.1.1.cmml" xref="S2.SS2.p2.6.m6.1.1">subscript</csymbol><apply id="S2.SS2.p2.6.m6.1.1.2.cmml" xref="S2.SS2.p2.6.m6.1.1.2"><ci id="S2.SS2.p2.6.m6.1.1.2.1.cmml" xref="S2.SS2.p2.6.m6.1.1.2.1">^</ci><ci id="S2.SS2.p2.6.m6.1.1.2.2.cmml" xref="S2.SS2.p2.6.m6.1.1.2.2">𝐕</ci></apply><apply id="S2.SS2.p2.6.m6.1.1.3.cmml" xref="S2.SS2.p2.6.m6.1.1.3"><ci id="S2.SS2.p2.6.m6.1.1.3.1.cmml" xref="S2.SS2.p2.6.m6.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.p2.6.m6.1.1.3.2.cmml" xref="S2.SS2.p2.6.m6.1.1.3.2">1</cn><ci id="S2.SS2.p2.6.m6.1.1.3.3.cmml" xref="S2.SS2.p2.6.m6.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.6.m6.1c">\mathbf{\hat{V}}_{1:T}</annotation></semantics></math>, similar to <math id="S2.SS2.p2.7.m7.1" class="ltx_Math" alttext="\mathbf{V}_{1:T}" display="inline"><semantics id="S2.SS2.p2.7.m7.1a"><msub id="S2.SS2.p2.7.m7.1.1" xref="S2.SS2.p2.7.m7.1.1.cmml"><mi id="S2.SS2.p2.7.m7.1.1.2" xref="S2.SS2.p2.7.m7.1.1.2.cmml">𝐕</mi><mrow id="S2.SS2.p2.7.m7.1.1.3" xref="S2.SS2.p2.7.m7.1.1.3.cmml"><mn id="S2.SS2.p2.7.m7.1.1.3.2" xref="S2.SS2.p2.7.m7.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.p2.7.m7.1.1.3.1" xref="S2.SS2.p2.7.m7.1.1.3.1.cmml">:</mo><mi id="S2.SS2.p2.7.m7.1.1.3.3" xref="S2.SS2.p2.7.m7.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.7.m7.1b"><apply id="S2.SS2.p2.7.m7.1.1.cmml" xref="S2.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.7.m7.1.1.1.cmml" xref="S2.SS2.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS2.p2.7.m7.1.1.2.cmml" xref="S2.SS2.p2.7.m7.1.1.2">𝐕</ci><apply id="S2.SS2.p2.7.m7.1.1.3.cmml" xref="S2.SS2.p2.7.m7.1.1.3"><ci id="S2.SS2.p2.7.m7.1.1.3.1.cmml" xref="S2.SS2.p2.7.m7.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.p2.7.m7.1.1.3.2.cmml" xref="S2.SS2.p2.7.m7.1.1.3.2">1</cn><ci id="S2.SS2.p2.7.m7.1.1.3.3.cmml" xref="S2.SS2.p2.7.m7.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.7.m7.1c">\mathbf{V}_{1:T}</annotation></semantics></math>.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Learning discrete facial motion</h4>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.1" class="ltx_p">Following CodeTalker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, we extend the use of vector quantized autoencoder (VQ-VAE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to learn a discrete codebook of context-rich facial motions
(refer to Stage 1 in Fig. <a href="#S2.F2" title="Figure 2 ‣ Lifting 2D video to 3D ‣ 2.1 MultiTalk dataset ‣ 2 Learning multilingual 3D talking head ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
As speech data is not required for training VQ-VAE, we utilize a large amount of 3D motion sequences from the MultiTalk dataset for learning the prior.
This enables the learned prior to cover a broad spectrum of facial motions observed in speakers of diverse languages.</p>
</div>
<div id="S2.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p2.12" class="ltx_p">VQ-VAE consists of an encoder (<math id="S2.SS2.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="E_{v}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.1.m1.1a"><msub id="S2.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.2" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml">E</mi><mi id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.1.m1.1b"><apply id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.2">𝐸</ci><ci id="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.1.m1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.1.m1.1c">E_{v}</annotation></semantics></math>), a decoder (<math id="S2.SS2.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="D_{v}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.2.m2.1a"><msub id="S2.SS2.SSS0.Px1.p2.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.2.m2.1.1.2" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1.2.cmml">D</mi><mi id="S2.SS2.SSS0.Px1.p2.2.m2.1.1.3" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.2.m2.1b"><apply id="S2.SS2.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1.2">𝐷</ci><ci id="S2.SS2.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.2.m2.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.2.m2.1c">D_{v}</annotation></semantics></math>), and a discrete codebook <math id="S2.SS2.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{Z}=\{\mathbf{z}_{k}\}_{k=1}^{K}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.3.m3.1a"><mrow id="S2.SS2.SSS0.Px1.p2.3.m3.1.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.3.cmml">𝒵</mi><mo id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.2.cmml">=</mo><msubsup id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.cmml"><mrow id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.2.cmml">{</mo><msub id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.2.cmml">𝐳</mi><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.2.cmml">k</mi><mo id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.1" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.1.cmml">=</mo><mn id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.3" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.3.cmml">K</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.3.m3.1b"><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1"><eq id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.2"></eq><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.3">𝒵</ci><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1">superscript</csymbol><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1">subscript</csymbol><set id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1"><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.2">𝐳</ci><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.1.1.1.3">𝑘</ci></apply></set><apply id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3"><eq id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.1"></eq><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.2">𝑘</ci><cn type="integer" id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.3.m3.1.1.1.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.3.m3.1c">\mathcal{Z}=\{\mathbf{z}_{k}\}_{k=1}^{K}</annotation></semantics></math>, where <math id="S2.SS2.SSS0.Px1.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{z}_{k}\in\mathbb{R}^{d_{z}}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.4.m4.1a"><mrow id="S2.SS2.SSS0.Px1.p2.4.m4.1.1" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.cmml"><msub id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.2" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.2.cmml">𝐳</mi><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.3" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.3.cmml">k</mi></msub><mo id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.1" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.2" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.2.cmml">ℝ</mi><msub id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.2" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.2.cmml">d</mi><mi id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.3" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.3.cmml">z</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.4.m4.1b"><apply id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1"><in id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.1"></in><apply id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.2">𝐳</ci><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.2.3">𝑘</ci></apply><apply id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.2">ℝ</ci><apply id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.2">𝑑</ci><ci id="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.3">𝑧</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.4.m4.1c">\mathbf{z}_{k}\in\mathbb{R}^{d_{z}}</annotation></semantics></math>, and is trained to self-reconstruct realistic facial motions.
Specifically, given facial motion sequences in continuous domain <math id="S2.SS2.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{V}_{1:T}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.5.m5.1a"><msub id="S2.SS2.SSS0.Px1.p2.5.m5.1.1" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.2" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.2.cmml">𝐕</mi><mrow id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.2" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.1" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.1.cmml">:</mo><mi id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.3" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.5.m5.1b"><apply id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.2">𝐕</ci><apply id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3"><ci id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.2">1</cn><ci id="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.5.m5.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.5.m5.1c">\mathbf{V}_{1:T}</annotation></semantics></math>, the VQ-VAE encoder (<math id="S2.SS2.SSS0.Px1.p2.6.m6.1" class="ltx_Math" alttext="E_{v}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.6.m6.1a"><msub id="S2.SS2.SSS0.Px1.p2.6.m6.1.1" xref="S2.SS2.SSS0.Px1.p2.6.m6.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.6.m6.1.1.2" xref="S2.SS2.SSS0.Px1.p2.6.m6.1.1.2.cmml">E</mi><mi id="S2.SS2.SSS0.Px1.p2.6.m6.1.1.3" xref="S2.SS2.SSS0.Px1.p2.6.m6.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.6.m6.1b"><apply id="S2.SS2.SSS0.Px1.p2.6.m6.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.6.m6.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.6.m6.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.6.m6.1.1.2">𝐸</ci><ci id="S2.SS2.SSS0.Px1.p2.6.m6.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.6.m6.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.6.m6.1c">E_{v}</annotation></semantics></math>), which is designed with a Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> layer, first encodes the continuous motion sequences into latent features <math id="S2.SS2.SSS0.Px1.p2.7.m7.1" class="ltx_Math" alttext="\mathbf{\hat{Z}}\in\mathbb{R}^{T^{\prime}\times d_{z}}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.7.m7.1a"><mrow id="S2.SS2.SSS0.Px1.p2.7.m7.1.1" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.2" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.2.cmml">𝐙</mi><mo id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.1" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.1.cmml">^</mo></mover><mo id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.1" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.1.cmml">∈</mo><msup id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.2" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.cmml"><msup id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.cmml"><mi id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.2" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.2.cmml">T</mi><mo id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.3" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.3.cmml">′</mo></msup><mo lspace="0.222em" rspace="0.222em" id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.1" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.1.cmml">×</mo><msub id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.2" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.2.cmml">d</mi><mi id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.3" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.3.cmml">z</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.7.m7.1b"><apply id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1"><in id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.1"></in><apply id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2"><ci id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.1">^</ci><ci id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.2.2">𝐙</ci></apply><apply id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.2">ℝ</ci><apply id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3"><times id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.1"></times><apply id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.2">𝑇</ci><ci id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.3.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.2.3">′</ci></apply><apply id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.2">𝑑</ci><ci id="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.7.m7.1.1.3.3.3.3">𝑧</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.7.m7.1c">\mathbf{\hat{Z}}\in\mathbb{R}^{T^{\prime}\times d_{z}}</annotation></semantics></math>, where <math id="S2.SS2.SSS0.Px1.p2.8.m8.1" class="ltx_Math" alttext="T^{\prime}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.8.m8.1a"><msup id="S2.SS2.SSS0.Px1.p2.8.m8.1.1" xref="S2.SS2.SSS0.Px1.p2.8.m8.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.8.m8.1.1.2" xref="S2.SS2.SSS0.Px1.p2.8.m8.1.1.2.cmml">T</mi><mo id="S2.SS2.SSS0.Px1.p2.8.m8.1.1.3" xref="S2.SS2.SSS0.Px1.p2.8.m8.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.8.m8.1b"><apply id="S2.SS2.SSS0.Px1.p2.8.m8.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.8.m8.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.8.m8.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.8.m8.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.8.m8.1.1.2">𝑇</ci><ci id="S2.SS2.SSS0.Px1.p2.8.m8.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.8.m8.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.8.m8.1c">T^{\prime}</annotation></semantics></math> denotes the number of frames of downsampled features.
Subsequently, <math id="S2.SS2.SSS0.Px1.p2.9.m9.1" class="ltx_Math" alttext="\mathbf{\hat{Z}}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.9.m9.1a"><mover accent="true" id="S2.SS2.SSS0.Px1.p2.9.m9.1.1" xref="S2.SS2.SSS0.Px1.p2.9.m9.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.9.m9.1.1.2" xref="S2.SS2.SSS0.Px1.p2.9.m9.1.1.2.cmml">𝐙</mi><mo id="S2.SS2.SSS0.Px1.p2.9.m9.1.1.1" xref="S2.SS2.SSS0.Px1.p2.9.m9.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.9.m9.1b"><apply id="S2.SS2.SSS0.Px1.p2.9.m9.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m9.1.1"><ci id="S2.SS2.SSS0.Px1.p2.9.m9.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m9.1.1.1">^</ci><ci id="S2.SS2.SSS0.Px1.p2.9.m9.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.9.m9.1.1.2">𝐙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.9.m9.1c">\mathbf{\hat{Z}}</annotation></semantics></math> is quantized to <math id="S2.SS2.SSS0.Px1.p2.10.m10.1" class="ltx_Math" alttext="\mathbf{Z^{q}}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.10.m10.1a"><msup id="S2.SS2.SSS0.Px1.p2.10.m10.1.1" xref="S2.SS2.SSS0.Px1.p2.10.m10.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.10.m10.1.1.2" xref="S2.SS2.SSS0.Px1.p2.10.m10.1.1.2.cmml">𝐙</mi><mi id="S2.SS2.SSS0.Px1.p2.10.m10.1.1.3" xref="S2.SS2.SSS0.Px1.p2.10.m10.1.1.3.cmml">𝐪</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.10.m10.1b"><apply id="S2.SS2.SSS0.Px1.p2.10.m10.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.10.m10.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m10.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.10.m10.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m10.1.1.2">𝐙</ci><ci id="S2.SS2.SSS0.Px1.p2.10.m10.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.10.m10.1.1.3">𝐪</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.10.m10.1c">\mathbf{Z^{q}}</annotation></semantics></math> through an element-wise quantization function <math id="S2.SS2.SSS0.Px1.p2.11.m11.1" class="ltx_Math" alttext="Q_{v}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.11.m11.1a"><msub id="S2.SS2.SSS0.Px1.p2.11.m11.1.1" xref="S2.SS2.SSS0.Px1.p2.11.m11.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.11.m11.1.1.2" xref="S2.SS2.SSS0.Px1.p2.11.m11.1.1.2.cmml">Q</mi><mi id="S2.SS2.SSS0.Px1.p2.11.m11.1.1.3" xref="S2.SS2.SSS0.Px1.p2.11.m11.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.11.m11.1b"><apply id="S2.SS2.SSS0.Px1.p2.11.m11.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.11.m11.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.11.m11.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.11.m11.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.11.m11.1.1.2">𝑄</ci><ci id="S2.SS2.SSS0.Px1.p2.11.m11.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.11.m11.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.11.m11.1c">Q_{v}</annotation></semantics></math> that maps each element in <math id="S2.SS2.SSS0.Px1.p2.12.m12.1" class="ltx_Math" alttext="\mathbf{\hat{Z}}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.12.m12.1a"><mover accent="true" id="S2.SS2.SSS0.Px1.p2.12.m12.1.1" xref="S2.SS2.SSS0.Px1.p2.12.m12.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.12.m12.1.1.2" xref="S2.SS2.SSS0.Px1.p2.12.m12.1.1.2.cmml">𝐙</mi><mo id="S2.SS2.SSS0.Px1.p2.12.m12.1.1.1" xref="S2.SS2.SSS0.Px1.p2.12.m12.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.12.m12.1b"><apply id="S2.SS2.SSS0.Px1.p2.12.m12.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.12.m12.1.1"><ci id="S2.SS2.SSS0.Px1.p2.12.m12.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.12.m12.1.1.1">^</ci><ci id="S2.SS2.SSS0.Px1.p2.12.m12.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.12.m12.1.1.2">𝐙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.12.m12.1c">\mathbf{\hat{Z}}</annotation></semantics></math> to its nearest codebook entry:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_math_unparsed" alttext="\mathbf{Z^{q}}=Q_{v}(\mathbf{\hat{Z}})\coloneqq(\operatornamewithlimits{\arg\min}_{\mathbf{z}_{k}\in\mathcal{Z}}\lVert\mathbf{\hat{z}}_{t}-\mathbf{z}_{k}\rVert_{2})\in\mathbb{R}^{T^{\prime}\times d_{z}}." display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1b"><msup id="S2.E1.m1.1.2"><mi id="S2.E1.m1.1.2.2">𝐙</mi><mi id="S2.E1.m1.1.2.3">𝐪</mi></msup><mo id="S2.E1.m1.1.3">=</mo><msub id="S2.E1.m1.1.4"><mi id="S2.E1.m1.1.4.2">Q</mi><mi id="S2.E1.m1.1.4.3">v</mi></msub><mrow id="S2.E1.m1.1.5"><mo stretchy="false" id="S2.E1.m1.1.5.1">(</mo><mover accent="true" id="S2.E1.m1.1.1"><mi id="S2.E1.m1.1.1.2">𝐙</mi><mo id="S2.E1.m1.1.1.1">^</mo></mover><mo stretchy="false" id="S2.E1.m1.1.5.2">)</mo></mrow><mo id="S2.E1.m1.1.6">≔</mo><mrow id="S2.E1.m1.1.7"><mo stretchy="false" id="S2.E1.m1.1.7.1">(</mo><munder id="S2.E1.m1.1.7.2"><mrow id="S2.E1.m1.1.7.2.2"><mi id="S2.E1.m1.1.7.2.2.1">arg</mi><mo lspace="0.167em" id="S2.E1.m1.1.7.2.2a">⁡</mo><mi id="S2.E1.m1.1.7.2.2.2">min</mi></mrow><mrow id="S2.E1.m1.1.7.2.3"><msub id="S2.E1.m1.1.7.2.3.2"><mi id="S2.E1.m1.1.7.2.3.2.2">𝐳</mi><mi id="S2.E1.m1.1.7.2.3.2.3">k</mi></msub><mo id="S2.E1.m1.1.7.2.3.1">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.7.2.3.3">𝒵</mi></mrow></munder><msub id="S2.E1.m1.1.7.3"><mrow id="S2.E1.m1.1.7.3.2"><mo fence="true" lspace="0em" rspace="0em" id="S2.E1.m1.1.7.3.2.1">∥</mo><msub id="S2.E1.m1.1.7.3.2.2"><mover accent="true" id="S2.E1.m1.1.7.3.2.2.2"><mi id="S2.E1.m1.1.7.3.2.2.2.2">𝐳</mi><mo id="S2.E1.m1.1.7.3.2.2.2.1">^</mo></mover><mi id="S2.E1.m1.1.7.3.2.2.3">t</mi></msub><mo id="S2.E1.m1.1.7.3.2.3">−</mo><msub id="S2.E1.m1.1.7.3.2.4"><mi id="S2.E1.m1.1.7.3.2.4.2">𝐳</mi><mi id="S2.E1.m1.1.7.3.2.4.3">k</mi></msub><mo fence="true" lspace="0em" rspace="0em" id="S2.E1.m1.1.7.3.2.5">∥</mo></mrow><mn id="S2.E1.m1.1.7.3.3">2</mn></msub><mo stretchy="false" id="S2.E1.m1.1.7.4">)</mo></mrow><mo id="S2.E1.m1.1.8">∈</mo><msup id="S2.E1.m1.1.9"><mi id="S2.E1.m1.1.9.2">ℝ</mi><mrow id="S2.E1.m1.1.9.3"><msup id="S2.E1.m1.1.9.3.2"><mi id="S2.E1.m1.1.9.3.2.2">T</mi><mo id="S2.E1.m1.1.9.3.2.3">′</mo></msup><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.1.9.3.1">×</mo><msub id="S2.E1.m1.1.9.3.3"><mi id="S2.E1.m1.1.9.3.3.2">d</mi><mi id="S2.E1.m1.1.9.3.3.3">z</mi></msub></mrow></msup><mo lspace="0em" id="S2.E1.m1.1.10">.</mo></mrow><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\mathbf{Z^{q}}=Q_{v}(\mathbf{\hat{Z}})\coloneqq(\operatornamewithlimits{\arg\min}_{\mathbf{z}_{k}\in\mathcal{Z}}\lVert\mathbf{\hat{z}}_{t}-\mathbf{z}_{k}\rVert_{2})\in\mathbb{R}^{T^{\prime}\times d_{z}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS0.Px1.p2.16" class="ltx_p"><math id="S2.SS2.SSS0.Px1.p2.13.m1.1" class="ltx_Math" alttext="\mathbf{Z_{q}}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.13.m1.1a"><msub id="S2.SS2.SSS0.Px1.p2.13.m1.1.1" xref="S2.SS2.SSS0.Px1.p2.13.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.13.m1.1.1.2" xref="S2.SS2.SSS0.Px1.p2.13.m1.1.1.2.cmml">𝐙</mi><mi id="S2.SS2.SSS0.Px1.p2.13.m1.1.1.3" xref="S2.SS2.SSS0.Px1.p2.13.m1.1.1.3.cmml">𝐪</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.13.m1.1b"><apply id="S2.SS2.SSS0.Px1.p2.13.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.13.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.13.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.13.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.13.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.13.m1.1.1.2">𝐙</ci><ci id="S2.SS2.SSS0.Px1.p2.13.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.13.m1.1.1.3">𝐪</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.13.m1.1c">\mathbf{Z_{q}}</annotation></semantics></math> is then reconstructed back into continuous motions <math id="S2.SS2.SSS0.Px1.p2.14.m2.1" class="ltx_Math" alttext="\mathbf{\hat{V}}_{1:T}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.14.m2.1a"><msub id="S2.SS2.SSS0.Px1.p2.14.m2.1.1" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.2" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.2.cmml">𝐕</mi><mo id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.1" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.1.cmml">^</mo></mover><mrow id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.2" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.1" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.1.cmml">:</mo><mi id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.3" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.14.m2.1b"><apply id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2"><ci id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.1">^</ci><ci id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.2.2">𝐕</ci></apply><apply id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3"><ci id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.2">1</cn><ci id="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p2.14.m2.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.14.m2.1c">\mathbf{\hat{V}}_{1:T}</annotation></semantics></math> by the VQ-VAE decoder (<math id="S2.SS2.SSS0.Px1.p2.15.m3.1" class="ltx_Math" alttext="D_{v}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.15.m3.1a"><msub id="S2.SS2.SSS0.Px1.p2.15.m3.1.1" xref="S2.SS2.SSS0.Px1.p2.15.m3.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.15.m3.1.1.2" xref="S2.SS2.SSS0.Px1.p2.15.m3.1.1.2.cmml">D</mi><mi id="S2.SS2.SSS0.Px1.p2.15.m3.1.1.3" xref="S2.SS2.SSS0.Px1.p2.15.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.15.m3.1b"><apply id="S2.SS2.SSS0.Px1.p2.15.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.15.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.15.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.15.m3.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.15.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.15.m3.1.1.2">𝐷</ci><ci id="S2.SS2.SSS0.Px1.p2.15.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.15.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.15.m3.1c">D_{v}</annotation></semantics></math>), which also has a symmetric structure with <math id="S2.SS2.SSS0.Px1.p2.16.m4.1" class="ltx_Math" alttext="E_{v}" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.16.m4.1a"><msub id="S2.SS2.SSS0.Px1.p2.16.m4.1.1" xref="S2.SS2.SSS0.Px1.p2.16.m4.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p2.16.m4.1.1.2" xref="S2.SS2.SSS0.Px1.p2.16.m4.1.1.2.cmml">E</mi><mi id="S2.SS2.SSS0.Px1.p2.16.m4.1.1.3" xref="S2.SS2.SSS0.Px1.p2.16.m4.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.16.m4.1b"><apply id="S2.SS2.SSS0.Px1.p2.16.m4.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.16.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p2.16.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.16.m4.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p2.16.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p2.16.m4.1.1.2">𝐸</ci><ci id="S2.SS2.SSS0.Px1.p2.16.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p2.16.m4.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.16.m4.1c">E_{v}</annotation></semantics></math>.
The entire model is trained with the following loss:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.40" class="ltx_Math" alttext="{\mathcal{L}}_{\text{VQ}}=\lVert\mathbf{V}_{1:T}-\hat{\mathbf{V}}_{1:T}\rVert_{1}\\
+\lVert\texttt{sg}(\mathbf{\hat{Z}})-\mathbf{Z^{q}}\rVert_{2}^{2}+\lambda\lVert\mathbf{\hat{Z}}-\texttt{sg}(\mathbf{Z^{q}})\rVert_{2}^{2}," display="block"><semantics id="S2.E2.m1.40a"><mtable displaystyle="true" rowspacing="0pt" id="S2.E2.m1.40.40.3"><mtr id="S2.E2.m1.40.40.3a"><mtd class="ltx_align_left" columnalign="left" id="S2.E2.m1.40.40.3b"><mrow id="S2.E2.m1.39.39.2.38.12.12"><msub id="S2.E2.m1.39.39.2.38.12.12.13"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml">ℒ</mi><mtext id="S2.E2.m1.2.2.2.2.2.2.1" xref="S2.E2.m1.2.2.2.2.2.2.1a.cmml">VQ</mtext></msub><mo rspace="0.1389em" id="S2.E2.m1.3.3.3.3.3.3" xref="S2.E2.m1.3.3.3.3.3.3.cmml">=</mo><msub id="S2.E2.m1.39.39.2.38.12.12.12"><mrow id="S2.E2.m1.39.39.2.38.12.12.12.1.1"><mo fence="true" lspace="0.1389em" rspace="0em" id="S2.E2.m1.4.4.4.4.4.4" xref="S2.E2.m1.38.38.1.1.1.cmml">∥</mo><mrow id="S2.E2.m1.39.39.2.38.12.12.12.1.1.1"><msub id="S2.E2.m1.39.39.2.38.12.12.12.1.1.1.1"><mi id="S2.E2.m1.5.5.5.5.5.5" xref="S2.E2.m1.5.5.5.5.5.5.cmml">𝐕</mi><mrow id="S2.E2.m1.6.6.6.6.6.6.1" xref="S2.E2.m1.6.6.6.6.6.6.1.cmml"><mn id="S2.E2.m1.6.6.6.6.6.6.1.2" xref="S2.E2.m1.6.6.6.6.6.6.1.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E2.m1.6.6.6.6.6.6.1.1" xref="S2.E2.m1.6.6.6.6.6.6.1.1.cmml">:</mo><mi id="S2.E2.m1.6.6.6.6.6.6.1.3" xref="S2.E2.m1.6.6.6.6.6.6.1.3.cmml">T</mi></mrow></msub><mo id="S2.E2.m1.7.7.7.7.7.7" xref="S2.E2.m1.7.7.7.7.7.7.cmml">−</mo><msub id="S2.E2.m1.39.39.2.38.12.12.12.1.1.1.2"><mover accent="true" id="S2.E2.m1.8.8.8.8.8.8" xref="S2.E2.m1.8.8.8.8.8.8.cmml"><mi id="S2.E2.m1.8.8.8.8.8.8.2" xref="S2.E2.m1.8.8.8.8.8.8.2.cmml">𝐕</mi><mo id="S2.E2.m1.8.8.8.8.8.8.1" xref="S2.E2.m1.8.8.8.8.8.8.1.cmml">^</mo></mover><mrow id="S2.E2.m1.9.9.9.9.9.9.1" xref="S2.E2.m1.9.9.9.9.9.9.1.cmml"><mn id="S2.E2.m1.9.9.9.9.9.9.1.2" xref="S2.E2.m1.9.9.9.9.9.9.1.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E2.m1.9.9.9.9.9.9.1.1" xref="S2.E2.m1.9.9.9.9.9.9.1.1.cmml">:</mo><mi id="S2.E2.m1.9.9.9.9.9.9.1.3" xref="S2.E2.m1.9.9.9.9.9.9.1.3.cmml">T</mi></mrow></msub></mrow><mo fence="true" lspace="0em" id="S2.E2.m1.10.10.10.10.10.10" xref="S2.E2.m1.38.38.1.1.1.cmml">∥</mo></mrow><mn id="S2.E2.m1.11.11.11.11.11.11.1" xref="S2.E2.m1.11.11.11.11.11.11.1.cmml">1</mn></msub></mrow></mtd></mtr><mtr id="S2.E2.m1.40.40.3c"><mtd class="ltx_align_right" columnalign="right" id="S2.E2.m1.40.40.3d"><mrow id="S2.E2.m1.40.40.3.39.27.27.27"><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1"><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.1"><mo id="S2.E2.m1.40.40.3.39.27.27.27.1.1a" xref="S2.E2.m1.38.38.1.1.1.cmml">+</mo><msubsup id="S2.E2.m1.40.40.3.39.27.27.27.1.1.1"><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.1.1.1.1.1"><mo fence="true" lspace="0em" rspace="0em" id="S2.E2.m1.13.13.13.2.2.2" xref="S2.E2.m1.38.38.1.1.1.cmml">∥</mo><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.1.1.1.1.1.1"><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.1.1.1.1.1.1.1"><mtext class="ltx_mathvariant_monospace" id="S2.E2.m1.14.14.14.3.3.3" xref="S2.E2.m1.14.14.14.3.3.3a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="S2.E2.m1.40.40.3.39.27.27.27.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.38.38.1.1.1.cmml">​</mo><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.1.1.1.1.1.1.1.2"><mo stretchy="false" id="S2.E2.m1.15.15.15.4.4.4" xref="S2.E2.m1.38.38.1.1.1.cmml">(</mo><mover accent="true" id="S2.E2.m1.16.16.16.5.5.5" xref="S2.E2.m1.16.16.16.5.5.5.cmml"><mi id="S2.E2.m1.16.16.16.5.5.5.2" xref="S2.E2.m1.16.16.16.5.5.5.2.cmml">𝐙</mi><mo id="S2.E2.m1.16.16.16.5.5.5.1" xref="S2.E2.m1.16.16.16.5.5.5.1.cmml">^</mo></mover><mo stretchy="false" id="S2.E2.m1.17.17.17.6.6.6" xref="S2.E2.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.18.18.18.7.7.7" xref="S2.E2.m1.18.18.18.7.7.7.cmml">−</mo><msup id="S2.E2.m1.40.40.3.39.27.27.27.1.1.1.1.1.1.1.2"><mi id="S2.E2.m1.19.19.19.8.8.8" xref="S2.E2.m1.19.19.19.8.8.8.cmml">𝐙</mi><mi id="S2.E2.m1.20.20.20.9.9.9.1" xref="S2.E2.m1.20.20.20.9.9.9.1.cmml">𝐪</mi></msup></mrow><mo fence="true" lspace="0em" rspace="0em" id="S2.E2.m1.21.21.21.10.10.10" xref="S2.E2.m1.38.38.1.1.1.cmml">∥</mo></mrow><mn id="S2.E2.m1.22.22.22.11.11.11.1" xref="S2.E2.m1.22.22.22.11.11.11.1.cmml">2</mn><mn id="S2.E2.m1.23.23.23.12.12.12.1" xref="S2.E2.m1.23.23.23.12.12.12.1.cmml">2</mn></msubsup></mrow><mo id="S2.E2.m1.24.24.24.13.13.13" xref="S2.E2.m1.38.38.1.1.1.cmml">+</mo><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.2"><mi id="S2.E2.m1.25.25.25.14.14.14" xref="S2.E2.m1.25.25.25.14.14.14.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.40.40.3.39.27.27.27.1.2.2" xref="S2.E2.m1.38.38.1.1.1.cmml">​</mo><msubsup id="S2.E2.m1.40.40.3.39.27.27.27.1.2.1"><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.2.1.1.1.1"><mo fence="true" rspace="0em" id="S2.E2.m1.26.26.26.15.15.15" xref="S2.E2.m1.38.38.1.1.1.cmml">∥</mo><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.2.1.1.1.1.1"><mover accent="true" id="S2.E2.m1.27.27.27.16.16.16" xref="S2.E2.m1.27.27.27.16.16.16.cmml"><mi id="S2.E2.m1.27.27.27.16.16.16.2" xref="S2.E2.m1.27.27.27.16.16.16.2.cmml">𝐙</mi><mo id="S2.E2.m1.27.27.27.16.16.16.1" xref="S2.E2.m1.27.27.27.16.16.16.1.cmml">^</mo></mover><mo id="S2.E2.m1.28.28.28.17.17.17" xref="S2.E2.m1.28.28.28.17.17.17.cmml">−</mo><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.2.1.1.1.1.1.1"><mtext class="ltx_mathvariant_monospace" id="S2.E2.m1.29.29.29.18.18.18" xref="S2.E2.m1.29.29.29.18.18.18a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="S2.E2.m1.40.40.3.39.27.27.27.1.2.1.1.1.1.1.1.2" xref="S2.E2.m1.38.38.1.1.1.cmml">​</mo><mrow id="S2.E2.m1.40.40.3.39.27.27.27.1.2.1.1.1.1.1.1.1.1"><mo stretchy="false" id="S2.E2.m1.30.30.30.19.19.19" xref="S2.E2.m1.38.38.1.1.1.cmml">(</mo><msup id="S2.E2.m1.40.40.3.39.27.27.27.1.2.1.1.1.1.1.1.1.1.1"><mi id="S2.E2.m1.31.31.31.20.20.20" xref="S2.E2.m1.31.31.31.20.20.20.cmml">𝐙</mi><mi id="S2.E2.m1.32.32.32.21.21.21.1" xref="S2.E2.m1.32.32.32.21.21.21.1.cmml">𝐪</mi></msup><mo stretchy="false" id="S2.E2.m1.33.33.33.22.22.22" xref="S2.E2.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo fence="true" lspace="0em" rspace="0em" id="S2.E2.m1.34.34.34.23.23.23" xref="S2.E2.m1.38.38.1.1.1.cmml">∥</mo></mrow><mn id="S2.E2.m1.35.35.35.24.24.24.1" xref="S2.E2.m1.35.35.35.24.24.24.1.cmml">2</mn><mn id="S2.E2.m1.36.36.36.25.25.25.1" xref="S2.E2.m1.36.36.36.25.25.25.1.cmml">2</mn></msubsup></mrow></mrow><mo id="S2.E2.m1.37.37.37.26.26.26" xref="S2.E2.m1.38.38.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S2.E2.m1.40b"><apply id="S2.E2.m1.38.38.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><eq id="S2.E2.m1.3.3.3.3.3.3.cmml" xref="S2.E2.m1.3.3.3.3.3.3"></eq><apply id="S2.E2.m1.38.38.1.1.1.5.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.5.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1">ℒ</ci><ci id="S2.E2.m1.2.2.2.2.2.2.1a.cmml" xref="S2.E2.m1.2.2.2.2.2.2.1"><mtext mathsize="70%" id="S2.E2.m1.2.2.2.2.2.2.1.cmml" xref="S2.E2.m1.2.2.2.2.2.2.1">VQ</mtext></ci></apply><apply id="S2.E2.m1.38.38.1.1.1.3.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><plus id="S2.E2.m1.12.12.12.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"></plus><apply id="S2.E2.m1.38.38.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4">subscript</csymbol><apply id="S2.E2.m1.38.38.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="latexml" id="S2.E2.m1.38.38.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4">delimited-∥∥</csymbol><apply id="S2.E2.m1.38.38.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><minus id="S2.E2.m1.7.7.7.7.7.7.cmml" xref="S2.E2.m1.7.7.7.7.7.7"></minus><apply id="S2.E2.m1.38.38.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4">subscript</csymbol><ci id="S2.E2.m1.5.5.5.5.5.5.cmml" xref="S2.E2.m1.5.5.5.5.5.5">𝐕</ci><apply id="S2.E2.m1.6.6.6.6.6.6.1.cmml" xref="S2.E2.m1.6.6.6.6.6.6.1"><ci id="S2.E2.m1.6.6.6.6.6.6.1.1.cmml" xref="S2.E2.m1.6.6.6.6.6.6.1.1">:</ci><cn type="integer" id="S2.E2.m1.6.6.6.6.6.6.1.2.cmml" xref="S2.E2.m1.6.6.6.6.6.6.1.2">1</cn><ci id="S2.E2.m1.6.6.6.6.6.6.1.3.cmml" xref="S2.E2.m1.6.6.6.6.6.6.1.3">𝑇</ci></apply></apply><apply id="S2.E2.m1.38.38.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4">subscript</csymbol><apply id="S2.E2.m1.8.8.8.8.8.8.cmml" xref="S2.E2.m1.8.8.8.8.8.8"><ci id="S2.E2.m1.8.8.8.8.8.8.1.cmml" xref="S2.E2.m1.8.8.8.8.8.8.1">^</ci><ci id="S2.E2.m1.8.8.8.8.8.8.2.cmml" xref="S2.E2.m1.8.8.8.8.8.8.2">𝐕</ci></apply><apply id="S2.E2.m1.9.9.9.9.9.9.1.cmml" xref="S2.E2.m1.9.9.9.9.9.9.1"><ci id="S2.E2.m1.9.9.9.9.9.9.1.1.cmml" xref="S2.E2.m1.9.9.9.9.9.9.1.1">:</ci><cn type="integer" id="S2.E2.m1.9.9.9.9.9.9.1.2.cmml" xref="S2.E2.m1.9.9.9.9.9.9.1.2">1</cn><ci id="S2.E2.m1.9.9.9.9.9.9.1.3.cmml" xref="S2.E2.m1.9.9.9.9.9.9.1.3">𝑇</ci></apply></apply></apply></apply><cn type="integer" id="S2.E2.m1.11.11.11.11.11.11.1.cmml" xref="S2.E2.m1.11.11.11.11.11.11.1">1</cn></apply><apply id="S2.E2.m1.38.38.1.1.1.2.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.2.2.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4">superscript</csymbol><apply id="S2.E2.m1.38.38.1.1.1.2.2.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.2.2.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4">subscript</csymbol><apply id="S2.E2.m1.38.38.1.1.1.2.2.1.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="latexml" id="S2.E2.m1.38.38.1.1.1.2.2.1.1.2.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4">delimited-∥∥</csymbol><apply id="S2.E2.m1.38.38.1.1.1.2.2.1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><minus id="S2.E2.m1.18.18.18.7.7.7.cmml" xref="S2.E2.m1.18.18.18.7.7.7"></minus><apply id="S2.E2.m1.38.38.1.1.1.2.2.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><times id="S2.E2.m1.38.38.1.1.1.2.2.1.1.1.1.2.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"></times><ci id="S2.E2.m1.14.14.14.3.3.3a.cmml" xref="S2.E2.m1.14.14.14.3.3.3"><mtext class="ltx_mathvariant_monospace" id="S2.E2.m1.14.14.14.3.3.3.cmml" xref="S2.E2.m1.14.14.14.3.3.3">sg</mtext></ci><apply id="S2.E2.m1.16.16.16.5.5.5.cmml" xref="S2.E2.m1.16.16.16.5.5.5"><ci id="S2.E2.m1.16.16.16.5.5.5.1.cmml" xref="S2.E2.m1.16.16.16.5.5.5.1">^</ci><ci id="S2.E2.m1.16.16.16.5.5.5.2.cmml" xref="S2.E2.m1.16.16.16.5.5.5.2">𝐙</ci></apply></apply><apply id="S2.E2.m1.38.38.1.1.1.2.2.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.2.2.1.1.1.1.3.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4">superscript</csymbol><ci id="S2.E2.m1.19.19.19.8.8.8.cmml" xref="S2.E2.m1.19.19.19.8.8.8">𝐙</ci><ci id="S2.E2.m1.20.20.20.9.9.9.1.cmml" xref="S2.E2.m1.20.20.20.9.9.9.1">𝐪</ci></apply></apply></apply><cn type="integer" id="S2.E2.m1.22.22.22.11.11.11.1.cmml" xref="S2.E2.m1.22.22.22.11.11.11.1">2</cn></apply><cn type="integer" id="S2.E2.m1.23.23.23.12.12.12.1.cmml" xref="S2.E2.m1.23.23.23.12.12.12.1">2</cn></apply><apply id="S2.E2.m1.38.38.1.1.1.3.3.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><times id="S2.E2.m1.38.38.1.1.1.3.3.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4"></times><ci id="S2.E2.m1.25.25.25.14.14.14.cmml" xref="S2.E2.m1.25.25.25.14.14.14">𝜆</ci><apply id="S2.E2.m1.38.38.1.1.1.3.3.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.3.3.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4">superscript</csymbol><apply id="S2.E2.m1.38.38.1.1.1.3.3.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.3.3.1.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4">subscript</csymbol><apply id="S2.E2.m1.38.38.1.1.1.3.3.1.1.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="latexml" id="S2.E2.m1.38.38.1.1.1.3.3.1.1.1.2.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4">delimited-∥∥</csymbol><apply id="S2.E2.m1.38.38.1.1.1.3.3.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><minus id="S2.E2.m1.28.28.28.17.17.17.cmml" xref="S2.E2.m1.28.28.28.17.17.17"></minus><apply id="S2.E2.m1.27.27.27.16.16.16.cmml" xref="S2.E2.m1.27.27.27.16.16.16"><ci id="S2.E2.m1.27.27.27.16.16.16.1.cmml" xref="S2.E2.m1.27.27.27.16.16.16.1">^</ci><ci id="S2.E2.m1.27.27.27.16.16.16.2.cmml" xref="S2.E2.m1.27.27.27.16.16.16.2">𝐙</ci></apply><apply id="S2.E2.m1.38.38.1.1.1.3.3.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><times id="S2.E2.m1.38.38.1.1.1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.4.4.4.4"></times><ci id="S2.E2.m1.29.29.29.18.18.18a.cmml" xref="S2.E2.m1.29.29.29.18.18.18"><mtext class="ltx_mathvariant_monospace" id="S2.E2.m1.29.29.29.18.18.18.cmml" xref="S2.E2.m1.29.29.29.18.18.18">sg</mtext></ci><apply id="S2.E2.m1.38.38.1.1.1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S2.E2.m1.38.38.1.1.1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.4.4.4.4">superscript</csymbol><ci id="S2.E2.m1.31.31.31.20.20.20.cmml" xref="S2.E2.m1.31.31.31.20.20.20">𝐙</ci><ci id="S2.E2.m1.32.32.32.21.21.21.1.cmml" xref="S2.E2.m1.32.32.32.21.21.21.1">𝐪</ci></apply></apply></apply></apply><cn type="integer" id="S2.E2.m1.35.35.35.24.24.24.1.cmml" xref="S2.E2.m1.35.35.35.24.24.24.1">2</cn></apply><cn type="integer" id="S2.E2.m1.36.36.36.25.25.25.1.cmml" xref="S2.E2.m1.36.36.36.25.25.25.1">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.40c">{\mathcal{L}}_{\text{VQ}}=\lVert\mathbf{V}_{1:T}-\hat{\mathbf{V}}_{1:T}\rVert_{1}\\
+\lVert\texttt{sg}(\mathbf{\hat{Z}})-\mathbf{Z^{q}}\rVert_{2}^{2}+\lambda\lVert\mathbf{\hat{Z}}-\texttt{sg}(\mathbf{Z^{q}})\rVert_{2}^{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS0.Px1.p2.17" class="ltx_p">where the first term is the motion reconstruction loss, the latter two terms are for updating the codebook, <span id="S2.SS2.SSS0.Px1.p2.17.1" class="ltx_text ltx_font_typewriter">sg</span> is a stop gradient operation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, and <math id="S2.SS2.SSS0.Px1.p2.17.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S2.SS2.SSS0.Px1.p2.17.m1.1a"><mi id="S2.SS2.SSS0.Px1.p2.17.m1.1.1" xref="S2.SS2.SSS0.Px1.p2.17.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p2.17.m1.1b"><ci id="S2.SS2.SSS0.Px1.p2.17.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p2.17.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p2.17.m1.1c">\lambda</annotation></semantics></math> is a weight factor.
After training the codebook of discrete facial motions, these discrete motions are utilized in the subsequent stage to learn the speech-conditioned synthesis of 3D facial movements.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Learning speech-driven motion synthesis</h4>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.2" class="ltx_p">In this stage, we develop a model that maps input speech to a sequence of discrete codes, which are later decoded into realistic continuous motions (refer to Stage 2 in Fig. <a href="#S2.F2" title="Figure 2 ‣ Lifting 2D video to 3D ‣ 2.1 MultiTalk dataset ‣ 2 Learning multilingual 3D talking head ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
As we target to handle multiple languages, we adopt a multilingual speech encoder <math id="S2.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="E_{m}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.1.m1.1a"><msub id="S2.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">E</mi><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2">𝐸</ci><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.1.m1.1c">E_{m}</annotation></semantics></math>, pretrained on 53 languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.
This enables the model to extract language-agnostic speech representations from the multilingual inputs.
Moreover, the model incorporates a language style embedding <math id="S2.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\bm{l}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.2.m2.1a"><mi id="S2.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">𝒍</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.2.m2.1b"><ci id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1">𝒍</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.2.m2.1c">\bm{l}</annotation></semantics></math> alongside the speech.
Each language style embedding is learnable, effectively capturing the distinct facial movement style associated with speaking in that particular language.</p>
</div>
<div id="S2.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p2.6" class="ltx_p">Conditioned on both the input speech and the language style embedding, a Transformer decoder <math id="S2.SS2.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="D_{m}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.1.m1.1a"><msub id="S2.SS2.SSS0.Px2.p2.1.m1.1.1" xref="S2.SS2.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p2.1.m1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.1.m1.1.1.2.cmml">D</mi><mi id="S2.SS2.SSS0.Px2.p2.1.m1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.1.m1.1b"><apply id="S2.SS2.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.1.m1.1.1.2">𝐷</ci><ci id="S2.SS2.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.1.m1.1c">D_{m}</annotation></semantics></math> is trained to autoregressively generate the sequence of discrete facial motions.
The Transformer decoder is equipped with the causal self-attention that learns the dependencies within the sequence of previous facial motions and uses cross-modal attention to align the audio with the facial motions.
The autoregressive modeling process of the Transformer decoder is written as:
<math id="S2.SS2.SSS0.Px2.p2.2.m2.3" class="ltx_Math" alttext="\mathbf{\hat{z}}_{t}=D_{m}(E_{m}(\mathbf{S}_{1:T}),\bm{l},\mathbf{\hat{V}}_{1:t-1})" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.2.m2.3a"><mrow id="S2.SS2.SSS0.Px2.p2.2.m2.3.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.cmml"><msub id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.2.cmml">𝐳</mi><mo id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.1.cmml">^</mo></mover><mi id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.3.cmml">t</mi></msub><mo id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.3.cmml">=</mo><mrow id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.cmml"><msub id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.cmml"><mi id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.2.cmml">D</mi><mi id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.3.cmml">​</mo><mrow id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.3.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.3.cmml">(</mo><mrow id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.cmml"><msub id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.2.cmml">E</mi><mi id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.2.cmml">𝐒</mi><mrow id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.1.cmml">:</mo><mi id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.4" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.3.cmml">,</mo><mi id="S2.SS2.SSS0.Px2.p2.2.m2.1.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.1.1.cmml">𝒍</mi><mo id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.5" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.3.cmml">,</mo><msub id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.2.cmml">𝐕</mi><mo id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.1.cmml">^</mo></mover><mrow id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.cmml"><mn id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.1.cmml">:</mo><mrow id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.cmml"><mi id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.2" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.2.cmml">t</mi><mo id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.1" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.1.cmml">−</mo><mn id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.3" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.3.cmml">1</mn></mrow></mrow></msub><mo stretchy="false" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.6" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.2.m2.3b"><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3"><eq id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.3"></eq><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2"><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.2.2">𝐳</ci></apply><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.4.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2"><times id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.3"></times><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.2">𝐷</ci><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.4.3">𝑚</ci></apply><vector id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2"><apply id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1"><times id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.2"></times><apply id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.2">𝐸</ci><ci id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.3.3">𝑚</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.2">𝐒</ci><apply id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3"><ci id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.2">1</cn><ci id="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.2.2.1.1.1.1.1.1.1.3.3">𝑇</ci></apply></apply></apply><ci id="S2.SS2.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.1.1">𝒍</ci><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2"><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.2.2">𝐕</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3"><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.2">1</cn><apply id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3"><minus id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.1"></minus><ci id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.2">𝑡</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.2.m2.3.3.2.2.2.2.3.3.3">1</cn></apply></apply></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.2.m2.3c">\mathbf{\hat{z}}_{t}=D_{m}(E_{m}(\mathbf{S}_{1:T}),\bm{l},\mathbf{\hat{V}}_{1:t-1})</annotation></semantics></math>, where <math id="S2.SS2.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{\hat{z}}_{t}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.3.m3.1a"><msub id="S2.SS2.SSS0.Px2.p2.3.m3.1.1" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.2" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.2.cmml">𝐳</mi><mo id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.1" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.3" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.3.m3.1b"><apply id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2"><ci id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.2.2">𝐳</ci></apply><ci id="S2.SS2.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.3.m3.1c">\mathbf{\hat{z}}_{t}</annotation></semantics></math> is the currently predicted discrete facial motion, and <math id="S2.SS2.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{\hat{V}}_{1:t-1}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.4.m4.1a"><msub id="S2.SS2.SSS0.Px2.p2.4.m4.1.1" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.2" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.2.cmml">𝐕</mi><mo id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.1" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.1.cmml">^</mo></mover><mrow id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.1" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.1.cmml">:</mo><mrow id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.cmml"><mi id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.2" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.2.cmml">t</mi><mo id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1.cmml">−</mo><mn id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.3" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.3.cmml">1</mn></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.4.m4.1b"><apply id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2"><ci id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.2.2">𝐕</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3"><ci id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.2">1</cn><apply id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3"><minus id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.1"></minus><ci id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.2">𝑡</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.4.m4.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.4.m4.1c">\mathbf{\hat{V}}_{1:t-1}</annotation></semantics></math> is the past predicted sequences.
The discrete code <math id="S2.SS2.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{\hat{z}}_{t}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.5.m5.1a"><msub id="S2.SS2.SSS0.Px2.p2.5.m5.1.1" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.2" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.2.cmml">𝐳</mi><mo id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.1" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.3" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.5.m5.1b"><apply id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2"><ci id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.2.2">𝐳</ci></apply><ci id="S2.SS2.SSS0.Px2.p2.5.m5.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.5.m5.1c">\mathbf{\hat{z}}_{t}</annotation></semantics></math> is then quantized by Eq. (<a href="#S2.E1" title="In Learning discrete facial motion ‣ 2.2 Speech-driven multilingual 3D talking head ‣ 2 Learning multilingual 3D talking head ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) and decoded to continuous motion, <math id="S2.SS2.SSS0.Px2.p2.6.m6.1" class="ltx_Math" alttext="\mathbf{\hat{v}}_{t}=D_{v}(Q_{v}(\mathbf{\hat{z}}_{t}))" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.6.m6.1a"><mrow id="S2.SS2.SSS0.Px2.p2.6.m6.1.1" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.cmml"><msub id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.2.cmml">𝐯</mi><mo id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.1" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.1.cmml">^</mo></mover><mi id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.3.cmml">t</mi></msub><mo id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.2.cmml">=</mo><mrow id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.cmml"><msub id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.2.cmml">D</mi><mi id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.2.cmml">​</mo><mrow id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.cmml"><msub id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.2.cmml">Q</mi><mi id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.2" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.2.cmml">𝐳</mi><mo id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.1" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mi id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.6.m6.1b"><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1"><eq id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.2"></eq><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2"><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.2.2">𝐯</ci></apply><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.3.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1"><times id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.2"></times><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.2">𝐷</ci><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.3.3">𝑣</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1"><times id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.2"></times><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.2">𝑄</ci><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.3.3">𝑣</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2"><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.2.2">𝐳</ci></apply><ci id="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.6.m6.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.6.m6.1c">\mathbf{\hat{v}}_{t}=D_{v}(Q_{v}(\mathbf{\hat{z}}_{t}))</annotation></semantics></math>.
The model is trained in a teacher-forcing manner with the following loss:</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.1" class="ltx_Math" alttext="{\mathcal{L}}_{\text{GEN}}=\lVert\mathbf{\hat{Z}}_{1:T}-\texttt{sg}(\mathbf{Z^{q}}_{1:T})\rVert^{2}_{2}+\lVert\mathbf{\hat{V}}_{1:T}-\mathbf{V}_{1:T}\rVert^{2}_{2}," display="block"><semantics id="S2.E3.m1.1a"><mrow id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><msub id="S2.E3.m1.1.1.1.1.4" xref="S2.E3.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.1.1.1.1.4.2" xref="S2.E3.m1.1.1.1.1.4.2.cmml">ℒ</mi><mtext id="S2.E3.m1.1.1.1.1.4.3" xref="S2.E3.m1.1.1.1.1.4.3a.cmml">GEN</mtext></msub><mo rspace="0.1389em" id="S2.E3.m1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.3.cmml">=</mo><mrow id="S2.E3.m1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.2.cmml"><msubsup id="S2.E3.m1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.2.cmml"><mo fence="true" lspace="0.1389em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml">∥</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">𝐙</mi><mo id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mn id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">:</mo><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">T</mi></mrow></msub><mo id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mmultiscripts id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">𝐙</mi><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"></mrow><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">𝐪</mi><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mn id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">:</mo><mi id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">T</mi></mrow><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1b" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"></mrow></mmultiscripts><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo fence="true" lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml">∥</mo></mrow><mn id="S2.E3.m1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.3.cmml">2</mn><mn id="S2.E3.m1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.3.cmml">2</mn></msubsup><mo id="S2.E3.m1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.2.3.cmml">+</mo><msubsup id="S2.E3.m1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.2.2.cmml"><mrow id="S2.E3.m1.1.1.1.1.2.2.1.1.1" xref="S2.E3.m1.1.1.1.1.2.2.1.1.2.cmml"><mo fence="true" lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.2" xref="S2.E3.m1.1.1.1.1.2.2.1.1.2.1.cmml">∥</mo><mrow id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.cmml"><msub id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.cmml"><mover accent="true" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.cmml"><mi id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.2" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.2.cmml">𝐕</mi><mo id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.1" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.1.cmml">^</mo></mover><mrow id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.cmml"><mn id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.2" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.1" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.1.cmml">:</mo><mi id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.3" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.3.cmml">T</mi></mrow></msub><mo id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.1.cmml">−</mo><msub id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.cmml"><mi id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.2.cmml">𝐕</mi><mrow id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.cmml"><mn id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.1" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.1.cmml">:</mo><mi id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.3.cmml">T</mi></mrow></msub></mrow><mo fence="true" lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.3" xref="S2.E3.m1.1.1.1.1.2.2.1.1.2.1.cmml">∥</mo></mrow><mn id="S2.E3.m1.1.1.1.1.2.2.3" xref="S2.E3.m1.1.1.1.1.2.2.3.cmml">2</mn><mn id="S2.E3.m1.1.1.1.1.2.2.1.3" xref="S2.E3.m1.1.1.1.1.2.2.1.3.cmml">2</mn></msubsup></mrow></mrow><mo id="S2.E3.m1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.1b"><apply id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"><eq id="S2.E3.m1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.3"></eq><apply id="S2.E3.m1.1.1.1.1.4.cmml" xref="S2.E3.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.4.1.cmml" xref="S2.E3.m1.1.1.1.1.4">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.4.2.cmml" xref="S2.E3.m1.1.1.1.1.4.2">ℒ</ci><ci id="S2.E3.m1.1.1.1.1.4.3a.cmml" xref="S2.E3.m1.1.1.1.1.4.3"><mtext mathsize="70%" id="S2.E3.m1.1.1.1.1.4.3.cmml" xref="S2.E3.m1.1.1.1.1.4.3">GEN</mtext></ci></apply><apply id="S2.E3.m1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.2"><plus id="S2.E3.m1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.2.3"></plus><apply id="S2.E3.m1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.2">delimited-∥∥</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1"><minus id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2"></minus><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.1">^</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.2.2">𝐙</ci></apply><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3"><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.1">:</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.2">1</cn><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.3.3.3">𝑇</ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1"><times id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3">sg</mtext></ci><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝐙</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝐪</ci></apply><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1">:</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">1</cn><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑇</ci></apply></apply></apply></apply></apply><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3">2</cn></apply><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3">2</cn></apply><apply id="S2.E3.m1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2">subscript</csymbol><apply id="S2.E3.m1.1.1.1.1.2.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.2.1.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2">superscript</csymbol><apply id="S2.E3.m1.1.1.1.1.2.2.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.1.1.1.1.2.2.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.2">delimited-∥∥</csymbol><apply id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1"><minus id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.1"></minus><apply id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2">subscript</csymbol><apply id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2"><ci id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.1">^</ci><ci id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.2.2">𝐕</ci></apply><apply id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3"><ci id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.1">:</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.2">1</cn><ci id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.2">𝐕</ci><apply id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3"><ci id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.1">:</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.2">1</cn><ci id="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.1.1.1.3.3.3">𝑇</ci></apply></apply></apply></apply><cn type="integer" id="S2.E3.m1.1.1.1.1.2.2.1.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.1.3">2</cn></apply><cn type="integer" id="S2.E3.m1.1.1.1.1.2.2.3.cmml" xref="S2.E3.m1.1.1.1.1.2.2.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.1c">{\mathcal{L}}_{\text{GEN}}=\lVert\mathbf{\hat{Z}}_{1:T}-\texttt{sg}(\mathbf{Z^{q}}_{1:T})\rVert^{2}_{2}+\lVert\mathbf{\hat{V}}_{1:T}-\mathbf{V}_{1:T}\rVert^{2}_{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.SSS0.Px2.p2.10" class="ltx_p">where the first term regularizes the deviation between the predicted motion features <math id="S2.SS2.SSS0.Px2.p2.7.m1.1" class="ltx_Math" alttext="\mathbf{\hat{Z}}_{1:T}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.7.m1.1a"><msub id="S2.SS2.SSS0.Px2.p2.7.m1.1.1" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.2" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.2.cmml">𝐙</mi><mo id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.1" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.1.cmml">^</mo></mover><mrow id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.1" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.1.cmml">:</mo><mi id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.7.m1.1b"><apply id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2"><ci id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.2.2">𝐙</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3"><ci id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.2">1</cn><ci id="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.7.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.7.m1.1c">\mathbf{\hat{Z}}_{1:T}</annotation></semantics></math> and the quantized features <math id="S2.SS2.SSS0.Px2.p2.8.m2.1" class="ltx_Math" alttext="\mathbf{Z^{q}}_{1:T}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.8.m2.1a"><mmultiscripts id="S2.SS2.SSS0.Px2.p2.8.m2.1.1" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.2" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.2.cmml">𝐙</mi><mrow id="S2.SS2.SSS0.Px2.p2.8.m2.1.1a" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.cmml"></mrow><mi id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.3" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.3.cmml">𝐪</mi><mrow id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.1" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.1.cmml">:</mo><mi id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.3.cmml">T</mi></mrow><mrow id="S2.SS2.SSS0.Px2.p2.8.m2.1.1b" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.8.m2.1b"><apply id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1">superscript</csymbol><ci id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.2">𝐙</ci><ci id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.2.3">𝐪</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3"><ci id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.2">1</cn><ci id="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.8.m2.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.8.m2.1c">\mathbf{Z^{q}}_{1:T}</annotation></semantics></math> from the codebook, while the latter term denotes the reconstruction loss between the predicted facial motions <math id="S2.SS2.SSS0.Px2.p2.9.m3.1" class="ltx_Math" alttext="\mathbf{\hat{V}}_{1:T}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.9.m3.1a"><msub id="S2.SS2.SSS0.Px2.p2.9.m3.1.1" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.2" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.2.cmml">𝐕</mi><mo id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.1" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.1.cmml">^</mo></mover><mrow id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.1" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.1.cmml">:</mo><mi id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.9.m3.1b"><apply id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2"><ci id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.1">^</ci><ci id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.2.2">𝐕</ci></apply><apply id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3"><ci id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.2">1</cn><ci id="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.9.m3.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.9.m3.1c">\mathbf{\hat{V}}_{1:T}</annotation></semantics></math> and the ground-truth <math id="S2.SS2.SSS0.Px2.p2.10.m4.1" class="ltx_Math" alttext="\mathbf{V}_{1:T}" display="inline"><semantics id="S2.SS2.SSS0.Px2.p2.10.m4.1a"><msub id="S2.SS2.SSS0.Px2.p2.10.m4.1.1" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.2" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.2.cmml">𝐕</mi><mrow id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.2" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.1" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.1.cmml">:</mo><mi id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.3" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p2.10.m4.1b"><apply id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.2">𝐕</ci><apply id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3"><ci id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.1">:</ci><cn type="integer" id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.2">1</cn><ci id="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p2.10.m4.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p2.10.m4.1c">\mathbf{V}_{1:T}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Implementation details</h4>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p1.4" class="ltx_p">The VQ-VAE in the first stage is trained for 150 epochs with the AdamW optimizer (<math id="S2.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\beta_{1}=0.9" display="inline"><semantics id="S2.SS2.SSS0.Px3.p1.1.m1.1a"><mrow id="S2.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><msub id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.2.cmml">β</mi><mn id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.3" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml">=</mo><mn id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1"><eq id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1"></eq><apply id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.2">𝛽</ci><cn type="integer" id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.3">1</cn></apply><cn type="float" id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.1.m1.1c">\beta_{1}=0.9</annotation></semantics></math>, <math id="S2.SS2.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\beta_{2}=0.999" display="inline"><semantics id="S2.SS2.SSS0.Px3.p1.2.m2.1a"><mrow id="S2.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.cmml"><msub id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.2" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.2.cmml">β</mi><mn id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.3" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.1" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.3" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml">0.999</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.2.m2.1b"><apply id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1"><eq id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.1"></eq><apply id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.2">𝛽</ci><cn type="integer" id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.3">2</cn></apply><cn type="float" id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.3">0.999</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.2.m2.1c">\beta_{2}=0.999</annotation></semantics></math> and <math id="S2.SS2.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="\epsilon=10^{-8}" display="inline"><semantics id="S2.SS2.SSS0.Px3.p1.3.m3.1a"><mrow id="S2.SS2.SSS0.Px3.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.2" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.2.cmml">ϵ</mi><mo id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.1" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.1.cmml">=</mo><msup id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.cmml"><mn id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.2" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.2.cmml">10</mn><mrow id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.cmml"><mo id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3a" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.cmml">−</mo><mn id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.2" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.2.cmml">8</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.3.m3.1b"><apply id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1"><eq id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.1"></eq><ci id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.2">italic-ϵ</ci><apply id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3">superscript</csymbol><cn type="integer" id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.2">10</cn><apply id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3"><minus id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.1.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3"></minus><cn type="integer" id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.2.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.3.3.2">8</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.3.m3.1c">\epsilon=10^{-8}</annotation></semantics></math>), where the learning rate is initialized as <math id="S2.SS2.SSS0.Px3.p1.4.m4.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S2.SS2.SSS0.Px3.p1.4.m4.1a"><msup id="S2.SS2.SSS0.Px3.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.cmml"><mn id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.2.cmml">10</mn><mrow id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3.cmml"><mo id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3a" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3.cmml">−</mo><mn id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.4.m4.1b"><apply id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1">superscript</csymbol><cn type="integer" id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.2">10</cn><apply id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3"><minus id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3"></minus><cn type="integer" id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.4.m4.1c">10^{-4}</annotation></semantics></math>, and a mini-batch size of 1.
In the second stage, the Transformer decoder model is trained for 100 epochs with the Adam optimizer, maintaining the same hyper-parameters as in the first stage.
Training for both stages is conducted on a single GeForce RTX 3090 GPU.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In the experiment, we aim to demonstrate the efficacy of our proposed dataset and the baseline model, MultiTalk, in enhancing the multilingual capabilities of 3D talking heads.
To this end, we compare MultiTalk trained on our dataset, against competing models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> trained on the existing dataset. Specifically, MultiTalk is trained on a subset of our proposed dataset, comprising approximately 20 hours of 3D facial sequences in diverse languages. In contrast, existing works utilize the VOCASET dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, which includes 480 sequences (approximately 30 minutes) only in English from 12 subjects.
We construct a test split in our MultiTalk dataset, involving 60 clips across 12 different languages. To ensure a fair comparison, all results are standardized to the same FLAME topology.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S3.T2.3.1" class="ltx_text ltx_font_bold">Preliminary experiment.</span> Audio-Visual Lip Readability (AVLR) demonstrates a high correlation with human evaluations, indicating its suitability as a metric for measuring the lip readability of 3D talking heads. The top three rows present WER (%) obtained from AVLR and VSR. The last row shows Spearman's correlation coefficient, which ranges from -1 to 1; a value of 1 indicates the highest correlation with human evaluations.</figcaption>
<div id="S3.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:114.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(46.8pt,-12.4pt) scale(1.27540066367446,1.27540066367446) ;">
<table id="S3.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.2.1" class="ltx_tr">
<th id="S3.T2.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Method</th>
<th id="S3.T2.1.1.2.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt">AVLR (SNR=-7.5)</th>
<th id="S3.T2.1.1.2.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt">AVLR (SNR=-10)</th>
<th id="S3.T2.1.1.2.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt">VSR</th>
<td id="S3.T2.1.1.2.1.5" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S3.T2.1.1.3.2" class="ltx_tr">
<th id="S3.T2.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">VOCASET (GT)</th>
<td id="S3.T2.1.1.3.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">39.4</td>
<td id="S3.T2.1.1.3.2.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">43.8</td>
<td id="S3.T2.1.1.3.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">111.2</td>
<td id="S3.T2.1.1.3.2.5" class="ltx_td ltx_nopad_l ltx_border_t"></td>
</tr>
<tr id="S3.T2.1.1.4.3" class="ltx_tr">
<th id="S3.T2.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">FaceFormer</th>
<td id="S3.T2.1.1.4.3.2" class="ltx_td ltx_nopad_l ltx_align_center">50.7</td>
<td id="S3.T2.1.1.4.3.3" class="ltx_td ltx_nopad_l ltx_align_center">56.9</td>
<td id="S3.T2.1.1.4.3.4" class="ltx_td ltx_nopad_l ltx_align_center">136.3</td>
<td id="S3.T2.1.1.4.3.5" class="ltx_td ltx_nopad_l"></td>
</tr>
<tr id="S3.T2.1.1.5.4" class="ltx_tr">
<th id="S3.T2.1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">VOCA</th>
<td id="S3.T2.1.1.5.4.2" class="ltx_td ltx_nopad_l ltx_align_center">53.1</td>
<td id="S3.T2.1.1.5.4.3" class="ltx_td ltx_nopad_l ltx_align_center">62.6</td>
<td id="S3.T2.1.1.5.4.4" class="ltx_td ltx_nopad_l ltx_align_center">153.1</td>
<td id="S3.T2.1.1.5.4.5" class="ltx_td ltx_nopad_l"></td>
</tr>
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t">Spearman's <math id="S3.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S3.T2.1.1.1.1.m1.1a"><mi id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\rho</annotation></semantics></math></th>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t">
<span id="S3.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">0.55</span></td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t">0.46</td>
<td id="S3.T2.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t">0.43</td>
<td id="S3.T2.1.1.1.5" class="ltx_td ltx_nopad_l ltx_border_bb ltx_border_t"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Comparison with existing methods</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To evaluate lip synchronization of generated mesh with the input speech, we measure the Lip Vertex Error (LVE) metric proposed in MeshTalk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. However, solely measuring the <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">ℓ</mi><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ℓ</ci><cn type="integer" id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\ell_{2}</annotation></semantics></math> error of lip vertices is insufficient for assessing the facial movement due to the one-to-many mapping nature of this task. As a complementary, we introduce a new metric to evaluate the lip readability of the generated mesh, <em id="S3.SS1.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>., audio-visual lip readability.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Lip Vertex Error (LVE)</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.2" class="ltx_p">LVE computes the average <math id="S3.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">ℓ</mi><mn id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2">ℓ</ci><cn type="integer" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">\ell_{2}</annotation></semantics></math> error between the lip regions of the generated mesh vertices and the ground-truth from the test set. For each frame, the LVE is defined as the maximum <math id="S3.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">ℓ</mi><mn id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2">ℓ</ci><cn type="integer" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">\ell_{2}</annotation></semantics></math> error across all lip vertices.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Audio-Visual Lip Readability (AVLR)</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">We propose the AVLR metric for evaluating perceptually accurate lip readability with a pre-trained Audio-Visual Speech Recognition (AVSR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> model.
A naïve way for assessing lip readability would be to use a pre-trained Visual Speech Recognition (VSR) model to measure the lip reading metric on the rendered 3D faces without accompanying speech.
However, relying solely on visual cues introduces ambiguity in inferring words. For example, distinguishing between ``ba''and ``ma'' is challenging by merely observing mouth shapes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. We hypothesize that supplementing visual information with subtle audio cues may reduce this ambiguity, leading to a more robust lip readability metric compared to using visual cues alone.
Specifically, we supply noisy audio alongside the rendered 3D faces to a pre-trained AVSR model and measure the Word Error Rate (WER) to evaluate the lip readability of the 3D talking head.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p2.1" class="ltx_p">To validate our proposed AVLR metric, we conduct a preliminary experiment. We collect meshes from the ground-truth VOCASET <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> dataset and those generated by FaceFormer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and VOCA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
We measure the WER for each model using VSR, and AVSR with Signal-to-Noise Ratio (SNR) settings of -7.5 and -10, and subsequently rank the models by their WERs.
We then compute the Spearman's correlation coefficient, <math id="S3.SS1.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.1.m1.1a"><mi id="S3.SS1.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.1.m1.1b"><ci id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.1.m1.1c">\rho</annotation></semantics></math>, to compare the model rankings with human evaluation rankings.
As shown in Table <a href="#S3.T2" title="Table 2 ‣ 3 Experiments ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, AVSR exhibits the highest correlation with human evaluations. Furthermore, VSR produces WERs exceeding 110%, confirming its unsuitability as a metric. These findings highlight the efficacy of our proposed AVLR metric in assessing lip accuracy.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p3.1" class="ltx_p">Utilizing the metrics described above, we conduct a quantitative comparison of our MultiTalk model against four different approaches: VOCA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, FaceFormer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, Codetalker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, and SelfTalk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.
Table <a href="#S3.T3" title="Table 3 ‣ Audio-Visual Lip Readability (AVLR) ‣ 3.1 Comparison with existing methods ‣ 3 Experiments ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> summarizes the LVE and AVLR over the test set of the MultiTalk dataset, with AVLR assessed across four different languages.
Notably, MultiTalk achieves superior performance compared to the other methods across all metrics.
Specifically, in the AVLR, the recent method SelfTalk shows comparable performance in English, but MultiTalk excels in languages other than English.
These results highlight the effectiveness of both our proposed method and the dataset in establishing multilingual capabilities for 3D talking head models.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p4" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p4.1" class="ltx_p">For a more comprehensive comparison, we visualize the generated samples in Fig. <a href="#S3.F3" title="Figure 3 ‣ Audio-Visual Lip Readability (AVLR) ‣ 3.1 Comparison with existing methods ‣ 3 Experiments ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
As shown, the meshes generated by our MultiTalk model exhibit detailed and expressive lip movements for closures and openings in sync with the input speech.
We postulate that such expressiveness could be learned from our dataset, which reflects the inherent diversity and includes various facial movements across languages.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S3.T3.6.1" class="ltx_text ltx_font_bold">Quantitative comparison to existing methods.</span> We compare MultiTalk (Ours) with existing methods on the test split of the MuliTalk dataset on 4 languages: English (En), Italian (It), French (Fr), and Greek
(El). LVE is measured in <math id="S3.T3.2.m1.1" class="ltx_Math" alttext="\times 10^{-4}\text{mm}" display="inline"><semantics id="S3.T3.2.m1.1b"><mrow id="S3.T3.2.m1.1.1" xref="S3.T3.2.m1.1.1.cmml"><mi id="S3.T3.2.m1.1.1.2" xref="S3.T3.2.m1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S3.T3.2.m1.1.1.1" xref="S3.T3.2.m1.1.1.1.cmml">×</mo><mrow id="S3.T3.2.m1.1.1.3" xref="S3.T3.2.m1.1.1.3.cmml"><msup id="S3.T3.2.m1.1.1.3.2" xref="S3.T3.2.m1.1.1.3.2.cmml"><mn id="S3.T3.2.m1.1.1.3.2.2" xref="S3.T3.2.m1.1.1.3.2.2.cmml">10</mn><mrow id="S3.T3.2.m1.1.1.3.2.3" xref="S3.T3.2.m1.1.1.3.2.3.cmml"><mo id="S3.T3.2.m1.1.1.3.2.3b" xref="S3.T3.2.m1.1.1.3.2.3.cmml">−</mo><mn id="S3.T3.2.m1.1.1.3.2.3.2" xref="S3.T3.2.m1.1.1.3.2.3.2.cmml">4</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.T3.2.m1.1.1.3.1" xref="S3.T3.2.m1.1.1.3.1.cmml">​</mo><mtext id="S3.T3.2.m1.1.1.3.3" xref="S3.T3.2.m1.1.1.3.3a.cmml">mm</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.2.m1.1c"><apply id="S3.T3.2.m1.1.1.cmml" xref="S3.T3.2.m1.1.1"><times id="S3.T3.2.m1.1.1.1.cmml" xref="S3.T3.2.m1.1.1.1"></times><csymbol cd="latexml" id="S3.T3.2.m1.1.1.2.cmml" xref="S3.T3.2.m1.1.1.2">absent</csymbol><apply id="S3.T3.2.m1.1.1.3.cmml" xref="S3.T3.2.m1.1.1.3"><times id="S3.T3.2.m1.1.1.3.1.cmml" xref="S3.T3.2.m1.1.1.3.1"></times><apply id="S3.T3.2.m1.1.1.3.2.cmml" xref="S3.T3.2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.T3.2.m1.1.1.3.2.1.cmml" xref="S3.T3.2.m1.1.1.3.2">superscript</csymbol><cn type="integer" id="S3.T3.2.m1.1.1.3.2.2.cmml" xref="S3.T3.2.m1.1.1.3.2.2">10</cn><apply id="S3.T3.2.m1.1.1.3.2.3.cmml" xref="S3.T3.2.m1.1.1.3.2.3"><minus id="S3.T3.2.m1.1.1.3.2.3.1.cmml" xref="S3.T3.2.m1.1.1.3.2.3"></minus><cn type="integer" id="S3.T3.2.m1.1.1.3.2.3.2.cmml" xref="S3.T3.2.m1.1.1.3.2.3.2">4</cn></apply></apply><ci id="S3.T3.2.m1.1.1.3.3a.cmml" xref="S3.T3.2.m1.1.1.3.3"><mtext id="S3.T3.2.m1.1.1.3.3.cmml" xref="S3.T3.2.m1.1.1.3.3">mm</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.m1.1d">\times 10^{-4}\text{mm}</annotation></semantics></math> scale, and AVSR (SNR=-7.5) is measured in WER (%).
</figcaption>
<div id="S3.T3.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:157.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(43.4pt,-15.8pt) scale(1.25032112996213,1.25032112996213) ;">
<table id="S3.T3.4.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.4.2.2" class="ltx_tr">
<th id="S3.T3.4.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" rowspan="2"><span id="S3.T3.4.2.2.3.1" class="ltx_text">Method</span></th>
<th id="S3.T3.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">LVE (<math id="S3.T3.3.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T3.3.1.1.1.m1.1a"><mo stretchy="false" id="S3.T3.3.1.1.1.m1.1.1" xref="S3.T3.3.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T3.3.1.1.1.m1.1b"><ci id="S3.T3.3.1.1.1.m1.1.1.cmml" xref="S3.T3.3.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</th>
<th id="S3.T3.4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">AVLR (<math id="S3.T3.4.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T3.4.2.2.2.m1.1a"><mo stretchy="false" id="S3.T3.4.2.2.2.m1.1.1" xref="S3.T3.4.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T3.4.2.2.2.m1.1b"><ci id="S3.T3.4.2.2.2.m1.1.1.cmml" xref="S3.T3.4.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.2.2.2.m1.1c">\downarrow</annotation></semantics></math>)</th>
</tr>
<tr id="S3.T3.4.2.3.1" class="ltx_tr">
<th id="S3.T3.4.2.3.1.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">En</th>
<th id="S3.T3.4.2.3.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">It</th>
<th id="S3.T3.4.2.3.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">Fr</th>
<th id="S3.T3.4.2.3.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">El</th>
<th id="S3.T3.4.2.3.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">En</th>
<th id="S3.T3.4.2.3.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">It</th>
<th id="S3.T3.4.2.3.1.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">Fr</th>
<th id="S3.T3.4.2.3.1.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">El</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.4.2.4.1" class="ltx_tr">
<th id="S3.T3.4.2.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">VOCA</th>
<td id="S3.T3.4.2.4.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">1.95</td>
<td id="S3.T3.4.2.4.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">2.78</td>
<td id="S3.T3.4.2.4.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">1.93</td>
<td id="S3.T3.4.2.4.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">2.18</td>
<td id="S3.T3.4.2.4.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">50.8</td>
<td id="S3.T3.4.2.4.1.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">60.4</td>
<td id="S3.T3.4.2.4.1.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">74.9</td>
<td id="S3.T3.4.2.4.1.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">82.1</td>
</tr>
<tr id="S3.T3.4.2.5.2" class="ltx_tr">
<th id="S3.T3.4.2.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">FaceFormer</th>
<td id="S3.T3.4.2.5.2.2" class="ltx_td ltx_nopad_l ltx_align_center">1.82</td>
<td id="S3.T3.4.2.5.2.3" class="ltx_td ltx_nopad_l ltx_align_center">2.56</td>
<td id="S3.T3.4.2.5.2.4" class="ltx_td ltx_nopad_l ltx_align_center">1.78</td>
<td id="S3.T3.4.2.5.2.5" class="ltx_td ltx_nopad_l ltx_align_center">1.99</td>
<td id="S3.T3.4.2.5.2.6" class="ltx_td ltx_nopad_l ltx_align_center">50.8</td>
<td id="S3.T3.4.2.5.2.7" class="ltx_td ltx_nopad_l ltx_align_center">58.9</td>
<td id="S3.T3.4.2.5.2.8" class="ltx_td ltx_nopad_l ltx_align_center">70.9</td>
<td id="S3.T3.4.2.5.2.9" class="ltx_td ltx_nopad_l ltx_align_center">79.0</td>
</tr>
<tr id="S3.T3.4.2.6.3" class="ltx_tr">
<th id="S3.T3.4.2.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">CodeTalker</th>
<td id="S3.T3.4.2.6.3.2" class="ltx_td ltx_nopad_l ltx_align_center">1.98</td>
<td id="S3.T3.4.2.6.3.3" class="ltx_td ltx_nopad_l ltx_align_center">2.56</td>
<td id="S3.T3.4.2.6.3.4" class="ltx_td ltx_nopad_l ltx_align_center">1.99</td>
<td id="S3.T3.4.2.6.3.5" class="ltx_td ltx_nopad_l ltx_align_center">2.09</td>
<td id="S3.T3.4.2.6.3.6" class="ltx_td ltx_nopad_l ltx_align_center">50.0</td>
<td id="S3.T3.4.2.6.3.7" class="ltx_td ltx_nopad_l ltx_align_center">59.4</td>
<td id="S3.T3.4.2.6.3.8" class="ltx_td ltx_nopad_l ltx_align_center">74.9</td>
<td id="S3.T3.4.2.6.3.9" class="ltx_td ltx_nopad_l ltx_align_center">77.8</td>
</tr>
<tr id="S3.T3.4.2.7.4" class="ltx_tr">
<th id="S3.T3.4.2.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">SelfTalk</th>
<td id="S3.T3.4.2.7.4.2" class="ltx_td ltx_nopad_l ltx_align_center">1.99</td>
<td id="S3.T3.4.2.7.4.3" class="ltx_td ltx_nopad_l ltx_align_center">2.59</td>
<td id="S3.T3.4.2.7.4.4" class="ltx_td ltx_nopad_l ltx_align_center">1.98</td>
<td id="S3.T3.4.2.7.4.5" class="ltx_td ltx_nopad_l ltx_align_center">2.11</td>
<td id="S3.T3.4.2.7.4.6" class="ltx_td ltx_nopad_l ltx_align_center">42.8</td>
<td id="S3.T3.4.2.7.4.7" class="ltx_td ltx_nopad_l ltx_align_center">56.5</td>
<td id="S3.T3.4.2.7.4.8" class="ltx_td ltx_nopad_l ltx_align_center">68.3</td>
<td id="S3.T3.4.2.7.4.9" class="ltx_td ltx_nopad_l ltx_align_center">80.3</td>
</tr>
<tr id="S3.T3.4.2.8.5" class="ltx_tr">
<th id="S3.T3.4.2.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">MultiTalk (Ours)</th>
<td id="S3.T3.4.2.8.5.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T3.4.2.8.5.2.1" class="ltx_text ltx_font_bold">1.16</span></td>
<td id="S3.T3.4.2.8.5.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T3.4.2.8.5.3.1" class="ltx_text ltx_font_bold">1.06</span></td>
<td id="S3.T3.4.2.8.5.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T3.4.2.8.5.4.1" class="ltx_text ltx_font_bold">1.39</span></td>
<td id="S3.T3.4.2.8.5.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">
<span id="S3.T3.4.2.8.5.5.1" class="ltx_text ltx_font_bold">1.26</span></td>
<td id="S3.T3.4.2.8.5.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T3.4.2.8.5.6.1" class="ltx_text ltx_font_bold">42.4</span></td>
<td id="S3.T3.4.2.8.5.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T3.4.2.8.5.7.1" class="ltx_text ltx_font_bold">50.5</span></td>
<td id="S3.T3.4.2.8.5.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T3.4.2.8.5.8.1" class="ltx_text ltx_font_bold">63.0</span></td>
<td id="S3.T3.4.2.8.5.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T3.4.2.8.5.9.1" class="ltx_text ltx_font_bold">74.2</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2406.14272/assets/x4.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="273" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S3.F3.2.1" class="ltx_text ltx_font_bold">Qualitative comparisons.</span> Compared to existing methods, MultiTalk (Ours) demonstrates detailed facial expressions with accurately synchronized lip movements to the input speech.</figcaption>
</figure>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S3.T4.2.1" class="ltx_text ltx_font_bold">User study results.</span> We adopt A vs. B test and report the percentage (%) of preferences for A (Ours) over B, assessing the generated meshes on lip sync and realism.</figcaption>
<div id="S3.T4.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:69pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(47.2pt,-7.5pt) scale(1.27848282929985,1.27848282929985) ;">
<table id="S3.T4.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.3.1.1.1" class="ltx_tr">
<th id="S3.T4.3.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Aspect</th>
<th id="S3.T4.3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T4.3.1.1.1.2.1" class="ltx_text ltx_font_italic">vs.</span> VOCA</th>
<th id="S3.T4.3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T4.3.1.1.1.3.1" class="ltx_text ltx_font_italic">vs.</span> FaceFormer</th>
<th id="S3.T4.3.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T4.3.1.1.1.4.1" class="ltx_text ltx_font_italic">vs.</span> CodeTalker</th>
<th id="S3.T4.3.1.1.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T4.3.1.1.1.5.1" class="ltx_text ltx_font_italic">vs.</span> SelfTalk</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.3.1.2.1" class="ltx_tr">
<th id="S3.T4.3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Lip sync.</th>
<td id="S3.T4.3.1.2.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">93.28</td>
<td id="S3.T4.3.1.2.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">84.17</td>
<td id="S3.T4.3.1.2.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">76.92</td>
<td id="S3.T4.3.1.2.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">53.78</td>
</tr>
<tr id="S3.T4.3.1.3.2" class="ltx_tr">
<th id="S3.T4.3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Realism.</th>
<td id="S3.T4.3.1.3.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">93.28</td>
<td id="S3.T4.3.1.3.2.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">91.53</td>
<td id="S3.T4.3.1.3.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">82.05</td>
<td id="S3.T4.3.1.3.2.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">66.95</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S3.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span><span id="S3.T5.10.1" class="ltx_text ltx_font_bold">Ablation studies on design choices.</span> We compare different configurations of our method by either incorporating the language style embedding <math id="S3.T5.3.m1.1" class="ltx_Math" alttext="\bm{l}" display="inline"><semantics id="S3.T5.3.m1.1b"><mi id="S3.T5.3.m1.1.1" xref="S3.T5.3.m1.1.1.cmml">𝒍</mi><annotation-xml encoding="MathML-Content" id="S3.T5.3.m1.1c"><ci id="S3.T5.3.m1.1.1.cmml" xref="S3.T5.3.m1.1.1">𝒍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.3.m1.1d">\bm{l}</annotation></semantics></math> or utilizing different speech encoders <math id="S3.T5.4.m2.1" class="ltx_Math" alttext="E_{m}" display="inline"><semantics id="S3.T5.4.m2.1b"><msub id="S3.T5.4.m2.1.1" xref="S3.T5.4.m2.1.1.cmml"><mi id="S3.T5.4.m2.1.1.2" xref="S3.T5.4.m2.1.1.2.cmml">E</mi><mi id="S3.T5.4.m2.1.1.3" xref="S3.T5.4.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T5.4.m2.1c"><apply id="S3.T5.4.m2.1.1.cmml" xref="S3.T5.4.m2.1.1"><csymbol cd="ambiguous" id="S3.T5.4.m2.1.1.1.cmml" xref="S3.T5.4.m2.1.1">subscript</csymbol><ci id="S3.T5.4.m2.1.1.2.cmml" xref="S3.T5.4.m2.1.1.2">𝐸</ci><ci id="S3.T5.4.m2.1.1.3.cmml" xref="S3.T5.4.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.4.m2.1d">E_{m}</annotation></semantics></math>. ``Multi.'' and ``En.'' denote the speech encoders trained on multilingual and English-only speeches, respectively.</figcaption>
<div id="S3.T5.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:108pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(36.1pt,-9.0pt) scale(1.20005048893312,1.20005048893312) ;">
<table id="S3.T5.8.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T5.8.4.4" class="ltx_tr">
<th id="S3.T5.8.4.4.5" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S3.T5.5.1.1.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T5.5.1.1.1.1" class="ltx_text">
<span id="S3.T5.5.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T5.5.1.1.1.1.1.1" class="ltx_tr">
<span id="S3.T5.5.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S3.T5.5.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\bm{l}" display="inline"><semantics id="S3.T5.5.1.1.1.1.1.1.1.m1.1a"><mi id="S3.T5.5.1.1.1.1.1.1.1.m1.1.1" xref="S3.T5.5.1.1.1.1.1.1.1.m1.1.1.cmml">𝒍</mi><annotation-xml encoding="MathML-Content" id="S3.T5.5.1.1.1.1.1.1.1.m1.1b"><ci id="S3.T5.5.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T5.5.1.1.1.1.1.1.1.m1.1.1">𝒍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.5.1.1.1.1.1.1.1.m1.1c">\bm{l}</annotation></semantics></math></span></span>
<span id="S3.T5.5.1.1.1.1.1.2" class="ltx_tr">
<span id="S3.T5.5.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">emb.</span></span>
</span></span></th>
<th id="S3.T5.6.2.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S3.T5.6.2.2.2.1" class="ltx_text">
<span id="S3.T5.6.2.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T5.6.2.2.2.1.1.1" class="ltx_tr">
<span id="S3.T5.6.2.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S3.T5.6.2.2.2.1.1.1.1.m1.1" class="ltx_Math" alttext="E_{m}" display="inline"><semantics id="S3.T5.6.2.2.2.1.1.1.1.m1.1a"><msub id="S3.T5.6.2.2.2.1.1.1.1.m1.1.1" xref="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.2" xref="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.2.cmml">E</mi><mi id="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.3" xref="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T5.6.2.2.2.1.1.1.1.m1.1b"><apply id="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.cmml" xref="S3.T5.6.2.2.2.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="S3.T5.6.2.2.2.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.2">𝐸</ci><ci id="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="S3.T5.6.2.2.2.1.1.1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.6.2.2.2.1.1.1.1.m1.1c">E_{m}</annotation></semantics></math></span></span>
<span id="S3.T5.6.2.2.2.1.1.2" class="ltx_tr">
<span id="S3.T5.6.2.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">type</span></span>
</span></span></th>
<th id="S3.T5.7.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">LVE (<math id="S3.T5.7.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T5.7.3.3.3.m1.1a"><mo stretchy="false" id="S3.T5.7.3.3.3.m1.1.1" xref="S3.T5.7.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T5.7.3.3.3.m1.1b"><ci id="S3.T5.7.3.3.3.m1.1.1.cmml" xref="S3.T5.7.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.7.3.3.3.m1.1c">\downarrow</annotation></semantics></math>)</th>
<th id="S3.T5.8.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">AVLR (<math id="S3.T5.8.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T5.8.4.4.4.m1.1a"><mo stretchy="false" id="S3.T5.8.4.4.4.m1.1.1" xref="S3.T5.8.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T5.8.4.4.4.m1.1b"><ci id="S3.T5.8.4.4.4.m1.1.1.cmml" xref="S3.T5.8.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.8.4.4.4.m1.1c">\downarrow</annotation></semantics></math>)</th>
</tr>
<tr id="S3.T5.8.4.5.1" class="ltx_tr">
<th id="S3.T5.8.4.5.1.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T5.8.4.5.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">En</th>
<th id="S3.T5.8.4.5.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">It</th>
<th id="S3.T5.8.4.5.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">Fr</th>
<th id="S3.T5.8.4.5.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">El</th>
<th id="S3.T5.8.4.5.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">En</th>
<th id="S3.T5.8.4.5.1.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">It</th>
<th id="S3.T5.8.4.5.1.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">Fr</th>
<th id="S3.T5.8.4.5.1.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column">El</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T5.8.4.6.1" class="ltx_tr">
<th id="S3.T5.8.4.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">(a)</th>
<td id="S3.T5.8.4.6.1.2" class="ltx_td ltx_nopad_l ltx_border_t"></td>
<td id="S3.T5.8.4.6.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">Multi.</td>
<td id="S3.T5.8.4.6.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">1.78</td>
<td id="S3.T5.8.4.6.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">2.07</td>
<td id="S3.T5.8.4.6.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">2.45</td>
<td id="S3.T5.8.4.6.1.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">1.82</td>
<td id="S3.T5.8.4.6.1.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t"><span id="S3.T5.8.4.6.1.8.1" class="ltx_text ltx_font_bold">41.9</span></td>
<td id="S3.T5.8.4.6.1.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">52.4</td>
<td id="S3.T5.8.4.6.1.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">64.1</td>
<td id="S3.T5.8.4.6.1.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t"><span id="S3.T5.8.4.6.1.11.1" class="ltx_text ltx_font_bold">72.0</span></td>
</tr>
<tr id="S3.T5.8.4.7.2" class="ltx_tr">
<th id="S3.T5.8.4.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">(b)</th>
<td id="S3.T5.8.4.7.2.2" class="ltx_td ltx_nopad_l ltx_align_center">✓</td>
<td id="S3.T5.8.4.7.2.3" class="ltx_td ltx_nopad_l ltx_align_center">En.</td>
<td id="S3.T5.8.4.7.2.4" class="ltx_td ltx_nopad_l ltx_align_center">1.56</td>
<td id="S3.T5.8.4.7.2.5" class="ltx_td ltx_nopad_l ltx_align_center">1.34</td>
<td id="S3.T5.8.4.7.2.6" class="ltx_td ltx_nopad_l ltx_align_center">1.91</td>
<td id="S3.T5.8.4.7.2.7" class="ltx_td ltx_nopad_l ltx_align_center">1.37</td>
<td id="S3.T5.8.4.7.2.8" class="ltx_td ltx_nopad_l ltx_align_center">50.3</td>
<td id="S3.T5.8.4.7.2.9" class="ltx_td ltx_nopad_l ltx_align_center">55.6</td>
<td id="S3.T5.8.4.7.2.10" class="ltx_td ltx_nopad_l ltx_align_center">71.7</td>
<td id="S3.T5.8.4.7.2.11" class="ltx_td ltx_nopad_l ltx_align_center">77.3</td>
</tr>
<tr id="S3.T5.8.4.8.3" class="ltx_tr">
<th id="S3.T5.8.4.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">(c)</th>
<td id="S3.T5.8.4.8.3.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">✓</td>
<td id="S3.T5.8.4.8.3.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">Multi.</td>
<td id="S3.T5.8.4.8.3.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T5.8.4.8.3.4.1" class="ltx_text ltx_font_bold">1.16</span></td>
<td id="S3.T5.8.4.8.3.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T5.8.4.8.3.5.1" class="ltx_text ltx_font_bold">1.06</span></td>
<td id="S3.T5.8.4.8.3.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T5.8.4.8.3.6.1" class="ltx_text ltx_font_bold">1.39</span></td>
<td id="S3.T5.8.4.8.3.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">
<span id="S3.T5.8.4.8.3.7.1" class="ltx_text ltx_font_bold">1.26</span></td>
<td id="S3.T5.8.4.8.3.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">42.4</td>
<td id="S3.T5.8.4.8.3.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T5.8.4.8.3.9.1" class="ltx_text ltx_font_bold">50.5</span></td>
<td id="S3.T5.8.4.8.3.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S3.T5.8.4.8.3.10.1" class="ltx_text ltx_font_bold">63.0</span></td>
<td id="S3.T5.8.4.8.3.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">74.2</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>User study</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We incorporate human perception as a metric through a user study.
We first generate 24 3D face videos using MultiTalk (A) and compare them with those generated by existing methods (B) from the test split of the MultiTalk dataset.
We design an A vs. B test, prompting participants to choose between two samples based on lip synchronization and realism.
To accurately evaluate multilingual capability, participants from various countries participated in this study.
As indicated in Table <a href="#S3.T4" title="Table 4 ‣ Audio-Visual Lip Readability (AVLR) ‣ 3.1 Comparison with existing methods ‣ 3 Experiments ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, MultiTalk is preferred by users, notably excelling in realism compared to other methods.
These results emphasize the expressiveness and multilingual capability of our model.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Ablation study</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We conduct ablation studies to validate our design choices, as in Table <a href="#S3.T5" title="Table 5 ‣ Audio-Visual Lip Readability (AVLR) ‣ 3.1 Comparison with existing methods ‣ 3 Experiments ‣ MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Comparing (a) and (c), we observe that utilizing the language style embedding stabilizes the learning and yields favorable performance. Moreover, comparisons between (b) and (c) indicate that incorporating the multilingual speech encoder facilitates the extraction of language-agnostic features. This enables the model to focus on universal speech representations, thereby accommodating motion synthesis from multiple languages.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion and conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this work, we introduce a novel task of animating 3D talking heads from multilingual speeches.
Recognizing the lack of diversity in existing datasets for learning multilingual capabilities,
we have collected the MultiTalk dataset, consisting of 2D talking videos in multiple languages, each paired with 3D metadata and transcripts.
Moreover, we present MultiTalk, a baseline model trained in two stages on our dataset.
Considering the novelty of this task, we have devised an audio-visual lip readability metric to assess the model's multilingual capability.
Our experiments demonstrate the effectiveness of our approach, showcasing robust lip synchronization performance across diverse languages.</p>
</div>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Limitation and future work</h4>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">While our dataset offers extensive annotations, the transcripts and 3D meshes are pseudo-annotated, which might introduce some level of noise compared to human annotations. Despite this limitation, these pseudo-annotations have proven to be effective in enhancing model performance in prior arts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Future work will focus on refining these annotations.
We would like to note that our proposed multilingual video dataset and the Audio-Visual Lip Readablity metric have broader usage beyond our immediate task, <em id="S4.SS0.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">e.g</em>., (audio) visual speech recognition and 2D talking heads.
Furthermore, the rich facial motion prior learned by diverse faces across various languages holds significant potential to advance research in facial motion synthesis for further exploration.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Acknowledgments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This research was supported by a grant from KRAFTON AI, and also partially supported by Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP) grant funded by the Korea government (MSIT) (RS-2022-II220124, Development of Artificial Intelligence Technology for Self-Improving Competency-Aware Learning Capabilities; RS-2021-II212068, Artificial Intelligence Innovation Hub; RS-2019-II191906, Artificial Intelligence Graduate School Program (POSTECH)).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
C. Liu, ``An analysis of the current and future state of 3d facial animation techniques and systems,'' <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Simon Fraser University</em>, 2009.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
C. Sondermann and M. Merkt, ``Like it or learn from it: Effects of talking heads in educational videos,'' <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Education</em>, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
I. Wohlgenannt, A. Simons, and S. Stieglitz, ``Virtual reality,'' <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Business &amp; Information Systems Engineering</em>, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
D. Cudeiro, T. Bolkart, C. Laidlaw, A. Ranjan, and M. J. Black, ``Capture, learning, and synthesis of 3d speaking styles,'' in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
T. Karras, T. Aila, S. Laine, A. Herva, and J. Lehtinen, ``Audio-driven facial animation by joint end-to-end learning of pose and emotion,'' <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (SIGGRAPH)</em>, 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A. Richard, M. Zollhöfer, Y. Wen, F. De la Torre, and Y. Sheikh, ``Meshtalk: 3d face animation from speech using cross-modality disentanglement,'' in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Computer Vision (ICCV)</em>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Y. Fan, Z. Lin, J. Saito, W. Wang, and T. Komura, ``Faceformer: Speech-driven 3d facial animation with transformers,'' in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J. Xing, M. Xia, Y. Zhang, X. Cun, J. Wang, and T.-T. Wong, ``Codetalker: Speech-driven 3d facial animation with discrete motion prior,'' in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Z. Peng, H. Wu, Z. Song, H. Xu, X. Zhu, H. Liu, J. He, and Z. Fan, ``Emotalk: Speech-driven emotional disentanglement for 3d face animation,'' in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Computer Vision (ICCV)</em>, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
R. Daněček, K. Chhatre, S. Tripathi, Y. Wen, M. J. Black, and T. Bolkart, ``Emotional speech-driven animation with content-emotion disentanglement,'' in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (SIGGRAPH Asia)</em>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
K. Sung-Bin, L. Hyun, D. H. Hong, S. Nam, J. Ju, and T.-H. Oh, ``Laughtalk: Expressive 3d talking head generation with laughter,'' in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Winter Conference on Applications of Computer Vision (WACV)</em>, 2024.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
B. Thambiraja, I. Habibie, S. Aliakbarian, D. Cosker, C. Theobalt, and J. Thies, ``Imitator: Personalized speech-driven 3d facial animation,'' in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Computer Vision (ICCV)</em>, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
H. Huang, Z. Wu, S. Kang, D. Dai, J. Jia, T. Fu, D. Tuo, G. Lei, P. Liu, D. Su <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Speaker independent and multilingual/mixlingual speech-driven talking head generation using phonetic posteriorgrams,'' in <em id="bib.bib13.2.2" class="ltx_emph ltx_font_italic">2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</em>, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
G. Fanelli, J. Gall, H. Romsdorfer, T. Weise, and L. Van Gool, ``A 3-d audio-visual corpus of affective communication,'' <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em>, 2010.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
P. P. Filntisis, G. Retsinas, F. Paraperas-Papantoniou, A. Katsamanis, A. Roussos, and P. Maragos, ``Spectre: Visual speech-informed perceptual 3d facial expression reconstruction from videos,'' in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
T. Li, T. Bolkart, M. J. Black, H. Li, and J. Romero, ``Learning a model of facial shape and expression from 4d scans.'' <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (SIGGRAPH)</em>, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
E. Ng, H. Joo, L. Hu, H. Li, T. Darrell, A. Kanazawa, and S. Ginosar, ``Learning to listen: Modeling non-deterministic dyadic facial motion,'' in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A. Van Den Oord, O. Vinyals <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Neural discrete representation learning,'' in <em id="bib.bib18.2.2" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems (NeurIPS)</em>, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Z. Peng, Y. Luo, Y. Shi, H. Xu, X. Zhu, H. Liu, J. He, and Z. Fan, ``Selftalk: A self-supervised commutative training diagram to comprehend 3d talking faces,'' in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">ACM International Conference on Multimedia (MM)</em>, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. Anwar, B. Shi, V. Goswami, W.-N. Hsu, J. Pino, and C. Wang, ``Muavic: A multilingual audio-visual corpus for robust speech recognition and robust speech-to-text translation,'' in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Conference of the International Speech Communication Association (INTERSPEECH)</em>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Yu, H. Zhu, L. Jiang, C. C. Loy, W. Cai, and W. Wu, ``Celebv-text: A large-scale facial text-video dataset,'' in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. S. Chung, A. Nagrani, and A. Zisserman, ``Voxceleb2: Deep speaker recognition,'' in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Conference of the International Speech Communication Association (INTERSPEECH)</em>, 2018.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
A. Nagrani, J. S. Chung, and A. Zisserman, ``Voxceleb: a large-scale speaker identification dataset,'' in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Conference of the International Speech Communication Association (INTERSPEECH)</em>, 2017.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever, ``Robust speech recognition via large-scale weak supervision,'' in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning (ICML)</em>, 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
R. Tao, Z. Pan, R. K. Das, X. Qian, M. Z. Shou, and H. Li, ``Is someone speaking? exploring long-term temporal features for audio-visual active speaker detection,'' in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ACM International Conference on Multimedia (MM)</em>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
C. Lugaresi, J. Tang, H. Nash, C. McClanahan, E. Uboweja, M. Hays, F. Zhang, C.-L. Chang, M. G. Yong, J. Lee <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Mediapipe: A framework for building perception pipelines,'' <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.08172</em>, 2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, ``Attention is all you need,'' in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems (NeurIPS)</em>, 2017.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Y. Bengio, N. Léonard, and A. Courville, ``Estimating or propagating gradients through stochastic neurons for conditional computation,'' <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1308.3432</em>, 2013.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
A. Conneau, A. Baevski, R. Collobert, A. Mohamed, and M. Auli, ``Unsupervised cross-lingual representation learning for speech recognition,'' <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.13979</em>, 2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
H. McGurk and J. MacDonald, ``Hearing lips and seeing voices,'' <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 1976.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J. H. Yeo, M. Kim, S. Watanabe, and Y. M. Ro, ``Visual speech recognition for low-resource languages with automatic labels from whisper model,'' in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2024.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
P. Ma, A. Haliassos, A. Fernandez-Lopez, H. Chen, S. Petridis, and M. Pantic, ``Auto-avsr: Audio-visual speech recognition with automatic labels,'' in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2023.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.14271" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.14272" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.14272">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.14272" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.14273" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Jul  6 00:44:16 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
