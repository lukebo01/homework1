<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.14887] Literary and Colloquial Dialect Identification for Tamil using Acoustic Features</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Literary and Colloquial Dialect Identification for Tamil using Acoustic Features">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Literary and Colloquial Dialect Identification for Tamil using Acoustic Features">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.14887">

<!--Generated on Thu Sep  5 14:32:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Literary and Colloquial Dialect Identification for Tamil using Acoustic Features</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">M. Nanmalar
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Sri Sivasubramaniya Nadar College of Engineering, Chennai
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">P. Vijayalakshmi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Sri Sivasubramaniya Nadar College of Engineering, Chennai
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">T. Nagarajan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Sri Sivasubramaniya Nadar College of Engineering, Chennai
</span></span></span>
</div>

<section id="Sx1" class="ltx_section ltx_centering">
<h2 class="ltx_title ltx_title_section">Abstract</h2>

</section>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">The evolution and diversity of a language is evident from it’s various dialects. If the various dialects are not addressed in technological advancements like automatic speech recognition and speech synthesis, there is a chance that these dialects may disappear. Speech technology plays a role in preserving various dialects of a language from going extinct. In order to build a full fledged automatic speech recognition system that addresses various dialects, an Automatic Dialect Identification (ADI) system acting as the front end is required. This is similar to how language identification systems act as front ends to automatic speech recognition systems that handle multiple languages. The current work proposes a way to identify two popular and broadly classified Tamil dialects, namely literary and colloquial Tamil. Acoustical characteristics rather than phonetics and phonotactics are used, alleviating the requirement of language-dependant linguistic tools. Hence one major advantage of the proposed method is that it does not require an annotated corpus, hence it can be easily adapted to other languages. Gaussian Mixture Models (GMM) using Mel Frequency Cepstral Coefficient (MFCC) features are used to perform the classification task. The experiments yielded an error rate of 12%. Vowel nasalization, as being the reason for this good performance, is discussed. The number of mixture models for the GMM is varied and the performance is analysed.</p>
</div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p ltx_align_center"><span id="p2.1.1" class="ltx_text ltx_font_bold">Keywords</span>: <span id="p2.1.2" class="ltx_text ltx_font_italic">dialect identification, corpus, GMM, MFCC</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Automatic Language Identification (LID) is the problem of identifying the language from a small segment of speech uttered by an unknown speaker, with or without any prior knowledge about the target languages. Automatic LID systems can be used as a front end for Automatic Speech Recognition (ASR) and Automatic Machine Translation (AMT) systems. For example, in public service points like airports and railway stations, non native speakers buying tickets use the enquiry systems using these ASR systems. An Automatic Dialect Identification (ADI) system is similar to an LID in that, it deals with the dialects of a single language instead of multiple languages. Here, our intention is to classify Literary Tamil (LT) and Colloquial Tamil (CT). Literary Tamil is an ancient form of Tamil that is used in spoken as well as written forms. Colloquial Tamil is the modern spoken form of Tamil that is not usually used in written form. Though they belong to the same language, there is a considerable difference between LT and CT, and are hence different dialects of the Tamil language.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The problem statement of the current work is, given a speech utterance, without any prior phonotactic knowledge about both LT and CT, the system is to classify whether the test utterance belongs to LT or CT. The current work would act as one of the main components of a full-fledged dialect identification system. It can also be used in a dialect conversion system. The system will be helpful for the common man who is not accustomed to literary Tamil, but is very familiar with the colloquial one. The task is not trivial because it involves dialects of the same language. The similarity complicates the classification problem. In the current work, we propose that Gaussian Mixture Models (GMM) can aptly model the acoustic characteristics of each of these dialects and classify them. We detail how GMM is helpful in building a dialect classifier with a small error rate and how vowel nasalization, as an important cue for classification, has aided in achieving the performance.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, GMM Tokenization along with Shifted Delta Cepstra (SDC) feature vectors, which provide additional temporal information about the speech, is used. This reduced the error rate of classifying Arabic and Vietnamese languages when compared to using MFCC features. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, Mel Frequency Cepstral Coefficients (MFCC) along with formant frequencies extracted using LP spectrum are combined to form a new feature and a GMM based classifier to classify 10 languages in the OGI corpus is built. The performance of the system is compared with that of a system that uses just MFCC features, and the authors claim better performance when the new feature is used. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, GMM and PRLM techniques for LID are compared. Both GMM and HMM models are compared in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and it is found that the results are comparable. The authors also state that, the Lincoln algorithm stated in their work requires no hand labeled training data, as compared to systems that require them. This would mean that the work can be easily expanded to other languages. The authors suggest that future work can focus on building over simple statistical approaches, as compared to sophisticated methods where phonological knowledge is required. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, a multi-accent mandarin corpus developed for four different accents is used to build GMMs which classify these accents. Hence, we find that GMM based methods that use additional features with MFCC as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, or just MFCC features, can be used to obtain good classification accuracy.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The organisation of the paper is as follows: The similarities and differences of literary Tamil and colloquial Tamil are detailed in Section <a href="#S2" title="2 Linguistic Nature Of Tamil ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Corpus details are provided in section <a href="#S3" title="3 Corpus ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Section <a href="#S4" title="4 Nasalization Analysis ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> describes the challenges in identifying dialects and how it can be resolved by finding distinctive cues such as vowel nasalization. Section <a href="#S5" title="5 System Building ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> details the GMM training process and an experiment performed to identify vowel nasalization. Section <a href="#S6" title="6 Results and Discussions ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> discusses the results obtained.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Linguistic Nature Of Tamil</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">As of 2017, 70 million people read, write or speak Tamil. All of these people come under the use of different forms of Tamil, called dialects. These dialects stem from culture, region and religion. Tamil dialects can be broadly classified into literary and colloquial Tamil. The differences between literary and colloquial forms of Tamil are as mentioned below:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">While literary Tamil has a standard orthographic representation (written form) and spelling, colloquial Tamil does not possess an official standard <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite></p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">The literary form possess standard grammar, while the colloquial form does not</p>
</div>
</li>
</ul>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Within this scenario, if comparisons have to be made between literary and colloquial Tamil, they can be made in three ways:</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">Word level changes: The whole word may be different</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">Phoneme level changes: Some phonemes of the word may be different</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p">Vowel nasalisation: Vowels may be nasalized</p>
</div>
</li>
</ul>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">This comparison is explained figuratively in Fig.<a href="#S2.F1" title="Figure 1 ‣ 2 Linguistic Nature Of Tamil ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Hence, we see that methods that use orthographic representations or knowledge thereof, may not produce satisfying results. In view of this, a GMM based method that considers only the acoustic characteristics of the signal can be used to obtain better results.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<p id="S2.F1.1" class="ltx_p ltx_align_center"><span id="S2.F1.1.1" class="ltx_text"><img src="/html/2408.14887/assets/x1.png" id="S2.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="276" height="86" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples showing differences between literary and colloquial Tamil</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Corpus</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Existing Corpus</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Existing work in LID literature use the Oregon Graduate Institute Multi-Language Telephone Speech (OGI-TS) corpus as mentioned in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. The OGI corpus contains more than ten languages and their dialects. But the corpus contains telephonic speech. This makes it unsuitable for training models that will be used in all environments. Also, this corpus has a limited vocabulary. Hence, it was decided to create a corpus that is customized to deal with literary and colloquial dialects.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Corpus created in the current work</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The corpus that is created in the current work has three main features,</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">they are collected from multiple speakers</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">they are collected in multiple noise conditions - quiet lab environment, lab environment with ac on, lab environment with the fan on.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">they are also collected using different microphones namely, a condenser and a dynamic microphone, simultaneously.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Text Corpus</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The text corpus contains text for both literary and colloquial Tamil. The literary Tamil text sentences are collected from short stories, literatures and proverbs. The sources that provide literary text data are abundantly available on the world wide web. The colloquial text sources are not as abundant as the literary ones. Hence, the authors had to rely on novels, magazine articles and interviews that appear on magazines. It is not assured that the quality of these sources will be satisfactory, hence a level of verification and correction is required. The type of corrections maybe removal of literary text that may be present in between, or just phonetic or spelling corrections to bring to an approximately standard form.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Speech Corpus</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The text collected in the previous step is used as a source to develop the speech corpus. The speech for the speech corpus is contributed by people of different age groups, namely students and faculties in the institution. Both male and female speech are collected. Almost all the speakers contributed both literary and colloquial speech. The collection of colloquial speech data is challenging as there is no standardized form of writing and interpretation of colloquial Tamil text. The speech corpus is recorded sentence by sentence. The average length of each of these sentences is 5 seconds. It must be stated that this is not a parallel corpus of literary and colloquial Tamil. The text sentences are independently collected. Details of the speech corpus collected are mentioned in Table <a href="#S3.T1" title="Table 1 ‣ 3.4 Speech Corpus ‣ 3 Corpus ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Details of the corpus</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Corpus detail</span></th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">LT</span></th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">CT</span></th>
<th id="S3.T1.1.1.1.4" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S3.T1.1.1.1.5" class="ltx_td ltx_th ltx_th_column"></th>
</tr>
<tr id="S3.T1.1.2.2" class="ltx_tr">
<th id="S3.T1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Total duration of speech corpus in hours</th>
<th id="S3.T1.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">8.03</th>
<th id="S3.T1.1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">5.48</th>
<th id="S3.T1.1.2.2.4" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S3.T1.1.2.2.5" class="ltx_td ltx_th ltx_th_column"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.3.1" class="ltx_tr">
<td id="S3.T1.1.3.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Total number of speakers</td>
<td id="S3.T1.1.3.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">79</td>
<td id="S3.T1.1.3.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">77</td>
<td id="S3.T1.1.3.1.4" class="ltx_td"></td>
<td id="S3.T1.1.3.1.5" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.4.2" class="ltx_tr">
<td id="S3.T1.1.4.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Total number of male speakers</td>
<td id="S3.T1.1.4.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">24</td>
<td id="S3.T1.1.4.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25</td>
<td id="S3.T1.1.4.2.4" class="ltx_td"></td>
<td id="S3.T1.1.4.2.5" class="ltx_td"></td>
</tr>
<tr id="S3.T1.1.5.3" class="ltx_tr">
<td id="S3.T1.1.5.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Total number of female speakers</td>
<td id="S3.T1.1.5.3.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">55</td>
<td id="S3.T1.1.5.3.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">52</td>
<td id="S3.T1.1.5.3.4" class="ltx_td"></td>
<td id="S3.T1.1.5.3.5" class="ltx_td"></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">There is no overlap between the train and test speakers. The details of how the data is split between train and test is detailed in Table <a href="#S3.T2" title="Table 2 ‣ 3.4 Speech Corpus ‣ 3 Corpus ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The condenser microphone used in the setup is Rode-NT1A and the dynamic microphone used in the setup is Ahuja 100XLR.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Train and Test split up</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Detail</span></td>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Train/Test</span></td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">LT</span></td>
<td id="S3.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">CT</span></td>
</tr>
<tr id="S3.T2.1.2.2" class="ltx_tr">
<td id="S3.T2.1.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Total duration in hours</td>
<td id="S3.T2.1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Train</td>
<td id="S3.T2.1.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6’19”</td>
<td id="S3.T2.1.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3’55”</td>
</tr>
<tr id="S3.T2.1.3.3" class="ltx_tr">
<td id="S3.T2.1.3.3.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Test</td>
<td id="S3.T2.1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1’43”</td>
<td id="S3.T2.1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1’52”</td>
</tr>
<tr id="S3.T2.1.4.4" class="ltx_tr">
<td id="S3.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Total number of male speakers</td>
<td id="S3.T2.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Train</td>
<td id="S3.T2.1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21</td>
<td id="S3.T2.1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20</td>
</tr>
<tr id="S3.T2.1.5.5" class="ltx_tr">
<td id="S3.T2.1.5.5.1" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Test</td>
<td id="S3.T2.1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3</td>
<td id="S3.T2.1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6</td>
</tr>
<tr id="S3.T2.1.6.6" class="ltx_tr">
<td id="S3.T2.1.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Total number of female speakers</td>
<td id="S3.T2.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Train</td>
<td id="S3.T2.1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43</td>
<td id="S3.T2.1.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37</td>
</tr>
<tr id="S3.T2.1.7.7" class="ltx_tr">
<td id="S3.T2.1.7.7.1" class="ltx_td ltx_border_b ltx_border_l ltx_border_r"></td>
<td id="S3.T2.1.7.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">Test</td>
<td id="S3.T2.1.7.7.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">12</td>
<td id="S3.T2.1.7.7.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">15</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Nasalization Analysis</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Challenges in dialect classification</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In text independent LID tasks, phonemes and other sub-word units alone may not be sufficient enough to classify between languages. Hence it is better to look at whole sentences and derive acoustic signatures from them to identify a language. To obtain acoustic signatures, the following parameters will be required <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Phonetics - frequency of occurence of phonemes</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">Prosodics - duration and intonation of the phonemes</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Phonotactics - grammar rules for the phonemes</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">The above characteristics can be used to identify dialects as well. However, in case of dialect identification the task is more complicated since there are a lot of similarities in the use of phonetics across dialects. The words with same meaning used in two different dialects often do not change. In the case of phonetics also, not much change can be guaranteed. Besides these phonetical changes are not standardized as well. Whether this can be used as a distinctive cue is doubtful. Hence we propose that vowel nasalization can be a distinctive cue to find the difference between LT and CT.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Vowel Nasalization</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">There are three kinds of vowels that are produced when speaking in Tamil. These are,</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p">Oral vowel: Resonance occurs only in the oral cavity</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">Nasal vowel: Velum lowers and hence resonance occurs in both the oral and nasal cavity simultaneously</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p">Nasalized vowel: Vowel that is nasalized due to coarticulation induced by the neighboring phoneme. In Tamil, this is produced due to assimilation of nasal consonants. It causes an increase in vowel height.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Nasalization can occur in various degrees producing, lightly or highly nasalized vowels. If a vowel and nasal consonant occur together, it automatically causes the vowel to be nasalized <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. If the vowel is short, then the quality of nasalization varies. Such nasalization also causes the nasal consonant to be eliminated in the colloquial form. This stems from the empirical observation of literary and colloquial Tamil.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>System Building</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">In the current work only acoustic models are used and no langugage models are used. Mel Frequency Cepstral Coefficient (MFCC) features, that contain 13 each of static, velocity and acceleration coefficients (39 dimensions in total), is used to model a GMM. A GMM is a probabilistic model where weighted component gaussian densities are combined. Eq.<a href="#S5.E1" title="In 5 System Building ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> describes GMM. Here, M represents mixture weights, <span id="S5.p1.2.1" class="ltx_text ltx_markedasmath ltx_font_bold">x</span> represents data vector from 39 dimension and <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="g(\textbf{x}|\mu_{i},\sigma_{i})" display="inline"><semantics id="S5.p1.2.m2.1a"><mrow id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml"><mi id="S5.p1.2.m2.1.1.3" xref="S5.p1.2.m2.1.1.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.p1.2.m2.1.1.2" xref="S5.p1.2.m2.1.1.2.cmml">​</mo><mrow id="S5.p1.2.m2.1.1.1.1" xref="S5.p1.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.p1.2.m2.1.1.1.1.2" xref="S5.p1.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S5.p1.2.m2.1.1.1.1.1" xref="S5.p1.2.m2.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.p1.2.m2.1.1.1.1.1.4" xref="S5.p1.2.m2.1.1.1.1.1.4a.cmml">x</mtext><mo fence="false" id="S5.p1.2.m2.1.1.1.1.1.3" xref="S5.p1.2.m2.1.1.1.1.1.3.cmml">|</mo><mrow id="S5.p1.2.m2.1.1.1.1.1.2.2" xref="S5.p1.2.m2.1.1.1.1.1.2.3.cmml"><msub id="S5.p1.2.m2.1.1.1.1.1.1.1.1" xref="S5.p1.2.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S5.p1.2.m2.1.1.1.1.1.1.1.1.2" xref="S5.p1.2.m2.1.1.1.1.1.1.1.1.2.cmml">μ</mi><mi id="S5.p1.2.m2.1.1.1.1.1.1.1.1.3" xref="S5.p1.2.m2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.p1.2.m2.1.1.1.1.1.2.2.3" xref="S5.p1.2.m2.1.1.1.1.1.2.3.cmml">,</mo><msub id="S5.p1.2.m2.1.1.1.1.1.2.2.2" xref="S5.p1.2.m2.1.1.1.1.1.2.2.2.cmml"><mi id="S5.p1.2.m2.1.1.1.1.1.2.2.2.2" xref="S5.p1.2.m2.1.1.1.1.1.2.2.2.2.cmml">σ</mi><mi id="S5.p1.2.m2.1.1.1.1.1.2.2.2.3" xref="S5.p1.2.m2.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub></mrow></mrow><mo stretchy="false" id="S5.p1.2.m2.1.1.1.1.3" xref="S5.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><apply id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1"><times id="S5.p1.2.m2.1.1.2.cmml" xref="S5.p1.2.m2.1.1.2"></times><ci id="S5.p1.2.m2.1.1.3.cmml" xref="S5.p1.2.m2.1.1.3">𝑔</ci><apply id="S5.p1.2.m2.1.1.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1.1"><csymbol cd="latexml" id="S5.p1.2.m2.1.1.1.1.1.3.cmml" xref="S5.p1.2.m2.1.1.1.1.1.3">conditional</csymbol><ci id="S5.p1.2.m2.1.1.1.1.1.4a.cmml" xref="S5.p1.2.m2.1.1.1.1.1.4"><mtext class="ltx_mathvariant_bold" id="S5.p1.2.m2.1.1.1.1.1.4.cmml" xref="S5.p1.2.m2.1.1.1.1.1.4">x</mtext></ci><list id="S5.p1.2.m2.1.1.1.1.1.2.3.cmml" xref="S5.p1.2.m2.1.1.1.1.1.2.2"><apply id="S5.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.p1.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S5.p1.2.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.p1.2.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S5.p1.2.m2.1.1.1.1.1.1.1.1.2">𝜇</ci><ci id="S5.p1.2.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S5.p1.2.m2.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S5.p1.2.m2.1.1.1.1.1.2.2.2.cmml" xref="S5.p1.2.m2.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.p1.2.m2.1.1.1.1.1.2.2.2.1.cmml" xref="S5.p1.2.m2.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S5.p1.2.m2.1.1.1.1.1.2.2.2.2.cmml" xref="S5.p1.2.m2.1.1.1.1.1.2.2.2.2">𝜎</ci><ci id="S5.p1.2.m2.1.1.1.1.1.2.2.2.3.cmml" xref="S5.p1.2.m2.1.1.1.1.1.2.2.2.3">𝑖</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">g(\textbf{x}|\mu_{i},\sigma_{i})</annotation></semantics></math> represents the component Guassian densities. Each density component contains its own mean, covariance and mixture weight. MFCC is a perceptual filtering technique which is used commonly for extraction of features from speech signals.</p>
</div>
<div id="S5.p2" class="ltx_para">
<table id="S5.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E1.m1.2" class="ltx_Math" alttext="p(\textbf{x}|\lambda)=\sum_{i=1}^{M}w_{i}g(\textbf{x}|\mu_{i},\sigma_{i})" display="block"><semantics id="S5.E1.m1.2a"><mrow id="S5.E1.m1.2.2" xref="S5.E1.m1.2.2.cmml"><mrow id="S5.E1.m1.1.1.1" xref="S5.E1.m1.1.1.1.cmml"><mi id="S5.E1.m1.1.1.1.3" xref="S5.E1.m1.1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.1.1.1.2" xref="S5.E1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.E1.m1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E1.m1.1.1.1.1.1.2" xref="S5.E1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E1.m1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.E1.m1.1.1.1.1.1.1.2" xref="S5.E1.m1.1.1.1.1.1.1.2a.cmml">x</mtext><mo fence="false" id="S5.E1.m1.1.1.1.1.1.1.1" xref="S5.E1.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S5.E1.m1.1.1.1.1.1.1.3" xref="S5.E1.m1.1.1.1.1.1.1.3.cmml">λ</mi></mrow><mo stretchy="false" id="S5.E1.m1.1.1.1.1.1.3" xref="S5.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S5.E1.m1.2.2.3" xref="S5.E1.m1.2.2.3.cmml">=</mo><mrow id="S5.E1.m1.2.2.2" xref="S5.E1.m1.2.2.2.cmml"><munderover id="S5.E1.m1.2.2.2.2" xref="S5.E1.m1.2.2.2.2.cmml"><mo movablelimits="false" id="S5.E1.m1.2.2.2.2.2.2" xref="S5.E1.m1.2.2.2.2.2.2.cmml">∑</mo><mrow id="S5.E1.m1.2.2.2.2.2.3" xref="S5.E1.m1.2.2.2.2.2.3.cmml"><mi id="S5.E1.m1.2.2.2.2.2.3.2" xref="S5.E1.m1.2.2.2.2.2.3.2.cmml">i</mi><mo id="S5.E1.m1.2.2.2.2.2.3.1" xref="S5.E1.m1.2.2.2.2.2.3.1.cmml">=</mo><mn id="S5.E1.m1.2.2.2.2.2.3.3" xref="S5.E1.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S5.E1.m1.2.2.2.2.3" xref="S5.E1.m1.2.2.2.2.3.cmml">M</mi></munderover><mrow id="S5.E1.m1.2.2.2.1" xref="S5.E1.m1.2.2.2.1.cmml"><msub id="S5.E1.m1.2.2.2.1.3" xref="S5.E1.m1.2.2.2.1.3.cmml"><mi id="S5.E1.m1.2.2.2.1.3.2" xref="S5.E1.m1.2.2.2.1.3.2.cmml">w</mi><mi id="S5.E1.m1.2.2.2.1.3.3" xref="S5.E1.m1.2.2.2.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.2.1.2" xref="S5.E1.m1.2.2.2.1.2.cmml">​</mo><mi id="S5.E1.m1.2.2.2.1.4" xref="S5.E1.m1.2.2.2.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.E1.m1.2.2.2.1.2a" xref="S5.E1.m1.2.2.2.1.2.cmml">​</mo><mrow id="S5.E1.m1.2.2.2.1.1.1" xref="S5.E1.m1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S5.E1.m1.2.2.2.1.1.1.2" xref="S5.E1.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S5.E1.m1.2.2.2.1.1.1.1" xref="S5.E1.m1.2.2.2.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.E1.m1.2.2.2.1.1.1.1.4" xref="S5.E1.m1.2.2.2.1.1.1.1.4a.cmml">x</mtext><mo fence="false" id="S5.E1.m1.2.2.2.1.1.1.1.3" xref="S5.E1.m1.2.2.2.1.1.1.1.3.cmml">|</mo><mrow id="S5.E1.m1.2.2.2.1.1.1.1.2.2" xref="S5.E1.m1.2.2.2.1.1.1.1.2.3.cmml"><msub id="S5.E1.m1.2.2.2.1.1.1.1.1.1.1" xref="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.2" xref="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.2.cmml">μ</mi><mi id="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.3" xref="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.E1.m1.2.2.2.1.1.1.1.2.2.3" xref="S5.E1.m1.2.2.2.1.1.1.1.2.3.cmml">,</mo><msub id="S5.E1.m1.2.2.2.1.1.1.1.2.2.2" xref="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.cmml"><mi id="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.2" xref="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.2.cmml">σ</mi><mi id="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.3" xref="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.3.cmml">i</mi></msub></mrow></mrow><mo stretchy="false" id="S5.E1.m1.2.2.2.1.1.1.3" xref="S5.E1.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.2b"><apply id="S5.E1.m1.2.2.cmml" xref="S5.E1.m1.2.2"><eq id="S5.E1.m1.2.2.3.cmml" xref="S5.E1.m1.2.2.3"></eq><apply id="S5.E1.m1.1.1.1.cmml" xref="S5.E1.m1.1.1.1"><times id="S5.E1.m1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.2"></times><ci id="S5.E1.m1.1.1.1.3.cmml" xref="S5.E1.m1.1.1.1.3">𝑝</ci><apply id="S5.E1.m1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.E1.m1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S5.E1.m1.1.1.1.1.1.1.2a.cmml" xref="S5.E1.m1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.E1.m1.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.1.1.1.1.1.1.2">x</mtext></ci><ci id="S5.E1.m1.1.1.1.1.1.1.3.cmml" xref="S5.E1.m1.1.1.1.1.1.1.3">𝜆</ci></apply></apply><apply id="S5.E1.m1.2.2.2.cmml" xref="S5.E1.m1.2.2.2"><apply id="S5.E1.m1.2.2.2.2.cmml" xref="S5.E1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.2.2.1.cmml" xref="S5.E1.m1.2.2.2.2">superscript</csymbol><apply id="S5.E1.m1.2.2.2.2.2.cmml" xref="S5.E1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.2.2.2.1.cmml" xref="S5.E1.m1.2.2.2.2">subscript</csymbol><sum id="S5.E1.m1.2.2.2.2.2.2.cmml" xref="S5.E1.m1.2.2.2.2.2.2"></sum><apply id="S5.E1.m1.2.2.2.2.2.3.cmml" xref="S5.E1.m1.2.2.2.2.2.3"><eq id="S5.E1.m1.2.2.2.2.2.3.1.cmml" xref="S5.E1.m1.2.2.2.2.2.3.1"></eq><ci id="S5.E1.m1.2.2.2.2.2.3.2.cmml" xref="S5.E1.m1.2.2.2.2.2.3.2">𝑖</ci><cn type="integer" id="S5.E1.m1.2.2.2.2.2.3.3.cmml" xref="S5.E1.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S5.E1.m1.2.2.2.2.3.cmml" xref="S5.E1.m1.2.2.2.2.3">𝑀</ci></apply><apply id="S5.E1.m1.2.2.2.1.cmml" xref="S5.E1.m1.2.2.2.1"><times id="S5.E1.m1.2.2.2.1.2.cmml" xref="S5.E1.m1.2.2.2.1.2"></times><apply id="S5.E1.m1.2.2.2.1.3.cmml" xref="S5.E1.m1.2.2.2.1.3"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.2.1.3.1.cmml" xref="S5.E1.m1.2.2.2.1.3">subscript</csymbol><ci id="S5.E1.m1.2.2.2.1.3.2.cmml" xref="S5.E1.m1.2.2.2.1.3.2">𝑤</ci><ci id="S5.E1.m1.2.2.2.1.3.3.cmml" xref="S5.E1.m1.2.2.2.1.3.3">𝑖</ci></apply><ci id="S5.E1.m1.2.2.2.1.4.cmml" xref="S5.E1.m1.2.2.2.1.4">𝑔</ci><apply id="S5.E1.m1.2.2.2.1.1.1.1.cmml" xref="S5.E1.m1.2.2.2.1.1.1"><csymbol cd="latexml" id="S5.E1.m1.2.2.2.1.1.1.1.3.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.3">conditional</csymbol><ci id="S5.E1.m1.2.2.2.1.1.1.1.4a.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.4"><mtext class="ltx_mathvariant_bold" id="S5.E1.m1.2.2.2.1.1.1.1.4.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.4">x</mtext></ci><list id="S5.E1.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.2.2"><apply id="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.2">𝜇</ci><ci id="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.1.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.2.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.2">𝜎</ci><ci id="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.3.cmml" xref="S5.E1.m1.2.2.2.1.1.1.1.2.2.2.3">𝑖</ci></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.2c">p(\textbf{x}|\lambda)=\sum_{i=1}^{M}w_{i}g(\textbf{x}|\mu_{i},\sigma_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">A GMM is built for LT and CT separately using the 39 dimensional MFCC features mentioned above. Cepstral mean subtraction is performed on the features in order to reduce the influence caused by the environment in which the audio is recorded for training. The same is applied during the testing phase as well. The number of mixture components of the GMM is varied and the performance is analysed. Depending on the data, the number of GMM components/mixtures can affect the performance of the system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. But as the number of mixture components are increased, the computational complexity also increases. The best performance of the system is 87% and it can be justified using the vowel nasalisation experiment explained in <a href="#S5.SS1" title="5.1 Experiment on vowel nasalisation ‣ 5 System Building ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>. The details of the performance are discussed in section <a href="#S6" title="6 Results and Discussions ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a></p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experiment on vowel nasalisation</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">As mentioned in the previous section, a vowel takes the form of a nasalized vowel because of the assimilation of the nasal consonant right next to it. A point to note is that the degree of nasalisation differs between literary Tamil and colloquial Tamil. In the case of literary Tamil, it is lightly nasalized, and in the case of colloquial Tamil it is highly nasalized.</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">In literary Tamil, when the vowel is nasalized by the nasal consonant that follows it, the influence of both the vowel and the consonant sounds is present</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">In colloquial Tamil, when the vowel is nasalized by the nasal consonant that follows it, it assimilates into a nasalized vowel, eliminating the nasal consonant in the process</p>
</div>
</li>
</ul>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Hence the degree of nasalization is high in colloquial Tamil, due to the elimination of nasal consonant. This concept is proved by a simple experiment where the characteristics of a nasal vowel is analysed in both literary Tamil and colloquial Tamil, as explained in detail below.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Mostly vowel nasalisation happens in the word boundary. In Tamil, nasal consonants that occur in word boundary are the phonemes ’m’ and ’n’. In this experiment, we acoustically analyse the long vowel ’aa’ in context with ’m’ and ’n’. We analyse its degree of nasalization and its correspondence with literary Tamil and colloquial Tamil. We record single words which contain ’m’ or ’n’ as the end phoneme, and preceeded by ’aa’, to show the nature of nasalisation in a single vowel. The segment at the end of the word is taken for analysis. The vowel nasal segment is divided into 20 ms frames, and the formants are extracted from the LP spectrum.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, it is shown that when the vowel ’aa’ followed by one of the two nasal consonants ’m’ or ’n’ exhibits nasalization, with a formant peak around 250Hz. In our experiment, we observed the same characteristic. In order to check the degree of nasalization, the magnitude of the formant peak is measured. When empirically measuring the magnitude of the peaks of nasalized vowels in colloquial and literary Tamil, we observe that colloquial Tamil consistently has stronger formants compared to literary Tamil. This phenomenon is graphically represented in Fig. <a href="#S5.F2" title="Figure 2 ‣ 5.1 Experiment on vowel nasalisation ‣ 5 System Building ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a></p>
</div>
<figure id="S5.F2" class="ltx_figure">
<p id="S5.F2.1" class="ltx_p ltx_align_center"><span id="S5.F2.1.1" class="ltx_text"><img src="/html/2408.14887/assets/x2.png" id="S5.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="392" height="205" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Comparison of the degree of nasalization of vowel ’aa’ in literary and colloquial Tamil</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results and Discussions</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The details of the test corpus is listed in Table <a href="#S3.T2" title="Table 2 ‣ 3.4 Speech Corpus ‣ 3 Corpus ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Each test utterance contains a sentence of speech. Testing is performed sentence by sentence. The maximum likelihood of a particular test utterance is calculated with respect to GMMs built for literary and colloquial Tamil. The one which has higher likelihood is chosen as the class for a particular test utterance. It must be noted that the average length of a test utterance is 5s. Even with such short utterences, the system is able to classify the literary and colloquial forms. Even though there are a lot of phonetic similarities between literary and colloquial forms, the results are promising.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">The mixture components of the GMM are varied and the performance is analysed in each case. It is observed that for the corpus as detailed in Table <a href="#S3.T1" title="Table 1 ‣ 3.4 Speech Corpus ‣ 3 Corpus ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S3.T2" title="Table 2 ‣ 3.4 Speech Corpus ‣ 3 Corpus ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, best classification performance of 88% is achieved with 256 mixture components. In this case, considering literary Tamil as the positive condition, the precision, recall and F1 measure are computed and found to be 0.82, 0.89 and 0.85 respectively. The results are detailed in Table <a href="#S6.T3" title="Table 3 ‣ 6 Results and Discussions ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a></p>
</div>
<figure id="S6.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance Comparison for Various Mixture Components</figcaption>
<table id="S6.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T3.1.1.1" class="ltx_tr">
<td id="S6.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S6.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Number of Components</span></td>
<td id="S6.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Performance (%)</span></td>
<td id="S6.T3.1.1.1.3" class="ltx_td"></td>
<td id="S6.T3.1.1.1.4" class="ltx_td"></td>
</tr>
<tr id="S6.T3.1.2.2" class="ltx_tr">
<td id="S6.T3.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">16</td>
<td id="S6.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">84.89</td>
<td id="S6.T3.1.2.2.3" class="ltx_td"></td>
<td id="S6.T3.1.2.2.4" class="ltx_td"></td>
</tr>
<tr id="S6.T3.1.3.3" class="ltx_tr">
<td id="S6.T3.1.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">32</td>
<td id="S6.T3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.06</td>
<td id="S6.T3.1.3.3.3" class="ltx_td"></td>
<td id="S6.T3.1.3.3.4" class="ltx_td"></td>
</tr>
<tr id="S6.T3.1.4.4" class="ltx_tr">
<td id="S6.T3.1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">64</td>
<td id="S6.T3.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.40</td>
<td id="S6.T3.1.4.4.3" class="ltx_td"></td>
<td id="S6.T3.1.4.4.4" class="ltx_td"></td>
</tr>
<tr id="S6.T3.1.5.5" class="ltx_tr">
<td id="S6.T3.1.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">128</td>
<td id="S6.T3.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.72</td>
<td id="S6.T3.1.5.5.3" class="ltx_td"></td>
<td id="S6.T3.1.5.5.4" class="ltx_td"></td>
</tr>
<tr id="S6.T3.1.6.6" class="ltx_tr">
<td id="S6.T3.1.6.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">256</td>
<td id="S6.T3.1.6.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">88.00</td>
<td id="S6.T3.1.6.6.3" class="ltx_td"></td>
<td id="S6.T3.1.6.6.4" class="ltx_td"></td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">From Table <a href="#S6.T3" title="Table 3 ‣ 6 Results and Discussions ‣ Literary and Colloquial Dialect Identification for Tamil using Acoustic Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, it is seen that, as the number of mixtures or, component gaussians increase, the performance also increases. But as the number of component gaussians are increased, the computational complexity also increases. For example, on a computer runnning on i5 processor with 8GB ram, it took 4 days for the models to be built. Since the performance has not increased considerably, we may trade off for better computational complexity, when there is a need.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">A GMM based classifier for idenfiying literary and colloquial Tamil is built. GMMs have been used in the past for language and dialect identification systems, but it has not been used in classifying Tamil dialects. Compared to other dialect classification attempts as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, the proposed method performs better with an error rate of just 12%. Considering the similarities between literary and colloquial Tamil, this is a commendable score. The justification of this performance is provided by the vowel nasalization analysis.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">The biggest advantage of the proposed method is that no transcription is needed. This means that, the methodology can be extended to other dialects in Tamil as well. The process is efficient in that, it eliminates the need for time-aligned transcription of the wave files, and language models. The dataset can be further extended by simply requesting users/participants to speak in a given dialect. This will increase the taining data, and cause an increase in performance. The solution achieved is simple and efficient.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">In the future, dialect identification systems can be built with transcriptions and the results can be compared with the current work. Deeper analysis on the importance of nasalization in dialect identification can be performed.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
P. A. Torres-Carrasquillo, E. Singer, M. A. Kohler, R. J. Greene, D. A.
Reynolds, and J. R. Deller Jr, “Approaches to language identification using
gaussian mixture models and shifted delta cepstral features,” in <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Seventh International Conference on Spoken Language Processing</span>, pp. 89–92,
2002.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S. Manchala, V. K. Prasad, and V. Janaki, “Gmm based language identification
system using robust features,” <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">International Journal of Speech
Technology</span>, vol. 17, no. 2, pp. 99–105, 2014.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. A. Zissman, “Comparison of four approaches to automatic language
identification of telephone speech,” <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on speech and
audio processing</span>, vol. 4, no. 1, p. 31, 1996.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Zissman, “Automatic language identification using gaussian mixture and
hidden markov models,” in <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Acoustics,
Speech, and Signal Processing</span>, vol. 2, pp. 399–402, IEEE, 1993.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
T. Chen, C. Huang, E. Chang, and J. Wang, “Automatic accent identification
using gaussian mixture models,” in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">IEEE Workshop on Automatic Speech
Recognition and Understanding, 2001. ASRU’01.</span>, pp. 343–346, IEEE, 2001.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
E. Keane, “Tamil,” <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Journal of the International Phonetic Association</span>,
vol. 34, no. 1, pp. 111–116, 2004.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Y. K. Muthusamy, E. Barnard, and R. A. Cole, “Reviewing automatic language
identification,” <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">IEEE Signal Processing Magazine</span>, vol. 11, no. 4,
pp. 33–41, 1994.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
P. Vijayalakshmi, M. R. Reddy, and D. O’Shaughnessy, “Acoustic analysis and
detection of hypernasality using a group delay function,” <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">IEEE
Transactions on biomedical engineering</span>, vol. 54, no. 4, pp. 621–629, 2007.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.14886" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.14887" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.14887">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.14887" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.14888" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 14:32:31 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
