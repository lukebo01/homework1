<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.02166] Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision</title><meta property="og:description" content="There exist three approaches for multilingual and crosslingual automatic speech recognition (MCL-ASR) - supervised pre-training with phonetic or graphemic transcription, and self-supervised pre-training.
We find that p…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.02166">

<!--Generated on Fri Jul  5 22:14:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
speech recognition,  multilingual,  crosslingual,  data-efficient,  IPA.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Saierdaer Yusuyin, Te Ma, Hao Huang,  , Wenbo Zhao, Zhijian Ou
</span><span class="ltx_author_notes">This work was supported by National Science and Technology Major Project (2023ZD0121401), Guangxi Science and Technology Project (2022AC16002).
Corresponding author and principal investigator of this work: Zhijian Ou.Saierdaer Yusuyin, Te Ma, Hao Huang are with the School of Computer Science and Technology, Xinjiang University, Urumqi 830046, China (e-mail: sar_dar@foxmail.com; mate153125@gmail.com; huanghao@xju.edu.cn)Wenbo Zhao is with the China Unicom (Guangdong) Industrial Internet Co., Ltd, Guangzhou 510555, China
(e-mail: zhaowb19@chinaunicom.cn)Zhijian Ou is with the Speech Processing and Machine Intelligence (SPMI) Lab, Department of Electronic Engineering, Tsinghua University, Beijing 100084, China,
(e-mail: ozj@tsinghua.edu.cn)</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">There exist three approaches for multilingual and crosslingual automatic speech recognition (MCL-ASR) - supervised pre-training with phonetic or graphemic transcription, and self-supervised pre-training.
We find that pre-training with phonetic supervision has been underappreciated so far for MCL-ASR, while conceptually it is more advantageous for information sharing between different languages.
This paper explores the approach of pre-training with weakly phonetic supervision towards data-efficient MCL-ASR, which is called Whistle.
We relax the requirement of gold-standard human-validated phonetic transcripts, and obtain International Phonetic Alphabet (IPA) based transcription by leveraging the LanguageNet grapheme-to-phoneme (G2P) models.
We construct a common experimental setup based on the CommonVoice dataset, called CV-Lang10, with 10 seen languages and 2 unseen languages.
A set of experiments are conducted on CV-Lang10 to compare, as fair as possible, the three approaches under the common setup for MCL-ASR.
Experiments demonstrate the advantages of phoneme-based models (Whistle) for MCL-ASR, in terms of speech recognition for seen languages, crosslingual performance for unseen languages with different amounts of few-shot data, overcoming catastrophic forgetting, and training efficiency.
It is found that when training data is more limited, phoneme supervision can achieve better results compared to subword supervision and self-supervision, thereby providing higher data-efficiency.
To support reproducibility and promote future research along this direction, we will release the code, models and data for the whole pipeline of Whistle at <a target="_blank" href="https://github.com/thu-spmi/CAT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/thu-spmi/CAT</a> upon publication.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
speech recognition, multilingual, crosslingual, data-efficient, IPA.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent years, deep neural network (DNN) based automatic speech recognition (ASR) systems have achieved significant progress, which are, however, data-hungry. A substantial amount of transcribed speech data are required for model training. There are more than 7,000 languages spoken around the world <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, but due to the lack of training data, only a small fraction of them benefit from current ASR technology. An important challenge for the speech community is that we can develop ASR systems to new unsupported languages rapidly and at reasonable costs. Multilingual and crosslingual ASR (MCL-ASR) have been studied as an effective way to address this problem.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">multilingual speech recognition</em>, training data for a number of languages, often referred to as seen languages, are merged to train a multilingual model, which can be used to recognize speech from all seen languages. The multilingual model can also serve as a pre-trained model, which can be further fine-tuned for crosslingual speech recognition.
<em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">Crosslingual speech recognition</em> refers to recognizing utterances in a new language, which is unseen in training the multilingual model.
From machine learning perspective, such multilingual and crosslingual training can be regarded as performing multi-task learning and transfer learning, which promotes sharing of statistical strength.
The advantage is that the ASR performance for low-resource languages, both seen and unseen, can be improved, and the cost of system building and maintenance for multiple languages can be reduced as well.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The general concept of multilingual and crosslingual speech recognition has been applied for a long time, dating back to the time when GMM-HMM based classic models and then DNN-HMM based hybrid models are prevalent in ASR research, to name a few, e.g., in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> respectively.
Recently, end-to-end models have emerged <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, which can be directly trained from phonetic or graphemic transcription, eliminating the first pass of producing HMM state alignment.
For end-to-end models, the approach of pre-training followed by fine-tuning has attracted increasing interests and achieved good performance.
There are mainly two classes of pre-training methods, based on either self-supervised learning or supervised learning.
Self-supervised pre-training is conducted over unlabeled speech data from multiple languages for speech representation learning in general <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Supervised pre-training, by applying end-to-end models on multilingual labeled speech data, can be further divided into two sub-categories of research, which are contrasted by using different types of modeling units.
The first is grapheme-based or subword-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, which, collectively referred to as based on graphemic transcription (orthography), creates a shared token set across multiple languages, e.g., using 10K sentence pieces <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
The second trains end-to-end models on phonetic transcriptions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, which usually utilizes International Phonetic Alphabet (IPA) symbols to create a (nearly-)universal phone inventory, e.g., using 187 phones <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Intuitively, the key to successful multilingual and crosslingual recognition is to optimize information sharing during multilingual training and maximize the knowledge transferring from a well trained multilingual model to the model trained for recognizing utterances in a new language <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
Taking this perspective, we could examine the pros and cons of the three approaches - <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">supervised pre-training with graphemic transcription or phonetic transcription, and self-supervised pre-training</em>, which is detailed in Section <a href="#S2" title="II Related work ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">While requiring pronunciation lexicons, pre-training with phonetic supervision is more advantageous for information sharing between different languages. For phonetic supervision, IPA symbols include enough symbols to represent the fundamental sounds of all languages, and sounds in different languages share these phonetic representations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.
In contrast, graphemes and subwords are in fact from writing systems of languages (orthography), not for describing and distinguishing all the sounds in human language throughout the world, which is exactly phonetic transcription does.
Creating a graphemic token set from multiple languages for supervision is non-trivial and delicately affects ASR performance; until recently, tokenization strategy is still under investigation and needs a balance between granularity and ASR performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>; adding new languages for crosslingual recognition further complicates the design of tokenization.
Besides the above theoretical analysis of supervised pre-training with graphemic transcription and phonetic transcription, an interesting research question is about empirical comparison.
It has been empirically found that compared to learning with graphemic supervision, learning with phonetic supervision performs equally strong and tends to be more <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">data-efficient</em> in monolingual ASR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
But to the best of our knowledge, there have been no solid experiments to study which approach is better or if they yields similar results for MCL-ASR, when evaluated in a common experimental setup (Research Question 1, referred to as RQ-1).</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To address the problem of requiring phonetic transcription for phonetic supervision, we note that phonetic resources and tools have been steadily developed over these years and are easily accessible, including grapheme-to-phoneme (G2P) models and tools <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, phoneme inventories <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
We can relax the requirement of gold-standard human-validated transcripts, and in this paper, we obtain the IPA phonetic transcripts by leveraging the LanguageNet G2P models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.
The LanguageNet G2P models are available for 142 languages, with the phoneme error rates (PERs) ranging from 7% to 45%.
So the main aim of this paper is to investigate weakly supervised pre-training with somewhat noisy phonetic transcription. This is in spirit similar to the work in Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. But instead of using weakly graphemic supervision in Whisper, our work employs weakly phonetic supervision.
We call the approach investigated in this paper: Whistle (<span id="S1.p6.1.1" class="ltx_text ltx_framed ltx_framed_underline">W</span>eakly p<span id="S1.p6.1.2" class="ltx_text ltx_framed ltx_framed_underline">h</span>onetic superv<span id="S1.p6.1.3" class="ltx_text ltx_framed ltx_framed_underline">i</span>sion <span id="S1.p6.1.4" class="ltx_text ltx_framed ltx_framed_underline">st</span>rategy for multilingua<span id="S1.p6.1.5" class="ltx_text ltx_framed ltx_framed_underline">l</span> and crosslingual sp<span id="S1.p6.1.6" class="ltx_text ltx_framed ltx_framed_underline">e</span>ech recognition).</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">A secondary interesting research question is to compare supervised pre-training and self-supervised/un-supervised pre-training. Basically, we agree with the comments in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Current pre-trained models for speech such as based on wav2vec 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> aim to learn speech representation in general over unlabeled data; They mostly are encoder-only and thus lack an equivalently performant decoder, which requires at least adding a classifier layer and supervised finetuning over labeled data even for seen languages. These comments, presumably, are suited to comparing self-supervision to both graphemic supervision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and phonetic supervision (our work).
These being said, to the best of our knowledge, there have been no strict experiments to study which approach is better or if they yields similar results for MCL-ASR, when evaluated in equal settings (Research Question 2, referred to as RQ-2).</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">In summary, this paper explores supervised pre-training with weakly phonetic supervision, towards data-efficient multilingual and crosslingual speech recognition. Our main contributions are as follows.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We construct a common experimental setup based on the CommonVoice dataset, called CV-Lang10, to evaluate multilingual and crosslingual speech recognition, with 10 seen languages and 2 unseen languages, measuring both phoneme error rate (PER) and word error rate (WER). A set of experiments are conducted on CV-Lang10 to compare, as fair as possible, the three approaches under the common setup - supervised pre-training with graphemic transcription or weakly phonetic transcription, and self-supervised pre-training for MCL-ASR.
These experiments present our effort to answer RQ-1 and RQ-2.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We develop Whistle, an approach to data-efficient multilingual and crosslingual speech recognition via weakly phonetic supervision, including the whole pipeline of data processing, model training and testing. Experiments demonstrate the advantages of Whistle for MCL-ASR, in terms of speech recognition for seen languages, crosslingual performance for unseen languages with different amounts of few-shot data, overcoming catastrophic forgetting, and training efficiency.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Many prior works on multilingual and crosslingual speech recognition were conducted on internal or proprietary datasets such as GlobalPhone <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and IARPA Babel<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.iarpa.gov/index.php/research-programs/babel" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.iarpa.gov/index.php/research-programs/babel</a></span></span></span>, which are not openly-available.
We find that supervised pre-training with phonetic supervision has been underappreciated so far for MCL-ASR. To promote future research along this direction, we release the code, models and data for the whole pipeline of Whistle at the following URL: <a target="_blank" href="https://github.com/thu-spmi/CAT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/thu-spmi/CAT</a>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related work</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">MCL-ASR with phonetic supervision</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Research in multilingual and cross-lingual ASR has long been motivated by phonetics and has used phonetic supervision, e.g., in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, to name a few.
The major phonetic alphbet in use is the International Phonetic Alphabet (IPA), which includes modified Roman letters and diacritics, by means of which the sounds of all human languages can be represented <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.
So a common practice is to combine the phonetic inventory of all languages to be recognized into a global phoneme set, often based on IPA.
Employing phonetic units is, presumably, the most intuitive way to promote information sharing and learn language-universal representations for MCL-ASR.
Modeling based on phonetic supervision further allows to pursue finer level of information sharing by decomposing phones into a list of phonological articulatory attributes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">To address the problem of requiring phonetic transcription for phonetic supervision, there have been steady efforts to develop phonetic resources and tools. Epitran provides a 61-language rule-based open-source G2P tool <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>; the LanguageNet includes FST (Finite State Transducer) based G2P models in nearly 150 languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, and PHOIBLE compiles a database of phone inventories for more than 2000 languages and dialects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Based on these phonetic resources and tools, there has been continuous studies. Base on Epitran G2P, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> first predicts over a shared phone inventory, and then introduces an allophone layer to map into language-specific phonemes. 11 training languages and 2 unseen languages were used. Based on LanuageNet G2P, monolingual, multilingual and (zero-shot) crosslingual CTC models are trained over 13 languages in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, with the output layer consisting of IPA symbols. Every modifier symbol is treated as a separate token, and so phonetic token error rates (PTERs) are measured. Compared to monolingual models, it reports major PTER improvements across all 13 languages in the multilingual setup, and stark degradation in the crosslingual systems.
The recent studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> mainly investigate universal phone recognition. There remains an interesting question, as also raised in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, whether improvements in error rates would also be observed in downstream metrics such as WER. Another related question is which approach of phonetic and graphemic supervision is better for MCL-ASR (RQ-1), since no comparison is conducted in these recent multilingual studies.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">MCL-ASR with graphemic supervision</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Graphemic transcription (orthography), as a part of the writing system in a language, does not represent the sounds of a language in a consistent way <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. In many languages, there is a discrepancy between graphemic transcription and phonetic transcription.
With the learning power of deep neural networks, people has begun to build ASR systems with the output layer consisting of graphemic units such as characters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, subwords <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, or words <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, initially for monolingual ASR and
recently applied to MCL-ASR.
Using graphemic supervision eliminates the requirement of pronunciation lexicons for different languages and simplifies the pipeline of MCL-ASR. On the other hand, pooling and creating a large set of graphemic tokens from multiple languages brings the label sparsity issue and the resulting MCL-ASR systems tend to be <em id="S2.SS2.p1.1.1" class="ltx_emph ltx_font_italic">data-hungry</em>, and tokenization scheme is an active research question <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Thanks to larger and larger amounts of transcribed speech data and increasingly large neural networks, subword-based supervised pre-training has obtained better and better performance and become a widely adopted strategy in industry to build MCL-ASR systems for increasingly many languages.
For example, the Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> models use the a Byte-Pair Encoding (BPE) text tokenizer and are trained over 680,000 hours cleaned web data by weakly graphemic supervision, capable of recognizing speech from 97 languages.
While achieving impressive performance, recent advances in large MCL-ASR models are presumably an effect of scaling power, and it is hard to argue that the good results are not due to having additional data, nor due to the large neural architecture.
It remains unclear which approach (phonetic supervision or grapheme supervision) is better when evaluated in an equal experimental setting, or if they produce similar results for MCL-ASR. This paper presents our preliminary effort to answer this question (RQ-1).
</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">MCL-ASR with self-supervision</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Self-supervised learning methods mainly refer to some recent learning methods based on contrastive learning such as wav2vec 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> or masking prediction such as BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, which can still be regarded as unsupervised learning methods from a classical perspective (no data annotation is required). Therefore, the literature often does not strictly distinguish between unsupervised and self-supervised learning methods in terms of terminology, and we can collectively referred to them as unsupervised learning methods.
Self-supervised learning methods such as wav2vec 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> have been proposed to learn speech representation in general from multilingual unlabeled speech data.
Based on wav2vec 2.0, XLS-R models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> are trained on unlabeled data from 128 languages.
In the recent Massively Multilingual Speech (MMS) project <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, wav2vec 2.0 based models are pre-trained over 1,406 languages, and CTC based multilingual ASR models for 1,107 languages are then fine-tuned using labeled data for each language. Specifically, a linear layer is added on top of pre-trained MMS models which maps to an output vocabulary which is the set of letters in the labeled training data, and is then fine-tuned with the CTC loss.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">As commented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, while current unsupervised pre-training has improved the quality of audio encoders, the lack of an equivalently high-quality pre-trained decoder is a crucial weakness which limits their usefulness. In the following, we provide a closely related comment. We find that current unsupervised pre-training methods in learning audio encoders such as wav2vec 2.0 does not satisfy the so-called principled unsupervised learning, since ``the unsupervised objective may be unrelated to the supervised task of interest'' <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. In contrast, the GPT based unsupervised pre-training method for natural language processing (NLP) tasks is principled, since the supervised objective is the same as (closely related to) the unsupervised objective but only evaluated on a subset of the sequence in NLP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.
For ASR tasks, these comments favor supervised pre-training (either grapheme-supervision or phonetic supervision) over the current unsupervised pre-training.
These being said, remarkably, it has been known in various machine learning tasks that supervised and unsupervised training methods are not mutually exclusive and could be jointly used to define semi-supervised learning, e.g., in image classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, speech recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, natural language labeling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, dialog systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.
A complete investigation into semi-supervised learning for ASR is outside the scope of this paper.
This paper presents a straightforward empirical comparison between self-supervision and phonetic supervision for MCL-ASR in a common experimental setup (RQ-2).</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div id="S2.F1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:348.4pt;height:168.5pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-43.6pt,21.0pt) scale(0.8,0.8) ;"><img src="/html/2406.02166/assets/figure/overview.png" id="S2.F1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="290" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of the pre-training and fine-tuning procedures with phonetic supervision, subword supervision, and self-supervision.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Approach</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe the three main classes of pre-training and fine-tuning methods for MCL-ASR, i.e., phoneme-based multilingual supervised pre-training (Section <a href="#S3.SS1" title="III-A Phoneme-based multilingual supervised pre-training ‣ III Approach ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>), subword-based multilingual supervised pre-training (Section <a href="#S3.SS2" title="III-B Subword-based multilingual supervised pre-training ‣ III Approach ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>) and multilingual self-supervised pre-training (Section <a href="#S3.SS3" title="III-C Multilingual self-supervised pre-training ‣ III Approach ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>).
Figure <a href="#S2.F1" title="Figure 1 ‣ II-C MCL-ASR with self-supervision ‣ II Related work ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the differences between the three methods.
We can see from Figure <a href="#S2.F1" title="Figure 1 ‣ II-C MCL-ASR with self-supervision ‣ II Related work ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> that similar neural network architectures can be used for the acoustic encoders in all the three methods, which is good for fair comparison.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.2" class="ltx_p">The input to the acoustic encoder is usually spectral features, obtained from short-time Fourier transform frame by frame, denoted by <math id="S3.p2.1.m1.3" class="ltx_Math" alttext="x_{1},\cdots,x_{T}\triangleq x_{1:T}" display="inline"><semantics id="S3.p2.1.m1.3a"><mrow id="S3.p2.1.m1.3.3" xref="S3.p2.1.m1.3.3.cmml"><mrow id="S3.p2.1.m1.3.3.2.2" xref="S3.p2.1.m1.3.3.2.3.cmml"><msub id="S3.p2.1.m1.2.2.1.1.1" xref="S3.p2.1.m1.2.2.1.1.1.cmml"><mi id="S3.p2.1.m1.2.2.1.1.1.2" xref="S3.p2.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S3.p2.1.m1.2.2.1.1.1.3" xref="S3.p2.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.p2.1.m1.3.3.2.2.3" xref="S3.p2.1.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">⋯</mi><mo id="S3.p2.1.m1.3.3.2.2.4" xref="S3.p2.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.p2.1.m1.3.3.2.2.2" xref="S3.p2.1.m1.3.3.2.2.2.cmml"><mi id="S3.p2.1.m1.3.3.2.2.2.2" xref="S3.p2.1.m1.3.3.2.2.2.2.cmml">x</mi><mi id="S3.p2.1.m1.3.3.2.2.2.3" xref="S3.p2.1.m1.3.3.2.2.2.3.cmml">T</mi></msub></mrow><mo id="S3.p2.1.m1.3.3.3" xref="S3.p2.1.m1.3.3.3.cmml">≜</mo><msub id="S3.p2.1.m1.3.3.4" xref="S3.p2.1.m1.3.3.4.cmml"><mi id="S3.p2.1.m1.3.3.4.2" xref="S3.p2.1.m1.3.3.4.2.cmml">x</mi><mrow id="S3.p2.1.m1.3.3.4.3" xref="S3.p2.1.m1.3.3.4.3.cmml"><mn id="S3.p2.1.m1.3.3.4.3.2" xref="S3.p2.1.m1.3.3.4.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.p2.1.m1.3.3.4.3.1" xref="S3.p2.1.m1.3.3.4.3.1.cmml">:</mo><mi id="S3.p2.1.m1.3.3.4.3.3" xref="S3.p2.1.m1.3.3.4.3.3.cmml">T</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.3b"><apply id="S3.p2.1.m1.3.3.cmml" xref="S3.p2.1.m1.3.3"><ci id="S3.p2.1.m1.3.3.3.cmml" xref="S3.p2.1.m1.3.3.3">≜</ci><list id="S3.p2.1.m1.3.3.2.3.cmml" xref="S3.p2.1.m1.3.3.2.2"><apply id="S3.p2.1.m1.2.2.1.1.1.cmml" xref="S3.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.2.2.1.1.1.1.cmml" xref="S3.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.2.2.1.1.1.2.cmml" xref="S3.p2.1.m1.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S3.p2.1.m1.2.2.1.1.1.3.cmml" xref="S3.p2.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">⋯</ci><apply id="S3.p2.1.m1.3.3.2.2.2.cmml" xref="S3.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p2.1.m1.3.3.2.2.2.1.cmml" xref="S3.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.p2.1.m1.3.3.2.2.2.2.cmml" xref="S3.p2.1.m1.3.3.2.2.2.2">𝑥</ci><ci id="S3.p2.1.m1.3.3.2.2.2.3.cmml" xref="S3.p2.1.m1.3.3.2.2.2.3">𝑇</ci></apply></list><apply id="S3.p2.1.m1.3.3.4.cmml" xref="S3.p2.1.m1.3.3.4"><csymbol cd="ambiguous" id="S3.p2.1.m1.3.3.4.1.cmml" xref="S3.p2.1.m1.3.3.4">subscript</csymbol><ci id="S3.p2.1.m1.3.3.4.2.cmml" xref="S3.p2.1.m1.3.3.4.2">𝑥</ci><apply id="S3.p2.1.m1.3.3.4.3.cmml" xref="S3.p2.1.m1.3.3.4.3"><ci id="S3.p2.1.m1.3.3.4.3.1.cmml" xref="S3.p2.1.m1.3.3.4.3.1">:</ci><cn type="integer" id="S3.p2.1.m1.3.3.4.3.2.cmml" xref="S3.p2.1.m1.3.3.4.3.2">1</cn><ci id="S3.p2.1.m1.3.3.4.3.3.cmml" xref="S3.p2.1.m1.3.3.4.3.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.3c">x_{1},\cdots,x_{T}\triangleq x_{1:T}</annotation></semantics></math>.
In DNN-based ASR, the acoustic encoder could be viewed as a non-linear feature extractor, which hopefully can be trained to extract high-level features (or say, representations), more discriminative than the raw spectral features.
The output representations from the acoustic encoder are denoted by <math id="S3.p2.2.m2.3" class="ltx_Math" alttext="h_{1},\cdots,h_{T}\triangleq h_{1:T}" display="inline"><semantics id="S3.p2.2.m2.3a"><mrow id="S3.p2.2.m2.3.3" xref="S3.p2.2.m2.3.3.cmml"><mrow id="S3.p2.2.m2.3.3.2.2" xref="S3.p2.2.m2.3.3.2.3.cmml"><msub id="S3.p2.2.m2.2.2.1.1.1" xref="S3.p2.2.m2.2.2.1.1.1.cmml"><mi id="S3.p2.2.m2.2.2.1.1.1.2" xref="S3.p2.2.m2.2.2.1.1.1.2.cmml">h</mi><mn id="S3.p2.2.m2.2.2.1.1.1.3" xref="S3.p2.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.p2.2.m2.3.3.2.2.3" xref="S3.p2.2.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">⋯</mi><mo id="S3.p2.2.m2.3.3.2.2.4" xref="S3.p2.2.m2.3.3.2.3.cmml">,</mo><msub id="S3.p2.2.m2.3.3.2.2.2" xref="S3.p2.2.m2.3.3.2.2.2.cmml"><mi id="S3.p2.2.m2.3.3.2.2.2.2" xref="S3.p2.2.m2.3.3.2.2.2.2.cmml">h</mi><mi id="S3.p2.2.m2.3.3.2.2.2.3" xref="S3.p2.2.m2.3.3.2.2.2.3.cmml">T</mi></msub></mrow><mo id="S3.p2.2.m2.3.3.3" xref="S3.p2.2.m2.3.3.3.cmml">≜</mo><msub id="S3.p2.2.m2.3.3.4" xref="S3.p2.2.m2.3.3.4.cmml"><mi id="S3.p2.2.m2.3.3.4.2" xref="S3.p2.2.m2.3.3.4.2.cmml">h</mi><mrow id="S3.p2.2.m2.3.3.4.3" xref="S3.p2.2.m2.3.3.4.3.cmml"><mn id="S3.p2.2.m2.3.3.4.3.2" xref="S3.p2.2.m2.3.3.4.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.p2.2.m2.3.3.4.3.1" xref="S3.p2.2.m2.3.3.4.3.1.cmml">:</mo><mi id="S3.p2.2.m2.3.3.4.3.3" xref="S3.p2.2.m2.3.3.4.3.3.cmml">T</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.3b"><apply id="S3.p2.2.m2.3.3.cmml" xref="S3.p2.2.m2.3.3"><ci id="S3.p2.2.m2.3.3.3.cmml" xref="S3.p2.2.m2.3.3.3">≜</ci><list id="S3.p2.2.m2.3.3.2.3.cmml" xref="S3.p2.2.m2.3.3.2.2"><apply id="S3.p2.2.m2.2.2.1.1.1.cmml" xref="S3.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.2.2.1.1.1.1.cmml" xref="S3.p2.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.p2.2.m2.2.2.1.1.1.2.cmml" xref="S3.p2.2.m2.2.2.1.1.1.2">ℎ</ci><cn type="integer" id="S3.p2.2.m2.2.2.1.1.1.3.cmml" xref="S3.p2.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">⋯</ci><apply id="S3.p2.2.m2.3.3.2.2.2.cmml" xref="S3.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p2.2.m2.3.3.2.2.2.1.cmml" xref="S3.p2.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.p2.2.m2.3.3.2.2.2.2.cmml" xref="S3.p2.2.m2.3.3.2.2.2.2">ℎ</ci><ci id="S3.p2.2.m2.3.3.2.2.2.3.cmml" xref="S3.p2.2.m2.3.3.2.2.2.3">𝑇</ci></apply></list><apply id="S3.p2.2.m2.3.3.4.cmml" xref="S3.p2.2.m2.3.3.4"><csymbol cd="ambiguous" id="S3.p2.2.m2.3.3.4.1.cmml" xref="S3.p2.2.m2.3.3.4">subscript</csymbol><ci id="S3.p2.2.m2.3.3.4.2.cmml" xref="S3.p2.2.m2.3.3.4.2">ℎ</ci><apply id="S3.p2.2.m2.3.3.4.3.cmml" xref="S3.p2.2.m2.3.3.4.3"><ci id="S3.p2.2.m2.3.3.4.3.1.cmml" xref="S3.p2.2.m2.3.3.4.3.1">:</ci><cn type="integer" id="S3.p2.2.m2.3.3.4.3.2.cmml" xref="S3.p2.2.m2.3.3.4.3.2">1</cn><ci id="S3.p2.2.m2.3.3.4.3.3.cmml" xref="S3.p2.2.m2.3.3.4.3.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.3c">h_{1},\cdots,h_{T}\triangleq h_{1:T}</annotation></semantics></math>.
A popular neural network architecture for the encoder is Conformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, which consists of convolution blocks followed by Conformer blocks.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.3" class="ltx_p">Given acoustic observations <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="x_{1:T}" display="inline"><semantics id="S3.p3.1.m1.1a"><msub id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><mi id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml">x</mi><mrow id="S3.p3.1.m1.1.1.3" xref="S3.p3.1.m1.1.1.3.cmml"><mn id="S3.p3.1.m1.1.1.3.2" xref="S3.p3.1.m1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.p3.1.m1.1.1.3.1" xref="S3.p3.1.m1.1.1.3.1.cmml">:</mo><mi id="S3.p3.1.m1.1.1.3.3" xref="S3.p3.1.m1.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">𝑥</ci><apply id="S3.p3.1.m1.1.1.3.cmml" xref="S3.p3.1.m1.1.1.3"><ci id="S3.p3.1.m1.1.1.3.1.cmml" xref="S3.p3.1.m1.1.1.3.1">:</ci><cn type="integer" id="S3.p3.1.m1.1.1.3.2.cmml" xref="S3.p3.1.m1.1.1.3.2">1</cn><ci id="S3.p3.1.m1.1.1.3.3.cmml" xref="S3.p3.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">x_{1:T}</annotation></semantics></math>, the task of ASR is to find the most likely labels <math id="S3.p3.2.m2.2" class="ltx_Math" alttext="y_{1},\cdots\,y_{L}\triangleq y_{1:L}" display="inline"><semantics id="S3.p3.2.m2.2a"><mrow id="S3.p3.2.m2.2.2" xref="S3.p3.2.m2.2.2.cmml"><mrow id="S3.p3.2.m2.2.2.2.2" xref="S3.p3.2.m2.2.2.2.3.cmml"><msub id="S3.p3.2.m2.1.1.1.1.1" xref="S3.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.p3.2.m2.1.1.1.1.1.2" xref="S3.p3.2.m2.1.1.1.1.1.2.cmml">y</mi><mn id="S3.p3.2.m2.1.1.1.1.1.3" xref="S3.p3.2.m2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.p3.2.m2.2.2.2.2.3" xref="S3.p3.2.m2.2.2.2.3.cmml">,</mo><mrow id="S3.p3.2.m2.2.2.2.2.2" xref="S3.p3.2.m2.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.p3.2.m2.2.2.2.2.2.2" xref="S3.p3.2.m2.2.2.2.2.2.2.cmml">⋯</mi><mo lspace="0.170em" rspace="0em" id="S3.p3.2.m2.2.2.2.2.2.1" xref="S3.p3.2.m2.2.2.2.2.2.1.cmml">​</mo><msub id="S3.p3.2.m2.2.2.2.2.2.3" xref="S3.p3.2.m2.2.2.2.2.2.3.cmml"><mi id="S3.p3.2.m2.2.2.2.2.2.3.2" xref="S3.p3.2.m2.2.2.2.2.2.3.2.cmml">y</mi><mi id="S3.p3.2.m2.2.2.2.2.2.3.3" xref="S3.p3.2.m2.2.2.2.2.2.3.3.cmml">L</mi></msub></mrow></mrow><mo id="S3.p3.2.m2.2.2.3" xref="S3.p3.2.m2.2.2.3.cmml">≜</mo><msub id="S3.p3.2.m2.2.2.4" xref="S3.p3.2.m2.2.2.4.cmml"><mi id="S3.p3.2.m2.2.2.4.2" xref="S3.p3.2.m2.2.2.4.2.cmml">y</mi><mrow id="S3.p3.2.m2.2.2.4.3" xref="S3.p3.2.m2.2.2.4.3.cmml"><mn id="S3.p3.2.m2.2.2.4.3.2" xref="S3.p3.2.m2.2.2.4.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.p3.2.m2.2.2.4.3.1" xref="S3.p3.2.m2.2.2.4.3.1.cmml">:</mo><mi id="S3.p3.2.m2.2.2.4.3.3" xref="S3.p3.2.m2.2.2.4.3.3.cmml">L</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.2b"><apply id="S3.p3.2.m2.2.2.cmml" xref="S3.p3.2.m2.2.2"><ci id="S3.p3.2.m2.2.2.3.cmml" xref="S3.p3.2.m2.2.2.3">≜</ci><list id="S3.p3.2.m2.2.2.2.3.cmml" xref="S3.p3.2.m2.2.2.2.2"><apply id="S3.p3.2.m2.1.1.1.1.1.cmml" xref="S3.p3.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.p3.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.p3.2.m2.1.1.1.1.1.2">𝑦</ci><cn type="integer" id="S3.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.p3.2.m2.1.1.1.1.1.3">1</cn></apply><apply id="S3.p3.2.m2.2.2.2.2.2.cmml" xref="S3.p3.2.m2.2.2.2.2.2"><times id="S3.p3.2.m2.2.2.2.2.2.1.cmml" xref="S3.p3.2.m2.2.2.2.2.2.1"></times><ci id="S3.p3.2.m2.2.2.2.2.2.2.cmml" xref="S3.p3.2.m2.2.2.2.2.2.2">⋯</ci><apply id="S3.p3.2.m2.2.2.2.2.2.3.cmml" xref="S3.p3.2.m2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.p3.2.m2.2.2.2.2.2.3.1.cmml" xref="S3.p3.2.m2.2.2.2.2.2.3">subscript</csymbol><ci id="S3.p3.2.m2.2.2.2.2.2.3.2.cmml" xref="S3.p3.2.m2.2.2.2.2.2.3.2">𝑦</ci><ci id="S3.p3.2.m2.2.2.2.2.2.3.3.cmml" xref="S3.p3.2.m2.2.2.2.2.2.3.3">𝐿</ci></apply></apply></list><apply id="S3.p3.2.m2.2.2.4.cmml" xref="S3.p3.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.p3.2.m2.2.2.4.1.cmml" xref="S3.p3.2.m2.2.2.4">subscript</csymbol><ci id="S3.p3.2.m2.2.2.4.2.cmml" xref="S3.p3.2.m2.2.2.4.2">𝑦</ci><apply id="S3.p3.2.m2.2.2.4.3.cmml" xref="S3.p3.2.m2.2.2.4.3"><ci id="S3.p3.2.m2.2.2.4.3.1.cmml" xref="S3.p3.2.m2.2.2.4.3.1">:</ci><cn type="integer" id="S3.p3.2.m2.2.2.4.3.2.cmml" xref="S3.p3.2.m2.2.2.4.3.2">1</cn><ci id="S3.p3.2.m2.2.2.4.3.3.cmml" xref="S3.p3.2.m2.2.2.4.3.3">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.2c">y_{1},\cdots\,y_{L}\triangleq y_{1:L}</annotation></semantics></math>.
Different units can be used for labeling <math id="S3.p3.3.m3.1" class="ltx_Math" alttext="y_{1:L}" display="inline"><semantics id="S3.p3.3.m3.1a"><msub id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml"><mi id="S3.p3.3.m3.1.1.2" xref="S3.p3.3.m3.1.1.2.cmml">y</mi><mrow id="S3.p3.3.m3.1.1.3" xref="S3.p3.3.m3.1.1.3.cmml"><mn id="S3.p3.3.m3.1.1.3.2" xref="S3.p3.3.m3.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.p3.3.m3.1.1.3.1" xref="S3.p3.3.m3.1.1.3.1.cmml">:</mo><mi id="S3.p3.3.m3.1.1.3.3" xref="S3.p3.3.m3.1.1.3.3.cmml">L</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><apply id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p3.3.m3.1.1.1.cmml" xref="S3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.p3.3.m3.1.1.2.cmml" xref="S3.p3.3.m3.1.1.2">𝑦</ci><apply id="S3.p3.3.m3.1.1.3.cmml" xref="S3.p3.3.m3.1.1.3"><ci id="S3.p3.3.m3.1.1.3.1.cmml" xref="S3.p3.3.m3.1.1.3.1">:</ci><cn type="integer" id="S3.p3.3.m3.1.1.3.2.cmml" xref="S3.p3.3.m3.1.1.3.2">1</cn><ci id="S3.p3.3.m3.1.1.3.3.cmml" xref="S3.p3.3.m3.1.1.3.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">y_{1:L}</annotation></semantics></math>, depending on what transcription is used for labeling, phonetic or graphemic, as shown in Table <a href="#S4.T2" title="TABLE II ‣ IV-A Dataset ‣ IV Experimental setup ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. Phonemes and subwords are two widely-used labels for MCL-ASR.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">In order to promote information sharing between different languages for MCL-ASR, training data from a number of languages, often referred to as seen languages, can be merged to pre-train a multilingual encoder in a supervised fashion, with labels of <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="y_{1:L}" display="inline"><semantics id="S3.p4.1.m1.1a"><msub id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml"><mi id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2.cmml">y</mi><mrow id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3.cmml"><mn id="S3.p4.1.m1.1.1.3.2" xref="S3.p4.1.m1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.p4.1.m1.1.1.3.1" xref="S3.p4.1.m1.1.1.3.1.cmml">:</mo><mi id="S3.p4.1.m1.1.1.3.3" xref="S3.p4.1.m1.1.1.3.3.cmml">L</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.cmml" xref="S3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2">𝑦</ci><apply id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3"><ci id="S3.p4.1.m1.1.1.3.1.cmml" xref="S3.p4.1.m1.1.1.3.1">:</ci><cn type="integer" id="S3.p4.1.m1.1.1.3.2.cmml" xref="S3.p4.1.m1.1.1.3.2">1</cn><ci id="S3.p4.1.m1.1.1.3.3.cmml" xref="S3.p4.1.m1.1.1.3.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">y_{1:L}</annotation></semantics></math> given in the form of either phonemes or subwords. Alternatively, the acoustic encoder could be pre-trained over unlabeled data by some self-supervised method, such as wav2vec 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, and then be fine-tuned over labeled data in the form of either phonemes or subwords.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Phoneme-based multilingual supervised pre-training</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.12" class="ltx_p">In this paper, we consider end-to-end ASR models based on the widely used connectionist temporal classification (CTC) method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
CTC introduces a blank symbol &lt;b&gt; in addition to the ordinary labels, and further introduces a state sequence <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="\pi_{1},\cdots\,\pi_{T}\triangleq\pi_{1:T}" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml"><mrow id="S3.SS1.p1.1.m1.2.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.3.cmml"><msub id="S3.SS1.p1.1.m1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml">π</mi><mn id="S3.SS1.p1.1.m1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.1.m1.2.2.2.2.3" xref="S3.SS1.p1.1.m1.2.2.2.3.cmml">,</mo><mrow id="S3.SS1.p1.1.m1.2.2.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.SS1.p1.1.m1.2.2.2.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.2.2.2.cmml">⋯</mi><mo lspace="0.170em" rspace="0em" id="S3.SS1.p1.1.m1.2.2.2.2.2.1" xref="S3.SS1.p1.1.m1.2.2.2.2.2.1.cmml">​</mo><msub id="S3.SS1.p1.1.m1.2.2.2.2.2.3" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.2.2.2.3.2" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3.2.cmml">π</mi><mi id="S3.SS1.p1.1.m1.2.2.2.2.2.3.3" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3.3.cmml">T</mi></msub></mrow></mrow><mo id="S3.SS1.p1.1.m1.2.2.3" xref="S3.SS1.p1.1.m1.2.2.3.cmml">≜</mo><msub id="S3.SS1.p1.1.m1.2.2.4" xref="S3.SS1.p1.1.m1.2.2.4.cmml"><mi id="S3.SS1.p1.1.m1.2.2.4.2" xref="S3.SS1.p1.1.m1.2.2.4.2.cmml">π</mi><mrow id="S3.SS1.p1.1.m1.2.2.4.3" xref="S3.SS1.p1.1.m1.2.2.4.3.cmml"><mn id="S3.SS1.p1.1.m1.2.2.4.3.2" xref="S3.SS1.p1.1.m1.2.2.4.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.1.m1.2.2.4.3.1" xref="S3.SS1.p1.1.m1.2.2.4.3.1.cmml">:</mo><mi id="S3.SS1.p1.1.m1.2.2.4.3.3" xref="S3.SS1.p1.1.m1.2.2.4.3.3.cmml">T</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2"><ci id="S3.SS1.p1.1.m1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.3">≜</ci><list id="S3.SS1.p1.1.m1.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2"><apply id="S3.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.2">𝜋</ci><cn type="integer" id="S3.SS1.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2"><times id="S3.SS1.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2.1"></times><ci id="S3.SS1.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2.2">⋯</ci><apply id="S3.SS1.p1.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3.2">𝜋</ci><ci id="S3.SS1.p1.1.m1.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2.3.3">𝑇</ci></apply></apply></list><apply id="S3.SS1.p1.1.m1.2.2.4.cmml" xref="S3.SS1.p1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.4.1.cmml" xref="S3.SS1.p1.1.m1.2.2.4">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.4.2.cmml" xref="S3.SS1.p1.1.m1.2.2.4.2">𝜋</ci><apply id="S3.SS1.p1.1.m1.2.2.4.3.cmml" xref="S3.SS1.p1.1.m1.2.2.4.3"><ci id="S3.SS1.p1.1.m1.2.2.4.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.4.3.1">:</ci><cn type="integer" id="S3.SS1.p1.1.m1.2.2.4.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.4.3.2">1</cn><ci id="S3.SS1.p1.1.m1.2.2.4.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.4.3.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">\pi_{1},\cdots\,\pi_{T}\triangleq\pi_{1:T}</annotation></semantics></math>, which aids the aligning between <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="x_{1:T}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">x</mi><mrow id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mn id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.2.m2.1.1.3.1" xref="S3.SS1.p1.2.m2.1.1.3.1.cmml">:</mo><mi id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝑥</ci><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><ci id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.1">:</ci><cn type="integer" id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">1</cn><ci id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">x_{1:T}</annotation></semantics></math> and <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="y_{1:L}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">y</mi><mrow id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mn id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.3.m3.1.1.3.1" xref="S3.SS1.p1.3.m3.1.1.3.1.cmml">:</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml">L</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑦</ci><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><ci id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.1">:</ci><cn type="integer" id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">1</cn><ci id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">y_{1:L}</annotation></semantics></math>.
Given acoustic sequence <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="x_{1:T}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">x</mi><mrow id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mn id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.4.m4.1.1.3.1" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">:</mo><mi id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝑥</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><ci id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.1">:</ci><cn type="integer" id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">1</cn><ci id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">x_{1:T}</annotation></semantics></math>, at each frame <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">t</annotation></semantics></math>, the possible values that <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="\pi_{t}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">π</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝜋</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\pi_{t}</annotation></semantics></math> can freely take is <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="V\cup\text{&lt;b&gt;}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">V</mi><mo id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml">∪</mo><mtext id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3a.cmml">&lt;b&gt;</mtext></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><union id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"></union><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">𝑉</ci><ci id="S3.SS1.p1.7.m7.1.1.3a.cmml" xref="S3.SS1.p1.7.m7.1.1.3"><mtext id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">&lt;b&gt;</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">V\cup\text{&lt;b&gt;}</annotation></semantics></math>, where <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">V</annotation></semantics></math> denotes the alphabet of labels.
The Conformer based acoustic encoder is used to extract high-level <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mi id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><ci id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">D</annotation></semantics></math>-dimensional representations <math id="S3.SS1.p1.10.m10.2" class="ltx_Math" alttext="h_{1:T}=(h_{1},\cdots\,h_{T})\in\mathbb{R}^{D\times T}" display="inline"><semantics id="S3.SS1.p1.10.m10.2a"><mrow id="S3.SS1.p1.10.m10.2.2" xref="S3.SS1.p1.10.m10.2.2.cmml"><msub id="S3.SS1.p1.10.m10.2.2.4" xref="S3.SS1.p1.10.m10.2.2.4.cmml"><mi id="S3.SS1.p1.10.m10.2.2.4.2" xref="S3.SS1.p1.10.m10.2.2.4.2.cmml">h</mi><mrow id="S3.SS1.p1.10.m10.2.2.4.3" xref="S3.SS1.p1.10.m10.2.2.4.3.cmml"><mn id="S3.SS1.p1.10.m10.2.2.4.3.2" xref="S3.SS1.p1.10.m10.2.2.4.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.10.m10.2.2.4.3.1" xref="S3.SS1.p1.10.m10.2.2.4.3.1.cmml">:</mo><mi id="S3.SS1.p1.10.m10.2.2.4.3.3" xref="S3.SS1.p1.10.m10.2.2.4.3.3.cmml">T</mi></mrow></msub><mo id="S3.SS1.p1.10.m10.2.2.5" xref="S3.SS1.p1.10.m10.2.2.5.cmml">=</mo><mrow id="S3.SS1.p1.10.m10.2.2.2.2" xref="S3.SS1.p1.10.m10.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.10.m10.2.2.2.2.3" xref="S3.SS1.p1.10.m10.2.2.2.3.cmml">(</mo><msub id="S3.SS1.p1.10.m10.1.1.1.1.1" xref="S3.SS1.p1.10.m10.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.10.m10.1.1.1.1.1.2" xref="S3.SS1.p1.10.m10.1.1.1.1.1.2.cmml">h</mi><mn id="S3.SS1.p1.10.m10.1.1.1.1.1.3" xref="S3.SS1.p1.10.m10.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.10.m10.2.2.2.2.4" xref="S3.SS1.p1.10.m10.2.2.2.3.cmml">,</mo><mrow id="S3.SS1.p1.10.m10.2.2.2.2.2" xref="S3.SS1.p1.10.m10.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.SS1.p1.10.m10.2.2.2.2.2.2" xref="S3.SS1.p1.10.m10.2.2.2.2.2.2.cmml">⋯</mi><mo lspace="0.170em" rspace="0em" id="S3.SS1.p1.10.m10.2.2.2.2.2.1" xref="S3.SS1.p1.10.m10.2.2.2.2.2.1.cmml">​</mo><msub id="S3.SS1.p1.10.m10.2.2.2.2.2.3" xref="S3.SS1.p1.10.m10.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p1.10.m10.2.2.2.2.2.3.2" xref="S3.SS1.p1.10.m10.2.2.2.2.2.3.2.cmml">h</mi><mi id="S3.SS1.p1.10.m10.2.2.2.2.2.3.3" xref="S3.SS1.p1.10.m10.2.2.2.2.2.3.3.cmml">T</mi></msub></mrow><mo stretchy="false" id="S3.SS1.p1.10.m10.2.2.2.2.5" xref="S3.SS1.p1.10.m10.2.2.2.3.cmml">)</mo></mrow><mo id="S3.SS1.p1.10.m10.2.2.6" xref="S3.SS1.p1.10.m10.2.2.6.cmml">∈</mo><msup id="S3.SS1.p1.10.m10.2.2.7" xref="S3.SS1.p1.10.m10.2.2.7.cmml"><mi id="S3.SS1.p1.10.m10.2.2.7.2" xref="S3.SS1.p1.10.m10.2.2.7.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.10.m10.2.2.7.3" xref="S3.SS1.p1.10.m10.2.2.7.3.cmml"><mi id="S3.SS1.p1.10.m10.2.2.7.3.2" xref="S3.SS1.p1.10.m10.2.2.7.3.2.cmml">D</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.10.m10.2.2.7.3.1" xref="S3.SS1.p1.10.m10.2.2.7.3.1.cmml">×</mo><mi id="S3.SS1.p1.10.m10.2.2.7.3.3" xref="S3.SS1.p1.10.m10.2.2.7.3.3.cmml">T</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.2b"><apply id="S3.SS1.p1.10.m10.2.2.cmml" xref="S3.SS1.p1.10.m10.2.2"><and id="S3.SS1.p1.10.m10.2.2a.cmml" xref="S3.SS1.p1.10.m10.2.2"></and><apply id="S3.SS1.p1.10.m10.2.2b.cmml" xref="S3.SS1.p1.10.m10.2.2"><eq id="S3.SS1.p1.10.m10.2.2.5.cmml" xref="S3.SS1.p1.10.m10.2.2.5"></eq><apply id="S3.SS1.p1.10.m10.2.2.4.cmml" xref="S3.SS1.p1.10.m10.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.2.2.4.1.cmml" xref="S3.SS1.p1.10.m10.2.2.4">subscript</csymbol><ci id="S3.SS1.p1.10.m10.2.2.4.2.cmml" xref="S3.SS1.p1.10.m10.2.2.4.2">ℎ</ci><apply id="S3.SS1.p1.10.m10.2.2.4.3.cmml" xref="S3.SS1.p1.10.m10.2.2.4.3"><ci id="S3.SS1.p1.10.m10.2.2.4.3.1.cmml" xref="S3.SS1.p1.10.m10.2.2.4.3.1">:</ci><cn type="integer" id="S3.SS1.p1.10.m10.2.2.4.3.2.cmml" xref="S3.SS1.p1.10.m10.2.2.4.3.2">1</cn><ci id="S3.SS1.p1.10.m10.2.2.4.3.3.cmml" xref="S3.SS1.p1.10.m10.2.2.4.3.3">𝑇</ci></apply></apply><interval closure="open" id="S3.SS1.p1.10.m10.2.2.2.3.cmml" xref="S3.SS1.p1.10.m10.2.2.2.2"><apply id="S3.SS1.p1.10.m10.1.1.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m10.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.1.1.1.2">ℎ</ci><cn type="integer" id="S3.SS1.p1.10.m10.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.10.m10.2.2.2.2.2.cmml" xref="S3.SS1.p1.10.m10.2.2.2.2.2"><times id="S3.SS1.p1.10.m10.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.10.m10.2.2.2.2.2.1"></times><ci id="S3.SS1.p1.10.m10.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.10.m10.2.2.2.2.2.2">⋯</ci><apply id="S3.SS1.p1.10.m10.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.10.m10.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.10.m10.2.2.2.2.2.3">subscript</csymbol><ci id="S3.SS1.p1.10.m10.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.10.m10.2.2.2.2.2.3.2">ℎ</ci><ci id="S3.SS1.p1.10.m10.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.10.m10.2.2.2.2.2.3.3">𝑇</ci></apply></apply></interval></apply><apply id="S3.SS1.p1.10.m10.2.2c.cmml" xref="S3.SS1.p1.10.m10.2.2"><in id="S3.SS1.p1.10.m10.2.2.6.cmml" xref="S3.SS1.p1.10.m10.2.2.6"></in><share href="#S3.SS1.p1.10.m10.2.2.2.cmml" id="S3.SS1.p1.10.m10.2.2d.cmml" xref="S3.SS1.p1.10.m10.2.2"></share><apply id="S3.SS1.p1.10.m10.2.2.7.cmml" xref="S3.SS1.p1.10.m10.2.2.7"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.2.2.7.1.cmml" xref="S3.SS1.p1.10.m10.2.2.7">superscript</csymbol><ci id="S3.SS1.p1.10.m10.2.2.7.2.cmml" xref="S3.SS1.p1.10.m10.2.2.7.2">ℝ</ci><apply id="S3.SS1.p1.10.m10.2.2.7.3.cmml" xref="S3.SS1.p1.10.m10.2.2.7.3"><times id="S3.SS1.p1.10.m10.2.2.7.3.1.cmml" xref="S3.SS1.p1.10.m10.2.2.7.3.1"></times><ci id="S3.SS1.p1.10.m10.2.2.7.3.2.cmml" xref="S3.SS1.p1.10.m10.2.2.7.3.2">𝐷</ci><ci id="S3.SS1.p1.10.m10.2.2.7.3.3.cmml" xref="S3.SS1.p1.10.m10.2.2.7.3.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.2c">h_{1:T}=(h_{1},\cdots\,h_{T})\in\mathbb{R}^{D\times T}</annotation></semantics></math> from the raw spectral features <math id="S3.SS1.p1.11.m11.1" class="ltx_Math" alttext="x_{1:T}" display="inline"><semantics id="S3.SS1.p1.11.m11.1a"><msub id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml"><mi id="S3.SS1.p1.11.m11.1.1.2" xref="S3.SS1.p1.11.m11.1.1.2.cmml">x</mi><mrow id="S3.SS1.p1.11.m11.1.1.3" xref="S3.SS1.p1.11.m11.1.1.3.cmml"><mn id="S3.SS1.p1.11.m11.1.1.3.2" xref="S3.SS1.p1.11.m11.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.11.m11.1.1.3.1" xref="S3.SS1.p1.11.m11.1.1.3.1.cmml">:</mo><mi id="S3.SS1.p1.11.m11.1.1.3.3" xref="S3.SS1.p1.11.m11.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b"><apply id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m11.1.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m11.1.1.2.cmml" xref="S3.SS1.p1.11.m11.1.1.2">𝑥</ci><apply id="S3.SS1.p1.11.m11.1.1.3.cmml" xref="S3.SS1.p1.11.m11.1.1.3"><ci id="S3.SS1.p1.11.m11.1.1.3.1.cmml" xref="S3.SS1.p1.11.m11.1.1.3.1">:</ci><cn type="integer" id="S3.SS1.p1.11.m11.1.1.3.2.cmml" xref="S3.SS1.p1.11.m11.1.1.3.2">1</cn><ci id="S3.SS1.p1.11.m11.1.1.3.3.cmml" xref="S3.SS1.p1.11.m11.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">x_{1:T}</annotation></semantics></math>. Then, we can apply a linear layer followed by a softmax activation to calculate the posteriori distribution of <math id="S3.SS1.p1.12.m12.1" class="ltx_Math" alttext="\pi_{t}" display="inline"><semantics id="S3.SS1.p1.12.m12.1a"><msub id="S3.SS1.p1.12.m12.1.1" xref="S3.SS1.p1.12.m12.1.1.cmml"><mi id="S3.SS1.p1.12.m12.1.1.2" xref="S3.SS1.p1.12.m12.1.1.2.cmml">π</mi><mi id="S3.SS1.p1.12.m12.1.1.3" xref="S3.SS1.p1.12.m12.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m12.1b"><apply id="S3.SS1.p1.12.m12.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m12.1.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p1.12.m12.1.1.2.cmml" xref="S3.SS1.p1.12.m12.1.1.2">𝜋</ci><ci id="S3.SS1.p1.12.m12.1.1.3.cmml" xref="S3.SS1.p1.12.m12.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m12.1c">\pi_{t}</annotation></semantics></math>, as follows:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.39" class="ltx_Math" alttext="\begin{split}z_{t}&amp;=W^{T}h_{t}\in\mathbb{R}^{|V|+1}\\
P(\pi_{t}=k|x_{1:T})&amp;=\frac{\exp(z_{t}^{k})}{\sum_{j=1}^{|V|+1}\exp(z_{t}^{j})},k=1,\cdots,|V|+1\end{split}" display="block"><semantics id="S3.E1.m1.39a"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S3.E1.m1.39.39.5"><mtr id="S3.E1.m1.39.39.5a"><mtd class="ltx_align_right" columnalign="right" id="S3.E1.m1.39.39.5b"><msub id="S3.E1.m1.2.2.2.2.2"><mi id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">z</mi><mi id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml">t</mi></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.39.39.5c"><mrow id="S3.E1.m1.10.10.10.10.8"><mi id="S3.E1.m1.10.10.10.10.8.10" xref="S3.E1.m1.36.36.2.3.cmml"></mi><mo id="S3.E1.m1.3.3.3.3.1.1" xref="S3.E1.m1.3.3.3.3.1.1.cmml">=</mo><mrow id="S3.E1.m1.10.10.10.10.8.11"><msup id="S3.E1.m1.10.10.10.10.8.11.2"><mi id="S3.E1.m1.4.4.4.4.2.2" xref="S3.E1.m1.4.4.4.4.2.2.cmml">W</mi><mi id="S3.E1.m1.5.5.5.5.3.3.1" xref="S3.E1.m1.5.5.5.5.3.3.1.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S3.E1.m1.10.10.10.10.8.11.1" xref="S3.E1.m1.36.36.2.3.cmml">​</mo><msub id="S3.E1.m1.10.10.10.10.8.11.3"><mi id="S3.E1.m1.6.6.6.6.4.4" xref="S3.E1.m1.6.6.6.6.4.4.cmml">h</mi><mi id="S3.E1.m1.7.7.7.7.5.5.1" xref="S3.E1.m1.7.7.7.7.5.5.1.cmml">t</mi></msub></mrow><mo id="S3.E1.m1.8.8.8.8.6.6" xref="S3.E1.m1.8.8.8.8.6.6.cmml">∈</mo><msup id="S3.E1.m1.10.10.10.10.8.12"><mi id="S3.E1.m1.9.9.9.9.7.7" xref="S3.E1.m1.9.9.9.9.7.7.cmml">ℝ</mi><mrow id="S3.E1.m1.10.10.10.10.8.8.1" xref="S3.E1.m1.10.10.10.10.8.8.1.cmml"><mrow id="S3.E1.m1.10.10.10.10.8.8.1.3.2" xref="S3.E1.m1.10.10.10.10.8.8.1.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.10.10.10.10.8.8.1.3.2.1" xref="S3.E1.m1.10.10.10.10.8.8.1.3.1.1.cmml">|</mo><mi id="S3.E1.m1.10.10.10.10.8.8.1.1" xref="S3.E1.m1.10.10.10.10.8.8.1.1.cmml">V</mi><mo stretchy="false" id="S3.E1.m1.10.10.10.10.8.8.1.3.2.2" xref="S3.E1.m1.10.10.10.10.8.8.1.3.1.1.cmml">|</mo></mrow><mo id="S3.E1.m1.10.10.10.10.8.8.1.2" xref="S3.E1.m1.10.10.10.10.8.8.1.2.cmml">+</mo><mn id="S3.E1.m1.10.10.10.10.8.8.1.4" xref="S3.E1.m1.10.10.10.10.8.8.1.4.cmml">1</mn></mrow></msup></mrow></mtd></mtr><mtr id="S3.E1.m1.39.39.5d"><mtd class="ltx_align_right" columnalign="right" id="S3.E1.m1.39.39.5e"><mrow id="S3.E1.m1.37.37.3.35.25.11"><mi id="S3.E1.m1.11.11.11.1.1.1" xref="S3.E1.m1.11.11.11.1.1.1.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.37.37.3.35.25.11.12" xref="S3.E1.m1.36.36.2.3.cmml">​</mo><mrow id="S3.E1.m1.37.37.3.35.25.11.11.1"><mo stretchy="false" id="S3.E1.m1.12.12.12.2.2.2" xref="S3.E1.m1.36.36.2.3.cmml">(</mo><mrow id="S3.E1.m1.37.37.3.35.25.11.11.1.1"><msub id="S3.E1.m1.37.37.3.35.25.11.11.1.1.1"><mi id="S3.E1.m1.13.13.13.3.3.3" xref="S3.E1.m1.13.13.13.3.3.3.cmml">π</mi><mi id="S3.E1.m1.14.14.14.4.4.4.1" xref="S3.E1.m1.14.14.14.4.4.4.1.cmml">t</mi></msub><mo id="S3.E1.m1.15.15.15.5.5.5" xref="S3.E1.m1.15.15.15.5.5.5.cmml">=</mo><mrow id="S3.E1.m1.37.37.3.35.25.11.11.1.1.2"><mi id="S3.E1.m1.16.16.16.6.6.6" xref="S3.E1.m1.16.16.16.6.6.6.cmml">k</mi><mo fence="false" id="S3.E1.m1.17.17.17.7.7.7" xref="S3.E1.m1.17.17.17.7.7.7.cmml">|</mo><msub id="S3.E1.m1.37.37.3.35.25.11.11.1.1.2.1"><mi id="S3.E1.m1.18.18.18.8.8.8" xref="S3.E1.m1.18.18.18.8.8.8.cmml">x</mi><mrow id="S3.E1.m1.19.19.19.9.9.9.1" xref="S3.E1.m1.19.19.19.9.9.9.1.cmml"><mn id="S3.E1.m1.19.19.19.9.9.9.1.2" xref="S3.E1.m1.19.19.19.9.9.9.1.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.E1.m1.19.19.19.9.9.9.1.1" xref="S3.E1.m1.19.19.19.9.9.9.1.1.cmml">:</mo><mi id="S3.E1.m1.19.19.19.9.9.9.1.3" xref="S3.E1.m1.19.19.19.9.9.9.1.3.cmml">T</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S3.E1.m1.20.20.20.10.10.10" xref="S3.E1.m1.36.36.2.3.cmml">)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.39.39.5f"><mrow id="S3.E1.m1.39.39.5.37.27.16.16"><mrow id="S3.E1.m1.38.38.4.36.26.15.15.1"><mi id="S3.E1.m1.38.38.4.36.26.15.15.1.1" xref="S3.E1.m1.36.36.2.3.cmml"></mi><mo id="S3.E1.m1.21.21.21.11.1.1" xref="S3.E1.m1.21.21.21.11.1.1.cmml">=</mo><mfrac id="S3.E1.m1.22.22.22.12.2.2" xref="S3.E1.m1.22.22.22.12.2.2.cmml"><mrow id="S3.E1.m1.22.22.22.12.2.2.2.2" xref="S3.E1.m1.22.22.22.12.2.2.2.3.cmml"><mi id="S3.E1.m1.22.22.22.12.2.2.1.1" xref="S3.E1.m1.22.22.22.12.2.2.1.1.cmml">exp</mi><mo id="S3.E1.m1.22.22.22.12.2.2.2.2a" xref="S3.E1.m1.22.22.22.12.2.2.2.3.cmml">⁡</mo><mrow id="S3.E1.m1.22.22.22.12.2.2.2.2.1" xref="S3.E1.m1.22.22.22.12.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.22.22.22.12.2.2.2.2.1.2" xref="S3.E1.m1.22.22.22.12.2.2.2.3.cmml">(</mo><msubsup id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.cmml"><mi id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.2" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.2.cmml">z</mi><mi id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.3" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.3.cmml">t</mi><mi id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.3" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.3.cmml">k</mi></msubsup><mo stretchy="false" id="S3.E1.m1.22.22.22.12.2.2.2.2.1.3" xref="S3.E1.m1.22.22.22.12.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S3.E1.m1.22.22.22.12.2.2.5" xref="S3.E1.m1.22.22.22.12.2.2.5.cmml"><msubsup id="S3.E1.m1.22.22.22.12.2.2.5.4" xref="S3.E1.m1.22.22.22.12.2.2.5.4.cmml"><mo id="S3.E1.m1.22.22.22.12.2.2.5.4.2.2" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.2.cmml">∑</mo><mrow id="S3.E1.m1.22.22.22.12.2.2.5.4.2.3" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.cmml"><mi id="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.2" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.2.cmml">j</mi><mo id="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.1" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.1.cmml">=</mo><mn id="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.3" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.3.cmml">1</mn></mrow><mrow id="S3.E1.m1.22.22.22.12.2.2.3.1.1" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.cmml"><mrow id="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.2" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.2.1" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.1.1.cmml">|</mo><mi id="S3.E1.m1.22.22.22.12.2.2.3.1.1.1" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.1.cmml">V</mi><mo stretchy="false" id="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.2.2" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.1.1.cmml">|</mo></mrow><mo id="S3.E1.m1.22.22.22.12.2.2.3.1.1.2" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.2.cmml">+</mo><mn id="S3.E1.m1.22.22.22.12.2.2.3.1.1.4" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.4.cmml">1</mn></mrow></msubsup><mrow id="S3.E1.m1.22.22.22.12.2.2.5.3.1" xref="S3.E1.m1.22.22.22.12.2.2.5.3.2.cmml"><mi id="S3.E1.m1.22.22.22.12.2.2.4.2" xref="S3.E1.m1.22.22.22.12.2.2.4.2.cmml">exp</mi><mo id="S3.E1.m1.22.22.22.12.2.2.5.3.1a" xref="S3.E1.m1.22.22.22.12.2.2.5.3.2.cmml">⁡</mo><mrow id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1" xref="S3.E1.m1.22.22.22.12.2.2.5.3.2.cmml"><mo stretchy="false" id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.2" xref="S3.E1.m1.22.22.22.12.2.2.5.3.2.cmml">(</mo><msubsup id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.cmml"><mi id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.2" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.2.cmml">z</mi><mi id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.3" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.3.cmml">t</mi><mi id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.3" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.3.cmml">j</mi></msubsup><mo stretchy="false" id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.3" xref="S3.E1.m1.22.22.22.12.2.2.5.3.2.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><mo id="S3.E1.m1.23.23.23.13.3.3" xref="S3.E1.m1.36.36.2.3.cmml">,</mo><mrow id="S3.E1.m1.39.39.5.37.27.16.16.2"><mi id="S3.E1.m1.24.24.24.14.4.4" xref="S3.E1.m1.24.24.24.14.4.4.cmml">k</mi><mo id="S3.E1.m1.25.25.25.15.5.5" xref="S3.E1.m1.25.25.25.15.5.5.cmml">=</mo><mrow id="S3.E1.m1.39.39.5.37.27.16.16.2.1.1"><mn id="S3.E1.m1.26.26.26.16.6.6" xref="S3.E1.m1.26.26.26.16.6.6.cmml">1</mn><mo id="S3.E1.m1.27.27.27.17.7.7" xref="S3.E1.m1.36.36.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.E1.m1.28.28.28.18.8.8" xref="S3.E1.m1.28.28.28.18.8.8.cmml">⋯</mi><mo id="S3.E1.m1.29.29.29.19.9.9" xref="S3.E1.m1.36.36.2.3.cmml">,</mo><mrow id="S3.E1.m1.39.39.5.37.27.16.16.2.1.1.1"><mrow id="S3.E1.m1.39.39.5.37.27.16.16.2.1.1.1.1"><mo stretchy="false" id="S3.E1.m1.30.30.30.20.10.10" xref="S3.E1.m1.36.36.2.3.cmml">|</mo><mi id="S3.E1.m1.31.31.31.21.11.11" xref="S3.E1.m1.31.31.31.21.11.11.cmml">V</mi><mo stretchy="false" id="S3.E1.m1.32.32.32.22.12.12" xref="S3.E1.m1.36.36.2.3.cmml">|</mo></mrow><mo id="S3.E1.m1.33.33.33.23.13.13" xref="S3.E1.m1.33.33.33.23.13.13.cmml">+</mo><mn id="S3.E1.m1.34.34.34.24.14.14" xref="S3.E1.m1.34.34.34.24.14.14.cmml">1</mn></mrow></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E1.m1.39b"><apply id="S3.E1.m1.36.36.2.3.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><csymbol cd="ambiguous" id="S3.E1.m1.36.36.2.3a.cmml" xref="S3.E1.m1.10.10.10.10.8.10">formulae-sequence</csymbol><apply id="S3.E1.m1.35.35.1.1.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><and id="S3.E1.m1.35.35.1.1.1a.cmml" xref="S3.E1.m1.10.10.10.10.8.10"></and><apply id="S3.E1.m1.35.35.1.1.1b.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><eq id="S3.E1.m1.3.3.3.3.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1"></eq><apply id="S3.E1.m1.35.35.1.1.1.3.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><csymbol cd="ambiguous" id="S3.E1.m1.35.35.1.1.1.3.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">𝑧</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1">𝑡</ci></apply><apply id="S3.E1.m1.35.35.1.1.1.5.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><times id="S3.E1.m1.35.35.1.1.1.5.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10"></times><apply id="S3.E1.m1.35.35.1.1.1.5.2.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><csymbol cd="ambiguous" id="S3.E1.m1.35.35.1.1.1.5.2.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10">superscript</csymbol><ci id="S3.E1.m1.4.4.4.4.2.2.cmml" xref="S3.E1.m1.4.4.4.4.2.2">𝑊</ci><ci id="S3.E1.m1.5.5.5.5.3.3.1.cmml" xref="S3.E1.m1.5.5.5.5.3.3.1">𝑇</ci></apply><apply id="S3.E1.m1.35.35.1.1.1.5.3.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><csymbol cd="ambiguous" id="S3.E1.m1.35.35.1.1.1.5.3.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10">subscript</csymbol><ci id="S3.E1.m1.6.6.6.6.4.4.cmml" xref="S3.E1.m1.6.6.6.6.4.4">ℎ</ci><ci id="S3.E1.m1.7.7.7.7.5.5.1.cmml" xref="S3.E1.m1.7.7.7.7.5.5.1">𝑡</ci></apply></apply></apply><apply id="S3.E1.m1.35.35.1.1.1c.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><in id="S3.E1.m1.8.8.8.8.6.6.cmml" xref="S3.E1.m1.8.8.8.8.6.6"></in><share href="#S3.E1.m1.35.35.1.1.1.5.cmml" id="S3.E1.m1.35.35.1.1.1d.cmml" xref="S3.E1.m1.10.10.10.10.8.10"></share><apply id="S3.E1.m1.35.35.1.1.1.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><times id="S3.E1.m1.35.35.1.1.1.1.2.cmml" xref="S3.E1.m1.10.10.10.10.8.10"></times><apply id="S3.E1.m1.35.35.1.1.1.1.3.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><csymbol cd="ambiguous" id="S3.E1.m1.35.35.1.1.1.1.3.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10">superscript</csymbol><ci id="S3.E1.m1.9.9.9.9.7.7.cmml" xref="S3.E1.m1.9.9.9.9.7.7">ℝ</ci><apply id="S3.E1.m1.10.10.10.10.8.8.1.cmml" xref="S3.E1.m1.10.10.10.10.8.8.1"><plus id="S3.E1.m1.10.10.10.10.8.8.1.2.cmml" xref="S3.E1.m1.10.10.10.10.8.8.1.2"></plus><apply id="S3.E1.m1.10.10.10.10.8.8.1.3.1.cmml" xref="S3.E1.m1.10.10.10.10.8.8.1.3.2"><abs id="S3.E1.m1.10.10.10.10.8.8.1.3.1.1.cmml" xref="S3.E1.m1.10.10.10.10.8.8.1.3.2.1"></abs><ci id="S3.E1.m1.10.10.10.10.8.8.1.1.cmml" xref="S3.E1.m1.10.10.10.10.8.8.1.1">𝑉</ci></apply><cn type="integer" id="S3.E1.m1.10.10.10.10.8.8.1.4.cmml" xref="S3.E1.m1.10.10.10.10.8.8.1.4">1</cn></apply></apply><ci id="S3.E1.m1.11.11.11.1.1.1.cmml" xref="S3.E1.m1.11.11.11.1.1.1">𝑃</ci><apply id="S3.E1.m1.35.35.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><eq id="S3.E1.m1.15.15.15.5.5.5.cmml" xref="S3.E1.m1.15.15.15.5.5.5"></eq><apply id="S3.E1.m1.35.35.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><csymbol cd="ambiguous" id="S3.E1.m1.35.35.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10">subscript</csymbol><ci id="S3.E1.m1.13.13.13.3.3.3.cmml" xref="S3.E1.m1.13.13.13.3.3.3">𝜋</ci><ci id="S3.E1.m1.14.14.14.4.4.4.1.cmml" xref="S3.E1.m1.14.14.14.4.4.4.1">𝑡</ci></apply><apply id="S3.E1.m1.35.35.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><csymbol cd="latexml" id="S3.E1.m1.17.17.17.7.7.7.cmml" xref="S3.E1.m1.17.17.17.7.7.7">conditional</csymbol><ci id="S3.E1.m1.16.16.16.6.6.6.cmml" xref="S3.E1.m1.16.16.16.6.6.6">𝑘</ci><apply id="S3.E1.m1.35.35.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><csymbol cd="ambiguous" id="S3.E1.m1.35.35.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10">subscript</csymbol><ci id="S3.E1.m1.18.18.18.8.8.8.cmml" xref="S3.E1.m1.18.18.18.8.8.8">𝑥</ci><apply id="S3.E1.m1.19.19.19.9.9.9.1.cmml" xref="S3.E1.m1.19.19.19.9.9.9.1"><ci id="S3.E1.m1.19.19.19.9.9.9.1.1.cmml" xref="S3.E1.m1.19.19.19.9.9.9.1.1">:</ci><cn type="integer" id="S3.E1.m1.19.19.19.9.9.9.1.2.cmml" xref="S3.E1.m1.19.19.19.9.9.9.1.2">1</cn><ci id="S3.E1.m1.19.19.19.9.9.9.1.3.cmml" xref="S3.E1.m1.19.19.19.9.9.9.1.3">𝑇</ci></apply></apply></apply></apply></apply></apply><apply id="S3.E1.m1.35.35.1.1.1e.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><eq id="S3.E1.m1.21.21.21.11.1.1.cmml" xref="S3.E1.m1.21.21.21.11.1.1"></eq><share href="#S3.E1.m1.35.35.1.1.1.1.cmml" id="S3.E1.m1.35.35.1.1.1f.cmml" xref="S3.E1.m1.10.10.10.10.8.10"></share><apply id="S3.E1.m1.22.22.22.12.2.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2"><divide id="S3.E1.m1.22.22.22.12.2.2.6.cmml" xref="S3.E1.m1.22.22.22.12.2.2"></divide><apply id="S3.E1.m1.22.22.22.12.2.2.2.3.cmml" xref="S3.E1.m1.22.22.22.12.2.2.2.2"><exp id="S3.E1.m1.22.22.22.12.2.2.1.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.1.1"></exp><apply id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1">superscript</csymbol><apply id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.2">𝑧</ci><ci id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.3.cmml" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.2.3">𝑡</ci></apply><ci id="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.3.cmml" xref="S3.E1.m1.22.22.22.12.2.2.2.2.1.1.3">𝑘</ci></apply></apply><apply id="S3.E1.m1.22.22.22.12.2.2.5.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5"><apply id="S3.E1.m1.22.22.22.12.2.2.5.4.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4"><csymbol cd="ambiguous" id="S3.E1.m1.22.22.22.12.2.2.5.4.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4">superscript</csymbol><apply id="S3.E1.m1.22.22.22.12.2.2.5.4.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4"><csymbol cd="ambiguous" id="S3.E1.m1.22.22.22.12.2.2.5.4.2.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4">subscript</csymbol><sum id="S3.E1.m1.22.22.22.12.2.2.5.4.2.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.2"></sum><apply id="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.3"><eq id="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.1"></eq><ci id="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.2">𝑗</ci><cn type="integer" id="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.3.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.4.2.3.3">1</cn></apply></apply><apply id="S3.E1.m1.22.22.22.12.2.2.3.1.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1"><plus id="S3.E1.m1.22.22.22.12.2.2.3.1.1.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.2"></plus><apply id="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.2"><abs id="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.1.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.3.2.1"></abs><ci id="S3.E1.m1.22.22.22.12.2.2.3.1.1.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.1">𝑉</ci></apply><cn type="integer" id="S3.E1.m1.22.22.22.12.2.2.3.1.1.4.cmml" xref="S3.E1.m1.22.22.22.12.2.2.3.1.1.4">1</cn></apply></apply><apply id="S3.E1.m1.22.22.22.12.2.2.5.3.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1"><exp id="S3.E1.m1.22.22.22.12.2.2.4.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.4.2"></exp><apply id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1">superscript</csymbol><apply id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.1.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1">subscript</csymbol><ci id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.2.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.2">𝑧</ci><ci id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.3.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.2.3">𝑡</ci></apply><ci id="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.3.cmml" xref="S3.E1.m1.22.22.22.12.2.2.5.3.1.1.1.3">𝑗</ci></apply></apply></apply></apply></apply></apply><apply id="S3.E1.m1.36.36.2.2.2.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><eq id="S3.E1.m1.25.25.25.15.5.5.cmml" xref="S3.E1.m1.25.25.25.15.5.5"></eq><ci id="S3.E1.m1.24.24.24.14.4.4.cmml" xref="S3.E1.m1.24.24.24.14.4.4">𝑘</ci><list id="S3.E1.m1.36.36.2.2.2.1.2.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><cn type="integer" id="S3.E1.m1.26.26.26.16.6.6.cmml" xref="S3.E1.m1.26.26.26.16.6.6">1</cn><ci id="S3.E1.m1.28.28.28.18.8.8.cmml" xref="S3.E1.m1.28.28.28.18.8.8">⋯</ci><apply id="S3.E1.m1.36.36.2.2.2.1.1.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><plus id="S3.E1.m1.33.33.33.23.13.13.cmml" xref="S3.E1.m1.33.33.33.23.13.13"></plus><apply id="S3.E1.m1.36.36.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.10.10.10.10.8.10"><abs id="S3.E1.m1.36.36.2.2.2.1.1.1.2.1.cmml" xref="S3.E1.m1.10.10.10.10.8.10"></abs><ci id="S3.E1.m1.31.31.31.21.11.11.cmml" xref="S3.E1.m1.31.31.31.21.11.11">𝑉</ci></apply><cn type="integer" id="S3.E1.m1.34.34.34.24.14.14.cmml" xref="S3.E1.m1.34.34.34.24.14.14">1</cn></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.39c">\begin{split}z_{t}&amp;=W^{T}h_{t}\in\mathbb{R}^{|V|+1}\\
P(\pi_{t}=k|x_{1:T})&amp;=\frac{\exp(z_{t}^{k})}{\sum_{j=1}^{|V|+1}\exp(z_{t}^{j})},k=1,\cdots,|V|+1\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.16" class="ltx_p">where <math id="S3.SS1.p1.13.m1.2" class="ltx_Math" alttext="W\in\mathbb{R}^{(|V|+1)\times D}" display="inline"><semantics id="S3.SS1.p1.13.m1.2a"><mrow id="S3.SS1.p1.13.m1.2.3" xref="S3.SS1.p1.13.m1.2.3.cmml"><mi id="S3.SS1.p1.13.m1.2.3.2" xref="S3.SS1.p1.13.m1.2.3.2.cmml">W</mi><mo id="S3.SS1.p1.13.m1.2.3.1" xref="S3.SS1.p1.13.m1.2.3.1.cmml">∈</mo><msup id="S3.SS1.p1.13.m1.2.3.3" xref="S3.SS1.p1.13.m1.2.3.3.cmml"><mi id="S3.SS1.p1.13.m1.2.3.3.2" xref="S3.SS1.p1.13.m1.2.3.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.13.m1.2.2.2" xref="S3.SS1.p1.13.m1.2.2.2.cmml"><mrow id="S3.SS1.p1.13.m1.2.2.2.2.1" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.13.m1.2.2.2.2.1.2" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S3.SS1.p1.13.m1.2.2.2.2.1.1" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.cmml"><mrow id="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.2" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.1.cmml"><mo stretchy="false" id="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.2.1" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.1.1.cmml">|</mo><mi id="S3.SS1.p1.13.m1.1.1.1.1" xref="S3.SS1.p1.13.m1.1.1.1.1.cmml">V</mi><mo stretchy="false" id="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.2.2" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.1.1.cmml">|</mo></mrow><mo id="S3.SS1.p1.13.m1.2.2.2.2.1.1.1" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.1.cmml">+</mo><mn id="S3.SS1.p1.13.m1.2.2.2.2.1.1.3" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.3.cmml">1</mn></mrow><mo rspace="0.055em" stretchy="false" id="S3.SS1.p1.13.m1.2.2.2.2.1.3" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.SS1.p1.13.m1.2.2.2.3" xref="S3.SS1.p1.13.m1.2.2.2.3.cmml">×</mo><mi id="S3.SS1.p1.13.m1.2.2.2.4" xref="S3.SS1.p1.13.m1.2.2.2.4.cmml">D</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m1.2b"><apply id="S3.SS1.p1.13.m1.2.3.cmml" xref="S3.SS1.p1.13.m1.2.3"><in id="S3.SS1.p1.13.m1.2.3.1.cmml" xref="S3.SS1.p1.13.m1.2.3.1"></in><ci id="S3.SS1.p1.13.m1.2.3.2.cmml" xref="S3.SS1.p1.13.m1.2.3.2">𝑊</ci><apply id="S3.SS1.p1.13.m1.2.3.3.cmml" xref="S3.SS1.p1.13.m1.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m1.2.3.3.1.cmml" xref="S3.SS1.p1.13.m1.2.3.3">superscript</csymbol><ci id="S3.SS1.p1.13.m1.2.3.3.2.cmml" xref="S3.SS1.p1.13.m1.2.3.3.2">ℝ</ci><apply id="S3.SS1.p1.13.m1.2.2.2.cmml" xref="S3.SS1.p1.13.m1.2.2.2"><times id="S3.SS1.p1.13.m1.2.2.2.3.cmml" xref="S3.SS1.p1.13.m1.2.2.2.3"></times><apply id="S3.SS1.p1.13.m1.2.2.2.2.1.1.cmml" xref="S3.SS1.p1.13.m1.2.2.2.2.1"><plus id="S3.SS1.p1.13.m1.2.2.2.2.1.1.1.cmml" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.1"></plus><apply id="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.1.cmml" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.2"><abs id="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.1.1.cmml" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.2.2.1"></abs><ci id="S3.SS1.p1.13.m1.1.1.1.1.cmml" xref="S3.SS1.p1.13.m1.1.1.1.1">𝑉</ci></apply><cn type="integer" id="S3.SS1.p1.13.m1.2.2.2.2.1.1.3.cmml" xref="S3.SS1.p1.13.m1.2.2.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.p1.13.m1.2.2.2.4.cmml" xref="S3.SS1.p1.13.m1.2.2.2.4">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m1.2c">W\in\mathbb{R}^{(|V|+1)\times D}</annotation></semantics></math> denotes the weight matrix, and we omit the bias vector in describing the linear layer.
The un-normalized outputs <math id="S3.SS1.p1.14.m2.1" class="ltx_Math" alttext="z_{t}" display="inline"><semantics id="S3.SS1.p1.14.m2.1a"><msub id="S3.SS1.p1.14.m2.1.1" xref="S3.SS1.p1.14.m2.1.1.cmml"><mi id="S3.SS1.p1.14.m2.1.1.2" xref="S3.SS1.p1.14.m2.1.1.2.cmml">z</mi><mi id="S3.SS1.p1.14.m2.1.1.3" xref="S3.SS1.p1.14.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m2.1b"><apply id="S3.SS1.p1.14.m2.1.1.cmml" xref="S3.SS1.p1.14.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.14.m2.1.1.1.cmml" xref="S3.SS1.p1.14.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.14.m2.1.1.2.cmml" xref="S3.SS1.p1.14.m2.1.1.2">𝑧</ci><ci id="S3.SS1.p1.14.m2.1.1.3.cmml" xref="S3.SS1.p1.14.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m2.1c">z_{t}</annotation></semantics></math> are often called logits, and <math id="S3.SS1.p1.15.m3.1" class="ltx_Math" alttext="z^{k}_{t}" display="inline"><semantics id="S3.SS1.p1.15.m3.1a"><msubsup id="S3.SS1.p1.15.m3.1.1" xref="S3.SS1.p1.15.m3.1.1.cmml"><mi id="S3.SS1.p1.15.m3.1.1.2.2" xref="S3.SS1.p1.15.m3.1.1.2.2.cmml">z</mi><mi id="S3.SS1.p1.15.m3.1.1.3" xref="S3.SS1.p1.15.m3.1.1.3.cmml">t</mi><mi id="S3.SS1.p1.15.m3.1.1.2.3" xref="S3.SS1.p1.15.m3.1.1.2.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m3.1b"><apply id="S3.SS1.p1.15.m3.1.1.cmml" xref="S3.SS1.p1.15.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.15.m3.1.1.1.cmml" xref="S3.SS1.p1.15.m3.1.1">subscript</csymbol><apply id="S3.SS1.p1.15.m3.1.1.2.cmml" xref="S3.SS1.p1.15.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.15.m3.1.1.2.1.cmml" xref="S3.SS1.p1.15.m3.1.1">superscript</csymbol><ci id="S3.SS1.p1.15.m3.1.1.2.2.cmml" xref="S3.SS1.p1.15.m3.1.1.2.2">𝑧</ci><ci id="S3.SS1.p1.15.m3.1.1.2.3.cmml" xref="S3.SS1.p1.15.m3.1.1.2.3">𝑘</ci></apply><ci id="S3.SS1.p1.15.m3.1.1.3.cmml" xref="S3.SS1.p1.15.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m3.1c">z^{k}_{t}</annotation></semantics></math> denotes the logit corresponding to label <math id="S3.SS1.p1.16.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p1.16.m4.1a"><mi id="S3.SS1.p1.16.m4.1.1" xref="S3.SS1.p1.16.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.16.m4.1b"><ci id="S3.SS1.p1.16.m4.1.1.cmml" xref="S3.SS1.p1.16.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.16.m4.1c">k</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.8" class="ltx_p">In phoneme-based multilingual supervised pre-training investigated in this paper, which is called Whistle, we take the union of the phoneme inventories from the seen languages to be the alphabet of labels <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="V_{\text{multi}}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">V</mi><mtext id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3a.cmml">multi</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝑉</ci><ci id="S3.SS1.p2.1.m1.1.1.3a.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">multi</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">V_{\text{multi}}</annotation></semantics></math>.
The <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">k</annotation></semantics></math>-th row vector from the matrix <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">W</annotation></semantics></math>, denoted by <math id="S3.SS1.p2.4.m4.2" class="ltx_Math" alttext="W(k,:)" display="inline"><semantics id="S3.SS1.p2.4.m4.2a"><mrow id="S3.SS1.p2.4.m4.2.3" xref="S3.SS1.p2.4.m4.2.3.cmml"><mi id="S3.SS1.p2.4.m4.2.3.2" xref="S3.SS1.p2.4.m4.2.3.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.2.3.1" xref="S3.SS1.p2.4.m4.2.3.1.cmml">​</mo><mrow id="S3.SS1.p2.4.m4.2.3.3.2" xref="S3.SS1.p2.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.4.m4.2.3.3.2.1" xref="S3.SS1.p2.4.m4.2.3.3.1.cmml">(</mo><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">k</mi><mo id="S3.SS1.p2.4.m4.2.3.3.2.2" xref="S3.SS1.p2.4.m4.2.3.3.1.cmml">,</mo><mo rspace="0em" id="S3.SS1.p2.4.m4.2.2" xref="S3.SS1.p2.4.m4.2.2.cmml">:</mo><mo stretchy="false" id="S3.SS1.p2.4.m4.2.3.3.2.3" xref="S3.SS1.p2.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.2b"><apply id="S3.SS1.p2.4.m4.2.3.cmml" xref="S3.SS1.p2.4.m4.2.3"><times id="S3.SS1.p2.4.m4.2.3.1.cmml" xref="S3.SS1.p2.4.m4.2.3.1"></times><ci id="S3.SS1.p2.4.m4.2.3.2.cmml" xref="S3.SS1.p2.4.m4.2.3.2">𝑊</ci><interval closure="open" id="S3.SS1.p2.4.m4.2.3.3.1.cmml" xref="S3.SS1.p2.4.m4.2.3.3.2"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">𝑘</ci><ci id="S3.SS1.p2.4.m4.2.2.cmml" xref="S3.SS1.p2.4.m4.2.2">:</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.2c">W(k,:)</annotation></semantics></math>, could be viewed as the phoneme embedding for phoneme <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">k</annotation></semantics></math>.
The logit for phoneme <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">k</annotation></semantics></math> at frame <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mi id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><ci id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">t</annotation></semantics></math> is actually an inner product between the phoneme embedding and the representation vector, <math id="S3.SS1.p2.8.m8.2" class="ltx_Math" alttext="z_{t}^{k}=W(k,:)^{T}h_{t}" display="inline"><semantics id="S3.SS1.p2.8.m8.2a"><mrow id="S3.SS1.p2.8.m8.2.3" xref="S3.SS1.p2.8.m8.2.3.cmml"><msubsup id="S3.SS1.p2.8.m8.2.3.2" xref="S3.SS1.p2.8.m8.2.3.2.cmml"><mi id="S3.SS1.p2.8.m8.2.3.2.2.2" xref="S3.SS1.p2.8.m8.2.3.2.2.2.cmml">z</mi><mi id="S3.SS1.p2.8.m8.2.3.2.2.3" xref="S3.SS1.p2.8.m8.2.3.2.2.3.cmml">t</mi><mi id="S3.SS1.p2.8.m8.2.3.2.3" xref="S3.SS1.p2.8.m8.2.3.2.3.cmml">k</mi></msubsup><mo id="S3.SS1.p2.8.m8.2.3.1" xref="S3.SS1.p2.8.m8.2.3.1.cmml">=</mo><mrow id="S3.SS1.p2.8.m8.2.3.3" xref="S3.SS1.p2.8.m8.2.3.3.cmml"><mi id="S3.SS1.p2.8.m8.2.3.3.2" xref="S3.SS1.p2.8.m8.2.3.3.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.8.m8.2.3.3.1" xref="S3.SS1.p2.8.m8.2.3.3.1.cmml">​</mo><msup id="S3.SS1.p2.8.m8.2.3.3.3" xref="S3.SS1.p2.8.m8.2.3.3.3.cmml"><mrow id="S3.SS1.p2.8.m8.2.3.3.3.2.2" xref="S3.SS1.p2.8.m8.2.3.3.3.2.1.cmml"><mo stretchy="false" id="S3.SS1.p2.8.m8.2.3.3.3.2.2.1" xref="S3.SS1.p2.8.m8.2.3.3.3.2.1.cmml">(</mo><mi id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">k</mi><mo id="S3.SS1.p2.8.m8.2.3.3.3.2.2.2" xref="S3.SS1.p2.8.m8.2.3.3.3.2.1.cmml">,</mo><mo rspace="0em" id="S3.SS1.p2.8.m8.2.2" xref="S3.SS1.p2.8.m8.2.2.cmml">:</mo><mo stretchy="false" id="S3.SS1.p2.8.m8.2.3.3.3.2.2.3" xref="S3.SS1.p2.8.m8.2.3.3.3.2.1.cmml">)</mo></mrow><mi id="S3.SS1.p2.8.m8.2.3.3.3.3" xref="S3.SS1.p2.8.m8.2.3.3.3.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS1.p2.8.m8.2.3.3.1a" xref="S3.SS1.p2.8.m8.2.3.3.1.cmml">​</mo><msub id="S3.SS1.p2.8.m8.2.3.3.4" xref="S3.SS1.p2.8.m8.2.3.3.4.cmml"><mi id="S3.SS1.p2.8.m8.2.3.3.4.2" xref="S3.SS1.p2.8.m8.2.3.3.4.2.cmml">h</mi><mi id="S3.SS1.p2.8.m8.2.3.3.4.3" xref="S3.SS1.p2.8.m8.2.3.3.4.3.cmml">t</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.2b"><apply id="S3.SS1.p2.8.m8.2.3.cmml" xref="S3.SS1.p2.8.m8.2.3"><eq id="S3.SS1.p2.8.m8.2.3.1.cmml" xref="S3.SS1.p2.8.m8.2.3.1"></eq><apply id="S3.SS1.p2.8.m8.2.3.2.cmml" xref="S3.SS1.p2.8.m8.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.2.3.2.1.cmml" xref="S3.SS1.p2.8.m8.2.3.2">superscript</csymbol><apply id="S3.SS1.p2.8.m8.2.3.2.2.cmml" xref="S3.SS1.p2.8.m8.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.2.3.2.2.1.cmml" xref="S3.SS1.p2.8.m8.2.3.2">subscript</csymbol><ci id="S3.SS1.p2.8.m8.2.3.2.2.2.cmml" xref="S3.SS1.p2.8.m8.2.3.2.2.2">𝑧</ci><ci id="S3.SS1.p2.8.m8.2.3.2.2.3.cmml" xref="S3.SS1.p2.8.m8.2.3.2.2.3">𝑡</ci></apply><ci id="S3.SS1.p2.8.m8.2.3.2.3.cmml" xref="S3.SS1.p2.8.m8.2.3.2.3">𝑘</ci></apply><apply id="S3.SS1.p2.8.m8.2.3.3.cmml" xref="S3.SS1.p2.8.m8.2.3.3"><times id="S3.SS1.p2.8.m8.2.3.3.1.cmml" xref="S3.SS1.p2.8.m8.2.3.3.1"></times><ci id="S3.SS1.p2.8.m8.2.3.3.2.cmml" xref="S3.SS1.p2.8.m8.2.3.3.2">𝑊</ci><apply id="S3.SS1.p2.8.m8.2.3.3.3.cmml" xref="S3.SS1.p2.8.m8.2.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.2.3.3.3.1.cmml" xref="S3.SS1.p2.8.m8.2.3.3.3">superscript</csymbol><interval closure="open" id="S3.SS1.p2.8.m8.2.3.3.3.2.1.cmml" xref="S3.SS1.p2.8.m8.2.3.3.3.2.2"><ci id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">𝑘</ci><ci id="S3.SS1.p2.8.m8.2.2.cmml" xref="S3.SS1.p2.8.m8.2.2">:</ci></interval><ci id="S3.SS1.p2.8.m8.2.3.3.3.3.cmml" xref="S3.SS1.p2.8.m8.2.3.3.3.3">𝑇</ci></apply><apply id="S3.SS1.p2.8.m8.2.3.3.4.cmml" xref="S3.SS1.p2.8.m8.2.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.2.3.3.4.1.cmml" xref="S3.SS1.p2.8.m8.2.3.3.4">subscript</csymbol><ci id="S3.SS1.p2.8.m8.2.3.3.4.2.cmml" xref="S3.SS1.p2.8.m8.2.3.3.4.2">ℎ</ci><ci id="S3.SS1.p2.8.m8.2.3.3.4.3.cmml" xref="S3.SS1.p2.8.m8.2.3.3.4.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.2c">z_{t}^{k}=W(k,:)^{T}h_{t}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">For recognizing speech from a seen language, the pre-trained encoder together with the phoneme embeddings can be directly used without fine-tuning.
Specifically, we build a weighted finite state transducer (WFST) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, obtained by composing the CTC topology, pronunciation lexicon and word-level n-gram language model, and use WFST-based decoding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
While requiring pronunciation lexicons (PROLEX), pre-training with phonetic supervision is more advantageous for information sharing between different languages.
In this paper, we relax the requirement of gold-standard human-validated PROLEX and transcripts, by leveraging the LanguageNet G2P models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. The LanguageNet G2P models are available for 142 languages. The phonemization procedure in Whistle is detailed in Section <a href="#S4.SS2" title="IV-B Text normalization and phonemization ‣ IV Experimental setup ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.5" class="ltx_p">For crosslingual speech recognition, denote the phoneme inventory for a new, target language (unseen in pre-training) by <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="V_{\text{cross}}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><msub id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">V</mi><mtext id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3a.cmml">cross</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">𝑉</ci><ci id="S3.SS1.p4.1.m1.1.1.3a.cmml" xref="S3.SS1.p4.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">cross</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">V_{\text{cross}}</annotation></semantics></math>.
For recognizing speech from the target language, we can initialize a CTC-based model from the pre-trained encoder. The embeddings corresponding to the phonemes in <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="V_{\text{multi}}\cap V_{\text{cross}}" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mrow id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><msub id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2.2" xref="S3.SS1.p4.2.m2.1.1.2.2.cmml">V</mi><mtext id="S3.SS1.p4.2.m2.1.1.2.3" xref="S3.SS1.p4.2.m2.1.1.2.3a.cmml">multi</mtext></msub><mo id="S3.SS1.p4.2.m2.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.cmml">∩</mo><msub id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml"><mi id="S3.SS1.p4.2.m2.1.1.3.2" xref="S3.SS1.p4.2.m2.1.1.3.2.cmml">V</mi><mtext id="S3.SS1.p4.2.m2.1.1.3.3" xref="S3.SS1.p4.2.m2.1.1.3.3a.cmml">cross</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><intersect id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1"></intersect><apply id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.2.1.cmml" xref="S3.SS1.p4.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.2.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2.2">𝑉</ci><ci id="S3.SS1.p4.2.m2.1.1.2.3a.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.p4.2.m2.1.1.2.3.cmml" xref="S3.SS1.p4.2.m2.1.1.2.3">multi</mtext></ci></apply><apply id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.3.2">𝑉</ci><ci id="S3.SS1.p4.2.m2.1.1.3.3a.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3"><mtext mathsize="70%" id="S3.SS1.p4.2.m2.1.1.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3">cross</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">V_{\text{multi}}\cap V_{\text{cross}}</annotation></semantics></math> are directly copied for initialization.
For those phonemes that are not included in the multilingual phoneme alphabet <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="V_{\text{multi}}" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><msub id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><mi id="S3.SS1.p4.3.m3.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml">V</mi><mtext id="S3.SS1.p4.3.m3.1.1.3" xref="S3.SS1.p4.3.m3.1.1.3a.cmml">multi</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2">𝑉</ci><ci id="S3.SS1.p4.3.m3.1.1.3a.cmml" xref="S3.SS1.p4.3.m3.1.1.3"><mtext mathsize="70%" id="S3.SS1.p4.3.m3.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3">multi</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">V_{\text{multi}}</annotation></semantics></math> but appeared in the target language inventory <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="V_{\text{cross}}" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><msub id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml"><mi id="S3.SS1.p4.4.m4.1.1.2" xref="S3.SS1.p4.4.m4.1.1.2.cmml">V</mi><mtext id="S3.SS1.p4.4.m4.1.1.3" xref="S3.SS1.p4.4.m4.1.1.3a.cmml">cross</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><apply id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2">𝑉</ci><ci id="S3.SS1.p4.4.m4.1.1.3a.cmml" xref="S3.SS1.p4.4.m4.1.1.3"><mtext mathsize="70%" id="S3.SS1.p4.4.m4.1.1.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3">cross</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">V_{\text{cross}}</annotation></semantics></math>, we randomly initialize their phoneme embeddings.
The initialized CTC model can then be fine-tuned over labeled speech from the target language.
In this way, the fine-tuned encoder and phoneme embeddings can be used to calculate the logits and the posteriori distribution of <math id="S3.SS1.p4.5.m5.1" class="ltx_Math" alttext="\pi_{t}" display="inline"><semantics id="S3.SS1.p4.5.m5.1a"><msub id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml"><mi id="S3.SS1.p4.5.m5.1.1.2" xref="S3.SS1.p4.5.m5.1.1.2.cmml">π</mi><mi id="S3.SS1.p4.5.m5.1.1.3" xref="S3.SS1.p4.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2">𝜋</ci><ci id="S3.SS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">\pi_{t}</annotation></semantics></math> in CTC, and WFST-based decoding can be applied for recognizing speech from the target language.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Subword-based multilingual supervised pre-training</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">Multilingual supervised pre-training based on subwords is very similar to that based on phonemes, as described in Section <a href="#S3.SS1" title="III-A Phoneme-based multilingual supervised pre-training ‣ III Approach ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>, which can still base on the CTC method and use WFST-based decoding with word-level n-gram language model.
The major difference is that subword-based multilingual supervised pre-training employs subwords for labeling. Thus, the alphabet of labels <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">V</annotation></semantics></math> consists of subwords; the lexicon for WFST-based decoing is an orthography lexicon (i.e., words are formed by a sequence of subwords); The row vectors from the matrix <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">W</annotation></semantics></math> could be viewed as embeddings for subwords.
Converting text into subwords is often referred to tokenization, which is still under investigation and needs a balance between granularity and ASR performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">In this paper, we use Byte Pair Encoding (BPE) based subwords, or say, tokens <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.
BPE introduces a word segmentation algorithm, which initializes the token alphabet with the character alphabet and iteratively merges the most frequent pair of tokens.
In this way, BPE obtains a compact token vocabulary of variable-length subword units.
Notably, the merging of tokens in BPE is based on their frequencies. A straightforward application of BPE may inappropriately favor the merging from high-resource languages; for low-resource languages, tokens may be mostly single characters.
Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, sentences are sampled according to a multinomial distribution with probabilities <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\left\{q_{l}\right\}_{l=1...N}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mrow id="S3.SS2.p2.1.m1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.2.cmml"><mo id="S3.SS2.p2.1.m1.1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.2.cmml">{</mo><msub id="S3.SS2.p2.1.m1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.1.1.2.cmml">q</mi><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.3.cmml">l</mi></msub><mo id="S3.SS2.p2.1.m1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.3.2.cmml">l</mi><mo id="S3.SS2.p2.1.m1.1.1.3.1" xref="S3.SS2.p2.1.m1.1.1.3.1.cmml">=</mo><mrow id="S3.SS2.p2.1.m1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.cmml"><mn id="S3.SS2.p2.1.m1.1.1.3.3.2" xref="S3.SS2.p2.1.m1.1.1.3.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.3.3.1" xref="S3.SS2.p2.1.m1.1.1.3.3.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS2.p2.1.m1.1.1.3.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.3.cmml">…</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.3.3.1a" xref="S3.SS2.p2.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S3.SS2.p2.1.m1.1.1.3.3.4" xref="S3.SS2.p2.1.m1.1.1.3.3.4.cmml">N</mi></mrow></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><set id="S3.SS2.p2.1.m1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1"><apply id="S3.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.2">𝑞</ci><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.3">𝑙</ci></apply></set><apply id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><eq id="S3.SS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.1"></eq><ci id="S3.SS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2">𝑙</ci><apply id="S3.SS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3"><times id="S3.SS2.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.1"></times><cn type="integer" id="S3.SS2.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.2">1</cn><ci id="S3.SS2.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.3">…</ci><ci id="S3.SS2.p2.1.m1.1.1.3.3.4.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.4">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\left\{q_{l}\right\}_{l=1...N}</annotation></semantics></math>:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="q_{l}=\frac{p_{l}^{\beta}}{\sum_{i=1}^{N}p_{i}^{\beta}}\quad with\quad p_{l}=\frac{n_{l}}{\sum_{i=1}^{N}n_{i}}," display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1"><mrow id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.3.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><msub id="S3.E2.m1.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.3.2.cmml">q</mi><mi id="S3.E2.m1.2.2.1.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.1.3.3.cmml">l</mi></msub><mo id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml"><mfrac id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><msubsup id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.2.2.2" xref="S3.E2.m1.1.1.2.2.2.cmml">p</mi><mi id="S3.E2.m1.1.1.2.2.3" xref="S3.E2.m1.1.1.2.2.3.cmml">l</mi><mi id="S3.E2.m1.1.1.2.3" xref="S3.E2.m1.1.1.2.3.cmml">β</mi></msubsup><mrow id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><msubsup id="S3.E2.m1.1.1.3.1" xref="S3.E2.m1.1.1.3.1.cmml"><mo id="S3.E2.m1.1.1.3.1.2.2" xref="S3.E2.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.E2.m1.1.1.3.1.2.3" xref="S3.E2.m1.1.1.3.1.2.3.cmml"><mi id="S3.E2.m1.1.1.3.1.2.3.2" xref="S3.E2.m1.1.1.3.1.2.3.2.cmml">i</mi><mo id="S3.E2.m1.1.1.3.1.2.3.1" xref="S3.E2.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E2.m1.1.1.3.1.2.3.3" xref="S3.E2.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.1.1.3.1.3" xref="S3.E2.m1.1.1.3.1.3.cmml">N</mi></msubsup><msubsup id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.3.2.2.2" xref="S3.E2.m1.1.1.3.2.2.2.cmml">p</mi><mi id="S3.E2.m1.1.1.3.2.2.3" xref="S3.E2.m1.1.1.3.2.2.3.cmml">i</mi><mi id="S3.E2.m1.1.1.3.2.3" xref="S3.E2.m1.1.1.3.2.3.cmml">β</mi></msubsup></mrow></mfrac><mspace width="1em" id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml"></mspace><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1a" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1b" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.5" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.5.cmml">h</mi></mrow></mrow></mrow><mspace width="1em" id="S3.E2.m1.2.2.1.1.2.3" xref="S3.E2.m1.2.2.1.1.3a.cmml"></mspace><mrow id="S3.E2.m1.2.2.1.1.2.2" xref="S3.E2.m1.2.2.1.1.2.2.cmml"><msub id="S3.E2.m1.2.2.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.cmml">l</mi></msub><mo id="S3.E2.m1.2.2.1.1.2.2.1" xref="S3.E2.m1.2.2.1.1.2.2.1.cmml">=</mo><mfrac id="S3.E2.m1.2.2.1.1.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.3.cmml"><msub id="S3.E2.m1.2.2.1.1.2.2.3.2" xref="S3.E2.m1.2.2.1.1.2.2.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.3.2.2" xref="S3.E2.m1.2.2.1.1.2.2.3.2.2.cmml">n</mi><mi id="S3.E2.m1.2.2.1.1.2.2.3.2.3" xref="S3.E2.m1.2.2.1.1.2.2.3.2.3.cmml">l</mi></msub><mrow id="S3.E2.m1.2.2.1.1.2.2.3.3" xref="S3.E2.m1.2.2.1.1.2.2.3.3.cmml"><msubsup id="S3.E2.m1.2.2.1.1.2.2.3.3.1" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.cmml"><mo id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.2" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.2.cmml">∑</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.2" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.2.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.1" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.1.cmml">=</mo><mn id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.3" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.2.2.1.1.2.2.3.3.1.3" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.3.cmml">N</mi></msubsup><msub id="S3.E2.m1.2.2.1.1.2.2.3.3.2" xref="S3.E2.m1.2.2.1.1.2.2.3.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.3.3.2.2" xref="S3.E2.m1.2.2.1.1.2.2.3.3.2.2.cmml">n</mi><mi id="S3.E2.m1.2.2.1.1.2.2.3.3.2.3" xref="S3.E2.m1.2.2.1.1.2.2.3.3.2.3.cmml">i</mi></msub></mrow></mfrac></mrow></mrow><mo id="S3.E2.m1.2.2.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3a.cmml" xref="S3.E2.m1.2.2.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><eq id="S3.E2.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.2"></eq><apply id="S3.E2.m1.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2">𝑞</ci><ci id="S3.E2.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.3">𝑙</ci></apply><list id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><divide id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1"></divide><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.2">superscript</csymbol><apply id="S3.E2.m1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.2.2.2">𝑝</ci><ci id="S3.E2.m1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.2.2.3">𝑙</ci></apply><ci id="S3.E2.m1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.2.3">𝛽</ci></apply><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><apply id="S3.E2.m1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.1.1.cmml" xref="S3.E2.m1.1.1.3.1">superscript</csymbol><apply id="S3.E2.m1.1.1.3.1.2.cmml" xref="S3.E2.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.1.2.1.cmml" xref="S3.E2.m1.1.1.3.1">subscript</csymbol><sum id="S3.E2.m1.1.1.3.1.2.2.cmml" xref="S3.E2.m1.1.1.3.1.2.2"></sum><apply id="S3.E2.m1.1.1.3.1.2.3.cmml" xref="S3.E2.m1.1.1.3.1.2.3"><eq id="S3.E2.m1.1.1.3.1.2.3.1.cmml" xref="S3.E2.m1.1.1.3.1.2.3.1"></eq><ci id="S3.E2.m1.1.1.3.1.2.3.2.cmml" xref="S3.E2.m1.1.1.3.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E2.m1.1.1.3.1.2.3.3.cmml" xref="S3.E2.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.1.1.3.1.3.cmml" xref="S3.E2.m1.1.1.3.1.3">𝑁</ci></apply><apply id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.3.2">superscript</csymbol><apply id="S3.E2.m1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.3.2.2.2">𝑝</ci><ci id="S3.E2.m1.1.1.3.2.2.3.cmml" xref="S3.E2.m1.1.1.3.2.2.3">𝑖</ci></apply><ci id="S3.E2.m1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.3.2.3">𝛽</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1"></times><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2">𝑤</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3">𝑖</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.4">𝑡</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.5.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.5">ℎ</ci></apply></list></apply><apply id="S3.E2.m1.2.2.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2"><eq id="S3.E2.m1.2.2.1.1.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.1"></eq><apply id="S3.E2.m1.2.2.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3">𝑙</ci></apply><apply id="S3.E2.m1.2.2.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3"><divide id="S3.E2.m1.2.2.1.1.2.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3"></divide><apply id="S3.E2.m1.2.2.1.1.2.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.2.2">𝑛</ci><ci id="S3.E2.m1.2.2.1.1.2.2.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.2.3">𝑙</ci></apply><apply id="S3.E2.m1.2.2.1.1.2.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3"><apply id="S3.E2.m1.2.2.1.1.2.2.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.3.3.1.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1">subscript</csymbol><sum id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.2"></sum><apply id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3"><eq id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.1"></eq><ci id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.2">𝑖</ci><cn type="integer" id="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.2.2.1.1.2.2.3.3.1.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.1.3">𝑁</ci></apply><apply id="S3.E2.m1.2.2.1.1.2.2.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.3.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.3.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.2.2">𝑛</ci><ci id="S3.E2.m1.2.2.1.1.2.2.3.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3.3.2.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">q_{l}=\frac{p_{l}^{\beta}}{\sum_{i=1}^{N}p_{i}^{\beta}}\quad with\quad p_{l}=\frac{n_{l}}{\sum_{i=1}^{N}n_{i}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.6" class="ltx_p">where <math id="S3.SS2.p2.2.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS2.p2.2.m1.1a"><mi id="S3.SS2.p2.2.m1.1.1" xref="S3.SS2.p2.2.m1.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m1.1b"><ci id="S3.SS2.p2.2.m1.1.1.cmml" xref="S3.SS2.p2.2.m1.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m1.1c">\beta</annotation></semantics></math> controls the sampling of languages with different frequencies. We use <math id="S3.SS2.p2.3.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS2.p2.3.m2.1a"><mi id="S3.SS2.p2.3.m2.1.1" xref="S3.SS2.p2.3.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m2.1b"><ci id="S3.SS2.p2.3.m2.1.1.cmml" xref="S3.SS2.p2.3.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m2.1c">\beta</annotation></semantics></math> = 0.5 in experiments. <math id="S3.SS2.p2.4.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p2.4.m3.1a"><mi id="S3.SS2.p2.4.m3.1.1" xref="S3.SS2.p2.4.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m3.1b"><ci id="S3.SS2.p2.4.m3.1.1.cmml" xref="S3.SS2.p2.4.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m3.1c">N</annotation></semantics></math> is the number of seen languages in the training data, and <math id="S3.SS2.p2.5.m4.1" class="ltx_Math" alttext="n_{l}" display="inline"><semantics id="S3.SS2.p2.5.m4.1a"><msub id="S3.SS2.p2.5.m4.1.1" xref="S3.SS2.p2.5.m4.1.1.cmml"><mi id="S3.SS2.p2.5.m4.1.1.2" xref="S3.SS2.p2.5.m4.1.1.2.cmml">n</mi><mi id="S3.SS2.p2.5.m4.1.1.3" xref="S3.SS2.p2.5.m4.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m4.1b"><apply id="S3.SS2.p2.5.m4.1.1.cmml" xref="S3.SS2.p2.5.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m4.1.1.1.cmml" xref="S3.SS2.p2.5.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m4.1.1.2.cmml" xref="S3.SS2.p2.5.m4.1.1.2">𝑛</ci><ci id="S3.SS2.p2.5.m4.1.1.3.cmml" xref="S3.SS2.p2.5.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m4.1c">n_{l}</annotation></semantics></math> denotes the number of sentences for language <math id="S3.SS2.p2.6.m5.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S3.SS2.p2.6.m5.1a"><mi id="S3.SS2.p2.6.m5.1.1" xref="S3.SS2.p2.6.m5.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m5.1b"><ci id="S3.SS2.p2.6.m5.1.1.cmml" xref="S3.SS2.p2.6.m5.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m5.1c">l</annotation></semantics></math>.
By such data sampling, we can increase the number of tokens associated to low-resource languages and reduce the bias towards high-resource languages.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Multilingual self-supervised pre-training</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.8" class="ltx_p">We pre-train a wav2vec 2.0 model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> on our multilingual pre-training data (just audio data).
The basic architecture of the wav2vec 2.0 model is as follows.
A convolutional feature encoder
maps raw audio <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="x_{1:T}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">x</mi><mrow id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mn id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS3.p1.1.m1.1.1.3.1" xref="S3.SS3.p1.1.m1.1.1.3.1.cmml">:</mo><mi id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑥</ci><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><ci id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.1">:</ci><cn type="integer" id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">1</cn><ci id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">x_{1:T}</annotation></semantics></math> to latent speech features <math id="S3.SS3.p1.2.m2.3" class="ltx_Math" alttext="z_{1},\dots,z_{T}" display="inline"><semantics id="S3.SS3.p1.2.m2.3a"><mrow id="S3.SS3.p1.2.m2.3.3.2" xref="S3.SS3.p1.2.m2.3.3.3.cmml"><msub id="S3.SS3.p1.2.m2.2.2.1.1" xref="S3.SS3.p1.2.m2.2.2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.2.2.1.1.2" xref="S3.SS3.p1.2.m2.2.2.1.1.2.cmml">z</mi><mn id="S3.SS3.p1.2.m2.2.2.1.1.3" xref="S3.SS3.p1.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p1.2.m2.3.3.2.3" xref="S3.SS3.p1.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">…</mi><mo id="S3.SS3.p1.2.m2.3.3.2.4" xref="S3.SS3.p1.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS3.p1.2.m2.3.3.2.2" xref="S3.SS3.p1.2.m2.3.3.2.2.cmml"><mi id="S3.SS3.p1.2.m2.3.3.2.2.2" xref="S3.SS3.p1.2.m2.3.3.2.2.2.cmml">z</mi><mi id="S3.SS3.p1.2.m2.3.3.2.2.3" xref="S3.SS3.p1.2.m2.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.3b"><list id="S3.SS3.p1.2.m2.3.3.3.cmml" xref="S3.SS3.p1.2.m2.3.3.2"><apply id="S3.SS3.p1.2.m2.2.2.1.1.cmml" xref="S3.SS3.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.2.2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.2.2.1.1.2">𝑧</ci><cn type="integer" id="S3.SS3.p1.2.m2.2.2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">…</ci><apply id="S3.SS3.p1.2.m2.3.3.2.2.cmml" xref="S3.SS3.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.3.3.2.2.1.cmml" xref="S3.SS3.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS3.p1.2.m2.3.3.2.2.2">𝑧</ci><ci id="S3.SS3.p1.2.m2.3.3.2.2.3.cmml" xref="S3.SS3.p1.2.m2.3.3.2.2.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.3c">z_{1},\dots,z_{T}</annotation></semantics></math>, which are then fed to a Transformer
to output contextual representations <math id="S3.SS3.p1.3.m3.3" class="ltx_Math" alttext="h_{1},\dots,h_{T}" display="inline"><semantics id="S3.SS3.p1.3.m3.3a"><mrow id="S3.SS3.p1.3.m3.3.3.2" xref="S3.SS3.p1.3.m3.3.3.3.cmml"><msub id="S3.SS3.p1.3.m3.2.2.1.1" xref="S3.SS3.p1.3.m3.2.2.1.1.cmml"><mi id="S3.SS3.p1.3.m3.2.2.1.1.2" xref="S3.SS3.p1.3.m3.2.2.1.1.2.cmml">h</mi><mn id="S3.SS3.p1.3.m3.2.2.1.1.3" xref="S3.SS3.p1.3.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p1.3.m3.3.3.2.3" xref="S3.SS3.p1.3.m3.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">…</mi><mo id="S3.SS3.p1.3.m3.3.3.2.4" xref="S3.SS3.p1.3.m3.3.3.3.cmml">,</mo><msub id="S3.SS3.p1.3.m3.3.3.2.2" xref="S3.SS3.p1.3.m3.3.3.2.2.cmml"><mi id="S3.SS3.p1.3.m3.3.3.2.2.2" xref="S3.SS3.p1.3.m3.3.3.2.2.2.cmml">h</mi><mi id="S3.SS3.p1.3.m3.3.3.2.2.3" xref="S3.SS3.p1.3.m3.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.3b"><list id="S3.SS3.p1.3.m3.3.3.3.cmml" xref="S3.SS3.p1.3.m3.3.3.2"><apply id="S3.SS3.p1.3.m3.2.2.1.1.cmml" xref="S3.SS3.p1.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SS3.p1.3.m3.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.2.2.1.1.2.cmml" xref="S3.SS3.p1.3.m3.2.2.1.1.2">ℎ</ci><cn type="integer" id="S3.SS3.p1.3.m3.2.2.1.1.3.cmml" xref="S3.SS3.p1.3.m3.2.2.1.1.3">1</cn></apply><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">…</ci><apply id="S3.SS3.p1.3.m3.3.3.2.2.cmml" xref="S3.SS3.p1.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.3.3.2.2.1.cmml" xref="S3.SS3.p1.3.m3.3.3.2.2">subscript</csymbol><ci id="S3.SS3.p1.3.m3.3.3.2.2.2.cmml" xref="S3.SS3.p1.3.m3.3.3.2.2.2">ℎ</ci><ci id="S3.SS3.p1.3.m3.3.3.2.2.3.cmml" xref="S3.SS3.p1.3.m3.3.3.2.2.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.3c">h_{1},\dots,h_{T}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.
The Transformer architecture is the same as in BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.
During training, a quantization module is employed to discretize the latent features <math id="S3.SS3.p1.4.m4.3" class="ltx_Math" alttext="z_{1},\dots,z_{T}" display="inline"><semantics id="S3.SS3.p1.4.m4.3a"><mrow id="S3.SS3.p1.4.m4.3.3.2" xref="S3.SS3.p1.4.m4.3.3.3.cmml"><msub id="S3.SS3.p1.4.m4.2.2.1.1" xref="S3.SS3.p1.4.m4.2.2.1.1.cmml"><mi id="S3.SS3.p1.4.m4.2.2.1.1.2" xref="S3.SS3.p1.4.m4.2.2.1.1.2.cmml">z</mi><mn id="S3.SS3.p1.4.m4.2.2.1.1.3" xref="S3.SS3.p1.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p1.4.m4.3.3.2.3" xref="S3.SS3.p1.4.m4.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">…</mi><mo id="S3.SS3.p1.4.m4.3.3.2.4" xref="S3.SS3.p1.4.m4.3.3.3.cmml">,</mo><msub id="S3.SS3.p1.4.m4.3.3.2.2" xref="S3.SS3.p1.4.m4.3.3.2.2.cmml"><mi id="S3.SS3.p1.4.m4.3.3.2.2.2" xref="S3.SS3.p1.4.m4.3.3.2.2.2.cmml">z</mi><mi id="S3.SS3.p1.4.m4.3.3.2.2.3" xref="S3.SS3.p1.4.m4.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.3b"><list id="S3.SS3.p1.4.m4.3.3.3.cmml" xref="S3.SS3.p1.4.m4.3.3.2"><apply id="S3.SS3.p1.4.m4.2.2.1.1.cmml" xref="S3.SS3.p1.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.2.2.1.1.1.cmml" xref="S3.SS3.p1.4.m4.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m4.2.2.1.1.2.cmml" xref="S3.SS3.p1.4.m4.2.2.1.1.2">𝑧</ci><cn type="integer" id="S3.SS3.p1.4.m4.2.2.1.1.3.cmml" xref="S3.SS3.p1.4.m4.2.2.1.1.3">1</cn></apply><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">…</ci><apply id="S3.SS3.p1.4.m4.3.3.2.2.cmml" xref="S3.SS3.p1.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.3.3.2.2.1.cmml" xref="S3.SS3.p1.4.m4.3.3.2.2">subscript</csymbol><ci id="S3.SS3.p1.4.m4.3.3.2.2.2.cmml" xref="S3.SS3.p1.4.m4.3.3.2.2.2">𝑧</ci><ci id="S3.SS3.p1.4.m4.3.3.2.2.3.cmml" xref="S3.SS3.p1.4.m4.3.3.2.2.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.3c">z_{1},\dots,z_{T}</annotation></semantics></math> to <math id="S3.SS3.p1.5.m5.3" class="ltx_Math" alttext="q_{1},\dots,q_{T}" display="inline"><semantics id="S3.SS3.p1.5.m5.3a"><mrow id="S3.SS3.p1.5.m5.3.3.2" xref="S3.SS3.p1.5.m5.3.3.3.cmml"><msub id="S3.SS3.p1.5.m5.2.2.1.1" xref="S3.SS3.p1.5.m5.2.2.1.1.cmml"><mi id="S3.SS3.p1.5.m5.2.2.1.1.2" xref="S3.SS3.p1.5.m5.2.2.1.1.2.cmml">q</mi><mn id="S3.SS3.p1.5.m5.2.2.1.1.3" xref="S3.SS3.p1.5.m5.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p1.5.m5.3.3.2.3" xref="S3.SS3.p1.5.m5.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">…</mi><mo id="S3.SS3.p1.5.m5.3.3.2.4" xref="S3.SS3.p1.5.m5.3.3.3.cmml">,</mo><msub id="S3.SS3.p1.5.m5.3.3.2.2" xref="S3.SS3.p1.5.m5.3.3.2.2.cmml"><mi id="S3.SS3.p1.5.m5.3.3.2.2.2" xref="S3.SS3.p1.5.m5.3.3.2.2.2.cmml">q</mi><mi id="S3.SS3.p1.5.m5.3.3.2.2.3" xref="S3.SS3.p1.5.m5.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.3b"><list id="S3.SS3.p1.5.m5.3.3.3.cmml" xref="S3.SS3.p1.5.m5.3.3.2"><apply id="S3.SS3.p1.5.m5.2.2.1.1.cmml" xref="S3.SS3.p1.5.m5.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.2.2.1.1.1.cmml" xref="S3.SS3.p1.5.m5.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p1.5.m5.2.2.1.1.2.cmml" xref="S3.SS3.p1.5.m5.2.2.1.1.2">𝑞</ci><cn type="integer" id="S3.SS3.p1.5.m5.2.2.1.1.3.cmml" xref="S3.SS3.p1.5.m5.2.2.1.1.3">1</cn></apply><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">…</ci><apply id="S3.SS3.p1.5.m5.3.3.2.2.cmml" xref="S3.SS3.p1.5.m5.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.3.3.2.2.1.cmml" xref="S3.SS3.p1.5.m5.3.3.2.2">subscript</csymbol><ci id="S3.SS3.p1.5.m5.3.3.2.2.2.cmml" xref="S3.SS3.p1.5.m5.3.3.2.2.2">𝑞</ci><ci id="S3.SS3.p1.5.m5.3.3.2.2.3.cmml" xref="S3.SS3.p1.5.m5.3.3.2.2.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.3c">q_{1},\dots,q_{T}</annotation></semantics></math>, which represent the targets in the contrastive learning objective.
The quantization module uses a Gumbel softmax to choose entries from the codebooks and the chosen entries are concatenated to be <math id="S3.SS3.p1.6.m6.3" class="ltx_Math" alttext="q_{1},\dots,q_{T}" display="inline"><semantics id="S3.SS3.p1.6.m6.3a"><mrow id="S3.SS3.p1.6.m6.3.3.2" xref="S3.SS3.p1.6.m6.3.3.3.cmml"><msub id="S3.SS3.p1.6.m6.2.2.1.1" xref="S3.SS3.p1.6.m6.2.2.1.1.cmml"><mi id="S3.SS3.p1.6.m6.2.2.1.1.2" xref="S3.SS3.p1.6.m6.2.2.1.1.2.cmml">q</mi><mn id="S3.SS3.p1.6.m6.2.2.1.1.3" xref="S3.SS3.p1.6.m6.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p1.6.m6.3.3.2.3" xref="S3.SS3.p1.6.m6.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml">…</mi><mo id="S3.SS3.p1.6.m6.3.3.2.4" xref="S3.SS3.p1.6.m6.3.3.3.cmml">,</mo><msub id="S3.SS3.p1.6.m6.3.3.2.2" xref="S3.SS3.p1.6.m6.3.3.2.2.cmml"><mi id="S3.SS3.p1.6.m6.3.3.2.2.2" xref="S3.SS3.p1.6.m6.3.3.2.2.2.cmml">q</mi><mi id="S3.SS3.p1.6.m6.3.3.2.2.3" xref="S3.SS3.p1.6.m6.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.3b"><list id="S3.SS3.p1.6.m6.3.3.3.cmml" xref="S3.SS3.p1.6.m6.3.3.2"><apply id="S3.SS3.p1.6.m6.2.2.1.1.cmml" xref="S3.SS3.p1.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.2.2.1.1.1.cmml" xref="S3.SS3.p1.6.m6.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m6.2.2.1.1.2.cmml" xref="S3.SS3.p1.6.m6.2.2.1.1.2">𝑞</ci><cn type="integer" id="S3.SS3.p1.6.m6.2.2.1.1.3.cmml" xref="S3.SS3.p1.6.m6.2.2.1.1.3">1</cn></apply><ci id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">…</ci><apply id="S3.SS3.p1.6.m6.3.3.2.2.cmml" xref="S3.SS3.p1.6.m6.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.3.3.2.2.1.cmml" xref="S3.SS3.p1.6.m6.3.3.2.2">subscript</csymbol><ci id="S3.SS3.p1.6.m6.3.3.2.2.2.cmml" xref="S3.SS3.p1.6.m6.3.3.2.2.2">𝑞</ci><ci id="S3.SS3.p1.6.m6.3.3.2.2.3.cmml" xref="S3.SS3.p1.6.m6.3.3.2.2.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.3c">q_{1},\dots,q_{T}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.
The wav2vec 2.0 model is trained by solving a contrastive task on masked feature encoder outputs. During training, spans of ten time steps with random starting indices are masked. The objective is to predict the true quantized latent <math id="S3.SS3.p1.7.m7.1" class="ltx_Math" alttext="q_{t}" display="inline"><semantics id="S3.SS3.p1.7.m7.1a"><msub id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml"><mi id="S3.SS3.p1.7.m7.1.1.2" xref="S3.SS3.p1.7.m7.1.1.2.cmml">q</mi><mi id="S3.SS3.p1.7.m7.1.1.3" xref="S3.SS3.p1.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><apply id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2">𝑞</ci><ci id="S3.SS3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">q_{t}</annotation></semantics></math> for masked time-steps within a set of <math id="S3.SS3.p1.8.m8.1" class="ltx_Math" alttext="K=100" display="inline"><semantics id="S3.SS3.p1.8.m8.1a"><mrow id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml"><mi id="S3.SS3.p1.8.m8.1.1.2" xref="S3.SS3.p1.8.m8.1.1.2.cmml">K</mi><mo id="S3.SS3.p1.8.m8.1.1.1" xref="S3.SS3.p1.8.m8.1.1.1.cmml">=</mo><mn id="S3.SS3.p1.8.m8.1.1.3" xref="S3.SS3.p1.8.m8.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><apply id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1"><eq id="S3.SS3.p1.8.m8.1.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1.1"></eq><ci id="S3.SS3.p1.8.m8.1.1.2.cmml" xref="S3.SS3.p1.8.m8.1.1.2">𝐾</ci><cn type="integer" id="S3.SS3.p1.8.m8.1.1.3.cmml" xref="S3.SS3.p1.8.m8.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">K=100</annotation></semantics></math> distractors sampled from other masked time steps.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.2" class="ltx_p">Basically, the pre-trained wav2vec 2.0 model is only an acoustic encoder, consisting of a convolutional feature encoder and a transformer contextual encoder.
In order to recognize speech from any language, we need to introduce a linear layer (parameterized by matrix <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">W</annotation></semantics></math>) followed by softmax on top of the encoder output <math id="S3.SS3.p2.2.m2.3" class="ltx_Math" alttext="h_{1},\cdots,h_{T}" display="inline"><semantics id="S3.SS3.p2.2.m2.3a"><mrow id="S3.SS3.p2.2.m2.3.3.2" xref="S3.SS3.p2.2.m2.3.3.3.cmml"><msub id="S3.SS3.p2.2.m2.2.2.1.1" xref="S3.SS3.p2.2.m2.2.2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.2.2.1.1.2" xref="S3.SS3.p2.2.m2.2.2.1.1.2.cmml">h</mi><mn id="S3.SS3.p2.2.m2.2.2.1.1.3" xref="S3.SS3.p2.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.p2.2.m2.3.3.2.3" xref="S3.SS3.p2.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">⋯</mi><mo id="S3.SS3.p2.2.m2.3.3.2.4" xref="S3.SS3.p2.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS3.p2.2.m2.3.3.2.2" xref="S3.SS3.p2.2.m2.3.3.2.2.cmml"><mi id="S3.SS3.p2.2.m2.3.3.2.2.2" xref="S3.SS3.p2.2.m2.3.3.2.2.2.cmml">h</mi><mi id="S3.SS3.p2.2.m2.3.3.2.2.3" xref="S3.SS3.p2.2.m2.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.3b"><list id="S3.SS3.p2.2.m2.3.3.3.cmml" xref="S3.SS3.p2.2.m2.3.3.2"><apply id="S3.SS3.p2.2.m2.2.2.1.1.cmml" xref="S3.SS3.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.2.2.1.1.2">ℎ</ci><cn type="integer" id="S3.SS3.p2.2.m2.2.2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">⋯</ci><apply id="S3.SS3.p2.2.m2.3.3.2.2.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.3.3.2.2.1.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS3.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2.2">ℎ</ci><ci id="S3.SS3.p2.2.m2.3.3.2.2.3.cmml" xref="S3.SS3.p2.2.m2.3.3.2.2.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.3c">h_{1},\cdots,h_{T}</annotation></semantics></math>, as shown in Eq. (<a href="#S3.E1" title="In III-A Phoneme-based multilingual supervised pre-training ‣ III Approach ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), and perform fine-tuning over labeled data. The labels could be in the form of either phonemes or subwords.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experimental setup</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Dataset</span>
</h3>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Multilingual and crosslingual data information, including the language code, the language family, the number of IPA phonemes, the sizes of train, development and test sets in hours.</figcaption>
<div id="S4.T1.1" class="ltx_inline-block ltx_transformed_outer" style="width:295.3pt;height:226.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.4pt,12.6pt) scale(0.9,0.9) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T1.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.2.1.1" class="ltx_p" style="width:14.2pt;"><span id="S4.T1.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Code</span></span>
</span>
</td>
<td id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Language</span></td>
<td id="S4.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Family</span></td>
<td id="S4.T1.1.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt">
<span id="S4.T1.1.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S4.T1.1.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">IPA</span></span>
</span>
</td>
<td id="S4.T1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T1.1.1.1.1.6.1" class="ltx_text ltx_font_bold">Hours</span></td>
</tr>
<tr id="S4.T1.1.1.2.2" class="ltx_tr">
<td id="S4.T1.1.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.2.1.1" class="ltx_p" style="width:14.2pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.2.2.3.1.1" class="ltx_p" style="width:11.4pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.2.2.4" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.2.2.4.1" class="ltx_text ltx_font_bold">Train</span></td>
<td id="S4.T1.1.1.2.2.5" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.2.2.5.1" class="ltx_text ltx_font_bold">Dev</span></td>
<td id="S4.T1.1.1.2.2.6" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.2.2.6.1" class="ltx_text ltx_font_bold">Test</span></td>
</tr>
<tr id="S4.T1.1.1.3.3" class="ltx_tr">
<td id="S4.T1.1.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.1.1.1" class="ltx_p" style="width:17.1pt;"><span id="S4.T1.1.1.3.3.1.1.1.1" class="ltx_text">Multi.</span></span>
</span>
</td>
<td id="S4.T1.1.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.2.1.1" class="ltx_p" style="width:14.2pt;">en</span>
</span>
</td>
<td id="S4.T1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">English</td>
<td id="S4.T1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">West Germanic</td>
<td id="S4.T1.1.1.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.3.3.5.1.1" class="ltx_p" style="width:11.4pt;">39</span>
</span>
</td>
<td id="S4.T1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">2227.3</td>
<td id="S4.T1.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">27.2</td>
<td id="S4.T1.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">27.0</td>
</tr>
<tr id="S4.T1.1.1.4.4" class="ltx_tr">
<td id="S4.T1.1.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.2.1.1" class="ltx_p" style="width:14.2pt;">es</span>
</span>
</td>
<td id="S4.T1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">Spanish</td>
<td id="S4.T1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">Romance</td>
<td id="S4.T1.1.1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.4.4.5.1.1" class="ltx_p" style="width:11.4pt;">32</span>
</span>
</td>
<td id="S4.T1.1.1.4.4.6" class="ltx_td ltx_align_center">382.3</td>
<td id="S4.T1.1.1.4.4.7" class="ltx_td ltx_align_center">26.0</td>
<td id="S4.T1.1.1.4.4.8" class="ltx_td ltx_align_center">26.5</td>
</tr>
<tr id="S4.T1.1.1.5.5" class="ltx_tr">
<td id="S4.T1.1.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.2.1.1" class="ltx_p" style="width:14.2pt;">fr</span>
</span>
</td>
<td id="S4.T1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">French</td>
<td id="S4.T1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">Romance</td>
<td id="S4.T1.1.1.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.5.5.5.1.1" class="ltx_p" style="width:11.4pt;">33</span>
</span>
</td>
<td id="S4.T1.1.1.5.5.6" class="ltx_td ltx_align_center">823.4</td>
<td id="S4.T1.1.1.5.5.7" class="ltx_td ltx_align_center">25.0</td>
<td id="S4.T1.1.1.5.5.8" class="ltx_td ltx_align_center">25.4</td>
</tr>
<tr id="S4.T1.1.1.6.6" class="ltx_tr">
<td id="S4.T1.1.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.2.1.1" class="ltx_p" style="width:14.2pt;">it</span>
</span>
</td>
<td id="S4.T1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r">Italian</td>
<td id="S4.T1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">Romance</td>
<td id="S4.T1.1.1.6.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.6.6.5.1.1" class="ltx_p" style="width:11.4pt;">30</span>
</span>
</td>
<td id="S4.T1.1.1.6.6.6" class="ltx_td ltx_align_center">271.5</td>
<td id="S4.T1.1.1.6.6.7" class="ltx_td ltx_align_center">24.7</td>
<td id="S4.T1.1.1.6.6.8" class="ltx_td ltx_align_center">26.0</td>
</tr>
<tr id="S4.T1.1.1.7.7" class="ltx_tr">
<td id="S4.T1.1.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.2.1.1" class="ltx_p" style="width:14.2pt;">ky</span>
</span>
</td>
<td id="S4.T1.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r">Kyrgyz</td>
<td id="S4.T1.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">Turkic</td>
<td id="S4.T1.1.1.7.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.7.7.5.1.1" class="ltx_p" style="width:11.4pt;">32</span>
</span>
</td>
<td id="S4.T1.1.1.7.7.6" class="ltx_td ltx_align_center">32.7</td>
<td id="S4.T1.1.1.7.7.7" class="ltx_td ltx_align_center">2.1</td>
<td id="S4.T1.1.1.7.7.8" class="ltx_td ltx_align_center">2.2</td>
</tr>
<tr id="S4.T1.1.1.8.8" class="ltx_tr">
<td id="S4.T1.1.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.2.1.1" class="ltx_p" style="width:14.2pt;">nl</span>
</span>
</td>
<td id="S4.T1.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r">Dutch</td>
<td id="S4.T1.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">West Germanic</td>
<td id="S4.T1.1.1.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.8.8.5.1.1" class="ltx_p" style="width:11.4pt;">39</span>
</span>
</td>
<td id="S4.T1.1.1.8.8.6" class="ltx_td ltx_align_center">70.2</td>
<td id="S4.T1.1.1.8.8.7" class="ltx_td ltx_align_center">13.8</td>
<td id="S4.T1.1.1.8.8.8" class="ltx_td ltx_align_center">13.9</td>
</tr>
<tr id="S4.T1.1.1.9.9" class="ltx_tr">
<td id="S4.T1.1.1.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.2.1.1" class="ltx_p" style="width:14.2pt;">ru</span>
</span>
</td>
<td id="S4.T1.1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r">Russian</td>
<td id="S4.T1.1.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r">East Slavic</td>
<td id="S4.T1.1.1.9.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.9.9.5.1.1" class="ltx_p" style="width:11.4pt;">32</span>
</span>
</td>
<td id="S4.T1.1.1.9.9.6" class="ltx_td ltx_align_center">149.8</td>
<td id="S4.T1.1.1.9.9.7" class="ltx_td ltx_align_center">14.6</td>
<td id="S4.T1.1.1.9.9.8" class="ltx_td ltx_align_center">15.0</td>
</tr>
<tr id="S4.T1.1.1.10.10" class="ltx_tr">
<td id="S4.T1.1.1.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.2.1.1" class="ltx_p" style="width:14.2pt;">sv</span>
</span>
</td>
<td id="S4.T1.1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r">Swedish</td>
<td id="S4.T1.1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">North Germanic</td>
<td id="S4.T1.1.1.10.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.10.10.5.1.1" class="ltx_p" style="width:11.4pt;">33</span>
</span>
</td>
<td id="S4.T1.1.1.10.10.6" class="ltx_td ltx_align_center">29.8</td>
<td id="S4.T1.1.1.10.10.7" class="ltx_td ltx_align_center">5.5</td>
<td id="S4.T1.1.1.10.10.8" class="ltx_td ltx_align_center">6.2</td>
</tr>
<tr id="S4.T1.1.1.11.11" class="ltx_tr">
<td id="S4.T1.1.1.11.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.11.11.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.11.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.11.11.2.1.1" class="ltx_p" style="width:14.2pt;">tr</span>
</span>
</td>
<td id="S4.T1.1.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r">Turkish</td>
<td id="S4.T1.1.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r">Turkic</td>
<td id="S4.T1.1.1.11.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.11.11.5.1.1" class="ltx_p" style="width:11.4pt;">41</span>
</span>
</td>
<td id="S4.T1.1.1.11.11.6" class="ltx_td ltx_align_center">61.5</td>
<td id="S4.T1.1.1.11.11.7" class="ltx_td ltx_align_center">10.1</td>
<td id="S4.T1.1.1.11.11.8" class="ltx_td ltx_align_center">11.4</td>
</tr>
<tr id="S4.T1.1.1.12.12" class="ltx_tr">
<td id="S4.T1.1.1.12.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.12.12.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.12.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.12.12.2.1.1" class="ltx_p" style="width:14.2pt;">tt</span>
</span>
</td>
<td id="S4.T1.1.1.12.12.3" class="ltx_td ltx_align_center ltx_border_r">Tatar</td>
<td id="S4.T1.1.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r">Turkic</td>
<td id="S4.T1.1.1.12.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S4.T1.1.1.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.12.12.5.1.1" class="ltx_p" style="width:11.4pt;">31</span>
</span>
</td>
<td id="S4.T1.1.1.12.12.6" class="ltx_td ltx_align_center">20.8</td>
<td id="S4.T1.1.1.12.12.7" class="ltx_td ltx_align_center">3.0</td>
<td id="S4.T1.1.1.12.12.8" class="ltx_td ltx_align_center">5.7</td>
</tr>
<tr id="S4.T1.1.1.13.13" class="ltx_tr">
<td id="S4.T1.1.1.13.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.13.13.1.1.1" class="ltx_p" style="width:17.1pt;"><span id="S4.T1.1.1.13.13.1.1.1.1" class="ltx_text">Cross.</span></span>
</span>
</td>
<td id="S4.T1.1.1.13.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.13.13.2.1.1" class="ltx_p" style="width:14.2pt;">pl</span>
</span>
</td>
<td id="S4.T1.1.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Polish</td>
<td id="S4.T1.1.1.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">West Slavic</td>
<td id="S4.T1.1.1.13.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S4.T1.1.1.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.13.13.5.1.1" class="ltx_p" style="width:11.4pt;">35</span>
</span>
</td>
<td id="S4.T1.1.1.13.13.6" class="ltx_td ltx_align_center ltx_border_t">129.9</td>
<td id="S4.T1.1.1.13.13.7" class="ltx_td ltx_align_center ltx_border_t">11.4</td>
<td id="S4.T1.1.1.13.13.8" class="ltx_td ltx_align_center ltx_border_t">11.5</td>
</tr>
<tr id="S4.T1.1.1.14.14" class="ltx_tr">
<td id="S4.T1.1.1.14.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S4.T1.1.1.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.14.14.1.1.1" class="ltx_p" style="width:17.1pt;"></span>
</span>
</td>
<td id="S4.T1.1.1.14.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S4.T1.1.1.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.14.14.2.1.1" class="ltx_p" style="width:14.2pt;">id</span>
</span>
</td>
<td id="S4.T1.1.1.14.14.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">Indonesian</td>
<td id="S4.T1.1.1.14.14.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">Austronesian</td>
<td id="S4.T1.1.1.14.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S4.T1.1.1.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.14.14.5.1.1" class="ltx_p" style="width:11.4pt;">35</span>
</span>
</td>
<td id="S4.T1.1.1.14.14.6" class="ltx_td ltx_align_center ltx_border_bb">20.8</td>
<td id="S4.T1.1.1.14.14.7" class="ltx_td ltx_align_center ltx_border_bb">3.7</td>
<td id="S4.T1.1.1.14.14.8" class="ltx_td ltx_align_center ltx_border_bb">4.1</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We conduct experiments on the CommonVoice dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> released at September 2022 (v11.0). CommonVoice is a large multilingual speech corpus, with spoken content taken primarily from Wikipedia articles. We select ten languages for multilingual pre-training experiments: English (en), Spanish (es), French (fr), Italian (it), Kyrgyz (ky), Dutch (nl), Russian (ru), Swedish (sv), Turkish (tr) and Tatar (tt), with a total of 4069.3 hours, which cover rich language families.
We refer to this dataset of 10 languages as CV-Lang10.
We select Polish (pl) and Indonesian (id) for crosslingual finetuning experiments, which are from two unseen language families. Detailed database descriptions are shown in Table <a href="#S4.T1" title="TABLE I ‣ IV-A Dataset ‣ IV Experimental setup ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. We combine all data from the ten languages to form the training, development, and test sets for multilingual pre-training experiments. For each language, we use its transcripts to separately train a word-level n-gram language model for WFST-based decoding.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Example transcriptions for each language in CV-Lang10</figcaption>
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Code</span></th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S4.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Text transcript</span></th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S4.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">Transcription with subwords</span></th>
<th id="S4.T2.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">Transcription with IPA symbols</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<th id="S4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">en</th>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">i know everything about you</td>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">i know everything about you</td>
<td id="S4.T2.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">    n o   v  i    N  b a  t j u</td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<th id="S4.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">es</th>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r">no lo he visto</td>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r">no lo he v ist o</td>
<td id="S4.T2.1.3.2.4" class="ltx_td ltx_align_left">n o l o e b i s t o</td>
</tr>
<tr id="S4.T2.1.4.3" class="ltx_tr">
<th id="S4.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">fr</th>
<td id="S4.T2.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r">vous ne me comprenez pas</td>
<td id="S4.T2.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r">vous ne me comp ren ez pas</td>
<td id="S4.T2.1.4.3.4" class="ltx_td ltx_align_left">v y n m k  p    n e p a</td>
</tr>
<tr id="S4.T2.1.5.4" class="ltx_tr">
<th id="S4.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">it</th>
<td id="S4.T2.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r">è meglio separarci adesso</td>
<td id="S4.T2.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r">è me g lio separ ar ci ad esso</td>
<td id="S4.T2.1.5.4.4" class="ltx_td ltx_align_left">m e  i o s e p a r a r t   a r s s o</td>
</tr>
<tr id="S4.T2.1.6.5" class="ltx_tr">
<th id="S4.T2.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">ky</th>
<td id="S4.T2.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r">менин эч кандай кuнм жок</td>
<td id="S4.T2.1.6.5.3" class="ltx_td ltx_align_left ltx_border_r">мен ин эч кандай кuн м жок</td>
<td id="S4.T2.1.6.5.4" class="ltx_td ltx_align_left">m e n i n e t k  n d  j k y n ø m d   o k</td>
</tr>
<tr id="S4.T2.1.7.6" class="ltx_tr">
<th id="S4.T2.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">nl</th>
<td id="S4.T2.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r">ze is een bekend model</td>
<td id="S4.T2.1.7.6.3" class="ltx_td ltx_align_left ltx_border_r">ze is een bek end mod el</td>
<td id="S4.T2.1.7.6.4" class="ltx_td ltx_align_left">z e  s e n b  k  n t m o d  l</td>
</tr>
<tr id="S4.T2.1.8.7" class="ltx_tr">
<th id="S4.T2.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">ru</th>
<td id="S4.T2.1.8.7.2" class="ltx_td ltx_align_left ltx_border_r">база данных обновлена</td>
<td id="S4.T2.1.8.7.3" class="ltx_td ltx_align_left ltx_border_r">ба за дан ных об нов лен а</td>
<td id="S4.T2.1.8.7.4" class="ltx_td ltx_align_left">b a z a d a n  x o b n o v l e n a</td>
</tr>
<tr id="S4.T2.1.9.8" class="ltx_tr">
<th id="S4.T2.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">sv</th>
<td id="S4.T2.1.9.8.2" class="ltx_td ltx_align_left ltx_border_r">hörni ta det lugnt</td>
<td id="S4.T2.1.9.8.3" class="ltx_td ltx_align_left ltx_border_r">h ör ni ta det lug n t</td>
<td id="S4.T2.1.9.8.4" class="ltx_td ltx_align_left">h œ r n i t  d e t l  N n t</td>
</tr>
<tr id="S4.T2.1.10.9" class="ltx_tr">
<th id="S4.T2.1.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">tr</th>
<td id="S4.T2.1.10.9.2" class="ltx_td ltx_align_left ltx_border_r">bunlar en büyükleri</td>
<td id="S4.T2.1.10.9.3" class="ltx_td ltx_align_left ltx_border_r">bun lar en b üy ük leri</td>
<td id="S4.T2.1.10.9.4" class="ltx_td ltx_align_left">b u n  a  e n b y j y k l e r i</td>
</tr>
<tr id="S4.T2.1.11.10" class="ltx_tr">
<th id="S4.T2.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">tt</th>
<td id="S4.T2.1.11.10.2" class="ltx_td ltx_align_left ltx_border_r">меншулай яшп ятабыз</td>
<td id="S4.T2.1.11.10.3" class="ltx_td ltx_align_left ltx_border_r">мен шулай яш п я та быз</td>
<td id="S4.T2.1.11.10.4" class="ltx_td ltx_align_left">m j e n æ  u l a j j a  æ p j a t a b  z</td>
</tr>
<tr id="S4.T2.1.12.11" class="ltx_tr">
<th id="S4.T2.1.12.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">pl</th>
<td id="S4.T2.1.12.11.2" class="ltx_td ltx_align_left ltx_border_r">lubię muzykę klasyczną</td>
<td id="S4.T2.1.12.11.3" class="ltx_td ltx_align_left ltx_border_r">lu b ię mu zy kę k la sy cz ną</td>
<td id="S4.T2.1.12.11.4" class="ltx_td ltx_align_left">l u a b v i  m u w z  k  k l a t s   n</td>
</tr>
<tr id="S4.T2.1.13.12" class="ltx_tr">
<th id="S4.T2.1.13.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">id</th>
<td id="S4.T2.1.13.12.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">semoga cepat sembuh</td>
<td id="S4.T2.1.13.12.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">sem o ga c ep at sem b uh</td>
<td id="S4.T2.1.13.12.4" class="ltx_td ltx_align_left ltx_border_bb">s  m   a t   p a t s  m b o h</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Text normalization and phonemization</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For text normalization, all punctuation marks are removed, except those that affect pronunciation (such as the apostrophe in English). Certain sentences contain many foreign words are discarded, since G2P converters cannot properly convert them. For reproducible research, details of text normalization and the IDs of deleted sentences for each language will be released in our public repository.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The FST (Finite State Transducer) based G2P toolkit, Phonetisaurus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, is utilized to generate labeling of utterances in IPA phonemes from text transcripts.
The trained FSTs for use with Phonetisaurus can be obtained from LanguageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.
Examples of phoneme annotations for each language in CV-Lang10 are shown in Table <a href="#S4.T2" title="TABLE II ‣ IV-A Dataset ‣ IV Experimental setup ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.
By applying Phonetisaurus G2P tool with LanguageNet FSTs, we can also create a PROLEX for each language, which is needed for WFST-based decoding with phoneme-based CTC model.
The phonetic transcripts and the PROLEXs for CV-Lang10 will be released in our public repository.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Remarkably, our phonemization procedure produces weakly phonetic supervision for model training.
The FST-based G2P procedure by LanguageNet and Phonetisaurus is not perfect. As noted in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, PERs ranging from 7% to 45%. We only correct a few obvious labeling errors, but the phoneme labels are still somewhat noisy in general.
Additionally, we remove the diacritics and suprasegmentals (like stress and tone) that may be necessary for representing phones, and mainly use base phonemes in our annotation<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>From phonetics and phonology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>,
while phones represent physical speech sounds (and thus language-independent), phonemes are not physical sounds; they are abstract mental representations of the phonological units of a language, the units used to represent words in our mental lexicon (and thus language dependent).
A particular realization (pronunciation) of a phoneme is called a phone. The collection of phones that are the realizations of the same phonemes are called the allophones of that phoneme.
Phonemes for annotation are thus in a coarser granularity than phones, which may facilitate sharing between languages.
The 12 languages examined in this paper are all non-tonal languages. So we preliminarily sidestep the problem how tones should be incorporated in phoneme-based multilingual models. This is a interesting future work, as previously investigated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>.
</span></span></span>.
While some recent studies pursue universal phone recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, this paper does not aim for phone recognition.
On the one hand, accurate gold-standard phone labeling is hard to obtain. On the other hand, when we use WFST-based decoding with PROLEXs and aim for reducing word error rates (WERs), the complexity of constructing an allophone layer to transform the language-independent phone distributions to the language-dependent distributions may not be necessary.
Training with weakly phonetic supervision and decoding with PROLEXs, with phonemes serving as an interface between acoustics and text, is found to obtain superior results in MCL-ASR in our experiments.
Presumably, as long as the PROLEXs and the phonetic transcriptions are aligned in some way, weakly phonetic supervision can well drive model learning.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div id="S4.F2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:392.0pt;height:300.7pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-21.8pt,16.7pt) scale(0.9,0.9) ;"><img src="/html/2406.02166/assets/figure/counting.png" id="S4.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="461" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Counts of phonemes (top) and subwords (down) in the CV-Lang10 training set.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Model training</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The CAT toolkit <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> is used for training CTC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> based ASR models in our experiments.
Three sizes of acoustic encoders are used in our experiments, all based on Conformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> networks.
The small-sized Conformer encoder (S) consists of 14 encoder blocks with dimension 512. We set the self-attention layer to have 4 heads with 36-dimension hidden states, and the feed-forward network (FFN) dimension to 512.
The middle-sized Conformer encoder (M) uses 22 blocks, model dimension 640, FFN dimension 640, attention dimension 160, while the large-sized Conformer encoder (L) uses 22 blocks, model dimension 1024, FFN dimension 1024, attention dimension 224.
For phoneme-based models, the multilingual alphabet size of phonemes is 73.
For subword-based models, the multilingual alphabet size of subwords is 4998.
Counting statistics for phonemes and subwords over CV-Lang10 are shown in Figure <a href="#S4.F2" title="Figure 2 ‣ IV-B Text normalization and phonemization ‣ IV Experimental setup ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">We train all the models using the Noam optimizer and warm up for the first 10<math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mo id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><csymbol cd="latexml" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">\%</annotation></semantics></math> of updates. We set the dropout rate to 0.1. For data augmentation, we use the spectral augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. We extract 80-dimension FBank features from audio (resampled to 16KHz) as inputs to the acoustic encoder. A beam size of 16 is used for decoding.
For model selection, we adopt an early-stop strategy, i.e., when the validation set loss does not decrease for 10 consecutive epochs, we stop training and then averaging the three best-performing checkpoints on the validation set for testing.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">By using the fairseq toolkit and following the wav2vec 2.0 base configuration provided by the toolkit<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml</a></span></span></span>, a wav2vec 2.0 model is pre-trained over the CV-Lang10 dataset, which is referred to as ``W2V (10 lang)''.
Meanwhile, we also download an existing wav2vec 2.0 base model<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_small.pt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_small.pt</a></span></span></span>, which was pre-trained over English data and is referred to as ``W2V (En)''.
The two wav2vec 2.0 models have same base architecture, which consists of 12 Transformer blocks, model dimension 768, FFN dimension 3072 and 8 attention heads. W2V (10 lang) uses Adam where the learning rate is warmed up for the first 10<math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mo id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><csymbol cd="latexml" id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">\%</annotation></semantics></math> of updates to a peak of 1e-5.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Phoneme error rates (PERs) for phoneme-based monolingual models and multilingual pre-trained models on the CV-Lang10 dataset. (S: small, M: middle, L: large)</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:461.7pt;height:81.9pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.7pt,4.5pt) scale(0.9,0.9) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">id</span></th>
<th id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Size (M)</span></th>
<th id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">en</span></th>
<th id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.5.1" class="ltx_text ltx_font_bold">es</span></th>
<th id="S4.T3.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.6.1" class="ltx_text ltx_font_bold">fr</span></th>
<th id="S4.T3.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.7.1" class="ltx_text ltx_font_bold">it</span></th>
<th id="S4.T3.1.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.8.1" class="ltx_text ltx_font_bold">ky</span></th>
<th id="S4.T3.1.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.9.1" class="ltx_text ltx_font_bold">nl</span></th>
<th id="S4.T3.1.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.10.1" class="ltx_text ltx_font_bold">ru</span></th>
<th id="S4.T3.1.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.11.1" class="ltx_text ltx_font_bold">sv</span></th>
<th id="S4.T3.1.1.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.12.1" class="ltx_text ltx_font_bold">tr</span></th>
<th id="S4.T3.1.1.1.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S4.T3.1.1.1.1.13.1" class="ltx_text ltx_font_bold">tt</span></th>
<th id="S4.T3.1.1.1.1.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.1.1.14.1" class="ltx_text ltx_font_bold">Avg.</span></th>
</tr>
<tr id="S4.T3.1.1.2.2" class="ltx_tr">
<th id="S4.T3.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">O1</th>
<th id="S4.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">Mono. phoneme</th>
<th id="S4.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">90</th>
<th id="S4.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">7.39</th>
<th id="S4.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">2.47</th>
<th id="S4.T3.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">4.93</th>
<th id="S4.T3.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">2.87</th>
<th id="S4.T3.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.8.1" class="ltx_text ltx_font_bold">2.23</span></th>
<th id="S4.T3.1.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">4.60</th>
<th id="S4.T3.1.1.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.2.2.10.1" class="ltx_text ltx_font_bold">2.72</span></th>
<th id="S4.T3.1.1.2.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">18.69</th>
<th id="S4.T3.1.1.2.2.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">6.00</th>
<th id="S4.T3.1.1.2.2.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">10.54</th>
<th id="S4.T3.1.1.2.2.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">6.11</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.3.1" class="ltx_tr">
<th id="S4.T3.1.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">M1</th>
<th id="S4.T3.1.1.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Multi. phoneme S</th>
<th id="S4.T3.1.1.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">90</th>
<td id="S4.T3.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">8.02</td>
<td id="S4.T3.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">3.37</td>
<td id="S4.T3.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">5.68</td>
<td id="S4.T3.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">4.04</td>
<td id="S4.T3.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">8.29</td>
<td id="S4.T3.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">5.77</td>
<td id="S4.T3.1.1.3.1.10" class="ltx_td ltx_align_center ltx_border_t">6.05</td>
<td id="S4.T3.1.1.3.1.11" class="ltx_td ltx_align_center ltx_border_t">18.07</td>
<td id="S4.T3.1.1.3.1.12" class="ltx_td ltx_align_center ltx_border_t">8.32</td>
<td id="S4.T3.1.1.3.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8.53</td>
<td id="S4.T3.1.1.3.1.14" class="ltx_td ltx_align_center ltx_border_t">7.61</td>
</tr>
<tr id="S4.T3.1.1.4.2" class="ltx_tr">
<th id="S4.T3.1.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">M2</th>
<th id="S4.T3.1.1.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Multi. phoneme M</th>
<th id="S4.T3.1.1.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">218</th>
<td id="S4.T3.1.1.4.2.4" class="ltx_td ltx_align_center">6.70</td>
<td id="S4.T3.1.1.4.2.5" class="ltx_td ltx_align_center">2.63</td>
<td id="S4.T3.1.1.4.2.6" class="ltx_td ltx_align_center">4.53</td>
<td id="S4.T3.1.1.4.2.7" class="ltx_td ltx_align_center">3.12</td>
<td id="S4.T3.1.1.4.2.8" class="ltx_td ltx_align_center">5.95</td>
<td id="S4.T3.1.1.4.2.9" class="ltx_td ltx_align_center">3.95</td>
<td id="S4.T3.1.1.4.2.10" class="ltx_td ltx_align_center">4.61</td>
<td id="S4.T3.1.1.4.2.11" class="ltx_td ltx_align_center">14.81</td>
<td id="S4.T3.1.1.4.2.12" class="ltx_td ltx_align_center">6.04</td>
<td id="S4.T3.1.1.4.2.13" class="ltx_td ltx_align_center ltx_border_r">8.47</td>
<td id="S4.T3.1.1.4.2.14" class="ltx_td ltx_align_center">6.08</td>
</tr>
<tr id="S4.T3.1.1.5.3" class="ltx_tr">
<th id="S4.T3.1.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">M3</th>
<th id="S4.T3.1.1.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Multi. phoneme L</th>
<th id="S4.T3.1.1.5.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">543</th>
<td id="S4.T3.1.1.5.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.1.5.3.4.1" class="ltx_text ltx_font_bold">5.42</span></td>
<td id="S4.T3.1.1.5.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.1.5.3.5.1" class="ltx_text ltx_font_bold">1.96</span></td>
<td id="S4.T3.1.1.5.3.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.1.5.3.6.1" class="ltx_text ltx_font_bold">3.52</span></td>
<td id="S4.T3.1.1.5.3.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.1.5.3.7.1" class="ltx_text ltx_font_bold">2.25</span></td>
<td id="S4.T3.1.1.5.3.8" class="ltx_td ltx_align_center ltx_border_bb">4.06</td>
<td id="S4.T3.1.1.5.3.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.1.5.3.9.1" class="ltx_text ltx_font_bold">2.64</span></td>
<td id="S4.T3.1.1.5.3.10" class="ltx_td ltx_align_center ltx_border_bb">2.97</td>
<td id="S4.T3.1.1.5.3.11" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.1.5.3.11.1" class="ltx_text ltx_font_bold">11.33</span></td>
<td id="S4.T3.1.1.5.3.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.1.5.3.12.1" class="ltx_text ltx_font_bold">4.04</span></td>
<td id="S4.T3.1.1.5.3.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T3.1.1.5.3.13.1" class="ltx_text ltx_font_bold">5.97</span></td>
<td id="S4.T3.1.1.5.3.14" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.1.1.5.3.14.1" class="ltx_text ltx_font_bold">4.41</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Word error rates (WERs) for phoneme-based monolingual models and multilingual pre-trained models on the CV-Lang10 dataset, compared with the subword-based multilingual pre-trained model.</figcaption>
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:466.2pt;height:98.1pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.9pt,5.4pt) scale(0.9,0.9) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">id</span></th>
<th id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T4.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T4.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Size (M)</span></th>
<td id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.4.1" class="ltx_text ltx_font_bold">en</span></td>
<td id="S4.T4.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.5.1" class="ltx_text ltx_font_bold">es</span></td>
<td id="S4.T4.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.6.1" class="ltx_text ltx_font_bold">fr</span></td>
<td id="S4.T4.1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.7.1" class="ltx_text ltx_font_bold">it</span></td>
<td id="S4.T4.1.1.1.1.8" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.8.1" class="ltx_text ltx_font_bold">ky</span></td>
<td id="S4.T4.1.1.1.1.9" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.9.1" class="ltx_text ltx_font_bold">nl</span></td>
<td id="S4.T4.1.1.1.1.10" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.10.1" class="ltx_text ltx_font_bold">ru</span></td>
<td id="S4.T4.1.1.1.1.11" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.11.1" class="ltx_text ltx_font_bold">sv</span></td>
<td id="S4.T4.1.1.1.1.12" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.12.1" class="ltx_text ltx_font_bold">tr</span></td>
<td id="S4.T4.1.1.1.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T4.1.1.1.1.13.1" class="ltx_text ltx_font_bold">tt</span></td>
<td id="S4.T4.1.1.1.1.14" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.1.1.1.1.14.1" class="ltx_text ltx_font_bold">Avg.</span></td>
</tr>
<tr id="S4.T4.1.1.2.2" class="ltx_tr">
<th id="S4.T4.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">O1</th>
<th id="S4.T4.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Mono. phoneme</th>
<th id="S4.T4.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">90</th>
<td id="S4.T4.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">10.59</td>
<td id="S4.T4.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">7.91</td>
<td id="S4.T4.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_t">15.58</td>
<td id="S4.T4.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t">9.26</td>
<td id="S4.T4.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t">1.03</td>
<td id="S4.T4.1.1.2.2.9" class="ltx_td ltx_align_center ltx_border_t">8.84</td>
<td id="S4.T4.1.1.2.2.10" class="ltx_td ltx_align_center ltx_border_t">1.62</td>
<td id="S4.T4.1.1.2.2.11" class="ltx_td ltx_align_center ltx_border_t">8.37</td>
<td id="S4.T4.1.1.2.2.12" class="ltx_td ltx_align_center ltx_border_t">8.46</td>
<td id="S4.T4.1.1.2.2.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">9.75</td>
<td id="S4.T4.1.1.2.2.14" class="ltx_td ltx_align_center ltx_border_t">8.14</td>
</tr>
<tr id="S4.T4.1.1.3.3" class="ltx_tr">
<th id="S4.T4.1.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">M4</th>
<th id="S4.T4.1.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Multi. subword</th>
<th id="S4.T4.1.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">92</th>
<td id="S4.T4.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">12.00</td>
<td id="S4.T4.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">9.82</td>
<td id="S4.T4.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.3.3.6.1" class="ltx_text ltx_font_bold">12.40</span></td>
<td id="S4.T4.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">9.98</td>
<td id="S4.T4.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">3.29</td>
<td id="S4.T4.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">9.67</td>
<td id="S4.T4.1.1.3.3.10" class="ltx_td ltx_align_center ltx_border_t">3.31</td>
<td id="S4.T4.1.1.3.3.11" class="ltx_td ltx_align_center ltx_border_t">9.95</td>
<td id="S4.T4.1.1.3.3.12" class="ltx_td ltx_align_center ltx_border_t">9.11</td>
<td id="S4.T4.1.1.3.3.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13.56</td>
<td id="S4.T4.1.1.3.3.14" class="ltx_td ltx_align_center ltx_border_t">9.30</td>
</tr>
<tr id="S4.T4.1.1.4.4" class="ltx_tr">
<th id="S4.T4.1.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">M1</th>
<th id="S4.T4.1.1.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Multi. phoneme S</th>
<th id="S4.T4.1.1.4.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">90</th>
<td id="S4.T4.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_t">10.76</td>
<td id="S4.T4.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_t">8.68</td>
<td id="S4.T4.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_t">16.01</td>
<td id="S4.T4.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t">9.98</td>
<td id="S4.T4.1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_t">1.02</td>
<td id="S4.T4.1.1.4.4.9" class="ltx_td ltx_align_center ltx_border_t">7.32</td>
<td id="S4.T4.1.1.4.4.10" class="ltx_td ltx_align_center ltx_border_t">1.59</td>
<td id="S4.T4.1.1.4.4.11" class="ltx_td ltx_align_center ltx_border_t">6.14</td>
<td id="S4.T4.1.1.4.4.12" class="ltx_td ltx_align_center ltx_border_t">7.63</td>
<td id="S4.T4.1.1.4.4.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7.30</td>
<td id="S4.T4.1.1.4.4.14" class="ltx_td ltx_align_center ltx_border_t">7.64</td>
</tr>
<tr id="S4.T4.1.1.5.5" class="ltx_tr">
<th id="S4.T4.1.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">M2</th>
<th id="S4.T4.1.1.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Multi. phoneme M</th>
<th id="S4.T4.1.1.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">218</th>
<td id="S4.T4.1.1.5.5.4" class="ltx_td ltx_align_center">9.83</td>
<td id="S4.T4.1.1.5.5.5" class="ltx_td ltx_align_center">7.82</td>
<td id="S4.T4.1.1.5.5.6" class="ltx_td ltx_align_center">14.94</td>
<td id="S4.T4.1.1.5.5.7" class="ltx_td ltx_align_center">9.04</td>
<td id="S4.T4.1.1.5.5.8" class="ltx_td ltx_align_center"><span id="S4.T4.1.1.5.5.8.1" class="ltx_text ltx_font_bold">0.91</span></td>
<td id="S4.T4.1.1.5.5.9" class="ltx_td ltx_align_center">6.57</td>
<td id="S4.T4.1.1.5.5.10" class="ltx_td ltx_align_center">1.65</td>
<td id="S4.T4.1.1.5.5.11" class="ltx_td ltx_align_center">5.65</td>
<td id="S4.T4.1.1.5.5.12" class="ltx_td ltx_align_center">7.27</td>
<td id="S4.T4.1.1.5.5.13" class="ltx_td ltx_align_center ltx_border_r">7.37</td>
<td id="S4.T4.1.1.5.5.14" class="ltx_td ltx_align_center">7.10</td>
</tr>
<tr id="S4.T4.1.1.6.6" class="ltx_tr">
<th id="S4.T4.1.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">M3</th>
<th id="S4.T4.1.1.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Multi. phoneme L</th>
<th id="S4.T4.1.1.6.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">543</th>
<td id="S4.T4.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.6.6.4.1" class="ltx_text ltx_font_bold">8.80</span></td>
<td id="S4.T4.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.6.6.5.1" class="ltx_text ltx_font_bold">7.02</span></td>
<td id="S4.T4.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_bb">14.02</td>
<td id="S4.T4.1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.6.6.7.1" class="ltx_text ltx_font_bold">8.16</span></td>
<td id="S4.T4.1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_bb">0.94</td>
<td id="S4.T4.1.1.6.6.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.6.6.9.1" class="ltx_text ltx_font_bold">6.22</span></td>
<td id="S4.T4.1.1.6.6.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.6.6.10.1" class="ltx_text ltx_font_bold">1.46</span></td>
<td id="S4.T4.1.1.6.6.11" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.6.6.11.1" class="ltx_text ltx_font_bold">5.06</span></td>
<td id="S4.T4.1.1.6.6.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.6.6.12.1" class="ltx_text ltx_font_bold">7.05</span></td>
<td id="S4.T4.1.1.6.6.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T4.1.1.6.6.13.1" class="ltx_text ltx_font_bold">6.92</span></td>
<td id="S4.T4.1.1.6.6.14" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T4.1.1.6.6.14.1" class="ltx_text ltx_font_bold">6.56</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Results</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In the following, we introduce the experimental results over CV-Lang10, which serves as a common setup for comparing the three MCL-ASR approaches -
supervised pre-training with weakly phonetic supervision (Whistle), subword-based supervised pre-training, and wav2vec 2.0 based self-supervised pre-training.
The three approaches are described in Section <a href="#S3.SS1" title="III-A Phoneme-based multilingual supervised pre-training ‣ III Approach ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>,
<a href="#S3.SS2" title="III-B Subword-based multilingual supervised pre-training ‣ III Approach ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>,
and <a href="#S3.SS3" title="III-C Multilingual self-supervised pre-training ‣ III Approach ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>, respectively.
An MCL-ASR approach is usually evaluated under two tasks. The first is to recognize utterances from seen languages, i.e., the languages that are included in multilingual pre-training. The second is to recognize utterances from unseen languages, i.e., crosslingual speech recognition, which is often performed by fine-tuning the model obtained from pre-training.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Multilingual pre-training</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">On the CV-Lang10 dataset, 10 phoneme-based monolingual models are trained, each for a single language and with 90M parameters.
Phoneme-based multilingual models (Whistle models) and subword-based multilingual models are trained for comparison.
WFST-based decoding are used for all models.
The PERs and WERs are shown in Table <a href="#S4.T3" title="TABLE III ‣ IV-C Model training ‣ IV Experimental setup ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> and <a href="#S4.T4" title="TABLE IV ‣ IV-C Model training ‣ IV Experimental setup ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> respectively.
The main observations are as follows.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">First, <em id="S5.SS1.p2.1.1" class="ltx_emph ltx_font_italic">comparing within phoneme-based models</em>, it can be seen that pooling data from multiple languages and training multilingual models clearly reduces PERs over monolingual models, as shown in prior works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
Particularly, a single multilingual model (Mult. phoneme L with 543M parameters) performs significantly better than the 10 monolingual separately-trained models (10 * 90M parameters), on averaged PERs over the 10 seen languages.
Furthermore, we can see that reductions in WERs can be obtained as well, by phoneme-based multilingual pre-training and WFST-based decoding.
Interestingly, in terms of WERs, even the small multilingual model (Mult. phoneme S with 90M parameters) surpasses the monolingual models.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Second, <em id="S5.SS1.p3.1.1" class="ltx_emph ltx_font_italic">comparing multilingual models based on phonemes and subwords</em>, it is found that the phoneme-based multilingual model (M1) obtains better WERs than the subword-based multilingual model (M4), with close model sizes (around 90M)<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>The minor difference in model sizes between phoneme-based model and subword-based model (90M vs 92M) is due to the size of the linear layer because of the different alphabet sizes.</span></span></span>, with 18% WER relative reduction<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>An exception is that for French, the phoneme-based multilingual model does not outperform the subword-based multilingual model in WER, though the PERs are good.
From the statistics of CV-Lang10, we find that the percentage of homophones in the G2P PROLEX of French is the highest (22.5%). The other large percentages of homophones in the 10 langauges in CV-Lang10 is 9.0% for English, 5.2% for Spanish, while others are below 3%.
Moreover, it is found that some consonants in French words are usually not pronounced, but they may be pronounced when they are spoken in sentences. The WFST-based decoding with a PROLEX may not be good at capturing these regularities. These issues could be alleviated by developing a better method of decoding from phonemes, which will be explored in future.</span></span></span>.
This is a fair comparison to answer RQ-1, since both models are trained with the same dataset and the same encoder architecture.
Presumably, compared to using subwords which mainly serve for text writing, using phonemes as labels is more natural and better for sound classification, since inherently they are more directly related to describing sounds for languages.
Moreover, it can been seen from Figure <a href="#S4.F2" title="Figure 2 ‣ IV-B Text normalization and phonemization ‣ IV Experimental setup ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> that data imbalance is more severe in subword supervision than phoneme supervision.
From a machine learning perspective, multi-task learning could be severely affected by data imbalance.
When data are not well balanced in training, an annoying phenomenon, often observed in subword-based systems, is that high resource languages may suffer from interference and low resource languages may be under-trained, which cause performance degradation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
Subword-based systems need special tricks to struggle with data imbalance, such as careful tokenization to appropriately creating the set of tokens <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, human-in-the-loop data mixing in training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.
In contrast, the superior performances from phoneme-based systems are obtained by training on natural data mixing and adopting the classic IPA symbols that have been matured for describing human sounds for a long time.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">Third, <em id="S5.SS1.p4.1.1" class="ltx_emph ltx_font_italic">we can see clear scaling properties of phoneme-based models</em> - PERs and WERs are consistently reduced for both high-resource and low-resource languages, as the model sizes are increased.
Again, remarkably, the performance improvements for different sizes of phoneme-based models are obtained by training on natural data mixing.</p>
</div>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE V: </span>PERs and WERs for phoneme-based crosslingual fine-tuning (FT) on Polish. The pre-training dataset is CV-Lang10.</figcaption>
<div id="S5.T5.1" class="ltx_inline-block ltx_transformed_outer" style="width:251.2pt;height:126.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.0pt,7.1pt) scale(0.9,0.9) ;">
<table id="S5.T5.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T5.1.1.1.1" class="ltx_tr">
<th id="S5.T5.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2">
<span id="S5.T5.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.1.1.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">id</span></span>
</span>
</th>
<th id="S5.T5.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2">
<span id="S5.T5.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.1.1.2.1.1" class="ltx_p" style="width:91.0pt;"><span id="S5.T5.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Model</span></span>
</span>
</th>
<td id="S5.T5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T5.1.1.1.1.3.1" class="ltx_text ltx_font_bold">1h</span></td>
<td id="S5.T5.1.1.1.1.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T5.1.1.1.1.4.1" class="ltx_text ltx_font_bold">10h</span></td>
<td id="S5.T5.1.1.1.1.5" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="S5.T5.1.1.1.1.5.1" class="ltx_text ltx_font_bold">130h</span></td>
</tr>
<tr id="S5.T5.1.1.2.2" class="ltx_tr">
<td id="S5.T5.1.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T5.1.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.2.2.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">PER</span></span>
</span>
</td>
<td id="S5.T5.1.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T5.1.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.2.2.2.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T5.1.1.2.2.2.1.1.1" class="ltx_text ltx_font_bold">WER</span></span>
</span>
</td>
<td id="S5.T5.1.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T5.1.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.2.2.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">PER</span></span>
</span>
</td>
<td id="S5.T5.1.1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T5.1.1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.2.2.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T5.1.1.2.2.4.1.1.1" class="ltx_text ltx_font_bold">WER</span></span>
</span>
</td>
<td id="S5.T5.1.1.2.2.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T5.1.1.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.2.2.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.2.2.5.1.1.1" class="ltx_text ltx_font_bold">PER</span></span>
</span>
</td>
<td id="S5.T5.1.1.2.2.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T5.1.1.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.2.2.6.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.2.2.6.1.1.1" class="ltx_text ltx_font_bold">WER</span></span>
</span>
</td>
</tr>
<tr id="S5.T5.1.1.3.3" class="ltx_tr">
<th id="S5.T5.1.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T5.1.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.3.3.1.1.1" class="ltx_p" style="width:11.4pt;">O2</span>
</span>
</th>
<th id="S5.T5.1.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T5.1.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.3.3.2.1.1" class="ltx_p" style="width:91.0pt;">Mono. phoneme</span>
</span>
</th>
<td id="S5.T5.1.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T5.1.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.3.3.3.1.1" class="ltx_p" style="width:11.4pt;">86.01</span>
</span>
</td>
<td id="S5.T5.1.1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T5.1.1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.3.3.4.1.1" class="ltx_p" style="width:14.2pt;">99.98</span>
</span>
</td>
<td id="S5.T5.1.1.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T5.1.1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.3.3.5.1.1" class="ltx_p" style="width:11.4pt;">30.38</span>
</span>
</td>
<td id="S5.T5.1.1.3.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T5.1.1.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.3.3.6.1.1" class="ltx_p" style="width:14.2pt;">13.86</span>
</span>
</td>
<td id="S5.T5.1.1.3.3.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T5.1.1.3.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.3.3.7.1.1" class="ltx_p" style="width:11.4pt;">2.82</span>
</span>
</td>
<td id="S5.T5.1.1.3.3.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T5.1.1.3.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.3.3.8.1.1" class="ltx_p" style="width:11.4pt;">4.97</span>
</span>
</td>
</tr>
<tr id="S5.T5.1.1.4.4" class="ltx_tr">
<th id="S5.T5.1.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T5.1.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.4.4.1.1.1" class="ltx_p" style="width:11.4pt;">M5</span>
</span>
</th>
<th id="S5.T5.1.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T5.1.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.4.4.2.1.1" class="ltx_p" style="width:91.0pt;">W2V (En) phoneme FT</span>
</span>
</th>
<td id="S5.T5.1.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T5.1.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.4.4.3.1.1" class="ltx_p" style="width:11.4pt;">25.76</span>
</span>
</td>
<td id="S5.T5.1.1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T5.1.1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.4.4.4.1.1" class="ltx_p" style="width:14.2pt;">11.09</span>
</span>
</td>
<td id="S5.T5.1.1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T5.1.1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.4.4.5.1.1" class="ltx_p" style="width:11.4pt;">16.64</span>
</span>
</td>
<td id="S5.T5.1.1.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T5.1.1.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.4.4.6.1.1" class="ltx_p" style="width:14.2pt;"> 6.75</span>
</span>
</td>
<td id="S5.T5.1.1.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T5.1.1.4.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.4.4.7.1.1" class="ltx_p" style="width:11.4pt;">5.80</span>
</span>
</td>
<td id="S5.T5.1.1.4.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T5.1.1.4.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.4.4.8.1.1" class="ltx_p" style="width:11.4pt;">4.57</span>
</span>
</td>
</tr>
<tr id="S5.T5.1.1.5.5" class="ltx_tr">
<th id="S5.T5.1.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T5.1.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.5.5.1.1.1" class="ltx_p" style="width:11.4pt;">M6</span>
</span>
</th>
<th id="S5.T5.1.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T5.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.5.5.2.1.1" class="ltx_p" style="width:91.0pt;">W2V (10 lang) phoneme FT</span>
</span>
</th>
<td id="S5.T5.1.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T5.1.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.5.5.3.1.1" class="ltx_p" style="width:11.4pt;">21.10</span>
</span>
</td>
<td id="S5.T5.1.1.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T5.1.1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.5.5.4.1.1" class="ltx_p" style="width:14.2pt;"> 7.94</span>
</span>
</td>
<td id="S5.T5.1.1.5.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T5.1.1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.5.5.5.1.1" class="ltx_p" style="width:11.4pt;">12.65</span>
</span>
</td>
<td id="S5.T5.1.1.5.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T5.1.1.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.5.5.6.1.1" class="ltx_p" style="width:14.2pt;"> 5.65</span>
</span>
</td>
<td id="S5.T5.1.1.5.5.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T5.1.1.5.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.5.5.7.1.1" class="ltx_p" style="width:11.4pt;">6.08</span>
</span>
</td>
<td id="S5.T5.1.1.5.5.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T5.1.1.5.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.5.5.8.1.1" class="ltx_p" style="width:11.4pt;">4.44</span>
</span>
</td>
</tr>
<tr id="S5.T5.1.1.6.6" class="ltx_tr">
<th id="S5.T5.1.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S5.T5.1.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.6.6.1.1.1" class="ltx_p" style="width:11.4pt;">M7</span>
</span>
</th>
<th id="S5.T5.1.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S5.T5.1.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.6.6.2.1.1" class="ltx_p" style="width:91.0pt;">M1 + phoneme FT</span>
</span>
</th>
<td id="S5.T5.1.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T5.1.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.6.6.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.6.6.3.1.1.1" class="ltx_text ltx_font_bold">17.96</span></span>
</span>
</td>
<td id="S5.T5.1.1.6.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S5.T5.1.1.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.6.6.4.1.1" class="ltx_p" style="width:14.2pt;"> <span id="S5.T5.1.1.6.6.4.1.1.1" class="ltx_text ltx_font_bold">6.95</span></span>
</span>
</td>
<td id="S5.T5.1.1.6.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T5.1.1.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.6.6.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.6.6.5.1.1.1" class="ltx_text ltx_font_bold">10.47</span></span>
</span>
</td>
<td id="S5.T5.1.1.6.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S5.T5.1.1.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.6.6.6.1.1" class="ltx_p" style="width:14.2pt;"> <span id="S5.T5.1.1.6.6.6.1.1.1" class="ltx_text ltx_font_bold">5.27</span></span>
</span>
</td>
<td id="S5.T5.1.1.6.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T5.1.1.6.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.6.6.7.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.6.6.7.1.1.1" class="ltx_text ltx_font_bold">1.97</span></span>
</span>
</td>
<td id="S5.T5.1.1.6.6.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T5.1.1.6.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T5.1.1.6.6.8.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T5.1.1.6.6.8.1.1.1" class="ltx_text ltx_font_bold">4.30</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>WERs for subword-based crosslingual fine-tuning (FT) on Polish. The pre-training dataset is CV-Lang10.</figcaption>
<div id="S5.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:251.2pt;height:162.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.0pt,9.0pt) scale(0.9,0.9) ;">
<table id="S5.T6.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T6.1.1.1.1" class="ltx_tr">
<th id="S5.T6.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="3">
<span id="S5.T6.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.1.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">id</span></span>
</span>
</th>
<th id="S5.T6.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="3">
<span id="S5.T6.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.1.1.2.1.1" class="ltx_p" style="width:91.0pt;"><span id="S5.T6.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Model</span></span>
</span>
</th>
<td id="S5.T6.1.1.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T6.1.1.1.1.3.1" class="ltx_text ltx_font_bold">1h</span></td>
<td id="S5.T6.1.1.1.1.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T6.1.1.1.1.4.1" class="ltx_text ltx_font_bold">10h</span></td>
<td id="S5.T6.1.1.1.1.5" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="S5.T6.1.1.1.1.5.1" class="ltx_text ltx_font_bold">130h</span></td>
</tr>
<tr id="S5.T6.1.1.2.2" class="ltx_tr">
<td id="S5.T6.1.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.2.2.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">w/o</span></span>
</span>
</td>
<td id="S5.T6.1.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T6.1.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.2.2.2.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T6.1.1.2.2.2.1.1.1" class="ltx_text ltx_font_bold"> w</span></span>
</span>
</td>
<td id="S5.T6.1.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.2.2.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">w/o</span></span>
</span>
</td>
<td id="S5.T6.1.1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T6.1.1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.2.2.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T6.1.1.2.2.4.1.1.1" class="ltx_text ltx_font_bold"> w</span></span>
</span>
</td>
<td id="S5.T6.1.1.2.2.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.2.2.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.2.2.5.1.1.1" class="ltx_text ltx_font_bold">w/o</span></span>
</span>
</td>
<td id="S5.T6.1.1.2.2.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.2.2.6.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.2.2.6.1.1.1" class="ltx_text ltx_font_bold"> w</span></span>
</span>
</td>
</tr>
<tr id="S5.T6.1.1.3.3" class="ltx_tr">
<td id="S5.T6.1.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.3.3.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T6.1.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T6.1.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.3.3.2.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T6.1.1.3.3.2.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T6.1.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.3.3.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.3.3.3.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T6.1.1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T6.1.1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.3.3.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T6.1.1.3.3.4.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T6.1.1.3.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.3.3.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.3.3.5.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T6.1.1.3.3.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.3.3.6.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.3.3.6.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
</tr>
<tr id="S5.T6.1.1.4.4" class="ltx_tr">
<th id="S5.T6.1.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.4.4.1.1.1" class="ltx_p" style="width:11.4pt;">O3</span>
</span>
</th>
<th id="S5.T6.1.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.4.4.2.1.1" class="ltx_p" style="width:91.0pt;">Mono. subword</span>
</span>
</th>
<td id="S5.T6.1.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T6.1.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.4.4.3.1.1" class="ltx_p" style="width:11.4pt;">98.41</span>
</span>
</td>
<td id="S5.T6.1.1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.4.4.4.1.1" class="ltx_p" style="width:14.2pt;">98.38</span>
</span>
</td>
<td id="S5.T6.1.1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T6.1.1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.4.4.5.1.1" class="ltx_p" style="width:11.4pt;">90.98</span>
</span>
</td>
<td id="S5.T6.1.1.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.4.4.6.1.1" class="ltx_p" style="width:14.2pt;">59.43</span>
</span>
</td>
<td id="S5.T6.1.1.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T6.1.1.4.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.4.4.7.1.1" class="ltx_p" style="width:11.4pt;">19.38</span>
</span>
</td>
<td id="S5.T6.1.1.4.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T6.1.1.4.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.4.4.8.1.1" class="ltx_p" style="width:11.4pt;">7.12</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.1.5.5" class="ltx_tr">
<th id="S5.T6.1.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.5.5.1.1.1" class="ltx_p" style="width:11.4pt;">M8</span>
</span>
</th>
<th id="S5.T6.1.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.5.5.2.1.1" class="ltx_p" style="width:91.0pt;">W2V (En) subword FT</span>
</span>
</th>
<td id="S5.T6.1.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T6.1.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.5.5.3.1.1" class="ltx_p" style="width:11.4pt;">100</span>
</span>
</td>
<td id="S5.T6.1.1.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.5.5.4.1.1" class="ltx_p" style="width:14.2pt;">100</span>
</span>
</td>
<td id="S5.T6.1.1.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T6.1.1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.5.5.5.1.1" class="ltx_p" style="width:11.4pt;">45.64</span>
</span>
</td>
<td id="S5.T6.1.1.5.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T6.1.1.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.5.5.6.1.1" class="ltx_p" style="width:14.2pt;">7.08</span>
</span>
</td>
<td id="S5.T6.1.1.5.5.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T6.1.1.5.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.5.5.7.1.1" class="ltx_p" style="width:11.4pt;">8.53</span>
</span>
</td>
<td id="S5.T6.1.1.5.5.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T6.1.1.5.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.5.5.8.1.1" class="ltx_p" style="width:11.4pt;">3.85</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.1.6.6" class="ltx_tr">
<th id="S5.T6.1.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T6.1.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.6.6.1.1.1" class="ltx_p" style="width:11.4pt;">M9</span>
</span>
</th>
<th id="S5.T6.1.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T6.1.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.6.6.2.1.1" class="ltx_p" style="width:91.0pt;">W2V (10 lang) subword FT</span>
</span>
</th>
<td id="S5.T6.1.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.6.6.3.1.1" class="ltx_p" style="width:11.4pt;">99.97</span>
</span>
</td>
<td id="S5.T6.1.1.6.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T6.1.1.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.6.6.4.1.1" class="ltx_p" style="width:14.2pt;">100</span>
</span>
</td>
<td id="S5.T6.1.1.6.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.6.6.5.1.1" class="ltx_p" style="width:11.4pt;">36.93</span>
</span>
</td>
<td id="S5.T6.1.1.6.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T6.1.1.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.6.6.6.1.1" class="ltx_p" style="width:14.2pt;">5.71</span>
</span>
</td>
<td id="S5.T6.1.1.6.6.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.6.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.6.6.7.1.1" class="ltx_p" style="width:11.4pt;">7.49</span>
</span>
</td>
<td id="S5.T6.1.1.6.6.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.6.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.6.6.8.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.6.6.8.1.1.1" class="ltx_text ltx_font_bold">3.45</span></span>
</span>
</td>
</tr>
<tr id="S5.T6.1.1.7.7" class="ltx_tr">
<th id="S5.T6.1.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T6.1.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.7.7.1.1.1" class="ltx_p" style="width:11.4pt;">M10</span>
</span>
</th>
<th id="S5.T6.1.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T6.1.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.7.7.2.1.1" class="ltx_p" style="width:91.0pt;">M4 + subword FT</span>
</span>
</th>
<td id="S5.T6.1.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.7.7.3.1.1" class="ltx_p" style="width:11.4pt;">70.13</span>
</span>
</td>
<td id="S5.T6.1.1.7.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T6.1.1.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.7.7.4.1.1" class="ltx_p" style="width:14.2pt;">9.16</span>
</span>
</td>
<td id="S5.T6.1.1.7.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.7.7.5.1.1" class="ltx_p" style="width:11.4pt;">31.90</span>
</span>
</td>
<td id="S5.T6.1.1.7.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T6.1.1.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.7.7.6.1.1" class="ltx_p" style="width:14.2pt;">4.89</span>
</span>
</td>
<td id="S5.T6.1.1.7.7.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.7.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.7.7.7.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.7.7.7.1.1.1" class="ltx_text ltx_font_bold">5.44</span></span>
</span>
</td>
<td id="S5.T6.1.1.7.7.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T6.1.1.7.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.7.7.8.1.1" class="ltx_p" style="width:11.4pt;">3.76</span>
</span>
</td>
</tr>
<tr id="S5.T6.1.1.8.8" class="ltx_tr">
<th id="S5.T6.1.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S5.T6.1.1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.8.8.1.1.1" class="ltx_p" style="width:11.4pt;">M11</span>
</span>
</th>
<th id="S5.T6.1.1.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S5.T6.1.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.8.8.2.1.1" class="ltx_p" style="width:91.0pt;">M1 + subword FT</span>
</span>
</th>
<td id="S5.T6.1.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T6.1.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.8.8.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.8.8.3.1.1.1" class="ltx_text ltx_font_bold">69.50</span></span>
</span>
</td>
<td id="S5.T6.1.1.8.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S5.T6.1.1.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.8.8.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T6.1.1.8.8.4.1.1.1" class="ltx_text ltx_font_bold">8.63</span></span>
</span>
</td>
<td id="S5.T6.1.1.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T6.1.1.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.8.8.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T6.1.1.8.8.5.1.1.1" class="ltx_text ltx_font_bold">31.89</span></span>
</span>
</td>
<td id="S5.T6.1.1.8.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S5.T6.1.1.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.8.8.6.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T6.1.1.8.8.6.1.1.1" class="ltx_text ltx_font_bold">4.83</span></span>
</span>
</td>
<td id="S5.T6.1.1.8.8.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T6.1.1.8.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.8.8.7.1.1" class="ltx_p" style="width:11.4pt;">5.84</span>
</span>
</td>
<td id="S5.T6.1.1.8.8.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T6.1.1.8.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T6.1.1.8.8.8.1.1" class="ltx_p" style="width:11.4pt;">3.82</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S5.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>PERs and WERs for phoneme-based crosslingual fine-tuning (FT) on Indonesian. The pre-training dataset is CV-Lang10.</figcaption>
<div id="S5.T7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:251.2pt;height:126.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.0pt,7.1pt) scale(0.9,0.9) ;">
<table id="S5.T7.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T7.1.1.1.1" class="ltx_tr">
<th id="S5.T7.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2">
<span id="S5.T7.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.1.1.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">id</span></span>
</span>
</th>
<th id="S5.T7.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2">
<span id="S5.T7.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.1.1.2.1.1" class="ltx_p" style="width:91.0pt;"><span id="S5.T7.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Model</span></span>
</span>
</th>
<td id="S5.T7.1.1.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T7.1.1.1.1.3.1" class="ltx_text ltx_font_bold">1h</span></td>
<td id="S5.T7.1.1.1.1.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T7.1.1.1.1.4.1" class="ltx_text ltx_font_bold">10h</span></td>
<td id="S5.T7.1.1.1.1.5" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="S5.T7.1.1.1.1.5.1" class="ltx_text ltx_font_bold">20h</span></td>
</tr>
<tr id="S5.T7.1.1.2.2" class="ltx_tr">
<td id="S5.T7.1.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T7.1.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.2.2.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">PER</span></span>
</span>
</td>
<td id="S5.T7.1.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T7.1.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.2.2.2.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T7.1.1.2.2.2.1.1.1" class="ltx_text ltx_font_bold">WER</span></span>
</span>
</td>
<td id="S5.T7.1.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T7.1.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.2.2.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">PER</span></span>
</span>
</td>
<td id="S5.T7.1.1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T7.1.1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.2.2.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T7.1.1.2.2.4.1.1.1" class="ltx_text ltx_font_bold">WER</span></span>
</span>
</td>
<td id="S5.T7.1.1.2.2.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T7.1.1.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.2.2.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.2.2.5.1.1.1" class="ltx_text ltx_font_bold">PER</span></span>
</span>
</td>
<td id="S5.T7.1.1.2.2.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T7.1.1.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.2.2.6.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.2.2.6.1.1.1" class="ltx_text ltx_font_bold">WER</span></span>
</span>
</td>
</tr>
<tr id="S5.T7.1.1.3.3" class="ltx_tr">
<th id="S5.T7.1.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T7.1.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.3.1.1.1" class="ltx_p" style="width:11.4pt;">O4</span>
</span>
</th>
<th id="S5.T7.1.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T7.1.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.3.2.1.1" class="ltx_p" style="width:91.0pt;">Mono. phoneme</span>
</span>
</th>
<td id="S5.T7.1.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.3.3.1.1" class="ltx_p" style="width:11.4pt;">96.52</span>
</span>
</td>
<td id="S5.T7.1.1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T7.1.1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.3.4.1.1" class="ltx_p" style="width:14.2pt;">100</span>
</span>
</td>
<td id="S5.T7.1.1.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.3.5.1.1" class="ltx_p" style="width:11.4pt;">27.30</span>
</span>
</td>
<td id="S5.T7.1.1.3.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T7.1.1.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.3.6.1.1" class="ltx_p" style="width:14.2pt;">7.71</span>
</span>
</td>
<td id="S5.T7.1.1.3.3.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.3.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.3.7.1.1" class="ltx_p" style="width:11.4pt;">5.74</span>
</span>
</td>
<td id="S5.T7.1.1.3.3.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.3.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.3.3.8.1.1" class="ltx_p" style="width:11.4pt;">3.28</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.1.4.4" class="ltx_tr">
<th id="S5.T7.1.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T7.1.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.4.4.1.1.1" class="ltx_p" style="width:11.4pt;">M12</span>
</span>
</th>
<th id="S5.T7.1.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T7.1.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.4.4.2.1.1" class="ltx_p" style="width:91.0pt;">W2V (En) phoneme FT</span>
</span>
</th>
<td id="S5.T7.1.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.4.4.3.1.1" class="ltx_p" style="width:11.4pt;">31.30</span>
</span>
</td>
<td id="S5.T7.1.1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T7.1.1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.4.4.4.1.1" class="ltx_p" style="width:14.2pt;">6.73</span>
</span>
</td>
<td id="S5.T7.1.1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.4.4.5.1.1" class="ltx_p" style="width:11.4pt;">10.89</span>
</span>
</td>
<td id="S5.T7.1.1.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T7.1.1.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.4.4.6.1.1" class="ltx_p" style="width:14.2pt;">3.31</span>
</span>
</td>
<td id="S5.T7.1.1.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.4.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.4.4.7.1.1" class="ltx_p" style="width:11.4pt;">6.84</span>
</span>
</td>
<td id="S5.T7.1.1.4.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T7.1.1.4.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.4.4.8.1.1" class="ltx_p" style="width:11.4pt;">2.83</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.1.5.5" class="ltx_tr">
<th id="S5.T7.1.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T7.1.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.5.5.1.1.1" class="ltx_p" style="width:11.4pt;">M13</span>
</span>
</th>
<th id="S5.T7.1.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T7.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.5.5.2.1.1" class="ltx_p" style="width:91.0pt;">W2V (10 lang) phoneme FT</span>
</span>
</th>
<td id="S5.T7.1.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T7.1.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.5.5.3.1.1" class="ltx_p" style="width:11.4pt;">24.91</span>
</span>
</td>
<td id="S5.T7.1.1.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T7.1.1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.5.5.4.1.1" class="ltx_p" style="width:14.2pt;">3.75</span>
</span>
</td>
<td id="S5.T7.1.1.5.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T7.1.1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.5.5.5.1.1" class="ltx_p" style="width:11.4pt;">10.32</span>
</span>
</td>
<td id="S5.T7.1.1.5.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T7.1.1.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.5.5.6.1.1" class="ltx_p" style="width:14.2pt;">2.79</span>
</span>
</td>
<td id="S5.T7.1.1.5.5.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T7.1.1.5.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.5.5.7.1.1" class="ltx_p" style="width:11.4pt;">6.30</span>
</span>
</td>
<td id="S5.T7.1.1.5.5.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T7.1.1.5.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.5.5.8.1.1" class="ltx_p" style="width:11.4pt;">2.47</span>
</span>
</td>
</tr>
<tr id="S5.T7.1.1.6.6" class="ltx_tr">
<th id="S5.T7.1.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S5.T7.1.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.6.6.1.1.1" class="ltx_p" style="width:11.4pt;">M14</span>
</span>
</th>
<th id="S5.T7.1.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S5.T7.1.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.6.6.2.1.1" class="ltx_p" style="width:91.0pt;">M1 + phoneme FT</span>
</span>
</th>
<td id="S5.T7.1.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T7.1.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.6.6.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.6.6.3.1.1.1" class="ltx_text ltx_font_bold">21.64</span></span>
</span>
</td>
<td id="S5.T7.1.1.6.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S5.T7.1.1.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.6.6.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T7.1.1.6.6.4.1.1.1" class="ltx_text ltx_font_bold">3.27</span></span>
</span>
</td>
<td id="S5.T7.1.1.6.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T7.1.1.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.6.6.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.6.6.5.1.1.1" class="ltx_text ltx_font_bold">7.90</span></span>
</span>
</td>
<td id="S5.T7.1.1.6.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S5.T7.1.1.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.6.6.6.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T7.1.1.6.6.6.1.1.1" class="ltx_text ltx_font_bold">2.54</span></span>
</span>
</td>
<td id="S5.T7.1.1.6.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T7.1.1.6.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.6.6.7.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.6.6.7.1.1.1" class="ltx_text ltx_font_bold">4.79</span></span>
</span>
</td>
<td id="S5.T7.1.1.6.6.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T7.1.1.6.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T7.1.1.6.6.8.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T7.1.1.6.6.8.1.1.1" class="ltx_text ltx_font_bold">2.43</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S5.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span>WERs for subword-based crosslingual fine-tuning (FT) on Indonesian. The pre-training dataset is CV-Lang10.</figcaption>
<div id="S5.T8.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:251.2pt;height:162.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.0pt,9.0pt) scale(0.9,0.9) ;">
<table id="S5.T8.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T8.1.1.1.1" class="ltx_tr">
<th id="S5.T8.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="3">
<span id="S5.T8.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.1.1.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">id</span></span>
</span>
</th>
<th id="S5.T8.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="3">
<span id="S5.T8.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.1.1.2.1.1" class="ltx_p" style="width:91.0pt;"><span id="S5.T8.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Model</span></span>
</span>
</th>
<td id="S5.T8.1.1.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T8.1.1.1.1.3.1" class="ltx_text ltx_font_bold">1h</span></td>
<td id="S5.T8.1.1.1.1.4" class="ltx_td ltx_align_center ltx_align_top ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T8.1.1.1.1.4.1" class="ltx_text ltx_font_bold">10h</span></td>
<td id="S5.T8.1.1.1.1.5" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="S5.T8.1.1.1.1.5.1" class="ltx_text ltx_font_bold">20h</span></td>
</tr>
<tr id="S5.T8.1.1.2.2" class="ltx_tr">
<td id="S5.T8.1.1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.2.2.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">w/o</span></span>
</span>
</td>
<td id="S5.T8.1.1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T8.1.1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.2.2.2.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T8.1.1.2.2.2.1.1.1" class="ltx_text ltx_font_bold"> w</span></span>
</span>
</td>
<td id="S5.T8.1.1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.2.2.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.2.2.3.1.1.1" class="ltx_text ltx_font_bold">w/o</span></span>
</span>
</td>
<td id="S5.T8.1.1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T8.1.1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.2.2.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T8.1.1.2.2.4.1.1.1" class="ltx_text ltx_font_bold"> w</span></span>
</span>
</td>
<td id="S5.T8.1.1.2.2.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.2.2.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.2.2.5.1.1.1" class="ltx_text ltx_font_bold">w/o</span></span>
</span>
</td>
<td id="S5.T8.1.1.2.2.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.2.2.6.1.1" class="ltx_p" style="width:11.4pt;"> <span id="S5.T8.1.1.2.2.6.1.1.1" class="ltx_text ltx_font_bold">w</span></span>
</span>
</td>
</tr>
<tr id="S5.T8.1.1.3.3" class="ltx_tr">
<td id="S5.T8.1.1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.3.3.1.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.3.3.1.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T8.1.1.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T8.1.1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.3.3.2.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T8.1.1.3.3.2.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T8.1.1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.3.3.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.3.3.3.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T8.1.1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T8.1.1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.3.3.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T8.1.1.3.3.4.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T8.1.1.3.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.3.3.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.3.3.5.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
<td id="S5.T8.1.1.3.3.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.3.3.6.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.3.3.6.1.1.1" class="ltx_text ltx_font_bold">LM</span></span>
</span>
</td>
</tr>
<tr id="S5.T8.1.1.4.4" class="ltx_tr">
<th id="S5.T8.1.1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T8.1.1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.4.4.1.1.1" class="ltx_p" style="width:11.4pt;">O5</span>
</span>
</th>
<th id="S5.T8.1.1.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T8.1.1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.4.4.2.1.1" class="ltx_p" style="width:91.0pt;">Mono. subword</span>
</span>
</th>
<td id="S5.T8.1.1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T8.1.1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.4.4.3.1.1" class="ltx_p" style="width:11.4pt;">96.62</span>
</span>
</td>
<td id="S5.T8.1.1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T8.1.1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.4.4.4.1.1" class="ltx_p" style="width:14.2pt;">96.42</span>
</span>
</td>
<td id="S5.T8.1.1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T8.1.1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.4.4.5.1.1" class="ltx_p" style="width:11.4pt;">69.57</span>
</span>
</td>
<td id="S5.T8.1.1.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T8.1.1.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.4.4.6.1.1" class="ltx_p" style="width:14.2pt;">49.67</span>
</span>
</td>
<td id="S5.T8.1.1.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T8.1.1.4.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.4.4.7.1.1" class="ltx_p" style="width:11.4pt;">31.96</span>
</span>
</td>
<td id="S5.T8.1.1.4.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T8.1.1.4.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.4.4.8.1.1" class="ltx_p" style="width:11.4pt;">10.85</span>
</span>
</td>
</tr>
<tr id="S5.T8.1.1.5.5" class="ltx_tr">
<th id="S5.T8.1.1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T8.1.1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.5.5.1.1.1" class="ltx_p" style="width:11.4pt;">M15</span>
</span>
</th>
<th id="S5.T8.1.1.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S5.T8.1.1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.5.5.2.1.1" class="ltx_p" style="width:91.0pt;">W2V (En) subword FT</span>
</span>
</th>
<td id="S5.T8.1.1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T8.1.1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.5.5.3.1.1" class="ltx_p" style="width:11.4pt;">100</span>
</span>
</td>
<td id="S5.T8.1.1.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T8.1.1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.5.5.4.1.1" class="ltx_p" style="width:14.2pt;">100</span>
</span>
</td>
<td id="S5.T8.1.1.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T8.1.1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.5.5.5.1.1" class="ltx_p" style="width:11.4pt;">19.98</span>
</span>
</td>
<td id="S5.T8.1.1.5.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S5.T8.1.1.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.5.5.6.1.1" class="ltx_p" style="width:14.2pt;">5.28</span>
</span>
</td>
<td id="S5.T8.1.1.5.5.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T8.1.1.5.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.5.5.7.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.5.5.7.1.1.1" class="ltx_text ltx_font_bold">11.68</span></span>
</span>
</td>
<td id="S5.T8.1.1.5.5.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S5.T8.1.1.5.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.5.5.8.1.1" class="ltx_p" style="width:11.4pt;">3.59</span>
</span>
</td>
</tr>
<tr id="S5.T8.1.1.6.6" class="ltx_tr">
<th id="S5.T8.1.1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T8.1.1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.6.6.1.1.1" class="ltx_p" style="width:11.4pt;">M16</span>
</span>
</th>
<th id="S5.T8.1.1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T8.1.1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.6.6.2.1.1" class="ltx_p" style="width:91.0pt;">W2V (10 lang) subword FT</span>
</span>
</th>
<td id="S5.T8.1.1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.6.6.3.1.1" class="ltx_p" style="width:11.4pt;">99.64</span>
</span>
</td>
<td id="S5.T8.1.1.6.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T8.1.1.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.6.6.4.1.1" class="ltx_p" style="width:14.2pt;">99.97</span>
</span>
</td>
<td id="S5.T8.1.1.6.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.6.6.5.1.1" class="ltx_p" style="width:11.4pt;">19.08</span>
</span>
</td>
<td id="S5.T8.1.1.6.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T8.1.1.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.6.6.6.1.1" class="ltx_p" style="width:14.2pt;">4.52</span>
</span>
</td>
<td id="S5.T8.1.1.6.6.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.6.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.6.6.7.1.1" class="ltx_p" style="width:11.4pt;">12.01</span>
</span>
</td>
<td id="S5.T8.1.1.6.6.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.6.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.6.6.8.1.1" class="ltx_p" style="width:11.4pt;">3.15</span>
</span>
</td>
</tr>
<tr id="S5.T8.1.1.7.7" class="ltx_tr">
<th id="S5.T8.1.1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T8.1.1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.7.7.1.1.1" class="ltx_p" style="width:11.4pt;">M17</span>
</span>
</th>
<th id="S5.T8.1.1.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r">
<span id="S5.T8.1.1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.7.7.2.1.1" class="ltx_p" style="width:91.0pt;">M4 + subword FT</span>
</span>
</th>
<td id="S5.T8.1.1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.7.7.3.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.7.7.3.1.1.1" class="ltx_text ltx_font_bold">64.00</span></span>
</span>
</td>
<td id="S5.T8.1.1.7.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T8.1.1.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.7.7.4.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T8.1.1.7.7.4.1.1.1" class="ltx_text ltx_font_bold">23.56</span></span>
</span>
</td>
<td id="S5.T8.1.1.7.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.7.7.5.1.1" class="ltx_p" style="width:11.4pt;">19.41</span>
</span>
</td>
<td id="S5.T8.1.1.7.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="S5.T8.1.1.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.7.7.6.1.1" class="ltx_p" style="width:14.2pt;">3.91</span>
</span>
</td>
<td id="S5.T8.1.1.7.7.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.7.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.7.7.7.1.1" class="ltx_p" style="width:11.4pt;">13.15</span>
</span>
</td>
<td id="S5.T8.1.1.7.7.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S5.T8.1.1.7.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.7.7.8.1.1" class="ltx_p" style="width:11.4pt;">3.07</span>
</span>
</td>
</tr>
<tr id="S5.T8.1.1.8.8" class="ltx_tr">
<th id="S5.T8.1.1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S5.T8.1.1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.8.8.1.1.1" class="ltx_p" style="width:11.4pt;">M18</span>
</span>
</th>
<th id="S5.T8.1.1.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S5.T8.1.1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.8.8.2.1.1" class="ltx_p" style="width:91.0pt;">M1 + subword FT</span>
</span>
</th>
<td id="S5.T8.1.1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T8.1.1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.8.8.3.1.1" class="ltx_p" style="width:11.4pt;">67.71</span>
</span>
</td>
<td id="S5.T8.1.1.8.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S5.T8.1.1.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.8.8.4.1.1" class="ltx_p" style="width:14.2pt;">24.57</span>
</span>
</td>
<td id="S5.T8.1.1.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T8.1.1.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.8.8.5.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.8.8.5.1.1.1" class="ltx_text ltx_font_bold">18.21</span></span>
</span>
</td>
<td id="S5.T8.1.1.8.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r">
<span id="S5.T8.1.1.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.8.8.6.1.1" class="ltx_p" style="width:14.2pt;"><span id="S5.T8.1.1.8.8.6.1.1.1" class="ltx_text ltx_font_bold">3.59</span></span>
</span>
</td>
<td id="S5.T8.1.1.8.8.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T8.1.1.8.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.8.8.7.1.1" class="ltx_p" style="width:11.4pt;">12.48</span>
</span>
</td>
<td id="S5.T8.1.1.8.8.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S5.T8.1.1.8.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T8.1.1.8.8.8.1.1" class="ltx_p" style="width:11.4pt;"><span id="S5.T8.1.1.8.8.8.1.1.1" class="ltx_text ltx_font_bold">2.92</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Crosslingual fine-tuning</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Over the CV-Lang10 dataset, we obtain the phoneme-based supervised pre-trained model (M1), which can be further fine-tuned with either phoneme labels or subword labels for crosslingual speech recognition.
The subword-based supervised pre-trained model (M4) is fine-tuned with subword labels for crosslingual speech recognition.
The wav2vec 2.0 models, ``W2V (10 lang)'' and ``W2V (En)'', can be fine-tuned with either phoneme labels or subword labels for crosslingual speech recognition.
The four pre-trained models used in the crosslingual experiments all have the same model size (around 90M parameters).
On the four pre-trained models, we perform full-parameter fine-tuning, except that for the two wav2vec 2.0 based pre-trained models, the convolutional feature encoder are frozen.
</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">To test different multilingual pre-trained models for crosslingual speech recognition, we conduct phoneme-based and subword-based crosslingual fine-tuning on unseen languages.
The training data from an unseen language is divided into three scales to simulate different resource scenarios, while the test and validation data remain unchanged.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">The first unseen language is Polish.
Polish has 31 phonemes contained in CV-Lang10 and 4 unseen phonemes. The training data is divided into three scales: 1 hour, 10 hours, and full (130 hours).
Combining Table <a href="#S5.T5" title="TABLE V ‣ V-A Multilingual pre-training ‣ V Results ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> and Table <a href="#S5.T6" title="TABLE VI ‣ V-A Multilingual pre-training ‣ V Results ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>, we have the following main observations.</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">In the low-resource scenario with 1-hour Polish training data, phoneme pre-training (PT) followed by phoneme fine-tuning (FT) performs the best (6.95).
Results with phoneme PT are much better than those with subword PT, which clearly shows the advantage of phonetic supervision in representation learning from multilingual data (RQ-1).
When comparing phoneme PT and wav2vec 2.0 PT (M7 vs M6, M11 vs M9), phoneme PT shows obvious superiority (RQ-2).</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">In the scenario with 10-hour Polish training data, the performance with subword PT models begins to improve. When followed by subword FT, both phoneme PT and subword-based PT show equally excellent results (4.83 and 4.89).</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">With the full Polish training data, the wav2vec 2.0 PT models start to perform well, surpassing results with both subword PT and phoneme PT (3.45 &lt; 3.76 &lt; 3.82). This may reflect some benefit of wav2vec 2.0 PT when fine-tuned with abundant labels, but such top-performing result with wav2vec 2.0 PT is not observed in Indonesian experiments, as shown below.</p>
</div>
</li>
</ul>
</div>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">The second unseen language is Indonesian.
All 35 phonemes of Indonesian are contained in CV-Lang10.
But Indonesian belongs to the Austronesian language family, which are somewhat more different from CV-Lang10, and only 20 hours of training data are available. These make crosslingual fine-tuning for Indonesian more challenging.
The training data is divided into three scales: 1 hour, 10 hours, and full (20 hours).</p>
</div>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p">From Table <a href="#S5.T7" title="TABLE VII ‣ V-A Multilingual pre-training ‣ V Results ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a> and Table <a href="#S5.T8" title="TABLE VIII ‣ V-A Multilingual pre-training ‣ V Results ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a> for Indonesian, the observations are similar to those for Polish.
In the more challenging scenario with larger linguistic difference and less training data, the advantages of phoneme PT followed by phoneme FT are more obvious, across all the three scales of data settings.
It seems that when training data are more limited, the better results can be obtained by phoneme supervision, compared to subword supervision and self-supervision.
When the amount of crosslingual training data increases, the performance gaps between phoneme supervision, subword supervision and self-supervision may diminish. Presumably, the fine-tuning with abundant data behaves like end-to-end monolingual training and the effect of different PT methods may become weak.</p>
</div>
<figure id="S5.F3" class="ltx_figure">
<div id="S5.F3.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:396.3pt;height:299.4pt;vertical-align:-147.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.0pt,8.5pt) scale(0.9,0.9) ;">
<div id="S5.F3.1.1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:216.8pt;">
<p id="S5.F3.1.1.1.1" class="ltx_p ltx_align_center"><span id="S5.F3.1.1.1.1.1" class="ltx_text"><img src="/html/2406.02166/assets/figure/phn_emb.png" id="S5.F3.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="448" alt="Refer to caption"></span></p>
<p id="S5.F3.1.1.1.2" class="ltx_p ltx_align_center"><span id="S5.F3.1.1.1.2.1" class="ltx_text" style="font-size:70%;">(a)</span></p>
</div>
<div id="S5.F3.2.2.2" class="ltx_block ltx_minipage ltx_align_middle" style="width:216.8pt;">
<p id="S5.F3.2.2.2.1" class="ltx_p ltx_align_center"><span id="S5.F3.2.2.2.1.1" class="ltx_text"><img src="/html/2406.02166/assets/figure/bpe_emb.png" id="S5.F3.2.2.2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="448" alt="Refer to caption"></span></p>
<p id="S5.F3.2.2.2.2" class="ltx_p ltx_align_center"><span id="S5.F3.2.2.2.2.1" class="ltx_text" style="font-size:70%;">(b)</span></p>
</div>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Visualization of embeddings by t-SNE. (a) Phoneme embeddings from M1, (b) Subword embeddings from M4. In (a), blue indicate the consonants and red indicate the vowels.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Ablation study</span>
</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.5.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.6.2" class="ltx_text ltx_font_italic">Analysis of embeddings</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">To gain intuitive understanding of the multilingual models trained under phonetic supervision and graphemic supervision, we apply t-SNE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> to draw the 512-dimensional embeddings on a 2-dimensional map. Figure <a href="#S5.F3" title="Figure 3 ‣ V-B Crosslingual fine-tuning ‣ V Results ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(a) and (b) show the maps of the 73 phoneme embeddings and the 4998 subword embeddings, obtained from the phoneme-based model M1 and subword-based model M4, respectively.
By comparing the two figures, it can be easily seen that the phoneme embeddings are more evenly dispersed in the high-dimensional space.
In contrast, subword embedings are densely crowded in the center and become sparser as they move outward.
This indicates that the representation learning in the subword-based model is not so balanced as in the phoneme-based model.
Presumably, this is due to the severe data imbalance in subword supervision.
Furthermore, it can be noticed that most of the vowels embeddings cluster in the bottom right area of Figure <a href="#S5.F3" title="Figure 3 ‣ V-B Crosslingual fine-tuning ‣ V Results ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(a). Certain consonant phonemes, like approximants ('', '' and 'j'),
also appear in this region, since approximants fall between fricatives and vowels.
This reflects that the phoneme-based model not only learns the differences between phonemes, but also captures some phonetic similarities between phonemes.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.5.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.6.2" class="ltx_text ltx_font_italic">Test of catastrophic forgetting</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">In previous sections, we show the advantage of multilingual pre-trained models by phoneme supervision over those by subword supervision for recognizing seen and unseen languages.
We see that after a pre-trained multilingual model is fine-tuned over data from a new language, the fine-tuned multilingual model can recognize speech from the new language.
Then, to what degree the performance of the fine-tuned multilingual model on previous seen languages would be affected?
This is an interesting question for continual pre-training of multilingual models to support more new languages, a question related to catastrophic forgetting of neural network based models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>.
A complete investigation into continual pre-training of multilingual models is outside the scope of this paper.
Here we present a preliminary examination of the two approaches, phoneme or subword-based multilingual models, in overcoming catastrophic forgetting.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.2" class="ltx_p">The phoneme-based multilingual model M1 and the subword-based multilingual model M4, both pre-trained over CV-Lang10 and with 90M parameters, are fine-tuned separately on 10 minutes of a new language (Polish). The fine-tuned models are then tested not only on Polish, but also on the ten languages in CV-Lang10.
The results are shown in Table <a href="#S6.T9" title="TABLE IX ‣ VI-B Test of catastrophic forgetting ‣ VI Ablation study ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IX</span></a>.
Phoneme PT followed by 10 minutes of phoneme FT obtains WER of 11.0<math id="S6.SS2.p2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S6.SS2.p2.1.m1.1a"><mo id="S6.SS2.p2.1.m1.1.1" xref="S6.SS2.p2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.1.m1.1b"><csymbol cd="latexml" id="S6.SS2.p2.1.m1.1.1.cmml" xref="S6.SS2.p2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.1.m1.1c">\%</annotation></semantics></math> on Polish, while showing a word accuracy relative degradation (WARD) of 48<math id="S6.SS2.p2.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S6.SS2.p2.2.m2.1a"><mo id="S6.SS2.p2.2.m2.1.1" xref="S6.SS2.p2.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S6.SS2.p2.2.m2.1b"><csymbol cd="latexml" id="S6.SS2.p2.2.m2.1.1.cmml" xref="S6.SS2.p2.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p2.2.m2.1c">\%</annotation></semantics></math><span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><math id="footnote7.m1.2" class="ltx_Math" alttext="(52.0-7.61)/(100-7.61)=48\%" display="inline"><semantics id="footnote7.m1.2b"><mrow id="footnote7.m1.2.2" xref="footnote7.m1.2.2.cmml"><mrow id="footnote7.m1.2.2.2" xref="footnote7.m1.2.2.2.cmml"><mrow id="footnote7.m1.1.1.1.1.1" xref="footnote7.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="footnote7.m1.1.1.1.1.1.2" xref="footnote7.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="footnote7.m1.1.1.1.1.1.1" xref="footnote7.m1.1.1.1.1.1.1.cmml"><mn id="footnote7.m1.1.1.1.1.1.1.2" xref="footnote7.m1.1.1.1.1.1.1.2.cmml">52.0</mn><mo id="footnote7.m1.1.1.1.1.1.1.1" xref="footnote7.m1.1.1.1.1.1.1.1.cmml">−</mo><mn id="footnote7.m1.1.1.1.1.1.1.3" xref="footnote7.m1.1.1.1.1.1.1.3.cmml">7.61</mn></mrow><mo stretchy="false" id="footnote7.m1.1.1.1.1.1.3" xref="footnote7.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="footnote7.m1.2.2.2.3" xref="footnote7.m1.2.2.2.3.cmml">/</mo><mrow id="footnote7.m1.2.2.2.2.1" xref="footnote7.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="footnote7.m1.2.2.2.2.1.2" xref="footnote7.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="footnote7.m1.2.2.2.2.1.1" xref="footnote7.m1.2.2.2.2.1.1.cmml"><mn id="footnote7.m1.2.2.2.2.1.1.2" xref="footnote7.m1.2.2.2.2.1.1.2.cmml">100</mn><mo id="footnote7.m1.2.2.2.2.1.1.1" xref="footnote7.m1.2.2.2.2.1.1.1.cmml">−</mo><mn id="footnote7.m1.2.2.2.2.1.1.3" xref="footnote7.m1.2.2.2.2.1.1.3.cmml">7.61</mn></mrow><mo stretchy="false" id="footnote7.m1.2.2.2.2.1.3" xref="footnote7.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow><mo id="footnote7.m1.2.2.3" xref="footnote7.m1.2.2.3.cmml">=</mo><mrow id="footnote7.m1.2.2.4" xref="footnote7.m1.2.2.4.cmml"><mn id="footnote7.m1.2.2.4.2" xref="footnote7.m1.2.2.4.2.cmml">48</mn><mo id="footnote7.m1.2.2.4.1" xref="footnote7.m1.2.2.4.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote7.m1.2c"><apply id="footnote7.m1.2.2.cmml" xref="footnote7.m1.2.2"><eq id="footnote7.m1.2.2.3.cmml" xref="footnote7.m1.2.2.3"></eq><apply id="footnote7.m1.2.2.2.cmml" xref="footnote7.m1.2.2.2"><divide id="footnote7.m1.2.2.2.3.cmml" xref="footnote7.m1.2.2.2.3"></divide><apply id="footnote7.m1.1.1.1.1.1.1.cmml" xref="footnote7.m1.1.1.1.1.1"><minus id="footnote7.m1.1.1.1.1.1.1.1.cmml" xref="footnote7.m1.1.1.1.1.1.1.1"></minus><cn type="float" id="footnote7.m1.1.1.1.1.1.1.2.cmml" xref="footnote7.m1.1.1.1.1.1.1.2">52.0</cn><cn type="float" id="footnote7.m1.1.1.1.1.1.1.3.cmml" xref="footnote7.m1.1.1.1.1.1.1.3">7.61</cn></apply><apply id="footnote7.m1.2.2.2.2.1.1.cmml" xref="footnote7.m1.2.2.2.2.1"><minus id="footnote7.m1.2.2.2.2.1.1.1.cmml" xref="footnote7.m1.2.2.2.2.1.1.1"></minus><cn type="integer" id="footnote7.m1.2.2.2.2.1.1.2.cmml" xref="footnote7.m1.2.2.2.2.1.1.2">100</cn><cn type="float" id="footnote7.m1.2.2.2.2.1.1.3.cmml" xref="footnote7.m1.2.2.2.2.1.1.3">7.61</cn></apply></apply><apply id="footnote7.m1.2.2.4.cmml" xref="footnote7.m1.2.2.4"><csymbol cd="latexml" id="footnote7.m1.2.2.4.1.cmml" xref="footnote7.m1.2.2.4.1">percent</csymbol><cn type="integer" id="footnote7.m1.2.2.4.2.cmml" xref="footnote7.m1.2.2.4.2">48</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m1.2d">(52.0-7.61)/(100-7.61)=48\%</annotation></semantics></math></span></span></span> for the averaged WER over the ten old languages in CV-Lang10.
In contrast, subword PT followed by 10 minutes of subword FT yields much worse result for Polish, and actually breaks down in recognizing the ten old languages, totally losing their multilingual recognition ability after fine-tuning on 10 minutes of a new language.
This suggests that phoneme PT and FT are more robust in overcoming catastrophic forgetting, presumably because the learned representations are stabler and more universal than those learned by subword PT and FT.
Meanwhile, it shows that continual pre-training of multilingual models is a non-trivial problem, which deserves more investigations.</p>
</div>
<figure id="S6.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IX: </span>Test of catastrophic forgetting for the multilingual models, pre-trained over CV-Lang10 and fine-tuned on 10 minutes of a new language (Polish). WARD denotes word accuracy relative degradation of the averaged WER over the ten old languages in CV-Lang10.</figcaption>
<table id="S6.T9.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T9.1.1.1" class="ltx_tr">
<th id="S6.T9.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T9.1.1.1.1.1" class="ltx_text ltx_font_bold">id</span></th>
<th id="S6.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T9.1.1.1.2.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S6.T9.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T9.1.1.1.3.1" class="ltx_text ltx_font_bold">pl</span>
</th>
<th id="S6.T9.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.4.1" class="ltx_text ltx_font_bold">en</span>
</th>
<th id="S6.T9.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.5.1" class="ltx_text ltx_font_bold">fr</span>
</th>
<th id="S6.T9.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.6.1" class="ltx_text ltx_font_bold">es</span></th>
<th id="S6.T9.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.7.1" class="ltx_text ltx_font_bold">it</span></th>
<th id="S6.T9.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.8.1" class="ltx_text ltx_font_bold">ru</span></th>
<th id="S6.T9.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.9.1" class="ltx_text ltx_font_bold">nl</span></th>
<th id="S6.T9.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.10.1" class="ltx_text ltx_font_bold">tr</span></th>
<th id="S6.T9.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.11.1" class="ltx_text ltx_font_bold">ky</span></th>
<th id="S6.T9.1.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.12.1" class="ltx_text ltx_font_bold">sv</span></th>
<th id="S6.T9.1.1.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T9.1.1.1.13.1" class="ltx_text ltx_font_bold">tt</span></th>
<th id="S6.T9.1.1.1.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T9.1.1.1.14.1" class="ltx_text ltx_font_bold">Avg.</span></th>
<th id="S6.T9.1.1.1.15" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T9.1.1.1.15.1" class="ltx_text ltx_font_bold">WARD</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T9.1.2.1" class="ltx_tr">
<td id="S6.T9.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">M19</td>
<td id="S6.T9.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">M1 + 10min phoneme FT</td>
<td id="S6.T9.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.0</td>
<td id="S6.T9.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">68.5</td>
<td id="S6.T9.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">69.3</td>
<td id="S6.T9.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">57.1</td>
<td id="S6.T9.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">50.3</td>
<td id="S6.T9.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t">48.3</td>
<td id="S6.T9.1.2.1.9" class="ltx_td ltx_align_center ltx_border_t">60.9</td>
<td id="S6.T9.1.2.1.10" class="ltx_td ltx_align_center ltx_border_t">31.8</td>
<td id="S6.T9.1.2.1.11" class="ltx_td ltx_align_center ltx_border_t">58.4</td>
<td id="S6.T9.1.2.1.12" class="ltx_td ltx_align_center ltx_border_t">42.3</td>
<td id="S6.T9.1.2.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.0</td>
<td id="S6.T9.1.2.1.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">52.0</td>
<td id="S6.T9.1.2.1.15" class="ltx_td ltx_align_center ltx_border_t">48</td>
</tr>
<tr id="S6.T9.1.3.2" class="ltx_tr">
<td id="S6.T9.1.3.2.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">M20</td>
<td id="S6.T9.1.3.2.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">M4 + 10min subword FT</td>
<td id="S6.T9.1.3.2.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">93.2</td>
<td id="S6.T9.1.3.2.4" class="ltx_td ltx_align_center ltx_border_bb">92.2</td>
<td id="S6.T9.1.3.2.5" class="ltx_td ltx_align_center ltx_border_bb">95.0</td>
<td id="S6.T9.1.3.2.6" class="ltx_td ltx_align_center ltx_border_bb">92.5</td>
<td id="S6.T9.1.3.2.7" class="ltx_td ltx_align_center ltx_border_bb">92.5</td>
<td id="S6.T9.1.3.2.8" class="ltx_td ltx_align_center ltx_border_bb">262.5</td>
<td id="S6.T9.1.3.2.9" class="ltx_td ltx_align_center ltx_border_bb">103.6</td>
<td id="S6.T9.1.3.2.10" class="ltx_td ltx_align_center ltx_border_bb">241.5</td>
<td id="S6.T9.1.3.2.11" class="ltx_td ltx_align_center ltx_border_bb">125.9</td>
<td id="S6.T9.1.3.2.12" class="ltx_td ltx_align_center ltx_border_bb">180.5</td>
<td id="S6.T9.1.3.2.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">254.4</td>
<td id="S6.T9.1.3.2.14" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">154.1</td>
<td id="S6.T9.1.3.2.15" class="ltx_td ltx_align_center ltx_border_bb">160</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS3.5.1.1" class="ltx_text">VI-C</span> </span><span id="S6.SS3.6.2" class="ltx_text ltx_font_italic">Training efficiency</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.2" class="ltx_p">Besides the performance advantage of phoneme-based supervision over subword-based supervision, we find that phoneme-based models tend to be more training efficient, i.e., they can converge with fewer optimzation steps.
Table <a href="#S6.T10" title="TABLE X ‣ VI-C Training efficiency ‣ VI Ablation study ‣ Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition via Weakly Phonetic Supervision" class="ltx_ref"><span class="ltx_text ltx_ref_tag">X</span></a> shows the training epochs when different models converge.
Under equal batch sizes, phoneme PT takes less training epochs than subword PT, with 24<math id="S6.SS3.p1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S6.SS3.p1.1.m1.1a"><mo id="S6.SS3.p1.1.m1.1.1" xref="S6.SS3.p1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.1.m1.1b"><csymbol cd="latexml" id="S6.SS3.p1.1.m1.1.1.cmml" xref="S6.SS3.p1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.1.m1.1c">\%</annotation></semantics></math> reduction.
When crosslingual subword FT is performed on Polish full data, finetuning the phoneme PT model achieves 12<math id="S6.SS3.p1.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S6.SS3.p1.2.m2.1a"><mo id="S6.SS3.p1.2.m2.1.1" xref="S6.SS3.p1.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S6.SS3.p1.2.m2.1b"><csymbol cd="latexml" id="S6.SS3.p1.2.m2.1.1.cmml" xref="S6.SS3.p1.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p1.2.m2.1c">\%</annotation></semantics></math> reduction in finetuning epochs relative to finetuning the subword PT model.
This finding again reveals that phoneme labels can provide more efficient supervision for sound classification than subword labels. It takes a longer, less efficient path for neural networks to learn sound classification from subword supervision.</p>
</div>
<figure id="S6.T10" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE X: </span>Training efficiency of phoneme-based and subword-based pre-training (PT) and fine-tuning (FT).</figcaption>
<table id="S6.T10.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T10.1.1.1" class="ltx_tr">
<th id="S6.T10.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T10.1.1.1.1.1" class="ltx_text ltx_font_bold">id</span></th>
<th id="S6.T10.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T10.1.1.1.2.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S6.T10.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T10.1.1.1.3.1" class="ltx_text ltx_font_bold">Batch size</span>
</th>
<th id="S6.T10.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T10.1.1.1.4.1" class="ltx_text ltx_font_bold">Epochs for converging</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T10.1.2.1" class="ltx_tr">
<th id="S6.T10.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">M1</th>
<th id="S6.T10.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">phoneme PT</th>
<td id="S6.T10.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">640</td>
<td id="S6.T10.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">63</td>
</tr>
<tr id="S6.T10.1.3.2" class="ltx_tr">
<th id="S6.T10.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">M11</th>
<th id="S6.T10.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">M1 + pl subword FT</th>
<td id="S6.T10.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">320</td>
<td id="S6.T10.1.3.2.4" class="ltx_td ltx_align_center">195</td>
</tr>
<tr id="S6.T10.1.4.3" class="ltx_tr">
<th id="S6.T10.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">M4</th>
<th id="S6.T10.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">subword PT</th>
<td id="S6.T10.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">640</td>
<td id="S6.T10.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">83</td>
</tr>
<tr id="S6.T10.1.5.4" class="ltx_tr">
<th id="S6.T10.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">M10</th>
<th id="S6.T10.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">M4 + pl subword FT</th>
<td id="S6.T10.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">320</td>
<td id="S6.T10.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb">223</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Conclusions and future work</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This paper starts from examining the pros and cons of the three main approaches for MCL-ASR - supervised pre-training with phonetic transcription or graphemic transcription, and self-supervised pre-training.
We find that pre-training with phonetic supervision has been underappreciated so far for MCL-ASR, while conceptually it is more advantageous for information sharing between different languages.
This paper explores the approach of pre-training with weakly phonetic supervision towards data-efficient MCL-ASR, which is called Whistle.
We relax the requirement of gold-standard human-validated phonetic transcripts, and obtain IPA based transcripts by leveraging Phonetisaurus (an FST based G2P toolkit) with LanguageNet G2P FSTs.
We construct a common experimental setup based on the CommonVoice dataset, called CV-Lang10, with 10 seen languages and 2 unseen languages (Polish and Indonesian).
A set of experiments are conducted on CV-Lang10 to compare, as fair as possible, the three approaches under the common setup for MCL-ASR.
Training with weakly phonetic supervision (though somewhat noisy) and decoding with PROLEXs, with phonemes serving as an interface between acoustics and text, is found to obtain superior results in MCL-ASR in our experiments, in terms of speech recognition for seen languages, crosslingual performance for unseen languages with different amounts of few-shot data, overcoming catastrophic forgetting, and training efficiency.
Moreover, phoneme-based models naturally overcome language imbalance and can be efficiently trained on natural data mixing, while subword-based models need careful tokenization and data mixing in training.
When training data is more limited, phoneme supervision can achieve better results compared to subword supervision and self-supervision, thereby providing higher data-efficiency.
</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">This work demonstrates some advantages of weakly phonetic supervision towards data-efficient MCL-ASR. There are interesting directions for future work.
First, we preliminarily sidestep the problem how tones should be incorporated in pre-training multilingual phoneme-based models, since the 12 languages examined in this paper are all non-tonal languages. There have been some effort towards addressing this problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>.
Second, this work mainly uses WFST based decoding with PROLEXs. Better methods of decoding from phonemes could be explored in future, such as based on sequence-to-sequence models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>.
Third, scaling the approach of Whistle with more languages and more data is expected to achieve increasingly better MCL-ASR performance. Meanwhile, it is worthwhile to investigate how to incrementally learn from new languages with a non-stationary stream
Continual learning methods such as based on prompt pool
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> could be incorporated into MCL-ASR.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Ethnologue, ``Languages of the world,'' <a target="_blank" href="https://www.ethnologue.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.ethnologue.com/</a>,
2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
L. Lu, A. Ghoshal, and S. Renals, ``Cross-lingual subspace gaussian mixture
models for low-resource speech recognition,'' <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM transactions on
audio, speech, and language processing</em>, vol. 22, pp. 17–27, 2013.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
J.-T. Huang, J. Li, D. Yu, L. Deng, and Y. Gong, ``Cross-language knowledge
transfer using multilingual deep neural network with shared hidden layers,''
in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE international conference on acoustics, speech and signal
processing</em>, 2013, pp. 7304–7308.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Graves, S. Fernández, F. Gomez, and J. Schmidhuber, ``Connectionist
temporal classification: Labelling unsegmented sequence data with recurrent
neural networks,'' in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>,
2006.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A. Graves, ``Sequence transduction with recurrent neural networks,''
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Computer Science</em>, vol. 58, pp. 235–242, 2012.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Chorowski, D. Bahdanau, K. Cho, and Y. Bengio, ``End-to-end continuous
speech recognition using attention-based recurrent NN: First results,'' in
<em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">NIPS Workshop on Deep Learning</em>, 2014.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Conneau, A. Baevski, R. Collobert, A. Mohamed, and M. Auli, ``Unsupervised
cross-lingual representation learning for speech recognition,'' in
<em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2021, pp. 2426–2430.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A. Babu, C. Wang, A. Tjandra, K. Lakhotia, Q. Xu, N. Goyal, K. Singh, P. von
Platen, Y. Saraf, J. Pino <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``XLS-R: Self-supervised
cross-lingual speech representation learning at scale,'' in
<em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">Interspeech</em>, 2021, pp. 2278–2282.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
V. Pratap, A. Tjandra, B. Shi, P. Tomasello, A. Babu, S. Kundu, A. Elkahky,
Z. Ni, A. Vyas, M. Fazel-Zarandi <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Scaling speech technology
to 1,000+ languages,'' <em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, vol. 25,
pp. 1–52, 2024.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
B. Li, R. Pang, T. N. Sainath, A. Gulati, Y. Zhang, J. Qin, P. Haghani, W. R.
Huang, M. Ma, and J. Bai, ``Scaling end-to-end models for large-scale
multilingual ASR,'' in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">IEEE Automatic Speech Recognition and
Understanding Workshop</em>, 2021, pp. 1011–1018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
V. Pratap, A. Sriram, P. Tomasello, A. Hannun, V. Liptchinsky, G. Synnaeve, and
R. Collobert, ``Massively multilingual ASR: 50 languages, 1 model, 1
billion parameters,'' in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2020, pp. 4751–4755.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
A. Tjandra, N. Singhal, D. Zhang, O. Kalinli, A. Mohamed, D. Le, and M. L.
Seltzer, ``Massively multilingual ASR on 70 languages: tokenization,
architecture, and generalization capabilities,'' in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE International
Conference on Acoustics, Speech and Signal Processing</em>, 2023, pp. 1–5.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, T. Xu, G. Brockman, C. McLeavey, and I. Sutskever,
``Robust speech recognition via large-scale weak supervision,'' in
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
X. Li, S. Dalmia, J. Li, M. Lee, P. Littell, J. Yao, A. Anastasopoulos, D. R.
Mortensen, G. Neubig, A. W. Black <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Universal phone
recognition with a multilingual allophone system,'' in <em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic">IEEE
International Conference on Acoustics, Speech and Signal Processing</em>, 2020,
pp. 8249–8253.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
C. Zhu, K. An, H. Zheng, and Z. Ou, ``Multilingual and crosslingual speech
recognition using phonological-vector based phone embeddings,'' in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE
Automatic Speech Recognition and Understanding Workshop</em>, 2021, pp.
2301–2312.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. Y. Tachbelie, S. T. Abate, and T. Schultz, ``Multilingual speech recognition
for GlobalPhone languages,'' <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Speech Communication</em>, 2022.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Q. Xu, A. Baevski, and M. Auli, ``Simple and effective zero-shot cross-lingual
phoneme recognition,'' in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2022, pp. 2113–2117.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S. Yusuyin, H. Huang, J. Liu, and C. Liu, ``Investigation into phone-based
subword units for multilingual end-to-end speech recognition,'' in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">IEEE
International Conference on Acoustics, Speech and Signal Processing</em>, 2023,
pp. 1–5.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
V. Fromkin, R. Rodman, and N. Hyams, ``An introduction to language: Eight
edition,'' <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Thomson Wadsworth</em>, 2007.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. Zeineldeen, A. Zeyer, W. Zhou, T. Ng, R. Schlüter, and H. Ney, ``A
systematic comparison of grapheme-based vs. phoneme-based label units for
encoder-decoder-attention models,'' <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.09336</em>,
2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
H. Xiang and Z. Ou, ``CRF-based single-stage acoustic modeling with CTC
topology,'' in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics, Speech and
Signal Processing</em>, 2019, pp. 5676–5680.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
K. An, H. Xiang, and Z. Ou, ``CAT: A CTC-CRF based ASR toolkit bridging
the hybrid and the end-to-end approaches towards data efficiency and low
latency,'' in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2020, pp. 566–570.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
H. Zheng, W. Peng, Z. Ou, and J. Zhang, ``Advancing CTC-CRF based end-to-end
speech recognition with wordpieces and conformers,'' <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2107.03007</em>, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
D. R. Mortensen, S. Dalmia, and P. Littell, ``Epitran: Precision G2P for many
languages,'' in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Eleventh International Conference on Language Resources
and Evaluation</em>, 2018.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
M. Hasegawa-Johnson, L. Rolston, C. Goudeseune, G.-A. Levow, and K. Kirchhoff,
``Grapheme-to-phoneme transduction for cross-language ASR,'' in
<em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">International Conference on Statistical Language and Speech
Processing</em>, 2020. [Online]. Available:
<a target="_blank" href="https://github.com/uiuc-sst/g2ps" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/uiuc-sst/g2ps</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
J. R. Novak, N. Minematsu, and K. Hirose, ``Phonetisaurus: Exploring
grapheme-to-phoneme conversion with joint n-gram models in the WFST
framework,'' <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Natural Language Engineering</em>, 2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
S. Moran and D. McCloy, Eds., <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">PHOIBLE 2.0</em>.   Jena: Max Planck Institute for the Science of Human History,
2019. [Online]. Available: <a target="_blank" href="https://phoible.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://phoible.org/</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
A. Baevski, Y. Zhou, A. Mohamed, and M. Auli, ``wav2vec 2.0: A framework for
self-supervised learning of speech representations,'' <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Advances in
neural information processing systems</em>, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
T. Schultz, N. T. Vu, and T. Schlippe, ``Globalphone: A multilingual text &amp;
speech database in 20 languages,'' in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on
Acoustics, Speech and Signal Processing</em>, 2013, pp. 8126–8130.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
T. Schultz and A. Waibel, ``Multilingual and crosslingual speech recognition,''
in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">DARPA Workshop on Broadcast News Transcription and Understanding</em>,
1998, pp. 259–262.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
P. Żelasko, L. Moro-Velázquez, M. Hasegawa-Johnson, O. Scharenborg, and
N. Dehak, ``That sounds familiar: an analysis of phonetic representations
transfer across languages,'' in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2020, pp. 3705–3709.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
X. Li, J. Li, F. Metze, and A. W. Black, ``Hierarchical phone recognition with
compositional phonetics.'' in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2021, pp. 2461–2465.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
K. Glocker, A. Herygers, and M. Georges, ``Allophant: Cross-lingual phoneme
recognition with articulatory attributes,'' in <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2023, pp.
2258–2262.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Z. Xiao, Z. Ou, W. Chu, and H. Lin, ``Hybrid CTC-attention based end-to-end
speech recognition using subword units,'' in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">11th International
Symposium on Chinese Spoken Language Processing</em>, 2018, pp. 146–150.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
H. Soltau, H. Liao, and H. Sak, ``Neural speech recognizer: Acoustic-to-word
LSTM model for large vocabulary speech recognition,'' in
<em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2017, pp. 3707–3711.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
B. Li, Y. Zhang, T. Sainath, Y. Wu, and W. Chan, ``Bytes are all you need:
End-to-end multilingual speech recognition and synthesis with bytes,'' in
<em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal
Processing</em>, 2019, pp. 5621–5625.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ``BERT: Pre-training of
deep bidirectional transformers for language understanding,'' in
<em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies</em>, 2019.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
I. Sutskever, R. Jozefowicz, K. Gregor, D. Rezende, T. Lillicrap, and
O. Vinyals, ``Towards principled unsupervised learning,'' <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1511.06440</em>, 2015.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">et al.</em>,
``Language models are unsupervised multitask learners,'' <em id="bib.bib39.2.2" class="ltx_emph ltx_font_italic">OpenAI blog</em>,
2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Y. Song, H. Zheng, and Z. Ou, ``An empirical comparison of joint-training and
pre-training for domain-agnostic semi-supervised learning via energy-based
models,'' in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">IEEE International Workshop on Machine Learning for Signal
Processing</em>, 2021, pp. 1–6.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
J. Bai, B. Li, Y. Zhang, A. Bapna, N. Siddhartha, K. C. Sim, and T. N. Sainath,
``Joint unsupervised and supervised training for multilingual ASR,'' in
<em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics, Speech and Signal
Processing</em>, 2022, pp. 6402–6406.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
A. Saif, X. Cui, H. Shen, S. Lu, B. Kingsbury, and T. Chen, ``Joint
unsupervised and supervised training for automatic speech recognition via
bilevel optimization,'' in <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics,
Speech and Signal Processing</em>, 2024, pp. 10 931–10 935.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Y. Song, Z. Ou, Z. Liu, and S. Yang, ``Upgrading CRFs to JRFs and its
benefits to sequence modeling and labeling,'' in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">IEEE International
Conference on Acoustics, Speech and Signal Processing</em>, 2020, pp. 8214–8218.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
H. Liu, Y. Cai, Z. Lin, Z. Ou, Y. Huang, and J. Feng, ``Variational
latent-state GPT for semi-supervised task-oriented dialog systems,''
<em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>,
vol. 31, pp. 970–984, 2023.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
A. Gulati, J. Qin, C.-C. Chiu, N. Parmar, Y. Zhang, J. Yu, W. Han, S. Wang,
Z. Zhang, Y. Wu, and R. Pang, ``Conformer: Convolution-augmented transformer
for speech recognition,'' in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2020, pp. 5036–5040.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
M. Mohri, F. Pereira, and M. Riley, ``Speech recognition with weighted
finite-state transducers,'' in <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Springer Handbook of Speech Processing</em>,
2008, pp. 559–584.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Y. Miao, M. Gowayyed, and F. Metze, ``EESEN: End-to-end speech recognition
using deep RNN models and WFST-based decoding,'' in <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">ASRU</em>, 2015,
pp. 167–174.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
R. Sennrich, B. Haddow, and A. Birch, ``Neural machine translation of rare
words with subword units,'' in <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for
Computational Linguistics</em>, 2016.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
A. Conneau and G. Lample, ``Cross-lingual language model pretraining,''
<em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 2019.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
A. Baevski, S. Schneider, and M. Auli, ``vq-wav2vec: Self-supervised learning
of discrete speech representations,'' in <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">International Conference on
Learning Representations</em>, 2019.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u.
Kaiser, and I. Polosukhin, ``Attention is all you need,'' in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Advances
in Neural Information Processing Systems</em>, I. Guyon, U. V. Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds.,
2017.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
H. Jegou, M. Douze, and C. Schmid, ``Product quantization for nearest neighbor
search,'' <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 2010.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
E. Jang, S. Gu, and B. Poole, ``Categorical reparametrization with
gumble-softmax,'' in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>, 2017.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
R. Ardila, M. Branson, K. Davis, M. Kohler, J. Meyer, M. Henretty, R. Morais,
L. Saunders, F. Tyers, and G. Weber, ``Common voice: A massively-multilingual
speech corpus,'' in <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Twelfth Language Resources and Evaluation
Conference</em>, 2020.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
J. Li and M. Hasegawa-Johnson, ``Autosegmental neural nets: Should phones and
tones be synchronous or asynchronous?'' in <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2020, pp.
1027–1031.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
D. S. Park, W. Chan, Y. Zhang, C.-C. Chiu, B. Zoph, E. D. Cubuk, and Q. V. Le,
``SpecAugment: A simple data augmentation method for automatic speech
recognition,'' in <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2019, pp. 2613–2617.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
L. van der Maaten and G. Hinton, ``Visualizing high-dimensional data using
t-SNE,'' <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, vol. 9, pp.
2579–2605, 2008.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
M. McCloskey and N. J. Cohen, ``Catastrophic interference in connectionist
networks: The sequential learning problem,'' in <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Psychology of learning
and motivation</em>.   Elsevier, 1989,
vol. 24, pp. 109–165.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
I. Sutskever, O. Vinyals, and Q. V. Le, ``Sequence to sequence learning with
neural networks,'' <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
vol. 27, 2014.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
G. M. Van de Ven, T. Tuytelaars, and A. S. Tolias, ``Three types of incremental
learning,'' <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, vol. 4, pp. 1185–1197, 2022.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
H. Liu, Y. Cai, Y. Zhou, Z. Ou, Y. Huang, and J. Feng, ``Prompt pool based
class-incremental continual learning for dialog state tracking,'' in
<em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">IEEE Automatic Speech Recognition and Understanding Workshop</em>, 2023,
pp. 1–8.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.02165" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.02166" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.02166">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.02166" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.02167" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 22:14:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
