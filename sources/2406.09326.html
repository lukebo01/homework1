<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.09326] PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance</title><meta property="og:description" content="Recently, artificial intelligence techniques for education have been received increasing attentions, while it still remains an open problem to design the effective music instrument instructing systems. Although key preâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.09326">

<!--Generated on Fri Jul  5 22:11:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
<img src="/html/2406.09326/assets/figs/favicon_crop.png" id="id1.g1" class="ltx_graphics ltx_img_landscape" width="28" height="21" alt="[Uncaptioned image]"> PianoMotion10M: Dataset and Benchmark 
<br class="ltx_break">for Hand Motion Generation in Piano Performance</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qijun Gan 
<br class="ltx_break">Zhejiang University
<br class="ltx_break"><span id="id2.1.id1" class="ltx_text ltx_font_typewriter">ganqijun@zju.edu.cn</span> 
<br class="ltx_break"><span id="id3.2.id2" class="ltx_ERROR undefined">\And</span>Song Wang 
<br class="ltx_break">Zhejiang University
<br class="ltx_break"><span id="id4.3.id3" class="ltx_text ltx_font_typewriter">songw@zju.edu.cn</span> 
<br class="ltx_break"><span id="id5.4.id4" class="ltx_ERROR undefined">\AND</span>Shengtao Wu 
<br class="ltx_break">Hangzhou Dianzi University
<br class="ltx_break"><span id="id6.5.id5" class="ltx_text ltx_font_typewriter">20010131@hdu.edu.cn</span> 
<br class="ltx_break"><span id="id7.6.id6" class="ltx_ERROR undefined">\And</span>Jianke Zhu
<br class="ltx_break">Zhejiang University
<br class="ltx_break"><span id="id8.7.id7" class="ltx_text ltx_font_typewriter">jkzhu@zju.edu.cn</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id9.id1" class="ltx_p">Recently, artificial intelligence techniques for education have been received increasing attentions, while it still remains an open problem to design the effective music instrument instructing systems. Although key presses can be directly derived from sheet music, the transitional movements among key presses require more extensive guidance in piano performance. In this work, we construct a piano-hand motion generation benchmark to guide hand movements and fingerings for piano playing. To this end, we collect an annotated dataset, PianoMotion10M, consisting of 116 hours of piano playing videos from a birdâ€™s-eye view with 10 million annotated hand poses. We also introduce a powerful baseline model that generates hand motions from piano audios through a position predictor and a position-guided gesture generator. Furthermore, a series of evaluation metrics are designed to assess the performance of the baseline model, including motion similarity, smoothness, positional accuracy of left and right hands, and overall fidelity of movement distribution. Despite that piano key presses with respect to music scores or audios are already accessible, PianoMotion10M aims to provide guidance on piano fingering for instruction purposes. The dataset and source code can be accessed at <a target="_blank" href="https://agnjason.github.io/PianoMotion-page" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://agnjason.github.io/PianoMotion-page</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">The process of learning has been significantly improved with artificial intelligence techniques, which enable individuals to enhance their skills under the guidance of an AI coachÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>.
This can be extended into learning to play the musical instruments. Particularly, piano performance requires a profound understanding of the underlying relationship between musical compositions and their corresponding physical motions.
As the rigorous practice and training program are necessary for athletes to master a diverse range of expressive human poses, it entails extensive practices to achieve proficiency in piano fingering and hand movement. To facilitate access to playing guidance, the development of AI piano coach has been spurred.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Large-scale piano-motion datasets are the foundation of a nuanced approach for motion generation, which offer valuable guidance for physical performance and musical expression.
The computational challenge of motion generation lies in capturing the nonlinear relationship between musical pieces and the intricate hand motions required for piano playing.
The hand poses vary for the same note across different melodies. Moreover, the dynamic nature of musical expression demands a level of continuous motion, which is challenging to be learnt from small datasets.
These limitations underscore the urgent need for a large-scale piano-motion dataset.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">To address the deficiency of the dataset for guiding hand movements and fingerings in playing piano, we introduce a large-scale 3D piano-motion dataset named PianoMotion10M.
As shown in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, PianoMotion10M contains piano audio tracks, Musical Instrument Digital Interface (MIDI) files, and annotated hand motions with their corresponding videos, meticulously collected from the Internet.
It comprises 1,966 pairs of video and music, with a total duration of 116 hours and 10 million annotated frames.
The parametric MANO hand modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> is employed to represent hand gestures.
Our constructed dataset offers a diverse range of music styles and piano techniques, which addresses the demands of various preferences and skill levels.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.09326/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="196" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S1.F1.2.1" class="ltx_text ltx_font_bold">Overview of our framework.</span> We collect videos of professional piano performances from the Internet and process them to construct a large-scale dataset, PianoMotion10M, which comprises piano music, MIDI files and hand motions. Building upon this dataset, we establish a benchmark for generating hand motions from piano music.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">Traditional applications like PianoPlayerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> are adept at generating static hand gestures and positions for piano scores, which typically make use of classifiers to predict the proper fingering combinations. However, they often fail to capture the diversity and continuity inherent of the piano performance in PianoMotion10M.
Both rule-based methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> and HMM-based approachesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> can estimate fingerings while they primarily focus on the local fingering constraints of continuous notes.
Consequently, they often overlook crucial information like long-range fingering relationships, while our task aims to estimate the motions of long clips.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">To address these limitations, a novel baseline model is presented to show the effectiveness of PianoMotion10M, which is able to generate realistic hand motions from piano melodies.
Given a piece of piano music, our model can locate the positions of both hands and generate a long sequence of hand gestures for the performance.
It effectively learns the music-position correlation through an efficient position predictor and produces continuous gestures with a position-guided gesture generator based on a diffusion probabilistic model.
To assess our baseline model, we propose several evaluation metrics, including <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">Frechet Gesture Distance</span> and <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">Wasserstein Gesture Distance</span> to measure the fidelity of each hand motions, <span id="S1.p5.1.3" class="ltx_text ltx_font_italic">Frechet Inception Distance</span> with a pre-trained auto-encoder to investigate the motion quality of double hands, and <span id="S1.p5.1.4" class="ltx_text ltx_font_italic">Position Distance</span> to assess the accuracy of hand positioning, and <span id="S1.p5.1.5" class="ltx_text ltx_font_italic">Smoothness</span> of the generated motions.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p">In summary, our main contributions are: 1) A large-scale piano-motion dataset PianoMotion10M comprises 116 hours of music and 10 million annotated frames with hand poses. To the best of our knowledge, it stands as the first dataset integrating piano music with its corresponding hand motions, which facilitates the tasks of 3D hand motion generation from piano audio tracks and piano music generation conditioned on hand motions.
2) Based on PianoMotion10M, we propose a benchmark with a series of evaluation metrics to investigate the effectiveness on hand motion generation, including the accuracy of positions and fidelity of gestures.
3) A novel baseline model bridges piano music with hand motions, which estimates hand location with a position predictor and generates hand gestures sequences through a position-guided gesture generator.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Motion-music Datasets.</span> While multi-modal datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> become the key of various learning tasks, there remains a significant gap in the availability of repository specially designed for music-conditional motion generation. Although the existing hand gesture datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> contain a large number of image-hand gesture pairs, they do not have audio or other related information. This limitation hinders them from the generative tasks, since they mainly focus on hand reconstruction and pose estimation.
Recently, datasets like AIST++Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and TikTokÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> are tailored for music-dance learning, which provide limited music segments, typically less than 5 hours in duration.
MoryossefÂ <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> manage to automatically detect which fingers pressed the key of the piano and provide a dataset of piano-fingering. However, it does not provide continuous hand gesture movements.
Therefore, there is a crucial need to build a piano-motion dataset specially tailored for motion generation tasks. To this end, we introduce the PianoMotion10M dataset, which comprises extensive piano music and their corresponding hand motion annotations.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">3D Human Motion Synthesis.</span> The problem of generating realistic and controllable 3D human motion sequences has been a subject of long-standing study.
By taking advantage of 2D keypoint detectionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, the synthesis of 2D skeletons has been extensively exploredÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
Considerable research efforts have been devoted to 2D speech-driven head generation for facial mouth and lip motion generationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, which usually employ either image-driven or voice-driven methods to produce realistic videos of speaking individuals.
However, the expressive capabilities of 2D pose skeletons are limited and they are not applicable to 3D character models.
Recent methods for full-body 3D dance generation have utilized LSTMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>, GANsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> or transformer encodersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>.
To generate vivid talking head videos, extensive research has been conducted in the field of speech-driven 3D facial animationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>.
EmoTalkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> animates emotional 3D faces from speech input by generating controllable personal and emotional styles.
TianÂ <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> introduce a speed controller and a face region controller to enhance stability during the head generation process.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">In the domain of hand motion generation, it has been primarily categorized into rule-based methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> and data-driven approachesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
For instance, Speech2GestureÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> utilizes conditional generative adversarial networks to generate personalized 2D keypoints from audio.
AhujaÂ <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> propose a method for personalized motion transfer.
AoÂ <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> learn the mapping between the speech and gestures from data using a combined network structure of the vector quantized variational auto-encoder (VQ-VAE). Beyond 2D keypoints generation, TriModalÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> extracts different upper body movements from TED talks and designs a LSTM-based neural network conditioned on audio, text, and identity to generate co-speech gestures.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p">Recently, diffusion models have achieved promising results in generating human motions. Previous works such as MDMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> and MotionDiffuseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite> have produced realistic motion inspired by denoising diffusion probabilistic models (DDPM)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. PhysDiffÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> extends MDM by imposing physical constraints. MLDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> utilizes latent carrier DDPM for forward denoising and reverse diffusion in motion latent space. MAAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> enhances the performance of non-distributed data by pre-training diffusion models. ZhangÂ <span id="S2.p4.1.1" class="ltx_text ltx_font_italic">et al.</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> introduce retrieval-enhanced DDPM, which improves the text-to-motion functionality in distribution.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>PianoMotion10M Dataset</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">It is a formidably challenging task to map piano music to hand motions due to the significant influence of note sequences and positions on hand movements and fingering.
Lacking diverse data may lead to the inferior performance on estimating various hand poses in piano playing.
To capture the variability, we present the first large-scale piano-motion dataset, PianoMotion10M, which comprises 1,966 piano performance videos along with 10 million hand poses and their corresponding MIDI files, resulting in an overall duration of 116 hours. Fig.Â <a href="#S3.F2" title="Figure 2 â€£ 3 PianoMotion10M Dataset â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents an example of our dataset.
These videos are segmented into 16,739 individual clips with a length of 30 seconds. To ensure comprehensive evaluation, we extract 7,519 clips for training, 821 for validation and 8,399 for testing.
The detailed comparisons with the existing datasets on hands and 3D human motions are summarized into Tab.Â <a href="#S3.T1" title="Table 1 â€£ 3 PianoMotion10M Dataset â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S3.T1.2.1" class="ltx_text ltx_font_bold">Comparison between different hand and motion datasets.</span> The proposed PianoMotion10M dataset consists of piano music with corresponding hand poses for hand motion generation. Existing hand-image datasets are listed in the first four rows, and music-motion datasets are presented in the subsequent four rows for reference.</figcaption>
<table id="S3.T1.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T1.3.1" class="ltx_tr">
<td id="S3.T1.3.1.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">Â </span>
<span id="S3.T1.3.1.1.1" class="ltx_text ltx_font_bold">Dataset</span>
</td>
<td id="S3.T1.3.1.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.1.2.1" class="ltx_text ltx_font_bold">Pose</span></td>
<td id="S3.T1.3.1.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.1.3.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="S3.T1.3.1.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.1.4.1" class="ltx_text ltx_font_bold">Subject</span></td>
<td id="S3.T1.3.1.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.1.5.1" class="ltx_text ltx_font_bold">Music</span></td>
<td id="S3.T1.3.1.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.1.6.1" class="ltx_text ltx_font_bold">MIDI</span></td>
<td id="S3.T1.3.1.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.1.7.1" class="ltx_text ltx_font_bold">Duration(hour)</span></td>
</tr>
<tr id="S3.T1.3.2" class="ltx_tr">
<td id="S3.T1.3.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">FreiHANDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>
</td>
<td id="S3.T1.3.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">134K</td>
<td id="S3.T1.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">32</td>
<td id="S3.T1.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">-</td>
</tr>
<tr id="S3.T1.3.3" class="ltx_tr">
<td id="S3.T1.3.3.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">InterHand2.6MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="S3.T1.3.3.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">2.6M</td>
<td id="S3.T1.3.3.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">27</td>
<td id="S3.T1.3.3.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.3.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.3.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">-</td>
</tr>
<tr id="S3.T1.3.4" class="ltx_tr">
<td id="S3.T1.3.4.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">RGB2HandsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>
</td>
<td id="S3.T1.3.4.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.4.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">1K</td>
<td id="S3.T1.3.4.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">2</td>
<td id="S3.T1.3.4.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.4.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.4.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">-</td>
</tr>
<tr id="S3.T1.3.5" class="ltx_tr">
<td id="S3.T1.3.5.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">Re:InterHandÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>
</td>
<td id="S3.T1.3.5.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.5.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">1.5M</td>
<td id="S3.T1.3.5.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">10</td>
<td id="S3.T1.3.5.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.5.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.5.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">-</td>
</tr>
<tr id="S3.T1.3.6" class="ltx_tr">
<td id="S3.T1.3.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">GrooveNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S3.T1.3.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">-</td>
<td id="S3.T1.3.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">1</td>
<td id="S3.T1.3.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.38</td>
</tr>
<tr id="S3.T1.3.7" class="ltx_tr">
<td id="S3.T1.3.7.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">DanceNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>
</td>
<td id="S3.T1.3.7.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.7.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">-</td>
<td id="S3.T1.3.7.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">2</td>
<td id="S3.T1.3.7.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.7.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.7.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.96</td>
</tr>
<tr id="S3.T1.3.8" class="ltx_tr">
<td id="S3.T1.3.8.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">EA-MUDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S3.T1.3.8.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.8.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">-</td>
<td id="S3.T1.3.8.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">-</td>
<td id="S3.T1.3.8.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.8.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.8.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.35</td>
</tr>
<tr id="S3.T1.3.9" class="ltx_tr">
<td id="S3.T1.3.9.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">AIST++Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</td>
<td id="S3.T1.3.9.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.9.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">10.1M</td>
<td id="S3.T1.3.9.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">30</td>
<td id="S3.T1.3.9.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ“</td>
<td id="S3.T1.3.9.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">âœ—</td>
<td id="S3.T1.3.9.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">5.19</td>
</tr>
<tr id="S3.T1.3.10" class="ltx_tr">
<td id="S3.T1.3.10.1" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.10.1.1" class="ltx_text" style="background-color:#E6E6FA;">PianoMotion10M</span></td>
<td id="S3.T1.3.10.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.10.2.1" class="ltx_text" style="background-color:#E6E6FA;">âœ“</span></td>
<td id="S3.T1.3.10.3" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.10.3.1" class="ltx_text" style="background-color:#E6E6FA;">10.5M</span></td>
<td id="S3.T1.3.10.4" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.10.4.1" class="ltx_text" style="background-color:#E6E6FA;">14</span></td>
<td id="S3.T1.3.10.5" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.10.5.1" class="ltx_text" style="background-color:#E6E6FA;">âœ“</span></td>
<td id="S3.T1.3.10.6" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.10.6.1" class="ltx_text" style="background-color:#E6E6FA;">âœ“</span></td>
<td id="S3.T1.3.10.7" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S3.T1.3.10.7.1" class="ltx_text" style="background-color:#E6E6FA;">116.16</span></td>
</tr>
<tr id="S3.T1.3.11" class="ltx_tr">
<td id="S3.T1.3.11.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">Â </span></td>
<td id="S3.T1.3.11.2" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T1.3.11.3" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T1.3.11.4" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T1.3.11.5" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T1.3.11.6" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T1.3.11.7" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
</table>
</figure>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2406.09326/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S3.F2.2.1" class="ltx_text ltx_font_bold">Illustration of sample from PianoMotion10M.</span> Each sample in our dataset includes audio, hand pose annotations, and a MIDI file along with the corresponding Bilibili video ID.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data Collection</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.3" class="ltx_p">There is a wealth of videos and live streams dedicated to musical instrument performances and tutorials from the Internet. Note that each individual has a unique playing style, we firstly select <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="14" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">14</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="integer" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">14</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">14</annotation></semantics></math> piano experts from Bilibili<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.bilibili.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.bilibili.com</a>, one of the most popular video-sharing platforms in China.</span></span></span> and collect a total of 3,647 candidate videos. To ensure consistency and enhance the quality of our dataset, we conduct pre-processing with five pivotal factors, including resolution, audio quality, camera perspective, presence of multiple individuals, and visibility of hands. We manually select pure piano music to ensure that the audio contained no human vocals or sounds from other instruments. Moreover, videos with a resolution lower than <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="1080\times 1920" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mn id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">1080</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">1920</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><times id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></times><cn type="integer" id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">1080</cn><cn type="integer" id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">1920</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">1080\times 1920</annotation></semantics></math> are discarded to ensure the quality of our dataset. To enhance the observation of hand movements and gestures, we choose videos with a birdâ€™s-eye view to minimize hand occlusion. Furthermore, we remove those videos where hand regions are frequently obstructed or invisible during performance. Additionally, we do not take consideration of videos with multiple piano players, which is beyond the scope of this dataset. By addressing these factors, the overall quality and coherence of the dataset have been substantially enhanced. Following this preprocessing stage, the result is a collection of <math id="S3.SS1.p1.3.m3.2" class="ltx_Math" alttext="1,966" display="inline"><semantics id="S3.SS1.p1.3.m3.2a"><mrow id="S3.SS1.p1.3.m3.2.3.2" xref="S3.SS1.p1.3.m3.2.3.1.cmml"><mn id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">1</mn><mo id="S3.SS1.p1.3.m3.2.3.2.1" xref="S3.SS1.p1.3.m3.2.3.1.cmml">,</mo><mn id="S3.SS1.p1.3.m3.2.2" xref="S3.SS1.p1.3.m3.2.2.cmml">966</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.2b"><list id="S3.SS1.p1.3.m3.2.3.1.cmml" xref="S3.SS1.p1.3.m3.2.3.2"><cn type="integer" id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">1</cn><cn type="integer" id="S3.SS1.p1.3.m3.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2">966</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.2c">1,966</annotation></semantics></math> high-quality raw videos. Each one showcases the piano playing by an individual, which is captured from a birdâ€™s-eye view along with pure piano audio.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data Annotations</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">MIDI</span> is a universal digital protocol to store musical data for various musical devices, which is served as a digital representation of musical notes, volume, tempo, and other performance parameters. Once video and pure piano audio pairs are collected, we transcribe the piano performances into MIDI files by utilizing a state-of-the-art automatic piano transcriptionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. To ensure the accuracy of the conversion results, we replay MIDI files and compare them with the original music tracks. Those files with high discrepancies are adjusted.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.5" class="ltx_p"><span id="S3.SS2.p2.5.1" class="ltx_text ltx_font_bold">Hand Pose</span> is captured via the parametric hand model MANOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, which serves as our hand prior model. It effectively maps the pose parameter <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\theta\in\mathbb{R}^{J\times 3}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">Î¸</mi><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.1.m1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.3.2" xref="S3.SS2.p2.1.m1.1.1.3.3.2.cmml">J</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.1.1.3.3.1" xref="S3.SS2.p2.1.m1.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS2.p2.1.m1.1.1.3.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><in id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></in><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">ğœƒ</ci><apply id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2">â„</ci><apply id="S3.SS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3"><times id="S3.SS2.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.1"></times><ci id="S3.SS2.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.2">ğ½</ci><cn type="integer" id="S3.SS2.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\theta\in\mathbb{R}^{J\times 3}</annotation></semantics></math> with <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="J" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">J</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">J</annotation></semantics></math> per-bone parts and the shape parameter <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\rho\in\mathbb{R}^{10}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">Ï</mi><mo id="S3.SS2.p2.3.m3.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml"><mi id="S3.SS2.p2.3.m3.1.1.3.2" xref="S3.SS2.p2.3.m3.1.1.3.2.cmml">â„</mi><mn id="S3.SS2.p2.3.m3.1.1.3.3" xref="S3.SS2.p2.3.m3.1.1.3.3.cmml">10</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><in id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1"></in><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">ğœŒ</ci><apply id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.3.1.cmml" xref="S3.SS2.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.3.2.cmml" xref="S3.SS2.p2.3.m3.1.1.3.2">â„</ci><cn type="integer" id="S3.SS2.p2.3.m3.1.1.3.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3.3">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\rho\in\mathbb{R}^{10}</annotation></semantics></math> onto a template mesh <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\bar{\mathcal{M}}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mover accent="true" id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">â„³</mi><mo id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><ci id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1">Â¯</ci><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">â„³</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\bar{\mathcal{M}}</annotation></semantics></math> with vertices <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">V</annotation></semantics></math>.
The MANO model enables the simulation of various hand gestures and movements during piano performances, which provides an effective way to study the relationship between hand gestures in playing piano. Due to the non-uniformity of hand sizes and positions in the collected videos, we first employ the MediaPipe hand detection frameworkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> to obtain bounding box of the hand region. Video frames are cropped according to the detected hand bounding boxes to enhance the robustness of the results. To this end, hand poses in collected videos are annotated using HaMeRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. HaMeR follows a fully transformer-based architecture and reconstructs hand models with increased accuracy and robustness. All images having hands detected by MediaPipe are annotated with hand poses by HaMeR, which result in a dataset of 10 million image-pose pairs.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.4" class="ltx_p">To enhance the smoothness and continuity of our dataset, the generated hand poses require to be cleaned and refined. The results of MediaPipe and HaMeR are usually accurate in most cases, while some inferior results may occur due to rapid motion and image blurring. The Hampel filterÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> with a window size of <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mn id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><cn type="integer" id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">20</annotation></semantics></math> is utilized to identify these outliers. The outliers and the timestamps where hands are undetected are firstly labeled as missing values. Within a small period, hand movements can be considered as the motion with constant speed. Therefore, the small gap can be interpolated bilaterally.
To address these missing data in the time series, missing segments with the frame length <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">Î´</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">ğ›¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\delta</annotation></semantics></math> less than <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mn id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><cn type="integer" id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">30</annotation></semantics></math> frames are filled by linear interpolation with respect to their surrounding values. The others are considered as periods when the hand is invisible. To ensure the reliability of detected hands, a similar strategy is employed to label observations with excessively short duration (<math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="\delta&lt;15" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mrow id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">Î´</mi><mo id="S3.SS2.p3.4.m4.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.cmml">&lt;</mo><mn id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><lt id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1"></lt><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">ğ›¿</ci><cn type="integer" id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">\delta&lt;15</annotation></semantics></math>) as invisible. Finally, to ensure the smoothness of hand motions, we make use of a Savitzky-Golay filterÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> for data smoothing. The annotated hand poses are manually checked to ensure their quality.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Data Statistics</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">The dataset is made of contributions from several subjects with different experts, and each provides varying amounts of data in terms of videos, clips, duration, and annotated frames.
Tab.Â <a href="#S3.T2" title="Table 2 â€£ 3.3 Data Statistics â€£ 3 PianoMotion10M Dataset â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the detailed statistics on the distribution of subjects within our PianoMotion10M dataset.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Statistics on the distribution of subjects in the PianoMotion10M dataset, where subject names denote the identity ID of experts.</figcaption>
<div id="S3.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:149.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-44.1pt,15.2pt) scale(0.830865146199849,0.830865146199849) ;">
<table id="S3.T2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">Â </span>
<span id="S3.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Subject Name</span>
</td>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.2.1" class="ltx_text ltx_font_bold">Videos</span></td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.3.1" class="ltx_text ltx_font_bold">Clips</span></td>
<td id="S3.T2.1.1.1.4" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.4.1" class="ltx_text ltx_font_bold">Time(sec)</span></td>
<td id="S3.T2.1.1.1.5" class="ltx_td ltx_align_right ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.5.1" class="ltx_text ltx_font_bold">Frames</span></td>
<td id="S3.T2.1.1.1.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.6.1" class="ltx_text ltx_font_bold">Subject Name</span></td>
<td id="S3.T2.1.1.1.7" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.7.1" class="ltx_text ltx_font_bold">Videos</span></td>
<td id="S3.T2.1.1.1.8" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.8.1" class="ltx_text ltx_font_bold">Clips</span></td>
<td id="S3.T2.1.1.1.9" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.9.1" class="ltx_text ltx_font_bold">Time(sec)</span></td>
<td id="S3.T2.1.1.1.10" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.1.10.1" class="ltx_text ltx_font_bold">Frames</span></td>
</tr>
<tr id="S3.T2.1.1.2" class="ltx_tr">
<td id="S3.T2.1.1.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.2.1.1" class="ltx_text ltx_font_typewriter">1467634</span></td>
<td id="S3.T2.1.1.2.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">337</td>
<td id="S3.T2.1.1.2.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">4,359</td>
<td id="S3.T2.1.1.2.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">103,293</td>
<td id="S3.T2.1.1.2.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">2,237,181</td>
<td id="S3.T2.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.2.6.1" class="ltx_text ltx_font_typewriter">470175873</span></td>
<td id="S3.T2.1.1.2.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">14</td>
<td id="S3.T2.1.1.2.8" class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">100</td>
<td id="S3.T2.1.1.2.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">2,450</td>
<td id="S3.T2.1.1.2.10" class="ltx_td ltx_align_right ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">64,946</td>
</tr>
<tr id="S3.T2.1.1.3" class="ltx_tr">
<td id="S3.T2.1.1.3.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.3.1.1" class="ltx_text ltx_font_typewriter">2084102325</span></td>
<td id="S3.T2.1.1.3.2" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">11</td>
<td id="S3.T2.1.1.3.3" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">103</td>
<td id="S3.T2.1.1.3.4" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">2,766</td>
<td id="S3.T2.1.1.3.5" class="ltx_td ltx_align_right ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">70,243</td>
<td id="S3.T2.1.1.3.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.3.6.1" class="ltx_text ltx_font_typewriter">478315001</span></td>
<td id="S3.T2.1.1.3.7" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">285</td>
<td id="S3.T2.1.1.3.8" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">2,674</td>
<td id="S3.T2.1.1.3.9" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">62,615</td>
<td id="S3.T2.1.1.3.10" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">1,792,707</td>
</tr>
<tr id="S3.T2.1.1.4" class="ltx_tr">
<td id="S3.T2.1.1.4.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.4.1.1" class="ltx_text ltx_font_typewriter">36760114</span></td>
<td id="S3.T2.1.1.4.2" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">22</td>
<td id="S3.T2.1.1.4.3" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">160</td>
<td id="S3.T2.1.1.4.4" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">4,772</td>
<td id="S3.T2.1.1.4.5" class="ltx_td ltx_align_right ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">106,037</td>
<td id="S3.T2.1.1.4.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.4.6.1" class="ltx_text ltx_font_typewriter">494725787</span></td>
<td id="S3.T2.1.1.4.7" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">1</td>
<td id="S3.T2.1.1.4.8" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">12</td>
<td id="S3.T2.1.1.4.9" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">586</td>
<td id="S3.T2.1.1.4.10" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">7,488</td>
</tr>
<tr id="S3.T2.1.1.5" class="ltx_tr">
<td id="S3.T2.1.1.5.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.5.1.1" class="ltx_text ltx_font_typewriter">37367458</span></td>
<td id="S3.T2.1.1.5.2" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">114</td>
<td id="S3.T2.1.1.5.3" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">859</td>
<td id="S3.T2.1.1.5.4" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">20,802</td>
<td id="S3.T2.1.1.5.5" class="ltx_td ltx_align_right ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">571,525</td>
<td id="S3.T2.1.1.5.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.5.6.1" class="ltx_text ltx_font_typewriter">66685747</span></td>
<td id="S3.T2.1.1.5.7" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">535</td>
<td id="S3.T2.1.1.5.8" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">5,136</td>
<td id="S3.T2.1.1.5.9" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">130,352</td>
<td id="S3.T2.1.1.5.10" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">3,520,370</td>
</tr>
<tr id="S3.T2.1.1.6" class="ltx_tr">
<td id="S3.T2.1.1.6.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.6.1.1" class="ltx_text ltx_font_typewriter">403444513</span></td>
<td id="S3.T2.1.1.6.2" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">12</td>
<td id="S3.T2.1.1.6.3" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">171</td>
<td id="S3.T2.1.1.6.4" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">4,245</td>
<td id="S3.T2.1.1.6.5" class="ltx_td ltx_align_right ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">99,973</td>
<td id="S3.T2.1.1.6.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.6.6.1" class="ltx_text ltx_font_typewriter">676539782</span></td>
<td id="S3.T2.1.1.6.7" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">19</td>
<td id="S3.T2.1.1.6.8" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">359</td>
<td id="S3.T2.1.1.6.9" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">11,314</td>
<td id="S3.T2.1.1.6.10" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">187,917</td>
</tr>
<tr id="S3.T2.1.1.7" class="ltx_tr">
<td id="S3.T2.1.1.7.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.7.1.1" class="ltx_text ltx_font_typewriter">434762078</span></td>
<td id="S3.T2.1.1.7.2" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">74</td>
<td id="S3.T2.1.1.7.3" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">128</td>
<td id="S3.T2.1.1.7.4" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">2,948</td>
<td id="S3.T2.1.1.7.5" class="ltx_td ltx_align_right ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">80,607</td>
<td id="S3.T2.1.1.7.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.7.6.1" class="ltx_text ltx_font_typewriter">688183660</span></td>
<td id="S3.T2.1.1.7.7" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">264</td>
<td id="S3.T2.1.1.7.8" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">872</td>
<td id="S3.T2.1.1.7.9" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">19,074</td>
<td id="S3.T2.1.1.7.10" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">564,699</td>
</tr>
<tr id="S3.T2.1.1.8" class="ltx_tr">
<td id="S3.T2.1.1.8.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.8.1.1" class="ltx_text ltx_font_typewriter">442401135</span></td>
<td id="S3.T2.1.1.8.2" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">275</td>
<td id="S3.T2.1.1.8.3" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">1,788</td>
<td id="S3.T2.1.1.8.4" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">52,030</td>
<td id="S3.T2.1.1.8.5" class="ltx_td ltx_align_right ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">1,209,905</td>
<td id="S3.T2.1.1.8.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S3.T2.1.1.8.6.1" class="ltx_text ltx_font_typewriter">864712</span></td>
<td id="S3.T2.1.1.8.7" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">3</td>
<td id="S3.T2.1.1.8.8" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">18</td>
<td id="S3.T2.1.1.8.9" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">923</td>
<td id="S3.T2.1.1.8.10" class="ltx_td ltx_align_right" style="padding-top:1pt;padding-bottom:1pt;">13,569</td>
</tr>
<tr id="S3.T2.1.1.9" class="ltx_tr">
<td id="S3.T2.1.1.9.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" colspan="10"><span id="S3.T2.1.1.9.1.1" class="ltx_text ltx_font_bold">Total Videos: 1,966, Clips: 16,739, Total Duration(hour): 116.16, Annotated Frames: 10,527,167</span></td>
</tr>
<tr id="S3.T2.1.1.10" class="ltx_tr">
<td id="S3.T2.1.1.10.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">Â </span></td>
<td id="S3.T2.1.1.10.2" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T2.1.1.10.3" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T2.1.1.10.4" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T2.1.1.10.5" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T2.1.1.10.6" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T2.1.1.10.7" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T2.1.1.10.8" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T2.1.1.10.9" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S3.T2.1.1.10.10" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
</table>
</span></div>
</figure>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p">The whole piano-motion dataset, PianoMotion10M, consists of 1,966 videos with approximately 116 total hours of footage.
Each piece of music is segmented into 30-second clips at 24-second intervals, resulting in a total of 16,739 clips. Note that we discard those clips where hand visibility is below 80%. Our dataset has 14 subjects with different playing styles.
This variability ensures a rich diversity of playing techniques and music styles, which is essential for training robust models to predict piano hand gestures from musical pieces. All videos in our dataset are publicly accessible with provided video IDs on the Bilibili website.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Baselines</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">To tackle the challenging task of generating hand motions synchronized with piano audio tracks, we introduce a novel motion generation framework upon the PianoMotion10M dataset. As illustrated in Fig.Â <a href="#S4.F3" title="Figure 3 â€£ 4 Baselines â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, our framework consists of a position predictor and a gesture generator. The position predictor extracts the hand positions from piano music and integrates them as contextual input for the gesture generator. By leveraging a DDPM modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, the gesture generator estimates hand pose sequence based on the piano audio and the predicted positions. Further details on each component are elaborated in the following subsections.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2406.09326/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="185" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S4.F3.2.1" class="ltx_text ltx_font_bold">Illustration of our baseline model.</span> Given a piece of piano music, our baseline model estimates the hand motions by predicting hand positions and generating hand gestures.</figcaption>
</figure>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.6" class="ltx_p"><span id="S4.p2.6.1" class="ltx_text ltx_font_bold">Problem Formulation.</span>
Given a piano audio piece <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">A</annotation></semantics></math> with <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">N</annotation></semantics></math> frames, our objective is to obtain the hand position sequence <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="P\in\mathbb{R}^{N\times 3\times 2}" display="inline"><semantics id="S4.p2.3.m3.1a"><mrow id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">P</mi><mo id="S4.p2.3.m3.1.1.1" xref="S4.p2.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml"><mi id="S4.p2.3.m3.1.1.3.2" xref="S4.p2.3.m3.1.1.3.2.cmml">â„</mi><mrow id="S4.p2.3.m3.1.1.3.3" xref="S4.p2.3.m3.1.1.3.3.cmml"><mi id="S4.p2.3.m3.1.1.3.3.2" xref="S4.p2.3.m3.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S4.p2.3.m3.1.1.3.3.1" xref="S4.p2.3.m3.1.1.3.3.1.cmml">Ã—</mo><mn id="S4.p2.3.m3.1.1.3.3.3" xref="S4.p2.3.m3.1.1.3.3.3.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p2.3.m3.1.1.3.3.1a" xref="S4.p2.3.m3.1.1.3.3.1.cmml">Ã—</mo><mn id="S4.p2.3.m3.1.1.3.3.4" xref="S4.p2.3.m3.1.1.3.3.4.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><in id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1"></in><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">ğ‘ƒ</ci><apply id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.3.1.cmml" xref="S4.p2.3.m3.1.1.3">superscript</csymbol><ci id="S4.p2.3.m3.1.1.3.2.cmml" xref="S4.p2.3.m3.1.1.3.2">â„</ci><apply id="S4.p2.3.m3.1.1.3.3.cmml" xref="S4.p2.3.m3.1.1.3.3"><times id="S4.p2.3.m3.1.1.3.3.1.cmml" xref="S4.p2.3.m3.1.1.3.3.1"></times><ci id="S4.p2.3.m3.1.1.3.3.2.cmml" xref="S4.p2.3.m3.1.1.3.3.2">ğ‘</ci><cn type="integer" id="S4.p2.3.m3.1.1.3.3.3.cmml" xref="S4.p2.3.m3.1.1.3.3.3">3</cn><cn type="integer" id="S4.p2.3.m3.1.1.3.3.4.cmml" xref="S4.p2.3.m3.1.1.3.3.4">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">P\in\mathbb{R}^{N\times 3\times 2}</annotation></semantics></math> and hand gestures <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="\Theta\in\mathbb{R}^{N\times J\times 3\times 2}" display="inline"><semantics id="S4.p2.4.m4.1a"><mrow id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><mi mathvariant="normal" id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml">Î˜</mi><mo id="S4.p2.4.m4.1.1.1" xref="S4.p2.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S4.p2.4.m4.1.1.3" xref="S4.p2.4.m4.1.1.3.cmml"><mi id="S4.p2.4.m4.1.1.3.2" xref="S4.p2.4.m4.1.1.3.2.cmml">â„</mi><mrow id="S4.p2.4.m4.1.1.3.3" xref="S4.p2.4.m4.1.1.3.3.cmml"><mi id="S4.p2.4.m4.1.1.3.3.2" xref="S4.p2.4.m4.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S4.p2.4.m4.1.1.3.3.1" xref="S4.p2.4.m4.1.1.3.3.1.cmml">Ã—</mo><mi id="S4.p2.4.m4.1.1.3.3.3" xref="S4.p2.4.m4.1.1.3.3.3.cmml">J</mi><mo lspace="0.222em" rspace="0.222em" id="S4.p2.4.m4.1.1.3.3.1a" xref="S4.p2.4.m4.1.1.3.3.1.cmml">Ã—</mo><mn id="S4.p2.4.m4.1.1.3.3.4" xref="S4.p2.4.m4.1.1.3.3.4.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p2.4.m4.1.1.3.3.1b" xref="S4.p2.4.m4.1.1.3.3.1.cmml">Ã—</mo><mn id="S4.p2.4.m4.1.1.3.3.5" xref="S4.p2.4.m4.1.1.3.3.5.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><in id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1"></in><ci id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2">Î˜</ci><apply id="S4.p2.4.m4.1.1.3.cmml" xref="S4.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.p2.4.m4.1.1.3.1.cmml" xref="S4.p2.4.m4.1.1.3">superscript</csymbol><ci id="S4.p2.4.m4.1.1.3.2.cmml" xref="S4.p2.4.m4.1.1.3.2">â„</ci><apply id="S4.p2.4.m4.1.1.3.3.cmml" xref="S4.p2.4.m4.1.1.3.3"><times id="S4.p2.4.m4.1.1.3.3.1.cmml" xref="S4.p2.4.m4.1.1.3.3.1"></times><ci id="S4.p2.4.m4.1.1.3.3.2.cmml" xref="S4.p2.4.m4.1.1.3.3.2">ğ‘</ci><ci id="S4.p2.4.m4.1.1.3.3.3.cmml" xref="S4.p2.4.m4.1.1.3.3.3">ğ½</ci><cn type="integer" id="S4.p2.4.m4.1.1.3.3.4.cmml" xref="S4.p2.4.m4.1.1.3.3.4">3</cn><cn type="integer" id="S4.p2.4.m4.1.1.3.3.5.cmml" xref="S4.p2.4.m4.1.1.3.3.5">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">\Theta\in\mathbb{R}^{N\times J\times 3\times 2}</annotation></semantics></math>. The hand position sequence <math id="S4.p2.5.m5.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.p2.5.m5.1a"><mi id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><ci id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">P</annotation></semantics></math> encompasses the 3D coordinates of the left and right hands. The hand gestures <math id="S4.p2.6.m6.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S4.p2.6.m6.1a"><mi mathvariant="normal" id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml">Î˜</mi><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.1b"><ci id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1">Î˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.1c">\Theta</annotation></semantics></math> consist of Euler angle at each joint of both hands.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.6" class="ltx_p">Due to the highly nonlinear relationship between acoustic signals and hand gestures, it poses a significant challenge to estimate motions through discriminative modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, which usually leads to an average pose, as demonstrated in SectionÂ <a href="#S5.SS2" title="5.2 Experiments â€£ 5 Benchmark â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>. To address this issue, a hand position predictor is introduced to estimate the continuous changes in hand positions. Moreover, a generative model is utilized to reconstruct hand gestures from a piano music piece. Hereby, the task of hand motion generation becomes more concise and comprehensive by disentangling it into hand position estimation and gesture generation. To extract the audio features <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="S4.p3.1.m1.1a"><msub id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mi id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml">f</mi><mi id="S4.p3.1.m1.1.1.3" xref="S4.p3.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1">subscript</csymbol><ci id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2">ğ‘“</ci><ci id="S4.p3.1.m1.1.1.3.cmml" xref="S4.p3.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">f_{a}</annotation></semantics></math> from the audio <math id="S4.p3.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">A</annotation></semantics></math>, we make use of a pre-trained audio feature extractor <math id="S4.p3.3.m3.1" class="ltx_Math" alttext="\Phi_{a}" display="inline"><semantics id="S4.p3.3.m3.1a"><msub id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml"><mi mathvariant="normal" id="S4.p3.3.m3.1.1.2" xref="S4.p3.3.m3.1.1.2.cmml">Î¦</mi><mi id="S4.p3.3.m3.1.1.3" xref="S4.p3.3.m3.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><apply id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p3.3.m3.1.1.1.cmml" xref="S4.p3.3.m3.1.1">subscript</csymbol><ci id="S4.p3.3.m3.1.1.2.cmml" xref="S4.p3.3.m3.1.1.2">Î¦</ci><ci id="S4.p3.3.m3.1.1.3.cmml" xref="S4.p3.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">\Phi_{a}</annotation></semantics></math>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, which is formulated as <math id="S4.p3.4.m4.3" class="ltx_Math" alttext="f_{a}=\Phi_{a}(A),f_{a}\in\mathbb{R}^{N\times C}" display="inline"><semantics id="S4.p3.4.m4.3a"><mrow id="S4.p3.4.m4.3.3.2" xref="S4.p3.4.m4.3.3.3.cmml"><mrow id="S4.p3.4.m4.2.2.1.1" xref="S4.p3.4.m4.2.2.1.1.cmml"><msub id="S4.p3.4.m4.2.2.1.1.2" xref="S4.p3.4.m4.2.2.1.1.2.cmml"><mi id="S4.p3.4.m4.2.2.1.1.2.2" xref="S4.p3.4.m4.2.2.1.1.2.2.cmml">f</mi><mi id="S4.p3.4.m4.2.2.1.1.2.3" xref="S4.p3.4.m4.2.2.1.1.2.3.cmml">a</mi></msub><mo id="S4.p3.4.m4.2.2.1.1.1" xref="S4.p3.4.m4.2.2.1.1.1.cmml">=</mo><mrow id="S4.p3.4.m4.2.2.1.1.3" xref="S4.p3.4.m4.2.2.1.1.3.cmml"><msub id="S4.p3.4.m4.2.2.1.1.3.2" xref="S4.p3.4.m4.2.2.1.1.3.2.cmml"><mi mathvariant="normal" id="S4.p3.4.m4.2.2.1.1.3.2.2" xref="S4.p3.4.m4.2.2.1.1.3.2.2.cmml">Î¦</mi><mi id="S4.p3.4.m4.2.2.1.1.3.2.3" xref="S4.p3.4.m4.2.2.1.1.3.2.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S4.p3.4.m4.2.2.1.1.3.1" xref="S4.p3.4.m4.2.2.1.1.3.1.cmml">â€‹</mo><mrow id="S4.p3.4.m4.2.2.1.1.3.3.2" xref="S4.p3.4.m4.2.2.1.1.3.cmml"><mo stretchy="false" id="S4.p3.4.m4.2.2.1.1.3.3.2.1" xref="S4.p3.4.m4.2.2.1.1.3.cmml">(</mo><mi id="S4.p3.4.m4.1.1" xref="S4.p3.4.m4.1.1.cmml">A</mi><mo stretchy="false" id="S4.p3.4.m4.2.2.1.1.3.3.2.2" xref="S4.p3.4.m4.2.2.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo id="S4.p3.4.m4.3.3.2.3" xref="S4.p3.4.m4.3.3.3a.cmml">,</mo><mrow id="S4.p3.4.m4.3.3.2.2" xref="S4.p3.4.m4.3.3.2.2.cmml"><msub id="S4.p3.4.m4.3.3.2.2.2" xref="S4.p3.4.m4.3.3.2.2.2.cmml"><mi id="S4.p3.4.m4.3.3.2.2.2.2" xref="S4.p3.4.m4.3.3.2.2.2.2.cmml">f</mi><mi id="S4.p3.4.m4.3.3.2.2.2.3" xref="S4.p3.4.m4.3.3.2.2.2.3.cmml">a</mi></msub><mo id="S4.p3.4.m4.3.3.2.2.1" xref="S4.p3.4.m4.3.3.2.2.1.cmml">âˆˆ</mo><msup id="S4.p3.4.m4.3.3.2.2.3" xref="S4.p3.4.m4.3.3.2.2.3.cmml"><mi id="S4.p3.4.m4.3.3.2.2.3.2" xref="S4.p3.4.m4.3.3.2.2.3.2.cmml">â„</mi><mrow id="S4.p3.4.m4.3.3.2.2.3.3" xref="S4.p3.4.m4.3.3.2.2.3.3.cmml"><mi id="S4.p3.4.m4.3.3.2.2.3.3.2" xref="S4.p3.4.m4.3.3.2.2.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S4.p3.4.m4.3.3.2.2.3.3.1" xref="S4.p3.4.m4.3.3.2.2.3.3.1.cmml">Ã—</mo><mi id="S4.p3.4.m4.3.3.2.2.3.3.3" xref="S4.p3.4.m4.3.3.2.2.3.3.3.cmml">C</mi></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.3b"><apply id="S4.p3.4.m4.3.3.3.cmml" xref="S4.p3.4.m4.3.3.2"><csymbol cd="ambiguous" id="S4.p3.4.m4.3.3.3a.cmml" xref="S4.p3.4.m4.3.3.2.3">formulae-sequence</csymbol><apply id="S4.p3.4.m4.2.2.1.1.cmml" xref="S4.p3.4.m4.2.2.1.1"><eq id="S4.p3.4.m4.2.2.1.1.1.cmml" xref="S4.p3.4.m4.2.2.1.1.1"></eq><apply id="S4.p3.4.m4.2.2.1.1.2.cmml" xref="S4.p3.4.m4.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.p3.4.m4.2.2.1.1.2.1.cmml" xref="S4.p3.4.m4.2.2.1.1.2">subscript</csymbol><ci id="S4.p3.4.m4.2.2.1.1.2.2.cmml" xref="S4.p3.4.m4.2.2.1.1.2.2">ğ‘“</ci><ci id="S4.p3.4.m4.2.2.1.1.2.3.cmml" xref="S4.p3.4.m4.2.2.1.1.2.3">ğ‘</ci></apply><apply id="S4.p3.4.m4.2.2.1.1.3.cmml" xref="S4.p3.4.m4.2.2.1.1.3"><times id="S4.p3.4.m4.2.2.1.1.3.1.cmml" xref="S4.p3.4.m4.2.2.1.1.3.1"></times><apply id="S4.p3.4.m4.2.2.1.1.3.2.cmml" xref="S4.p3.4.m4.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.p3.4.m4.2.2.1.1.3.2.1.cmml" xref="S4.p3.4.m4.2.2.1.1.3.2">subscript</csymbol><ci id="S4.p3.4.m4.2.2.1.1.3.2.2.cmml" xref="S4.p3.4.m4.2.2.1.1.3.2.2">Î¦</ci><ci id="S4.p3.4.m4.2.2.1.1.3.2.3.cmml" xref="S4.p3.4.m4.2.2.1.1.3.2.3">ğ‘</ci></apply><ci id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1">ğ´</ci></apply></apply><apply id="S4.p3.4.m4.3.3.2.2.cmml" xref="S4.p3.4.m4.3.3.2.2"><in id="S4.p3.4.m4.3.3.2.2.1.cmml" xref="S4.p3.4.m4.3.3.2.2.1"></in><apply id="S4.p3.4.m4.3.3.2.2.2.cmml" xref="S4.p3.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.p3.4.m4.3.3.2.2.2.1.cmml" xref="S4.p3.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S4.p3.4.m4.3.3.2.2.2.2.cmml" xref="S4.p3.4.m4.3.3.2.2.2.2">ğ‘“</ci><ci id="S4.p3.4.m4.3.3.2.2.2.3.cmml" xref="S4.p3.4.m4.3.3.2.2.2.3">ğ‘</ci></apply><apply id="S4.p3.4.m4.3.3.2.2.3.cmml" xref="S4.p3.4.m4.3.3.2.2.3"><csymbol cd="ambiguous" id="S4.p3.4.m4.3.3.2.2.3.1.cmml" xref="S4.p3.4.m4.3.3.2.2.3">superscript</csymbol><ci id="S4.p3.4.m4.3.3.2.2.3.2.cmml" xref="S4.p3.4.m4.3.3.2.2.3.2">â„</ci><apply id="S4.p3.4.m4.3.3.2.2.3.3.cmml" xref="S4.p3.4.m4.3.3.2.2.3.3"><times id="S4.p3.4.m4.3.3.2.2.3.3.1.cmml" xref="S4.p3.4.m4.3.3.2.2.3.3.1"></times><ci id="S4.p3.4.m4.3.3.2.2.3.3.2.cmml" xref="S4.p3.4.m4.3.3.2.2.3.3.2">ğ‘</ci><ci id="S4.p3.4.m4.3.3.2.2.3.3.3.cmml" xref="S4.p3.4.m4.3.3.2.2.3.3.3">ğ¶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.3c">f_{a}=\Phi_{a}(A),f_{a}\in\mathbb{R}^{N\times C}</annotation></semantics></math>. <math id="S4.p3.5.m5.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.p3.5.m5.1a"><mi id="S4.p3.5.m5.1.1" xref="S4.p3.5.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.p3.5.m5.1b"><ci id="S4.p3.5.m5.1.1.cmml" xref="S4.p3.5.m5.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.5.m5.1c">C</annotation></semantics></math> is the feature dimension of <math id="S4.p3.6.m6.1" class="ltx_Math" alttext="\Phi_{a}" display="inline"><semantics id="S4.p3.6.m6.1a"><msub id="S4.p3.6.m6.1.1" xref="S4.p3.6.m6.1.1.cmml"><mi mathvariant="normal" id="S4.p3.6.m6.1.1.2" xref="S4.p3.6.m6.1.1.2.cmml">Î¦</mi><mi id="S4.p3.6.m6.1.1.3" xref="S4.p3.6.m6.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.6.m6.1b"><apply id="S4.p3.6.m6.1.1.cmml" xref="S4.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.p3.6.m6.1.1.1.cmml" xref="S4.p3.6.m6.1.1">subscript</csymbol><ci id="S4.p3.6.m6.1.1.2.cmml" xref="S4.p3.6.m6.1.1.2">Î¦</ci><ci id="S4.p3.6.m6.1.1.3.cmml" xref="S4.p3.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.6.m6.1c">\Phi_{a}</annotation></semantics></math>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Position Predictor</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.7" class="ltx_p">The position predictor is employed to predict the 6-dimensional 3D positions for both the left and right hands. Since the audio features <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><msub id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">f</mi><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">ğ‘“</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">f_{a}</annotation></semantics></math> cannot directly be mapped to the positions, a feature embedding module is treated as our position decoder <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="\Phi_{p}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><msub id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">Î¦</mi><mi id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">Î¦</ci><ci id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\Phi_{p}</annotation></semantics></math> to extract the latent features. It projects the sequential audio features <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><msub id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">ğ‘“</ci><ci id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">f_{a}</annotation></semantics></math> onto the latent features <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="f_{p}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">f</mi><mi id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">ğ‘“</ci><ci id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">f_{p}</annotation></semantics></math> with more comprehensive temporal information, which is formulated as <math id="S4.SS1.p1.5.m5.2" class="ltx_Math" alttext="f_{p}=\Phi_{p}(f_{a}),f_{p}\in\mathbb{R}^{N\times 512}" display="inline"><semantics id="S4.SS1.p1.5.m5.2a"><mrow id="S4.SS1.p1.5.m5.2.2.2" xref="S4.SS1.p1.5.m5.2.2.3.cmml"><mrow id="S4.SS1.p1.5.m5.1.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.1.cmml"><msub id="S4.SS1.p1.5.m5.1.1.1.1.3" xref="S4.SS1.p1.5.m5.1.1.1.1.3.cmml"><mi id="S4.SS1.p1.5.m5.1.1.1.1.3.2" xref="S4.SS1.p1.5.m5.1.1.1.1.3.2.cmml">f</mi><mi id="S4.SS1.p1.5.m5.1.1.1.1.3.3" xref="S4.SS1.p1.5.m5.1.1.1.1.3.3.cmml">p</mi></msub><mo id="S4.SS1.p1.5.m5.1.1.1.1.2" xref="S4.SS1.p1.5.m5.1.1.1.1.2.cmml">=</mo><mrow id="S4.SS1.p1.5.m5.1.1.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.1.1.cmml"><msub id="S4.SS1.p1.5.m5.1.1.1.1.1.3" xref="S4.SS1.p1.5.m5.1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S4.SS1.p1.5.m5.1.1.1.1.1.3.2" xref="S4.SS1.p1.5.m5.1.1.1.1.1.3.2.cmml">Î¦</mi><mi id="S4.SS1.p1.5.m5.1.1.1.1.1.3.3" xref="S4.SS1.p1.5.m5.1.1.1.1.1.3.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS1.p1.5.m5.1.1.1.1.1.2" xref="S4.SS1.p1.5.m5.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.2" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.2" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.2.cmml">f</mi><mi id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.3" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.3.cmml">a</mi></msub><mo stretchy="false" id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.3" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.SS1.p1.5.m5.2.2.2.3" xref="S4.SS1.p1.5.m5.2.2.3a.cmml">,</mo><mrow id="S4.SS1.p1.5.m5.2.2.2.2" xref="S4.SS1.p1.5.m5.2.2.2.2.cmml"><msub id="S4.SS1.p1.5.m5.2.2.2.2.2" xref="S4.SS1.p1.5.m5.2.2.2.2.2.cmml"><mi id="S4.SS1.p1.5.m5.2.2.2.2.2.2" xref="S4.SS1.p1.5.m5.2.2.2.2.2.2.cmml">f</mi><mi id="S4.SS1.p1.5.m5.2.2.2.2.2.3" xref="S4.SS1.p1.5.m5.2.2.2.2.2.3.cmml">p</mi></msub><mo id="S4.SS1.p1.5.m5.2.2.2.2.1" xref="S4.SS1.p1.5.m5.2.2.2.2.1.cmml">âˆˆ</mo><msup id="S4.SS1.p1.5.m5.2.2.2.2.3" xref="S4.SS1.p1.5.m5.2.2.2.2.3.cmml"><mi id="S4.SS1.p1.5.m5.2.2.2.2.3.2" xref="S4.SS1.p1.5.m5.2.2.2.2.3.2.cmml">â„</mi><mrow id="S4.SS1.p1.5.m5.2.2.2.2.3.3" xref="S4.SS1.p1.5.m5.2.2.2.2.3.3.cmml"><mi id="S4.SS1.p1.5.m5.2.2.2.2.3.3.2" xref="S4.SS1.p1.5.m5.2.2.2.2.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.5.m5.2.2.2.2.3.3.1" xref="S4.SS1.p1.5.m5.2.2.2.2.3.3.1.cmml">Ã—</mo><mn id="S4.SS1.p1.5.m5.2.2.2.2.3.3.3" xref="S4.SS1.p1.5.m5.2.2.2.2.3.3.3.cmml">512</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.2b"><apply id="S4.SS1.p1.5.m5.2.2.3.cmml" xref="S4.SS1.p1.5.m5.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.2.2.3a.cmml" xref="S4.SS1.p1.5.m5.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.p1.5.m5.1.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1"><eq id="S4.SS1.p1.5.m5.1.1.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.2"></eq><apply id="S4.SS1.p1.5.m5.1.1.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.1.1.3.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.3">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.1.1.3.2.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.3.2">ğ‘“</ci><ci id="S4.SS1.p1.5.m5.1.1.1.1.3.3.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S4.SS1.p1.5.m5.1.1.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1"><times id="S4.SS1.p1.5.m5.1.1.1.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.2"></times><apply id="S4.SS1.p1.5.m5.1.1.1.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.1.1.1.3.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.1.1.1.3.2.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.3.2">Î¦</ci><ci id="S4.SS1.p1.5.m5.1.1.1.1.1.3.3.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.2">ğ‘“</ci><ci id="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply><apply id="S4.SS1.p1.5.m5.2.2.2.2.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2"><in id="S4.SS1.p1.5.m5.2.2.2.2.1.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.1"></in><apply id="S4.SS1.p1.5.m5.2.2.2.2.2.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.2.2.2.2.2.1.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p1.5.m5.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.2.2">ğ‘“</ci><ci id="S4.SS1.p1.5.m5.2.2.2.2.2.3.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.2.3">ğ‘</ci></apply><apply id="S4.SS1.p1.5.m5.2.2.2.2.3.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.3"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.2.2.2.2.3.1.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.3">superscript</csymbol><ci id="S4.SS1.p1.5.m5.2.2.2.2.3.2.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.3.2">â„</ci><apply id="S4.SS1.p1.5.m5.2.2.2.2.3.3.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.3.3"><times id="S4.SS1.p1.5.m5.2.2.2.2.3.3.1.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.3.3.1"></times><ci id="S4.SS1.p1.5.m5.2.2.2.2.3.3.2.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.3.3.2">ğ‘</ci><cn type="integer" id="S4.SS1.p1.5.m5.2.2.2.2.3.3.3.cmml" xref="S4.SS1.p1.5.m5.2.2.2.2.3.3.3">512</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.2c">f_{p}=\Phi_{p}(f_{a}),f_{p}\in\mathbb{R}^{N\times 512}</annotation></semantics></math>. Subsequently, a linear mapping is employed to project the feature <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="f_{p}" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><msub id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml"><mi id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml">f</mi><mi id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2">ğ‘“</ci><ci id="S4.SS1.p1.6.m6.1.1.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">f_{p}</annotation></semantics></math> onto the output positions <math id="S4.SS1.p1.7.m7.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.SS1.p1.7.m7.1a"><mi id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><ci id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">P</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p">In our experiments, we can make use of either TransformerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> or State-Space Model (SSM)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> as our feature embedding module.
Transformer leverages self-attention mechanisms to effectively capture long-range dependencies and contextual information in order to learn temporal relationships.
Recently, a different representation inspired by classical SSMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> is proposed to replace the attention mechanism, which is built upon a more contemporary Selective Structured State Space Model (S6)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> suitable for deep learning. By sharing a similar architecture to the classical RNN, it can efficiently capture information from previous inputs.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Position-guided Gesture Generator</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.4" class="ltx_p">Leveraging recent achievementsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> in motion generation, our approach incorporates a diffusion probabilistic modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
By mastering denoising, this model effectively captures the complex distribution of hand motions observed in large-scale piano-motion datasets, which has the capability to generate motions with different conditions.
Starting with a clean sample <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\Theta_{0}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msub id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">Î˜</mi><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">Î˜</ci><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\Theta_{0}</annotation></semantics></math> of motion sequence, the forward diffusion process establishes a Markov chain that gradually adds noise to <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\Theta_{0}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msub id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">Î˜</mi><mn id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">Î˜</ci><cn type="integer" id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\Theta_{0}</annotation></semantics></math> in <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mi id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><ci id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">T</annotation></semantics></math> steps, which generates a series of noisy samples <math id="S4.SS2.p1.4.m4.3" class="ltx_Math" alttext="\Theta_{1},...,\Theta_{T}" display="inline"><semantics id="S4.SS2.p1.4.m4.3a"><mrow id="S4.SS2.p1.4.m4.3.3.2" xref="S4.SS2.p1.4.m4.3.3.3.cmml"><msub id="S4.SS2.p1.4.m4.2.2.1.1" xref="S4.SS2.p1.4.m4.2.2.1.1.cmml"><mi mathvariant="normal" id="S4.SS2.p1.4.m4.2.2.1.1.2" xref="S4.SS2.p1.4.m4.2.2.1.1.2.cmml">Î˜</mi><mn id="S4.SS2.p1.4.m4.2.2.1.1.3" xref="S4.SS2.p1.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.SS2.p1.4.m4.3.3.2.3" xref="S4.SS2.p1.4.m4.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">â€¦</mi><mo id="S4.SS2.p1.4.m4.3.3.2.4" xref="S4.SS2.p1.4.m4.3.3.3.cmml">,</mo><msub id="S4.SS2.p1.4.m4.3.3.2.2" xref="S4.SS2.p1.4.m4.3.3.2.2.cmml"><mi mathvariant="normal" id="S4.SS2.p1.4.m4.3.3.2.2.2" xref="S4.SS2.p1.4.m4.3.3.2.2.2.cmml">Î˜</mi><mi id="S4.SS2.p1.4.m4.3.3.2.2.3" xref="S4.SS2.p1.4.m4.3.3.2.2.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.3b"><list id="S4.SS2.p1.4.m4.3.3.3.cmml" xref="S4.SS2.p1.4.m4.3.3.2"><apply id="S4.SS2.p1.4.m4.2.2.1.1.cmml" xref="S4.SS2.p1.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m4.2.2.1.1.1.cmml" xref="S4.SS2.p1.4.m4.2.2.1.1">subscript</csymbol><ci id="S4.SS2.p1.4.m4.2.2.1.1.2.cmml" xref="S4.SS2.p1.4.m4.2.2.1.1.2">Î˜</ci><cn type="integer" id="S4.SS2.p1.4.m4.2.2.1.1.3.cmml" xref="S4.SS2.p1.4.m4.2.2.1.1.3">1</cn></apply><ci id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">â€¦</ci><apply id="S4.SS2.p1.4.m4.3.3.2.2.cmml" xref="S4.SS2.p1.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.4.m4.3.3.2.2.1.cmml" xref="S4.SS2.p1.4.m4.3.3.2.2">subscript</csymbol><ci id="S4.SS2.p1.4.m4.3.3.2.2.2.cmml" xref="S4.SS2.p1.4.m4.3.3.2.2.2">Î˜</ci><ci id="S4.SS2.p1.4.m4.3.3.2.2.3.cmml" xref="S4.SS2.p1.4.m4.3.3.2.2.3">ğ‘‡</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.3c">\Theta_{1},...,\Theta_{T}</annotation></semantics></math> as</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.1" class="ltx_Math" alttext="q(\Theta_{t}|x_{0})=\mathcal{N}(\Theta_{t};\sqrt{\bar{\alpha}_{t}}x_{0},(1-\bar{\alpha}_{t})I)," display="block"><semantics id="S4.E1.m1.1a"><mrow id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.cmml"><mrow id="S4.E1.m1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.cmml"><mi id="S4.E1.m1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E1.m1.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathvariant="normal" id="S4.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml">Î˜</mi><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S4.E1.m1.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S4.E1.m1.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.3.2" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mn id="S4.E1.m1.1.1.1.1.1.1.1.1.3.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml">0</mn></msub></mrow><mo stretchy="false" id="S4.E1.m1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.1.1.1.1.5" xref="S4.E1.m1.1.1.1.1.5.cmml">=</mo><mrow id="S4.E1.m1.1.1.1.1.4" xref="S4.E1.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.1.4.5" xref="S4.E1.m1.1.1.1.1.4.5.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.4.4" xref="S4.E1.m1.1.1.1.1.4.4.cmml">â€‹</mo><mrow id="S4.E1.m1.1.1.1.1.4.3.3" xref="S4.E1.m1.1.1.1.1.4.3.4.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.1.4.3.3.4" xref="S4.E1.m1.1.1.1.1.4.3.4.cmml">(</mo><msub id="S4.E1.m1.1.1.1.1.2.1.1.1" xref="S4.E1.m1.1.1.1.1.2.1.1.1.cmml"><mi mathvariant="normal" id="S4.E1.m1.1.1.1.1.2.1.1.1.2" xref="S4.E1.m1.1.1.1.1.2.1.1.1.2.cmml">Î˜</mi><mi id="S4.E1.m1.1.1.1.1.2.1.1.1.3" xref="S4.E1.m1.1.1.1.1.2.1.1.1.3.cmml">t</mi></msub><mo id="S4.E1.m1.1.1.1.1.4.3.3.5" xref="S4.E1.m1.1.1.1.1.4.3.4.cmml">;</mo><mrow id="S4.E1.m1.1.1.1.1.3.2.2.2" xref="S4.E1.m1.1.1.1.1.3.2.2.2.cmml"><msqrt id="S4.E1.m1.1.1.1.1.3.2.2.2.2" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.cmml"><msub id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.cmml"><mover accent="true" id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.cmml"><mi id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.2" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.2.cmml">Î±</mi><mo id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.1" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.1.cmml">Â¯</mo></mover><mi id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.3" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.3.cmml">t</mi></msub></msqrt><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.3.2.2.2.1" xref="S4.E1.m1.1.1.1.1.3.2.2.2.1.cmml">â€‹</mo><msub id="S4.E1.m1.1.1.1.1.3.2.2.2.3" xref="S4.E1.m1.1.1.1.1.3.2.2.2.3.cmml"><mi id="S4.E1.m1.1.1.1.1.3.2.2.2.3.2" xref="S4.E1.m1.1.1.1.1.3.2.2.2.3.2.cmml">x</mi><mn id="S4.E1.m1.1.1.1.1.3.2.2.2.3.3" xref="S4.E1.m1.1.1.1.1.3.2.2.2.3.3.cmml">0</mn></msub></mrow><mo id="S4.E1.m1.1.1.1.1.4.3.3.6" xref="S4.E1.m1.1.1.1.1.4.3.4.cmml">,</mo><mrow id="S4.E1.m1.1.1.1.1.4.3.3.3" xref="S4.E1.m1.1.1.1.1.4.3.3.3.cmml"><mrow id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.2" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.cmml"><mn id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.2" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.2.cmml">1</mn><mo id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.1" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.1.cmml">âˆ’</mo><msub id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.cmml"><mover accent="true" id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.cmml"><mi id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.2" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.2.cmml">Î±</mi><mo id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.1" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.1.cmml">Â¯</mo></mover><mi id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.3" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.3" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E1.m1.1.1.1.1.4.3.3.3.2" xref="S4.E1.m1.1.1.1.1.4.3.3.3.2.cmml">â€‹</mo><mi id="S4.E1.m1.1.1.1.1.4.3.3.3.3" xref="S4.E1.m1.1.1.1.1.4.3.3.3.3.cmml">I</mi></mrow><mo stretchy="false" id="S4.E1.m1.1.1.1.1.4.3.3.7" xref="S4.E1.m1.1.1.1.1.4.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E1.m1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.1b"><apply id="S4.E1.m1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1"><eq id="S4.E1.m1.1.1.1.1.5.cmml" xref="S4.E1.m1.1.1.1.1.5"></eq><apply id="S4.E1.m1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1"><times id="S4.E1.m1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.2"></times><ci id="S4.E1.m1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.3">ğ‘</ci><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.2">Î˜</ci><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S4.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.2">ğ‘¥</ci><cn type="integer" id="S4.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.3.3">0</cn></apply></apply></apply><apply id="S4.E1.m1.1.1.1.1.4.cmml" xref="S4.E1.m1.1.1.1.1.4"><times id="S4.E1.m1.1.1.1.1.4.4.cmml" xref="S4.E1.m1.1.1.1.1.4.4"></times><ci id="S4.E1.m1.1.1.1.1.4.5.cmml" xref="S4.E1.m1.1.1.1.1.4.5">ğ’©</ci><list id="S4.E1.m1.1.1.1.1.4.3.4.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3"><apply id="S4.E1.m1.1.1.1.1.2.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.2.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.2.1.1.1">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.2.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.2.1.1.1.2">Î˜</ci><ci id="S4.E1.m1.1.1.1.1.2.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.2.1.1.1.3">ğ‘¡</ci></apply><apply id="S4.E1.m1.1.1.1.1.3.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2"><times id="S4.E1.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.1"></times><apply id="S4.E1.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2"><root id="S4.E1.m1.1.1.1.1.3.2.2.2.2a.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2"></root><apply id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2">subscript</csymbol><apply id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2"><ci id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.1">Â¯</ci><ci id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.2.2">ğ›¼</ci></apply><ci id="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.2.2.3">ğ‘¡</ci></apply></apply><apply id="S4.E1.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.3.2.2.2.3.1.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.3">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.3.2.2.2.3.2.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.3.2">ğ‘¥</ci><cn type="integer" id="S4.E1.m1.1.1.1.1.3.2.2.2.3.3.cmml" xref="S4.E1.m1.1.1.1.1.3.2.2.2.3.3">0</cn></apply></apply><apply id="S4.E1.m1.1.1.1.1.4.3.3.3.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3"><times id="S4.E1.m1.1.1.1.1.4.3.3.3.2.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.2"></times><apply id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1"><minus id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.1"></minus><cn type="integer" id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.2">1</cn><apply id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.1.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3">subscript</csymbol><apply id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2"><ci id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.1.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.1">Â¯</ci><ci id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.2.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.2.2">ğ›¼</ci></apply><ci id="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.3.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.1.1.1.3.3">ğ‘¡</ci></apply></apply><ci id="S4.E1.m1.1.1.1.1.4.3.3.3.3.cmml" xref="S4.E1.m1.1.1.1.1.4.3.3.3.3">ğ¼</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.1c">q(\Theta_{t}|x_{0})=\mathcal{N}(\Theta_{t};\sqrt{\bar{\alpha}_{t}}x_{0},(1-\bar{\alpha}_{t})I),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p1.11" class="ltx_p">where <math id="S4.SS2.p1.5.m1.1" class="ltx_Math" alttext="\mathcal{N}" display="inline"><semantics id="S4.SS2.p1.5.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.5.m1.1.1" xref="S4.SS2.p1.5.m1.1.1.cmml">ğ’©</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m1.1b"><ci id="S4.SS2.p1.5.m1.1.1.cmml" xref="S4.SS2.p1.5.m1.1.1">ğ’©</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m1.1c">\mathcal{N}</annotation></semantics></math> denotes the Gaussian distribution. <math id="S4.SS2.p1.6.m2.1" class="ltx_Math" alttext="\bar{\alpha}_{t}=\prod_{s=1}^{t}(1-\beta_{s})" display="inline"><semantics id="S4.SS2.p1.6.m2.1a"><mrow id="S4.SS2.p1.6.m2.1.1" xref="S4.SS2.p1.6.m2.1.1.cmml"><msub id="S4.SS2.p1.6.m2.1.1.3" xref="S4.SS2.p1.6.m2.1.1.3.cmml"><mover accent="true" id="S4.SS2.p1.6.m2.1.1.3.2" xref="S4.SS2.p1.6.m2.1.1.3.2.cmml"><mi id="S4.SS2.p1.6.m2.1.1.3.2.2" xref="S4.SS2.p1.6.m2.1.1.3.2.2.cmml">Î±</mi><mo id="S4.SS2.p1.6.m2.1.1.3.2.1" xref="S4.SS2.p1.6.m2.1.1.3.2.1.cmml">Â¯</mo></mover><mi id="S4.SS2.p1.6.m2.1.1.3.3" xref="S4.SS2.p1.6.m2.1.1.3.3.cmml">t</mi></msub><mo rspace="0.111em" id="S4.SS2.p1.6.m2.1.1.2" xref="S4.SS2.p1.6.m2.1.1.2.cmml">=</mo><mrow id="S4.SS2.p1.6.m2.1.1.1" xref="S4.SS2.p1.6.m2.1.1.1.cmml"><msubsup id="S4.SS2.p1.6.m2.1.1.1.2" xref="S4.SS2.p1.6.m2.1.1.1.2.cmml"><mo rspace="0em" id="S4.SS2.p1.6.m2.1.1.1.2.2.2" xref="S4.SS2.p1.6.m2.1.1.1.2.2.2.cmml">âˆ</mo><mrow id="S4.SS2.p1.6.m2.1.1.1.2.2.3" xref="S4.SS2.p1.6.m2.1.1.1.2.2.3.cmml"><mi id="S4.SS2.p1.6.m2.1.1.1.2.2.3.2" xref="S4.SS2.p1.6.m2.1.1.1.2.2.3.2.cmml">s</mi><mo id="S4.SS2.p1.6.m2.1.1.1.2.2.3.1" xref="S4.SS2.p1.6.m2.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.SS2.p1.6.m2.1.1.1.2.2.3.3" xref="S4.SS2.p1.6.m2.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p1.6.m2.1.1.1.2.3" xref="S4.SS2.p1.6.m2.1.1.1.2.3.cmml">t</mi></msubsup><mrow id="S4.SS2.p1.6.m2.1.1.1.1.1" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p1.6.m2.1.1.1.1.1.2" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p1.6.m2.1.1.1.1.1.1" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.cmml"><mn id="S4.SS2.p1.6.m2.1.1.1.1.1.1.2" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.SS2.p1.6.m2.1.1.1.1.1.1.1" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S4.SS2.p1.6.m2.1.1.1.1.1.1.3" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.cmml"><mi id="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.2" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.2.cmml">Î²</mi><mi id="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.3" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.3.cmml">s</mi></msub></mrow><mo stretchy="false" id="S4.SS2.p1.6.m2.1.1.1.1.1.3" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m2.1b"><apply id="S4.SS2.p1.6.m2.1.1.cmml" xref="S4.SS2.p1.6.m2.1.1"><eq id="S4.SS2.p1.6.m2.1.1.2.cmml" xref="S4.SS2.p1.6.m2.1.1.2"></eq><apply id="S4.SS2.p1.6.m2.1.1.3.cmml" xref="S4.SS2.p1.6.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m2.1.1.3.1.cmml" xref="S4.SS2.p1.6.m2.1.1.3">subscript</csymbol><apply id="S4.SS2.p1.6.m2.1.1.3.2.cmml" xref="S4.SS2.p1.6.m2.1.1.3.2"><ci id="S4.SS2.p1.6.m2.1.1.3.2.1.cmml" xref="S4.SS2.p1.6.m2.1.1.3.2.1">Â¯</ci><ci id="S4.SS2.p1.6.m2.1.1.3.2.2.cmml" xref="S4.SS2.p1.6.m2.1.1.3.2.2">ğ›¼</ci></apply><ci id="S4.SS2.p1.6.m2.1.1.3.3.cmml" xref="S4.SS2.p1.6.m2.1.1.3.3">ğ‘¡</ci></apply><apply id="S4.SS2.p1.6.m2.1.1.1.cmml" xref="S4.SS2.p1.6.m2.1.1.1"><apply id="S4.SS2.p1.6.m2.1.1.1.2.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m2.1.1.1.2.1.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2">superscript</csymbol><apply id="S4.SS2.p1.6.m2.1.1.1.2.2.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m2.1.1.1.2.2.1.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2">subscript</csymbol><csymbol cd="latexml" id="S4.SS2.p1.6.m2.1.1.1.2.2.2.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2.2.2">product</csymbol><apply id="S4.SS2.p1.6.m2.1.1.1.2.2.3.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2.2.3"><eq id="S4.SS2.p1.6.m2.1.1.1.2.2.3.1.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2.2.3.1"></eq><ci id="S4.SS2.p1.6.m2.1.1.1.2.2.3.2.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2.2.3.2">ğ‘ </ci><cn type="integer" id="S4.SS2.p1.6.m2.1.1.1.2.2.3.3.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.SS2.p1.6.m2.1.1.1.2.3.cmml" xref="S4.SS2.p1.6.m2.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S4.SS2.p1.6.m2.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.6.m2.1.1.1.1.1"><minus id="S4.SS2.p1.6.m2.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.SS2.p1.6.m2.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.2">1</cn><apply id="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.1.cmml" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.2.cmml" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.2">ğ›½</ci><ci id="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.3.cmml" xref="S4.SS2.p1.6.m2.1.1.1.1.1.1.3.3">ğ‘ </ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m2.1c">\bar{\alpha}_{t}=\prod_{s=1}^{t}(1-\beta_{s})</annotation></semantics></math> and <math id="S4.SS2.p1.7.m3.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.SS2.p1.7.m3.1a"><mi id="S4.SS2.p1.7.m3.1.1" xref="S4.SS2.p1.7.m3.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m3.1b"><ci id="S4.SS2.p1.7.m3.1.1.cmml" xref="S4.SS2.p1.7.m3.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m3.1c">\beta</annotation></semantics></math> represent the variance scheduler for the added noise. Therefore, a model parameterized by a deep neural network <math id="S4.SS2.p1.8.m4.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS2.p1.8.m4.1a"><mi id="S4.SS2.p1.8.m4.1.1" xref="S4.SS2.p1.8.m4.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m4.1b"><ci id="S4.SS2.p1.8.m4.1.1.cmml" xref="S4.SS2.p1.8.m4.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m4.1c">G</annotation></semantics></math> is trained to master the inverse process within another Markov chain, which learns the mapping <math id="S4.SS2.p1.9.m5.1" class="ltx_Math" alttext="p(\Theta_{t-1}|\Theta_{t})" display="inline"><semantics id="S4.SS2.p1.9.m5.1a"><mrow id="S4.SS2.p1.9.m5.1.1" xref="S4.SS2.p1.9.m5.1.1.cmml"><mi id="S4.SS2.p1.9.m5.1.1.3" xref="S4.SS2.p1.9.m5.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p1.9.m5.1.1.2" xref="S4.SS2.p1.9.m5.1.1.2.cmml">â€‹</mo><mrow id="S4.SS2.p1.9.m5.1.1.1.1" xref="S4.SS2.p1.9.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p1.9.m5.1.1.1.1.2" xref="S4.SS2.p1.9.m5.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS2.p1.9.m5.1.1.1.1.1" xref="S4.SS2.p1.9.m5.1.1.1.1.1.cmml"><msub id="S4.SS2.p1.9.m5.1.1.1.1.1.2" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.cmml"><mi mathvariant="normal" id="S4.SS2.p1.9.m5.1.1.1.1.1.2.2" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.2.cmml">Î˜</mi><mrow id="S4.SS2.p1.9.m5.1.1.1.1.1.2.3" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.cmml"><mi id="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.2" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.1" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.1.cmml">âˆ’</mo><mn id="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.3" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S4.SS2.p1.9.m5.1.1.1.1.1.1" xref="S4.SS2.p1.9.m5.1.1.1.1.1.1.cmml">|</mo><msub id="S4.SS2.p1.9.m5.1.1.1.1.1.3" xref="S4.SS2.p1.9.m5.1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S4.SS2.p1.9.m5.1.1.1.1.1.3.2" xref="S4.SS2.p1.9.m5.1.1.1.1.1.3.2.cmml">Î˜</mi><mi id="S4.SS2.p1.9.m5.1.1.1.1.1.3.3" xref="S4.SS2.p1.9.m5.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S4.SS2.p1.9.m5.1.1.1.1.3" xref="S4.SS2.p1.9.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m5.1b"><apply id="S4.SS2.p1.9.m5.1.1.cmml" xref="S4.SS2.p1.9.m5.1.1"><times id="S4.SS2.p1.9.m5.1.1.2.cmml" xref="S4.SS2.p1.9.m5.1.1.2"></times><ci id="S4.SS2.p1.9.m5.1.1.3.cmml" xref="S4.SS2.p1.9.m5.1.1.3">ğ‘</ci><apply id="S4.SS2.p1.9.m5.1.1.1.1.1.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.9.m5.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.1">conditional</csymbol><apply id="S4.SS2.p1.9.m5.1.1.1.1.1.2.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.9.m5.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS2.p1.9.m5.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.2">Î˜</ci><apply id="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.3"><minus id="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.1.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.1"></minus><ci id="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.2.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.3.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S4.SS2.p1.9.m5.1.1.1.1.1.3.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.9.m5.1.1.1.1.1.3.1.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS2.p1.9.m5.1.1.1.1.1.3.2.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.3.2">Î˜</ci><ci id="S4.SS2.p1.9.m5.1.1.1.1.1.3.3.cmml" xref="S4.SS2.p1.9.m5.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m5.1c">p(\Theta_{t-1}|\Theta_{t})</annotation></semantics></math> to sequentially denoise samples over <math id="S4.SS2.p1.10.m6.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS2.p1.10.m6.1a"><mi id="S4.SS2.p1.10.m6.1.1" xref="S4.SS2.p1.10.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m6.1b"><ci id="S4.SS2.p1.10.m6.1.1.cmml" xref="S4.SS2.p1.10.m6.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m6.1c">T</annotation></semantics></math> steps. Specifically, denoising model <math id="S4.SS2.p1.11.m7.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS2.p1.11.m7.1a"><mi id="S4.SS2.p1.11.m7.1.1" xref="S4.SS2.p1.11.m7.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.11.m7.1b"><ci id="S4.SS2.p1.11.m7.1.1.cmml" xref="S4.SS2.p1.11.m7.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.11.m7.1c">G</annotation></semantics></math> consists of a 4-layer U-NetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> with 256, 512, 1024, 2048 dimensions for each layer.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.10" class="ltx_p">To reduce the noise in piano audio, the audio features <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">f</mi><mi id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">ğ‘“</ci><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">f_{a}</annotation></semantics></math> are simultaneously fed into the denoising neural network <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">G</annotation></semantics></math> as conditions. Similar to the position decoder <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="\Phi_{p}" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><msub id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mi mathvariant="normal" id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml">Î¦</mi><mi id="S4.SS2.p2.3.m3.1.1.3" xref="S4.SS2.p2.3.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2">Î¦</ci><ci id="S4.SS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">\Phi_{p}</annotation></semantics></math>, a gesture decoder <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="\Phi_{g}" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><msub id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mi mathvariant="normal" id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">Î¦</mi><mi id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2">Î¦</ci><ci id="S4.SS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">\Phi_{g}</annotation></semantics></math> is utilized to extract gesture features <math id="S4.SS2.p2.5.m5.1" class="ltx_Math" alttext="f_{g}" display="inline"><semantics id="S4.SS2.p2.5.m5.1a"><msub id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml"><mi id="S4.SS2.p2.5.m5.1.1.2" xref="S4.SS2.p2.5.m5.1.1.2.cmml">f</mi><mi id="S4.SS2.p2.5.m5.1.1.3" xref="S4.SS2.p2.5.m5.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><apply id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.5.m5.1.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S4.SS2.p2.5.m5.1.1.2.cmml" xref="S4.SS2.p2.5.m5.1.1.2">ğ‘“</ci><ci id="S4.SS2.p2.5.m5.1.1.3.cmml" xref="S4.SS2.p2.5.m5.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">f_{g}</annotation></semantics></math> from the audio features <math id="S4.SS2.p2.6.m6.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="S4.SS2.p2.6.m6.1a"><msub id="S4.SS2.p2.6.m6.1.1" xref="S4.SS2.p2.6.m6.1.1.cmml"><mi id="S4.SS2.p2.6.m6.1.1.2" xref="S4.SS2.p2.6.m6.1.1.2.cmml">f</mi><mi id="S4.SS2.p2.6.m6.1.1.3" xref="S4.SS2.p2.6.m6.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.6.m6.1b"><apply id="S4.SS2.p2.6.m6.1.1.cmml" xref="S4.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.6.m6.1.1.1.cmml" xref="S4.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="S4.SS2.p2.6.m6.1.1.2.cmml" xref="S4.SS2.p2.6.m6.1.1.2">ğ‘“</ci><ci id="S4.SS2.p2.6.m6.1.1.3.cmml" xref="S4.SS2.p2.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.6.m6.1c">f_{a}</annotation></semantics></math> as <math id="S4.SS2.p2.7.m7.1" class="ltx_Math" alttext="f_{g}=\Phi_{g}(f_{a})" display="inline"><semantics id="S4.SS2.p2.7.m7.1a"><mrow id="S4.SS2.p2.7.m7.1.1" xref="S4.SS2.p2.7.m7.1.1.cmml"><msub id="S4.SS2.p2.7.m7.1.1.3" xref="S4.SS2.p2.7.m7.1.1.3.cmml"><mi id="S4.SS2.p2.7.m7.1.1.3.2" xref="S4.SS2.p2.7.m7.1.1.3.2.cmml">f</mi><mi id="S4.SS2.p2.7.m7.1.1.3.3" xref="S4.SS2.p2.7.m7.1.1.3.3.cmml">g</mi></msub><mo id="S4.SS2.p2.7.m7.1.1.2" xref="S4.SS2.p2.7.m7.1.1.2.cmml">=</mo><mrow id="S4.SS2.p2.7.m7.1.1.1" xref="S4.SS2.p2.7.m7.1.1.1.cmml"><msub id="S4.SS2.p2.7.m7.1.1.1.3" xref="S4.SS2.p2.7.m7.1.1.1.3.cmml"><mi mathvariant="normal" id="S4.SS2.p2.7.m7.1.1.1.3.2" xref="S4.SS2.p2.7.m7.1.1.1.3.2.cmml">Î¦</mi><mi id="S4.SS2.p2.7.m7.1.1.1.3.3" xref="S4.SS2.p2.7.m7.1.1.1.3.3.cmml">g</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS2.p2.7.m7.1.1.1.2" xref="S4.SS2.p2.7.m7.1.1.1.2.cmml">â€‹</mo><mrow id="S4.SS2.p2.7.m7.1.1.1.1.1" xref="S4.SS2.p2.7.m7.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS2.p2.7.m7.1.1.1.1.1.2" xref="S4.SS2.p2.7.m7.1.1.1.1.1.1.cmml">(</mo><msub id="S4.SS2.p2.7.m7.1.1.1.1.1.1" xref="S4.SS2.p2.7.m7.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p2.7.m7.1.1.1.1.1.1.2" xref="S4.SS2.p2.7.m7.1.1.1.1.1.1.2.cmml">f</mi><mi id="S4.SS2.p2.7.m7.1.1.1.1.1.1.3" xref="S4.SS2.p2.7.m7.1.1.1.1.1.1.3.cmml">a</mi></msub><mo stretchy="false" id="S4.SS2.p2.7.m7.1.1.1.1.1.3" xref="S4.SS2.p2.7.m7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.7.m7.1b"><apply id="S4.SS2.p2.7.m7.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1"><eq id="S4.SS2.p2.7.m7.1.1.2.cmml" xref="S4.SS2.p2.7.m7.1.1.2"></eq><apply id="S4.SS2.p2.7.m7.1.1.3.cmml" xref="S4.SS2.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p2.7.m7.1.1.3.1.cmml" xref="S4.SS2.p2.7.m7.1.1.3">subscript</csymbol><ci id="S4.SS2.p2.7.m7.1.1.3.2.cmml" xref="S4.SS2.p2.7.m7.1.1.3.2">ğ‘“</ci><ci id="S4.SS2.p2.7.m7.1.1.3.3.cmml" xref="S4.SS2.p2.7.m7.1.1.3.3">ğ‘”</ci></apply><apply id="S4.SS2.p2.7.m7.1.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1.1"><times id="S4.SS2.p2.7.m7.1.1.1.2.cmml" xref="S4.SS2.p2.7.m7.1.1.1.2"></times><apply id="S4.SS2.p2.7.m7.1.1.1.3.cmml" xref="S4.SS2.p2.7.m7.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p2.7.m7.1.1.1.3.1.cmml" xref="S4.SS2.p2.7.m7.1.1.1.3">subscript</csymbol><ci id="S4.SS2.p2.7.m7.1.1.1.3.2.cmml" xref="S4.SS2.p2.7.m7.1.1.1.3.2">Î¦</ci><ci id="S4.SS2.p2.7.m7.1.1.1.3.3.cmml" xref="S4.SS2.p2.7.m7.1.1.1.3.3">ğ‘”</ci></apply><apply id="S4.SS2.p2.7.m7.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.7.m7.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.7.m7.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p2.7.m7.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p2.7.m7.1.1.1.1.1.1.2">ğ‘“</ci><ci id="S4.SS2.p2.7.m7.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p2.7.m7.1.1.1.1.1.1.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.7.m7.1c">f_{g}=\Phi_{g}(f_{a})</annotation></semantics></math>. Considering that the finger movements at different positions for the same pitch are distinct, <math id="S4.SS2.p2.8.m8.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS2.p2.8.m8.1a"><mi id="S4.SS2.p2.8.m8.1.1" xref="S4.SS2.p2.8.m8.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.8.m8.1b"><ci id="S4.SS2.p2.8.m8.1.1.cmml" xref="S4.SS2.p2.8.m8.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.8.m8.1c">G</annotation></semantics></math> requires the guidance of hand positions <math id="S4.SS2.p2.9.m9.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.SS2.p2.9.m9.1a"><mi id="S4.SS2.p2.9.m9.1.1" xref="S4.SS2.p2.9.m9.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.9.m9.1b"><ci id="S4.SS2.p2.9.m9.1.1.cmml" xref="S4.SS2.p2.9.m9.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.9.m9.1c">P</annotation></semantics></math> from the position predictor. This will enhance the fidelity of the generation process. As for the additional conditions, the time step embeddings of time <math id="S4.SS2.p2.10.m10.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.p2.10.m10.1a"><mi id="S4.SS2.p2.10.m10.1.1" xref="S4.SS2.p2.10.m10.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.10.m10.1b"><ci id="S4.SS2.p2.10.m10.1.1.cmml" xref="S4.SS2.p2.10.m10.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.10.m10.1c">t</annotation></semantics></math> are concatenated in denoising process. The denoising process can be formulated as follows</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.3" class="ltx_Math" alttext="\hat{\Theta}_{0}=G(\Theta_{t},t;f_{g},P)," display="block"><semantics id="S4.E2.m1.3a"><mrow id="S4.E2.m1.3.3.1" xref="S4.E2.m1.3.3.1.1.cmml"><mrow id="S4.E2.m1.3.3.1.1" xref="S4.E2.m1.3.3.1.1.cmml"><msub id="S4.E2.m1.3.3.1.1.4" xref="S4.E2.m1.3.3.1.1.4.cmml"><mover accent="true" id="S4.E2.m1.3.3.1.1.4.2" xref="S4.E2.m1.3.3.1.1.4.2.cmml"><mi mathvariant="normal" id="S4.E2.m1.3.3.1.1.4.2.2" xref="S4.E2.m1.3.3.1.1.4.2.2.cmml">Î˜</mi><mo id="S4.E2.m1.3.3.1.1.4.2.1" xref="S4.E2.m1.3.3.1.1.4.2.1.cmml">^</mo></mover><mn id="S4.E2.m1.3.3.1.1.4.3" xref="S4.E2.m1.3.3.1.1.4.3.cmml">0</mn></msub><mo id="S4.E2.m1.3.3.1.1.3" xref="S4.E2.m1.3.3.1.1.3.cmml">=</mo><mrow id="S4.E2.m1.3.3.1.1.2" xref="S4.E2.m1.3.3.1.1.2.cmml"><mi id="S4.E2.m1.3.3.1.1.2.4" xref="S4.E2.m1.3.3.1.1.2.4.cmml">G</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.1.2.3" xref="S4.E2.m1.3.3.1.1.2.3.cmml">â€‹</mo><mrow id="S4.E2.m1.3.3.1.1.2.2.2" xref="S4.E2.m1.3.3.1.1.2.2.3.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.2.2.2.3" xref="S4.E2.m1.3.3.1.1.2.2.3.cmml">(</mo><msub id="S4.E2.m1.3.3.1.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S4.E2.m1.3.3.1.1.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.1.1.2.cmml">Î˜</mi><mi id="S4.E2.m1.3.3.1.1.1.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S4.E2.m1.3.3.1.1.2.2.2.4" xref="S4.E2.m1.3.3.1.1.2.2.3.cmml">,</mo><mi id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml">t</mi><mo id="S4.E2.m1.3.3.1.1.2.2.2.5" xref="S4.E2.m1.3.3.1.1.2.2.3.cmml">;</mo><msub id="S4.E2.m1.3.3.1.1.2.2.2.2" xref="S4.E2.m1.3.3.1.1.2.2.2.2.cmml"><mi id="S4.E2.m1.3.3.1.1.2.2.2.2.2" xref="S4.E2.m1.3.3.1.1.2.2.2.2.2.cmml">f</mi><mi id="S4.E2.m1.3.3.1.1.2.2.2.2.3" xref="S4.E2.m1.3.3.1.1.2.2.2.2.3.cmml">g</mi></msub><mo id="S4.E2.m1.3.3.1.1.2.2.2.6" xref="S4.E2.m1.3.3.1.1.2.2.3.cmml">,</mo><mi id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml">P</mi><mo stretchy="false" id="S4.E2.m1.3.3.1.1.2.2.2.7" xref="S4.E2.m1.3.3.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E2.m1.3.3.1.2" xref="S4.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.3b"><apply id="S4.E2.m1.3.3.1.1.cmml" xref="S4.E2.m1.3.3.1"><eq id="S4.E2.m1.3.3.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.3"></eq><apply id="S4.E2.m1.3.3.1.1.4.cmml" xref="S4.E2.m1.3.3.1.1.4"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.4.1.cmml" xref="S4.E2.m1.3.3.1.1.4">subscript</csymbol><apply id="S4.E2.m1.3.3.1.1.4.2.cmml" xref="S4.E2.m1.3.3.1.1.4.2"><ci id="S4.E2.m1.3.3.1.1.4.2.1.cmml" xref="S4.E2.m1.3.3.1.1.4.2.1">^</ci><ci id="S4.E2.m1.3.3.1.1.4.2.2.cmml" xref="S4.E2.m1.3.3.1.1.4.2.2">Î˜</ci></apply><cn type="integer" id="S4.E2.m1.3.3.1.1.4.3.cmml" xref="S4.E2.m1.3.3.1.1.4.3">0</cn></apply><apply id="S4.E2.m1.3.3.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.2"><times id="S4.E2.m1.3.3.1.1.2.3.cmml" xref="S4.E2.m1.3.3.1.1.2.3"></times><ci id="S4.E2.m1.3.3.1.1.2.4.cmml" xref="S4.E2.m1.3.3.1.1.2.4">ğº</ci><vector id="S4.E2.m1.3.3.1.1.2.2.3.cmml" xref="S4.E2.m1.3.3.1.1.2.2.2"><apply id="S4.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.2">Î˜</ci><ci id="S4.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1">ğ‘¡</ci><apply id="S4.E2.m1.3.3.1.1.2.2.2.2.cmml" xref="S4.E2.m1.3.3.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.2.2.2.2.1.cmml" xref="S4.E2.m1.3.3.1.1.2.2.2.2">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S4.E2.m1.3.3.1.1.2.2.2.2.2">ğ‘“</ci><ci id="S4.E2.m1.3.3.1.1.2.2.2.2.3.cmml" xref="S4.E2.m1.3.3.1.1.2.2.2.2.3">ğ‘”</ci></apply><ci id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2">ğ‘ƒ</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.3c">\hat{\Theta}_{0}=G(\Theta_{t},t;f_{g},P),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2.p2.12" class="ltx_p">where <math id="S4.SS2.p2.11.m1.1" class="ltx_Math" alttext="\hat{\Theta}_{0}\in\mathbb{R}^{N\times J\times 3}" display="inline"><semantics id="S4.SS2.p2.11.m1.1a"><mrow id="S4.SS2.p2.11.m1.1.1" xref="S4.SS2.p2.11.m1.1.1.cmml"><msub id="S4.SS2.p2.11.m1.1.1.2" xref="S4.SS2.p2.11.m1.1.1.2.cmml"><mover accent="true" id="S4.SS2.p2.11.m1.1.1.2.2" xref="S4.SS2.p2.11.m1.1.1.2.2.cmml"><mi mathvariant="normal" id="S4.SS2.p2.11.m1.1.1.2.2.2" xref="S4.SS2.p2.11.m1.1.1.2.2.2.cmml">Î˜</mi><mo id="S4.SS2.p2.11.m1.1.1.2.2.1" xref="S4.SS2.p2.11.m1.1.1.2.2.1.cmml">^</mo></mover><mn id="S4.SS2.p2.11.m1.1.1.2.3" xref="S4.SS2.p2.11.m1.1.1.2.3.cmml">0</mn></msub><mo id="S4.SS2.p2.11.m1.1.1.1" xref="S4.SS2.p2.11.m1.1.1.1.cmml">âˆˆ</mo><msup id="S4.SS2.p2.11.m1.1.1.3" xref="S4.SS2.p2.11.m1.1.1.3.cmml"><mi id="S4.SS2.p2.11.m1.1.1.3.2" xref="S4.SS2.p2.11.m1.1.1.3.2.cmml">â„</mi><mrow id="S4.SS2.p2.11.m1.1.1.3.3" xref="S4.SS2.p2.11.m1.1.1.3.3.cmml"><mi id="S4.SS2.p2.11.m1.1.1.3.3.2" xref="S4.SS2.p2.11.m1.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p2.11.m1.1.1.3.3.1" xref="S4.SS2.p2.11.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S4.SS2.p2.11.m1.1.1.3.3.3" xref="S4.SS2.p2.11.m1.1.1.3.3.3.cmml">J</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p2.11.m1.1.1.3.3.1a" xref="S4.SS2.p2.11.m1.1.1.3.3.1.cmml">Ã—</mo><mn id="S4.SS2.p2.11.m1.1.1.3.3.4" xref="S4.SS2.p2.11.m1.1.1.3.3.4.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.11.m1.1b"><apply id="S4.SS2.p2.11.m1.1.1.cmml" xref="S4.SS2.p2.11.m1.1.1"><in id="S4.SS2.p2.11.m1.1.1.1.cmml" xref="S4.SS2.p2.11.m1.1.1.1"></in><apply id="S4.SS2.p2.11.m1.1.1.2.cmml" xref="S4.SS2.p2.11.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p2.11.m1.1.1.2.1.cmml" xref="S4.SS2.p2.11.m1.1.1.2">subscript</csymbol><apply id="S4.SS2.p2.11.m1.1.1.2.2.cmml" xref="S4.SS2.p2.11.m1.1.1.2.2"><ci id="S4.SS2.p2.11.m1.1.1.2.2.1.cmml" xref="S4.SS2.p2.11.m1.1.1.2.2.1">^</ci><ci id="S4.SS2.p2.11.m1.1.1.2.2.2.cmml" xref="S4.SS2.p2.11.m1.1.1.2.2.2">Î˜</ci></apply><cn type="integer" id="S4.SS2.p2.11.m1.1.1.2.3.cmml" xref="S4.SS2.p2.11.m1.1.1.2.3">0</cn></apply><apply id="S4.SS2.p2.11.m1.1.1.3.cmml" xref="S4.SS2.p2.11.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p2.11.m1.1.1.3.1.cmml" xref="S4.SS2.p2.11.m1.1.1.3">superscript</csymbol><ci id="S4.SS2.p2.11.m1.1.1.3.2.cmml" xref="S4.SS2.p2.11.m1.1.1.3.2">â„</ci><apply id="S4.SS2.p2.11.m1.1.1.3.3.cmml" xref="S4.SS2.p2.11.m1.1.1.3.3"><times id="S4.SS2.p2.11.m1.1.1.3.3.1.cmml" xref="S4.SS2.p2.11.m1.1.1.3.3.1"></times><ci id="S4.SS2.p2.11.m1.1.1.3.3.2.cmml" xref="S4.SS2.p2.11.m1.1.1.3.3.2">ğ‘</ci><ci id="S4.SS2.p2.11.m1.1.1.3.3.3.cmml" xref="S4.SS2.p2.11.m1.1.1.3.3.3">ğ½</ci><cn type="integer" id="S4.SS2.p2.11.m1.1.1.3.3.4.cmml" xref="S4.SS2.p2.11.m1.1.1.3.3.4">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.11.m1.1c">\hat{\Theta}_{0}\in\mathbb{R}^{N\times J\times 3}</annotation></semantics></math> denotes the result of hand motions within <math id="S4.SS2.p2.12.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS2.p2.12.m2.1a"><mi id="S4.SS2.p2.12.m2.1.1" xref="S4.SS2.p2.12.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.12.m2.1b"><ci id="S4.SS2.p2.12.m2.1.1.cmml" xref="S4.SS2.p2.12.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.12.m2.1c">N</annotation></semantics></math> frames.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Implementation Details</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.11" class="ltx_p">We employ a two-stage scheme to train our proposed network. At the first stage, the position predictor is trained using position error <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{p}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><msub id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">â„’</mi><mi id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">â„’</ci><ci id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\mathcal{L}_{p}</annotation></semantics></math> and velocity loss <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{v}" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><msub id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">â„’</mi><mi id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">â„’</ci><ci id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\mathcal{L}_{v}</annotation></semantics></math>. The position error <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{p}" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><msub id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.3.m3.1.1.2" xref="S4.SS3.p1.3.m3.1.1.2.cmml">â„’</mi><mi id="S4.SS3.p1.3.m3.1.1.3" xref="S4.SS3.p1.3.m3.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">â„’</ci><ci id="S4.SS3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">\mathcal{L}_{p}</annotation></semantics></math> computes the <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="L_{1}" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><msub id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mi id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml">L</mi><mn id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2">ğ¿</ci><cn type="integer" id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">L_{1}</annotation></semantics></math> loss between the predicted position <math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="\hat{P}" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><mover accent="true" id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mi id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml">P</mi><mo id="S4.SS3.p1.5.m5.1.1.1" xref="S4.SS3.p1.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><ci id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1.1">^</ci><ci id="S4.SS3.p1.5.m5.1.1.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2">ğ‘ƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">\hat{P}</annotation></semantics></math> and the ground truth <math id="S4.SS3.p1.6.m6.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.SS3.p1.6.m6.1a"><mi id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><ci id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">P</annotation></semantics></math>, expressed as <math id="S4.SS3.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{L}_{p}=||\hat{P}-P||_{1}" display="inline"><semantics id="S4.SS3.p1.7.m7.1a"><mrow id="S4.SS3.p1.7.m7.1.1" xref="S4.SS3.p1.7.m7.1.1.cmml"><msub id="S4.SS3.p1.7.m7.1.1.3" xref="S4.SS3.p1.7.m7.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.7.m7.1.1.3.2" xref="S4.SS3.p1.7.m7.1.1.3.2.cmml">â„’</mi><mi id="S4.SS3.p1.7.m7.1.1.3.3" xref="S4.SS3.p1.7.m7.1.1.3.3.cmml">p</mi></msub><mo id="S4.SS3.p1.7.m7.1.1.2" xref="S4.SS3.p1.7.m7.1.1.2.cmml">=</mo><msub id="S4.SS3.p1.7.m7.1.1.1" xref="S4.SS3.p1.7.m7.1.1.1.cmml"><mrow id="S4.SS3.p1.7.m7.1.1.1.1.1" xref="S4.SS3.p1.7.m7.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS3.p1.7.m7.1.1.1.1.1.2" xref="S4.SS3.p1.7.m7.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S4.SS3.p1.7.m7.1.1.1.1.1.1" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.SS3.p1.7.m7.1.1.1.1.1.1.2" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.cmml"><mi id="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.2" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.2.cmml">P</mi><mo id="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.1" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S4.SS3.p1.7.m7.1.1.1.1.1.1.1" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S4.SS3.p1.7.m7.1.1.1.1.1.1.3" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.3.cmml">P</mi></mrow><mo stretchy="false" id="S4.SS3.p1.7.m7.1.1.1.1.1.3" xref="S4.SS3.p1.7.m7.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S4.SS3.p1.7.m7.1.1.1.3" xref="S4.SS3.p1.7.m7.1.1.1.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.1b"><apply id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1"><eq id="S4.SS3.p1.7.m7.1.1.2.cmml" xref="S4.SS3.p1.7.m7.1.1.2"></eq><apply id="S4.SS3.p1.7.m7.1.1.3.cmml" xref="S4.SS3.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.7.m7.1.1.3.1.cmml" xref="S4.SS3.p1.7.m7.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.7.m7.1.1.3.2.cmml" xref="S4.SS3.p1.7.m7.1.1.3.2">â„’</ci><ci id="S4.SS3.p1.7.m7.1.1.3.3.cmml" xref="S4.SS3.p1.7.m7.1.1.3.3">ğ‘</ci></apply><apply id="S4.SS3.p1.7.m7.1.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.7.m7.1.1.1.2.cmml" xref="S4.SS3.p1.7.m7.1.1.1">subscript</csymbol><apply id="S4.SS3.p1.7.m7.1.1.1.1.2.cmml" xref="S4.SS3.p1.7.m7.1.1.1.1.1"><csymbol cd="latexml" id="S4.SS3.p1.7.m7.1.1.1.1.2.1.cmml" xref="S4.SS3.p1.7.m7.1.1.1.1.1.2">norm</csymbol><apply id="S4.SS3.p1.7.m7.1.1.1.1.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1"><minus id="S4.SS3.p1.7.m7.1.1.1.1.1.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.1"></minus><apply id="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.cmml" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.2"><ci id="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.1.cmml" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.1">^</ci><ci id="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.2.cmml" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.2.2">ğ‘ƒ</ci></apply><ci id="S4.SS3.p1.7.m7.1.1.1.1.1.1.3.cmml" xref="S4.SS3.p1.7.m7.1.1.1.1.1.1.3">ğ‘ƒ</ci></apply></apply><cn type="integer" id="S4.SS3.p1.7.m7.1.1.1.3.cmml" xref="S4.SS3.p1.7.m7.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.1c">\mathcal{L}_{p}=||\hat{P}-P||_{1}</annotation></semantics></math>. Inspired byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, velocity loss is adopted to induce temporal stability for generating smoothing movements, which is formulated as <math id="S4.SS3.p1.8.m8.1" class="ltx_Math" alttext="\mathcal{L}_{v}=||(\hat{P}_{n}-\hat{P}_{n-1})-(P_{n}-P_{n-1})||_{2}" display="inline"><semantics id="S4.SS3.p1.8.m8.1a"><mrow id="S4.SS3.p1.8.m8.1.1" xref="S4.SS3.p1.8.m8.1.1.cmml"><msub id="S4.SS3.p1.8.m8.1.1.3" xref="S4.SS3.p1.8.m8.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.8.m8.1.1.3.2" xref="S4.SS3.p1.8.m8.1.1.3.2.cmml">â„’</mi><mi id="S4.SS3.p1.8.m8.1.1.3.3" xref="S4.SS3.p1.8.m8.1.1.3.3.cmml">v</mi></msub><mo id="S4.SS3.p1.8.m8.1.1.2" xref="S4.SS3.p1.8.m8.1.1.2.cmml">=</mo><msub id="S4.SS3.p1.8.m8.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.cmml"><mrow id="S4.SS3.p1.8.m8.1.1.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS3.p1.8.m8.1.1.1.1.1.2" xref="S4.SS3.p1.8.m8.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S4.SS3.p1.8.m8.1.1.1.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.cmml"><mrow id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.2.cmml">P</mi><mo id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.2.cmml">P</mi><mo id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mrow id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.2.cmml">n</mi><mo id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.1.cmml">âˆ’</mo><mn id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo stretchy="false" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.SS3.p1.8.m8.1.1.1.1.1.1.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.3.cmml">âˆ’</mo><mrow id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.cmml"><mo stretchy="false" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.cmml"><msub id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.cmml"><mi id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.2.cmml">P</mi><mi id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.3.cmml">n</mi></msub><mo id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.1.cmml">âˆ’</mo><msub id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.cmml"><mi id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.2.cmml">P</mi><mrow id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.cmml"><mi id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.2" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.2.cmml">n</mi><mo id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.1" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.1.cmml">âˆ’</mo><mn id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo stretchy="false" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.3" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.SS3.p1.8.m8.1.1.1.1.1.3" xref="S4.SS3.p1.8.m8.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S4.SS3.p1.8.m8.1.1.1.3" xref="S4.SS3.p1.8.m8.1.1.1.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m8.1b"><apply id="S4.SS3.p1.8.m8.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1"><eq id="S4.SS3.p1.8.m8.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.2"></eq><apply id="S4.SS3.p1.8.m8.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.8.m8.1.1.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.3.2">â„’</ci><ci id="S4.SS3.p1.8.m8.1.1.3.3.cmml" xref="S4.SS3.p1.8.m8.1.1.3.3">ğ‘£</ci></apply><apply id="S4.SS3.p1.8.m8.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1">subscript</csymbol><apply id="S4.SS3.p1.8.m8.1.1.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1"><csymbol cd="latexml" id="S4.SS3.p1.8.m8.1.1.1.1.2.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.2">norm</csymbol><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1"><minus id="S4.SS3.p1.8.m8.1.1.1.1.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.3"></minus><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1"><minus id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2"><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.2.2">ğ‘ƒ</ci></apply><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.2.3">ğ‘›</ci></apply><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2"><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.1">^</ci><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.2.2">ğ‘ƒ</ci></apply><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3"><minus id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.1"></minus><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.2">ğ‘›</ci><cn type="integer" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1"><minus id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.1"></minus><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.2">ğ‘ƒ</ci><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.2.3">ğ‘›</ci></apply><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.2">ğ‘ƒ</ci><apply id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3"><minus id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.1"></minus><ci id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.2">ğ‘›</ci><cn type="integer" id="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.1.1.1.2.1.1.3.3.3">1</cn></apply></apply></apply></apply></apply><cn type="integer" id="S4.SS3.p1.8.m8.1.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.8.m8.1c">\mathcal{L}_{v}=||(\hat{P}_{n}-\hat{P}_{n-1})-(P_{n}-P_{n-1})||_{2}</annotation></semantics></math>. <math id="S4.SS3.p1.9.m9.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS3.p1.9.m9.1a"><mi id="S4.SS3.p1.9.m9.1.1" xref="S4.SS3.p1.9.m9.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m9.1b"><ci id="S4.SS3.p1.9.m9.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.9.m9.1c">n</annotation></semantics></math> denotes the <math id="S4.SS3.p1.10.m10.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS3.p1.10.m10.1a"><mi id="S4.SS3.p1.10.m10.1.1" xref="S4.SS3.p1.10.m10.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.10.m10.1b"><ci id="S4.SS3.p1.10.m10.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.10.m10.1c">n</annotation></semantics></math>-th frame in a motion sequence. Specifically, our model is trained by subject <span id="S4.SS3.p1.11.1" class="ltx_text ltx_font_typewriter">1467634</span> and subject <span id="S4.SS3.p1.11.2" class="ltx_text ltx_font_typewriter">66685747</span>, which have the similar piano keyboard layout. At the second stage, the parameters of position predictor are frozen, and the estimated positions are employed as a guidance for the gesture generator. As inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, the denoising process is modified from noise prediction to velocity prediction. During the whole training process, the parameters of audio feature extractor <math id="S4.SS3.p1.11.m11.1" class="ltx_Math" alttext="\Phi_{a}" display="inline"><semantics id="S4.SS3.p1.11.m11.1a"><msub id="S4.SS3.p1.11.m11.1.1" xref="S4.SS3.p1.11.m11.1.1.cmml"><mi mathvariant="normal" id="S4.SS3.p1.11.m11.1.1.2" xref="S4.SS3.p1.11.m11.1.1.2.cmml">Î¦</mi><mi id="S4.SS3.p1.11.m11.1.1.3" xref="S4.SS3.p1.11.m11.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.11.m11.1b"><apply id="S4.SS3.p1.11.m11.1.1.cmml" xref="S4.SS3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.11.m11.1.1.1.cmml" xref="S4.SS3.p1.11.m11.1.1">subscript</csymbol><ci id="S4.SS3.p1.11.m11.1.1.2.cmml" xref="S4.SS3.p1.11.m11.1.1.2">Î¦</ci><ci id="S4.SS3.p1.11.m11.1.1.3.cmml" xref="S4.SS3.p1.11.m11.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.11.m11.1c">\Phi_{a}</annotation></semantics></math> are frozen.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.3" class="ltx_p">The baseline model is implemented with PyTorch. We normalize the inputs into 30 FPS through interpolation, where each piece of music lasts 8 seconds. Both stages involve training for <math id="S4.SS3.p2.1.m1.2" class="ltx_Math" alttext="100,000" display="inline"><semantics id="S4.SS3.p2.1.m1.2a"><mrow id="S4.SS3.p2.1.m1.2.3.2" xref="S4.SS3.p2.1.m1.2.3.1.cmml"><mn id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">100</mn><mo id="S4.SS3.p2.1.m1.2.3.2.1" xref="S4.SS3.p2.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS3.p2.1.m1.2.2" xref="S4.SS3.p2.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.2b"><list id="S4.SS3.p2.1.m1.2.3.1.cmml" xref="S4.SS3.p2.1.m1.2.3.2"><cn type="integer" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">100</cn><cn type="integer" id="S4.SS3.p2.1.m1.2.2.cmml" xref="S4.SS3.p2.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.2c">100,000</annotation></semantics></math> iterations at the learning rates of <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="2e^{-5}" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mn id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p2.2.m2.1.1.1" xref="S4.SS3.p2.2.m2.1.1.1.cmml">â€‹</mo><msup id="S4.SS3.p2.2.m2.1.1.3" xref="S4.SS3.p2.2.m2.1.1.3.cmml"><mi id="S4.SS3.p2.2.m2.1.1.3.2" xref="S4.SS3.p2.2.m2.1.1.3.2.cmml">e</mi><mrow id="S4.SS3.p2.2.m2.1.1.3.3" xref="S4.SS3.p2.2.m2.1.1.3.3.cmml"><mo id="S4.SS3.p2.2.m2.1.1.3.3a" xref="S4.SS3.p2.2.m2.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS3.p2.2.m2.1.1.3.3.2" xref="S4.SS3.p2.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><times id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1.1"></times><cn type="integer" id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">2</cn><apply id="S4.SS3.p2.2.m2.1.1.3.cmml" xref="S4.SS3.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p2.2.m2.1.1.3.1.cmml" xref="S4.SS3.p2.2.m2.1.1.3">superscript</csymbol><ci id="S4.SS3.p2.2.m2.1.1.3.2.cmml" xref="S4.SS3.p2.2.m2.1.1.3.2">ğ‘’</ci><apply id="S4.SS3.p2.2.m2.1.1.3.3.cmml" xref="S4.SS3.p2.2.m2.1.1.3.3"><minus id="S4.SS3.p2.2.m2.1.1.3.3.1.cmml" xref="S4.SS3.p2.2.m2.1.1.3.3"></minus><cn type="integer" id="S4.SS3.p2.2.m2.1.1.3.3.2.cmml" xref="S4.SS3.p2.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">2e^{-5}</annotation></semantics></math> and <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="5e^{-5}" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mn id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">â€‹</mo><msup id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml"><mi id="S4.SS3.p2.3.m3.1.1.3.2" xref="S4.SS3.p2.3.m3.1.1.3.2.cmml">e</mi><mrow id="S4.SS3.p2.3.m3.1.1.3.3" xref="S4.SS3.p2.3.m3.1.1.3.3.cmml"><mo id="S4.SS3.p2.3.m3.1.1.3.3a" xref="S4.SS3.p2.3.m3.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS3.p2.3.m3.1.1.3.3.2" xref="S4.SS3.p2.3.m3.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><times id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1"></times><cn type="integer" id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">5</cn><apply id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p2.3.m3.1.1.3.1.cmml" xref="S4.SS3.p2.3.m3.1.1.3">superscript</csymbol><ci id="S4.SS3.p2.3.m3.1.1.3.2.cmml" xref="S4.SS3.p2.3.m3.1.1.3.2">ğ‘’</ci><apply id="S4.SS3.p2.3.m3.1.1.3.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3"><minus id="S4.SS3.p2.3.m3.1.1.3.3.1.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3"></minus><cn type="integer" id="S4.SS3.p2.3.m3.1.1.3.3.2.cmml" xref="S4.SS3.p2.3.m3.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">5e^{-5}</annotation></semantics></math>, respectively. We conducted all the experiments on a PC with single NVIDIA RTX 3090Ti GPU, which has 24GB of GPU RAM.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Benchmark</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation Metrics</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p id="S5.SS1.p1.1" class="ltx_p">To assess the performance of our proposed baseline, we employ several evaluation metrics to examine the effectiveness of hand poses generated by the input piano music, which are crucial in understanding the relationship between piano melody and its corresponding playing motions.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Frechet Inception Distance (FID).</span>
<span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_italic">Frechet Inception Distance</span> is introduced to measure the Frechet distance between the feature vectors of prediction and ground truth. We pre-train an auto-encoderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> to project motion sequence onto a latent space for double hands. The FID is adopted to assess the fidelity of the overall motions generated by our baseline model.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_bold">Frechet Gesture Distance (FGD).</span> Unlike FID, <span id="S5.SS1.p3.1.2" class="ltx_text ltx_font_italic">Frechet Gesture Distance</span> is utilized to compute the disparity between predicted gestures and ground truth of one hand. This metric is instrumental in evaluating the similarity of single hand gestures.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para ltx_noindent">
<p id="S5.SS1.p4.8" class="ltx_p"><span id="S5.SS1.p4.8.1" class="ltx_text ltx_font_bold">Wasserstein Gesture Distance (WGD).</span> <span id="S5.SS1.p4.8.2" class="ltx_text ltx_font_italic">Wasserstein Gesture Distance</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> is computed between two distributions, each of which is represented as a Gaussian Mixture Model (GMM)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> as below</p>
<table id="S5.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E3.m1.5" class="ltx_Math" alttext="W(\mathcal{I}_{x},\mathcal{I}_{y})=\inf_{\gamma\sim\Pi(\mathcal{I}_{x},\mathcal{I}_{y})}\mathbb{E}_{(x,y)\sim\gamma}\left[\|x-y\|\right]," display="block"><semantics id="S5.E3.m1.5a"><mrow id="S5.E3.m1.5.5.1" xref="S5.E3.m1.5.5.1.1.cmml"><mrow id="S5.E3.m1.5.5.1.1" xref="S5.E3.m1.5.5.1.1.cmml"><mrow id="S5.E3.m1.5.5.1.1.2" xref="S5.E3.m1.5.5.1.1.2.cmml"><mi id="S5.E3.m1.5.5.1.1.2.4" xref="S5.E3.m1.5.5.1.1.2.4.cmml">W</mi><mo lspace="0em" rspace="0em" id="S5.E3.m1.5.5.1.1.2.3" xref="S5.E3.m1.5.5.1.1.2.3.cmml">â€‹</mo><mrow id="S5.E3.m1.5.5.1.1.2.2.2" xref="S5.E3.m1.5.5.1.1.2.2.3.cmml"><mo stretchy="false" id="S5.E3.m1.5.5.1.1.2.2.2.3" xref="S5.E3.m1.5.5.1.1.2.2.3.cmml">(</mo><msub id="S5.E3.m1.5.5.1.1.1.1.1.1" xref="S5.E3.m1.5.5.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E3.m1.5.5.1.1.1.1.1.1.2" xref="S5.E3.m1.5.5.1.1.1.1.1.1.2.cmml">â„</mi><mi id="S5.E3.m1.5.5.1.1.1.1.1.1.3" xref="S5.E3.m1.5.5.1.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S5.E3.m1.5.5.1.1.2.2.2.4" xref="S5.E3.m1.5.5.1.1.2.2.3.cmml">,</mo><msub id="S5.E3.m1.5.5.1.1.2.2.2.2" xref="S5.E3.m1.5.5.1.1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E3.m1.5.5.1.1.2.2.2.2.2" xref="S5.E3.m1.5.5.1.1.2.2.2.2.2.cmml">â„</mi><mi id="S5.E3.m1.5.5.1.1.2.2.2.2.3" xref="S5.E3.m1.5.5.1.1.2.2.2.2.3.cmml">y</mi></msub><mo stretchy="false" id="S5.E3.m1.5.5.1.1.2.2.2.5" xref="S5.E3.m1.5.5.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo rspace="0.1389em" id="S5.E3.m1.5.5.1.1.4" xref="S5.E3.m1.5.5.1.1.4.cmml">=</mo><mrow id="S5.E3.m1.5.5.1.1.3" xref="S5.E3.m1.5.5.1.1.3.cmml"><munder id="S5.E3.m1.5.5.1.1.3.2" xref="S5.E3.m1.5.5.1.1.3.2.cmml"><mo lspace="0.1389em" movablelimits="false" rspace="0.167em" id="S5.E3.m1.5.5.1.1.3.2.2" xref="S5.E3.m1.5.5.1.1.3.2.2.cmml">inf</mo><mrow id="S5.E3.m1.2.2.2" xref="S5.E3.m1.2.2.2.cmml"><mi id="S5.E3.m1.2.2.2.4" xref="S5.E3.m1.2.2.2.4.cmml">Î³</mi><mo id="S5.E3.m1.2.2.2.3" xref="S5.E3.m1.2.2.2.3.cmml">âˆ¼</mo><mrow id="S5.E3.m1.2.2.2.2" xref="S5.E3.m1.2.2.2.2.cmml"><mi mathvariant="normal" id="S5.E3.m1.2.2.2.2.4" xref="S5.E3.m1.2.2.2.2.4.cmml">Î </mi><mo lspace="0em" rspace="0em" id="S5.E3.m1.2.2.2.2.3" xref="S5.E3.m1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S5.E3.m1.2.2.2.2.2.2" xref="S5.E3.m1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S5.E3.m1.2.2.2.2.2.2.3" xref="S5.E3.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S5.E3.m1.1.1.1.1.1.1.1" xref="S5.E3.m1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E3.m1.1.1.1.1.1.1.1.2" xref="S5.E3.m1.1.1.1.1.1.1.1.2.cmml">â„</mi><mi id="S5.E3.m1.1.1.1.1.1.1.1.3" xref="S5.E3.m1.1.1.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S5.E3.m1.2.2.2.2.2.2.4" xref="S5.E3.m1.2.2.2.2.2.3.cmml">,</mo><msub id="S5.E3.m1.2.2.2.2.2.2.2" xref="S5.E3.m1.2.2.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E3.m1.2.2.2.2.2.2.2.2" xref="S5.E3.m1.2.2.2.2.2.2.2.2.cmml">â„</mi><mi id="S5.E3.m1.2.2.2.2.2.2.2.3" xref="S5.E3.m1.2.2.2.2.2.2.2.3.cmml">y</mi></msub><mo stretchy="false" id="S5.E3.m1.2.2.2.2.2.2.5" xref="S5.E3.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></munder><mrow id="S5.E3.m1.5.5.1.1.3.1" xref="S5.E3.m1.5.5.1.1.3.1.cmml"><msub id="S5.E3.m1.5.5.1.1.3.1.3" xref="S5.E3.m1.5.5.1.1.3.1.3.cmml"><mi id="S5.E3.m1.5.5.1.1.3.1.3.2" xref="S5.E3.m1.5.5.1.1.3.1.3.2.cmml">ğ”¼</mi><mrow id="S5.E3.m1.4.4.2" xref="S5.E3.m1.4.4.2.cmml"><mrow id="S5.E3.m1.4.4.2.4.2" xref="S5.E3.m1.4.4.2.4.1.cmml"><mo stretchy="false" id="S5.E3.m1.4.4.2.4.2.1" xref="S5.E3.m1.4.4.2.4.1.cmml">(</mo><mi id="S5.E3.m1.3.3.1.1" xref="S5.E3.m1.3.3.1.1.cmml">x</mi><mo id="S5.E3.m1.4.4.2.4.2.2" xref="S5.E3.m1.4.4.2.4.1.cmml">,</mo><mi id="S5.E3.m1.4.4.2.2" xref="S5.E3.m1.4.4.2.2.cmml">y</mi><mo stretchy="false" id="S5.E3.m1.4.4.2.4.2.3" xref="S5.E3.m1.4.4.2.4.1.cmml">)</mo></mrow><mo id="S5.E3.m1.4.4.2.3" xref="S5.E3.m1.4.4.2.3.cmml">âˆ¼</mo><mi id="S5.E3.m1.4.4.2.5" xref="S5.E3.m1.4.4.2.5.cmml">Î³</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S5.E3.m1.5.5.1.1.3.1.2" xref="S5.E3.m1.5.5.1.1.3.1.2.cmml">â€‹</mo><mrow id="S5.E3.m1.5.5.1.1.3.1.1.1" xref="S5.E3.m1.5.5.1.1.3.1.1.2.cmml"><mo id="S5.E3.m1.5.5.1.1.3.1.1.1.2" xref="S5.E3.m1.5.5.1.1.3.1.1.2.1.cmml">[</mo><mrow id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.2" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.cmml"><mi id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.2" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.2.cmml">x</mi><mo id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.1" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.3" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.3" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.2.1.cmml">â€–</mo></mrow><mo id="S5.E3.m1.5.5.1.1.3.1.1.1.3" xref="S5.E3.m1.5.5.1.1.3.1.1.2.1.cmml">]</mo></mrow></mrow></mrow></mrow><mo id="S5.E3.m1.5.5.1.2" xref="S5.E3.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E3.m1.5b"><apply id="S5.E3.m1.5.5.1.1.cmml" xref="S5.E3.m1.5.5.1"><eq id="S5.E3.m1.5.5.1.1.4.cmml" xref="S5.E3.m1.5.5.1.1.4"></eq><apply id="S5.E3.m1.5.5.1.1.2.cmml" xref="S5.E3.m1.5.5.1.1.2"><times id="S5.E3.m1.5.5.1.1.2.3.cmml" xref="S5.E3.m1.5.5.1.1.2.3"></times><ci id="S5.E3.m1.5.5.1.1.2.4.cmml" xref="S5.E3.m1.5.5.1.1.2.4">ğ‘Š</ci><interval closure="open" id="S5.E3.m1.5.5.1.1.2.2.3.cmml" xref="S5.E3.m1.5.5.1.1.2.2.2"><apply id="S5.E3.m1.5.5.1.1.1.1.1.1.cmml" xref="S5.E3.m1.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E3.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.5.5.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E3.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S5.E3.m1.5.5.1.1.1.1.1.1.2">â„</ci><ci id="S5.E3.m1.5.5.1.1.1.1.1.1.3.cmml" xref="S5.E3.m1.5.5.1.1.1.1.1.1.3">ğ‘¥</ci></apply><apply id="S5.E3.m1.5.5.1.1.2.2.2.2.cmml" xref="S5.E3.m1.5.5.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S5.E3.m1.5.5.1.1.2.2.2.2.1.cmml" xref="S5.E3.m1.5.5.1.1.2.2.2.2">subscript</csymbol><ci id="S5.E3.m1.5.5.1.1.2.2.2.2.2.cmml" xref="S5.E3.m1.5.5.1.1.2.2.2.2.2">â„</ci><ci id="S5.E3.m1.5.5.1.1.2.2.2.2.3.cmml" xref="S5.E3.m1.5.5.1.1.2.2.2.2.3">ğ‘¦</ci></apply></interval></apply><apply id="S5.E3.m1.5.5.1.1.3.cmml" xref="S5.E3.m1.5.5.1.1.3"><apply id="S5.E3.m1.5.5.1.1.3.2.cmml" xref="S5.E3.m1.5.5.1.1.3.2"><csymbol cd="ambiguous" id="S5.E3.m1.5.5.1.1.3.2.1.cmml" xref="S5.E3.m1.5.5.1.1.3.2">subscript</csymbol><csymbol cd="latexml" id="S5.E3.m1.5.5.1.1.3.2.2.cmml" xref="S5.E3.m1.5.5.1.1.3.2.2">infimum</csymbol><apply id="S5.E3.m1.2.2.2.cmml" xref="S5.E3.m1.2.2.2"><csymbol cd="latexml" id="S5.E3.m1.2.2.2.3.cmml" xref="S5.E3.m1.2.2.2.3">similar-to</csymbol><ci id="S5.E3.m1.2.2.2.4.cmml" xref="S5.E3.m1.2.2.2.4">ğ›¾</ci><apply id="S5.E3.m1.2.2.2.2.cmml" xref="S5.E3.m1.2.2.2.2"><times id="S5.E3.m1.2.2.2.2.3.cmml" xref="S5.E3.m1.2.2.2.2.3"></times><ci id="S5.E3.m1.2.2.2.2.4.cmml" xref="S5.E3.m1.2.2.2.2.4">Î </ci><interval closure="open" id="S5.E3.m1.2.2.2.2.2.3.cmml" xref="S5.E3.m1.2.2.2.2.2.2"><apply id="S5.E3.m1.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.2">â„</ci><ci id="S5.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E3.m1.1.1.1.1.1.1.1.3">ğ‘¥</ci></apply><apply id="S5.E3.m1.2.2.2.2.2.2.2.cmml" xref="S5.E3.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.E3.m1.2.2.2.2.2.2.2.1.cmml" xref="S5.E3.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S5.E3.m1.2.2.2.2.2.2.2.2.cmml" xref="S5.E3.m1.2.2.2.2.2.2.2.2">â„</ci><ci id="S5.E3.m1.2.2.2.2.2.2.2.3.cmml" xref="S5.E3.m1.2.2.2.2.2.2.2.3">ğ‘¦</ci></apply></interval></apply></apply></apply><apply id="S5.E3.m1.5.5.1.1.3.1.cmml" xref="S5.E3.m1.5.5.1.1.3.1"><times id="S5.E3.m1.5.5.1.1.3.1.2.cmml" xref="S5.E3.m1.5.5.1.1.3.1.2"></times><apply id="S5.E3.m1.5.5.1.1.3.1.3.cmml" xref="S5.E3.m1.5.5.1.1.3.1.3"><csymbol cd="ambiguous" id="S5.E3.m1.5.5.1.1.3.1.3.1.cmml" xref="S5.E3.m1.5.5.1.1.3.1.3">subscript</csymbol><ci id="S5.E3.m1.5.5.1.1.3.1.3.2.cmml" xref="S5.E3.m1.5.5.1.1.3.1.3.2">ğ”¼</ci><apply id="S5.E3.m1.4.4.2.cmml" xref="S5.E3.m1.4.4.2"><csymbol cd="latexml" id="S5.E3.m1.4.4.2.3.cmml" xref="S5.E3.m1.4.4.2.3">similar-to</csymbol><interval closure="open" id="S5.E3.m1.4.4.2.4.1.cmml" xref="S5.E3.m1.4.4.2.4.2"><ci id="S5.E3.m1.3.3.1.1.cmml" xref="S5.E3.m1.3.3.1.1">ğ‘¥</ci><ci id="S5.E3.m1.4.4.2.2.cmml" xref="S5.E3.m1.4.4.2.2">ğ‘¦</ci></interval><ci id="S5.E3.m1.4.4.2.5.cmml" xref="S5.E3.m1.4.4.2.5">ğ›¾</ci></apply></apply><apply id="S5.E3.m1.5.5.1.1.3.1.1.2.cmml" xref="S5.E3.m1.5.5.1.1.3.1.1.1"><csymbol cd="latexml" id="S5.E3.m1.5.5.1.1.3.1.1.2.1.cmml" xref="S5.E3.m1.5.5.1.1.3.1.1.1.2">delimited-[]</csymbol><apply id="S5.E3.m1.5.5.1.1.3.1.1.1.1.2.cmml" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1"><csymbol cd="latexml" id="S5.E3.m1.5.5.1.1.3.1.1.1.1.2.1.cmml" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.2">norm</csymbol><apply id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.cmml" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1"><minus id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.1"></minus><ci id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.2.cmml" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.3.cmml" xref="S5.E3.m1.5.5.1.1.3.1.1.1.1.1.1.3">ğ‘¦</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E3.m1.5c">W(\mathcal{I}_{x},\mathcal{I}_{y})=\inf_{\gamma\sim\Pi(\mathcal{I}_{x},\mathcal{I}_{y})}\mathbb{E}_{(x,y)\sim\gamma}\left[\|x-y\|\right],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S5.SS1.p4.7" class="ltx_p">where <math id="S5.SS1.p4.1.m1.2" class="ltx_Math" alttext="\Pi(\mathcal{I}_{x},\mathcal{I}_{y})" display="inline"><semantics id="S5.SS1.p4.1.m1.2a"><mrow id="S5.SS1.p4.1.m1.2.2" xref="S5.SS1.p4.1.m1.2.2.cmml"><mi mathvariant="normal" id="S5.SS1.p4.1.m1.2.2.4" xref="S5.SS1.p4.1.m1.2.2.4.cmml">Î </mi><mo lspace="0em" rspace="0em" id="S5.SS1.p4.1.m1.2.2.3" xref="S5.SS1.p4.1.m1.2.2.3.cmml">â€‹</mo><mrow id="S5.SS1.p4.1.m1.2.2.2.2" xref="S5.SS1.p4.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S5.SS1.p4.1.m1.2.2.2.2.3" xref="S5.SS1.p4.1.m1.2.2.2.3.cmml">(</mo><msub id="S5.SS1.p4.1.m1.1.1.1.1.1" xref="S5.SS1.p4.1.m1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p4.1.m1.1.1.1.1.1.2" xref="S5.SS1.p4.1.m1.1.1.1.1.1.2.cmml">â„</mi><mi id="S5.SS1.p4.1.m1.1.1.1.1.1.3" xref="S5.SS1.p4.1.m1.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S5.SS1.p4.1.m1.2.2.2.2.4" xref="S5.SS1.p4.1.m1.2.2.2.3.cmml">,</mo><msub id="S5.SS1.p4.1.m1.2.2.2.2.2" xref="S5.SS1.p4.1.m1.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p4.1.m1.2.2.2.2.2.2" xref="S5.SS1.p4.1.m1.2.2.2.2.2.2.cmml">â„</mi><mi id="S5.SS1.p4.1.m1.2.2.2.2.2.3" xref="S5.SS1.p4.1.m1.2.2.2.2.2.3.cmml">y</mi></msub><mo stretchy="false" id="S5.SS1.p4.1.m1.2.2.2.2.5" xref="S5.SS1.p4.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.1.m1.2b"><apply id="S5.SS1.p4.1.m1.2.2.cmml" xref="S5.SS1.p4.1.m1.2.2"><times id="S5.SS1.p4.1.m1.2.2.3.cmml" xref="S5.SS1.p4.1.m1.2.2.3"></times><ci id="S5.SS1.p4.1.m1.2.2.4.cmml" xref="S5.SS1.p4.1.m1.2.2.4">Î </ci><interval closure="open" id="S5.SS1.p4.1.m1.2.2.2.3.cmml" xref="S5.SS1.p4.1.m1.2.2.2.2"><apply id="S5.SS1.p4.1.m1.1.1.1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS1.p4.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S5.SS1.p4.1.m1.1.1.1.1.1.2.cmml" xref="S5.SS1.p4.1.m1.1.1.1.1.1.2">â„</ci><ci id="S5.SS1.p4.1.m1.1.1.1.1.1.3.cmml" xref="S5.SS1.p4.1.m1.1.1.1.1.1.3">ğ‘¥</ci></apply><apply id="S5.SS1.p4.1.m1.2.2.2.2.2.cmml" xref="S5.SS1.p4.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS1.p4.1.m1.2.2.2.2.2.1.cmml" xref="S5.SS1.p4.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S5.SS1.p4.1.m1.2.2.2.2.2.2.cmml" xref="S5.SS1.p4.1.m1.2.2.2.2.2.2">â„</ci><ci id="S5.SS1.p4.1.m1.2.2.2.2.2.3.cmml" xref="S5.SS1.p4.1.m1.2.2.2.2.2.3">ğ‘¦</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.1.m1.2c">\Pi(\mathcal{I}_{x},\mathcal{I}_{y})</annotation></semantics></math> indicates the joint distributions that combine the parametric GMM distributions <math id="S5.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{I}_{x}" display="inline"><semantics id="S5.SS1.p4.2.m2.1a"><msub id="S5.SS1.p4.2.m2.1.1" xref="S5.SS1.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p4.2.m2.1.1.2" xref="S5.SS1.p4.2.m2.1.1.2.cmml">â„</mi><mi id="S5.SS1.p4.2.m2.1.1.3" xref="S5.SS1.p4.2.m2.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.2.m2.1b"><apply id="S5.SS1.p4.2.m2.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.2.m2.1.1.1.cmml" xref="S5.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p4.2.m2.1.1.2.cmml" xref="S5.SS1.p4.2.m2.1.1.2">â„</ci><ci id="S5.SS1.p4.2.m2.1.1.3.cmml" xref="S5.SS1.p4.2.m2.1.1.3">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.2.m2.1c">\mathcal{I}_{x}</annotation></semantics></math> and <math id="S5.SS1.p4.3.m3.1" class="ltx_Math" alttext="\mathcal{I}_{y}" display="inline"><semantics id="S5.SS1.p4.3.m3.1a"><msub id="S5.SS1.p4.3.m3.1.1" xref="S5.SS1.p4.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p4.3.m3.1.1.2" xref="S5.SS1.p4.3.m3.1.1.2.cmml">â„</mi><mi id="S5.SS1.p4.3.m3.1.1.3" xref="S5.SS1.p4.3.m3.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.3.m3.1b"><apply id="S5.SS1.p4.3.m3.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.3.m3.1.1.1.cmml" xref="S5.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S5.SS1.p4.3.m3.1.1.2.cmml" xref="S5.SS1.p4.3.m3.1.1.2">â„</ci><ci id="S5.SS1.p4.3.m3.1.1.3.cmml" xref="S5.SS1.p4.3.m3.1.1.3">ğ‘¦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.3.m3.1c">\mathcal{I}_{y}</annotation></semantics></math>. Distributions <math id="S5.SS1.p4.4.m4.1" class="ltx_Math" alttext="\mathcal{I}_{x}" display="inline"><semantics id="S5.SS1.p4.4.m4.1a"><msub id="S5.SS1.p4.4.m4.1.1" xref="S5.SS1.p4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p4.4.m4.1.1.2" xref="S5.SS1.p4.4.m4.1.1.2.cmml">â„</mi><mi id="S5.SS1.p4.4.m4.1.1.3" xref="S5.SS1.p4.4.m4.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.4.m4.1b"><apply id="S5.SS1.p4.4.m4.1.1.cmml" xref="S5.SS1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.4.m4.1.1.1.cmml" xref="S5.SS1.p4.4.m4.1.1">subscript</csymbol><ci id="S5.SS1.p4.4.m4.1.1.2.cmml" xref="S5.SS1.p4.4.m4.1.1.2">â„</ci><ci id="S5.SS1.p4.4.m4.1.1.3.cmml" xref="S5.SS1.p4.4.m4.1.1.3">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.4.m4.1c">\mathcal{I}_{x}</annotation></semantics></math> and <math id="S5.SS1.p4.5.m5.1" class="ltx_Math" alttext="\mathcal{I}_{y}" display="inline"><semantics id="S5.SS1.p4.5.m5.1a"><msub id="S5.SS1.p4.5.m5.1.1" xref="S5.SS1.p4.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS1.p4.5.m5.1.1.2" xref="S5.SS1.p4.5.m5.1.1.2.cmml">â„</mi><mi id="S5.SS1.p4.5.m5.1.1.3" xref="S5.SS1.p4.5.m5.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.5.m5.1b"><apply id="S5.SS1.p4.5.m5.1.1.cmml" xref="S5.SS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p4.5.m5.1.1.1.cmml" xref="S5.SS1.p4.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.p4.5.m5.1.1.2.cmml" xref="S5.SS1.p4.5.m5.1.1.2">â„</ci><ci id="S5.SS1.p4.5.m5.1.1.3.cmml" xref="S5.SS1.p4.5.m5.1.1.3">ğ‘¦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.5.m5.1c">\mathcal{I}_{y}</annotation></semantics></math> are fitted by predicted gestures and ground truth of single hand. <math id="S5.SS1.p4.6.m6.1" class="ltx_Math" alttext="\mathbb{E}" display="inline"><semantics id="S5.SS1.p4.6.m6.1a"><mi id="S5.SS1.p4.6.m6.1.1" xref="S5.SS1.p4.6.m6.1.1.cmml">ğ”¼</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.6.m6.1b"><ci id="S5.SS1.p4.6.m6.1.1.cmml" xref="S5.SS1.p4.6.m6.1.1">ğ”¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.6.m6.1c">\mathbb{E}</annotation></semantics></math> calculates the expectation of the sample pairs <math id="S5.SS1.p4.7.m7.2" class="ltx_Math" alttext="(x,y)" display="inline"><semantics id="S5.SS1.p4.7.m7.2a"><mrow id="S5.SS1.p4.7.m7.2.3.2" xref="S5.SS1.p4.7.m7.2.3.1.cmml"><mo stretchy="false" id="S5.SS1.p4.7.m7.2.3.2.1" xref="S5.SS1.p4.7.m7.2.3.1.cmml">(</mo><mi id="S5.SS1.p4.7.m7.1.1" xref="S5.SS1.p4.7.m7.1.1.cmml">x</mi><mo id="S5.SS1.p4.7.m7.2.3.2.2" xref="S5.SS1.p4.7.m7.2.3.1.cmml">,</mo><mi id="S5.SS1.p4.7.m7.2.2" xref="S5.SS1.p4.7.m7.2.2.cmml">y</mi><mo stretchy="false" id="S5.SS1.p4.7.m7.2.3.2.3" xref="S5.SS1.p4.7.m7.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p4.7.m7.2b"><interval closure="open" id="S5.SS1.p4.7.m7.2.3.1.cmml" xref="S5.SS1.p4.7.m7.2.3.2"><ci id="S5.SS1.p4.7.m7.1.1.cmml" xref="S5.SS1.p4.7.m7.1.1">ğ‘¥</ci><ci id="S5.SS1.p4.7.m7.2.2.cmml" xref="S5.SS1.p4.7.m7.2.2">ğ‘¦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p4.7.m7.2c">(x,y)</annotation></semantics></math>. The WGD metric offers a robust measure of dissimilarity between the generated motion and ground truth.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para ltx_noindent">
<p id="S5.SS1.p5.1" class="ltx_p"><span id="S5.SS1.p5.1.1" class="ltx_text ltx_font_bold">Position Distance (PD).</span> The <span id="S5.SS1.p5.1.2" class="ltx_text ltx_font_italic">Position Distance</span> calculates the <math id="S5.SS1.p5.1.m1.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S5.SS1.p5.1.m1.1a"><msub id="S5.SS1.p5.1.m1.1.1" xref="S5.SS1.p5.1.m1.1.1.cmml"><mi id="S5.SS1.p5.1.m1.1.1.2" xref="S5.SS1.p5.1.m1.1.1.2.cmml">L</mi><mn id="S5.SS1.p5.1.m1.1.1.3" xref="S5.SS1.p5.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p5.1.m1.1b"><apply id="S5.SS1.p5.1.m1.1.1.cmml" xref="S5.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p5.1.m1.1.1.1.cmml" xref="S5.SS1.p5.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p5.1.m1.1.1.2.cmml" xref="S5.SS1.p5.1.m1.1.1.2">ğ¿</ci><cn type="integer" id="S5.SS1.p5.1.m1.1.1.3.cmml" xref="S5.SS1.p5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p5.1.m1.1c">L_{2}</annotation></semantics></math> distance between estimated positions and the ground truth. It is essential to evaluate the precision of predicted hand positions to ensure the accuracy required for piano fingerings.</p>
</div>
<div id="S5.SS1.p6" class="ltx_para ltx_noindent">
<p id="S5.SS1.p6.3" class="ltx_p"><span id="S5.SS1.p6.3.1" class="ltx_text ltx_font_bold">Smoothness.</span> <span id="S5.SS1.p6.3.2" class="ltx_text ltx_font_italic">Smoothness</span> is measured by computing the acceleration of each joint. However, hands in a static state exhibit maximum smoothness, which are contrary to the desired outcome.
Consequently, we consider the acceleration of ground truth as a reference and utilize relative acceleration as the evaluation metric for smoothness, which is formulated as <math id="S5.SS1.p6.1.m1.1" class="ltx_Math" alttext="Smooth=\sum_{i}|\hat{\tau_{i}}-\tau_{i}|" display="inline"><semantics id="S5.SS1.p6.1.m1.1a"><mrow id="S5.SS1.p6.1.m1.1.1" xref="S5.SS1.p6.1.m1.1.1.cmml"><mrow id="S5.SS1.p6.1.m1.1.1.3" xref="S5.SS1.p6.1.m1.1.1.3.cmml"><mi id="S5.SS1.p6.1.m1.1.1.3.2" xref="S5.SS1.p6.1.m1.1.1.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p6.1.m1.1.1.3.1" xref="S5.SS1.p6.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS1.p6.1.m1.1.1.3.3" xref="S5.SS1.p6.1.m1.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p6.1.m1.1.1.3.1a" xref="S5.SS1.p6.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS1.p6.1.m1.1.1.3.4" xref="S5.SS1.p6.1.m1.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p6.1.m1.1.1.3.1b" xref="S5.SS1.p6.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS1.p6.1.m1.1.1.3.5" xref="S5.SS1.p6.1.m1.1.1.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p6.1.m1.1.1.3.1c" xref="S5.SS1.p6.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS1.p6.1.m1.1.1.3.6" xref="S5.SS1.p6.1.m1.1.1.3.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.SS1.p6.1.m1.1.1.3.1d" xref="S5.SS1.p6.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.SS1.p6.1.m1.1.1.3.7" xref="S5.SS1.p6.1.m1.1.1.3.7.cmml">h</mi></mrow><mo rspace="0.111em" id="S5.SS1.p6.1.m1.1.1.2" xref="S5.SS1.p6.1.m1.1.1.2.cmml">=</mo><mrow id="S5.SS1.p6.1.m1.1.1.1" xref="S5.SS1.p6.1.m1.1.1.1.cmml"><msub id="S5.SS1.p6.1.m1.1.1.1.2" xref="S5.SS1.p6.1.m1.1.1.1.2.cmml"><mo rspace="0em" id="S5.SS1.p6.1.m1.1.1.1.2.2" xref="S5.SS1.p6.1.m1.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S5.SS1.p6.1.m1.1.1.1.2.3" xref="S5.SS1.p6.1.m1.1.1.1.2.3.cmml">i</mi></msub><mrow id="S5.SS1.p6.1.m1.1.1.1.1.1" xref="S5.SS1.p6.1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.SS1.p6.1.m1.1.1.1.1.1.2" xref="S5.SS1.p6.1.m1.1.1.1.1.2.1.cmml">|</mo><mrow id="S5.SS1.p6.1.m1.1.1.1.1.1.1" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.cmml"><mover accent="true" id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.cmml"><msub id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.2" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.2.cmml">Ï„</mi><mi id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.3" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.1" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S5.SS1.p6.1.m1.1.1.1.1.1.1.1" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S5.SS1.p6.1.m1.1.1.1.1.1.1.3" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.cmml"><mi id="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.2" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.2.cmml">Ï„</mi><mi id="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.3" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S5.SS1.p6.1.m1.1.1.1.1.1.3" xref="S5.SS1.p6.1.m1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.1.m1.1b"><apply id="S5.SS1.p6.1.m1.1.1.cmml" xref="S5.SS1.p6.1.m1.1.1"><eq id="S5.SS1.p6.1.m1.1.1.2.cmml" xref="S5.SS1.p6.1.m1.1.1.2"></eq><apply id="S5.SS1.p6.1.m1.1.1.3.cmml" xref="S5.SS1.p6.1.m1.1.1.3"><times id="S5.SS1.p6.1.m1.1.1.3.1.cmml" xref="S5.SS1.p6.1.m1.1.1.3.1"></times><ci id="S5.SS1.p6.1.m1.1.1.3.2.cmml" xref="S5.SS1.p6.1.m1.1.1.3.2">ğ‘†</ci><ci id="S5.SS1.p6.1.m1.1.1.3.3.cmml" xref="S5.SS1.p6.1.m1.1.1.3.3">ğ‘š</ci><ci id="S5.SS1.p6.1.m1.1.1.3.4.cmml" xref="S5.SS1.p6.1.m1.1.1.3.4">ğ‘œ</ci><ci id="S5.SS1.p6.1.m1.1.1.3.5.cmml" xref="S5.SS1.p6.1.m1.1.1.3.5">ğ‘œ</ci><ci id="S5.SS1.p6.1.m1.1.1.3.6.cmml" xref="S5.SS1.p6.1.m1.1.1.3.6">ğ‘¡</ci><ci id="S5.SS1.p6.1.m1.1.1.3.7.cmml" xref="S5.SS1.p6.1.m1.1.1.3.7">â„</ci></apply><apply id="S5.SS1.p6.1.m1.1.1.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1"><apply id="S5.SS1.p6.1.m1.1.1.1.2.cmml" xref="S5.SS1.p6.1.m1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p6.1.m1.1.1.1.2.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1.2">subscript</csymbol><sum id="S5.SS1.p6.1.m1.1.1.1.2.2.cmml" xref="S5.SS1.p6.1.m1.1.1.1.2.2"></sum><ci id="S5.SS1.p6.1.m1.1.1.1.2.3.cmml" xref="S5.SS1.p6.1.m1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S5.SS1.p6.1.m1.1.1.1.1.2.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1"><abs id="S5.SS1.p6.1.m1.1.1.1.1.2.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.2"></abs><apply id="S5.SS1.p6.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1"><minus id="S5.SS1.p6.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.1"></minus><apply id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2"><ci id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.1">^</ci><apply id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.2">ğœ</ci><ci id="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.2.2.3">ğ‘–</ci></apply></apply><apply id="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.2">ğœ</ci><ci id="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S5.SS1.p6.1.m1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.1.m1.1c">Smooth=\sum_{i}|\hat{\tau_{i}}-\tau_{i}|</annotation></semantics></math>. <math id="S5.SS1.p6.2.m2.1" class="ltx_Math" alttext="\tau_{i}" display="inline"><semantics id="S5.SS1.p6.2.m2.1a"><msub id="S5.SS1.p6.2.m2.1.1" xref="S5.SS1.p6.2.m2.1.1.cmml"><mi id="S5.SS1.p6.2.m2.1.1.2" xref="S5.SS1.p6.2.m2.1.1.2.cmml">Ï„</mi><mi id="S5.SS1.p6.2.m2.1.1.3" xref="S5.SS1.p6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.2.m2.1b"><apply id="S5.SS1.p6.2.m2.1.1.cmml" xref="S5.SS1.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p6.2.m2.1.1.1.cmml" xref="S5.SS1.p6.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p6.2.m2.1.1.2.cmml" xref="S5.SS1.p6.2.m2.1.1.2">ğœ</ci><ci id="S5.SS1.p6.2.m2.1.1.3.cmml" xref="S5.SS1.p6.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.2.m2.1c">\tau_{i}</annotation></semantics></math> denotes the acceleration of the <math id="S5.SS1.p6.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.SS1.p6.3.m3.1a"><mi id="S5.SS1.p6.3.m3.1.1" xref="S5.SS1.p6.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p6.3.m3.1b"><ci id="S5.SS1.p6.3.m3.1.1.cmml" xref="S5.SS1.p6.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p6.3.m3.1c">i</annotation></semantics></math>-th joint.
It reflects the continuance and coherence of the estimated gestures.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Experiments</h3>

<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S5.T3.11.1" class="ltx_text ltx_font_bold">Quantitative evaluation</span> of our proposed hand motion generation baseline and existing models on the validation set. We present a comparative analysis of various network architectures, highlighting the performance and efficiency of our baselines in generating hand motion.</figcaption>
<div id="S5.T3.9" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:152.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-116.8pt,41.0pt) scale(0.64987383272026,0.64987383272026) ;">
<table id="S5.T3.9.9" class="ltx_tabular ltx_align_middle">
<tr id="S5.T3.1.1.1" class="ltx_tr">
<td id="S5.T3.1.1.1.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;" colspan="5">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">Â </span> Â Â Â Â  <span id="S5.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S5.T3.1.1.1.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Decoder</span></td>
<td id="S5.T3.1.1.1.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">Step</span></td>
<td id="S5.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;" colspan="4"><span id="S5.T3.1.1.1.5.1" class="ltx_text ltx_font_bold">Right Hand</span></td>
<td id="S5.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;" colspan="4"><span id="S5.T3.1.1.1.6.1" class="ltx_text ltx_font_bold">Left Hand</span></td>
<td id="S5.T3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S5.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">FID<math id="S5.T3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T3.1.1.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.1.1.m1.1b"><ci id="S5.T3.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.1.1.1.7" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S5.T3.1.1.1.7.1" class="ltx_text">
<span id="S5.T3.1.1.1.7.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.1.1.1.7.1.1.1" class="ltx_tr">
<span id="S5.T3.1.1.1.7.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.1.1.1.7.1.1.1.1.1" class="ltx_text ltx_font_bold">Params</span></span></span>
<span id="S5.T3.1.1.1.7.1.1.2" class="ltx_tr">
<span id="S5.T3.1.1.1.7.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.1.1.1.7.1.1.2.1.1" class="ltx_text ltx_font_bold">(M)</span></span></span>
</span></span></td>
</tr>
<tr id="S5.T3.9.9.9" class="ltx_tr">
<td id="S5.T3.9.9.9.9" class="ltx_td ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;" colspan="2"></td>
<td id="S5.T3.9.9.9.10" class="ltx_td ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.9.11" class="ltx_td ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.2.2.2.1.1" class="ltx_text ltx_font_bold">FGD<math id="S5.T3.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.2.2.2.1.1.m1.1a"><mo stretchy="false" id="S5.T3.2.2.2.1.1.m1.1.1" xref="S5.T3.2.2.2.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.1.1.m1.1b"><ci id="S5.T3.2.2.2.1.1.m1.1.1.cmml" xref="S5.T3.2.2.2.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.3.3.3.2.1" class="ltx_text ltx_font_bold">WGD<math id="S5.T3.3.3.3.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.3.3.3.2.1.m1.1a"><mo stretchy="false" id="S5.T3.3.3.3.2.1.m1.1.1" xref="S5.T3.3.3.3.2.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.2.1.m1.1b"><ci id="S5.T3.3.3.3.2.1.m1.1.1.cmml" xref="S5.T3.3.3.3.2.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.4.4.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.4.4.4.3.1" class="ltx_text ltx_font_bold">PD<math id="S5.T3.4.4.4.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.4.4.4.3.1.m1.1a"><mo stretchy="false" id="S5.T3.4.4.4.3.1.m1.1.1" xref="S5.T3.4.4.4.3.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.3.1.m1.1b"><ci id="S5.T3.4.4.4.3.1.m1.1.1.cmml" xref="S5.T3.4.4.4.3.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.3.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.5.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.5.5.5.4.1" class="ltx_text ltx_font_bold">Smooth<math id="S5.T3.5.5.5.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.5.5.5.4.1.m1.1a"><mo stretchy="false" id="S5.T3.5.5.5.4.1.m1.1.1" xref="S5.T3.5.5.5.4.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.5.4.1.m1.1b"><ci id="S5.T3.5.5.5.4.1.m1.1.1.cmml" xref="S5.T3.5.5.5.4.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.5.4.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.6.6.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.6.6.6.5.1" class="ltx_text ltx_font_bold">FGD<math id="S5.T3.6.6.6.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.6.6.6.5.1.m1.1a"><mo stretchy="false" id="S5.T3.6.6.6.5.1.m1.1.1" xref="S5.T3.6.6.6.5.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.6.5.1.m1.1b"><ci id="S5.T3.6.6.6.5.1.m1.1.1.cmml" xref="S5.T3.6.6.6.5.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.6.5.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.7.7.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.7.7.7.6.1" class="ltx_text ltx_font_bold">WGD<math id="S5.T3.7.7.7.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.7.7.7.6.1.m1.1a"><mo stretchy="false" id="S5.T3.7.7.7.6.1.m1.1.1" xref="S5.T3.7.7.7.6.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.7.6.1.m1.1b"><ci id="S5.T3.7.7.7.6.1.m1.1.1.cmml" xref="S5.T3.7.7.7.6.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.7.6.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.8.8.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.8.8.8.7.1" class="ltx_text ltx_font_bold">PD<math id="S5.T3.8.8.8.7.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.8.8.8.7.1.m1.1a"><mo stretchy="false" id="S5.T3.8.8.8.7.1.m1.1.1" xref="S5.T3.8.8.8.7.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.8.7.1.m1.1b"><ci id="S5.T3.8.8.8.7.1.m1.1.1.cmml" xref="S5.T3.8.8.8.7.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.8.7.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.9.9.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.9.8.1" class="ltx_text ltx_font_bold">Smooth<math id="S5.T3.9.9.9.8.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.9.9.9.8.1.m1.1a"><mo stretchy="false" id="S5.T3.9.9.9.8.1.m1.1.1" xref="S5.T3.9.9.9.8.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.9.8.1.m1.1b"><ci id="S5.T3.9.9.9.8.1.m1.1.1.cmml" xref="S5.T3.9.9.9.8.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.9.8.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.9.9.9.12" class="ltx_td ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.9.13" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.9.14" class="ltx_td ltx_nopad_r" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.10" class="ltx_tr">
<td id="S5.T3.9.9.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" colspan="2">EmoTalkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
<td id="S5.T3.9.9.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">TF</td>
<td id="S5.T3.9.9.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">-</td>
<td id="S5.T3.9.9.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.360</td>
<td id="S5.T3.9.9.10.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.259</td>
<td id="S5.T3.9.9.10.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.033</td>
<td id="S5.T3.9.9.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.313</td>
<td id="S5.T3.9.9.10.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.445</td>
<td id="S5.T3.9.9.10.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.232</td>
<td id="S5.T3.9.9.10.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.044</td>
<td id="S5.T3.9.9.10.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.353</td>
<td id="S5.T3.9.9.10.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">4.645</td>
<td id="S5.T3.9.9.10.13" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">308</td>
<td id="S5.T3.9.9.10.14" class="ltx_td ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.11" class="ltx_tr">
<td id="S5.T3.9.9.11.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;" colspan="2">LivelySpeakerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>
</td>
<td id="S5.T3.9.9.11.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">TF</td>
<td id="S5.T3.9.9.11.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.11.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.535</td>
<td id="S5.T3.9.9.11.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.249</td>
<td id="S5.T3.9.9.11.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.030</td>
<td id="S5.T3.9.9.11.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.334</td>
<td id="S5.T3.9.9.11.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.538</td>
<td id="S5.T3.9.9.11.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.220</td>
<td id="S5.T3.9.9.11.10" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.038</td>
<td id="S5.T3.9.9.11.11" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.406</td>
<td id="S5.T3.9.9.11.12" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">4.157</td>
<td id="S5.T3.9.9.11.13" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">321</td>
<td id="S5.T3.9.9.11.14" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.12" class="ltx_tr">
<td id="S5.T3.9.9.12.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;" rowspan="4"><span id="S5.T3.9.9.12.1.1" class="ltx_text">Our-Base</span></td>
<td id="S5.T3.9.9.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S5.T3.9.9.12.2.1" class="ltx_text">Wav2vec</span></td>
<td id="S5.T3.9.9.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">SSM</td>
<td id="S5.T3.9.9.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.12.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">0.416</td>
<td id="S5.T3.9.9.12.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">0.246</td>
<td id="S5.T3.9.9.12.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">0.034</td>
<td id="S5.T3.9.9.12.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">0.335</td>
<td id="S5.T3.9.9.12.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">0.425</td>
<td id="S5.T3.9.9.12.10" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">0.223</td>
<td id="S5.T3.9.9.12.11" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">0.042</td>
<td id="S5.T3.9.9.12.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">0.412</td>
<td id="S5.T3.9.9.12.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">3.587</td>
<td id="S5.T3.9.9.12.14" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">320</td>
<td id="S5.T3.9.9.12.15" class="ltx_td ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.13" class="ltx_tr">
<td id="S5.T3.9.9.13.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">TF</td>
<td id="S5.T3.9.9.13.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.13.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.424</td>
<td id="S5.T3.9.9.13.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.246</td>
<td id="S5.T3.9.9.13.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.033</td>
<td id="S5.T3.9.9.13.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.334</td>
<td id="S5.T3.9.9.13.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.426</td>
<td id="S5.T3.9.9.13.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.219</td>
<td id="S5.T3.9.9.13.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.040</td>
<td id="S5.T3.9.9.13.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.402</td>
<td id="S5.T3.9.9.13.11" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">3.608</td>
<td id="S5.T3.9.9.13.12" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">323</td>
<td id="S5.T3.9.9.13.13" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.14" class="ltx_tr">
<td id="S5.T3.9.9.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S5.T3.9.9.14.1.1" class="ltx_text">HuBERT</span></td>
<td id="S5.T3.9.9.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">SSM</td>
<td id="S5.T3.9.9.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.14.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.402</td>
<td id="S5.T3.9.9.14.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.247</td>
<td id="S5.T3.9.9.14.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.033</td>
<td id="S5.T3.9.9.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.336</td>
<td id="S5.T3.9.9.14.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.432</td>
<td id="S5.T3.9.9.14.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.218</td>
<td id="S5.T3.9.9.14.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.041</td>
<td id="S5.T3.9.9.14.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.407</td>
<td id="S5.T3.9.9.14.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">3.412</td>
<td id="S5.T3.9.9.14.13" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">320</td>
<td id="S5.T3.9.9.14.14" class="ltx_td ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.15" class="ltx_tr">
<td id="S5.T3.9.9.15.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">TF</td>
<td id="S5.T3.9.9.15.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.15.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.418</td>
<td id="S5.T3.9.9.15.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.247</td>
<td id="S5.T3.9.9.15.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.034</td>
<td id="S5.T3.9.9.15.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.338</td>
<td id="S5.T3.9.9.15.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.432</td>
<td id="S5.T3.9.9.15.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.219</td>
<td id="S5.T3.9.9.15.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.041</td>
<td id="S5.T3.9.9.15.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.412</td>
<td id="S5.T3.9.9.15.11" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">3.529</td>
<td id="S5.T3.9.9.15.12" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">323</td>
<td id="S5.T3.9.9.15.13" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.16" class="ltx_tr">
<td id="S5.T3.9.9.16.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="4"><span id="S5.T3.9.9.16.1.1" class="ltx_text">Our-Large</span></td>
<td id="S5.T3.9.9.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S5.T3.9.9.16.2.1" class="ltx_text">Wav2vec</span></td>
<td id="S5.T3.9.9.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">SSM</td>
<td id="S5.T3.9.9.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.16.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.421</td>
<td id="S5.T3.9.9.16.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.244</td>
<td id="S5.T3.9.9.16.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.031</td>
<td id="S5.T3.9.9.16.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.208</td>
<td id="S5.T3.9.9.16.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.430</td>
<td id="S5.T3.9.9.16.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.219</td>
<td id="S5.T3.9.9.16.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.038</td>
<td id="S5.T3.9.9.16.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.253</td>
<td id="S5.T3.9.9.16.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">3.453</td>
<td id="S5.T3.9.9.16.14" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">539</td>
<td id="S5.T3.9.9.16.15" class="ltx_td ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.17" class="ltx_tr">
<td id="S5.T3.9.9.17.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">TF</td>
<td id="S5.T3.9.9.17.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.17.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.354</td>
<td id="S5.T3.9.9.17.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.244</td>
<td id="S5.T3.9.9.17.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.030</td>
<td id="S5.T3.9.9.17.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.209</td>
<td id="S5.T3.9.9.17.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.372</td>
<td id="S5.T3.9.9.17.8" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.17.8.1" class="ltx_text" style="background-color:#E6E6FA;">0.214</span></td>
<td id="S5.T3.9.9.17.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.038</td>
<td id="S5.T3.9.9.17.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.251</td>
<td id="S5.T3.9.9.17.11" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">3.376</td>
<td id="S5.T3.9.9.17.12" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">557</td>
<td id="S5.T3.9.9.17.13" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.18" class="ltx_tr">
<td id="S5.T3.9.9.18.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;" rowspan="2"><span id="S5.T3.9.9.18.1.1" class="ltx_text">HuBERT</span></td>
<td id="S5.T3.9.9.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">SSM</td>
<td id="S5.T3.9.9.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.18.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.403</td>
<td id="S5.T3.9.9.18.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.244</td>
<td id="S5.T3.9.9.18.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.030</td>
<td id="S5.T3.9.9.18.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.214</td>
<td id="S5.T3.9.9.18.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.406</td>
<td id="S5.T3.9.9.18.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.217</td>
<td id="S5.T3.9.9.18.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.037</td>
<td id="S5.T3.9.9.18.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.18.11.1" class="ltx_text" style="background-color:#E6E6FA;">0.237</span></td>
<td id="S5.T3.9.9.18.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">3.395</td>
<td id="S5.T3.9.9.18.13" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">539</td>
<td id="S5.T3.9.9.18.14" class="ltx_td ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.19" class="ltx_tr">
<td id="S5.T3.9.9.19.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">TF</td>
<td id="S5.T3.9.9.19.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T3.9.9.19.3" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.19.3.1" class="ltx_text" style="background-color:#E6E6FA;">0.351</span></td>
<td id="S5.T3.9.9.19.4" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.19.4.1" class="ltx_text" style="background-color:#E6E6FA;">0.244</span></td>
<td id="S5.T3.9.9.19.5" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.19.5.1" class="ltx_text" style="background-color:#E6E6FA;">0.030</span></td>
<td id="S5.T3.9.9.19.6" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.19.6.1" class="ltx_text" style="background-color:#E6E6FA;">0.205</span></td>
<td id="S5.T3.9.9.19.7" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.19.7.1" class="ltx_text" style="background-color:#E6E6FA;">0.372</span></td>
<td id="S5.T3.9.9.19.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.217</td>
<td id="S5.T3.9.9.19.9" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.19.9.1" class="ltx_text" style="background-color:#E6E6FA;">0.037</span></td>
<td id="S5.T3.9.9.19.10" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">0.248</td>
<td id="S5.T3.9.9.19.11" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T3.9.9.19.11.1" class="ltx_text" style="background-color:#E6E6FA;">3.281</span></td>
<td id="S5.T3.9.9.19.12" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">557</td>
<td id="S5.T3.9.9.19.13" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
<tr id="S5.T3.9.9.20" class="ltx_tr">
<td id="S5.T3.9.9.20.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">Â </span></td>
<td id="S5.T3.9.9.20.2" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.3" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.4" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.5" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.6" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.7" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.8" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.9" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.10" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.11" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.12" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.13" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.14" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T3.9.9.20.15" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
</table>
</span></div>
</figure>
<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p id="S5.SS2.p1.1" class="ltx_p"><span id="S5.SS2.p1.1.1" class="ltx_text ltx_font_bold">Experimental Setup.</span>
Within the network, we compare two transformer-based audio feature extractors, Wav2Vec2.0Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and HuBERTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, which are popular in the field of self-supervised speech recognition. Regarding the feature embedding module (Decoder), we evaluate the performance of SSM-based modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> in contrast to the transformer (TF) approachÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. We conduct experiments using two different model configurations. Both of them employ the same diffusion architecture while differing in the feature extractor setup. The base model incorporates Wav2Vec2.0-base/HuBERT-base as the audio feature extractors, featuring a model dimension of 768 and containing 8-layer TF/SSM decoder. The large model utilizes Wav2Vec2.0-large/HuBERT-large, with a model dimension of 1,024 and 16-layer TF/SSM decoder.</p>
</div>
<figure id="S5.T4" class="ltx_table ltx_align_floatright">
<table id="S5.T4.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T4.4.4" class="ltx_tr">
<td id="S5.T4.4.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">
<span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">Â </span>
<span id="S5.T4.4.4.5.1" class="ltx_text ltx_font_bold">Step</span>
</td>
<td id="S5.T4.1.1.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.1.1.1.1" class="ltx_text ltx_font_bold">FID<math id="S5.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T4.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T4.1.1.1.1.m1.1.1" xref="S5.T4.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b"><ci id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T4.2.2.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.2.2.2.1" class="ltx_text ltx_font_bold">FGD<math id="S5.T4.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T4.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T4.2.2.2.1.m1.1.1" xref="S5.T4.2.2.2.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.1.m1.1b"><ci id="S5.T4.2.2.2.1.m1.1.1.cmml" xref="S5.T4.2.2.2.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T4.3.3.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.3.3.3.1" class="ltx_text ltx_font_bold">WGD<math id="S5.T4.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T4.3.3.3.1.m1.1a"><mo stretchy="false" id="S5.T4.3.3.3.1.m1.1.1" xref="S5.T4.3.3.3.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.1.m1.1b"><ci id="S5.T4.3.3.3.1.m1.1.1.cmml" xref="S5.T4.3.3.3.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T4.4.4.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.4.4.4.1" class="ltx_text ltx_font_bold">Smooth<math id="S5.T4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T4.4.4.4.1.m1.1a"><mo stretchy="false" id="S5.T4.4.4.4.1.m1.1.1" xref="S5.T4.4.4.4.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.1.m1.1b"><ci id="S5.T4.4.4.4.1.m1.1.1.cmml" xref="S5.T4.4.4.4.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S5.T4.4.5" class="ltx_tr">
<td id="S5.T4.4.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">5</td>
<td id="S5.T4.4.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">3.540</td>
<td id="S5.T4.4.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.361</td>
<td id="S5.T4.4.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.237</td>
<td id="S5.T4.4.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">0.354</td>
</tr>
<tr id="S5.T4.4.6" class="ltx_tr">
<td id="S5.T4.4.6.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">10</td>
<td id="S5.T4.4.6.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">3.682</td>
<td id="S5.T4.4.6.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.363</td>
<td id="S5.T4.4.6.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.236</td>
<td id="S5.T4.4.6.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.310</td>
</tr>
<tr id="S5.T4.4.7" class="ltx_tr">
<td id="S5.T4.4.7.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">100</td>
<td id="S5.T4.4.7.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">3.438</td>
<td id="S5.T4.4.7.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.366</td>
<td id="S5.T4.4.7.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.232</td>
<td id="S5.T4.4.7.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.254</td>
</tr>
<tr id="S5.T4.4.8" class="ltx_tr">
<td id="S5.T4.4.8.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">300</td>
<td id="S5.T4.4.8.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">3.360</td>
<td id="S5.T4.4.8.3" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.4.8.3.1" class="ltx_text" style="background-color:#E6E6FA;">0.348</span></td>
<td id="S5.T4.4.8.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.233</td>
<td id="S5.T4.4.8.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.240</td>
</tr>
<tr id="S5.T4.4.9" class="ltx_tr">
<td id="S5.T4.4.9.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;">1000</td>
<td id="S5.T4.4.9.2" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.4.9.2.1" class="ltx_text" style="background-color:#E6E6FA;">3.281</span></td>
<td id="S5.T4.4.9.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">0.362</td>
<td id="S5.T4.4.9.4" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.4.9.4.1" class="ltx_text" style="background-color:#E6E6FA;">0.231</span></td>
<td id="S5.T4.4.9.5" class="ltx_td ltx_align_center" style="background-color:#E6E6FA;padding-top:1pt;padding-bottom:1pt;"><span id="S5.T4.4.9.5.1" class="ltx_text" style="background-color:#E6E6FA;">0.227</span></td>
</tr>
<tr id="S5.T4.4.10" class="ltx_tr">
<td id="S5.T4.4.10.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1pt;padding-bottom:1pt;"><span class="ltx_rule" style="width:100%;height:1.0pt;background:black;display:inline-block;">Â </span></td>
<td id="S5.T4.4.10.2" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T4.4.10.3" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T4.4.10.4" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
<td id="S5.T4.4.10.5" class="ltx_td" style="padding-top:1pt;padding-bottom:1pt;"></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S5.T4.6.1" class="ltx_text ltx_font_bold">Ablation study</span> on denoising steps.</figcaption>
</figure>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_bold">Quantitative Results.</span>
Tab.Â <a href="#S5.T3" title="Table 3 â€£ 5.2 Experiments â€£ 5 Benchmark â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> provides the results of existing methods and our baseline under various experimental settings on PianoMotion10M dataset. Due to the absence of prior work on generating gestures for piano music, we refer to the network structures of EmoTalkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> and LivelySpeakerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> and re-implement them to account for our task. EmoTalk directly generates poses from audio, while LivelySpeaker utilizes an MLP-based diffusion backbone for gesture generation. Our baseline models achieve better fidelity on hand motions by estimating positions and gestures, separately.
In our baseline models, TF-based models outperform the SSM-based models in processing our time-series information, especially in our large model. For the audio feature extractor, the performance of the HuBERT model slightly outperforms the Wav2vec2.
Additionally, we conduct ablation experiments on different denoising steps and our model also achieves competitive results with fewer steps, as shown in TableÂ <a href="#S5.T4" title="Table 4 â€£ 5.2 Experiments â€£ 5 Benchmark â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p id="S5.SS2.p3.1" class="ltx_p"><span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_bold">Qualitative Results.</span> Fig.Â <a href="#S5.F4" title="Figure 4 â€£ 5.2 Experiments â€£ 5 Benchmark â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> demonstrates the visual results of our baseline and the existing models. The output of EmoTalk method exhibits a static average gesture. While MLPs afford LivelySpeaker rapid inference speed, they compromise the fidelity of generated motions. Conversely, our model demonstrates notably superior performance compared to previous methods by taking advantage of a two-stage approach, as illustrated in Fig.Â <a href="#S5.F4" title="Figure 4 â€£ 5.2 Experiments â€£ 5 Benchmark â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. To attain accurate positional information, we utilize an end-to-end position predictor rather than making use of an uncontrollable diffusion model for position generation. Furthermore, we employ a position-guided approach with a diffusion-based gesture generator for hand motion estimation.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2406.09326/assets/x4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S5.F4.2.1" class="ltx_text ltx_font_bold">Illustration of the qualitative results.</span> We display the generated gestures across frames using different methods. Our method stands out due to its greater fidelity, as shown in the examples.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">In this work, we present PianoMotion10M, a new large-scale piano-motion dataset for hands, which has 116 hours of piano music and 10 million frames annotated with hand poses.
We address the critical issue that the current datasets are insufficient for human-piano interaction.
Based on PianoMotion10M, we develop a benchmark model that maps the piano music pieces to hand motions.
To simplify the learning target, we divide the motion into position and gesture by introducing a position predictor along with a gesture generator guided by the estimated positions.
We suggest the evaluation metrics to measure the fidelity and smoothness of the hand motions compared to the ground truth.
Our dataset and benchmark will further advance the automation of piano performance simulation and assist in learning piano playing.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Ahuja, C., Lee, D.W., Nakano, Y.I., Morency, L.P.: Style transfer for co-speech gesture animation: A multi-speaker conditional-mixture approach. In: ECCV. pp. 248â€“265 (2020)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Alemi, O., FranÃ§oise, J., Pasquier, P.: Groovenet: Real-time music-driven dance movement generation using artificial neural networks. Networks <span id="bib.bib2.1.1" class="ltx_text ltx_font_bold">8</span>(17), Â 26 (2017)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Azadi, S., Shah, A., Hayes, T., Parikh, D., Gupta, S.: Make-an-animation: Large-scale text-conditional 3d human motion generation. In: ICCV. pp. 15039â€“15048 (2023)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Baevski, A., Zhou, Y., Mohamed, A., Auli, M.: wav2vec 2.0: A framework for self-supervised learning of speech representations. NeurIPS <span id="bib.bib4.1.1" class="ltx_text ltx_font_bold">33</span>, 12449â€“12460 (2020)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Balliauw, M., Herremans, D., PalhaziÂ Cuervo, D., SÃ¶rensen, K.: A variable neighborhood search algorithm to generate piano fingerings for polyphonic sheet music. ITOR <span id="bib.bib5.1.1" class="ltx_text ltx_font_bold">24</span>(3), 509â€“535 (2017)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Bhattacharya, U., Rewkowski, N., Banerjee, A., Guhan, P., Bera, A., Manocha, D.: Text2gestures: A transformer-based network for generating emotive body gestures for virtual agents. In: VR. pp. 1â€“10 (2021)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Cao, Y., Tien, W.C., Faloutsos, P., Pighin, F.: Expressive speech-driven facial animation. TOG <span id="bib.bib7.1.1" class="ltx_text ltx_font_bold">24</span>(4), 1283â€“1302 (2005)

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Cao, Z., Simon, T., Wei, S.E., Sheikh, Y.: Realtime multi-person 2d pose estimation using part affinity fields. In: CVPR. pp. 7291â€“7299 (2017)

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Cassell, J., VilhjÃ¡lmsson, H.H., Bickmore, T.: Beat: the behavior expression animation toolkit. In: SIGGRAPH. pp. 477â€“486 (2001)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Chen, L., Maddox, R.K., Duan, Z., Xu, C.: Hierarchical cross-modal talking face generation with dynamic pixel-wise loss. In: CVPR. pp. 7832â€“7841 (2019)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Chen, X., Jiang, B., Liu, W., Huang, Z., Fu, B., Chen, T., Yu, G.: Executing your commands via motion diffusion in latent space. In: CVPR. pp. 18000â€“18010 (2023)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Chiu, C.C., Morency, L.P., Marsella, S.: Predicting co-verbal gestures: A deep and temporal modeling approach. In: Intelligent Virtual Agents: 15th International Conference. pp. 152â€“166 (2015)

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Cudeiro, D., Bolkart, T., Laidlaw, C., Ranjan, A., Black, M.J.: Capture, learning, and synthesis of 3d speaking styles. In: CVPR. pp. 10101â€“10111 (2019)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Fan, Y., Lin, Z., Saito, J., Wang, W., Komura, T.: Faceformer: Speech-driven 3d facial animation with transformers. In: CVPR. pp. 18770â€“18780 (2022)

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Ferreira, J.P., Coutinho, T.M., Gomes, T.L., Neto, J.F., Azevedo, R., Martins, R., Nascimento, E.R.: Learning to dance: A graph convolutional adversarial network to generate realistic dance motions from audio. Computers &amp; Graphics <span id="bib.bib15.1.1" class="ltx_text ltx_font_bold">94</span>, 11â€“21 (2021)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Gan, Q., Li, W., Ren, J., Zhu, J.: Fine-grained multi-view hand reconstruction using inverse rendering. In: AAAI. pp. 1779â€“1787 (2024)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Ginosar, S., Bar, A., Kohavi, G., Chan, C., Owens, A., Malik, J.: Learning individual styles of conversational gesture. In: CVPR. pp. 3497â€“3506 (2019)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Gu, A., Dao, T.: Mamba: Linear-time sequence modeling with selective state spaces. arXiv preprint arXiv:2312.00752 (2023)

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Guo, Y., Chen, K., Liang, S., Liu, Y.J., Bao, H., Zhang, J.: Ad-nerf: Audio driven neural radiance fields for talking head synthesis. In: ICCV. pp. 5784â€“5794 (2021)

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. NeurIPS <span id="bib.bib20.1.1" class="ltx_text ltx_font_bold">33</span>, 6840â€“6851 (2020)

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Hong, F.T., Zhang, L., Shen, L., Xu, D.: Depth-aware generative adversarial network for talking head video generation. In: CVPR. pp. 3397â€“3406 (2022)

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Hsu, W.N., Bolte, B., Tsai, Y.H.H., Lakhotia, K., Salakhutdinov, R., Mohamed, A.: Hubert: Self-supervised speech representation learning by masked prediction of hidden units. TASLP <span id="bib.bib22.1.1" class="ltx_text ltx_font_bold">29</span>, 3451â€“3460 (2021)

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Huang, C.M., Mutlu, B.: Robot behavior toolkit: generating effective social behaviors for robots. In: HRI. pp. 25â€“32 (2012)

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Huang, R., Hu, H., Wu, W., Sawada, K., Zhang, M., Jiang, D.: Dance revolution: Long-term dance generation with music via curriculum learning. arXiv preprint arXiv:2006.06119 (2020)

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Ji, X., Zhou, H., Wang, K., Wu, W., Loy, C.C., Cao, X., Xu, F.: Audio-driven emotional video portraits. In: CVPR. pp. 14080â€“14089 (2021)

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Kalman, R.E.: A new approach to linear filtering and prediction problems (1960)

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Kolouri, S., Rohde, G.K., Hoffmann, H.: Sliced wasserstein distance for learning gaussian mixture models. In: CVPR. pp. 3427â€“3436 (2018)

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Kong, Q., Li, B., Song, X., Wan, Y., Wang, Y.: High-resolution piano transcription with pedals by regressing onset and offset times. TASLP <span id="bib.bib28.1.1" class="ltx_text ltx_font_bold">29</span>, 3707â€“3717 (2021)

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Kopp, S., Krenn, B., Marsella, S., Marshall, A.N., Pelachaud, C., Pirker, H., ThÃ³risson, K.R., VilhjÃ¡lmsson, H.: Towards a common framework for multimodal generation: The behavior markup language. In: Intelligent Virtual Agents: 6th International Conference. pp. 205â€“217 (2006)

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Kwon, T., Tekin, B., StÃ¼hmer, J., Bogo, F., Pollefeys, M.: H2o: Two hands manipulating objects for first person interaction recognition. In: ICCV. pp. 10138â€“10148 (2021)

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Lee, S., Chung, J., Yu, Y., Kim, G., Breuel, T., Chechik, G., Song, Y.: Acav100m: Automatic curation of large-scale datasets for audio-visual video representation learning. In: ICCV. pp. 10274â€“10284 (2021)

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Li, R., Yang, S., Ross, D.A., Kanazawa, A.: Ai choreographer: Music conditioned 3d dance generation with aist++. In: ICCV. pp. 13401â€“13412 (2021)

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Lin, C.C., Liu, D.S.M.: An intelligent virtual piano tutor. In: VRCIA. pp. 353â€“356 (2006)

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Liu, X., Wu, Q., Zhou, H., Xu, Y., Qian, R., Lin, X., Zhou, X., Wu, W., Dai, B., Zhou, B.: Learning hierarchical cross-modal association for co-speech gesture generation. In: CVPR. pp. 10462â€“10472 (2022)

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Lugaresi, C., Tang, J., Nash, H., McClanahan, C., Uboweja, E., Hays, M., Zhang, F., Chang, C.L., Yong, M.G., Lee, J., etÂ al.: Mediapipe: A framework for building perception pipelines. arXiv preprint arXiv:1906.08172 (2019)

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Miech, A., Zhukov, D., Alayrac, J.B., Tapaswi, M., Laptev, I., Sivic, J.: Howto100m: Learning a text-video embedding by watching hundred million narrated video clips. In: ICCV. pp. 2630â€“2640 (2019)

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Moon, G., Saito, S., Xu, W., Joshi, R., Buffalini, J., Bellan, H., Rosen, N., Richardson, J., Mize, M., DeÂ Bree, P., etÂ al.: A dataset of relighted 3d interacting hands. NeurIPS <span id="bib.bib37.1.1" class="ltx_text ltx_font_bold">36</span> (2023)

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Moon, G., Shiratori, T., Lee, K.M.: Deephandmesh: A weakly-supervised deep encoder-decoder framework for high-fidelity hand mesh modeling. In: ECCV. pp. 440â€“455 (2020)

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Moon, G., Yu, S.I., Wen, H., Shiratori, T., Lee, K.M.: Interhand2.6m: A dataset and baseline for 3d interacting hand pose estimation from a single rgb image. In: ECCV. pp. 548â€“564 (2020)

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Moryossef, A., Elazar, Y., Goldberg, Y.: At your fingertips: Extracting piano fingering instructions from videos. arXiv preprint arXiv:2303.03745 (2023)

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Nakamura, E., Sagayama, S.: Automatic piano reduction from ensemble scores based on merged-output hidden markov model. In: ICMC (2015)

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Pavlakos, G., Shan, D., Radosavovic, I., Kanazawa, A., Fouhey, D., Malik, J.: Reconstructing hands in 3d with transformers. arXiv preprint arXiv:2312.05251 (2023)

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Pearson, R.K., Neuvo, Y., Astola, J., Gabbouj, M.: Generalized hampel filters. EURASIP <span id="bib.bib43.1.1" class="ltx_text ltx_font_bold">2016</span>, 1â€“18 (2016)

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Peng, Z., Wu, H., Song, Z., Xu, H., Zhu, X., He, J., Liu, H., Fan, Z.: Emotalk: Speech-driven emotional disentanglement for 3d face animation. In: ICCV. pp. 20687â€“20697 (2023)

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
PianoPlayer: (2018), <a target="_blank" href="https://github.com/marcomusy/pianoplayer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/marcomusy/pianoplayer</a>

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Ren, X., Li, H., Huang, Z., Chen, Q.: Self-supervised dance video synthesis conditioned on music. In: ACM MM. pp. 46â€“54 (2020)

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Romero, J., Tzionas, D., Black, M.J.: Embodied hands: modeling and capturing hands and bodies together. ACM TOG pp. 245:1â€“245:17 (2017)

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: LNCS. pp. 234â€“241 (2015)

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Rubner, Y., Tomasi, C., Guibas, L.J.: The earth moverâ€™s distance as a metric for image retrieval. IJCV <span id="bib.bib49.1.1" class="ltx_text ltx_font_bold">40</span>, 99â€“121 (2000)

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Salimans, T., Ho, J.: Progressive distillation for fast sampling of diffusion models. arXiv preprint arXiv:2202.00512 (2022)

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Schafer, R.W.: What is a savitzky-golay filter?[lecture notes]. IEEE Signal processing magazine <span id="bib.bib51.1.1" class="ltx_text ltx_font_bold">28</span>(4), 111â€“117 (2011)

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Schuhmann, C., Vencu, R., Beaumont, R., Kaczmarczyk, R., Mullis, C., Katta, A., Coombes, T., Jitsev, J., Komatsuzaki, A.: Laion-400m: Open dataset of clip-filtered 400 million image-text pairs. arXiv preprint arXiv:2111.02114 (2021)

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Shiratori, T., Nakazawa, A., Ikeuchi, K.: Dancing-to-music character animation. In: CGF. pp. 449â€“458 (2006)

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Siyao, L., Yu, W., Gu, T., Lin, C., Wang, Q., Qian, C., Loy, C.C., Liu, Z.: Bailando: 3d dance generation by actor-critic gpt with choreographic memory. In: CVPR. pp. 11050â€“11059 (2022)

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Srinivasan, K., Raman, K., Chen, J., Bendersky, M., Najork, M.: Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning. In: SIGIR. pp. 2443â€“2449 (2021)

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Starke, S., Mason, I., Komura, T.: Deepphase: Periodic autoencoders for learning motion phase manifolds. TOG <span id="bib.bib56.1.1" class="ltx_text ltx_font_bold">41</span>(4), 1â€“13 (2022)

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Sun, G., Wong, Y., Cheng, Z., Kankanhalli, M.S., Geng, W., Li, X.: Deepdance: music-to-dance motion choreography with adversarial learning. TOMM <span id="bib.bib57.1.1" class="ltx_text ltx_font_bold">23</span>, 497â€“509 (2020)

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Tang, T., Jia, J., Mao, H.: Dance with melody: An lstm-autoencoder approach to music-oriented dance synthesis. In: ACM MM. pp. 1598â€“1606 (2018)

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Tevet, G., Raab, S., Gordon, B., Shafir, Y., Cohen-Or, D., Bermano, A.H.: Human motion diffusion model. arXiv preprint arXiv:2209.14916 (2022)

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Tian, G., Yuan, Y., Liu, Y.: Audio2face: Generating speech/face animation from single audio with attention-based bidirectional lstm networks. In: ICMEW. pp. 366â€“371. IEEE (2019)

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Tian, L., Wang, Q., Zhang, B., Bo, L.: Emo: Emote portrait alive-generating expressive portrait videos with audio2video diffusion model under weak conditions. arXiv preprint arXiv:2402.17485 (2024)

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Van DenÂ Oord, A., Vinyals, O., etÂ al.: Neural discrete representation learning. NeurIPS <span id="bib.bib62.1.1" class="ltx_text ltx_font_bold">30</span> (2017)

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Å., Polosukhin, I.: Attention is all you need. NeurIPS <span id="bib.bib63.1.1" class="ltx_text ltx_font_bold">30</span> (2017)

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Wang, J., Qiu, K., Peng, H., Fu, J., Zhu, J.: Ai coach: Deep human pose estimation and analysis for personalized athletic training assistance. In: ACM MM. pp. 374â€“382 (2019)

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Wang, J., Mueller, F., Bernard, F., Sorli, S., Sotnychenko, O., Qian, N., Otaduy, M.A., Casas, D., Theobalt, C.: Rgb2hands: real-time tracking of 3d hand interactions from monocular rgb video. ACM TOG <span id="bib.bib65.1.1" class="ltx_text ltx_font_bold">39</span>(6), 1â€“16 (2020)

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Wang, Z., VeliÄkoviÄ‡, P., Hennes, D., TomaÅ¡ev, N., Prince, L., Kaisers, M., Bachrach, Y., Elie, R., Wenliang, L.K., Piccinini, F., etÂ al.: Tacticai: an ai assistant for football tactics. Nature communications <span id="bib.bib66.1.1" class="ltx_text ltx_font_bold">15</span>(1), 1â€“13 (2024)

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Wu, E., Nishioka, H., Furuya, S., Koike, H.: Marker-removal networks to collect precise 3d hand data for rgb-based estimation and its application in piano. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. pp. 2977â€“2986 (2023)

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Yalta, N., Watanabe, S., Nakadai, K., Ogata, T.: Weakly-supervised deep recurrent neural networks for basic dance step generation. In: IJCNN. pp.Â 1â€“8 (2019)

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Yonebayashi, Y., Kameoka, H., Sagayama, S.: Automatic decision of piano fingering based on a hidden markov models. In: IJCAI. vol.Â 7, pp. 2915â€“2921 (2007)

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Yoon, Y., Cha, B., Lee, J.H., Jang, M., Lee, J., Kim, J., Lee, G.: Speech gesture generation from the trimodal context of text, audio, and speaker identity. TOG <span id="bib.bib70.1.1" class="ltx_text ltx_font_bold">39</span>(6), 1â€“16 (2020)

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Yuan, Y., Song, J., Iqbal, U., Vahdat, A., Kautz, J.: Physdiff: Physics-guided human motion diffusion model. In: ICCV. pp. 16010â€“16021 (2023)

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Zakharov, E., Shysheya, A., Burkov, E., Lempitsky, V.: Few-shot adversarial learning of realistic neural talking head models. In: ICCV. pp. 9459â€“9468 (2019)

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Zhang, C., Zhao, Y., Huang, Y., Zeng, M., Ni, S., Budagavi, M., Guo, X.: Facial: Synthesizing dynamic talking face with implicit attribute learning. In: ICCV. pp. 3867â€“3876 (2021)

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Zhang, M., Cai, Z., Pan, L., Hong, F., Guo, X., Yang, L., Liu, Z.: Motiondiffuse: Text-driven human motion generation with diffusion model. TPAMI (2024)

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Zhang, M., Guo, X., Pan, L., Cai, Z., Hong, F., Li, H., Yang, L., Liu, Z.: Remodiffuse: Retrieval-augmented motion diffusion model. In: ICCV. pp. 364â€“373 (2023)

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Zhi, Y., Cun, X., Chen, X., Shen, X., Guo, W., Huang, S., Gao, S.: Livelyspeaker: Towards semantic-aware co-speech gesture generation. In: ICCV. pp. 20807â€“20817 (2023)

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Zhu, Y., Olszewski, K., Wu, Y., Achlioptas, P., Chai, M., Yan, Y., Tulyakov, S.: Quantized gan for complex music generation from dance videos. In: ECCV. pp. 182â€“199 (2022)

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Zhuang, W., Wang, C., Chai, J., Wang, Y., Shao, M., Xia, S.: Music2dance: Dancenet for music-driven dance generation. TOMM <span id="bib.bib78.1.1" class="ltx_text ltx_font_bold">18</span>(2), 1â€“21 (2022)

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Zimmermann, C., Ceylan, D., Yang, J., Russell, B., Argus, M., Brox, T.: Freihand: A dataset for markerless capture of hand pose and shape from single rgb images. In: ICCV. pp. 813â€“822 (2019)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>

<div id="Ax1.p1" class="ltx_para ltx_noindent">
<p id="Ax1.p1.1" class="ltx_p">In this part, we further provide more details and discussions on our proposed dataset and benchmark:</p>
<ul id="Ax1.I1" class="ltx_itemize">
<li id="Ax1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i1.p1" class="ltx_para">
<p id="Ax1.I1.i1.p1.1" class="ltx_p">Â§<a href="#A1" title="Appendix A More Statistics of PianoMotion10M â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>: More statistics of PianoMotion10M;</p>
</div>
</li>
<li id="Ax1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i2.p1" class="ltx_para">
<p id="Ax1.I1.i2.p1.1" class="ltx_p">Â§<a href="#A2" title="Appendix B More Visual Samples of PianoMotion10M Dataset â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>: More visual samples of PianoMotion10M dataset;</p>
</div>
</li>
<li id="Ax1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i3.p1" class="ltx_para">
<p id="Ax1.I1.i3.p1.1" class="ltx_p">Â§<a href="#A3" title="Appendix C More Details of Our Baseline â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>: More details of our baseline;</p>
</div>
</li>
<li id="Ax1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i4.p1" class="ltx_para">
<p id="Ax1.I1.i4.p1.1" class="ltx_p">Â§<a href="#A4" title="Appendix D Limitation and Future Work â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>: Limitation and future work;</p>
</div>
</li>
<li id="Ax1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i5.p1" class="ltx_para">
<p id="Ax1.I1.i5.p1.1" class="ltx_p">Â§<a href="#A5" title="Appendix E Ethical Considerations â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a>: Ethical considerations;</p>
</div>
</li>
<li id="Ax1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i6.p1" class="ltx_para">
<p id="Ax1.I1.i6.p1.1" class="ltx_p">Â§<a href="#A6" title="Appendix F Author Statement â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></a>: Author statement;</p>
</div>
</li>
<li id="Ax1.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="Ax1.I1.i7.p1" class="ltx_para ltx_noindent">
<p id="Ax1.I1.i7.p1.1" class="ltx_p">Â§<a href="#A7" title="Appendix G License and Consent with Public Resources â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">G</span></a>: License and consent with public resources.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>More Statistics of PianoMotion10M</h2>

<figure id="A1.F5" class="ltx_figure"><img src="/html/2406.09326/assets/x5.png" id="A1.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="243" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="A1.F5.2.1" class="ltx_text ltx_font_bold">Distribution of Note Clicks and Volume Levels in the PianoMotion10M Dataset.</span> The top figure depicts note click frequency, and the bottom one shows the volume distribution.</figcaption>
</figure>
<div id="A1.p1" class="ltx_para ltx_noindent">
<p id="A1.p1.1" class="ltx_p">Fig.Â <a href="#A1.F5" title="Figure 5 â€£ Appendix A More Statistics of PianoMotion10M â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents a detailed statistical analysis of piano fingerings, which focuses on the frequency of note clicks and the distribution of volume levels.</p>
</div>
<div id="A1.p2" class="ltx_para ltx_noindent">
<p id="A1.p2.1" class="ltx_p"><span id="A1.p2.1.1" class="ltx_text ltx_font_bold">Note Click Counts.</span>
The top figure in Fig.Â <a href="#A1.F5" title="Figure 5 â€£ Appendix A More Statistics of PianoMotion10M â€£ PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> displays the frequency of each note played, measured in millions. This distribution spans 128 keys of the piano, which indicates frequent usage of those keys in performances. It shows higher counts in specific note ranges.</p>
</div>
<div id="A1.p3" class="ltx_para ltx_noindent">
<p id="A1.p3.1" class="ltx_p">Notes around the middle of the keyboard, particularly from C4 to C6, exhibit significantly higher click counts, aligning with their common use in melodies and harmonic accompaniments. Conversely, notes in the low (A0 to B1) and high (C7 to C8) octaves have markedly fewer clicks, as these ranges are less frequently used and typically reserved for specific musical effects or embellishments.
It is worth noting that, certain notes, particularly those fundamental to common chords and scales (e.g., A, C, E, and G), exhibit higher frequencies, reflecting their frequent use in various musical pieces.</p>
</div>
<div id="A1.p4" class="ltx_para ltx_noindent">
<p id="A1.p4.1" class="ltx_p"><span id="A1.p4.1.1" class="ltx_text ltx_font_bold">Volume Distribution.</span>
In addition to note frequency, the figure below presents a comprehensive distribution of volume levels, spanning various ranges to highlight the dynamics of piano playing. Volume counts, measured in millions, provide insights into the intensity and expression captured in our constructed dataset.</p>
</div>
<div id="A1.p5" class="ltx_para ltx_noindent">
<p id="A1.p5.1" class="ltx_p">There is a higher count of notes played at moderate volume levels. This reflects the natural dynamics of piano playing, where most notes are neither extremely soft nor loud.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>More Visual Samples of PianoMotion10M Dataset</h2>

<figure id="A2.F6" class="ltx_figure"><img src="/html/2406.09326/assets/x6.png" id="A2.F6.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="671" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="A2.F6.2.1" class="ltx_text ltx_font_bold">More samples from PianoMotion10M dataset.</span> BV*** denote the corresponding video iDs.</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>More Details of Our Baseline</h2>

<div id="A3.p1" class="ltx_para ltx_noindent">
<p id="A3.p1.5" class="ltx_p">The audio feature extractor <math id="A3.p1.1.m1.1" class="ltx_Math" alttext="\Phi_{a}" display="inline"><semantics id="A3.p1.1.m1.1a"><msub id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="A3.p1.1.m1.1.1.2" xref="A3.p1.1.m1.1.1.2.cmml">Î¦</mi><mi id="A3.p1.1.m1.1.1.3" xref="A3.p1.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><apply id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.p1.1.m1.1.1.1.cmml" xref="A3.p1.1.m1.1.1">subscript</csymbol><ci id="A3.p1.1.m1.1.1.2.cmml" xref="A3.p1.1.m1.1.1.2">Î¦</ci><ci id="A3.p1.1.m1.1.1.3.cmml" xref="A3.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">\Phi_{a}</annotation></semantics></math> maps the audio <math id="A3.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="A3.p1.2.m2.1a"><mi id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b"><ci id="A3.p1.2.m2.1.1.cmml" xref="A3.p1.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">A</annotation></semantics></math> to the feature vector <math id="A3.p1.3.m3.1" class="ltx_Math" alttext="f_{a}" display="inline"><semantics id="A3.p1.3.m3.1a"><msub id="A3.p1.3.m3.1.1" xref="A3.p1.3.m3.1.1.cmml"><mi id="A3.p1.3.m3.1.1.2" xref="A3.p1.3.m3.1.1.2.cmml">f</mi><mi id="A3.p1.3.m3.1.1.3" xref="A3.p1.3.m3.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.3.m3.1b"><apply id="A3.p1.3.m3.1.1.cmml" xref="A3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A3.p1.3.m3.1.1.1.cmml" xref="A3.p1.3.m3.1.1">subscript</csymbol><ci id="A3.p1.3.m3.1.1.2.cmml" xref="A3.p1.3.m3.1.1.2">ğ‘“</ci><ci id="A3.p1.3.m3.1.1.3.cmml" xref="A3.p1.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.3.m3.1c">f_{a}</annotation></semantics></math>. We use pre-trained Wav2Vec2.0Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and HuBERTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> models developed by Facebook AI for <math id="A3.p1.4.m4.1" class="ltx_Math" alttext="\Phi_{a}" display="inline"><semantics id="A3.p1.4.m4.1a"><msub id="A3.p1.4.m4.1.1" xref="A3.p1.4.m4.1.1.cmml"><mi mathvariant="normal" id="A3.p1.4.m4.1.1.2" xref="A3.p1.4.m4.1.1.2.cmml">Î¦</mi><mi id="A3.p1.4.m4.1.1.3" xref="A3.p1.4.m4.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.4.m4.1b"><apply id="A3.p1.4.m4.1.1.cmml" xref="A3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A3.p1.4.m4.1.1.1.cmml" xref="A3.p1.4.m4.1.1">subscript</csymbol><ci id="A3.p1.4.m4.1.1.2.cmml" xref="A3.p1.4.m4.1.1.2">Î¦</ci><ci id="A3.p1.4.m4.1.1.3.cmml" xref="A3.p1.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.4.m4.1c">\Phi_{a}</annotation></semantics></math>. Both models leverage extensive unlabeled data for unsupervised pretraining to learn high-dimensional speech representations. HuBERT extends its semi-supervised learning approach with pseudo-labels to self-supervised learning. In our experiments, we use <a target="_blank" href="https://huggingface.co/facebook/wav2vec2-base-960h" title="" class="ltx_ref ltx_href ltx_font_typewriter">wav2vec2-base-960h</a> and <a target="_blank" href="https://huggingface.co/facebook/hubert-base-ls960" title="" class="ltx_ref ltx_href ltx_font_typewriter">hubert-base-ls960</a> for the base model, and <a target="_blank" href="https://huggingface.co/facebook/wav2vec2-large-960h-lv60-self" title="" class="ltx_ref ltx_href ltx_font_typewriter">wav2vec2-large-960h-lv60-self</a> and <a target="_blank" href="https://huggingface.co/facebook/hubert-large-ls960-ft" title="" class="ltx_ref ltx_href ltx_font_typewriter">hubert-large-ls960-ft</a> for the large model as the audio feature extractor <math id="A3.p1.5.m5.1" class="ltx_Math" alttext="\Phi_{a}" display="inline"><semantics id="A3.p1.5.m5.1a"><msub id="A3.p1.5.m5.1.1" xref="A3.p1.5.m5.1.1.cmml"><mi mathvariant="normal" id="A3.p1.5.m5.1.1.2" xref="A3.p1.5.m5.1.1.2.cmml">Î¦</mi><mi id="A3.p1.5.m5.1.1.3" xref="A3.p1.5.m5.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.5.m5.1b"><apply id="A3.p1.5.m5.1.1.cmml" xref="A3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A3.p1.5.m5.1.1.1.cmml" xref="A3.p1.5.m5.1.1">subscript</csymbol><ci id="A3.p1.5.m5.1.1.2.cmml" xref="A3.p1.5.m5.1.1.2">Î¦</ci><ci id="A3.p1.5.m5.1.1.3.cmml" xref="A3.p1.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.5.m5.1c">\Phi_{a}</annotation></semantics></math>.</p>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Limitation and Future Work</h2>

<div id="A4.p1" class="ltx_para ltx_noindent">
<p id="A4.p1.1" class="ltx_p">Our dataset closely associates piano music with hand movements. Due to data diversity, we have not yet aligned piano positions in all videos. We plan to engage extra experts to annotate piano key positions for more precise spatial alignment in the next version. Additionally, the variance in piano tones across recordings may also affect the baseline modelâ€™s performance.</p>
</div>
<div id="A4.p2" class="ltx_para ltx_noindent">
<p id="A4.p2.1" class="ltx_p">PianoMotion10M provides piano music, corresponding MIDI files, and hand poses, offering researchers a valuable resource for studying human-piano interaction. This dataset enables the analysis of piano music through hand gestures and the generation of hand poses from audio tracks. With PianoMotion10M, we hope to benefit and facilitate further research in relevant fields.</p>
</div>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Ethical Considerations</h2>

<div id="A5.p1" class="ltx_para ltx_noindent">
<p id="A5.p1.1" class="ltx_p">Piano motion datasets may pose significant privacy challenges, particularly concerning the pianistâ€™s identifiable aspect, mainly their hands, during piano performance. Our dataset comprises videos uploaded by users on Bilibili, which are publicly accessible.
To address privacy risks, we adopt a strict policy of releasing only video IDs, not the videos or images directly. Furthermore, we employ the MANO hand prior modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> as a form of robust anonymization. This approach ensures the protection of personal information, mitigates the risk of individual identification, and minimizes privacy concerns. With these precautions, our dataset enables valuable research in piano motion analysis and generation.</p>
</div>
</section>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Author Statement</h2>

<div id="A6.p1" class="ltx_para ltx_noindent">
<p id="A6.p1.1" class="ltx_p">The authors bear all responsibility in case of violation of rights. We confirm that the PianoMotion10M dataset is open-sourced under the <a target="_blank" href="https://creativecommons.org/licenses/by-nc/4.0/" title="" class="ltx_ref ltx_href">CC BY-NC 4.0</a> International license and the released code is publicly available under the <a target="_blank" href="http://www.apache.org/licenses/" title="" class="ltx_ref ltx_href">Apache-2.0</a> license, ensuring open access and permissive usage for academic and research purposes.</p>
</div>
</section>
<section id="A7" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>License and Consent with Public Resources</h2>

<section id="A7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.1 </span>Tools for Annotation</h3>

<div id="A7.SS1.p1" class="ltx_para ltx_noindent">
<p id="A7.SS1.p1.1" class="ltx_p">The piano audios were transcribed by piano_transcription_inferenceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and the hand poses of the MANO modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> in videos were annotated with MediaPipeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> and HaMeRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>:</p>
</div>
<div id="A7.SS1.p2" class="ltx_para ltx_noindent">
<ul id="A7.I1" class="ltx_itemize">
<li id="A7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I1.i1.p1" class="ltx_para">
<p id="A7.I1.i1.p1.1" class="ltx_p">piano_transcription_inference<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/bytedance/piano_transcription" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/bytedance/piano_transcription</a>.</span></span></span> Apache License 2.0</p>
</div>
</li>
<li id="A7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I1.i2.p1" class="ltx_para">
<p id="A7.I1.i2.p1.1" class="ltx_p">MANO<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://mano.is.tue.mpg.de/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://mano.is.tue.mpg.de/</a>.</span></span></span> CC BY-NC</p>
</div>
</li>
<li id="A7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I1.i3.p1" class="ltx_para">
<p id="A7.I1.i3.p1.1" class="ltx_p">MediaPipe<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://ai.google.dev/edge/mediapipe" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ai.google.dev/edge/mediapipe</a>.</span></span></span> Apache License 2.0</p>
</div>
</li>
<li id="A7.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="A7.I1.i4.p1.1" class="ltx_p">HaMeR<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://github.com/geopavlakos/hamer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/geopavlakos/hamer</a>.</span></span></span> MIT License</p>
</div>
</li>
</ul>
</div>
</section>
<section id="A7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.2 </span>Models for Baseline</h3>

<div id="A7.SS2.p1" class="ltx_para ltx_noindent">
<p id="A7.SS2.p1.1" class="ltx_p">Pre-trained Wav2Vec2.0Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and HuBERTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> were utilized as audio feature extractor, while transformerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> approach and SSM-based modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> were employed as our feature decoder:</p>
</div>
<div id="A7.SS2.p2" class="ltx_para ltx_noindent">
<ul id="A7.I2" class="ltx_itemize">
<li id="A7.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I2.i1.p1" class="ltx_para">
<p id="A7.I2.i1.p1.1" class="ltx_p">Wav2Vec2.0<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec</a>.</span></span></span> MIT license</p>
</div>
</li>
<li id="A7.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I2.i2.p1" class="ltx_para">
<p id="A7.I2.i2.p1.1" class="ltx_p">HuBERT<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://github.com/pytorch/fairseq/tree/master/examples/hubert" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/pytorch/fairseq/tree/master/examples/hubert</a>.</span></span></span> MIT license</p>
</div>
</li>
<li id="A7.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I2.i3.p1" class="ltx_para">
<p id="A7.I2.i3.p1.1" class="ltx_p">Transformer<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://github.com/huggingface/transformers" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/transformers</a>.</span></span></span> Apache License 2.0</p>
</div>
</li>
<li id="A7.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I2.i4.p1" class="ltx_para ltx_noindent">
<p id="A7.I2.i4.p1.1" class="ltx_p">SSM<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://github.com/state-spaces/mamba" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/state-spaces/mamba</a>.</span></span></span> Apache License 2.0</p>
</div>
</li>
</ul>
</div>
</section>
<section id="A7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.3 </span>Re-evaluated Methods</h3>

<div id="A7.SS3.p1" class="ltx_para ltx_noindent">
<p id="A7.SS3.p1.1" class="ltx_p">In the experimental section, we evaluated EmoTalkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> and LivelySpeakerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>, and models were reproduced using the official code:</p>
</div>
<div id="A7.SS3.p2" class="ltx_para ltx_noindent">
<ul id="A7.I3" class="ltx_itemize">
<li id="A7.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I3.i1.p1" class="ltx_para">
<p id="A7.I3.i1.p1.1" class="ltx_p">EmoTalk<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a target="_blank" href="https://github.com/psyai-net/EmoTalk_release" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/psyai-net/EmoTalk_release</a>.</span></span></span> CC BY-NC 4.0</p>
</div>
</li>
<li id="A7.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A7.I3.i2.p1" class="ltx_para ltx_noindent">
<p id="A7.I3.i2.p1.1" class="ltx_p">LivelySpeaker<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://github.com/zyhbili/LivelySpeaker" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/zyhbili/LivelySpeaker</a>.</span></span></span> Unknown</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.09325" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.09326" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.09326">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.09326" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.09327" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 22:11:21 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
