<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.06264] Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.06264">

<!--Generated on Thu Sep  5 16:47:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Audio Enhancement for Computer Audition 
<br class="ltx_break">– An Iterative Training Paradigm Using Sample Importance</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Manuel <span id="1.1" class="ltx_text" style="color:#0000FF;">Milling<sup id="1.1.1" class="ltx_sup"><span id="1.1.1.1" class="ltx_text ltx_font_italic" style="color:#000000;">1,2,3,∗</span></sup></span>, Shuo Liu<sup id="12.6.2" class="ltx_sup"><span id="12.6.2.1" class="ltx_text ltx_font_italic">1</span></sup> (刘硕),
Andreas Triantafyllopoulos<sup id="13.7.3" class="ltx_sup"><span id="13.7.3.1" class="ltx_text ltx_font_italic">1,2,3</span></sup>, Ilhan Aslan<sup id="14.8.4" class="ltx_sup"><span id="14.8.4.1" class="ltx_text ltx_font_italic">4</span></sup>,
and Björn W. Schuller<sup id="15.9.5" class="ltx_sup"><span id="15.9.5.1" class="ltx_text ltx_font_italic">1,2,3,5,6</span></sup>
</span></span>
</div>

<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text" style="font-size:90%;">Manuel Milling, Shuo Liu, Andreas Triantafyllopoulos <span id="p1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> Journal of computer science and technology: Instruction for authors.
JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY  33(1): 1–<span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title">Audio Enhancement for Computer Audition <span class="ltx_text"> </span>– An Iterative Training Paradigm Using Sample Importance</span></span>
 January 2018. DOI 10.1007/s11390-015-0000-0</span></p>
</div>
<div id="id6" class="ltx_para">
<p id="id6.1" class="ltx_p ltx_align_left"><sup id="id6.1.1" class="ltx_sup"><span id="id6.1.1.1" class="ltx_text ltx_font_italic">1</span></sup><span id="id6.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">EIHW – Chair of Embedded Intelligence for Health Care &amp; Wellbeing, University of Augsburg, Germany</span></p>
</div>
<div id="id7" class="ltx_para">
<p id="id7.1" class="ltx_p ltx_align_left"><sup id="id7.1.1" class="ltx_sup"><span id="id7.1.1.1" class="ltx_text ltx_font_italic">2</span></sup><span id="id7.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CHI – Chair of Health Informatics, MRI, Technical University of Munich, Germany</span></p>
</div>
<div id="id8" class="ltx_para">
<p id="id8.1" class="ltx_p ltx_align_left"><sup id="id8.1.1" class="ltx_sup"><span id="id8.1.1.1" class="ltx_text ltx_font_italic">3</span></sup><span id="id8.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">MCML – Munich Center for Machine Learning, Germany</span></p>
</div>
<div id="id9" class="ltx_para">
<p id="id9.1" class="ltx_p ltx_align_left"><sup id="id9.1.1" class="ltx_sup"><span id="id9.1.1.1" class="ltx_text ltx_font_italic">4</span></sup><span id="id9.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Huawei Technologies, Munich, Germany</span></p>
</div>
<div id="id10" class="ltx_para">
<p id="id10.1" class="ltx_p ltx_align_left"><sup id="id10.1.1" class="ltx_sup"><span id="id10.1.1.1" class="ltx_text ltx_font_italic">5</span></sup><span id="id10.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">MDSI – Munich Data Science Institute, Germany</span></p>
</div>
<div id="id11" class="ltx_para">
<p id="id11.1" class="ltx_p ltx_align_left"><sup id="id11.1.1" class="ltx_sup"><span id="id11.1.1.1" class="ltx_text ltx_font_italic">6</span></sup><span id="id11.1.2" class="ltx_text ltx_font_italic" style="font-size:90%;">GLAM – the Group on Language, Audio,
&amp; Music, Imperial College London, UK</span></p>
</div>
<div id="p2" class="ltx_para ltx_noindent">
<p id="p2.1" class="ltx_p">E-mail: manuel.milling@tum.de; shuo.liu@informatik.uni-augsburg.de; andreas.triantafyllopoulos@tum.de; ilhan.aslan@huawei.com; schuller@tum.de
<br class="ltx_break"></p>
</div>
<div id="p3" class="ltx_para ltx_noindent">
<p id="p3.1" class="ltx_p">Received October 26, 2022; accepted March 08, 2024.
<br class="ltx_break"></p>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span>
<br class="ltx_break"> Regular Paper
<br class="ltx_break">
 by the National Natural Science Foundation of China under Grant Nos. ******** and ********, the National High Technology Research and Development 863 Program of China under Grant No. ********, the National Basic Research 973 Program of China under Grant No. ********, and the Natural Science Foundation of Shandong Province of China under Grant No. *******. 
<br class="ltx_break">
 <sup id="footnotex1.1" class="ltx_sup">∗</sup>Corresponding Author

<br class="ltx_break"> <sup id="footnotex1.2" class="ltx_sup"><span id="footnotex1.2.1" class="ltx_text ltx_font_italic">\tiny1⃝</span></sup><a target="_blank" href="https://jcst.ict.ac.cn/Guidelines_for_Authors" title="" class="ltx_ref ltx_href">https://jcst.ict.ac.cn/Guidelines_for_Authors</a>, Dec. 2023.

<br class="ltx_break"> ©Institute of Computing Technology, Chinese Academy of Sciences 2021</span></span></span>
<div id="p4" class="ltx_para ltx_noindent">
<p id="p4.1" class="ltx_p"><span id="p4.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Abstract</span>  <span id="p4.1.2" class="ltx_text" style="font-size:90%;">Neural network models for audio tasks, such as automatic speech recognition (ASR) and acoustic scene classification (ASC), are susceptible to noise contamination for real-life applications. To improve audio quality, an enhancement module, which can be developed independently, is explicitly used at the front-end of the target audio applications.
In this paper, we present an end-to-end learning solution to jointly optimise the models for audio enhancement (AE) and the subsequent applications.
To guide the optimisation of the AE module towards a target application, and especially to overcome difficult samples, we make use of the sample-wise performance measure as an indication of sample importance.
In experiments, we consider four representative applications to evaluate our training paradigm, i.e., ASR, speech command recognition
(SCR), speech emotion recognition (SER), and ASC.
These applications are associated with speech and non-speech tasks concerning semantic and non-semantic features, transient and global information,
and the experimental results indicate that our proposed approach can considerably boost the noise robustness of the models, especially at low signal-to-noise ratios (SNRs), for a wide range of computer audition tasks in everyday-life noisy environments.
</span></p>
</div>
<div id="p5" class="ltx_para ltx_noindent">
<p id="p5.1" class="ltx_p"><span id="p5.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Keywords</span>  <span id="p5.1.2" class="ltx_text" style="font-size:90%;">audio enhancement, computer audition, joint optimisation, multi-task learning, voice suppression</span></p>
</div>
<div class="ltx_pagination ltx_role_start_2_columns"></div>
<section id="S1" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span title="" class="ltx_glossaryref">Computer audition (CA)</span> is one of the most prominent fields currently being revolutionised by the advent of <span title="" class="ltx_glossaryref">deep learning (DL)</span>, with <span title="" class="ltx_glossaryref">deep neural networks (DNNs)</span> increasingly becoming the state-of-the-art in a multitude of applications, such as the ones discussed in this work: <span title="" class="ltx_glossaryref">speech command recognition (SCR)</span> <cite class="ltx_cite ltx_citemacro_citep">(De Andrade et al., <a href="#bib.bib12" title="" class="ltx_ref">2018</a>)</cite>, <span title="" class="ltx_glossaryref">automatic speech recognition (ASR)</span> <cite class="ltx_cite ltx_citemacro_citep">(Baevski et al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite>, <span title="" class="ltx_glossaryref">speech emotion recognition (SER)</span> <cite class="ltx_cite ltx_citemacro_citep">(Wagner et al., <a href="#bib.bib54" title="" class="ltx_ref">2022</a>)</cite>, and <span title="" class="ltx_glossaryref">acoustic scene classification (ASC)</span> <cite class="ltx_cite ltx_citemacro_citep">(Ren et al., <a href="#bib.bib43" title="" class="ltx_ref">2019</a>)</cite>.
However, these applications are susceptible to different heterogeneities present in real-life conditions.
Taking <span title="" class="ltx_glossaryref">ASR</span> as an example, this may include amongst other within- and cross-speaker variations, for instance, disfluencies, differences in language, and recording devices and setups.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">One of the most prominent causes that impedes the practical application of <span title="" class="ltx_glossaryref">CA</span> models is the innumerable types of ambient noises or interference that deteriorate the audio recording, including environmental background noise, interfering speakers, reverberation, etc.
The sound of these noises can be stationary or non-stationary, instantaneous or continuous, and can be of different intensities (stable or variable), all of which have audio models confronting diverse and very complex situations.
Meanwhile, in practical applications, multiple interfering sources can be present at the same time, each affecting the effectiveness of such audio models to a different extent.
Hence, while considerable performance improvements are leading to the continuous adoption of <span title="" class="ltx_glossaryref">CA</span> modules in several <span title="" class="ltx_glossaryref">artificial intelligence (AI)</span> pipelines, <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">robustness to noise</em> remains a critical consideration for most of them.
This has led to an accompanying rise of <span title="" class="ltx_glossaryref">audio enhancement (AE)</span> methods, which typically also fall under the auspices of <span title="" class="ltx_glossaryref">DL</span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib30" title="" class="ltx_ref">2021a</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To that end, we present a novel framework for general <span title="" class="ltx_glossaryref">audio enhancement</span> targeted towards increased robustness of different <span title="" class="ltx_glossaryref">computer audition task</span> s.
In this framework, the cascaded <span title="" class="ltx_glossaryref">AE</span> and <span title="" class="ltx_glossaryref">CA</span> models perform two iterative training steps, strengthening the interplay between the different components of a <span title="" class="ltx_glossaryref">DL</span> pipeline to minimise potential mismatches and benefit from potential synergies.
The motivation is that the <span title="" class="ltx_glossaryref">computer audition task (CAT)</span> model can guide the <span title="" class="ltx_glossaryref">AE</span> frontend to preserve those signal components that are particularly important for the task at hand; for instance, an <span title="" class="ltx_glossaryref">AE</span> frontend for <span title="" class="ltx_glossaryref">ASR</span> might be optimised to improve the intelligibility of the signal, whilst a <span title="" class="ltx_glossaryref">SER</span> frontend might focus on the preservation of prosody instead, as this property is more important for the identification of emotional information.
Contrary to conventional joint optimisation, samples are not treated equally, but we utilise the loss of the target CAT model as an indication of difficulty in order to guide the training of <span title="" class="ltx_glossaryref">AE</span> towards harder samples.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We hypothesise that the proposed training framework utilises the symbiotic and interdependent nature between the AE and CAT models, and thus counterbalances and mutually promotes the models to reach an optimal performance of the entire system.
The technique is experimentally assessed using four relevant target <span title="" class="ltx_glossaryref">CA</span> applications, aiming to cover a broad spectrum from linguistic speech content in the case of <span title="" class="ltx_glossaryref">automatic speech recognition</span> and <span title="" class="ltx_glossaryref">speech command recognition</span>, to acoustic speech content in the case of <span title="" class="ltx_glossaryref">speech emotion recognition</span>, to ambient audio in the case of <span title="" class="ltx_glossaryref">acoustic scene classification</span>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The remainder of the paper is organised as follows. In <a href="#S3" title="3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>, we provide an overview of our methodology, including the U-Net-based SE model, as well as the different CAT models. Then, we detail the utilised datasets and experiments and report our results in <a href="#S4" title="4 Experimental Results ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4</span></a>, before putting said results in perspective in <a href="#S5" title="5 Discussion ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a>. Finally, we conclude our work and point towards future research directories in <a href="#S6" title="6 Conclusion ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.06264/assets/x1.png" id="S1.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="410" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S1.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Cold cascade + data augmentation</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.06264/assets/x2.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="410" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S1.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Multi-task learning</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S1.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.06264/assets/x3.png" id="S1.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="410" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S1.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">Iterative optimisation</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.5.2.1" class="ltx_text" style="font-size:80%;">Fig.​​ 1</span>: </span><span id="S1.F1.2.1" class="ltx_text" style="font-size:90%;">Diagrams showing the methodologies used. The red arrows demonstrate the back-propagation through the network modules with respect to the losses <math id="S1.F1.2.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S1.F1.2.1.m1.1b"><mi id="S1.F1.2.1.m1.1.1" xref="S1.F1.2.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S1.F1.2.1.m1.1c"><ci id="S1.F1.2.1.m1.1.1.cmml" xref="S1.F1.2.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.2.1.m1.1d">L</annotation></semantics></math> of the AE and the CAT. In a) only the CAT loss is optimised with a frozen AE, whilst the optimisation in b) is based on the CAT and the AE loss with the AE parameters being affected through both losses. In our suggested approach c) the parameters of the CAT and the AE are only affected through their respective loss with the AE including a sample-level importance in contrast to the previous approaches.
</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">At its core, the task of <span title="" class="ltx_glossaryref">AE</span> aims at the separation of the audio of interest from other interfering sounds, i. e., it aims at the preservation of the target signal while reducing the uncertainties in audio. The unwanted interference can be the result of several phenomena which affect different steps of the typical <span title="" class="ltx_glossaryref">CA</span> pipeline:

<span id="S2.I1" class="ltx_inline-enumerate">
<span id="S2.I1.i1" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">a)</span> <span id="S2.I1.i1.1" class="ltx_text">additive noise,
</span></span>
<span id="S2.I1.i2" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">b)</span> <span id="S2.I1.i2.1" class="ltx_text">reverberation,
</span></span>
<span id="S2.I1.i3" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">c)</span> <span id="S2.I1.i3.1" class="ltx_text">encoding noise, and,
</span></span>
<span id="S2.I1.i4" class="ltx_inline-item"><span class="ltx_tag ltx_tag_inline-item">d)</span> <span id="S2.I1.i4.1" class="ltx_text">package loss.
</span></span>
</span>
From these, additive noise has been most thoroughly studied in previous work, due to its ubiquitous presence in <span title="" class="ltx_glossaryref">CA</span> applications and its detrimental effects on performance <cite class="ltx_cite ltx_citemacro_citep">(Spille et al., <a href="#bib.bib49" title="" class="ltx_ref">2018</a>; Triantafyllopoulos et al., <a href="#bib.bib51" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Within <span title="" class="ltx_glossaryref">AE</span>, particular attention has traditionally been paid to <span title="" class="ltx_glossaryref">speech enhancement (SE)</span>, as a typical <span title="" class="ltx_glossaryref">CAT</span> is mostly focused on extracting information from the human voice.
<span title="" class="ltx_glossaryref">ASR</span>, being the flagship task of <span title="" class="ltx_glossaryref">computer audition</span>, is the primary testbed for most <span title="" class="ltx_glossaryref">SE</span> methods, with other tasks such as <span title="" class="ltx_glossaryref">SER</span> and <span title="" class="ltx_glossaryref">SCR</span> following closely.
However, enhancement of audio signals beyond speech is needed in a number of <span title="" class="ltx_glossaryref">CAT</span> s, such as <span title="" class="ltx_glossaryref">ASC</span> and <span title="" class="ltx_glossaryref">sound event detection (SED)</span>.
In contrast to the purpose of speech enhancement,
the presence of speech is often deemed as the noise that can considerably affect the identification of surrounding environments <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>. To tackle this problem, voice suppression, as another type of audio enhancement task, has the goal to eliminate the human voice from ambient recordings. These contradicting definitions of target audio signal and confounding noise show that a single one-shoe-fits-all solution for <span title="" class="ltx_glossaryref">AE</span> systems seems rather difficult to achieve.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Utilising <em id="S2.p3.1.1" class="ltx_emph ltx_font_italic">enhancement frontends</em>, i. e., separately developed enhancement modules (typically based on <span title="" class="ltx_glossaryref">DNNs</span>), can enhance the input for the subsequent <span title="" class="ltx_glossaryref">CA</span> models,
which can explicitly be empowered using <em id="S2.p3.1.2" class="ltx_emph ltx_font_italic">data augmentation</em> techniques, such as SpecAugment <cite class="ltx_cite ltx_citemacro_citep">(Park et al., <a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite> or additive noise <cite class="ltx_cite ltx_citemacro_citep">(Triantafyllopoulos et al., <a href="#bib.bib51" title="" class="ltx_ref">2019</a>)</cite> for their better robustness against expected perturbations.
This is typically performed for ASR tasks <cite class="ltx_cite ltx_citemacro_cite">Weninger et al. (<a href="#bib.bib59" title="" class="ltx_ref">2015</a>); Kinoshita et al. (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>); Sivasankaran et al. (<a href="#bib.bib48" title="" class="ltx_ref">2015</a>); Zorilă et al. (<a href="#bib.bib64" title="" class="ltx_ref">2019</a>)</cite>. However, in practice, such independent enhancement can introduce unwanted distortions and artefacts <cite class="ltx_cite ltx_citemacro_cite">Iwamoto et al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite> in the enhanced audio, yielding limited improvements or even worsen the performance of cascaded ASR models.
In order to improve the tolerance to these distortions, the ASR model can be trained based on the enhanced audio, which is sometimes referred to as joint training <cite class="ltx_cite ltx_citemacro_cite">Wang and Wang (<a href="#bib.bib57" title="" class="ltx_ref">2016</a>); Narayanan et al. (<a href="#bib.bib38" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">When optimising the ASR, the parameters of its frontend SE model can be either frozen or trainable. In the case of trainable parameters, the loss of the ASR task backpropagates through the whole combined model, i. e., the cascade of <span title="" class="ltx_glossaryref">SE</span> and <span title="" class="ltx_glossaryref">ASR</span>. This leads to a parameter update of the <span title="" class="ltx_glossaryref">SE</span> model based on the <span title="" class="ltx_glossaryref">ASR</span> loss <cite class="ltx_cite ltx_citemacro_cite">Wang and Wang (<a href="#bib.bib57" title="" class="ltx_ref">2016</a>)</cite>.
However, to have no explicit restrictions on the <span title="" class="ltx_glossaryref">SE</span> model during the training poses a risk to weaken or even corrupt the SE effect.
Considering the training objectives of SE and ASR together, recent work <cite class="ltx_cite ltx_citemacro_cite">Ma et al. (<a href="#bib.bib33" title="" class="ltx_ref">2021</a>); Chen et al. (<a href="#bib.bib9" title="" class="ltx_ref">2015</a>)</cite> frames the task into a multi-task learning problem, where the losses of SE and ASR are typically added up resulting in a combined optimisation. Other noteworthy approaches include the exploitation of more advanced deep learning techniques, such as generative adversarial networks (GANs) for SE <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib28" title="" class="ltx_ref">2019</a>); Li et al. (<a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite>, and self-supervised learning (SSL) for ASR <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a href="#bib.bib63" title="" class="ltx_ref">2022</a>)</cite>. The combination of the two losses is commonly scaled by a dynamic factor, which gradually shifts the training focus between the AE and ASR task <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>.
Joint training has also primarily been used in <span title="" class="ltx_glossaryref">SCR</span> or keyword spotting <cite class="ltx_cite ltx_citemacro_cite">Cámbara et al. (<a href="#bib.bib8" title="" class="ltx_ref">2022</a>); Gu et al. (<a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite>, however, it is rarely used in other <span title="" class="ltx_glossaryref">CA</span> applications. For most cases, the <span title="" class="ltx_glossaryref">SE</span> module is trained separately and then cascaded to the target CA models for noise reduction, as for <span title="" class="ltx_glossaryref">SER</span> <cite class="ltx_cite ltx_citemacro_cite">Triantafyllopoulos et al. (<a href="#bib.bib51" title="" class="ltx_ref">2019</a>); Zhou et al. (<a href="#bib.bib62" title="" class="ltx_ref">2020</a>)</cite> and <span title="" class="ltx_glossaryref">ASC</span> <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
<section id="S3" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodologies</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">At the core of our methodology we put two hypotheses, which are already partly supported by the literature, but have not yet been validated on a wide range of applications: 1) the enhancement of audio signals, which contain highly relevant information for a given computer audition task, as part of a processing pipeline, can improve the performance on the target task, and 2) a training procedure, which optimises the audio enhancement and the <span title="" class="ltx_glossaryref">CAT</span> jointly can specialise the audio enhancement module for task-specific signals and therefore lead to better performance on the <span title="" class="ltx_glossaryref">CAT</span>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">In order to further explore the hypotheses mentioned above, we report a set of experiments, based on <span title="" class="ltx_glossaryref">AE</span> models using a U-Net architecture, to explore several training paradigms, including the joint optimisation of the audio enhancement for the <span title="" class="ltx_glossaryref">CAT</span> s: automatic speech recognition, speech command recognition, speech emotion recognition and acoustic scene classification. Despite the difference in implementation details, the general framework stays the same amongst the different types of applications and is further illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
All data for AE and CATs is resampled to 16 kHz.</p>
</div>
<section id="S3.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Comparison Methods</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To assess the performance of our proposed iterative optimisation approach, we compare it with a wide range of methods commonly applied in the context of audio enhancement, which will be introduced in the following.
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Baseline
<br class="ltx_break"></span>The general baseline for all experiments is a CAT-specific model taken from related literature, which is not trained on any noise-specific data and does not use an AE component. The model is not specifically designed for robustness towards noise and we thus expect a noticeable performance drop-off when confronted with noisy data.
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Data Augmentation
<br class="ltx_break"></span>In a first attempt to make the baseline model more robust, we train it on noise-augmented data. For this purpose, we artificially add noise with different SNR ratios to the mostly clean audio recordings. With data augmentation being one of the most common machine learning practices to increase robustness, we expect the model to perform better on the noisy test data, which was generated in the same manner as the train data. 
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Cold Cascade
<br class="ltx_break"></span>The simplest training paradigm with an AE component is a cold cascade of U-Net, as described in section <a href="#S3.SS3" title="3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> and CAT-specific model. Cold cascade means in this context that both models are being optimised independently. First, the U-Net is trained to achieve a good AE performance, then, the CAT model is trained based on clean data and then stacked on top of the U-Net.
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">Cold Cascade + Data Augmentation
<br class="ltx_break"></span>We further combine the cold cascade and data augmentation approach, i. e., first, the U-Net is trained to achieve a good AE performance, and then,
we train the cold cascade architecture with augmented, noisy data. This approach promises decent noise robustness, as the model has previously seen noisy data and it includes a powerful AE component.
<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p6" class="ltx_para ltx_noindent">
<p id="S3.SS1.p6.1" class="ltx_p"><span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_bold">State-of-the-art
<br class="ltx_break"></span>To further evaluate the effectiveness of our methods against the state-of-the-art, we additionally utilise two recent denoising methods; this we only do for one of the CA tasks (SCR) due to space limitations.
Specifically, we use MetricGAN+ <cite class="ltx_cite ltx_citemacro_citep">(Fu et al., <a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite> and DeepFilterNet-3 (DFNet-3) <cite class="ltx_cite ltx_citemacro_citep">(Schröter et al., <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>.
MetricGAN+ is a bLSTM model trained in generative-adversarial fashion to optimise perceptual losses; the training set is VoiceBank-DEMAND <cite class="ltx_cite ltx_citemacro_citep">(Valentini-Botinhao et al., <a href="#bib.bib53" title="" class="ltx_ref">2016</a>)</cite>.
DFNet-3, on the other hand, follows a two-stage approach with ERB-based enhancement followed by deep filtering to enhance the periodicity of the output signal and has been trained with a multi-spectral loss on DNS-4 <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al., <a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite>, which is closer to our current setup (i. e., the noise data partially comes from AudioSet).
Both models are used to enhance the noisy mixtures of SCR on which we evaluate the baseline model trained without data augmentation on the original data; they thus simulate the scenario of using an off-the-shelf denoising model before evaluation.
This setup is essentially equivalent to Cold Cascade, only this time using different models.

<br class="ltx_break"></p>
</div>
<div id="S3.SS1.p7" class="ltx_para ltx_noindent">
<p id="S3.SS1.p7.3" class="ltx_p"><span id="S3.SS1.p7.3.1" class="ltx_text ltx_font_bold">Multi-Task Learning
<br class="ltx_break"></span>We finally compare our method to an implementation of multi-task learning, i. e., an optimisation of both the <span title="" class="ltx_glossaryref">AE</span> task and the <span title="" class="ltx_glossaryref">CAT</span> at the same time with an additive loss function</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="L=L_{\mathrm{AE}}+L_{\mathrm{CA}}," display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">L</mi><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><msub id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">L</mi><mi id="S3.E1.m1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.3.2.3.cmml">AE</mi></msub><mo id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.2.cmml">L</mi><mi id="S3.E1.m1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.cmml">CA</mi></msub></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><ci id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2">𝐿</ci><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><plus id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"></plus><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">𝐿</ci><ci id="S3.E1.m1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3">AE</ci></apply><apply id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2">𝐿</ci><ci id="S3.E1.m1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3">CA</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">L=L_{\mathrm{AE}}+L_{\mathrm{CA}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p7.2" class="ltx_p">where <math id="S3.SS1.p7.1.m1.1" class="ltx_Math" alttext="L_{\mathrm{AE}}" display="inline"><semantics id="S3.SS1.p7.1.m1.1a"><msub id="S3.SS1.p7.1.m1.1.1" xref="S3.SS1.p7.1.m1.1.1.cmml"><mi id="S3.SS1.p7.1.m1.1.1.2" xref="S3.SS1.p7.1.m1.1.1.2.cmml">L</mi><mi id="S3.SS1.p7.1.m1.1.1.3" xref="S3.SS1.p7.1.m1.1.1.3.cmml">AE</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.1.m1.1b"><apply id="S3.SS1.p7.1.m1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p7.1.m1.1.1.2.cmml" xref="S3.SS1.p7.1.m1.1.1.2">𝐿</ci><ci id="S3.SS1.p7.1.m1.1.1.3.cmml" xref="S3.SS1.p7.1.m1.1.1.3">AE</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.1.m1.1c">L_{\mathrm{AE}}</annotation></semantics></math> is the loss of the speech enhancement task as presented in (<a href="#S3.E5" title="Equation 5 ‣ 3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) and <math id="S3.SS1.p7.2.m2.1" class="ltx_Math" alttext="L_{\mathrm{CA}}" display="inline"><semantics id="S3.SS1.p7.2.m2.1a"><msub id="S3.SS1.p7.2.m2.1.1" xref="S3.SS1.p7.2.m2.1.1.cmml"><mi id="S3.SS1.p7.2.m2.1.1.2" xref="S3.SS1.p7.2.m2.1.1.2.cmml">L</mi><mi id="S3.SS1.p7.2.m2.1.1.3" xref="S3.SS1.p7.2.m2.1.1.3.cmml">CA</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.2.m2.1b"><apply id="S3.SS1.p7.2.m2.1.1.cmml" xref="S3.SS1.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.2.m2.1.1.1.cmml" xref="S3.SS1.p7.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p7.2.m2.1.1.2.cmml" xref="S3.SS1.p7.2.m2.1.1.2">𝐿</ci><ci id="S3.SS1.p7.2.m2.1.1.3.cmml" xref="S3.SS1.p7.2.m2.1.1.3">CA</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.2.m2.1c">L_{\mathrm{CA}}</annotation></semantics></math> is the loss of the computer audition task.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<p id="S3.SS1.p8.1" class="ltx_p">In contrast to common applications of multi-task learning, the two models do not only share a certain set of layers but the AE and CA models are put in sequence of each other, i. e., the AE loss is derived from an intermediate layer of the overall system.
Thus, minimising the <span title="" class="ltx_glossaryref">AE</span> loss has no effect on the parameters of the <span title="" class="ltx_glossaryref">CA</span> model, while the <span title="" class="ltx_glossaryref">CA</span> loss back-propagates through the AE model.
Consequently, the <span title="" class="ltx_glossaryref">AE</span> and the <span title="" class="ltx_glossaryref">CA</span> losses, whilst working as mutual regularisation terms, introduce a bias towards the update of the AE parameters.
Similar ideas have been explored for the structure of a supervised auto-encoder <cite class="ltx_cite ltx_citemacro_cite">Le et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Iterative Optimisation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Similar to the concept of multitask learning, the main motivation behind an iterative optimisation approach is a joint view of the two models. At its core, there are two hypotheses: 1) The CA model should always be adapted to the output of the AE model, which might contain residual noise, introduced speech distortions, artefacts, etc. This specialisation to specific characteristics of the AE can be considered as a form of domain adaptation of the CAT, which has long been shown to help alleviate performance<cite class="ltx_cite ltx_citemacro_cite">Ben-David et al. (<a href="#bib.bib6" title="" class="ltx_ref">2006</a>)</cite> 2) the performance of the CAT can be utilised to move the focus of the AE model onto particularly difficult samples. Thereby, we aim at achieving the optimum result of the entire neural system, i. e., the front-end audio processing and the subsequent target applications.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">The implementation of the iterative optimisation approach is straightforward, yet rarely considered in the literature: first, the optimisation of the AE model involves the loss of the target <span title="" class="ltx_glossaryref">CAT</span> as a reference to indicate the difficulty of each training sample. This plays the role of sample-level importance to assist the <span title="" class="ltx_glossaryref">AE</span> component to be biased towards relatively harder samples, for example, those corrupted by more intensive noise. Second, during training for the <span title="" class="ltx_glossaryref">CAT</span>, the model should process the enhanced audio signal, rather than the completely clean signal, in order to avoid a common performance gap resulting from a cold cascade of the front- and back-end models.
However, as long as the <span title="" class="ltx_glossaryref">AE</span> model is optimised, a more robust CA model needs to be adapted to the enhanced audio. On the other side, a more robust CA model can further assist the optimisation of the AE model by updating the difficulties of new samples.
Having this in mind, we hypothesise that both optimisation steps need to be performed iteratively to gradually approach an optimal solution.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In order to implement the latter idea, we calculate a weight for each sample in a given batch when optimising the AE model. The weight for each sample <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">i</annotation></semantics></math> is defined as</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="w_{i}=L_{\mathrm{CA}}(t_{i},\hat{t}_{i})," display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.4.cmml"><mi id="S3.E2.m1.1.1.1.1.4.2" xref="S3.E2.m1.1.1.1.1.4.2.cmml">w</mi><mi id="S3.E2.m1.1.1.1.1.4.3" xref="S3.E2.m1.1.1.1.1.4.3.cmml">i</mi></msub><mo id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml"><msub id="S3.E2.m1.1.1.1.1.2.4" xref="S3.E2.m1.1.1.1.1.2.4.cmml"><mi id="S3.E2.m1.1.1.1.1.2.4.2" xref="S3.E2.m1.1.1.1.1.2.4.2.cmml">L</mi><mi id="S3.E2.m1.1.1.1.1.2.4.3" xref="S3.E2.m1.1.1.1.1.2.4.3.cmml">CA</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.3.cmml">​</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.1.1.1.1.2.2.2.4" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E2.m1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.cmml">t</mi><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.2.1" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E2.m1.1.1.1.1.2.2.2.5" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"></eq><apply id="S3.E2.m1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.4.1.cmml" xref="S3.E2.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.4.2.cmml" xref="S3.E2.m1.1.1.1.1.4.2">𝑤</ci><ci id="S3.E2.m1.1.1.1.1.4.3.cmml" xref="S3.E2.m1.1.1.1.1.4.3">𝑖</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"><times id="S3.E2.m1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3"></times><apply id="S3.E2.m1.1.1.1.1.2.4.cmml" xref="S3.E2.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.4.1.cmml" xref="S3.E2.m1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.4.2.cmml" xref="S3.E2.m1.1.1.1.1.2.4.2">𝐿</ci><ci id="S3.E2.m1.1.1.1.1.2.4.3.cmml" xref="S3.E2.m1.1.1.1.1.2.4.3">CA</ci></apply><interval closure="open" id="S3.E2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2">𝑡</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2"><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.1">^</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2">𝑡</ci></apply><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">w_{i}=L_{\mathrm{CA}}(t_{i},\hat{t}_{i}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.3" class="ltx_p">with the target <math id="S3.SS2.p3.2.m1.1" class="ltx_Math" alttext="t_{i}" display="inline"><semantics id="S3.SS2.p3.2.m1.1a"><msub id="S3.SS2.p3.2.m1.1.1" xref="S3.SS2.p3.2.m1.1.1.cmml"><mi id="S3.SS2.p3.2.m1.1.1.2" xref="S3.SS2.p3.2.m1.1.1.2.cmml">t</mi><mi id="S3.SS2.p3.2.m1.1.1.3" xref="S3.SS2.p3.2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m1.1b"><apply id="S3.SS2.p3.2.m1.1.1.cmml" xref="S3.SS2.p3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m1.1.1.1.cmml" xref="S3.SS2.p3.2.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m1.1.1.2.cmml" xref="S3.SS2.p3.2.m1.1.1.2">𝑡</ci><ci id="S3.SS2.p3.2.m1.1.1.3.cmml" xref="S3.SS2.p3.2.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m1.1c">t_{i}</annotation></semantics></math> and the predicted target <math id="S3.SS2.p3.3.m2.1" class="ltx_Math" alttext="\hat{t}_{i}" display="inline"><semantics id="S3.SS2.p3.3.m2.1a"><msub id="S3.SS2.p3.3.m2.1.1" xref="S3.SS2.p3.3.m2.1.1.cmml"><mover accent="true" id="S3.SS2.p3.3.m2.1.1.2" xref="S3.SS2.p3.3.m2.1.1.2.cmml"><mi id="S3.SS2.p3.3.m2.1.1.2.2" xref="S3.SS2.p3.3.m2.1.1.2.2.cmml">t</mi><mo id="S3.SS2.p3.3.m2.1.1.2.1" xref="S3.SS2.p3.3.m2.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.p3.3.m2.1.1.3" xref="S3.SS2.p3.3.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m2.1b"><apply id="S3.SS2.p3.3.m2.1.1.cmml" xref="S3.SS2.p3.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m2.1.1.1.cmml" xref="S3.SS2.p3.3.m2.1.1">subscript</csymbol><apply id="S3.SS2.p3.3.m2.1.1.2.cmml" xref="S3.SS2.p3.3.m2.1.1.2"><ci id="S3.SS2.p3.3.m2.1.1.2.1.cmml" xref="S3.SS2.p3.3.m2.1.1.2.1">^</ci><ci id="S3.SS2.p3.3.m2.1.1.2.2.cmml" xref="S3.SS2.p3.3.m2.1.1.2.2">𝑡</ci></apply><ci id="S3.SS2.p3.3.m2.1.1.3.cmml" xref="S3.SS2.p3.3.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m2.1c">\hat{t}_{i}</annotation></semantics></math>.
The weights therefore give an indication of how difficult a given sample is for the <span title="" class="ltx_glossaryref">CAT</span>. We choose a linear relationship between the sample weight and the loss for the CAT as the most straightforward implementation, even though other approaches, such as softmax normalisation, are possible. This choice does not add any new hyperparameters, as linear scaling would only affect the training in the same way as changing the learning rate. In practice, we normalise the weights by dividing by their sum within one batch.
The loss of the <span title="" class="ltx_glossaryref">AE</span> component is then defined as</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_Math" alttext="L_{AE}^{\mathrm{I}}(x,\hat{x})=\frac{1}{N}\sum_{i=1}^{N}w_{i}L_{AE}(x_{i},\hat{x}_{i})," display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.4" xref="S3.E3.m1.3.3.1.1.4.cmml"><msubsup id="S3.E3.m1.3.3.1.1.4.2" xref="S3.E3.m1.3.3.1.1.4.2.cmml"><mi id="S3.E3.m1.3.3.1.1.4.2.2.2" xref="S3.E3.m1.3.3.1.1.4.2.2.2.cmml">L</mi><mrow id="S3.E3.m1.3.3.1.1.4.2.2.3" xref="S3.E3.m1.3.3.1.1.4.2.2.3.cmml"><mi id="S3.E3.m1.3.3.1.1.4.2.2.3.2" xref="S3.E3.m1.3.3.1.1.4.2.2.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.4.2.2.3.1" xref="S3.E3.m1.3.3.1.1.4.2.2.3.1.cmml">​</mo><mi id="S3.E3.m1.3.3.1.1.4.2.2.3.3" xref="S3.E3.m1.3.3.1.1.4.2.2.3.3.cmml">E</mi></mrow><mi mathvariant="normal" id="S3.E3.m1.3.3.1.1.4.2.3" xref="S3.E3.m1.3.3.1.1.4.2.3.cmml">I</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.4.1" xref="S3.E3.m1.3.3.1.1.4.1.cmml">​</mo><mrow id="S3.E3.m1.3.3.1.1.4.3.2" xref="S3.E3.m1.3.3.1.1.4.3.1.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.1.1.4.3.2.1" xref="S3.E3.m1.3.3.1.1.4.3.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">x</mi><mo id="S3.E3.m1.3.3.1.1.4.3.2.2" xref="S3.E3.m1.3.3.1.1.4.3.1.cmml">,</mo><mover accent="true" id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><mi id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml">x</mi><mo id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S3.E3.m1.3.3.1.1.4.3.2.3" xref="S3.E3.m1.3.3.1.1.4.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.3" xref="S3.E3.m1.3.3.1.1.3.cmml">=</mo><mrow id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.1.2.cmml"><mfrac id="S3.E3.m1.3.3.1.1.2.4" xref="S3.E3.m1.3.3.1.1.2.4.cmml"><mn id="S3.E3.m1.3.3.1.1.2.4.2" xref="S3.E3.m1.3.3.1.1.2.4.2.cmml">1</mn><mi id="S3.E3.m1.3.3.1.1.2.4.3" xref="S3.E3.m1.3.3.1.1.2.4.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.2.3" xref="S3.E3.m1.3.3.1.1.2.3.cmml">​</mo><mrow id="S3.E3.m1.3.3.1.1.2.2" xref="S3.E3.m1.3.3.1.1.2.2.cmml"><munderover id="S3.E3.m1.3.3.1.1.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.3.cmml"><mo movablelimits="false" id="S3.E3.m1.3.3.1.1.2.2.3.2.2" xref="S3.E3.m1.3.3.1.1.2.2.3.2.2.cmml">∑</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.3.2.3" xref="S3.E3.m1.3.3.1.1.2.2.3.2.3.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.3.2.3.2" xref="S3.E3.m1.3.3.1.1.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E3.m1.3.3.1.1.2.2.3.2.3.1" xref="S3.E3.m1.3.3.1.1.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E3.m1.3.3.1.1.2.2.3.2.3.3" xref="S3.E3.m1.3.3.1.1.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.3.3.1.1.2.2.3.3" xref="S3.E3.m1.3.3.1.1.2.2.3.3.cmml">N</mi></munderover><mrow id="S3.E3.m1.3.3.1.1.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.cmml"><msub id="S3.E3.m1.3.3.1.1.2.2.2.4" xref="S3.E3.m1.3.3.1.1.2.2.2.4.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.2.4.2" xref="S3.E3.m1.3.3.1.1.2.2.2.4.2.cmml">w</mi><mi id="S3.E3.m1.3.3.1.1.2.2.2.4.3" xref="S3.E3.m1.3.3.1.1.2.2.2.4.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.2.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml">​</mo><msub id="S3.E3.m1.3.3.1.1.2.2.2.5" xref="S3.E3.m1.3.3.1.1.2.2.2.5.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.2.5.2" xref="S3.E3.m1.3.3.1.1.2.2.2.5.2.cmml">L</mi><mrow id="S3.E3.m1.3.3.1.1.2.2.2.5.3" xref="S3.E3.m1.3.3.1.1.2.2.2.5.3.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.2.5.3.2" xref="S3.E3.m1.3.3.1.1.2.2.2.5.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.2.2.2.5.3.1" xref="S3.E3.m1.3.3.1.1.2.2.2.5.3.1.cmml">​</mo><mi id="S3.E3.m1.3.3.1.1.2.2.2.5.3.3" xref="S3.E3.m1.3.3.1.1.2.2.2.5.3.3.cmml">E</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.2.2.2.3a" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml">​</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.2.4" xref="S3.E3.m1.3.3.1.1.2.2.2.2.3.cmml">,</mo><msub id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.cmml"><mover accent="true" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.cmml">x</mi><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.1" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.5" xref="S3.E3.m1.3.3.1.1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1"><eq id="S3.E3.m1.3.3.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.3"></eq><apply id="S3.E3.m1.3.3.1.1.4.cmml" xref="S3.E3.m1.3.3.1.1.4"><times id="S3.E3.m1.3.3.1.1.4.1.cmml" xref="S3.E3.m1.3.3.1.1.4.1"></times><apply id="S3.E3.m1.3.3.1.1.4.2.cmml" xref="S3.E3.m1.3.3.1.1.4.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.4.2.1.cmml" xref="S3.E3.m1.3.3.1.1.4.2">superscript</csymbol><apply id="S3.E3.m1.3.3.1.1.4.2.2.cmml" xref="S3.E3.m1.3.3.1.1.4.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.4.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.4.2">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.4.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.4.2.2.2">𝐿</ci><apply id="S3.E3.m1.3.3.1.1.4.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.4.2.2.3"><times id="S3.E3.m1.3.3.1.1.4.2.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.4.2.2.3.1"></times><ci id="S3.E3.m1.3.3.1.1.4.2.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.4.2.2.3.2">𝐴</ci><ci id="S3.E3.m1.3.3.1.1.4.2.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.4.2.2.3.3">𝐸</ci></apply></apply><ci id="S3.E3.m1.3.3.1.1.4.2.3.cmml" xref="S3.E3.m1.3.3.1.1.4.2.3">I</ci></apply><interval closure="open" id="S3.E3.m1.3.3.1.1.4.3.1.cmml" xref="S3.E3.m1.3.3.1.1.4.3.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝑥</ci><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><ci id="S3.E3.m1.2.2.1.cmml" xref="S3.E3.m1.2.2.1">^</ci><ci id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2">𝑥</ci></apply></interval></apply><apply id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2"><times id="S3.E3.m1.3.3.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.3"></times><apply id="S3.E3.m1.3.3.1.1.2.4.cmml" xref="S3.E3.m1.3.3.1.1.2.4"><divide id="S3.E3.m1.3.3.1.1.2.4.1.cmml" xref="S3.E3.m1.3.3.1.1.2.4"></divide><cn type="integer" id="S3.E3.m1.3.3.1.1.2.4.2.cmml" xref="S3.E3.m1.3.3.1.1.2.4.2">1</cn><ci id="S3.E3.m1.3.3.1.1.2.4.3.cmml" xref="S3.E3.m1.3.3.1.1.2.4.3">𝑁</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2"><apply id="S3.E3.m1.3.3.1.1.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3">superscript</csymbol><apply id="S3.E3.m1.3.3.1.1.2.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.3.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3">subscript</csymbol><sum id="S3.E3.m1.3.3.1.1.2.2.3.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.2.2"></sum><apply id="S3.E3.m1.3.3.1.1.2.2.3.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.2.3"><eq id="S3.E3.m1.3.3.1.1.2.2.3.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.2.3.1"></eq><ci id="S3.E3.m1.3.3.1.1.2.2.3.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.2.3.2">𝑖</ci><cn type="integer" id="S3.E3.m1.3.3.1.1.2.2.3.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.3.3.1.1.2.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3.3">𝑁</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2"><times id="S3.E3.m1.3.3.1.1.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.3"></times><apply id="S3.E3.m1.3.3.1.1.2.2.2.4.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.2.4.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.4">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.2.4.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.4.2">𝑤</ci><ci id="S3.E3.m1.3.3.1.1.2.2.2.4.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.4.3">𝑖</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.2.5.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.5"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.2.5.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.5">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.2.5.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.5.2">𝐿</ci><apply id="S3.E3.m1.3.3.1.1.2.2.2.5.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.5.3"><times id="S3.E3.m1.3.3.1.1.2.2.2.5.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.5.3.1"></times><ci id="S3.E3.m1.3.3.1.1.2.2.2.5.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.5.3.2">𝐴</ci><ci id="S3.E3.m1.3.3.1.1.2.2.2.5.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.5.3.3">𝐸</ci></apply></apply><interval closure="open" id="S3.E3.m1.3.3.1.1.2.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2"><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2">subscript</csymbol><apply id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2"><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.1">^</ci><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2">𝑥</ci></apply><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">L_{AE}^{\mathrm{I}}(x,\hat{x})=\frac{1}{N}\sum_{i=1}^{N}w_{i}L_{AE}(x_{i},\hat{x}_{i}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.5" class="ltx_p">with the noisy inputs <math id="S3.SS2.p3.4.m1.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS2.p3.4.m1.1a"><msub id="S3.SS2.p3.4.m1.1.1" xref="S3.SS2.p3.4.m1.1.1.cmml"><mi id="S3.SS2.p3.4.m1.1.1.2" xref="S3.SS2.p3.4.m1.1.1.2.cmml">x</mi><mi id="S3.SS2.p3.4.m1.1.1.3" xref="S3.SS2.p3.4.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m1.1b"><apply id="S3.SS2.p3.4.m1.1.1.cmml" xref="S3.SS2.p3.4.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m1.1.1.1.cmml" xref="S3.SS2.p3.4.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m1.1.1.2.cmml" xref="S3.SS2.p3.4.m1.1.1.2">𝑥</ci><ci id="S3.SS2.p3.4.m1.1.1.3.cmml" xref="S3.SS2.p3.4.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m1.1c">x_{i}</annotation></semantics></math> and the reconstructed signals <math id="S3.SS2.p3.5.m2.1" class="ltx_Math" alttext="\hat{x}_{i}" display="inline"><semantics id="S3.SS2.p3.5.m2.1a"><msub id="S3.SS2.p3.5.m2.1.1" xref="S3.SS2.p3.5.m2.1.1.cmml"><mover accent="true" id="S3.SS2.p3.5.m2.1.1.2" xref="S3.SS2.p3.5.m2.1.1.2.cmml"><mi id="S3.SS2.p3.5.m2.1.1.2.2" xref="S3.SS2.p3.5.m2.1.1.2.2.cmml">x</mi><mo id="S3.SS2.p3.5.m2.1.1.2.1" xref="S3.SS2.p3.5.m2.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.p3.5.m2.1.1.3" xref="S3.SS2.p3.5.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m2.1b"><apply id="S3.SS2.p3.5.m2.1.1.cmml" xref="S3.SS2.p3.5.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m2.1.1.1.cmml" xref="S3.SS2.p3.5.m2.1.1">subscript</csymbol><apply id="S3.SS2.p3.5.m2.1.1.2.cmml" xref="S3.SS2.p3.5.m2.1.1.2"><ci id="S3.SS2.p3.5.m2.1.1.2.1.cmml" xref="S3.SS2.p3.5.m2.1.1.2.1">^</ci><ci id="S3.SS2.p3.5.m2.1.1.2.2.cmml" xref="S3.SS2.p3.5.m2.1.1.2.2">𝑥</ci></apply><ci id="S3.SS2.p3.5.m2.1.1.3.cmml" xref="S3.SS2.p3.5.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m2.1c">\hat{x}_{i}</annotation></semantics></math>.
In the iterative training paradigm, we alternate with each batch by first optimising the CA system based on the AE output, while freezing the parameters of the AE system, and secondly optimising the AE system according to the loss (<a href="#S3.E3" title="Equation 3 ‣ 3.2 Iterative Optimisation ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), while freezing the parameters of the CA model in the weights (<a href="#S3.E2" title="Equation 2 ‣ 3.2 Iterative Optimisation ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
The iterative training augments the interplay between the two models by persistently adapting the CA to the improved SE model while the updated CA can further be used as an indicator to improve the SE model.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Audio Enhancement Model</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The audio enhancement is based on U-net <cite class="ltx_cite ltx_citemacro_cite">Ronneberger et al. (<a href="#bib.bib45" title="" class="ltx_ref">2015</a>); Choi et al. (<a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite>, an auto-encoder architecture, operating in the frequency domain, with feed-forward layers that stack the encoder layers to their corresponding decoder layers, as seen in Fig. <a href="#S3.F2" title="Figure 2 ‣ 3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2408.06264/assets/x4.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="275" height="63" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:80%;">Fig.​​ 2</span>: </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">Schematic diagram of the U-net architecture. The raw audio is transformed with a short-time Fourier transform (STFT) into a spectrogram, which is then fed into a fully convolutional network with an encoder and decoder and skip connections between corresponding encoder and decoder layers in the U-shaped architecture. The final reconstructed or enhanced spectrogram is then transformed back into a raw audio signal with an inverse STFT.</span></figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.06264/assets/x5.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="97" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text ltx_align_center" style="font-size:90%;">Speech Command Recognition</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.06264/assets/x6.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_portrait" width="61" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text ltx_align_center" style="font-size:90%;">Automatic Speech Recognition</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.06264/assets/x7.png" id="S3.F3.sf3.g1" class="ltx_graphics ltx_img_portrait" width="86" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F3.sf3.3.2" class="ltx_text ltx_align_center" style="font-size:90%;">Speech Emotion Recognition</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2408.06264/assets/x8.png" id="S3.F3.sf4.g1" class="ltx_graphics ltx_img_square" width="129" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F3.sf4.3.2" class="ltx_text ltx_align_center" style="font-size:90%;">Audio Scene Classification</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:80%;">Fig.​​ 3</span>: </span><span id="S3.F3.4.2" class="ltx_text" style="font-size:90%;">Schematic diagrams showing architectures for downstream computer audition tasks. The architecture for speech command recognition in a) is the only one acting on the raw audio signal compared to the architectures of b) to d), which take 2-dimensional spectrogram representations of the audio signal as an input. In a) we apply 1D convolutional and maxpooling layers, prior to a global average pooling and classification layer. The automatic speech emotion recognition model depicted in b) consists of 2D convolutional layers and convolutional blocks with skip connections, followed by a layer normalisation and a bi-directional GRU-RNN layer prior to the classification layer. The Speech emotion recognition architecture in c) only applies convolutional blocks prior to a global average pooling and a classification layer. The audio scene classification model in d) concatenates the outputs of different convolutional blocks and works in a fully convolutional manner.</span></figcaption>
</figure>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.4" class="ltx_p">Given a noisy audio <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">y</annotation></semantics></math> and its corresponding clean sample <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">x</annotation></semantics></math>, the noisy sample is converted into a spectrogram <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">Y</annotation></semantics></math>, using the short-time Fourier transform (STFT). The U-Net estimates a ratio mask <math id="S3.SS3.p2.4.m4.2" class="ltx_Math" alttext="\operatorname{Mask}(Y)" display="inline"><semantics id="S3.SS3.p2.4.m4.2a"><mrow id="S3.SS3.p2.4.m4.2.3.2" xref="S3.SS3.p2.4.m4.2.3.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">Mask</mi><mo id="S3.SS3.p2.4.m4.2.3.2a" xref="S3.SS3.p2.4.m4.2.3.1.cmml">⁡</mo><mrow id="S3.SS3.p2.4.m4.2.3.2.1" xref="S3.SS3.p2.4.m4.2.3.1.cmml"><mo stretchy="false" id="S3.SS3.p2.4.m4.2.3.2.1.1" xref="S3.SS3.p2.4.m4.2.3.1.cmml">(</mo><mi id="S3.SS3.p2.4.m4.2.2" xref="S3.SS3.p2.4.m4.2.2.cmml">Y</mi><mo stretchy="false" id="S3.SS3.p2.4.m4.2.3.2.1.2" xref="S3.SS3.p2.4.m4.2.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.2b"><apply id="S3.SS3.p2.4.m4.2.3.1.cmml" xref="S3.SS3.p2.4.m4.2.3.2"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">Mask</ci><ci id="S3.SS3.p2.4.m4.2.2.cmml" xref="S3.SS3.p2.4.m4.2.2">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.2c">\operatorname{Mask}(Y)</annotation></semantics></math>, which is then applied to the original noisy input to predict the clean spectrogram:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\hat{X}=Y\cdot\operatorname{Mask}(Y)." display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml"><mi id="S3.E4.m1.3.3.1.1.2.2" xref="S3.E4.m1.3.3.1.1.2.2.cmml">X</mi><mo id="S3.E4.m1.3.3.1.1.2.1" xref="S3.E4.m1.3.3.1.1.2.1.cmml">^</mo></mover><mo id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.3.3.1.1.3" xref="S3.E4.m1.3.3.1.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.cmml">Y</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.3.3.1.1.3.1" xref="S3.E4.m1.3.3.1.1.3.1.cmml">⋅</mo><mrow id="S3.E4.m1.3.3.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml"><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">Mask</mi><mo id="S3.E4.m1.3.3.1.1.3.3.2a" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">⁡</mo><mrow id="S3.E4.m1.3.3.1.1.3.3.2.1" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.3.2.1.1" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">Y</mi><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.3.2.1.2" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"></eq><apply id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"><ci id="S3.E4.m1.3.3.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.2.1">^</ci><ci id="S3.E4.m1.3.3.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.2.2">𝑋</ci></apply><apply id="S3.E4.m1.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3"><ci id="S3.E4.m1.3.3.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.1">⋅</ci><ci id="S3.E4.m1.3.3.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2">𝑌</ci><apply id="S3.E4.m1.3.3.1.1.3.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.3.2"><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">Mask</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝑌</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\hat{X}=Y\cdot\operatorname{Mask}(Y).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.5" class="ltx_p">The estimated clean audio <math id="S3.SS3.p2.5.m1.1" class="ltx_Math" alttext="\hat{x}" display="inline"><semantics id="S3.SS3.p2.5.m1.1a"><mover accent="true" id="S3.SS3.p2.5.m1.1.1" xref="S3.SS3.p2.5.m1.1.1.cmml"><mi id="S3.SS3.p2.5.m1.1.1.2" xref="S3.SS3.p2.5.m1.1.1.2.cmml">x</mi><mo id="S3.SS3.p2.5.m1.1.1.1" xref="S3.SS3.p2.5.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m1.1b"><apply id="S3.SS3.p2.5.m1.1.1.cmml" xref="S3.SS3.p2.5.m1.1.1"><ci id="S3.SS3.p2.5.m1.1.1.1.cmml" xref="S3.SS3.p2.5.m1.1.1.1">^</ci><ci id="S3.SS3.p2.5.m1.1.1.2.cmml" xref="S3.SS3.p2.5.m1.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m1.1c">\hat{x}</annotation></semantics></math> can then be reconstructed by applying inverse STFT. The parameters of the model are optimised by minimising the weighted SDR (wSDR) loss of the original and the estimated clean speech and noise <cite class="ltx_cite ltx_citemacro_cite">Choi et al. (<a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite>:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.7" class="ltx_Math" alttext="L_{AE}(x,\hat{x})=\alpha L_{SDR}(x,\hat{x})+(1-\alpha)L_{SDR}(n,\hat{n})," display="block"><semantics id="S3.E5.m1.7a"><mrow id="S3.E5.m1.7.7.1" xref="S3.E5.m1.7.7.1.1.cmml"><mrow id="S3.E5.m1.7.7.1.1" xref="S3.E5.m1.7.7.1.1.cmml"><mrow id="S3.E5.m1.7.7.1.1.3" xref="S3.E5.m1.7.7.1.1.3.cmml"><msub id="S3.E5.m1.7.7.1.1.3.2" xref="S3.E5.m1.7.7.1.1.3.2.cmml"><mi id="S3.E5.m1.7.7.1.1.3.2.2" xref="S3.E5.m1.7.7.1.1.3.2.2.cmml">L</mi><mrow id="S3.E5.m1.7.7.1.1.3.2.3" xref="S3.E5.m1.7.7.1.1.3.2.3.cmml"><mi id="S3.E5.m1.7.7.1.1.3.2.3.2" xref="S3.E5.m1.7.7.1.1.3.2.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.3.2.3.1" xref="S3.E5.m1.7.7.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.7.7.1.1.3.2.3.3" xref="S3.E5.m1.7.7.1.1.3.2.3.3.cmml">E</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.3.1" xref="S3.E5.m1.7.7.1.1.3.1.cmml">​</mo><mrow id="S3.E5.m1.7.7.1.1.3.3.2" xref="S3.E5.m1.7.7.1.1.3.3.1.cmml"><mo stretchy="false" id="S3.E5.m1.7.7.1.1.3.3.2.1" xref="S3.E5.m1.7.7.1.1.3.3.1.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">x</mi><mo id="S3.E5.m1.7.7.1.1.3.3.2.2" xref="S3.E5.m1.7.7.1.1.3.3.1.cmml">,</mo><mover accent="true" id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml"><mi id="S3.E5.m1.2.2.2" xref="S3.E5.m1.2.2.2.cmml">x</mi><mo id="S3.E5.m1.2.2.1" xref="S3.E5.m1.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S3.E5.m1.7.7.1.1.3.3.2.3" xref="S3.E5.m1.7.7.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.7.7.1.1.2" xref="S3.E5.m1.7.7.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.7.7.1.1.1" xref="S3.E5.m1.7.7.1.1.1.cmml"><mrow id="S3.E5.m1.7.7.1.1.1.3" xref="S3.E5.m1.7.7.1.1.1.3.cmml"><mi id="S3.E5.m1.7.7.1.1.1.3.2" xref="S3.E5.m1.7.7.1.1.1.3.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.1.3.1" xref="S3.E5.m1.7.7.1.1.1.3.1.cmml">​</mo><msub id="S3.E5.m1.7.7.1.1.1.3.3" xref="S3.E5.m1.7.7.1.1.1.3.3.cmml"><mi id="S3.E5.m1.7.7.1.1.1.3.3.2" xref="S3.E5.m1.7.7.1.1.1.3.3.2.cmml">L</mi><mrow id="S3.E5.m1.7.7.1.1.1.3.3.3" xref="S3.E5.m1.7.7.1.1.1.3.3.3.cmml"><mi id="S3.E5.m1.7.7.1.1.1.3.3.3.2" xref="S3.E5.m1.7.7.1.1.1.3.3.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.1.3.3.3.1" xref="S3.E5.m1.7.7.1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.7.7.1.1.1.3.3.3.3" xref="S3.E5.m1.7.7.1.1.1.3.3.3.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.1.3.3.3.1a" xref="S3.E5.m1.7.7.1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.7.7.1.1.1.3.3.3.4" xref="S3.E5.m1.7.7.1.1.1.3.3.3.4.cmml">R</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.1.3.1a" xref="S3.E5.m1.7.7.1.1.1.3.1.cmml">​</mo><mrow id="S3.E5.m1.7.7.1.1.1.3.4.2" xref="S3.E5.m1.7.7.1.1.1.3.4.1.cmml"><mo stretchy="false" id="S3.E5.m1.7.7.1.1.1.3.4.2.1" xref="S3.E5.m1.7.7.1.1.1.3.4.1.cmml">(</mo><mi id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml">x</mi><mo id="S3.E5.m1.7.7.1.1.1.3.4.2.2" xref="S3.E5.m1.7.7.1.1.1.3.4.1.cmml">,</mo><mover accent="true" id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml"><mi id="S3.E5.m1.4.4.2" xref="S3.E5.m1.4.4.2.cmml">x</mi><mo id="S3.E5.m1.4.4.1" xref="S3.E5.m1.4.4.1.cmml">^</mo></mover><mo stretchy="false" id="S3.E5.m1.7.7.1.1.1.3.4.2.3" xref="S3.E5.m1.7.7.1.1.1.3.4.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.7.7.1.1.1.2" xref="S3.E5.m1.7.7.1.1.1.2.cmml">+</mo><mrow id="S3.E5.m1.7.7.1.1.1.1" xref="S3.E5.m1.7.7.1.1.1.1.cmml"><mrow id="S3.E5.m1.7.7.1.1.1.1.1.1" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.7.7.1.1.1.1.1.1.2" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.7.7.1.1.1.1.1.1.1" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.cmml"><mn id="S3.E5.m1.7.7.1.1.1.1.1.1.1.2" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E5.m1.7.7.1.1.1.1.1.1.1.1" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E5.m1.7.7.1.1.1.1.1.1.1.3" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo stretchy="false" id="S3.E5.m1.7.7.1.1.1.1.1.1.3" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.1.1.2" xref="S3.E5.m1.7.7.1.1.1.1.2.cmml">​</mo><msub id="S3.E5.m1.7.7.1.1.1.1.3" xref="S3.E5.m1.7.7.1.1.1.1.3.cmml"><mi id="S3.E5.m1.7.7.1.1.1.1.3.2" xref="S3.E5.m1.7.7.1.1.1.1.3.2.cmml">L</mi><mrow id="S3.E5.m1.7.7.1.1.1.1.3.3" xref="S3.E5.m1.7.7.1.1.1.1.3.3.cmml"><mi id="S3.E5.m1.7.7.1.1.1.1.3.3.2" xref="S3.E5.m1.7.7.1.1.1.1.3.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.1.1.3.3.1" xref="S3.E5.m1.7.7.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E5.m1.7.7.1.1.1.1.3.3.3" xref="S3.E5.m1.7.7.1.1.1.1.3.3.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.1.1.3.3.1a" xref="S3.E5.m1.7.7.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E5.m1.7.7.1.1.1.1.3.3.4" xref="S3.E5.m1.7.7.1.1.1.1.3.3.4.cmml">R</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.7.7.1.1.1.1.2a" xref="S3.E5.m1.7.7.1.1.1.1.2.cmml">​</mo><mrow id="S3.E5.m1.7.7.1.1.1.1.4.2" xref="S3.E5.m1.7.7.1.1.1.1.4.1.cmml"><mo stretchy="false" id="S3.E5.m1.7.7.1.1.1.1.4.2.1" xref="S3.E5.m1.7.7.1.1.1.1.4.1.cmml">(</mo><mi id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml">n</mi><mo id="S3.E5.m1.7.7.1.1.1.1.4.2.2" xref="S3.E5.m1.7.7.1.1.1.1.4.1.cmml">,</mo><mover accent="true" id="S3.E5.m1.6.6" xref="S3.E5.m1.6.6.cmml"><mi id="S3.E5.m1.6.6.2" xref="S3.E5.m1.6.6.2.cmml">n</mi><mo id="S3.E5.m1.6.6.1" xref="S3.E5.m1.6.6.1.cmml">^</mo></mover><mo stretchy="false" id="S3.E5.m1.7.7.1.1.1.1.4.2.3" xref="S3.E5.m1.7.7.1.1.1.1.4.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E5.m1.7.7.1.2" xref="S3.E5.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.7b"><apply id="S3.E5.m1.7.7.1.1.cmml" xref="S3.E5.m1.7.7.1"><eq id="S3.E5.m1.7.7.1.1.2.cmml" xref="S3.E5.m1.7.7.1.1.2"></eq><apply id="S3.E5.m1.7.7.1.1.3.cmml" xref="S3.E5.m1.7.7.1.1.3"><times id="S3.E5.m1.7.7.1.1.3.1.cmml" xref="S3.E5.m1.7.7.1.1.3.1"></times><apply id="S3.E5.m1.7.7.1.1.3.2.cmml" xref="S3.E5.m1.7.7.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.1.1.3.2.1.cmml" xref="S3.E5.m1.7.7.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.7.7.1.1.3.2.2.cmml" xref="S3.E5.m1.7.7.1.1.3.2.2">𝐿</ci><apply id="S3.E5.m1.7.7.1.1.3.2.3.cmml" xref="S3.E5.m1.7.7.1.1.3.2.3"><times id="S3.E5.m1.7.7.1.1.3.2.3.1.cmml" xref="S3.E5.m1.7.7.1.1.3.2.3.1"></times><ci id="S3.E5.m1.7.7.1.1.3.2.3.2.cmml" xref="S3.E5.m1.7.7.1.1.3.2.3.2">𝐴</ci><ci id="S3.E5.m1.7.7.1.1.3.2.3.3.cmml" xref="S3.E5.m1.7.7.1.1.3.2.3.3">𝐸</ci></apply></apply><interval closure="open" id="S3.E5.m1.7.7.1.1.3.3.1.cmml" xref="S3.E5.m1.7.7.1.1.3.3.2"><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝑥</ci><apply id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2"><ci id="S3.E5.m1.2.2.1.cmml" xref="S3.E5.m1.2.2.1">^</ci><ci id="S3.E5.m1.2.2.2.cmml" xref="S3.E5.m1.2.2.2">𝑥</ci></apply></interval></apply><apply id="S3.E5.m1.7.7.1.1.1.cmml" xref="S3.E5.m1.7.7.1.1.1"><plus id="S3.E5.m1.7.7.1.1.1.2.cmml" xref="S3.E5.m1.7.7.1.1.1.2"></plus><apply id="S3.E5.m1.7.7.1.1.1.3.cmml" xref="S3.E5.m1.7.7.1.1.1.3"><times id="S3.E5.m1.7.7.1.1.1.3.1.cmml" xref="S3.E5.m1.7.7.1.1.1.3.1"></times><ci id="S3.E5.m1.7.7.1.1.1.3.2.cmml" xref="S3.E5.m1.7.7.1.1.1.3.2">𝛼</ci><apply id="S3.E5.m1.7.7.1.1.1.3.3.cmml" xref="S3.E5.m1.7.7.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.1.1.1.3.3.1.cmml" xref="S3.E5.m1.7.7.1.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.7.7.1.1.1.3.3.2.cmml" xref="S3.E5.m1.7.7.1.1.1.3.3.2">𝐿</ci><apply id="S3.E5.m1.7.7.1.1.1.3.3.3.cmml" xref="S3.E5.m1.7.7.1.1.1.3.3.3"><times id="S3.E5.m1.7.7.1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.7.7.1.1.1.3.3.3.1"></times><ci id="S3.E5.m1.7.7.1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.7.7.1.1.1.3.3.3.2">𝑆</ci><ci id="S3.E5.m1.7.7.1.1.1.3.3.3.3.cmml" xref="S3.E5.m1.7.7.1.1.1.3.3.3.3">𝐷</ci><ci id="S3.E5.m1.7.7.1.1.1.3.3.3.4.cmml" xref="S3.E5.m1.7.7.1.1.1.3.3.3.4">𝑅</ci></apply></apply><interval closure="open" id="S3.E5.m1.7.7.1.1.1.3.4.1.cmml" xref="S3.E5.m1.7.7.1.1.1.3.4.2"><ci id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3">𝑥</ci><apply id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4"><ci id="S3.E5.m1.4.4.1.cmml" xref="S3.E5.m1.4.4.1">^</ci><ci id="S3.E5.m1.4.4.2.cmml" xref="S3.E5.m1.4.4.2">𝑥</ci></apply></interval></apply><apply id="S3.E5.m1.7.7.1.1.1.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1"><times id="S3.E5.m1.7.7.1.1.1.1.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.2"></times><apply id="S3.E5.m1.7.7.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.1.1"><minus id="S3.E5.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E5.m1.7.7.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E5.m1.7.7.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.7.7.1.1.1.1.1.1.1.3">𝛼</ci></apply><apply id="S3.E5.m1.7.7.1.1.1.1.3.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.7.7.1.1.1.1.3.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.7.7.1.1.1.1.3.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3.2">𝐿</ci><apply id="S3.E5.m1.7.7.1.1.1.1.3.3.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3.3"><times id="S3.E5.m1.7.7.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3.3.1"></times><ci id="S3.E5.m1.7.7.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3.3.2">𝑆</ci><ci id="S3.E5.m1.7.7.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3.3.3">𝐷</ci><ci id="S3.E5.m1.7.7.1.1.1.1.3.3.4.cmml" xref="S3.E5.m1.7.7.1.1.1.1.3.3.4">𝑅</ci></apply></apply><interval closure="open" id="S3.E5.m1.7.7.1.1.1.1.4.1.cmml" xref="S3.E5.m1.7.7.1.1.1.1.4.2"><ci id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5">𝑛</ci><apply id="S3.E5.m1.6.6.cmml" xref="S3.E5.m1.6.6"><ci id="S3.E5.m1.6.6.1.cmml" xref="S3.E5.m1.6.6.1">^</ci><ci id="S3.E5.m1.6.6.2.cmml" xref="S3.E5.m1.6.6.2">𝑛</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.7c">L_{AE}(x,\hat{x})=\alpha L_{SDR}(x,\hat{x})+(1-\alpha)L_{SDR}(n,\hat{n}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.6" class="ltx_p">where</p>
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.3" class="ltx_Math" alttext="n=y-x\quad\mathrm{and}\quad\hat{n}=y-\hat{x}" display="block"><semantics id="S3.Ex1.m1.3a"><mrow id="S3.Ex1.m1.3.3.2" xref="S3.Ex1.m1.3.3.3.cmml"><mrow id="S3.Ex1.m1.2.2.1.1" xref="S3.Ex1.m1.2.2.1.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.3" xref="S3.Ex1.m1.2.2.1.1.3.cmml">n</mi><mo id="S3.Ex1.m1.2.2.1.1.2" xref="S3.Ex1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.2.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.2.cmml">y</mi><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.cmml">−</mo><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.3.cmml">x</mi></mrow><mspace width="1em" id="S3.Ex1.m1.2.2.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.2.cmml"></mspace><mi id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">and</mi></mrow></mrow><mspace width="1em" id="S3.Ex1.m1.3.3.2.3" xref="S3.Ex1.m1.3.3.3a.cmml"></mspace><mrow id="S3.Ex1.m1.3.3.2.2" xref="S3.Ex1.m1.3.3.2.2.cmml"><mover accent="true" id="S3.Ex1.m1.3.3.2.2.2" xref="S3.Ex1.m1.3.3.2.2.2.cmml"><mi id="S3.Ex1.m1.3.3.2.2.2.2" xref="S3.Ex1.m1.3.3.2.2.2.2.cmml">n</mi><mo id="S3.Ex1.m1.3.3.2.2.2.1" xref="S3.Ex1.m1.3.3.2.2.2.1.cmml">^</mo></mover><mo id="S3.Ex1.m1.3.3.2.2.1" xref="S3.Ex1.m1.3.3.2.2.1.cmml">=</mo><mrow id="S3.Ex1.m1.3.3.2.2.3" xref="S3.Ex1.m1.3.3.2.2.3.cmml"><mi id="S3.Ex1.m1.3.3.2.2.3.2" xref="S3.Ex1.m1.3.3.2.2.3.2.cmml">y</mi><mo id="S3.Ex1.m1.3.3.2.2.3.1" xref="S3.Ex1.m1.3.3.2.2.3.1.cmml">−</mo><mover accent="true" id="S3.Ex1.m1.3.3.2.2.3.3" xref="S3.Ex1.m1.3.3.2.2.3.3.cmml"><mi id="S3.Ex1.m1.3.3.2.2.3.3.2" xref="S3.Ex1.m1.3.3.2.2.3.3.2.cmml">x</mi><mo id="S3.Ex1.m1.3.3.2.2.3.3.1" xref="S3.Ex1.m1.3.3.2.2.3.3.1.cmml">^</mo></mover></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.3b"><apply id="S3.Ex1.m1.3.3.3.cmml" xref="S3.Ex1.m1.3.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.3.3.3a.cmml" xref="S3.Ex1.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S3.Ex1.m1.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1"><eq id="S3.Ex1.m1.2.2.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.2"></eq><ci id="S3.Ex1.m1.2.2.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3">𝑛</ci><list id="S3.Ex1.m1.2.2.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1"><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1"><minus id="S3.Ex1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1"></minus><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.2">𝑦</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.3">𝑥</ci></apply><ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">and</ci></list></apply><apply id="S3.Ex1.m1.3.3.2.2.cmml" xref="S3.Ex1.m1.3.3.2.2"><eq id="S3.Ex1.m1.3.3.2.2.1.cmml" xref="S3.Ex1.m1.3.3.2.2.1"></eq><apply id="S3.Ex1.m1.3.3.2.2.2.cmml" xref="S3.Ex1.m1.3.3.2.2.2"><ci id="S3.Ex1.m1.3.3.2.2.2.1.cmml" xref="S3.Ex1.m1.3.3.2.2.2.1">^</ci><ci id="S3.Ex1.m1.3.3.2.2.2.2.cmml" xref="S3.Ex1.m1.3.3.2.2.2.2">𝑛</ci></apply><apply id="S3.Ex1.m1.3.3.2.2.3.cmml" xref="S3.Ex1.m1.3.3.2.2.3"><minus id="S3.Ex1.m1.3.3.2.2.3.1.cmml" xref="S3.Ex1.m1.3.3.2.2.3.1"></minus><ci id="S3.Ex1.m1.3.3.2.2.3.2.cmml" xref="S3.Ex1.m1.3.3.2.2.3.2">𝑦</ci><apply id="S3.Ex1.m1.3.3.2.2.3.3.cmml" xref="S3.Ex1.m1.3.3.2.2.3.3"><ci id="S3.Ex1.m1.3.3.2.2.3.3.1.cmml" xref="S3.Ex1.m1.3.3.2.2.3.3.1">^</ci><ci id="S3.Ex1.m1.3.3.2.2.3.3.2.cmml" xref="S3.Ex1.m1.3.3.2.2.3.3.2">𝑥</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.3c">n=y-x\quad\mathrm{and}\quad\hat{n}=y-\hat{x}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.7" class="ltx_p">represent the true and estimated noise signal, and</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.7" class="ltx_math_unparsed" alttext="L_{SDR}(x,\hat{x})=-\frac{&lt;x,\hat{x}&gt;}{||x||\cdot||\hat{x}||}," display="block"><semantics id="S3.E6.m1.7a"><mrow id="S3.E6.m1.7.7.1"><mrow id="S3.E6.m1.7.7.1.1"><mrow id="S3.E6.m1.7.7.1.1.2"><msub id="S3.E6.m1.7.7.1.1.2.2"><mi id="S3.E6.m1.7.7.1.1.2.2.2">L</mi><mrow id="S3.E6.m1.7.7.1.1.2.2.3"><mi id="S3.E6.m1.7.7.1.1.2.2.3.2">S</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.7.7.1.1.2.2.3.1">​</mo><mi id="S3.E6.m1.7.7.1.1.2.2.3.3">D</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.7.7.1.1.2.2.3.1a">​</mo><mi id="S3.E6.m1.7.7.1.1.2.2.3.4">R</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.7.7.1.1.2.1">​</mo><mrow id="S3.E6.m1.7.7.1.1.2.3.2"><mo stretchy="false" id="S3.E6.m1.7.7.1.1.2.3.2.1">(</mo><mi id="S3.E6.m1.5.5">x</mi><mo id="S3.E6.m1.7.7.1.1.2.3.2.2">,</mo><mover accent="true" id="S3.E6.m1.6.6"><mi id="S3.E6.m1.6.6.2">x</mi><mo id="S3.E6.m1.6.6.1">^</mo></mover><mo stretchy="false" id="S3.E6.m1.7.7.1.1.2.3.2.3">)</mo></mrow></mrow><mo id="S3.E6.m1.7.7.1.1.1">=</mo><mrow id="S3.E6.m1.7.7.1.1.3"><mo id="S3.E6.m1.7.7.1.1.3a">−</mo><mfrac id="S3.E6.m1.4.4"><mrow id="S3.E6.m1.2.2.2"><mo id="S3.E6.m1.2.2.2.3">&lt;</mo><mi id="S3.E6.m1.1.1.1.1">x</mi><mo id="S3.E6.m1.2.2.2.4">,</mo><mover accent="true" id="S3.E6.m1.2.2.2.2"><mi id="S3.E6.m1.2.2.2.2.2">x</mi><mo id="S3.E6.m1.2.2.2.2.1">^</mo></mover><mo id="S3.E6.m1.2.2.2.5">&gt;</mo></mrow><mrow id="S3.E6.m1.4.4.4"><mrow id="S3.E6.m1.4.4.4.4.2"><mo stretchy="false" id="S3.E6.m1.4.4.4.4.2.1">‖</mo><mi id="S3.E6.m1.3.3.3.1">x</mi><mo rspace="0.055em" stretchy="false" id="S3.E6.m1.4.4.4.4.2.2">‖</mo></mrow><mo rspace="0.222em" id="S3.E6.m1.4.4.4.3">⋅</mo><mrow id="S3.E6.m1.4.4.4.5.2"><mo stretchy="false" id="S3.E6.m1.4.4.4.5.2.1">‖</mo><mover accent="true" id="S3.E6.m1.4.4.4.2"><mi id="S3.E6.m1.4.4.4.2.2">x</mi><mo id="S3.E6.m1.4.4.4.2.1">^</mo></mover><mo stretchy="false" id="S3.E6.m1.4.4.4.5.2.2">‖</mo></mrow></mrow></mfrac></mrow></mrow><mo id="S3.E6.m1.7.7.1.2">,</mo></mrow><annotation encoding="application/x-tex" id="S3.E6.m1.7b">L_{SDR}(x,\hat{x})=-\frac{&lt;x,\hat{x}&gt;}{||x||\cdot||\hat{x}||},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.8" class="ltx_p">as well as</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.4" class="ltx_Math" alttext="\alpha=\frac{||x||^{2}}{||x||^{2}+||n||^{2}}." display="block"><semantics id="S3.E7.m1.4a"><mrow id="S3.E7.m1.4.4.1" xref="S3.E7.m1.4.4.1.1.cmml"><mrow id="S3.E7.m1.4.4.1.1" xref="S3.E7.m1.4.4.1.1.cmml"><mi id="S3.E7.m1.4.4.1.1.2" xref="S3.E7.m1.4.4.1.1.2.cmml">α</mi><mo id="S3.E7.m1.4.4.1.1.1" xref="S3.E7.m1.4.4.1.1.1.cmml">=</mo><mfrac id="S3.E7.m1.3.3" xref="S3.E7.m1.3.3.cmml"><msup id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E7.m1.1.1.1.3.2.1" xref="S3.E7.m1.1.1.1.3.1.1.cmml">‖</mo><mi id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E7.m1.1.1.1.3.2.2" xref="S3.E7.m1.1.1.1.3.1.1.cmml">‖</mo></mrow><mn id="S3.E7.m1.1.1.1.4" xref="S3.E7.m1.1.1.1.4.cmml">2</mn></msup><mrow id="S3.E7.m1.3.3.3" xref="S3.E7.m1.3.3.3.cmml"><msup id="S3.E7.m1.3.3.3.4" xref="S3.E7.m1.3.3.3.4.cmml"><mrow id="S3.E7.m1.3.3.3.4.2.2" xref="S3.E7.m1.3.3.3.4.2.1.cmml"><mo stretchy="false" id="S3.E7.m1.3.3.3.4.2.2.1" xref="S3.E7.m1.3.3.3.4.2.1.1.cmml">‖</mo><mi id="S3.E7.m1.2.2.2.1" xref="S3.E7.m1.2.2.2.1.cmml">x</mi><mo stretchy="false" id="S3.E7.m1.3.3.3.4.2.2.2" xref="S3.E7.m1.3.3.3.4.2.1.1.cmml">‖</mo></mrow><mn id="S3.E7.m1.3.3.3.4.3" xref="S3.E7.m1.3.3.3.4.3.cmml">2</mn></msup><mo id="S3.E7.m1.3.3.3.3" xref="S3.E7.m1.3.3.3.3.cmml">+</mo><msup id="S3.E7.m1.3.3.3.5" xref="S3.E7.m1.3.3.3.5.cmml"><mrow id="S3.E7.m1.3.3.3.5.2.2" xref="S3.E7.m1.3.3.3.5.2.1.cmml"><mo stretchy="false" id="S3.E7.m1.3.3.3.5.2.2.1" xref="S3.E7.m1.3.3.3.5.2.1.1.cmml">‖</mo><mi id="S3.E7.m1.3.3.3.2" xref="S3.E7.m1.3.3.3.2.cmml">n</mi><mo stretchy="false" id="S3.E7.m1.3.3.3.5.2.2.2" xref="S3.E7.m1.3.3.3.5.2.1.1.cmml">‖</mo></mrow><mn id="S3.E7.m1.3.3.3.5.3" xref="S3.E7.m1.3.3.3.5.3.cmml">2</mn></msup></mrow></mfrac></mrow><mo lspace="0em" id="S3.E7.m1.4.4.1.2" xref="S3.E7.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.4b"><apply id="S3.E7.m1.4.4.1.1.cmml" xref="S3.E7.m1.4.4.1"><eq id="S3.E7.m1.4.4.1.1.1.cmml" xref="S3.E7.m1.4.4.1.1.1"></eq><ci id="S3.E7.m1.4.4.1.1.2.cmml" xref="S3.E7.m1.4.4.1.1.2">𝛼</ci><apply id="S3.E7.m1.3.3.cmml" xref="S3.E7.m1.3.3"><divide id="S3.E7.m1.3.3.4.cmml" xref="S3.E7.m1.3.3"></divide><apply id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1">superscript</csymbol><apply id="S3.E7.m1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.3.2"><csymbol cd="latexml" id="S3.E7.m1.1.1.1.3.1.1.cmml" xref="S3.E7.m1.1.1.1.3.2.1">norm</csymbol><ci id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1">𝑥</ci></apply><cn type="integer" id="S3.E7.m1.1.1.1.4.cmml" xref="S3.E7.m1.1.1.1.4">2</cn></apply><apply id="S3.E7.m1.3.3.3.cmml" xref="S3.E7.m1.3.3.3"><plus id="S3.E7.m1.3.3.3.3.cmml" xref="S3.E7.m1.3.3.3.3"></plus><apply id="S3.E7.m1.3.3.3.4.cmml" xref="S3.E7.m1.3.3.3.4"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.3.4.1.cmml" xref="S3.E7.m1.3.3.3.4">superscript</csymbol><apply id="S3.E7.m1.3.3.3.4.2.1.cmml" xref="S3.E7.m1.3.3.3.4.2.2"><csymbol cd="latexml" id="S3.E7.m1.3.3.3.4.2.1.1.cmml" xref="S3.E7.m1.3.3.3.4.2.2.1">norm</csymbol><ci id="S3.E7.m1.2.2.2.1.cmml" xref="S3.E7.m1.2.2.2.1">𝑥</ci></apply><cn type="integer" id="S3.E7.m1.3.3.3.4.3.cmml" xref="S3.E7.m1.3.3.3.4.3">2</cn></apply><apply id="S3.E7.m1.3.3.3.5.cmml" xref="S3.E7.m1.3.3.3.5"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.3.5.1.cmml" xref="S3.E7.m1.3.3.3.5">superscript</csymbol><apply id="S3.E7.m1.3.3.3.5.2.1.cmml" xref="S3.E7.m1.3.3.3.5.2.2"><csymbol cd="latexml" id="S3.E7.m1.3.3.3.5.2.1.1.cmml" xref="S3.E7.m1.3.3.3.5.2.2.1">norm</csymbol><ci id="S3.E7.m1.3.3.3.2.cmml" xref="S3.E7.m1.3.3.3.2">𝑛</ci></apply><cn type="integer" id="S3.E7.m1.3.3.3.5.3.cmml" xref="S3.E7.m1.3.3.3.5.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.4c">\alpha=\frac{||x||^{2}}{||x||^{2}+||n||^{2}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">In order to capture the advantages of enhanced audio signals from U-Net some slight architectural changes need to be applied in order to make it compatible in a cascading fashion with any of the above-mentioned application scenarios. For this purpose, we set the max-pooling along the time-axis equal to 1, while the pooling along the frequency-axis stays unchanged. The main motivation of this step is to allow the U-Net to process audio segments of different lengths, which is a crucial ability for some of the application tasks, like for instance ASR.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">Any of the considered <span title="" class="ltx_glossaryref">CAT</span> can do further processing, like feature extraction based on the enhanced waveform, as it would normally be done on the original waveform. Alternatively, the reconstructed time-frequency features of the AE model can directly be passed on. In a cold cascade, the AE model is first optimised based on its loss <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="L_{\mathrm{AE}}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">L</mi><mi id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">AE</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">𝐿</ci><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">AE</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">L_{\mathrm{AE}}</annotation></semantics></math> according to (<a href="#S3.E5" title="Equation 5 ‣ 3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) in order to obtain a decent AE model for pre-processing before the CA model is trained for its task independently.
Beyond the U-Net architecture, we further investigated a complex U-Net<cite class="ltx_cite ltx_citemacro_cite">Choi et al. (<a href="#bib.bib10" title="" class="ltx_ref">2018</a>)</cite> architecture, as well as a Wave U-Net architecture<cite class="ltx_cite ltx_citemacro_cite">Stoller et al. (<a href="#bib.bib50" title="" class="ltx_ref">2018</a>)</cite>. An analysis with respect to Cepstral Distortion (CD), signal-to-distortion ratio (SDR), short-time objective intelligibility (STOI) and log spectral distortion (LSD) however showed a superior performance of the U-Net compared to the other candidate models. Experiments for downstream CATs where therefore only carried out with the U-Net architecture in order to limit the already computation-heavy experiments.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Computer Audition Tasks</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">In the following, we will introduce the four different computer audition tasks namely <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_italic">speech command recognition</span> (SCR), <span id="S3.SS4.p1.1.2" class="ltx_text ltx_font_italic">automatic speech recognition</span> (ASR), <span id="S3.SS4.p1.1.3" class="ltx_text ltx_font_italic">speech emotion recognition</span> (SER) and <span id="S3.SS4.p1.1.4" class="ltx_text ltx_font_italic">audio scene classification</span> (ASC), as well as the corresponding NN architectures, on which we evaluated our iterative training strategies. An overview of the applied architectures is given in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<section id="S3.SS4.SSS1" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Speech Command Recognition</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">SCR belongs to the category of tasks, in which linguistic information has to be extracted from speech.
Common SCR tasks are implemented such that audio recordings, potentially of identical length, have to be assigned to one speech command or a single word out of a given set of commands or vocabulary.
Due to the limitations regarding the variability of audio and labels, SCR can be considered less complex compared to general ASR and solutions do not necessarily contain language models.
Hence, models for SCR have the potential to be designed shallowly in order to run on mobile edge devices or other assistive devices without the necessity of an internet connection <cite class="ltx_cite ltx_citemacro_citep">(De Andrade et al., <a href="#bib.bib12" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S3.SS4.SSS1.p2" class="ltx_para">
<p id="S3.SS4.SSS1.p2.1" class="ltx_p">We evaluate our methodology on the 35-word limited-vocabulary speech recognition data set introduced in <cite class="ltx_cite ltx_citemacro_cite">Warden (<a href="#bib.bib58" title="" class="ltx_ref">2018</a>)</cite>. Accordingly, we choose the M5 version of the very deep CNN, as introduced in <cite class="ltx_cite ltx_citemacro_cite">Dai et al. (<a href="#bib.bib11" title="" class="ltx_ref">2017</a>)</cite> with 35 neurons in the softmax output layer. The network consists of a set of 1D convolutional layers acting on the raw waveform in its time-domain without further pre-processing. Fig <a href="#S3.F3.sf1" title="Figure 3(a) ‣ Figure 3 ‣ 3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> provides a visualisation of the approach.</p>
</div>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>Automatic Speech Recognition</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">ASR is certainly one of the most prominently researched problems in CA, as the automatic transcriptions of spoken language
have a multitude of applications, which are already available in commercial devices. As the nature of speech can be considered quite complex, general ASR models need to cope with different speaker characteristics, such as different speaking speeds, and, in general, a variable length of sentences.
Applications of ASR are manifold and are a cornerstone of human-machine interaction (HMI), for instance in digital assistants, such as Alexa, Siri, and alike.
The era of deep learning has helped boost the performance of ASR systems, which have previously been dominated by Hidden Markov Models-Gaussian Mixture Models (HMM-GMM) <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib55" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S3.SS4.SSS2.p2" class="ltx_para">
<p id="S3.SS4.SSS2.p2.1" class="ltx_p">Common architectures for ASR tasks can be split into two components: an acoustic model, which finds a probability-based mapping between spoken utterances and characters within an alphabet, and a language model, which converts the probability distribution to coherent text. Most state-of-the-art acoustic models are based on self-supervised learning (SSL), which can be employed to learn powerful representations from large-scale data, which has not previously been annotated. The learnt representations find application beyond ASR <cite class="ltx_cite ltx_citemacro_cite">Baevski et al. (<a href="#bib.bib3" title="" class="ltx_ref">2020</a>); Hsu et al. (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>); Babu et al. (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite> in multiple
downstream tasks <cite class="ltx_cite ltx_citemacro_cite">Jing and Tian (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>); Liu et al. (<a href="#bib.bib32" title="" class="ltx_ref">2021b</a>)</cite>.</p>
</div>
<div id="S3.SS4.SSS2.p3" class="ltx_para">
<p id="S3.SS4.SSS2.p3.1" class="ltx_p">In order to explore the idea of iterative optimisation however, we choose an acoustic model, which is not relying on SSL, as an SSL-based system would not be compatible with our training paradigm. Instead, we choose an architecture similar to Deep Speech 2 <cite class="ltx_cite ltx_citemacro_cite">Amodei et al. (<a href="#bib.bib1" title="" class="ltx_ref">2016</a>)</cite>.
The basis of the architecture is a set of three residual blocks, each of which consists of two convolutional layers with batch normalisation, GeLU activation, and dropout. The addition of skip-connections in our model compared to Deep Speech 2, promises a more stable convergence <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib26" title="" class="ltx_ref">2018</a>); Zheng et al. (<a href="#bib.bib61" title="" class="ltx_ref">2020</a>)</cite>. The output of the residual blocks is then further processed by several recurrent layers with bidirectional gated recurrent units (GRUs) leading to speech representations, which capture the temporal dynamics in the speech signal. The final layer of the architecture is a fully connected layer, which maps the input to the character indices of the alphabet. In order to improve the quality of the recognised text from the acoustic model,
we apply beam search with a 3-gram ARPA language model on the output of the acoustic model. An overview of the system is depicted in Fig. <a href="#S3.F3.sf2" title="Figure 3(b) ‣ Figure 3 ‣ 3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_tag ltx_tag_note">*</span>The language model can be found at <a target="_blank" href="https://www.openslr.org/11/" title="" class="ltx_ref ltx_href">https://www.openslr.org/11/</a>.</span></span></span>.</p>
</div>
<div id="S3.SS4.SSS2.p4" class="ltx_para">
<p id="S3.SS4.SSS2.p4.1" class="ltx_p">Given the importance of ASR in research, there have already been an extensive amount of studies investigating the robustness of ASR models against noise. Common approaches utilise data augmentation techniques, either by distorting the frequency-domain representation of audio, like in the case of SpecAugment <cite class="ltx_cite ltx_citemacro_cite">Park et al. (<a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite>, by incorporating additive synthesised noise to the clean speech samples <cite class="ltx_cite ltx_citemacro_cite">Hannun et al. (<a href="#bib.bib17" title="" class="ltx_ref">2014</a>); Yin et al. (<a href="#bib.bib60" title="" class="ltx_ref">2015</a>)</cite>, or in a teacher-student architecture, in which the student network is gradually taught to adapt to noise <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a href="#bib.bib23" title="" class="ltx_ref">2018</a>); Meng et al. (<a href="#bib.bib35" title="" class="ltx_ref">2019</a>)</cite>.
For the input to the network, we extract Mel spectrograms from the raw audio using STFT applying a step size of 10 ms and a window length of 20 ms with 32 Mel-scale filters.</p>
</div>
</section>
<section id="S3.SS4.SSS3" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.3 </span>Speech Emotion Recognition</h4>

<div id="S3.SS4.SSS3.p1" class="ltx_para">
<p id="S3.SS4.SSS3.p1.1" class="ltx_p"><span title="" class="ltx_glossaryref">Speech emotion recognition</span> is a cornerstone technology for the development of successful HMI applications <cite class="ltx_cite ltx_citemacro_citep">(Schuller, <a href="#bib.bib47" title="" class="ltx_ref">2018</a>)</cite>.
It involves the development of algorithms that can understand human emotions from vocalisations and is typically formulated as a classification (of ‘basic’ emotions) or a regression task (of emotional dimensions) <cite class="ltx_cite ltx_citemacro_citep">(Schuller, <a href="#bib.bib47" title="" class="ltx_ref">2018</a>)</cite> and studies often focus on specific contexts, such as to recognise acted emotions <cite class="ltx_cite ltx_citemacro_cite">Busso et al. (<a href="#bib.bib7" title="" class="ltx_ref">2008</a>)</cite>, emotions in public speaking scenarios <cite class="ltx_cite ltx_citemacro_cite">Baird et al. (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> or emotions of individuals with autism <cite class="ltx_cite ltx_citemacro_cite">Milling et al. (<a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>.
While the field has seen tremendous progress in recent years, especially with the increasing improvement of <span title="" class="ltx_glossaryref">DL</span> algorithms <cite class="ltx_cite ltx_citemacro_citep">(Wagner et al., <a href="#bib.bib54" title="" class="ltx_ref">2022</a>)</cite>, <em id="S3.SS4.SSS3.p1.1.1" class="ltx_emph ltx_font_italic">robustness</em> remains a key issue.
In particular, <span title="" class="ltx_glossaryref">SER</span> models have been shown to suffer from susceptibility to encoding errors <cite class="ltx_cite ltx_citemacro_citep">(Oates et al., <a href="#bib.bib39" title="" class="ltx_ref">2019</a>)</cite>, packet loss <cite class="ltx_cite ltx_citemacro_citep">(Mohamed and Schuller, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite>, and additive noise <cite class="ltx_cite ltx_citemacro_citep">(Triantafyllopoulos et al., <a href="#bib.bib51" title="" class="ltx_ref">2019</a>; Wagner et al., <a href="#bib.bib54" title="" class="ltx_ref">2022</a>)</cite>.
Of those, additive noise is the more insidious, as it is beyond the control of the application designer (unlike encoding errors and packet loss which can be fixed by other means) and needs to be addressed with <span title="" class="ltx_glossaryref">audio enhancement</span> methods.</p>
</div>
<div id="S3.SS4.SSS3.p2" class="ltx_para">
<p id="S3.SS4.SSS3.p2.1" class="ltx_p">In recent years, <span title="" class="ltx_glossaryref">SER</span> research has transitioned to the use of <span title="" class="ltx_glossaryref">DL</span> models like <span title="" class="ltx_glossaryref">convolutional neural networks (CNNs)</span> <cite class="ltx_cite ltx_citemacro_citep">(Triantafyllopoulos et al., <a href="#bib.bib52" title="" class="ltx_ref">2021</a>)</cite>, an approach we follow here as well.
In particular, we use a 4-layered <span title="" class="ltx_glossaryref">CNN</span>, where each layer consists of a sequence of convolution, batch normalisation, ReLU activation, max-pooling, and dropout.
Its input consists of the Mel spectrogram, computed with 32 Mel-scale filters, a window length of 20 ms, and a step size of 10 ms.
This architecture has been shown to be effective in previous works<span id="todo1" class="ltx_note ltx_role_todo"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">todo: </span><span class="ltx_tag ltx_tag_note">1</span>which ones?</span></span></span>.
Its output is projected to emotion labels using a dense layer, as depicted in Fig. <a href="#S3.F3.sf3" title="Figure 3(c) ‣ Figure 3 ‣ 3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a>.</p>
</div>
</section>
<section id="S3.SS4.SSS4" class="ltx_subsubsection ltx_indent_first">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.4 </span>Acoustic Scene Classification</h4>

<div id="S3.SS4.SSS4.p1" class="ltx_para">
<p id="S3.SS4.SSS4.p1.1" class="ltx_p">Our final audio application, <span title="" class="ltx_glossaryref">ASC</span>, is concerned with the classification of soundscapes in discrete categories that characterise their content (e. g., a park or a shopping mall).
This application departs from the standard assumption that speech is the signal to be preserved.
Instead, speech is now considered a contaminating source which needs to be removed.
There are two primary motivating factors for this unorthodox formulation: a) improving the robustness of <span title="" class="ltx_glossaryref">ASC</span> classification in the presence of speech <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>, and b) enforcing privacy regulations in the case of large-scale, monitoring applications <cite class="ltx_cite ltx_citemacro_citep">(Bajovic et al., <a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>.
In fact, the two factors have a strong overlap as data collection for <span title="" class="ltx_glossaryref">ASC</span> applications typically takes mitigating steps to avoid the capturing of speech (e. g., filtering out segments where a VAD is triggered <cite class="ltx_cite ltx_citemacro_citep">(Bajovic et al., <a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>) resulting in datasets that do not violate privacy requirements, but will have trouble generalising to real-world environments where human speech is ubiquitous.
To that end, we propose to enhance <span title="" class="ltx_glossaryref">ASC</span> signals by removing speech – a form of <em id="S3.SS4.SSS4.p1.1.1" class="ltx_emph ltx_font_italic">voice suppression</em> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib29" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S3.SS4.SSS4.p2" class="ltx_para">
<p id="S3.SS4.SSS4.p2.2" class="ltx_p">As our <span title="" class="ltx_glossaryref">ASC</span> model, we use Dual-ResNet <cite class="ltx_cite ltx_citemacro_citep">(McDonnell and Gao, <a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>, which was awarded as the most reproducible system for the first task of the 2020 <span title="" class="ltx_glossaryref">Detection and Classification of Acoustic Scenes and Events (DCASE)</span> challenge <cite class="ltx_cite ltx_citemacro_citep">(Heittola et al., <a href="#bib.bib18" title="" class="ltx_ref">2020</a>)</cite>.
The model contains two different paths for separately processing the low- (lower 64) and high-frequency bands (upper 64).
Late fusion is used to concatenate the outputs of these two paths, before going through two additional <math id="S3.SS4.SSS4.p2.1.m1.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S3.SS4.SSS4.p2.1.m1.1a"><mrow id="S3.SS4.SSS4.p2.1.m1.1.1" xref="S3.SS4.SSS4.p2.1.m1.1.1.cmml"><mn id="S3.SS4.SSS4.p2.1.m1.1.1.2" xref="S3.SS4.SSS4.p2.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.SSS4.p2.1.m1.1.1.1" xref="S3.SS4.SSS4.p2.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS4.SSS4.p2.1.m1.1.1.3" xref="S3.SS4.SSS4.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS4.p2.1.m1.1b"><apply id="S3.SS4.SSS4.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS4.p2.1.m1.1.1"><times id="S3.SS4.SSS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.SSS4.p2.1.m1.1.1.1"></times><cn type="integer" id="S3.SS4.SSS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.SSS4.p2.1.m1.1.1.2">1</cn><cn type="integer" id="S3.SS4.SSS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.SSS4.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS4.p2.1.m1.1c">1\times 1</annotation></semantics></math> convolutional layers to reduce the dimensionality to the number of classes.
A schematic visualisation of the architecture can be found in Fig.  <a href="#S3.F3.sf4" title="Figure 3(d) ‣ Figure 3 ‣ 3.3 Audio Enhancement Model ‣ 3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(d)</span></a>.
The low- and high-frequency paths have an identical architecture, namely, a residual network of 8 convolutional blocks, each block a sequence of batch normalisation, ReLU activation, and a final convolutional layer.
The Log Mel spectrogram of <math id="S3.SS4.SSS4.p2.2.m2.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S3.SS4.SSS4.p2.2.m2.1a"><mn id="S3.SS4.SSS4.p2.2.m2.1.1" xref="S3.SS4.SSS4.p2.2.m2.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS4.p2.2.m2.1b"><cn type="integer" id="S3.SS4.SSS4.p2.2.m2.1.1.cmml" xref="S3.SS4.SSS4.p2.2.m2.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS4.p2.2.m2.1c">128</annotation></semantics></math> Mel-bands, extracted from the audio waveform by applying STFT with the window length of 64 ms and a hop size of 16 ms, are used as the model input.
<br class="ltx_break"></p>
</div>
</section>
</section>
<section id="S3.SS5" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Training Details</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">During the training we applied a batch size of 16 for the U-Net audio enhancement, which has shown optimal performance in preliminary experiments.
All models are trained with an Adam optimiser and additional weight decay is applied for the SCR and ASC models in the form of L2 regularisation. The ASR model is trained with a connectionist temporal classification (CTC) loss <cite class="ltx_cite ltx_citemacro_cite">Graves et al. (<a href="#bib.bib15" title="" class="ltx_ref">2006</a>)</cite>, whilst we optimise the cross-entropy loss for the remaining CATs.
For the AE, ASR and ASC models, we set the learning rate to 0.0001, while we set it to 0.001 for SER. For the SCR task, we reduce an initial learning
rate of 0.01 to 0.001 after 20 epochs. In order to train the audios of varying lengths for CATs like ASR and SER we pad the shorter audios to the length of the longest sample.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We conducted experiments to evaluate the proposed training paradigm
on all four <span title="" class="ltx_glossaryref">CAT</span> s introduced. In the following, we describe the datasets, evaluation metrics, and experimental setups for each case and report our results.
<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_tag ltx_tag_note">†</span>Examples to show our audio enhancement performance, including speech enhancement for different languages and voice suppression, can be found in: <a target="_blank" href="https://github.com/EIHW/AE_SampleImportance" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/EIHW/AE_SampleImportance</a></span></span></span></p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.55.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Table 1</span>: </span><span id="S4.T1.2.2.1" class="ltx_text" style="font-size:90%;">Speech command recognition testing results, (Acc)uray[<math id="S4.T1.2.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T1.2.2.1.m1.1b"><mo id="S4.T1.2.2.1.m1.1.1" xref="S4.T1.2.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.1.m1.1c"><csymbol cd="latexml" id="S4.T1.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.1.m1.1d">\%</annotation></semantics></math>], using the Speech commands data set and the AudioSet corpus. DA stands for the method using only data augmentation. MTL represents the proposed multi-task learning solution.</span></figcaption>
<table id="S4.T1.52.52" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.8.8.6" class="ltx_tr">
<th id="S4.T1.8.8.6.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">Methods</th>
<th id="S4.T1.8.8.6.8" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">Inf</th>
<td id="S4.T1.3.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.3.3.1.1.m1.1" class="ltx_Math" alttext="25$\mathrm{dB}$" display="inline"><semantics id="S4.T1.3.3.1.1.m1.1a"><mrow id="S4.T1.3.3.1.1.m1.1.2" xref="S4.T1.3.3.1.1.m1.1.2.cmml"><mn id="S4.T1.3.3.1.1.m1.1.2.2" xref="S4.T1.3.3.1.1.m1.1.2.2.cmml">25</mn><mo lspace="0em" rspace="0em" id="S4.T1.3.3.1.1.m1.1.2.1" xref="S4.T1.3.3.1.1.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T1.3.3.1.1.m1.1.2.3" xref="S4.T1.3.3.1.1.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.1.1.m1.1b"><apply id="S4.T1.3.3.1.1.m1.1.2.cmml" xref="S4.T1.3.3.1.1.m1.1.2"><times id="S4.T1.3.3.1.1.m1.1.2.1.cmml" xref="S4.T1.3.3.1.1.m1.1.2.1"></times><cn type="integer" id="S4.T1.3.3.1.1.m1.1.2.2.cmml" xref="S4.T1.3.3.1.1.m1.1.2.2">25</cn><csymbol cd="latexml" id="S4.T1.3.3.1.1.m1.1.2.3.cmml" xref="S4.T1.3.3.1.1.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.1.1.m1.1c">25$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T1.4.4.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.4.4.2.2.m1.1" class="ltx_Math" alttext="20$\mathrm{dB}$" display="inline"><semantics id="S4.T1.4.4.2.2.m1.1a"><mrow id="S4.T1.4.4.2.2.m1.1.2" xref="S4.T1.4.4.2.2.m1.1.2.cmml"><mn id="S4.T1.4.4.2.2.m1.1.2.2" xref="S4.T1.4.4.2.2.m1.1.2.2.cmml">20</mn><mo lspace="0em" rspace="0em" id="S4.T1.4.4.2.2.m1.1.2.1" xref="S4.T1.4.4.2.2.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T1.4.4.2.2.m1.1.2.3" xref="S4.T1.4.4.2.2.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.2.2.m1.1b"><apply id="S4.T1.4.4.2.2.m1.1.2.cmml" xref="S4.T1.4.4.2.2.m1.1.2"><times id="S4.T1.4.4.2.2.m1.1.2.1.cmml" xref="S4.T1.4.4.2.2.m1.1.2.1"></times><cn type="integer" id="S4.T1.4.4.2.2.m1.1.2.2.cmml" xref="S4.T1.4.4.2.2.m1.1.2.2">20</cn><csymbol cd="latexml" id="S4.T1.4.4.2.2.m1.1.2.3.cmml" xref="S4.T1.4.4.2.2.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.2.2.m1.1c">20$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T1.5.5.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.5.5.3.3.m1.1" class="ltx_Math" alttext="15$\mathrm{dB}$" display="inline"><semantics id="S4.T1.5.5.3.3.m1.1a"><mrow id="S4.T1.5.5.3.3.m1.1.2" xref="S4.T1.5.5.3.3.m1.1.2.cmml"><mn id="S4.T1.5.5.3.3.m1.1.2.2" xref="S4.T1.5.5.3.3.m1.1.2.2.cmml">15</mn><mo lspace="0em" rspace="0em" id="S4.T1.5.5.3.3.m1.1.2.1" xref="S4.T1.5.5.3.3.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T1.5.5.3.3.m1.1.2.3" xref="S4.T1.5.5.3.3.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.3.3.m1.1b"><apply id="S4.T1.5.5.3.3.m1.1.2.cmml" xref="S4.T1.5.5.3.3.m1.1.2"><times id="S4.T1.5.5.3.3.m1.1.2.1.cmml" xref="S4.T1.5.5.3.3.m1.1.2.1"></times><cn type="integer" id="S4.T1.5.5.3.3.m1.1.2.2.cmml" xref="S4.T1.5.5.3.3.m1.1.2.2">15</cn><csymbol cd="latexml" id="S4.T1.5.5.3.3.m1.1.2.3.cmml" xref="S4.T1.5.5.3.3.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.3.3.m1.1c">15$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T1.6.6.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.6.6.4.4.m1.1" class="ltx_Math" alttext="10$\mathrm{dB}$" display="inline"><semantics id="S4.T1.6.6.4.4.m1.1a"><mrow id="S4.T1.6.6.4.4.m1.1.2" xref="S4.T1.6.6.4.4.m1.1.2.cmml"><mn id="S4.T1.6.6.4.4.m1.1.2.2" xref="S4.T1.6.6.4.4.m1.1.2.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S4.T1.6.6.4.4.m1.1.2.1" xref="S4.T1.6.6.4.4.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T1.6.6.4.4.m1.1.2.3" xref="S4.T1.6.6.4.4.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.4.4.m1.1b"><apply id="S4.T1.6.6.4.4.m1.1.2.cmml" xref="S4.T1.6.6.4.4.m1.1.2"><times id="S4.T1.6.6.4.4.m1.1.2.1.cmml" xref="S4.T1.6.6.4.4.m1.1.2.1"></times><cn type="integer" id="S4.T1.6.6.4.4.m1.1.2.2.cmml" xref="S4.T1.6.6.4.4.m1.1.2.2">10</cn><csymbol cd="latexml" id="S4.T1.6.6.4.4.m1.1.2.3.cmml" xref="S4.T1.6.6.4.4.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.4.4.m1.1c">10$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T1.7.7.5.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.7.7.5.5.m1.1" class="ltx_Math" alttext="5$\mathrm{dB}$" display="inline"><semantics id="S4.T1.7.7.5.5.m1.1a"><mrow id="S4.T1.7.7.5.5.m1.1.2" xref="S4.T1.7.7.5.5.m1.1.2.cmml"><mn id="S4.T1.7.7.5.5.m1.1.2.2" xref="S4.T1.7.7.5.5.m1.1.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.T1.7.7.5.5.m1.1.2.1" xref="S4.T1.7.7.5.5.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T1.7.7.5.5.m1.1.2.3" xref="S4.T1.7.7.5.5.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.5.5.m1.1b"><apply id="S4.T1.7.7.5.5.m1.1.2.cmml" xref="S4.T1.7.7.5.5.m1.1.2"><times id="S4.T1.7.7.5.5.m1.1.2.1.cmml" xref="S4.T1.7.7.5.5.m1.1.2.1"></times><cn type="integer" id="S4.T1.7.7.5.5.m1.1.2.2.cmml" xref="S4.T1.7.7.5.5.m1.1.2.2">5</cn><csymbol cd="latexml" id="S4.T1.7.7.5.5.m1.1.2.3.cmml" xref="S4.T1.7.7.5.5.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.5.5.m1.1c">5$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T1.8.8.6.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.8.8.6.6.m1.1" class="ltx_Math" alttext="0$\mathrm{dB}$" display="inline"><semantics id="S4.T1.8.8.6.6.m1.1a"><mrow id="S4.T1.8.8.6.6.m1.1.2" xref="S4.T1.8.8.6.6.m1.1.2.cmml"><mn id="S4.T1.8.8.6.6.m1.1.2.2" xref="S4.T1.8.8.6.6.m1.1.2.2.cmml">0</mn><mo lspace="0em" rspace="0em" id="S4.T1.8.8.6.6.m1.1.2.1" xref="S4.T1.8.8.6.6.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T1.8.8.6.6.m1.1.2.3" xref="S4.T1.8.8.6.6.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.6.6.m1.1b"><apply id="S4.T1.8.8.6.6.m1.1.2.cmml" xref="S4.T1.8.8.6.6.m1.1.2"><times id="S4.T1.8.8.6.6.m1.1.2.1.cmml" xref="S4.T1.8.8.6.6.m1.1.2.1"></times><cn type="integer" id="S4.T1.8.8.6.6.m1.1.2.2.cmml" xref="S4.T1.8.8.6.6.m1.1.2.2">0</cn><csymbol cd="latexml" id="S4.T1.8.8.6.6.m1.1.2.3.cmml" xref="S4.T1.8.8.6.6.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.6.6.m1.1c">0$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T1.8.8.6.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">average</td>
</tr>
<tr id="S4.T1.16.16.14" class="ltx_tr">
<th id="S4.T1.16.16.14.9" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">original SCR</th>
<th id="S4.T1.9.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.9.9.7.1.m1.1" class="ltx_Math" alttext="85.07" display="inline"><semantics id="S4.T1.9.9.7.1.m1.1a"><mn id="S4.T1.9.9.7.1.m1.1.1" xref="S4.T1.9.9.7.1.m1.1.1.cmml">85.07</mn><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.7.1.m1.1b"><cn type="float" id="S4.T1.9.9.7.1.m1.1.1.cmml" xref="S4.T1.9.9.7.1.m1.1.1">85.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.7.1.m1.1c">85.07</annotation></semantics></math></th>
<td id="S4.T1.10.10.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.10.10.8.2.m1.1" class="ltx_Math" alttext="83.37" display="inline"><semantics id="S4.T1.10.10.8.2.m1.1a"><mn id="S4.T1.10.10.8.2.m1.1.1" xref="S4.T1.10.10.8.2.m1.1.1.cmml">83.37</mn><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.8.2.m1.1b"><cn type="float" id="S4.T1.10.10.8.2.m1.1.1.cmml" xref="S4.T1.10.10.8.2.m1.1.1">83.37</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.8.2.m1.1c">83.37</annotation></semantics></math></td>
<td id="S4.T1.11.11.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.11.11.9.3.m1.1" class="ltx_Math" alttext="81.35" display="inline"><semantics id="S4.T1.11.11.9.3.m1.1a"><mn id="S4.T1.11.11.9.3.m1.1.1" xref="S4.T1.11.11.9.3.m1.1.1.cmml">81.35</mn><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.9.3.m1.1b"><cn type="float" id="S4.T1.11.11.9.3.m1.1.1.cmml" xref="S4.T1.11.11.9.3.m1.1.1">81.35</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.9.3.m1.1c">81.35</annotation></semantics></math></td>
<td id="S4.T1.12.12.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.12.12.10.4.m1.1" class="ltx_Math" alttext="76.87" display="inline"><semantics id="S4.T1.12.12.10.4.m1.1a"><mn id="S4.T1.12.12.10.4.m1.1.1" xref="S4.T1.12.12.10.4.m1.1.1.cmml">76.87</mn><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.10.4.m1.1b"><cn type="float" id="S4.T1.12.12.10.4.m1.1.1.cmml" xref="S4.T1.12.12.10.4.m1.1.1">76.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.10.4.m1.1c">76.87</annotation></semantics></math></td>
<td id="S4.T1.13.13.11.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.13.13.11.5.m1.1" class="ltx_Math" alttext="67.57" display="inline"><semantics id="S4.T1.13.13.11.5.m1.1a"><mn id="S4.T1.13.13.11.5.m1.1.1" xref="S4.T1.13.13.11.5.m1.1.1.cmml">67.57</mn><annotation-xml encoding="MathML-Content" id="S4.T1.13.13.11.5.m1.1b"><cn type="float" id="S4.T1.13.13.11.5.m1.1.1.cmml" xref="S4.T1.13.13.11.5.m1.1.1">67.57</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.13.11.5.m1.1c">67.57</annotation></semantics></math></td>
<td id="S4.T1.14.14.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.14.14.12.6.m1.1" class="ltx_Math" alttext="51.52" display="inline"><semantics id="S4.T1.14.14.12.6.m1.1a"><mn id="S4.T1.14.14.12.6.m1.1.1" xref="S4.T1.14.14.12.6.m1.1.1.cmml">51.52</mn><annotation-xml encoding="MathML-Content" id="S4.T1.14.14.12.6.m1.1b"><cn type="float" id="S4.T1.14.14.12.6.m1.1.1.cmml" xref="S4.T1.14.14.12.6.m1.1.1">51.52</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.14.12.6.m1.1c">51.52</annotation></semantics></math></td>
<td id="S4.T1.15.15.13.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.15.15.13.7.m1.1" class="ltx_Math" alttext="33.12" display="inline"><semantics id="S4.T1.15.15.13.7.m1.1a"><mn id="S4.T1.15.15.13.7.m1.1.1" xref="S4.T1.15.15.13.7.m1.1.1.cmml">33.12</mn><annotation-xml encoding="MathML-Content" id="S4.T1.15.15.13.7.m1.1b"><cn type="float" id="S4.T1.15.15.13.7.m1.1.1.cmml" xref="S4.T1.15.15.13.7.m1.1.1">33.12</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.15.13.7.m1.1c">33.12</annotation></semantics></math></td>
<td id="S4.T1.16.16.14.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.16.16.14.8.m1.1" class="ltx_Math" alttext="65.63" display="inline"><semantics id="S4.T1.16.16.14.8.m1.1a"><mn id="S4.T1.16.16.14.8.m1.1.1" xref="S4.T1.16.16.14.8.m1.1.1.cmml">65.63</mn><annotation-xml encoding="MathML-Content" id="S4.T1.16.16.14.8.m1.1b"><cn type="float" id="S4.T1.16.16.14.8.m1.1.1.cmml" xref="S4.T1.16.16.14.8.m1.1.1">65.63</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.16.14.8.m1.1c">65.63</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.23.23.21" class="ltx_tr">
<th id="S4.T1.23.23.21.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">DA</th>
<th id="S4.T1.23.23.21.9" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T1.17.17.15.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.17.17.15.1.m1.1" class="ltx_Math" alttext="82.69" display="inline"><semantics id="S4.T1.17.17.15.1.m1.1a"><mn id="S4.T1.17.17.15.1.m1.1.1" xref="S4.T1.17.17.15.1.m1.1.1.cmml">82.69</mn><annotation-xml encoding="MathML-Content" id="S4.T1.17.17.15.1.m1.1b"><cn type="float" id="S4.T1.17.17.15.1.m1.1.1.cmml" xref="S4.T1.17.17.15.1.m1.1.1">82.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.17.17.15.1.m1.1c">82.69</annotation></semantics></math></td>
<td id="S4.T1.18.18.16.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.18.18.16.2.m1.1" class="ltx_Math" alttext="82.07" display="inline"><semantics id="S4.T1.18.18.16.2.m1.1a"><mn id="S4.T1.18.18.16.2.m1.1.1" xref="S4.T1.18.18.16.2.m1.1.1.cmml">82.07</mn><annotation-xml encoding="MathML-Content" id="S4.T1.18.18.16.2.m1.1b"><cn type="float" id="S4.T1.18.18.16.2.m1.1.1.cmml" xref="S4.T1.18.18.16.2.m1.1.1">82.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.18.18.16.2.m1.1c">82.07</annotation></semantics></math></td>
<td id="S4.T1.19.19.17.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.19.19.17.3.m1.1" class="ltx_Math" alttext="80.09" display="inline"><semantics id="S4.T1.19.19.17.3.m1.1a"><mn id="S4.T1.19.19.17.3.m1.1.1" xref="S4.T1.19.19.17.3.m1.1.1.cmml">80.09</mn><annotation-xml encoding="MathML-Content" id="S4.T1.19.19.17.3.m1.1b"><cn type="float" id="S4.T1.19.19.17.3.m1.1.1.cmml" xref="S4.T1.19.19.17.3.m1.1.1">80.09</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.19.19.17.3.m1.1c">80.09</annotation></semantics></math></td>
<td id="S4.T1.20.20.18.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.20.20.18.4.m1.1" class="ltx_Math" alttext="77.53" display="inline"><semantics id="S4.T1.20.20.18.4.m1.1a"><mn id="S4.T1.20.20.18.4.m1.1.1" xref="S4.T1.20.20.18.4.m1.1.1.cmml">77.53</mn><annotation-xml encoding="MathML-Content" id="S4.T1.20.20.18.4.m1.1b"><cn type="float" id="S4.T1.20.20.18.4.m1.1.1.cmml" xref="S4.T1.20.20.18.4.m1.1.1">77.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.20.20.18.4.m1.1c">77.53</annotation></semantics></math></td>
<td id="S4.T1.21.21.19.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.21.21.19.5.m1.1" class="ltx_Math" alttext="71.66" display="inline"><semantics id="S4.T1.21.21.19.5.m1.1a"><mn id="S4.T1.21.21.19.5.m1.1.1" xref="S4.T1.21.21.19.5.m1.1.1.cmml">71.66</mn><annotation-xml encoding="MathML-Content" id="S4.T1.21.21.19.5.m1.1b"><cn type="float" id="S4.T1.21.21.19.5.m1.1.1.cmml" xref="S4.T1.21.21.19.5.m1.1.1">71.66</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.21.21.19.5.m1.1c">71.66</annotation></semantics></math></td>
<td id="S4.T1.22.22.20.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.22.22.20.6.m1.1" class="ltx_Math" alttext="58.26" display="inline"><semantics id="S4.T1.22.22.20.6.m1.1a"><mn id="S4.T1.22.22.20.6.m1.1.1" xref="S4.T1.22.22.20.6.m1.1.1.cmml">58.26</mn><annotation-xml encoding="MathML-Content" id="S4.T1.22.22.20.6.m1.1b"><cn type="float" id="S4.T1.22.22.20.6.m1.1.1.cmml" xref="S4.T1.22.22.20.6.m1.1.1">58.26</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.22.22.20.6.m1.1c">58.26</annotation></semantics></math></td>
<td id="S4.T1.23.23.21.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.23.23.21.7.m1.1" class="ltx_Math" alttext="75.38" display="inline"><semantics id="S4.T1.23.23.21.7.m1.1a"><mn id="S4.T1.23.23.21.7.m1.1.1" xref="S4.T1.23.23.21.7.m1.1.1.cmml">75.38</mn><annotation-xml encoding="MathML-Content" id="S4.T1.23.23.21.7.m1.1b"><cn type="float" id="S4.T1.23.23.21.7.m1.1.1.cmml" xref="S4.T1.23.23.21.7.m1.1.1">75.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.23.23.21.7.m1.1c">75.38</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.30.30.28" class="ltx_tr">
<th id="S4.T1.30.30.28.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">Cold Cascade</th>
<th id="S4.T1.30.30.28.9" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T1.24.24.22.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.24.24.22.1.m1.1" class="ltx_Math" alttext="84.34" display="inline"><semantics id="S4.T1.24.24.22.1.m1.1a"><mn id="S4.T1.24.24.22.1.m1.1.1" xref="S4.T1.24.24.22.1.m1.1.1.cmml">84.34</mn><annotation-xml encoding="MathML-Content" id="S4.T1.24.24.22.1.m1.1b"><cn type="float" id="S4.T1.24.24.22.1.m1.1.1.cmml" xref="S4.T1.24.24.22.1.m1.1.1">84.34</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.24.24.22.1.m1.1c">84.34</annotation></semantics></math></td>
<td id="S4.T1.25.25.23.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.25.25.23.2.m1.1" class="ltx_Math" alttext="83.38" display="inline"><semantics id="S4.T1.25.25.23.2.m1.1a"><mn id="S4.T1.25.25.23.2.m1.1.1" xref="S4.T1.25.25.23.2.m1.1.1.cmml">83.38</mn><annotation-xml encoding="MathML-Content" id="S4.T1.25.25.23.2.m1.1b"><cn type="float" id="S4.T1.25.25.23.2.m1.1.1.cmml" xref="S4.T1.25.25.23.2.m1.1.1">83.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.25.25.23.2.m1.1c">83.38</annotation></semantics></math></td>
<td id="S4.T1.26.26.24.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.26.26.24.3.m1.1" class="ltx_Math" alttext="80.85" display="inline"><semantics id="S4.T1.26.26.24.3.m1.1a"><mn id="S4.T1.26.26.24.3.m1.1.1" xref="S4.T1.26.26.24.3.m1.1.1.cmml">80.85</mn><annotation-xml encoding="MathML-Content" id="S4.T1.26.26.24.3.m1.1b"><cn type="float" id="S4.T1.26.26.24.3.m1.1.1.cmml" xref="S4.T1.26.26.24.3.m1.1.1">80.85</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.26.26.24.3.m1.1c">80.85</annotation></semantics></math></td>
<td id="S4.T1.27.27.25.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.27.27.25.4.m1.1" class="ltx_Math" alttext="75.54" display="inline"><semantics id="S4.T1.27.27.25.4.m1.1a"><mn id="S4.T1.27.27.25.4.m1.1.1" xref="S4.T1.27.27.25.4.m1.1.1.cmml">75.54</mn><annotation-xml encoding="MathML-Content" id="S4.T1.27.27.25.4.m1.1b"><cn type="float" id="S4.T1.27.27.25.4.m1.1.1.cmml" xref="S4.T1.27.27.25.4.m1.1.1">75.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.27.27.25.4.m1.1c">75.54</annotation></semantics></math></td>
<td id="S4.T1.28.28.26.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.28.28.26.5.m1.1" class="ltx_Math" alttext="66.06" display="inline"><semantics id="S4.T1.28.28.26.5.m1.1a"><mn id="S4.T1.28.28.26.5.m1.1.1" xref="S4.T1.28.28.26.5.m1.1.1.cmml">66.06</mn><annotation-xml encoding="MathML-Content" id="S4.T1.28.28.26.5.m1.1b"><cn type="float" id="S4.T1.28.28.26.5.m1.1.1.cmml" xref="S4.T1.28.28.26.5.m1.1.1">66.06</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.28.28.26.5.m1.1c">66.06</annotation></semantics></math></td>
<td id="S4.T1.29.29.27.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.29.29.27.6.m1.1" class="ltx_Math" alttext="51.92" display="inline"><semantics id="S4.T1.29.29.27.6.m1.1a"><mn id="S4.T1.29.29.27.6.m1.1.1" xref="S4.T1.29.29.27.6.m1.1.1.cmml">51.92</mn><annotation-xml encoding="MathML-Content" id="S4.T1.29.29.27.6.m1.1b"><cn type="float" id="S4.T1.29.29.27.6.m1.1.1.cmml" xref="S4.T1.29.29.27.6.m1.1.1">51.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.29.29.27.6.m1.1c">51.92</annotation></semantics></math></td>
<td id="S4.T1.30.30.28.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.30.30.28.7.m1.1" class="ltx_Math" alttext="73.68" display="inline"><semantics id="S4.T1.30.30.28.7.m1.1a"><mn id="S4.T1.30.30.28.7.m1.1.1" xref="S4.T1.30.30.28.7.m1.1.1.cmml">73.68</mn><annotation-xml encoding="MathML-Content" id="S4.T1.30.30.28.7.m1.1b"><cn type="float" id="S4.T1.30.30.28.7.m1.1.1.cmml" xref="S4.T1.30.30.28.7.m1.1.1">73.68</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.30.30.28.7.m1.1c">73.68</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.38.38.36" class="ltx_tr">
<th id="S4.T1.38.38.36.9" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">Cold Cascade + DA</th>
<th id="S4.T1.31.31.29.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.31.31.29.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S4.T1.31.31.29.1.m1.1a"><mo id="S4.T1.31.31.29.1.m1.1.1" xref="S4.T1.31.31.29.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T1.31.31.29.1.m1.1b"><minus id="S4.T1.31.31.29.1.m1.1.1.cmml" xref="S4.T1.31.31.29.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.31.31.29.1.m1.1c">-</annotation></semantics></math></th>
<td id="S4.T1.32.32.30.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.32.32.30.2.m1.1" class="ltx_Math" alttext="82.65" display="inline"><semantics id="S4.T1.32.32.30.2.m1.1a"><mn id="S4.T1.32.32.30.2.m1.1.1" xref="S4.T1.32.32.30.2.m1.1.1.cmml">82.65</mn><annotation-xml encoding="MathML-Content" id="S4.T1.32.32.30.2.m1.1b"><cn type="float" id="S4.T1.32.32.30.2.m1.1.1.cmml" xref="S4.T1.32.32.30.2.m1.1.1">82.65</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.32.32.30.2.m1.1c">82.65</annotation></semantics></math></td>
<td id="S4.T1.33.33.31.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.33.33.31.3.m1.1" class="ltx_Math" alttext="82.31" display="inline"><semantics id="S4.T1.33.33.31.3.m1.1a"><mn id="S4.T1.33.33.31.3.m1.1.1" xref="S4.T1.33.33.31.3.m1.1.1.cmml">82.31</mn><annotation-xml encoding="MathML-Content" id="S4.T1.33.33.31.3.m1.1b"><cn type="float" id="S4.T1.33.33.31.3.m1.1.1.cmml" xref="S4.T1.33.33.31.3.m1.1.1">82.31</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.33.33.31.3.m1.1c">82.31</annotation></semantics></math></td>
<td id="S4.T1.34.34.32.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.34.34.32.4.m1.1" class="ltx_Math" alttext="81.64" display="inline"><semantics id="S4.T1.34.34.32.4.m1.1a"><mn id="S4.T1.34.34.32.4.m1.1.1" xref="S4.T1.34.34.32.4.m1.1.1.cmml">81.64</mn><annotation-xml encoding="MathML-Content" id="S4.T1.34.34.32.4.m1.1b"><cn type="float" id="S4.T1.34.34.32.4.m1.1.1.cmml" xref="S4.T1.34.34.32.4.m1.1.1">81.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.34.34.32.4.m1.1c">81.64</annotation></semantics></math></td>
<td id="S4.T1.35.35.33.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.35.35.33.5.m1.1" class="ltx_Math" alttext="79.31" display="inline"><semantics id="S4.T1.35.35.33.5.m1.1a"><mn id="S4.T1.35.35.33.5.m1.1.1" xref="S4.T1.35.35.33.5.m1.1.1.cmml">79.31</mn><annotation-xml encoding="MathML-Content" id="S4.T1.35.35.33.5.m1.1b"><cn type="float" id="S4.T1.35.35.33.5.m1.1.1.cmml" xref="S4.T1.35.35.33.5.m1.1.1">79.31</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.35.35.33.5.m1.1c">79.31</annotation></semantics></math></td>
<td id="S4.T1.36.36.34.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.36.36.34.6.m1.1" class="ltx_Math" alttext="74.22" display="inline"><semantics id="S4.T1.36.36.34.6.m1.1a"><mn id="S4.T1.36.36.34.6.m1.1.1" xref="S4.T1.36.36.34.6.m1.1.1.cmml">74.22</mn><annotation-xml encoding="MathML-Content" id="S4.T1.36.36.34.6.m1.1b"><cn type="float" id="S4.T1.36.36.34.6.m1.1.1.cmml" xref="S4.T1.36.36.34.6.m1.1.1">74.22</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.36.36.34.6.m1.1c">74.22</annotation></semantics></math></td>
<td id="S4.T1.37.37.35.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.37.37.35.7.m1.1" class="ltx_Math" alttext="64.93" display="inline"><semantics id="S4.T1.37.37.35.7.m1.1a"><mn id="S4.T1.37.37.35.7.m1.1.1" xref="S4.T1.37.37.35.7.m1.1.1.cmml">64.93</mn><annotation-xml encoding="MathML-Content" id="S4.T1.37.37.35.7.m1.1b"><cn type="float" id="S4.T1.37.37.35.7.m1.1.1.cmml" xref="S4.T1.37.37.35.7.m1.1.1">64.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.37.37.35.7.m1.1c">64.93</annotation></semantics></math></td>
<td id="S4.T1.38.38.36.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.38.38.36.8.m1.1" class="ltx_Math" alttext="77.51" display="inline"><semantics id="S4.T1.38.38.36.8.m1.1a"><mn id="S4.T1.38.38.36.8.m1.1.1" xref="S4.T1.38.38.36.8.m1.1.1.cmml">77.51</mn><annotation-xml encoding="MathML-Content" id="S4.T1.38.38.36.8.m1.1b"><cn type="float" id="S4.T1.38.38.36.8.m1.1.1.cmml" xref="S4.T1.38.38.36.8.m1.1.1">77.51</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.38.38.36.8.m1.1c">77.51</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.52.52.51.1" class="ltx_tr">
<th id="S4.T1.52.52.51.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">MetricGAN+</th>
<th id="S4.T1.52.52.51.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T1.52.52.51.1.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">77.78</td>
<td id="S4.T1.52.52.51.1.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">75.81</td>
<td id="S4.T1.52.52.51.1.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">71.95</td>
<td id="S4.T1.52.52.51.1.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">64.49</td>
<td id="S4.T1.52.52.51.1.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">52.60</td>
<td id="S4.T1.52.52.51.1.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">35.37</td>
<td id="S4.T1.52.52.51.1.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">63.00</td>
</tr>
<tr id="S4.T1.52.52.52.2" class="ltx_tr">
<th id="S4.T1.52.52.52.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">DFNet-3</th>
<th id="S4.T1.52.52.52.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T1.52.52.52.2.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">80.81</td>
<td id="S4.T1.52.52.52.2.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">79.83</td>
<td id="S4.T1.52.52.52.2.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">78.07</td>
<td id="S4.T1.52.52.52.2.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">74.89</td>
<td id="S4.T1.52.52.52.2.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">69.72</td>
<td id="S4.T1.52.52.52.2.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">62.88</td>
<td id="S4.T1.52.52.52.2.9" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;">74.37</td>
</tr>
<tr id="S4.T1.45.45.43" class="ltx_tr">
<th id="S4.T1.45.45.43.8" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.45.45.43.8.1" class="ltx_text ltx_font_bold">MTL</span></th>
<th id="S4.T1.45.45.43.9" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T1.39.39.37.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.39.39.37.1.1" class="ltx_text ltx_markedasmath ltx_font_bold">85.53</span></td>
<td id="S4.T1.40.40.38.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.40.40.38.2.1" class="ltx_text ltx_markedasmath ltx_font_bold">84.21</span></td>
<td id="S4.T1.41.41.39.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.41.41.39.3.m1.1" class="ltx_Math" alttext="82.12" display="inline"><semantics id="S4.T1.41.41.39.3.m1.1a"><mn id="S4.T1.41.41.39.3.m1.1.1" xref="S4.T1.41.41.39.3.m1.1.1.cmml">82.12</mn><annotation-xml encoding="MathML-Content" id="S4.T1.41.41.39.3.m1.1b"><cn type="float" id="S4.T1.41.41.39.3.m1.1.1.cmml" xref="S4.T1.41.41.39.3.m1.1.1">82.12</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.41.41.39.3.m1.1c">82.12</annotation></semantics></math></td>
<td id="S4.T1.42.42.40.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.42.42.40.4.m1.1" class="ltx_Math" alttext="80.04" display="inline"><semantics id="S4.T1.42.42.40.4.m1.1a"><mn id="S4.T1.42.42.40.4.m1.1.1" xref="S4.T1.42.42.40.4.m1.1.1.cmml">80.04</mn><annotation-xml encoding="MathML-Content" id="S4.T1.42.42.40.4.m1.1b"><cn type="float" id="S4.T1.42.42.40.4.m1.1.1.cmml" xref="S4.T1.42.42.40.4.m1.1.1">80.04</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.42.42.40.4.m1.1c">80.04</annotation></semantics></math></td>
<td id="S4.T1.43.43.41.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.43.43.41.5.m1.1" class="ltx_Math" alttext="76.54" display="inline"><semantics id="S4.T1.43.43.41.5.m1.1a"><mn id="S4.T1.43.43.41.5.m1.1.1" xref="S4.T1.43.43.41.5.m1.1.1.cmml">76.54</mn><annotation-xml encoding="MathML-Content" id="S4.T1.43.43.41.5.m1.1b"><cn type="float" id="S4.T1.43.43.41.5.m1.1.1.cmml" xref="S4.T1.43.43.41.5.m1.1.1">76.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.43.43.41.5.m1.1c">76.54</annotation></semantics></math></td>
<td id="S4.T1.44.44.42.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.44.44.42.6.m1.1" class="ltx_Math" alttext="67.18" display="inline"><semantics id="S4.T1.44.44.42.6.m1.1a"><mn id="S4.T1.44.44.42.6.m1.1.1" xref="S4.T1.44.44.42.6.m1.1.1.cmml">67.18</mn><annotation-xml encoding="MathML-Content" id="S4.T1.44.44.42.6.m1.1b"><cn type="float" id="S4.T1.44.44.42.6.m1.1.1.cmml" xref="S4.T1.44.44.42.6.m1.1.1">67.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.44.44.42.6.m1.1c">67.18</annotation></semantics></math></td>
<td id="S4.T1.45.45.43.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.45.45.43.7.m1.1" class="ltx_Math" alttext="79.27" display="inline"><semantics id="S4.T1.45.45.43.7.m1.1a"><mn id="S4.T1.45.45.43.7.m1.1.1" xref="S4.T1.45.45.43.7.m1.1.1.cmml">79.27</mn><annotation-xml encoding="MathML-Content" id="S4.T1.45.45.43.7.m1.1b"><cn type="float" id="S4.T1.45.45.43.7.m1.1.1.cmml" xref="S4.T1.45.45.43.7.m1.1.1">79.27</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.45.45.43.7.m1.1c">79.27</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.52.52.50" class="ltx_tr">
<th id="S4.T1.52.52.50.8" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.52.52.50.8.1" class="ltx_text ltx_font_bold">iterative optimisation</span></th>
<th id="S4.T1.52.52.50.9" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T1.46.46.44.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.46.46.44.1.m1.1" class="ltx_Math" alttext="85.35" display="inline"><semantics id="S4.T1.46.46.44.1.m1.1a"><mn id="S4.T1.46.46.44.1.m1.1.1" xref="S4.T1.46.46.44.1.m1.1.1.cmml">85.35</mn><annotation-xml encoding="MathML-Content" id="S4.T1.46.46.44.1.m1.1b"><cn type="float" id="S4.T1.46.46.44.1.m1.1.1.cmml" xref="S4.T1.46.46.44.1.m1.1.1">85.35</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.46.46.44.1.m1.1c">85.35</annotation></semantics></math></td>
<td id="S4.T1.47.47.45.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T1.47.47.45.2.m1.1" class="ltx_Math" alttext="83.93" display="inline"><semantics id="S4.T1.47.47.45.2.m1.1a"><mn id="S4.T1.47.47.45.2.m1.1.1" xref="S4.T1.47.47.45.2.m1.1.1.cmml">83.93</mn><annotation-xml encoding="MathML-Content" id="S4.T1.47.47.45.2.m1.1b"><cn type="float" id="S4.T1.47.47.45.2.m1.1.1.cmml" xref="S4.T1.47.47.45.2.m1.1.1">83.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.47.47.45.2.m1.1c">83.93</annotation></semantics></math></td>
<td id="S4.T1.48.48.46.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.48.48.46.3.1" class="ltx_text ltx_markedasmath ltx_font_bold">82.37</span></td>
<td id="S4.T1.49.49.47.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.49.49.47.4.1" class="ltx_text ltx_markedasmath ltx_font_bold">81.56</span></td>
<td id="S4.T1.50.50.48.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.50.50.48.5.1" class="ltx_text ltx_markedasmath ltx_font_bold">77.41</span></td>
<td id="S4.T1.51.51.49.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.51.51.49.6.1" class="ltx_text ltx_markedasmath ltx_font_bold">69.18</span></td>
<td id="S4.T1.52.52.50.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T1.52.52.50.7.1" class="ltx_text ltx_markedasmath ltx_font_bold">79.97</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Downstream Task I: Speech Command Recognition</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The first <span title="" class="ltx_glossaryref">CAT</span> application investigated in this work is SCR based on the limited-vocabulary dataset
<cite class="ltx_cite ltx_citemacro_cite">Warden (<a href="#bib.bib58" title="" class="ltx_ref">2018</a>)</cite>. The data includes 105 829 one-second-long audio clips of 35 common words, including digits zero to nine, fourteen words, which are considered useful as commands for IoT and robotics, as well as some additional words covering a variety of phonemes. The data further provide instances, which contain only background noise or speech that does include the target words. The negative samples are expected to help the keyword spotting systems to differentiate relevant from non-relevant audio clips, thereby lowering false positives in applications.
The problem at hand is thus formulated as a 35-class classification task based on an audio recording of constant length. Given the quite balanced distribution amongst classes in the test set, we choose accuracy, i. e., the ratio of correctly classified samples over all samples, for evaluation.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.8" class="ltx_p">In order to apply our audio enhancement methodology, we augment the original (‘clean’) data with noise recordings from AudioSet, which are truncated to a length of one second.
The two signals are added considering uniformly distributed SNR levels between <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mn id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><cn type="integer" id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">0</cn></annotation-xml></semantics></math> and <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="25" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mn id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><cn type="integer" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">25</annotation></semantics></math> <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="\mathrm{dB}" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mi class="ltx_unit" id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">dB</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><csymbol cd="latexml" id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">decibel</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\mathrm{dB}</annotation></semantics></math>, covering a range from very low volume noise (at 25 <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathrm{dB}" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mi class="ltx_unit" id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">dB</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><csymbol cd="latexml" id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">decibel</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">\mathrm{dB}</annotation></semantics></math>) to equal volume of noise and target signal (0 <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="\mathrm{dB}" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mi class="ltx_unit" id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">dB</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><csymbol cd="latexml" id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">decibel</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">\mathrm{dB}</annotation></semantics></math>).
Since the applied SCR model directly acts on the raw audio, no further data processing is necessary.
We evaluated our model at the constant SNR levels <math id="S4.SS1.p2.6.m6.5" class="ltx_Math" alttext="25,20,15,10,5" display="inline"><semantics id="S4.SS1.p2.6.m6.5a"><mrow id="S4.SS1.p2.6.m6.5.6.2" xref="S4.SS1.p2.6.m6.5.6.1.cmml"><mn id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml">25</mn><mo id="S4.SS1.p2.6.m6.5.6.2.1" xref="S4.SS1.p2.6.m6.5.6.1.cmml">,</mo><mn id="S4.SS1.p2.6.m6.2.2" xref="S4.SS1.p2.6.m6.2.2.cmml">20</mn><mo id="S4.SS1.p2.6.m6.5.6.2.2" xref="S4.SS1.p2.6.m6.5.6.1.cmml">,</mo><mn id="S4.SS1.p2.6.m6.3.3" xref="S4.SS1.p2.6.m6.3.3.cmml">15</mn><mo id="S4.SS1.p2.6.m6.5.6.2.3" xref="S4.SS1.p2.6.m6.5.6.1.cmml">,</mo><mn id="S4.SS1.p2.6.m6.4.4" xref="S4.SS1.p2.6.m6.4.4.cmml">10</mn><mo id="S4.SS1.p2.6.m6.5.6.2.4" xref="S4.SS1.p2.6.m6.5.6.1.cmml">,</mo><mn id="S4.SS1.p2.6.m6.5.5" xref="S4.SS1.p2.6.m6.5.5.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.5b"><list id="S4.SS1.p2.6.m6.5.6.1.cmml" xref="S4.SS1.p2.6.m6.5.6.2"><cn type="integer" id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1">25</cn><cn type="integer" id="S4.SS1.p2.6.m6.2.2.cmml" xref="S4.SS1.p2.6.m6.2.2">20</cn><cn type="integer" id="S4.SS1.p2.6.m6.3.3.cmml" xref="S4.SS1.p2.6.m6.3.3">15</cn><cn type="integer" id="S4.SS1.p2.6.m6.4.4.cmml" xref="S4.SS1.p2.6.m6.4.4">10</cn><cn type="integer" id="S4.SS1.p2.6.m6.5.5.cmml" xref="S4.SS1.p2.6.m6.5.5">5</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.5c">25,20,15,10,5</annotation></semantics></math> and <math id="S4.SS1.p2.7.m7.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS1.p2.7.m7.1a"><mn id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><cn type="integer" id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1">0</cn></annotation-xml></semantics></math> <math id="S4.SS1.p2.8.m8.1" class="ltx_Math" alttext="\mathrm{dB}" display="inline"><semantics id="S4.SS1.p2.8.m8.1a"><mi class="ltx_unit" id="S4.SS1.p2.8.m8.1.1" xref="S4.SS1.p2.8.m8.1.1.cmml">dB</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m8.1b"><csymbol cd="latexml" id="S4.SS1.p2.8.m8.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1">decibel</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m8.1c">\mathrm{dB}</annotation></semantics></math>. We picked these specific SNR levels to show how our models deal with increasingly noisy samples from the test set.
The AudioSet corpus contains more than two million human-labelled 10 s environmental sound clips drawn from YouTube videos.
We exclude all human-related noise samples labelled as “human sounds” from AudioSet and obtain 16 198 samples for the training set, 636 samples for the development set, and 714 samples for the test set.
The model architecture –as described in <a href="#S3" title="3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>
– is independently trained for the different noise levels and the training paradigms, as described in <a href="#S3" title="3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>, i. e., <span id="S4.SS1.p2.8.1" class="ltx_text ltx_font_italic">baseline</span>, <span id="S4.SS1.p2.8.2" class="ltx_text ltx_font_italic">data augmentation</span>, <span id="S4.SS1.p2.8.3" class="ltx_text ltx_font_italic">cold cascade</span>, <span id="S4.SS1.p2.8.4" class="ltx_text ltx_font_italic">cold cascade + data augmentation</span>, <span id="S4.SS1.p2.8.5" class="ltx_text ltx_font_italic">multi-task learning</span>, and <span id="S4.SS1.p2.8.6" class="ltx_text ltx_font_italic">iterative optimisation</span>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.3" class="ltx_p">The baseline of the SCR model without additive noise achieves an accuracy of <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="85.07\,\%" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mrow id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mn id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">85.07</mn><mo lspace="0.170em" id="S4.SS1.p3.1.m1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">85.07</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">85.07\,\%</annotation></semantics></math> (cf. Table <a href="#S4.T1" title="Table 1 ‣ 4 Experimental Results ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Intuitively, the performance of the same system decreases monotonically with increasing noise levels, dropping to <math id="S4.SS1.p3.2.m2.1" class="ltx_Math" alttext="33.12\,\%" display="inline"><semantics id="S4.SS1.p3.2.m2.1a"><mrow id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mn id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">33.12</mn><mo lspace="0.170em" id="S4.SS1.p3.2.m2.1.1.1" xref="S4.SS1.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><csymbol cd="latexml" id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">33.12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">33.12\,\%</annotation></semantics></math> with 0 dB SNR. All of the suggested approaches aim at increased robustness to help mitigate said drop-off. This effect becomes more noticeable with lower SNR values as, at 0 dB, even the worst improvement compared to the baseline alleviates the accuracy to more than <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="50\,\%" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mrow id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mn id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">50</mn><mo lspace="0.170em" id="S4.SS1.p3.3.m3.1.1.1" xref="S4.SS1.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><csymbol cd="latexml" id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">50\,\%</annotation></semantics></math>. The suggested iterative optimisation and MTL training paradigms outperform competing approaches in every instance, with the MTL achieving slightly better performance at high SNRs and the iterative optimisation performing better on low SNRs. At 0 dB, the iterative optimisation allows for an accuracy more than twice as high as the baseline. Noticeably, at 25 dB, MTL and iterative optimisation even outperform the baseline without additive noise. One possible explanation for this effect is that the AE filters small levels of inherent noise in the “clean” data itself. However, this claim is hard to verify, as quantitative measures of noise levels without completely noise-free ground-truths to compare against are difficult to obtain, making a deeper analysis necessary.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.3" class="ltx_p">Our iterative optimisation and MTL methods also perform favourably with respect to the state-of-the-art.
DFNet-3 denoising achieves an average accuracy of <math id="S4.SS1.p4.1.m1.1" class="ltx_math_unparsed" alttext="74.37,\%" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mrow id="S4.SS1.p4.1.m1.1b"><mn id="S4.SS1.p4.1.m1.1.1">74.37</mn><mo id="S4.SS1.p4.1.m1.1.2">,</mo><mo id="S4.SS1.p4.1.m1.1.3">%</mo></mrow><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">74.37,\%</annotation></semantics></math>, which is substantially lower than our <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="79.97\%" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mrow id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml"><mn id="S4.SS1.p4.2.m2.1.1.2" xref="S4.SS1.p4.2.m2.1.1.2.cmml">79.97</mn><mo id="S4.SS1.p4.2.m2.1.1.1" xref="S4.SS1.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><apply id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1"><csymbol cd="latexml" id="S4.SS1.p4.2.m2.1.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p4.2.m2.1.1.2.cmml" xref="S4.SS1.p4.2.m2.1.1.2">79.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">79.97\%</annotation></semantics></math>.
The same is true for MetricGAN+, which ranks lower even than the baseline model at <math id="S4.SS1.p4.3.m3.1" class="ltx_Math" alttext="63.00\%" display="inline"><semantics id="S4.SS1.p4.3.m3.1a"><mrow id="S4.SS1.p4.3.m3.1.1" xref="S4.SS1.p4.3.m3.1.1.cmml"><mn id="S4.SS1.p4.3.m3.1.1.2" xref="S4.SS1.p4.3.m3.1.1.2.cmml">63.00</mn><mo id="S4.SS1.p4.3.m3.1.1.1" xref="S4.SS1.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.3.m3.1b"><apply id="S4.SS1.p4.3.m3.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1"><csymbol cd="latexml" id="S4.SS1.p4.3.m3.1.1.1.cmml" xref="S4.SS1.p4.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p4.3.m3.1.1.2.cmml" xref="S4.SS1.p4.3.m3.1.1.2">63.00</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.3.m3.1c">63.00\%</annotation></semantics></math>; this failure particularly illustrates how difficult the task is, and how a simple denoising frontend can fail.
Both models underperform the baseline at higher SNRs, which indicates that they introduce some unwanted distortion into the signal – something that our methods avoid.
We also note that DFNet-3 is only marginally better than our own Cold Cascade method, even though the DNS-4 dataset is vastly bigger and more diverse than ours, which shows that our model is competitive in terms of enhancement performance.
Overall, the comparison to state-of-the-art illustrates that iterative optimisation is crucial for bridging the gap to downstream performance between clean and noisy audio.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.55.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Table 2</span>: </span><span id="S4.T2.2.2.1" class="ltx_text" style="font-size:90%;">Automatic speech recognition testing results, WER [<math id="S4.T2.2.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T2.2.2.1.m1.1b"><mo id="S4.T2.2.2.1.m1.1.1" xref="S4.T2.2.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1c"><csymbol cd="latexml" id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1d">\%</annotation></semantics></math>], using Librispeech and the AudioSet corpus. DA stands for the method using only data augmentation. MTL represents the proposed multi-task learning solution.</span></figcaption>
<table id="S4.T2.52.52" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.8.8.6" class="ltx_tr">
<th id="S4.T2.8.8.6.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">Methods</th>
<th id="S4.T2.8.8.6.8" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">Inf</th>
<td id="S4.T2.3.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.3.3.1.1.m1.1" class="ltx_Math" alttext="25$\mathrm{dB}$" display="inline"><semantics id="S4.T2.3.3.1.1.m1.1a"><mrow id="S4.T2.3.3.1.1.m1.1.2" xref="S4.T2.3.3.1.1.m1.1.2.cmml"><mn id="S4.T2.3.3.1.1.m1.1.2.2" xref="S4.T2.3.3.1.1.m1.1.2.2.cmml">25</mn><mo lspace="0em" rspace="0em" id="S4.T2.3.3.1.1.m1.1.2.1" xref="S4.T2.3.3.1.1.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T2.3.3.1.1.m1.1.2.3" xref="S4.T2.3.3.1.1.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.1.1.m1.1b"><apply id="S4.T2.3.3.1.1.m1.1.2.cmml" xref="S4.T2.3.3.1.1.m1.1.2"><times id="S4.T2.3.3.1.1.m1.1.2.1.cmml" xref="S4.T2.3.3.1.1.m1.1.2.1"></times><cn type="integer" id="S4.T2.3.3.1.1.m1.1.2.2.cmml" xref="S4.T2.3.3.1.1.m1.1.2.2">25</cn><csymbol cd="latexml" id="S4.T2.3.3.1.1.m1.1.2.3.cmml" xref="S4.T2.3.3.1.1.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.1.1.m1.1c">25$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T2.4.4.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.4.4.2.2.m1.1" class="ltx_Math" alttext="20$\mathrm{dB}$" display="inline"><semantics id="S4.T2.4.4.2.2.m1.1a"><mrow id="S4.T2.4.4.2.2.m1.1.2" xref="S4.T2.4.4.2.2.m1.1.2.cmml"><mn id="S4.T2.4.4.2.2.m1.1.2.2" xref="S4.T2.4.4.2.2.m1.1.2.2.cmml">20</mn><mo lspace="0em" rspace="0em" id="S4.T2.4.4.2.2.m1.1.2.1" xref="S4.T2.4.4.2.2.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T2.4.4.2.2.m1.1.2.3" xref="S4.T2.4.4.2.2.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.2.2.m1.1b"><apply id="S4.T2.4.4.2.2.m1.1.2.cmml" xref="S4.T2.4.4.2.2.m1.1.2"><times id="S4.T2.4.4.2.2.m1.1.2.1.cmml" xref="S4.T2.4.4.2.2.m1.1.2.1"></times><cn type="integer" id="S4.T2.4.4.2.2.m1.1.2.2.cmml" xref="S4.T2.4.4.2.2.m1.1.2.2">20</cn><csymbol cd="latexml" id="S4.T2.4.4.2.2.m1.1.2.3.cmml" xref="S4.T2.4.4.2.2.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.2.2.m1.1c">20$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T2.5.5.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.5.5.3.3.m1.1" class="ltx_Math" alttext="15$\mathrm{dB}$" display="inline"><semantics id="S4.T2.5.5.3.3.m1.1a"><mrow id="S4.T2.5.5.3.3.m1.1.2" xref="S4.T2.5.5.3.3.m1.1.2.cmml"><mn id="S4.T2.5.5.3.3.m1.1.2.2" xref="S4.T2.5.5.3.3.m1.1.2.2.cmml">15</mn><mo lspace="0em" rspace="0em" id="S4.T2.5.5.3.3.m1.1.2.1" xref="S4.T2.5.5.3.3.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T2.5.5.3.3.m1.1.2.3" xref="S4.T2.5.5.3.3.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.3.3.m1.1b"><apply id="S4.T2.5.5.3.3.m1.1.2.cmml" xref="S4.T2.5.5.3.3.m1.1.2"><times id="S4.T2.5.5.3.3.m1.1.2.1.cmml" xref="S4.T2.5.5.3.3.m1.1.2.1"></times><cn type="integer" id="S4.T2.5.5.3.3.m1.1.2.2.cmml" xref="S4.T2.5.5.3.3.m1.1.2.2">15</cn><csymbol cd="latexml" id="S4.T2.5.5.3.3.m1.1.2.3.cmml" xref="S4.T2.5.5.3.3.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.3.3.m1.1c">15$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T2.6.6.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.6.6.4.4.m1.1" class="ltx_Math" alttext="10$\mathrm{dB}$" display="inline"><semantics id="S4.T2.6.6.4.4.m1.1a"><mrow id="S4.T2.6.6.4.4.m1.1.2" xref="S4.T2.6.6.4.4.m1.1.2.cmml"><mn id="S4.T2.6.6.4.4.m1.1.2.2" xref="S4.T2.6.6.4.4.m1.1.2.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S4.T2.6.6.4.4.m1.1.2.1" xref="S4.T2.6.6.4.4.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T2.6.6.4.4.m1.1.2.3" xref="S4.T2.6.6.4.4.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.4.4.m1.1b"><apply id="S4.T2.6.6.4.4.m1.1.2.cmml" xref="S4.T2.6.6.4.4.m1.1.2"><times id="S4.T2.6.6.4.4.m1.1.2.1.cmml" xref="S4.T2.6.6.4.4.m1.1.2.1"></times><cn type="integer" id="S4.T2.6.6.4.4.m1.1.2.2.cmml" xref="S4.T2.6.6.4.4.m1.1.2.2">10</cn><csymbol cd="latexml" id="S4.T2.6.6.4.4.m1.1.2.3.cmml" xref="S4.T2.6.6.4.4.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.4.4.m1.1c">10$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T2.7.7.5.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.7.7.5.5.m1.1" class="ltx_Math" alttext="5$\mathrm{dB}$" display="inline"><semantics id="S4.T2.7.7.5.5.m1.1a"><mrow id="S4.T2.7.7.5.5.m1.1.2" xref="S4.T2.7.7.5.5.m1.1.2.cmml"><mn id="S4.T2.7.7.5.5.m1.1.2.2" xref="S4.T2.7.7.5.5.m1.1.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.T2.7.7.5.5.m1.1.2.1" xref="S4.T2.7.7.5.5.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T2.7.7.5.5.m1.1.2.3" xref="S4.T2.7.7.5.5.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.5.5.m1.1b"><apply id="S4.T2.7.7.5.5.m1.1.2.cmml" xref="S4.T2.7.7.5.5.m1.1.2"><times id="S4.T2.7.7.5.5.m1.1.2.1.cmml" xref="S4.T2.7.7.5.5.m1.1.2.1"></times><cn type="integer" id="S4.T2.7.7.5.5.m1.1.2.2.cmml" xref="S4.T2.7.7.5.5.m1.1.2.2">5</cn><csymbol cd="latexml" id="S4.T2.7.7.5.5.m1.1.2.3.cmml" xref="S4.T2.7.7.5.5.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.5.5.m1.1c">5$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T2.8.8.6.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.8.8.6.6.m1.1" class="ltx_Math" alttext="0$\mathrm{dB}$" display="inline"><semantics id="S4.T2.8.8.6.6.m1.1a"><mrow id="S4.T2.8.8.6.6.m1.1.2" xref="S4.T2.8.8.6.6.m1.1.2.cmml"><mn id="S4.T2.8.8.6.6.m1.1.2.2" xref="S4.T2.8.8.6.6.m1.1.2.2.cmml">0</mn><mo lspace="0em" rspace="0em" id="S4.T2.8.8.6.6.m1.1.2.1" xref="S4.T2.8.8.6.6.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T2.8.8.6.6.m1.1.2.3" xref="S4.T2.8.8.6.6.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.6.6.m1.1b"><apply id="S4.T2.8.8.6.6.m1.1.2.cmml" xref="S4.T2.8.8.6.6.m1.1.2"><times id="S4.T2.8.8.6.6.m1.1.2.1.cmml" xref="S4.T2.8.8.6.6.m1.1.2.1"></times><cn type="integer" id="S4.T2.8.8.6.6.m1.1.2.2.cmml" xref="S4.T2.8.8.6.6.m1.1.2.2">0</cn><csymbol cd="latexml" id="S4.T2.8.8.6.6.m1.1.2.3.cmml" xref="S4.T2.8.8.6.6.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.6.6.m1.1c">0$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T2.8.8.6.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">average</td>
</tr>
<tr id="S4.T2.16.16.14" class="ltx_tr">
<th id="S4.T2.16.16.14.9" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">original ASR</th>
<th id="S4.T2.9.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.9.9.7.1.m1.1" class="ltx_Math" alttext="7.84" display="inline"><semantics id="S4.T2.9.9.7.1.m1.1a"><mn id="S4.T2.9.9.7.1.m1.1.1" xref="S4.T2.9.9.7.1.m1.1.1.cmml">7.84</mn><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.7.1.m1.1b"><cn type="float" id="S4.T2.9.9.7.1.m1.1.1.cmml" xref="S4.T2.9.9.7.1.m1.1.1">7.84</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.7.1.m1.1c">7.84</annotation></semantics></math></th>
<td id="S4.T2.10.10.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.10.10.8.2.m1.1" class="ltx_Math" alttext="10.74" display="inline"><semantics id="S4.T2.10.10.8.2.m1.1a"><mn id="S4.T2.10.10.8.2.m1.1.1" xref="S4.T2.10.10.8.2.m1.1.1.cmml">10.74</mn><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.8.2.m1.1b"><cn type="float" id="S4.T2.10.10.8.2.m1.1.1.cmml" xref="S4.T2.10.10.8.2.m1.1.1">10.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.8.2.m1.1c">10.74</annotation></semantics></math></td>
<td id="S4.T2.11.11.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.11.11.9.3.m1.1" class="ltx_Math" alttext="13.53" display="inline"><semantics id="S4.T2.11.11.9.3.m1.1a"><mn id="S4.T2.11.11.9.3.m1.1.1" xref="S4.T2.11.11.9.3.m1.1.1.cmml">13.53</mn><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.9.3.m1.1b"><cn type="float" id="S4.T2.11.11.9.3.m1.1.1.cmml" xref="S4.T2.11.11.9.3.m1.1.1">13.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.9.3.m1.1c">13.53</annotation></semantics></math></td>
<td id="S4.T2.12.12.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.12.12.10.4.m1.1" class="ltx_Math" alttext="19.87" display="inline"><semantics id="S4.T2.12.12.10.4.m1.1a"><mn id="S4.T2.12.12.10.4.m1.1.1" xref="S4.T2.12.12.10.4.m1.1.1.cmml">19.87</mn><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.10.4.m1.1b"><cn type="float" id="S4.T2.12.12.10.4.m1.1.1.cmml" xref="S4.T2.12.12.10.4.m1.1.1">19.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.10.4.m1.1c">19.87</annotation></semantics></math></td>
<td id="S4.T2.13.13.11.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.13.13.11.5.m1.1" class="ltx_Math" alttext="31.97" display="inline"><semantics id="S4.T2.13.13.11.5.m1.1a"><mn id="S4.T2.13.13.11.5.m1.1.1" xref="S4.T2.13.13.11.5.m1.1.1.cmml">31.97</mn><annotation-xml encoding="MathML-Content" id="S4.T2.13.13.11.5.m1.1b"><cn type="float" id="S4.T2.13.13.11.5.m1.1.1.cmml" xref="S4.T2.13.13.11.5.m1.1.1">31.97</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.13.11.5.m1.1c">31.97</annotation></semantics></math></td>
<td id="S4.T2.14.14.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.14.14.12.6.m1.1" class="ltx_Math" alttext="49.72" display="inline"><semantics id="S4.T2.14.14.12.6.m1.1a"><mn id="S4.T2.14.14.12.6.m1.1.1" xref="S4.T2.14.14.12.6.m1.1.1.cmml">49.72</mn><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.12.6.m1.1b"><cn type="float" id="S4.T2.14.14.12.6.m1.1.1.cmml" xref="S4.T2.14.14.12.6.m1.1.1">49.72</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.12.6.m1.1c">49.72</annotation></semantics></math></td>
<td id="S4.T2.15.15.13.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.15.15.13.7.m1.1" class="ltx_Math" alttext="68.46" display="inline"><semantics id="S4.T2.15.15.13.7.m1.1a"><mn id="S4.T2.15.15.13.7.m1.1.1" xref="S4.T2.15.15.13.7.m1.1.1.cmml">68.46</mn><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.13.7.m1.1b"><cn type="float" id="S4.T2.15.15.13.7.m1.1.1.cmml" xref="S4.T2.15.15.13.7.m1.1.1">68.46</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.13.7.m1.1c">68.46</annotation></semantics></math></td>
<td id="S4.T2.16.16.14.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.16.16.14.8.m1.1" class="ltx_Math" alttext="32.38" display="inline"><semantics id="S4.T2.16.16.14.8.m1.1a"><mn id="S4.T2.16.16.14.8.m1.1.1" xref="S4.T2.16.16.14.8.m1.1.1.cmml">32.38</mn><annotation-xml encoding="MathML-Content" id="S4.T2.16.16.14.8.m1.1b"><cn type="float" id="S4.T2.16.16.14.8.m1.1.1.cmml" xref="S4.T2.16.16.14.8.m1.1.1">32.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.16.14.8.m1.1c">32.38</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.23.23.21" class="ltx_tr">
<th id="S4.T2.23.23.21.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">DA</th>
<th id="S4.T2.23.23.21.9" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T2.17.17.15.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.17.17.15.1.m1.1" class="ltx_Math" alttext="9.58" display="inline"><semantics id="S4.T2.17.17.15.1.m1.1a"><mn id="S4.T2.17.17.15.1.m1.1.1" xref="S4.T2.17.17.15.1.m1.1.1.cmml">9.58</mn><annotation-xml encoding="MathML-Content" id="S4.T2.17.17.15.1.m1.1b"><cn type="float" id="S4.T2.17.17.15.1.m1.1.1.cmml" xref="S4.T2.17.17.15.1.m1.1.1">9.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.17.17.15.1.m1.1c">9.58</annotation></semantics></math></td>
<td id="S4.T2.18.18.16.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.18.18.16.2.m1.1" class="ltx_Math" alttext="10.18" display="inline"><semantics id="S4.T2.18.18.16.2.m1.1a"><mn id="S4.T2.18.18.16.2.m1.1.1" xref="S4.T2.18.18.16.2.m1.1.1.cmml">10.18</mn><annotation-xml encoding="MathML-Content" id="S4.T2.18.18.16.2.m1.1b"><cn type="float" id="S4.T2.18.18.16.2.m1.1.1.cmml" xref="S4.T2.18.18.16.2.m1.1.1">10.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.18.18.16.2.m1.1c">10.18</annotation></semantics></math></td>
<td id="S4.T2.19.19.17.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.19.19.17.3.m1.1" class="ltx_Math" alttext="11.17" display="inline"><semantics id="S4.T2.19.19.17.3.m1.1a"><mn id="S4.T2.19.19.17.3.m1.1.1" xref="S4.T2.19.19.17.3.m1.1.1.cmml">11.17</mn><annotation-xml encoding="MathML-Content" id="S4.T2.19.19.17.3.m1.1b"><cn type="float" id="S4.T2.19.19.17.3.m1.1.1.cmml" xref="S4.T2.19.19.17.3.m1.1.1">11.17</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.19.19.17.3.m1.1c">11.17</annotation></semantics></math></td>
<td id="S4.T2.20.20.18.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.20.20.18.4.m1.1" class="ltx_Math" alttext="14.50" display="inline"><semantics id="S4.T2.20.20.18.4.m1.1a"><mn id="S4.T2.20.20.18.4.m1.1.1" xref="S4.T2.20.20.18.4.m1.1.1.cmml">14.50</mn><annotation-xml encoding="MathML-Content" id="S4.T2.20.20.18.4.m1.1b"><cn type="float" id="S4.T2.20.20.18.4.m1.1.1.cmml" xref="S4.T2.20.20.18.4.m1.1.1">14.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.20.20.18.4.m1.1c">14.50</annotation></semantics></math></td>
<td id="S4.T2.21.21.19.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.21.21.19.5.m1.1" class="ltx_Math" alttext="21.05" display="inline"><semantics id="S4.T2.21.21.19.5.m1.1a"><mn id="S4.T2.21.21.19.5.m1.1.1" xref="S4.T2.21.21.19.5.m1.1.1.cmml">21.05</mn><annotation-xml encoding="MathML-Content" id="S4.T2.21.21.19.5.m1.1b"><cn type="float" id="S4.T2.21.21.19.5.m1.1.1.cmml" xref="S4.T2.21.21.19.5.m1.1.1">21.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.21.21.19.5.m1.1c">21.05</annotation></semantics></math></td>
<td id="S4.T2.22.22.20.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.22.22.20.6.m1.1" class="ltx_Math" alttext="35.46" display="inline"><semantics id="S4.T2.22.22.20.6.m1.1a"><mn id="S4.T2.22.22.20.6.m1.1.1" xref="S4.T2.22.22.20.6.m1.1.1.cmml">35.46</mn><annotation-xml encoding="MathML-Content" id="S4.T2.22.22.20.6.m1.1b"><cn type="float" id="S4.T2.22.22.20.6.m1.1.1.cmml" xref="S4.T2.22.22.20.6.m1.1.1">35.46</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.22.22.20.6.m1.1c">35.46</annotation></semantics></math></td>
<td id="S4.T2.23.23.21.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.23.23.21.7.m1.1" class="ltx_Math" alttext="16.99" display="inline"><semantics id="S4.T2.23.23.21.7.m1.1a"><mn id="S4.T2.23.23.21.7.m1.1.1" xref="S4.T2.23.23.21.7.m1.1.1.cmml">16.99</mn><annotation-xml encoding="MathML-Content" id="S4.T2.23.23.21.7.m1.1b"><cn type="float" id="S4.T2.23.23.21.7.m1.1.1.cmml" xref="S4.T2.23.23.21.7.m1.1.1">16.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.23.23.21.7.m1.1c">16.99</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.30.30.28" class="ltx_tr">
<th id="S4.T2.30.30.28.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">Cold Cascade</th>
<th id="S4.T2.30.30.28.9" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T2.24.24.22.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.24.24.22.1.m1.1" class="ltx_Math" alttext="9.53" display="inline"><semantics id="S4.T2.24.24.22.1.m1.1a"><mn id="S4.T2.24.24.22.1.m1.1.1" xref="S4.T2.24.24.22.1.m1.1.1.cmml">9.53</mn><annotation-xml encoding="MathML-Content" id="S4.T2.24.24.22.1.m1.1b"><cn type="float" id="S4.T2.24.24.22.1.m1.1.1.cmml" xref="S4.T2.24.24.22.1.m1.1.1">9.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.24.24.22.1.m1.1c">9.53</annotation></semantics></math></td>
<td id="S4.T2.25.25.23.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.25.25.23.2.m1.1" class="ltx_Math" alttext="10.84" display="inline"><semantics id="S4.T2.25.25.23.2.m1.1a"><mn id="S4.T2.25.25.23.2.m1.1.1" xref="S4.T2.25.25.23.2.m1.1.1.cmml">10.84</mn><annotation-xml encoding="MathML-Content" id="S4.T2.25.25.23.2.m1.1b"><cn type="float" id="S4.T2.25.25.23.2.m1.1.1.cmml" xref="S4.T2.25.25.23.2.m1.1.1">10.84</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.25.25.23.2.m1.1c">10.84</annotation></semantics></math></td>
<td id="S4.T2.26.26.24.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.26.26.24.3.m1.1" class="ltx_Math" alttext="13.31" display="inline"><semantics id="S4.T2.26.26.24.3.m1.1a"><mn id="S4.T2.26.26.24.3.m1.1.1" xref="S4.T2.26.26.24.3.m1.1.1.cmml">13.31</mn><annotation-xml encoding="MathML-Content" id="S4.T2.26.26.24.3.m1.1b"><cn type="float" id="S4.T2.26.26.24.3.m1.1.1.cmml" xref="S4.T2.26.26.24.3.m1.1.1">13.31</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.26.26.24.3.m1.1c">13.31</annotation></semantics></math></td>
<td id="S4.T2.27.27.25.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.27.27.25.4.m1.1" class="ltx_Math" alttext="18.16" display="inline"><semantics id="S4.T2.27.27.25.4.m1.1a"><mn id="S4.T2.27.27.25.4.m1.1.1" xref="S4.T2.27.27.25.4.m1.1.1.cmml">18.16</mn><annotation-xml encoding="MathML-Content" id="S4.T2.27.27.25.4.m1.1b"><cn type="float" id="S4.T2.27.27.25.4.m1.1.1.cmml" xref="S4.T2.27.27.25.4.m1.1.1">18.16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.27.27.25.4.m1.1c">18.16</annotation></semantics></math></td>
<td id="S4.T2.28.28.26.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.28.28.26.5.m1.1" class="ltx_Math" alttext="28.07" display="inline"><semantics id="S4.T2.28.28.26.5.m1.1a"><mn id="S4.T2.28.28.26.5.m1.1.1" xref="S4.T2.28.28.26.5.m1.1.1.cmml">28.07</mn><annotation-xml encoding="MathML-Content" id="S4.T2.28.28.26.5.m1.1b"><cn type="float" id="S4.T2.28.28.26.5.m1.1.1.cmml" xref="S4.T2.28.28.26.5.m1.1.1">28.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.28.28.26.5.m1.1c">28.07</annotation></semantics></math></td>
<td id="S4.T2.29.29.27.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.29.29.27.6.m1.1" class="ltx_Math" alttext="43.78" display="inline"><semantics id="S4.T2.29.29.27.6.m1.1a"><mn id="S4.T2.29.29.27.6.m1.1.1" xref="S4.T2.29.29.27.6.m1.1.1.cmml">43.78</mn><annotation-xml encoding="MathML-Content" id="S4.T2.29.29.27.6.m1.1b"><cn type="float" id="S4.T2.29.29.27.6.m1.1.1.cmml" xref="S4.T2.29.29.27.6.m1.1.1">43.78</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.29.29.27.6.m1.1c">43.78</annotation></semantics></math></td>
<td id="S4.T2.30.30.28.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.30.30.28.7.m1.1" class="ltx_Math" alttext="20.62" display="inline"><semantics id="S4.T2.30.30.28.7.m1.1a"><mn id="S4.T2.30.30.28.7.m1.1.1" xref="S4.T2.30.30.28.7.m1.1.1.cmml">20.62</mn><annotation-xml encoding="MathML-Content" id="S4.T2.30.30.28.7.m1.1b"><cn type="float" id="S4.T2.30.30.28.7.m1.1.1.cmml" xref="S4.T2.30.30.28.7.m1.1.1">20.62</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.30.30.28.7.m1.1c">20.62</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.38.38.36" class="ltx_tr">
<th id="S4.T2.38.38.36.9" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">Cold Cascade + DA</th>
<th id="S4.T2.31.31.29.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.31.31.29.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S4.T2.31.31.29.1.m1.1a"><mo id="S4.T2.31.31.29.1.m1.1.1" xref="S4.T2.31.31.29.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T2.31.31.29.1.m1.1b"><minus id="S4.T2.31.31.29.1.m1.1.1.cmml" xref="S4.T2.31.31.29.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.31.31.29.1.m1.1c">-</annotation></semantics></math></th>
<td id="S4.T2.32.32.30.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.32.32.30.2.m1.1" class="ltx_Math" alttext="8.15" display="inline"><semantics id="S4.T2.32.32.30.2.m1.1a"><mn id="S4.T2.32.32.30.2.m1.1.1" xref="S4.T2.32.32.30.2.m1.1.1.cmml">8.15</mn><annotation-xml encoding="MathML-Content" id="S4.T2.32.32.30.2.m1.1b"><cn type="float" id="S4.T2.32.32.30.2.m1.1.1.cmml" xref="S4.T2.32.32.30.2.m1.1.1">8.15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.32.32.30.2.m1.1c">8.15</annotation></semantics></math></td>
<td id="S4.T2.33.33.31.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.33.33.31.3.m1.1" class="ltx_Math" alttext="8.76" display="inline"><semantics id="S4.T2.33.33.31.3.m1.1a"><mn id="S4.T2.33.33.31.3.m1.1.1" xref="S4.T2.33.33.31.3.m1.1.1.cmml">8.76</mn><annotation-xml encoding="MathML-Content" id="S4.T2.33.33.31.3.m1.1b"><cn type="float" id="S4.T2.33.33.31.3.m1.1.1.cmml" xref="S4.T2.33.33.31.3.m1.1.1">8.76</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.33.33.31.3.m1.1c">8.76</annotation></semantics></math></td>
<td id="S4.T2.34.34.32.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.34.34.32.4.m1.1" class="ltx_Math" alttext="10.03" display="inline"><semantics id="S4.T2.34.34.32.4.m1.1a"><mn id="S4.T2.34.34.32.4.m1.1.1" xref="S4.T2.34.34.32.4.m1.1.1.cmml">10.03</mn><annotation-xml encoding="MathML-Content" id="S4.T2.34.34.32.4.m1.1b"><cn type="float" id="S4.T2.34.34.32.4.m1.1.1.cmml" xref="S4.T2.34.34.32.4.m1.1.1">10.03</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.34.34.32.4.m1.1c">10.03</annotation></semantics></math></td>
<td id="S4.T2.35.35.33.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.35.35.33.5.m1.1" class="ltx_Math" alttext="13.30" display="inline"><semantics id="S4.T2.35.35.33.5.m1.1a"><mn id="S4.T2.35.35.33.5.m1.1.1" xref="S4.T2.35.35.33.5.m1.1.1.cmml">13.30</mn><annotation-xml encoding="MathML-Content" id="S4.T2.35.35.33.5.m1.1b"><cn type="float" id="S4.T2.35.35.33.5.m1.1.1.cmml" xref="S4.T2.35.35.33.5.m1.1.1">13.30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.35.35.33.5.m1.1c">13.30</annotation></semantics></math></td>
<td id="S4.T2.36.36.34.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.36.36.34.6.m1.1" class="ltx_Math" alttext="20.89" display="inline"><semantics id="S4.T2.36.36.34.6.m1.1a"><mn id="S4.T2.36.36.34.6.m1.1.1" xref="S4.T2.36.36.34.6.m1.1.1.cmml">20.89</mn><annotation-xml encoding="MathML-Content" id="S4.T2.36.36.34.6.m1.1b"><cn type="float" id="S4.T2.36.36.34.6.m1.1.1.cmml" xref="S4.T2.36.36.34.6.m1.1.1">20.89</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.36.36.34.6.m1.1c">20.89</annotation></semantics></math></td>
<td id="S4.T2.37.37.35.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.37.37.35.7.m1.1" class="ltx_Math" alttext="34.67" display="inline"><semantics id="S4.T2.37.37.35.7.m1.1a"><mn id="S4.T2.37.37.35.7.m1.1.1" xref="S4.T2.37.37.35.7.m1.1.1.cmml">34.67</mn><annotation-xml encoding="MathML-Content" id="S4.T2.37.37.35.7.m1.1b"><cn type="float" id="S4.T2.37.37.35.7.m1.1.1.cmml" xref="S4.T2.37.37.35.7.m1.1.1">34.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.37.37.35.7.m1.1c">34.67</annotation></semantics></math></td>
<td id="S4.T2.38.38.36.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.38.38.36.8.m1.1" class="ltx_Math" alttext="15.97" display="inline"><semantics id="S4.T2.38.38.36.8.m1.1a"><mn id="S4.T2.38.38.36.8.m1.1.1" xref="S4.T2.38.38.36.8.m1.1.1.cmml">15.97</mn><annotation-xml encoding="MathML-Content" id="S4.T2.38.38.36.8.m1.1b"><cn type="float" id="S4.T2.38.38.36.8.m1.1.1.cmml" xref="S4.T2.38.38.36.8.m1.1.1">15.97</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.38.38.36.8.m1.1c">15.97</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.45.45.43" class="ltx_tr">
<th id="S4.T2.45.45.43.8" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.45.45.43.8.1" class="ltx_text ltx_font_bold">MTL</span></th>
<th id="S4.T2.45.45.43.9" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T2.39.39.37.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.39.39.37.1.1" class="ltx_text ltx_markedasmath ltx_font_bold">8.03</span></td>
<td id="S4.T2.40.40.38.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.40.40.38.2.1" class="ltx_text ltx_markedasmath ltx_font_bold">8.69</span></td>
<td id="S4.T2.41.41.39.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.41.41.39.3.1" class="ltx_text ltx_markedasmath ltx_font_bold">9.91</span></td>
<td id="S4.T2.42.42.40.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.42.42.40.4.m1.1" class="ltx_Math" alttext="12.93" display="inline"><semantics id="S4.T2.42.42.40.4.m1.1a"><mn id="S4.T2.42.42.40.4.m1.1.1" xref="S4.T2.42.42.40.4.m1.1.1.cmml">12.93</mn><annotation-xml encoding="MathML-Content" id="S4.T2.42.42.40.4.m1.1b"><cn type="float" id="S4.T2.42.42.40.4.m1.1.1.cmml" xref="S4.T2.42.42.40.4.m1.1.1">12.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.42.42.40.4.m1.1c">12.93</annotation></semantics></math></td>
<td id="S4.T2.43.43.41.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.43.43.41.5.m1.1" class="ltx_Math" alttext="19.45" display="inline"><semantics id="S4.T2.43.43.41.5.m1.1a"><mn id="S4.T2.43.43.41.5.m1.1.1" xref="S4.T2.43.43.41.5.m1.1.1.cmml">19.45</mn><annotation-xml encoding="MathML-Content" id="S4.T2.43.43.41.5.m1.1b"><cn type="float" id="S4.T2.43.43.41.5.m1.1.1.cmml" xref="S4.T2.43.43.41.5.m1.1.1">19.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.43.43.41.5.m1.1c">19.45</annotation></semantics></math></td>
<td id="S4.T2.44.44.42.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.44.44.42.6.m1.1" class="ltx_Math" alttext="32.64" display="inline"><semantics id="S4.T2.44.44.42.6.m1.1a"><mn id="S4.T2.44.44.42.6.m1.1.1" xref="S4.T2.44.44.42.6.m1.1.1.cmml">32.64</mn><annotation-xml encoding="MathML-Content" id="S4.T2.44.44.42.6.m1.1b"><cn type="float" id="S4.T2.44.44.42.6.m1.1.1.cmml" xref="S4.T2.44.44.42.6.m1.1.1">32.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.44.44.42.6.m1.1c">32.64</annotation></semantics></math></td>
<td id="S4.T2.45.45.43.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.45.45.43.7.m1.1" class="ltx_Math" alttext="15.27" display="inline"><semantics id="S4.T2.45.45.43.7.m1.1a"><mn id="S4.T2.45.45.43.7.m1.1.1" xref="S4.T2.45.45.43.7.m1.1.1.cmml">15.27</mn><annotation-xml encoding="MathML-Content" id="S4.T2.45.45.43.7.m1.1b"><cn type="float" id="S4.T2.45.45.43.7.m1.1.1.cmml" xref="S4.T2.45.45.43.7.m1.1.1">15.27</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.45.45.43.7.m1.1c">15.27</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.52.52.50" class="ltx_tr">
<th id="S4.T2.52.52.50.8" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.52.52.50.8.1" class="ltx_text ltx_font_bold">iterative optimisation</span></th>
<th id="S4.T2.52.52.50.9" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T2.46.46.44.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.46.46.44.1.m1.1" class="ltx_Math" alttext="8.35" display="inline"><semantics id="S4.T2.46.46.44.1.m1.1a"><mn id="S4.T2.46.46.44.1.m1.1.1" xref="S4.T2.46.46.44.1.m1.1.1.cmml">8.35</mn><annotation-xml encoding="MathML-Content" id="S4.T2.46.46.44.1.m1.1b"><cn type="float" id="S4.T2.46.46.44.1.m1.1.1.cmml" xref="S4.T2.46.46.44.1.m1.1.1">8.35</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.46.46.44.1.m1.1c">8.35</annotation></semantics></math></td>
<td id="S4.T2.47.47.45.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.47.47.45.2.m1.1" class="ltx_Math" alttext="8.79" display="inline"><semantics id="S4.T2.47.47.45.2.m1.1a"><mn id="S4.T2.47.47.45.2.m1.1.1" xref="S4.T2.47.47.45.2.m1.1.1.cmml">8.79</mn><annotation-xml encoding="MathML-Content" id="S4.T2.47.47.45.2.m1.1b"><cn type="float" id="S4.T2.47.47.45.2.m1.1.1.cmml" xref="S4.T2.47.47.45.2.m1.1.1">8.79</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.47.47.45.2.m1.1c">8.79</annotation></semantics></math></td>
<td id="S4.T2.48.48.46.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T2.48.48.46.3.m1.1" class="ltx_Math" alttext="10.00" display="inline"><semantics id="S4.T2.48.48.46.3.m1.1a"><mn id="S4.T2.48.48.46.3.m1.1.1" xref="S4.T2.48.48.46.3.m1.1.1.cmml">10.00</mn><annotation-xml encoding="MathML-Content" id="S4.T2.48.48.46.3.m1.1b"><cn type="float" id="S4.T2.48.48.46.3.m1.1.1.cmml" xref="S4.T2.48.48.46.3.m1.1.1">10.00</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.48.48.46.3.m1.1c">10.00</annotation></semantics></math></td>
<td id="S4.T2.49.49.47.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.49.49.47.4.1" class="ltx_text ltx_markedasmath ltx_font_bold">12.71</span></td>
<td id="S4.T2.50.50.48.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.50.50.48.5.1" class="ltx_text ltx_markedasmath ltx_font_bold">19.27</span></td>
<td id="S4.T2.51.51.49.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.51.51.49.6.1" class="ltx_text ltx_markedasmath ltx_font_bold">31.93</span></td>
<td id="S4.T2.52.52.50.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T2.52.52.50.7.1" class="ltx_text ltx_markedasmath ltx_font_bold">15.18</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.25.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Table 3</span>: </span><span id="S4.T3.2.2.1" class="ltx_text" style="font-size:90%;">Automatic speech recognition testing results, WER [<math id="S4.T3.2.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T3.2.2.1.m1.1b"><mo id="S4.T3.2.2.1.m1.1.1" xref="S4.T3.2.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1c"><csymbol cd="latexml" id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1d">\%</annotation></semantics></math>], using the CHiME-4 challenge set. DA stands for the method using only data augmentation. MTL represents the proposed multi-task learning solution.</span></figcaption>
<table id="S4.T3.22.22" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.22.22.21.1" class="ltx_tr">
<th id="S4.T3.22.22.21.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt" style="padding:1pt 7.5pt;"></th>
<th id="S4.T3.22.22.21.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:1pt 7.5pt;" colspan="2"><span id="S4.T3.22.22.21.1.2.1" class="ltx_text ltx_font_bold">GMM-HMM</span></th>
<th id="S4.T3.22.22.21.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:1pt 7.5pt;" colspan="2"><span id="S4.T3.22.22.21.1.3.1" class="ltx_text ltx_font_bold">DNN-HMM</span></th>
</tr>
<tr id="S4.T3.22.22.22.2" class="ltx_tr">
<th id="S4.T3.22.22.22.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" style="padding:1pt 7.5pt;"><span id="S4.T3.22.22.22.2.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S4.T3.22.22.22.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1pt 7.5pt;"><span id="S4.T3.22.22.22.2.2.1" class="ltx_text ltx_font_bold">simu</span></th>
<th id="S4.T3.22.22.22.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1pt 7.5pt;"><span id="S4.T3.22.22.22.2.3.1" class="ltx_text ltx_font_bold">real</span></th>
<th id="S4.T3.22.22.22.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1pt 7.5pt;"><span id="S4.T3.22.22.22.2.4.1" class="ltx_text ltx_font_bold">simu</span></th>
<th id="S4.T3.22.22.22.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:1pt 7.5pt;"><span id="S4.T3.22.22.22.2.5.1" class="ltx_text ltx_font_bold">real</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.6.6.4" class="ltx_tr">
<th id="S4.T3.6.6.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:1pt 7.5pt;">original ASR</th>
<td id="S4.T3.3.3.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 7.5pt;"><math id="S4.T3.3.3.1.1.m1.1" class="ltx_Math" alttext="24.46" display="inline"><semantics id="S4.T3.3.3.1.1.m1.1a"><mn id="S4.T3.3.3.1.1.m1.1.1" xref="S4.T3.3.3.1.1.m1.1.1.cmml">24.46</mn><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.1.1.m1.1b"><cn type="float" id="S4.T3.3.3.1.1.m1.1.1.cmml" xref="S4.T3.3.3.1.1.m1.1.1">24.46</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.1.1.m1.1c">24.46</annotation></semantics></math></td>
<td id="S4.T3.4.4.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 7.5pt;"><math id="S4.T3.4.4.2.2.m1.1" class="ltx_Math" alttext="22.19" display="inline"><semantics id="S4.T3.4.4.2.2.m1.1a"><mn id="S4.T3.4.4.2.2.m1.1.1" xref="S4.T3.4.4.2.2.m1.1.1.cmml">22.19</mn><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.2.2.m1.1b"><cn type="float" id="S4.T3.4.4.2.2.m1.1.1.cmml" xref="S4.T3.4.4.2.2.m1.1.1">22.19</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.2.2.m1.1c">22.19</annotation></semantics></math></td>
<td id="S4.T3.5.5.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 7.5pt;"><math id="S4.T3.5.5.3.3.m1.1" class="ltx_Math" alttext="12.96" display="inline"><semantics id="S4.T3.5.5.3.3.m1.1a"><mn id="S4.T3.5.5.3.3.m1.1.1" xref="S4.T3.5.5.3.3.m1.1.1.cmml">12.96</mn><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.3.3.m1.1b"><cn type="float" id="S4.T3.5.5.3.3.m1.1.1.cmml" xref="S4.T3.5.5.3.3.m1.1.1">12.96</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.3.3.m1.1c">12.96</annotation></semantics></math></td>
<td id="S4.T3.6.6.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 7.5pt;"><math id="S4.T3.6.6.4.4.m1.1" class="ltx_Math" alttext="11.56" display="inline"><semantics id="S4.T3.6.6.4.4.m1.1a"><mn id="S4.T3.6.6.4.4.m1.1.1" xref="S4.T3.6.6.4.4.m1.1.1.cmml">11.56</mn><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.4.4.m1.1b"><cn type="float" id="S4.T3.6.6.4.4.m1.1.1.cmml" xref="S4.T3.6.6.4.4.m1.1.1">11.56</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.4.4.m1.1c">11.56</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.10.10.8" class="ltx_tr">
<th id="S4.T3.10.10.8.5" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 7.5pt;">Cold Cascade 1</th>
<td id="S4.T3.7.7.5.1" class="ltx_td ltx_align_center" style="padding:1pt 7.5pt;"><math id="S4.T3.7.7.5.1.m1.1" class="ltx_Math" alttext="18.48" display="inline"><semantics id="S4.T3.7.7.5.1.m1.1a"><mn id="S4.T3.7.7.5.1.m1.1.1" xref="S4.T3.7.7.5.1.m1.1.1.cmml">18.48</mn><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.5.1.m1.1b"><cn type="float" id="S4.T3.7.7.5.1.m1.1.1.cmml" xref="S4.T3.7.7.5.1.m1.1.1">18.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.5.1.m1.1c">18.48</annotation></semantics></math></td>
<td id="S4.T3.8.8.6.2" class="ltx_td ltx_align_center" style="padding:1pt 7.5pt;"><math id="S4.T3.8.8.6.2.m1.1" class="ltx_Math" alttext="18.06" display="inline"><semantics id="S4.T3.8.8.6.2.m1.1a"><mn id="S4.T3.8.8.6.2.m1.1.1" xref="S4.T3.8.8.6.2.m1.1.1.cmml">18.06</mn><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.6.2.m1.1b"><cn type="float" id="S4.T3.8.8.6.2.m1.1.1.cmml" xref="S4.T3.8.8.6.2.m1.1.1">18.06</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.6.2.m1.1c">18.06</annotation></semantics></math></td>
<td id="S4.T3.9.9.7.3" class="ltx_td ltx_align_center" style="padding:1pt 7.5pt;"><math id="S4.T3.9.9.7.3.m1.1" class="ltx_Math" alttext="12.54" display="inline"><semantics id="S4.T3.9.9.7.3.m1.1a"><mn id="S4.T3.9.9.7.3.m1.1.1" xref="S4.T3.9.9.7.3.m1.1.1.cmml">12.54</mn><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.7.3.m1.1b"><cn type="float" id="S4.T3.9.9.7.3.m1.1.1.cmml" xref="S4.T3.9.9.7.3.m1.1.1">12.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.7.3.m1.1c">12.54</annotation></semantics></math></td>
<td id="S4.T3.10.10.8.4" class="ltx_td ltx_align_center" style="padding:1pt 7.5pt;"><math id="S4.T3.10.10.8.4.m1.1" class="ltx_Math" alttext="11.14" display="inline"><semantics id="S4.T3.10.10.8.4.m1.1a"><mn id="S4.T3.10.10.8.4.m1.1.1" xref="S4.T3.10.10.8.4.m1.1.1.cmml">11.14</mn><annotation-xml encoding="MathML-Content" id="S4.T3.10.10.8.4.m1.1b"><cn type="float" id="S4.T3.10.10.8.4.m1.1.1.cmml" xref="S4.T3.10.10.8.4.m1.1.1">11.14</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.10.8.4.m1.1c">11.14</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.14.14.12" class="ltx_tr">
<th id="S4.T3.14.14.12.5" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 7.5pt;">Cold Cascade 2</th>
<td id="S4.T3.11.11.9.1" class="ltx_td ltx_align_center" style="padding:1pt 7.5pt;"><math id="S4.T3.11.11.9.1.m1.1" class="ltx_Math" alttext="16.06" display="inline"><semantics id="S4.T3.11.11.9.1.m1.1a"><mn id="S4.T3.11.11.9.1.m1.1.1" xref="S4.T3.11.11.9.1.m1.1.1.cmml">16.06</mn><annotation-xml encoding="MathML-Content" id="S4.T3.11.11.9.1.m1.1b"><cn type="float" id="S4.T3.11.11.9.1.m1.1.1.cmml" xref="S4.T3.11.11.9.1.m1.1.1">16.06</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.11.9.1.m1.1c">16.06</annotation></semantics></math></td>
<td id="S4.T3.12.12.10.2" class="ltx_td ltx_align_center" style="padding:1pt 7.5pt;"><math id="S4.T3.12.12.10.2.m1.1" class="ltx_Math" alttext="14.59" display="inline"><semantics id="S4.T3.12.12.10.2.m1.1a"><mn id="S4.T3.12.12.10.2.m1.1.1" xref="S4.T3.12.12.10.2.m1.1.1.cmml">14.59</mn><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.10.2.m1.1b"><cn type="float" id="S4.T3.12.12.10.2.m1.1.1.cmml" xref="S4.T3.12.12.10.2.m1.1.1">14.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.10.2.m1.1c">14.59</annotation></semantics></math></td>
<td id="S4.T3.13.13.11.3" class="ltx_td ltx_align_center" style="padding:1pt 7.5pt;"><math id="S4.T3.13.13.11.3.m1.1" class="ltx_Math" alttext="11.15" display="inline"><semantics id="S4.T3.13.13.11.3.m1.1a"><mn id="S4.T3.13.13.11.3.m1.1.1" xref="S4.T3.13.13.11.3.m1.1.1.cmml">11.15</mn><annotation-xml encoding="MathML-Content" id="S4.T3.13.13.11.3.m1.1b"><cn type="float" id="S4.T3.13.13.11.3.m1.1.1.cmml" xref="S4.T3.13.13.11.3.m1.1.1">11.15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.13.11.3.m1.1c">11.15</annotation></semantics></math></td>
<td id="S4.T3.14.14.12.4" class="ltx_td ltx_align_center" style="padding:1pt 7.5pt;"><math id="S4.T3.14.14.12.4.m1.1" class="ltx_Math" alttext="9.50" display="inline"><semantics id="S4.T3.14.14.12.4.m1.1a"><mn id="S4.T3.14.14.12.4.m1.1.1" xref="S4.T3.14.14.12.4.m1.1.1.cmml">9.50</mn><annotation-xml encoding="MathML-Content" id="S4.T3.14.14.12.4.m1.1b"><cn type="float" id="S4.T3.14.14.12.4.m1.1.1.cmml" xref="S4.T3.14.14.12.4.m1.1.1">9.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.14.12.4.m1.1c">9.50</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.18.18.16" class="ltx_tr">
<th id="S4.T3.18.18.16.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:1pt 7.5pt;"><span id="S4.T3.18.18.16.5.1" class="ltx_text ltx_font_bold">MTL</span></th>
<td id="S4.T3.15.15.13.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 7.5pt;"><math id="S4.T3.15.15.13.1.m1.1" class="ltx_Math" alttext="15.04" display="inline"><semantics id="S4.T3.15.15.13.1.m1.1a"><mn id="S4.T3.15.15.13.1.m1.1.1" xref="S4.T3.15.15.13.1.m1.1.1.cmml">15.04</mn><annotation-xml encoding="MathML-Content" id="S4.T3.15.15.13.1.m1.1b"><cn type="float" id="S4.T3.15.15.13.1.m1.1.1.cmml" xref="S4.T3.15.15.13.1.m1.1.1">15.04</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.15.13.1.m1.1c">15.04</annotation></semantics></math></td>
<td id="S4.T3.16.16.14.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 7.5pt;"><math id="S4.T3.16.16.14.2.m1.1" class="ltx_Math" alttext="12.76" display="inline"><semantics id="S4.T3.16.16.14.2.m1.1a"><mn id="S4.T3.16.16.14.2.m1.1.1" xref="S4.T3.16.16.14.2.m1.1.1.cmml">12.76</mn><annotation-xml encoding="MathML-Content" id="S4.T3.16.16.14.2.m1.1b"><cn type="float" id="S4.T3.16.16.14.2.m1.1.1.cmml" xref="S4.T3.16.16.14.2.m1.1.1">12.76</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.16.14.2.m1.1c">12.76</annotation></semantics></math></td>
<td id="S4.T3.17.17.15.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 7.5pt;"><math id="S4.T3.17.17.15.3.m1.1" class="ltx_Math" alttext="9.88" display="inline"><semantics id="S4.T3.17.17.15.3.m1.1a"><mn id="S4.T3.17.17.15.3.m1.1.1" xref="S4.T3.17.17.15.3.m1.1.1.cmml">9.88</mn><annotation-xml encoding="MathML-Content" id="S4.T3.17.17.15.3.m1.1b"><cn type="float" id="S4.T3.17.17.15.3.m1.1.1.cmml" xref="S4.T3.17.17.15.3.m1.1.1">9.88</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.17.15.3.m1.1c">9.88</annotation></semantics></math></td>
<td id="S4.T3.18.18.16.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 7.5pt;"><math id="S4.T3.18.18.16.4.m1.1" class="ltx_Math" alttext="8.73" display="inline"><semantics id="S4.T3.18.18.16.4.m1.1a"><mn id="S4.T3.18.18.16.4.m1.1.1" xref="S4.T3.18.18.16.4.m1.1.1.cmml">8.73</mn><annotation-xml encoding="MathML-Content" id="S4.T3.18.18.16.4.m1.1b"><cn type="float" id="S4.T3.18.18.16.4.m1.1.1.cmml" xref="S4.T3.18.18.16.4.m1.1.1">8.73</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.18.16.4.m1.1c">8.73</annotation></semantics></math></td>
</tr>
<tr id="S4.T3.22.22.20" class="ltx_tr">
<th id="S4.T3.22.22.20.5" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding:1pt 7.5pt;"><span id="S4.T3.22.22.20.5.1" class="ltx_text ltx_font_bold">iterative optimisation</span></th>
<td id="S4.T3.19.19.17.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 7.5pt;"><math id="S4.T3.19.19.17.1.m1.1" class="ltx_Math" alttext="\mathbf{14.08}" display="inline"><semantics id="S4.T3.19.19.17.1.m1.1a"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S4.T3.19.19.17.1.m1.1.1" xref="S4.T3.19.19.17.1.m1.1.1.cmml">14.08</mn><annotation-xml encoding="MathML-Content" id="S4.T3.19.19.17.1.m1.1b"><cn type="float" id="S4.T3.19.19.17.1.m1.1.1.cmml" xref="S4.T3.19.19.17.1.m1.1.1">14.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.19.17.1.m1.1c">\mathbf{14.08}</annotation></semantics></math></td>
<td id="S4.T3.20.20.18.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 7.5pt;"><math id="S4.T3.20.20.18.2.m1.1" class="ltx_Math" alttext="\mathbf{12.53}" display="inline"><semantics id="S4.T3.20.20.18.2.m1.1a"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S4.T3.20.20.18.2.m1.1.1" xref="S4.T3.20.20.18.2.m1.1.1.cmml">12.53</mn><annotation-xml encoding="MathML-Content" id="S4.T3.20.20.18.2.m1.1b"><cn type="float" id="S4.T3.20.20.18.2.m1.1.1.cmml" xref="S4.T3.20.20.18.2.m1.1.1">12.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.20.20.18.2.m1.1c">\mathbf{12.53}</annotation></semantics></math></td>
<td id="S4.T3.21.21.19.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 7.5pt;"><math id="S4.T3.21.21.19.3.m1.1" class="ltx_Math" alttext="\mathbf{9.45}" display="inline"><semantics id="S4.T3.21.21.19.3.m1.1a"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S4.T3.21.21.19.3.m1.1.1" xref="S4.T3.21.21.19.3.m1.1.1.cmml">9.45</mn><annotation-xml encoding="MathML-Content" id="S4.T3.21.21.19.3.m1.1b"><cn type="float" id="S4.T3.21.21.19.3.m1.1.1.cmml" xref="S4.T3.21.21.19.3.m1.1.1">9.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.21.21.19.3.m1.1c">\mathbf{9.45}</annotation></semantics></math></td>
<td id="S4.T3.22.22.20.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 7.5pt;"><math id="S4.T3.22.22.20.4.m1.1" class="ltx_Math" alttext="\mathbf{8.12}" display="inline"><semantics id="S4.T3.22.22.20.4.m1.1a"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="S4.T3.22.22.20.4.m1.1.1" xref="S4.T3.22.22.20.4.m1.1.1.cmml">8.12</mn><annotation-xml encoding="MathML-Content" id="S4.T3.22.22.20.4.m1.1b"><cn type="float" id="S4.T3.22.22.20.4.m1.1.1.cmml" xref="S4.T3.22.22.20.4.m1.1.1">8.12</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.22.22.20.4.m1.1c">\mathbf{8.12}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Downstream Task II: Automatic Speech Recognition</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">ASR experiments are performed on two datasets, the first of which being Librispeech <cite class="ltx_cite ltx_citemacro_cite">Panayotov et al. (<a href="#bib.bib40" title="" class="ltx_ref">2015</a>)</cite>, as for the previous task noise-enhanced with AudioSet recordings, the second of which being the already artificially noise-enhanced dataset of the CHiME-4 challenge.
LibriSpeech consists of approximately 960 hours of read, clean speech derived from over 8 000 public domain audiobooks, containing its own train, development, and test splits. The data set has previously been used for similar tasks under the assumption of not containing any noise contamination <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib30" title="" class="ltx_ref">2021a</a>, <a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite>. The CHiME dataset is based on the Wall Street Journal (WSJ0) corpus. The training set mixes clean speech with noisy backgrounds, leading to 35 690 utterances from 83 speakers in 4 different noisy environments. The test set contains simulated recordings and utterances recorded in real-world noisy environments from 4 other speakers.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">We choose Mel-frequency cepstral coefficients (MFCCs) as input features for the ASR model with 40 Mel-band filters. The MFCCs are based on the STFT and a mapping onto the Mel scale with triangular overlapping windows, followed by a discrete cosine transform. Note that for the MTL and the iterative optimisation approach, the MFCCs are extracted from the output of the AE.
For evaluation of the ASR task, we use Word Error Rate (WER), an evaluation metric measuring misclassification rate with respect to the words in an utterance, which is commonly used in the literature and therefore allows for a reasonable
comparisons to previous works.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">The results of our experiments on Librispeech are summarised in Table <a href="#S4.T2" title="Table 2 ‣ 4.1 Downstream Task I: Speech Command Recognition ‣ 4 Experimental Results ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Naturally, the best result is obtained with the noise-free samples at a WER below 8. Even though this result, as well as the benchmark architecture are below state-of-the-art, we expect the benefits of our SE approach to translate to state-of-the-art models.
Similar to the SCR case, we observe that the iterative optimisation outperforms all other approaches for the low SNRs (10 dB and lower), whilst the MTL shows the best performance for high SNRs (15 dB and higher) with the DA and cold cascade + DA approaches performing slightly worse in general.
In the 0 dB case, the WER with iterative optimisation is more than halved compared to the baseline model.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">In contrast to the other datasets, CHiME-4 does not offer a variable SNR. In our experiments, we report on two variants of the cold cascade. In the first case, the SE model is trained cross-corpus with the Librispeech dataset, in the second case, it is trained on the CHiME-4 training set. Note that the training of the cold cascade approaches only implies a training of the AE component, while the evaluation is based on the ASR models supplied by the challenge. Similarly, for the MTL and iterative training approach, we train an AE and ASR system on CHiME-4 as described in <a href="#S3" title="3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>, but evaluate the SE system in combination with the provided ASR systems GMM-HMM and DNN-HMM.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.55.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Table 4</span>: </span><span id="S4.T4.2.2.1" class="ltx_text" style="font-size:90%;">Speech emotion recognition testing results, Unweighted Average Recall (UAR)[<math id="S4.T4.2.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T4.2.2.1.m1.1b"><mo id="S4.T4.2.2.1.m1.1.1" xref="S4.T4.2.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.1.m1.1c"><csymbol cd="latexml" id="S4.T4.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.1.m1.1d">\%</annotation></semantics></math>], using DEMoS and the AudioSet corpus. DA stands for the method using only data augmentation. MTL represents the proposed multi-task learning solution.</span></figcaption>
<table id="S4.T4.52.52" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.8.8.6" class="ltx_tr">
<th id="S4.T4.8.8.6.7" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">Methods</th>
<th id="S4.T4.8.8.6.8" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">Inf</th>
<td id="S4.T4.3.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.3.3.1.1.m1.1" class="ltx_Math" alttext="25$\mathrm{dB}$" display="inline"><semantics id="S4.T4.3.3.1.1.m1.1a"><mrow id="S4.T4.3.3.1.1.m1.1.2" xref="S4.T4.3.3.1.1.m1.1.2.cmml"><mn id="S4.T4.3.3.1.1.m1.1.2.2" xref="S4.T4.3.3.1.1.m1.1.2.2.cmml">25</mn><mo lspace="0em" rspace="0em" id="S4.T4.3.3.1.1.m1.1.2.1" xref="S4.T4.3.3.1.1.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T4.3.3.1.1.m1.1.2.3" xref="S4.T4.3.3.1.1.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.1.1.m1.1b"><apply id="S4.T4.3.3.1.1.m1.1.2.cmml" xref="S4.T4.3.3.1.1.m1.1.2"><times id="S4.T4.3.3.1.1.m1.1.2.1.cmml" xref="S4.T4.3.3.1.1.m1.1.2.1"></times><cn type="integer" id="S4.T4.3.3.1.1.m1.1.2.2.cmml" xref="S4.T4.3.3.1.1.m1.1.2.2">25</cn><csymbol cd="latexml" id="S4.T4.3.3.1.1.m1.1.2.3.cmml" xref="S4.T4.3.3.1.1.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.1.1.m1.1c">25$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T4.4.4.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.4.4.2.2.m1.1" class="ltx_Math" alttext="20$\mathrm{dB}$" display="inline"><semantics id="S4.T4.4.4.2.2.m1.1a"><mrow id="S4.T4.4.4.2.2.m1.1.2" xref="S4.T4.4.4.2.2.m1.1.2.cmml"><mn id="S4.T4.4.4.2.2.m1.1.2.2" xref="S4.T4.4.4.2.2.m1.1.2.2.cmml">20</mn><mo lspace="0em" rspace="0em" id="S4.T4.4.4.2.2.m1.1.2.1" xref="S4.T4.4.4.2.2.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T4.4.4.2.2.m1.1.2.3" xref="S4.T4.4.4.2.2.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.2.2.m1.1b"><apply id="S4.T4.4.4.2.2.m1.1.2.cmml" xref="S4.T4.4.4.2.2.m1.1.2"><times id="S4.T4.4.4.2.2.m1.1.2.1.cmml" xref="S4.T4.4.4.2.2.m1.1.2.1"></times><cn type="integer" id="S4.T4.4.4.2.2.m1.1.2.2.cmml" xref="S4.T4.4.4.2.2.m1.1.2.2">20</cn><csymbol cd="latexml" id="S4.T4.4.4.2.2.m1.1.2.3.cmml" xref="S4.T4.4.4.2.2.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.2.2.m1.1c">20$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T4.5.5.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.5.5.3.3.m1.1" class="ltx_Math" alttext="15$\mathrm{dB}$" display="inline"><semantics id="S4.T4.5.5.3.3.m1.1a"><mrow id="S4.T4.5.5.3.3.m1.1.2" xref="S4.T4.5.5.3.3.m1.1.2.cmml"><mn id="S4.T4.5.5.3.3.m1.1.2.2" xref="S4.T4.5.5.3.3.m1.1.2.2.cmml">15</mn><mo lspace="0em" rspace="0em" id="S4.T4.5.5.3.3.m1.1.2.1" xref="S4.T4.5.5.3.3.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T4.5.5.3.3.m1.1.2.3" xref="S4.T4.5.5.3.3.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.3.3.m1.1b"><apply id="S4.T4.5.5.3.3.m1.1.2.cmml" xref="S4.T4.5.5.3.3.m1.1.2"><times id="S4.T4.5.5.3.3.m1.1.2.1.cmml" xref="S4.T4.5.5.3.3.m1.1.2.1"></times><cn type="integer" id="S4.T4.5.5.3.3.m1.1.2.2.cmml" xref="S4.T4.5.5.3.3.m1.1.2.2">15</cn><csymbol cd="latexml" id="S4.T4.5.5.3.3.m1.1.2.3.cmml" xref="S4.T4.5.5.3.3.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.3.3.m1.1c">15$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T4.6.6.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.6.6.4.4.m1.1" class="ltx_Math" alttext="10$\mathrm{dB}$" display="inline"><semantics id="S4.T4.6.6.4.4.m1.1a"><mrow id="S4.T4.6.6.4.4.m1.1.2" xref="S4.T4.6.6.4.4.m1.1.2.cmml"><mn id="S4.T4.6.6.4.4.m1.1.2.2" xref="S4.T4.6.6.4.4.m1.1.2.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S4.T4.6.6.4.4.m1.1.2.1" xref="S4.T4.6.6.4.4.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T4.6.6.4.4.m1.1.2.3" xref="S4.T4.6.6.4.4.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.4.4.m1.1b"><apply id="S4.T4.6.6.4.4.m1.1.2.cmml" xref="S4.T4.6.6.4.4.m1.1.2"><times id="S4.T4.6.6.4.4.m1.1.2.1.cmml" xref="S4.T4.6.6.4.4.m1.1.2.1"></times><cn type="integer" id="S4.T4.6.6.4.4.m1.1.2.2.cmml" xref="S4.T4.6.6.4.4.m1.1.2.2">10</cn><csymbol cd="latexml" id="S4.T4.6.6.4.4.m1.1.2.3.cmml" xref="S4.T4.6.6.4.4.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.4.4.m1.1c">10$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T4.7.7.5.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.7.7.5.5.m1.1" class="ltx_Math" alttext="5$\mathrm{dB}$" display="inline"><semantics id="S4.T4.7.7.5.5.m1.1a"><mrow id="S4.T4.7.7.5.5.m1.1.2" xref="S4.T4.7.7.5.5.m1.1.2.cmml"><mn id="S4.T4.7.7.5.5.m1.1.2.2" xref="S4.T4.7.7.5.5.m1.1.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.T4.7.7.5.5.m1.1.2.1" xref="S4.T4.7.7.5.5.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T4.7.7.5.5.m1.1.2.3" xref="S4.T4.7.7.5.5.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.5.5.m1.1b"><apply id="S4.T4.7.7.5.5.m1.1.2.cmml" xref="S4.T4.7.7.5.5.m1.1.2"><times id="S4.T4.7.7.5.5.m1.1.2.1.cmml" xref="S4.T4.7.7.5.5.m1.1.2.1"></times><cn type="integer" id="S4.T4.7.7.5.5.m1.1.2.2.cmml" xref="S4.T4.7.7.5.5.m1.1.2.2">5</cn><csymbol cd="latexml" id="S4.T4.7.7.5.5.m1.1.2.3.cmml" xref="S4.T4.7.7.5.5.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.5.5.m1.1c">5$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T4.8.8.6.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.8.8.6.6.m1.1" class="ltx_Math" alttext="0$\mathrm{dB}$" display="inline"><semantics id="S4.T4.8.8.6.6.m1.1a"><mrow id="S4.T4.8.8.6.6.m1.1.2" xref="S4.T4.8.8.6.6.m1.1.2.cmml"><mn id="S4.T4.8.8.6.6.m1.1.2.2" xref="S4.T4.8.8.6.6.m1.1.2.2.cmml">0</mn><mo lspace="0em" rspace="0em" id="S4.T4.8.8.6.6.m1.1.2.1" xref="S4.T4.8.8.6.6.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T4.8.8.6.6.m1.1.2.3" xref="S4.T4.8.8.6.6.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.8.8.6.6.m1.1b"><apply id="S4.T4.8.8.6.6.m1.1.2.cmml" xref="S4.T4.8.8.6.6.m1.1.2"><times id="S4.T4.8.8.6.6.m1.1.2.1.cmml" xref="S4.T4.8.8.6.6.m1.1.2.1"></times><cn type="integer" id="S4.T4.8.8.6.6.m1.1.2.2.cmml" xref="S4.T4.8.8.6.6.m1.1.2.2">0</cn><csymbol cd="latexml" id="S4.T4.8.8.6.6.m1.1.2.3.cmml" xref="S4.T4.8.8.6.6.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.8.8.6.6.m1.1c">0$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T4.8.8.6.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">average</td>
</tr>
<tr id="S4.T4.16.16.14" class="ltx_tr">
<th id="S4.T4.16.16.14.9" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">original SER</th>
<th id="S4.T4.9.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.9.9.7.1.m1.1" class="ltx_Math" alttext="81.32" display="inline"><semantics id="S4.T4.9.9.7.1.m1.1a"><mn id="S4.T4.9.9.7.1.m1.1.1" xref="S4.T4.9.9.7.1.m1.1.1.cmml">81.32</mn><annotation-xml encoding="MathML-Content" id="S4.T4.9.9.7.1.m1.1b"><cn type="float" id="S4.T4.9.9.7.1.m1.1.1.cmml" xref="S4.T4.9.9.7.1.m1.1.1">81.32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.9.9.7.1.m1.1c">81.32</annotation></semantics></math></th>
<td id="S4.T4.10.10.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.10.10.8.2.m1.1" class="ltx_Math" alttext="81.18" display="inline"><semantics id="S4.T4.10.10.8.2.m1.1a"><mn id="S4.T4.10.10.8.2.m1.1.1" xref="S4.T4.10.10.8.2.m1.1.1.cmml">81.18</mn><annotation-xml encoding="MathML-Content" id="S4.T4.10.10.8.2.m1.1b"><cn type="float" id="S4.T4.10.10.8.2.m1.1.1.cmml" xref="S4.T4.10.10.8.2.m1.1.1">81.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.10.10.8.2.m1.1c">81.18</annotation></semantics></math></td>
<td id="S4.T4.11.11.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.11.11.9.3.m1.1" class="ltx_Math" alttext="79.95" display="inline"><semantics id="S4.T4.11.11.9.3.m1.1a"><mn id="S4.T4.11.11.9.3.m1.1.1" xref="S4.T4.11.11.9.3.m1.1.1.cmml">79.95</mn><annotation-xml encoding="MathML-Content" id="S4.T4.11.11.9.3.m1.1b"><cn type="float" id="S4.T4.11.11.9.3.m1.1.1.cmml" xref="S4.T4.11.11.9.3.m1.1.1">79.95</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.11.11.9.3.m1.1c">79.95</annotation></semantics></math></td>
<td id="S4.T4.12.12.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.12.12.10.4.m1.1" class="ltx_Math" alttext="78.98" display="inline"><semantics id="S4.T4.12.12.10.4.m1.1a"><mn id="S4.T4.12.12.10.4.m1.1.1" xref="S4.T4.12.12.10.4.m1.1.1.cmml">78.98</mn><annotation-xml encoding="MathML-Content" id="S4.T4.12.12.10.4.m1.1b"><cn type="float" id="S4.T4.12.12.10.4.m1.1.1.cmml" xref="S4.T4.12.12.10.4.m1.1.1">78.98</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.12.12.10.4.m1.1c">78.98</annotation></semantics></math></td>
<td id="S4.T4.13.13.11.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.13.13.11.5.m1.1" class="ltx_Math" alttext="73.70" display="inline"><semantics id="S4.T4.13.13.11.5.m1.1a"><mn id="S4.T4.13.13.11.5.m1.1.1" xref="S4.T4.13.13.11.5.m1.1.1.cmml">73.70</mn><annotation-xml encoding="MathML-Content" id="S4.T4.13.13.11.5.m1.1b"><cn type="float" id="S4.T4.13.13.11.5.m1.1.1.cmml" xref="S4.T4.13.13.11.5.m1.1.1">73.70</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.13.13.11.5.m1.1c">73.70</annotation></semantics></math></td>
<td id="S4.T4.14.14.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.14.14.12.6.m1.1" class="ltx_Math" alttext="59.82" display="inline"><semantics id="S4.T4.14.14.12.6.m1.1a"><mn id="S4.T4.14.14.12.6.m1.1.1" xref="S4.T4.14.14.12.6.m1.1.1.cmml">59.82</mn><annotation-xml encoding="MathML-Content" id="S4.T4.14.14.12.6.m1.1b"><cn type="float" id="S4.T4.14.14.12.6.m1.1.1.cmml" xref="S4.T4.14.14.12.6.m1.1.1">59.82</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.14.14.12.6.m1.1c">59.82</annotation></semantics></math></td>
<td id="S4.T4.15.15.13.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.15.15.13.7.m1.1" class="ltx_Math" alttext="40.32" display="inline"><semantics id="S4.T4.15.15.13.7.m1.1a"><mn id="S4.T4.15.15.13.7.m1.1.1" xref="S4.T4.15.15.13.7.m1.1.1.cmml">40.32</mn><annotation-xml encoding="MathML-Content" id="S4.T4.15.15.13.7.m1.1b"><cn type="float" id="S4.T4.15.15.13.7.m1.1.1.cmml" xref="S4.T4.15.15.13.7.m1.1.1">40.32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.15.15.13.7.m1.1c">40.32</annotation></semantics></math></td>
<td id="S4.T4.16.16.14.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.16.16.14.8.m1.1" class="ltx_Math" alttext="68.99" display="inline"><semantics id="S4.T4.16.16.14.8.m1.1a"><mn id="S4.T4.16.16.14.8.m1.1.1" xref="S4.T4.16.16.14.8.m1.1.1.cmml">68.99</mn><annotation-xml encoding="MathML-Content" id="S4.T4.16.16.14.8.m1.1b"><cn type="float" id="S4.T4.16.16.14.8.m1.1.1.cmml" xref="S4.T4.16.16.14.8.m1.1.1">68.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.16.16.14.8.m1.1c">68.99</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.23.23.21" class="ltx_tr">
<th id="S4.T4.23.23.21.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">DA</th>
<th id="S4.T4.23.23.21.9" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T4.17.17.15.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.17.17.15.1.m1.1" class="ltx_Math" alttext="79.53" display="inline"><semantics id="S4.T4.17.17.15.1.m1.1a"><mn id="S4.T4.17.17.15.1.m1.1.1" xref="S4.T4.17.17.15.1.m1.1.1.cmml">79.53</mn><annotation-xml encoding="MathML-Content" id="S4.T4.17.17.15.1.m1.1b"><cn type="float" id="S4.T4.17.17.15.1.m1.1.1.cmml" xref="S4.T4.17.17.15.1.m1.1.1">79.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.17.17.15.1.m1.1c">79.53</annotation></semantics></math></td>
<td id="S4.T4.18.18.16.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.18.18.16.2.m1.1" class="ltx_Math" alttext="79.46" display="inline"><semantics id="S4.T4.18.18.16.2.m1.1a"><mn id="S4.T4.18.18.16.2.m1.1.1" xref="S4.T4.18.18.16.2.m1.1.1.cmml">79.46</mn><annotation-xml encoding="MathML-Content" id="S4.T4.18.18.16.2.m1.1b"><cn type="float" id="S4.T4.18.18.16.2.m1.1.1.cmml" xref="S4.T4.18.18.16.2.m1.1.1">79.46</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.18.18.16.2.m1.1c">79.46</annotation></semantics></math></td>
<td id="S4.T4.19.19.17.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.19.19.17.3.m1.1" class="ltx_Math" alttext="79.05" display="inline"><semantics id="S4.T4.19.19.17.3.m1.1a"><mn id="S4.T4.19.19.17.3.m1.1.1" xref="S4.T4.19.19.17.3.m1.1.1.cmml">79.05</mn><annotation-xml encoding="MathML-Content" id="S4.T4.19.19.17.3.m1.1b"><cn type="float" id="S4.T4.19.19.17.3.m1.1.1.cmml" xref="S4.T4.19.19.17.3.m1.1.1">79.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.19.19.17.3.m1.1c">79.05</annotation></semantics></math></td>
<td id="S4.T4.20.20.18.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.20.20.18.4.m1.1" class="ltx_Math" alttext="78.30" display="inline"><semantics id="S4.T4.20.20.18.4.m1.1a"><mn id="S4.T4.20.20.18.4.m1.1.1" xref="S4.T4.20.20.18.4.m1.1.1.cmml">78.30</mn><annotation-xml encoding="MathML-Content" id="S4.T4.20.20.18.4.m1.1b"><cn type="float" id="S4.T4.20.20.18.4.m1.1.1.cmml" xref="S4.T4.20.20.18.4.m1.1.1">78.30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.20.20.18.4.m1.1c">78.30</annotation></semantics></math></td>
<td id="S4.T4.21.21.19.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.21.21.19.5.m1.1" class="ltx_Math" alttext="75.69" display="inline"><semantics id="S4.T4.21.21.19.5.m1.1a"><mn id="S4.T4.21.21.19.5.m1.1.1" xref="S4.T4.21.21.19.5.m1.1.1.cmml">75.69</mn><annotation-xml encoding="MathML-Content" id="S4.T4.21.21.19.5.m1.1b"><cn type="float" id="S4.T4.21.21.19.5.m1.1.1.cmml" xref="S4.T4.21.21.19.5.m1.1.1">75.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.21.21.19.5.m1.1c">75.69</annotation></semantics></math></td>
<td id="S4.T4.22.22.20.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.22.22.20.6.m1.1" class="ltx_Math" alttext="68.06" display="inline"><semantics id="S4.T4.22.22.20.6.m1.1a"><mn id="S4.T4.22.22.20.6.m1.1.1" xref="S4.T4.22.22.20.6.m1.1.1.cmml">68.06</mn><annotation-xml encoding="MathML-Content" id="S4.T4.22.22.20.6.m1.1b"><cn type="float" id="S4.T4.22.22.20.6.m1.1.1.cmml" xref="S4.T4.22.22.20.6.m1.1.1">68.06</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.22.22.20.6.m1.1c">68.06</annotation></semantics></math></td>
<td id="S4.T4.23.23.21.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.23.23.21.7.m1.1" class="ltx_Math" alttext="76.68" display="inline"><semantics id="S4.T4.23.23.21.7.m1.1a"><mn id="S4.T4.23.23.21.7.m1.1.1" xref="S4.T4.23.23.21.7.m1.1.1.cmml">76.68</mn><annotation-xml encoding="MathML-Content" id="S4.T4.23.23.21.7.m1.1b"><cn type="float" id="S4.T4.23.23.21.7.m1.1.1.cmml" xref="S4.T4.23.23.21.7.m1.1.1">76.68</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.23.23.21.7.m1.1c">76.68</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.30.30.28" class="ltx_tr">
<th id="S4.T4.30.30.28.8" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">Cold Cascade</th>
<th id="S4.T4.30.30.28.9" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T4.24.24.22.1" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.24.24.22.1.m1.1" class="ltx_Math" alttext="80.45" display="inline"><semantics id="S4.T4.24.24.22.1.m1.1a"><mn id="S4.T4.24.24.22.1.m1.1.1" xref="S4.T4.24.24.22.1.m1.1.1.cmml">80.45</mn><annotation-xml encoding="MathML-Content" id="S4.T4.24.24.22.1.m1.1b"><cn type="float" id="S4.T4.24.24.22.1.m1.1.1.cmml" xref="S4.T4.24.24.22.1.m1.1.1">80.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.24.24.22.1.m1.1c">80.45</annotation></semantics></math></td>
<td id="S4.T4.25.25.23.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.25.25.23.2.m1.1" class="ltx_Math" alttext="79.59" display="inline"><semantics id="S4.T4.25.25.23.2.m1.1a"><mn id="S4.T4.25.25.23.2.m1.1.1" xref="S4.T4.25.25.23.2.m1.1.1.cmml">79.59</mn><annotation-xml encoding="MathML-Content" id="S4.T4.25.25.23.2.m1.1b"><cn type="float" id="S4.T4.25.25.23.2.m1.1.1.cmml" xref="S4.T4.25.25.23.2.m1.1.1">79.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.25.25.23.2.m1.1c">79.59</annotation></semantics></math></td>
<td id="S4.T4.26.26.24.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.26.26.24.3.m1.1" class="ltx_Math" alttext="79.45" display="inline"><semantics id="S4.T4.26.26.24.3.m1.1a"><mn id="S4.T4.26.26.24.3.m1.1.1" xref="S4.T4.26.26.24.3.m1.1.1.cmml">79.45</mn><annotation-xml encoding="MathML-Content" id="S4.T4.26.26.24.3.m1.1b"><cn type="float" id="S4.T4.26.26.24.3.m1.1.1.cmml" xref="S4.T4.26.26.24.3.m1.1.1">79.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.26.26.24.3.m1.1c">79.45</annotation></semantics></math></td>
<td id="S4.T4.27.27.25.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.27.27.25.4.m1.1" class="ltx_Math" alttext="77.86" display="inline"><semantics id="S4.T4.27.27.25.4.m1.1a"><mn id="S4.T4.27.27.25.4.m1.1.1" xref="S4.T4.27.27.25.4.m1.1.1.cmml">77.86</mn><annotation-xml encoding="MathML-Content" id="S4.T4.27.27.25.4.m1.1b"><cn type="float" id="S4.T4.27.27.25.4.m1.1.1.cmml" xref="S4.T4.27.27.25.4.m1.1.1">77.86</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.27.27.25.4.m1.1c">77.86</annotation></semantics></math></td>
<td id="S4.T4.28.28.26.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.28.28.26.5.m1.1" class="ltx_Math" alttext="69.93" display="inline"><semantics id="S4.T4.28.28.26.5.m1.1a"><mn id="S4.T4.28.28.26.5.m1.1.1" xref="S4.T4.28.28.26.5.m1.1.1.cmml">69.93</mn><annotation-xml encoding="MathML-Content" id="S4.T4.28.28.26.5.m1.1b"><cn type="float" id="S4.T4.28.28.26.5.m1.1.1.cmml" xref="S4.T4.28.28.26.5.m1.1.1">69.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.28.28.26.5.m1.1c">69.93</annotation></semantics></math></td>
<td id="S4.T4.29.29.27.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.29.29.27.6.m1.1" class="ltx_Math" alttext="54.34" display="inline"><semantics id="S4.T4.29.29.27.6.m1.1a"><mn id="S4.T4.29.29.27.6.m1.1.1" xref="S4.T4.29.29.27.6.m1.1.1.cmml">54.34</mn><annotation-xml encoding="MathML-Content" id="S4.T4.29.29.27.6.m1.1b"><cn type="float" id="S4.T4.29.29.27.6.m1.1.1.cmml" xref="S4.T4.29.29.27.6.m1.1.1">54.34</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.29.29.27.6.m1.1c">54.34</annotation></semantics></math></td>
<td id="S4.T4.30.30.28.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.30.30.28.7.m1.1" class="ltx_Math" alttext="73.60" display="inline"><semantics id="S4.T4.30.30.28.7.m1.1a"><mn id="S4.T4.30.30.28.7.m1.1.1" xref="S4.T4.30.30.28.7.m1.1.1.cmml">73.60</mn><annotation-xml encoding="MathML-Content" id="S4.T4.30.30.28.7.m1.1b"><cn type="float" id="S4.T4.30.30.28.7.m1.1.1.cmml" xref="S4.T4.30.30.28.7.m1.1.1">73.60</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.30.30.28.7.m1.1c">73.60</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.38.38.36" class="ltx_tr">
<th id="S4.T4.38.38.36.9" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;">Cold Cascade + DA</th>
<th id="S4.T4.31.31.29.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.31.31.29.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S4.T4.31.31.29.1.m1.1a"><mo id="S4.T4.31.31.29.1.m1.1.1" xref="S4.T4.31.31.29.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T4.31.31.29.1.m1.1b"><minus id="S4.T4.31.31.29.1.m1.1.1.cmml" xref="S4.T4.31.31.29.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.31.31.29.1.m1.1c">-</annotation></semantics></math></th>
<td id="S4.T4.32.32.30.2" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.32.32.30.2.m1.1" class="ltx_Math" alttext="77.59" display="inline"><semantics id="S4.T4.32.32.30.2.m1.1a"><mn id="S4.T4.32.32.30.2.m1.1.1" xref="S4.T4.32.32.30.2.m1.1.1.cmml">77.59</mn><annotation-xml encoding="MathML-Content" id="S4.T4.32.32.30.2.m1.1b"><cn type="float" id="S4.T4.32.32.30.2.m1.1.1.cmml" xref="S4.T4.32.32.30.2.m1.1.1">77.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.32.32.30.2.m1.1c">77.59</annotation></semantics></math></td>
<td id="S4.T4.33.33.31.3" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.33.33.31.3.m1.1" class="ltx_Math" alttext="77.27" display="inline"><semantics id="S4.T4.33.33.31.3.m1.1a"><mn id="S4.T4.33.33.31.3.m1.1.1" xref="S4.T4.33.33.31.3.m1.1.1.cmml">77.27</mn><annotation-xml encoding="MathML-Content" id="S4.T4.33.33.31.3.m1.1b"><cn type="float" id="S4.T4.33.33.31.3.m1.1.1.cmml" xref="S4.T4.33.33.31.3.m1.1.1">77.27</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.33.33.31.3.m1.1c">77.27</annotation></semantics></math></td>
<td id="S4.T4.34.34.32.4" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.34.34.32.4.m1.1" class="ltx_Math" alttext="77.07" display="inline"><semantics id="S4.T4.34.34.32.4.m1.1a"><mn id="S4.T4.34.34.32.4.m1.1.1" xref="S4.T4.34.34.32.4.m1.1.1.cmml">77.07</mn><annotation-xml encoding="MathML-Content" id="S4.T4.34.34.32.4.m1.1b"><cn type="float" id="S4.T4.34.34.32.4.m1.1.1.cmml" xref="S4.T4.34.34.32.4.m1.1.1">77.07</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.34.34.32.4.m1.1c">77.07</annotation></semantics></math></td>
<td id="S4.T4.35.35.33.5" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.35.35.33.5.m1.1" class="ltx_Math" alttext="77.54" display="inline"><semantics id="S4.T4.35.35.33.5.m1.1a"><mn id="S4.T4.35.35.33.5.m1.1.1" xref="S4.T4.35.35.33.5.m1.1.1.cmml">77.54</mn><annotation-xml encoding="MathML-Content" id="S4.T4.35.35.33.5.m1.1b"><cn type="float" id="S4.T4.35.35.33.5.m1.1.1.cmml" xref="S4.T4.35.35.33.5.m1.1.1">77.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.35.35.33.5.m1.1c">77.54</annotation></semantics></math></td>
<td id="S4.T4.36.36.34.6" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.36.36.34.6.m1.1" class="ltx_Math" alttext="74.52" display="inline"><semantics id="S4.T4.36.36.34.6.m1.1a"><mn id="S4.T4.36.36.34.6.m1.1.1" xref="S4.T4.36.36.34.6.m1.1.1.cmml">74.52</mn><annotation-xml encoding="MathML-Content" id="S4.T4.36.36.34.6.m1.1b"><cn type="float" id="S4.T4.36.36.34.6.m1.1.1.cmml" xref="S4.T4.36.36.34.6.m1.1.1">74.52</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.36.36.34.6.m1.1c">74.52</annotation></semantics></math></td>
<td id="S4.T4.37.37.35.7" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.37.37.35.7.m1.1" class="ltx_Math" alttext="69.02" display="inline"><semantics id="S4.T4.37.37.35.7.m1.1a"><mn id="S4.T4.37.37.35.7.m1.1.1" xref="S4.T4.37.37.35.7.m1.1.1.cmml">69.02</mn><annotation-xml encoding="MathML-Content" id="S4.T4.37.37.35.7.m1.1b"><cn type="float" id="S4.T4.37.37.35.7.m1.1.1.cmml" xref="S4.T4.37.37.35.7.m1.1.1">69.02</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.37.37.35.7.m1.1c">69.02</annotation></semantics></math></td>
<td id="S4.T4.38.38.36.8" class="ltx_td ltx_align_center" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.38.38.36.8.m1.1" class="ltx_Math" alttext="75.49" display="inline"><semantics id="S4.T4.38.38.36.8.m1.1a"><mn id="S4.T4.38.38.36.8.m1.1.1" xref="S4.T4.38.38.36.8.m1.1.1.cmml">75.49</mn><annotation-xml encoding="MathML-Content" id="S4.T4.38.38.36.8.m1.1b"><cn type="float" id="S4.T4.38.38.36.8.m1.1.1.cmml" xref="S4.T4.38.38.36.8.m1.1.1">75.49</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.38.38.36.8.m1.1c">75.49</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.45.45.43" class="ltx_tr">
<th id="S4.T4.45.45.43.8" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.45.45.43.8.1" class="ltx_text ltx_font_bold">MTL</span></th>
<th id="S4.T4.45.45.43.9" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T4.39.39.37.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.39.39.37.1.m1.1" class="ltx_Math" alttext="81.30" display="inline"><semantics id="S4.T4.39.39.37.1.m1.1a"><mn id="S4.T4.39.39.37.1.m1.1.1" xref="S4.T4.39.39.37.1.m1.1.1.cmml">81.30</mn><annotation-xml encoding="MathML-Content" id="S4.T4.39.39.37.1.m1.1b"><cn type="float" id="S4.T4.39.39.37.1.m1.1.1.cmml" xref="S4.T4.39.39.37.1.m1.1.1">81.30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.39.39.37.1.m1.1c">81.30</annotation></semantics></math></td>
<td id="S4.T4.40.40.38.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.40.40.38.2.m1.1" class="ltx_Math" alttext="80.67" display="inline"><semantics id="S4.T4.40.40.38.2.m1.1a"><mn id="S4.T4.40.40.38.2.m1.1.1" xref="S4.T4.40.40.38.2.m1.1.1.cmml">80.67</mn><annotation-xml encoding="MathML-Content" id="S4.T4.40.40.38.2.m1.1b"><cn type="float" id="S4.T4.40.40.38.2.m1.1.1.cmml" xref="S4.T4.40.40.38.2.m1.1.1">80.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.40.40.38.2.m1.1c">80.67</annotation></semantics></math></td>
<td id="S4.T4.41.41.39.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.41.41.39.3.m1.1" class="ltx_Math" alttext="80.31" display="inline"><semantics id="S4.T4.41.41.39.3.m1.1a"><mn id="S4.T4.41.41.39.3.m1.1.1" xref="S4.T4.41.41.39.3.m1.1.1.cmml">80.31</mn><annotation-xml encoding="MathML-Content" id="S4.T4.41.41.39.3.m1.1b"><cn type="float" id="S4.T4.41.41.39.3.m1.1.1.cmml" xref="S4.T4.41.41.39.3.m1.1.1">80.31</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.41.41.39.3.m1.1c">80.31</annotation></semantics></math></td>
<td id="S4.T4.42.42.40.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.42.42.40.4.m1.1" class="ltx_Math" alttext="79.93" display="inline"><semantics id="S4.T4.42.42.40.4.m1.1a"><mn id="S4.T4.42.42.40.4.m1.1.1" xref="S4.T4.42.42.40.4.m1.1.1.cmml">79.93</mn><annotation-xml encoding="MathML-Content" id="S4.T4.42.42.40.4.m1.1b"><cn type="float" id="S4.T4.42.42.40.4.m1.1.1.cmml" xref="S4.T4.42.42.40.4.m1.1.1">79.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.42.42.40.4.m1.1c">79.93</annotation></semantics></math></td>
<td id="S4.T4.43.43.41.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.43.43.41.5.m1.1" class="ltx_Math" alttext="77.29" display="inline"><semantics id="S4.T4.43.43.41.5.m1.1a"><mn id="S4.T4.43.43.41.5.m1.1.1" xref="S4.T4.43.43.41.5.m1.1.1.cmml">77.29</mn><annotation-xml encoding="MathML-Content" id="S4.T4.43.43.41.5.m1.1b"><cn type="float" id="S4.T4.43.43.41.5.m1.1.1.cmml" xref="S4.T4.43.43.41.5.m1.1.1">77.29</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.43.43.41.5.m1.1c">77.29</annotation></semantics></math></td>
<td id="S4.T4.44.44.42.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.44.44.42.6.m1.1" class="ltx_Math" alttext="75.44" display="inline"><semantics id="S4.T4.44.44.42.6.m1.1a"><mn id="S4.T4.44.44.42.6.m1.1.1" xref="S4.T4.44.44.42.6.m1.1.1.cmml">75.44</mn><annotation-xml encoding="MathML-Content" id="S4.T4.44.44.42.6.m1.1b"><cn type="float" id="S4.T4.44.44.42.6.m1.1.1.cmml" xref="S4.T4.44.44.42.6.m1.1.1">75.44</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.44.44.42.6.m1.1c">75.44</annotation></semantics></math></td>
<td id="S4.T4.45.45.43.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;"><math id="S4.T4.45.45.43.7.m1.1" class="ltx_Math" alttext="79.16" display="inline"><semantics id="S4.T4.45.45.43.7.m1.1a"><mn id="S4.T4.45.45.43.7.m1.1.1" xref="S4.T4.45.45.43.7.m1.1.1.cmml">79.16</mn><annotation-xml encoding="MathML-Content" id="S4.T4.45.45.43.7.m1.1b"><cn type="float" id="S4.T4.45.45.43.7.m1.1.1.cmml" xref="S4.T4.45.45.43.7.m1.1.1">79.16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.45.45.43.7.m1.1c">79.16</annotation></semantics></math></td>
</tr>
<tr id="S4.T4.52.52.50" class="ltx_tr">
<th id="S4.T4.52.52.50.8" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.52.52.50.8.1" class="ltx_text ltx_font_bold">iterative optimisation</span></th>
<th id="S4.T4.52.52.50.9" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">-</th>
<td id="S4.T4.46.46.44.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.46.46.44.1.1" class="ltx_text ltx_markedasmath ltx_font_bold">81.31</span></td>
<td id="S4.T4.47.47.45.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.47.47.45.2.1" class="ltx_text ltx_markedasmath ltx_font_bold">80.76</span></td>
<td id="S4.T4.48.48.46.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.48.48.46.3.1" class="ltx_text ltx_markedasmath ltx_font_bold">80.35</span></td>
<td id="S4.T4.49.49.47.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.49.49.47.4.1" class="ltx_text ltx_markedasmath ltx_font_bold">79.95</span></td>
<td id="S4.T4.50.50.48.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.50.50.48.5.1" class="ltx_text ltx_markedasmath ltx_font_bold">78.09</span></td>
<td id="S4.T4.51.51.49.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.51.51.49.6.1" class="ltx_text ltx_markedasmath ltx_font_bold">76.91</span></td>
<td id="S4.T4.52.52.50.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;"><span id="S4.T4.52.52.50.7.1" class="ltx_text ltx_markedasmath ltx_font_bold">79.56</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p"><a href="#S4.T3" title="In 4.1 Downstream Task I: Speech Command Recognition ‣ 4 Experimental Results ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> shows the results for simulated (simu) and real test set with the two provided ML approaches GMM-HMM and DNN-HMM, as introduced in <a href="#S3" title="3 Methodologies ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3</span></a>.
The iterative optimisation achieves the lowest WER in all cases with MTL being the follow-up. The cross-corpus approach cold cascade 1 consistently performs worse than cold cascade 2, however, still outperforming the baseline. Overall, the WERs are comparable to the 25 dB case of the Librispeech experiments with the best result being the iterative optimisation with a DNN-HMM on the real test data at a WER of <math id="S4.SS2.p5.1.m1.1" class="ltx_Math" alttext="8.12\,\%" display="inline"><semantics id="S4.SS2.p5.1.m1.1a"><mrow id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml"><mn id="S4.SS2.p5.1.m1.1.1.2" xref="S4.SS2.p5.1.m1.1.1.2.cmml">8.12</mn><mo lspace="0.170em" id="S4.SS2.p5.1.m1.1.1.1" xref="S4.SS2.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><apply id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p5.1.m1.1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p5.1.m1.1.1.2.cmml" xref="S4.SS2.p5.1.m1.1.1.2">8.12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">8.12\,\%</annotation></semantics></math></p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Downstream Task III: Speech Emotion Recognition</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Our method is evaluated for the task of <span title="" class="ltx_glossaryref">SER</span> on a dataset of elicited mood in Italian speech, DEMoS <cite class="ltx_cite ltx_citemacro_citep">(Parada-Cabaleiro et al., <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>.
DEMoS contains 9 365 emotional and 322 neutral samples recorded from 68 native speakers (23 females and 45 males; mean age 23.7 years, standard deviation 4.3 years).
Six emotions – anger, sadness, happiness, fear, surprise, and guilt – are elicited by listening to music, watching pictures or movies, pronouncing or reading emotional sentences, and recalling personal memories.
Original recordings are captured at 44.1 kHz with 16-bit depth.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">In our experiments, we use all of the emotional samples in DEMoS, while keeping the partitioning of the data for training, development, and testing identical to <cite class="ltx_cite ltx_citemacro_cite">Ren et al. (<a href="#bib.bib44" title="" class="ltx_ref">2020</a>)</cite>, ensuring a speaker-independent split and accounting for gender and class balance.
To be consistent with the other target audio applications, the audio samples from DEMoS are down-sampled to 16 kHz, which yields no evident information loss according to <cite class="ltx_cite ltx_citemacro_cite">Ren et al. (<a href="#bib.bib44" title="" class="ltx_ref">2020</a>)</cite>.
As for the previous experiments, we simulate the background noise along with the speech utterances by adding environmental recordings from AudioSet<span id="todo2" class="ltx_note ltx_role_todo"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">todo: </span><span class="ltx_tag ltx_tag_note">2</span>+++</span></span></span>.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">The <span title="" class="ltx_glossaryref">CNN</span> model predicts the emotion label given a single utterance as input.
To account for the imbalanced class distribution in the test set, we use <span title="" class="ltx_glossaryref">unweighted average recall (UAR)</span>, the unweighted average of the class-specific recalls, to evaluate the trained models throughout the experiments.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.6" class="ltx_p"><a href="#S4.T4" title="In 4.2 Downstream Task II: Automatic Speech Recognition ‣ 4 Experimental Results ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a> shows the results of our experiments.
On the clean test set, our model achieved a <span title="" class="ltx_glossaryref">UAR</span> of <math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="81.32\,\%" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mrow id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml"><mn id="S4.SS3.p4.1.m1.1.1.2" xref="S4.SS3.p4.1.m1.1.1.2.cmml">81.32</mn><mo lspace="0.170em" id="S4.SS3.p4.1.m1.1.1.1" xref="S4.SS3.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><apply id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p4.1.m1.1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p4.1.m1.1.1.2.cmml" xref="S4.SS3.p4.1.m1.1.1.2">81.32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">81.32\,\%</annotation></semantics></math>.
It is relatively robust to additive noise up to <span title="" class="ltx_glossaryref">signal-to-noise ratio (SNR)</span> values of <math id="S4.SS3.p4.2.m2.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S4.SS3.p4.2.m2.1a"><mn id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.1b"><cn type="integer" id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.1c">15</annotation></semantics></math> <math id="S4.SS3.p4.3.m3.1" class="ltx_Math" alttext="\mathrm{dB}" display="inline"><semantics id="S4.SS3.p4.3.m3.1a"><mi class="ltx_unit" id="S4.SS3.p4.3.m3.1.1" xref="S4.SS3.p4.3.m3.1.1.cmml">dB</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.3.m3.1b"><csymbol cd="latexml" id="S4.SS3.p4.3.m3.1.1.cmml" xref="S4.SS3.p4.3.m3.1.1">decibel</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.3.m3.1c">\mathrm{dB}</annotation></semantics></math>; further increasing noise intensity over that leads to an average <span title="" class="ltx_glossaryref">UAR</span> of <math id="S4.SS3.p4.4.m4.1" class="ltx_Math" alttext="68.99\,\%" display="inline"><semantics id="S4.SS3.p4.4.m4.1a"><mrow id="S4.SS3.p4.4.m4.1.1" xref="S4.SS3.p4.4.m4.1.1.cmml"><mn id="S4.SS3.p4.4.m4.1.1.2" xref="S4.SS3.p4.4.m4.1.1.2.cmml">68.99</mn><mo lspace="0.170em" id="S4.SS3.p4.4.m4.1.1.1" xref="S4.SS3.p4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.m4.1b"><apply id="S4.SS3.p4.4.m4.1.1.cmml" xref="S4.SS3.p4.4.m4.1.1"><csymbol cd="latexml" id="S4.SS3.p4.4.m4.1.1.1.cmml" xref="S4.SS3.p4.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p4.4.m4.1.1.2.cmml" xref="S4.SS3.p4.4.m4.1.1.2">68.99</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.m4.1c">68.99\,\%</annotation></semantics></math>, far below the performance on the clean test set.
As for the baseline methods, data augmentation increases robustness, especially in low <span title="" class="ltx_glossaryref">SNR</span> levels under <math id="S4.SS3.p4.5.m5.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.p4.5.m5.1a"><mn id="S4.SS3.p4.5.m5.1.1" xref="S4.SS3.p4.5.m5.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.5.m5.1b"><cn type="integer" id="S4.SS3.p4.5.m5.1.1.cmml" xref="S4.SS3.p4.5.m5.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.5.m5.1c">10</annotation></semantics></math> <math id="S4.SS3.p4.6.m6.1" class="ltx_Math" alttext="\mathrm{dB}" display="inline"><semantics id="S4.SS3.p4.6.m6.1a"><mi class="ltx_unit" id="S4.SS3.p4.6.m6.1.1" xref="S4.SS3.p4.6.m6.1.1.cmml">dB</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.6.m6.1b"><csymbol cd="latexml" id="S4.SS3.p4.6.m6.1.1.cmml" xref="S4.SS3.p4.6.m6.1.1">decibel</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.6.m6.1c">\mathrm{dB}</annotation></semantics></math>, but using a <span title="" class="ltx_glossaryref">SE</span> frontend hardly improves, and even hampers, performance.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.3" class="ltx_p">Both of our joint optimisation approaches indicate better SER performance, resulting in an average UAR of <math id="S4.SS3.p5.1.m1.1" class="ltx_Math" alttext="79.16\,\%" display="inline"><semantics id="S4.SS3.p5.1.m1.1a"><mrow id="S4.SS3.p5.1.m1.1.1" xref="S4.SS3.p5.1.m1.1.1.cmml"><mn id="S4.SS3.p5.1.m1.1.1.2" xref="S4.SS3.p5.1.m1.1.1.2.cmml">79.16</mn><mo lspace="0.170em" id="S4.SS3.p5.1.m1.1.1.1" xref="S4.SS3.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.1.m1.1b"><apply id="S4.SS3.p5.1.m1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p5.1.m1.1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p5.1.m1.1.1.2.cmml" xref="S4.SS3.p5.1.m1.1.1.2">79.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.1.m1.1c">79.16\,\%</annotation></semantics></math> and <math id="S4.SS3.p5.2.m2.1" class="ltx_Math" alttext="79.56\,\%" display="inline"><semantics id="S4.SS3.p5.2.m2.1a"><mrow id="S4.SS3.p5.2.m2.1.1" xref="S4.SS3.p5.2.m2.1.1.cmml"><mn id="S4.SS3.p5.2.m2.1.1.2" xref="S4.SS3.p5.2.m2.1.1.2.cmml">79.56</mn><mo lspace="0.170em" id="S4.SS3.p5.2.m2.1.1.1" xref="S4.SS3.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.2.m2.1b"><apply id="S4.SS3.p5.2.m2.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p5.2.m2.1.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p5.2.m2.1.1.2.cmml" xref="S4.SS3.p5.2.m2.1.1.2">79.56</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.2.m2.1c">79.56\,\%</annotation></semantics></math>, surpassing the best performing baseline model (DA) which produces a UAR of <math id="S4.SS3.p5.3.m3.1" class="ltx_Math" alttext="76.68\,\%" display="inline"><semantics id="S4.SS3.p5.3.m3.1a"><mrow id="S4.SS3.p5.3.m3.1.1" xref="S4.SS3.p5.3.m3.1.1.cmml"><mn id="S4.SS3.p5.3.m3.1.1.2" xref="S4.SS3.p5.3.m3.1.1.2.cmml">76.68</mn><mo lspace="0.170em" id="S4.SS3.p5.3.m3.1.1.1" xref="S4.SS3.p5.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.3.m3.1b"><apply id="S4.SS3.p5.3.m3.1.1.cmml" xref="S4.SS3.p5.3.m3.1.1"><csymbol cd="latexml" id="S4.SS3.p5.3.m3.1.1.1.cmml" xref="S4.SS3.p5.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p5.3.m3.1.1.2.cmml" xref="S4.SS3.p5.3.m3.1.1.2">76.68</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.3.m3.1c">76.68\,\%</annotation></semantics></math>.
This improvement partially arises from mitigating the language gap introduced by the cold cascade models, as the AE model is trained on data in English and the SER model in Italian, whilst additionally strengthening the integration of the two models.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.69.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Table 5</span>: </span><span id="S4.T5.2.2.1" class="ltx_text" style="font-size:90%;">Acoustic scene classification testing results, (Acc)uracy[<math id="S4.T5.2.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T5.2.2.1.m1.1b"><mo id="S4.T5.2.2.1.m1.1.1" xref="S4.T5.2.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.1.m1.1c"><csymbol cd="latexml" id="S4.T5.2.2.1.m1.1.1.cmml" xref="S4.T5.2.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.1.m1.1d">\%</annotation></semantics></math>], using the DCASE2021 and Librispeech corpus. DA stands for the method using only data augmentation. MTL represents the proposed multi-task learning solution.</span></figcaption>
<table id="S4.T5.66.66" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.10.10.8" class="ltx_tr">
<th id="S4.T5.10.10.8.9" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" style="padding:1pt 4.0pt;">Methods</th>
<th id="S4.T5.10.10.8.10" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" style="padding:1pt 4.0pt;">Inf</th>
<td id="S4.T5.3.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;"><math id="S4.T5.3.3.1.1.m1.1" class="ltx_Math" alttext="-25$\mathrm{dB}$" display="inline"><semantics id="S4.T5.3.3.1.1.m1.1a"><mrow id="S4.T5.3.3.1.1.m1.1.2" xref="S4.T5.3.3.1.1.m1.1.2.cmml"><mo id="S4.T5.3.3.1.1.m1.1.2a" xref="S4.T5.3.3.1.1.m1.1.2.cmml">−</mo><mrow id="S4.T5.3.3.1.1.m1.1.2.2" xref="S4.T5.3.3.1.1.m1.1.2.2.cmml"><mn id="S4.T5.3.3.1.1.m1.1.2.2.2" xref="S4.T5.3.3.1.1.m1.1.2.2.2.cmml">25</mn><mo lspace="0em" rspace="0em" id="S4.T5.3.3.1.1.m1.1.2.2.1" xref="S4.T5.3.3.1.1.m1.1.2.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T5.3.3.1.1.m1.1.2.2.3" xref="S4.T5.3.3.1.1.m1.1.2.2.3.cmml">dB</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.1.1.m1.1b"><apply id="S4.T5.3.3.1.1.m1.1.2.cmml" xref="S4.T5.3.3.1.1.m1.1.2"><minus id="S4.T5.3.3.1.1.m1.1.2.1.cmml" xref="S4.T5.3.3.1.1.m1.1.2"></minus><apply id="S4.T5.3.3.1.1.m1.1.2.2.cmml" xref="S4.T5.3.3.1.1.m1.1.2.2"><times id="S4.T5.3.3.1.1.m1.1.2.2.1.cmml" xref="S4.T5.3.3.1.1.m1.1.2.2.1"></times><cn type="integer" id="S4.T5.3.3.1.1.m1.1.2.2.2.cmml" xref="S4.T5.3.3.1.1.m1.1.2.2.2">25</cn><csymbol cd="latexml" id="S4.T5.3.3.1.1.m1.1.2.2.3.cmml" xref="S4.T5.3.3.1.1.m1.1.2.2.3">decibel</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.1.1.m1.1c">-25$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T5.4.4.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;"><math id="S4.T5.4.4.2.2.m1.1" class="ltx_Math" alttext="-20$\mathrm{dB}$" display="inline"><semantics id="S4.T5.4.4.2.2.m1.1a"><mrow id="S4.T5.4.4.2.2.m1.1.2" xref="S4.T5.4.4.2.2.m1.1.2.cmml"><mo id="S4.T5.4.4.2.2.m1.1.2a" xref="S4.T5.4.4.2.2.m1.1.2.cmml">−</mo><mrow id="S4.T5.4.4.2.2.m1.1.2.2" xref="S4.T5.4.4.2.2.m1.1.2.2.cmml"><mn id="S4.T5.4.4.2.2.m1.1.2.2.2" xref="S4.T5.4.4.2.2.m1.1.2.2.2.cmml">20</mn><mo lspace="0em" rspace="0em" id="S4.T5.4.4.2.2.m1.1.2.2.1" xref="S4.T5.4.4.2.2.m1.1.2.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T5.4.4.2.2.m1.1.2.2.3" xref="S4.T5.4.4.2.2.m1.1.2.2.3.cmml">dB</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.2.2.m1.1b"><apply id="S4.T5.4.4.2.2.m1.1.2.cmml" xref="S4.T5.4.4.2.2.m1.1.2"><minus id="S4.T5.4.4.2.2.m1.1.2.1.cmml" xref="S4.T5.4.4.2.2.m1.1.2"></minus><apply id="S4.T5.4.4.2.2.m1.1.2.2.cmml" xref="S4.T5.4.4.2.2.m1.1.2.2"><times id="S4.T5.4.4.2.2.m1.1.2.2.1.cmml" xref="S4.T5.4.4.2.2.m1.1.2.2.1"></times><cn type="integer" id="S4.T5.4.4.2.2.m1.1.2.2.2.cmml" xref="S4.T5.4.4.2.2.m1.1.2.2.2">20</cn><csymbol cd="latexml" id="S4.T5.4.4.2.2.m1.1.2.2.3.cmml" xref="S4.T5.4.4.2.2.m1.1.2.2.3">decibel</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.2.2.m1.1c">-20$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T5.5.5.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;"><math id="S4.T5.5.5.3.3.m1.1" class="ltx_Math" alttext="-15$\mathrm{dB}$" display="inline"><semantics id="S4.T5.5.5.3.3.m1.1a"><mrow id="S4.T5.5.5.3.3.m1.1.2" xref="S4.T5.5.5.3.3.m1.1.2.cmml"><mo id="S4.T5.5.5.3.3.m1.1.2a" xref="S4.T5.5.5.3.3.m1.1.2.cmml">−</mo><mrow id="S4.T5.5.5.3.3.m1.1.2.2" xref="S4.T5.5.5.3.3.m1.1.2.2.cmml"><mn id="S4.T5.5.5.3.3.m1.1.2.2.2" xref="S4.T5.5.5.3.3.m1.1.2.2.2.cmml">15</mn><mo lspace="0em" rspace="0em" id="S4.T5.5.5.3.3.m1.1.2.2.1" xref="S4.T5.5.5.3.3.m1.1.2.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T5.5.5.3.3.m1.1.2.2.3" xref="S4.T5.5.5.3.3.m1.1.2.2.3.cmml">dB</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.3.3.m1.1b"><apply id="S4.T5.5.5.3.3.m1.1.2.cmml" xref="S4.T5.5.5.3.3.m1.1.2"><minus id="S4.T5.5.5.3.3.m1.1.2.1.cmml" xref="S4.T5.5.5.3.3.m1.1.2"></minus><apply id="S4.T5.5.5.3.3.m1.1.2.2.cmml" xref="S4.T5.5.5.3.3.m1.1.2.2"><times id="S4.T5.5.5.3.3.m1.1.2.2.1.cmml" xref="S4.T5.5.5.3.3.m1.1.2.2.1"></times><cn type="integer" id="S4.T5.5.5.3.3.m1.1.2.2.2.cmml" xref="S4.T5.5.5.3.3.m1.1.2.2.2">15</cn><csymbol cd="latexml" id="S4.T5.5.5.3.3.m1.1.2.2.3.cmml" xref="S4.T5.5.5.3.3.m1.1.2.2.3">decibel</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.3.3.m1.1c">-15$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T5.6.6.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;"><math id="S4.T5.6.6.4.4.m1.1" class="ltx_Math" alttext="-10$\mathrm{dB}$" display="inline"><semantics id="S4.T5.6.6.4.4.m1.1a"><mrow id="S4.T5.6.6.4.4.m1.1.2" xref="S4.T5.6.6.4.4.m1.1.2.cmml"><mo id="S4.T5.6.6.4.4.m1.1.2a" xref="S4.T5.6.6.4.4.m1.1.2.cmml">−</mo><mrow id="S4.T5.6.6.4.4.m1.1.2.2" xref="S4.T5.6.6.4.4.m1.1.2.2.cmml"><mn id="S4.T5.6.6.4.4.m1.1.2.2.2" xref="S4.T5.6.6.4.4.m1.1.2.2.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S4.T5.6.6.4.4.m1.1.2.2.1" xref="S4.T5.6.6.4.4.m1.1.2.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T5.6.6.4.4.m1.1.2.2.3" xref="S4.T5.6.6.4.4.m1.1.2.2.3.cmml">dB</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.4.4.m1.1b"><apply id="S4.T5.6.6.4.4.m1.1.2.cmml" xref="S4.T5.6.6.4.4.m1.1.2"><minus id="S4.T5.6.6.4.4.m1.1.2.1.cmml" xref="S4.T5.6.6.4.4.m1.1.2"></minus><apply id="S4.T5.6.6.4.4.m1.1.2.2.cmml" xref="S4.T5.6.6.4.4.m1.1.2.2"><times id="S4.T5.6.6.4.4.m1.1.2.2.1.cmml" xref="S4.T5.6.6.4.4.m1.1.2.2.1"></times><cn type="integer" id="S4.T5.6.6.4.4.m1.1.2.2.2.cmml" xref="S4.T5.6.6.4.4.m1.1.2.2.2">10</cn><csymbol cd="latexml" id="S4.T5.6.6.4.4.m1.1.2.2.3.cmml" xref="S4.T5.6.6.4.4.m1.1.2.2.3">decibel</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.4.4.m1.1c">-10$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T5.7.7.5.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;"><math id="S4.T5.7.7.5.5.m1.1" class="ltx_Math" alttext="-5$\mathrm{dB}$" display="inline"><semantics id="S4.T5.7.7.5.5.m1.1a"><mrow id="S4.T5.7.7.5.5.m1.1.2" xref="S4.T5.7.7.5.5.m1.1.2.cmml"><mo id="S4.T5.7.7.5.5.m1.1.2a" xref="S4.T5.7.7.5.5.m1.1.2.cmml">−</mo><mrow id="S4.T5.7.7.5.5.m1.1.2.2" xref="S4.T5.7.7.5.5.m1.1.2.2.cmml"><mn id="S4.T5.7.7.5.5.m1.1.2.2.2" xref="S4.T5.7.7.5.5.m1.1.2.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.T5.7.7.5.5.m1.1.2.2.1" xref="S4.T5.7.7.5.5.m1.1.2.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T5.7.7.5.5.m1.1.2.2.3" xref="S4.T5.7.7.5.5.m1.1.2.2.3.cmml">dB</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.7.7.5.5.m1.1b"><apply id="S4.T5.7.7.5.5.m1.1.2.cmml" xref="S4.T5.7.7.5.5.m1.1.2"><minus id="S4.T5.7.7.5.5.m1.1.2.1.cmml" xref="S4.T5.7.7.5.5.m1.1.2"></minus><apply id="S4.T5.7.7.5.5.m1.1.2.2.cmml" xref="S4.T5.7.7.5.5.m1.1.2.2"><times id="S4.T5.7.7.5.5.m1.1.2.2.1.cmml" xref="S4.T5.7.7.5.5.m1.1.2.2.1"></times><cn type="integer" id="S4.T5.7.7.5.5.m1.1.2.2.2.cmml" xref="S4.T5.7.7.5.5.m1.1.2.2.2">5</cn><csymbol cd="latexml" id="S4.T5.7.7.5.5.m1.1.2.2.3.cmml" xref="S4.T5.7.7.5.5.m1.1.2.2.3">decibel</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.7.5.5.m1.1c">-5$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T5.8.8.6.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;"><math id="S4.T5.8.8.6.6.m1.1" class="ltx_Math" alttext="0$\mathrm{dB}$" display="inline"><semantics id="S4.T5.8.8.6.6.m1.1a"><mrow id="S4.T5.8.8.6.6.m1.1.2" xref="S4.T5.8.8.6.6.m1.1.2.cmml"><mn id="S4.T5.8.8.6.6.m1.1.2.2" xref="S4.T5.8.8.6.6.m1.1.2.2.cmml">0</mn><mo lspace="0em" rspace="0em" id="S4.T5.8.8.6.6.m1.1.2.1" xref="S4.T5.8.8.6.6.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T5.8.8.6.6.m1.1.2.3" xref="S4.T5.8.8.6.6.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.8.8.6.6.m1.1b"><apply id="S4.T5.8.8.6.6.m1.1.2.cmml" xref="S4.T5.8.8.6.6.m1.1.2"><times id="S4.T5.8.8.6.6.m1.1.2.1.cmml" xref="S4.T5.8.8.6.6.m1.1.2.1"></times><cn type="integer" id="S4.T5.8.8.6.6.m1.1.2.2.cmml" xref="S4.T5.8.8.6.6.m1.1.2.2">0</cn><csymbol cd="latexml" id="S4.T5.8.8.6.6.m1.1.2.3.cmml" xref="S4.T5.8.8.6.6.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.8.6.6.m1.1c">0$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T5.9.9.7.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;"><math id="S4.T5.9.9.7.7.m1.1" class="ltx_Math" alttext="5$\mathrm{dB}$" display="inline"><semantics id="S4.T5.9.9.7.7.m1.1a"><mrow id="S4.T5.9.9.7.7.m1.1.2" xref="S4.T5.9.9.7.7.m1.1.2.cmml"><mn id="S4.T5.9.9.7.7.m1.1.2.2" xref="S4.T5.9.9.7.7.m1.1.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.T5.9.9.7.7.m1.1.2.1" xref="S4.T5.9.9.7.7.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T5.9.9.7.7.m1.1.2.3" xref="S4.T5.9.9.7.7.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.9.9.7.7.m1.1b"><apply id="S4.T5.9.9.7.7.m1.1.2.cmml" xref="S4.T5.9.9.7.7.m1.1.2"><times id="S4.T5.9.9.7.7.m1.1.2.1.cmml" xref="S4.T5.9.9.7.7.m1.1.2.1"></times><cn type="integer" id="S4.T5.9.9.7.7.m1.1.2.2.cmml" xref="S4.T5.9.9.7.7.m1.1.2.2">5</cn><csymbol cd="latexml" id="S4.T5.9.9.7.7.m1.1.2.3.cmml" xref="S4.T5.9.9.7.7.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.9.7.7.m1.1c">5$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T5.10.10.8.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;"><math id="S4.T5.10.10.8.8.m1.1" class="ltx_Math" alttext="10$\mathrm{dB}$" display="inline"><semantics id="S4.T5.10.10.8.8.m1.1a"><mrow id="S4.T5.10.10.8.8.m1.1.2" xref="S4.T5.10.10.8.8.m1.1.2.cmml"><mn id="S4.T5.10.10.8.8.m1.1.2.2" xref="S4.T5.10.10.8.8.m1.1.2.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S4.T5.10.10.8.8.m1.1.2.1" xref="S4.T5.10.10.8.8.m1.1.2.1.cmml">​</mo><mi class="ltx_unit" id="S4.T5.10.10.8.8.m1.1.2.3" xref="S4.T5.10.10.8.8.m1.1.2.3.cmml">dB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.10.10.8.8.m1.1b"><apply id="S4.T5.10.10.8.8.m1.1.2.cmml" xref="S4.T5.10.10.8.8.m1.1.2"><times id="S4.T5.10.10.8.8.m1.1.2.1.cmml" xref="S4.T5.10.10.8.8.m1.1.2.1"></times><cn type="integer" id="S4.T5.10.10.8.8.m1.1.2.2.cmml" xref="S4.T5.10.10.8.8.m1.1.2.2">10</cn><csymbol cd="latexml" id="S4.T5.10.10.8.8.m1.1.2.3.cmml" xref="S4.T5.10.10.8.8.m1.1.2.3">decibel</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.10.8.8.m1.1c">10$\mathrm{dB}$</annotation></semantics></math></td>
<td id="S4.T5.10.10.8.11" class="ltx_td ltx_align_center ltx_border_tt" style="padding:1pt 4.0pt;">average</td>
</tr>
<tr id="S4.T5.20.20.18" class="ltx_tr">
<th id="S4.T5.20.20.18.11" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:1pt 4.0pt;">original ASC</th>
<th id="S4.T5.11.11.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.11.11.9.1.m1.1" class="ltx_Math" alttext="77.81" display="inline"><semantics id="S4.T5.11.11.9.1.m1.1a"><mn id="S4.T5.11.11.9.1.m1.1.1" xref="S4.T5.11.11.9.1.m1.1.1.cmml">77.81</mn><annotation-xml encoding="MathML-Content" id="S4.T5.11.11.9.1.m1.1b"><cn type="float" id="S4.T5.11.11.9.1.m1.1.1.cmml" xref="S4.T5.11.11.9.1.m1.1.1">77.81</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.11.11.9.1.m1.1c">77.81</annotation></semantics></math></th>
<td id="S4.T5.12.12.10.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.12.12.10.2.m1.1" class="ltx_Math" alttext="75.45" display="inline"><semantics id="S4.T5.12.12.10.2.m1.1a"><mn id="S4.T5.12.12.10.2.m1.1.1" xref="S4.T5.12.12.10.2.m1.1.1.cmml">75.45</mn><annotation-xml encoding="MathML-Content" id="S4.T5.12.12.10.2.m1.1b"><cn type="float" id="S4.T5.12.12.10.2.m1.1.1.cmml" xref="S4.T5.12.12.10.2.m1.1.1">75.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.12.12.10.2.m1.1c">75.45</annotation></semantics></math></td>
<td id="S4.T5.13.13.11.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.13.13.11.3.m1.1" class="ltx_Math" alttext="72.92" display="inline"><semantics id="S4.T5.13.13.11.3.m1.1a"><mn id="S4.T5.13.13.11.3.m1.1.1" xref="S4.T5.13.13.11.3.m1.1.1.cmml">72.92</mn><annotation-xml encoding="MathML-Content" id="S4.T5.13.13.11.3.m1.1b"><cn type="float" id="S4.T5.13.13.11.3.m1.1.1.cmml" xref="S4.T5.13.13.11.3.m1.1.1">72.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.13.13.11.3.m1.1c">72.92</annotation></semantics></math></td>
<td id="S4.T5.14.14.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.14.14.12.4.m1.1" class="ltx_Math" alttext="69.05" display="inline"><semantics id="S4.T5.14.14.12.4.m1.1a"><mn id="S4.T5.14.14.12.4.m1.1.1" xref="S4.T5.14.14.12.4.m1.1.1.cmml">69.05</mn><annotation-xml encoding="MathML-Content" id="S4.T5.14.14.12.4.m1.1b"><cn type="float" id="S4.T5.14.14.12.4.m1.1.1.cmml" xref="S4.T5.14.14.12.4.m1.1.1">69.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.14.14.12.4.m1.1c">69.05</annotation></semantics></math></td>
<td id="S4.T5.15.15.13.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.15.15.13.5.m1.1" class="ltx_Math" alttext="65.02" display="inline"><semantics id="S4.T5.15.15.13.5.m1.1a"><mn id="S4.T5.15.15.13.5.m1.1.1" xref="S4.T5.15.15.13.5.m1.1.1.cmml">65.02</mn><annotation-xml encoding="MathML-Content" id="S4.T5.15.15.13.5.m1.1b"><cn type="float" id="S4.T5.15.15.13.5.m1.1.1.cmml" xref="S4.T5.15.15.13.5.m1.1.1">65.02</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.15.15.13.5.m1.1c">65.02</annotation></semantics></math></td>
<td id="S4.T5.16.16.14.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.16.16.14.6.m1.1" class="ltx_Math" alttext="60.14" display="inline"><semantics id="S4.T5.16.16.14.6.m1.1a"><mn id="S4.T5.16.16.14.6.m1.1.1" xref="S4.T5.16.16.14.6.m1.1.1.cmml">60.14</mn><annotation-xml encoding="MathML-Content" id="S4.T5.16.16.14.6.m1.1b"><cn type="float" id="S4.T5.16.16.14.6.m1.1.1.cmml" xref="S4.T5.16.16.14.6.m1.1.1">60.14</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.16.16.14.6.m1.1c">60.14</annotation></semantics></math></td>
<td id="S4.T5.17.17.15.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.17.17.15.7.m1.1" class="ltx_Math" alttext="51.19" display="inline"><semantics id="S4.T5.17.17.15.7.m1.1a"><mn id="S4.T5.17.17.15.7.m1.1.1" xref="S4.T5.17.17.15.7.m1.1.1.cmml">51.19</mn><annotation-xml encoding="MathML-Content" id="S4.T5.17.17.15.7.m1.1b"><cn type="float" id="S4.T5.17.17.15.7.m1.1.1.cmml" xref="S4.T5.17.17.15.7.m1.1.1">51.19</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.17.17.15.7.m1.1c">51.19</annotation></semantics></math></td>
<td id="S4.T5.18.18.16.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.18.18.16.8.m1.1" class="ltx_Math" alttext="39.12" display="inline"><semantics id="S4.T5.18.18.16.8.m1.1a"><mn id="S4.T5.18.18.16.8.m1.1.1" xref="S4.T5.18.18.16.8.m1.1.1.cmml">39.12</mn><annotation-xml encoding="MathML-Content" id="S4.T5.18.18.16.8.m1.1b"><cn type="float" id="S4.T5.18.18.16.8.m1.1.1.cmml" xref="S4.T5.18.18.16.8.m1.1.1">39.12</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.18.18.16.8.m1.1c">39.12</annotation></semantics></math></td>
<td id="S4.T5.19.19.17.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.19.19.17.9.m1.1" class="ltx_Math" alttext="26.91" display="inline"><semantics id="S4.T5.19.19.17.9.m1.1a"><mn id="S4.T5.19.19.17.9.m1.1.1" xref="S4.T5.19.19.17.9.m1.1.1.cmml">26.91</mn><annotation-xml encoding="MathML-Content" id="S4.T5.19.19.17.9.m1.1b"><cn type="float" id="S4.T5.19.19.17.9.m1.1.1.cmml" xref="S4.T5.19.19.17.9.m1.1.1">26.91</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.19.19.17.9.m1.1c">26.91</annotation></semantics></math></td>
<td id="S4.T5.20.20.18.10" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.20.20.18.10.m1.1" class="ltx_Math" alttext="57.48" display="inline"><semantics id="S4.T5.20.20.18.10.m1.1a"><mn id="S4.T5.20.20.18.10.m1.1.1" xref="S4.T5.20.20.18.10.m1.1.1.cmml">57.48</mn><annotation-xml encoding="MathML-Content" id="S4.T5.20.20.18.10.m1.1b"><cn type="float" id="S4.T5.20.20.18.10.m1.1.1.cmml" xref="S4.T5.20.20.18.10.m1.1.1">57.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.20.20.18.10.m1.1c">57.48</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.29.29.27" class="ltx_tr">
<th id="S4.T5.29.29.27.10" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 4.0pt;">DA</th>
<th id="S4.T5.29.29.27.11" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding:1pt 4.0pt;">-</th>
<td id="S4.T5.21.21.19.1" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.21.21.19.1.m1.1" class="ltx_Math" alttext="70.51" display="inline"><semantics id="S4.T5.21.21.19.1.m1.1a"><mn id="S4.T5.21.21.19.1.m1.1.1" xref="S4.T5.21.21.19.1.m1.1.1.cmml">70.51</mn><annotation-xml encoding="MathML-Content" id="S4.T5.21.21.19.1.m1.1b"><cn type="float" id="S4.T5.21.21.19.1.m1.1.1.cmml" xref="S4.T5.21.21.19.1.m1.1.1">70.51</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.21.21.19.1.m1.1c">70.51</annotation></semantics></math></td>
<td id="S4.T5.22.22.20.2" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.22.22.20.2.m1.1" class="ltx_Math" alttext="71.44" display="inline"><semantics id="S4.T5.22.22.20.2.m1.1a"><mn id="S4.T5.22.22.20.2.m1.1.1" xref="S4.T5.22.22.20.2.m1.1.1.cmml">71.44</mn><annotation-xml encoding="MathML-Content" id="S4.T5.22.22.20.2.m1.1b"><cn type="float" id="S4.T5.22.22.20.2.m1.1.1.cmml" xref="S4.T5.22.22.20.2.m1.1.1">71.44</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.22.22.20.2.m1.1c">71.44</annotation></semantics></math></td>
<td id="S4.T5.23.23.21.3" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.23.23.21.3.m1.1" class="ltx_Math" alttext="71.50" display="inline"><semantics id="S4.T5.23.23.21.3.m1.1a"><mn id="S4.T5.23.23.21.3.m1.1.1" xref="S4.T5.23.23.21.3.m1.1.1.cmml">71.50</mn><annotation-xml encoding="MathML-Content" id="S4.T5.23.23.21.3.m1.1b"><cn type="float" id="S4.T5.23.23.21.3.m1.1.1.cmml" xref="S4.T5.23.23.21.3.m1.1.1">71.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.23.23.21.3.m1.1c">71.50</annotation></semantics></math></td>
<td id="S4.T5.24.24.22.4" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.24.24.22.4.m1.1" class="ltx_Math" alttext="70.84" display="inline"><semantics id="S4.T5.24.24.22.4.m1.1a"><mn id="S4.T5.24.24.22.4.m1.1.1" xref="S4.T5.24.24.22.4.m1.1.1.cmml">70.84</mn><annotation-xml encoding="MathML-Content" id="S4.T5.24.24.22.4.m1.1b"><cn type="float" id="S4.T5.24.24.22.4.m1.1.1.cmml" xref="S4.T5.24.24.22.4.m1.1.1">70.84</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.24.24.22.4.m1.1c">70.84</annotation></semantics></math></td>
<td id="S4.T5.25.25.23.5" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.25.25.23.5.m1.1" class="ltx_Math" alttext="69.08" display="inline"><semantics id="S4.T5.25.25.23.5.m1.1a"><mn id="S4.T5.25.25.23.5.m1.1.1" xref="S4.T5.25.25.23.5.m1.1.1.cmml">69.08</mn><annotation-xml encoding="MathML-Content" id="S4.T5.25.25.23.5.m1.1b"><cn type="float" id="S4.T5.25.25.23.5.m1.1.1.cmml" xref="S4.T5.25.25.23.5.m1.1.1">69.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.25.25.23.5.m1.1c">69.08</annotation></semantics></math></td>
<td id="S4.T5.26.26.24.6" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.26.26.24.6.m1.1" class="ltx_Math" alttext="68.86" display="inline"><semantics id="S4.T5.26.26.24.6.m1.1a"><mn id="S4.T5.26.26.24.6.m1.1.1" xref="S4.T5.26.26.24.6.m1.1.1.cmml">68.86</mn><annotation-xml encoding="MathML-Content" id="S4.T5.26.26.24.6.m1.1b"><cn type="float" id="S4.T5.26.26.24.6.m1.1.1.cmml" xref="S4.T5.26.26.24.6.m1.1.1">68.86</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.26.26.24.6.m1.1c">68.86</annotation></semantics></math></td>
<td id="S4.T5.27.27.25.7" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.27.27.25.7.m1.1" class="ltx_Math" alttext="63.73" display="inline"><semantics id="S4.T5.27.27.25.7.m1.1a"><mn id="S4.T5.27.27.25.7.m1.1.1" xref="S4.T5.27.27.25.7.m1.1.1.cmml">63.73</mn><annotation-xml encoding="MathML-Content" id="S4.T5.27.27.25.7.m1.1b"><cn type="float" id="S4.T5.27.27.25.7.m1.1.1.cmml" xref="S4.T5.27.27.25.7.m1.1.1">63.73</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.27.27.25.7.m1.1c">63.73</annotation></semantics></math></td>
<td id="S4.T5.28.28.26.8" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.28.28.26.8.m1.1" class="ltx_Math" alttext="59.31" display="inline"><semantics id="S4.T5.28.28.26.8.m1.1a"><mn id="S4.T5.28.28.26.8.m1.1.1" xref="S4.T5.28.28.26.8.m1.1.1.cmml">59.31</mn><annotation-xml encoding="MathML-Content" id="S4.T5.28.28.26.8.m1.1b"><cn type="float" id="S4.T5.28.28.26.8.m1.1.1.cmml" xref="S4.T5.28.28.26.8.m1.1.1">59.31</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.28.28.26.8.m1.1c">59.31</annotation></semantics></math></td>
<td id="S4.T5.29.29.27.9" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.29.29.27.9.m1.1" class="ltx_Math" alttext="68.16" display="inline"><semantics id="S4.T5.29.29.27.9.m1.1a"><mn id="S4.T5.29.29.27.9.m1.1.1" xref="S4.T5.29.29.27.9.m1.1.1.cmml">68.16</mn><annotation-xml encoding="MathML-Content" id="S4.T5.29.29.27.9.m1.1b"><cn type="float" id="S4.T5.29.29.27.9.m1.1.1.cmml" xref="S4.T5.29.29.27.9.m1.1.1">68.16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.29.29.27.9.m1.1c">68.16</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.38.38.36" class="ltx_tr">
<th id="S4.T5.38.38.36.10" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 4.0pt;">Cold Cascade</th>
<th id="S4.T5.38.38.36.11" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding:1pt 4.0pt;">-</th>
<td id="S4.T5.30.30.28.1" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.30.30.28.1.m1.1" class="ltx_Math" alttext="73.83" display="inline"><semantics id="S4.T5.30.30.28.1.m1.1a"><mn id="S4.T5.30.30.28.1.m1.1.1" xref="S4.T5.30.30.28.1.m1.1.1.cmml">73.83</mn><annotation-xml encoding="MathML-Content" id="S4.T5.30.30.28.1.m1.1b"><cn type="float" id="S4.T5.30.30.28.1.m1.1.1.cmml" xref="S4.T5.30.30.28.1.m1.1.1">73.83</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.30.30.28.1.m1.1c">73.83</annotation></semantics></math></td>
<td id="S4.T5.31.31.29.2" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.31.31.29.2.m1.1" class="ltx_Math" alttext="73.11" display="inline"><semantics id="S4.T5.31.31.29.2.m1.1a"><mn id="S4.T5.31.31.29.2.m1.1.1" xref="S4.T5.31.31.29.2.m1.1.1.cmml">73.11</mn><annotation-xml encoding="MathML-Content" id="S4.T5.31.31.29.2.m1.1b"><cn type="float" id="S4.T5.31.31.29.2.m1.1.1.cmml" xref="S4.T5.31.31.29.2.m1.1.1">73.11</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.31.31.29.2.m1.1c">73.11</annotation></semantics></math></td>
<td id="S4.T5.32.32.30.3" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.32.32.30.3.m1.1" class="ltx_Math" alttext="71.14" display="inline"><semantics id="S4.T5.32.32.30.3.m1.1a"><mn id="S4.T5.32.32.30.3.m1.1.1" xref="S4.T5.32.32.30.3.m1.1.1.cmml">71.14</mn><annotation-xml encoding="MathML-Content" id="S4.T5.32.32.30.3.m1.1b"><cn type="float" id="S4.T5.32.32.30.3.m1.1.1.cmml" xref="S4.T5.32.32.30.3.m1.1.1">71.14</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.32.32.30.3.m1.1c">71.14</annotation></semantics></math></td>
<td id="S4.T5.33.33.31.4" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.33.33.31.4.m1.1" class="ltx_Math" alttext="67.60" display="inline"><semantics id="S4.T5.33.33.31.4.m1.1a"><mn id="S4.T5.33.33.31.4.m1.1.1" xref="S4.T5.33.33.31.4.m1.1.1.cmml">67.60</mn><annotation-xml encoding="MathML-Content" id="S4.T5.33.33.31.4.m1.1b"><cn type="float" id="S4.T5.33.33.31.4.m1.1.1.cmml" xref="S4.T5.33.33.31.4.m1.1.1">67.60</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.33.33.31.4.m1.1c">67.60</annotation></semantics></math></td>
<td id="S4.T5.34.34.32.5" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.34.34.32.5.m1.1" class="ltx_Math" alttext="62.58" display="inline"><semantics id="S4.T5.34.34.32.5.m1.1a"><mn id="S4.T5.34.34.32.5.m1.1.1" xref="S4.T5.34.34.32.5.m1.1.1.cmml">62.58</mn><annotation-xml encoding="MathML-Content" id="S4.T5.34.34.32.5.m1.1b"><cn type="float" id="S4.T5.34.34.32.5.m1.1.1.cmml" xref="S4.T5.34.34.32.5.m1.1.1">62.58</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.34.34.32.5.m1.1c">62.58</annotation></semantics></math></td>
<td id="S4.T5.35.35.33.6" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.35.35.33.6.m1.1" class="ltx_Math" alttext="56.87" display="inline"><semantics id="S4.T5.35.35.33.6.m1.1a"><mn id="S4.T5.35.35.33.6.m1.1.1" xref="S4.T5.35.35.33.6.m1.1.1.cmml">56.87</mn><annotation-xml encoding="MathML-Content" id="S4.T5.35.35.33.6.m1.1b"><cn type="float" id="S4.T5.35.35.33.6.m1.1.1.cmml" xref="S4.T5.35.35.33.6.m1.1.1">56.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.35.35.33.6.m1.1c">56.87</annotation></semantics></math></td>
<td id="S4.T5.36.36.34.7" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.36.36.34.7.m1.1" class="ltx_Math" alttext="50.53" display="inline"><semantics id="S4.T5.36.36.34.7.m1.1a"><mn id="S4.T5.36.36.34.7.m1.1.1" xref="S4.T5.36.36.34.7.m1.1.1.cmml">50.53</mn><annotation-xml encoding="MathML-Content" id="S4.T5.36.36.34.7.m1.1b"><cn type="float" id="S4.T5.36.36.34.7.m1.1.1.cmml" xref="S4.T5.36.36.34.7.m1.1.1">50.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.36.36.34.7.m1.1c">50.53</annotation></semantics></math></td>
<td id="S4.T5.37.37.35.8" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.37.37.35.8.m1.1" class="ltx_Math" alttext="44.53" display="inline"><semantics id="S4.T5.37.37.35.8.m1.1a"><mn id="S4.T5.37.37.35.8.m1.1.1" xref="S4.T5.37.37.35.8.m1.1.1.cmml">44.53</mn><annotation-xml encoding="MathML-Content" id="S4.T5.37.37.35.8.m1.1b"><cn type="float" id="S4.T5.37.37.35.8.m1.1.1.cmml" xref="S4.T5.37.37.35.8.m1.1.1">44.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.37.37.35.8.m1.1c">44.53</annotation></semantics></math></td>
<td id="S4.T5.38.38.36.9" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.38.38.36.9.m1.1" class="ltx_Math" alttext="62.53" display="inline"><semantics id="S4.T5.38.38.36.9.m1.1a"><mn id="S4.T5.38.38.36.9.m1.1.1" xref="S4.T5.38.38.36.9.m1.1.1.cmml">62.53</mn><annotation-xml encoding="MathML-Content" id="S4.T5.38.38.36.9.m1.1b"><cn type="float" id="S4.T5.38.38.36.9.m1.1.1.cmml" xref="S4.T5.38.38.36.9.m1.1.1">62.53</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.38.38.36.9.m1.1c">62.53</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.48.48.46" class="ltx_tr">
<th id="S4.T5.48.48.46.11" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding:1pt 4.0pt;">Cold Cascade + DA</th>
<th id="S4.T5.39.39.37.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding:1pt 4.0pt;"><math id="S4.T5.39.39.37.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S4.T5.39.39.37.1.m1.1a"><mo id="S4.T5.39.39.37.1.m1.1.1" xref="S4.T5.39.39.37.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S4.T5.39.39.37.1.m1.1b"><minus id="S4.T5.39.39.37.1.m1.1.1.cmml" xref="S4.T5.39.39.37.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.39.39.37.1.m1.1c">-</annotation></semantics></math></th>
<td id="S4.T5.40.40.38.2" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.40.40.38.2.m1.1" class="ltx_Math" alttext="72.92" display="inline"><semantics id="S4.T5.40.40.38.2.m1.1a"><mn id="S4.T5.40.40.38.2.m1.1.1" xref="S4.T5.40.40.38.2.m1.1.1.cmml">72.92</mn><annotation-xml encoding="MathML-Content" id="S4.T5.40.40.38.2.m1.1b"><cn type="float" id="S4.T5.40.40.38.2.m1.1.1.cmml" xref="S4.T5.40.40.38.2.m1.1.1">72.92</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.40.40.38.2.m1.1c">72.92</annotation></semantics></math></td>
<td id="S4.T5.41.41.39.3" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.41.41.39.3.m1.1" class="ltx_Math" alttext="72.84" display="inline"><semantics id="S4.T5.41.41.39.3.m1.1a"><mn id="S4.T5.41.41.39.3.m1.1.1" xref="S4.T5.41.41.39.3.m1.1.1.cmml">72.84</mn><annotation-xml encoding="MathML-Content" id="S4.T5.41.41.39.3.m1.1b"><cn type="float" id="S4.T5.41.41.39.3.m1.1.1.cmml" xref="S4.T5.41.41.39.3.m1.1.1">72.84</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.41.41.39.3.m1.1c">72.84</annotation></semantics></math></td>
<td id="S4.T5.42.42.40.4" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.42.42.40.4.m1.1" class="ltx_Math" alttext="72.65" display="inline"><semantics id="S4.T5.42.42.40.4.m1.1a"><mn id="S4.T5.42.42.40.4.m1.1.1" xref="S4.T5.42.42.40.4.m1.1.1.cmml">72.65</mn><annotation-xml encoding="MathML-Content" id="S4.T5.42.42.40.4.m1.1b"><cn type="float" id="S4.T5.42.42.40.4.m1.1.1.cmml" xref="S4.T5.42.42.40.4.m1.1.1">72.65</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.42.42.40.4.m1.1c">72.65</annotation></semantics></math></td>
<td id="S4.T5.43.43.41.5" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.43.43.41.5.m1.1" class="ltx_Math" alttext="71.71" display="inline"><semantics id="S4.T5.43.43.41.5.m1.1a"><mn id="S4.T5.43.43.41.5.m1.1.1" xref="S4.T5.43.43.41.5.m1.1.1.cmml">71.71</mn><annotation-xml encoding="MathML-Content" id="S4.T5.43.43.41.5.m1.1b"><cn type="float" id="S4.T5.43.43.41.5.m1.1.1.cmml" xref="S4.T5.43.43.41.5.m1.1.1">71.71</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.43.43.41.5.m1.1c">71.71</annotation></semantics></math></td>
<td id="S4.T5.44.44.42.6" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.44.44.42.6.m1.1" class="ltx_Math" alttext="69.27" display="inline"><semantics id="S4.T5.44.44.42.6.m1.1a"><mn id="S4.T5.44.44.42.6.m1.1.1" xref="S4.T5.44.44.42.6.m1.1.1.cmml">69.27</mn><annotation-xml encoding="MathML-Content" id="S4.T5.44.44.42.6.m1.1b"><cn type="float" id="S4.T5.44.44.42.6.m1.1.1.cmml" xref="S4.T5.44.44.42.6.m1.1.1">69.27</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.44.44.42.6.m1.1c">69.27</annotation></semantics></math></td>
<td id="S4.T5.45.45.43.7" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.45.45.43.7.m1.1" class="ltx_Math" alttext="63.59" display="inline"><semantics id="S4.T5.45.45.43.7.m1.1a"><mn id="S4.T5.45.45.43.7.m1.1.1" xref="S4.T5.45.45.43.7.m1.1.1.cmml">63.59</mn><annotation-xml encoding="MathML-Content" id="S4.T5.45.45.43.7.m1.1b"><cn type="float" id="S4.T5.45.45.43.7.m1.1.1.cmml" xref="S4.T5.45.45.43.7.m1.1.1">63.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.45.45.43.7.m1.1c">63.59</annotation></semantics></math></td>
<td id="S4.T5.46.46.44.8" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.46.46.44.8.m1.1" class="ltx_Math" alttext="60.16" display="inline"><semantics id="S4.T5.46.46.44.8.m1.1a"><mn id="S4.T5.46.46.44.8.m1.1.1" xref="S4.T5.46.46.44.8.m1.1.1.cmml">60.16</mn><annotation-xml encoding="MathML-Content" id="S4.T5.46.46.44.8.m1.1b"><cn type="float" id="S4.T5.46.46.44.8.m1.1.1.cmml" xref="S4.T5.46.46.44.8.m1.1.1">60.16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.46.46.44.8.m1.1c">60.16</annotation></semantics></math></td>
<td id="S4.T5.47.47.45.9" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.47.47.45.9.m1.1" class="ltx_Math" alttext="59.23" display="inline"><semantics id="S4.T5.47.47.45.9.m1.1a"><mn id="S4.T5.47.47.45.9.m1.1.1" xref="S4.T5.47.47.45.9.m1.1.1.cmml">59.23</mn><annotation-xml encoding="MathML-Content" id="S4.T5.47.47.45.9.m1.1b"><cn type="float" id="S4.T5.47.47.45.9.m1.1.1.cmml" xref="S4.T5.47.47.45.9.m1.1.1">59.23</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.47.47.45.9.m1.1c">59.23</annotation></semantics></math></td>
<td id="S4.T5.48.48.46.10" class="ltx_td ltx_align_center" style="padding:1pt 4.0pt;"><math id="S4.T5.48.48.46.10.m1.1" class="ltx_Math" alttext="67.80" display="inline"><semantics id="S4.T5.48.48.46.10.m1.1a"><mn id="S4.T5.48.48.46.10.m1.1.1" xref="S4.T5.48.48.46.10.m1.1.1.cmml">67.80</mn><annotation-xml encoding="MathML-Content" id="S4.T5.48.48.46.10.m1.1b"><cn type="float" id="S4.T5.48.48.46.10.m1.1.1.cmml" xref="S4.T5.48.48.46.10.m1.1.1">67.80</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.48.48.46.10.m1.1c">67.80</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.57.57.55" class="ltx_tr">
<th id="S4.T5.57.57.55.10" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:1pt 4.0pt;"><span id="S4.T5.57.57.55.10.1" class="ltx_text ltx_font_bold">MTL</span></th>
<th id="S4.T5.57.57.55.11" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding:1pt 4.0pt;">-</th>
<td id="S4.T5.49.49.47.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><span id="S4.T5.49.49.47.1.1" class="ltx_text ltx_markedasmath ltx_font_bold">74.31</span></td>
<td id="S4.T5.50.50.48.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><span id="S4.T5.50.50.48.2.1" class="ltx_text ltx_markedasmath ltx_font_bold">73.97</span></td>
<td id="S4.T5.51.51.49.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.51.51.49.3.m1.1" class="ltx_Math" alttext="73.01" display="inline"><semantics id="S4.T5.51.51.49.3.m1.1a"><mn id="S4.T5.51.51.49.3.m1.1.1" xref="S4.T5.51.51.49.3.m1.1.1.cmml">73.01</mn><annotation-xml encoding="MathML-Content" id="S4.T5.51.51.49.3.m1.1b"><cn type="float" id="S4.T5.51.51.49.3.m1.1.1.cmml" xref="S4.T5.51.51.49.3.m1.1.1">73.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.51.51.49.3.m1.1c">73.01</annotation></semantics></math></td>
<td id="S4.T5.52.52.50.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.52.52.50.4.m1.1" class="ltx_Math" alttext="72.48" display="inline"><semantics id="S4.T5.52.52.50.4.m1.1a"><mn id="S4.T5.52.52.50.4.m1.1.1" xref="S4.T5.52.52.50.4.m1.1.1.cmml">72.48</mn><annotation-xml encoding="MathML-Content" id="S4.T5.52.52.50.4.m1.1b"><cn type="float" id="S4.T5.52.52.50.4.m1.1.1.cmml" xref="S4.T5.52.52.50.4.m1.1.1">72.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.52.52.50.4.m1.1c">72.48</annotation></semantics></math></td>
<td id="S4.T5.53.53.51.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.53.53.51.5.m1.1" class="ltx_Math" alttext="71.52" display="inline"><semantics id="S4.T5.53.53.51.5.m1.1a"><mn id="S4.T5.53.53.51.5.m1.1.1" xref="S4.T5.53.53.51.5.m1.1.1.cmml">71.52</mn><annotation-xml encoding="MathML-Content" id="S4.T5.53.53.51.5.m1.1b"><cn type="float" id="S4.T5.53.53.51.5.m1.1.1.cmml" xref="S4.T5.53.53.51.5.m1.1.1">71.52</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.53.53.51.5.m1.1c">71.52</annotation></semantics></math></td>
<td id="S4.T5.54.54.52.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.54.54.52.6.m1.1" class="ltx_Math" alttext="70.10" display="inline"><semantics id="S4.T5.54.54.52.6.m1.1a"><mn id="S4.T5.54.54.52.6.m1.1.1" xref="S4.T5.54.54.52.6.m1.1.1.cmml">70.10</mn><annotation-xml encoding="MathML-Content" id="S4.T5.54.54.52.6.m1.1b"><cn type="float" id="S4.T5.54.54.52.6.m1.1.1.cmml" xref="S4.T5.54.54.52.6.m1.1.1">70.10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.54.54.52.6.m1.1c">70.10</annotation></semantics></math></td>
<td id="S4.T5.55.55.53.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.55.55.53.7.m1.1" class="ltx_Math" alttext="65.79" display="inline"><semantics id="S4.T5.55.55.53.7.m1.1a"><mn id="S4.T5.55.55.53.7.m1.1.1" xref="S4.T5.55.55.53.7.m1.1.1.cmml">65.79</mn><annotation-xml encoding="MathML-Content" id="S4.T5.55.55.53.7.m1.1b"><cn type="float" id="S4.T5.55.55.53.7.m1.1.1.cmml" xref="S4.T5.55.55.53.7.m1.1.1">65.79</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.55.55.53.7.m1.1c">65.79</annotation></semantics></math></td>
<td id="S4.T5.56.56.54.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.56.56.54.8.m1.1" class="ltx_Math" alttext="61.34" display="inline"><semantics id="S4.T5.56.56.54.8.m1.1a"><mn id="S4.T5.56.56.54.8.m1.1.1" xref="S4.T5.56.56.54.8.m1.1.1.cmml">61.34</mn><annotation-xml encoding="MathML-Content" id="S4.T5.56.56.54.8.m1.1b"><cn type="float" id="S4.T5.56.56.54.8.m1.1.1.cmml" xref="S4.T5.56.56.54.8.m1.1.1">61.34</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.56.56.54.8.m1.1c">61.34</annotation></semantics></math></td>
<td id="S4.T5.57.57.55.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:1pt 4.0pt;"><math id="S4.T5.57.57.55.9.m1.1" class="ltx_Math" alttext="70.32" display="inline"><semantics id="S4.T5.57.57.55.9.m1.1a"><mn id="S4.T5.57.57.55.9.m1.1.1" xref="S4.T5.57.57.55.9.m1.1.1.cmml">70.32</mn><annotation-xml encoding="MathML-Content" id="S4.T5.57.57.55.9.m1.1b"><cn type="float" id="S4.T5.57.57.55.9.m1.1.1.cmml" xref="S4.T5.57.57.55.9.m1.1.1">70.32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.57.57.55.9.m1.1c">70.32</annotation></semantics></math></td>
</tr>
<tr id="S4.T5.66.66.64" class="ltx_tr">
<th id="S4.T5.66.66.64.10" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding:1pt 4.0pt;"><span id="S4.T5.66.66.64.10.1" class="ltx_text ltx_font_bold">iterative optimisation</span></th>
<th id="S4.T5.66.66.64.11" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" style="padding:1pt 4.0pt;">-</th>
<td id="S4.T5.58.58.56.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><math id="S4.T5.58.58.56.1.m1.1" class="ltx_Math" alttext="74.26" display="inline"><semantics id="S4.T5.58.58.56.1.m1.1a"><mn id="S4.T5.58.58.56.1.m1.1.1" xref="S4.T5.58.58.56.1.m1.1.1.cmml">74.26</mn><annotation-xml encoding="MathML-Content" id="S4.T5.58.58.56.1.m1.1b"><cn type="float" id="S4.T5.58.58.56.1.m1.1.1.cmml" xref="S4.T5.58.58.56.1.m1.1.1">74.26</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.58.58.56.1.m1.1c">74.26</annotation></semantics></math></td>
<td id="S4.T5.59.59.57.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><math id="S4.T5.59.59.57.2.m1.1" class="ltx_Math" alttext="73.50" display="inline"><semantics id="S4.T5.59.59.57.2.m1.1a"><mn id="S4.T5.59.59.57.2.m1.1.1" xref="S4.T5.59.59.57.2.m1.1.1.cmml">73.50</mn><annotation-xml encoding="MathML-Content" id="S4.T5.59.59.57.2.m1.1b"><cn type="float" id="S4.T5.59.59.57.2.m1.1.1.cmml" xref="S4.T5.59.59.57.2.m1.1.1">73.50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.59.59.57.2.m1.1c">73.50</annotation></semantics></math></td>
<td id="S4.T5.60.60.58.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><span id="S4.T5.60.60.58.3.1" class="ltx_text ltx_markedasmath ltx_font_bold">73.12</span></td>
<td id="S4.T5.61.61.59.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><span id="S4.T5.61.61.59.4.1" class="ltx_text ltx_markedasmath ltx_font_bold">72.71</span></td>
<td id="S4.T5.62.62.60.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><span id="S4.T5.62.62.60.5.1" class="ltx_text ltx_markedasmath ltx_font_bold">72.09</span></td>
<td id="S4.T5.63.63.61.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><span id="S4.T5.63.63.61.6.1" class="ltx_text ltx_markedasmath ltx_font_bold">71.43</span></td>
<td id="S4.T5.64.64.62.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><span id="S4.T5.64.64.62.7.1" class="ltx_text ltx_markedasmath ltx_font_bold">66.81</span></td>
<td id="S4.T5.65.65.63.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><span id="S4.T5.65.65.63.8.1" class="ltx_text ltx_markedasmath ltx_font_bold">63.19</span></td>
<td id="S4.T5.66.66.64.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding:1pt 4.0pt;"><span id="S4.T5.66.66.64.9.1" class="ltx_text ltx_markedasmath ltx_font_bold">70.89</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection ltx_indent_first">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Downstream Task IV: Acoustic Scene Classification</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">To test our approach on the final task, acoustic scene classification, we use the <span title="" class="ltx_glossaryref">DCASE</span> 2021 Challenge dataset <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib56" title="" class="ltx_ref">2021</a>)</cite>.
To create the noisy scene audio, speech samples from LibriSpeech are added to the soundscape recordings from the <span title="" class="ltx_glossaryref">DCASE</span> 2021 challenge.
The range of <span title="" class="ltx_glossaryref">SNRs</span> is enlarged to -25, -20, -15, -10, -5, 0, 5, and 10 <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="\mathrm{dB}" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mi class="ltx_unit" id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">dB</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">decibel</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\mathrm{dB}</annotation></semantics></math>, covering a wide range of real-life conditions.
We note that in computing <span title="" class="ltx_glossaryref">SNR</span>, we still consider <em id="S4.SS4.p1.1.1" class="ltx_emph ltx_font_italic">speech</em> as the ‘signal’ and <em id="S4.SS4.p1.1.2" class="ltx_emph ltx_font_italic">scene</em> as the ‘noise’, to be consistent with other literature.
So a lower <span title="" class="ltx_glossaryref">SNR</span> means that the scene is dominating the soundscape, while a higher <span title="" class="ltx_glossaryref">SNR</span> means that the speech interference is greater.
Since the test data is balanced, we can use the standard classification accuracy as the evaluation metric, similar to the DCASE challenge.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.2" class="ltx_p">Results are shown in <a href="#S4.T5" title="In 4.3 Downstream Task III: Speech Emotion Recognition ‣ 4 Experimental Results ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">5</span></a>.
Training and testing our <span title="" class="ltx_glossaryref">ASC</span> model on the original recordings leads to a classification accuracy of <math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="77.81\%" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mrow id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml"><mn id="S4.SS4.p2.1.m1.1.1.2" xref="S4.SS4.p2.1.m1.1.1.2.cmml">77.81</mn><mo id="S4.SS4.p2.1.m1.1.1.1" xref="S4.SS4.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><apply id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p2.1.m1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.1.m1.1.1.2.cmml" xref="S4.SS4.p2.1.m1.1.1.2">77.81</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">77.81\%</annotation></semantics></math>.
Increasing the interference caused by speech leads to severe degradation of performance with an average accuracy of <math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="57.48\%" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mrow id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml"><mn id="S4.SS4.p2.2.m2.1.1.2" xref="S4.SS4.p2.2.m2.1.1.2.cmml">57.48</mn><mo id="S4.SS4.p2.2.m2.1.1.1" xref="S4.SS4.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><apply id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS4.p2.2.m2.1.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.2.m2.1.1.2.cmml" xref="S4.SS4.p2.2.m2.1.1.2">57.48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">57.48\%</annotation></semantics></math> over all SNR values, as was the case for all other tasks when increasing noise levels.
This illustrates why the <span title="" class="ltx_glossaryref">ASC</span> task would also benefit from a denoising component.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.6" class="ltx_p">Overall, our joint optimisation approaches yield higher average accuracies over all <span title="" class="ltx_glossaryref">SNRs</span>, with <math id="S4.SS4.p3.1.m1.1" class="ltx_Math" alttext="70.89\,\%" display="inline"><semantics id="S4.SS4.p3.1.m1.1a"><mrow id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml"><mn id="S4.SS4.p3.1.m1.1.1.2" xref="S4.SS4.p3.1.m1.1.1.2.cmml">70.89</mn><mo lspace="0.170em" id="S4.SS4.p3.1.m1.1.1.1" xref="S4.SS4.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><apply id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p3.1.m1.1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.1.m1.1.1.2.cmml" xref="S4.SS4.p3.1.m1.1.1.2">70.89</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">70.89\,\%</annotation></semantics></math> and <math id="S4.SS4.p3.2.m2.1" class="ltx_Math" alttext="70.32\,\%" display="inline"><semantics id="S4.SS4.p3.2.m2.1a"><mrow id="S4.SS4.p3.2.m2.1.1" xref="S4.SS4.p3.2.m2.1.1.cmml"><mn id="S4.SS4.p3.2.m2.1.1.2" xref="S4.SS4.p3.2.m2.1.1.2.cmml">70.32</mn><mo lspace="0.170em" id="S4.SS4.p3.2.m2.1.1.1" xref="S4.SS4.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.m2.1b"><apply id="S4.SS4.p3.2.m2.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1"><csymbol cd="latexml" id="S4.SS4.p3.2.m2.1.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.2.m2.1.1.2.cmml" xref="S4.SS4.p3.2.m2.1.1.2">70.32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.m2.1c">70.32\,\%</annotation></semantics></math> over the best-performing baseline of <math id="S4.SS4.p3.3.m3.1" class="ltx_Math" alttext="68.16\,\%" display="inline"><semantics id="S4.SS4.p3.3.m3.1a"><mrow id="S4.SS4.p3.3.m3.1.1" xref="S4.SS4.p3.3.m3.1.1.cmml"><mn id="S4.SS4.p3.3.m3.1.1.2" xref="S4.SS4.p3.3.m3.1.1.2.cmml">68.16</mn><mo lspace="0.170em" id="S4.SS4.p3.3.m3.1.1.1" xref="S4.SS4.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.3.m3.1b"><apply id="S4.SS4.p3.3.m3.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1"><csymbol cd="latexml" id="S4.SS4.p3.3.m3.1.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.3.m3.1.1.2.cmml" xref="S4.SS4.p3.3.m3.1.1.2">68.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.3.m3.1c">68.16\,\%</annotation></semantics></math>, respectively.
Our iterative optimisation is particularly suited to the high <span title="" class="ltx_glossaryref">SNR</span> conditions, where speech dominates the soundscape, and its accuracy <math id="S4.SS4.p3.4.m4.1" class="ltx_Math" alttext="63.19\,\%" display="inline"><semantics id="S4.SS4.p3.4.m4.1a"><mrow id="S4.SS4.p3.4.m4.1.1" xref="S4.SS4.p3.4.m4.1.1.cmml"><mn id="S4.SS4.p3.4.m4.1.1.2" xref="S4.SS4.p3.4.m4.1.1.2.cmml">63.19</mn><mo lspace="0.170em" id="S4.SS4.p3.4.m4.1.1.1" xref="S4.SS4.p3.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.4.m4.1b"><apply id="S4.SS4.p3.4.m4.1.1.cmml" xref="S4.SS4.p3.4.m4.1.1"><csymbol cd="latexml" id="S4.SS4.p3.4.m4.1.1.1.cmml" xref="S4.SS4.p3.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.4.m4.1.1.2.cmml" xref="S4.SS4.p3.4.m4.1.1.2">63.19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.4.m4.1c">63.19\,\%</annotation></semantics></math> clealry surpasses that of our MTL method (<math id="S4.SS4.p3.5.m5.1" class="ltx_Math" alttext="61.34\,\%" display="inline"><semantics id="S4.SS4.p3.5.m5.1a"><mrow id="S4.SS4.p3.5.m5.1.1" xref="S4.SS4.p3.5.m5.1.1.cmml"><mn id="S4.SS4.p3.5.m5.1.1.2" xref="S4.SS4.p3.5.m5.1.1.2.cmml">61.34</mn><mo lspace="0.170em" id="S4.SS4.p3.5.m5.1.1.1" xref="S4.SS4.p3.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.5.m5.1b"><apply id="S4.SS4.p3.5.m5.1.1.cmml" xref="S4.SS4.p3.5.m5.1.1"><csymbol cd="latexml" id="S4.SS4.p3.5.m5.1.1.1.cmml" xref="S4.SS4.p3.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.5.m5.1.1.2.cmml" xref="S4.SS4.p3.5.m5.1.1.2">61.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.5.m5.1c">61.34\,\%</annotation></semantics></math>).
In most other cases, our optimisation approaches are near equivalent, while consistently outperforming all baselines.
We note that in this case, the baseline deteriorates to near chance-level performance, with <math id="S4.SS4.p3.6.m6.1" class="ltx_Math" alttext="26.91\,\%" display="inline"><semantics id="S4.SS4.p3.6.m6.1a"><mrow id="S4.SS4.p3.6.m6.1.1" xref="S4.SS4.p3.6.m6.1.1.cmml"><mn id="S4.SS4.p3.6.m6.1.1.2" xref="S4.SS4.p3.6.m6.1.1.2.cmml">26.91</mn><mo lspace="0.170em" id="S4.SS4.p3.6.m6.1.1.1" xref="S4.SS4.p3.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.6.m6.1b"><apply id="S4.SS4.p3.6.m6.1.1.cmml" xref="S4.SS4.p3.6.m6.1.1"><csymbol cd="latexml" id="S4.SS4.p3.6.m6.1.1.1.cmml" xref="S4.SS4.p3.6.m6.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.6.m6.1.1.2.cmml" xref="S4.SS4.p3.6.m6.1.1.2">26.91</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.6.m6.1c">26.91\,\%</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Collectively, our results on four different application domains show that the proposed methods consistently outperform comparable baselines.
In particular, joint training, either in the form of MTL or in the form of iterative optimisation, yields better results than methods relying on data augmentation or cascade enhancement, which are standard baselines in the field.
This demonstrates that adapting an enhancement model to the downstream task can bring substantial improvements, which underlines the need for specialised <span title="" class="ltx_glossaryref">AE</span> systems that are able to differentiate between the task-specific relevancy of audio signals and noise sources.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">This aspect becomes even more apparent when comparing the audio enhancement output of the two tasks ASR and ASC depicted in Fig. <a href="#S5.F4" title="Figure 4 ‣ 5 Discussion ‣ Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. For the ASC task (upper row) the clean audio can be described as background music with relatively stable frequency patterns over time. To construct the noisy sample, this is overlayed with a speech sample, which visually interrupts the smoothness of the background music. The AE module trained for ASC is thus capable of removing the disruptive speech signal and reconstructing the original target with only a few artefacts. In the bottom row, the clean sample is a speech sample, without any audible background noise. The spectrogram is thus characterised by an irregular frequency distribution –due to pauses and a change of frequencies between phonemes– over a dark (quiet) background. After adding noise from a construction site, the frequency patterns of the speech samples stand out to a lesser degree from the stable background noise. The AE component trained on the ASR however is able to reconstruct the distinctiveness of the speech sample by suppressing the noise frequencies.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2408.06264/assets/x9.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="333" height="177" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.3.1.1" class="ltx_text" style="font-size:80%;">Fig.​​ 4</span>: </span><span id="S5.F4.4.2" class="ltx_text" style="font-size:90%;">Spectrograms for visualisation of audio enhancement samples. The left column displays the clean target samples, the middle column contains the artificially added noisy sample and the last column represents the reconstructed (denoised) audio. In the first row (audio scene classification) the clean sample is a sample of music and the considered noise is a speech sample, while in the second row (automatic speech recognition), the clean sample is a speech sample and the noise originates from a construction site.</span></figcaption>
</figure>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.5" class="ltx_p">Furthermore, our iterative optimisation is also consistently superior to MTL; it is only outperformed in very few of the high SNR conditions for speech command recognition and acoustic scene classification.
In most cases, it is able to recover a substantial percentage of the performance loss incurred by noise, even at 0 <math id="S5.p3.1.m1.1" class="ltx_Math" alttext="\mathrm{dB}" display="inline"><semantics id="S5.p3.1.m1.1a"><mi class="ltx_unit" id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">dB</mi><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><csymbol cd="latexml" id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">decibel</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">\mathrm{dB}</annotation></semantics></math>: <math id="S5.p3.2.m2.1" class="ltx_Math" alttext="\backsim 69\,\%" display="inline"><semantics id="S5.p3.2.m2.1a"><mrow id="S5.p3.2.m2.1.1" xref="S5.p3.2.m2.1.1.cmml"><mi id="S5.p3.2.m2.1.1.2" xref="S5.p3.2.m2.1.1.2.cmml"></mi><mo id="S5.p3.2.m2.1.1.1" xref="S5.p3.2.m2.1.1.1.cmml">∽</mo><mrow id="S5.p3.2.m2.1.1.3" xref="S5.p3.2.m2.1.1.3.cmml"><mn id="S5.p3.2.m2.1.1.3.2" xref="S5.p3.2.m2.1.1.3.2.cmml">69</mn><mo lspace="0.170em" id="S5.p3.2.m2.1.1.3.1" xref="S5.p3.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.2.m2.1b"><apply id="S5.p3.2.m2.1.1.cmml" xref="S5.p3.2.m2.1.1"><ci id="S5.p3.2.m2.1.1.1.cmml" xref="S5.p3.2.m2.1.1.1">∽</ci><csymbol cd="latexml" id="S5.p3.2.m2.1.1.2.cmml" xref="S5.p3.2.m2.1.1.2">absent</csymbol><apply id="S5.p3.2.m2.1.1.3.cmml" xref="S5.p3.2.m2.1.1.3"><csymbol cd="latexml" id="S5.p3.2.m2.1.1.3.1.cmml" xref="S5.p3.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S5.p3.2.m2.1.1.3.2.cmml" xref="S5.p3.2.m2.1.1.3.2">69</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.2.m2.1c">\backsim 69\,\%</annotation></semantics></math> for SCR, <math id="S5.p3.3.m3.1" class="ltx_Math" alttext="\backsim 60\,\%" display="inline"><semantics id="S5.p3.3.m3.1a"><mrow id="S5.p3.3.m3.1.1" xref="S5.p3.3.m3.1.1.cmml"><mi id="S5.p3.3.m3.1.1.2" xref="S5.p3.3.m3.1.1.2.cmml"></mi><mo id="S5.p3.3.m3.1.1.1" xref="S5.p3.3.m3.1.1.1.cmml">∽</mo><mrow id="S5.p3.3.m3.1.1.3" xref="S5.p3.3.m3.1.1.3.cmml"><mn id="S5.p3.3.m3.1.1.3.2" xref="S5.p3.3.m3.1.1.3.2.cmml">60</mn><mo lspace="0.170em" id="S5.p3.3.m3.1.1.3.1" xref="S5.p3.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.3.m3.1b"><apply id="S5.p3.3.m3.1.1.cmml" xref="S5.p3.3.m3.1.1"><ci id="S5.p3.3.m3.1.1.1.cmml" xref="S5.p3.3.m3.1.1.1">∽</ci><csymbol cd="latexml" id="S5.p3.3.m3.1.1.2.cmml" xref="S5.p3.3.m3.1.1.2">absent</csymbol><apply id="S5.p3.3.m3.1.1.3.cmml" xref="S5.p3.3.m3.1.1.3"><csymbol cd="latexml" id="S5.p3.3.m3.1.1.3.1.cmml" xref="S5.p3.3.m3.1.1.3.1">percent</csymbol><cn type="integer" id="S5.p3.3.m3.1.1.3.2.cmml" xref="S5.p3.3.m3.1.1.3.2">60</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.3.m3.1c">\backsim 60\,\%</annotation></semantics></math> for ASR, <math id="S5.p3.4.m4.1" class="ltx_Math" alttext="\backsim\,89\%" display="inline"><semantics id="S5.p3.4.m4.1a"><mrow id="S5.p3.4.m4.1.1" xref="S5.p3.4.m4.1.1.cmml"><mi id="S5.p3.4.m4.1.1.2" xref="S5.p3.4.m4.1.1.2.cmml"></mi><mo id="S5.p3.4.m4.1.1.1" xref="S5.p3.4.m4.1.1.1.cmml">∽</mo><mrow id="S5.p3.4.m4.1.1.3" xref="S5.p3.4.m4.1.1.3.cmml"><mn id="S5.p3.4.m4.1.1.3.2" xref="S5.p3.4.m4.1.1.3.2.cmml"> 89</mn><mo id="S5.p3.4.m4.1.1.3.1" xref="S5.p3.4.m4.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.4.m4.1b"><apply id="S5.p3.4.m4.1.1.cmml" xref="S5.p3.4.m4.1.1"><ci id="S5.p3.4.m4.1.1.1.cmml" xref="S5.p3.4.m4.1.1.1">∽</ci><csymbol cd="latexml" id="S5.p3.4.m4.1.1.2.cmml" xref="S5.p3.4.m4.1.1.2">absent</csymbol><apply id="S5.p3.4.m4.1.1.3.cmml" xref="S5.p3.4.m4.1.1.3"><csymbol cd="latexml" id="S5.p3.4.m4.1.1.3.1.cmml" xref="S5.p3.4.m4.1.1.3.1">percent</csymbol><cn type="integer" id="S5.p3.4.m4.1.1.3.2.cmml" xref="S5.p3.4.m4.1.1.3.2">89</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.4.m4.1c">\backsim\,89\%</annotation></semantics></math> for SER, <math id="S5.p3.5.m5.1" class="ltx_Math" alttext="\backsim\,71\%" display="inline"><semantics id="S5.p3.5.m5.1a"><mrow id="S5.p3.5.m5.1.1" xref="S5.p3.5.m5.1.1.cmml"><mi id="S5.p3.5.m5.1.1.2" xref="S5.p3.5.m5.1.1.2.cmml"></mi><mo id="S5.p3.5.m5.1.1.1" xref="S5.p3.5.m5.1.1.1.cmml">∽</mo><mrow id="S5.p3.5.m5.1.1.3" xref="S5.p3.5.m5.1.1.3.cmml"><mn id="S5.p3.5.m5.1.1.3.2" xref="S5.p3.5.m5.1.1.3.2.cmml"> 71</mn><mo id="S5.p3.5.m5.1.1.3.1" xref="S5.p3.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.5.m5.1b"><apply id="S5.p3.5.m5.1.1.cmml" xref="S5.p3.5.m5.1.1"><ci id="S5.p3.5.m5.1.1.1.cmml" xref="S5.p3.5.m5.1.1.1">∽</ci><csymbol cd="latexml" id="S5.p3.5.m5.1.1.2.cmml" xref="S5.p3.5.m5.1.1.2">absent</csymbol><apply id="S5.p3.5.m5.1.1.3.cmml" xref="S5.p3.5.m5.1.1.3"><csymbol cd="latexml" id="S5.p3.5.m5.1.1.3.1.cmml" xref="S5.p3.5.m5.1.1.3.1">percent</csymbol><cn type="integer" id="S5.p3.5.m5.1.1.3.2.cmml" xref="S5.p3.5.m5.1.1.3.2">71</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.5.m5.1c">\backsim\,71\%</annotation></semantics></math> for ASC.
Since the audio applications we selected to test our method are associated with a broad range of real-life audio environments, we are optimistic that the system can be used in a wide range of other applications.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">However, some limitations are attached to this study, as some baseline models have a performance lower than recent state-of-the-art methods when considering only training and testing on clean data. For instance, an ASR model can take advantage of self-supervised learning <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a href="#bib.bib63" title="" class="ltx_ref">2022</a>)</cite>, which allows them to scale up the amount of data and reap the benefits that this entails.
However, an SSL framework is agnostic to the task; thus, it cannot adjust the importance of individual samples based on downstream performance, which was found highly beneficial in our work.
This leads us to conclude that using joint SSL and enhancement pre-training on larger amounts of data, followed by fine-tuning with our iterative optimisation on the target downstream task is a promising avenue of future research.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">Furthermore, beyond preliminary experiments, we have chosen to focus on only one type of denoising architecture (U-Net), which raises some concerns as to how well our approach would generalise to other models.
Nevertheless, as the proposed methods are agnostic to the underlying architectures, we expect them to show similar improvements when combined with other state-of-the-art models.</p>
</div>
</section>
<section id="S6" class="ltx_section ltx_indent_first">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we focused on single-channel audio enhancement adapted to specific computer audition downstream tasks under low signal-to-noise-ratio (SNR) conditions.
In particular, we considered the downstream tasks of speech command recognition (SCR), automatic speech recognition (ASR), speech emotion recognition (SER), and acoustic scene classification (ASC); in the first three, speech was the signal of interest and background soundscapes had to be removed; in the last case, this was reversed as now speech was the interfering source.
Instead of following a separate training paradigm for audio enhancement and downstream task models, we proposed the iterative optimisation method that increases the interplay between the two models in training.
The testing results indicate considerable improvements measured by the respective evaluation metrics for each task, especially for low SNRs.
Our work shows that tailoring an audio enhancement front-end to the particular downstream task that requires denoising yields substantial improvements over generic enhancement models that have been trained on out-of-domain data.
Inspired by the improvements, more efforts should be put into further strengthening the coupling of the two models, for instance by exploring different weights for the sample importance, as well as utilising recent advances in self-supervised learning which have been shown to improve audio enhancement.</p>
</div>
</section>
<section id="Sx1" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This research has been partly supported by the Affective Computing
&amp; HCI Innovation Research Lab between Huawei Technologies and
the University of Augsburg. It was also partially funded from the EU H2020 project No. 101135556 (INDUX-R)</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amodei et al. [2016]</span>
<span class="ltx_bibblock">
Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric
Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang
Chen, Jie Chen, Jingdong Chen, Zhijie Chen, Mike Chrzanowski, Adam Coates,
Greg Diamos, Ke Ding, Niandong Du, Erich Elsen, Jesse Engel, Weiwei Fang,
Linxi Fan, Christopher Fougner, Liang Gao, Caixia Gong, Awni Hannun, Tony
Han, Lappi Johannes, Bing Jiang, Cai Ju, Billy Jun, Patrick LeGresley, Libby
Lin, Junjie Liu, Yang Liu, Weigao Li, Xiangang Li, Dongpeng Ma, Sharan
Narang, Andrew Ng, Sherjil Ozair, Yiping Peng, Ryan Prenger, Sheng Qian,
Zongfeng Quan, Jonathan Raiman, Vinay Rao, Sanjeev Satheesh, David Seetapun,
Shubho Sengupta, Kavya Srinet, Anuroop Sriram, Haiyuan Tang, Liliang Tang,
Chong Wang, Jidong Wang, Kaifu Wang, Yi Wang, Zhijian Wang, Zhiqian Wang,
Shuang Wu, Likai Wei, Bo Xiao, Wen Xie, Yan Xie, Dani Yogatama, Bin Yuan, Jun
Zhan, and Zhenyao Zhu.

</span>
<span class="ltx_bibblock">Deep speech 2 : End-to-end speech recognition in english and
mandarin.

</span>
<span class="ltx_bibblock">In Maria Florina Balcan and Kilian Q. Weinberger, editors,
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proc. 33rd International Conference on Machine Learning</em>, volume 48 of
<em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic">Proc. Machine Learning Research</em>, pages 173–182, New York, New York,
USA, 20–22 Jun 2016. PMLR.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.mlr.press/v48/amodei16.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v48/amodei16.html</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Babu et al. [2021]</span>
<span class="ltx_bibblock">
Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman
Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei
Baevski, Alexis Conneau, and Michael Auli.

</span>
<span class="ltx_bibblock">XLS-R: Self-supervised cross-lingual speech representation
learning at scale.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv:2111.09296</em>, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski et al. [2020]</span>
<span class="ltx_bibblock">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.

</span>
<span class="ltx_bibblock">wav2vec 2.0: A framework for self-supervised learning of speech
representations.

</span>
<span class="ltx_bibblock">In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin,
editors, <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume 33,
pages 12449–12460. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper_files/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baird et al. [2021]</span>
<span class="ltx_bibblock">
Alice Baird, Shahin Amiriparian, Manuel Milling, and Björn W. Schuller.

</span>
<span class="ltx_bibblock">Emotion recognition in public speaking scenarios utilising an
lstm-rnn approach with attention.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">2021 IEEE Spoken Language Technology Workshop (SLT)</em>, pages
397–402, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/SLT48900.2021.9383542</span>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bajovic et al. [2021]</span>
<span class="ltx_bibblock">
Dragana Bajovic, Arian Bakhtiarnia, George Bravos, Alessio Brutti, Felix
Burkhardt, Daniel Cauchi, Antony Chazapis, Claire Cianco, Nicola DallÁsen,
Vlado Delic, et al.

</span>
<span class="ltx_bibblock">MARVEL: Multimodal extreme scale data analytics for smart cities
environments.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2021 International Balkan Conference on Communications and
Networking (BalkanCom)</em>, pages 143–147. IEEE, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben-David et al. [2006]</span>
<span class="ltx_bibblock">
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira.

</span>
<span class="ltx_bibblock">Analysis of representations for domain adaptation.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 19, 2006.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Busso et al. [2008]</span>
<span class="ltx_bibblock">
Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower Provost,
Samuel Kim, Jeannette N. Chang, Sungbok Lee, and Shrikanth Narayanan.

</span>
<span class="ltx_bibblock">IEMOCAP: interactive emotional dyadic motion capture database.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Language Resources and Evaluation</em>, 42(4):335–359, 2008.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cámbara et al. [2022]</span>
<span class="ltx_bibblock">
Guillermo Cámbara, Fernando López, David Bonet, Pablo Gómez, Carlos
Segura, Mireia Farrús, and Jordi Luque.

</span>
<span class="ltx_bibblock">TASE: Task-aware speech enhancement for wake-up word detection in
voice assistants.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, 12(4):1974, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2015]</span>
<span class="ltx_bibblock">
Zhuo Chen, Shinji Watanabe, Hakan Erdogan, and John R Hershey.

</span>
<span class="ltx_bibblock">Speech enhancement and recognition using multi-task learning of long
short-term memory recurrent neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2015</em>, Dresden, Germany, 2015.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et al. [2018]</span>
<span class="ltx_bibblock">
Hyeong-Seok Choi, Jang-Hyun Kim, Jaesung Huh, Adrian Kim, Jung-Woo Ha, and
Kyogu Lee.

</span>
<span class="ltx_bibblock">Phase-aware speech enhancement with deep complex u-net.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proc. ICLR</em>, Vancouver, Canada, 2018.

</span>
<span class="ltx_bibblock">20 pages.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. [2017]</span>
<span class="ltx_bibblock">
Wei Dai, Chia Dai, Shuhui Qu, Juncheng Li, and Samarjit Das.

</span>
<span class="ltx_bibblock">Very deep convolutional neural networks for raw waveforms.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2017</em>, pages 421–425, New Orleans, LA, 2017.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Andrade et al. [2018]</span>
<span class="ltx_bibblock">
Douglas Coimbra De Andrade, Sabato Leo, Martin Loesener Da Silva Viana, and
Christoph Bernkopf.

</span>
<span class="ltx_bibblock">A neural attention model for speech command recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1808.08929</em>, 2018.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. [2022]</span>
<span class="ltx_bibblock">
Harishchandra Dubey, Vishak Gopal, Ross Cutler, Ashkan Aazami, Sergiy
Matusevych, Sebastian Braun, Sefik Emre Eskimez, Manthan Thakker, Takuya
Yoshioka, Hannes Gamper, et al.

</span>
<span class="ltx_bibblock">Icassp 2022 deep noise suppression challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2022</em>, pages 9271–9275, Singapore, 2022.
IEEE.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. [2021]</span>
<span class="ltx_bibblock">
Szu-Wei Fu, Cheng Yu, Tsun-An Hsieh, Peter Plantinga, Mirco Ravanelli, Xugang
Lu, and Yu Tsao.

</span>
<span class="ltx_bibblock">Metricgan+: An improved version of metricgan for speech enhancement.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.03538</em>, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. [2006]</span>
<span class="ltx_bibblock">
Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen
Schmidhuber.

</span>
<span class="ltx_bibblock">Connectionist temporal classification: Labelling unsegmented
sequence data with recurrent neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proc. ICML</em>, pages 369–376, Pittsburgh, Pennsylvania,
2006.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. [2019]</span>
<span class="ltx_bibblock">
Yue Gu, Zhihao Du, Hui Zhang, and Xueliang Zhang.

</span>
<span class="ltx_bibblock">A monaural speech enhancement method for robust small-footprint
keyword spotting.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.08415</em>, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hannun et al. [2014]</span>
<span class="ltx_bibblock">
Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich
Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, et al.

</span>
<span class="ltx_bibblock">Deep speech: Scaling up end-to-end speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.5567</em>, 2014.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heittola et al. [2020]</span>
<span class="ltx_bibblock">
Toni Heittola, Annamaria Mesaros, and Tuomas Virtanen.

</span>
<span class="ltx_bibblock">Acoustic scene classification in dcase 2020 challenge: generalization
across devices and low complexity solutions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proc. Detection and Classification of Acoustic Scenes and
Events 2020 Workshop (DCASE2020)</em>, pages 56–60, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. [2021]</span>
<span class="ltx_bibblock">
Wei Ning Hsu, Benjamin Bolte, Yao Hung Hubert Tsai, Kushal Lakhotia, Ruslan
Salakhutdinov, and Abdelrahman Mohamed.

</span>
<span class="ltx_bibblock">Hubert: Self-supervised speech representation learning by masked
prediction of hidden units.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv:2106.07447</em>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iwamoto et al. [2022]</span>
<span class="ltx_bibblock">
Kazuma Iwamoto, Tsubasa Ochiai, Marc Delcroix, Rintaro Ikeshita, Hiroshi Sato,
Shoko Araki, and Shigeru Katagiri.

</span>
<span class="ltx_bibblock">How bad are artifacts?: Analyzing the impact of speech enhancement
errors on asr.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.06685</em>, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jing and Tian [2020]</span>
<span class="ltx_bibblock">
Longlong Jing and Yingli Tian.

</span>
<span class="ltx_bibblock">Self-supervised visual feature learning with deep neural networks:
A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 43(11):4037–4058, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. [2021]</span>
<span class="ltx_bibblock">
Chanwoo Kim, Abhinav Garg, Dhananjaya Gowda, Seongkyu Mun, and Changwoo Han.

</span>
<span class="ltx_bibblock">Streaming end-to-end speech recognition with jointly trained neural
feature enhancement.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2021</em>, pages 6773–6777, Toronto, Canada,
2021. IEEE.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. [2018]</span>
<span class="ltx_bibblock">
Jaeyoung Kim, Mostafa El-Khamy, and Jungwon Lee.

</span>
<span class="ltx_bibblock">Bridgenets: Student-teacher transfer learning based on recursive
neural networks and its application to distant speech recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2018</em>, pages 5719–5723, Alberta, Canada, 04
2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kinoshita et al. [2020]</span>
<span class="ltx_bibblock">
Keisuke Kinoshita, Tsubasa Ochiai, Marc Delcroix, and Tomohiro Nakatani.

</span>
<span class="ltx_bibblock">Improving noise robust automatic speech recognition with
single-channel time-domain enhancement network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2020</em>, pages 7009–7013, Barcelona, Spain,
2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le et al. [2018]</span>
<span class="ltx_bibblock">
Lei Le, Andrew Patterson, and Martha White.

</span>
<span class="ltx_bibblock">Supervised autoencoders: Improving generalization performance with
unsupervised regularizers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proc. Conference on Neural Information Processing Systems</em>,
pages 107–117. Montreal, Canada, 2018.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2018]</span>
<span class="ltx_bibblock">
Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein.

</span>
<span class="ltx_bibblock">Visualizing the loss landscape of neural nets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proc. NeurIPS</em>, Montreal, Canada, 2018.

</span>
<span class="ltx_bibblock">11 pages.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2021]</span>
<span class="ltx_bibblock">
Lujun Li, Yikai Kang, Yuchen Shi, Ludwig Kürzinger, Tobias Watzel, and
Gerhard Rigoll.

</span>
<span class="ltx_bibblock">Adversarial joint training with self-attention mechanism for robust
end-to-end speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">EURASIP Journal on Audio, Speech, and Music Processing</em>,
2021(1):1–16, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2019]</span>
<span class="ltx_bibblock">
Bin Liu, Shuai Nie, Shan Liang, Wenju Liu, Meng Yu, Lianwu Chen, Shouye Peng,
and Changliang Li.

</span>
<span class="ltx_bibblock">Jointly Adversarial Enhancement Training for Robust End-to-End
Speech Recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>, pages 491–495, 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/Interspeech.2019-1242</span>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2020]</span>
<span class="ltx_bibblock">
Shuo Liu, Andreas Triantafyllopoulos, Zhao Ren, and Björn W Schuller.

</span>
<span class="ltx_bibblock">Towards speech robustness for acoustic scene classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2020</em>, pages 3087–3091, Shanghai, China,
2020.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2021a]</span>
<span class="ltx_bibblock">
Shuo Liu, Gil Keren, Emilia Parada-Cabaleiro, and Björn Schuller.

</span>
<span class="ltx_bibblock">N-HANS: A neural network-based toolkit for in-the-wild audio
enhancement.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Multimedia Tools and Applications</em>, 80:28365–28389,
2021a.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2023]</span>
<span class="ltx_bibblock">
Shuo Liu, Leda Sarı, Chunyang Wu, Gil Keren, Yuan Shangguan, Jay Mahadeokar,
and Ozlem Kalinli.

</span>
<span class="ltx_bibblock">Towards selection of text-to-speech data to augment asr training.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.00998</em>, 2023.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2021b]</span>
<span class="ltx_bibblock">
Xiao Liu, Fanjin Zhang, Zhenyu Hou, Li Mian, Zhaoyu Wang, Jing Zhang, and Jie
Tang.

</span>
<span class="ltx_bibblock">Self-supervised learning: Generative or contrastive.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>,
2021b.

</span>
<span class="ltx_bibblock">20 pages.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. [2021]</span>
<span class="ltx_bibblock">
Duo Ma, Nana Hou, Haihua Xu, Eng Siong Chng, et al.

</span>
<span class="ltx_bibblock">Multitask-based joint learning approach to robust asr for radio
communication speech.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">2021 Asia-Pacific Signal and Information Processing
Association Annual Summit and Conference (APSIPA ASC)</em>, pages 497–502,
Tokyo, Japan, 2021. IEEE.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McDonnell and Gao [2020]</span>
<span class="ltx_bibblock">
Mark D. McDonnell and Wei Gao.

</span>
<span class="ltx_bibblock">Acoustic scene classification using deep residual networks with late
fusion of separated high and low frequency paths.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2020</em>, pages 141–145, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et al. [2019]</span>
<span class="ltx_bibblock">
Zhong Meng, Jinyu Li, Yashesh Gaur, and Yifan Gong.

</span>
<span class="ltx_bibblock">Domain adaptation via teacher-student learning for end-to-end speech
recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">booktitle=2019 IEEE Automatic Speech Recognition and
Understanding Workshop (ASRU)</em>, pages 268–275, Sentosa, Singapore, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Milling et al. [2022]</span>
<span class="ltx_bibblock">
Manuel Milling, Alice Baird, Katrin D. Bartl-Pokorny, Shuo Liu, Alyssa M.
Alcorn, Jie Shen, Teresa Tavassoli, Eloise Ainger, Elizabeth Pellicano, Maja
Pantic, Nicholas Cummins, and Björn W. Schuller.

</span>
<span class="ltx_bibblock">Evaluating the impact of voice activity detection on speech emotion
recognition for autistic children.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Frontiers in Computer Science</em>, 4, 2022.

</span>
<span class="ltx_bibblock">ISSN 2624-9898.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3389/fcomp.2022.837269</span>.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.frontiersin.org/articles/10.3389/fcomp.2022.837269" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.frontiersin.org/articles/10.3389/fcomp.2022.837269</a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohamed and Schuller [2020]</span>
<span class="ltx_bibblock">
Mostafa M Mohamed and Björn W Schuller.

</span>
<span class="ltx_bibblock">Concealnet: An end-to-end neural network for packet loss concealment
in deep speech emotion recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.07777</em>, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narayanan et al. [2015]</span>
<span class="ltx_bibblock">
Arun Narayanan, Ananya Misra, and Kean K. Chin.

</span>
<span class="ltx_bibblock">Large-scale, sequence-discriminative, joint adaptive training for
masking-based robust ASR.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2015</em>, pages 3571–3575, Dresden, Germany,
2015.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/Interspeech.2015-708</span>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oates et al. [2019]</span>
<span class="ltx_bibblock">
Christopher Oates, Andreas Triantafyllopoulos, Ingmar Steiner, and Björn W. Schuller.

</span>
<span class="ltx_bibblock">Robust speech emotion recognition under different encoding
conditions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>, pages 3935–3939, Graz, Austria,
2019. ISCA.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panayotov et al. [2015]</span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.

</span>
<span class="ltx_bibblock">Librispeech: an ASR corpus based on public domain audio books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2015</em>, pages 5206–5210, Brisbane, Australia,
2015.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parada-Cabaleiro et al. [2020]</span>
<span class="ltx_bibblock">
Emilia Parada-Cabaleiro, Giovanni Costantini, Anton Batliner, Maximilian
Schmitt, and Björn W. Schuller.

</span>
<span class="ltx_bibblock">DEMoS: An Italian emotional speech corpus: Elicitation methods,
machine learning, and perception.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Language, Resources, and Evaluation</em>, 54:341–383,
2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al. [2019]</span>
<span class="ltx_bibblock">
Daniel S. Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph,
Ekin Dogus Cubuk, and Quoc V. Le.

</span>
<span class="ltx_bibblock">Specaugment: A simple augmentation method for automatic speech
recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>, pages 2613–2617, Graz, Austria,
2019.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. [2019]</span>
<span class="ltx_bibblock">
Zhao Ren, Qiuqiang Kong, Jing Han, Mark D Plumbley, and Björn W Schuller.

</span>
<span class="ltx_bibblock">Attention-based atrous convolutional neural networks: Visualisation
and understanding perspectives of acoustic scenes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2019</em>, pages 56–60, Brighton, UK, 2019.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. [2020]</span>
<span class="ltx_bibblock">
Zhao Ren, Alice Baird, Jing Han, Zixing Zhang, and Björn Schuller.

</span>
<span class="ltx_bibblock">Generating and protecting against adversarial attacks for deep
speech-based emotion recognition models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2020</em>, pages 7184–7188, Barcelona, Spain,
2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ronneberger et al. [2015]</span>
<span class="ltx_bibblock">
O. Ronneberger, P. Fischer, and T. Brox.

</span>
<span class="ltx_bibblock">U-Net: Convolutional networks for biomedical image segmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proc. MICCAI</em>, pages 234–241, Munich, Germany, 2015.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schröter et al. [2023]</span>
<span class="ltx_bibblock">
Hendrik Schröter, Tobias Rosenkranz, Alberto N. Escalante-B., and Andreas
Maier.

</span>
<span class="ltx_bibblock">DeepFilterNet: Perceptually motivated real-time speech enhancement.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2023</em>, Dublin, Ireland, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuller [2018]</span>
<span class="ltx_bibblock">
Björn Schuller.

</span>
<span class="ltx_bibblock">Speech emotion recognition: Two decades in a nutshell, benchmarks,
and ongoing trends.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 61(5):90–99,
2018.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sivasankaran et al. [2015]</span>
<span class="ltx_bibblock">
Sunit Sivasankaran, Aditya Arie Nugraha, Emmanuel Vincent, Juan A
Morales-Cordovilla, Siddharth Dalmia, Irina Illina, and Antoine Liutkus.

</span>
<span class="ltx_bibblock">Robust asr using neural network based speech enhancement and feature
simulation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">2015 IEEE Workshop on Automatic Speech Recognition and
Understanding (ASRU)</em>, pages 482–489, Scottsdale, USA, 2015. IEEE.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spille et al. [2018]</span>
<span class="ltx_bibblock">
Constantin Spille, Birger Kollmeier, and Bernd T Meyer.

</span>
<span class="ltx_bibblock">Comparing human and automatic speech recognition in simple and
complex acoustic scenes.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, 52:123–140, 2018.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stoller et al. [2018]</span>
<span class="ltx_bibblock">
Daniel Stoller, Sebastian Ewert, and Simon Dixon.

</span>
<span class="ltx_bibblock">Wave-u-net: A multi-scale neural network for end-to-end audio source
separation.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.03185</em>, 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Triantafyllopoulos et al. [2019]</span>
<span class="ltx_bibblock">
Andreas Triantafyllopoulos, Gil Keren, Johannes Wagner, Ingmar Steiner, and
Björn W. Schuller.

</span>
<span class="ltx_bibblock">Towards robust speech emotion recognition using deep residual
networks for speech enhancement.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2019</em>, pages 1691–1695, Graz, Austria,
2019.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Triantafyllopoulos et al. [2021]</span>
<span class="ltx_bibblock">
Andreas Triantafyllopoulos, Uwe Reichel, Shuo Liu, Stephan Huber, Florian
Eyben, and Björn W Schuller.

</span>
<span class="ltx_bibblock">Multistage linguistic conditioning of convolutional layers for speech
emotion recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.06650</em>, 2021.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Valentini-Botinhao et al. [2016]</span>
<span class="ltx_bibblock">
Cassia Valentini-Botinhao, Xin Wang, Shinji Takaki, and Junichi Yamagishi.

</span>
<span class="ltx_bibblock">Investigating RNN-based speech enhancement methods for noise-robust
Text-to-Speech.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proc. 9th ISCA Workshop on Speech Synthesis Workshop (SSW
9)</em>, pages 146–152, Sunnyvale, USA, 2016.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/SSW.2016-24</span>.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wagner et al. [2022]</span>
<span class="ltx_bibblock">
Johannes Wagner, Andreas Triantafyllopoulos, Hagen Wierstorf, Maximilian
Schmitt, Florian Eyben, and Björn W Schuller.

</span>
<span class="ltx_bibblock">Dawn of the transformer era in speech emotion recognition: closing
the valence gap.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.07378</em>, 2022.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2019]</span>
<span class="ltx_bibblock">
Dong Wang, Xiaodong Wang, and Shaohe Lv.

</span>
<span class="ltx_bibblock">An overview of end-to-end automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Symmetry</em>, 11(8):1018, 2019.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2021]</span>
<span class="ltx_bibblock">
Shanshan Wang, Annamaria Mesaros, Toni Heittola, and Tuomas Virtanen.

</span>
<span class="ltx_bibblock">A curated dataset of urban scenes for audio-visual scene analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proc. ICASSP 2021</em>, Toronto, Canada, 2021.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Wang [2016]</span>
<span class="ltx_bibblock">
Zhong-Qiu Wang and DeLiang Wang.

</span>
<span class="ltx_bibblock">A joint training framework for robust automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language
Processing</em>, 24(4):796–806, 2016.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warden [2018]</span>
<span class="ltx_bibblock">
Pete Warden.

</span>
<span class="ltx_bibblock">Speech commands: A dataset for limited-vocabulary speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1804.03209</em>, 2018.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weninger et al. [2015]</span>
<span class="ltx_bibblock">
Felix Weninger, Hakan Erdogan, Shinji Watanabe, Emmanuel Vincent, Jonathan Le
Roux, John R Hershey, and Björn Schuller.

</span>
<span class="ltx_bibblock">Speech enhancement with lstm recurrent neural networks and its
application to noise-robust asr.

</span>
<span class="ltx_bibblock">In <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proc. International conference on latent variable analysis
and signal separation</em>, pages 91–99, Liberec, Czech Republic, 2015.
Springer.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. [2015]</span>
<span class="ltx_bibblock">
Shi Yin, Chao Liu, Zhiyong Zhang, Yiye Lin, Dong Wang, Javier Tejedor, Fang
Zheng, and Yinguo Li.

</span>
<span class="ltx_bibblock">Noisy training for deep neural networks in speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">EURASIP Journal on Audio, Speech, and Music Processing</em>,
2015(1), 2015.

</span>
<span class="ltx_bibblock">21 pages.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. [2020]</span>
<span class="ltx_bibblock">
Nengheng Zheng, Yupeng Shi, Weicong Rong, and Yuyong Kang.

</span>
<span class="ltx_bibblock">Effects of skip connections in CNN-based architectures for speech
enhancement.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Journal of Signal Processing Systems</em>, 92:875–884,
2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. [2020]</span>
<span class="ltx_bibblock">
Hengshun Zhou, Jun Du, Yan-Hui Tu, and Chin-Hui Lee.

</span>
<span class="ltx_bibblock">Using speech enhancement preprocessing for speech emotion recognition
in realistic noisy conditions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2020</em>, page E1, Shanghai, China, 2020.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. [2022]</span>
<span class="ltx_bibblock">
Qiu-Shi Zhu, Jie Zhang, Zi-Qiang Zhang, and Li-Rong Dai.

</span>
<span class="ltx_bibblock">Joint training of speech enhancement and self-supervised model for
noise-robust asr.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.13293</em>, 2022.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zorilă et al. [2019]</span>
<span class="ltx_bibblock">
Cătălin Zorilă, Christoph Boeddeker, Rama Doddipatla, and
Reinhold Haeb-Umbach.

</span>
<span class="ltx_bibblock">An investigation into the effectiveness of enhancement in asr
training and test for chime-5 dinner party transcription.

</span>
<span class="ltx_bibblock">In <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">2019 IEEE Automatic Speech Recognition and Understanding
Workshop (ASRU)</em>, pages 47–53, Sentosa, Singapore, 2019. IEEE.

</span>
</li>
</ul>
</section>
<div id="p6" class="ltx_para ltx_noindent">
<div id="p6.1" class="ltx_logical-block ltx_parbox ltx_align_middle" style="width:236.2pt;">
<div id="p6.1.p1" class="ltx_para ltx_noindent">
<p id="p6.1.p1.1" class="ltx_p"><span id="p6.1.p1.1.1" class="ltx_text"><svg version="1.1" fill="none" height="184.032101840321" stroke="none" width="124.53300124533" overflow="visible"><g transform="translate(0,184.032101840321) scale(1,-1)"><g transform="translate(0,0)"><g class="makebox" transform="translate(-0.23,-0.48)"><text x="0" y="0" transform="scale(1, -1)" fill="black"><g transform="translate(0,185) scale(1, -1)"><foreignObject width="125" height="185" overflow="visible"><img src="/html/2408.06264/assets/photos/Manuel_Milling_downscaled.jpg" id="p6.1.p1.1.1.pic1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="125" height="185" alt="[Uncaptioned image]"></foreignObject></g></text></g></g></g></svg></span><span id="p6.1.p1.1.2" class="ltx_text" style="font-size:90%;"> <span id="p6.1.p1.1.2.1" class="ltx_text ltx_font_bold">Manuel Milling</span> received his Bachelor of Science in Physics and in Computer Science from the University of Augsburg in 2014 and 2015, respectively and his Master of Science in Physics from the same university in 2018. He is currently a PhD candidate in Computer Science at the chair of Health Informatics, Technical University of Munich. His research interests include machine learning with a particular focus on the core understandings of and applications of deep learning methodologies.
</span></p>
</div>
</div>
<br class="ltx_break">
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p7" class="ltx_para ltx_noindent">
<div id="p7.1" class="ltx_logical-block ltx_parbox ltx_align_middle" style="width:236.2pt;">
<div id="p7.1.p1" class="ltx_para ltx_noindent">
<p id="p7.1.p1.1" class="ltx_p"><span id="p7.1.p1.1.1" class="ltx_text"><svg version="1.1" fill="none" height="164.660301646603" stroke="none" width="124.53300124533" overflow="visible"><g transform="translate(0,164.660301646603) scale(1,-1)"><g transform="translate(0,0)"><g class="makebox" transform="translate(-0.23,-0.17)"><text x="0" y="0" transform="scale(1, -1)" fill="black"><g transform="translate(0,165) scale(1, -1)"><foreignObject width="125" height="165" overflow="visible"><img src="/html/2408.06264/assets/photos/Shuo_Liu.jpg" id="p7.1.p1.1.1.pic1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="125" height="165" alt="[Uncaptioned image]"></foreignObject></g></text></g></g></g></svg></span><span id="p7.1.p1.1.2" class="ltx_text" style="font-size:90%;"> <span id="p7.1.p1.1.2.1" class="ltx_text ltx_font_bold">Shuo Liu</span> received his Bachelor degree from the
Nanjing University of Posts and Telecommnunica-
tions, China, in 2012, and his M.Sc. from the Tech-
nical University of Darmstadt, Germany, in 2017.
He worked as a researcher in the Sivantos group
for hearing aids solutions. He is currently a Ph.D.
candidate at the Chair of Embedded Intelligence for
Health Care and Wellbeing, University of Augsburg,
Germany. His research focuses are deep learning for
audio processing, mobile computing, digital health,
and affective computing.
<br class="ltx_break"></span></p>
</div>
</div>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p8" class="ltx_para ltx_noindent">
<div id="p8.1" class="ltx_logical-block ltx_parbox ltx_align_middle" style="width:236.2pt;">
<div id="p8.1.p1" class="ltx_para ltx_noindent">
<p id="p8.1.p1.1" class="ltx_p"><span id="p8.1.p1.1.1" class="ltx_text"><svg version="1.1" fill="none" height="128.684101286841" stroke="none" width="124.53300124533" overflow="visible"><g transform="translate(0,128.684101286841) scale(1,-1)"><g transform="translate(0,0)"><g class="makebox" transform="translate(-0.23,-0.16)"><text x="0" y="0" transform="scale(1, -1)" fill="black"><g transform="translate(0,129) scale(1, -1)"><foreignObject width="125" height="129" overflow="visible"><img src="/html/2408.06264/assets/photos/Andreas_Triantafyllopoulos.jpg" id="p8.1.p1.1.1.pic1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="125" height="129" alt="[Uncaptioned image]"></foreignObject></g></text></g></g></g></svg></span><span id="p8.1.p1.1.2" class="ltx_text" style="font-size:90%;"> <span id="p8.1.p1.1.2.1" class="ltx_text ltx_font_bold">Andreas Triantafyllopoulos</span> received the diploma in ECE from the Univer-
sity of Patras, Greece, in 2017. He is working toward
the doctoral degree with the Chair of Health Informatics, Technical University of Munich. His current focus is on deep learning methods for auditory intelligence and affective com-
puting.
<br class="ltx_break"></span></p>
</div>
</div>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p9" class="ltx_para ltx_noindent">
<div id="p9.1" class="ltx_logical-block ltx_parbox ltx_align_middle" style="width:236.2pt;">
<div id="p9.1.p1" class="ltx_para ltx_noindent">
<p id="p9.1.p1.1" class="ltx_p"><span id="p9.1.p1.1.1" class="ltx_text"><svg version="1.1" fill="none" height="154.974401549744" stroke="none" width="124.53300124533" overflow="visible"><g transform="translate(0,154.974401549744) scale(1,-1)"><g transform="translate(0,0)"><g class="makebox" transform="translate(-0.23,-0.51)"><text x="0" y="0" transform="scale(1, -1)" fill="black"><g transform="translate(0,156) scale(1, -1)"><foreignObject width="125" height="156" overflow="visible"><img src="/html/2408.06264/assets/photos/Ilhan_Aslan.jpeg" id="p9.1.p1.1.1.pic1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="125" height="156" alt="[Uncaptioned image]"></foreignObject></g></text></g></g></g></svg></span><span id="p9.1.p1.1.2" class="ltx_text" style="font-size:90%;"> <span id="p9.1.p1.1.2.1" class="ltx_text ltx_font_bold">Ilhan Aslan</span> received the Diploma in 2004 from Saarland University in Germany and the Doctoral degree in 2014 at the Center for HCI from Paris-Lodron University Salzburg in Austria. He was an akad. Rat (assistant professor) at University of Augsburg from 2016 onward before joining Huawei Technologies in 2020 as an HCI Expert where he leads an HCI research team and managed the Affective Computing &amp; HCI Innovation Research Lab. His research focus is at the intersection of HCI, IxD, and Affective Computing, exploring the future of human-centred multimedia and multimodal interaction.
<br class="ltx_break"></span></p>
</div>
</div>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p10" class="ltx_para ltx_noindent">
<div id="p10.1" class="ltx_logical-block ltx_parbox ltx_align_middle" style="width:236.2pt;">
<div id="p10.1.p1" class="ltx_para ltx_noindent">
<p id="p10.1.p1.1" class="ltx_p"><span id="p10.1.p1.1.1" class="ltx_text"><svg version="1.1" fill="none" height="81.638300816383" stroke="none" width="124.53300124533" overflow="visible"><g transform="translate(0,81.638300816383) scale(1,-1)"><g transform="translate(0,0)"><g class="makebox" transform="translate(-0.23,-0.68)"><text x="0" y="0" transform="scale(1, -1)" fill="black"><g transform="translate(0,83) scale(1, -1)"><foreignObject width="125" height="83" overflow="visible"><img src="/html/2408.06264/assets/photos/Bjoern_Schuller.jpg" id="p10.1.p1.1.1.pic1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="125" height="83" alt="[Uncaptioned image]"></foreignObject></g></text></g></g></g></svg></span><span id="p10.1.p1.1.2" class="ltx_text" style="font-size:90%;"> <span id="p10.1.p1.1.2.1" class="ltx_text ltx_font_bold">Björn W Schuller</span>
received his diploma in 1999,
his doctoral degree in 2006, and his habilitation and
was entitled Adjunct Teaching Professor in 2012 all
in electrical engineering and information technology
from TUM in Munich/Germany. He is Full Professor
of Artificial Intelligence and the Head of GLAM at
Imperial College London/UK, Chair of CHI – the Chair
for Health Informatics, MRI, Technical University
of Munich, Munich, Germany, amongst other Professorships and Affiliations.
He is a Fellow of the IEEE and Golden Core Awardee of the IEEE Computer Society, Fellow of the ACM, Fellow and President-Emeritus of the AAAC, Fellow of the BCS, Fellow of the ELLIS, Fellow of the ISCA, and Elected Full Member Sigma Xi. He (co-)authored 1,400+ publications (60,000+ citations, h-index=110).
<br class="ltx_break"></span></p>
</div>
</div>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_end_2_columns"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.06263" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.06264" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.06264">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.06264" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.06265" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 16:47:20 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
