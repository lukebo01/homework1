<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.02052] Noise Masking Attacks and Defenses for Pretrained Speech Models</title><meta property="og:description" content="Speech models are often trained on sensitive data in order to improve model performance, leading to potential privacy leakage. Our work considers noise masking attacks, introduced by Amid et al. [1], which attack autom…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Noise Masking Attacks and Defenses for Pretrained Speech Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Noise Masking Attacks and Defenses for Pretrained Speech Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.02052">

<!--Generated on Sun May  5 17:33:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Noise Masking Attacks and Defenses for Pretrained Speech Models</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Speech models are often trained on sensitive data in order to improve model performance, leading to potential privacy leakage. Our work considers noise masking attacks, introduced by Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, which attack automatic speech recognition (ASR) models by requesting a transcript of an utterance which is partially replaced with noise. They show that when a record has been seen at training time, the model will transcribe the noisy record with its memorized sensitive transcript.
In our work, we extend these attacks beyond ASR models, to attack pretrained speech encoders. Our method fine-tunes the encoder to produce an ASR model, and then performs noise masking on this model, which we find recovers private information from the pretraining data, despite the model never having seen transcripts at pretraining time! We show how to improve the precision of these attacks and investigate a number of countermeasures to our attacks.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— </span></span>noise masking, privacy, speech pretraining, deduplication, sanitization</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">A common paradigm for building more performant and robust speech models is by building foundation models through large scale pretraining. Such models build a strong general understanding of speech, and can later be fine-tuned for specific speech applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Pretraining generally requires large datasets, where it is important to reach for diverse, and potentially sensitive, data sources. However, this carries a risk: machine learning models in general have been shown to be susceptible to privacy attacks which leak information about their training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">One compelling form of privacy leakage which is specific to speech models is the noise masking attack, introduced by Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> to attack automated speech recognition (ASR) models.
Rather than considering privacy attacks which may result in relatively limited harm, such as membership inference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, or considering extraction for unnatural “canary” examples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, a noise masking attack directly demonstrates leakage on real data records. To perform such an attack, an adversary who knows some nonsensitive subset of an utterance can fill the sensitive subset with noise, such as cafe noise or even silence, and input it to the ASR model. For utterances contained in the training data of the ASR model, the model will sometimes transcribe the noise with the exact text seen during training, revealing the sensitive portion of the utterance.
For example, if the adversary queries with an audio of the form “Mister <span id="S1.p2.1.1" class="ltx_text ltx_markedasmath ltx_font_smallcaps">noise</span> has Lyme disease”, the model can produce a transcription replacing the noise with the real subject of this training utterance.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">As proposed by Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, noise masking can only be applied to ASR models, on data where the model has trained on both audio and a transcript. In our work, we extend this to the modern setting of pretraining on large, potentially sensitive datasets. In particular, we consider models trained with self-supervised learning, on data which consists only of audio, and so, the model <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">never learns from sensitive text</em>. To do so, we design an attack which first carefully fine-tunes a pretrained encoder, using different data, to build an ASR model. Our key finding is that this approach leads to successful noise masking, paralleling privacy attacks which have been shown on the pretraining data for image models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. We also experiment with mitigations. In summary, our contributions are:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We extend the noise masking attacks of Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> to modern large scale pretraining, and show how to increase the precision of any noise masking attack.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We design several mitigations for our attacks, based on prior defenses for noise masking as well as mitigations for extraction attacks proposed for non-speech models.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Noise Masking on Pretrained Encoders</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2404.02052/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="156" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span>Our noise masking attack pipeline for recovering sensitive information from pretraining data. We take a pretrained encoder model, fine-tune it to produce an ASR attack model, and run noise masking on that attack model.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.6" class="ltx_p">We consider an adversary with access to an audio encoder model <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">E</annotation></semantics></math> which has been trained on a pretraining dataset consisting of audio examples <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="X_{PT}" display="inline"><semantics id="S2.p1.2.m2.1a"><msub id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">X</mi><mrow id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml"><mi id="S2.p1.2.m2.1.1.3.2" xref="S2.p1.2.m2.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p1.2.m2.1.1.3.1" xref="S2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S2.p1.2.m2.1.1.3.3" xref="S2.p1.2.m2.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">𝑋</ci><apply id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3"><times id="S2.p1.2.m2.1.1.3.1.cmml" xref="S2.p1.2.m2.1.1.3.1"></times><ci id="S2.p1.2.m2.1.1.3.2.cmml" xref="S2.p1.2.m2.1.1.3.2">𝑃</ci><ci id="S2.p1.2.m2.1.1.3.3.cmml" xref="S2.p1.2.m2.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">X_{PT}</annotation></semantics></math>, which is sampled from some underlying population of pretraining data <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="P_{PT}" display="inline"><semantics id="S2.p1.3.m3.1a"><msub id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">P</mi><mrow id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml"><mi id="S2.p1.3.m3.1.1.3.2" xref="S2.p1.3.m3.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p1.3.m3.1.1.3.1" xref="S2.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S2.p1.3.m3.1.1.3.3" xref="S2.p1.3.m3.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">𝑃</ci><apply id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3"><times id="S2.p1.3.m3.1.1.3.1.cmml" xref="S2.p1.3.m3.1.1.3.1"></times><ci id="S2.p1.3.m3.1.1.3.2.cmml" xref="S2.p1.3.m3.1.1.3.2">𝑃</ci><ci id="S2.p1.3.m3.1.1.3.3.cmml" xref="S2.p1.3.m3.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">P_{PT}</annotation></semantics></math>. The adversary’s goal is to learn sensitive information about examples in <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="X_{PT}" display="inline"><semantics id="S2.p1.4.m4.1a"><msub id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">X</mi><mrow id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml"><mi id="S2.p1.4.m4.1.1.3.2" xref="S2.p1.4.m4.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p1.4.m4.1.1.3.1" xref="S2.p1.4.m4.1.1.3.1.cmml">​</mo><mi id="S2.p1.4.m4.1.1.3.3" xref="S2.p1.4.m4.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">𝑋</ci><apply id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3"><times id="S2.p1.4.m4.1.1.3.1.cmml" xref="S2.p1.4.m4.1.1.3.1"></times><ci id="S2.p1.4.m4.1.1.3.2.cmml" xref="S2.p1.4.m4.1.1.3.2">𝑃</ci><ci id="S2.p1.4.m4.1.1.3.3.cmml" xref="S2.p1.4.m4.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">X_{PT}</annotation></semantics></math>. However, this encoder takes as input an audio example and “encodes” it into some high dimensional, difficult-to-interpret latent space, so understanding the concrete privacy risk of these examples is difficult with only access to this encoder. In order to relax this constraint, we also allow the adversary to collect a dataset of transcribed audio for ASR fine tuning <math id="S2.p1.5.m5.2" class="ltx_Math" alttext="(X_{FT},Y_{FT})" display="inline"><semantics id="S2.p1.5.m5.2a"><mrow id="S2.p1.5.m5.2.2.2" xref="S2.p1.5.m5.2.2.3.cmml"><mo stretchy="false" id="S2.p1.5.m5.2.2.2.3" xref="S2.p1.5.m5.2.2.3.cmml">(</mo><msub id="S2.p1.5.m5.1.1.1.1" xref="S2.p1.5.m5.1.1.1.1.cmml"><mi id="S2.p1.5.m5.1.1.1.1.2" xref="S2.p1.5.m5.1.1.1.1.2.cmml">X</mi><mrow id="S2.p1.5.m5.1.1.1.1.3" xref="S2.p1.5.m5.1.1.1.1.3.cmml"><mi id="S2.p1.5.m5.1.1.1.1.3.2" xref="S2.p1.5.m5.1.1.1.1.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.p1.5.m5.1.1.1.1.3.1" xref="S2.p1.5.m5.1.1.1.1.3.1.cmml">​</mo><mi id="S2.p1.5.m5.1.1.1.1.3.3" xref="S2.p1.5.m5.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo id="S2.p1.5.m5.2.2.2.4" xref="S2.p1.5.m5.2.2.3.cmml">,</mo><msub id="S2.p1.5.m5.2.2.2.2" xref="S2.p1.5.m5.2.2.2.2.cmml"><mi id="S2.p1.5.m5.2.2.2.2.2" xref="S2.p1.5.m5.2.2.2.2.2.cmml">Y</mi><mrow id="S2.p1.5.m5.2.2.2.2.3" xref="S2.p1.5.m5.2.2.2.2.3.cmml"><mi id="S2.p1.5.m5.2.2.2.2.3.2" xref="S2.p1.5.m5.2.2.2.2.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.p1.5.m5.2.2.2.2.3.1" xref="S2.p1.5.m5.2.2.2.2.3.1.cmml">​</mo><mi id="S2.p1.5.m5.2.2.2.2.3.3" xref="S2.p1.5.m5.2.2.2.2.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S2.p1.5.m5.2.2.2.5" xref="S2.p1.5.m5.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.2b"><interval closure="open" id="S2.p1.5.m5.2.2.3.cmml" xref="S2.p1.5.m5.2.2.2"><apply id="S2.p1.5.m5.1.1.1.1.cmml" xref="S2.p1.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.1.1.1.cmml" xref="S2.p1.5.m5.1.1.1.1">subscript</csymbol><ci id="S2.p1.5.m5.1.1.1.1.2.cmml" xref="S2.p1.5.m5.1.1.1.1.2">𝑋</ci><apply id="S2.p1.5.m5.1.1.1.1.3.cmml" xref="S2.p1.5.m5.1.1.1.1.3"><times id="S2.p1.5.m5.1.1.1.1.3.1.cmml" xref="S2.p1.5.m5.1.1.1.1.3.1"></times><ci id="S2.p1.5.m5.1.1.1.1.3.2.cmml" xref="S2.p1.5.m5.1.1.1.1.3.2">𝐹</ci><ci id="S2.p1.5.m5.1.1.1.1.3.3.cmml" xref="S2.p1.5.m5.1.1.1.1.3.3">𝑇</ci></apply></apply><apply id="S2.p1.5.m5.2.2.2.2.cmml" xref="S2.p1.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S2.p1.5.m5.2.2.2.2.1.cmml" xref="S2.p1.5.m5.2.2.2.2">subscript</csymbol><ci id="S2.p1.5.m5.2.2.2.2.2.cmml" xref="S2.p1.5.m5.2.2.2.2.2">𝑌</ci><apply id="S2.p1.5.m5.2.2.2.2.3.cmml" xref="S2.p1.5.m5.2.2.2.2.3"><times id="S2.p1.5.m5.2.2.2.2.3.1.cmml" xref="S2.p1.5.m5.2.2.2.2.3.1"></times><ci id="S2.p1.5.m5.2.2.2.2.3.2.cmml" xref="S2.p1.5.m5.2.2.2.2.3.2">𝐹</ci><ci id="S2.p1.5.m5.2.2.2.2.3.3.cmml" xref="S2.p1.5.m5.2.2.2.2.3.3">𝑇</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.2c">(X_{FT},Y_{FT})</annotation></semantics></math>, which does not overlap with the sensitive audio in <math id="S2.p1.6.m6.1" class="ltx_Math" alttext="X_{PT}" display="inline"><semantics id="S2.p1.6.m6.1a"><msub id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">X</mi><mrow id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml"><mi id="S2.p1.6.m6.1.1.3.2" xref="S2.p1.6.m6.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p1.6.m6.1.1.3.1" xref="S2.p1.6.m6.1.1.3.1.cmml">​</mo><mi id="S2.p1.6.m6.1.1.3.3" xref="S2.p1.6.m6.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">𝑋</ci><apply id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3"><times id="S2.p1.6.m6.1.1.3.1.cmml" xref="S2.p1.6.m6.1.1.3.1"></times><ci id="S2.p1.6.m6.1.1.3.2.cmml" xref="S2.p1.6.m6.1.1.3.2">𝑃</ci><ci id="S2.p1.6.m6.1.1.3.3.cmml" xref="S2.p1.6.m6.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">X_{PT}</annotation></semantics></math>. We also carry over several assumptions from the existing noise masking work:</p>
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">The adversary has domain knowledge which allows them to identify target utterances, containing both nonsensitive and sensitive portions, where the former portion can be easily produced, but the latter is unknown (e.g., being able to produce “Mister <span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_markedasmath ltx_font_smallcaps">unknown</span> lives in Seoul”, but not knowing the sensitive name).</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">The adversary has a function <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><mi id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><ci id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">N</annotation></semantics></math>, which adds noise to an utterance, in place of the sensitive utterance portion.</p>
</div>
</li>
</ol>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.5" class="ltx_p"><span id="S2.p2.5.1" class="ltx_text ltx_font_bold">Our Noise Masking Attack.</span>
Our approach begins by taking the encoder model <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">E</annotation></semantics></math> and performing supervised fine tuning on it using <math id="S2.p2.2.m2.2" class="ltx_Math" alttext="(X_{FT},Y_{FT})" display="inline"><semantics id="S2.p2.2.m2.2a"><mrow id="S2.p2.2.m2.2.2.2" xref="S2.p2.2.m2.2.2.3.cmml"><mo stretchy="false" id="S2.p2.2.m2.2.2.2.3" xref="S2.p2.2.m2.2.2.3.cmml">(</mo><msub id="S2.p2.2.m2.1.1.1.1" xref="S2.p2.2.m2.1.1.1.1.cmml"><mi id="S2.p2.2.m2.1.1.1.1.2" xref="S2.p2.2.m2.1.1.1.1.2.cmml">X</mi><mrow id="S2.p2.2.m2.1.1.1.1.3" xref="S2.p2.2.m2.1.1.1.1.3.cmml"><mi id="S2.p2.2.m2.1.1.1.1.3.2" xref="S2.p2.2.m2.1.1.1.1.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.p2.2.m2.1.1.1.1.3.1" xref="S2.p2.2.m2.1.1.1.1.3.1.cmml">​</mo><mi id="S2.p2.2.m2.1.1.1.1.3.3" xref="S2.p2.2.m2.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo id="S2.p2.2.m2.2.2.2.4" xref="S2.p2.2.m2.2.2.3.cmml">,</mo><msub id="S2.p2.2.m2.2.2.2.2" xref="S2.p2.2.m2.2.2.2.2.cmml"><mi id="S2.p2.2.m2.2.2.2.2.2" xref="S2.p2.2.m2.2.2.2.2.2.cmml">Y</mi><mrow id="S2.p2.2.m2.2.2.2.2.3" xref="S2.p2.2.m2.2.2.2.2.3.cmml"><mi id="S2.p2.2.m2.2.2.2.2.3.2" xref="S2.p2.2.m2.2.2.2.2.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.p2.2.m2.2.2.2.2.3.1" xref="S2.p2.2.m2.2.2.2.2.3.1.cmml">​</mo><mi id="S2.p2.2.m2.2.2.2.2.3.3" xref="S2.p2.2.m2.2.2.2.2.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S2.p2.2.m2.2.2.2.5" xref="S2.p2.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.2b"><interval closure="open" id="S2.p2.2.m2.2.2.3.cmml" xref="S2.p2.2.m2.2.2.2"><apply id="S2.p2.2.m2.1.1.1.1.cmml" xref="S2.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.2.m2.1.1.1.1.1.cmml" xref="S2.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S2.p2.2.m2.1.1.1.1.2.cmml" xref="S2.p2.2.m2.1.1.1.1.2">𝑋</ci><apply id="S2.p2.2.m2.1.1.1.1.3.cmml" xref="S2.p2.2.m2.1.1.1.1.3"><times id="S2.p2.2.m2.1.1.1.1.3.1.cmml" xref="S2.p2.2.m2.1.1.1.1.3.1"></times><ci id="S2.p2.2.m2.1.1.1.1.3.2.cmml" xref="S2.p2.2.m2.1.1.1.1.3.2">𝐹</ci><ci id="S2.p2.2.m2.1.1.1.1.3.3.cmml" xref="S2.p2.2.m2.1.1.1.1.3.3">𝑇</ci></apply></apply><apply id="S2.p2.2.m2.2.2.2.2.cmml" xref="S2.p2.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p2.2.m2.2.2.2.2.1.cmml" xref="S2.p2.2.m2.2.2.2.2">subscript</csymbol><ci id="S2.p2.2.m2.2.2.2.2.2.cmml" xref="S2.p2.2.m2.2.2.2.2.2">𝑌</ci><apply id="S2.p2.2.m2.2.2.2.2.3.cmml" xref="S2.p2.2.m2.2.2.2.2.3"><times id="S2.p2.2.m2.2.2.2.2.3.1.cmml" xref="S2.p2.2.m2.2.2.2.2.3.1"></times><ci id="S2.p2.2.m2.2.2.2.2.3.2.cmml" xref="S2.p2.2.m2.2.2.2.2.3.2">𝐹</ci><ci id="S2.p2.2.m2.2.2.2.2.3.3.cmml" xref="S2.p2.2.m2.2.2.2.2.3.3">𝑇</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.2c">(X_{FT},Y_{FT})</annotation></semantics></math>, producing an ASR model <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.p2.3.m3.1a"><mi id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><ci id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">M</annotation></semantics></math>. From here, we can perform noise masking directly on <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.p2.4.m4.1a"><mi id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">M</annotation></semantics></math> as proposed in Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. One significant challenge in our work is that continued training, as done in fine tuning, has been shown to reduce privacy leakage on prior examples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, which in our setting is the privacy leakage on <math id="S2.p2.5.m5.1" class="ltx_Math" alttext="X_{PT}" display="inline"><semantics id="S2.p2.5.m5.1a"><msub id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml"><mi id="S2.p2.5.m5.1.1.2" xref="S2.p2.5.m5.1.1.2.cmml">X</mi><mrow id="S2.p2.5.m5.1.1.3" xref="S2.p2.5.m5.1.1.3.cmml"><mi id="S2.p2.5.m5.1.1.3.2" xref="S2.p2.5.m5.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p2.5.m5.1.1.3.1" xref="S2.p2.5.m5.1.1.3.1.cmml">​</mo><mi id="S2.p2.5.m5.1.1.3.3" xref="S2.p2.5.m5.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><apply id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.cmml" xref="S2.p2.5.m5.1.1">subscript</csymbol><ci id="S2.p2.5.m5.1.1.2.cmml" xref="S2.p2.5.m5.1.1.2">𝑋</ci><apply id="S2.p2.5.m5.1.1.3.cmml" xref="S2.p2.5.m5.1.1.3"><times id="S2.p2.5.m5.1.1.3.1.cmml" xref="S2.p2.5.m5.1.1.3.1"></times><ci id="S2.p2.5.m5.1.1.3.2.cmml" xref="S2.p2.5.m5.1.1.3.2">𝑃</ci><ci id="S2.p2.5.m5.1.1.3.3.cmml" xref="S2.p2.5.m5.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">X_{PT}</annotation></semantics></math>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">High Precision Noise Masking.</span>
While noise masking attacks have been traditionally designed to maximize overall attack success rate, the privacy literature has recently begun to allow adversaries the ability to “abstain” from predictions when they are not confident about the result of an attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. When the adversary abstains from predictions, attack success rate can be evaluated only on trials without abstention. This captures a setting where leakage is more harmful if it is more actionable (i.e., an adversary has higher confidence in the information).</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">We extend noise masking attacks to maximize precision as well, by allowing our adversary to abstain on low confidence attack results. We consider two different ways for an adversary to abstain from a prediction: transcript-based and agreement-based. In transcript-based abstention, the adversary filters out attack outputs which transcribe only the nonsensitive audio. In an agreement-based abstention, the adversary tries multiple types of noises, and only keeps predictions where multiple noise types provide the same transcript. We define how we measure precision in Section <a href="#S3.SS1" title="3.1 Experiment Setup ‣ 3 Experiments ‣ Noise Masking Attacks and Defenses for Pretrained Speech Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We now evaluate the effectiveness of our noise masking attacks. We first describe our experiment setup, and then we evaluate three research questions.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experiment Setup</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">We use the LibriLight dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> for pretraining (i.e., <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="X_{PT}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">X</mi><mrow id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml">T</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝑋</ci><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><times id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">X_{PT}</annotation></semantics></math>), and the LibriSpeech (LS) dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> for fine tuning (i.e., <math id="S3.SS1.p1.2.m2.2" class="ltx_Math" alttext="(X_{FT},Y_{FT})" display="inline"><semantics id="S3.SS1.p1.2.m2.2a"><mrow id="S3.SS1.p1.2.m2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.2.2.2.3" xref="S3.SS1.p1.2.m2.2.2.3.cmml">(</mo><msub id="S3.SS1.p1.2.m2.1.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.1.1.2" xref="S3.SS1.p1.2.m2.1.1.1.1.2.cmml">X</mi><mrow id="S3.SS1.p1.2.m2.1.1.1.1.3" xref="S3.SS1.p1.2.m2.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.1.1.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.1.1.1.1.3.1" xref="S3.SS1.p1.2.m2.1.1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.2.m2.1.1.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.1.1.3.3.cmml">T</mi></mrow></msub><mo id="S3.SS1.p1.2.m2.2.2.2.4" xref="S3.SS1.p1.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.2.m2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.cmml"><mi id="S3.SS1.p1.2.m2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.cmml">Y</mi><mrow id="S3.SS1.p1.2.m2.2.2.2.2.3" xref="S3.SS1.p1.2.m2.2.2.2.2.3.cmml"><mi id="S3.SS1.p1.2.m2.2.2.2.2.3.2" xref="S3.SS1.p1.2.m2.2.2.2.2.3.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.2.2.2.2.3.1" xref="S3.SS1.p1.2.m2.2.2.2.2.3.1.cmml">​</mo><mi id="S3.SS1.p1.2.m2.2.2.2.2.3.3" xref="S3.SS1.p1.2.m2.2.2.2.2.3.3.cmml">T</mi></mrow></msub><mo stretchy="false" id="S3.SS1.p1.2.m2.2.2.2.5" xref="S3.SS1.p1.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.2b"><interval closure="open" id="S3.SS1.p1.2.m2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2"><apply id="S3.SS1.p1.2.m2.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.2">𝑋</ci><apply id="S3.SS1.p1.2.m2.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.3"><times id="S3.SS1.p1.2.m2.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.3.1"></times><ci id="S3.SS1.p1.2.m2.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.3.2">𝐹</ci><ci id="S3.SS1.p1.2.m2.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.3.3">𝑇</ci></apply></apply><apply id="S3.SS1.p1.2.m2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2">𝑌</ci><apply id="S3.SS1.p1.2.m2.2.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.3"><times id="S3.SS1.p1.2.m2.2.2.2.2.3.1.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.3.1"></times><ci id="S3.SS1.p1.2.m2.2.2.2.2.3.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.3.2">𝐹</ci><ci id="S3.SS1.p1.2.m2.2.2.2.2.3.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.3.3">𝑇</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.2c">(X_{FT},Y_{FT})</annotation></semantics></math>). We use these as they are standard datasets for evaluating pretraining and fine tuning. One important consideration for these datasets is their overlap - because LibriSpeech overlaps with LibriLight, if we pretrain a model on LibriLight and fine-tune on LibriSpeech, a noise masking attack on a record from LibriLight could rely on memorization from the a similar record in LibriSpeech, overestimating risk to the pretraining data.
To overcome this confounder, we produce a filtered version of LibriSpeech (LS-NoName) without <em id="S3.SS1.p1.2.1" class="ltx_emph ltx_font_italic">any</em> formatted names<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We find formatted names by searching for the titles “mister”, “miss”, and “misses” in LS transcripts, and filter out those cases where the next word is a common word.</span></span></span>. Then, any successful noise masking attack extracting formatted names must come as a result of memorization of the name seen during pretraining.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">All of our models use the BEST-RQ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> pretraining recipe on a 600M parameter encoder containing a stack of 24 Conformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> models, and are fine-tuned for ASR with CTC loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
All training parameter values are set following the original BEST-RQ setup.
Unless otherwise specified, we run pretraining for 1 million steps.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">To run our attacks, we use roughly 1000 utterances containing names from the LibriSpeech training set (i.e., not contained in LS-NoName), and all of the roughly 80 LibriSpeech test examples which contain names.
Following the setup in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, we consider noise masking with 5 sampled noises per utterance, from ‘car’, cabin noise, ‘cafe’ chatter with background
noise, ‘music’, ‘kitchen’ background noise, and ‘podcast’. We also separately consider silence masking.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Metrics.</span>
We consider multiple metrics, computed over 5 trials. We also sometimes report Word Error Rate (WER) after fine-tuning to measure encoder quality.</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">“Exact name” accuracy - the fraction of utterances for which any attack (i.e., any of the 5 noise samples) successfully recovers the correct name. This reflects the risk to an average sensitive pretraining example.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">“Exact name” precision - the fraction of utterances for which any non-abstained attack successfully recovers the correct name. This reflects how confident an adversary can be in the name produced by an attack.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">“Any name” accuracy - the fraction of utterances for which any name is returned by noise masking. This means someone’s private information has leaked, even if not the exact target.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">“Any name” precision - the fraction of utterances for which any non-abstained attack successfully recovers any name. Private information has leaked, and the adversary is confident that it is private.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Results</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We organize our results around answering three questions.
<span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">RQ1: Is it possible to perform a noise masking attack on pretraining data?</span>
We run our attacks on two models, fine-tuned on LS and LS-NoName for 10,000 steps. We report the results of noise masking in Table <a href="#S3.T1" title="Table 1 ‣ 3.2 Results ‣ 3 Experiments ‣ Noise Masking Attacks and Defenses for Pretrained Speech Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Noise masking attacks are possible on the pretraining data. When finetuning on both LS and LS-NoName, we find our attacks can correctly recover the exact name from roughly 1-2% of training utterances, even without any overlap with the finetuning set (for LS-NoName), and leakage of any name is much higher.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Recall that there is an overlap between LibriSpeech and LibriLight, so results with LS finetuning can be the result of memorization of both pretraining and finetuning data, rather than just pretraining data in LS-NoName. However, even this result is somewhat positive, as attacks on end-to-end ASR training in Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> result in much higher success rates. For example, with silence masking, Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> recover correct names from 11.8% of training utterances, while we recover correct names from only 2.7% of training utterances (although our best attacks are with noise masking). This is likely because more epochs are required to train a good ASR model from scratch compared to a pretrained encoder; Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> train for 100,000 steps, 10 times longer than our models, which allows much more memorization.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.2.1.1" class="ltx_tr">
<th id="S3.T1.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" rowspan="2"><span id="S3.T1.2.1.1.1.1" class="ltx_text">Finetune</span></th>
<th id="S3.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" rowspan="2"><span id="S3.T1.2.1.1.2.1" class="ltx_text">Attack</span></th>
<th id="S3.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Train</th>
<th id="S3.T1.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Test</th>
</tr>
<tr id="S3.T1.2.2.2" class="ltx_tr">
<th id="S3.T1.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Exact</th>
<th id="S3.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Any</th>
<th id="S3.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Any</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.2.3.1" class="ltx_tr">
<th id="S3.T1.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">LS</th>
<th id="S3.T1.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Noise</th>
<td id="S3.T1.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">2.7/2.6</td>
<td id="S3.T1.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">11.9/14.2</td>
<td id="S3.T1.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">5.7/9.3</td>
</tr>
<tr id="S3.T1.2.4.2" class="ltx_tr">
<th id="S3.T1.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">LS</th>
<th id="S3.T1.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Silence</th>
<td id="S3.T1.2.4.2.3" class="ltx_td ltx_align_center">1.4/1.5</td>
<td id="S3.T1.2.4.2.4" class="ltx_td ltx_align_center">6.5/9.3</td>
<td id="S3.T1.2.4.2.5" class="ltx_td ltx_align_center">2.9/3.7</td>
</tr>
<tr id="S3.T1.2.5.3" class="ltx_tr">
<th id="S3.T1.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">LS-NoName</th>
<th id="S3.T1.2.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Noise</th>
<td id="S3.T1.2.5.3.3" class="ltx_td ltx_align_center">1.6/1.5</td>
<td id="S3.T1.2.5.3.4" class="ltx_td ltx_align_center">10.8/13.8</td>
<td id="S3.T1.2.5.3.5" class="ltx_td ltx_align_center">2.9/1.9</td>
</tr>
<tr id="S3.T1.2.6.4" class="ltx_tr">
<th id="S3.T1.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">LS-NoName</th>
<th id="S3.T1.2.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Silence</th>
<td id="S3.T1.2.6.4.3" class="ltx_td ltx_align_center">1.1/1.0</td>
<td id="S3.T1.2.6.4.4" class="ltx_td ltx_align_center">4.9/7.3</td>
<td id="S3.T1.2.6.4.5" class="ltx_td ltx_align_center">0/1.9</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.3.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>It is possible to run a noise masking attack to recover sensitive information seen during pretraining. Each cell contains reported values for the clean/other split from LibriSpeech. We report both exact name accuracy and any name accuracy, measured in percentages. Test Exact results are omitted as they are all 0: the model cannot exactly complete data it has never seen.</figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">RQ2: How precise can noise masking attacks be?</span>
For the attacks in RQ1, we also evaluate their precision using transcript-based and agreement-based filtering as described in Section 2, reporting the best precisions achieved by these approaches in Table <a href="#S3.T2" title="Table 2 ‣ 3.2 Results ‣ 3 Experiments ‣ Noise Masking Attacks and Defenses for Pretrained Speech Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. All of the best results use transcript-based filtering, although sometimes combining transcript and agreement-based filtering outperforms transcript-based filtering alone. Precision can be much higher than accuracy, as transcript and agreement filtering can reliably identify unlikely continuations. For example, silence masking attacks can reach over 12% utterance precision, when these attacks had under 2% accuracy without filtering.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.2.1.1" class="ltx_tr">
<th id="S3.T2.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" rowspan="2"><span id="S3.T2.2.1.1.1.1" class="ltx_text">Finetune</span></th>
<th id="S3.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" rowspan="2"><span id="S3.T2.2.1.1.2.1" class="ltx_text">Attack</span></th>
<th id="S3.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Train</th>
<th id="S3.T2.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Test</th>
</tr>
<tr id="S3.T2.2.2.2" class="ltx_tr">
<th id="S3.T2.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Exact</th>
<th id="S3.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Any</th>
<th id="S3.T2.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Any</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.2.3.1" class="ltx_tr">
<th id="S3.T2.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">LS</th>
<th id="S3.T2.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Noise</th>
<td id="S3.T2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">4.7/4.0</td>
<td id="S3.T2.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">17.0/19.0</td>
<td id="S3.T2.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">15.6/15.2</td>
</tr>
<tr id="S3.T2.2.4.2" class="ltx_tr">
<th id="S3.T2.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">LS</th>
<th id="S3.T2.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Silence</th>
<td id="S3.T2.2.4.2.3" class="ltx_td ltx_align_center">2.5/2.6</td>
<td id="S3.T2.2.4.2.4" class="ltx_td ltx_align_center">35.9/45.5</td>
<td id="S3.T2.2.4.2.5" class="ltx_td ltx_align_center">33.3/35.2</td>
</tr>
<tr id="S3.T2.2.5.3" class="ltx_tr">
<th id="S3.T2.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">LS-NoName</th>
<th id="S3.T2.2.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Noise</th>
<td id="S3.T2.2.5.3.3" class="ltx_td ltx_align_center">2.1/3.0</td>
<td id="S3.T2.2.5.3.4" class="ltx_td ltx_align_center">12.8/20.5</td>
<td id="S3.T2.2.5.3.5" class="ltx_td ltx_align_center">3.6/0</td>
</tr>
<tr id="S3.T2.2.6.4" class="ltx_tr">
<th id="S3.T2.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">LS-NoName</th>
<th id="S3.T2.2.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Silence</th>
<td id="S3.T2.2.6.4.3" class="ltx_td ltx_align_center">8.5/7.6</td>
<td id="S3.T2.2.6.4.4" class="ltx_td ltx_align_center">25.6/37.9</td>
<td id="S3.T2.2.6.4.5" class="ltx_td ltx_align_center">0/0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.3.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>Noise masking can be made more precise (often substantially) by abstaining from attack predictions where the adversary has low confidence. We report the best filtering strategy for each result. Transcript-based filtering is always effective, and combining it alignment-based filtering can sometimes improve precision further. Each cell contains precision, in percentages, for the clean/other split from LibriSpeech. Test Exact results are all 0, as in Table <a href="#S3.T1" title="Table 1 ‣ 3.2 Results ‣ 3 Experiments ‣ Noise Masking Attacks and Defenses for Pretrained Speech Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</figcaption>
</figure>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">RQ3: Are there any modeling/training choices which impact the risk of the attack to the pretraining data?</span>
We experiment with pretraining length and codebook dimension for pretraining. Intuitively, shorter pretraining results in less effective noise masking, due to less ability to memorize pretraining data — pretraining for only 20k steps instead of 1M steps (50 times shorter) results in worse attacks (accuracy of 0.1/0.2), but also significantly higher WER (8.7 instead of 3.6). We also experiment with changing BestRQ parameters such as the codebook dimension and vocab size, which control the size of the random projections used for tokenization in BestRQ pretraining. In general, we find that changing these parameters from their defaults (codebook dimension of 16, and vocab size of 8192) has little impact on noise masking risk, except for when model performance is harmed. For a very small codebook dimension of 2, WER increases from 4.0 to 4.6, and reduces exact name accuracy to only 0.1% under silence masking. For the remaining models, attacks perform comparably to the results reported in Table <a href="#S3.T1" title="Table 1 ‣ 3.2 Results ‣ 3 Experiments ‣ Noise Masking Attacks and Defenses for Pretrained Speech Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Mitigations</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We consider a number of mitigations for our attacks, inspired by those proposed in prior work to prevent noise masking directly, and those that have been considered in the literature for defending against other types of extraction attacks.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Our Mitigations</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Data Sanitization.</span> Data curation has been proposed in prior work to mitigate extraction attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Intuitively, removing sensitive data from pretraining will prevent it from being memorized. However, such curation can be difficult, as curating before training requires anticipating all potential sensitivities in the dataset. Furthermore, detecting such sensitivity at scale is challenging, as it may require training an additional model, such as a sensitivity classifier, and running that model over all pretraining data. We propose here an ideal defense for our noise masking attacks, where the learner removes all names from LibriLight. To construct this dataset, we automatically transcribe all of LibriLight with an ASR model, and then filter out all utterances whose transcripts contain any formatted name, similar to how we created LS-NoName earlier.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Modified Pretraining.</span> Amid et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> show that modifying ASR training by adding silences and noise (through MTR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>) can reduce the model’s propensity to complete noise masked utterances. Our learner cannot influence the ASR model’s training, so we experiment instead with using MTR (with the same parameters as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>) and silencing during pretraining. Both these approaches can encourage the pretrained model to predict noise/silence when given noisy/silent context, potentially reducing how frequently the fine-tuned model “overconfidently” makes predictions with a noise masking attack. For silence masking during pretraining, we consider adding 100ms and 500ms of silence, but only report results for 100ms silence due to the limited impact of this parameter.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.15" class="ltx_p"><span id="S4.SS1.p3.15.1" class="ltx_text ltx_font_bold">Data Deduplication.</span>
Prior work has shown that deduplicating training data can mitigate extraction risk in language models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and diffusion models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. However, these works consider extraction of entire records or large portions of records, while our focus is on extracting small subrecords. To deduplicate sensitive data, such as names, we choose to deduplicate our pretraining dataset by removing highly duplicated <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">k</annotation></semantics></math>-grams in the transcripts of utterances. Our deduplication approach, which we call DD-<math id="S4.SS1.p3.2.m2.2" class="ltx_Math" alttext="(k,p)" display="inline"><semantics id="S4.SS1.p3.2.m2.2a"><mrow id="S4.SS1.p3.2.m2.2.3.2" xref="S4.SS1.p3.2.m2.2.3.1.cmml"><mo stretchy="false" id="S4.SS1.p3.2.m2.2.3.2.1" xref="S4.SS1.p3.2.m2.2.3.1.cmml">(</mo><mi id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml">k</mi><mo id="S4.SS1.p3.2.m2.2.3.2.2" xref="S4.SS1.p3.2.m2.2.3.1.cmml">,</mo><mi id="S4.SS1.p3.2.m2.2.2" xref="S4.SS1.p3.2.m2.2.2.cmml">p</mi><mo stretchy="false" id="S4.SS1.p3.2.m2.2.3.2.3" xref="S4.SS1.p3.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.2b"><interval closure="open" id="S4.SS1.p3.2.m2.2.3.1.cmml" xref="S4.SS1.p3.2.m2.2.3.2"><ci id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">𝑘</ci><ci id="S4.SS1.p3.2.m2.2.2.cmml" xref="S4.SS1.p3.2.m2.2.2">𝑝</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.2c">(k,p)</annotation></semantics></math> has two parameters: <math id="S4.SS1.p3.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p3.3.m3.1a"><mi id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><ci id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">k</annotation></semantics></math>, the length of <math id="S4.SS1.p3.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p3.4.m4.1a"><mi id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><ci id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">k</annotation></semantics></math>-grams to use for deduplication, and <math id="S4.SS1.p3.5.m5.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS1.p3.5.m5.1a"><mi id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><ci id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">p</annotation></semantics></math>, the fraction of the dataset to remove. That is, we remove the most highly duplicated <math id="S4.SS1.p3.6.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p3.6.m6.1a"><mi id="S4.SS1.p3.6.m6.1.1" xref="S4.SS1.p3.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m6.1b"><ci id="S4.SS1.p3.6.m6.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m6.1c">k</annotation></semantics></math>-grams until a <math id="S4.SS1.p3.7.m7.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS1.p3.7.m7.1a"><mi id="S4.SS1.p3.7.m7.1.1" xref="S4.SS1.p3.7.m7.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.7.m7.1b"><ci id="S4.SS1.p3.7.m7.1.1.cmml" xref="S4.SS1.p3.7.m7.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.7.m7.1c">p</annotation></semantics></math> fraction of the dataset has been removed. Note that names may not be the most duplicated <math id="S4.SS1.p3.8.m8.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p3.8.m8.1a"><mi id="S4.SS1.p3.8.m8.1.1" xref="S4.SS1.p3.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.8.m8.1b"><ci id="S4.SS1.p3.8.m8.1.1.cmml" xref="S4.SS1.p3.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.8.m8.1c">k</annotation></semantics></math>-grams, so even large values of <math id="S4.SS1.p3.9.m9.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS1.p3.9.m9.1a"><mi id="S4.SS1.p3.9.m9.1.1" xref="S4.SS1.p3.9.m9.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.9.m9.1b"><ci id="S4.SS1.p3.9.m9.1.1.cmml" xref="S4.SS1.p3.9.m9.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.9.m9.1c">p</annotation></semantics></math> may remove few names. We vary <math id="S4.SS1.p3.10.m10.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p3.10.m10.1a"><mi id="S4.SS1.p3.10.m10.1.1" xref="S4.SS1.p3.10.m10.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.10.m10.1b"><ci id="S4.SS1.p3.10.m10.1.1.cmml" xref="S4.SS1.p3.10.m10.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.10.m10.1c">k</annotation></semantics></math> from 3 and 5, and set <math id="S4.SS1.p3.11.m11.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS1.p3.11.m11.1a"><mi id="S4.SS1.p3.11.m11.1.1" xref="S4.SS1.p3.11.m11.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.11.m11.1b"><ci id="S4.SS1.p3.11.m11.1.1.cmml" xref="S4.SS1.p3.11.m11.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.11.m11.1c">p</annotation></semantics></math> to remove no more than 10% of the training set. For <math id="S4.SS1.p3.12.m12.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.SS1.p3.12.m12.1a"><mn id="S4.SS1.p3.12.m12.1.1" xref="S4.SS1.p3.12.m12.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.12.m12.1b"><cn type="integer" id="S4.SS1.p3.12.m12.1.1.cmml" xref="S4.SS1.p3.12.m12.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.12.m12.1c">3</annotation></semantics></math>-grams, we find that removing 35% of the dataset is required to remove even 1% of <math id="S4.SS1.p3.13.m13.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS1.p3.13.m13.1a"><mi id="S4.SS1.p3.13.m13.1.1" xref="S4.SS1.p3.13.m13.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.13.m13.1b"><ci id="S4.SS1.p3.13.m13.1.1.cmml" xref="S4.SS1.p3.13.m13.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.13.m13.1c">k</annotation></semantics></math>-grams containing names, so we set <math id="S4.SS1.p3.14.m14.1" class="ltx_Math" alttext="p=0.35" display="inline"><semantics id="S4.SS1.p3.14.m14.1a"><mrow id="S4.SS1.p3.14.m14.1.1" xref="S4.SS1.p3.14.m14.1.1.cmml"><mi id="S4.SS1.p3.14.m14.1.1.2" xref="S4.SS1.p3.14.m14.1.1.2.cmml">p</mi><mo id="S4.SS1.p3.14.m14.1.1.1" xref="S4.SS1.p3.14.m14.1.1.1.cmml">=</mo><mn id="S4.SS1.p3.14.m14.1.1.3" xref="S4.SS1.p3.14.m14.1.1.3.cmml">0.35</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.14.m14.1b"><apply id="S4.SS1.p3.14.m14.1.1.cmml" xref="S4.SS1.p3.14.m14.1.1"><eq id="S4.SS1.p3.14.m14.1.1.1.cmml" xref="S4.SS1.p3.14.m14.1.1.1"></eq><ci id="S4.SS1.p3.14.m14.1.1.2.cmml" xref="S4.SS1.p3.14.m14.1.1.2">𝑝</ci><cn type="float" id="S4.SS1.p3.14.m14.1.1.3.cmml" xref="S4.SS1.p3.14.m14.1.1.3">0.35</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.14.m14.1c">p=0.35</annotation></semantics></math> for <math id="S4.SS1.p3.15.m15.1" class="ltx_Math" alttext="k=3" display="inline"><semantics id="S4.SS1.p3.15.m15.1a"><mrow id="S4.SS1.p3.15.m15.1.1" xref="S4.SS1.p3.15.m15.1.1.cmml"><mi id="S4.SS1.p3.15.m15.1.1.2" xref="S4.SS1.p3.15.m15.1.1.2.cmml">k</mi><mo id="S4.SS1.p3.15.m15.1.1.1" xref="S4.SS1.p3.15.m15.1.1.1.cmml">=</mo><mn id="S4.SS1.p3.15.m15.1.1.3" xref="S4.SS1.p3.15.m15.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.15.m15.1b"><apply id="S4.SS1.p3.15.m15.1.1.cmml" xref="S4.SS1.p3.15.m15.1.1"><eq id="S4.SS1.p3.15.m15.1.1.1.cmml" xref="S4.SS1.p3.15.m15.1.1.1"></eq><ci id="S4.SS1.p3.15.m15.1.1.2.cmml" xref="S4.SS1.p3.15.m15.1.1.2">𝑘</ci><cn type="integer" id="S4.SS1.p3.15.m15.1.1.3.cmml" xref="S4.SS1.p3.15.m15.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.15.m15.1c">k=3</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We run pretraining with each mitigation, and apply our noise masking attack to each resulting encoder after fine tuning on LS-NoName. We report the attack accuracies in Table <a href="#S4.T3" title="Table 3 ‣ 4.2 Results ‣ 4 Mitigations ‣ Noise Masking Attacks and Defenses for Pretrained Speech Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We do not report silence masking results due to their qualitatively similar results to noise masking. We measure encoder quality with the ASR model’s WER on Librispeech test-other partition, but among mitigations we find limited WER difference.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Our most successful mitigation is data sanitization, with near-zero exact name accuracy. Despite removing all names, data sanitization does not perfectly prevent the attack, likely due to some imperfection in our name filtering or inaccuracies in our transcription which we use to filter.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">We also observe small exact name attack success rates when modifying pretraining with MTR and when combined with silencing. This parallels the effectiveness of a comparable combined strategy from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Interestingly, silencing alone is not effective, even against silencing attacks. This could be the result of “catastrophic forgetting” <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> during fine tuning of the silencing behavior seen during pretraining.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.5" class="ltx_p">Deduplication has limited effectiveness at mitigating our attacks, with attack success rates as high or even higher than unmitigated results. This poor performance is likely the result of many names remaining in the pretraining data, due to not being duplicated enough to be removed. For example, by removing highly duplicated <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><mn id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><cn type="integer" id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">3</annotation></semantics></math>-grams to remove <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="35\%" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><mrow id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mn id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml">35</mn><mo id="S4.SS2.p4.2.m2.1.1.1" xref="S4.SS2.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">35</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">35\%</annotation></semantics></math> of the pretraining data, we deduplicate only <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mrow id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml"><mn id="S4.SS2.p4.3.m3.1.1.2" xref="S4.SS2.p4.3.m3.1.1.2.cmml">5</mn><mo id="S4.SS2.p4.3.m3.1.1.1" xref="S4.SS2.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><apply id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.p4.3.m3.1.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p4.3.m3.1.1.2.cmml" xref="S4.SS2.p4.3.m3.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">5\%</annotation></semantics></math> of <math id="S4.SS2.p4.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.SS2.p4.4.m4.1a"><mn id="S4.SS2.p4.4.m4.1.1" xref="S4.SS2.p4.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.1b"><cn type="integer" id="S4.SS2.p4.4.m4.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.1c">3</annotation></semantics></math>-grams with names. Diverse pretraining data could contain sensitive <math id="S4.SS2.p4.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.p4.5.m5.1a"><mi id="S4.SS2.p4.5.m5.1.1" xref="S4.SS2.p4.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m5.1b"><ci id="S4.SS2.p4.5.m5.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m5.1c">k</annotation></semantics></math>-grams of varying lengths, so deduplication is unlikely to be a panacea for dealing with privacy risks in speech data.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">No mitigation significantly reduces the “any name” accuracy. This could be the result of the model repeating names found in non-formatted contexts. We also remark that these accuracies are still lower than those found for the best mitigation on end-to-end ASR training from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.4.5.1" class="ltx_tr">
<th id="S4.T3.4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" rowspan="2"><span id="S4.T3.4.5.1.1.1" class="ltx_text">Mitigation</span></th>
<th id="S4.T3.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" rowspan="2"><span id="S4.T3.4.5.1.2.1" class="ltx_text">WER</span></th>
<th id="S4.T3.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Train</th>
<th id="S4.T3.4.5.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Test</th>
</tr>
<tr id="S4.T3.4.6.2" class="ltx_tr">
<th id="S4.T3.4.6.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Exact</th>
<th id="S4.T3.4.6.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Any</th>
<th id="S4.T3.4.6.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Any</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.4.7.1" class="ltx_tr">
<th id="S4.T3.4.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">None (Baseline)</th>
<th id="S4.T3.4.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">4.0</th>
<td id="S4.T3.4.7.1.3" class="ltx_td ltx_align_center ltx_border_t">1.6/1.5</td>
<td id="S4.T3.4.7.1.4" class="ltx_td ltx_align_center ltx_border_t">10.8/13.8</td>
<td id="S4.T3.4.7.1.5" class="ltx_td ltx_align_center ltx_border_t">2.9/1.9</td>
</tr>
<tr id="S4.T3.4.8.2" class="ltx_tr">
<th id="S4.T3.4.8.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sanitization</th>
<th id="S4.T3.4.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4.4</th>
<td id="S4.T3.4.8.2.3" class="ltx_td ltx_align_center">0/0.3</td>
<td id="S4.T3.4.8.2.4" class="ltx_td ltx_align_center">10.0/12.0</td>
<td id="S4.T3.4.8.2.5" class="ltx_td ltx_align_center">8.6/3.7</td>
</tr>
<tr id="S4.T3.4.9.3" class="ltx_tr">
<th id="S4.T3.4.9.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Silence</th>
<th id="S4.T3.4.9.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4.0</th>
<td id="S4.T3.4.9.3.3" class="ltx_td ltx_align_center">2.9/1.3</td>
<td id="S4.T3.4.9.3.4" class="ltx_td ltx_align_center">13.5/14.5</td>
<td id="S4.T3.4.9.3.5" class="ltx_td ltx_align_center">5.7/7.4</td>
</tr>
<tr id="S4.T3.4.10.4" class="ltx_tr">
<th id="S4.T3.4.10.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">MTR</th>
<th id="S4.T3.4.10.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4.6</th>
<td id="S4.T3.4.10.4.3" class="ltx_td ltx_align_center">0.4/0.4</td>
<td id="S4.T3.4.10.4.4" class="ltx_td ltx_align_center">12.7/13.6</td>
<td id="S4.T3.4.10.4.5" class="ltx_td ltx_align_center">8.6/7.4</td>
</tr>
<tr id="S4.T3.4.11.5" class="ltx_tr">
<th id="S4.T3.4.11.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Silence+MTR</th>
<th id="S4.T3.4.11.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4.0</th>
<td id="S4.T3.4.11.5.3" class="ltx_td ltx_align_center">0.1/0.3</td>
<td id="S4.T3.4.11.5.4" class="ltx_td ltx_align_center">13.8/14.8</td>
<td id="S4.T3.4.11.5.5" class="ltx_td ltx_align_center">5.7/1.9</td>
</tr>
<tr id="S4.T3.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">DD-<math id="S4.T3.1.1.1.m1.2" class="ltx_Math" alttext="(3,0.35)" display="inline"><semantics id="S4.T3.1.1.1.m1.2a"><mrow id="S4.T3.1.1.1.m1.2.3.2" xref="S4.T3.1.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T3.1.1.1.m1.2.3.2.1" xref="S4.T3.1.1.1.m1.2.3.1.cmml">(</mo><mn id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml">3</mn><mo id="S4.T3.1.1.1.m1.2.3.2.2" xref="S4.T3.1.1.1.m1.2.3.1.cmml">,</mo><mn id="S4.T3.1.1.1.m1.2.2" xref="S4.T3.1.1.1.m1.2.2.cmml">0.35</mn><mo stretchy="false" id="S4.T3.1.1.1.m1.2.3.2.3" xref="S4.T3.1.1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.2b"><interval closure="open" id="S4.T3.1.1.1.m1.2.3.1.cmml" xref="S4.T3.1.1.1.m1.2.3.2"><cn type="integer" id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">3</cn><cn type="float" id="S4.T3.1.1.1.m1.2.2.cmml" xref="S4.T3.1.1.1.m1.2.2">0.35</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.2c">(3,0.35)</annotation></semantics></math>
</th>
<th id="S4.T3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4.0</th>
<td id="S4.T3.1.1.3" class="ltx_td ltx_align_center">0.6/1.1</td>
<td id="S4.T3.1.1.4" class="ltx_td ltx_align_center">10.4/14.1</td>
<td id="S4.T3.1.1.5" class="ltx_td ltx_align_center">5.7/7.4</td>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<th id="S4.T3.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">DD-<math id="S4.T3.2.2.1.m1.2" class="ltx_Math" alttext="(4,0.05)" display="inline"><semantics id="S4.T3.2.2.1.m1.2a"><mrow id="S4.T3.2.2.1.m1.2.3.2" xref="S4.T3.2.2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T3.2.2.1.m1.2.3.2.1" xref="S4.T3.2.2.1.m1.2.3.1.cmml">(</mo><mn id="S4.T3.2.2.1.m1.1.1" xref="S4.T3.2.2.1.m1.1.1.cmml">4</mn><mo id="S4.T3.2.2.1.m1.2.3.2.2" xref="S4.T3.2.2.1.m1.2.3.1.cmml">,</mo><mn id="S4.T3.2.2.1.m1.2.2" xref="S4.T3.2.2.1.m1.2.2.cmml">0.05</mn><mo stretchy="false" id="S4.T3.2.2.1.m1.2.3.2.3" xref="S4.T3.2.2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.2b"><interval closure="open" id="S4.T3.2.2.1.m1.2.3.1.cmml" xref="S4.T3.2.2.1.m1.2.3.2"><cn type="integer" id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1">4</cn><cn type="float" id="S4.T3.2.2.1.m1.2.2.cmml" xref="S4.T3.2.2.1.m1.2.2">0.05</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.2c">(4,0.05)</annotation></semantics></math>
</th>
<th id="S4.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3.8</th>
<td id="S4.T3.2.2.3" class="ltx_td ltx_align_center">1.4/0.5</td>
<td id="S4.T3.2.2.4" class="ltx_td ltx_align_center">12.3/14.1</td>
<td id="S4.T3.2.2.5" class="ltx_td ltx_align_center">5.7/5.6</td>
</tr>
<tr id="S4.T3.3.3" class="ltx_tr">
<th id="S4.T3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">DD-<math id="S4.T3.3.3.1.m1.2" class="ltx_Math" alttext="(4,0.1)" display="inline"><semantics id="S4.T3.3.3.1.m1.2a"><mrow id="S4.T3.3.3.1.m1.2.3.2" xref="S4.T3.3.3.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T3.3.3.1.m1.2.3.2.1" xref="S4.T3.3.3.1.m1.2.3.1.cmml">(</mo><mn id="S4.T3.3.3.1.m1.1.1" xref="S4.T3.3.3.1.m1.1.1.cmml">4</mn><mo id="S4.T3.3.3.1.m1.2.3.2.2" xref="S4.T3.3.3.1.m1.2.3.1.cmml">,</mo><mn id="S4.T3.3.3.1.m1.2.2" xref="S4.T3.3.3.1.m1.2.2.cmml">0.1</mn><mo stretchy="false" id="S4.T3.3.3.1.m1.2.3.2.3" xref="S4.T3.3.3.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.1.m1.2b"><interval closure="open" id="S4.T3.3.3.1.m1.2.3.1.cmml" xref="S4.T3.3.3.1.m1.2.3.2"><cn type="integer" id="S4.T3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.1.m1.1.1">4</cn><cn type="float" id="S4.T3.3.3.1.m1.2.2.cmml" xref="S4.T3.3.3.1.m1.2.2">0.1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.1.m1.2c">(4,0.1)</annotation></semantics></math>
</th>
<th id="S4.T3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4.0</th>
<td id="S4.T3.3.3.3" class="ltx_td ltx_align_center">2.3/1.3</td>
<td id="S4.T3.3.3.4" class="ltx_td ltx_align_center">13.2/15.2</td>
<td id="S4.T3.3.3.5" class="ltx_td ltx_align_center">8.6/7.4</td>
</tr>
<tr id="S4.T3.4.4" class="ltx_tr">
<th id="S4.T3.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">DD-<math id="S4.T3.4.4.1.m1.2" class="ltx_Math" alttext="(5,0.05)" display="inline"><semantics id="S4.T3.4.4.1.m1.2a"><mrow id="S4.T3.4.4.1.m1.2.3.2" xref="S4.T3.4.4.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T3.4.4.1.m1.2.3.2.1" xref="S4.T3.4.4.1.m1.2.3.1.cmml">(</mo><mn id="S4.T3.4.4.1.m1.1.1" xref="S4.T3.4.4.1.m1.1.1.cmml">5</mn><mo id="S4.T3.4.4.1.m1.2.3.2.2" xref="S4.T3.4.4.1.m1.2.3.1.cmml">,</mo><mn id="S4.T3.4.4.1.m1.2.2" xref="S4.T3.4.4.1.m1.2.2.cmml">0.05</mn><mo stretchy="false" id="S4.T3.4.4.1.m1.2.3.2.3" xref="S4.T3.4.4.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.1.m1.2b"><interval closure="open" id="S4.T3.4.4.1.m1.2.3.1.cmml" xref="S4.T3.4.4.1.m1.2.3.2"><cn type="integer" id="S4.T3.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.1.m1.1.1">5</cn><cn type="float" id="S4.T3.4.4.1.m1.2.2.cmml" xref="S4.T3.4.4.1.m1.2.2">0.05</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.1.m1.2c">(5,0.05)</annotation></semantics></math>
</th>
<th id="S4.T3.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4.0</th>
<td id="S4.T3.4.4.3" class="ltx_td ltx_align_center">1.6/1.3</td>
<td id="S4.T3.4.4.4" class="ltx_td ltx_align_center">9.8/13.5</td>
<td id="S4.T3.4.4.5" class="ltx_td ltx_align_center">14.3/1.9</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.6.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>Noise masking can be mitigated. Our best mitigations are silence masking + MTR and data sanitization, while data deduplication and silence masking are not very effective.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our work finds that privacy leakage is possible on sensitive data seen only during pretraining time. Our attacks are less successful than those on end-to-end ASR models trained on sensitive data as in prior work, but due to the continued risk, we propose data curation and training techniques to limit the risks of privacy attacks. Stronger attacks than those we devise may be possible using more sophisticated noise generation or attack model training, so we also recommend continued research into privacy-preserving training techniques.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
E. Amid, O. D. Thakkar, A. Narayanan, R. Mathews, and F. Beaufays, “Extracting
targeted training data from ASR models, and how to mitigate it,” in
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Interspeech 2022, 23rd Annual Conference of the International Speech
Communication Association</em>, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
C. Chiu, J. Qin, Y. Zhang, J. Yu, and Y. Wu, “Self-supervised learning with
random-projection quantizer for speech recognition,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">International
Conference on Machine Learning, ICML 2022</em>, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y. Zhang, W. Han, J. Qin, Y. Wang, A. Bapna, Z. Chen, N. Chen, B. Li,
V. Axelrod, G. Wang <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Google usm: Scaling automatic speech
recognition beyond 100 languages,” <em id="bib.bib3.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.01037</em>,
2023.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
R. Shokri, M. Stronati, C. Song, and V. Shmatikov, “Membership inference
attacks against machine learning models,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">2017 IEEE symposium on
security and privacy (SP)</em>.   IEEE,
2017, pp. 3–18.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
N. Carlini, F. Tramer, E. Wallace, M. Jagielski, A. Herbert-Voss, K. Lee,
A. Roberts, T. Brown, D. Song, U. Erlingsson <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Extracting
training data from large language models,” in <em id="bib.bib5.2.2" class="ltx_emph ltx_font_italic">30th USENIX Security
Symposium (USENIX Security 21)</em>, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
W. R. Huang, S. Chien, O. D. Thakkar, and R. Mathews, “Detecting unintended
memorization in language-model-fused ASR,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Interspeech 2022, 23rd
Annual Conference of the International Speech Communication
Association</em>.   ISCA, 2022, pp.
2808–2812.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
C. Guo, F. Bordes, P. Vincent, and K. Chaudhuri, “Do ssl models have
d<math id="bib.bib7.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="bib.bib7.1.m1.1a"><mo id="bib.bib7.1.m1.1.1" xref="bib.bib7.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="bib.bib7.1.m1.1b"><ci id="bib.bib7.1.m1.1.1.cmml" xref="bib.bib7.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib7.1.m1.1c">\backslash</annotation></semantics></math>’ej<math id="bib.bib7.2.m2.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="bib.bib7.2.m2.1a"><mo id="bib.bib7.2.m2.1.1" xref="bib.bib7.2.m2.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="bib.bib7.2.m2.1b"><ci id="bib.bib7.2.m2.1.1.cmml" xref="bib.bib7.2.m2.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib7.2.m2.1c">\backslash</annotation></semantics></math>a vu? a case of unintended memorization in
self-supervised learning,” <em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.13850</em>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J. Abascal, S. Wu, A. Oprea, and J. Ullman, “Tmi! finetuned models leak
private information from their pretraining data,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2306.01181</em>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M. Jagielski, O. Thakkar, F. Tramer, D. Ippolito, K. Lee, N. Carlini,
E. Wallace, S. Song, A. G. Thakurta, N. Papernot <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Measuring
forgetting of memorized training examples,” in <em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic">The Eleventh
International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
K. Leino and M. Fredrikson, “Stolen memories: Leveraging model memorization
for calibrated <math id="bib.bib10.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib10.1.m1.1a"><mo stretchy="false" id="bib.bib10.1.m1.1.1" xref="bib.bib10.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib10.1.m1.1b"><ci id="bib.bib10.1.m1.1.1.cmml" xref="bib.bib10.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib10.1.m1.1c">\{</annotation></semantics></math>White-Box<math id="bib.bib10.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib10.2.m2.1a"><mo stretchy="false" id="bib.bib10.2.m2.1.1" xref="bib.bib10.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib10.2.m2.1b"><ci id="bib.bib10.2.m2.1.1.cmml" xref="bib.bib10.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib10.2.m2.1c">\}</annotation></semantics></math> membership inference,” in <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">29th USENIX
security symposium (USENIX Security 20)</em>, 2020, pp. 1605–1622.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
N. Carlini, S. Chien, M. Nasr, S. Song, A. Terzis, and F. Tramer, “Membership
inference attacks from first principles,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">2022 IEEE Symposium on
Security and Privacy (SP)</em>.   IEEE,
2022, pp. 1897–1914.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J. Kahn, M. Rivière, W. Zheng, E. Kharitonov, Q. Xu, P. Mazaré,
J. Karadayi, V. Liptchinsky, R. Collobert, C. Fuegen, T. Likhomanenko,
G. Synnaeve, A. Joulin, A. Mohamed, and E. Dupoux, “Libri-light: A
benchmark for ASR with limited or no supervision,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">2020 IEEE
International Conference on Acoustics, Speech and Signal Processing, ICASSP
2020</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “Librispeech: An ASR
corpus based on public domain audio books,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">2015 IEEE
International Conference on Acoustics, Speech and Signal Processing, ICASSP
2015</em>.   IEEE, 2015, pp. 5206–5210.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. Gulati, J. Qin, C. Chiu, N. Parmar, Y. Zhang, J. Yu, W. Han, S. Wang,
Z. Zhang, Y. Wu, and R. Pang, “Conformer: Convolution-augmented transformer
for speech recognition,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Interspeech 2020, 21st Annual Conference
of the International Speech Communication Association</em>.   ISCA, 2020, pp. 5036–5040.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A. Graves and A. Graves, “Connectionist temporal classification,”
<em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Supervised sequence labelling with recurrent neural networks</em>, pp.
61–93, 2012.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
N. Lukas, A. Salem, R. Sim, S. Tople, L. Wutschitz, and
S. Zanella-Béguelin, “Analyzing leakage of personally identifiable
information in language models,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.00539</em>,
2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
C. Kim, A. Misra, K. K. Chin, T. Hughes, A. Narayanan, T. N. Sainath, and
M. Bacchiani, “Generation of large-scale simulated utterances in virtual
rooms to train deep-neural networks for far-field speech recognition in
google home,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Interspeech 2017, 18th Annual Conference of the
International Speech Communication Association</em>.   ISCA, 2017, pp. 379–383.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
K. Lee, D. Ippolito, A. Nystrom, C. Zhang, D. Eck, C. Callison-Burch, and
N. Carlini, “Deduplicating training data makes language models better,”
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06499</em>, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
N. Kandpal, E. Wallace, and C. Raffel, “Deduplicating training data mitigates
privacy risks in language models,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">International Conference on
Machine Learning</em>.   PMLR, 2022, pp.
10 697–10 707.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
N. Carlini, J. Hayes, M. Nasr, M. Jagielski, V. Sehwag, F. Tramer, B. Balle,
D. Ippolito, and E. Wallace, “Extracting training data from diffusion
models,” in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">32nd USENIX Security Symposium (USENIX Security 23)</em>,
2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M. McCloskey and N. J. Cohen, “Catastrophic interference in connectionist
networks: The sequential learning problem,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Psychology of learning
and motivation</em>.   Elsevier, 1989,
vol. 24, pp. 109–165.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.02051" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.02052" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.02052">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.02052" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.02053" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 17:33:40 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
