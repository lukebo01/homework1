<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.07966] ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE</title><meta property="og:description" content="Audio-driven 3D facial animation synthesis has been an active field of research with attention from both academia and industry. While there are promising results in this area, recent approaches largely focus on lip-synâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.07966">

<!--Generated on Sun Oct  6 00:29:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="facial animation synthesis,  deep learning,  virtual humans,  non-deterministic models,  emotion-controlled facial animation">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sichun Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Utrecht University</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Utrecht</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">The Netherlands</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:wsc462@gmail.com">wsc462@gmail.com</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kazi Injamamul Haque
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Utrecht University</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Utrecht</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">The Netherlands</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:k.i.haque@uu.nl">k.i.haque@uu.nl</a>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zerrin Yumak
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">Utrecht University</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Utrecht</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">The Netherlands</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:z.yumak@uu.nl">z.yumak@uu.nl</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id10.id1" class="ltx_p">Audio-driven 3D facial animation synthesis has been an active field of research with attention from both academia and industry. While there are promising results in this area, recent approaches largely focus on lip-sync and identity control, neglecting the role of emotions and emotion control in the generative process. That is mainly due to the lack of emotionally rich facial animation data and algorithms that can synthesize speech animations with emotional expressions at the same time. In addition, majority of the models are deterministic, meaning given the same audio input, they produce the same output motion. We argue that emotions and non-determinism are crucial to generate diverse and emotionally-rich facial animations. In this paper, we propose ProbTalk3D a non-deterministic neural network approach for emotion controllable speech-driven 3D facial animation synthesis using a two-stage VQ-VAE model and an emotionally rich facial animation dataset 3DMEAD. We provide an extensive comparative analysis of our model against the recent 3D facial animation synthesis approaches, by evaluating the results objectively, qualitatively, and with a perceptual user study. We highlight several objective metrics that are more suitable for evaluating stochastic outputs and use both in-the-wild and ground truth data for subjective evaluation. To our knowledge, that is the first non-deterministic 3D facial animation synthesis method incorporating a rich emotion dataset and emotion control with emotion labels and intensity levels. Our evaluation demonstrates that the proposed model achieves superior performance compared to state-of-the-art emotion-controlled, deterministic and non-deterministic models. We recommend watching the supplementary video for quality judgement. The entire codebase is publicly available<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/uuembodiedsocialai/ProbTalk3D/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/uuembodiedsocialai/ProbTalk3D/</a></span></span></span>.</p>
</div>
<div class="ltx_keywords">facial animation synthesis, deep learning, virtual humans, non-deterministic models, emotion-controlled facial animation
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Computing methodologiesÂ Neural networks</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Computing methodologiesÂ Animation</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Human-centered computingÂ User studies</span></span></span>
<figure id="S0.F1" class="ltx_figure ltx_teaserfigure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2409.07966/assets/Assets/teaser.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="479" height="250" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S0.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S0.F1.3.2" class="ltx_text" style="font-size:90%;">ProbTalk3D can non-deterministically synthesize 3D facial animation given audio, subject ID, emotion class, and emotion intensity as inputs. The generated samples using the same set of inputs of ProbTalk3D demonstrate diversity across multiple generations while ensuring proper lip-synchrony, emotional expressivity and visual quality.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S0.F1.4" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S0.F1.5" class="ltx_p ltx_figure_panel ltx_align_center">Description of the teaser figure of proposed the proposed model, ProbTalk3D.</p>
</div>
</div>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">3D facial animation is not only crucial in film-making and game production but also in a variety of XR applications that involve digital humans. Creating facial animations for 3D characters require lots of manual work from skilled technical artists or relies on performance capture pipelines. Researchers are actively addressing the challenges of 3D animation synthesis, aiming to minimize the manual effort. In particular, the relationship between speech and facial animation has been extensively studied and shown to be a promising direction <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Cudeiro etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>; Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>; Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>. However, recent speech-driven 3D facial animation synthesis methods mostly focus on lip-sync and identity control neglecting the role of emotions and emotion control. They are also mostly deterministic methods limiting the generation of diverse facial animations. These limitations are what we address in this paper.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Early 3D facial animation generation synthesis methods use procedural approaches <cite class="ltx_cite ltx_citemacro_citep">(Edwards etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2016</a>; Charalambous etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2019</a>)</cite> by employing linguistic rules to map phonemes to visemes (visual counterparts of phonemes). Despite their artist-friendly features, these models require defining explicit rules and their output is limited to lip-sync only. In recent years, end-to-end deep learning methods have demonstrated their effectiveness in speech-driven 3D facial animation synthesis <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Taylor etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2017</a>; Cudeiro etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>; Fan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>; Richard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2021b</a>; Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>; Thambiraja etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2023c</a>; Haque and Yumak, <a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite> generalizing to diverse audio inputs and different languages. They rely on 3D vertex-based datasets such as VOCASET <cite class="ltx_cite ltx_citemacro_citep">(Cudeiro etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>, Multiface <cite class="ltx_cite ltx_citemacro_citep">(Wuu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2022</a>)</cite> and BIWI <cite class="ltx_cite ltx_citemacro_citep">(Fanelli etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2010</a>)</cite> with limited size and emotional variations. Lately non-deterministic approaches <cite class="ltx_cite ltx_citemacro_citep">(Ng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2022</a>; Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>; Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>; Zhao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2024</a>; Aneja etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2024a</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2024</a>)</cite> have been proposed and there is an increasing number of papers that are listed on Arxiv <cite class="ltx_cite ltx_citemacro_citep">(Ma etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2024</a>; Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2023b</a>; Thambiraja etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2023a</a>; Park etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite>. A few approaches focus on rigged characters and blendshapes such as <cite class="ltx_cite ltx_citemacro_citep">(Aylagas etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2022</a>; Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>; Park and Cho, <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite>. Another group of work focus on holistic motion generation including face and body <cite class="ltx_cite ltx_citemacro_citep">(Yi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2023</a>; Liu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2024</a>; Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2024</a>; Ng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2024</a>)</cite>. While there is an increasing number of papers in this area, only a few papers focus on emotion control and emotionally-rich animation generation <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Peng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2023</a>; DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>; Zhao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The work from Karras et al. <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>)</cite> although focusing on emotions, is based on a small dataset with two actors and there is no explicit emotion control. The closest to our work are EmoTalk <cite class="ltx_cite ltx_citemacro_citep">(Peng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite> and EMOTE <cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>. They both rely on 3D datasets constructed from 2D videos with EMOTE having superior visual quality and wider range of emotions. Similar to EMOTE, we opt for using the 3DMEAD dataset as it provides facial animations with various emotions at different intensity levels and for several identities. However, none of these methods are non-deterministic and they cannot generate diverse outputs given the same audio input. A recent method <cite class="ltx_cite ltx_citemacro_citep">(Zhao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2024</a>)</cite> introduces a 4D high-quality dataset with emotion variations, however this dataset and codebase is not publicly available yet.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">The contributions of our work are enumerated below:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">A novel two-stage probabilistic (i.e. non-deterministic) emotion controllable speech-driven 3D facial animation synthesis model based on VQ-VAE, producing diverse yet high-quality facial animations by learning a latent representation of emotional speech animation.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Extensive comparative analysis of our approach with respect to recent non-deterministic approaches using an enhanced list of objective metrics following <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Qualitative evaluation and perceptual user study to demonstrate the superior perceptual quality of our modelâ€™s results compared to the state-of-the-art emotion-control enabled as well as non-deterministic models.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section provides a review of related work on speech-driven 3D facial animation synthesis using deep learning algorithms. Although there is a vast amount of deep learning methods that are used to generate 2D facial animation <cite class="ltx_cite ltx_citemacro_citep">(Ji etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2022</a>; StypuÅ‚kowski etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2024</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2023</a>)</cite>, that is out of the scope of this paper. Another group of work focus on learning representations of facial animation, tracking and reconstruction <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2017a</a>; Giebenhain etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2024</a>; Danecek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022</a>; Egger etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>. 3D speech-driven facial animation methods typically relied on phoneme-based procedural approaches <cite class="ltx_cite ltx_citemacro_citep">(JALI, <a href="#bib.bib28" title="" class="ltx_ref">2023</a>; Charalambous etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2019</a>)</cite> or intermediary representations <cite class="ltx_cite ltx_citemacro_citep">(Taylor etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2012</a>)</cite>. With the end-to-end deep learning approaches <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Taylor etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2017</a>; Cudeiro etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2019</a>; Fan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>; Richard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2021b</a>; Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>; Thambiraja etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2023c</a>; Haque and Yumak, <a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite>, a new era in 3D speech-driven facial animation started. Although providing promising results, these models are deterministic models limiting the generation of diverse outputs given the same speech input. They also do not provide explicit emotion control while most of them provide identity control. In this paper, we focus on non-deterministic speech-driven and emotion-controllable 3D facial animation synthesis. We will present the state-of-the-art in these two categories in the following two subsections.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Non-Deterministic 3D Facial Animation</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In recent years, researchers have increasingly focused on the non-deterministic aspects of human motion both for body <cite class="ltx_cite ltx_citemacro_citep">(Tevet etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2022</a>; Alexanderson etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2023</a>; Ao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2023</a>; Yi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2023</a>; Chhatre etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2024</a>)</cite> and facial motion <cite class="ltx_cite ltx_citemacro_citep">(Ng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2022</a>; Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>; Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>; Zhao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2024</a>; Aneja etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2024a</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2024</a>)</cite> as well as for holistic animation <cite class="ltx_cite ltx_citemacro_citep">(Yi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2023</a>; Liu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2024</a>; Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2024</a>; Ng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2024</a>)</cite>. Non-deterministic models are mostly based on Variational Auto Encoders (VAEs), Vector Quantized Variational Auto Encoders (VQ-VAEs) or diffusion models. Compared to Generative Adversarial Networks (GANs), VAE-based and diffusion models stand out by generating diverse outputs by explicitly modeling the underlying data distribution <cite class="ltx_cite ltx_citemacro_citep">(StypuÅ‚kowski etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2024</a>)</cite>. Unlike traditional VAEs that encode input into a continuous space, VQ-VAEs represent data using discrete codebook embeddings preventing the posterior collapse problem <cite class="ltx_cite ltx_citemacro_citep">(vanÂ den Oord etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2017</a>)</cite>. Richard et al. <cite class="ltx_cite ltx_citemacro_citep">(Richard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2021a</a>)</cite> propose a Temporal Convolutional Network (TCNN)-based VAE method to drive Codec Avatars <cite class="ltx_cite ltx_citemacro_citep">(Lombardi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2018</a>)</cite>, while Voice2Face <cite class="ltx_cite ltx_citemacro_citep">(Aylagas etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite> proposes an LSTM-based conditional VAE. MeshTalk <cite class="ltx_cite ltx_citemacro_citep">(Richard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2021b</a>)</cite> learns a categorical latent space while CodeTalker <cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite> uses VQ-VAE for learning a discrete code space. However, these methods were not explicitly declared non-deterministic and do not provide an evaluation on the diverse outputs generated. Learning to Listen <cite class="ltx_cite ltx_citemacro_citep">(Ng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite> employs a transformer-based VQ-VAE for facial animation synthesis in dyadic conversations and introduces evaluation metrics to assess diversity including diverseness within and across sequences. Yang et al. <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>)</cite> uses Residual Vector-Quantized (RVQ) codebook achieving improved diversity and high fidelity in facial motion. They provide an extensive benchmarking framework and introduce novel evaluation metrics. FaceDiffuser <cite class="ltx_cite ltx_citemacro_citep">(Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite> is the first model to apply diffusion models for the speech-driven 3D facial animation synthesis task. They introduce a new diversity metric that allows the comparison of this model to other deterministic models by measuring variation over identity instead of audio input. Facetalker <cite class="ltx_cite ltx_citemacro_citep">(Aneja etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2024b</a>)</cite> employs a transformer-based diffusion model and predicts animations of neural parametric head models (NPHMs) <cite class="ltx_cite ltx_citemacro_citep">(Giebenhain etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2023</a>)</cite> offering detailed representations of the human head. They measure diversity using metrics similar to the ones used in the body animation domain <cite class="ltx_cite ltx_citemacro_citep">(Ren etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>. DiffPoseTalk <cite class="ltx_cite ltx_citemacro_citep">(Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2024</a>)</cite> introduces a new dataset that also includes head poses which is constructed from 2D videos and uses a combination of diffusion and transformer networks. EMAGE <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2024</a>)</cite> being a holistic model encode different body parts using VQ-VAEs and uses various evaluation metrics including diversity based on <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite>. Another holistic model Audio2PhotoReal <cite class="ltx_cite ltx_citemacro_citep">(Ng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2024</a>)</cite> employs a diffusion model for the face. Although the above methods are non-deterministic, they do not provide explicit emotion control for speech-driven 3D facial animation.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Emotion-Controllable 3D Facial Animation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">There are a few papers in this space <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>; Peng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2023</a>; DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>; Zhao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2024</a>)</cite>. Karras et al. <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>)</cite> proposed an end-to-end method using CNNs aiming to resolve the ambiguity in mapping between audio and face by introducing an additional emotion component to the network. The dataset is based on two actors and cannot handle identity variations. In addition, there is no explicit emotion control but emotions are learned from data. The advantage is that the dataset is collected with a commercial high-end 4D performance capture system. EmoTalk <cite class="ltx_cite ltx_citemacro_citep">(Peng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite> introduces an emotion disentangling encoder to disentangle the emotion and content in the speech using a cross-reconstruction loss. In contrast with Karras et al. <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2017</a>)</cite>, they use a dataset that is semantically annotated with emotion labels. Given the emotion and content features, personal style and emotion control features, an emotion-guided multi-head attention decoder generates the output motion. Considering the limited availability of emotional 3D audio-visual datasets, EmoTalk addresses this gap by creating their own dataset 3D-ETF using two 2D datasets RAVDESS <cite class="ltx_cite ltx_citemacro_citep">(Livingstone and Russo, <a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite> and HDTF <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2021</a>)</cite>. They use the â€Live Link Faceâ€ application to map input videos to blendshape parameters. They also include a blendshape to FLAME <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2017a</a>)</cite> parameters converter which allows to transfer facial expressions across different virtual characters. EMOTE <cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> adopts a similar approach to EmoTalk and constructs a new dataset 3DMEAD based on the 2D dataset MEAD <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite> including annotated 8 basic emotion types, 3 emotion intensity types per emotion type, and speaker identities. To simplify the problem, they first learn a motion prior based on FLAME parameters changing in time using a temporal VAE. In the audio-driven training stage, they combine audio, identity and emotion features using transformer encoder and decoder structures to infer the motion. In contrast with FaceFormer <cite class="ltx_cite ltx_citemacro_citep">(Fan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite> and CodeTalker <cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite>, they employ a non-autoregressive model for improved efficiency. Although EMOTE does not provide explicit objective and subjective evaluations with respect to EmoTalk, visual results indicates better visual quality. None of these models can produce diverse results in a non-deterministic manner. A recent paper Media2Face <cite class="ltx_cite ltx_citemacro_citep">(Zhao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2024</a>)</cite> proposes a two-stage model and a 4D dataset M2F-D. Different from EmoTalk and EMOTE, emotion control is not categorical emotions but rely on CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite> text encoding. In the first stage, a latent space is learned using geometry and expression VAE models. The extracted latent codes are used to augment the dataset with 2D videos such as MEAD <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite>, RAVDESS <cite class="ltx_cite ltx_citemacro_citep">(Livingstone and Russo, <a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite> and HDTF <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2021</a>)</cite> similar to EmoTalk and EMOTE. In the second stage a transformer-based diffusion model is used. Although Media2Face is essentially a non-deterministic generative model, they do not employ an explicit diversity metric and use only FDD (Upper face Dynamics Deviation) metric similar to CodeTalker <cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite>. The visual quality of the results are good, however the dataset and codebase is not yet available for direct comparison.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2409.07966/assets/Assets/stage1.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="509" height="134" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.14.7.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S2.F2.12.6" class="ltx_text" style="font-size:90%;">Stage 1: The motion autoencoder is trained by utilizing VQ-VAE to learn a motion prior in terms of discrete quantized codebook embeddings, <math id="S2.F2.7.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S2.F2.7.1.m1.1b"><mi id="S2.F2.7.1.m1.1.1" xref="S2.F2.7.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S2.F2.7.1.m1.1c"><ci id="S2.F2.7.1.m1.1.1.cmml" xref="S2.F2.7.1.m1.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.7.1.m1.1d">E</annotation></semantics></math> . The autoencoder consists of a motion encoder that encodes the 53-dimensional temporal facial animation data into 256-dimensional latent space, <math id="S2.F2.8.2.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S2.F2.8.2.m2.1b"><mi id="S2.F2.8.2.m2.1.1" xref="S2.F2.8.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.F2.8.2.m2.1c"><ci id="S2.F2.8.2.m2.1.1.cmml" xref="S2.F2.8.2.m2.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.8.2.m2.1d">z</annotation></semantics></math> that undergoes quantization to produce <math id="S2.F2.9.3.m3.1" class="ltx_Math" alttext="z^{\prime}" display="inline"><semantics id="S2.F2.9.3.m3.1b"><msup id="S2.F2.9.3.m3.1.1" xref="S2.F2.9.3.m3.1.1.cmml"><mi id="S2.F2.9.3.m3.1.1.2" xref="S2.F2.9.3.m3.1.1.2.cmml">z</mi><mo id="S2.F2.9.3.m3.1.1.3" xref="S2.F2.9.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S2.F2.9.3.m3.1c"><apply id="S2.F2.9.3.m3.1.1.cmml" xref="S2.F2.9.3.m3.1.1"><csymbol cd="ambiguous" id="S2.F2.9.3.m3.1.1.1.cmml" xref="S2.F2.9.3.m3.1.1">superscript</csymbol><ci id="S2.F2.9.3.m3.1.1.2.cmml" xref="S2.F2.9.3.m3.1.1.2">ğ‘§</ci><ci id="S2.F2.9.3.m3.1.1.3.cmml" xref="S2.F2.9.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.9.3.m3.1d">z^{\prime}</annotation></semantics></math>. With the help of a motion decoder, <math id="S2.F2.10.4.m4.1" class="ltx_Math" alttext="z^{\prime}" display="inline"><semantics id="S2.F2.10.4.m4.1b"><msup id="S2.F2.10.4.m4.1.1" xref="S2.F2.10.4.m4.1.1.cmml"><mi id="S2.F2.10.4.m4.1.1.2" xref="S2.F2.10.4.m4.1.1.2.cmml">z</mi><mo id="S2.F2.10.4.m4.1.1.3" xref="S2.F2.10.4.m4.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S2.F2.10.4.m4.1c"><apply id="S2.F2.10.4.m4.1.1.cmml" xref="S2.F2.10.4.m4.1.1"><csymbol cd="ambiguous" id="S2.F2.10.4.m4.1.1.1.cmml" xref="S2.F2.10.4.m4.1.1">superscript</csymbol><ci id="S2.F2.10.4.m4.1.1.2.cmml" xref="S2.F2.10.4.m4.1.1.2">ğ‘§</ci><ci id="S2.F2.10.4.m4.1.1.3.cmml" xref="S2.F2.10.4.m4.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.10.4.m4.1d">z^{\prime}</annotation></semantics></math> gets decoded into facial animation data, <math id="S2.F2.11.5.m5.1" class="ltx_Math" alttext="\hat{\mathcal{X}}" display="inline"><semantics id="S2.F2.11.5.m5.1b"><mover accent="true" id="S2.F2.11.5.m5.1.1" xref="S2.F2.11.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.F2.11.5.m5.1.1.2" xref="S2.F2.11.5.m5.1.1.2.cmml">ğ’³</mi><mo id="S2.F2.11.5.m5.1.1.1" xref="S2.F2.11.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.F2.11.5.m5.1c"><apply id="S2.F2.11.5.m5.1.1.cmml" xref="S2.F2.11.5.m5.1.1"><ci id="S2.F2.11.5.m5.1.1.1.cmml" xref="S2.F2.11.5.m5.1.1.1">^</ci><ci id="S2.F2.11.5.m5.1.1.2.cmml" xref="S2.F2.11.5.m5.1.1.2">ğ’³</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.11.5.m5.1d">\hat{\mathcal{X}}</annotation></semantics></math> with the same shape as the <math id="S2.F2.12.6.m6.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="S2.F2.12.6.m6.1b"><mi class="ltx_font_mathcaligraphic" id="S2.F2.12.6.m6.1.1" xref="S2.F2.12.6.m6.1.1.cmml">ğ’³</mi><annotation-xml encoding="MathML-Content" id="S2.F2.12.6.m6.1c"><ci id="S2.F2.12.6.m6.1.1.cmml" xref="S2.F2.12.6.m6.1.1">ğ’³</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.12.6.m6.1d">\mathcal{X}</annotation></semantics></math>.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S2.F2.15" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.F2.16" class="ltx_p ltx_figure_panel ltx_align_center">ProbTalk3D stage 1 detailed figure.</p>
</div>
</div>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe our methodology including a description of the dataset, problem formulation, details about the proposed model, and two other non-deterministic approaches (VAE and diffusion-based) that are used to compare and evaluate our proposed model. The results and the comparative analysis are then presented in Sec. <a href="#S4" title="4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Dataset: 3DMEAD</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">3DMEAD dataset is reconstructed from 2D audio-visual dataset MEAD <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite>. The 3D reconstruction from the 2D videos was carried out using DECA <cite class="ltx_cite ltx_citemacro_citep">(Feng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> and MICA <cite class="ltx_cite ltx_citemacro_citep">(Zielonka etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2022</a>)</cite> methods which was first introduced with the EMOTE <cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> paper. 3DMEAD dataset includes 3D reconstructions of 47 subjects speaking in English, comprising eight emotions at three intensity levels. The emotion categories include neutral, happy, sad, surprised, fear, disgusted, angry, and contempt. Except for the neutral class, each emotion category has three intensity levels: weak, medium, and strong. Every subject contributes 30 short sentences for seven basic emotions, each expressed at three aforementioned intensity levels, along with an additional 40 sentences with the neutral emotion.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.8" class="ltx_p">We choose 3DMEAD for our experiments as it offers a relatively large-scale, high-quality facial animation data with coverage of diverse emotions. Motion data is sampled at <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="25fps" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mn id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">25</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.1.1.1a" xref="S3.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p2.1.m1.1.1.4" xref="S3.SS1.p2.1.m1.1.1.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.1.1.1b" xref="S3.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p2.1.m1.1.1.5" xref="S3.SS1.p2.1.m1.1.1.5.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><times id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">25</cn><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ‘“</ci><ci id="S3.SS1.p2.1.m1.1.1.4.cmml" xref="S3.SS1.p2.1.m1.1.1.4">ğ‘</ci><ci id="S3.SS1.p2.1.m1.1.1.5.cmml" xref="S3.SS1.p2.1.m1.1.1.5">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">25fps</annotation></semantics></math>. Each frame in the dataset is represented using FLAME <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2017b</a>)</cite> 3D Morphable Model (3DMM) parameters <math id="S3.SS1.p2.2.m2.3" class="ltx_Math" alttext="\{\beta,\theta,\psi\}\in\mathbb{R}^{406}" display="inline"><semantics id="S3.SS1.p2.2.m2.3a"><mrow id="S3.SS1.p2.2.m2.3.4" xref="S3.SS1.p2.2.m2.3.4.cmml"><mrow id="S3.SS1.p2.2.m2.3.4.2.2" xref="S3.SS1.p2.2.m2.3.4.2.1.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.3.4.2.2.1" xref="S3.SS1.p2.2.m2.3.4.2.1.cmml">{</mo><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">Î²</mi><mo id="S3.SS1.p2.2.m2.3.4.2.2.2" xref="S3.SS1.p2.2.m2.3.4.2.1.cmml">,</mo><mi id="S3.SS1.p2.2.m2.2.2" xref="S3.SS1.p2.2.m2.2.2.cmml">Î¸</mi><mo id="S3.SS1.p2.2.m2.3.4.2.2.3" xref="S3.SS1.p2.2.m2.3.4.2.1.cmml">,</mo><mi id="S3.SS1.p2.2.m2.3.3" xref="S3.SS1.p2.2.m2.3.3.cmml">Ïˆ</mi><mo stretchy="false" id="S3.SS1.p2.2.m2.3.4.2.2.4" xref="S3.SS1.p2.2.m2.3.4.2.1.cmml">}</mo></mrow><mo id="S3.SS1.p2.2.m2.3.4.1" xref="S3.SS1.p2.2.m2.3.4.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.2.m2.3.4.3" xref="S3.SS1.p2.2.m2.3.4.3.cmml"><mi id="S3.SS1.p2.2.m2.3.4.3.2" xref="S3.SS1.p2.2.m2.3.4.3.2.cmml">â„</mi><mn id="S3.SS1.p2.2.m2.3.4.3.3" xref="S3.SS1.p2.2.m2.3.4.3.3.cmml">406</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.3b"><apply id="S3.SS1.p2.2.m2.3.4.cmml" xref="S3.SS1.p2.2.m2.3.4"><in id="S3.SS1.p2.2.m2.3.4.1.cmml" xref="S3.SS1.p2.2.m2.3.4.1"></in><set id="S3.SS1.p2.2.m2.3.4.2.1.cmml" xref="S3.SS1.p2.2.m2.3.4.2.2"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">ğ›½</ci><ci id="S3.SS1.p2.2.m2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2">ğœƒ</ci><ci id="S3.SS1.p2.2.m2.3.3.cmml" xref="S3.SS1.p2.2.m2.3.3">ğœ“</ci></set><apply id="S3.SS1.p2.2.m2.3.4.3.cmml" xref="S3.SS1.p2.2.m2.3.4.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.3.4.3.1.cmml" xref="S3.SS1.p2.2.m2.3.4.3">superscript</csymbol><ci id="S3.SS1.p2.2.m2.3.4.3.2.cmml" xref="S3.SS1.p2.2.m2.3.4.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.2.m2.3.4.3.3.cmml" xref="S3.SS1.p2.2.m2.3.4.3.3">406</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.3c">\{\beta,\theta,\psi\}\in\mathbb{R}^{406}</annotation></semantics></math>, where <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\beta\in\mathbb{R}^{300}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">Î²</mi><mo id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml"><mi id="S3.SS1.p2.3.m3.1.1.3.2" xref="S3.SS1.p2.3.m3.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.3.m3.1.1.3.3" xref="S3.SS1.p2.3.m3.1.1.3.3.cmml">300</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><in id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"></in><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">ğ›½</ci><apply id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.3.2.cmml" xref="S3.SS1.p2.3.m3.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.3.m3.1.1.3.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3">300</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\beta\in\mathbb{R}^{300}</annotation></semantics></math> denotes the face shape, <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\theta_{jaw}\in\mathbb{R}^{3}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><msub id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2.2" xref="S3.SS1.p2.4.m4.1.1.2.2.cmml">Î¸</mi><mrow id="S3.SS1.p2.4.m4.1.1.2.3" xref="S3.SS1.p2.4.m4.1.1.2.3.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2.3.2" xref="S3.SS1.p2.4.m4.1.1.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.2.3.1" xref="S3.SS1.p2.4.m4.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.4.m4.1.1.2.3.3" xref="S3.SS1.p2.4.m4.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.2.3.1a" xref="S3.SS1.p2.4.m4.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.4.m4.1.1.2.3.4" xref="S3.SS1.p2.4.m4.1.1.2.3.4.cmml">w</mi></mrow></msub><mo id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml"><mi id="S3.SS1.p2.4.m4.1.1.3.2" xref="S3.SS1.p2.4.m4.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.4.m4.1.1.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><in id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></in><apply id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.2.1.cmml" xref="S3.SS1.p2.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2.2">ğœƒ</ci><apply id="S3.SS1.p2.4.m4.1.1.2.3.cmml" xref="S3.SS1.p2.4.m4.1.1.2.3"><times id="S3.SS1.p2.4.m4.1.1.2.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.2.3.1"></times><ci id="S3.SS1.p2.4.m4.1.1.2.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2.3.2">ğ‘—</ci><ci id="S3.SS1.p2.4.m4.1.1.2.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.2.3.3">ğ‘</ci><ci id="S3.SS1.p2.4.m4.1.1.2.3.4.cmml" xref="S3.SS1.p2.4.m4.1.1.2.3.4">ğ‘¤</ci></apply></apply><apply id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.4.m4.1.1.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\theta_{jaw}\in\mathbb{R}^{3}</annotation></semantics></math> denotes the eular angle rotation (x,y,z) of the jaw bone, <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="\theta_{global}\in\mathbb{R}^{3}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mrow id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><msub id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2.2" xref="S3.SS1.p2.5.m5.1.1.2.2.cmml">Î¸</mi><mrow id="S3.SS1.p2.5.m5.1.1.2.3" xref="S3.SS1.p2.5.m5.1.1.2.3.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2.3.2" xref="S3.SS1.p2.5.m5.1.1.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.2.3.1" xref="S3.SS1.p2.5.m5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.5.m5.1.1.2.3.3" xref="S3.SS1.p2.5.m5.1.1.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.2.3.1a" xref="S3.SS1.p2.5.m5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.5.m5.1.1.2.3.4" xref="S3.SS1.p2.5.m5.1.1.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.2.3.1b" xref="S3.SS1.p2.5.m5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.5.m5.1.1.2.3.5" xref="S3.SS1.p2.5.m5.1.1.2.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.2.3.1c" xref="S3.SS1.p2.5.m5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.5.m5.1.1.2.3.6" xref="S3.SS1.p2.5.m5.1.1.2.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.2.3.1d" xref="S3.SS1.p2.5.m5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.5.m5.1.1.2.3.7" xref="S3.SS1.p2.5.m5.1.1.2.3.7.cmml">l</mi></mrow></msub><mo id="S3.SS1.p2.5.m5.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml"><mi id="S3.SS1.p2.5.m5.1.1.3.2" xref="S3.SS1.p2.5.m5.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.5.m5.1.1.3.3" xref="S3.SS1.p2.5.m5.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><in id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1"></in><apply id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.2.1.cmml" xref="S3.SS1.p2.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2.2">ğœƒ</ci><apply id="S3.SS1.p2.5.m5.1.1.2.3.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3"><times id="S3.SS1.p2.5.m5.1.1.2.3.1.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3.1"></times><ci id="S3.SS1.p2.5.m5.1.1.2.3.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3.2">ğ‘”</ci><ci id="S3.SS1.p2.5.m5.1.1.2.3.3.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3.3">ğ‘™</ci><ci id="S3.SS1.p2.5.m5.1.1.2.3.4.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3.4">ğ‘œ</ci><ci id="S3.SS1.p2.5.m5.1.1.2.3.5.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3.5">ğ‘</ci><ci id="S3.SS1.p2.5.m5.1.1.2.3.6.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3.6">ğ‘</ci><ci id="S3.SS1.p2.5.m5.1.1.2.3.7.cmml" xref="S3.SS1.p2.5.m5.1.1.2.3.7">ğ‘™</ci></apply></apply><apply id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.3.1.cmml" xref="S3.SS1.p2.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.3.2.cmml" xref="S3.SS1.p2.5.m5.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.5.m5.1.1.3.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\theta_{global}\in\mathbb{R}^{3}</annotation></semantics></math> denotes the global head pose, and <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="\psi\in\mathbb{R}^{100}" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mrow id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml">Ïˆ</mi><mo id="S3.SS1.p2.6.m6.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml"><mi id="S3.SS1.p2.6.m6.1.1.3.2" xref="S3.SS1.p2.6.m6.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.6.m6.1.1.3.3" xref="S3.SS1.p2.6.m6.1.1.3.3.cmml">100</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><in id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1"></in><ci id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2">ğœ“</ci><apply id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.3.1.cmml" xref="S3.SS1.p2.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.3.2.cmml" xref="S3.SS1.p2.6.m6.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.6.m6.1.1.3.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3.3">100</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\psi\in\mathbb{R}^{100}</annotation></semantics></math> denotes the expression parameters. However, similar to EMOTE, we utilize only <math id="S3.SS1.p2.7.m7.2" class="ltx_Math" alttext="\{\psi,\theta_{jaw}\}\in\mathbb{R}^{53}" display="inline"><semantics id="S3.SS1.p2.7.m7.2a"><mrow id="S3.SS1.p2.7.m7.2.2" xref="S3.SS1.p2.7.m7.2.2.cmml"><mrow id="S3.SS1.p2.7.m7.2.2.1.1" xref="S3.SS1.p2.7.m7.2.2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.7.m7.2.2.1.1.2" xref="S3.SS1.p2.7.m7.2.2.1.2.cmml">{</mo><mi id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">Ïˆ</mi><mo id="S3.SS1.p2.7.m7.2.2.1.1.3" xref="S3.SS1.p2.7.m7.2.2.1.2.cmml">,</mo><msub id="S3.SS1.p2.7.m7.2.2.1.1.1" xref="S3.SS1.p2.7.m7.2.2.1.1.1.cmml"><mi id="S3.SS1.p2.7.m7.2.2.1.1.1.2" xref="S3.SS1.p2.7.m7.2.2.1.1.1.2.cmml">Î¸</mi><mrow id="S3.SS1.p2.7.m7.2.2.1.1.1.3" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.cmml"><mi id="S3.SS1.p2.7.m7.2.2.1.1.1.3.2" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.7.m7.2.2.1.1.1.3.1" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.7.m7.2.2.1.1.1.3.3" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.7.m7.2.2.1.1.1.3.1a" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.7.m7.2.2.1.1.1.3.4" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.4.cmml">w</mi></mrow></msub><mo stretchy="false" id="S3.SS1.p2.7.m7.2.2.1.1.4" xref="S3.SS1.p2.7.m7.2.2.1.2.cmml">}</mo></mrow><mo id="S3.SS1.p2.7.m7.2.2.2" xref="S3.SS1.p2.7.m7.2.2.2.cmml">âˆˆ</mo><msup id="S3.SS1.p2.7.m7.2.2.3" xref="S3.SS1.p2.7.m7.2.2.3.cmml"><mi id="S3.SS1.p2.7.m7.2.2.3.2" xref="S3.SS1.p2.7.m7.2.2.3.2.cmml">â„</mi><mn id="S3.SS1.p2.7.m7.2.2.3.3" xref="S3.SS1.p2.7.m7.2.2.3.3.cmml">53</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.2b"><apply id="S3.SS1.p2.7.m7.2.2.cmml" xref="S3.SS1.p2.7.m7.2.2"><in id="S3.SS1.p2.7.m7.2.2.2.cmml" xref="S3.SS1.p2.7.m7.2.2.2"></in><set id="S3.SS1.p2.7.m7.2.2.1.2.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1"><ci id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">ğœ“</ci><apply id="S3.SS1.p2.7.m7.2.2.1.1.1.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.2.2.1.1.1.1.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.7.m7.2.2.1.1.1.2.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1.1.2">ğœƒ</ci><apply id="S3.SS1.p2.7.m7.2.2.1.1.1.3.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3"><times id="S3.SS1.p2.7.m7.2.2.1.1.1.3.1.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.1"></times><ci id="S3.SS1.p2.7.m7.2.2.1.1.1.3.2.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.2">ğ‘—</ci><ci id="S3.SS1.p2.7.m7.2.2.1.1.1.3.3.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.3">ğ‘</ci><ci id="S3.SS1.p2.7.m7.2.2.1.1.1.3.4.cmml" xref="S3.SS1.p2.7.m7.2.2.1.1.1.3.4">ğ‘¤</ci></apply></apply></set><apply id="S3.SS1.p2.7.m7.2.2.3.cmml" xref="S3.SS1.p2.7.m7.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.2.2.3.1.cmml" xref="S3.SS1.p2.7.m7.2.2.3">superscript</csymbol><ci id="S3.SS1.p2.7.m7.2.2.3.2.cmml" xref="S3.SS1.p2.7.m7.2.2.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.7.m7.2.2.3.3.cmml" xref="S3.SS1.p2.7.m7.2.2.3.3">53</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.2c">\{\psi,\theta_{jaw}\}\in\mathbb{R}^{53}</annotation></semantics></math> for model training, where <math id="S3.SS1.p2.8.m8.1" class="ltx_Math" alttext="\psi\in\mathbb{R}^{50}" display="inline"><semantics id="S3.SS1.p2.8.m8.1a"><mrow id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml"><mi id="S3.SS1.p2.8.m8.1.1.2" xref="S3.SS1.p2.8.m8.1.1.2.cmml">Ïˆ</mi><mo id="S3.SS1.p2.8.m8.1.1.1" xref="S3.SS1.p2.8.m8.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.8.m8.1.1.3" xref="S3.SS1.p2.8.m8.1.1.3.cmml"><mi id="S3.SS1.p2.8.m8.1.1.3.2" xref="S3.SS1.p2.8.m8.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.8.m8.1.1.3.3" xref="S3.SS1.p2.8.m8.1.1.3.3.cmml">50</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><apply id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1"><in id="S3.SS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1.1"></in><ci id="S3.SS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.2">ğœ“</ci><apply id="S3.SS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.3.1.cmml" xref="S3.SS1.p2.8.m8.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.8.m8.1.1.3.2.cmml" xref="S3.SS1.p2.8.m8.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.8.m8.1.1.3.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3.3">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">\psi\in\mathbb{R}^{50}</annotation></semantics></math> representing the first 50 of the total 100 expression parameters. The original training configuration of EMOTE splits the dataset into training-validation-test sets keeping all sequences per subject while having different subjects in each set. In this way, there is no ground truth data to perform a quantitative evaluation for which EMOTE only conducted a perceptual user study. In contrast, our proposed split keeps a small number of sequences from each training subject for validation and testing allowing comparison of generated samples with respect to the ground truth. Although our training is done on fewer sequences than EMOTE, given the large scale of 3DMEAD dataset, we demonstrate that this split provides sufficient information for effective training and generation of animations perceptually superior in comparison to the EMOTE model. More details about the dataset split can be found in the supplementary material.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Problem Formulation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The task is to generate facial animation sequences based on audio and style inputs. To this end, we propose a supervised neural network model training approach to learn from data so that after training, we can predict the facial motion on any arbitrary unseen inputs. To train such a model, we leverage the audio-motion pairs in 3DMEAD dataset. The problem can be formulated as follows-</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.5" class="ltx_p">Let <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{X}=\{\mathcal{X}^{f}\}_{f=1}^{F}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">ğ’³</mi><mo id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml"><mrow id="S3.SS2.p2.1.m1.1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><msup id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.2.cmml">ğ’³</mi><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.3.cmml">f</mi></msup><mo stretchy="false" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS2.p2.1.m1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.1.1.3.2.cmml">f</mi><mo id="S3.SS2.p2.1.m1.1.1.1.1.3.1" xref="S3.SS2.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS2.p2.1.m1.1.1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS2.p2.1.m1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.3.cmml">F</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><eq id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2"></eq><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">ğ’³</ci><apply id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1">superscript</csymbol><apply id="S3.SS2.p2.1.m1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1">subscript</csymbol><set id="S3.SS2.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1"><apply id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.2">ğ’³</ci><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.3">ğ‘“</ci></apply></set><apply id="S3.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.3"><eq id="S3.SS2.p2.1.m1.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S3.SS2.p2.1.m1.1.1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.3.2">ğ‘“</ci><cn type="integer" id="S3.SS2.p2.1.m1.1.1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS2.p2.1.m1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3">ğ¹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathcal{X}=\{\mathcal{X}^{f}\}_{f=1}^{F}</annotation></semantics></math> represent a facial animation sequence containing <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">F</annotation></semantics></math> frames, paired with audio sequence <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">a</annotation></semantics></math>. Each sequence is also annotated in terms of style, <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\mathcal{C}</annotation></semantics></math>. Hence, the training process to learn the weights of the defined model, <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">M</annotation></semantics></math> can be expressed as -</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\hat{\mathcal{X}}=M(\mathcal{X},a,\mathcal{C})" display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.4" xref="S3.E1.m1.3.4.cmml"><mover accent="true" id="S3.E1.m1.3.4.2" xref="S3.E1.m1.3.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.3.4.2.2" xref="S3.E1.m1.3.4.2.2.cmml">ğ’³</mi><mo id="S3.E1.m1.3.4.2.1" xref="S3.E1.m1.3.4.2.1.cmml">^</mo></mover><mo id="S3.E1.m1.3.4.1" xref="S3.E1.m1.3.4.1.cmml">=</mo><mrow id="S3.E1.m1.3.4.3" xref="S3.E1.m1.3.4.3.cmml"><mi id="S3.E1.m1.3.4.3.2" xref="S3.E1.m1.3.4.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.4.3.1" xref="S3.E1.m1.3.4.3.1.cmml">â€‹</mo><mrow id="S3.E1.m1.3.4.3.3.2" xref="S3.E1.m1.3.4.3.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.4.3.3.2.1" xref="S3.E1.m1.3.4.3.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">ğ’³</mi><mo id="S3.E1.m1.3.4.3.3.2.2" xref="S3.E1.m1.3.4.3.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">a</mi><mo id="S3.E1.m1.3.4.3.3.2.3" xref="S3.E1.m1.3.4.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">ğ’</mi><mo stretchy="false" id="S3.E1.m1.3.4.3.3.2.4" xref="S3.E1.m1.3.4.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.4.cmml" xref="S3.E1.m1.3.4"><eq id="S3.E1.m1.3.4.1.cmml" xref="S3.E1.m1.3.4.1"></eq><apply id="S3.E1.m1.3.4.2.cmml" xref="S3.E1.m1.3.4.2"><ci id="S3.E1.m1.3.4.2.1.cmml" xref="S3.E1.m1.3.4.2.1">^</ci><ci id="S3.E1.m1.3.4.2.2.cmml" xref="S3.E1.m1.3.4.2.2">ğ’³</ci></apply><apply id="S3.E1.m1.3.4.3.cmml" xref="S3.E1.m1.3.4.3"><times id="S3.E1.m1.3.4.3.1.cmml" xref="S3.E1.m1.3.4.3.1"></times><ci id="S3.E1.m1.3.4.3.2.cmml" xref="S3.E1.m1.3.4.3.2">ğ‘€</ci><vector id="S3.E1.m1.3.4.3.3.1.cmml" xref="S3.E1.m1.3.4.3.3.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğ’³</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ğ‘</ci><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">ğ’</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\hat{\mathcal{X}}=M(\mathcal{X},a,\mathcal{C})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.10" class="ltx_p">where given audio <math id="S3.SS2.p2.6.m1.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.SS2.p2.6.m1.1a"><mi id="S3.SS2.p2.6.m1.1.1" xref="S3.SS2.p2.6.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m1.1b"><ci id="S3.SS2.p2.6.m1.1.1.cmml" xref="S3.SS2.p2.6.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m1.1c">a</annotation></semantics></math> and style <math id="S3.SS2.p2.7.m2.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS2.p2.7.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.7.m2.1.1" xref="S3.SS2.p2.7.m2.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m2.1b"><ci id="S3.SS2.p2.7.m2.1.1.cmml" xref="S3.SS2.p2.7.m2.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m2.1c">\mathcal{C}</annotation></semantics></math>, the model weights of <math id="S3.SS2.p2.8.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.p2.8.m3.1a"><mi id="S3.SS2.p2.8.m3.1.1" xref="S3.SS2.p2.8.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m3.1b"><ci id="S3.SS2.p2.8.m3.1.1.cmml" xref="S3.SS2.p2.8.m3.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m3.1c">M</annotation></semantics></math> are optimized to be able to predict <math id="S3.SS2.p2.9.m4.1" class="ltx_Math" alttext="\hat{\mathcal{X}}" display="inline"><semantics id="S3.SS2.p2.9.m4.1a"><mover accent="true" id="S3.SS2.p2.9.m4.1.1" xref="S3.SS2.p2.9.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.9.m4.1.1.2" xref="S3.SS2.p2.9.m4.1.1.2.cmml">ğ’³</mi><mo id="S3.SS2.p2.9.m4.1.1.1" xref="S3.SS2.p2.9.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m4.1b"><apply id="S3.SS2.p2.9.m4.1.1.cmml" xref="S3.SS2.p2.9.m4.1.1"><ci id="S3.SS2.p2.9.m4.1.1.1.cmml" xref="S3.SS2.p2.9.m4.1.1.1">^</ci><ci id="S3.SS2.p2.9.m4.1.1.2.cmml" xref="S3.SS2.p2.9.m4.1.1.2">ğ’³</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m4.1c">\hat{\mathcal{X}}</annotation></semantics></math> that resembles the real facial animation data, <math id="S3.SS2.p2.10.m5.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="S3.SS2.p2.10.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.10.m5.1.1" xref="S3.SS2.p2.10.m5.1.1.cmml">ğ’³</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m5.1b"><ci id="S3.SS2.p2.10.m5.1.1.cmml" xref="S3.SS2.p2.10.m5.1.1">ğ’³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m5.1c">\mathcal{X}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">After training, the inference process on arbitrary audio and style inputs can be formulated as-</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\hat{\mathcal{X}}=M(a,\mathcal{C})" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.3" xref="S3.E2.m1.2.3.cmml"><mover accent="true" id="S3.E2.m1.2.3.2" xref="S3.E2.m1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.3.2.2" xref="S3.E2.m1.2.3.2.2.cmml">ğ’³</mi><mo id="S3.E2.m1.2.3.2.1" xref="S3.E2.m1.2.3.2.1.cmml">^</mo></mover><mo id="S3.E2.m1.2.3.1" xref="S3.E2.m1.2.3.1.cmml">=</mo><mrow id="S3.E2.m1.2.3.3" xref="S3.E2.m1.2.3.3.cmml"><mi id="S3.E2.m1.2.3.3.2" xref="S3.E2.m1.2.3.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.3.3.1" xref="S3.E2.m1.2.3.3.1.cmml">â€‹</mo><mrow id="S3.E2.m1.2.3.3.3.2" xref="S3.E2.m1.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.3.3.3.2.1" xref="S3.E2.m1.2.3.3.3.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">a</mi><mo id="S3.E2.m1.2.3.3.3.2.2" xref="S3.E2.m1.2.3.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">ğ’</mi><mo stretchy="false" id="S3.E2.m1.2.3.3.3.2.3" xref="S3.E2.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.3.cmml" xref="S3.E2.m1.2.3"><eq id="S3.E2.m1.2.3.1.cmml" xref="S3.E2.m1.2.3.1"></eq><apply id="S3.E2.m1.2.3.2.cmml" xref="S3.E2.m1.2.3.2"><ci id="S3.E2.m1.2.3.2.1.cmml" xref="S3.E2.m1.2.3.2.1">^</ci><ci id="S3.E2.m1.2.3.2.2.cmml" xref="S3.E2.m1.2.3.2.2">ğ’³</ci></apply><apply id="S3.E2.m1.2.3.3.cmml" xref="S3.E2.m1.2.3.3"><times id="S3.E2.m1.2.3.3.1.cmml" xref="S3.E2.m1.2.3.3.1"></times><ci id="S3.E2.m1.2.3.3.2.cmml" xref="S3.E2.m1.2.3.3.2">ğ‘€</ci><interval closure="open" id="S3.E2.m1.2.3.3.3.1.cmml" xref="S3.E2.m1.2.3.3.3.2"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğ‘</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">ğ’</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\hat{\mathcal{X}}=M(a,\mathcal{C})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.7" class="ltx_p">The facial motion is defined as, <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">ğ’³</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">ğ’³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathcal{X}</annotation></semantics></math> or <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="\hat{\mathcal{X}}\in\mathbb{R}^{F\times P}" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><mrow id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mover accent="true" id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.2.m2.1.1.2.2" xref="S3.SS2.p4.2.m2.1.1.2.2.cmml">ğ’³</mi><mo id="S3.SS2.p4.2.m2.1.1.2.1" xref="S3.SS2.p4.2.m2.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS2.p4.2.m2.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.p4.2.m2.1.1.3.2" xref="S3.SS2.p4.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p4.2.m2.1.1.3.3" xref="S3.SS2.p4.2.m2.1.1.3.3.cmml"><mi id="S3.SS2.p4.2.m2.1.1.3.3.2" xref="S3.SS2.p4.2.m2.1.1.3.3.2.cmml">F</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p4.2.m2.1.1.3.3.1" xref="S3.SS2.p4.2.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p4.2.m2.1.1.3.3.3" xref="S3.SS2.p4.2.m2.1.1.3.3.3.cmml">P</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><in id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1"></in><apply id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2"><ci id="S3.SS2.p4.2.m2.1.1.2.1.cmml" xref="S3.SS2.p4.2.m2.1.1.2.1">^</ci><ci id="S3.SS2.p4.2.m2.1.1.2.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2.2">ğ’³</ci></apply><apply id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2">â„</ci><apply id="S3.SS2.p4.2.m2.1.1.3.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3.3"><times id="S3.SS2.p4.2.m2.1.1.3.3.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3.3.1"></times><ci id="S3.SS2.p4.2.m2.1.1.3.3.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3.3.2">ğ¹</ci><ci id="S3.SS2.p4.2.m2.1.1.3.3.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3.3.3">ğ‘ƒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">\hat{\mathcal{X}}\in\mathbb{R}^{F\times P}</annotation></semantics></math>, where <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">F</annotation></semantics></math> represents the number of total visual frames and <math id="S3.SS2.p4.4.m4.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.SS2.p4.4.m4.1a"><mi id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><ci id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">P</annotation></semantics></math> represents the dimension of animation data. While training the model with 3DMEAD, <math id="S3.SS2.p4.5.m5.1" class="ltx_Math" alttext="P=53" display="inline"><semantics id="S3.SS2.p4.5.m5.1a"><mrow id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml"><mi id="S3.SS2.p4.5.m5.1.1.2" xref="S3.SS2.p4.5.m5.1.1.2.cmml">P</mi><mo id="S3.SS2.p4.5.m5.1.1.1" xref="S3.SS2.p4.5.m5.1.1.1.cmml">=</mo><mn id="S3.SS2.p4.5.m5.1.1.3" xref="S3.SS2.p4.5.m5.1.1.3.cmml">53</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><apply id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1"><eq id="S3.SS2.p4.5.m5.1.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1.1"></eq><ci id="S3.SS2.p4.5.m5.1.1.2.cmml" xref="S3.SS2.p4.5.m5.1.1.2">ğ‘ƒ</ci><cn type="integer" id="S3.SS2.p4.5.m5.1.1.3.cmml" xref="S3.SS2.p4.5.m5.1.1.3">53</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">P=53</annotation></semantics></math> comprises the first 50 FLAME expression parameters and 3 jaw parameters (x,y,z Euler rotation of the jaw bone). The training process is conditioned on a style vector <math id="S3.SS2.p4.6.m6.1" class="ltx_Math" alttext="\mathcal{C}=[c_{id}|c_{emo}|c_{int}]" display="inline"><semantics id="S3.SS2.p4.6.m6.1a"><mrow id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.6.m6.1.1.3" xref="S3.SS2.p4.6.m6.1.1.3.cmml">ğ’</mi><mo id="S3.SS2.p4.6.m6.1.1.2" xref="S3.SS2.p4.6.m6.1.1.2.cmml">=</mo><mrow id="S3.SS2.p4.6.m6.1.1.1.1" xref="S3.SS2.p4.6.m6.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p4.6.m6.1.1.1.1.2" xref="S3.SS2.p4.6.m6.1.1.1.2.1.cmml">[</mo><mrow id="S3.SS2.p4.6.m6.1.1.1.1.1" xref="S3.SS2.p4.6.m6.1.1.1.1.1.cmml"><msub id="S3.SS2.p4.6.m6.1.1.1.1.1.3" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.3.2" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.2.cmml">c</mi><mrow id="S3.SS2.p4.6.m6.1.1.1.1.1.3.3" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.cmml"><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.2" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.1" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.3" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.3.cmml">d</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1.1.1.2" xref="S3.SS2.p4.6.m6.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.2" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.2.1.cmml">|</mo><msub id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.2.cmml">c</mi><mrow id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.2" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.1" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.3" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.1a" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.4" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.4.cmml">o</mi></mrow></msub><mo stretchy="false" id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.3" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1.1.1.2a" xref="S3.SS2.p4.6.m6.1.1.1.1.1.2.cmml">â€‹</mo><msub id="S3.SS2.p4.6.m6.1.1.1.1.1.4" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.cmml"><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.4.2" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.2.cmml">c</mi><mrow id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.cmml"><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.2" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.1" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.3" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.1a" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.4" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.4.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S3.SS2.p4.6.m6.1.1.1.1.3" xref="S3.SS2.p4.6.m6.1.1.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><apply id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1"><eq id="S3.SS2.p4.6.m6.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.2"></eq><ci id="S3.SS2.p4.6.m6.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3">ğ’</ci><apply id="S3.SS2.p4.6.m6.1.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p4.6.m6.1.1.1.2.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS2.p4.6.m6.1.1.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1"><times id="S3.SS2.p4.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.2"></times><apply id="S3.SS2.p4.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.2">ğ‘</ci><apply id="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.3"><times id="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.1"></times><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.2">ğ‘–</ci><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.3.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.3.3.3">ğ‘‘</ci></apply></apply><apply id="S3.SS2.p4.6.m6.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1"><abs id="S3.SS2.p4.6.m6.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.2"></abs><apply id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.2">ğ‘</ci><apply id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3"><times id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.2">ğ‘’</ci><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.3">ğ‘š</ci><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.1.1.1.3.4">ğ‘œ</ci></apply></apply></apply><apply id="S3.SS2.p4.6.m6.1.1.1.1.1.4.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.1.1.4.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4">subscript</csymbol><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.4.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.2">ğ‘</ci><apply id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3"><times id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.1.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.1"></times><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.2.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.2">ğ‘–</ci><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.3.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.3">ğ‘›</ci><ci id="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.4.cmml" xref="S3.SS2.p4.6.m6.1.1.1.1.1.4.3.4">ğ‘¡</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">\mathcal{C}=[c_{id}|c_{emo}|c_{int}]</annotation></semantics></math>, where <math id="S3.SS2.p4.7.m7.3" class="ltx_Math" alttext="c_{id},c_{emo},c_{int}" display="inline"><semantics id="S3.SS2.p4.7.m7.3a"><mrow id="S3.SS2.p4.7.m7.3.3.3" xref="S3.SS2.p4.7.m7.3.3.4.cmml"><msub id="S3.SS2.p4.7.m7.1.1.1.1" xref="S3.SS2.p4.7.m7.1.1.1.1.cmml"><mi id="S3.SS2.p4.7.m7.1.1.1.1.2" xref="S3.SS2.p4.7.m7.1.1.1.1.2.cmml">c</mi><mrow id="S3.SS2.p4.7.m7.1.1.1.1.3" xref="S3.SS2.p4.7.m7.1.1.1.1.3.cmml"><mi id="S3.SS2.p4.7.m7.1.1.1.1.3.2" xref="S3.SS2.p4.7.m7.1.1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m7.1.1.1.1.3.1" xref="S3.SS2.p4.7.m7.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.7.m7.1.1.1.1.3.3" xref="S3.SS2.p4.7.m7.1.1.1.1.3.3.cmml">d</mi></mrow></msub><mo id="S3.SS2.p4.7.m7.3.3.3.4" xref="S3.SS2.p4.7.m7.3.3.4.cmml">,</mo><msub id="S3.SS2.p4.7.m7.2.2.2.2" xref="S3.SS2.p4.7.m7.2.2.2.2.cmml"><mi id="S3.SS2.p4.7.m7.2.2.2.2.2" xref="S3.SS2.p4.7.m7.2.2.2.2.2.cmml">c</mi><mrow id="S3.SS2.p4.7.m7.2.2.2.2.3" xref="S3.SS2.p4.7.m7.2.2.2.2.3.cmml"><mi id="S3.SS2.p4.7.m7.2.2.2.2.3.2" xref="S3.SS2.p4.7.m7.2.2.2.2.3.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m7.2.2.2.2.3.1" xref="S3.SS2.p4.7.m7.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.7.m7.2.2.2.2.3.3" xref="S3.SS2.p4.7.m7.2.2.2.2.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m7.2.2.2.2.3.1a" xref="S3.SS2.p4.7.m7.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.7.m7.2.2.2.2.3.4" xref="S3.SS2.p4.7.m7.2.2.2.2.3.4.cmml">o</mi></mrow></msub><mo id="S3.SS2.p4.7.m7.3.3.3.5" xref="S3.SS2.p4.7.m7.3.3.4.cmml">,</mo><msub id="S3.SS2.p4.7.m7.3.3.3.3" xref="S3.SS2.p4.7.m7.3.3.3.3.cmml"><mi id="S3.SS2.p4.7.m7.3.3.3.3.2" xref="S3.SS2.p4.7.m7.3.3.3.3.2.cmml">c</mi><mrow id="S3.SS2.p4.7.m7.3.3.3.3.3" xref="S3.SS2.p4.7.m7.3.3.3.3.3.cmml"><mi id="S3.SS2.p4.7.m7.3.3.3.3.3.2" xref="S3.SS2.p4.7.m7.3.3.3.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m7.3.3.3.3.3.1" xref="S3.SS2.p4.7.m7.3.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.7.m7.3.3.3.3.3.3" xref="S3.SS2.p4.7.m7.3.3.3.3.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m7.3.3.3.3.3.1a" xref="S3.SS2.p4.7.m7.3.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.7.m7.3.3.3.3.3.4" xref="S3.SS2.p4.7.m7.3.3.3.3.3.4.cmml">t</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m7.3b"><list id="S3.SS2.p4.7.m7.3.3.4.cmml" xref="S3.SS2.p4.7.m7.3.3.3"><apply id="S3.SS2.p4.7.m7.1.1.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m7.1.1.1.1.1.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p4.7.m7.1.1.1.1.2.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1.2">ğ‘</ci><apply id="S3.SS2.p4.7.m7.1.1.1.1.3.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1.3"><times id="S3.SS2.p4.7.m7.1.1.1.1.3.1.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1.3.1"></times><ci id="S3.SS2.p4.7.m7.1.1.1.1.3.2.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1.3.2">ğ‘–</ci><ci id="S3.SS2.p4.7.m7.1.1.1.1.3.3.cmml" xref="S3.SS2.p4.7.m7.1.1.1.1.3.3">ğ‘‘</ci></apply></apply><apply id="S3.SS2.p4.7.m7.2.2.2.2.cmml" xref="S3.SS2.p4.7.m7.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m7.2.2.2.2.1.cmml" xref="S3.SS2.p4.7.m7.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p4.7.m7.2.2.2.2.2.cmml" xref="S3.SS2.p4.7.m7.2.2.2.2.2">ğ‘</ci><apply id="S3.SS2.p4.7.m7.2.2.2.2.3.cmml" xref="S3.SS2.p4.7.m7.2.2.2.2.3"><times id="S3.SS2.p4.7.m7.2.2.2.2.3.1.cmml" xref="S3.SS2.p4.7.m7.2.2.2.2.3.1"></times><ci id="S3.SS2.p4.7.m7.2.2.2.2.3.2.cmml" xref="S3.SS2.p4.7.m7.2.2.2.2.3.2">ğ‘’</ci><ci id="S3.SS2.p4.7.m7.2.2.2.2.3.3.cmml" xref="S3.SS2.p4.7.m7.2.2.2.2.3.3">ğ‘š</ci><ci id="S3.SS2.p4.7.m7.2.2.2.2.3.4.cmml" xref="S3.SS2.p4.7.m7.2.2.2.2.3.4">ğ‘œ</ci></apply></apply><apply id="S3.SS2.p4.7.m7.3.3.3.3.cmml" xref="S3.SS2.p4.7.m7.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m7.3.3.3.3.1.cmml" xref="S3.SS2.p4.7.m7.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p4.7.m7.3.3.3.3.2.cmml" xref="S3.SS2.p4.7.m7.3.3.3.3.2">ğ‘</ci><apply id="S3.SS2.p4.7.m7.3.3.3.3.3.cmml" xref="S3.SS2.p4.7.m7.3.3.3.3.3"><times id="S3.SS2.p4.7.m7.3.3.3.3.3.1.cmml" xref="S3.SS2.p4.7.m7.3.3.3.3.3.1"></times><ci id="S3.SS2.p4.7.m7.3.3.3.3.3.2.cmml" xref="S3.SS2.p4.7.m7.3.3.3.3.3.2">ğ‘–</ci><ci id="S3.SS2.p4.7.m7.3.3.3.3.3.3.cmml" xref="S3.SS2.p4.7.m7.3.3.3.3.3.3">ğ‘›</ci><ci id="S3.SS2.p4.7.m7.3.3.3.3.3.4.cmml" xref="S3.SS2.p4.7.m7.3.3.3.3.3.4">ğ‘¡</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m7.3c">c_{id},c_{emo},c_{int}</annotation></semantics></math> are concatenated one-hot vectors representing subject identity, emotion class, and intensity category respectively.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2409.07966/assets/Assets/stage2.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="521" height="249" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.16.8.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S3.F3.14.7" class="ltx_text" style="font-size:90%;">Stage 2: We keep the motion autoencoder trained in the previous stage frozen and train the HuBERT based Audio Encoder in such a way that given audio, <math id="S3.F3.8.1.m1.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.F3.8.1.m1.1b"><mi id="S3.F3.8.1.m1.1.1" xref="S3.F3.8.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.F3.8.1.m1.1c"><ci id="S3.F3.8.1.m1.1.1.cmml" xref="S3.F3.8.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.8.1.m1.1d">a</annotation></semantics></math>, it produces audio latent, <math id="S3.F3.9.2.m2.1" class="ltx_Math" alttext="z^{\text{a}}" display="inline"><semantics id="S3.F3.9.2.m2.1b"><msup id="S3.F3.9.2.m2.1.1" xref="S3.F3.9.2.m2.1.1.cmml"><mi id="S3.F3.9.2.m2.1.1.2" xref="S3.F3.9.2.m2.1.1.2.cmml">z</mi><mtext id="S3.F3.9.2.m2.1.1.3" xref="S3.F3.9.2.m2.1.1.3a.cmml">a</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F3.9.2.m2.1c"><apply id="S3.F3.9.2.m2.1.1.cmml" xref="S3.F3.9.2.m2.1.1"><csymbol cd="ambiguous" id="S3.F3.9.2.m2.1.1.1.cmml" xref="S3.F3.9.2.m2.1.1">superscript</csymbol><ci id="S3.F3.9.2.m2.1.1.2.cmml" xref="S3.F3.9.2.m2.1.1.2">ğ‘§</ci><ci id="S3.F3.9.2.m2.1.1.3a.cmml" xref="S3.F3.9.2.m2.1.1.3"><mtext mathsize="70%" id="S3.F3.9.2.m2.1.1.3.cmml" xref="S3.F3.9.2.m2.1.1.3">a</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.9.2.m2.1d">z^{\text{a}}</annotation></semantics></math> that closely resembles the motion latent, <math id="S3.F3.10.3.m3.1" class="ltx_Math" alttext="z^{\text{m}}" display="inline"><semantics id="S3.F3.10.3.m3.1b"><msup id="S3.F3.10.3.m3.1.1" xref="S3.F3.10.3.m3.1.1.cmml"><mi id="S3.F3.10.3.m3.1.1.2" xref="S3.F3.10.3.m3.1.1.2.cmml">z</mi><mtext id="S3.F3.10.3.m3.1.1.3" xref="S3.F3.10.3.m3.1.1.3a.cmml">m</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F3.10.3.m3.1c"><apply id="S3.F3.10.3.m3.1.1.cmml" xref="S3.F3.10.3.m3.1.1"><csymbol cd="ambiguous" id="S3.F3.10.3.m3.1.1.1.cmml" xref="S3.F3.10.3.m3.1.1">superscript</csymbol><ci id="S3.F3.10.3.m3.1.1.2.cmml" xref="S3.F3.10.3.m3.1.1.2">ğ‘§</ci><ci id="S3.F3.10.3.m3.1.1.3a.cmml" xref="S3.F3.10.3.m3.1.1.3"><mtext mathsize="70%" id="S3.F3.10.3.m3.1.1.3.cmml" xref="S3.F3.10.3.m3.1.1.3">m</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.10.3.m3.1d">z^{\text{m}}</annotation></semantics></math> produced by the frozen motion encoder. The Style Vector, <math id="S3.F3.11.4.m4.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.F3.11.4.m4.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F3.11.4.m4.1.1" xref="S3.F3.11.4.m4.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.F3.11.4.m4.1c"><ci id="S3.F3.11.4.m4.1.1.cmml" xref="S3.F3.11.4.m4.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.11.4.m4.1d">\mathcal{C}</annotation></semantics></math> (i.e. concatenated one-hot vectors containing information about subject ID, emotion class and emotion intensity) is used to learn the Style Embedding that is fused with the encoded audio information. Unlike stage 1 training, the audio latent <math id="S3.F3.12.5.m5.1" class="ltx_Math" alttext="z^{\text{a}}" display="inline"><semantics id="S3.F3.12.5.m5.1b"><msup id="S3.F3.12.5.m5.1.1" xref="S3.F3.12.5.m5.1.1.cmml"><mi id="S3.F3.12.5.m5.1.1.2" xref="S3.F3.12.5.m5.1.1.2.cmml">z</mi><mtext id="S3.F3.12.5.m5.1.1.3" xref="S3.F3.12.5.m5.1.1.3a.cmml">a</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F3.12.5.m5.1c"><apply id="S3.F3.12.5.m5.1.1.cmml" xref="S3.F3.12.5.m5.1.1"><csymbol cd="ambiguous" id="S3.F3.12.5.m5.1.1.1.cmml" xref="S3.F3.12.5.m5.1.1">superscript</csymbol><ci id="S3.F3.12.5.m5.1.1.2.cmml" xref="S3.F3.12.5.m5.1.1.2">ğ‘§</ci><ci id="S3.F3.12.5.m5.1.1.3a.cmml" xref="S3.F3.12.5.m5.1.1.3"><mtext mathsize="70%" id="S3.F3.12.5.m5.1.1.3.cmml" xref="S3.F3.12.5.m5.1.1.3">a</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.12.5.m5.1d">z^{\text{a}}</annotation></semantics></math> is used to get the quantized codebook latent <math id="S3.F3.13.6.m6.1" class="ltx_Math" alttext="z^{\prime}" display="inline"><semantics id="S3.F3.13.6.m6.1b"><msup id="S3.F3.13.6.m6.1.1" xref="S3.F3.13.6.m6.1.1.cmml"><mi id="S3.F3.13.6.m6.1.1.2" xref="S3.F3.13.6.m6.1.1.2.cmml">z</mi><mo id="S3.F3.13.6.m6.1.1.3" xref="S3.F3.13.6.m6.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.F3.13.6.m6.1c"><apply id="S3.F3.13.6.m6.1.1.cmml" xref="S3.F3.13.6.m6.1.1"><csymbol cd="ambiguous" id="S3.F3.13.6.m6.1.1.1.cmml" xref="S3.F3.13.6.m6.1.1">superscript</csymbol><ci id="S3.F3.13.6.m6.1.1.2.cmml" xref="S3.F3.13.6.m6.1.1.2">ğ‘§</ci><ci id="S3.F3.13.6.m6.1.1.3.cmml" xref="S3.F3.13.6.m6.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.13.6.m6.1d">z^{\prime}</annotation></semantics></math> that is then decoded into facial animation <math id="S3.F3.14.7.m7.1" class="ltx_Math" alttext="\hat{\mathcal{X}}" display="inline"><semantics id="S3.F3.14.7.m7.1b"><mover accent="true" id="S3.F3.14.7.m7.1.1" xref="S3.F3.14.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F3.14.7.m7.1.1.2" xref="S3.F3.14.7.m7.1.1.2.cmml">ğ’³</mi><mo id="S3.F3.14.7.m7.1.1.1" xref="S3.F3.14.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F3.14.7.m7.1c"><apply id="S3.F3.14.7.m7.1.1.cmml" xref="S3.F3.14.7.m7.1.1"><ci id="S3.F3.14.7.m7.1.1.1.cmml" xref="S3.F3.14.7.m7.1.1.1">^</ci><ci id="S3.F3.14.7.m7.1.1.2.cmml" xref="S3.F3.14.7.m7.1.1.2">ğ’³</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.14.7.m7.1d">\hat{\mathcal{X}}</annotation></semantics></math>, utilizing the frozen motion decoder.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S3.F3.17" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.F3.18" class="ltx_p ltx_figure_panel ltx_align_center">ProbTalk3D stage 2 detailed figure.</p>
</div>
</div>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Proposed Model: ProbTalk3D</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Our proposed model ProbTalk3D follows a 2-stage training process similar to CodeTalker <cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite> and EMOTE <cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> where in the first stage, we learn a motion prior with a motion autoencoder and in the second stage, we train a speech and style conditioned network by leveraging the pretrained HuBERT audio encoder<cite class="ltx_cite ltx_citemacro_citep">(Hsu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite> and the motion prior from stage 1. Different from EMOTE <cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>, our proposed model produces diverse outputs non-deterministically with less training data, a less complex and more efficient architecture. The perceptual losses from EMOTE (lip-reading and video-emotion loss) require the ground truth performance videos from the original MEAD dataset, and these involve extra processing that ours does not require. Instead we use quantization and reconstruction losses in the first and second stage.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1. </span>Stage 1: Motion Autoencoder</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.10" class="ltx_p">The Motion Autoencoder consists of a motion encoder and a decoder aimed to learn a facial motion prior, leveraging the concept of Vector Quantized Variational Autoencoder (VQ-VAE) as laid out in Fig. <a href="#S2.F2" title="Figure 2 â€£ 2.2. Emotion-Controllable 3D Facial Animation â€£ 2. Related Work â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The Motion Encoder maps the motion input into a latent space during training. We employ transformers, which are proven to effectively capture and learn temporal context. Specifically, the encoder contains a linear projection layer, a 1D convolutional layer, and 6 transformer layers with residual attention and positional encoding. Given an input <math id="S3.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="X\in\mathbb{R}^{F\times P}" display="inline"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mrow id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS3.SSS1.p1.1.m1.1.1.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.2.cmml">X</mi><mo id="S3.SS3.SSS1.p1.1.m1.1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS3.SSS1.p1.1.m1.1.1.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS1.p1.1.m1.1.1.3.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS3.SSS1.p1.1.m1.1.1.3.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS3.SSS1.p1.1.m1.1.1.3.3.2" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.3.2.cmml">F</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.SSS1.p1.1.m1.1.1.3.3.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS3.SSS1.p1.1.m1.1.1.3.3.3" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.3.3.cmml">P</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><apply id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1"><in id="S3.SS3.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.1"></in><ci id="S3.SS3.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.2">ğ‘‹</ci><apply id="S3.SS3.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.2">â„</ci><apply id="S3.SS3.SSS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.3"><times id="S3.SS3.SSS1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.3.1"></times><ci id="S3.SS3.SSS1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.3.2">ğ¹</ci><ci id="S3.SS3.SSS1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1.3.3.3">ğ‘ƒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">X\in\mathbb{R}^{F\times P}</annotation></semantics></math>, the Motion Encoder encodes the data to a latent vector <math id="S3.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="z\in\mathbb{R}^{F\times 256}" display="inline"><semantics id="S3.SS3.SSS1.p1.2.m2.1a"><mrow id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.1.1.2" xref="S3.SS3.SSS1.p1.2.m2.1.1.2.cmml">z</mi><mo id="S3.SS3.SSS1.p1.2.m2.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS3.SSS1.p1.2.m2.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.1.1.3.2" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS3.SSS1.p1.2.m2.1.1.3.3" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.1.1.3.3.2" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3.2.cmml">F</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.SSS1.p1.2.m2.1.1.3.3.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS3.SSS1.p1.2.m2.1.1.3.3.3" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3.3.cmml">256</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b"><apply id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1"><in id="S3.SS3.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.1"></in><ci id="S3.SS3.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.2">ğ‘§</ci><apply id="S3.SS3.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.2">â„</ci><apply id="S3.SS3.SSS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3"><times id="S3.SS3.SSS1.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3.1"></times><ci id="S3.SS3.SSS1.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3.2">ğ¹</ci><cn type="integer" id="S3.SS3.SSS1.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1.3.3.3">256</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">z\in\mathbb{R}^{F\times 256}</annotation></semantics></math>. The encoded motion, <math id="S3.SS3.SSS1.p1.3.m3.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS3.SSS1.p1.3.m3.1a"><mi id="S3.SS3.SSS1.p1.3.m3.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.1b"><ci id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.1c">z</annotation></semantics></math> undergoes vector quantization and learns a discrete latent embedding codebook, <math id="S3.SS3.SSS1.p1.4.m4.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS3.SSS1.p1.4.m4.1a"><mi id="S3.SS3.SSS1.p1.4.m4.1.1" xref="S3.SS3.SSS1.p1.4.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.4.m4.1b"><ci id="S3.SS3.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.4.m4.1c">E</annotation></semantics></math>. We configure <math id="S3.SS3.SSS1.p1.5.m5.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS3.SSS1.p1.5.m5.1a"><mi id="S3.SS3.SSS1.p1.5.m5.1.1" xref="S3.SS3.SSS1.p1.5.m5.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.5.m5.1b"><ci id="S3.SS3.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS1.p1.5.m5.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.5.m5.1c">E</annotation></semantics></math> to have 256 latent embeddings with each embedding dimension being 128. This setup implies a codebook size of 256, indicating that the motion is categorized into 256 types and each category is represented by a 128-dimensional vector. From the codebook, we find the embedding that is close to <math id="S3.SS3.SSS1.p1.6.m6.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS3.SSS1.p1.6.m6.1a"><mi id="S3.SS3.SSS1.p1.6.m6.1.1" xref="S3.SS3.SSS1.p1.6.m6.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.6.m6.1b"><ci id="S3.SS3.SSS1.p1.6.m6.1.1.cmml" xref="S3.SS3.SSS1.p1.6.m6.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.6.m6.1c">z</annotation></semantics></math> in terms of distance in the quantization process. This selected embedding is then reshaped to align with the dimension of <math id="S3.SS3.SSS1.p1.7.m7.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS3.SSS1.p1.7.m7.1a"><mi id="S3.SS3.SSS1.p1.7.m7.1.1" xref="S3.SS3.SSS1.p1.7.m7.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.7.m7.1b"><ci id="S3.SS3.SSS1.p1.7.m7.1.1.cmml" xref="S3.SS3.SSS1.p1.7.m7.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.7.m7.1c">z</annotation></semantics></math>, resulting in a quantized latent motion feature, <math id="S3.SS3.SSS1.p1.8.m8.1" class="ltx_Math" alttext="z^{\prime}" display="inline"><semantics id="S3.SS3.SSS1.p1.8.m8.1a"><msup id="S3.SS3.SSS1.p1.8.m8.1.1" xref="S3.SS3.SSS1.p1.8.m8.1.1.cmml"><mi id="S3.SS3.SSS1.p1.8.m8.1.1.2" xref="S3.SS3.SSS1.p1.8.m8.1.1.2.cmml">z</mi><mo id="S3.SS3.SSS1.p1.8.m8.1.1.3" xref="S3.SS3.SSS1.p1.8.m8.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.8.m8.1b"><apply id="S3.SS3.SSS1.p1.8.m8.1.1.cmml" xref="S3.SS3.SSS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.8.m8.1.1.1.cmml" xref="S3.SS3.SSS1.p1.8.m8.1.1">superscript</csymbol><ci id="S3.SS3.SSS1.p1.8.m8.1.1.2.cmml" xref="S3.SS3.SSS1.p1.8.m8.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS1.p1.8.m8.1.1.3.cmml" xref="S3.SS3.SSS1.p1.8.m8.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.8.m8.1c">z^{\prime}</annotation></semantics></math>. More details on the background knowledge of VQ-VAE can be found in the supplementary material.
The Motion Decoder consists of a 1D convolutional layer followed by 6 transformer layers. Additionally, a fully connected layer projects the hidden units back to the original input dimension. The Motion Decoder accepts <math id="S3.SS3.SSS1.p1.9.m9.1" class="ltx_Math" alttext="z^{\prime}\in\mathbb{R}^{N\times 256}" display="inline"><semantics id="S3.SS3.SSS1.p1.9.m9.1a"><mrow id="S3.SS3.SSS1.p1.9.m9.1.1" xref="S3.SS3.SSS1.p1.9.m9.1.1.cmml"><msup id="S3.SS3.SSS1.p1.9.m9.1.1.2" xref="S3.SS3.SSS1.p1.9.m9.1.1.2.cmml"><mi id="S3.SS3.SSS1.p1.9.m9.1.1.2.2" xref="S3.SS3.SSS1.p1.9.m9.1.1.2.2.cmml">z</mi><mo id="S3.SS3.SSS1.p1.9.m9.1.1.2.3" xref="S3.SS3.SSS1.p1.9.m9.1.1.2.3.cmml">â€²</mo></msup><mo id="S3.SS3.SSS1.p1.9.m9.1.1.1" xref="S3.SS3.SSS1.p1.9.m9.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS3.SSS1.p1.9.m9.1.1.3" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.cmml"><mi id="S3.SS3.SSS1.p1.9.m9.1.1.3.2" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.2.cmml">â„</mi><mrow id="S3.SS3.SSS1.p1.9.m9.1.1.3.3" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.3.cmml"><mi id="S3.SS3.SSS1.p1.9.m9.1.1.3.3.2" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.SSS1.p1.9.m9.1.1.3.3.1" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS3.SSS1.p1.9.m9.1.1.3.3.3" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.3.3.cmml">256</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.9.m9.1b"><apply id="S3.SS3.SSS1.p1.9.m9.1.1.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1"><in id="S3.SS3.SSS1.p1.9.m9.1.1.1.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.1"></in><apply id="S3.SS3.SSS1.p1.9.m9.1.1.2.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.9.m9.1.1.2.1.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.2">superscript</csymbol><ci id="S3.SS3.SSS1.p1.9.m9.1.1.2.2.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.2.2">ğ‘§</ci><ci id="S3.SS3.SSS1.p1.9.m9.1.1.2.3.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.2.3">â€²</ci></apply><apply id="S3.SS3.SSS1.p1.9.m9.1.1.3.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.9.m9.1.1.3.1.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS1.p1.9.m9.1.1.3.2.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.2">â„</ci><apply id="S3.SS3.SSS1.p1.9.m9.1.1.3.3.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.3"><times id="S3.SS3.SSS1.p1.9.m9.1.1.3.3.1.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.3.1"></times><ci id="S3.SS3.SSS1.p1.9.m9.1.1.3.3.2.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.3.2">ğ‘</ci><cn type="integer" id="S3.SS3.SSS1.p1.9.m9.1.1.3.3.3.cmml" xref="S3.SS3.SSS1.p1.9.m9.1.1.3.3.3">256</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.9.m9.1c">z^{\prime}\in\mathbb{R}^{N\times 256}</annotation></semantics></math> as input and processes it to yield <math id="S3.SS3.SSS1.p1.10.m10.1" class="ltx_Math" alttext="\hat{\mathcal{X}}\in\mathbb{R}^{F\times P}" display="inline"><semantics id="S3.SS3.SSS1.p1.10.m10.1a"><mrow id="S3.SS3.SSS1.p1.10.m10.1.1" xref="S3.SS3.SSS1.p1.10.m10.1.1.cmml"><mover accent="true" id="S3.SS3.SSS1.p1.10.m10.1.1.2" xref="S3.SS3.SSS1.p1.10.m10.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.p1.10.m10.1.1.2.2" xref="S3.SS3.SSS1.p1.10.m10.1.1.2.2.cmml">ğ’³</mi><mo id="S3.SS3.SSS1.p1.10.m10.1.1.2.1" xref="S3.SS3.SSS1.p1.10.m10.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS3.SSS1.p1.10.m10.1.1.1" xref="S3.SS3.SSS1.p1.10.m10.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS3.SSS1.p1.10.m10.1.1.3" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.cmml"><mi id="S3.SS3.SSS1.p1.10.m10.1.1.3.2" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.2.cmml">â„</mi><mrow id="S3.SS3.SSS1.p1.10.m10.1.1.3.3" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.3.cmml"><mi id="S3.SS3.SSS1.p1.10.m10.1.1.3.3.2" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.3.2.cmml">F</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.SSS1.p1.10.m10.1.1.3.3.1" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS3.SSS1.p1.10.m10.1.1.3.3.3" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.3.3.cmml">P</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.10.m10.1b"><apply id="S3.SS3.SSS1.p1.10.m10.1.1.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1"><in id="S3.SS3.SSS1.p1.10.m10.1.1.1.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.1"></in><apply id="S3.SS3.SSS1.p1.10.m10.1.1.2.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.2"><ci id="S3.SS3.SSS1.p1.10.m10.1.1.2.1.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.2.1">^</ci><ci id="S3.SS3.SSS1.p1.10.m10.1.1.2.2.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.2.2">ğ’³</ci></apply><apply id="S3.SS3.SSS1.p1.10.m10.1.1.3.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.10.m10.1.1.3.1.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS1.p1.10.m10.1.1.3.2.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.2">â„</ci><apply id="S3.SS3.SSS1.p1.10.m10.1.1.3.3.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.3"><times id="S3.SS3.SSS1.p1.10.m10.1.1.3.3.1.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.3.1"></times><ci id="S3.SS3.SSS1.p1.10.m10.1.1.3.3.2.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.3.2">ğ¹</ci><ci id="S3.SS3.SSS1.p1.10.m10.1.1.3.3.3.cmml" xref="S3.SS3.SSS1.p1.10.m10.1.1.3.3.3">ğ‘ƒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.10.m10.1c">\hat{\mathcal{X}}\in\mathbb{R}^{F\times P}</annotation></semantics></math>.
The architecture shares similarities with recent VQ-VAE based works <cite class="ltx_cite ltx_citemacro_citep">(Ng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2022</a>; Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite>. However, unlike these models that autoregressively predict future frames based on previously generated frames for a given sequence, ours is non-autoregressive similar to EMOTE <cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>, notably improving training and inference efficiency.</p>
</div>
<section id="S3.SS3.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Loss function</h5>

<div id="S3.SS3.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.Px1.p1.5" class="ltx_p">We define the loss function for training stage 1 in Eq.(<a href="#S3.E4" title="In Loss function â€£ 3.3.1. Stage 1: Motion Autoencoder â€£ 3.3. Proposed Model: ProbTalk3D â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). There are three weighted loss terms- (i) <math id="S3.SS3.SSS1.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{qua}" display="inline"><semantics id="S3.SS3.SSS1.Px1.p1.1.m1.1a"><msub id="S3.SS3.SSS1.Px1.p1.1.m1.1.1" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.2" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.2" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.1" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.3" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.1a" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.4" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.4.cmml">a</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p1.1.m1.1b"><apply id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.2">â„’</ci><apply id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3"><times id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.3">ğ‘¢</ci><ci id="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.4.cmml" xref="S3.SS3.SSS1.Px1.p1.1.m1.1.1.3.4">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p1.1.m1.1c">\mathcal{L}_{qua}</annotation></semantics></math>, that represents the standard quantization loss with codebook loss term and commitment loss term proposed for VQ-VAE models (see Eq.(<a href="#S3.E3" title="In Loss function â€£ 3.3.1. Stage 1: Motion Autoencoder â€£ 3.3. Proposed Model: ProbTalk3D â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>)), (ii) <math id="S3.SS3.SSS1.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{rec}^{exp}" display="inline"><semantics id="S3.SS3.SSS1.Px1.p1.2.m2.1a"><msubsup id="S3.SS3.SSS1.Px1.p1.2.m2.1.1" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.2" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.2.cmml">â„’</mi><mrow id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.cmml"><mi id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.2" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.1" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.3" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.1a" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.4" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.4.cmml">c</mi></mrow><mrow id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.2" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.1" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.3" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.3.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.1a" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.4" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.4.cmml">p</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p1.2.m2.1b"><apply id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1">superscript</csymbol><apply id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.2">â„’</ci><apply id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3"><times id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.1.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.1"></times><ci id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.2.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.3.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.3">ğ‘’</ci><ci id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.4.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.2.3.4">ğ‘</ci></apply></apply><apply id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3"><times id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.2">ğ‘’</ci><ci id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.3">ğ‘¥</ci><ci id="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.4.cmml" xref="S3.SS3.SSS1.Px1.p1.2.m2.1.1.3.4">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p1.2.m2.1c">\mathcal{L}_{rec}^{exp}</annotation></semantics></math>, that computes the <math id="S3.SS3.SSS1.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{1}" display="inline"><semantics id="S3.SS3.SSS1.Px1.p1.3.m3.1a"><msub id="S3.SS3.SSS1.Px1.p1.3.m3.1.1" xref="S3.SS3.SSS1.Px1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.Px1.p1.3.m3.1.1.2" xref="S3.SS3.SSS1.Px1.p1.3.m3.1.1.2.cmml">â„’</mi><mn id="S3.SS3.SSS1.Px1.p1.3.m3.1.1.3" xref="S3.SS3.SSS1.Px1.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p1.3.m3.1b"><apply id="S3.SS3.SSS1.Px1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.Px1.p1.3.m3.1.1.2">â„’</ci><cn type="integer" id="S3.SS3.SSS1.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.Px1.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p1.3.m3.1c">\mathcal{L}_{1}</annotation></semantics></math> loss between decoded motion and ground truth in terms of the 50 expression parameters, (iii) <math id="S3.SS3.SSS1.Px1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{L}_{rec}^{jaw}" display="inline"><semantics id="S3.SS3.SSS1.Px1.p1.4.m4.1a"><msubsup id="S3.SS3.SSS1.Px1.p1.4.m4.1.1" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.2" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.2.cmml">â„’</mi><mrow id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.cmml"><mi id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.2" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.1" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.3" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.1a" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.4" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.4.cmml">c</mi></mrow><mrow id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.2" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.1" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.3" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.1a" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.4" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.4.cmml">w</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p1.4.m4.1b"><apply id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1">superscript</csymbol><apply id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.1.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.2.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.2">â„’</ci><apply id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3"><times id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.1.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.1"></times><ci id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.2.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.2">ğ‘Ÿ</ci><ci id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.3.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.3">ğ‘’</ci><ci id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.4.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.2.3.4">ğ‘</ci></apply></apply><apply id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3"><times id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.1"></times><ci id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.2">ğ‘—</ci><ci id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.3">ğ‘</ci><ci id="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.4.cmml" xref="S3.SS3.SSS1.Px1.p1.4.m4.1.1.3.4">ğ‘¤</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p1.4.m4.1c">\mathcal{L}_{rec}^{jaw}</annotation></semantics></math>, that computes the <math id="S3.SS3.SSS1.Px1.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{L}_{1}" display="inline"><semantics id="S3.SS3.SSS1.Px1.p1.5.m5.1a"><msub id="S3.SS3.SSS1.Px1.p1.5.m5.1.1" xref="S3.SS3.SSS1.Px1.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS1.Px1.p1.5.m5.1.1.2" xref="S3.SS3.SSS1.Px1.p1.5.m5.1.1.2.cmml">â„’</mi><mn id="S3.SS3.SSS1.Px1.p1.5.m5.1.1.3" xref="S3.SS3.SSS1.Px1.p1.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p1.5.m5.1b"><apply id="S3.SS3.SSS1.Px1.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS3.SSS1.Px1.p1.5.m5.1.1.2">â„’</ci><cn type="integer" id="S3.SS3.SSS1.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS3.SSS1.Px1.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p1.5.m5.1c">\mathcal{L}_{1}</annotation></semantics></math> loss between decoded motion and ground truth in terms of the 3 jaw parameters.</p>
</div>
<div id="S3.SS3.SSS1.Px1.p2" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_Math" alttext="\mathcal{L_{\text{qua}}}=\|\text{sg}[z]-{z^{\prime}}\|_{2}^{2}+\beta\|z-\text{sg}[z^{\prime}]\|_{2}^{2}" display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><msub id="S3.E3.m1.3.3.4" xref="S3.E3.m1.3.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.4.2" xref="S3.E3.m1.3.3.4.2.cmml">â„’</mi><mtext id="S3.E3.m1.3.3.4.3" xref="S3.E3.m1.3.3.4.3a.cmml">qua</mtext></msub><mo id="S3.E3.m1.3.3.3" xref="S3.E3.m1.3.3.3.cmml">=</mo><mrow id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml"><msubsup id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml"><mtext id="S3.E3.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.2a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.2.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.2.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.1.1.cmml">[</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">z</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.1.1.cmml">]</mo></mrow></mrow><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml">âˆ’</mo><msup id="S3.E3.m1.2.2.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.2.cmml">z</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.1.3.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.3.cmml">â€²</mo></msup></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E3.m1.2.2.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.3.cmml">2</mn><mn id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml">2</mn></msubsup><mo id="S3.E3.m1.3.3.2.3" xref="S3.E3.m1.3.3.2.3.cmml">+</mo><mrow id="S3.E3.m1.3.3.2.2" xref="S3.E3.m1.3.3.2.2.cmml"><mi id="S3.E3.m1.3.3.2.2.3" xref="S3.E3.m1.3.3.2.2.3.cmml">Î²</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.2.2.2" xref="S3.E3.m1.3.3.2.2.2.cmml">â€‹</mo><msubsup id="S3.E3.m1.3.3.2.2.1" xref="S3.E3.m1.3.3.2.2.1.cmml"><mrow id="S3.E3.m1.3.3.2.2.1.1.1.1" xref="S3.E3.m1.3.3.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.2.2.1.1.1.1.2" xref="S3.E3.m1.3.3.2.2.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E3.m1.3.3.2.2.1.1.1.1.1" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.2.2.1.1.1.1.1.3" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.3.cmml">z</mi><mo id="S3.E3.m1.3.3.2.2.1.1.1.1.1.2" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.cmml"><mtext id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.3a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.2.1.cmml">[</mo><msup id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mo id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E3.m1.3.3.2.2.1.1.1.1.3" xref="S3.E3.m1.3.3.2.2.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E3.m1.3.3.2.2.1.1.3" xref="S3.E3.m1.3.3.2.2.1.1.3.cmml">2</mn><mn id="S3.E3.m1.3.3.2.2.1.3" xref="S3.E3.m1.3.3.2.2.1.3.cmml">2</mn></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3"><eq id="S3.E3.m1.3.3.3.cmml" xref="S3.E3.m1.3.3.3"></eq><apply id="S3.E3.m1.3.3.4.cmml" xref="S3.E3.m1.3.3.4"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.4.1.cmml" xref="S3.E3.m1.3.3.4">subscript</csymbol><ci id="S3.E3.m1.3.3.4.2.cmml" xref="S3.E3.m1.3.3.4.2">â„’</ci><ci id="S3.E3.m1.3.3.4.3a.cmml" xref="S3.E3.m1.3.3.4.3"><mtext mathsize="70%" id="S3.E3.m1.3.3.4.3.cmml" xref="S3.E3.m1.3.3.4.3">qua</mtext></ci></apply><apply id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2"><plus id="S3.E3.m1.3.3.2.3.cmml" xref="S3.E3.m1.3.3.2.3"></plus><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1">subscript</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1"><minus id="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1"></minus><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2"><times id="S3.E3.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.1"></times><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.2.2a.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.2"><mtext id="S3.E3.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.2">sg</mtext></ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.2"><csymbol cd="latexml" id="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.3.2.1">delimited-[]</csymbol><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘§</ci></apply></apply><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.3">â€²</ci></apply></apply></apply><cn type="integer" id="S3.E3.m1.2.2.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.3">2</cn></apply><cn type="integer" id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3">2</cn></apply><apply id="S3.E3.m1.3.3.2.2.cmml" xref="S3.E3.m1.3.3.2.2"><times id="S3.E3.m1.3.3.2.2.2.cmml" xref="S3.E3.m1.3.3.2.2.2"></times><ci id="S3.E3.m1.3.3.2.2.3.cmml" xref="S3.E3.m1.3.3.2.2.3">ğ›½</ci><apply id="S3.E3.m1.3.3.2.2.1.cmml" xref="S3.E3.m1.3.3.2.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.1.2.cmml" xref="S3.E3.m1.3.3.2.2.1">superscript</csymbol><apply id="S3.E3.m1.3.3.2.2.1.1.cmml" xref="S3.E3.m1.3.3.2.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.1.1.2.cmml" xref="S3.E3.m1.3.3.2.2.1">subscript</csymbol><apply id="S3.E3.m1.3.3.2.2.1.1.1.2.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.3.3.2.2.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.3.3.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1"><minus id="S3.E3.m1.3.3.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.2"></minus><ci id="S3.E3.m1.3.3.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.3">ğ‘§</ci><apply id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1"><times id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.2"></times><ci id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.3a.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.3"><mtext id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.3">sg</mtext></ci><apply id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.2.2.1.1.1.1.1.1.1.1.1.3">â€²</ci></apply></apply></apply></apply></apply><cn type="integer" id="S3.E3.m1.3.3.2.2.1.1.3.cmml" xref="S3.E3.m1.3.3.2.2.1.1.3">2</cn></apply><cn type="integer" id="S3.E3.m1.3.3.2.2.1.3.cmml" xref="S3.E3.m1.3.3.2.2.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\mathcal{L_{\text{qua}}}=\|\text{sg}[z]-{z^{\prime}}\|_{2}^{2}+\beta\|z-\text{sg}[z^{\prime}]\|_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.SSS1.Px1.p3" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\mathcal{L_{\text{stage1}}}=\lambda_{\text{qua}}\mathcal{L}_{\text{qua}}+\lambda_{\text{rec}}^{\text{exp}}\mathcal{L}_{\text{rec}}^{\text{exp}}+\lambda_{\text{rec}}^{\text{jaw}}\mathcal{L}_{\text{rec}}^{\text{jaw}}" display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><msub id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.2.2" xref="S3.E4.m1.1.1.2.2.cmml">â„’</mi><mtext id="S3.E4.m1.1.1.2.3" xref="S3.E4.m1.1.1.2.3a.cmml">stage1</mtext></msub><mo id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><mrow id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml"><msub id="S3.E4.m1.1.1.3.2.2" xref="S3.E4.m1.1.1.3.2.2.cmml"><mi id="S3.E4.m1.1.1.3.2.2.2" xref="S3.E4.m1.1.1.3.2.2.2.cmml">Î»</mi><mtext id="S3.E4.m1.1.1.3.2.2.3" xref="S3.E4.m1.1.1.3.2.2.3a.cmml">qua</mtext></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.2.1" xref="S3.E4.m1.1.1.3.2.1.cmml">â€‹</mo><msub id="S3.E4.m1.1.1.3.2.3" xref="S3.E4.m1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.3.2.3.2" xref="S3.E4.m1.1.1.3.2.3.2.cmml">â„’</mi><mtext id="S3.E4.m1.1.1.3.2.3.3" xref="S3.E4.m1.1.1.3.2.3.3a.cmml">qua</mtext></msub></mrow><mo id="S3.E4.m1.1.1.3.1" xref="S3.E4.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml"><msubsup id="S3.E4.m1.1.1.3.3.2" xref="S3.E4.m1.1.1.3.3.2.cmml"><mi id="S3.E4.m1.1.1.3.3.2.2.2" xref="S3.E4.m1.1.1.3.3.2.2.2.cmml">Î»</mi><mtext id="S3.E4.m1.1.1.3.3.2.2.3" xref="S3.E4.m1.1.1.3.3.2.2.3a.cmml">rec</mtext><mtext id="S3.E4.m1.1.1.3.3.2.3" xref="S3.E4.m1.1.1.3.3.2.3a.cmml">exp</mtext></msubsup><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.3.1" xref="S3.E4.m1.1.1.3.3.1.cmml">â€‹</mo><msubsup id="S3.E4.m1.1.1.3.3.3" xref="S3.E4.m1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.3.3.3.2.2" xref="S3.E4.m1.1.1.3.3.3.2.2.cmml">â„’</mi><mtext id="S3.E4.m1.1.1.3.3.3.2.3" xref="S3.E4.m1.1.1.3.3.3.2.3a.cmml">rec</mtext><mtext id="S3.E4.m1.1.1.3.3.3.3" xref="S3.E4.m1.1.1.3.3.3.3a.cmml">exp</mtext></msubsup></mrow><mo id="S3.E4.m1.1.1.3.1a" xref="S3.E4.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E4.m1.1.1.3.4" xref="S3.E4.m1.1.1.3.4.cmml"><msubsup id="S3.E4.m1.1.1.3.4.2" xref="S3.E4.m1.1.1.3.4.2.cmml"><mi id="S3.E4.m1.1.1.3.4.2.2.2" xref="S3.E4.m1.1.1.3.4.2.2.2.cmml">Î»</mi><mtext id="S3.E4.m1.1.1.3.4.2.2.3" xref="S3.E4.m1.1.1.3.4.2.2.3a.cmml">rec</mtext><mtext id="S3.E4.m1.1.1.3.4.2.3" xref="S3.E4.m1.1.1.3.4.2.3a.cmml">jaw</mtext></msubsup><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.3.4.1" xref="S3.E4.m1.1.1.3.4.1.cmml">â€‹</mo><msubsup id="S3.E4.m1.1.1.3.4.3" xref="S3.E4.m1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.3.4.3.2.2" xref="S3.E4.m1.1.1.3.4.3.2.2.cmml">â„’</mi><mtext id="S3.E4.m1.1.1.3.4.3.2.3" xref="S3.E4.m1.1.1.3.4.3.2.3a.cmml">rec</mtext><mtext id="S3.E4.m1.1.1.3.4.3.3" xref="S3.E4.m1.1.1.3.4.3.3a.cmml">jaw</mtext></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"></eq><apply id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.2.2">â„’</ci><ci id="S3.E4.m1.1.1.2.3a.cmml" xref="S3.E4.m1.1.1.2.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.2.3">stage1</mtext></ci></apply><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><plus id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3.1"></plus><apply id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2"><times id="S3.E4.m1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.3.2.1"></times><apply id="S3.E4.m1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.2.1.cmml" xref="S3.E4.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2.2">ğœ†</ci><ci id="S3.E4.m1.1.1.3.2.2.3a.cmml" xref="S3.E4.m1.1.1.3.2.2.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.2.2.3.cmml" xref="S3.E4.m1.1.1.3.2.2.3">qua</mtext></ci></apply><apply id="S3.E4.m1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.1.1.3.2.3.2">â„’</ci><ci id="S3.E4.m1.1.1.3.2.3.3a.cmml" xref="S3.E4.m1.1.1.3.2.3.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.2.3.3.cmml" xref="S3.E4.m1.1.1.3.2.3.3">qua</mtext></ci></apply></apply><apply id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3"><times id="S3.E4.m1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3.1"></times><apply id="S3.E4.m1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.3.2.1.cmml" xref="S3.E4.m1.1.1.3.3.2">superscript</csymbol><apply id="S3.E4.m1.1.1.3.3.2.2.cmml" xref="S3.E4.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.3.2.2.1.cmml" xref="S3.E4.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.E4.m1.1.1.3.3.2.2.2.cmml" xref="S3.E4.m1.1.1.3.3.2.2.2">ğœ†</ci><ci id="S3.E4.m1.1.1.3.3.2.2.3a.cmml" xref="S3.E4.m1.1.1.3.3.2.2.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.3.2.2.3.cmml" xref="S3.E4.m1.1.1.3.3.2.2.3">rec</mtext></ci></apply><ci id="S3.E4.m1.1.1.3.3.2.3a.cmml" xref="S3.E4.m1.1.1.3.3.2.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.3.2.3.cmml" xref="S3.E4.m1.1.1.3.3.2.3">exp</mtext></ci></apply><apply id="S3.E4.m1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3.3">superscript</csymbol><apply id="S3.E4.m1.1.1.3.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.3.3.2.1.cmml" xref="S3.E4.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.3.3.2.2.cmml" xref="S3.E4.m1.1.1.3.3.3.2.2">â„’</ci><ci id="S3.E4.m1.1.1.3.3.3.2.3a.cmml" xref="S3.E4.m1.1.1.3.3.3.2.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.3.3.2.3.cmml" xref="S3.E4.m1.1.1.3.3.3.2.3">rec</mtext></ci></apply><ci id="S3.E4.m1.1.1.3.3.3.3a.cmml" xref="S3.E4.m1.1.1.3.3.3.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.3.3.3.cmml" xref="S3.E4.m1.1.1.3.3.3.3">exp</mtext></ci></apply></apply><apply id="S3.E4.m1.1.1.3.4.cmml" xref="S3.E4.m1.1.1.3.4"><times id="S3.E4.m1.1.1.3.4.1.cmml" xref="S3.E4.m1.1.1.3.4.1"></times><apply id="S3.E4.m1.1.1.3.4.2.cmml" xref="S3.E4.m1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.4.2.1.cmml" xref="S3.E4.m1.1.1.3.4.2">superscript</csymbol><apply id="S3.E4.m1.1.1.3.4.2.2.cmml" xref="S3.E4.m1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.4.2.2.1.cmml" xref="S3.E4.m1.1.1.3.4.2">subscript</csymbol><ci id="S3.E4.m1.1.1.3.4.2.2.2.cmml" xref="S3.E4.m1.1.1.3.4.2.2.2">ğœ†</ci><ci id="S3.E4.m1.1.1.3.4.2.2.3a.cmml" xref="S3.E4.m1.1.1.3.4.2.2.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.4.2.2.3.cmml" xref="S3.E4.m1.1.1.3.4.2.2.3">rec</mtext></ci></apply><ci id="S3.E4.m1.1.1.3.4.2.3a.cmml" xref="S3.E4.m1.1.1.3.4.2.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.4.2.3.cmml" xref="S3.E4.m1.1.1.3.4.2.3">jaw</mtext></ci></apply><apply id="S3.E4.m1.1.1.3.4.3.cmml" xref="S3.E4.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.4.3.1.cmml" xref="S3.E4.m1.1.1.3.4.3">superscript</csymbol><apply id="S3.E4.m1.1.1.3.4.3.2.cmml" xref="S3.E4.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.4.3.2.1.cmml" xref="S3.E4.m1.1.1.3.4.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.4.3.2.2.cmml" xref="S3.E4.m1.1.1.3.4.3.2.2">â„’</ci><ci id="S3.E4.m1.1.1.3.4.3.2.3a.cmml" xref="S3.E4.m1.1.1.3.4.3.2.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.4.3.2.3.cmml" xref="S3.E4.m1.1.1.3.4.3.2.3">rec</mtext></ci></apply><ci id="S3.E4.m1.1.1.3.4.3.3a.cmml" xref="S3.E4.m1.1.1.3.4.3.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.3.4.3.3.cmml" xref="S3.E4.m1.1.1.3.4.3.3">jaw</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\mathcal{L_{\text{stage1}}}=\lambda_{\text{qua}}\mathcal{L}_{\text{qua}}+\lambda_{\text{rec}}^{\text{exp}}\mathcal{L}_{\text{rec}}^{\text{exp}}+\lambda_{\text{rec}}^{\text{jaw}}\mathcal{L}_{\text{rec}}^{\text{jaw}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.SSS1.Px1.p4" class="ltx_para">
<p id="S3.SS3.SSS1.Px1.p4.3" class="ltx_p">The weights of the loss function in Eq.(<a href="#S3.E4" title="In Loss function â€£ 3.3.1. Stage 1: Motion Autoencoder â€£ 3.3. Proposed Model: ProbTalk3D â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) are empirically set as follows: <math id="S3.SS3.SSS1.Px1.p4.1.m1.1" class="ltx_Math" alttext="\lambda_{\text{qua}}=1.5" display="inline"><semantics id="S3.SS3.SSS1.Px1.p4.1.m1.1a"><mrow id="S3.SS3.SSS1.Px1.p4.1.m1.1.1" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.cmml"><msub id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.cmml"><mi id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.2" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.2.cmml">Î»</mi><mtext id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.3" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.3a.cmml">qua</mtext></msub><mo id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.1" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.3" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p4.1.m1.1b"><apply id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1"><eq id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.1"></eq><apply id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.1.cmml" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.2.cmml" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.2">ğœ†</ci><ci id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.3a.cmml" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.3"><mtext mathsize="70%" id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.3.cmml" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.2.3">qua</mtext></ci></apply><cn type="float" id="S3.SS3.SSS1.Px1.p4.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.Px1.p4.1.m1.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p4.1.m1.1c">\lambda_{\text{qua}}=1.5</annotation></semantics></math>, <math id="S3.SS3.SSS1.Px1.p4.2.m2.1" class="ltx_Math" alttext="\lambda_{\text{rec}}^{\text{exp}}=0.5" display="inline"><semantics id="S3.SS3.SSS1.Px1.p4.2.m2.1a"><mrow id="S3.SS3.SSS1.Px1.p4.2.m2.1.1" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.cmml"><msubsup id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.cmml"><mi id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.2" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.2.cmml">Î»</mi><mtext id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.3" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.3a.cmml">rec</mtext><mtext id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.3" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.3a.cmml">exp</mtext></msubsup><mo id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.1" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.3" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p4.2.m2.1b"><apply id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1"><eq id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.1"></eq><apply id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.1.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2">superscript</csymbol><apply id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.1.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.2.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.2">ğœ†</ci><ci id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.3a.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.3"><mtext mathsize="70%" id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.3.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.2.3">rec</mtext></ci></apply><ci id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.3a.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.3"><mtext mathsize="70%" id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.3.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.2.3">exp</mtext></ci></apply><cn type="float" id="S3.SS3.SSS1.Px1.p4.2.m2.1.1.3.cmml" xref="S3.SS3.SSS1.Px1.p4.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p4.2.m2.1c">\lambda_{\text{rec}}^{\text{exp}}=0.5</annotation></semantics></math>, and <math id="S3.SS3.SSS1.Px1.p4.3.m3.1" class="ltx_Math" alttext="\lambda_{\text{rec}}^{\text{jaw}}=0.1" display="inline"><semantics id="S3.SS3.SSS1.Px1.p4.3.m3.1a"><mrow id="S3.SS3.SSS1.Px1.p4.3.m3.1.1" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.cmml"><msubsup id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.cmml"><mi id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.2" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.2.cmml">Î»</mi><mtext id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.3" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.3a.cmml">rec</mtext><mtext id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.3" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.3a.cmml">jaw</mtext></msubsup><mo id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.1" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.3" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px1.p4.3.m3.1b"><apply id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1"><eq id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.1"></eq><apply id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.1.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2">superscript</csymbol><apply id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.1.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.2.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.2">ğœ†</ci><ci id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.3a.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.3"><mtext mathsize="70%" id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.3.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.2.3">rec</mtext></ci></apply><ci id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.3a.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.3"><mtext mathsize="70%" id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.3.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.2.3">jaw</mtext></ci></apply><cn type="float" id="S3.SS3.SSS1.Px1.p4.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.Px1.p4.3.m3.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px1.p4.3.m3.1c">\lambda_{\text{rec}}^{\text{jaw}}=0.1</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2. </span>Stage 2: Speech and Emotion Conditioned</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.3" class="ltx_p">After learning the motion prior in stage 1, speech and emotion conditioned stage 2 is trained which consists of an audio encoder that encodes the continuous raw audio/speech data into discrete hidden representations and fuses the speaking style (i.e. style embedding obtained using Style Vector, <math id="S3.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS3.SSS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.p1.1.m1.1.1" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.1b"><ci id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.1c">\mathcal{C}</annotation></semantics></math>) with the encoded audio information. As shown in Fig.<a href="#S3.F3" title="Figure 3 â€£ 3.2. Problem Formulation â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the Motion Autoencoder trained in stage 1 is kept frozen in this stage to train the Audio Encoder in a supervised manner so that the latent representation, <math id="S3.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="z^{a}" display="inline"><semantics id="S3.SS3.SSS2.p1.2.m2.1a"><msup id="S3.SS3.SSS2.p1.2.m2.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.cmml"><mi id="S3.SS3.SSS2.p1.2.m2.1.1.2" xref="S3.SS3.SSS2.p1.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS3.SSS2.p1.2.m2.1.1.3" xref="S3.SS3.SSS2.p1.2.m2.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.2.m2.1b"><apply id="S3.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.2.m2.1c">z^{a}</annotation></semantics></math> from the audio encoder closely resembles the latent representation, <math id="S3.SS3.SSS2.p1.3.m3.1" class="ltx_Math" alttext="z^{m}" display="inline"><semantics id="S3.SS3.SSS2.p1.3.m3.1a"><msup id="S3.SS3.SSS2.p1.3.m3.1.1" xref="S3.SS3.SSS2.p1.3.m3.1.1.cmml"><mi id="S3.SS3.SSS2.p1.3.m3.1.1.2" xref="S3.SS3.SSS2.p1.3.m3.1.1.2.cmml">z</mi><mi id="S3.SS3.SSS2.p1.3.m3.1.1.3" xref="S3.SS3.SSS2.p1.3.m3.1.1.3.cmml">m</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.3.m3.1b"><apply id="S3.SS3.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS2.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS2.p1.3.m3.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.3.m3.1c">z^{m}</annotation></semantics></math> from the frozen Motion Encoder.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2409.07966/assets/Assets/inference.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="538" height="124" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.16.8.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S3.F4.14.7" class="ltx_text" style="font-size:90%;">Inference: Given audio <math id="S3.F4.8.1.m1.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.F4.8.1.m1.1b"><mi id="S3.F4.8.1.m1.1.1" xref="S3.F4.8.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.F4.8.1.m1.1c"><ci id="S3.F4.8.1.m1.1.1.cmml" xref="S3.F4.8.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.8.1.m1.1d">a</annotation></semantics></math> and Style Vector <math id="S3.F4.9.2.m2.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.F4.9.2.m2.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F4.9.2.m2.1.1" xref="S3.F4.9.2.m2.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.F4.9.2.m2.1c"><ci id="S3.F4.9.2.m2.1.1.cmml" xref="S3.F4.9.2.m2.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.9.2.m2.1d">\mathcal{C}</annotation></semantics></math> (i.e. subject ID, emotion, intensity) as inputs, the audio encoder produces hidden representation <math id="S3.F4.10.3.m3.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.F4.10.3.m3.1b"><mi id="S3.F4.10.3.m3.1.1" xref="S3.F4.10.3.m3.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.F4.10.3.m3.1c"><ci id="S3.F4.10.3.m3.1.1.cmml" xref="S3.F4.10.3.m3.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.10.3.m3.1d">z</annotation></semantics></math> that undergoes the quantization process based on the learned codebook embeddings <math id="S3.F4.11.4.m4.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.F4.11.4.m4.1b"><mi id="S3.F4.11.4.m4.1.1" xref="S3.F4.11.4.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.F4.11.4.m4.1c"><ci id="S3.F4.11.4.m4.1.1.cmml" xref="S3.F4.11.4.m4.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.11.4.m4.1d">E</annotation></semantics></math> and probabilistically produces <math id="S3.F4.12.5.m5.1" class="ltx_Math" alttext="z^{\prime}" display="inline"><semantics id="S3.F4.12.5.m5.1b"><msup id="S3.F4.12.5.m5.1.1" xref="S3.F4.12.5.m5.1.1.cmml"><mi id="S3.F4.12.5.m5.1.1.2" xref="S3.F4.12.5.m5.1.1.2.cmml">z</mi><mo id="S3.F4.12.5.m5.1.1.3" xref="S3.F4.12.5.m5.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.F4.12.5.m5.1c"><apply id="S3.F4.12.5.m5.1.1.cmml" xref="S3.F4.12.5.m5.1.1"><csymbol cd="ambiguous" id="S3.F4.12.5.m5.1.1.1.cmml" xref="S3.F4.12.5.m5.1.1">superscript</csymbol><ci id="S3.F4.12.5.m5.1.1.2.cmml" xref="S3.F4.12.5.m5.1.1.2">ğ‘§</ci><ci id="S3.F4.12.5.m5.1.1.3.cmml" xref="S3.F4.12.5.m5.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.12.5.m5.1d">z^{\prime}</annotation></semantics></math>. The motion decoder then decodes <math id="S3.F4.13.6.m6.1" class="ltx_Math" alttext="z^{\prime}" display="inline"><semantics id="S3.F4.13.6.m6.1b"><msup id="S3.F4.13.6.m6.1.1" xref="S3.F4.13.6.m6.1.1.cmml"><mi id="S3.F4.13.6.m6.1.1.2" xref="S3.F4.13.6.m6.1.1.2.cmml">z</mi><mo id="S3.F4.13.6.m6.1.1.3" xref="S3.F4.13.6.m6.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.F4.13.6.m6.1c"><apply id="S3.F4.13.6.m6.1.1.cmml" xref="S3.F4.13.6.m6.1.1"><csymbol cd="ambiguous" id="S3.F4.13.6.m6.1.1.1.cmml" xref="S3.F4.13.6.m6.1.1">superscript</csymbol><ci id="S3.F4.13.6.m6.1.1.2.cmml" xref="S3.F4.13.6.m6.1.1.2">ğ‘§</ci><ci id="S3.F4.13.6.m6.1.1.3.cmml" xref="S3.F4.13.6.m6.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.13.6.m6.1d">z^{\prime}</annotation></semantics></math> into facial animation <math id="S3.F4.14.7.m7.1" class="ltx_Math" alttext="\hat{\mathcal{X}}" display="inline"><semantics id="S3.F4.14.7.m7.1b"><mover accent="true" id="S3.F4.14.7.m7.1.1" xref="S3.F4.14.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F4.14.7.m7.1.1.2" xref="S3.F4.14.7.m7.1.1.2.cmml">ğ’³</mi><mo id="S3.F4.14.7.m7.1.1.1" xref="S3.F4.14.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.F4.14.7.m7.1c"><apply id="S3.F4.14.7.m7.1.1.cmml" xref="S3.F4.14.7.m7.1.1"><ci id="S3.F4.14.7.m7.1.1.1.cmml" xref="S3.F4.14.7.m7.1.1.1">^</ci><ci id="S3.F4.14.7.m7.1.1.2.cmml" xref="S3.F4.14.7.m7.1.1.2">ğ’³</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.14.7.m7.1d">\hat{\mathcal{X}}</annotation></semantics></math>.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S3.F4.17" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.F4.18" class="ltx_p ltx_figure_panel ltx_align_center">ProbTalk3D inference figure.</p>
</div>
</div>
</figure>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.3" class="ltx_p">We employ pretrained HuBERT <cite class="ltx_cite ltx_citemacro_citep">(Hsu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite>, a transformer based speech recognition model in our audio encoder, and made appropriate modifications to apply it to our downstream task of facial animation synthesis following <cite class="ltx_cite ltx_citemacro_citep">(Haque and Yumak, <a href="#bib.bib24" title="" class="ltx_ref">2023</a>; Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>. After the last hidden layer of HuBERT, inspired by the aforementioned previous works, we adjust the input representation so it temporally aligns with the paired animation data and add a linear projection layer that projects the encoded hidden state into a 256-dimensional hidden state to be element-wisely multiplied with the Style Embedding. Style Embedding is obtained using a linear projection of concatenated one-hot vectors of the style annotations (subject ID, emotion, intensity). In our case, the style vector, <math id="S3.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS3.SSS2.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.p2.1.m1.1.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.1.m1.1b"><ci id="S3.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.1.m1.1c">\mathcal{C}</annotation></semantics></math> is a 43-dimensional vector (as we have 32 subjects, 8 basic emotions, and 3 emotion intensity categories) that is linearly transformed into a 256-dimensional Style Embedding to facilitate the fusion of audio and style information. After fusing the audio information and style information, we introduce a 1D convolutional layer followed by 12 transformer layers to get the latent representation <math id="S3.SS3.SSS2.p2.2.m2.1" class="ltx_Math" alttext="z^{a}" display="inline"><semantics id="S3.SS3.SSS2.p2.2.m2.1a"><msup id="S3.SS3.SSS2.p2.2.m2.1.1" xref="S3.SS3.SSS2.p2.2.m2.1.1.cmml"><mi id="S3.SS3.SSS2.p2.2.m2.1.1.2" xref="S3.SS3.SSS2.p2.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS3.SSS2.p2.2.m2.1.1.3" xref="S3.SS3.SSS2.p2.2.m2.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.2.m2.1b"><apply id="S3.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.2.m2.1c">z^{a}</annotation></semantics></math> that goes through the frozen motion decoder to obtain the predicted motion, <math id="S3.SS3.SSS2.p2.3.m3.1" class="ltx_Math" alttext="\hat{\mathcal{X}}" display="inline"><semantics id="S3.SS3.SSS2.p2.3.m3.1a"><mover accent="true" id="S3.SS3.SSS2.p2.3.m3.1.1" xref="S3.SS3.SSS2.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.p2.3.m3.1.1.2" xref="S3.SS3.SSS2.p2.3.m3.1.1.2.cmml">ğ’³</mi><mo id="S3.SS3.SSS2.p2.3.m3.1.1.1" xref="S3.SS3.SSS2.p2.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.3.m3.1b"><apply id="S3.SS3.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1"><ci id="S3.SS3.SSS2.p2.3.m3.1.1.1.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1.1">^</ci><ci id="S3.SS3.SSS2.p2.3.m3.1.1.2.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1.2">ğ’³</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.3.m3.1c">\hat{\mathcal{X}}</annotation></semantics></math>.</p>
</div>
<section id="S3.SS3.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Loss function</h5>

<div id="S3.SS3.SSS2.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS2.Px1.p1.7" class="ltx_p">The goal in stage 2 training is to get audio latent <math id="S3.SS3.SSS2.Px1.p1.1.m1.1" class="ltx_Math" alttext="z^{a}" display="inline"><semantics id="S3.SS3.SSS2.Px1.p1.1.m1.1a"><msup id="S3.SS3.SSS2.Px1.p1.1.m1.1.1" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS3.SSS2.Px1.p1.1.m1.1.1.2" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1.2.cmml">z</mi><mi id="S3.SS3.SSS2.Px1.p1.1.m1.1.1.3" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.1.m1.1b"><apply id="S3.SS3.SSS2.Px1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS2.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS2.Px1.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.1.m1.1c">z^{a}</annotation></semantics></math> such that it is as close as possible to the motion latent, <math id="S3.SS3.SSS2.Px1.p1.2.m2.1" class="ltx_Math" alttext="z^{m}" display="inline"><semantics id="S3.SS3.SSS2.Px1.p1.2.m2.1a"><msup id="S3.SS3.SSS2.Px1.p1.2.m2.1.1" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS3.SSS2.Px1.p1.2.m2.1.1.2" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS3.SSS2.Px1.p1.2.m2.1.1.3" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1.3.cmml">m</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.2.m2.1b"><apply id="S3.SS3.SSS2.Px1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS2.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS2.Px1.p1.2.m2.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.2.m2.1c">z^{m}</annotation></semantics></math>. Therefore, we construct <math id="S3.SS3.SSS2.Px1.p1.3.m3.2" class="ltx_Math" alttext="\mathcal{L}_{lat}=\mathcal{L}_{1}(z^{m},z^{a})" display="inline"><semantics id="S3.SS3.SSS2.Px1.p1.3.m3.2a"><mrow id="S3.SS3.SSS2.Px1.p1.3.m3.2.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.cmml"><msub id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.2.cmml">â„’</mi><mrow id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.cmml"><mi id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.1" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.3" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.1a" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.4" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.3" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.3.cmml">=</mo><mrow id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.cmml"><msub id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.2.cmml">â„’</mi><mn id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.3" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.3" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.3.cmml">â€‹</mo><mrow id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.3" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.3.cmml">(</mo><msup id="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.cmml"><mi id="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.3" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.3.cmml">m</mi></msup><mo id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.4" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.3.cmml">,</mo><msup id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.cmml"><mi id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.2" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.2.cmml">z</mi><mi id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.3" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.3.cmml">a</mi></msup><mo stretchy="false" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.5" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.3.m3.2b"><apply id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2"><eq id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.3"></eq><apply id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.1.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4">subscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.2.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.2">â„’</ci><apply id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3"><times id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.1.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.1"></times><ci id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.2.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.2">ğ‘™</ci><ci id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.3.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.3">ğ‘</ci><ci id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.4.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.4.3.4">ğ‘¡</ci></apply></apply><apply id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2"><times id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.3"></times><apply id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.1.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4">subscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.2.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.2">â„’</ci><cn type="integer" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.3.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.4.3">1</cn></apply><interval closure="open" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2"><apply id="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.1.1.1.1.1.1.3">ğ‘š</ci></apply><apply id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.1.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2">superscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.2">ğ‘§</ci><ci id="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.3.m3.2.2.2.2.2.2.3">ğ‘</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.3.m3.2c">\mathcal{L}_{lat}=\mathcal{L}_{1}(z^{m},z^{a})</annotation></semantics></math> that computes the <math id="S3.SS3.SSS2.Px1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{L}_{1}" display="inline"><semantics id="S3.SS3.SSS2.Px1.p1.4.m4.1a"><msub id="S3.SS3.SSS2.Px1.p1.4.m4.1.1" xref="S3.SS3.SSS2.Px1.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.Px1.p1.4.m4.1.1.2" xref="S3.SS3.SSS2.Px1.p1.4.m4.1.1.2.cmml">â„’</mi><mn id="S3.SS3.SSS2.Px1.p1.4.m4.1.1.3" xref="S3.SS3.SSS2.Px1.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.4.m4.1b"><apply id="S3.SS3.SSS2.Px1.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p1.4.m4.1.1.2">â„’</ci><cn type="integer" id="S3.SS3.SSS2.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS3.SSS2.Px1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.4.m4.1c">\mathcal{L}_{1}</annotation></semantics></math> loss between the latent representations. Additionally, we further add the reconstruction losses. The overall loss function is then defined in Eq.(<a href="#S3.E5" title="In Loss function â€£ 3.3.2. Stage 2: Speech and Emotion Conditioned â€£ 3.3. Proposed Model: ProbTalk3D â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). The loss weights set for training are <math id="S3.SS3.SSS2.Px1.p1.5.m5.1" class="ltx_Math" alttext="\lambda_{\text{lat}}=1" display="inline"><semantics id="S3.SS3.SSS2.Px1.p1.5.m5.1a"><mrow id="S3.SS3.SSS2.Px1.p1.5.m5.1.1" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.cmml"><msub id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.2" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.2.cmml">Î»</mi><mtext id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.3" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.3a.cmml">lat</mtext></msub><mo id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.1" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.3" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.5.m5.1b"><apply id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1"><eq id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.1"></eq><apply id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.2">ğœ†</ci><ci id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.3a.cmml" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.3"><mtext mathsize="70%" id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.2.3">lat</mtext></ci></apply><cn type="integer" id="S3.SS3.SSS2.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS3.SSS2.Px1.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.5.m5.1c">\lambda_{\text{lat}}=1</annotation></semantics></math>, <math id="S3.SS3.SSS2.Px1.p1.6.m6.1" class="ltx_Math" alttext="\lambda_{\text{rec}}^{\text{exp}}=0.15" display="inline"><semantics id="S3.SS3.SSS2.Px1.p1.6.m6.1a"><mrow id="S3.SS3.SSS2.Px1.p1.6.m6.1.1" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.cmml"><msubsup id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.cmml"><mi id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.2" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.2.cmml">Î»</mi><mtext id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.3" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.3a.cmml">rec</mtext><mtext id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.3" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.3a.cmml">exp</mtext></msubsup><mo id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.1" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.3" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.3.cmml">0.15</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.6.m6.1b"><apply id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1"><eq id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.1"></eq><apply id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.1.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2">superscript</csymbol><apply id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.1.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.2">ğœ†</ci><ci id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.3a.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.3"><mtext mathsize="70%" id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.2.3">rec</mtext></ci></apply><ci id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.3a.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.3"><mtext mathsize="70%" id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.2.3">exp</mtext></ci></apply><cn type="float" id="S3.SS3.SSS2.Px1.p1.6.m6.1.1.3.cmml" xref="S3.SS3.SSS2.Px1.p1.6.m6.1.1.3">0.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.6.m6.1c">\lambda_{\text{rec}}^{\text{exp}}=0.15</annotation></semantics></math>, and <math id="S3.SS3.SSS2.Px1.p1.7.m7.1" class="ltx_Math" alttext="\lambda_{\text{rec}}^{\text{jaw}}=0.1" display="inline"><semantics id="S3.SS3.SSS2.Px1.p1.7.m7.1a"><mrow id="S3.SS3.SSS2.Px1.p1.7.m7.1.1" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.cmml"><msubsup id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.cmml"><mi id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.2" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.2.cmml">Î»</mi><mtext id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.3" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.3a.cmml">rec</mtext><mtext id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.3" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.3a.cmml">jaw</mtext></msubsup><mo id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.1" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.3" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.Px1.p1.7.m7.1b"><apply id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1"><eq id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.1.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.1"></eq><apply id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.1.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2">superscript</csymbol><apply id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.1.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.2.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.2">ğœ†</ci><ci id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.3a.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.3"><mtext mathsize="70%" id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.2.3">rec</mtext></ci></apply><ci id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.3a.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.3"><mtext mathsize="70%" id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.3.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.2.3">jaw</mtext></ci></apply><cn type="float" id="S3.SS3.SSS2.Px1.p1.7.m7.1.1.3.cmml" xref="S3.SS3.SSS2.Px1.p1.7.m7.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.Px1.p1.7.m7.1c">\lambda_{\text{rec}}^{\text{jaw}}=0.1</annotation></semantics></math>.</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="\mathcal{L_{\text{stage2}}}=\lambda_{\text{lat}}\mathcal{L}_{\text{lat}}+\lambda_{\text{rec}}^{\text{exp}}\mathcal{L}_{\text{rec}}^{\text{exp}}+\lambda_{\text{rec}}^{\text{jaw}}\mathcal{L}_{\text{rec}}^{\text{jaw}}" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><msub id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1.2.2" xref="S3.E5.m1.1.1.2.2.cmml">â„’</mi><mtext id="S3.E5.m1.1.1.2.3" xref="S3.E5.m1.1.1.2.3a.cmml">stage2</mtext></msub><mo id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml"><mrow id="S3.E5.m1.1.1.3.2" xref="S3.E5.m1.1.1.3.2.cmml"><msub id="S3.E5.m1.1.1.3.2.2" xref="S3.E5.m1.1.1.3.2.2.cmml"><mi id="S3.E5.m1.1.1.3.2.2.2" xref="S3.E5.m1.1.1.3.2.2.2.cmml">Î»</mi><mtext id="S3.E5.m1.1.1.3.2.2.3" xref="S3.E5.m1.1.1.3.2.2.3a.cmml">lat</mtext></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.1" xref="S3.E5.m1.1.1.3.2.1.cmml">â€‹</mo><msub id="S3.E5.m1.1.1.3.2.3" xref="S3.E5.m1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1.3.2.3.2" xref="S3.E5.m1.1.1.3.2.3.2.cmml">â„’</mi><mtext id="S3.E5.m1.1.1.3.2.3.3" xref="S3.E5.m1.1.1.3.2.3.3a.cmml">lat</mtext></msub></mrow><mo id="S3.E5.m1.1.1.3.1" xref="S3.E5.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E5.m1.1.1.3.3" xref="S3.E5.m1.1.1.3.3.cmml"><msubsup id="S3.E5.m1.1.1.3.3.2" xref="S3.E5.m1.1.1.3.3.2.cmml"><mi id="S3.E5.m1.1.1.3.3.2.2.2" xref="S3.E5.m1.1.1.3.3.2.2.2.cmml">Î»</mi><mtext id="S3.E5.m1.1.1.3.3.2.2.3" xref="S3.E5.m1.1.1.3.3.2.2.3a.cmml">rec</mtext><mtext id="S3.E5.m1.1.1.3.3.2.3" xref="S3.E5.m1.1.1.3.3.2.3a.cmml">exp</mtext></msubsup><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.1" xref="S3.E5.m1.1.1.3.3.1.cmml">â€‹</mo><msubsup id="S3.E5.m1.1.1.3.3.3" xref="S3.E5.m1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1.3.3.3.2.2" xref="S3.E5.m1.1.1.3.3.3.2.2.cmml">â„’</mi><mtext id="S3.E5.m1.1.1.3.3.3.2.3" xref="S3.E5.m1.1.1.3.3.3.2.3a.cmml">rec</mtext><mtext id="S3.E5.m1.1.1.3.3.3.3" xref="S3.E5.m1.1.1.3.3.3.3a.cmml">exp</mtext></msubsup></mrow><mo id="S3.E5.m1.1.1.3.1a" xref="S3.E5.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E5.m1.1.1.3.4" xref="S3.E5.m1.1.1.3.4.cmml"><msubsup id="S3.E5.m1.1.1.3.4.2" xref="S3.E5.m1.1.1.3.4.2.cmml"><mi id="S3.E5.m1.1.1.3.4.2.2.2" xref="S3.E5.m1.1.1.3.4.2.2.2.cmml">Î»</mi><mtext id="S3.E5.m1.1.1.3.4.2.2.3" xref="S3.E5.m1.1.1.3.4.2.2.3a.cmml">rec</mtext><mtext id="S3.E5.m1.1.1.3.4.2.3" xref="S3.E5.m1.1.1.3.4.2.3a.cmml">jaw</mtext></msubsup><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.4.1" xref="S3.E5.m1.1.1.3.4.1.cmml">â€‹</mo><msubsup id="S3.E5.m1.1.1.3.4.3" xref="S3.E5.m1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1.3.4.3.2.2" xref="S3.E5.m1.1.1.3.4.3.2.2.cmml">â„’</mi><mtext id="S3.E5.m1.1.1.3.4.3.2.3" xref="S3.E5.m1.1.1.3.4.3.2.3a.cmml">rec</mtext><mtext id="S3.E5.m1.1.1.3.4.3.3" xref="S3.E5.m1.1.1.3.4.3.3a.cmml">jaw</mtext></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"></eq><apply id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.2.2">â„’</ci><ci id="S3.E5.m1.1.1.2.3a.cmml" xref="S3.E5.m1.1.1.2.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.2.3">stage2</mtext></ci></apply><apply id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"><plus id="S3.E5.m1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.3.1"></plus><apply id="S3.E5.m1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.3.2"><times id="S3.E5.m1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.3.2.1"></times><apply id="S3.E5.m1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.2.1.cmml" xref="S3.E5.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2.2">ğœ†</ci><ci id="S3.E5.m1.1.1.3.2.2.3a.cmml" xref="S3.E5.m1.1.1.3.2.2.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.2.2.3.cmml" xref="S3.E5.m1.1.1.3.2.2.3">lat</mtext></ci></apply><apply id="S3.E5.m1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.3.1.cmml" xref="S3.E5.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.3.2.cmml" xref="S3.E5.m1.1.1.3.2.3.2">â„’</ci><ci id="S3.E5.m1.1.1.3.2.3.3a.cmml" xref="S3.E5.m1.1.1.3.2.3.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.2.3.3.cmml" xref="S3.E5.m1.1.1.3.2.3.3">lat</mtext></ci></apply></apply><apply id="S3.E5.m1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.3.3"><times id="S3.E5.m1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3.1"></times><apply id="S3.E5.m1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.2.1.cmml" xref="S3.E5.m1.1.1.3.3.2">superscript</csymbol><apply id="S3.E5.m1.1.1.3.3.2.2.cmml" xref="S3.E5.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.2.2.1.cmml" xref="S3.E5.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.3.3.2.2.2.cmml" xref="S3.E5.m1.1.1.3.3.2.2.2">ğœ†</ci><ci id="S3.E5.m1.1.1.3.3.2.2.3a.cmml" xref="S3.E5.m1.1.1.3.3.2.2.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.3.2.2.3.cmml" xref="S3.E5.m1.1.1.3.3.2.2.3">rec</mtext></ci></apply><ci id="S3.E5.m1.1.1.3.3.2.3a.cmml" xref="S3.E5.m1.1.1.3.3.2.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.3.2.3.cmml" xref="S3.E5.m1.1.1.3.3.2.3">exp</mtext></ci></apply><apply id="S3.E5.m1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3.3">superscript</csymbol><apply id="S3.E5.m1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.3.2.1.cmml" xref="S3.E5.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.3.3.2.2.cmml" xref="S3.E5.m1.1.1.3.3.3.2.2">â„’</ci><ci id="S3.E5.m1.1.1.3.3.3.2.3a.cmml" xref="S3.E5.m1.1.1.3.3.3.2.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.3.3.2.3.cmml" xref="S3.E5.m1.1.1.3.3.3.2.3">rec</mtext></ci></apply><ci id="S3.E5.m1.1.1.3.3.3.3a.cmml" xref="S3.E5.m1.1.1.3.3.3.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3.3">exp</mtext></ci></apply></apply><apply id="S3.E5.m1.1.1.3.4.cmml" xref="S3.E5.m1.1.1.3.4"><times id="S3.E5.m1.1.1.3.4.1.cmml" xref="S3.E5.m1.1.1.3.4.1"></times><apply id="S3.E5.m1.1.1.3.4.2.cmml" xref="S3.E5.m1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.4.2.1.cmml" xref="S3.E5.m1.1.1.3.4.2">superscript</csymbol><apply id="S3.E5.m1.1.1.3.4.2.2.cmml" xref="S3.E5.m1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.4.2.2.1.cmml" xref="S3.E5.m1.1.1.3.4.2">subscript</csymbol><ci id="S3.E5.m1.1.1.3.4.2.2.2.cmml" xref="S3.E5.m1.1.1.3.4.2.2.2">ğœ†</ci><ci id="S3.E5.m1.1.1.3.4.2.2.3a.cmml" xref="S3.E5.m1.1.1.3.4.2.2.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.4.2.2.3.cmml" xref="S3.E5.m1.1.1.3.4.2.2.3">rec</mtext></ci></apply><ci id="S3.E5.m1.1.1.3.4.2.3a.cmml" xref="S3.E5.m1.1.1.3.4.2.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.4.2.3.cmml" xref="S3.E5.m1.1.1.3.4.2.3">jaw</mtext></ci></apply><apply id="S3.E5.m1.1.1.3.4.3.cmml" xref="S3.E5.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.4.3.1.cmml" xref="S3.E5.m1.1.1.3.4.3">superscript</csymbol><apply id="S3.E5.m1.1.1.3.4.3.2.cmml" xref="S3.E5.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.4.3.2.1.cmml" xref="S3.E5.m1.1.1.3.4.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.4.3.2.2.cmml" xref="S3.E5.m1.1.1.3.4.3.2.2">â„’</ci><ci id="S3.E5.m1.1.1.3.4.3.2.3a.cmml" xref="S3.E5.m1.1.1.3.4.3.2.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.4.3.2.3.cmml" xref="S3.E5.m1.1.1.3.4.3.2.3">rec</mtext></ci></apply><ci id="S3.E5.m1.1.1.3.4.3.3a.cmml" xref="S3.E5.m1.1.1.3.4.3.3"><mtext mathsize="70%" id="S3.E5.m1.1.1.3.4.3.3.cmml" xref="S3.E5.m1.1.1.3.4.3.3">jaw</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\mathcal{L_{\text{stage2}}}=\lambda_{\text{lat}}\mathcal{L}_{\text{lat}}+\lambda_{\text{rec}}^{\text{exp}}\mathcal{L}_{\text{rec}}^{\text{exp}}+\lambda_{\text{rec}}^{\text{jaw}}\mathcal{L}_{\text{rec}}^{\text{jaw}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3. </span>Inference</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.5" class="ltx_p">During inference on unseen audio sequences, the <span id="S3.SS3.SSS3.p1.5.1" class="ltx_text ltx_font_italic">Motion Encoder</span> in the Motion Autoencoder is not used as there is no ground truth motion to encode. The trained Audio Encoder in our model maps input audio to the latent representation <math id="S3.SS3.SSS3.p1.1.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS3.SSS3.p1.1.m1.1a"><mi id="S3.SS3.SSS3.p1.1.m1.1.1" xref="S3.SS3.SSS3.p1.1.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p1.1.m1.1b"><ci id="S3.SS3.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS3.p1.1.m1.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p1.1.m1.1c">z</annotation></semantics></math>. Subsequently, the quantization process extracts an embedding from the learned codebook <math id="S3.SS3.SSS3.p1.2.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS3.SSS3.p1.2.m2.1a"><mi id="S3.SS3.SSS3.p1.2.m2.1.1" xref="S3.SS3.SSS3.p1.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p1.2.m2.1b"><ci id="S3.SS3.SSS3.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS3.p1.2.m2.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p1.2.m2.1c">E</annotation></semantics></math>, yielding <math id="S3.SS3.SSS3.p1.3.m3.1" class="ltx_Math" alttext="z^{\prime}" display="inline"><semantics id="S3.SS3.SSS3.p1.3.m3.1a"><msup id="S3.SS3.SSS3.p1.3.m3.1.1" xref="S3.SS3.SSS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.SSS3.p1.3.m3.1.1.2" xref="S3.SS3.SSS3.p1.3.m3.1.1.2.cmml">z</mi><mo id="S3.SS3.SSS3.p1.3.m3.1.1.3" xref="S3.SS3.SSS3.p1.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p1.3.m3.1b"><apply id="S3.SS3.SSS3.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS3.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.SSS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS3.p1.3.m3.1.1.2">ğ‘§</ci><ci id="S3.SS3.SSS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS3.p1.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p1.3.m3.1c">z^{\prime}</annotation></semantics></math>, which is then passed to the decoder of the Motion Autoencoder to synthesize facial animation, <math id="S3.SS3.SSS3.p1.4.m4.1" class="ltx_Math" alttext="\hat{\mathcal{X}}" display="inline"><semantics id="S3.SS3.SSS3.p1.4.m4.1a"><mover accent="true" id="S3.SS3.SSS3.p1.4.m4.1.1" xref="S3.SS3.SSS3.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS3.p1.4.m4.1.1.2" xref="S3.SS3.SSS3.p1.4.m4.1.1.2.cmml">ğ’³</mi><mo id="S3.SS3.SSS3.p1.4.m4.1.1.1" xref="S3.SS3.SSS3.p1.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p1.4.m4.1b"><apply id="S3.SS3.SSS3.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS3.p1.4.m4.1.1"><ci id="S3.SS3.SSS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.SSS3.p1.4.m4.1.1.1">^</ci><ci id="S3.SS3.SSS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.SSS3.p1.4.m4.1.1.2">ğ’³</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p1.4.m4.1c">\hat{\mathcal{X}}</annotation></semantics></math>. Style <math id="S3.SS3.SSS3.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S3.SS3.SSS3.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS3.p1.5.m5.1.1" xref="S3.SS3.SSS3.p1.5.m5.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p1.5.m5.1b"><ci id="S3.SS3.SSS3.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS3.p1.5.m5.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p1.5.m5.1c">\mathcal{C}</annotation></semantics></math> can be specified to generate a particular subjectâ€™s speaking style with specific emotion class and emotion intensity. The inference process is illustrated in Fig.<a href="#S3.F4" title="Figure 4 â€£ 3.3.2. Stage 2: Speech and Emotion Conditioned â€£ 3.3. Proposed Model: ProbTalk3D â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. During training iterations, our model is optimized to retrieve the closest learned codebook embedding index. We introduce non-deterministic output generation by incorporating a probabilistic sampling process for the codebook embedding index retrieval in the quantization step.</p>
</div>
</section>
<section id="S3.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4. </span>Training Details</h4>

<div id="S3.SS3.SSS4.p1" class="ltx_para">
<p id="S3.SS3.SSS4.p1.4" class="ltx_p">Our proposed model is implemented using the PyTorch Lightning <cite class="ltx_cite ltx_citemacro_citep">(Falcon and The PyTorch Lightning team, <a href="#bib.bib18" title="" class="ltx_ref">2019</a>)</cite> framework and trained on a single NVIDIA A16 GPU. During stage-1 training of the Motion Autoencoder, we use the AdamW optimizer while the Adam optimizer is used in stage 2. We empirically choose the learning rate to be <math id="S3.SS3.SSS4.p1.1.m1.1" class="ltx_Math" alttext="1e^{-4}" display="inline"><semantics id="S3.SS3.SSS4.p1.1.m1.1a"><mrow id="S3.SS3.SSS4.p1.1.m1.1.1" xref="S3.SS3.SSS4.p1.1.m1.1.1.cmml"><mn id="S3.SS3.SSS4.p1.1.m1.1.1.2" xref="S3.SS3.SSS4.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS3.SSS4.p1.1.m1.1.1.1" xref="S3.SS3.SSS4.p1.1.m1.1.1.1.cmml">â€‹</mo><msup id="S3.SS3.SSS4.p1.1.m1.1.1.3" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS4.p1.1.m1.1.1.3.2" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="S3.SS3.SSS4.p1.1.m1.1.1.3.3" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.3.cmml"><mo id="S3.SS3.SSS4.p1.1.m1.1.1.3.3a" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S3.SS3.SSS4.p1.1.m1.1.1.3.3.2" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS4.p1.1.m1.1b"><apply id="S3.SS3.SSS4.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1"><times id="S3.SS3.SSS4.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.SSS4.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.2">1</cn><apply id="S3.SS3.SSS4.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS4.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS4.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.2">ğ‘’</ci><apply id="S3.SS3.SSS4.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.3"><minus id="S3.SS3.SSS4.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S3.SS3.SSS4.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS4.p1.1.m1.1c">1e^{-4}</annotation></semantics></math> and <math id="S3.SS3.SSS4.p1.2.m2.1" class="ltx_Math" alttext="1e^{-5}" display="inline"><semantics id="S3.SS3.SSS4.p1.2.m2.1a"><mrow id="S3.SS3.SSS4.p1.2.m2.1.1" xref="S3.SS3.SSS4.p1.2.m2.1.1.cmml"><mn id="S3.SS3.SSS4.p1.2.m2.1.1.2" xref="S3.SS3.SSS4.p1.2.m2.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS3.SSS4.p1.2.m2.1.1.1" xref="S3.SS3.SSS4.p1.2.m2.1.1.1.cmml">â€‹</mo><msup id="S3.SS3.SSS4.p1.2.m2.1.1.3" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.SSS4.p1.2.m2.1.1.3.2" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.2.cmml">e</mi><mrow id="S3.SS3.SSS4.p1.2.m2.1.1.3.3" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.3.cmml"><mo id="S3.SS3.SSS4.p1.2.m2.1.1.3.3a" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.3.cmml">âˆ’</mo><mn id="S3.SS3.SSS4.p1.2.m2.1.1.3.3.2" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS4.p1.2.m2.1b"><apply id="S3.SS3.SSS4.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1"><times id="S3.SS3.SSS4.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.1"></times><cn type="integer" id="S3.SS3.SSS4.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.2">1</cn><apply id="S3.SS3.SSS4.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS4.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS4.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.2">ğ‘’</ci><apply id="S3.SS3.SSS4.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.3"><minus id="S3.SS3.SSS4.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.3"></minus><cn type="integer" id="S3.SS3.SSS4.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS4.p1.2.m2.1c">1e^{-5}</annotation></semantics></math> for stage 1 and stage 2 respectively while we monitor the validation loss by employing an early stopping technique to mitigate overfitting in both stages. More specifically, if the validation loss does not improve in the next 5 epochs, we stop the training and save the model weights from the final epoch. For our proposed model, stage 1 converges after training for 21 epochs (<math id="S3.SS3.SSS4.p1.3.m3.1" class="ltx_Math" alttext="\approx 6.5" display="inline"><semantics id="S3.SS3.SSS4.p1.3.m3.1a"><mrow id="S3.SS3.SSS4.p1.3.m3.1.1" xref="S3.SS3.SSS4.p1.3.m3.1.1.cmml"><mi id="S3.SS3.SSS4.p1.3.m3.1.1.2" xref="S3.SS3.SSS4.p1.3.m3.1.1.2.cmml"></mi><mo id="S3.SS3.SSS4.p1.3.m3.1.1.1" xref="S3.SS3.SSS4.p1.3.m3.1.1.1.cmml">â‰ˆ</mo><mn id="S3.SS3.SSS4.p1.3.m3.1.1.3" xref="S3.SS3.SSS4.p1.3.m3.1.1.3.cmml">6.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS4.p1.3.m3.1b"><apply id="S3.SS3.SSS4.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS4.p1.3.m3.1.1"><approx id="S3.SS3.SSS4.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS4.p1.3.m3.1.1.1"></approx><csymbol cd="latexml" id="S3.SS3.SSS4.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS4.p1.3.m3.1.1.2">absent</csymbol><cn type="float" id="S3.SS3.SSS4.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS4.p1.3.m3.1.1.3">6.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS4.p1.3.m3.1c">\approx 6.5</annotation></semantics></math> hours) while stage 2 after 48 epochs (<math id="S3.SS3.SSS4.p1.4.m4.1" class="ltx_Math" alttext="\approx 42" display="inline"><semantics id="S3.SS3.SSS4.p1.4.m4.1a"><mrow id="S3.SS3.SSS4.p1.4.m4.1.1" xref="S3.SS3.SSS4.p1.4.m4.1.1.cmml"><mi id="S3.SS3.SSS4.p1.4.m4.1.1.2" xref="S3.SS3.SSS4.p1.4.m4.1.1.2.cmml"></mi><mo id="S3.SS3.SSS4.p1.4.m4.1.1.1" xref="S3.SS3.SSS4.p1.4.m4.1.1.1.cmml">â‰ˆ</mo><mn id="S3.SS3.SSS4.p1.4.m4.1.1.3" xref="S3.SS3.SSS4.p1.4.m4.1.1.3.cmml">42</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS4.p1.4.m4.1b"><apply id="S3.SS3.SSS4.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS4.p1.4.m4.1.1"><approx id="S3.SS3.SSS4.p1.4.m4.1.1.1.cmml" xref="S3.SS3.SSS4.p1.4.m4.1.1.1"></approx><csymbol cd="latexml" id="S3.SS3.SSS4.p1.4.m4.1.1.2.cmml" xref="S3.SS3.SSS4.p1.4.m4.1.1.2">absent</csymbol><cn type="integer" id="S3.SS3.SSS4.p1.4.m4.1.1.3.cmml" xref="S3.SS3.SSS4.p1.4.m4.1.1.3">42</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS4.p1.4.m4.1c">\approx 42</annotation></semantics></math> hours).</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Comparison Model: VAE Based</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.3" class="ltx_p">In order to compare our model with a VAE-based model, we trained a variant of ProbTalk3D by replacing the VQ-VAE structure with a VAE keeping the rest of the architecture the same, ensuring a fair comparison between VAE and VQ-VAE based models. Unlike VQ-VAE which learns a discrete codebook embedding in stage 1 training, VAE learns the mean, <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">Î¼</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">ğœ‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\mu</annotation></semantics></math> and covariance matrix <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mi mathvariant="normal" id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><ci id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">\Sigma</annotation></semantics></math> of the latent space so that it follows a normal distribution <math id="S3.SS4.p1.3.m3.2" class="ltx_Math" alttext="\phi=\mathcal{N}(\mu,\Sigma)" display="inline"><semantics id="S3.SS4.p1.3.m3.2a"><mrow id="S3.SS4.p1.3.m3.2.3" xref="S3.SS4.p1.3.m3.2.3.cmml"><mi id="S3.SS4.p1.3.m3.2.3.2" xref="S3.SS4.p1.3.m3.2.3.2.cmml">Ï•</mi><mo id="S3.SS4.p1.3.m3.2.3.1" xref="S3.SS4.p1.3.m3.2.3.1.cmml">=</mo><mrow id="S3.SS4.p1.3.m3.2.3.3" xref="S3.SS4.p1.3.m3.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.3.m3.2.3.3.2" xref="S3.SS4.p1.3.m3.2.3.3.2.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.3.m3.2.3.3.1" xref="S3.SS4.p1.3.m3.2.3.3.1.cmml">â€‹</mo><mrow id="S3.SS4.p1.3.m3.2.3.3.3.2" xref="S3.SS4.p1.3.m3.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.SS4.p1.3.m3.2.3.3.3.2.1" xref="S3.SS4.p1.3.m3.2.3.3.3.1.cmml">(</mo><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">Î¼</mi><mo id="S3.SS4.p1.3.m3.2.3.3.3.2.2" xref="S3.SS4.p1.3.m3.2.3.3.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS4.p1.3.m3.2.2" xref="S3.SS4.p1.3.m3.2.2.cmml">Î£</mi><mo stretchy="false" id="S3.SS4.p1.3.m3.2.3.3.3.2.3" xref="S3.SS4.p1.3.m3.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.2b"><apply id="S3.SS4.p1.3.m3.2.3.cmml" xref="S3.SS4.p1.3.m3.2.3"><eq id="S3.SS4.p1.3.m3.2.3.1.cmml" xref="S3.SS4.p1.3.m3.2.3.1"></eq><ci id="S3.SS4.p1.3.m3.2.3.2.cmml" xref="S3.SS4.p1.3.m3.2.3.2">italic-Ï•</ci><apply id="S3.SS4.p1.3.m3.2.3.3.cmml" xref="S3.SS4.p1.3.m3.2.3.3"><times id="S3.SS4.p1.3.m3.2.3.3.1.cmml" xref="S3.SS4.p1.3.m3.2.3.3.1"></times><ci id="S3.SS4.p1.3.m3.2.3.3.2.cmml" xref="S3.SS4.p1.3.m3.2.3.3.2">ğ’©</ci><interval closure="open" id="S3.SS4.p1.3.m3.2.3.3.3.1.cmml" xref="S3.SS4.p1.3.m3.2.3.3.3.2"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">ğœ‡</ci><ci id="S3.SS4.p1.3.m3.2.2.cmml" xref="S3.SS4.p1.3.m3.2.2">Î£</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.2c">\phi=\mathcal{N}(\mu,\Sigma)</annotation></semantics></math>.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.7" class="ltx_p">Similar to ProbTalk3D, this model learns the motion prior and in stage 2 the learned mean <math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><mi id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml">Î¼</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><ci id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">ğœ‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">\mu</annotation></semantics></math> and covariance matrix <math id="S3.SS4.p2.2.m2.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS4.p2.2.m2.1a"><mi mathvariant="normal" id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><ci id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">\Sigma</annotation></semantics></math> are used and reparameterized for decoding audio and style conditioned facial animation. We use a similar loss function to our proposed model, replacing only the quantization loss term, <math id="S3.SS4.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{qua}" display="inline"><semantics id="S3.SS4.p2.3.m3.1a"><msub id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.3.m3.1.1.2" xref="S3.SS4.p2.3.m3.1.1.2.cmml">â„’</mi><mrow id="S3.SS4.p2.3.m3.1.1.3" xref="S3.SS4.p2.3.m3.1.1.3.cmml"><mi id="S3.SS4.p2.3.m3.1.1.3.2" xref="S3.SS4.p2.3.m3.1.1.3.2.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.3.m3.1.1.3.1" xref="S3.SS4.p2.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.3.m3.1.1.3.3" xref="S3.SS4.p2.3.m3.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.3.m3.1.1.3.1a" xref="S3.SS4.p2.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.3.m3.1.1.3.4" xref="S3.SS4.p2.3.m3.1.1.3.4.cmml">a</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><apply id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.3.m3.1.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p2.3.m3.1.1.2.cmml" xref="S3.SS4.p2.3.m3.1.1.2">â„’</ci><apply id="S3.SS4.p2.3.m3.1.1.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3"><times id="S3.SS4.p2.3.m3.1.1.3.1.cmml" xref="S3.SS4.p2.3.m3.1.1.3.1"></times><ci id="S3.SS4.p2.3.m3.1.1.3.2.cmml" xref="S3.SS4.p2.3.m3.1.1.3.2">ğ‘</ci><ci id="S3.SS4.p2.3.m3.1.1.3.3.cmml" xref="S3.SS4.p2.3.m3.1.1.3.3">ğ‘¢</ci><ci id="S3.SS4.p2.3.m3.1.1.3.4.cmml" xref="S3.SS4.p2.3.m3.1.1.3.4">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">\mathcal{L}_{qua}</annotation></semantics></math> in Eq.(<a href="#S3.E4" title="In Loss function â€£ 3.3.1. Stage 1: Motion Autoencoder â€£ 3.3. Proposed Model: ProbTalk3D â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) with a Kullback-Leibler (KL) Divergence loss, <math id="S3.SS4.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{L}_{KL}" display="inline"><semantics id="S3.SS4.p2.4.m4.1a"><msub id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p2.4.m4.1.1.2" xref="S3.SS4.p2.4.m4.1.1.2.cmml">â„’</mi><mrow id="S3.SS4.p2.4.m4.1.1.3" xref="S3.SS4.p2.4.m4.1.1.3.cmml"><mi id="S3.SS4.p2.4.m4.1.1.3.2" xref="S3.SS4.p2.4.m4.1.1.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.4.m4.1.1.3.1" xref="S3.SS4.p2.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.4.m4.1.1.3.3" xref="S3.SS4.p2.4.m4.1.1.3.3.cmml">L</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><apply id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.4.m4.1.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.p2.4.m4.1.1.2.cmml" xref="S3.SS4.p2.4.m4.1.1.2">â„’</ci><apply id="S3.SS4.p2.4.m4.1.1.3.cmml" xref="S3.SS4.p2.4.m4.1.1.3"><times id="S3.SS4.p2.4.m4.1.1.3.1.cmml" xref="S3.SS4.p2.4.m4.1.1.3.1"></times><ci id="S3.SS4.p2.4.m4.1.1.3.2.cmml" xref="S3.SS4.p2.4.m4.1.1.3.2">ğ¾</ci><ci id="S3.SS4.p2.4.m4.1.1.3.3.cmml" xref="S3.SS4.p2.4.m4.1.1.3.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">\mathcal{L}_{KL}</annotation></semantics></math> with <math id="S3.SS4.p2.5.m5.1" class="ltx_Math" alttext="\lambda_{KL}=1e^{-4}" display="inline"><semantics id="S3.SS4.p2.5.m5.1a"><mrow id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml"><msub id="S3.SS4.p2.5.m5.1.1.2" xref="S3.SS4.p2.5.m5.1.1.2.cmml"><mi id="S3.SS4.p2.5.m5.1.1.2.2" xref="S3.SS4.p2.5.m5.1.1.2.2.cmml">Î»</mi><mrow id="S3.SS4.p2.5.m5.1.1.2.3" xref="S3.SS4.p2.5.m5.1.1.2.3.cmml"><mi id="S3.SS4.p2.5.m5.1.1.2.3.2" xref="S3.SS4.p2.5.m5.1.1.2.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.5.m5.1.1.2.3.1" xref="S3.SS4.p2.5.m5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.5.m5.1.1.2.3.3" xref="S3.SS4.p2.5.m5.1.1.2.3.3.cmml">L</mi></mrow></msub><mo id="S3.SS4.p2.5.m5.1.1.1" xref="S3.SS4.p2.5.m5.1.1.1.cmml">=</mo><mrow id="S3.SS4.p2.5.m5.1.1.3" xref="S3.SS4.p2.5.m5.1.1.3.cmml"><mn id="S3.SS4.p2.5.m5.1.1.3.2" xref="S3.SS4.p2.5.m5.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS4.p2.5.m5.1.1.3.1" xref="S3.SS4.p2.5.m5.1.1.3.1.cmml">â€‹</mo><msup id="S3.SS4.p2.5.m5.1.1.3.3" xref="S3.SS4.p2.5.m5.1.1.3.3.cmml"><mi id="S3.SS4.p2.5.m5.1.1.3.3.2" xref="S3.SS4.p2.5.m5.1.1.3.3.2.cmml">e</mi><mrow id="S3.SS4.p2.5.m5.1.1.3.3.3" xref="S3.SS4.p2.5.m5.1.1.3.3.3.cmml"><mo id="S3.SS4.p2.5.m5.1.1.3.3.3a" xref="S3.SS4.p2.5.m5.1.1.3.3.3.cmml">âˆ’</mo><mn id="S3.SS4.p2.5.m5.1.1.3.3.3.2" xref="S3.SS4.p2.5.m5.1.1.3.3.3.2.cmml">4</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><apply id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1"><eq id="S3.SS4.p2.5.m5.1.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1.1"></eq><apply id="S3.SS4.p2.5.m5.1.1.2.cmml" xref="S3.SS4.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.5.m5.1.1.2.1.cmml" xref="S3.SS4.p2.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS4.p2.5.m5.1.1.2.2.cmml" xref="S3.SS4.p2.5.m5.1.1.2.2">ğœ†</ci><apply id="S3.SS4.p2.5.m5.1.1.2.3.cmml" xref="S3.SS4.p2.5.m5.1.1.2.3"><times id="S3.SS4.p2.5.m5.1.1.2.3.1.cmml" xref="S3.SS4.p2.5.m5.1.1.2.3.1"></times><ci id="S3.SS4.p2.5.m5.1.1.2.3.2.cmml" xref="S3.SS4.p2.5.m5.1.1.2.3.2">ğ¾</ci><ci id="S3.SS4.p2.5.m5.1.1.2.3.3.cmml" xref="S3.SS4.p2.5.m5.1.1.2.3.3">ğ¿</ci></apply></apply><apply id="S3.SS4.p2.5.m5.1.1.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3"><times id="S3.SS4.p2.5.m5.1.1.3.1.cmml" xref="S3.SS4.p2.5.m5.1.1.3.1"></times><cn type="integer" id="S3.SS4.p2.5.m5.1.1.3.2.cmml" xref="S3.SS4.p2.5.m5.1.1.3.2">1</cn><apply id="S3.SS4.p2.5.m5.1.1.3.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS4.p2.5.m5.1.1.3.3.1.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3">superscript</csymbol><ci id="S3.SS4.p2.5.m5.1.1.3.3.2.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3.2">ğ‘’</ci><apply id="S3.SS4.p2.5.m5.1.1.3.3.3.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3.3"><minus id="S3.SS4.p2.5.m5.1.1.3.3.3.1.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3.3"></minus><cn type="integer" id="S3.SS4.p2.5.m5.1.1.3.3.3.2.cmml" xref="S3.SS4.p2.5.m5.1.1.3.3.3.2">4</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.5.m5.1c">\lambda_{KL}=1e^{-4}</annotation></semantics></math>, <math id="S3.SS4.p2.6.m6.1" class="ltx_Math" alttext="\lambda_{rec}^{exp}=1.5" display="inline"><semantics id="S3.SS4.p2.6.m6.1a"><mrow id="S3.SS4.p2.6.m6.1.1" xref="S3.SS4.p2.6.m6.1.1.cmml"><msubsup id="S3.SS4.p2.6.m6.1.1.2" xref="S3.SS4.p2.6.m6.1.1.2.cmml"><mi id="S3.SS4.p2.6.m6.1.1.2.2.2" xref="S3.SS4.p2.6.m6.1.1.2.2.2.cmml">Î»</mi><mrow id="S3.SS4.p2.6.m6.1.1.2.2.3" xref="S3.SS4.p2.6.m6.1.1.2.2.3.cmml"><mi id="S3.SS4.p2.6.m6.1.1.2.2.3.2" xref="S3.SS4.p2.6.m6.1.1.2.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.6.m6.1.1.2.2.3.1" xref="S3.SS4.p2.6.m6.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.6.m6.1.1.2.2.3.3" xref="S3.SS4.p2.6.m6.1.1.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.6.m6.1.1.2.2.3.1a" xref="S3.SS4.p2.6.m6.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.6.m6.1.1.2.2.3.4" xref="S3.SS4.p2.6.m6.1.1.2.2.3.4.cmml">c</mi></mrow><mrow id="S3.SS4.p2.6.m6.1.1.2.3" xref="S3.SS4.p2.6.m6.1.1.2.3.cmml"><mi id="S3.SS4.p2.6.m6.1.1.2.3.2" xref="S3.SS4.p2.6.m6.1.1.2.3.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.6.m6.1.1.2.3.1" xref="S3.SS4.p2.6.m6.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.6.m6.1.1.2.3.3" xref="S3.SS4.p2.6.m6.1.1.2.3.3.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.6.m6.1.1.2.3.1a" xref="S3.SS4.p2.6.m6.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.6.m6.1.1.2.3.4" xref="S3.SS4.p2.6.m6.1.1.2.3.4.cmml">p</mi></mrow></msubsup><mo id="S3.SS4.p2.6.m6.1.1.1" xref="S3.SS4.p2.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS4.p2.6.m6.1.1.3" xref="S3.SS4.p2.6.m6.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m6.1b"><apply id="S3.SS4.p2.6.m6.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1"><eq id="S3.SS4.p2.6.m6.1.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1.1"></eq><apply id="S3.SS4.p2.6.m6.1.1.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.6.m6.1.1.2.1.cmml" xref="S3.SS4.p2.6.m6.1.1.2">superscript</csymbol><apply id="S3.SS4.p2.6.m6.1.1.2.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.6.m6.1.1.2.2.1.cmml" xref="S3.SS4.p2.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS4.p2.6.m6.1.1.2.2.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2.2.2">ğœ†</ci><apply id="S3.SS4.p2.6.m6.1.1.2.2.3.cmml" xref="S3.SS4.p2.6.m6.1.1.2.2.3"><times id="S3.SS4.p2.6.m6.1.1.2.2.3.1.cmml" xref="S3.SS4.p2.6.m6.1.1.2.2.3.1"></times><ci id="S3.SS4.p2.6.m6.1.1.2.2.3.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2.2.3.2">ğ‘Ÿ</ci><ci id="S3.SS4.p2.6.m6.1.1.2.2.3.3.cmml" xref="S3.SS4.p2.6.m6.1.1.2.2.3.3">ğ‘’</ci><ci id="S3.SS4.p2.6.m6.1.1.2.2.3.4.cmml" xref="S3.SS4.p2.6.m6.1.1.2.2.3.4">ğ‘</ci></apply></apply><apply id="S3.SS4.p2.6.m6.1.1.2.3.cmml" xref="S3.SS4.p2.6.m6.1.1.2.3"><times id="S3.SS4.p2.6.m6.1.1.2.3.1.cmml" xref="S3.SS4.p2.6.m6.1.1.2.3.1"></times><ci id="S3.SS4.p2.6.m6.1.1.2.3.2.cmml" xref="S3.SS4.p2.6.m6.1.1.2.3.2">ğ‘’</ci><ci id="S3.SS4.p2.6.m6.1.1.2.3.3.cmml" xref="S3.SS4.p2.6.m6.1.1.2.3.3">ğ‘¥</ci><ci id="S3.SS4.p2.6.m6.1.1.2.3.4.cmml" xref="S3.SS4.p2.6.m6.1.1.2.3.4">ğ‘</ci></apply></apply><cn type="float" id="S3.SS4.p2.6.m6.1.1.3.cmml" xref="S3.SS4.p2.6.m6.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m6.1c">\lambda_{rec}^{exp}=1.5</annotation></semantics></math>, <math id="S3.SS4.p2.7.m7.1" class="ltx_Math" alttext="\lambda_{rec}^{jaw}=1" display="inline"><semantics id="S3.SS4.p2.7.m7.1a"><mrow id="S3.SS4.p2.7.m7.1.1" xref="S3.SS4.p2.7.m7.1.1.cmml"><msubsup id="S3.SS4.p2.7.m7.1.1.2" xref="S3.SS4.p2.7.m7.1.1.2.cmml"><mi id="S3.SS4.p2.7.m7.1.1.2.2.2" xref="S3.SS4.p2.7.m7.1.1.2.2.2.cmml">Î»</mi><mrow id="S3.SS4.p2.7.m7.1.1.2.2.3" xref="S3.SS4.p2.7.m7.1.1.2.2.3.cmml"><mi id="S3.SS4.p2.7.m7.1.1.2.2.3.2" xref="S3.SS4.p2.7.m7.1.1.2.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.7.m7.1.1.2.2.3.1" xref="S3.SS4.p2.7.m7.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.7.m7.1.1.2.2.3.3" xref="S3.SS4.p2.7.m7.1.1.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.7.m7.1.1.2.2.3.1a" xref="S3.SS4.p2.7.m7.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.7.m7.1.1.2.2.3.4" xref="S3.SS4.p2.7.m7.1.1.2.2.3.4.cmml">c</mi></mrow><mrow id="S3.SS4.p2.7.m7.1.1.2.3" xref="S3.SS4.p2.7.m7.1.1.2.3.cmml"><mi id="S3.SS4.p2.7.m7.1.1.2.3.2" xref="S3.SS4.p2.7.m7.1.1.2.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.7.m7.1.1.2.3.1" xref="S3.SS4.p2.7.m7.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.7.m7.1.1.2.3.3" xref="S3.SS4.p2.7.m7.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.7.m7.1.1.2.3.1a" xref="S3.SS4.p2.7.m7.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS4.p2.7.m7.1.1.2.3.4" xref="S3.SS4.p2.7.m7.1.1.2.3.4.cmml">w</mi></mrow></msubsup><mo id="S3.SS4.p2.7.m7.1.1.1" xref="S3.SS4.p2.7.m7.1.1.1.cmml">=</mo><mn id="S3.SS4.p2.7.m7.1.1.3" xref="S3.SS4.p2.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.7.m7.1b"><apply id="S3.SS4.p2.7.m7.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1"><eq id="S3.SS4.p2.7.m7.1.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1.1"></eq><apply id="S3.SS4.p2.7.m7.1.1.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.7.m7.1.1.2.1.cmml" xref="S3.SS4.p2.7.m7.1.1.2">superscript</csymbol><apply id="S3.SS4.p2.7.m7.1.1.2.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.7.m7.1.1.2.2.1.cmml" xref="S3.SS4.p2.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS4.p2.7.m7.1.1.2.2.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2.2.2">ğœ†</ci><apply id="S3.SS4.p2.7.m7.1.1.2.2.3.cmml" xref="S3.SS4.p2.7.m7.1.1.2.2.3"><times id="S3.SS4.p2.7.m7.1.1.2.2.3.1.cmml" xref="S3.SS4.p2.7.m7.1.1.2.2.3.1"></times><ci id="S3.SS4.p2.7.m7.1.1.2.2.3.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2.2.3.2">ğ‘Ÿ</ci><ci id="S3.SS4.p2.7.m7.1.1.2.2.3.3.cmml" xref="S3.SS4.p2.7.m7.1.1.2.2.3.3">ğ‘’</ci><ci id="S3.SS4.p2.7.m7.1.1.2.2.3.4.cmml" xref="S3.SS4.p2.7.m7.1.1.2.2.3.4">ğ‘</ci></apply></apply><apply id="S3.SS4.p2.7.m7.1.1.2.3.cmml" xref="S3.SS4.p2.7.m7.1.1.2.3"><times id="S3.SS4.p2.7.m7.1.1.2.3.1.cmml" xref="S3.SS4.p2.7.m7.1.1.2.3.1"></times><ci id="S3.SS4.p2.7.m7.1.1.2.3.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2.3.2">ğ‘—</ci><ci id="S3.SS4.p2.7.m7.1.1.2.3.3.cmml" xref="S3.SS4.p2.7.m7.1.1.2.3.3">ğ‘</ci><ci id="S3.SS4.p2.7.m7.1.1.2.3.4.cmml" xref="S3.SS4.p2.7.m7.1.1.2.3.4">ğ‘¤</ci></apply></apply><cn type="integer" id="S3.SS4.p2.7.m7.1.1.3.cmml" xref="S3.SS4.p2.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.7.m7.1c">\lambda_{rec}^{jaw}=1</annotation></semantics></math>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.12" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.6.6" class="ltx_tr">
<td id="S3.T1.6.6.7" class="ltx_td ltx_align_center ltx_border_tt">Model</td>
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">MVE<math id="S3.T1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S3.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_tt">LVE <math id="S3.T1.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.2.2.2.m1.1a"><mo stretchy="false" id="S3.T1.2.2.2.m1.1.1" xref="S3.T1.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.m1.1b"><ci id="S3.T1.2.2.2.m1.1.1.cmml" xref="S3.T1.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_tt">FDD<math id="S3.T1.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.3.3.3.m1.1a"><mo stretchy="false" id="S3.T1.3.3.3.m1.1.1" xref="S3.T1.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.m1.1b"><ci id="S3.T1.3.3.3.m1.1.1.cmml" xref="S3.T1.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S3.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_tt">MEE <math id="S3.T1.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.4.4.4.m1.1a"><mo stretchy="false" id="S3.T1.4.4.4.m1.1.1" xref="S3.T1.4.4.4.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.m1.1b"><ci id="S3.T1.4.4.4.m1.1.1.cmml" xref="S3.T1.4.4.4.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S3.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_tt">CE <math id="S3.T1.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T1.5.5.5.m1.1a"><mo stretchy="false" id="S3.T1.5.5.5.m1.1.1" xref="S3.T1.5.5.5.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.m1.1b"><ci id="S3.T1.5.5.5.m1.1.1.cmml" xref="S3.T1.5.5.5.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S3.T1.6.6.6" class="ltx_td ltx_align_center ltx_border_tt">Diversity<math id="S3.T1.6.6.6.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T1.6.6.6.m1.1a"><mo stretchy="false" id="S3.T1.6.6.6.m1.1.1" xref="S3.T1.6.6.6.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.6.m1.1b"><ci id="S3.T1.6.6.6.m1.1.1.cmml" xref="S3.T1.6.6.6.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.6.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T1.12.12" class="ltx_tr">
<td id="S3.T1.12.12.7" class="ltx_td"></td>
<td id="S3.T1.7.7.1" class="ltx_td ltx_align_center">x<math id="S3.T1.7.7.1.m1.1" class="ltx_Math" alttext="10^{-3}mm" display="inline"><semantics id="S3.T1.7.7.1.m1.1a"><mrow id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml"><msup id="S3.T1.7.7.1.m1.1.1.2" xref="S3.T1.7.7.1.m1.1.1.2.cmml"><mn id="S3.T1.7.7.1.m1.1.1.2.2" xref="S3.T1.7.7.1.m1.1.1.2.2.cmml">10</mn><mrow id="S3.T1.7.7.1.m1.1.1.2.3" xref="S3.T1.7.7.1.m1.1.1.2.3.cmml"><mo id="S3.T1.7.7.1.m1.1.1.2.3a" xref="S3.T1.7.7.1.m1.1.1.2.3.cmml">âˆ’</mo><mn id="S3.T1.7.7.1.m1.1.1.2.3.2" xref="S3.T1.7.7.1.m1.1.1.2.3.2.cmml">3</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.T1.7.7.1.m1.1.1.1" xref="S3.T1.7.7.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.7.7.1.m1.1.1.3" xref="S3.T1.7.7.1.m1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T1.7.7.1.m1.1.1.1a" xref="S3.T1.7.7.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.7.7.1.m1.1.1.4" xref="S3.T1.7.7.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><apply id="S3.T1.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1"><times id="S3.T1.7.7.1.m1.1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1.1"></times><apply id="S3.T1.7.7.1.m1.1.1.2.cmml" xref="S3.T1.7.7.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.7.7.1.m1.1.1.2.1.cmml" xref="S3.T1.7.7.1.m1.1.1.2">superscript</csymbol><cn type="integer" id="S3.T1.7.7.1.m1.1.1.2.2.cmml" xref="S3.T1.7.7.1.m1.1.1.2.2">10</cn><apply id="S3.T1.7.7.1.m1.1.1.2.3.cmml" xref="S3.T1.7.7.1.m1.1.1.2.3"><minus id="S3.T1.7.7.1.m1.1.1.2.3.1.cmml" xref="S3.T1.7.7.1.m1.1.1.2.3"></minus><cn type="integer" id="S3.T1.7.7.1.m1.1.1.2.3.2.cmml" xref="S3.T1.7.7.1.m1.1.1.2.3.2">3</cn></apply></apply><ci id="S3.T1.7.7.1.m1.1.1.3.cmml" xref="S3.T1.7.7.1.m1.1.1.3">ğ‘š</ci><ci id="S3.T1.7.7.1.m1.1.1.4.cmml" xref="S3.T1.7.7.1.m1.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">10^{-3}mm</annotation></semantics></math>
</td>
<td id="S3.T1.8.8.2" class="ltx_td ltx_align_center">x<math id="S3.T1.8.8.2.m1.1" class="ltx_Math" alttext="10^{-4}mm" display="inline"><semantics id="S3.T1.8.8.2.m1.1a"><mrow id="S3.T1.8.8.2.m1.1.1" xref="S3.T1.8.8.2.m1.1.1.cmml"><msup id="S3.T1.8.8.2.m1.1.1.2" xref="S3.T1.8.8.2.m1.1.1.2.cmml"><mn id="S3.T1.8.8.2.m1.1.1.2.2" xref="S3.T1.8.8.2.m1.1.1.2.2.cmml">10</mn><mrow id="S3.T1.8.8.2.m1.1.1.2.3" xref="S3.T1.8.8.2.m1.1.1.2.3.cmml"><mo id="S3.T1.8.8.2.m1.1.1.2.3a" xref="S3.T1.8.8.2.m1.1.1.2.3.cmml">âˆ’</mo><mn id="S3.T1.8.8.2.m1.1.1.2.3.2" xref="S3.T1.8.8.2.m1.1.1.2.3.2.cmml">4</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.T1.8.8.2.m1.1.1.1" xref="S3.T1.8.8.2.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.8.8.2.m1.1.1.3" xref="S3.T1.8.8.2.m1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T1.8.8.2.m1.1.1.1a" xref="S3.T1.8.8.2.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.8.8.2.m1.1.1.4" xref="S3.T1.8.8.2.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.2.m1.1b"><apply id="S3.T1.8.8.2.m1.1.1.cmml" xref="S3.T1.8.8.2.m1.1.1"><times id="S3.T1.8.8.2.m1.1.1.1.cmml" xref="S3.T1.8.8.2.m1.1.1.1"></times><apply id="S3.T1.8.8.2.m1.1.1.2.cmml" xref="S3.T1.8.8.2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.8.8.2.m1.1.1.2.1.cmml" xref="S3.T1.8.8.2.m1.1.1.2">superscript</csymbol><cn type="integer" id="S3.T1.8.8.2.m1.1.1.2.2.cmml" xref="S3.T1.8.8.2.m1.1.1.2.2">10</cn><apply id="S3.T1.8.8.2.m1.1.1.2.3.cmml" xref="S3.T1.8.8.2.m1.1.1.2.3"><minus id="S3.T1.8.8.2.m1.1.1.2.3.1.cmml" xref="S3.T1.8.8.2.m1.1.1.2.3"></minus><cn type="integer" id="S3.T1.8.8.2.m1.1.1.2.3.2.cmml" xref="S3.T1.8.8.2.m1.1.1.2.3.2">4</cn></apply></apply><ci id="S3.T1.8.8.2.m1.1.1.3.cmml" xref="S3.T1.8.8.2.m1.1.1.3">ğ‘š</ci><ci id="S3.T1.8.8.2.m1.1.1.4.cmml" xref="S3.T1.8.8.2.m1.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.2.m1.1c">10^{-4}mm</annotation></semantics></math>
</td>
<td id="S3.T1.9.9.3" class="ltx_td ltx_align_center">x<math id="S3.T1.9.9.3.m1.1" class="ltx_Math" alttext="10^{-4}mm" display="inline"><semantics id="S3.T1.9.9.3.m1.1a"><mrow id="S3.T1.9.9.3.m1.1.1" xref="S3.T1.9.9.3.m1.1.1.cmml"><msup id="S3.T1.9.9.3.m1.1.1.2" xref="S3.T1.9.9.3.m1.1.1.2.cmml"><mn id="S3.T1.9.9.3.m1.1.1.2.2" xref="S3.T1.9.9.3.m1.1.1.2.2.cmml">10</mn><mrow id="S3.T1.9.9.3.m1.1.1.2.3" xref="S3.T1.9.9.3.m1.1.1.2.3.cmml"><mo id="S3.T1.9.9.3.m1.1.1.2.3a" xref="S3.T1.9.9.3.m1.1.1.2.3.cmml">âˆ’</mo><mn id="S3.T1.9.9.3.m1.1.1.2.3.2" xref="S3.T1.9.9.3.m1.1.1.2.3.2.cmml">4</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.T1.9.9.3.m1.1.1.1" xref="S3.T1.9.9.3.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.9.9.3.m1.1.1.3" xref="S3.T1.9.9.3.m1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T1.9.9.3.m1.1.1.1a" xref="S3.T1.9.9.3.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.9.9.3.m1.1.1.4" xref="S3.T1.9.9.3.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.3.m1.1b"><apply id="S3.T1.9.9.3.m1.1.1.cmml" xref="S3.T1.9.9.3.m1.1.1"><times id="S3.T1.9.9.3.m1.1.1.1.cmml" xref="S3.T1.9.9.3.m1.1.1.1"></times><apply id="S3.T1.9.9.3.m1.1.1.2.cmml" xref="S3.T1.9.9.3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.9.9.3.m1.1.1.2.1.cmml" xref="S3.T1.9.9.3.m1.1.1.2">superscript</csymbol><cn type="integer" id="S3.T1.9.9.3.m1.1.1.2.2.cmml" xref="S3.T1.9.9.3.m1.1.1.2.2">10</cn><apply id="S3.T1.9.9.3.m1.1.1.2.3.cmml" xref="S3.T1.9.9.3.m1.1.1.2.3"><minus id="S3.T1.9.9.3.m1.1.1.2.3.1.cmml" xref="S3.T1.9.9.3.m1.1.1.2.3"></minus><cn type="integer" id="S3.T1.9.9.3.m1.1.1.2.3.2.cmml" xref="S3.T1.9.9.3.m1.1.1.2.3.2">4</cn></apply></apply><ci id="S3.T1.9.9.3.m1.1.1.3.cmml" xref="S3.T1.9.9.3.m1.1.1.3">ğ‘š</ci><ci id="S3.T1.9.9.3.m1.1.1.4.cmml" xref="S3.T1.9.9.3.m1.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.3.m1.1c">10^{-4}mm</annotation></semantics></math>
</td>
<td id="S3.T1.10.10.4" class="ltx_td ltx_align_center">x<math id="S3.T1.10.10.4.m1.1" class="ltx_Math" alttext="10^{-4}mm" display="inline"><semantics id="S3.T1.10.10.4.m1.1a"><mrow id="S3.T1.10.10.4.m1.1.1" xref="S3.T1.10.10.4.m1.1.1.cmml"><msup id="S3.T1.10.10.4.m1.1.1.2" xref="S3.T1.10.10.4.m1.1.1.2.cmml"><mn id="S3.T1.10.10.4.m1.1.1.2.2" xref="S3.T1.10.10.4.m1.1.1.2.2.cmml">10</mn><mrow id="S3.T1.10.10.4.m1.1.1.2.3" xref="S3.T1.10.10.4.m1.1.1.2.3.cmml"><mo id="S3.T1.10.10.4.m1.1.1.2.3a" xref="S3.T1.10.10.4.m1.1.1.2.3.cmml">âˆ’</mo><mn id="S3.T1.10.10.4.m1.1.1.2.3.2" xref="S3.T1.10.10.4.m1.1.1.2.3.2.cmml">4</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.T1.10.10.4.m1.1.1.1" xref="S3.T1.10.10.4.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.10.10.4.m1.1.1.3" xref="S3.T1.10.10.4.m1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T1.10.10.4.m1.1.1.1a" xref="S3.T1.10.10.4.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.10.10.4.m1.1.1.4" xref="S3.T1.10.10.4.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.4.m1.1b"><apply id="S3.T1.10.10.4.m1.1.1.cmml" xref="S3.T1.10.10.4.m1.1.1"><times id="S3.T1.10.10.4.m1.1.1.1.cmml" xref="S3.T1.10.10.4.m1.1.1.1"></times><apply id="S3.T1.10.10.4.m1.1.1.2.cmml" xref="S3.T1.10.10.4.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.10.10.4.m1.1.1.2.1.cmml" xref="S3.T1.10.10.4.m1.1.1.2">superscript</csymbol><cn type="integer" id="S3.T1.10.10.4.m1.1.1.2.2.cmml" xref="S3.T1.10.10.4.m1.1.1.2.2">10</cn><apply id="S3.T1.10.10.4.m1.1.1.2.3.cmml" xref="S3.T1.10.10.4.m1.1.1.2.3"><minus id="S3.T1.10.10.4.m1.1.1.2.3.1.cmml" xref="S3.T1.10.10.4.m1.1.1.2.3"></minus><cn type="integer" id="S3.T1.10.10.4.m1.1.1.2.3.2.cmml" xref="S3.T1.10.10.4.m1.1.1.2.3.2">4</cn></apply></apply><ci id="S3.T1.10.10.4.m1.1.1.3.cmml" xref="S3.T1.10.10.4.m1.1.1.3">ğ‘š</ci><ci id="S3.T1.10.10.4.m1.1.1.4.cmml" xref="S3.T1.10.10.4.m1.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.4.m1.1c">10^{-4}mm</annotation></semantics></math>
</td>
<td id="S3.T1.11.11.5" class="ltx_td ltx_align_center">x<math id="S3.T1.11.11.5.m1.1" class="ltx_Math" alttext="10^{-5}mm" display="inline"><semantics id="S3.T1.11.11.5.m1.1a"><mrow id="S3.T1.11.11.5.m1.1.1" xref="S3.T1.11.11.5.m1.1.1.cmml"><msup id="S3.T1.11.11.5.m1.1.1.2" xref="S3.T1.11.11.5.m1.1.1.2.cmml"><mn id="S3.T1.11.11.5.m1.1.1.2.2" xref="S3.T1.11.11.5.m1.1.1.2.2.cmml">10</mn><mrow id="S3.T1.11.11.5.m1.1.1.2.3" xref="S3.T1.11.11.5.m1.1.1.2.3.cmml"><mo id="S3.T1.11.11.5.m1.1.1.2.3a" xref="S3.T1.11.11.5.m1.1.1.2.3.cmml">âˆ’</mo><mn id="S3.T1.11.11.5.m1.1.1.2.3.2" xref="S3.T1.11.11.5.m1.1.1.2.3.2.cmml">5</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.T1.11.11.5.m1.1.1.1" xref="S3.T1.11.11.5.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.11.11.5.m1.1.1.3" xref="S3.T1.11.11.5.m1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T1.11.11.5.m1.1.1.1a" xref="S3.T1.11.11.5.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.11.11.5.m1.1.1.4" xref="S3.T1.11.11.5.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.5.m1.1b"><apply id="S3.T1.11.11.5.m1.1.1.cmml" xref="S3.T1.11.11.5.m1.1.1"><times id="S3.T1.11.11.5.m1.1.1.1.cmml" xref="S3.T1.11.11.5.m1.1.1.1"></times><apply id="S3.T1.11.11.5.m1.1.1.2.cmml" xref="S3.T1.11.11.5.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.11.11.5.m1.1.1.2.1.cmml" xref="S3.T1.11.11.5.m1.1.1.2">superscript</csymbol><cn type="integer" id="S3.T1.11.11.5.m1.1.1.2.2.cmml" xref="S3.T1.11.11.5.m1.1.1.2.2">10</cn><apply id="S3.T1.11.11.5.m1.1.1.2.3.cmml" xref="S3.T1.11.11.5.m1.1.1.2.3"><minus id="S3.T1.11.11.5.m1.1.1.2.3.1.cmml" xref="S3.T1.11.11.5.m1.1.1.2.3"></minus><cn type="integer" id="S3.T1.11.11.5.m1.1.1.2.3.2.cmml" xref="S3.T1.11.11.5.m1.1.1.2.3.2">5</cn></apply></apply><ci id="S3.T1.11.11.5.m1.1.1.3.cmml" xref="S3.T1.11.11.5.m1.1.1.3">ğ‘š</ci><ci id="S3.T1.11.11.5.m1.1.1.4.cmml" xref="S3.T1.11.11.5.m1.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.5.m1.1c">10^{-5}mm</annotation></semantics></math>
</td>
<td id="S3.T1.12.12.6" class="ltx_td ltx_align_center">x<math id="S3.T1.12.12.6.m1.1" class="ltx_Math" alttext="10^{-3}mm" display="inline"><semantics id="S3.T1.12.12.6.m1.1a"><mrow id="S3.T1.12.12.6.m1.1.1" xref="S3.T1.12.12.6.m1.1.1.cmml"><msup id="S3.T1.12.12.6.m1.1.1.2" xref="S3.T1.12.12.6.m1.1.1.2.cmml"><mn id="S3.T1.12.12.6.m1.1.1.2.2" xref="S3.T1.12.12.6.m1.1.1.2.2.cmml">10</mn><mrow id="S3.T1.12.12.6.m1.1.1.2.3" xref="S3.T1.12.12.6.m1.1.1.2.3.cmml"><mo id="S3.T1.12.12.6.m1.1.1.2.3a" xref="S3.T1.12.12.6.m1.1.1.2.3.cmml">âˆ’</mo><mn id="S3.T1.12.12.6.m1.1.1.2.3.2" xref="S3.T1.12.12.6.m1.1.1.2.3.2.cmml">3</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.T1.12.12.6.m1.1.1.1" xref="S3.T1.12.12.6.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.12.12.6.m1.1.1.3" xref="S3.T1.12.12.6.m1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.T1.12.12.6.m1.1.1.1a" xref="S3.T1.12.12.6.m1.1.1.1.cmml">â€‹</mo><mi id="S3.T1.12.12.6.m1.1.1.4" xref="S3.T1.12.12.6.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.6.m1.1b"><apply id="S3.T1.12.12.6.m1.1.1.cmml" xref="S3.T1.12.12.6.m1.1.1"><times id="S3.T1.12.12.6.m1.1.1.1.cmml" xref="S3.T1.12.12.6.m1.1.1.1"></times><apply id="S3.T1.12.12.6.m1.1.1.2.cmml" xref="S3.T1.12.12.6.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.12.12.6.m1.1.1.2.1.cmml" xref="S3.T1.12.12.6.m1.1.1.2">superscript</csymbol><cn type="integer" id="S3.T1.12.12.6.m1.1.1.2.2.cmml" xref="S3.T1.12.12.6.m1.1.1.2.2">10</cn><apply id="S3.T1.12.12.6.m1.1.1.2.3.cmml" xref="S3.T1.12.12.6.m1.1.1.2.3"><minus id="S3.T1.12.12.6.m1.1.1.2.3.1.cmml" xref="S3.T1.12.12.6.m1.1.1.2.3"></minus><cn type="integer" id="S3.T1.12.12.6.m1.1.1.2.3.2.cmml" xref="S3.T1.12.12.6.m1.1.1.2.3.2">3</cn></apply></apply><ci id="S3.T1.12.12.6.m1.1.1.3.cmml" xref="S3.T1.12.12.6.m1.1.1.3">ğ‘š</ci><ci id="S3.T1.12.12.6.m1.1.1.4.cmml" xref="S3.T1.12.12.6.m1.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.6.m1.1c">10^{-3}mm</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T1.12.13.1" class="ltx_tr">
<td id="S3.T1.12.13.1.1" class="ltx_td ltx_align_center ltx_border_t">FaceFormer<cite class="ltx_cite ltx_citemacro_citep">(Fan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S3.T1.12.13.1.2" class="ltx_td ltx_align_center ltx_border_t">2.8548</td>
<td id="S3.T1.12.13.1.3" class="ltx_td ltx_align_center ltx_border_t">2.0266</td>
<td id="S3.T1.12.13.1.4" class="ltx_td ltx_align_center ltx_border_t">0.0659</td>
<td id="S3.T1.12.13.1.5" class="ltx_td ltx_align_center ltx_border_t">N/A</td>
<td id="S3.T1.12.13.1.6" class="ltx_td ltx_align_center ltx_border_t">N/A</td>
<td id="S3.T1.12.13.1.7" class="ltx_td ltx_align_center ltx_border_t">N/A</td>
</tr>
<tr id="S3.T1.12.14.2" class="ltx_tr">
<td id="S3.T1.12.14.2.1" class="ltx_td ltx_align_center">CodeTalker<cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite>
</td>
<td id="S3.T1.12.14.2.2" class="ltx_td ltx_align_center">1.7121</td>
<td id="S3.T1.12.14.2.3" class="ltx_td ltx_align_center">1.5978</td>
<td id="S3.T1.12.14.2.4" class="ltx_td ltx_align_center">0.2036</td>
<td id="S3.T1.12.14.2.5" class="ltx_td ltx_align_center">N/A</td>
<td id="S3.T1.12.14.2.6" class="ltx_td ltx_align_center">N/A</td>
<td id="S3.T1.12.14.2.7" class="ltx_td ltx_align_center">N/A</td>
</tr>
<tr id="S3.T1.12.15.3" class="ltx_tr">
<td id="S3.T1.12.15.3.1" class="ltx_td ltx_align_center">CodeTalker-ND</td>
<td id="S3.T1.12.15.3.2" class="ltx_td ltx_align_center">3.4783</td>
<td id="S3.T1.12.15.3.3" class="ltx_td ltx_align_center">3.1325</td>
<td id="S3.T1.12.15.3.4" class="ltx_td ltx_align_center">0.3089</td>
<td id="S3.T1.12.15.3.5" class="ltx_td ltx_align_center">3.1593</td>
<td id="S3.T1.12.15.3.6" class="ltx_td ltx_align_center">3.0205</td>
<td id="S3.T1.12.15.3.7" class="ltx_td ltx_align_center">0.1696</td>
</tr>
<tr id="S3.T1.12.16.4" class="ltx_tr">
<td id="S3.T1.12.16.4.1" class="ltx_td ltx_align_center">FaceDiffuser - DDPM <cite class="ltx_cite ltx_citemacro_citep">(Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>
</td>
<td id="S3.T1.12.16.4.2" class="ltx_td ltx_align_center">1.3242</td>
<td id="S3.T1.12.16.4.3" class="ltx_td ltx_align_center">0.8938</td>
<td id="S3.T1.12.16.4.4" class="ltx_td ltx_align_center">0.0906</td>
<td id="S3.T1.12.16.4.5" class="ltx_td ltx_align_center">0.8848</td>
<td id="S3.T1.12.16.4.6" class="ltx_td ltx_align_center">0.8784</td>
<td id="S3.T1.12.16.4.7" class="ltx_td ltx_align_center">0.0449</td>
</tr>
<tr id="S3.T1.12.17.5" class="ltx_tr">
<td id="S3.T1.12.17.5.1" class="ltx_td ltx_align_center">FaceDiffuser - DDIM</td>
<td id="S3.T1.12.17.5.2" class="ltx_td ltx_align_center">0.9334</td>
<td id="S3.T1.12.17.5.3" class="ltx_td ltx_align_center"><span id="S3.T1.12.17.5.3.1" class="ltx_text ltx_font_bold">0.4440</span></td>
<td id="S3.T1.12.17.5.4" class="ltx_td ltx_align_center">0.0625</td>
<td id="S3.T1.12.17.5.5" class="ltx_td ltx_align_center"><span id="S3.T1.12.17.5.5.1" class="ltx_text ltx_font_bold">0.4440</span></td>
<td id="S3.T1.12.17.5.6" class="ltx_td ltx_align_center"><span id="S3.T1.12.17.5.6.1" class="ltx_text ltx_font_bold">0.4438</span></td>
<td id="S3.T1.12.17.5.7" class="ltx_td ltx_align_center">0.0009</td>
</tr>
<tr id="S3.T1.12.18.6" class="ltx_tr">
<td id="S3.T1.12.18.6.1" class="ltx_td ltx_align_center">VAE-based</td>
<td id="S3.T1.12.18.6.2" class="ltx_td ltx_align_center"><span id="S3.T1.12.18.6.2.1" class="ltx_text ltx_font_bold">0.6959</span></td>
<td id="S3.T1.12.18.6.3" class="ltx_td ltx_align_center">0.5673</td>
<td id="S3.T1.12.18.6.4" class="ltx_td ltx_align_center"><span id="S3.T1.12.18.6.4.1" class="ltx_text ltx_font_bold">0.0010</span></td>
<td id="S3.T1.12.18.6.5" class="ltx_td ltx_align_center">0.5657</td>
<td id="S3.T1.12.18.6.6" class="ltx_td ltx_align_center">0.5550</td>
<td id="S3.T1.12.18.6.7" class="ltx_td ltx_align_center">0.0722</td>
</tr>
<tr id="S3.T1.12.19.7" class="ltx_tr">
<td id="S3.T1.12.19.7.1" class="ltx_td ltx_align_center">ProbTalk3D (proposed)</td>
<td id="S3.T1.12.19.7.2" class="ltx_td ltx_align_center">0.7243</td>
<td id="S3.T1.12.19.7.3" class="ltx_td ltx_align_center">0.6040</td>
<td id="S3.T1.12.19.7.4" class="ltx_td ltx_align_center">0.0415</td>
<td id="S3.T1.12.19.7.5" class="ltx_td ltx_align_center">0.5549</td>
<td id="S3.T1.12.19.7.6" class="ltx_td ltx_align_center">0.5227</td>
<td id="S3.T1.12.19.7.7" class="ltx_td ltx_align_center"><span id="S3.T1.12.19.7.7.1" class="ltx_text ltx_font_bold">0.3274</span></td>
</tr>
<tr id="S3.T1.12.20.8" class="ltx_tr">
<td id="S3.T1.12.20.8.1" class="ltx_td ltx_align_center ltx_border_t" colspan="7">Ablation Study</td>
</tr>
<tr id="S3.T1.12.21.9" class="ltx_tr">
<td id="S3.T1.12.21.9.1" class="ltx_td ltx_align_center ltx_border_t">VAE-based (w/o emo)</td>
<td id="S3.T1.12.21.9.2" class="ltx_td ltx_align_center ltx_border_t">1.3357</td>
<td id="S3.T1.12.21.9.3" class="ltx_td ltx_align_center ltx_border_t">1.4576</td>
<td id="S3.T1.12.21.9.4" class="ltx_td ltx_align_center ltx_border_t">0.1022</td>
<td id="S3.T1.12.21.9.5" class="ltx_td ltx_align_center ltx_border_t">1.4529</td>
<td id="S3.T1.12.21.9.6" class="ltx_td ltx_align_center ltx_border_t">1.4110</td>
<td id="S3.T1.12.21.9.7" class="ltx_td ltx_align_center ltx_border_t">0.1158</td>
</tr>
<tr id="S3.T1.12.22.10" class="ltx_tr">
<td id="S3.T1.12.22.10.1" class="ltx_td ltx_align_center ltx_border_bb">ProbTalk3D (w/o emo)</td>
<td id="S3.T1.12.22.10.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.12.22.10.2.1" class="ltx_text ltx_font_bold">0.7799</span></td>
<td id="S3.T1.12.22.10.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.12.22.10.3.1" class="ltx_text ltx_font_bold">0.5794</span></td>
<td id="S3.T1.12.22.10.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.12.22.10.4.1" class="ltx_text ltx_font_bold">0.0579</span></td>
<td id="S3.T1.12.22.10.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.12.22.10.5.1" class="ltx_text ltx_font_bold">0.5323</span></td>
<td id="S3.T1.12.22.10.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.12.22.10.6.1" class="ltx_text ltx_font_bold">0.4989</span></td>
<td id="S3.T1.12.22.10.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.12.22.10.7.1" class="ltx_text ltx_font_bold">0.3136</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.14.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S3.T1.15.2" class="ltx_text" style="font-size:90%;">Quantitative evaluation results comparing our proposed model ProbTalk3D with VAE-based variant and a modified version of FaceDiffuser together with other SOTA models. Our proposed model achieves significantly better results regarding the Diversity metric while providing comparable results to other non-deterministic models with respect to other metrics. Non-deterministic models including ours (ProbTalk3D and VAE-based model) are better than deterministic models overall. The ablation study results related to Sec.<a href="#S4.SS4" title="4.4. Ablation Study â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a> are also shown here.</span></figcaption>
</figure>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5. </span>Comparison Model: Diffusion Based</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">For our comparative analysis, we chose state-of-the-art diffusion based method FaceDiffuser<cite class="ltx_cite ltx_citemacro_citep">(Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>. FaceDiffuser also uses HuBERT as an audio encoder which ensures similarity with respect to our model. In addition to the original model, we train FaceDiffuser on 3DMEAD with a modification of the original model structure in order to incorporate the emotion and intensity categories. We use 3D vertex coordinates instead of FLAME parameters for training FaceDiffuser as our experiments indicate that using low dimensional FLAME parameters data does not yield realistic facial animations for this architecture. To obtain the vertex coordinate data, scripts provided by FLAME<cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2017b</a>)</cite> are utilized to convert temporal FLAME parameters into temporal 3D vertex coordinates. In the revised FaceDiffuser model, the style embedding is multiplied earlier in the network with audio features extracted by HuBERT, rather than fusing it later in the network, before the last fully connected layer, as it was done in the original model. The style embedding includes information about subject identity, emotion class, and emotion intensity, using the same format as the style vector <math id="S3.SS5.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS5.p1.1.m1.1a"><mi id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><ci id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">C</annotation></semantics></math> in our proposed model, while the original FaceDiffuser only uses one-hot vectors for subject identities. Our experiments show that integrating the style at an earlier stage generates better results. We define two versions: FaceDiffuser - DDPM and FaceDiffuser - DDIM (See Tab.<a href="#S3.T1" title="Table 1 â€£ 3.4. Comparison Model: VAE Based â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The former is trained with Denoising Diffusion Probabilistic Model (DDPM) <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2020a</a>)</cite> same as the original FaceDiffuser. We further improve the diffusion sampling efficiency of the modified model by changing the original one with Denoising Diffusion Implicit Model (DDIM) <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2020b</a>)</cite>. Aside from these changes, the model structure and hyperparameters are identical to the V-FaceDiffuser in <cite class="ltx_cite ltx_citemacro_citep">(Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we present the results of our proposed model and evaluate the model quantitatively, qualitatively, and with a perceptual user study. In addition to the relevant objective metrics from the literature <cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>; Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>, we use an extensive list of objective metrics following <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>)</cite>. The non-deterministic generation ability of our model is illustrated using a diversity metric, in line with recent probabilistic models <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>; Ren etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>. Furthermore, qualitative evaluations provide visual demonstrations of animation quality and emotion control aspects. Following that, results of the user study are provided, aiming to evaluate the perceived realism, lip-synchrony, and emotional expressivity of the synthesized animations. Finally, the ablation study showcases the impact of incorporating emotion control into our model.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Quantitative Evaluation</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We quantitatively evaluate our model performance based on multiple metrics. Mean Vertex Error (MVE), Lip Vertex Error (LVE) and Upper Face Dynamics Deviation (FDD) are calculated based on one sample output which are metrics commonly used for evaluating deterministic models. Mean Estimate Error (MEE), CE (Coverage Error) and Diversity are calculated over multiple samples providing a better picture for evaluating non-deterministic models. The widely applied evaluation metrics used by recent models mostly operate in vertex coordinate space. To compare accuracy with these models, we employ scripts provided by FLAME <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2017b</a>)</cite> to convert predicted motion parameters into vertex coordinate space. In addition to VAE-based and Diffusion-based models, we compare our model to deterministic models FaceFormer<cite class="ltx_cite ltx_citemacro_citep">(Fan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite> and CodeTalker<cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite> trained on 3DMEAD. To ensure a fair comparison, we also implement a non-deterministic version of CodeTalker called CodeTalker-ND by incorporating probabilistic sampling during inference. Retraining EMOTE from scratch on our slightly modified dataset split was not an option as we found the publicly available training codebase to be difficult to reproduce within a reasonable time frame, as also reported in <cite class="ltx_cite ltx_citemacro_citep">(Zhao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2024</a>)</cite>. Hence, we only provide subjective comparisons to EMOTE as explained in Sec.<a href="#S4.SS2" title="4.2. Qualitative Evaluation â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>. The evaluation metrics are concisely described below.</p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">MVE</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.4" class="ltx_p">Mean Vertex Error calculates the average Euclidean distance between predicted frames and ground truth across the entire test set. Let <math id="S4.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S4.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.1.m1.1c">N</annotation></semantics></math> represent the total number of frames generated for all the test-set audio inputs. We denote <math id="S4.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S4.SS1.SSS0.Px1.p1.2.m2.1a"><msub id="S4.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">x</mi><mi id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.2">ğ‘¥</ci><ci id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.2.m2.1c">x_{i}</annotation></semantics></math> as the ground truth of <math id="S4.SS1.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.SSS0.Px1.p1.3.m3.1a"><mi id="S4.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.3.m3.1b"><ci id="S4.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.3.m3.1c">i</annotation></semantics></math>-th frame, and <math id="S4.SS1.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="\hat{x}_{i}" display="inline"><semantics id="S4.SS1.SSS0.Px1.p1.4.m4.1a"><msub id="S4.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.cmml"><mover accent="true" id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml"><mi id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.2" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.2.cmml">x</mi><mo id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.1" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.1.cmml">^</mo></mover><mi id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.4.m4.1b"><apply id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><apply id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2"><ci id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.1">^</ci><ci id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.2.2">ğ‘¥</ci></apply><ci id="S4.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p1.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.4.m4.1c">\hat{x}_{i}</annotation></semantics></math> as the predicted frame. The computation of MVE can be expressed as follows:</p>
<table id="S4.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E6.m1.1" class="ltx_Math" alttext="\text{MVE}=\frac{1}{N}\sum_{i=1}^{N}\|x_{i}-\hat{x}_{i}\|" display="block"><semantics id="S4.E6.m1.1a"><mrow id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1.cmml"><mtext id="S4.E6.m1.1.1.3" xref="S4.E6.m1.1.1.3a.cmml">MVE</mtext><mo id="S4.E6.m1.1.1.2" xref="S4.E6.m1.1.1.2.cmml">=</mo><mrow id="S4.E6.m1.1.1.1" xref="S4.E6.m1.1.1.1.cmml"><mfrac id="S4.E6.m1.1.1.1.3" xref="S4.E6.m1.1.1.1.3.cmml"><mn id="S4.E6.m1.1.1.1.3.2" xref="S4.E6.m1.1.1.1.3.2.cmml">1</mn><mi id="S4.E6.m1.1.1.1.3.3" xref="S4.E6.m1.1.1.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E6.m1.1.1.1.2" xref="S4.E6.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E6.m1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.cmml"><munderover id="S4.E6.m1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S4.E6.m1.1.1.1.1.2.2.2" xref="S4.E6.m1.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E6.m1.1.1.1.1.2.2.3" xref="S4.E6.m1.1.1.1.1.2.2.3.cmml"><mi id="S4.E6.m1.1.1.1.1.2.2.3.2" xref="S4.E6.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S4.E6.m1.1.1.1.1.2.2.3.1" xref="S4.E6.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E6.m1.1.1.1.1.2.2.3.3" xref="S4.E6.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E6.m1.1.1.1.1.2.3" xref="S4.E6.m1.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S4.E6.m1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E6.m1.1.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S4.E6.m1.1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.1.cmml"><msub id="S4.E6.m1.1.1.1.1.1.1.1.2" xref="S4.E6.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E6.m1.1.1.1.1.1.1.1.2.2" xref="S4.E6.m1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S4.E6.m1.1.1.1.1.1.1.1.2.3" xref="S4.E6.m1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.E6.m1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S4.E6.m1.1.1.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S4.E6.m1.1.1.1.1.1.1.1.3.2" xref="S4.E6.m1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S4.E6.m1.1.1.1.1.1.1.1.3.2.2" xref="S4.E6.m1.1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mo id="S4.E6.m1.1.1.1.1.1.1.1.3.2.1" xref="S4.E6.m1.1.1.1.1.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S4.E6.m1.1.1.1.1.1.1.1.3.3" xref="S4.E6.m1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S4.E6.m1.1.1.1.1.1.1.3" xref="S4.E6.m1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.1b"><apply id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1"><eq id="S4.E6.m1.1.1.2.cmml" xref="S4.E6.m1.1.1.2"></eq><ci id="S4.E6.m1.1.1.3a.cmml" xref="S4.E6.m1.1.1.3"><mtext id="S4.E6.m1.1.1.3.cmml" xref="S4.E6.m1.1.1.3">MVE</mtext></ci><apply id="S4.E6.m1.1.1.1.cmml" xref="S4.E6.m1.1.1.1"><times id="S4.E6.m1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.2"></times><apply id="S4.E6.m1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.3"><divide id="S4.E6.m1.1.1.1.3.1.cmml" xref="S4.E6.m1.1.1.1.3"></divide><cn type="integer" id="S4.E6.m1.1.1.1.3.2.cmml" xref="S4.E6.m1.1.1.1.3.2">1</cn><ci id="S4.E6.m1.1.1.1.3.3.cmml" xref="S4.E6.m1.1.1.1.3.3">ğ‘</ci></apply><apply id="S4.E6.m1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1"><apply id="S4.E6.m1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.2.1.cmml" xref="S4.E6.m1.1.1.1.1.2">superscript</csymbol><apply id="S4.E6.m1.1.1.1.1.2.2.cmml" xref="S4.E6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.2.2.1.cmml" xref="S4.E6.m1.1.1.1.1.2">subscript</csymbol><sum id="S4.E6.m1.1.1.1.1.2.2.2.cmml" xref="S4.E6.m1.1.1.1.1.2.2.2"></sum><apply id="S4.E6.m1.1.1.1.1.2.2.3.cmml" xref="S4.E6.m1.1.1.1.1.2.2.3"><eq id="S4.E6.m1.1.1.1.1.2.2.3.1.cmml" xref="S4.E6.m1.1.1.1.1.2.2.3.1"></eq><ci id="S4.E6.m1.1.1.1.1.2.2.3.2.cmml" xref="S4.E6.m1.1.1.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S4.E6.m1.1.1.1.1.2.2.3.3.cmml" xref="S4.E6.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E6.m1.1.1.1.1.2.3.cmml" xref="S4.E6.m1.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S4.E6.m1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E6.m1.1.1.1.1.1.2.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.2">norm</csymbol><apply id="S4.E6.m1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1"><minus id="S4.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E6.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E6.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S4.E6.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S4.E6.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E6.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S4.E6.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.3.2"><ci id="S4.E6.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.3.2.1">^</ci><ci id="S4.E6.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.3.2.2">ğ‘¥</ci></apply><ci id="S4.E6.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E6.m1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.1c">\text{MVE}=\frac{1}{N}\sum_{i=1}^{N}\|x_{i}-\hat{x}_{i}\|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">LVE</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.4" class="ltx_p">Lip Vertex Error calculates the maximal <math id="S4.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{2}" display="inline"><semantics id="S4.SS1.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">â„’</mi><mn id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2">â„’</ci><cn type="integer" id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.1.m1.1c">\mathcal{L}_{2}</annotation></semantics></math> error between vertices belonging to the lip/mouth region of a predicted frame compared to the ground truth, and then computes the mean across all generated frames. As the facial topology is same for 3DMEAD and VOCASET, we adopt the same lip mask utilized in <cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>; Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>. For <math id="S4.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS1.SSS0.Px2.p1.2.m2.1a"><mi id="S4.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.2.m2.1b"><ci id="S4.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.2.m2.1c">N</annotation></semantics></math> predicted frames from all test audio, let <math id="S4.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="x_{lip}^{i}" display="inline"><semantics id="S4.SS1.SSS0.Px2.p1.3.m3.1a"><msubsup id="S4.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.2" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.2.cmml">x</mi><mrow id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.cmml"><mi id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.2" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.1" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.3" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.1a" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.4" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.4.cmml">p</mi></mrow><mi id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1">superscript</csymbol><apply id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.2">ğ‘¥</ci><apply id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3"><times id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.1.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.1"></times><ci id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.2.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.2">ğ‘™</ci><ci id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.3.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.3">ğ‘–</ci><ci id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.4.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.4">ğ‘</ci></apply></apply><ci id="S4.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.3.m3.1c">x_{lip}^{i}</annotation></semantics></math> denote the lip region vertices of a ground truth frame, and <math id="S4.SS1.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\hat{x}_{lip}^{i}" display="inline"><semantics id="S4.SS1.SSS0.Px2.p1.4.m4.1a"><msubsup id="S4.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.cmml"><mover accent="true" id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.cmml"><mi id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.2" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.2.cmml">x</mi><mo id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.1" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.1.cmml">^</mo></mover><mrow id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.cmml"><mi id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.2" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.1" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.3" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.1a" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.4" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.4.cmml">p</mi></mrow><mi id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.3" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.4.m4.1b"><apply id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1">superscript</csymbol><apply id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1">subscript</csymbol><apply id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2"><ci id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.1.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.1">^</ci><ci id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.2.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.2.2">ğ‘¥</ci></apply><apply id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3"><times id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.1.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.1"></times><ci id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.2.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.2">ğ‘™</ci><ci id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.3.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.3">ğ‘–</ci><ci id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.4.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.2.3.4">ğ‘</ci></apply></apply><ci id="S4.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S4.SS1.SSS0.Px2.p1.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.4.m4.1c">\hat{x}_{lip}^{i}</annotation></semantics></math> represent the same region of a predicted frame. Then LVE is computed by:</p>
<table id="S4.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(7)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E7.m1.1" class="ltx_Math" alttext="\text{LVE}=\frac{1}{N}\sum_{i=1}^{N}\max\|x_{lip}^{i}-\hat{x}_{lip}^{i}\|_{2}" display="block"><semantics id="S4.E7.m1.1a"><mrow id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml"><mtext id="S4.E7.m1.1.1.3" xref="S4.E7.m1.1.1.3a.cmml">LVE</mtext><mo id="S4.E7.m1.1.1.2" xref="S4.E7.m1.1.1.2.cmml">=</mo><mrow id="S4.E7.m1.1.1.1" xref="S4.E7.m1.1.1.1.cmml"><mfrac id="S4.E7.m1.1.1.1.3" xref="S4.E7.m1.1.1.1.3.cmml"><mn id="S4.E7.m1.1.1.1.3.2" xref="S4.E7.m1.1.1.1.3.2.cmml">1</mn><mi id="S4.E7.m1.1.1.1.3.3" xref="S4.E7.m1.1.1.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E7.m1.1.1.1.2" xref="S4.E7.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E7.m1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.cmml"><munderover id="S4.E7.m1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S4.E7.m1.1.1.1.1.2.2.2" xref="S4.E7.m1.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E7.m1.1.1.1.1.2.2.3" xref="S4.E7.m1.1.1.1.1.2.2.3.cmml"><mi id="S4.E7.m1.1.1.1.1.2.2.3.2" xref="S4.E7.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S4.E7.m1.1.1.1.1.2.2.3.1" xref="S4.E7.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E7.m1.1.1.1.1.2.2.3.3" xref="S4.E7.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E7.m1.1.1.1.1.2.3" xref="S4.E7.m1.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S4.E7.m1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.cmml"><mi id="S4.E7.m1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.2.cmml">max</mi><mo id="S4.E7.m1.1.1.1.1.1a" xref="S4.E7.m1.1.1.1.1.1.cmml">â¡</mo><msub id="S4.E7.m1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.cmml"><mrow id="S4.E7.m1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E7.m1.1.1.1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S4.E7.m1.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">x</mi><mrow id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.2" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1a" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.4" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.4.cmml">p</mi></mrow><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msubsup><mo id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.2" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml">x</mi><mo id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.1" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml">^</mo></mover><mrow id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.2" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.1" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.1a" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.4" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.4.cmml">p</mi></mrow><mi id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msubsup></mrow><mo stretchy="false" id="S4.E7.m1.1.1.1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S4.E7.m1.1.1.1.1.1.1.3" xref="S4.E7.m1.1.1.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m1.1b"><apply id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1"><eq id="S4.E7.m1.1.1.2.cmml" xref="S4.E7.m1.1.1.2"></eq><ci id="S4.E7.m1.1.1.3a.cmml" xref="S4.E7.m1.1.1.3"><mtext id="S4.E7.m1.1.1.3.cmml" xref="S4.E7.m1.1.1.3">LVE</mtext></ci><apply id="S4.E7.m1.1.1.1.cmml" xref="S4.E7.m1.1.1.1"><times id="S4.E7.m1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.2"></times><apply id="S4.E7.m1.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.3"><divide id="S4.E7.m1.1.1.1.3.1.cmml" xref="S4.E7.m1.1.1.1.3"></divide><cn type="integer" id="S4.E7.m1.1.1.1.3.2.cmml" xref="S4.E7.m1.1.1.1.3.2">1</cn><ci id="S4.E7.m1.1.1.1.3.3.cmml" xref="S4.E7.m1.1.1.1.3.3">ğ‘</ci></apply><apply id="S4.E7.m1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1"><apply id="S4.E7.m1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.1.1.1.1.2">superscript</csymbol><apply id="S4.E7.m1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.2.2.1.cmml" xref="S4.E7.m1.1.1.1.1.2">subscript</csymbol><sum id="S4.E7.m1.1.1.1.1.2.2.2.cmml" xref="S4.E7.m1.1.1.1.1.2.2.2"></sum><apply id="S4.E7.m1.1.1.1.1.2.2.3.cmml" xref="S4.E7.m1.1.1.1.1.2.2.3"><eq id="S4.E7.m1.1.1.1.1.2.2.3.1.cmml" xref="S4.E7.m1.1.1.1.1.2.2.3.1"></eq><ci id="S4.E7.m1.1.1.1.1.2.2.3.2.cmml" xref="S4.E7.m1.1.1.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S4.E7.m1.1.1.1.1.2.2.3.3.cmml" xref="S4.E7.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E7.m1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S4.E7.m1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1"><max id="S4.E7.m1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.2"></max><apply id="S4.E7.m1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E7.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E7.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1"><minus id="S4.E7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.2">ğ‘¥</ci><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3"><times id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.1"></times><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.2">ğ‘™</ci><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.3">ğ‘–</ci><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.4.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.2.3.4">ğ‘</ci></apply></apply><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2"><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.1">^</ci><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.2.2">ğ‘¥</ci></apply><apply id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3"><times id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.1"></times><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.2">ğ‘™</ci><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.3">ğ‘–</ci><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.4.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.2.3.4">ğ‘</ci></apply></apply><ci id="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><cn type="integer" id="S4.E7.m1.1.1.1.1.1.1.3.cmml" xref="S4.E7.m1.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.1c">\text{LVE}=\frac{1}{N}\sum_{i=1}^{N}\max\|x_{lip}^{i}-\hat{x}_{lip}^{i}\|_{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">FDD</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">Upper Face Dynamic Deviation was proposed in <cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite>, it measures the variation of facial dynamics for motion sequences in comparison with ground truth. It gives an indication of how close the standard deviation (or upper face motion variation) of generated sequences (of test-set audios) is compared to the variation observed in ground truth.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">MEE</h5>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p1.3" class="ltx_p">Mean Estimate Error <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>)</cite> is proposed to assess how close the mean of the sampling distribution is to the ground truth. To compute this, we generate a set of samples <math id="S4.SS1.SSS0.Px4.p1.1.m1.4" class="ltx_Math" alttext="S=\{\hat{x_{1}},\hat{x_{2}},...,\hat{x_{10}}\}" display="inline"><semantics id="S4.SS1.SSS0.Px4.p1.1.m1.4a"><mrow id="S4.SS1.SSS0.Px4.p1.1.m1.4.5" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.cmml"><mi id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.2.cmml">S</mi><mo id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.1.cmml">=</mo><mrow id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.2.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.1.cmml">{</mo><mover accent="true" id="S4.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml"><msub id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.2.cmml">x</mi><mn id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1.cmml">^</mo></mover><mo id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.1.cmml">,</mo><mover accent="true" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.cmml"><msub id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.2.cmml">x</mi><mn id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.cmml">^</mo></mover><mo id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.2.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S4.SS1.SSS0.Px4.p1.1.m1.3.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.cmml">â€¦</mi><mo id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.2.4" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.1.cmml">,</mo><mover accent="true" id="S4.SS1.SSS0.Px4.p1.1.m1.4.4" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.cmml"><msub id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.2.cmml">x</mi><mn id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.3.cmml">10</mn></msub><mo id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.1.cmml">^</mo></mover><mo stretchy="false" id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.2.5" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.1.m1.4b"><apply id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5"><eq id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.1"></eq><ci id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.2">ğ‘†</ci><set id="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.5.3.2"><apply id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1"><ci id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.1">^</ci><apply id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.2">ğ‘¥</ci><cn type="integer" id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.3.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.2.3">1</cn></apply></apply><apply id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2"><ci id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1">^</ci><apply id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.2">ğ‘¥</ci><cn type="integer" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.3.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.3">2</cn></apply></apply><ci id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3">â€¦</ci><apply id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4"><ci id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.1">^</ci><apply id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.2">ğ‘¥</ci><cn type="integer" id="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.3.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.4.4.2.3">10</cn></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.1.m1.4c">S=\{\hat{x_{1}},\hat{x_{2}},...,\hat{x_{10}}\}</annotation></semantics></math>. For each test audio, we generate <math id="S4.SS1.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS1.SSS0.Px4.p1.2.m2.1a"><mn id="S4.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.2.m2.1b"><cn type="integer" id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.2.m2.1c">10</annotation></semantics></math> motion sequences and calculate the mean, <math id="S4.SS1.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="E(\hat{x})" display="inline"><semantics id="S4.SS1.SSS0.Px4.p1.3.m3.1a"><mrow id="S4.SS1.SSS0.Px4.p1.3.m3.1.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.3.m3.1.2.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS0.Px4.p1.3.m3.1.2.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.2.1.cmml">â€‹</mo><mrow id="S4.SS1.SSS0.Px4.p1.3.m3.1.2.3.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml"><mo stretchy="false" id="S4.SS1.SSS0.Px4.p1.3.m3.1.2.3.2.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml">(</mo><mover accent="true" id="S4.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.2.cmml">x</mi><mo id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S4.SS1.SSS0.Px4.p1.3.m3.1.2.3.2.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.3.m3.1b"><apply id="S4.SS1.SSS0.Px4.p1.3.m3.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.2"><times id="S4.SS1.SSS0.Px4.p1.3.m3.1.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.2.1"></times><ci id="S4.SS1.SSS0.Px4.p1.3.m3.1.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.2.2">ğ¸</ci><apply id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.2.3.2"><ci id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.1">^</ci><ci id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.2">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.3.m3.1c">E(\hat{x})</annotation></semantics></math> of these 10 samples. Then we compute the MEE using Eq.(<a href="#S4.E8" title="In MEE â€£ 4.1. Quantitative Evaluation â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>) for all the test sequences and take the average across the number of test sequences. A smaller MEE indicates that the model is more effective at generating ground truth lip movements. This metric is more suitable for probabilistic and non-deterministic models because it considers a set of samples instead of one sample.</p>
<table id="S4.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(8)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E8.m1.3" class="ltx_Math" alttext="\text{MEE}=\text{LVE}(x,E(\hat{x}))" display="block"><semantics id="S4.E8.m1.3a"><mrow id="S4.E8.m1.3.3" xref="S4.E8.m1.3.3.cmml"><mtext id="S4.E8.m1.3.3.3" xref="S4.E8.m1.3.3.3a.cmml">MEE</mtext><mo id="S4.E8.m1.3.3.2" xref="S4.E8.m1.3.3.2.cmml">=</mo><mrow id="S4.E8.m1.3.3.1" xref="S4.E8.m1.3.3.1.cmml"><mtext id="S4.E8.m1.3.3.1.3" xref="S4.E8.m1.3.3.1.3a.cmml">LVE</mtext><mo lspace="0em" rspace="0em" id="S4.E8.m1.3.3.1.2" xref="S4.E8.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S4.E8.m1.3.3.1.1.1" xref="S4.E8.m1.3.3.1.1.2.cmml"><mo stretchy="false" id="S4.E8.m1.3.3.1.1.1.2" xref="S4.E8.m1.3.3.1.1.2.cmml">(</mo><mi id="S4.E8.m1.2.2" xref="S4.E8.m1.2.2.cmml">x</mi><mo id="S4.E8.m1.3.3.1.1.1.3" xref="S4.E8.m1.3.3.1.1.2.cmml">,</mo><mrow id="S4.E8.m1.3.3.1.1.1.1" xref="S4.E8.m1.3.3.1.1.1.1.cmml"><mi id="S4.E8.m1.3.3.1.1.1.1.2" xref="S4.E8.m1.3.3.1.1.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E8.m1.3.3.1.1.1.1.1" xref="S4.E8.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E8.m1.3.3.1.1.1.1.3.2" xref="S4.E8.m1.1.1.cmml"><mo stretchy="false" id="S4.E8.m1.3.3.1.1.1.1.3.2.1" xref="S4.E8.m1.1.1.cmml">(</mo><mover accent="true" id="S4.E8.m1.1.1" xref="S4.E8.m1.1.1.cmml"><mi id="S4.E8.m1.1.1.2" xref="S4.E8.m1.1.1.2.cmml">x</mi><mo id="S4.E8.m1.1.1.1" xref="S4.E8.m1.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S4.E8.m1.3.3.1.1.1.1.3.2.2" xref="S4.E8.m1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E8.m1.3.3.1.1.1.4" xref="S4.E8.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E8.m1.3b"><apply id="S4.E8.m1.3.3.cmml" xref="S4.E8.m1.3.3"><eq id="S4.E8.m1.3.3.2.cmml" xref="S4.E8.m1.3.3.2"></eq><ci id="S4.E8.m1.3.3.3a.cmml" xref="S4.E8.m1.3.3.3"><mtext id="S4.E8.m1.3.3.3.cmml" xref="S4.E8.m1.3.3.3">MEE</mtext></ci><apply id="S4.E8.m1.3.3.1.cmml" xref="S4.E8.m1.3.3.1"><times id="S4.E8.m1.3.3.1.2.cmml" xref="S4.E8.m1.3.3.1.2"></times><ci id="S4.E8.m1.3.3.1.3a.cmml" xref="S4.E8.m1.3.3.1.3"><mtext id="S4.E8.m1.3.3.1.3.cmml" xref="S4.E8.m1.3.3.1.3">LVE</mtext></ci><interval closure="open" id="S4.E8.m1.3.3.1.1.2.cmml" xref="S4.E8.m1.3.3.1.1.1"><ci id="S4.E8.m1.2.2.cmml" xref="S4.E8.m1.2.2">ğ‘¥</ci><apply id="S4.E8.m1.3.3.1.1.1.1.cmml" xref="S4.E8.m1.3.3.1.1.1.1"><times id="S4.E8.m1.3.3.1.1.1.1.1.cmml" xref="S4.E8.m1.3.3.1.1.1.1.1"></times><ci id="S4.E8.m1.3.3.1.1.1.1.2.cmml" xref="S4.E8.m1.3.3.1.1.1.1.2">ğ¸</ci><apply id="S4.E8.m1.1.1.cmml" xref="S4.E8.m1.3.3.1.1.1.1.3.2"><ci id="S4.E8.m1.1.1.1.cmml" xref="S4.E8.m1.1.1.1">^</ci><ci id="S4.E8.m1.1.1.2.cmml" xref="S4.E8.m1.1.1.2">ğ‘¥</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m1.3c">\text{MEE}=\text{LVE}(x,E(\hat{x}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S4.SS1.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">CE</h5>

<div id="S4.SS1.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px5.p1.2" class="ltx_p">Coverage Error measures how close the sampling distribution of a probabilistic model is to the ground truth <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>)</cite>. In order to calculate CE for one test sequence, we generate <math id="S4.SS1.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS1.SSS0.Px5.p1.1.m1.1a"><mi id="S4.SS1.SSS0.Px5.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px5.p1.1.m1.1b"><ci id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px5.p1.1.m1.1c">S</annotation></semantics></math> containing <math id="S4.SS1.SSS0.Px5.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS1.SSS0.Px5.p1.2.m2.1a"><mn id="S4.SS1.SSS0.Px5.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px5.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px5.p1.2.m2.1b"><cn type="integer" id="S4.SS1.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px5.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px5.p1.2.m2.1c">10</annotation></semantics></math> samples similar to MEE using our model and take the minimum of LVE calculation between ground truth and generated samples using Eq.(<a href="#S4.E9" title="In CE â€£ 4.1. Quantitative Evaluation â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>). Taking the mean of CE over all test sequences yields the final CE in Tab.<a href="#S3.T1" title="Table 1 â€£ 3.4. Comparison Model: VAE Based â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. A probabilistic model with a smaller CE has predictions that cover the ground truth samples in terms of lip motion.</p>
</div>
<div id="S4.SS1.SSS0.Px5.p2" class="ltx_para">
<table id="S4.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(9)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E9.m1.2" class="ltx_Math" alttext="\text{CE}=\underset{\hat{x}\in S}{\min}\ \text{LVE}(x,\hat{x})" display="block"><semantics id="S4.E9.m1.2a"><mrow id="S4.E9.m1.2.3" xref="S4.E9.m1.2.3.cmml"><mtext id="S4.E9.m1.2.3.2" xref="S4.E9.m1.2.3.2a.cmml">CE</mtext><mo id="S4.E9.m1.2.3.1" xref="S4.E9.m1.2.3.1.cmml">=</mo><mrow id="S4.E9.m1.2.3.3" xref="S4.E9.m1.2.3.3.cmml"><munder accentunder="true" id="S4.E9.m1.2.3.3.2" xref="S4.E9.m1.2.3.3.2.cmml"><mi id="S4.E9.m1.2.3.3.2.2" xref="S4.E9.m1.2.3.3.2.2.cmml">min</mi><mrow id="S4.E9.m1.2.3.3.2.1" xref="S4.E9.m1.2.3.3.2.1.cmml"><mover accent="true" id="S4.E9.m1.2.3.3.2.1.2" xref="S4.E9.m1.2.3.3.2.1.2.cmml"><mi id="S4.E9.m1.2.3.3.2.1.2.2" xref="S4.E9.m1.2.3.3.2.1.2.2.cmml">x</mi><mo id="S4.E9.m1.2.3.3.2.1.2.1" xref="S4.E9.m1.2.3.3.2.1.2.1.cmml">^</mo></mover><mo id="S4.E9.m1.2.3.3.2.1.1" xref="S4.E9.m1.2.3.3.2.1.1.cmml">âˆˆ</mo><mi id="S4.E9.m1.2.3.3.2.1.3" xref="S4.E9.m1.2.3.3.2.1.3.cmml">S</mi></mrow></munder><mo lspace="0.167em" rspace="0em" id="S4.E9.m1.2.3.3.1" xref="S4.E9.m1.2.3.3.1.cmml">â€‹</mo><mtext id="S4.E9.m1.2.3.3.3" xref="S4.E9.m1.2.3.3.3a.cmml">LVE</mtext><mo lspace="0em" rspace="0em" id="S4.E9.m1.2.3.3.1a" xref="S4.E9.m1.2.3.3.1.cmml">â€‹</mo><mrow id="S4.E9.m1.2.3.3.4.2" xref="S4.E9.m1.2.3.3.4.1.cmml"><mo stretchy="false" id="S4.E9.m1.2.3.3.4.2.1" xref="S4.E9.m1.2.3.3.4.1.cmml">(</mo><mi id="S4.E9.m1.1.1" xref="S4.E9.m1.1.1.cmml">x</mi><mo id="S4.E9.m1.2.3.3.4.2.2" xref="S4.E9.m1.2.3.3.4.1.cmml">,</mo><mover accent="true" id="S4.E9.m1.2.2" xref="S4.E9.m1.2.2.cmml"><mi id="S4.E9.m1.2.2.2" xref="S4.E9.m1.2.2.2.cmml">x</mi><mo id="S4.E9.m1.2.2.1" xref="S4.E9.m1.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S4.E9.m1.2.3.3.4.2.3" xref="S4.E9.m1.2.3.3.4.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E9.m1.2b"><apply id="S4.E9.m1.2.3.cmml" xref="S4.E9.m1.2.3"><eq id="S4.E9.m1.2.3.1.cmml" xref="S4.E9.m1.2.3.1"></eq><ci id="S4.E9.m1.2.3.2a.cmml" xref="S4.E9.m1.2.3.2"><mtext id="S4.E9.m1.2.3.2.cmml" xref="S4.E9.m1.2.3.2">CE</mtext></ci><apply id="S4.E9.m1.2.3.3.cmml" xref="S4.E9.m1.2.3.3"><times id="S4.E9.m1.2.3.3.1.cmml" xref="S4.E9.m1.2.3.3.1"></times><apply id="S4.E9.m1.2.3.3.2.cmml" xref="S4.E9.m1.2.3.3.2"><apply id="S4.E9.m1.2.3.3.2.1.cmml" xref="S4.E9.m1.2.3.3.2.1"><in id="S4.E9.m1.2.3.3.2.1.1.cmml" xref="S4.E9.m1.2.3.3.2.1.1"></in><apply id="S4.E9.m1.2.3.3.2.1.2.cmml" xref="S4.E9.m1.2.3.3.2.1.2"><ci id="S4.E9.m1.2.3.3.2.1.2.1.cmml" xref="S4.E9.m1.2.3.3.2.1.2.1">^</ci><ci id="S4.E9.m1.2.3.3.2.1.2.2.cmml" xref="S4.E9.m1.2.3.3.2.1.2.2">ğ‘¥</ci></apply><ci id="S4.E9.m1.2.3.3.2.1.3.cmml" xref="S4.E9.m1.2.3.3.2.1.3">ğ‘†</ci></apply><min id="S4.E9.m1.2.3.3.2.2.cmml" xref="S4.E9.m1.2.3.3.2.2"></min></apply><ci id="S4.E9.m1.2.3.3.3a.cmml" xref="S4.E9.m1.2.3.3.3"><mtext id="S4.E9.m1.2.3.3.3.cmml" xref="S4.E9.m1.2.3.3.3">LVE</mtext></ci><interval closure="open" id="S4.E9.m1.2.3.3.4.1.cmml" xref="S4.E9.m1.2.3.3.4.2"><ci id="S4.E9.m1.1.1.cmml" xref="S4.E9.m1.1.1">ğ‘¥</ci><apply id="S4.E9.m1.2.2.cmml" xref="S4.E9.m1.2.2"><ci id="S4.E9.m1.2.2.1.cmml" xref="S4.E9.m1.2.2.1">^</ci><ci id="S4.E9.m1.2.2.2.cmml" xref="S4.E9.m1.2.2.2">ğ‘¥</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m1.2c">\text{CE}=\underset{\hat{x}\in S}{\min}\ \text{LVE}(x,\hat{x})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F5.30" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:434.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(19.2pt,-19.3pt) scale(1.09739523041183,1.09739523041183) ;">
<table id="S4.F5.30.30" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F5.30.30.31.1" class="ltx_tr">
<td id="S4.F5.30.30.31.1.1" class="ltx_td"></td>
<th id="S4.F5.30.30.31.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F5.30.30.31.1.2.1" class="ltx_text" style="color:#FF8000;">p</span>rice</th>
<th id="S4.F5.30.30.31.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F5.30.30.31.1.3.1" class="ltx_text" style="color:#FF8000;">str</span>anger</th>
<th id="S4.F5.30.30.31.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F5.30.30.31.1.4.1" class="ltx_text" style="color:#FF8000;">m</span>an</th>
<th id="S4.F5.30.30.31.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F5.30.30.31.1.5.1" class="ltx_text" style="color:#FF8000;">w</span>as</th>
<th id="S4.F5.30.30.31.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F5.30.30.31.1.6.1" class="ltx_text" style="color:#FF8000;">dr</span>unk</th>
<th id="S4.F5.30.30.31.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.F5.30.30.31.1.7.1" class="ltx_text" style="color:#FF8000;">how</span></th>
</tr>
<tr id="S4.F5.6.6.6" class="ltx_tr">
<th id="S4.F5.6.6.6.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F5.6.6.6.7.1" class="ltx_text" style="position:relative; bottom:50.0pt;">GT</span></th>
<td id="S4.F5.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_gt/14_price.png" id="S4.F5.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.2.2.2.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_gt/142_stranger.png" id="S4.F5.2.2.2.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.3.3.3.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_gt/20_man.png" id="S4.F5.3.3.3.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.4.4.4.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_gt/27_was.png" id="S4.F5.4.4.4.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.5.5.5.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_gt/42_drunk.png" id="S4.F5.5.5.5.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.6.6.6.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_gt/91_how.png" id="S4.F5.6.6.6.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F5.12.12.12" class="ltx_tr">
<th id="S4.F5.12.12.12.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F5.12.12.12.7.1" class="ltx_text" style="position:relative; bottom:50.0pt;">VAE based</span></th>
<td id="S4.F5.7.7.7.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vae/14_price.png" id="S4.F5.7.7.7.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.8.8.8.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vae/142_stranger.png" id="S4.F5.8.8.8.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.9.9.9.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vae/20_man.png" id="S4.F5.9.9.9.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.10.10.10.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vae/27_was.png" id="S4.F5.10.10.10.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.11.11.11.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vae/42_drunk.png" id="S4.F5.11.11.11.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.12.12.12.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vae/91_how.png" id="S4.F5.12.12.12.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F5.18.18.18" class="ltx_tr">
<th id="S4.F5.18.18.18.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F5.18.18.18.7.1" class="ltx_text" style="position:relative; bottom:50.0pt;">FaceDiffuser</span></th>
<td id="S4.F5.13.13.13.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_facediffuser/14_price.png" id="S4.F5.13.13.13.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="98" alt="Refer to caption"></td>
<td id="S4.F5.14.14.14.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_facediffuser/142_stranger.png" id="S4.F5.14.14.14.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="96" alt="Refer to caption"></td>
<td id="S4.F5.15.15.15.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_facediffuser/20_man.png" id="S4.F5.15.15.15.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.16.16.16.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_facediffuser/27_was.png" id="S4.F5.16.16.16.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.17.17.17.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_facediffuser/42_drunk.png" id="S4.F5.17.17.17.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.18.18.18.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_facediffuser/91_how.png" id="S4.F5.18.18.18.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F5.24.24.24" class="ltx_tr">
<th id="S4.F5.24.24.24.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F5.24.24.24.7.1" class="ltx_text" style="position:relative; bottom:50.0pt;">EMOTE</span></th>
<td id="S4.F5.19.19.19.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_emote/14_price.png" id="S4.F5.19.19.19.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.20.20.20.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_emote/142_stranger.png" id="S4.F5.20.20.20.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.21.21.21.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_emote/20_man.png" id="S4.F5.21.21.21.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.22.22.22.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_emote/27_was.png" id="S4.F5.22.22.22.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.23.23.23.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_emote/42_drunk.png" id="S4.F5.23.23.23.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.24.24.24.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_emote/91_how.png" id="S4.F5.24.24.24.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F5.30.30.30" class="ltx_tr">
<th id="S4.F5.30.30.30.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F5.30.30.30.7.1" class="ltx_text" style="position:relative; bottom:50.0pt;">ProbTalk3D</span></th>
<td id="S4.F5.25.25.25.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vq/14_price.png" id="S4.F5.25.25.25.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.26.26.26.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vq/142_stranger.png" id="S4.F5.26.26.26.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.27.27.27.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vq/20_man.png" id="S4.F5.27.27.27.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.28.28.28.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vq/27_was.png" id="S4.F5.28.28.28.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.29.29.29.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vq/42_drunk.png" id="S4.F5.29.29.29.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F5.30.30.30.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/quality_vq/91_how.png" id="S4.F5.30.30.30.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.32.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>. </span><span id="S4.F5.33.2" class="ltx_text" style="font-size:90%;">Visual comparison of generated facial animations by different models together with ground truth (GT).</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S4.F5.34" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.F5.35" class="ltx_p ltx_figure_panel ltx_align_center">Visual comparisons of generated facial motions by different models</p>
</div>
</div>
</figure>
</section>
<section id="S4.SS1.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Diversity</h5>

<div id="S4.SS1.SSS0.Px6.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px6.p1.9" class="ltx_p">To assess diversity, we adopt the concept proposed in <cite class="ltx_cite ltx_citemacro_citep">(Ren etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>. It was originally introduced for analyzing synthesized human motions and subsequently adapted for evaluating facial animations in DiffPoseTalk <cite class="ltx_cite ltx_citemacro_citep">(Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2024</a>)</cite> and 3DiFACE <cite class="ltx_cite ltx_citemacro_citep">(Thambiraja etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2023b</a>)</cite>. We aim to quantify diversity under an identical set of input conditions. Given <math id="S4.SS1.SSS0.Px6.p1.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.1.m1.1a"><mi id="S4.SS1.SSS0.Px6.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.1.m1.1b"><ci id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.1.m1.1c">A</annotation></semantics></math> audio inputs, we generate a set of facial animations comprising 10 samples for each audio, all guided by the same control signals. For the <math id="S4.SS1.SSS0.Px6.p1.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.2.m2.1a"><mi id="S4.SS1.SSS0.Px6.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.2.m2.1b"><ci id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.2.m2.1c">i</annotation></semantics></math>-th audio input, we randomly sample two subsets, each containing <math id="S4.SS1.SSS0.Px6.p1.3.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.3.m3.1a"><mi id="S4.SS1.SSS0.Px6.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.3.m3.1b"><ci id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.3.m3.1c">B</annotation></semantics></math> samples from the generated animation set. In our analysis, <math id="S4.SS1.SSS0.Px6.p1.4.m4.1" class="ltx_Math" alttext="A=1909" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.4.m4.1a"><mrow id="S4.SS1.SSS0.Px6.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.cmml"><mi id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.2" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.2.cmml">A</mi><mo id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.1" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.3" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.3.cmml">1909</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.4.m4.1b"><apply id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1"><eq id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.1"></eq><ci id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.2">ğ´</ci><cn type="integer" id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.3">1909</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.4.m4.1c">A=1909</annotation></semantics></math> (i.e. test set audios) and <math id="S4.SS1.SSS0.Px6.p1.5.m5.1" class="ltx_Math" alttext="B=5" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.5.m5.1a"><mrow id="S4.SS1.SSS0.Px6.p1.5.m5.1.1" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.cmml"><mi id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.2" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.2.cmml">B</mi><mo id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.1" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.5.m5.1b"><apply id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1"><eq id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.1"></eq><ci id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.2">ğµ</ci><cn type="integer" id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.5.m5.1c">B=5</annotation></semantics></math> (10 generated samples randomly split into two subsets <math id="S4.SS1.SSS0.Px6.p1.6.m6.1" class="ltx_Math" alttext="S_{1}" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.6.m6.1a"><msub id="S4.SS1.SSS0.Px6.p1.6.m6.1.1" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.cmml"><mi id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.2" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.2.cmml">S</mi><mn id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.6.m6.1b"><apply id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.2">ğ‘†</ci><cn type="integer" id="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.6.m6.1c">S_{1}</annotation></semantics></math> and <math id="S4.SS1.SSS0.Px6.p1.7.m7.1" class="ltx_Math" alttext="S_{2}" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.7.m7.1a"><msub id="S4.SS1.SSS0.Px6.p1.7.m7.1.1" xref="S4.SS1.SSS0.Px6.p1.7.m7.1.1.cmml"><mi id="S4.SS1.SSS0.Px6.p1.7.m7.1.1.2" xref="S4.SS1.SSS0.Px6.p1.7.m7.1.1.2.cmml">S</mi><mn id="S4.SS1.SSS0.Px6.p1.7.m7.1.1.3" xref="S4.SS1.SSS0.Px6.p1.7.m7.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.7.m7.1b"><apply id="S4.SS1.SSS0.Px6.p1.7.m7.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.7.m7.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.7.m7.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.7.m7.1.1.2">ğ‘†</ci><cn type="integer" id="S4.SS1.SSS0.Px6.p1.7.m7.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.7.m7.1c">S_{2}</annotation></semantics></math> of 5 samples). Subsequently, we compute the average euclidean difference between the <math id="S4.SS1.SSS0.Px6.p1.8.m8.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.8.m8.1a"><mi id="S4.SS1.SSS0.Px6.p1.8.m8.1.1" xref="S4.SS1.SSS0.Px6.p1.8.m8.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.8.m8.1b"><ci id="S4.SS1.SSS0.Px6.p1.8.m8.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.8.m8.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.8.m8.1c">j</annotation></semantics></math>-th sample within the two subsets. This process is repeated for all <math id="S4.SS1.SSS0.Px6.p1.9.m9.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.SSS0.Px6.p1.9.m9.1a"><mi id="S4.SS1.SSS0.Px6.p1.9.m9.1.1" xref="S4.SS1.SSS0.Px6.p1.9.m9.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.9.m9.1b"><ci id="S4.SS1.SSS0.Px6.p1.9.m9.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.9.m9.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.9.m9.1c">A</annotation></semantics></math> audio inputs, and the mean value is calculated as the final result. The diversity metric is formalized as:</p>
<table id="S4.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(10)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E10.m1.5" class="ltx_Math" alttext="\text{Diversity}=\frac{1}{A\times B}\sum_{i=1}^{A}\sum_{j=1}^{B}\|(\hat{x}_{i,j}\in S_{1})-(\hat{x}_{i,j}\in S_{2})\|_{2}" display="block"><semantics id="S4.E10.m1.5a"><mrow id="S4.E10.m1.5.5" xref="S4.E10.m1.5.5.cmml"><mtext id="S4.E10.m1.5.5.3" xref="S4.E10.m1.5.5.3a.cmml">Diversity</mtext><mo id="S4.E10.m1.5.5.2" xref="S4.E10.m1.5.5.2.cmml">=</mo><mrow id="S4.E10.m1.5.5.1" xref="S4.E10.m1.5.5.1.cmml"><mfrac id="S4.E10.m1.5.5.1.3" xref="S4.E10.m1.5.5.1.3.cmml"><mn id="S4.E10.m1.5.5.1.3.2" xref="S4.E10.m1.5.5.1.3.2.cmml">1</mn><mrow id="S4.E10.m1.5.5.1.3.3" xref="S4.E10.m1.5.5.1.3.3.cmml"><mi id="S4.E10.m1.5.5.1.3.3.2" xref="S4.E10.m1.5.5.1.3.3.2.cmml">A</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E10.m1.5.5.1.3.3.1" xref="S4.E10.m1.5.5.1.3.3.1.cmml">Ã—</mo><mi id="S4.E10.m1.5.5.1.3.3.3" xref="S4.E10.m1.5.5.1.3.3.3.cmml">B</mi></mrow></mfrac><mo lspace="0em" rspace="0em" id="S4.E10.m1.5.5.1.2" xref="S4.E10.m1.5.5.1.2.cmml">â€‹</mo><mrow id="S4.E10.m1.5.5.1.1" xref="S4.E10.m1.5.5.1.1.cmml"><munderover id="S4.E10.m1.5.5.1.1.2" xref="S4.E10.m1.5.5.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S4.E10.m1.5.5.1.1.2.2.2" xref="S4.E10.m1.5.5.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E10.m1.5.5.1.1.2.2.3" xref="S4.E10.m1.5.5.1.1.2.2.3.cmml"><mi id="S4.E10.m1.5.5.1.1.2.2.3.2" xref="S4.E10.m1.5.5.1.1.2.2.3.2.cmml">i</mi><mo id="S4.E10.m1.5.5.1.1.2.2.3.1" xref="S4.E10.m1.5.5.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E10.m1.5.5.1.1.2.2.3.3" xref="S4.E10.m1.5.5.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E10.m1.5.5.1.1.2.3" xref="S4.E10.m1.5.5.1.1.2.3.cmml">A</mi></munderover><mrow id="S4.E10.m1.5.5.1.1.1" xref="S4.E10.m1.5.5.1.1.1.cmml"><munderover id="S4.E10.m1.5.5.1.1.1.2" xref="S4.E10.m1.5.5.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S4.E10.m1.5.5.1.1.1.2.2.2" xref="S4.E10.m1.5.5.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E10.m1.5.5.1.1.1.2.2.3" xref="S4.E10.m1.5.5.1.1.1.2.2.3.cmml"><mi id="S4.E10.m1.5.5.1.1.1.2.2.3.2" xref="S4.E10.m1.5.5.1.1.1.2.2.3.2.cmml">j</mi><mo id="S4.E10.m1.5.5.1.1.1.2.2.3.1" xref="S4.E10.m1.5.5.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E10.m1.5.5.1.1.1.2.2.3.3" xref="S4.E10.m1.5.5.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E10.m1.5.5.1.1.1.2.3" xref="S4.E10.m1.5.5.1.1.1.2.3.cmml">B</mi></munderover><msub id="S4.E10.m1.5.5.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.cmml"><mrow id="S4.E10.m1.5.5.1.1.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E10.m1.5.5.1.1.1.1.1.1.2" xref="S4.E10.m1.5.5.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S4.E10.m1.5.5.1.1.1.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.cmml"><mrow id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">x</mi><mo id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mrow id="S4.E10.m1.2.2.2.4" xref="S4.E10.m1.2.2.2.3.cmml"><mi id="S4.E10.m1.1.1.1.1" xref="S4.E10.m1.1.1.1.1.cmml">i</mi><mo id="S4.E10.m1.2.2.2.4.1" xref="S4.E10.m1.2.2.2.3.cmml">,</mo><mi id="S4.E10.m1.2.2.2.2" xref="S4.E10.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">âˆˆ</mo><msub id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.2.cmml">S</mi><mn id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo stretchy="false" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E10.m1.5.5.1.1.1.1.1.1.1.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.3.cmml">âˆ’</mo><mrow id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.cmml"><mo stretchy="false" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.cmml"><msub id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.cmml"><mover accent="true" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.cmml"><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml">x</mi><mo id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml">^</mo></mover><mrow id="S4.E10.m1.4.4.2.4" xref="S4.E10.m1.4.4.2.3.cmml"><mi id="S4.E10.m1.3.3.1.1" xref="S4.E10.m1.3.3.1.1.cmml">i</mi><mo id="S4.E10.m1.4.4.2.4.1" xref="S4.E10.m1.4.4.2.3.cmml">,</mo><mi id="S4.E10.m1.4.4.2.2" xref="S4.E10.m1.4.4.2.2.cmml">j</mi></mrow></msub><mo id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.1" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.1.cmml">âˆˆ</mo><msub id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.cmml"><mi id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.2" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.2.cmml">S</mi><mn id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.3.cmml">2</mn></msub></mrow><mo stretchy="false" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.3" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E10.m1.5.5.1.1.1.1.1.1.3" xref="S4.E10.m1.5.5.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S4.E10.m1.5.5.1.1.1.1.3" xref="S4.E10.m1.5.5.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E10.m1.5b"><apply id="S4.E10.m1.5.5.cmml" xref="S4.E10.m1.5.5"><eq id="S4.E10.m1.5.5.2.cmml" xref="S4.E10.m1.5.5.2"></eq><ci id="S4.E10.m1.5.5.3a.cmml" xref="S4.E10.m1.5.5.3"><mtext id="S4.E10.m1.5.5.3.cmml" xref="S4.E10.m1.5.5.3">Diversity</mtext></ci><apply id="S4.E10.m1.5.5.1.cmml" xref="S4.E10.m1.5.5.1"><times id="S4.E10.m1.5.5.1.2.cmml" xref="S4.E10.m1.5.5.1.2"></times><apply id="S4.E10.m1.5.5.1.3.cmml" xref="S4.E10.m1.5.5.1.3"><divide id="S4.E10.m1.5.5.1.3.1.cmml" xref="S4.E10.m1.5.5.1.3"></divide><cn type="integer" id="S4.E10.m1.5.5.1.3.2.cmml" xref="S4.E10.m1.5.5.1.3.2">1</cn><apply id="S4.E10.m1.5.5.1.3.3.cmml" xref="S4.E10.m1.5.5.1.3.3"><times id="S4.E10.m1.5.5.1.3.3.1.cmml" xref="S4.E10.m1.5.5.1.3.3.1"></times><ci id="S4.E10.m1.5.5.1.3.3.2.cmml" xref="S4.E10.m1.5.5.1.3.3.2">ğ´</ci><ci id="S4.E10.m1.5.5.1.3.3.3.cmml" xref="S4.E10.m1.5.5.1.3.3.3">ğµ</ci></apply></apply><apply id="S4.E10.m1.5.5.1.1.cmml" xref="S4.E10.m1.5.5.1.1"><apply id="S4.E10.m1.5.5.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.2.1.cmml" xref="S4.E10.m1.5.5.1.1.2">superscript</csymbol><apply id="S4.E10.m1.5.5.1.1.2.2.cmml" xref="S4.E10.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.2.2.1.cmml" xref="S4.E10.m1.5.5.1.1.2">subscript</csymbol><sum id="S4.E10.m1.5.5.1.1.2.2.2.cmml" xref="S4.E10.m1.5.5.1.1.2.2.2"></sum><apply id="S4.E10.m1.5.5.1.1.2.2.3.cmml" xref="S4.E10.m1.5.5.1.1.2.2.3"><eq id="S4.E10.m1.5.5.1.1.2.2.3.1.cmml" xref="S4.E10.m1.5.5.1.1.2.2.3.1"></eq><ci id="S4.E10.m1.5.5.1.1.2.2.3.2.cmml" xref="S4.E10.m1.5.5.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S4.E10.m1.5.5.1.1.2.2.3.3.cmml" xref="S4.E10.m1.5.5.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E10.m1.5.5.1.1.2.3.cmml" xref="S4.E10.m1.5.5.1.1.2.3">ğ´</ci></apply><apply id="S4.E10.m1.5.5.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1"><apply id="S4.E10.m1.5.5.1.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.2.1.cmml" xref="S4.E10.m1.5.5.1.1.1.2">superscript</csymbol><apply id="S4.E10.m1.5.5.1.1.1.2.2.cmml" xref="S4.E10.m1.5.5.1.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.2.2.1.cmml" xref="S4.E10.m1.5.5.1.1.1.2">subscript</csymbol><sum id="S4.E10.m1.5.5.1.1.1.2.2.2.cmml" xref="S4.E10.m1.5.5.1.1.1.2.2.2"></sum><apply id="S4.E10.m1.5.5.1.1.1.2.2.3.cmml" xref="S4.E10.m1.5.5.1.1.1.2.2.3"><eq id="S4.E10.m1.5.5.1.1.1.2.2.3.1.cmml" xref="S4.E10.m1.5.5.1.1.1.2.2.3.1"></eq><ci id="S4.E10.m1.5.5.1.1.1.2.2.3.2.cmml" xref="S4.E10.m1.5.5.1.1.1.2.2.3.2">ğ‘—</ci><cn type="integer" id="S4.E10.m1.5.5.1.1.1.2.2.3.3.cmml" xref="S4.E10.m1.5.5.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E10.m1.5.5.1.1.1.2.3.cmml" xref="S4.E10.m1.5.5.1.1.1.2.3">ğµ</ci></apply><apply id="S4.E10.m1.5.5.1.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1">subscript</csymbol><apply id="S4.E10.m1.5.5.1.1.1.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E10.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.2">norm</csymbol><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1"><minus id="S4.E10.m1.5.5.1.1.1.1.1.1.1.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.3"></minus><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1"><in id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.1"></in><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2"><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.2.2.2">ğ‘¥</ci></apply><list id="S4.E10.m1.2.2.2.3.cmml" xref="S4.E10.m1.2.2.2.4"><ci id="S4.E10.m1.1.1.1.1.cmml" xref="S4.E10.m1.1.1.1.1">ğ‘–</ci><ci id="S4.E10.m1.2.2.2.2.cmml" xref="S4.E10.m1.2.2.2.2">ğ‘—</ci></list></apply><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘†</ci><cn type="integer" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1"><in id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.1"></in><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2">subscript</csymbol><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2"><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.1">^</ci><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.2.2.2">ğ‘¥</ci></apply><list id="S4.E10.m1.4.4.2.3.cmml" xref="S4.E10.m1.4.4.2.4"><ci id="S4.E10.m1.3.3.1.1.cmml" xref="S4.E10.m1.3.3.1.1">ğ‘–</ci><ci id="S4.E10.m1.4.4.2.2.cmml" xref="S4.E10.m1.4.4.2.2">ğ‘—</ci></list></apply><apply id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.1.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.2.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.2">ğ‘†</ci><cn type="integer" id="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.1.1.1.2.1.1.3.3">2</cn></apply></apply></apply></apply><cn type="integer" id="S4.E10.m1.5.5.1.1.1.1.3.cmml" xref="S4.E10.m1.5.5.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E10.m1.5c">\text{Diversity}=\frac{1}{A\times B}\sum_{i=1}^{A}\sum_{j=1}^{B}\|(\hat{x}_{i,j}\in S_{1})-(\hat{x}_{i,j}\in S_{2})\|_{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.SSS0.Px6.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px6.p2.1" class="ltx_p">The comparative analysis among the models using the quantitative metrics is presented in Tab.<a href="#S3.T1" title="Table 1 â€£ 3.4. Comparison Model: VAE Based â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. We can observe that ProbTalk3D scores significantly higher on the Diversity metric in comparison to VAE-based and Diffusion-based models. ProbTalk3D have similar values for MVE, LVE, MEE, and CE metrics in comparison to the VAE-based model while producing significantly better results than the original FaceDiffuser (with DDPM). The MVE, LVE, and FDD metrics which are calculated based on a single output sample demonstrate that the VAE-based method achieves slightly better results than ProbTalk3D, although pretty close. We argue that the MEE and CE metrics provide a better indication of lip movement accuracy for probabilistic models in comparison to LVE. VAE-based model and ProbTalk3D come closer to each other on these two metrics. FaceDiffuser-DDIM performs best on lip-sync related measures LVE, MEE and CE, while it performs worse than ProbTalk3D and VAE-based model for the whole face animation, upper face dynamics (MVE and FDD) and Diversity metrics. VAE-based model has the best FDD score followed by ProbTalk3D. The two models we present in this paper, ProbTalk3D and VAE-based model, produce the best results in terms of diversity and whole face animation related metrics while being comparable to FaceDiffuser on lip-related metrics. Non-deterministic methods produce better results than deterministic methods overall.</p>
</div>
<div id="S4.SS1.SSS0.Px6.p3" class="ltx_para">
<p id="S4.SS1.SSS0.Px6.p3.1" class="ltx_p">The results points out to a trade-off between lip-sync accuracy, whole face animation, facial dynamics and Diversity metric. ProbTalk3D trades off some accuracy compared to the ground truth while achieving higher diversity. This accuracy-diversity trade-off for non-deterministic approaches was also observed and presented in <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F6.11" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:174.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(6.0pt,-2.7pt) scale(1.03170142000175,1.03170142000175) ;">
<table id="S4.F6.11.11" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F6.5.5.5" class="ltx_tr">
<td id="S4.F6.5.5.5.6" class="ltx_td ltx_align_center"><span id="S4.F6.5.5.5.6.1" class="ltx_text" style="position:relative; bottom:50.0pt;">MEAN</span></td>
<td id="S4.F6.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_gt/M005_029_6_2_angry_gt_mean.png" id="S4.F6.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.2.2.2.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_vae/M005_029_6_2_angry_9_mean.png" id="S4.F6.2.2.2.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.3.3.3.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_facediffuser/M005_029_6_2_3DMEAD_condition_M005_6_2_mean.png" id="S4.F6.3.3.3.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.4.4.4.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_emote/M005_029_6_2_mean.png" id="S4.F6.4.4.4.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.5.5.5.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_vq/M005_029_6_2_angry_9_mean.png" id="S4.F6.5.5.5.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.5.5.5.7" class="ltx_td"></td>
</tr>
<tr id="S4.F6.11.11.11" class="ltx_tr">
<td id="S4.F6.11.11.11.7" class="ltx_td ltx_align_center"><span id="S4.F6.11.11.11.7.1" class="ltx_text" style="position:relative; bottom:50.0pt;">STD</span></td>
<td id="S4.F6.6.6.6.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_gt/M005_029_6_2_angry_gt_std.png" id="S4.F6.6.6.6.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.7.7.7.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_vae/M005_029_6_2_angry_9_std.png" id="S4.F6.7.7.7.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.8.8.8.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_facediffuser/M005_029_6_2_3DMEAD_condition_M005_6_2_std.png" id="S4.F6.8.8.8.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.9.9.9.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_emote/M005_029_6_2_std.png" id="S4.F6.9.9.9.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.10.10.10.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/heatmap_vq/M005_029_6_2_angry_9_std.png" id="S4.F6.10.10.10.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F6.11.11.11.6" class="ltx_td ltx_align_center"><svg version="1.1" fill="none" height="0" stroke="none" width="0" overflow="visible"><g transform="translate(0,0) scale(1,-1)"><g transform="translate(0,0)"><g class="makebox" transform="translate(-15.91,72.59)"><g transform="translate(0,12.453300124533) scale(1, -1)"><foreignObject width="66.417600664176" height="11.3463401134634" overflow="visible"><math id="S4.F6.11.11.11.6.pic1.1.1.m1.1" class="ltx_Math" alttext="\times 10^{-3}" display="inline"><semantics id="S4.F6.11.11.11.6.pic1.1.1.m1.1a"><mrow id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.cmml"><mi id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.2" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.1" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.1.cmml">Ã—</mo><msup id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.cmml"><mn id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.2" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3.cmml"><mo id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3a" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3.2" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.11.11.11.6.pic1.1.1.m1.1b"><apply id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1"><times id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.1.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.1"></times><csymbol cd="latexml" id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.2.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.2">absent</csymbol><apply id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.1.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.2.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.2">10</cn><apply id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3"><minus id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3.1.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3.2.cmml" xref="S4.F6.11.11.11.6.pic1.1.1.m1.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.11.11.11.6.pic1.1.1.m1.1c">\times 10^{-3}</annotation></semantics></math></foreignObject></g><text x="0" y="0" transform="scale(1, -1)" fill="black">mm</text></g></g><g transform="translate(0,0)"><g class="makebox" transform="translate(7.76,61.27)"><g transform="translate(0,8.8556800885568) scale(1, -1)"><foreignObject width="24.6298602462986" height="8.8556800885568" overflow="visible"><math id="S4.F6.11.11.11.6.pic1.2.1.m1.1" class="ltx_Math" alttext="3.7" display="inline"><semantics id="S4.F6.11.11.11.6.pic1.2.1.m1.1a"><mn id="S4.F6.11.11.11.6.pic1.2.1.m1.1.1" xref="S4.F6.11.11.11.6.pic1.2.1.m1.1.1.cmml">3.7</mn><annotation-xml encoding="MathML-Content" id="S4.F6.11.11.11.6.pic1.2.1.m1.1b"><cn type="float" id="S4.F6.11.11.11.6.pic1.2.1.m1.1.1.cmml" xref="S4.F6.11.11.11.6.pic1.2.1.m1.1.1">3.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.11.11.11.6.pic1.2.1.m1.1c">3.7</annotation></semantics></math></foreignObject></g></g></g><g transform="translate(0,0)"><g transform="translate(0,7) scale(1, -1)"><foreignObject width="1" height="7" overflow="visible"><img src="/html/2409.07966/assets/Assets/heatmap_gt/heatmap_color.jpg" id="S4.F6.11.11.11.6.pic1.3.g1" class="ltx_graphics ltx_img_portrait" width="1" height="7" alt="Refer to caption"></foreignObject></g></g><g transform="translate(0,0)"><g class="makebox" transform="translate(10.15,-0.31)"><g transform="translate(0,8.8556800885568) scale(1, -1)"><foreignObject width="11.4847101148471" height="8.8556800885568" overflow="visible"><math id="S4.F6.11.11.11.6.pic1.4.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.F6.11.11.11.6.pic1.4.1.m1.1a"><mn id="S4.F6.11.11.11.6.pic1.4.1.m1.1.1" xref="S4.F6.11.11.11.6.pic1.4.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.F6.11.11.11.6.pic1.4.1.m1.1b"><cn type="integer" id="S4.F6.11.11.11.6.pic1.4.1.m1.1.1.cmml" xref="S4.F6.11.11.11.6.pic1.4.1.m1.1.1">0</cn></annotation-xml></semantics></math></foreignObject></g></g></g></g></svg></td>
</tr>
<tr id="S4.F6.11.11.12.1" class="ltx_tr">
<td id="S4.F6.11.11.12.1.1" class="ltx_td"></td>
<td id="S4.F6.11.11.12.1.2" class="ltx_td ltx_align_center">Ground truth</td>
<td id="S4.F6.11.11.12.1.3" class="ltx_td ltx_align_center">VAE based</td>
<td id="S4.F6.11.11.12.1.4" class="ltx_td ltx_align_center">FaceDiffuser</td>
<td id="S4.F6.11.11.12.1.5" class="ltx_td ltx_align_center">EMOTE</td>
<td id="S4.F6.11.11.12.1.6" class="ltx_td ltx_align_center">ProbTalk3D</td>
<td id="S4.F6.11.11.12.1.7" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.13.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>. </span><span id="S4.F6.14.2" class="ltx_text" style="font-size:90%;">Comparison using heatmap visualization of mean and standard deviation of generated animation by different models together with ground truth (GT) given audio sequence, uttering the sentence: â€œThe revolution now underway in materials handling makes this much easierâ€. </span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S4.F6.15" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.F6.16" class="ltx_p ltx_figure_panel ltx_align_center">Visual comparisons of generated facial motions using heatmaps.</p>
</div>
</div>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Qualitative Evaluation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For qualitative assessment, we visually compare the generated animations of different models pronouncing specific syllables, focusing on assessing the quality of lip synchronization. The syllables are chosen to assess the modelâ€™s capability in synthesizing diverse mouth shapes. This includes challenging sounds like the bilabial consonants /p/ and /m/, which require precise lip closure, as well as syllables that require a pout and sounds that demand an open-mouth posture. This quality judgement uses audio sequences that express a neutral emotion, selected from the test set of 3DMEAD. To compare our model against SOTAs, we include animations generated by the modified FaceDiffuser and the deterministic model, EMOTE. Note that we did not retrain EMOTE and utilized the publicly available trained model and inference script for motion generation. Fig.<a href="#S4.F5" title="Figure 5 â€£ CE â€£ 4.1. Quantitative Evaluation â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> showcases the results, with the ground truth provided as a reference. It can be seen from the figure that both ProbTalk3D and the VAE-based model closely resemble the ground truth, and achieve proper mouth closure. Inspecting the results of FaceDiffuser and EMOTE, we observe similar results indicating that our model performs comparable or better with respect to the recent non-deterministic and deterministic models.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">To illustrate the capability of our model in generating a wide range of facial movements, we adopt the approach used in <cite class="ltx_cite ltx_citemacro_citep">(Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>)</cite> to present facial motion dynamics through heatmap visualization. We calculate the temporal statistics of adjacent-frame facial motions within a sequence, represented by the mean and standard deviation of the <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{2}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">â„’</mi><mn id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">â„’</ci><cn type="integer" id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\mathcal{L}_{2}</annotation></semantics></math> distance between frames. A higher mean indicates more frequent facial movements, described by warmer colors in Figure <a href="#S4.F6" title="Figure 6 â€£ Diversity â€£ 4.1. Quantitative Evaluation â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Similarly, a higher standard deviation represents richer variations in facial dynamics. Fig.<a href="#S4.F6" title="Figure 6 â€£ Diversity â€£ 4.1. Quantitative Evaluation â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> demonstrates that both ProbTalk3D and the VAE-based mode can produce animations with diverse facial movements in the mouth region and the forehead. The predicted motions closely resemble the dynamics of the ground truth, showcasing the accuracy of our approaches. Furthermore, we present Fig.<a href="#S4.F7" title="Figure 7 â€£ 4.3. Perceptual User Study â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> to demonstrate our modelâ€™s capability to generate emotion-controlled facial animation. Evidently, the distinction between emotions is clear and perceptually aligns with the semantic labels.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Perceptual User Study</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We conduct A/B testing to compare our proposed modelâ€™s results against ground truth and results from SOTA models- FaceDiffuser-DDIM (non-deterministic - trained on 3DMEAD with emotion control) and EMOTE (i.e. deterministic - trained on 3DMEAD with emotion control using the publicly available model). These SOTAs have previously demonstrated superior performance compared to several earlier works. For the user study, we generate 32 videos using each model. These videos cover 8 emotions and different speaking styles, with 4 video sequences generated for each emotion. For the 7 emotions other than neutral, we create 2 videos with medium intensity and 2 with high intensity. Videos under a specific emotion are synthesized using 2 audio sequences from 3DMEAD (with identities unseen during the second stage of training) and 2 in-the-wild audio samples from the VoxMovies <cite class="ltx_cite ltx_citemacro_citep">(Brown etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2021</a>)</cite> dataset for generalizability. Additionally, we generate another set of 32 videos using our model to compare with the ground truth belonging to the unseen test-set of 3DMEAD. The survey is set to randomly choose 1 video pair within 4 pairs for each emotion. This results in a total of 24 video pairs: 8 pairs each comparing our model with- (i) the ground truth, (ii) FaceDiffuser and (iii) EMOTE.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">We use Qualtrics <cite class="ltx_cite ltx_citemacro_citep">(Qualtrics, <a href="#bib.bib44" title="" class="ltx_ref">2023</a>)</cite> as the survey tool and recruit participants through Prolific <cite class="ltx_cite ltx_citemacro_citep">(Prolific, <a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite>, ensuring proper remuneration. Participants are queried about lip synchronization, realism, and emotional expressivity after viewing each video pair, requiring them to select the one they perceive as better. In total, 73 responses are collected, with 4 responses discarded due to failing the attention test, resulting in 69 valid responses. The result of the perceptual study is reported in Tab.<a href="#S4.T2" title="Table 2 â€£ 4.3. Perceptual User Study â€£ 4. Results â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, demonstrating that our modelâ€™s output is generally less preferred than the ground truth across lip synchronization, realism, and emotional expression. This is expected and in line with other recent works. However, our model outperforms the competitors in all three aspects. The user study demonstrates the superiority of our model over the competitors, showcasing its capability to generate animations with good lip synchronization, high overall face realism, and superior emotional expressivity. More details about the user study can be found in the supplementary material.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.9.10.1" class="ltx_tr">
<td id="S4.T2.9.10.1.1" class="ltx_td"></td>
<th id="S4.T2.9.10.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T2.9.10.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Lip Sync</span></th>
<th id="S4.T2.9.10.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T2.9.10.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Realism</span></th>
<th id="S4.T2.9.10.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T2.9.10.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Emotional Expression</span></th>
</tr>
<tr id="S4.T2.3.3" class="ltx_tr">
<th id="S4.T2.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.T2.3.3.4.1" class="ltx_text" style="position:relative; bottom:5.2pt;">

<span id="S4.T2.3.3.4.1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<span id="S4.T2.3.3.4.1.1.1" class="ltx_tr">
<span id="S4.T2.3.3.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.3.3.4.1.1.1.1.1" class="ltx_text" style="color:#4D8CBF;">Ours</span> vs.  <span id="S4.T2.3.3.4.1.1.1.1.2" class="ltx_text" style="color:#008000;">GT</span></span></span>
</span></span></th>
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_center"><svg id="S4.T2.1.1.1.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 61.89 19.69 L 61.89 0 Z M 61.89 19.69" style="stroke:none"></path></g><g stroke="#ADDEAD" fill="#ADDEAD" color="#ADDEAD"><path d="M 61.89 0 M 61.89 0 L 61.89 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 13.88 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.1.1.1.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">39.31%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 92.62 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.1.1.1.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">60.69%</span></foreignObject></g></g></svg>
</td>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_center"><svg id="S4.T2.2.2.2.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 67.05 19.69 L 67.05 0 Z M 67.05 19.69" style="stroke:none"></path></g><g stroke="#ADDEAD" fill="#ADDEAD" color="#ADDEAD"><path d="M 67.05 0 M 67.05 0 L 67.05 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 16.25 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.2.2.2.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">42.57%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 94.99 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.2.2.2.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">57.43%</span></foreignObject></g></g></svg>
</td>
<td id="S4.T2.3.3.3" class="ltx_td ltx_align_center"><svg id="S4.T2.3.3.3.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 60.47 19.69 L 60.47 0 Z M 60.47 19.69" style="stroke:none"></path></g><g stroke="#ADDEAD" fill="#ADDEAD" color="#ADDEAD"><path d="M 60.47 0 M 60.47 0 L 60.47 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 13.1 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.3.3.3.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">38.41%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 91.84 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.3.3.3.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">61.59%</span></foreignObject></g></g></svg>
</td>
</tr>
<tr id="S4.T2.6.6" class="ltx_tr">
<th id="S4.T2.6.6.4" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.T2.6.6.4.1" class="ltx_text" style="position:relative; bottom:5.2pt;">

<span id="S4.T2.6.6.4.1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<span id="S4.T2.6.6.4.1.1.1" class="ltx_tr">
<span id="S4.T2.6.6.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.6.6.4.1.1.1.1.1" class="ltx_text" style="color:#4D8CBF;">Ours</span> vs.  <span id="S4.T2.6.6.4.1.1.1.1.2" class="ltx_text" style="color:#FF9999;">FaceDiffuser</span></span></span>
</span></span></th>
<td id="S4.T2.4.4.1" class="ltx_td ltx_align_center"><svg id="S4.T2.4.4.1.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 93.31 19.69 L 93.31 0 Z M 93.31 19.69" style="stroke:none"></path></g><g stroke="#FF9999" fill="#FF9999" color="#FF9999"><path d="M 93.31 0 M 93.31 0 L 93.31 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 29.24 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.4.4.1.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">59.24%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 107.98 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.4.4.1.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">40.76%</span></foreignObject></g></g></svg>
</td>
<td id="S4.T2.5.5.2" class="ltx_td ltx_align_center"><svg id="S4.T2.5.5.2.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 93.58 19.69 L 93.58 0 Z M 93.58 19.69" style="stroke:none"></path></g><g stroke="#FF9999" fill="#FF9999" color="#FF9999"><path d="M 93.58 0 M 93.58 0 L 93.58 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 29.63 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.5.5.2.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">59.42%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 108.37 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.5.5.2.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">40.58%</span></foreignObject></g></g></svg>
</td>
<td id="S4.T2.6.6.3" class="ltx_td ltx_align_center"><svg id="S4.T2.6.6.3.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 94.72 19.69 L 94.72 0 Z M 94.72 19.69" style="stroke:none"></path></g><g stroke="#FF9999" fill="#FF9999" color="#FF9999"><path d="M 94.72 0 M 94.72 0 L 94.72 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 30.02 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.6.6.3.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">60.14%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 108.76 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.6.6.3.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">39.86%</span></foreignObject></g></g></svg>
</td>
</tr>
<tr id="S4.T2.9.9" class="ltx_tr">
<th id="S4.T2.9.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.T2.9.9.4.1" class="ltx_text" style="position:relative; bottom:5.2pt;">

<span id="S4.T2.9.9.4.1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<span id="S4.T2.9.9.4.1.1.1" class="ltx_tr">
<span id="S4.T2.9.9.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.9.9.4.1.1.1.1.1" class="ltx_text" style="color:#4D8CBF;">Ours</span> vs.  <span id="S4.T2.9.9.4.1.1.1.1.2" class="ltx_text" style="color:#D9AB00;">EMOTE</span></span></span>
</span></span></th>
<td id="S4.T2.7.7.1" class="ltx_td ltx_align_center"><svg id="S4.T2.7.7.1.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 88.15 19.69 L 88.15 0 Z M 88.15 19.69" style="stroke:none"></path></g><g stroke="#FFD700" fill="#FFD700" color="#FFD700"><path d="M 88.15 0 M 88.15 0 L 88.15 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 26.87 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.7.7.1.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">55.98%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 105.62 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.7.7.1.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">44.02%</span></foreignObject></g></g></svg>
</td>
<td id="S4.T2.8.8.2" class="ltx_td ltx_align_center"><svg id="S4.T2.8.8.2.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 84.72 19.69 L 84.72 0 Z M 84.72 19.69" style="stroke:none"></path></g><g stroke="#FFD700" fill="#FFD700" color="#FFD700"><path d="M 84.72 0 M 84.72 0 L 84.72 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 25.3 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.8.8.2.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">53.80%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 104.04 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.8.8.2.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">46.20%</span></foreignObject></g></g></svg>
</td>
<td id="S4.T2.9.9.3" class="ltx_td ltx_align_center"><svg id="S4.T2.9.9.3.pic1" class="ltx_picture" height="19.69" overflow="visible" version="1.1" width="157.48"><g transform="translate(0,19.69) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#9CDEFF" fill="#9CDEFF" color="#9CDEFF"><path d="M 0 0 M 0 0 L 0 19.69 L 89.57 19.69 L 89.57 0 Z M 89.57 19.69" style="stroke:none"></path></g><g stroke="#FFD700" fill="#FFD700" color="#FFD700"><path d="M 89.57 0 M 89.57 0 L 89.57 19.69 L 157.48 19.69 L 157.48 0 Z M 157.48 19.69" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 27.66 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.9.9.3.pic1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">56.88%</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 106.4 6)" fill="#000000" stroke="#000000"><foreignObject width="34.44" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T2.9.9.3.pic1.2.2.2.1.1" class="ltx_text" style="font-size:80%;">43.12%</span></foreignObject></g></g></svg>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.11.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S4.T2.12.2" class="ltx_text" style="font-size:90%;">We conduct A/B testing to assess our modelâ€™s perceived quality in terms of lip synchronization, realism, and emotional expressivity. We compare against the ground truth, FaceDiffuser, and EMOTE where the result reports the percentage of times each modelâ€™s output (or the ground truth animation, in case of Ours vs. GT) is perceived better.</span></figcaption>
</figure>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F7.48" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:429.3pt;height:717.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(28.3pt,-47.3pt) scale(1.15176899394269,1.15176899394269) ;">
<table id="S4.F7.48.48" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F7.48.48.49.1" class="ltx_tr">
<td id="S4.F7.48.48.49.1.1" class="ltx_td"></td>
<th id="S4.F7.48.48.49.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F7.48.48.49.1.2.1" class="ltx_text" style="color:#FF8000;">Wi</span>ll</th>
<th id="S4.F7.48.48.49.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F7.48.48.49.1.3.1" class="ltx_text" style="color:#FF8000;">yo</span>u</th>
<th id="S4.F7.48.48.49.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">te<span id="S4.F7.48.48.49.1.4.1" class="ltx_text" style="color:#FF8000;">ll</span>
</th>
<th id="S4.F7.48.48.49.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.F7.48.48.49.1.5.1" class="ltx_text" style="color:#FF8000;">me</span></th>
<th id="S4.F7.48.48.49.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F7.48.48.49.1.6.1" class="ltx_text" style="color:#FF8000;">wh</span>-</th>
<th id="S4.F7.48.48.49.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.F7.48.48.49.1.7.1" class="ltx_text" style="color:#FF8000;">y</span>?</th>
</tr>
<tr id="S4.F7.6.6.6" class="ltx_tr">
<th id="S4.F7.6.6.6.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F7.6.6.6.7.1" class="ltx_text" style="font-size:80%;position:relative; bottom:60.0pt;">Neutral</span></th>
<td id="S4.F7.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/neutral/14.png" id="S4.F7.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.2.2.2.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/neutral/20.png" id="S4.F7.2.2.2.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.3.3.3.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/neutral/24.png" id="S4.F7.3.3.3.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.4.4.4.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/neutral/27.png" id="S4.F7.4.4.4.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.5.5.5.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/neutral/32.png" id="S4.F7.5.5.5.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.6.6.6.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/neutral/34.png" id="S4.F7.6.6.6.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F7.12.12.12" class="ltx_tr">
<th id="S4.F7.12.12.12.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F7.12.12.12.7.1" class="ltx_text" style="font-size:80%;position:relative; bottom:60.0pt;">Happy</span></th>
<td id="S4.F7.7.7.7.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/happy/14.png" id="S4.F7.7.7.7.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.8.8.8.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/happy/20.png" id="S4.F7.8.8.8.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.9.9.9.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/happy/24.png" id="S4.F7.9.9.9.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.10.10.10.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/happy/27.png" id="S4.F7.10.10.10.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.11.11.11.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/happy/32.png" id="S4.F7.11.11.11.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.12.12.12.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/happy/34.png" id="S4.F7.12.12.12.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F7.18.18.18" class="ltx_tr">
<th id="S4.F7.18.18.18.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F7.18.18.18.7.1" class="ltx_text" style="font-size:80%;position:relative; bottom:60.0pt;">Sad</span></th>
<td id="S4.F7.13.13.13.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/sad/14.png" id="S4.F7.13.13.13.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.14.14.14.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/sad/20.png" id="S4.F7.14.14.14.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.15.15.15.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/sad/24.png" id="S4.F7.15.15.15.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.16.16.16.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/sad/27.png" id="S4.F7.16.16.16.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.17.17.17.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/sad/32.png" id="S4.F7.17.17.17.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.18.18.18.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/sad/34.png" id="S4.F7.18.18.18.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F7.24.24.24" class="ltx_tr">
<th id="S4.F7.24.24.24.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F7.24.24.24.7.1" class="ltx_text" style="font-size:80%;position:relative; bottom:60.0pt;">Surprised</span></th>
<td id="S4.F7.19.19.19.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/surprised/14.png" id="S4.F7.19.19.19.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.20.20.20.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/surprised/20.png" id="S4.F7.20.20.20.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.21.21.21.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/surprised/24.png" id="S4.F7.21.21.21.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.22.22.22.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/surprised/27.png" id="S4.F7.22.22.22.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.23.23.23.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/surprised/32.png" id="S4.F7.23.23.23.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.24.24.24.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/surprised/34.png" id="S4.F7.24.24.24.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="98" alt="Refer to caption"></td>
</tr>
<tr id="S4.F7.30.30.30" class="ltx_tr">
<th id="S4.F7.30.30.30.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F7.30.30.30.7.1" class="ltx_text" style="font-size:80%;position:relative; bottom:60.0pt;">Fear</span></th>
<td id="S4.F7.25.25.25.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/fear/14.png" id="S4.F7.25.25.25.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.26.26.26.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/fear/20.png" id="S4.F7.26.26.26.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.27.27.27.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/fear/24.png" id="S4.F7.27.27.27.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.28.28.28.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/fear/27.png" id="S4.F7.28.28.28.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.29.29.29.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/fear/32.png" id="S4.F7.29.29.29.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.30.30.30.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/fear/34.png" id="S4.F7.30.30.30.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F7.36.36.36" class="ltx_tr">
<th id="S4.F7.36.36.36.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F7.36.36.36.7.1" class="ltx_text" style="font-size:80%;position:relative; bottom:60.0pt;">Disgusted</span></th>
<td id="S4.F7.31.31.31.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/disgusted/14.png" id="S4.F7.31.31.31.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.32.32.32.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/disgusted/20.png" id="S4.F7.32.32.32.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.33.33.33.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/disgusted/24.png" id="S4.F7.33.33.33.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.34.34.34.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/disgusted/27.png" id="S4.F7.34.34.34.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.35.35.35.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/disgusted/32.png" id="S4.F7.35.35.35.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.36.36.36.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/disgusted/34.png" id="S4.F7.36.36.36.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F7.42.42.42" class="ltx_tr">
<th id="S4.F7.42.42.42.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F7.42.42.42.7.1" class="ltx_text" style="font-size:80%;position:relative; bottom:60.0pt;">Angry</span></th>
<td id="S4.F7.37.37.37.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/angry/14.png" id="S4.F7.37.37.37.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.38.38.38.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/angry/20.png" id="S4.F7.38.38.38.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.39.39.39.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/angry/24.png" id="S4.F7.39.39.39.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.40.40.40.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/angry/27.png" id="S4.F7.40.40.40.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.41.41.41.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/angry/32.png" id="S4.F7.41.41.41.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.42.42.42.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/angry/34.png" id="S4.F7.42.42.42.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S4.F7.48.48.48" class="ltx_tr">
<th id="S4.F7.48.48.48.7" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.F7.48.48.48.7.1" class="ltx_text" style="font-size:80%;position:relative; bottom:60.0pt;">Contempt</span></th>
<td id="S4.F7.43.43.43.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/contempt/14.png" id="S4.F7.43.43.43.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.44.44.44.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/contempt/20.png" id="S4.F7.44.44.44.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.45.45.45.3" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/contempt/24.png" id="S4.F7.45.45.45.3.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.46.46.46.4" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/contempt/27.png" id="S4.F7.46.46.46.4.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.47.47.47.5" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/contempt/32.png" id="S4.F7.47.47.47.5.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S4.F7.48.48.48.6" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/emo_vq/contempt/34.png" id="S4.F7.48.48.48.6.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.51.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>. </span><span id="S4.F7.52.2" class="ltx_text" style="font-size:90%;">Visual results of facial animations with different driving emotions generated by ProbTalk3D for an audio sequence uttering- <span id="S4.F7.52.2.1" class="ltx_text ltx_font_italic">â€œWill you tell me why?â€</span>. Each row here showcases some key visual frames corresponding to the specific emotion controlled generated animation.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S4.F7.53" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.F7.54" class="ltx_p ltx_figure_panel ltx_align_center">Emotion Generation</p>
</div>
</div>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Ablation Study</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We conduct an ablation study to understand whether emotion control enhances synthesized animation quality. We remove the Style Vector input, <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{C}" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\mathcal{C}</annotation></semantics></math>, and instead, learn a general representation that is not specific to any of the style vector attributes. The remaining training settings stay identical to the proposed approach. The objective metrics related to the ablation study are provided in Tab.<a href="#S3.T1" title="Table 1 â€£ 3.4. Comparison Model: VAE Based â€£ 3. Methodology â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. When emotion control is excluded, ProbTalk3D outperforms the VAE variant across all evaluation metrics. The VAE variant without emotion control shows worse reconstruction quality but a slightly better Diversity value than the emotion control-enabled VAE model. ProbTalk3D without emotion control achieves slightly better results in LVE, MEE, and CE metrics in comparison to the version with emotion control. Fig.<a href="#S5.F8" title="Figure 8 â€£ 5. Discussion and Future Work â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> displays a frame of the synthesized motion generated by models with and without emotion control, given the same audio input. The ground truth frame is included for reference. We notice that without emotion control, the models produce less expressive outputs or fail to accurately convey the intended emotion.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Discussion and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our model is limited to generate facial animations conditioned on 8 basic emotions and 3 discrete emotion intensities as per ground truth annotations of the dataset. However, human emotion is much more detailed and richer to be controlled by pre-defined categories. We believe that by combining our model with textual descriptions would enable us to learn and control the generation of richer emotions rather than relying solely on one-hot vectors for style embedding, similar to <cite class="ltx_cite ltx_citemacro_citep">(Ao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite> which was applied in the body motion generation domain. Furthermore, due to the 3DMEAD dataset, our model shares similar limitations as EMOTE <cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> as presented in their work that include- (i) not being able to generate eye blinks, (ii) absence of mouth cavity, teeth and tongue animation that effect perception of speech animation (iii) visual artefacts for high-frequency speech as the reconstructed visual data is of low frequency.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Similar to our model ProbTalk3D and the VAE variant, we believe a 2-stage diffusion-based model, utilizing the more recent conditional diffusion <cite class="ltx_cite ltx_citemacro_citep">(Park and Cho, <a href="#bib.bib40" title="" class="ltx_ref">2023</a>)</cite> or latent diffusion <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2023a</a>)</cite> approaches might prove to be fruitful. Latent diffusion methods have demonstrated success in image generation and are applied in recent models for human motion synthesis <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2023a</a>)</cite> for enhanced diversity. More experiments are needed to effectively leverage diffusion based approaches for 3D facial animation synthesis. Moreover, additional datasets can be used for training and analysis to validate our modelâ€™s generalizability and 4D datasets can be employed for enhanced realism.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Intuitively, the animation produced by a generative model should resemble human-like facial motion, meaning the diversity between generations should be close to that of the ground truth. If a model can generate a wide range of diverse samples, but they lack meaning, it does not necessarily indicate superior performance. However, to the best of our knowledge, in contrast with body animation datasets <cite class="ltx_cite ltx_citemacro_citep">(Zhu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2024</a>)</cite>, no existing facial animation datasets exhibit this kind of natural diversity. Current datasets that include different ways of expressing the same sentence often involve performers being directed to convey specific emotions. To obtain ground truth diversity, we need multiple performances under the same style condition. With this information in the dataset, we can evaluate our models by assessing how closely their diversity matches as observed in ground truth. Future work can focus on constructing datasets that enable this diversity analysis.</p>
</div>
<figure id="S5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S5.F8.5" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:237.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(50.0pt,-34.2pt) scale(1.40447976559902,1.40447976559902) ;">
<table id="S5.F8.5.5" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.F8.3.3.3" class="ltx_tr">
<td id="S5.F8.3.3.3.4" class="ltx_td ltx_align_center"><span id="S5.F8.3.3.3.4.1" class="ltx_text" style="font-size:80%;position:relative; bottom:50.0pt;">w/ emotion control</span></td>
<td id="S5.F8.1.1.1.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/ablation/facediffuser-88-noemo.png" id="S5.F8.1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S5.F8.2.2.2.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/ablation/vq-88.png" id="S5.F8.2.2.2.2.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S5.F8.3.3.3.3" class="ltx_td ltx_align_center" rowspan="2"><span id="S5.F8.3.3.3.3.1" class="ltx_text"><img src="/html/2409.07966/assets/Assets/ablation/gt-88.png" id="S5.F8.3.3.3.3.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></span></td>
</tr>
<tr id="S5.F8.5.5.5" class="ltx_tr">
<td id="S5.F8.5.5.5.3" class="ltx_td ltx_align_center"><span id="S5.F8.5.5.5.3.1" class="ltx_text" style="font-size:80%;position:relative; bottom:50.0pt;">w/o emotion control</span></td>
<td id="S5.F8.4.4.4.1" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/ablation/vae-88-noemo.png" id="S5.F8.4.4.4.1.g1" class="ltx_graphics ltx_img_portrait" width="57" height="97" alt="Refer to caption"></td>
<td id="S5.F8.5.5.5.2" class="ltx_td ltx_align_center"><img src="/html/2409.07966/assets/Assets/ablation/vq-88-noemo.png" id="S5.F8.5.5.5.2.g1" class="ltx_graphics ltx_img_portrait" width="58" height="97" alt="Refer to caption"></td>
</tr>
<tr id="S5.F8.5.5.6.1" class="ltx_tr">
<td id="S5.F8.5.5.6.1.1" class="ltx_td"></td>
<td id="S5.F8.5.5.6.1.2" class="ltx_td ltx_align_center"><span id="S5.F8.5.5.6.1.2.1" class="ltx_text" style="font-size:80%;">VAE based</span></td>
<td id="S5.F8.5.5.6.1.3" class="ltx_td ltx_align_center"><span id="S5.F8.5.5.6.1.3.1" class="ltx_text" style="font-size:80%;">Proposed</span></td>
<td id="S5.F8.5.5.6.1.4" class="ltx_td ltx_align_center"><span id="S5.F8.5.5.6.1.4.1" class="ltx_text" style="font-size:80%;">GT</span></td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.7.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>. </span><span id="S5.F8.8.2" class="ltx_text" style="font-size:90%;">Visual comparison against ground truth (GT) frame using frames generated by proposed and VAE-based variant models trained with and without emotion control.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F8.9" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F8.10" class="ltx_p ltx_figure_panel ltx_align_center">Ablation figure</p>
</div>
</div>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we propose ProbTalk3D, a novel non-deterministic approach for emotion controllable speech-driven 3D facial animation synthesis that outperforms most recent deterministic and non-deterministic methods. Our approach is based on VQ-VAE and trained in 2 stages. In the first stage, we learn a motion prior leveraging a VQ-VAE based motion autoencoder. In the second stage, we train our audio and emotion conditioned 3D facial animation synthesis network that takes advantage of the learned motion prior for generation. Extensive evaluations have been conducted to validate our model performance. Quantitative evaluation results demonstrate that our model achieves results that are comparable to state-of-the-arts while ensuring a wider range of diverse yet high-quality acceptable animation outputs. Furthermore, qualitative comparisons with the non-deterministic model- FaceDiffuser<cite class="ltx_cite ltx_citemacro_citep">(Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite> and deterministic model- EMOTE<cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> show that our approach perform better against state-of-the-art models while being less computationally complex and more efficient. The perceptual user study provides further evidence that our model is preferred to both FaceDiffuser and EMOTE on lip synchronization, realism, and emotional expressivity ratings. Our work highlights the necessity of non-deterministic methodologies for generative 3D facial animation by introducing a novel probabilistic model that is capable of generating high-quality yet diverse animations. We hope our findings will inspire new discussions and research directions in generative 3D facial animation landscape.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We thank the authors of FaceFormer, CodeTalker, EMOTE and MEAD dataset for making their codebases and datasets available.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alexanderson etÂ al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Simon Alexanderson, Rajmund Nagy, Jonas Beskow, and GustavÂ Eje Henter. 2023.

</span>
<span class="ltx_bibblock">Listen, Denoise, Action! Audio-Driven Motion Synthesis with Diffusion Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">ACM Trans. Graph.</em> 42, 4 (2023), 1â€“20.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3592458" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3592458</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aneja etÂ al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2024a)</span>
<span class="ltx_bibblock">
Shivangi Aneja, Justus Thies, Angela Dai, and Matthias NieÃŸner. 2024a.

</span>
<span class="ltx_bibblock">FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head Models. In <em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>. 21263â€“21273.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aneja etÂ al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2024b)</span>
<span class="ltx_bibblock">
Shivangi Aneja, Justus Thies, Angela Dai, and Matthias NieÃŸner. 2024b.

</span>
<span class="ltx_bibblock">FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head Models. In <em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ao etÂ al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Tenglong Ao, Zeyi Zhang, and Libin Liu. 2023.

</span>
<span class="ltx_bibblock">GestureDiffuCLIP: Gesture Diffusion Model with CLIP Latents.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">ACM Trans. Graph.</em> (2023), 18Â pages.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3592097" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3592097</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aylagas etÂ al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
MÃ³nicaÂ Villanueva Aylagas, HÃ©ctorÂ Anadon Leon, Mattias Teye, and Konrad Tollmar. 2022.

</span>
<span class="ltx_bibblock">Voice2Face: Audio-driven Facial and Tongue Rig Animations with cVAEs. In <em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2022</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Andrew Brown, Jaesung Huh, Arsha Nagrani, JoonÂ Son Chung, and Andrew Zisserman. 2021.

</span>
<span class="ltx_bibblock">Playing a part: Speaker verification at the movies. In <em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 6174â€“6178.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Charalambous etÂ al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Constantinos Charalambous, Zerrin Yumak, and A.F. vanÂ der Stappen. 2019.

</span>
<span class="ltx_bibblock">Audioâ€driven emotional speech animation for interactive virtual characters.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Computer Animation and Virtual Worlds</em> 30 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Junming Chen, Yunfei Liu, Jianan Wang, Ailing Zeng, Yu Li, and Qifeng Chen. 2024.

</span>
<span class="ltx_bibblock">DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>. 7352â€“7361.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Peng Chen, Xiaobao Wei, Ming Lu, Yitong Zhu, Naiming Yao, Xingyu Xiao, and Hui Chen. 2023b.

</span>
<span class="ltx_bibblock">DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D Face Diffuser.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.16565</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Xin Chen, Biao Jiang, Wen Liu, Zilong Huang, Bin Fu, Tao Chen, and Gang Yu. 2023a.

</span>
<span class="ltx_bibblock">Executing your commands via motion diffusion in latent space. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 18000â€“18010.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chhatre etÂ al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Kiran Chhatre, Radek DanÄ›Äek, Nikos Athanasiou, Giorgio Becherini, Christopher Peters, MichaelÂ J. Black, and Timo Bolkart. 2024.

</span>
<span class="ltx_bibblock">AMUSE: Emotional Speech-driven 3D Body Animation via Disentangled Latent Diffusion. In <em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>. 1942â€“1953.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://amuse.is.tue.mpg.de" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://amuse.is.tue.mpg.de</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cudeiro etÂ al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Daniel Cudeiro, Timo Bolkart, Cassidy Laidlaw, Anurag Ranjan, and MichaelÂ J Black. 2019.

</span>
<span class="ltx_bibblock">Capture, learning, and synthesis of 3D speaking styles. In <em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 10101â€“10111.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Danecek etÂ al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Radek Danecek, MichaelÂ J. Black, and Timo Bolkart. 2022.

</span>
<span class="ltx_bibblock">EMOCA: Emotion Driven Monocular Face Capture and Animation. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Conference on Computer Vision and Pattern Recognition (CVPR)</em>. 20311â€“20322.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">DanÄ›Äek etÂ al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Radek DanÄ›Äek, Kiran Chhatre, Shashank Tripathi, Yandong Wen, Michael Black, and Timo Bolkart. 2023.

</span>
<span class="ltx_bibblock">Emotional Speech-Driven Animation with Content-Emotion Disentanglement. ACM.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3610548.3618183" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3610548.3618183</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Edwards etÂ al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Pif Edwards, Chris Landreth, Eugene Fiume, and Karan Singh. 2016.

</span>
<span class="ltx_bibblock">Jali: an animator-centric viseme model for expressive lip synchronization.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on graphics (TOG)</em> 35, 4 (2016), 1â€“11.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Egger etÂ al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Bernhard Egger, William A.Â P. Smith, Ayush Tewari, Stefanie Wuhrer, Michael Zollhoefer, Thabo Beeler, Florian Bernard, Timo Bolkart, Adam Kortylewski, Sami Romdhani, Christian Theobalt, Volker Blanz, and Thomas Vetter. 2020.

</span>
<span class="ltx_bibblock">3D Morphable Face Modelsâ€”Past, Present, and Future.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">ACM Trans. Graph.</em> 39, 5, Article 157 (jun 2020), 38Â pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3395208" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3395208</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Falcon and The PyTorch Lightning team (2019)</span>
<span class="ltx_bibblock">
William Falcon and The PyTorch Lightning team. 2019.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">PyTorch Lightning</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.5281/zenodo.3828935" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.3828935</a>

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan etÂ al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yingruo Fan, Zhaojiang Lin, Jun Saito, Wenping Wang, and Taku Komura. 2022.

</span>
<span class="ltx_bibblock">FaceFormer: Speech-Driven 3D Facial Animation with Transformers. In <em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 18770â€“18780.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fanelli etÂ al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Gabriele Fanelli, Juergen Gall, Harald Romsdorfer, Thibaut Weise, and Luc VanÂ Gool. 2010.

</span>
<span class="ltx_bibblock">A 3-d audio-visual corpus of affective communication.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em> 12, 6 (2010), 591â€“598.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng etÂ al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yao Feng, Haiwen Feng, MichaelÂ J. Black, and Timo Bolkart. 2021.

</span>
<span class="ltx_bibblock">Learning an Animatable Detailed 3D Face Model from In-The-Wild Images.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics, (Proc. SIGGRAPH)</em> 40, 8.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3450626.3459936" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3450626.3459936</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Giebenhain etÂ al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Simon Giebenhain, Tobias Kirschstein, Markos Georgopoulos, Martin RÃ¼nz, Lourdes Agapito, and Matthias NieÃŸner. 2023.

</span>
<span class="ltx_bibblock">MonoNPHM: Dynamic Head Reconstruction from Monocular Videos.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.06740</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Giebenhain etÂ al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Simon Giebenhain, Tobias Kirschstein, Markos Georgopoulos, Martin RÃ¼nz, Lourdes Agapito, and Matthias NieÃŸner. 2024.

</span>
<span class="ltx_bibblock">MonoNPHM: Dynamic Head Reconstruction from Monocular Videos. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>. 10747â€“10758.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haque and Yumak (2023)</span>
<span class="ltx_bibblock">
KaziÂ Injamamul Haque and Zerrin Yumak. 2023.

</span>
<span class="ltx_bibblock">FaceXHuBERT: Text-less Speech-driven E(X)pressive 3D Facial Animation Synthesis Using Self-Supervised Speech Representation Learning. In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI â€™23)</em> (Paris, France). ACM, New York, NY, USA, 10Â pages.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3577190.3614157" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3577190.3614157</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho etÂ al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020a.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models. In <em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th International Conference on Neural Information Processing Systems</em> (Vancouver, BC, Canada) <em id="bib.bib25.4.2" class="ltx_emph ltx_font_italic">(NIPS â€™20)</em>. Curran Associates Inc., Red Hook, NY, USA, Article 574, 12Â pages.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho etÂ al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020b.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em> 33 (2020), 6840â€“6851.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu etÂ al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Wei-Ning Hsu, Benjamin Bolte, Yao-HungÂ Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed. 2021.

</span>
<span class="ltx_bibblock">HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2106.07447" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2106.07447</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">JALI (2023)</span>
<span class="ltx_bibblock">
JALI 2023.

</span>
<span class="ltx_bibblock">JALI Research.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://jaliresearch.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://jaliresearch.com/</a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji etÂ al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xinya Ji, Hang Zhou, Kaisiyuan Wang, Qianyi Wu, Wayne Wu, Feng Xu, and Xun Cao. 2022.

</span>
<span class="ltx_bibblock">EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model. In <em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">ACM SIGGRAPH 2022 Conference Proceedings</em> (Vancouver, BC, Canada) <em id="bib.bib29.4.2" class="ltx_emph ltx_font_italic">(SIGGRAPH â€™22)</em>. Association for Computing Machinery, New York, NY, USA, Article 61, 10Â pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3528233.3530745" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3528233.3530745</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras etÂ al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Tero Karras, Timo Aila, Samuli Laine, Antti Herva, and Jaakko Lehtinen. 2017.

</span>
<span class="ltx_bibblock">Audio-driven facial animation by joint end-to-end learning of pose and emotion.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (TOG)</em> 36, 4 (2017), 1â€“12.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jing Li, Di Kang, Wenjie Pei, Xuefei Zhe, Ying Zhang, Zhenyu He, and Linchao Bao. 2021.

</span>
<span class="ltx_bibblock">Audio2Gestures: Generating Diverse Gestures from Speech Audio with Conditional Variational Autoencoders. In <em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">2021 IEEE/CVF International Conference on Computer Vision (ICCV)</em>. 11273â€“11282.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICCV48922.2021.01110" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICCV48922.2021.01110</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2017a)</span>
<span class="ltx_bibblock">
Tianye Li, Timo Bolkart, MichaelÂ J. Black, Hao Li, and Javier Romero. 2017a.

</span>
<span class="ltx_bibblock">Learning a model of facial shape and expression from 4D scans.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">ACM Trans. Graph.</em> 36, 6, Article 194 (nov 2017), 17Â pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3130800.3130813" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3130800.3130813</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2017b)</span>
<span class="ltx_bibblock">
Tianye Li, Timo Bolkart, MichaelÂ J Black, Hao Li, and Javier Romero. 2017b.

</span>
<span class="ltx_bibblock">Learning a model of facial shape and expression from 4D scans.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">ACM Trans. Graph.</em> 36, 6 (2017), 194â€“1.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Haiyang Liu, Zihao Zhu, Giorgio Becherini, Yichen Peng, Mingyang Su, You Zhou, Xuefei Zhe, Naoya Iwamoto, Bo Zheng, and MichaelÂ J. Black. 2024.

</span>
<span class="ltx_bibblock">EMAGE: Towards Unified Holistic Co-Speech Gesture Generation via Expressive Masked Audio Gesture Modeling. In <em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">IEEE/CVF Conf.Â on Computer Vision and Pattern Recognition (CVPR)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Livingstone and Russo (2018)</span>
<span class="ltx_bibblock">
StevenÂ R Livingstone and FrankÂ A Russo. 2018.

</span>
<span class="ltx_bibblock">The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">PloS one</em> 13, 5 (2018), e0196391.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lombardi etÂ al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Stephen Lombardi, Jason Saragih, Tomas Simon, and Yaser Sheikh. 2018.

</span>
<span class="ltx_bibblock">Deep appearance models for face rendering.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (ToG)</em> 37, 4 (2018), 1â€“13.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Zhiyuan Ma, Xiangyu Zhu, Guojun Qi, Chen Qian, Zhaoxiang Zhang, and Zhen Lei. 2024.

</span>
<span class="ltx_bibblock">DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.05712</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ng etÂ al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Evonne Ng, Hanbyul Joo, Liwen Hu, Hao Li, , Trevor Darrell, Angjoo Kanazawa, and Shiry Ginosar. 2022.

</span>
<span class="ltx_bibblock">Learning to Listen: Modeling Non-Deterministic Dyadic Facial Motion.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ng etÂ al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Evonne Ng, Javier Romero, Timur Bagautdinov, Shaojie Bai, Trevor Darrell, Angjoo Kanazawa, and Alexander Richard. 2024.

</span>
<span class="ltx_bibblock">From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations. In <em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park and Cho (2023)</span>
<span class="ltx_bibblock">
Inkyu Park and Jaewoong Cho. 2023.

</span>
<span class="ltx_bibblock">SAiD: Speech-driven Blendshape Facial Animation with Diffusion.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2401.08655Â [cs.CV]

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park etÂ al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
SeÂ Jin Park, Joanna Hong, Minsu Kim, and YongÂ Man Ro. 2023.

</span>
<span class="ltx_bibblock">DF-3DFace: One-to-Many Speech Synchronized 3D Face Animation with Diffusion.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.05934</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng etÂ al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Ziqiao Peng, Haoyu Wu, Zhenbo Song, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, and Zhaoxin Fan. 2023.

</span>
<span class="ltx_bibblock">EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation. In <em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on computer vision</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prolific (2023)</span>
<span class="ltx_bibblock">
Prolific 2023.

</span>
<span class="ltx_bibblock">Prolific.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.prolific.co" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.prolific.co</a>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qualtrics (2023)</span>
<span class="ltx_bibblock">
Qualtrics 2023.

</span>
<span class="ltx_bibblock">Qualtrics.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.qualtrics.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.qualtrics.com</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021.

</span>
<span class="ltx_bibblock">Learning Transferable Visual Models From Natural Language Supervision. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 38th International Conference on Machine Learning</em> <em id="bib.bib45.4.2" class="ltx_emph ltx_font_italic">(Proceedings of Machine Learning Research, Vol.Â 139)</em>, Marina Meila and Tong Zhang (Eds.). PMLR, 8748â€“8763.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v139/radford21a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v139/radford21a.html</a>

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren etÂ al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhiyuan Ren, Zhihong Pan, Xin Zhou, and Le Kang. 2023.

</span>
<span class="ltx_bibblock">Diffusion motion: Generate text-guided 3d human motion by diffusion model. In <em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 1â€“5.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Richard etÂ al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Alexander Richard, Colin Lea, Shugao Ma, Jurgen Gall, Fernando DeÂ la Torre, and Yaser Sheikh. 2021a.

</span>
<span class="ltx_bibblock">Audio-and gaze-driven facial animation of codec avatars. In <em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF winter conference on applications of computer vision</em>. 41â€“50.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Richard etÂ al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Alexander Richard, Michael ZollhÃ¶fer, Yandong Wen, Fernando DeÂ la Torre, and Yaser Sheikh. 2021b.

</span>
<span class="ltx_bibblock">Meshtalk: 3d face animation from speech using cross-modality disentanglement. In <em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 1173â€“1182.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stan etÂ al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Stefan Stan, KaziÂ Injamamul Haque, and Zerrin Yumak. 2023.

</span>
<span class="ltx_bibblock">FaceDiffuser: Speech-Driven 3D Facial Animation Synthesis Using Diffusion. In <em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">ACM SIGGRAPH Conference on Motion, Interaction and Games (MIG â€™23), November 15â€“17, 2023, Rennes, France</em> (Rennes, France). ACM, New York, NY, USA, 11Â pages.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3623264.3624447" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3623264.3624447</a>

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">StypuÅ‚kowski etÂ al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
MichaÅ‚ StypuÅ‚kowski, Konstantinos Vougioukas, Sen He, Maciej Zi<span id="bib.bib50.3.1" class="ltx_ERROR undefined">\k</span>eba, Stavros Petridis, and Maja Pantic. 2024.

</span>
<span class="ltx_bibblock">Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation. In <em id="bib.bib50.4.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>. 5091â€“5100.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Zhiyao Sun, Tian Lv, Sheng Ye, Matthieu Lin, Jenny Sheng, Yu-Hui Wen, Minjing Yu, and Yong-Jin Liu. 2024.

</span>
<span class="ltx_bibblock">DiffPoseTalk: Speech-Driven Stylistic 3D Facial Animation and Head Pose Generation via Diffusion Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">ACM Trans. Graph.</em> 43, 4, Article 46 (jul 2024), 9Â pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3658221" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3658221</a>

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taylor etÂ al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Sarah Taylor, Taehwan Kim, Yisong Yue, Moshe Mahler, James Krahe, AnastasioÂ Garcia Rodriguez, Jessica Hodgins, and Iain Matthews. 2017.

</span>
<span class="ltx_bibblock">A deep learning approach for generalized speech animation.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (TOG)</em> 36, 4 (2017), 1â€“11.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taylor etÂ al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
SarahÂ L. Taylor, Moshe Mahler, Barry-John Theobald, and Iain Matthews. 2012.

</span>
<span class="ltx_bibblock">Dynamic Units of Visual Speech. In <em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation</em> (Lausanne, Switzerland) <em id="bib.bib53.4.2" class="ltx_emph ltx_font_italic">(SCA â€™12)</em>. Eurographics Association, Goslar, DEU, 275â€“284.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tevet etÂ al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, and AmitÂ H Bermano. 2022.

</span>
<span class="ltx_bibblock">Human motion diffusion model.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2209.14916</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thambiraja etÂ al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Balamurugan Thambiraja, Sadegh Aliakbarian, Darren Cosker, and Justus Thies. 2023a.

</span>
<span class="ltx_bibblock">3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2312.00870Â [cs.CV]

<a target="_blank" href="https://arxiv.org/abs/2312.00870" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2312.00870</a>

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thambiraja etÂ al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Balamurugan Thambiraja, Sadegh Aliakbarian, Darren Cosker, and Justus Thies. 2023b.

</span>
<span class="ltx_bibblock">3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.00870</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thambiraja etÂ al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2023c)</span>
<span class="ltx_bibblock">
Balamurugan Thambiraja, Ikhsanul Habibie, Sadegh Aliakbarian, Darren Cosker, Christian Theobalt, and Justus Thies. 2023c.

</span>
<span class="ltx_bibblock">Imitator: Personalized speech-driven 3d facial animation. In <em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>. 20621â€“20631.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van DenÂ Oord etÂ al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Aaron Van DenÂ Oord, Oriol Vinyals, etÂ al<span id="bib.bib58.3.1" class="ltx_text">.</span> 2017.

</span>
<span class="ltx_bibblock">Neural discrete representation learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.4.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em> 30 (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">vanÂ den Oord etÂ al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Aaron vanÂ den Oord, Oriol Vinyals, and Koray Kavukcuoglu. 2017.

</span>
<span class="ltx_bibblock">Neural discrete representation learning. In <em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 31st International Conference on Neural Information Processing Systems</em> (Long Beach, California, USA) <em id="bib.bib59.4.2" class="ltx_emph ltx_font_italic">(NIPSâ€™17)</em>. Curran Associates Inc., Red Hook, NY, USA, 6309â€“6318.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Kaisiyuan Wang, Qianyi Wu, Linsen Song, Zhuoqian Yang, Wayne Wu, Chen Qian, Ran He, Yu Qiao, and ChenÂ Change Loy. 2020.

</span>
<span class="ltx_bibblock">MEAD: A Large-scale Audio-visual Dataset for Emotional Talking-face Generation. In <em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">ECCV</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wuu etÂ al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Cheng-hsin Wuu, Ningyuan Zheng, Scott Ardisson, Rohan Bali, Danielle Belko, Eric Brockmeyer, Lucas Evans, Timothy Godisart, Hyowon Ha, Alexander Hypes, etÂ al<span id="bib.bib61.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Multiface: A dataset for neural face rendering.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.11243</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xing etÂ al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Jinbo Xing, Menghan Xia, Yuechen Zhang, Xiaodong Cun, Jue Wang, and Tien-Tsin Wong. 2023.

</span>
<span class="ltx_bibblock">CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.02379</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
KarrenÂ D Yang, Anurag Ranjan, Jen-HaoÂ Rick Chang, Raviteja Vemulapalli, and Oncel Tuzel. 2024.

</span>
<span class="ltx_bibblock">Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks Methods and Applications. In <em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 27294â€“27303.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi etÂ al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hongwei Yi, Hualin Liang, Yifei Liu, Qiong Cao, Yandong Wen, Timo Bolkart, Dacheng Tao, and MichaelÂ J Black. 2023.

</span>
<span class="ltx_bibblock">Generating Holistic 3D Human Motion from Speech. In <em id="bib.bib64.3.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>. 469â€“480.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Wenxuan Zhang, Xiaodong Cun, Xuan Wang, Yong Zhang, Xi Shen, Yu Guo, Ying Shan, and Fei Wang. 2023.

</span>
<span class="ltx_bibblock">SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation. In <em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 8652â€“8661.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhimeng Zhang, Lincheng Li, Yu Ding, and Changjie Fan. 2021.

</span>
<span class="ltx_bibblock">Flow-guided one-shot talking face generation with a high-resolution audio-visual dataset. In <em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 3661â€“3670.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao etÂ al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Qingcheng Zhao, Pengyu Long, Qixuan Zhang, Dafei Qin, Han Liang, Longwen Zhang, Yingliang Zhang, Jingyi Yu, and Lan Xu. 2024.

</span>
<span class="ltx_bibblock">Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance. In <em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">ACM SIGGRAPH 2024 Conference Papers</em> (Denver, CO, USA) <em id="bib.bib67.4.2" class="ltx_emph ltx_font_italic">(SIGGRAPH â€™24)</em>. Association for Computing Machinery, New York, NY, USA, Article 18, 13Â pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3641519.3657413" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3641519.3657413</a>

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao etÂ al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Wei Zhao, Yijun Wang, Tianyu He, Lianying Yin, Jianxin Lin, and Xin Jin. 2023.

</span>
<span class="ltx_bibblock">Breathing Life into Faces: Speech-driven 3D Facial Animation with Natural Head Pose and Detailed Shape.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.20240</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2024)</span>
<span class="ltx_bibblock">
Wentao Zhu, Xiaoxuan Ma, Dongwoo Ro, Hai Ci, Jinlu Zhang, Jiaxin Shi, Feng Gao, Qi Tian, and Yizhou Wang. 2024.

</span>
<span class="ltx_bibblock">Human Motion Generation: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 46, 4 (2024), 2430â€“2449.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/TPAMI.2023.3330935" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TPAMI.2023.3330935</a>

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zielonka etÂ al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Wojciech Zielonka, Timo Bolkart, and Justus Thies. 2022.

</span>
<span class="ltx_bibblock">Towards Metrical Reconstruction of Human Faces. In <em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">Computer Vision â€“ ECCV 2022</em> <em id="bib.bib70.4.2" class="ltx_emph ltx_font_italic">(Lecture Notes in Computer Science, 13673, Vol.Â 13)</em>. Springer, Cham, 250â€“269.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/978-3-031-19778-9_15" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-031-19778-9_15</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Supplementary Material</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1. </span>Dataset and Split</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">FLAME parameter datasets have been constructed in several studies <cite class="ltx_cite ltx_citemacro_citep">(Ng etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2022</a>; Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2024</a>; Park etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2023</a>; Zhao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2023</a>)</cite>. As stated in <cite class="ltx_cite ltx_citemacro_citep">(Sun etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2024</a>)</cite>, the use of lower-dimensional 3DMM parameters allows for faster computational speed compared to predicting mesh vertices which are typically much higher dimensional than 3DMM parameters (analogous to blendshapes and morph targets). More recently, EMOTE<cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> reconstructed 3DMEAD (a FLAME parameter dataset) from videos of audio-visual dataset MEAD <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2020</a>)</cite>. 3DMEAD includes the facial animation data (in terms of reconstructed FLAME 3DMM parameters), audios, emotion annotations and intensity annotations from the original MEAD dataset. The emotion and intensity annotations makes this dataset useful for our work as it is the only large-scale audio-3D dataset with labeled emotion variations that can be accessed and used publicly for research and academic purposes.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<p id="A1.SS1.p2.1" class="ltx_p">EMOTE <cite class="ltx_cite ltx_citemacro_citep">(DanÄ›Äek etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite> uses all sequences from 32 subjects for training and 7 subjects for validation, without any sequences allocated for evaluation. However, we find this split insufficient for objective model evaluation. In our 2-stage approach, the first stage trains a prior model to learn from the motion data sequences. To maximize data utilization, we adopt the EMOTE split. For the second stage which involves audio-to-motion generation, we propose a novel split inspired by the dataset split of BIWI dataset <cite class="ltx_cite ltx_citemacro_citep">(Fanelli etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2010</a>)</cite> as also used in <cite class="ltx_cite ltx_citemacro_citep">(Fan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>; Haque and Yumak, <a href="#bib.bib24" title="" class="ltx_ref">2023</a>; Xing etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2023</a>; Stan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite> that lets us evaluate the results with objective metrics. We divide the sentences of the 32 training subjects into training, validation, and test sets in an 80-10-10 ratio. The training subjects utilized are identical to those in EMOTE, facilitating a meaningful performance comparison during perceptual evaluation. Additionally, given the scale of 3DMEAD, we believe our split provides sufficient data for effective learning and generation. To elaborate further, each subject utters 40 sentences in the neutral expression. We allocate the first 32 sentences for training, the subsequent 4 for validation, and the remaining 4 for evaluation. For each of the 7 emotions, every subject performs 30 sentences across 3 intensity levels. Similarly, we assign the first 24 sentences (including all intensities) for training, the next 3 for validation, and the remaining 3 for evaluation. The split is summarized in Table <a href="#A1.T3" title="Table 3 â€£ A.1. Dataset and Split â€£ Appendix A Supplementary Material â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. When examining the sequence numbers in the table, please be aware that the reconstructed 3DMEAD dataset is missing some sequences from the original 2D MEAD dataset. For the user study, we then utilize sequences from the remaining <math id="A1.SS1.p2.1.m1.1" class="ltx_Math" alttext="(47-32-7=8)" display="inline"><semantics id="A1.SS1.p2.1.m1.1a"><mrow id="A1.SS1.p2.1.m1.1.1.1" xref="A1.SS1.p2.1.m1.1.1.1.1.cmml"><mo stretchy="false" id="A1.SS1.p2.1.m1.1.1.1.2" xref="A1.SS1.p2.1.m1.1.1.1.1.cmml">(</mo><mrow id="A1.SS1.p2.1.m1.1.1.1.1" xref="A1.SS1.p2.1.m1.1.1.1.1.cmml"><mrow id="A1.SS1.p2.1.m1.1.1.1.1.2" xref="A1.SS1.p2.1.m1.1.1.1.1.2.cmml"><mn id="A1.SS1.p2.1.m1.1.1.1.1.2.2" xref="A1.SS1.p2.1.m1.1.1.1.1.2.2.cmml">47</mn><mo id="A1.SS1.p2.1.m1.1.1.1.1.2.1" xref="A1.SS1.p2.1.m1.1.1.1.1.2.1.cmml">âˆ’</mo><mn id="A1.SS1.p2.1.m1.1.1.1.1.2.3" xref="A1.SS1.p2.1.m1.1.1.1.1.2.3.cmml">32</mn><mo id="A1.SS1.p2.1.m1.1.1.1.1.2.1a" xref="A1.SS1.p2.1.m1.1.1.1.1.2.1.cmml">âˆ’</mo><mn id="A1.SS1.p2.1.m1.1.1.1.1.2.4" xref="A1.SS1.p2.1.m1.1.1.1.1.2.4.cmml">7</mn></mrow><mo id="A1.SS1.p2.1.m1.1.1.1.1.1" xref="A1.SS1.p2.1.m1.1.1.1.1.1.cmml">=</mo><mn id="A1.SS1.p2.1.m1.1.1.1.1.3" xref="A1.SS1.p2.1.m1.1.1.1.1.3.cmml">8</mn></mrow><mo stretchy="false" id="A1.SS1.p2.1.m1.1.1.1.3" xref="A1.SS1.p2.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.1.m1.1b"><apply id="A1.SS1.p2.1.m1.1.1.1.1.cmml" xref="A1.SS1.p2.1.m1.1.1.1"><eq id="A1.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="A1.SS1.p2.1.m1.1.1.1.1.1"></eq><apply id="A1.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="A1.SS1.p2.1.m1.1.1.1.1.2"><minus id="A1.SS1.p2.1.m1.1.1.1.1.2.1.cmml" xref="A1.SS1.p2.1.m1.1.1.1.1.2.1"></minus><cn type="integer" id="A1.SS1.p2.1.m1.1.1.1.1.2.2.cmml" xref="A1.SS1.p2.1.m1.1.1.1.1.2.2">47</cn><cn type="integer" id="A1.SS1.p2.1.m1.1.1.1.1.2.3.cmml" xref="A1.SS1.p2.1.m1.1.1.1.1.2.3">32</cn><cn type="integer" id="A1.SS1.p2.1.m1.1.1.1.1.2.4.cmml" xref="A1.SS1.p2.1.m1.1.1.1.1.2.4">7</cn></apply><cn type="integer" id="A1.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="A1.SS1.p2.1.m1.1.1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.1.m1.1c">(47-32-7=8)</annotation></semantics></math> unseen identities, as well as the unseen audio during training (including the test set in stage 2 and the validation set in stage 1). Specifically, we want to explain our choice of data split for stage 1. Intuitively, the data split for both stages should be the same. However, our experiments show that using less data in stage 1 can significantly affect the performance of the motion prior. Therefore, we adopt the stage 1 split shown in Table <a href="#A1.T3" title="Table 3 â€£ A.1. Dataset and Split â€£ Appendix A Supplementary Material â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="A1.T3" class="ltx_table">
<table id="A1.T3.5" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T3.5.6.1" class="ltx_tr">
<td id="A1.T3.5.6.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.5.6.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.6.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A1.T3.5.6.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span>
</span>
</td>
<td id="A1.T3.5.6.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.5.6.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.6.1.2.1.1" class="ltx_p" style="width:136.6pt;"><span id="A1.T3.5.6.1.2.1.1.1" class="ltx_text ltx_font_bold">Stage-1 split</span></span>
</span>
</td>
<td id="A1.T3.5.6.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.5.6.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.6.1.3.1.1" class="ltx_p" style="width:136.6pt;"><span id="A1.T3.5.6.1.3.1.1.1" class="ltx_text ltx_font_bold">Stage-2 split</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.5.7.2" class="ltx_tr">
<td id="A1.T3.5.7.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.T3.5.7.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.7.2.1.1.1" class="ltx_p" style="width:85.4pt;"></span>
</span>
</td>
<td id="A1.T3.5.7.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.T3.5.7.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.7.2.2.1.1" class="ltx_p" style="width:136.6pt;"></span>
</span>
</td>
<td id="A1.T3.5.7.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A1.T3.5.7.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.7.2.3.1.1" class="ltx_p" style="width:136.6pt;"></span>
</span>
</td>
</tr>
<tr id="A1.T3.2.2" class="ltx_tr">
<td id="A1.T3.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.2.3.1.1" class="ltx_p" style="width:85.4pt;">Training set</span>
</span>
</td>
<td id="A1.T3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.1.1.1.1.1" class="ltx_p" style="width:136.6pt;">
<span id="A1.T3.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.1.1.1.1.1.1.2" class="ltx_tr">
<span id="A1.T3.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">32 identities</span></span>
<span id="A1.T3.1.1.1.1.1.1.1" class="ltx_tr">
<span id="A1.T3.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="A1.T3.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="40+(30\times 7\times 3)" display="inline"><semantics id="A1.T3.1.1.1.1.1.1.1.1.m1.1a"><mrow id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mn id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.3" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.3.cmml">40</mn><mo id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.2" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">+</mo><mrow id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mn id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.2" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.2.cmml">30</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.1" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.3" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.3.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.1a" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.4" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.4.cmml">3</mn></mrow><mo stretchy="false" id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.3" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.1.1.1.1.m1.1b"><apply id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1"><plus id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.2"></plus><cn type="integer" id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.3">40</cn><apply id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1"><times id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.1"></times><cn type="integer" id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.2">30</cn><cn type="integer" id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.3">7</cn><cn type="integer" id="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.4.cmml" xref="A1.T3.1.1.1.1.1.1.1.1.m1.1.1.1.1.1.4">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.1.1.1.1.m1.1c">40+(30\times 7\times 3)</annotation></semantics></math> sentences</span></span>
<span id="A1.T3.1.1.1.1.1.1.3" class="ltx_tr">
<span id="A1.T3.1.1.1.1.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">= 21,115 sequences</span></span>
</span></span>
</span>
</td>
<td id="A1.T3.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.2.2.2.1.1" class="ltx_p" style="width:136.6pt;">
<span id="A1.T3.2.2.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.2.2.2.1.1.1.2" class="ltx_tr">
<span id="A1.T3.2.2.2.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">32 identities</span></span>
<span id="A1.T3.2.2.2.1.1.1.1" class="ltx_tr">
<span id="A1.T3.2.2.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="A1.T3.2.2.2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="32+(24\times 7\times 3)" display="inline"><semantics id="A1.T3.2.2.2.1.1.1.1.1.m1.1a"><mrow id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.cmml"><mn id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.3" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.3.cmml">32</mn><mo id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.2" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.2.cmml">+</mo><mrow id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.2" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mn id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.2" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.2.cmml">24</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.1" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.3" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.3.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.1a" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.4" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.4.cmml">3</mn></mrow><mo stretchy="false" id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.3" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.1.1.1.1.1.m1.1b"><apply id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.cmml" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1"><plus id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.2"></plus><cn type="integer" id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.3">32</cn><apply id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1"><times id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.1"></times><cn type="integer" id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.2">24</cn><cn type="integer" id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.3">7</cn><cn type="integer" id="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.4.cmml" xref="A1.T3.2.2.2.1.1.1.1.1.m1.1.1.1.1.1.4">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.1.1.1.1.1.m1.1c">32+(24\times 7\times 3)</annotation></semantics></math> sentences</span></span>
<span id="A1.T3.2.2.2.1.1.1.3" class="ltx_tr">
<span id="A1.T3.2.2.2.1.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">= 17,098 sequences</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.4.4" class="ltx_tr">
<td id="A1.T3.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.4.4.3.1.1" class="ltx_p" style="width:85.4pt;">Validation set</span>
</span>
</td>
<td id="A1.T3.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.3.3.1.1.1" class="ltx_p" style="width:136.6pt;">
<span id="A1.T3.3.3.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.3.3.1.1.1.1.2" class="ltx_tr">
<span id="A1.T3.3.3.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">7 identities</span></span>
<span id="A1.T3.3.3.1.1.1.1.1" class="ltx_tr">
<span id="A1.T3.3.3.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="A1.T3.3.3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="40+(30\times 7\times 3)" display="inline"><semantics id="A1.T3.3.3.1.1.1.1.1.1.m1.1a"><mrow id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.cmml"><mn id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.3" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.3.cmml">40</mn><mo id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.2" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.2.cmml">+</mo><mrow id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mn id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.2" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.2.cmml">30</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.1" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.3" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.3.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.1a" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.4" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.4.cmml">3</mn></mrow><mo stretchy="false" id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.3" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.1.1.1.1.1.1.m1.1b"><apply id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1"><plus id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.2"></plus><cn type="integer" id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.3">40</cn><apply id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1"><times id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.1"></times><cn type="integer" id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.2">30</cn><cn type="integer" id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.3">7</cn><cn type="integer" id="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.4.cmml" xref="A1.T3.3.3.1.1.1.1.1.1.m1.1.1.1.1.1.4">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.1.1.1.1.1.1.m1.1c">40+(30\times 7\times 3)</annotation></semantics></math> sentences</span></span>
<span id="A1.T3.3.3.1.1.1.1.3" class="ltx_tr">
<span id="A1.T3.3.3.1.1.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">= 4,584 sequences</span></span>
</span></span>
</span>
</td>
<td id="A1.T3.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T3.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.4.4.2.1.1" class="ltx_p" style="width:136.6pt;">
<span id="A1.T3.4.4.2.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.4.4.2.1.1.1.2" class="ltx_tr">
<span id="A1.T3.4.4.2.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">32 identities</span></span>
<span id="A1.T3.4.4.2.1.1.1.1" class="ltx_tr">
<span id="A1.T3.4.4.2.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="A1.T3.4.4.2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="4+(3\times 7\times 3)" display="inline"><semantics id="A1.T3.4.4.2.1.1.1.1.1.m1.1a"><mrow id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.cmml"><mn id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.3" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.3.cmml">4</mn><mo id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.2" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.2.cmml">+</mo><mrow id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.2" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mn id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.2" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.1" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.3" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.3.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.1a" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.4" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.4.cmml">3</mn></mrow><mo stretchy="false" id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.3" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.4.4.2.1.1.1.1.1.m1.1b"><apply id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.cmml" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1"><plus id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.2"></plus><cn type="integer" id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.3">4</cn><apply id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1"><times id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.1"></times><cn type="integer" id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.2">3</cn><cn type="integer" id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.3">7</cn><cn type="integer" id="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.4.cmml" xref="A1.T3.4.4.2.1.1.1.1.1.m1.1.1.1.1.1.4">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.4.4.2.1.1.1.1.1.m1.1c">4+(3\times 7\times 3)</annotation></semantics></math> sentences</span></span>
<span id="A1.T3.4.4.2.1.1.1.3" class="ltx_tr">
<span id="A1.T3.4.4.2.1.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">= 2,108 sequences</span></span>
</span></span>
</span>
</td>
</tr>
<tr id="A1.T3.5.5" class="ltx_tr">
<td id="A1.T3.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="A1.T3.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.5.2.1.1" class="ltx_p" style="width:85.4pt;">Test set</span>
</span>
</td>
<td id="A1.T3.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="A1.T3.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.5.3.1.1" class="ltx_p" style="width:136.6pt;"><span id="A1.T3.5.5.3.1.1.1" class="ltx_text ltx_font_bold">x</span></span>
</span>
</td>
<td id="A1.T3.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t">
<span id="A1.T3.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T3.5.5.1.1.1" class="ltx_p" style="width:136.6pt;">
<span id="A1.T3.5.5.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A1.T3.5.5.1.1.1.1.2" class="ltx_tr">
<span id="A1.T3.5.5.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">32 identities</span></span>
<span id="A1.T3.5.5.1.1.1.1.1" class="ltx_tr">
<span id="A1.T3.5.5.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="A1.T3.5.5.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="4+(3\times 7\times 3)" display="inline"><semantics id="A1.T3.5.5.1.1.1.1.1.1.m1.1a"><mrow id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.cmml"><mn id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.3" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.3.cmml">4</mn><mo id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.2" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.2.cmml">+</mo><mrow id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.cmml"><mn id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.2" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.1" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.3" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.3.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.1a" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml">Ã—</mo><mn id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.4" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.4.cmml">3</mn></mrow><mo stretchy="false" id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.3" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.5.5.1.1.1.1.1.1.m1.1b"><apply id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1"><plus id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.2"></plus><cn type="integer" id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.3">4</cn><apply id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1"><times id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.1"></times><cn type="integer" id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.2.cmml" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.2">3</cn><cn type="integer" id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.3.cmml" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.3">7</cn><cn type="integer" id="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.4.cmml" xref="A1.T3.5.5.1.1.1.1.1.1.m1.1.1.1.1.1.4">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.5.5.1.1.1.1.1.1.m1.1c">4+(3\times 7\times 3)</annotation></semantics></math> sentences</span></span>
<span id="A1.T3.5.5.1.1.1.1.3" class="ltx_tr">
<span id="A1.T3.5.5.1.1.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">= 1,909 sequences</span></span>
</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A1.T3.7.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>. </span><span id="A1.T3.8.2" class="ltx_text" style="font-size:90%;">Dataset split of 3DMEAD used in our experiments.</span></figcaption>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2. </span>VQ-VAE Background</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.5" class="ltx_p">VQ-VAE <cite class="ltx_cite ltx_citemacro_citep">(Van DenÂ Oord etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2017</a>)</cite> introduces a novel approach by using a discrete codebook to categorically model the input data, rather than using a continuous representation. In a VQ-VAE, the encoder outputs go through a procedure known as vector quantization. Specifically, this involves comparing the encoder output to vectors embedded in a codebook. The codebook comprises discrete vectors, each representing a different category in the data. Initially, the VQ-VAE algorithm selects the nearest vector in the codebook to the encoder output, a process inherently deterministic. However, by incorporating stochastic sampling techniques, the modelâ€™s behavior can be transformed into non-deterministic. The prior distribution <math id="A1.SS2.p1.1.m1.1" class="ltx_Math" alttext="P(z)" display="inline"><semantics id="A1.SS2.p1.1.m1.1a"><mrow id="A1.SS2.p1.1.m1.1.2" xref="A1.SS2.p1.1.m1.1.2.cmml"><mi id="A1.SS2.p1.1.m1.1.2.2" xref="A1.SS2.p1.1.m1.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="A1.SS2.p1.1.m1.1.2.1" xref="A1.SS2.p1.1.m1.1.2.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.1.m1.1.2.3.2" xref="A1.SS2.p1.1.m1.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.1.m1.1.2.3.2.1" xref="A1.SS2.p1.1.m1.1.2.cmml">(</mo><mi id="A1.SS2.p1.1.m1.1.1" xref="A1.SS2.p1.1.m1.1.1.cmml">z</mi><mo stretchy="false" id="A1.SS2.p1.1.m1.1.2.3.2.2" xref="A1.SS2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.m1.1b"><apply id="A1.SS2.p1.1.m1.1.2.cmml" xref="A1.SS2.p1.1.m1.1.2"><times id="A1.SS2.p1.1.m1.1.2.1.cmml" xref="A1.SS2.p1.1.m1.1.2.1"></times><ci id="A1.SS2.p1.1.m1.1.2.2.cmml" xref="A1.SS2.p1.1.m1.1.2.2">ğ‘ƒ</ci><ci id="A1.SS2.p1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.m1.1.1">ğ‘§</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.m1.1c">P(z)</annotation></semantics></math> is a categorical distribution in a VQ-VAE. During the generation process, an embedding vector is sampled from the distribution and decoded to motion. The vector quantization methodology mitigates the posterior collapse often observed in VAEs, where latent variables may be ignored, particularly when coupled with a powerful decoder <cite class="ltx_cite ltx_citemacro_citep">(Van DenÂ Oord etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2017</a>)</cite>. This occurs when the learned latent variables become uninformative due to an overemphasis on minimizing the KL divergence term. The decoder might produce similar outputs, regardless of the latent variable input. Furthermore, the use of a discrete codebook contributes to increased memory efficiency, showcasing its ability to capture crucial features of the input data within a compressed, discrete latent space. In the context of a VQ-VAE, <math id="A1.SS2.p1.2.m2.1" class="ltx_Math" alttext="z_{e}(x)" display="inline"><semantics id="A1.SS2.p1.2.m2.1a"><mrow id="A1.SS2.p1.2.m2.1.2" xref="A1.SS2.p1.2.m2.1.2.cmml"><msub id="A1.SS2.p1.2.m2.1.2.2" xref="A1.SS2.p1.2.m2.1.2.2.cmml"><mi id="A1.SS2.p1.2.m2.1.2.2.2" xref="A1.SS2.p1.2.m2.1.2.2.2.cmml">z</mi><mi id="A1.SS2.p1.2.m2.1.2.2.3" xref="A1.SS2.p1.2.m2.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.SS2.p1.2.m2.1.2.1" xref="A1.SS2.p1.2.m2.1.2.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.2.m2.1.2.3.2" xref="A1.SS2.p1.2.m2.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.2.m2.1.2.3.2.1" xref="A1.SS2.p1.2.m2.1.2.cmml">(</mo><mi id="A1.SS2.p1.2.m2.1.1" xref="A1.SS2.p1.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="A1.SS2.p1.2.m2.1.2.3.2.2" xref="A1.SS2.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.m2.1b"><apply id="A1.SS2.p1.2.m2.1.2.cmml" xref="A1.SS2.p1.2.m2.1.2"><times id="A1.SS2.p1.2.m2.1.2.1.cmml" xref="A1.SS2.p1.2.m2.1.2.1"></times><apply id="A1.SS2.p1.2.m2.1.2.2.cmml" xref="A1.SS2.p1.2.m2.1.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.2.m2.1.2.2.1.cmml" xref="A1.SS2.p1.2.m2.1.2.2">subscript</csymbol><ci id="A1.SS2.p1.2.m2.1.2.2.2.cmml" xref="A1.SS2.p1.2.m2.1.2.2.2">ğ‘§</ci><ci id="A1.SS2.p1.2.m2.1.2.2.3.cmml" xref="A1.SS2.p1.2.m2.1.2.2.3">ğ‘’</ci></apply><ci id="A1.SS2.p1.2.m2.1.1.cmml" xref="A1.SS2.p1.2.m2.1.1">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.m2.1c">z_{e}(x)</annotation></semantics></math> denotes the output of the encoder, <math id="A1.SS2.p1.3.m3.1" class="ltx_Math" alttext="e_{i}" display="inline"><semantics id="A1.SS2.p1.3.m3.1a"><msub id="A1.SS2.p1.3.m3.1.1" xref="A1.SS2.p1.3.m3.1.1.cmml"><mi id="A1.SS2.p1.3.m3.1.1.2" xref="A1.SS2.p1.3.m3.1.1.2.cmml">e</mi><mi id="A1.SS2.p1.3.m3.1.1.3" xref="A1.SS2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.3.m3.1b"><apply id="A1.SS2.p1.3.m3.1.1.cmml" xref="A1.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.3.m3.1.1.1.cmml" xref="A1.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="A1.SS2.p1.3.m3.1.1.2.cmml" xref="A1.SS2.p1.3.m3.1.1.2">ğ‘’</ci><ci id="A1.SS2.p1.3.m3.1.1.3.cmml" xref="A1.SS2.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.3.m3.1c">e_{i}</annotation></semantics></math> represents the <math id="A1.SS2.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="A1.SS2.p1.4.m4.1a"><mi id="A1.SS2.p1.4.m4.1.1" xref="A1.SS2.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.4.m4.1b"><ci id="A1.SS2.p1.4.m4.1.1.cmml" xref="A1.SS2.p1.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.4.m4.1c">i</annotation></semantics></math>-th codebook vector, and <math id="A1.SS2.p1.5.m5.1" class="ltx_Math" alttext="Q(z|x)" display="inline"><semantics id="A1.SS2.p1.5.m5.1a"><mrow id="A1.SS2.p1.5.m5.1.1" xref="A1.SS2.p1.5.m5.1.1.cmml"><mi id="A1.SS2.p1.5.m5.1.1.3" xref="A1.SS2.p1.5.m5.1.1.3.cmml">Q</mi><mo lspace="0em" rspace="0em" id="A1.SS2.p1.5.m5.1.1.2" xref="A1.SS2.p1.5.m5.1.1.2.cmml">â€‹</mo><mrow id="A1.SS2.p1.5.m5.1.1.1.1" xref="A1.SS2.p1.5.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.SS2.p1.5.m5.1.1.1.1.2" xref="A1.SS2.p1.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="A1.SS2.p1.5.m5.1.1.1.1.1" xref="A1.SS2.p1.5.m5.1.1.1.1.1.cmml"><mi id="A1.SS2.p1.5.m5.1.1.1.1.1.2" xref="A1.SS2.p1.5.m5.1.1.1.1.1.2.cmml">z</mi><mo fence="false" id="A1.SS2.p1.5.m5.1.1.1.1.1.1" xref="A1.SS2.p1.5.m5.1.1.1.1.1.1.cmml">|</mo><mi id="A1.SS2.p1.5.m5.1.1.1.1.1.3" xref="A1.SS2.p1.5.m5.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="A1.SS2.p1.5.m5.1.1.1.1.3" xref="A1.SS2.p1.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.5.m5.1b"><apply id="A1.SS2.p1.5.m5.1.1.cmml" xref="A1.SS2.p1.5.m5.1.1"><times id="A1.SS2.p1.5.m5.1.1.2.cmml" xref="A1.SS2.p1.5.m5.1.1.2"></times><ci id="A1.SS2.p1.5.m5.1.1.3.cmml" xref="A1.SS2.p1.5.m5.1.1.3">ğ‘„</ci><apply id="A1.SS2.p1.5.m5.1.1.1.1.1.cmml" xref="A1.SS2.p1.5.m5.1.1.1.1"><csymbol cd="latexml" id="A1.SS2.p1.5.m5.1.1.1.1.1.1.cmml" xref="A1.SS2.p1.5.m5.1.1.1.1.1.1">conditional</csymbol><ci id="A1.SS2.p1.5.m5.1.1.1.1.1.2.cmml" xref="A1.SS2.p1.5.m5.1.1.1.1.1.2">ğ‘§</ci><ci id="A1.SS2.p1.5.m5.1.1.1.1.1.3.cmml" xref="A1.SS2.p1.5.m5.1.1.1.1.1.3">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.5.m5.1c">Q(z|x)</annotation></semantics></math> is the approximate posterior categorical distribution, defined as one-hot vectors:</p>
<table id="A1.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(11)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.E11.m1.5" class="ltx_Math" alttext="Q(z=k|x)=\begin{cases}1&amp;\text{for }k=\text{argmin}_{i}\|z_{e}(x)-e_{i}\|_{2},\\
0&amp;\text{otherwise.}\end{cases}" display="block"><semantics id="A1.E11.m1.5a"><mrow id="A1.E11.m1.5.5" xref="A1.E11.m1.5.5.cmml"><mrow id="A1.E11.m1.5.5.1" xref="A1.E11.m1.5.5.1.cmml"><mi id="A1.E11.m1.5.5.1.3" xref="A1.E11.m1.5.5.1.3.cmml">Q</mi><mo lspace="0em" rspace="0em" id="A1.E11.m1.5.5.1.2" xref="A1.E11.m1.5.5.1.2.cmml">â€‹</mo><mrow id="A1.E11.m1.5.5.1.1.1" xref="A1.E11.m1.5.5.1.1.1.1.cmml"><mo stretchy="false" id="A1.E11.m1.5.5.1.1.1.2" xref="A1.E11.m1.5.5.1.1.1.1.cmml">(</mo><mrow id="A1.E11.m1.5.5.1.1.1.1" xref="A1.E11.m1.5.5.1.1.1.1.cmml"><mi id="A1.E11.m1.5.5.1.1.1.1.2" xref="A1.E11.m1.5.5.1.1.1.1.2.cmml">z</mi><mo id="A1.E11.m1.5.5.1.1.1.1.1" xref="A1.E11.m1.5.5.1.1.1.1.1.cmml">=</mo><mrow id="A1.E11.m1.5.5.1.1.1.1.3" xref="A1.E11.m1.5.5.1.1.1.1.3.cmml"><mi id="A1.E11.m1.5.5.1.1.1.1.3.2" xref="A1.E11.m1.5.5.1.1.1.1.3.2.cmml">k</mi><mo fence="false" id="A1.E11.m1.5.5.1.1.1.1.3.1" xref="A1.E11.m1.5.5.1.1.1.1.3.1.cmml">|</mo><mi id="A1.E11.m1.5.5.1.1.1.1.3.3" xref="A1.E11.m1.5.5.1.1.1.1.3.3.cmml">x</mi></mrow></mrow><mo stretchy="false" id="A1.E11.m1.5.5.1.1.1.3" xref="A1.E11.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E11.m1.5.5.2" xref="A1.E11.m1.5.5.2.cmml">=</mo><mrow id="A1.E11.m1.4.4" xref="A1.E11.m1.5.5.3.1.cmml"><mo id="A1.E11.m1.4.4.5" xref="A1.E11.m1.5.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="A1.E11.m1.4.4.4" xref="A1.E11.m1.5.5.3.1.cmml"><mtr id="A1.E11.m1.4.4.4a" xref="A1.E11.m1.5.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="A1.E11.m1.4.4.4b" xref="A1.E11.m1.5.5.3.1.cmml"><mn id="A1.E11.m1.1.1.1.1.1.1" xref="A1.E11.m1.1.1.1.1.1.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="A1.E11.m1.4.4.4c" xref="A1.E11.m1.5.5.3.1.cmml"><mrow id="A1.E11.m1.2.2.2.2.2.1.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.cmml"><mrow id="A1.E11.m1.2.2.2.2.2.1.2.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.cmml"><mrow id="A1.E11.m1.2.2.2.2.2.1.2.1.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3.cmml"><mtext id="A1.E11.m1.2.2.2.2.2.1.2.1.3.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3.2a.cmml">forÂ </mtext><mo lspace="0em" rspace="0em" id="A1.E11.m1.2.2.2.2.2.1.2.1.3.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3.1.cmml">â€‹</mo><mi id="A1.E11.m1.2.2.2.2.2.1.2.1.3.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3.3.cmml">k</mi></mrow><mo id="A1.E11.m1.2.2.2.2.2.1.2.1.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.2.cmml">=</mo><mrow id="A1.E11.m1.2.2.2.2.2.1.2.1.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.cmml"><msub id="A1.E11.m1.2.2.2.2.2.1.2.1.1.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.cmml"><mtext id="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.2a.cmml">argmin</mtext><mi id="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.2.cmml">â€‹</mo><msub id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.cmml"><mrow id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.2.cmml"><mo stretchy="false" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.2.1.cmml">â€–</mo><mrow id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.cmml"><mrow id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.cmml"><msub id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.cmml"><mi id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.2.cmml">z</mi><mi id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.3.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.3.2.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.cmml">(</mo><mi id="A1.E11.m1.2.2.2.2.2.1.1" xref="A1.E11.m1.2.2.2.2.2.1.1.cmml">x</mi><mo stretchy="false" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.3.2.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.1" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.cmml"><mi id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.2.cmml">e</mi><mi id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.3" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.3.cmml">2</mn></msub></mrow></mrow><mo id="A1.E11.m1.2.2.2.2.2.1.2.2" xref="A1.E11.m1.2.2.2.2.2.1.2.1.cmml">,</mo></mrow></mtd></mtr><mtr id="A1.E11.m1.4.4.4d" xref="A1.E11.m1.5.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="A1.E11.m1.4.4.4e" xref="A1.E11.m1.5.5.3.1.cmml"><mn id="A1.E11.m1.3.3.3.3.1.1" xref="A1.E11.m1.3.3.3.3.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="A1.E11.m1.4.4.4f" xref="A1.E11.m1.5.5.3.1.cmml"><mtext id="A1.E11.m1.4.4.4.4.2.1" xref="A1.E11.m1.4.4.4.4.2.1a.cmml">otherwise.</mtext></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E11.m1.5b"><apply id="A1.E11.m1.5.5.cmml" xref="A1.E11.m1.5.5"><eq id="A1.E11.m1.5.5.2.cmml" xref="A1.E11.m1.5.5.2"></eq><apply id="A1.E11.m1.5.5.1.cmml" xref="A1.E11.m1.5.5.1"><times id="A1.E11.m1.5.5.1.2.cmml" xref="A1.E11.m1.5.5.1.2"></times><ci id="A1.E11.m1.5.5.1.3.cmml" xref="A1.E11.m1.5.5.1.3">ğ‘„</ci><apply id="A1.E11.m1.5.5.1.1.1.1.cmml" xref="A1.E11.m1.5.5.1.1.1"><eq id="A1.E11.m1.5.5.1.1.1.1.1.cmml" xref="A1.E11.m1.5.5.1.1.1.1.1"></eq><ci id="A1.E11.m1.5.5.1.1.1.1.2.cmml" xref="A1.E11.m1.5.5.1.1.1.1.2">ğ‘§</ci><apply id="A1.E11.m1.5.5.1.1.1.1.3.cmml" xref="A1.E11.m1.5.5.1.1.1.1.3"><csymbol cd="latexml" id="A1.E11.m1.5.5.1.1.1.1.3.1.cmml" xref="A1.E11.m1.5.5.1.1.1.1.3.1">conditional</csymbol><ci id="A1.E11.m1.5.5.1.1.1.1.3.2.cmml" xref="A1.E11.m1.5.5.1.1.1.1.3.2">ğ‘˜</ci><ci id="A1.E11.m1.5.5.1.1.1.1.3.3.cmml" xref="A1.E11.m1.5.5.1.1.1.1.3.3">ğ‘¥</ci></apply></apply></apply><apply id="A1.E11.m1.5.5.3.1.cmml" xref="A1.E11.m1.4.4"><csymbol cd="latexml" id="A1.E11.m1.5.5.3.1.1.cmml" xref="A1.E11.m1.4.4.5">cases</csymbol><cn type="integer" id="A1.E11.m1.1.1.1.1.1.1.cmml" xref="A1.E11.m1.1.1.1.1.1.1">1</cn><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2"><eq id="A1.E11.m1.2.2.2.2.2.1.2.1.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.2"></eq><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.3.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3"><times id="A1.E11.m1.2.2.2.2.2.1.2.1.3.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3.1"></times><ci id="A1.E11.m1.2.2.2.2.2.1.2.1.3.2a.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3.2"><mtext id="A1.E11.m1.2.2.2.2.2.1.2.1.3.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3.2">forÂ </mtext></ci><ci id="A1.E11.m1.2.2.2.2.2.1.2.1.3.3.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.3.3">ğ‘˜</ci></apply><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1"><times id="A1.E11.m1.2.2.2.2.2.1.2.1.1.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.2"></times><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.3"><csymbol cd="ambiguous" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.3">subscript</csymbol><ci id="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.2a.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.2"><mtext id="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.2">argmin</mtext></ci><ci id="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.3.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.3.3">ğ‘–</ci></apply><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1"><csymbol cd="ambiguous" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1">subscript</csymbol><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1"><csymbol cd="latexml" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.2.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.2">norm</csymbol><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1"><minus id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.1"></minus><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2"><times id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.1"></times><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.2">ğ‘§</ci><ci id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.3.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.2.2.3">ğ‘’</ci></apply><ci id="A1.E11.m1.2.2.2.2.2.1.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.1">ğ‘¥</ci></apply><apply id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.1.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.2.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.2">ğ‘’</ci><ci id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.3.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><cn type="integer" id="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.3.cmml" xref="A1.E11.m1.2.2.2.2.2.1.2.1.1.1.3">2</cn></apply></apply></apply><cn type="integer" id="A1.E11.m1.3.3.3.3.1.1.cmml" xref="A1.E11.m1.3.3.3.3.1.1">0</cn><ci id="A1.E11.m1.4.4.4.4.2.1a.cmml" xref="A1.E11.m1.4.4.4.4.2.1"><mtext id="A1.E11.m1.4.4.4.4.2.1.cmml" xref="A1.E11.m1.4.4.4.4.2.1">otherwise.</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E11.m1.5c">Q(z=k|x)=\begin{cases}1&amp;\text{for }k=\text{argmin}_{i}\|z_{e}(x)-e_{i}\|_{2},\\
0&amp;\text{otherwise.}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A1.SS2.p1.10" class="ltx_p">In the given equation, <math id="A1.SS2.p1.6.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.SS2.p1.6.m1.1a"><mi id="A1.SS2.p1.6.m1.1.1" xref="A1.SS2.p1.6.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.6.m1.1b"><ci id="A1.SS2.p1.6.m1.1.1.cmml" xref="A1.SS2.p1.6.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.6.m1.1c">k</annotation></semantics></math> is the codebook index corresponding to the embedding <math id="A1.SS2.p1.7.m2.1" class="ltx_Math" alttext="e" display="inline"><semantics id="A1.SS2.p1.7.m2.1a"><mi id="A1.SS2.p1.7.m2.1.1" xref="A1.SS2.p1.7.m2.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.7.m2.1b"><ci id="A1.SS2.p1.7.m2.1.1.cmml" xref="A1.SS2.p1.7.m2.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.7.m2.1c">e</annotation></semantics></math> with the minimum distance from <math id="A1.SS2.p1.8.m3.1" class="ltx_Math" alttext="z_{e}(x)" display="inline"><semantics id="A1.SS2.p1.8.m3.1a"><mrow id="A1.SS2.p1.8.m3.1.2" xref="A1.SS2.p1.8.m3.1.2.cmml"><msub id="A1.SS2.p1.8.m3.1.2.2" xref="A1.SS2.p1.8.m3.1.2.2.cmml"><mi id="A1.SS2.p1.8.m3.1.2.2.2" xref="A1.SS2.p1.8.m3.1.2.2.2.cmml">z</mi><mi id="A1.SS2.p1.8.m3.1.2.2.3" xref="A1.SS2.p1.8.m3.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.SS2.p1.8.m3.1.2.1" xref="A1.SS2.p1.8.m3.1.2.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.8.m3.1.2.3.2" xref="A1.SS2.p1.8.m3.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.8.m3.1.2.3.2.1" xref="A1.SS2.p1.8.m3.1.2.cmml">(</mo><mi id="A1.SS2.p1.8.m3.1.1" xref="A1.SS2.p1.8.m3.1.1.cmml">x</mi><mo stretchy="false" id="A1.SS2.p1.8.m3.1.2.3.2.2" xref="A1.SS2.p1.8.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.8.m3.1b"><apply id="A1.SS2.p1.8.m3.1.2.cmml" xref="A1.SS2.p1.8.m3.1.2"><times id="A1.SS2.p1.8.m3.1.2.1.cmml" xref="A1.SS2.p1.8.m3.1.2.1"></times><apply id="A1.SS2.p1.8.m3.1.2.2.cmml" xref="A1.SS2.p1.8.m3.1.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.8.m3.1.2.2.1.cmml" xref="A1.SS2.p1.8.m3.1.2.2">subscript</csymbol><ci id="A1.SS2.p1.8.m3.1.2.2.2.cmml" xref="A1.SS2.p1.8.m3.1.2.2.2">ğ‘§</ci><ci id="A1.SS2.p1.8.m3.1.2.2.3.cmml" xref="A1.SS2.p1.8.m3.1.2.2.3">ğ‘’</ci></apply><ci id="A1.SS2.p1.8.m3.1.1.cmml" xref="A1.SS2.p1.8.m3.1.1">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.8.m3.1c">z_{e}(x)</annotation></semantics></math>. The quantization process maps the encoder outputs <math id="A1.SS2.p1.9.m4.1" class="ltx_Math" alttext="z_{e}(x)" display="inline"><semantics id="A1.SS2.p1.9.m4.1a"><mrow id="A1.SS2.p1.9.m4.1.2" xref="A1.SS2.p1.9.m4.1.2.cmml"><msub id="A1.SS2.p1.9.m4.1.2.2" xref="A1.SS2.p1.9.m4.1.2.2.cmml"><mi id="A1.SS2.p1.9.m4.1.2.2.2" xref="A1.SS2.p1.9.m4.1.2.2.2.cmml">z</mi><mi id="A1.SS2.p1.9.m4.1.2.2.3" xref="A1.SS2.p1.9.m4.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.SS2.p1.9.m4.1.2.1" xref="A1.SS2.p1.9.m4.1.2.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.9.m4.1.2.3.2" xref="A1.SS2.p1.9.m4.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.9.m4.1.2.3.2.1" xref="A1.SS2.p1.9.m4.1.2.cmml">(</mo><mi id="A1.SS2.p1.9.m4.1.1" xref="A1.SS2.p1.9.m4.1.1.cmml">x</mi><mo stretchy="false" id="A1.SS2.p1.9.m4.1.2.3.2.2" xref="A1.SS2.p1.9.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.9.m4.1b"><apply id="A1.SS2.p1.9.m4.1.2.cmml" xref="A1.SS2.p1.9.m4.1.2"><times id="A1.SS2.p1.9.m4.1.2.1.cmml" xref="A1.SS2.p1.9.m4.1.2.1"></times><apply id="A1.SS2.p1.9.m4.1.2.2.cmml" xref="A1.SS2.p1.9.m4.1.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.9.m4.1.2.2.1.cmml" xref="A1.SS2.p1.9.m4.1.2.2">subscript</csymbol><ci id="A1.SS2.p1.9.m4.1.2.2.2.cmml" xref="A1.SS2.p1.9.m4.1.2.2.2">ğ‘§</ci><ci id="A1.SS2.p1.9.m4.1.2.2.3.cmml" xref="A1.SS2.p1.9.m4.1.2.2.3">ğ‘’</ci></apply><ci id="A1.SS2.p1.9.m4.1.1.cmml" xref="A1.SS2.p1.9.m4.1.1">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.9.m4.1c">z_{e}(x)</annotation></semantics></math> to the nearest embedding vectors in the codebook, resulting in a quantized vector <math id="A1.SS2.p1.10.m5.1" class="ltx_Math" alttext="z_{Q}(x)" display="inline"><semantics id="A1.SS2.p1.10.m5.1a"><mrow id="A1.SS2.p1.10.m5.1.2" xref="A1.SS2.p1.10.m5.1.2.cmml"><msub id="A1.SS2.p1.10.m5.1.2.2" xref="A1.SS2.p1.10.m5.1.2.2.cmml"><mi id="A1.SS2.p1.10.m5.1.2.2.2" xref="A1.SS2.p1.10.m5.1.2.2.2.cmml">z</mi><mi id="A1.SS2.p1.10.m5.1.2.2.3" xref="A1.SS2.p1.10.m5.1.2.2.3.cmml">Q</mi></msub><mo lspace="0em" rspace="0em" id="A1.SS2.p1.10.m5.1.2.1" xref="A1.SS2.p1.10.m5.1.2.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.10.m5.1.2.3.2" xref="A1.SS2.p1.10.m5.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.10.m5.1.2.3.2.1" xref="A1.SS2.p1.10.m5.1.2.cmml">(</mo><mi id="A1.SS2.p1.10.m5.1.1" xref="A1.SS2.p1.10.m5.1.1.cmml">x</mi><mo stretchy="false" id="A1.SS2.p1.10.m5.1.2.3.2.2" xref="A1.SS2.p1.10.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.10.m5.1b"><apply id="A1.SS2.p1.10.m5.1.2.cmml" xref="A1.SS2.p1.10.m5.1.2"><times id="A1.SS2.p1.10.m5.1.2.1.cmml" xref="A1.SS2.p1.10.m5.1.2.1"></times><apply id="A1.SS2.p1.10.m5.1.2.2.cmml" xref="A1.SS2.p1.10.m5.1.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.10.m5.1.2.2.1.cmml" xref="A1.SS2.p1.10.m5.1.2.2">subscript</csymbol><ci id="A1.SS2.p1.10.m5.1.2.2.2.cmml" xref="A1.SS2.p1.10.m5.1.2.2.2">ğ‘§</ci><ci id="A1.SS2.p1.10.m5.1.2.2.3.cmml" xref="A1.SS2.p1.10.m5.1.2.2.3">ğ‘„</ci></apply><ci id="A1.SS2.p1.10.m5.1.1.cmml" xref="A1.SS2.p1.10.m5.1.1">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.10.m5.1c">z_{Q}(x)</annotation></semantics></math>. It can be formulated as equation (<a href="#A1.E12" title="In A.2. VQ-VAE Background â€£ Appendix A Supplementary Material â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>).</p>
<table id="A1.E12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(12)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.E12.m1.4" class="ltx_Math" alttext="z_{Q}(x)=e_{k},\text{where }k=\text{argmin}_{i}\|z_{e}(x)-e_{i}\|_{2}" display="block"><semantics id="A1.E12.m1.4a"><mrow id="A1.E12.m1.4.4.2" xref="A1.E12.m1.4.4.3.cmml"><mrow id="A1.E12.m1.3.3.1.1" xref="A1.E12.m1.3.3.1.1.cmml"><mrow id="A1.E12.m1.3.3.1.1.2" xref="A1.E12.m1.3.3.1.1.2.cmml"><msub id="A1.E12.m1.3.3.1.1.2.2" xref="A1.E12.m1.3.3.1.1.2.2.cmml"><mi id="A1.E12.m1.3.3.1.1.2.2.2" xref="A1.E12.m1.3.3.1.1.2.2.2.cmml">z</mi><mi id="A1.E12.m1.3.3.1.1.2.2.3" xref="A1.E12.m1.3.3.1.1.2.2.3.cmml">Q</mi></msub><mo lspace="0em" rspace="0em" id="A1.E12.m1.3.3.1.1.2.1" xref="A1.E12.m1.3.3.1.1.2.1.cmml">â€‹</mo><mrow id="A1.E12.m1.3.3.1.1.2.3.2" xref="A1.E12.m1.3.3.1.1.2.cmml"><mo stretchy="false" id="A1.E12.m1.3.3.1.1.2.3.2.1" xref="A1.E12.m1.3.3.1.1.2.cmml">(</mo><mi id="A1.E12.m1.1.1" xref="A1.E12.m1.1.1.cmml">x</mi><mo stretchy="false" id="A1.E12.m1.3.3.1.1.2.3.2.2" xref="A1.E12.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.E12.m1.3.3.1.1.1" xref="A1.E12.m1.3.3.1.1.1.cmml">=</mo><msub id="A1.E12.m1.3.3.1.1.3" xref="A1.E12.m1.3.3.1.1.3.cmml"><mi id="A1.E12.m1.3.3.1.1.3.2" xref="A1.E12.m1.3.3.1.1.3.2.cmml">e</mi><mi id="A1.E12.m1.3.3.1.1.3.3" xref="A1.E12.m1.3.3.1.1.3.3.cmml">k</mi></msub></mrow><mo id="A1.E12.m1.4.4.2.3" xref="A1.E12.m1.4.4.3a.cmml">,</mo><mrow id="A1.E12.m1.4.4.2.2" xref="A1.E12.m1.4.4.2.2.cmml"><mrow id="A1.E12.m1.4.4.2.2.3" xref="A1.E12.m1.4.4.2.2.3.cmml"><mtext id="A1.E12.m1.4.4.2.2.3.2" xref="A1.E12.m1.4.4.2.2.3.2a.cmml">whereÂ </mtext><mo lspace="0em" rspace="0em" id="A1.E12.m1.4.4.2.2.3.1" xref="A1.E12.m1.4.4.2.2.3.1.cmml">â€‹</mo><mi id="A1.E12.m1.4.4.2.2.3.3" xref="A1.E12.m1.4.4.2.2.3.3.cmml">k</mi></mrow><mo id="A1.E12.m1.4.4.2.2.2" xref="A1.E12.m1.4.4.2.2.2.cmml">=</mo><mrow id="A1.E12.m1.4.4.2.2.1" xref="A1.E12.m1.4.4.2.2.1.cmml"><msub id="A1.E12.m1.4.4.2.2.1.3" xref="A1.E12.m1.4.4.2.2.1.3.cmml"><mtext id="A1.E12.m1.4.4.2.2.1.3.2" xref="A1.E12.m1.4.4.2.2.1.3.2a.cmml">argmin</mtext><mi id="A1.E12.m1.4.4.2.2.1.3.3" xref="A1.E12.m1.4.4.2.2.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="A1.E12.m1.4.4.2.2.1.2" xref="A1.E12.m1.4.4.2.2.1.2.cmml">â€‹</mo><msub id="A1.E12.m1.4.4.2.2.1.1" xref="A1.E12.m1.4.4.2.2.1.1.cmml"><mrow id="A1.E12.m1.4.4.2.2.1.1.1.1" xref="A1.E12.m1.4.4.2.2.1.1.1.2.cmml"><mo stretchy="false" id="A1.E12.m1.4.4.2.2.1.1.1.1.2" xref="A1.E12.m1.4.4.2.2.1.1.1.2.1.cmml">â€–</mo><mrow id="A1.E12.m1.4.4.2.2.1.1.1.1.1" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.cmml"><mrow id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.cmml"><msub id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.cmml"><mi id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.2" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.2.cmml">z</mi><mi id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.3" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.1" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.3.2" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.3.2.1" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.cmml">(</mo><mi id="A1.E12.m1.2.2" xref="A1.E12.m1.2.2.cmml">x</mi><mo stretchy="false" id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.3.2.2" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.E12.m1.4.4.2.2.1.1.1.1.1.1" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="A1.E12.m1.4.4.2.2.1.1.1.1.1.3" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.cmml"><mi id="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.2" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.2.cmml">e</mi><mi id="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.3" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="A1.E12.m1.4.4.2.2.1.1.1.1.3" xref="A1.E12.m1.4.4.2.2.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="A1.E12.m1.4.4.2.2.1.1.3" xref="A1.E12.m1.4.4.2.2.1.1.3.cmml">2</mn></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E12.m1.4b"><apply id="A1.E12.m1.4.4.3.cmml" xref="A1.E12.m1.4.4.2"><csymbol cd="ambiguous" id="A1.E12.m1.4.4.3a.cmml" xref="A1.E12.m1.4.4.2.3">formulae-sequence</csymbol><apply id="A1.E12.m1.3.3.1.1.cmml" xref="A1.E12.m1.3.3.1.1"><eq id="A1.E12.m1.3.3.1.1.1.cmml" xref="A1.E12.m1.3.3.1.1.1"></eq><apply id="A1.E12.m1.3.3.1.1.2.cmml" xref="A1.E12.m1.3.3.1.1.2"><times id="A1.E12.m1.3.3.1.1.2.1.cmml" xref="A1.E12.m1.3.3.1.1.2.1"></times><apply id="A1.E12.m1.3.3.1.1.2.2.cmml" xref="A1.E12.m1.3.3.1.1.2.2"><csymbol cd="ambiguous" id="A1.E12.m1.3.3.1.1.2.2.1.cmml" xref="A1.E12.m1.3.3.1.1.2.2">subscript</csymbol><ci id="A1.E12.m1.3.3.1.1.2.2.2.cmml" xref="A1.E12.m1.3.3.1.1.2.2.2">ğ‘§</ci><ci id="A1.E12.m1.3.3.1.1.2.2.3.cmml" xref="A1.E12.m1.3.3.1.1.2.2.3">ğ‘„</ci></apply><ci id="A1.E12.m1.1.1.cmml" xref="A1.E12.m1.1.1">ğ‘¥</ci></apply><apply id="A1.E12.m1.3.3.1.1.3.cmml" xref="A1.E12.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="A1.E12.m1.3.3.1.1.3.1.cmml" xref="A1.E12.m1.3.3.1.1.3">subscript</csymbol><ci id="A1.E12.m1.3.3.1.1.3.2.cmml" xref="A1.E12.m1.3.3.1.1.3.2">ğ‘’</ci><ci id="A1.E12.m1.3.3.1.1.3.3.cmml" xref="A1.E12.m1.3.3.1.1.3.3">ğ‘˜</ci></apply></apply><apply id="A1.E12.m1.4.4.2.2.cmml" xref="A1.E12.m1.4.4.2.2"><eq id="A1.E12.m1.4.4.2.2.2.cmml" xref="A1.E12.m1.4.4.2.2.2"></eq><apply id="A1.E12.m1.4.4.2.2.3.cmml" xref="A1.E12.m1.4.4.2.2.3"><times id="A1.E12.m1.4.4.2.2.3.1.cmml" xref="A1.E12.m1.4.4.2.2.3.1"></times><ci id="A1.E12.m1.4.4.2.2.3.2a.cmml" xref="A1.E12.m1.4.4.2.2.3.2"><mtext id="A1.E12.m1.4.4.2.2.3.2.cmml" xref="A1.E12.m1.4.4.2.2.3.2">whereÂ </mtext></ci><ci id="A1.E12.m1.4.4.2.2.3.3.cmml" xref="A1.E12.m1.4.4.2.2.3.3">ğ‘˜</ci></apply><apply id="A1.E12.m1.4.4.2.2.1.cmml" xref="A1.E12.m1.4.4.2.2.1"><times id="A1.E12.m1.4.4.2.2.1.2.cmml" xref="A1.E12.m1.4.4.2.2.1.2"></times><apply id="A1.E12.m1.4.4.2.2.1.3.cmml" xref="A1.E12.m1.4.4.2.2.1.3"><csymbol cd="ambiguous" id="A1.E12.m1.4.4.2.2.1.3.1.cmml" xref="A1.E12.m1.4.4.2.2.1.3">subscript</csymbol><ci id="A1.E12.m1.4.4.2.2.1.3.2a.cmml" xref="A1.E12.m1.4.4.2.2.1.3.2"><mtext id="A1.E12.m1.4.4.2.2.1.3.2.cmml" xref="A1.E12.m1.4.4.2.2.1.3.2">argmin</mtext></ci><ci id="A1.E12.m1.4.4.2.2.1.3.3.cmml" xref="A1.E12.m1.4.4.2.2.1.3.3">ğ‘–</ci></apply><apply id="A1.E12.m1.4.4.2.2.1.1.cmml" xref="A1.E12.m1.4.4.2.2.1.1"><csymbol cd="ambiguous" id="A1.E12.m1.4.4.2.2.1.1.2.cmml" xref="A1.E12.m1.4.4.2.2.1.1">subscript</csymbol><apply id="A1.E12.m1.4.4.2.2.1.1.1.2.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1"><csymbol cd="latexml" id="A1.E12.m1.4.4.2.2.1.1.1.2.1.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.2">norm</csymbol><apply id="A1.E12.m1.4.4.2.2.1.1.1.1.1.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1"><minus id="A1.E12.m1.4.4.2.2.1.1.1.1.1.1.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.1"></minus><apply id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2"><times id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.1.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.1"></times><apply id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.1.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.2.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.2">ğ‘§</ci><ci id="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.3.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.2.2.3">ğ‘’</ci></apply><ci id="A1.E12.m1.2.2.cmml" xref="A1.E12.m1.2.2">ğ‘¥</ci></apply><apply id="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.1.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.2.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.2">ğ‘’</ci><ci id="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.3.cmml" xref="A1.E12.m1.4.4.2.2.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><cn type="integer" id="A1.E12.m1.4.4.2.2.1.1.3.cmml" xref="A1.E12.m1.4.4.2.2.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E12.m1.4c">z_{Q}(x)=e_{k},\text{where }k=\text{argmin}_{i}\|z_{e}(x)-e_{i}\|_{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A1.SS2.p1.17" class="ltx_p">The total training objective is expressed as:</p>
<table id="A1.E13" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(13)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.E13.m1.7" class="ltx_Math" alttext="\mathcal{L}=\log P(x|z_{Q}(x))+\|\text{sg}[z_{e}(x)]-e\|_{2}^{2}+\beta\|z_{e}(x)-\text{sg}[e]\|_{2}^{2}" display="block"><semantics id="A1.E13.m1.7a"><mrow id="A1.E13.m1.7.7" xref="A1.E13.m1.7.7.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E13.m1.7.7.5" xref="A1.E13.m1.7.7.5.cmml">â„’</mi><mo id="A1.E13.m1.7.7.4" xref="A1.E13.m1.7.7.4.cmml">=</mo><mrow id="A1.E13.m1.7.7.3" xref="A1.E13.m1.7.7.3.cmml"><mrow id="A1.E13.m1.5.5.1.1" xref="A1.E13.m1.5.5.1.1.cmml"><mrow id="A1.E13.m1.5.5.1.1.3" xref="A1.E13.m1.5.5.1.1.3.cmml"><mi id="A1.E13.m1.5.5.1.1.3.1" xref="A1.E13.m1.5.5.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="A1.E13.m1.5.5.1.1.3a" xref="A1.E13.m1.5.5.1.1.3.cmml">â¡</mo><mi id="A1.E13.m1.5.5.1.1.3.2" xref="A1.E13.m1.5.5.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="A1.E13.m1.5.5.1.1.2" xref="A1.E13.m1.5.5.1.1.2.cmml">â€‹</mo><mrow id="A1.E13.m1.5.5.1.1.1.1" xref="A1.E13.m1.5.5.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.E13.m1.5.5.1.1.1.1.2" xref="A1.E13.m1.5.5.1.1.1.1.1.cmml">(</mo><mrow id="A1.E13.m1.5.5.1.1.1.1.1" xref="A1.E13.m1.5.5.1.1.1.1.1.cmml"><mi id="A1.E13.m1.5.5.1.1.1.1.1.2" xref="A1.E13.m1.5.5.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="A1.E13.m1.5.5.1.1.1.1.1.1" xref="A1.E13.m1.5.5.1.1.1.1.1.1.cmml">|</mo><mrow id="A1.E13.m1.5.5.1.1.1.1.1.3" xref="A1.E13.m1.5.5.1.1.1.1.1.3.cmml"><msub id="A1.E13.m1.5.5.1.1.1.1.1.3.2" xref="A1.E13.m1.5.5.1.1.1.1.1.3.2.cmml"><mi id="A1.E13.m1.5.5.1.1.1.1.1.3.2.2" xref="A1.E13.m1.5.5.1.1.1.1.1.3.2.2.cmml">z</mi><mi id="A1.E13.m1.5.5.1.1.1.1.1.3.2.3" xref="A1.E13.m1.5.5.1.1.1.1.1.3.2.3.cmml">Q</mi></msub><mo lspace="0em" rspace="0em" id="A1.E13.m1.5.5.1.1.1.1.1.3.1" xref="A1.E13.m1.5.5.1.1.1.1.1.3.1.cmml">â€‹</mo><mrow id="A1.E13.m1.5.5.1.1.1.1.1.3.3.2" xref="A1.E13.m1.5.5.1.1.1.1.1.3.cmml"><mo stretchy="false" id="A1.E13.m1.5.5.1.1.1.1.1.3.3.2.1" xref="A1.E13.m1.5.5.1.1.1.1.1.3.cmml">(</mo><mi id="A1.E13.m1.1.1" xref="A1.E13.m1.1.1.cmml">x</mi><mo stretchy="false" id="A1.E13.m1.5.5.1.1.1.1.1.3.3.2.2" xref="A1.E13.m1.5.5.1.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="A1.E13.m1.5.5.1.1.1.1.3" xref="A1.E13.m1.5.5.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.E13.m1.7.7.3.4" xref="A1.E13.m1.7.7.3.4.cmml">+</mo><msubsup id="A1.E13.m1.6.6.2.2" xref="A1.E13.m1.6.6.2.2.cmml"><mrow id="A1.E13.m1.6.6.2.2.1.1.1" xref="A1.E13.m1.6.6.2.2.1.1.2.cmml"><mo stretchy="false" id="A1.E13.m1.6.6.2.2.1.1.1.2" xref="A1.E13.m1.6.6.2.2.1.1.2.1.cmml">â€–</mo><mrow id="A1.E13.m1.6.6.2.2.1.1.1.1" xref="A1.E13.m1.6.6.2.2.1.1.1.1.cmml"><mrow id="A1.E13.m1.6.6.2.2.1.1.1.1.1" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.cmml"><mtext id="A1.E13.m1.6.6.2.2.1.1.1.1.1.3" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.3a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="A1.E13.m1.6.6.2.2.1.1.1.1.1.2" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.2" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.2" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.2.cmml">z</mi><mi id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.3" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.1" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.3.2" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.3.2.1" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="A1.E13.m1.2.2" xref="A1.E13.m1.2.2.cmml">x</mi><mo stretchy="false" id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.3.2.2" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.3" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="A1.E13.m1.6.6.2.2.1.1.1.1.2" xref="A1.E13.m1.6.6.2.2.1.1.1.1.2.cmml">âˆ’</mo><mi id="A1.E13.m1.6.6.2.2.1.1.1.1.3" xref="A1.E13.m1.6.6.2.2.1.1.1.1.3.cmml">e</mi></mrow><mo stretchy="false" id="A1.E13.m1.6.6.2.2.1.1.1.3" xref="A1.E13.m1.6.6.2.2.1.1.2.1.cmml">â€–</mo></mrow><mn id="A1.E13.m1.6.6.2.2.1.3" xref="A1.E13.m1.6.6.2.2.1.3.cmml">2</mn><mn id="A1.E13.m1.6.6.2.2.3" xref="A1.E13.m1.6.6.2.2.3.cmml">2</mn></msubsup><mo id="A1.E13.m1.7.7.3.4a" xref="A1.E13.m1.7.7.3.4.cmml">+</mo><mrow id="A1.E13.m1.7.7.3.3" xref="A1.E13.m1.7.7.3.3.cmml"><mi id="A1.E13.m1.7.7.3.3.3" xref="A1.E13.m1.7.7.3.3.3.cmml">Î²</mi><mo lspace="0em" rspace="0em" id="A1.E13.m1.7.7.3.3.2" xref="A1.E13.m1.7.7.3.3.2.cmml">â€‹</mo><msubsup id="A1.E13.m1.7.7.3.3.1" xref="A1.E13.m1.7.7.3.3.1.cmml"><mrow id="A1.E13.m1.7.7.3.3.1.1.1.1" xref="A1.E13.m1.7.7.3.3.1.1.1.2.cmml"><mo stretchy="false" id="A1.E13.m1.7.7.3.3.1.1.1.1.2" xref="A1.E13.m1.7.7.3.3.1.1.1.2.1.cmml">â€–</mo><mrow id="A1.E13.m1.7.7.3.3.1.1.1.1.1" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.cmml"><mrow id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.cmml"><msub id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.cmml"><mi id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.2" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.2.cmml">z</mi><mi id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.3" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.1" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.3.2" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.3.2.1" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.cmml">(</mo><mi id="A1.E13.m1.3.3" xref="A1.E13.m1.3.3.cmml">x</mi><mo stretchy="false" id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.3.2.2" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.E13.m1.7.7.3.3.1.1.1.1.1.1" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.1.cmml">âˆ’</mo><mrow id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.cmml"><mtext id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.2" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.2a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.1" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.1.cmml">â€‹</mo><mrow id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.2" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.1.cmml"><mo stretchy="false" id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.2.1" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.1.1.cmml">[</mo><mi id="A1.E13.m1.4.4" xref="A1.E13.m1.4.4.cmml">e</mi><mo stretchy="false" id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.2.2" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.1.1.cmml">]</mo></mrow></mrow></mrow><mo stretchy="false" id="A1.E13.m1.7.7.3.3.1.1.1.1.3" xref="A1.E13.m1.7.7.3.3.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="A1.E13.m1.7.7.3.3.1.1.3" xref="A1.E13.m1.7.7.3.3.1.1.3.cmml">2</mn><mn id="A1.E13.m1.7.7.3.3.1.3" xref="A1.E13.m1.7.7.3.3.1.3.cmml">2</mn></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.E13.m1.7b"><apply id="A1.E13.m1.7.7.cmml" xref="A1.E13.m1.7.7"><eq id="A1.E13.m1.7.7.4.cmml" xref="A1.E13.m1.7.7.4"></eq><ci id="A1.E13.m1.7.7.5.cmml" xref="A1.E13.m1.7.7.5">â„’</ci><apply id="A1.E13.m1.7.7.3.cmml" xref="A1.E13.m1.7.7.3"><plus id="A1.E13.m1.7.7.3.4.cmml" xref="A1.E13.m1.7.7.3.4"></plus><apply id="A1.E13.m1.5.5.1.1.cmml" xref="A1.E13.m1.5.5.1.1"><times id="A1.E13.m1.5.5.1.1.2.cmml" xref="A1.E13.m1.5.5.1.1.2"></times><apply id="A1.E13.m1.5.5.1.1.3.cmml" xref="A1.E13.m1.5.5.1.1.3"><log id="A1.E13.m1.5.5.1.1.3.1.cmml" xref="A1.E13.m1.5.5.1.1.3.1"></log><ci id="A1.E13.m1.5.5.1.1.3.2.cmml" xref="A1.E13.m1.5.5.1.1.3.2">ğ‘ƒ</ci></apply><apply id="A1.E13.m1.5.5.1.1.1.1.1.cmml" xref="A1.E13.m1.5.5.1.1.1.1"><csymbol cd="latexml" id="A1.E13.m1.5.5.1.1.1.1.1.1.cmml" xref="A1.E13.m1.5.5.1.1.1.1.1.1">conditional</csymbol><ci id="A1.E13.m1.5.5.1.1.1.1.1.2.cmml" xref="A1.E13.m1.5.5.1.1.1.1.1.2">ğ‘¥</ci><apply id="A1.E13.m1.5.5.1.1.1.1.1.3.cmml" xref="A1.E13.m1.5.5.1.1.1.1.1.3"><times id="A1.E13.m1.5.5.1.1.1.1.1.3.1.cmml" xref="A1.E13.m1.5.5.1.1.1.1.1.3.1"></times><apply id="A1.E13.m1.5.5.1.1.1.1.1.3.2.cmml" xref="A1.E13.m1.5.5.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A1.E13.m1.5.5.1.1.1.1.1.3.2.1.cmml" xref="A1.E13.m1.5.5.1.1.1.1.1.3.2">subscript</csymbol><ci id="A1.E13.m1.5.5.1.1.1.1.1.3.2.2.cmml" xref="A1.E13.m1.5.5.1.1.1.1.1.3.2.2">ğ‘§</ci><ci id="A1.E13.m1.5.5.1.1.1.1.1.3.2.3.cmml" xref="A1.E13.m1.5.5.1.1.1.1.1.3.2.3">ğ‘„</ci></apply><ci id="A1.E13.m1.1.1.cmml" xref="A1.E13.m1.1.1">ğ‘¥</ci></apply></apply></apply><apply id="A1.E13.m1.6.6.2.2.cmml" xref="A1.E13.m1.6.6.2.2"><csymbol cd="ambiguous" id="A1.E13.m1.6.6.2.2.2.cmml" xref="A1.E13.m1.6.6.2.2">superscript</csymbol><apply id="A1.E13.m1.6.6.2.2.1.cmml" xref="A1.E13.m1.6.6.2.2"><csymbol cd="ambiguous" id="A1.E13.m1.6.6.2.2.1.2.cmml" xref="A1.E13.m1.6.6.2.2">subscript</csymbol><apply id="A1.E13.m1.6.6.2.2.1.1.2.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1"><csymbol cd="latexml" id="A1.E13.m1.6.6.2.2.1.1.2.1.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.2">norm</csymbol><apply id="A1.E13.m1.6.6.2.2.1.1.1.1.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1"><minus id="A1.E13.m1.6.6.2.2.1.1.1.1.2.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.2"></minus><apply id="A1.E13.m1.6.6.2.2.1.1.1.1.1.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1"><times id="A1.E13.m1.6.6.2.2.1.1.1.1.1.2.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.2"></times><ci id="A1.E13.m1.6.6.2.2.1.1.1.1.1.3a.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.3"><mtext id="A1.E13.m1.6.6.2.2.1.1.1.1.1.3.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.3">sg</mtext></ci><apply id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.2.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.2.1.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1"><times id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.1"></times><apply id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.2">ğ‘§</ci><ci id="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.1.1.1.1.2.3">ğ‘’</ci></apply><ci id="A1.E13.m1.2.2.cmml" xref="A1.E13.m1.2.2">ğ‘¥</ci></apply></apply></apply><ci id="A1.E13.m1.6.6.2.2.1.1.1.1.3.cmml" xref="A1.E13.m1.6.6.2.2.1.1.1.1.3">ğ‘’</ci></apply></apply><cn type="integer" id="A1.E13.m1.6.6.2.2.1.3.cmml" xref="A1.E13.m1.6.6.2.2.1.3">2</cn></apply><cn type="integer" id="A1.E13.m1.6.6.2.2.3.cmml" xref="A1.E13.m1.6.6.2.2.3">2</cn></apply><apply id="A1.E13.m1.7.7.3.3.cmml" xref="A1.E13.m1.7.7.3.3"><times id="A1.E13.m1.7.7.3.3.2.cmml" xref="A1.E13.m1.7.7.3.3.2"></times><ci id="A1.E13.m1.7.7.3.3.3.cmml" xref="A1.E13.m1.7.7.3.3.3">ğ›½</ci><apply id="A1.E13.m1.7.7.3.3.1.cmml" xref="A1.E13.m1.7.7.3.3.1"><csymbol cd="ambiguous" id="A1.E13.m1.7.7.3.3.1.2.cmml" xref="A1.E13.m1.7.7.3.3.1">superscript</csymbol><apply id="A1.E13.m1.7.7.3.3.1.1.cmml" xref="A1.E13.m1.7.7.3.3.1"><csymbol cd="ambiguous" id="A1.E13.m1.7.7.3.3.1.1.2.cmml" xref="A1.E13.m1.7.7.3.3.1">subscript</csymbol><apply id="A1.E13.m1.7.7.3.3.1.1.1.2.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1"><csymbol cd="latexml" id="A1.E13.m1.7.7.3.3.1.1.1.2.1.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.2">norm</csymbol><apply id="A1.E13.m1.7.7.3.3.1.1.1.1.1.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1"><minus id="A1.E13.m1.7.7.3.3.1.1.1.1.1.1.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.1"></minus><apply id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2"><times id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.1.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.1"></times><apply id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.1.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2">subscript</csymbol><ci id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.2.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.2">ğ‘§</ci><ci id="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.3.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.2.2.3">ğ‘’</ci></apply><ci id="A1.E13.m1.3.3.cmml" xref="A1.E13.m1.3.3">ğ‘¥</ci></apply><apply id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3"><times id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.1.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.1"></times><ci id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.2a.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.2"><mtext id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.2.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.2">sg</mtext></ci><apply id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.1.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.2"><csymbol cd="latexml" id="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.1.1.cmml" xref="A1.E13.m1.7.7.3.3.1.1.1.1.1.3.3.2.1">delimited-[]</csymbol><ci id="A1.E13.m1.4.4.cmml" xref="A1.E13.m1.4.4">ğ‘’</ci></apply></apply></apply></apply><cn type="integer" id="A1.E13.m1.7.7.3.3.1.1.3.cmml" xref="A1.E13.m1.7.7.3.3.1.1.3">2</cn></apply><cn type="integer" id="A1.E13.m1.7.7.3.3.1.3.cmml" xref="A1.E13.m1.7.7.3.3.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E13.m1.7c">\mathcal{L}=\log P(x|z_{Q}(x))+\|\text{sg}[z_{e}(x)]-e\|_{2}^{2}+\beta\|z_{e}(x)-\text{sg}[e]\|_{2}^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A1.SS2.p1.16" class="ltx_p">In this function, <math id="A1.SS2.p1.11.m1.2" class="ltx_Math" alttext="\log P(x|z_{Q}(x))" display="inline"><semantics id="A1.SS2.p1.11.m1.2a"><mrow id="A1.SS2.p1.11.m1.2.2" xref="A1.SS2.p1.11.m1.2.2.cmml"><mrow id="A1.SS2.p1.11.m1.2.2.3" xref="A1.SS2.p1.11.m1.2.2.3.cmml"><mi id="A1.SS2.p1.11.m1.2.2.3.1" xref="A1.SS2.p1.11.m1.2.2.3.1.cmml">log</mi><mo lspace="0.167em" id="A1.SS2.p1.11.m1.2.2.3a" xref="A1.SS2.p1.11.m1.2.2.3.cmml">â¡</mo><mi id="A1.SS2.p1.11.m1.2.2.3.2" xref="A1.SS2.p1.11.m1.2.2.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="A1.SS2.p1.11.m1.2.2.2" xref="A1.SS2.p1.11.m1.2.2.2.cmml">â€‹</mo><mrow id="A1.SS2.p1.11.m1.2.2.1.1" xref="A1.SS2.p1.11.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="A1.SS2.p1.11.m1.2.2.1.1.2" xref="A1.SS2.p1.11.m1.2.2.1.1.1.cmml">(</mo><mrow id="A1.SS2.p1.11.m1.2.2.1.1.1" xref="A1.SS2.p1.11.m1.2.2.1.1.1.cmml"><mi id="A1.SS2.p1.11.m1.2.2.1.1.1.2" xref="A1.SS2.p1.11.m1.2.2.1.1.1.2.cmml">x</mi><mo fence="false" id="A1.SS2.p1.11.m1.2.2.1.1.1.1" xref="A1.SS2.p1.11.m1.2.2.1.1.1.1.cmml">|</mo><mrow id="A1.SS2.p1.11.m1.2.2.1.1.1.3" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.cmml"><msub id="A1.SS2.p1.11.m1.2.2.1.1.1.3.2" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.cmml"><mi id="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.2" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.2.cmml">z</mi><mi id="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.3" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.3.cmml">Q</mi></msub><mo lspace="0em" rspace="0em" id="A1.SS2.p1.11.m1.2.2.1.1.1.3.1" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.11.m1.2.2.1.1.1.3.3.2" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.cmml"><mo stretchy="false" id="A1.SS2.p1.11.m1.2.2.1.1.1.3.3.2.1" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.cmml">(</mo><mi id="A1.SS2.p1.11.m1.1.1" xref="A1.SS2.p1.11.m1.1.1.cmml">x</mi><mo stretchy="false" id="A1.SS2.p1.11.m1.2.2.1.1.1.3.3.2.2" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="A1.SS2.p1.11.m1.2.2.1.1.3" xref="A1.SS2.p1.11.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.11.m1.2b"><apply id="A1.SS2.p1.11.m1.2.2.cmml" xref="A1.SS2.p1.11.m1.2.2"><times id="A1.SS2.p1.11.m1.2.2.2.cmml" xref="A1.SS2.p1.11.m1.2.2.2"></times><apply id="A1.SS2.p1.11.m1.2.2.3.cmml" xref="A1.SS2.p1.11.m1.2.2.3"><log id="A1.SS2.p1.11.m1.2.2.3.1.cmml" xref="A1.SS2.p1.11.m1.2.2.3.1"></log><ci id="A1.SS2.p1.11.m1.2.2.3.2.cmml" xref="A1.SS2.p1.11.m1.2.2.3.2">ğ‘ƒ</ci></apply><apply id="A1.SS2.p1.11.m1.2.2.1.1.1.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1"><csymbol cd="latexml" id="A1.SS2.p1.11.m1.2.2.1.1.1.1.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1.1.1">conditional</csymbol><ci id="A1.SS2.p1.11.m1.2.2.1.1.1.2.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1.1.2">ğ‘¥</ci><apply id="A1.SS2.p1.11.m1.2.2.1.1.1.3.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3"><times id="A1.SS2.p1.11.m1.2.2.1.1.1.3.1.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.1"></times><apply id="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.2"><csymbol cd="ambiguous" id="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.1.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.2">subscript</csymbol><ci id="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.2.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.2">ğ‘§</ci><ci id="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.3.cmml" xref="A1.SS2.p1.11.m1.2.2.1.1.1.3.2.3">ğ‘„</ci></apply><ci id="A1.SS2.p1.11.m1.1.1.cmml" xref="A1.SS2.p1.11.m1.1.1">ğ‘¥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.11.m1.2c">\log P(x|z_{Q}(x))</annotation></semantics></math> denotes the reconstruction loss, while <math id="A1.SS2.p1.12.m2.2" class="ltx_Math" alttext="\|\text{sg}[z_{e}(x)]-e\|_{2}^{2}" display="inline"><semantics id="A1.SS2.p1.12.m2.2a"><msubsup id="A1.SS2.p1.12.m2.2.2" xref="A1.SS2.p1.12.m2.2.2.cmml"><mrow id="A1.SS2.p1.12.m2.2.2.1.1.1" xref="A1.SS2.p1.12.m2.2.2.1.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.12.m2.2.2.1.1.1.2" xref="A1.SS2.p1.12.m2.2.2.1.1.2.1.cmml">â€–</mo><mrow id="A1.SS2.p1.12.m2.2.2.1.1.1.1" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.cmml"><mrow id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.cmml"><mtext id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.3" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.3a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.2" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.2" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.2" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.2.cmml">z</mi><mi id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.3" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.1" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.3.2" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.3.2.1" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="A1.SS2.p1.12.m2.1.1" xref="A1.SS2.p1.12.m2.1.1.cmml">x</mi><mo stretchy="false" id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.3.2.2" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.3" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="A1.SS2.p1.12.m2.2.2.1.1.1.1.2" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.2.cmml">âˆ’</mo><mi id="A1.SS2.p1.12.m2.2.2.1.1.1.1.3" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.3.cmml">e</mi></mrow><mo stretchy="false" id="A1.SS2.p1.12.m2.2.2.1.1.1.3" xref="A1.SS2.p1.12.m2.2.2.1.1.2.1.cmml">â€–</mo></mrow><mn id="A1.SS2.p1.12.m2.2.2.1.3" xref="A1.SS2.p1.12.m2.2.2.1.3.cmml">2</mn><mn id="A1.SS2.p1.12.m2.2.2.3" xref="A1.SS2.p1.12.m2.2.2.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.12.m2.2b"><apply id="A1.SS2.p1.12.m2.2.2.cmml" xref="A1.SS2.p1.12.m2.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.12.m2.2.2.2.cmml" xref="A1.SS2.p1.12.m2.2.2">superscript</csymbol><apply id="A1.SS2.p1.12.m2.2.2.1.cmml" xref="A1.SS2.p1.12.m2.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.12.m2.2.2.1.2.cmml" xref="A1.SS2.p1.12.m2.2.2">subscript</csymbol><apply id="A1.SS2.p1.12.m2.2.2.1.1.2.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1"><csymbol cd="latexml" id="A1.SS2.p1.12.m2.2.2.1.1.2.1.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.2">norm</csymbol><apply id="A1.SS2.p1.12.m2.2.2.1.1.1.1.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1"><minus id="A1.SS2.p1.12.m2.2.2.1.1.1.1.2.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.2"></minus><apply id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1"><times id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.2.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.2"></times><ci id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.3a.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.3"><mtext id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.3.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.3">sg</mtext></ci><apply id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.2.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.2.1.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1"><times id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.1"></times><apply id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.2">ğ‘§</ci><ci id="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.1.1.1.1.2.3">ğ‘’</ci></apply><ci id="A1.SS2.p1.12.m2.1.1.cmml" xref="A1.SS2.p1.12.m2.1.1">ğ‘¥</ci></apply></apply></apply><ci id="A1.SS2.p1.12.m2.2.2.1.1.1.1.3.cmml" xref="A1.SS2.p1.12.m2.2.2.1.1.1.1.3">ğ‘’</ci></apply></apply><cn type="integer" id="A1.SS2.p1.12.m2.2.2.1.3.cmml" xref="A1.SS2.p1.12.m2.2.2.1.3">2</cn></apply><cn type="integer" id="A1.SS2.p1.12.m2.2.2.3.cmml" xref="A1.SS2.p1.12.m2.2.2.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.12.m2.2c">\|\text{sg}[z_{e}(x)]-e\|_{2}^{2}</annotation></semantics></math> represents the codebook loss, move the codebook embedding vectors <math id="A1.SS2.p1.13.m3.1" class="ltx_Math" alttext="e_{i}" display="inline"><semantics id="A1.SS2.p1.13.m3.1a"><msub id="A1.SS2.p1.13.m3.1.1" xref="A1.SS2.p1.13.m3.1.1.cmml"><mi id="A1.SS2.p1.13.m3.1.1.2" xref="A1.SS2.p1.13.m3.1.1.2.cmml">e</mi><mi id="A1.SS2.p1.13.m3.1.1.3" xref="A1.SS2.p1.13.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.13.m3.1b"><apply id="A1.SS2.p1.13.m3.1.1.cmml" xref="A1.SS2.p1.13.m3.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.13.m3.1.1.1.cmml" xref="A1.SS2.p1.13.m3.1.1">subscript</csymbol><ci id="A1.SS2.p1.13.m3.1.1.2.cmml" xref="A1.SS2.p1.13.m3.1.1.2">ğ‘’</ci><ci id="A1.SS2.p1.13.m3.1.1.3.cmml" xref="A1.SS2.p1.13.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.13.m3.1c">e_{i}</annotation></semantics></math> towards the encoder outputs. Additionally, <math id="A1.SS2.p1.14.m4.3" class="ltx_Math" alttext="\|z_{e}(x)-\text{sg}[e]\|_{2}^{2}" display="inline"><semantics id="A1.SS2.p1.14.m4.3a"><msubsup id="A1.SS2.p1.14.m4.3.3" xref="A1.SS2.p1.14.m4.3.3.cmml"><mrow id="A1.SS2.p1.14.m4.3.3.1.1.1" xref="A1.SS2.p1.14.m4.3.3.1.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.14.m4.3.3.1.1.1.2" xref="A1.SS2.p1.14.m4.3.3.1.1.2.1.cmml">â€–</mo><mrow id="A1.SS2.p1.14.m4.3.3.1.1.1.1" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.cmml"><mrow id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.cmml"><msub id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.cmml"><mi id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.2" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.2.cmml">z</mi><mi id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.3" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.1" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.3.2" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.3.2.1" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.cmml">(</mo><mi id="A1.SS2.p1.14.m4.1.1" xref="A1.SS2.p1.14.m4.1.1.cmml">x</mi><mo stretchy="false" id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.3.2.2" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.SS2.p1.14.m4.3.3.1.1.1.1.1" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.1.cmml">âˆ’</mo><mrow id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.cmml"><mtext id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.2" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.2a.cmml">sg</mtext><mo lspace="0em" rspace="0em" id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.1" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.1.cmml">â€‹</mo><mrow id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.2" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.1.cmml"><mo stretchy="false" id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.2.1" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.1.1.cmml">[</mo><mi id="A1.SS2.p1.14.m4.2.2" xref="A1.SS2.p1.14.m4.2.2.cmml">e</mi><mo stretchy="false" id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.2.2" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.1.1.cmml">]</mo></mrow></mrow></mrow><mo stretchy="false" id="A1.SS2.p1.14.m4.3.3.1.1.1.3" xref="A1.SS2.p1.14.m4.3.3.1.1.2.1.cmml">â€–</mo></mrow><mn id="A1.SS2.p1.14.m4.3.3.1.3" xref="A1.SS2.p1.14.m4.3.3.1.3.cmml">2</mn><mn id="A1.SS2.p1.14.m4.3.3.3" xref="A1.SS2.p1.14.m4.3.3.3.cmml">2</mn></msubsup><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.14.m4.3b"><apply id="A1.SS2.p1.14.m4.3.3.cmml" xref="A1.SS2.p1.14.m4.3.3"><csymbol cd="ambiguous" id="A1.SS2.p1.14.m4.3.3.2.cmml" xref="A1.SS2.p1.14.m4.3.3">superscript</csymbol><apply id="A1.SS2.p1.14.m4.3.3.1.cmml" xref="A1.SS2.p1.14.m4.3.3"><csymbol cd="ambiguous" id="A1.SS2.p1.14.m4.3.3.1.2.cmml" xref="A1.SS2.p1.14.m4.3.3">subscript</csymbol><apply id="A1.SS2.p1.14.m4.3.3.1.1.2.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1"><csymbol cd="latexml" id="A1.SS2.p1.14.m4.3.3.1.1.2.1.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.2">norm</csymbol><apply id="A1.SS2.p1.14.m4.3.3.1.1.1.1.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1"><minus id="A1.SS2.p1.14.m4.3.3.1.1.1.1.1.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.1"></minus><apply id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2"><times id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.1.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.1"></times><apply id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2"><csymbol cd="ambiguous" id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.1.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2">subscript</csymbol><ci id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.2.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.2">ğ‘§</ci><ci id="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.3.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.2.2.3">ğ‘’</ci></apply><ci id="A1.SS2.p1.14.m4.1.1.cmml" xref="A1.SS2.p1.14.m4.1.1">ğ‘¥</ci></apply><apply id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3"><times id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.1.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.1"></times><ci id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.2a.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.2"><mtext id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.2.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.2">sg</mtext></ci><apply id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.1.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.2"><csymbol cd="latexml" id="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.1.1.cmml" xref="A1.SS2.p1.14.m4.3.3.1.1.1.1.3.3.2.1">delimited-[]</csymbol><ci id="A1.SS2.p1.14.m4.2.2.cmml" xref="A1.SS2.p1.14.m4.2.2">ğ‘’</ci></apply></apply></apply></apply><cn type="integer" id="A1.SS2.p1.14.m4.3.3.1.3.cmml" xref="A1.SS2.p1.14.m4.3.3.1.3">2</cn></apply><cn type="integer" id="A1.SS2.p1.14.m4.3.3.3.cmml" xref="A1.SS2.p1.14.m4.3.3.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.14.m4.3c">\|z_{e}(x)-\text{sg}[e]\|_{2}^{2}</annotation></semantics></math> represents the commitment loss, ensuring the encoder outputs commit to specific embeddings. Here, <math id="A1.SS2.p1.15.m5.1" class="ltx_Math" alttext="sg" display="inline"><semantics id="A1.SS2.p1.15.m5.1a"><mrow id="A1.SS2.p1.15.m5.1.1" xref="A1.SS2.p1.15.m5.1.1.cmml"><mi id="A1.SS2.p1.15.m5.1.1.2" xref="A1.SS2.p1.15.m5.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="A1.SS2.p1.15.m5.1.1.1" xref="A1.SS2.p1.15.m5.1.1.1.cmml">â€‹</mo><mi id="A1.SS2.p1.15.m5.1.1.3" xref="A1.SS2.p1.15.m5.1.1.3.cmml">g</mi></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.15.m5.1b"><apply id="A1.SS2.p1.15.m5.1.1.cmml" xref="A1.SS2.p1.15.m5.1.1"><times id="A1.SS2.p1.15.m5.1.1.1.cmml" xref="A1.SS2.p1.15.m5.1.1.1"></times><ci id="A1.SS2.p1.15.m5.1.1.2.cmml" xref="A1.SS2.p1.15.m5.1.1.2">ğ‘ </ci><ci id="A1.SS2.p1.15.m5.1.1.3.cmml" xref="A1.SS2.p1.15.m5.1.1.3">ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.15.m5.1c">sg</annotation></semantics></math> stands for the stop gradient operator, and <math id="A1.SS2.p1.16.m6.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.SS2.p1.16.m6.1a"><mi id="A1.SS2.p1.16.m6.1.1" xref="A1.SS2.p1.16.m6.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.16.m6.1b"><ci id="A1.SS2.p1.16.m6.1.1.cmml" xref="A1.SS2.p1.16.m6.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.16.m6.1c">\beta</annotation></semantics></math> is a hyperparameter controlling the weight of the commitment loss.</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3. </span>User Study</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.1" class="ltx_p">We post the survey on Prolific <cite class="ltx_cite ltx_citemacro_citep">(Prolific, <a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite> to gather responses. The platform allows researchers to pay a fair amount for participants and provides solutions for addressing privacy and ethical issues. Participants who speak fluent English are recruited through Prolific, providing 40 responses. Additionally, we find 33 participants online who voluntarily took part in the perceptual study in kind. In total, 73 responses are collected, with 4 responses discarded due to failing the attention test, resulting in 69 valid responses. Demographically, 24.64% of participants are aged 18 to 23, 33.33% aged 24 to 28, 14.49% aged 29 to 33, and 27.54% are above 33 years old. Participants are asked to rate their familiarity with virtual humans, 3D animated films, and video games on a scale of 0 to 7 at the beginning of the user study. Among the 69 participants, the average familiarity scores are 3.90 for virtual humans, 5.22 for 3D animated films, and 5.52 for video games.</p>
</div>
<div id="A1.SS3.p2" class="ltx_para">
<p id="A1.SS3.p2.1" class="ltx_p">All audio samples selected for the user study are between 3 and 9 seconds. Note that since our model and EMOTE only produces output with expression and jaw parameters, we post-process the outputs to add an average shape of specific subjects and transfer them to the vertex space for rendering. This is done to align with the face shapes in the outputs of FaceDiffuser. We apply the same post-processing to the ground truth, using an average shape for a fair comparison.</p>
</div>
<div id="A1.SS3.p3" class="ltx_para">
<p id="A1.SS3.p3.1" class="ltx_p">An attention test is incorporated into the study to filter out unreliable responses, where one video intentionally has significant video and audio out of sync. Failure to correctly identify the higher-quality video in this test leads to early termination of the survey and disregarding the response. Altogether, 25 video pairs (including the attention test) are presented to the participants in random order. For each video pair, two videos are displayed in a left-right layout on desktops or a top-bottom layout on mobile phones. One video showcases the output of our model, while the other showcases either the ground truth or the output of another model. We also randomize the position of the two videos to eliminate any potential bias that could arise from their placement. The survey is evenly distributed so that participants have an opportunity to view different video pairs for each emotion. The UI of the user study survey designed for perceptual evaluation is shown in Figure <a href="#A1.F9" title="Figure 9 â€£ A.3. User Study â€£ Appendix A Supplementary Material â€£ ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure id="A1.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A1.F9.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2409.07966/assets/x1.png" id="A1.F9.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="222" height="173" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A1.F9.sf1.3.2" class="ltx_text" style="font-size:90%;">User study instructions.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A1.F9.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2409.07966/assets/x2.png" id="A1.F9.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="222" height="173" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A1.F9.sf2.3.2" class="ltx_text" style="font-size:90%;">UI of the perceptual user study.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>. </span><span id="A1.F9.3.2" class="ltx_text" style="font-size:90%;">Example screenshots of the user study displayed on desktop environment.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.07965" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.07966" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.07966">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.07966" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.07967" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 00:29:24 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
