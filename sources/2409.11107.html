<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.11107] Zero Shot Text to Speech Augmentation for Automatic Speech Recognition on Low-Resource Accented Speech Corpora</title><meta property="og:description" content="In recent years, automatic speech recognition (ASR) models greatly improved transcription performance both in clean, low noise, acoustic conditions and in reverberant environments. However, all these systems rely on thâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Zero Shot Text to Speech Augmentation for Automatic Speech Recognition on Low-Resource Accented Speech Corpora">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Zero Shot Text to Speech Augmentation for Automatic Speech Recognition on Low-Resource Accented Speech Corpora">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.11107">

<!--Generated on Sat Oct  5 20:35:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.4" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.5" class="ltx_ERROR undefined">\name</span>
<p id="p1.3" class="ltx_p">Francesco Nespoli<sup id="p1.3.1" class="ltx_sup"><span id="p1.3.1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Daniel Barreda<sup id="p1.3.2" class="ltx_sup">1</sup>, Patrick A. Naylor<sup id="p1.3.3" class="ltx_sup">2</sup></p>
</div>
<h1 class="ltx_title ltx_title_document">Zero Shot Text to Speech Augmentation for Automatic Speech Recognition on Low-Resource Accented Speech Corpora</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id5.id1" class="ltx_p">In recent years, automatic speech recognition (ASR) models greatly improved transcription performance both in clean, low noise, acoustic conditions and in reverberant environments. However, all these systems rely on the availability of hundreds of hours of labelled training data in specific acoustic conditions. When such a training dataset is not available, the performance of the system is heavily impacted. For example, this happens when a specific acoustic environment or a particular population of speakers is under-represented in the training dataset. Specifically, in this paper we investigate the effect of accented speech data on an off-the-shelf ASR system. Furthermore, we suggest a strategy based on zero-shot text-to-speech to augment the accented speech corpora. We show that this augmentation method is able to mitigate the loss in performance of the ASR system on accented data up to 5% word error rate reduction (WERR). In conclusion, we demonstrate that by incorporating a modest fraction of real with synthetically generated data, the ASR system exhibits superior performance compared to a model trained exclusively on authentic accented speech with up to 14% WERR.</p>
</div>
<div id="p2" class="ltx_para ltx_noindent">
<p id="p2.1" class="ltx_p"><span id="p2.1.1" class="ltx_text ltx_font_bold">Index Terms</span>: speech recognition, data augmentation, text to speech, accented data</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Contemporary ASR systems necessitate a substantial volume of meticulously labeled speech data to yield accurate and effective transcriptions. Many of these sophisticated models leverage open-source datasets such as Librispeech [1], as integral components of their training. However, the transition from controlled training environments to real-world applications results in a notable disparity in performance. This discrepancy can be attributed to a superposition of different factors, including diverse acoustic conditions and the under-representation of certain language groups within the training data. While it is widely acknowledged that the mere presence of bias in training data does not inherently translate to biased models [2], the subtle speech variations introduced by regional accents among native speakers [3] and even racial characteristics [4] pose potential sources of bias in ASR models. The substantial decline in ASR system performance when confronted with non-native speech patterns provides empirical evidence that models primarily trained on the utterances of native speakers lack the required robustness to effectively model underrepresented pronunciation patterns. These findings underline the importance for a more inclusive approach in the development and training of ASR systems. 
<br class="ltx_break">Many different techniques have been suggested to mitigate ASR degradation. In the context of English accented speech data, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> provide the ASR model an extra input carrying accent information. In this case, the extra input is an accent embedding which is computed from an external pre-trained model. This strategy has been shown to be beneficial for the ASR system in the form of an improved robustness to different accents. Another effective technique is the application of domain adversarial neural networks (DANN). This technique employs a domain discriminator (DD) in addition to the primary task network (ASR in this case). The idea behind DANN is to push the ASR front-end to extract domain-invariant representations. During training, the DD tries to distinguish between the source and target domains based on the feature representations extracted by the model, while the primary task network aims to perform its main task. However, at the optimization stage, the DD loss is subtracted from the ASR loss effectively pushing the feature extractor to learn domain-invariant representations. When applied on accented speech, domain adversarial training has been shown to diminish the mismatch between the accented and standard speech distributions (at the feature level) therefore leading to a more robust ASR model for accented speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Finally, accent conversion techniques have been investigated for converting foreign to native <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and native to foreign accents <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In the first case, foreign speech is normalized to the native accent and then the resulting audio signal is fed to the ASR model. In the second case, native speech can be employed to synthetically produce accented utterances. These data can then be mixed with the original training corpus to perform data augmentation. 
<br class="ltx_break">In this work, we investigated the impact of accented data on ASR systems performance. Our findings underscore the need for innovative strategies to enhance ASR model performance in presence of linguistic variations and accents. To address this challenge, we propose the integration of a state-of-the-art zero-shot text-to-speech (ZS-TTS) system for the augmentation of accented data. The rationale behind this lies in the inherent capability of ZS-TTS to assimilate the acoustic characteristic of a specific speaker, by utilizing only few seconds of training data. These features prove particularly advantageous in the context of accented corpora, where datasets predominantly consist of a limited number of speakers, coupled with a scarcity of recordings. Moreover, the distinguishing feature of ZS-TTS lies in its capacity for virtually limitless data production from each available speaker. In the context of accented corpora, this unique attribute can be strategically harnessed to significantly augment the training dataset for the ASR model, thereby effectively mitigating the inherent mismatch between the training and production data. 
<br class="ltx_break">Our methodological approach involves the utilization of the ZS-TTS system as outlined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, coupled with the employment of a transformer-based ASR model from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. This choice is motivated by the openness and ease of training and deployment of both models. Furthermore, our selection is underscored by the multi-lingual capabilities embedded in ZS-TTS, a feature that we have repurposed and exploited to address the challenges posed by multi-accent learning.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Proposed Method</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Zero Shot Text-to-Speech</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We exploit YourTTS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, a multi-speaker and multilingual TTS architecture employing variational inference and adversarial learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<p id="S2.F1.1" class="ltx_p ltx_align_center"><span id="S2.F1.1.1" class="ltx_text"><img src="/html/2409.11107/assets/images/FigiresPaperAsilomar2023.png" id="S2.F1.1.1.g1" class="ltx_graphics ltx_img_square" width="495" height="412" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overviwew of the Zero Shot TTS architecture. Left: training stage. Right: inference stage.</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.7" class="ltx_p">The model has five main components: text encoder, transform encoder, alignment stage, an invertible flow-based decoder and a vocoder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. While training, we input the linear spectrogram to the posterior encoder and it outputs a latent representation <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">Z</annotation></semantics></math>. This goes into the vocoder and the flow-based decoder whose output <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="Z\textsubscript{p}" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mrow id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml"><mi id="S2.SS1.p2.2.m2.1.1.2" xref="S2.SS1.p2.2.m2.1.1.2.cmml">Z</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.2.m2.1.1.1" xref="S2.SS1.p2.2.m2.1.1.1.cmml">â€‹</mo><mtext id="S2.SS1.p2.2.m2.1.1.3" xref="S2.SS1.p2.2.m2.1.1.3b.cmml"><sub id="S2.SS1.p2.2.m2.1.1.3.1nest" class="ltx_sub">p</sub></mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><apply id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1"><times id="S2.SS1.p2.2.m2.1.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1.1"></times><ci id="S2.SS1.p2.2.m2.1.1.2.cmml" xref="S2.SS1.p2.2.m2.1.1.2">ğ‘</ci><ci id="S2.SS1.p2.2.m2.1.1.3b.cmml" xref="S2.SS1.p2.2.m2.1.1.3"><mtext id="S2.SS1.p2.2.m2.1.1.3.cmml" xref="S2.SS1.p2.2.m2.1.1.3"><sub id="S2.SS1.p2.2.m2.1.1.3.1anest" class="ltx_sub">p</sub></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">Z\textsubscript{p}</annotation></semantics></math> is then aligned with the text encoder representation with monotonic alignment search (MAS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. At inference time, the text encoder generates the alignment <math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="Z\textsubscript{p}" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><mrow id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml"><mi id="S2.SS1.p2.3.m3.1.1.2" xref="S2.SS1.p2.3.m3.1.1.2.cmml">Z</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.3.m3.1.1.1" xref="S2.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mtext id="S2.SS1.p2.3.m3.1.1.3" xref="S2.SS1.p2.3.m3.1.1.3b.cmml"><sub id="S2.SS1.p2.3.m3.1.1.3.1nest" class="ltx_sub">p</sub></mtext></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><apply id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1"><times id="S2.SS1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1.1"></times><ci id="S2.SS1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.p2.3.m3.1.1.2">ğ‘</ci><ci id="S2.SS1.p2.3.m3.1.1.3b.cmml" xref="S2.SS1.p2.3.m3.1.1.3"><mtext id="S2.SS1.p2.3.m3.1.1.3.cmml" xref="S2.SS1.p2.3.m3.1.1.3"><sub id="S2.SS1.p2.3.m3.1.1.3.1anest" class="ltx_sub">p</sub></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">Z\textsubscript{p}</annotation></semantics></math> which is then used by the inverted flow decoder to produce <math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mi id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">Z</annotation></semantics></math> which, when input into the vocoder, generates an audio. The speaker encoder in Fig.Â 1 is the H/ASP architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> based on ResNet-34 and generates embeddings used for the speaker conditioning task. The model is also able to learn multiple languages. This objective is accomplished through the utilization of trainable language embeddings, as illustrated in Fig.Â 1. These vectors, characterized by four dimensions, are appended to the embeddings associated with each input character, thereby generating a language-specific character representation. Expanding on this concept, in instances where multiple accents are present, we leverage the language embedding as an accent embedding. Initially, we start with an open-source multi-lingual checkpoint that encompasses French, Portuguese, and English <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Subsequently, we undertake the random initialization of the existing <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><mi id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><ci id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">N</annotation></semantics></math> language embedding layers. If <math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><mi id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">M</annotation></semantics></math> denotes the number of accents within the training data, we introduce an additional set of random accent embeddings, totaling <math id="S2.SS1.p2.7.m7.1" class="ltx_Math" alttext="|M-N|" display="inline"><semantics id="S2.SS1.p2.7.m7.1a"><mrow id="S2.SS1.p2.7.m7.1.1.1" xref="S2.SS1.p2.7.m7.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p2.7.m7.1.1.1.2" xref="S2.SS1.p2.7.m7.1.1.2.1.cmml">|</mo><mrow id="S2.SS1.p2.7.m7.1.1.1.1" xref="S2.SS1.p2.7.m7.1.1.1.1.cmml"><mi id="S2.SS1.p2.7.m7.1.1.1.1.2" xref="S2.SS1.p2.7.m7.1.1.1.1.2.cmml">M</mi><mo id="S2.SS1.p2.7.m7.1.1.1.1.1" xref="S2.SS1.p2.7.m7.1.1.1.1.1.cmml">âˆ’</mo><mi id="S2.SS1.p2.7.m7.1.1.1.1.3" xref="S2.SS1.p2.7.m7.1.1.1.1.3.cmml">N</mi></mrow><mo stretchy="false" id="S2.SS1.p2.7.m7.1.1.1.3" xref="S2.SS1.p2.7.m7.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><apply id="S2.SS1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.1"><abs id="S2.SS1.p2.7.m7.1.1.2.1.cmml" xref="S2.SS1.p2.7.m7.1.1.1.2"></abs><apply id="S2.SS1.p2.7.m7.1.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1.1.1"><minus id="S2.SS1.p2.7.m7.1.1.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1.1.1.1"></minus><ci id="S2.SS1.p2.7.m7.1.1.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.1.1.2">ğ‘€</ci><ci id="S2.SS1.p2.7.m7.1.1.1.1.3.cmml" xref="S2.SS1.p2.7.m7.1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">|M-N|</annotation></semantics></math>, to accommodate every accent featured in the training set. This augmentation ensures a comprehensive coverage of accent variations, enhancing the model's ability to capture and represent diverse linguistic nuances. Moreover, the integration of accent embeddings enriches the accent-dependent character representations, contributing to a more contextually aware language model.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Automatic Speech Recognition Model</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The experimental results shown in SectionÂ 3 have been computed by employing an ASR system based on a transformer acoustic model encoder and a joint transformer decoder combining connectionist temporal classification (CTC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, with decoding stage integrating also CTC probabilities. The ASR model was implemented with <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> and was pre-trained for 90 epochs on Librispeech 960 hours with a batch size of 16, gradient accumulation factor 16, Adam optimizer with learning rate 0.001 and noam learning rate decay scheme.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Data and Results</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We conducted both single and multi accent experiments. In the first case, we used the VCTK <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> dataset from which we selected 3 English speakers with Indian accent. In our multi-accent experiments, we used the Interspeech 2020 accented english recognition challenge dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The dataset contains ten distinct subsets of accented English recordings namely: United States (USA), Canadian (CAN), Great Britain (GBR), Chinese (CHN), Japanese (JPN), Korean (KOR), Russian (RUS), Portuguese (PRT) and Spanish (ES). Audio signals were captured utilizing commercially available devices, specifically smartphones. These recordings were obtained from individuals who red designated scripts, contributing to a comprehensive and diverse collection of linguistic variations. Furthermore, for eight of the available accents, namely USA, CAN, GBR, CHN, KOR, PRT, RUS, and JPN, there is a provision of both a training dataset comprising approximately 20 hours and a corresponding 2 hours test set. In contrast, for the remaining two accents, CAN and ES, although no training data is available, an equivalent amount of testing data is provided. This distribution ensures a balanced evaluation of the model's performance across the various accents.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>ASR decoding results for the Interspeech 2020 test sets. Upper, light grey, ASR decoding results for real data only. <math id="S3.T1.10.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.T1.10.m1.1b"><mi id="S3.T1.10.m1.1.1" xref="S3.T1.10.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.T1.10.m1.1c"><ci id="S3.T1.10.m1.1.1.cmml" xref="S3.T1.10.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.m1.1d">C</annotation></semantics></math>: model trained on Librispeech 960-hours <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. <math id="S3.T1.11.m2.1" class="ltx_Math" alttext="FT" display="inline"><semantics id="S3.T1.11.m2.1b"><mrow id="S3.T1.11.m2.1.1" xref="S3.T1.11.m2.1.1.cmml"><mi id="S3.T1.11.m2.1.1.2" xref="S3.T1.11.m2.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.T1.11.m2.1.1.1" xref="S3.T1.11.m2.1.1.1.cmml">â€‹</mo><mi id="S3.T1.11.m2.1.1.3" xref="S3.T1.11.m2.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.11.m2.1c"><apply id="S3.T1.11.m2.1.1.cmml" xref="S3.T1.11.m2.1.1"><times id="S3.T1.11.m2.1.1.1.cmml" xref="S3.T1.11.m2.1.1.1"></times><ci id="S3.T1.11.m2.1.1.2.cmml" xref="S3.T1.11.m2.1.1.2">ğ¹</ci><ci id="S3.T1.11.m2.1.1.3.cmml" xref="S3.T1.11.m2.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.m2.1d">FT</annotation></semantics></math>: model <math id="S3.T1.12.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.T1.12.m3.1b"><mi id="S3.T1.12.m3.1.1" xref="S3.T1.12.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.T1.12.m3.1c"><ci id="S3.T1.12.m3.1.1.cmml" xref="S3.T1.12.m3.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.m3.1d">C</annotation></semantics></math> adapted to each accented training set separately. <math id="S3.T1.13.m4.1" class="ltx_Math" alttext="FM" display="inline"><semantics id="S3.T1.13.m4.1b"><mrow id="S3.T1.13.m4.1.1" xref="S3.T1.13.m4.1.1.cmml"><mi id="S3.T1.13.m4.1.1.2" xref="S3.T1.13.m4.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.T1.13.m4.1.1.1" xref="S3.T1.13.m4.1.1.1.cmml">â€‹</mo><mi id="S3.T1.13.m4.1.1.3" xref="S3.T1.13.m4.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.13.m4.1c"><apply id="S3.T1.13.m4.1.1.cmml" xref="S3.T1.13.m4.1.1"><times id="S3.T1.13.m4.1.1.1.cmml" xref="S3.T1.13.m4.1.1.1"></times><ci id="S3.T1.13.m4.1.1.2.cmml" xref="S3.T1.13.m4.1.1.2">ğ¹</ci><ci id="S3.T1.13.m4.1.1.3.cmml" xref="S3.T1.13.m4.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.13.m4.1d">FM</annotation></semantics></math>: model <math id="S3.T1.14.m5.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.T1.14.m5.1b"><mi id="S3.T1.14.m5.1.1" xref="S3.T1.14.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.T1.14.m5.1c"><ci id="S3.T1.14.m5.1.1.cmml" xref="S3.T1.14.m5.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.14.m5.1d">C</annotation></semantics></math> fine-tuned on the mix of all training accented sets. Lower, dark grey. ASR decoding results for TTS data augmentation (75%/25% TTS/real data). <math id="S3.T1.15.m6.1" class="ltx_Math" alttext="FT_{aug}" display="inline"><semantics id="S3.T1.15.m6.1b"><mrow id="S3.T1.15.m6.1.1" xref="S3.T1.15.m6.1.1.cmml"><mi id="S3.T1.15.m6.1.1.2" xref="S3.T1.15.m6.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.T1.15.m6.1.1.1" xref="S3.T1.15.m6.1.1.1.cmml">â€‹</mo><msub id="S3.T1.15.m6.1.1.3" xref="S3.T1.15.m6.1.1.3.cmml"><mi id="S3.T1.15.m6.1.1.3.2" xref="S3.T1.15.m6.1.1.3.2.cmml">T</mi><mrow id="S3.T1.15.m6.1.1.3.3" xref="S3.T1.15.m6.1.1.3.3.cmml"><mi id="S3.T1.15.m6.1.1.3.3.2" xref="S3.T1.15.m6.1.1.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T1.15.m6.1.1.3.3.1" xref="S3.T1.15.m6.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.T1.15.m6.1.1.3.3.3" xref="S3.T1.15.m6.1.1.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T1.15.m6.1.1.3.3.1b" xref="S3.T1.15.m6.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.T1.15.m6.1.1.3.3.4" xref="S3.T1.15.m6.1.1.3.3.4.cmml">g</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.15.m6.1c"><apply id="S3.T1.15.m6.1.1.cmml" xref="S3.T1.15.m6.1.1"><times id="S3.T1.15.m6.1.1.1.cmml" xref="S3.T1.15.m6.1.1.1"></times><ci id="S3.T1.15.m6.1.1.2.cmml" xref="S3.T1.15.m6.1.1.2">ğ¹</ci><apply id="S3.T1.15.m6.1.1.3.cmml" xref="S3.T1.15.m6.1.1.3"><csymbol cd="ambiguous" id="S3.T1.15.m6.1.1.3.1.cmml" xref="S3.T1.15.m6.1.1.3">subscript</csymbol><ci id="S3.T1.15.m6.1.1.3.2.cmml" xref="S3.T1.15.m6.1.1.3.2">ğ‘‡</ci><apply id="S3.T1.15.m6.1.1.3.3.cmml" xref="S3.T1.15.m6.1.1.3.3"><times id="S3.T1.15.m6.1.1.3.3.1.cmml" xref="S3.T1.15.m6.1.1.3.3.1"></times><ci id="S3.T1.15.m6.1.1.3.3.2.cmml" xref="S3.T1.15.m6.1.1.3.3.2">ğ‘</ci><ci id="S3.T1.15.m6.1.1.3.3.3.cmml" xref="S3.T1.15.m6.1.1.3.3.3">ğ‘¢</ci><ci id="S3.T1.15.m6.1.1.3.3.4.cmml" xref="S3.T1.15.m6.1.1.3.3.4">ğ‘”</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.m6.1d">FT_{aug}</annotation></semantics></math>, <math id="S3.T1.16.m7.1" class="ltx_Math" alttext="FM_{aug}" display="inline"><semantics id="S3.T1.16.m7.1b"><mrow id="S3.T1.16.m7.1.1" xref="S3.T1.16.m7.1.1.cmml"><mi id="S3.T1.16.m7.1.1.2" xref="S3.T1.16.m7.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.T1.16.m7.1.1.1" xref="S3.T1.16.m7.1.1.1.cmml">â€‹</mo><msub id="S3.T1.16.m7.1.1.3" xref="S3.T1.16.m7.1.1.3.cmml"><mi id="S3.T1.16.m7.1.1.3.2" xref="S3.T1.16.m7.1.1.3.2.cmml">M</mi><mrow id="S3.T1.16.m7.1.1.3.3" xref="S3.T1.16.m7.1.1.3.3.cmml"><mi id="S3.T1.16.m7.1.1.3.3.2" xref="S3.T1.16.m7.1.1.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T1.16.m7.1.1.3.3.1" xref="S3.T1.16.m7.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.T1.16.m7.1.1.3.3.3" xref="S3.T1.16.m7.1.1.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T1.16.m7.1.1.3.3.1b" xref="S3.T1.16.m7.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.T1.16.m7.1.1.3.3.4" xref="S3.T1.16.m7.1.1.3.3.4.cmml">g</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.16.m7.1c"><apply id="S3.T1.16.m7.1.1.cmml" xref="S3.T1.16.m7.1.1"><times id="S3.T1.16.m7.1.1.1.cmml" xref="S3.T1.16.m7.1.1.1"></times><ci id="S3.T1.16.m7.1.1.2.cmml" xref="S3.T1.16.m7.1.1.2">ğ¹</ci><apply id="S3.T1.16.m7.1.1.3.cmml" xref="S3.T1.16.m7.1.1.3"><csymbol cd="ambiguous" id="S3.T1.16.m7.1.1.3.1.cmml" xref="S3.T1.16.m7.1.1.3">subscript</csymbol><ci id="S3.T1.16.m7.1.1.3.2.cmml" xref="S3.T1.16.m7.1.1.3.2">ğ‘€</ci><apply id="S3.T1.16.m7.1.1.3.3.cmml" xref="S3.T1.16.m7.1.1.3.3"><times id="S3.T1.16.m7.1.1.3.3.1.cmml" xref="S3.T1.16.m7.1.1.3.3.1"></times><ci id="S3.T1.16.m7.1.1.3.3.2.cmml" xref="S3.T1.16.m7.1.1.3.3.2">ğ‘</ci><ci id="S3.T1.16.m7.1.1.3.3.3.cmml" xref="S3.T1.16.m7.1.1.3.3.3">ğ‘¢</ci><ci id="S3.T1.16.m7.1.1.3.3.4.cmml" xref="S3.T1.16.m7.1.1.3.3.4">ğ‘”</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.m7.1d">FM_{aug}</annotation></semantics></math> analogous as above with TTS augmentation. <math id="S3.T1.17.m8.1" class="ltx_Math" alttext="FM_{aug+db}" display="inline"><semantics id="S3.T1.17.m8.1b"><mrow id="S3.T1.17.m8.1.1" xref="S3.T1.17.m8.1.1.cmml"><mi id="S3.T1.17.m8.1.1.2" xref="S3.T1.17.m8.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.T1.17.m8.1.1.1" xref="S3.T1.17.m8.1.1.1.cmml">â€‹</mo><msub id="S3.T1.17.m8.1.1.3" xref="S3.T1.17.m8.1.1.3.cmml"><mi id="S3.T1.17.m8.1.1.3.2" xref="S3.T1.17.m8.1.1.3.2.cmml">M</mi><mrow id="S3.T1.17.m8.1.1.3.3" xref="S3.T1.17.m8.1.1.3.3.cmml"><mrow id="S3.T1.17.m8.1.1.3.3.2" xref="S3.T1.17.m8.1.1.3.3.2.cmml"><mi id="S3.T1.17.m8.1.1.3.3.2.2" xref="S3.T1.17.m8.1.1.3.3.2.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T1.17.m8.1.1.3.3.2.1" xref="S3.T1.17.m8.1.1.3.3.2.1.cmml">â€‹</mo><mi id="S3.T1.17.m8.1.1.3.3.2.3" xref="S3.T1.17.m8.1.1.3.3.2.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T1.17.m8.1.1.3.3.2.1b" xref="S3.T1.17.m8.1.1.3.3.2.1.cmml">â€‹</mo><mi id="S3.T1.17.m8.1.1.3.3.2.4" xref="S3.T1.17.m8.1.1.3.3.2.4.cmml">g</mi></mrow><mo id="S3.T1.17.m8.1.1.3.3.1" xref="S3.T1.17.m8.1.1.3.3.1.cmml">+</mo><mrow id="S3.T1.17.m8.1.1.3.3.3" xref="S3.T1.17.m8.1.1.3.3.3.cmml"><mi id="S3.T1.17.m8.1.1.3.3.3.2" xref="S3.T1.17.m8.1.1.3.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.T1.17.m8.1.1.3.3.3.1" xref="S3.T1.17.m8.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.T1.17.m8.1.1.3.3.3.3" xref="S3.T1.17.m8.1.1.3.3.3.3.cmml">b</mi></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.17.m8.1c"><apply id="S3.T1.17.m8.1.1.cmml" xref="S3.T1.17.m8.1.1"><times id="S3.T1.17.m8.1.1.1.cmml" xref="S3.T1.17.m8.1.1.1"></times><ci id="S3.T1.17.m8.1.1.2.cmml" xref="S3.T1.17.m8.1.1.2">ğ¹</ci><apply id="S3.T1.17.m8.1.1.3.cmml" xref="S3.T1.17.m8.1.1.3"><csymbol cd="ambiguous" id="S3.T1.17.m8.1.1.3.1.cmml" xref="S3.T1.17.m8.1.1.3">subscript</csymbol><ci id="S3.T1.17.m8.1.1.3.2.cmml" xref="S3.T1.17.m8.1.1.3.2">ğ‘€</ci><apply id="S3.T1.17.m8.1.1.3.3.cmml" xref="S3.T1.17.m8.1.1.3.3"><plus id="S3.T1.17.m8.1.1.3.3.1.cmml" xref="S3.T1.17.m8.1.1.3.3.1"></plus><apply id="S3.T1.17.m8.1.1.3.3.2.cmml" xref="S3.T1.17.m8.1.1.3.3.2"><times id="S3.T1.17.m8.1.1.3.3.2.1.cmml" xref="S3.T1.17.m8.1.1.3.3.2.1"></times><ci id="S3.T1.17.m8.1.1.3.3.2.2.cmml" xref="S3.T1.17.m8.1.1.3.3.2.2">ğ‘</ci><ci id="S3.T1.17.m8.1.1.3.3.2.3.cmml" xref="S3.T1.17.m8.1.1.3.3.2.3">ğ‘¢</ci><ci id="S3.T1.17.m8.1.1.3.3.2.4.cmml" xref="S3.T1.17.m8.1.1.3.3.2.4">ğ‘”</ci></apply><apply id="S3.T1.17.m8.1.1.3.3.3.cmml" xref="S3.T1.17.m8.1.1.3.3.3"><times id="S3.T1.17.m8.1.1.3.3.3.1.cmml" xref="S3.T1.17.m8.1.1.3.3.3.1"></times><ci id="S3.T1.17.m8.1.1.3.3.3.2.cmml" xref="S3.T1.17.m8.1.1.3.3.3.2">ğ‘‘</ci><ci id="S3.T1.17.m8.1.1.3.3.3.3.cmml" xref="S3.T1.17.m8.1.1.3.3.3.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.m8.1d">FM_{aug+db}</annotation></semantics></math>: <math id="S3.T1.18.m9.1" class="ltx_Math" alttext="FM_{aug}" display="inline"><semantics id="S3.T1.18.m9.1b"><mrow id="S3.T1.18.m9.1.1" xref="S3.T1.18.m9.1.1.cmml"><mi id="S3.T1.18.m9.1.1.2" xref="S3.T1.18.m9.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.T1.18.m9.1.1.1" xref="S3.T1.18.m9.1.1.1.cmml">â€‹</mo><msub id="S3.T1.18.m9.1.1.3" xref="S3.T1.18.m9.1.1.3.cmml"><mi id="S3.T1.18.m9.1.1.3.2" xref="S3.T1.18.m9.1.1.3.2.cmml">M</mi><mrow id="S3.T1.18.m9.1.1.3.3" xref="S3.T1.18.m9.1.1.3.3.cmml"><mi id="S3.T1.18.m9.1.1.3.3.2" xref="S3.T1.18.m9.1.1.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T1.18.m9.1.1.3.3.1" xref="S3.T1.18.m9.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.T1.18.m9.1.1.3.3.3" xref="S3.T1.18.m9.1.1.3.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T1.18.m9.1.1.3.3.1b" xref="S3.T1.18.m9.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.T1.18.m9.1.1.3.3.4" xref="S3.T1.18.m9.1.1.3.3.4.cmml">g</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.18.m9.1c"><apply id="S3.T1.18.m9.1.1.cmml" xref="S3.T1.18.m9.1.1"><times id="S3.T1.18.m9.1.1.1.cmml" xref="S3.T1.18.m9.1.1.1"></times><ci id="S3.T1.18.m9.1.1.2.cmml" xref="S3.T1.18.m9.1.1.2">ğ¹</ci><apply id="S3.T1.18.m9.1.1.3.cmml" xref="S3.T1.18.m9.1.1.3"><csymbol cd="ambiguous" id="S3.T1.18.m9.1.1.3.1.cmml" xref="S3.T1.18.m9.1.1.3">subscript</csymbol><ci id="S3.T1.18.m9.1.1.3.2.cmml" xref="S3.T1.18.m9.1.1.3.2">ğ‘€</ci><apply id="S3.T1.18.m9.1.1.3.3.cmml" xref="S3.T1.18.m9.1.1.3.3"><times id="S3.T1.18.m9.1.1.3.3.1.cmml" xref="S3.T1.18.m9.1.1.3.3.1"></times><ci id="S3.T1.18.m9.1.1.3.3.2.cmml" xref="S3.T1.18.m9.1.1.3.3.2">ğ‘</ci><ci id="S3.T1.18.m9.1.1.3.3.3.cmml" xref="S3.T1.18.m9.1.1.3.3.3">ğ‘¢</ci><ci id="S3.T1.18.m9.1.1.3.3.4.cmml" xref="S3.T1.18.m9.1.1.3.3.4">ğ‘”</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.18.m9.1d">FM_{aug}</annotation></semantics></math> with batches built with 75%/25% TTS/real data.</figcaption>
<table id="S3.T1.26" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.19.1" class="ltx_tr">
<th id="S3.T1.19.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T1.19.1.2.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S3.T1.19.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" colspan="11">
<span id="S3.T1.19.1.1.1" class="ltx_text ltx_font_bold">WER[%]</span> Â Â   <svg id="S3.T1.19.1.1.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>
</th>
<th id="S3.T1.19.1.3" class="ltx_td ltx_th ltx_th_column ltx_border_tt"></th>
</tr>
<tr id="S3.T1.26.9.1" class="ltx_tr">
<th id="S3.T1.26.9.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S3.T1.26.9.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S3.T1.26.9.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">GBR</th>
<th id="S3.T1.26.9.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">USA</th>
<th id="S3.T1.26.9.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">CAN</th>
<th id="S3.T1.26.9.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">PRT</th>
<th id="S3.T1.26.9.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">IND</th>
<th id="S3.T1.26.9.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">CHN</th>
<th id="S3.T1.26.9.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">ESP</th>
<th id="S3.T1.26.9.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">KOR</th>
<th id="S3.T1.26.9.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">RUS</th>
<th id="S3.T1.26.9.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">JPN</th>
<th id="S3.T1.26.9.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Avg</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.21.3" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T1.21.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.2.2" class="ltx_text" style="background-color:#E6E6E6;"> <svg id="S3.T1.20.2.1.1.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>
<math id="S3.T1.21.3.2.2.m1.1" class="ltx_Math" style="background-color:#E6E6E6;" alttext="\mathit{C}" display="inline"><semantics id="S3.T1.21.3.2.2.m1.1a"><mi mathbackground="#E6E6E6" id="S3.T1.21.3.2.2.m1.1.1" xref="S3.T1.21.3.2.2.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.T1.21.3.2.2.m1.1b"><ci id="S3.T1.21.3.2.2.m1.1.1.cmml" xref="S3.T1.21.3.2.2.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.21.3.2.2.m1.1c">\mathit{C}</annotation></semantics></math></span></td>
<td id="S3.T1.21.3.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.21.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.4.1" class="ltx_text" style="background-color:#E6E6E6;">7.47</span></td>
<td id="S3.T1.21.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.5.1" class="ltx_text" style="background-color:#E6E6E6;">17.74</span></td>
<td id="S3.T1.21.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.6.1" class="ltx_text" style="background-color:#E6E6E6;">18.26</span></td>
<td id="S3.T1.21.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.7.1" class="ltx_text" style="background-color:#E6E6E6;">19.28</span></td>
<td id="S3.T1.21.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.8.1" class="ltx_text" style="background-color:#E6E6E6;">23.40</span></td>
<td id="S3.T1.21.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.9.1" class="ltx_text" style="background-color:#E6E6E6;">24.03</span></td>
<td id="S3.T1.21.3.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.10.1" class="ltx_text" style="background-color:#E6E6E6;">26.35</span></td>
<td id="S3.T1.21.3.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.11.1" class="ltx_text" style="background-color:#E6E6E6;">33.78</span></td>
<td id="S3.T1.21.3.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.21.3.12.1" class="ltx_text" style="background-color:#E6E6E6;">35.75</span></td>
<td id="S3.T1.21.3.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.21.3.13.1" class="ltx_text" style="background-color:#E6E6E6;">36.97</span></td>
<td id="S3.T1.21.3.14" class="ltx_td ltx_align_center"><span id="S3.T1.21.3.14.1" class="ltx_text" style="background-color:#E6E6E6;">24.3</span></td>
</tr>
<tr id="S3.T1.22.4" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T1.22.4.1" class="ltx_td ltx_align_center"><math id="S3.T1.22.4.1.m1.1" class="ltx_Math" style="background-color:#E6E6E6;" alttext="\mathit{FT}" display="inline"><semantics id="S3.T1.22.4.1.m1.1a"><mi mathbackground="#E6E6E6" id="S3.T1.22.4.1.m1.1.1" xref="S3.T1.22.4.1.m1.1.1.cmml">ğ¹ğ‘‡</mi><annotation-xml encoding="MathML-Content" id="S3.T1.22.4.1.m1.1b"><ci id="S3.T1.22.4.1.m1.1.1.cmml" xref="S3.T1.22.4.1.m1.1.1">ğ¹ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.22.4.1.m1.1c">\mathit{FT}</annotation></semantics></math></td>
<td id="S3.T1.22.4.2" class="ltx_td"></td>
<td id="S3.T1.22.4.3" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.3.1" class="ltx_text" style="background-color:#E6E6E6;">2.32</span></td>
<td id="S3.T1.22.4.4" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.4.1" class="ltx_text" style="background-color:#E6E6E6;">8.18</span></td>
<td id="S3.T1.22.4.5" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.5.1" class="ltx_text" style="background-color:#E6E6E6;">X</span></td>
<td id="S3.T1.22.4.6" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.6.1" class="ltx_text" style="background-color:#E6E6E6;">6.67</span></td>
<td id="S3.T1.22.4.7" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.7.1" class="ltx_text" style="background-color:#E6E6E6;">9.46</span></td>
<td id="S3.T1.22.4.8" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.8.1" class="ltx_text" style="background-color:#E6E6E6;">9.97</span></td>
<td id="S3.T1.22.4.9" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.9.1" class="ltx_text" style="background-color:#E6E6E6;">X</span></td>
<td id="S3.T1.22.4.10" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.10.1" class="ltx_text" style="background-color:#E6E6E6;">7.16</span></td>
<td id="S3.T1.22.4.11" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.11.1" class="ltx_text" style="background-color:#E6E6E6;">10.15</span></td>
<td id="S3.T1.22.4.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.22.4.12.1" class="ltx_text" style="background-color:#E6E6E6;">7.36</span></td>
<td id="S3.T1.22.4.13" class="ltx_td ltx_align_center"><span id="S3.T1.22.4.13.1" class="ltx_text" style="background-color:#E6E6E6;">7.66</span></td>
</tr>
<tr id="S3.T1.23.5" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T1.23.5.1" class="ltx_td ltx_align_center"><math id="S3.T1.23.5.1.m1.1" class="ltx_Math" style="background-color:#E6E6E6;" alttext="\mathit{FM}" display="inline"><semantics id="S3.T1.23.5.1.m1.1a"><mi mathbackground="#E6E6E6" id="S3.T1.23.5.1.m1.1.1" xref="S3.T1.23.5.1.m1.1.1.cmml">ğ¹ğ‘€</mi><annotation-xml encoding="MathML-Content" id="S3.T1.23.5.1.m1.1b"><ci id="S3.T1.23.5.1.m1.1.1.cmml" xref="S3.T1.23.5.1.m1.1.1">ğ¹ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.23.5.1.m1.1c">\mathit{FM}</annotation></semantics></math></td>
<td id="S3.T1.23.5.2" class="ltx_td"></td>
<td id="S3.T1.23.5.3" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.3.1" class="ltx_text" style="background-color:#E6E6E6;">2.06</span></td>
<td id="S3.T1.23.5.4" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.4.1" class="ltx_text" style="background-color:#E6E6E6;">4.95</span></td>
<td id="S3.T1.23.5.5" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.5.1" class="ltx_text" style="background-color:#E6E6E6;">4.51</span></td>
<td id="S3.T1.23.5.6" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.6.1" class="ltx_text" style="background-color:#E6E6E6;">5.31</span></td>
<td id="S3.T1.23.5.7" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.7.1" class="ltx_text" style="background-color:#E6E6E6;">8.51</span></td>
<td id="S3.T1.23.5.8" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.8.1" class="ltx_text" style="background-color:#E6E6E6;">9.87</span></td>
<td id="S3.T1.23.5.9" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.9.1" class="ltx_text" style="background-color:#E6E6E6;">7.39</span></td>
<td id="S3.T1.23.5.10" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.10.1" class="ltx_text" style="background-color:#E6E6E6;">5.40</span></td>
<td id="S3.T1.23.5.11" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.11.1" class="ltx_text" style="background-color:#E6E6E6;">8.98</span></td>
<td id="S3.T1.23.5.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.23.5.12.1" class="ltx_text" style="background-color:#E6E6E6;">6.31</span></td>
<td id="S3.T1.23.5.13" class="ltx_td ltx_align_center"><span id="S3.T1.23.5.13.1" class="ltx_text" style="background-color:#E6E6E6;">6.33</span></td>
</tr>
<tr id="S3.T1.26.10.1" class="ltx_tr">
<td id="S3.T1.26.10.1.1" class="ltx_td ltx_align_center ltx_border_t">TTS-AUG</td>
<td id="S3.T1.26.10.1.2" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.3" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.4" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.5" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.6" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.7" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.8" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.9" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.10" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.11" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.12" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.26.10.1.13" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T1.24.6" class="ltx_tr" style="background-color:#BFBFBF;">
<td id="S3.T1.24.6.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S3.T1.24.6.1.m1.1" class="ltx_Math" style="background-color:#BFBFBF;" alttext="\mathit{FT_{aug}}" display="inline"><semantics id="S3.T1.24.6.1.m1.1a"><msub id="S3.T1.24.6.1.m1.1.1" xref="S3.T1.24.6.1.m1.1.1.cmml"><mi mathbackground="#BFBFBF" id="S3.T1.24.6.1.m1.1.1.2" xref="S3.T1.24.6.1.m1.1.1.2.cmml">ğ¹ğ‘‡</mi><mi mathbackground="#BFBFBF" id="S3.T1.24.6.1.m1.1.1.3" xref="S3.T1.24.6.1.m1.1.1.3.cmml">ğ‘ğ‘¢ğ‘”</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T1.24.6.1.m1.1b"><apply id="S3.T1.24.6.1.m1.1.1.cmml" xref="S3.T1.24.6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.24.6.1.m1.1.1.1.cmml" xref="S3.T1.24.6.1.m1.1.1">subscript</csymbol><ci id="S3.T1.24.6.1.m1.1.1.2.cmml" xref="S3.T1.24.6.1.m1.1.1.2">ğ¹ğ‘‡</ci><ci id="S3.T1.24.6.1.m1.1.1.3.cmml" xref="S3.T1.24.6.1.m1.1.1.3">ğ‘ğ‘¢ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.24.6.1.m1.1c">\mathit{FT_{aug}}</annotation></semantics></math></td>
<td id="S3.T1.24.6.2" class="ltx_td ltx_border_t"></td>
<td id="S3.T1.24.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.3.1" class="ltx_text" style="background-color:#BFBFBF;">2.42</span></td>
<td id="S3.T1.24.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.4.1" class="ltx_text" style="background-color:#BFBFBF;">6.82</span></td>
<td id="S3.T1.24.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.5.1" class="ltx_text" style="background-color:#BFBFBF;">X</span></td>
<td id="S3.T1.24.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.6.1" class="ltx_text" style="background-color:#BFBFBF;">6.65</span></td>
<td id="S3.T1.24.6.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.7.1" class="ltx_text" style="background-color:#BFBFBF;">9.21</span></td>
<td id="S3.T1.24.6.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.8.1" class="ltx_text" style="background-color:#BFBFBF;">11.96</span></td>
<td id="S3.T1.24.6.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.9.1" class="ltx_text" style="background-color:#BFBFBF;">X</span></td>
<td id="S3.T1.24.6.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.10.1" class="ltx_text" style="background-color:#BFBFBF;">7.21</span></td>
<td id="S3.T1.24.6.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.11.1" class="ltx_text" style="background-color:#BFBFBF;">10.87</span></td>
<td id="S3.T1.24.6.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.24.6.12.1" class="ltx_text" style="background-color:#BFBFBF;">7.90</span></td>
<td id="S3.T1.24.6.13" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.24.6.13.1" class="ltx_text" style="background-color:#BFBFBF;">7.88</span></td>
</tr>
<tr id="S3.T1.25.7" class="ltx_tr" style="background-color:#BFBFBF;">
<td id="S3.T1.25.7.1" class="ltx_td ltx_align_center"><math id="S3.T1.25.7.1.m1.1" class="ltx_Math" style="background-color:#BFBFBF;" alttext="\mathit{FM_{aug}}" display="inline"><semantics id="S3.T1.25.7.1.m1.1a"><msub id="S3.T1.25.7.1.m1.1.1" xref="S3.T1.25.7.1.m1.1.1.cmml"><mi mathbackground="#BFBFBF" id="S3.T1.25.7.1.m1.1.1.2" xref="S3.T1.25.7.1.m1.1.1.2.cmml">ğ¹ğ‘€</mi><mi mathbackground="#BFBFBF" id="S3.T1.25.7.1.m1.1.1.3" xref="S3.T1.25.7.1.m1.1.1.3.cmml">ğ‘ğ‘¢ğ‘”</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T1.25.7.1.m1.1b"><apply id="S3.T1.25.7.1.m1.1.1.cmml" xref="S3.T1.25.7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.25.7.1.m1.1.1.1.cmml" xref="S3.T1.25.7.1.m1.1.1">subscript</csymbol><ci id="S3.T1.25.7.1.m1.1.1.2.cmml" xref="S3.T1.25.7.1.m1.1.1.2">ğ¹ğ‘€</ci><ci id="S3.T1.25.7.1.m1.1.1.3.cmml" xref="S3.T1.25.7.1.m1.1.1.3">ğ‘ğ‘¢ğ‘”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.25.7.1.m1.1c">\mathit{FM_{aug}}</annotation></semantics></math></td>
<td id="S3.T1.25.7.2" class="ltx_td"></td>
<td id="S3.T1.25.7.3" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.3.1" class="ltx_text" style="background-color:#BFBFBF;">2.22</span></td>
<td id="S3.T1.25.7.4" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.4.1" class="ltx_text" style="background-color:#BFBFBF;">5.46</span></td>
<td id="S3.T1.25.7.5" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.5.1" class="ltx_text" style="background-color:#BFBFBF;">4.72</span></td>
<td id="S3.T1.25.7.6" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.6.1" class="ltx_text" style="background-color:#BFBFBF;">5.62</span></td>
<td id="S3.T1.25.7.7" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.7.1" class="ltx_text" style="background-color:#BFBFBF;">8.64</span></td>
<td id="S3.T1.25.7.8" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.8.1" class="ltx_text" style="background-color:#BFBFBF;">10.74</span></td>
<td id="S3.T1.25.7.9" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.9.1" class="ltx_text" style="background-color:#BFBFBF;">8.14</span></td>
<td id="S3.T1.25.7.10" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.10.1" class="ltx_text" style="background-color:#BFBFBF;">5.92</span></td>
<td id="S3.T1.25.7.11" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.11.1" class="ltx_text" style="background-color:#BFBFBF;">9.65</span></td>
<td id="S3.T1.25.7.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T1.25.7.12.1" class="ltx_text" style="background-color:#BFBFBF;">6.82</span></td>
<td id="S3.T1.25.7.13" class="ltx_td ltx_align_center"><span id="S3.T1.25.7.13.1" class="ltx_text" style="background-color:#BFBFBF;">6.79</span></td>
</tr>
<tr id="S3.T1.26.8" class="ltx_tr" style="background-color:#BFBFBF;">
<td id="S3.T1.26.8.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S3.T1.26.8.1.m1.1" class="ltx_Math" style="background-color:#BFBFBF;" alttext="\mathit{FM_{aug+db}}" display="inline"><semantics id="S3.T1.26.8.1.m1.1a"><msub id="S3.T1.26.8.1.m1.1.1" xref="S3.T1.26.8.1.m1.1.1.cmml"><mi mathbackground="#BFBFBF" id="S3.T1.26.8.1.m1.1.1.2" xref="S3.T1.26.8.1.m1.1.1.2.cmml">ğ¹ğ‘€</mi><mrow id="S3.T1.26.8.1.m1.1.1.3" xref="S3.T1.26.8.1.m1.1.1.3.cmml"><mi mathbackground="#BFBFBF" id="S3.T1.26.8.1.m1.1.1.3.2" xref="S3.T1.26.8.1.m1.1.1.3.2.cmml">ğ‘ğ‘¢ğ‘”</mi><mo mathbackground="#BFBFBF" id="S3.T1.26.8.1.m1.1.1.3.1" xref="S3.T1.26.8.1.m1.1.1.3.1.cmml">+</mo><mi mathbackground="#BFBFBF" id="S3.T1.26.8.1.m1.1.1.3.3" xref="S3.T1.26.8.1.m1.1.1.3.3.cmml">ğ‘‘ğ‘</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T1.26.8.1.m1.1b"><apply id="S3.T1.26.8.1.m1.1.1.cmml" xref="S3.T1.26.8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.26.8.1.m1.1.1.1.cmml" xref="S3.T1.26.8.1.m1.1.1">subscript</csymbol><ci id="S3.T1.26.8.1.m1.1.1.2.cmml" xref="S3.T1.26.8.1.m1.1.1.2">ğ¹ğ‘€</ci><apply id="S3.T1.26.8.1.m1.1.1.3.cmml" xref="S3.T1.26.8.1.m1.1.1.3"><plus id="S3.T1.26.8.1.m1.1.1.3.1.cmml" xref="S3.T1.26.8.1.m1.1.1.3.1"></plus><ci id="S3.T1.26.8.1.m1.1.1.3.2.cmml" xref="S3.T1.26.8.1.m1.1.1.3.2">ğ‘ğ‘¢ğ‘”</ci><ci id="S3.T1.26.8.1.m1.1.1.3.3.cmml" xref="S3.T1.26.8.1.m1.1.1.3.3">ğ‘‘ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.26.8.1.m1.1c">\mathit{FM_{aug+db}}</annotation></semantics></math></td>
<td id="S3.T1.26.8.2" class="ltx_td ltx_border_bb"></td>
<td id="S3.T1.26.8.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.3.1" class="ltx_text" style="background-color:#BFBFBF;">2.25</span></td>
<td id="S3.T1.26.8.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.4.1" class="ltx_text" style="background-color:#BFBFBF;">5.38</span></td>
<td id="S3.T1.26.8.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.5.1" class="ltx_text" style="background-color:#BFBFBF;">4.63</span></td>
<td id="S3.T1.26.8.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.6.1" class="ltx_text" style="background-color:#BFBFBF;">5.50</span></td>
<td id="S3.T1.26.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.7.1" class="ltx_text" style="background-color:#BFBFBF;">8.50</span></td>
<td id="S3.T1.26.8.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.8.1" class="ltx_text" style="background-color:#BFBFBF;">11.21</span></td>
<td id="S3.T1.26.8.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.9.1" class="ltx_text" style="background-color:#BFBFBF;">8.00</span></td>
<td id="S3.T1.26.8.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.10.1" class="ltx_text" style="background-color:#BFBFBF;">5.85</span></td>
<td id="S3.T1.26.8.11" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.11.1" class="ltx_text" style="background-color:#BFBFBF;">9.47</span></td>
<td id="S3.T1.26.8.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S3.T1.26.8.12.1" class="ltx_text" style="background-color:#BFBFBF;">6.87</span></td>
<td id="S3.T1.26.8.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T1.26.8.13.1" class="ltx_text" style="background-color:#BFBFBF;">6.77</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Single accent</h3>

<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>ASR fine-tuning on mixed real and TTS data</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">For preliminary results, we focused on one accent specifically, the Indian English accent. Initially, we trained the ASR model from scratch on the full 960 hours of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. The model scored a WER of 2.34% and 5.55% on the <span id="S3.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_italic">test-clean</span> and <span id="S3.SS1.SSS1.p1.1.2" class="ltx_text ltx_font_italic">test-others</span> partitions of Librispeech. However, when decoding the <span id="S3.SS1.SSS1.p1.1.3" class="ltx_text ltx_font_italic">test-IND</span> partition of the Interspeech 2020 dataset with the aforementioned ASR model, we obtained a consistent performance degradation in terms of WER (22.24%). This degradation in performance can be attributed to the inherent mismatch in acoustic and linguistic characteristics between the training data and the <span id="S3.SS1.SSS1.p1.1.4" class="ltx_text ltx_font_italic">test-IND</span> partition, underscoring the need for further refinement and adaptation of the ASR model to effectively handle diverse and unseen conditions.</p>
</div>
<figure id="S3.T2" class="ltx_table">

<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>ASR decoding results for the <span id="S3.T2.17.1" class="ltx_text ltx_font_italic">test-IND</span> set with ASR model fine-tuned on different partitions of <span id="S3.T2.18.2" class="ltx_text ltx_font_italic">train-IND</span> augmented with TTS generated data. R: model trained on real data. <math id="S3.T2.5.m1.1" class="ltx_Math" alttext="\mathrm{R}-\mathrm{TTS_{c}}" display="inline"><semantics id="S3.T2.5.m1.1b"><mrow id="S3.T2.5.m1.1.1" xref="S3.T2.5.m1.1.1.cmml"><mi mathvariant="normal" id="S3.T2.5.m1.1.1.2" xref="S3.T2.5.m1.1.1.2.cmml">R</mi><mo id="S3.T2.5.m1.1.1.1" xref="S3.T2.5.m1.1.1.1.cmml">âˆ’</mo><msub id="S3.T2.5.m1.1.1.3" xref="S3.T2.5.m1.1.1.3.cmml"><mi id="S3.T2.5.m1.1.1.3.2" xref="S3.T2.5.m1.1.1.3.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T2.5.m1.1.1.3.3" xref="S3.T2.5.m1.1.1.3.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.5.m1.1c"><apply id="S3.T2.5.m1.1.1.cmml" xref="S3.T2.5.m1.1.1"><minus id="S3.T2.5.m1.1.1.1.cmml" xref="S3.T2.5.m1.1.1.1"></minus><ci id="S3.T2.5.m1.1.1.2.cmml" xref="S3.T2.5.m1.1.1.2">R</ci><apply id="S3.T2.5.m1.1.1.3.cmml" xref="S3.T2.5.m1.1.1.3"><csymbol cd="ambiguous" id="S3.T2.5.m1.1.1.3.1.cmml" xref="S3.T2.5.m1.1.1.3">subscript</csymbol><ci id="S3.T2.5.m1.1.1.3.2.cmml" xref="S3.T2.5.m1.1.1.3.2">TTS</ci><ci id="S3.T2.5.m1.1.1.3.3.cmml" xref="S3.T2.5.m1.1.1.3.3">c</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.m1.1d">\mathrm{R}-\mathrm{TTS_{c}}</annotation></semantics></math>: model trained on real data mixed with synthetic data generated from <math id="S3.T2.6.m2.1" class="ltx_Math" alttext="\mathrm{TTS_{c}}" display="inline"><semantics id="S3.T2.6.m2.1b"><msub id="S3.T2.6.m2.1.1" xref="S3.T2.6.m2.1.1.cmml"><mi id="S3.T2.6.m2.1.1.2" xref="S3.T2.6.m2.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T2.6.m2.1.1.3" xref="S3.T2.6.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T2.6.m2.1c"><apply id="S3.T2.6.m2.1.1.cmml" xref="S3.T2.6.m2.1.1"><csymbol cd="ambiguous" id="S3.T2.6.m2.1.1.1.cmml" xref="S3.T2.6.m2.1.1">subscript</csymbol><ci id="S3.T2.6.m2.1.1.2.cmml" xref="S3.T2.6.m2.1.1.2">TTS</ci><ci id="S3.T2.6.m2.1.1.3.cmml" xref="S3.T2.6.m2.1.1.3">c</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.m2.1d">\mathrm{TTS_{c}}</annotation></semantics></math>. <math id="S3.T2.7.m3.1" class="ltx_Math" alttext="\mathrm{R}-\mathrm{TTS_{I}}" display="inline"><semantics id="S3.T2.7.m3.1b"><mrow id="S3.T2.7.m3.1.1" xref="S3.T2.7.m3.1.1.cmml"><mi mathvariant="normal" id="S3.T2.7.m3.1.1.2" xref="S3.T2.7.m3.1.1.2.cmml">R</mi><mo id="S3.T2.7.m3.1.1.1" xref="S3.T2.7.m3.1.1.1.cmml">âˆ’</mo><msub id="S3.T2.7.m3.1.1.3" xref="S3.T2.7.m3.1.1.3.cmml"><mi id="S3.T2.7.m3.1.1.3.2" xref="S3.T2.7.m3.1.1.3.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T2.7.m3.1.1.3.3" xref="S3.T2.7.m3.1.1.3.3.cmml">I</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.7.m3.1c"><apply id="S3.T2.7.m3.1.1.cmml" xref="S3.T2.7.m3.1.1"><minus id="S3.T2.7.m3.1.1.1.cmml" xref="S3.T2.7.m3.1.1.1"></minus><ci id="S3.T2.7.m3.1.1.2.cmml" xref="S3.T2.7.m3.1.1.2">R</ci><apply id="S3.T2.7.m3.1.1.3.cmml" xref="S3.T2.7.m3.1.1.3"><csymbol cd="ambiguous" id="S3.T2.7.m3.1.1.3.1.cmml" xref="S3.T2.7.m3.1.1.3">subscript</csymbol><ci id="S3.T2.7.m3.1.1.3.2.cmml" xref="S3.T2.7.m3.1.1.3.2">TTS</ci><ci id="S3.T2.7.m3.1.1.3.3.cmml" xref="S3.T2.7.m3.1.1.3.3">I</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.m3.1d">\mathrm{R}-\mathrm{TTS_{I}}</annotation></semantics></math>: model trained on real data mixed with synthetic data generated from <math id="S3.T2.8.m4.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.T2.8.m4.1b"><msub id="S3.T2.8.m4.1.1" xref="S3.T2.8.m4.1.1.cmml"><mi id="S3.T2.8.m4.1.1.2" xref="S3.T2.8.m4.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T2.8.m4.1.1.3" xref="S3.T2.8.m4.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T2.8.m4.1c"><apply id="S3.T2.8.m4.1.1.cmml" xref="S3.T2.8.m4.1.1"><csymbol cd="ambiguous" id="S3.T2.8.m4.1.1.1.cmml" xref="S3.T2.8.m4.1.1">subscript</csymbol><ci id="S3.T2.8.m4.1.1.2.cmml" xref="S3.T2.8.m4.1.1.2">TTS</ci><ci id="S3.T2.8.m4.1.1.3.cmml" xref="S3.T2.8.m4.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.m4.1d">\mathrm{TTS_{I}}</annotation></semantics></math>. The last column refers to the WERR achieved by each augmentation strategy with respect to no augmentation.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S3.T2.14" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.9.1" class="ltx_tr">
<th id="S3.T2.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.9.1.2.1" class="ltx_text ltx_font_bold">real data</span></th>
<th id="S3.T2.9.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3"><span id="S3.T2.9.1.3.1" class="ltx_text ltx_font_bold">WER[%]</span></th>
<th id="S3.T2.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T2.9.1.1.1" class="ltx_text ltx_font_bold">WERR[%]</span>  <svg id="S3.T2.9.1.1.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.14.6" class="ltx_tr">
<td id="S3.T2.14.6.6" class="ltx_td ltx_border_t"></td>
<th id="S3.T2.10.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S3.T2.10.2.1.m1.1" class="ltx_Math" alttext="\mathrm{R}" display="inline"><semantics id="S3.T2.10.2.1.m1.1a"><mi mathvariant="normal" id="S3.T2.10.2.1.m1.1.1" xref="S3.T2.10.2.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.T2.10.2.1.m1.1b"><ci id="S3.T2.10.2.1.m1.1.1.cmml" xref="S3.T2.10.2.1.m1.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.2.1.m1.1c">\mathrm{R}</annotation></semantics></math></th>
<th id="S3.T2.12.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S3.T2.11.3.2.m1.1" class="ltx_Math" alttext="\mathrm{R}" display="inline"><semantics id="S3.T2.11.3.2.m1.1a"><mi mathvariant="normal" id="S3.T2.11.3.2.m1.1.1" xref="S3.T2.11.3.2.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.T2.11.3.2.m1.1b"><ci id="S3.T2.11.3.2.m1.1.1.cmml" xref="S3.T2.11.3.2.m1.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.3.2.m1.1c">\mathrm{R}</annotation></semantics></math>-<math id="S3.T2.12.4.3.m2.1" class="ltx_Math" alttext="\mathrm{TTS_{c}}" display="inline"><semantics id="S3.T2.12.4.3.m2.1a"><msub id="S3.T2.12.4.3.m2.1.1" xref="S3.T2.12.4.3.m2.1.1.cmml"><mi id="S3.T2.12.4.3.m2.1.1.2" xref="S3.T2.12.4.3.m2.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T2.12.4.3.m2.1.1.3" xref="S3.T2.12.4.3.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T2.12.4.3.m2.1b"><apply id="S3.T2.12.4.3.m2.1.1.cmml" xref="S3.T2.12.4.3.m2.1.1"><csymbol cd="ambiguous" id="S3.T2.12.4.3.m2.1.1.1.cmml" xref="S3.T2.12.4.3.m2.1.1">subscript</csymbol><ci id="S3.T2.12.4.3.m2.1.1.2.cmml" xref="S3.T2.12.4.3.m2.1.1.2">TTS</ci><ci id="S3.T2.12.4.3.m2.1.1.3.cmml" xref="S3.T2.12.4.3.m2.1.1.3">c</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.4.3.m2.1c">\mathrm{TTS_{c}}</annotation></semantics></math>
</th>
<th id="S3.T2.14.6.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S3.T2.13.5.4.m1.1" class="ltx_Math" alttext="\mathrm{R}" display="inline"><semantics id="S3.T2.13.5.4.m1.1a"><mi mathvariant="normal" id="S3.T2.13.5.4.m1.1.1" xref="S3.T2.13.5.4.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.T2.13.5.4.m1.1b"><ci id="S3.T2.13.5.4.m1.1.1.cmml" xref="S3.T2.13.5.4.m1.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.5.4.m1.1c">\mathrm{R}</annotation></semantics></math>-<math id="S3.T2.14.6.5.m2.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.T2.14.6.5.m2.1a"><msub id="S3.T2.14.6.5.m2.1.1" xref="S3.T2.14.6.5.m2.1.1.cmml"><mi id="S3.T2.14.6.5.m2.1.1.2" xref="S3.T2.14.6.5.m2.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T2.14.6.5.m2.1.1.3" xref="S3.T2.14.6.5.m2.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T2.14.6.5.m2.1b"><apply id="S3.T2.14.6.5.m2.1.1.cmml" xref="S3.T2.14.6.5.m2.1.1"><csymbol cd="ambiguous" id="S3.T2.14.6.5.m2.1.1.1.cmml" xref="S3.T2.14.6.5.m2.1.1">subscript</csymbol><ci id="S3.T2.14.6.5.m2.1.1.2.cmml" xref="S3.T2.14.6.5.m2.1.1.2">TTS</ci><ci id="S3.T2.14.6.5.m2.1.1.3.cmml" xref="S3.T2.14.6.5.m2.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.6.5.m2.1c">\mathrm{TTS_{I}}</annotation></semantics></math>
</th>
<td id="S3.T2.14.6.7" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T2.14.7.1" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T2.14.7.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.14.7.1.1.1" class="ltx_text" style="background-color:#E6E6E6;">10%</span></td>
<td id="S3.T2.14.7.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.14.7.1.2.1" class="ltx_text" style="background-color:#E6E6E6;">13.29</span></td>
<td id="S3.T2.14.7.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.14.7.1.3.1" class="ltx_text" style="background-color:#E6E6E6;">11.82</span></td>
<td id="S3.T2.14.7.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.14.7.1.4.1" class="ltx_text" style="background-color:#E6E6E6;">10.98</span></td>
<td id="S3.T2.14.7.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.14.7.1.5.1" class="ltx_text" style="background-color:#E6E6E6;">11/17</span></td>
</tr>
<tr id="S3.T2.14.8.2" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T2.14.8.2.1" class="ltx_td ltx_align_center"><span id="S3.T2.14.8.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">25%</span></td>
<td id="S3.T2.14.8.2.2" class="ltx_td ltx_align_center"><span id="S3.T2.14.8.2.2.1" class="ltx_text" style="background-color:#E6E6E6;">11.80</span></td>
<td id="S3.T2.14.8.2.3" class="ltx_td ltx_align_center"><span id="S3.T2.14.8.2.3.1" class="ltx_text" style="background-color:#E6E6E6;">10.34</span></td>
<td id="S3.T2.14.8.2.4" class="ltx_td ltx_align_center"><span id="S3.T2.14.8.2.4.1" class="ltx_text" style="background-color:#E6E6E6;">10.15</span></td>
<td id="S3.T2.14.8.2.5" class="ltx_td ltx_align_center"><span id="S3.T2.14.8.2.5.1" class="ltx_text" style="background-color:#E6E6E6;">12/14</span></td>
</tr>
<tr id="S3.T2.14.9.3" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T2.14.9.3.1" class="ltx_td ltx_align_center"><span id="S3.T2.14.9.3.1.1" class="ltx_text" style="background-color:#E6E6E6;">50%</span></td>
<td id="S3.T2.14.9.3.2" class="ltx_td ltx_align_center"><span id="S3.T2.14.9.3.2.1" class="ltx_text" style="background-color:#E6E6E6;">10.51</span></td>
<td id="S3.T2.14.9.3.3" class="ltx_td ltx_align_center"><span id="S3.T2.14.9.3.3.1" class="ltx_text" style="background-color:#E6E6E6;">9.39</span></td>
<td id="S3.T2.14.9.3.4" class="ltx_td ltx_align_center"><span id="S3.T2.14.9.3.4.1" class="ltx_text" style="background-color:#E6E6E6;">9.40</span></td>
<td id="S3.T2.14.9.3.5" class="ltx_td ltx_align_center"><span id="S3.T2.14.9.3.5.1" class="ltx_text" style="background-color:#E6E6E6;">11/11</span></td>
</tr>
<tr id="S3.T2.14.10.4" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T2.14.10.4.1" class="ltx_td ltx_align_center"><span id="S3.T2.14.10.4.1.1" class="ltx_text" style="background-color:#E6E6E6;">75%</span></td>
<td id="S3.T2.14.10.4.2" class="ltx_td ltx_align_center"><span id="S3.T2.14.10.4.2.1" class="ltx_text" style="background-color:#E6E6E6;">9.74</span></td>
<td id="S3.T2.14.10.4.3" class="ltx_td ltx_align_center"><span id="S3.T2.14.10.4.3.1" class="ltx_text" style="background-color:#E6E6E6;">8.81</span></td>
<td id="S3.T2.14.10.4.4" class="ltx_td ltx_align_center"><span id="S3.T2.14.10.4.4.1" class="ltx_text" style="background-color:#E6E6E6;">8.64</span></td>
<td id="S3.T2.14.10.4.5" class="ltx_td ltx_align_center"><span id="S3.T2.14.10.4.5.1" class="ltx_text" style="background-color:#E6E6E6;">9.5/11</span></td>
</tr>
<tr id="S3.T2.14.11.5" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T2.14.11.5.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.14.11.5.1.1" class="ltx_text" style="background-color:#E6E6E6;">90%</span></td>
<td id="S3.T2.14.11.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.14.11.5.2.1" class="ltx_text" style="background-color:#E6E6E6;">9.53</span></td>
<td id="S3.T2.14.11.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.14.11.5.3.1" class="ltx_text" style="background-color:#E6E6E6;">8.59</span></td>
<td id="S3.T2.14.11.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.14.11.5.4.1" class="ltx_text" style="background-color:#E6E6E6;">8.53</span></td>
<td id="S3.T2.14.11.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.14.11.5.5.1" class="ltx_text" style="background-color:#E6E6E6;">11/12</span></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.T2.19" class="ltx_p ltx_figure_panel ltx_align_center">model trained on full accented set (14Â hours): 8.33% WER</p>
</div>
</div>
</figure>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.6" class="ltx_p">Afterwards, we fine-tuned the ASR model on the full 20 hours of the <span id="S3.SS1.SSS1.p2.6.1" class="ltx_text ltx_font_italic">train-IND</span> subset for 10 more epochs and decoded the <span id="S3.SS1.SSS1.p2.6.2" class="ltx_text ltx_font_italic">test-IND</span> partition. We obtained a WER of 8.33% which will be the lower-bound for the WER in the following TTS augmentation experiments on the Indian English accent. In the TTS augmentation experiments, we considered two ZS-TTS models: the first (<math id="S3.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\mathrm{TTS_{c}}" display="inline"><semantics id="S3.SS1.SSS1.p2.1.m1.1a"><msub id="S3.SS1.SSS1.p2.1.m1.1.1" xref="S3.SS1.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p2.1.m1.1.1.2" xref="S3.SS1.SSS1.p2.1.m1.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.SS1.SSS1.p2.1.m1.1.1.3" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.1.m1.1b"><apply id="S3.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.2">TTS</ci><ci id="S3.SS1.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3">c</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.1.m1.1c">\mathrm{TTS_{c}}</annotation></semantics></math>, TableÂ 2) is a pre-trained checkpoint provided by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> which is trained on the LJ-Speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, VCTK <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, the TTS-Portuguese Corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and part of the M-AILABS dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. The second model (<math id="S3.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.SS1.SSS1.p2.2.m2.1a"><msub id="S3.SS1.SSS1.p2.2.m2.1.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p2.2.m2.1.1.2" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.SS1.SSS1.p2.2.m2.1.1.3" xref="S3.SS1.SSS1.p2.2.m2.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.2.m2.1b"><apply id="S3.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2">TTS</ci><ci id="S3.SS1.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.2.m2.1c">\mathrm{TTS_{I}}</annotation></semantics></math>, TableÂ 2) is obtained from the previous checkpoint by continuing the training for 300 epochs on the three Indian speakers available in the VCTK dataset for a total of approximately 1.5Â hours of speech divided equally across the speakers. To simulate different low resource scenarios, we sampled different fractions of the original <span id="S3.SS1.SSS1.p2.6.3" class="ltx_text ltx_font_italic">train-IND</span> training dataset and augmenting it to the full 20 hours with TTS data generated from both of the aforementioned models. Importantly, the text input for the TTS model is specifically drawn from the original <span id="S3.SS1.SSS1.p2.6.4" class="ltx_text ltx_font_italic">train-IND</span> set post-random sampling. This selection ensures the consistent preservation of textual content across all mixing conditions. This standardization is crucial for the accurate assessment of TTS augmentation and the systematic isolation of textual content, a factor that could potentially impact ASR performance, from the acoustic aspects under consideration. For example, to obtain the results for 25% mixing in TableÂ 2, we randomly selected 25% of the <span id="S3.SS1.SSS1.p2.6.5" class="ltx_text ltx_font_italic">train-IND</span> dataset and augmented it to 20 hours generating synthetic speech with both of the TTS models. Moreover, the synthetic speaker for each TTS utterance is randomly selected among the three available VCTK Indian speakers. Following the data generation process, we proceed to fine-tune the ASR model that was originally trained exclusively on the LibriSpeech 960-hour dataset. This fine-tuning is conducted across all datasets augmented using TTS. Subsequently, we perform decoding on the <span id="S3.SS1.SSS1.p2.6.6" class="ltx_text ltx_font_italic">test-IND</span> subset using each fine-tuned model. The outcomes for each condition are presented in TableÂ 2. Here, we can observe that WERs generated by the ASR models fine-tuned on augmented sets generated by the two TTS models (<math id="S3.SS1.SSS1.p2.3.m3.1" class="ltx_Math" alttext="\mathrm{TTS_{c}}" display="inline"><semantics id="S3.SS1.SSS1.p2.3.m3.1a"><msub id="S3.SS1.SSS1.p2.3.m3.1.1" xref="S3.SS1.SSS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.SSS1.p2.3.m3.1.1.2" xref="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.SS1.SSS1.p2.3.m3.1.1.3" xref="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.3.m3.1b"><apply id="S3.SS1.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.2">TTS</ci><ci id="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.3">c</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.3.m3.1c">\mathrm{TTS_{c}}</annotation></semantics></math> and <math id="S3.SS1.SSS1.p2.4.m4.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.SS1.SSS1.p2.4.m4.1a"><msub id="S3.SS1.SSS1.p2.4.m4.1.1" xref="S3.SS1.SSS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.SSS1.p2.4.m4.1.1.2" xref="S3.SS1.SSS1.p2.4.m4.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.SS1.SSS1.p2.4.m4.1.1.3" xref="S3.SS1.SSS1.p2.4.m4.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.4.m4.1b"><apply id="S3.SS1.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.2">TTS</ci><ci id="S3.SS1.SSS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.4.m4.1c">\mathrm{TTS_{I}}</annotation></semantics></math>) are lower than using only real data (<math id="S3.SS1.SSS1.p2.5.m5.1" class="ltx_Math" alttext="\mathrm{R}" display="inline"><semantics id="S3.SS1.SSS1.p2.5.m5.1a"><mi mathvariant="normal" id="S3.SS1.SSS1.p2.5.m5.1.1" xref="S3.SS1.SSS1.p2.5.m5.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.5.m5.1b"><ci id="S3.SS1.SSS1.p2.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.5.m5.1c">\mathrm{R}</annotation></semantics></math>). However, the model fine-tuned on the Indian speakers from VCTK (<math id="S3.SS1.SSS1.p2.6.m6.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.SS1.SSS1.p2.6.m6.1a"><msub id="S3.SS1.SSS1.p2.6.m6.1.1" xref="S3.SS1.SSS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.SSS1.p2.6.m6.1.1.2" xref="S3.SS1.SSS1.p2.6.m6.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.SS1.SSS1.p2.6.m6.1.1.3" xref="S3.SS1.SSS1.p2.6.m6.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.6.m6.1b"><apply id="S3.SS1.SSS1.p2.6.m6.1.1.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1.2">TTS</ci><ci id="S3.SS1.SSS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.6.m6.1c">\mathrm{TTS_{I}}</annotation></semantics></math>) provides a higher WERR when compared with the publicly available checkpoint from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>ASR fine-tuning on TTS data</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">Furthermore, we fine-tuned the ASR model trained on the LibriSpeech 960-hour, exclusively on TTS-generated data. The results in TableÂ 3 show that, in this condition, only the TTS model tuned on the three Indians speakers (<math id="S3.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.SS1.SSS2.p1.1.m1.1a"><msub id="S3.SS1.SSS2.p1.1.m1.1.1" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p1.1.m1.1.1.2" xref="S3.SS1.SSS2.p1.1.m1.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.SS1.SSS2.p1.1.m1.1.1.3" xref="S3.SS1.SSS2.p1.1.m1.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.1b"><apply id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1.2">TTS</ci><ci id="S3.SS1.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.1c">\mathrm{TTS_{I}}</annotation></semantics></math>) is able to provide a lower WER with respect to the original ASR model trained on Librispeech 960 (Dark grey rows, TableÂ 3). However, this phenomenon is evident only when employing limited quantities of TTS data. We argue that this occurs because the ASR model exhibits overfitting tendencies when exposed to an excessive volume of TTS-generated data, resulting in a lapse of its ability to retain the speech characteristics inherent in real-world speech corpora.</p>
</div>
<figure id="S3.T3" class="ltx_table">

<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>ASR decoding results for the <span id="S3.T3.13.1" class="ltx_text ltx_font_italic">test-IND</span> set with ASR model fine-tuned on TTS generated data. <math id="S3.T3.5.m1.1" class="ltx_Math" alttext="\mathrm{TTS_{c}}" display="inline"><semantics id="S3.T3.5.m1.1b"><msub id="S3.T3.5.m1.1.1" xref="S3.T3.5.m1.1.1.cmml"><mi id="S3.T3.5.m1.1.1.2" xref="S3.T3.5.m1.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T3.5.m1.1.1.3" xref="S3.T3.5.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T3.5.m1.1c"><apply id="S3.T3.5.m1.1.1.cmml" xref="S3.T3.5.m1.1.1"><csymbol cd="ambiguous" id="S3.T3.5.m1.1.1.1.cmml" xref="S3.T3.5.m1.1.1">subscript</csymbol><ci id="S3.T3.5.m1.1.1.2.cmml" xref="S3.T3.5.m1.1.1.2">TTS</ci><ci id="S3.T3.5.m1.1.1.3.cmml" xref="S3.T3.5.m1.1.1.3">c</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.m1.1d">\mathrm{TTS_{c}}</annotation></semantics></math>: model trained synthetic data generated from <math id="S3.T3.6.m2.1" class="ltx_Math" alttext="\mathrm{TTS_{c}}" display="inline"><semantics id="S3.T3.6.m2.1b"><msub id="S3.T3.6.m2.1.1" xref="S3.T3.6.m2.1.1.cmml"><mi id="S3.T3.6.m2.1.1.2" xref="S3.T3.6.m2.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T3.6.m2.1.1.3" xref="S3.T3.6.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T3.6.m2.1c"><apply id="S3.T3.6.m2.1.1.cmml" xref="S3.T3.6.m2.1.1"><csymbol cd="ambiguous" id="S3.T3.6.m2.1.1.1.cmml" xref="S3.T3.6.m2.1.1">subscript</csymbol><ci id="S3.T3.6.m2.1.1.2.cmml" xref="S3.T3.6.m2.1.1.2">TTS</ci><ci id="S3.T3.6.m2.1.1.3.cmml" xref="S3.T3.6.m2.1.1.3">c</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.m2.1d">\mathrm{TTS_{c}}</annotation></semantics></math>. <math id="S3.T3.7.m3.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.T3.7.m3.1b"><msub id="S3.T3.7.m3.1.1" xref="S3.T3.7.m3.1.1.cmml"><mi id="S3.T3.7.m3.1.1.2" xref="S3.T3.7.m3.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T3.7.m3.1.1.3" xref="S3.T3.7.m3.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T3.7.m3.1c"><apply id="S3.T3.7.m3.1.1.cmml" xref="S3.T3.7.m3.1.1"><csymbol cd="ambiguous" id="S3.T3.7.m3.1.1.1.cmml" xref="S3.T3.7.m3.1.1">subscript</csymbol><ci id="S3.T3.7.m3.1.1.2.cmml" xref="S3.T3.7.m3.1.1.2">TTS</ci><ci id="S3.T3.7.m3.1.1.3.cmml" xref="S3.T3.7.m3.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.m3.1d">\mathrm{TTS_{I}}</annotation></semantics></math>: model trained synthetic data generated from <math id="S3.T3.8.m4.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.T3.8.m4.1b"><msub id="S3.T3.8.m4.1.1" xref="S3.T3.8.m4.1.1.cmml"><mi id="S3.T3.8.m4.1.1.2" xref="S3.T3.8.m4.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T3.8.m4.1.1.3" xref="S3.T3.8.m4.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T3.8.m4.1c"><apply id="S3.T3.8.m4.1.1.cmml" xref="S3.T3.8.m4.1.1"><csymbol cd="ambiguous" id="S3.T3.8.m4.1.1.1.cmml" xref="S3.T3.8.m4.1.1">subscript</csymbol><ci id="S3.T3.8.m4.1.1.2.cmml" xref="S3.T3.8.m4.1.1.2">TTS</ci><ci id="S3.T3.8.m4.1.1.3.cmml" xref="S3.T3.8.m4.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.m4.1d">\mathrm{TTS_{I}}</annotation></semantics></math>. The last column refers to the WERR achieved by each augmentation strategy with respect to the model trained only on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S3.T3.11" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.9.1" class="ltx_tr">
<th id="S3.T3.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T3.9.1.2.1" class="ltx_text ltx_font_bold">tts data</span></th>
<th id="S3.T3.9.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S3.T3.9.1.3.1" class="ltx_text ltx_font_bold">WER[%]</span></th>
<th id="S3.T3.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T3.9.1.1.1" class="ltx_text ltx_font_bold">WERR[%]</span>  <svg id="S3.T3.9.1.1.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.11.3" class="ltx_tr">
<td id="S3.T3.11.3.3" class="ltx_td ltx_border_t"></td>
<th id="S3.T3.10.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S3.T3.10.2.1.m1.1" class="ltx_Math" alttext="\mathrm{TTS_{c}}" display="inline"><semantics id="S3.T3.10.2.1.m1.1a"><msub id="S3.T3.10.2.1.m1.1.1" xref="S3.T3.10.2.1.m1.1.1.cmml"><mi id="S3.T3.10.2.1.m1.1.1.2" xref="S3.T3.10.2.1.m1.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T3.10.2.1.m1.1.1.3" xref="S3.T3.10.2.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T3.10.2.1.m1.1b"><apply id="S3.T3.10.2.1.m1.1.1.cmml" xref="S3.T3.10.2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T3.10.2.1.m1.1.1.1.cmml" xref="S3.T3.10.2.1.m1.1.1">subscript</csymbol><ci id="S3.T3.10.2.1.m1.1.1.2.cmml" xref="S3.T3.10.2.1.m1.1.1.2">TTS</ci><ci id="S3.T3.10.2.1.m1.1.1.3.cmml" xref="S3.T3.10.2.1.m1.1.1.3">c</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.2.1.m1.1c">\mathrm{TTS_{c}}</annotation></semantics></math></th>
<th id="S3.T3.11.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S3.T3.11.3.2.m1.1" class="ltx_Math" alttext="\mathrm{TTS_{I}}" display="inline"><semantics id="S3.T3.11.3.2.m1.1a"><msub id="S3.T3.11.3.2.m1.1.1" xref="S3.T3.11.3.2.m1.1.1.cmml"><mi id="S3.T3.11.3.2.m1.1.1.2" xref="S3.T3.11.3.2.m1.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.T3.11.3.2.m1.1.1.3" xref="S3.T3.11.3.2.m1.1.1.3.cmml">I</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T3.11.3.2.m1.1b"><apply id="S3.T3.11.3.2.m1.1.1.cmml" xref="S3.T3.11.3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.T3.11.3.2.m1.1.1.1.cmml" xref="S3.T3.11.3.2.m1.1.1">subscript</csymbol><ci id="S3.T3.11.3.2.m1.1.1.2.cmml" xref="S3.T3.11.3.2.m1.1.1.2">TTS</ci><ci id="S3.T3.11.3.2.m1.1.1.3.cmml" xref="S3.T3.11.3.2.m1.1.1.3">I</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.3.2.m1.1c">\mathrm{TTS_{I}}</annotation></semantics></math></th>
<td id="S3.T3.11.3.4" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S3.T3.11.4.1" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T3.11.4.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.11.4.1.1.1" class="ltx_text" style="background-color:#BFBFBF;">1.4 hours</span></td>
<td id="S3.T3.11.4.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.11.4.1.2.1" class="ltx_text" style="background-color:#BFBFBF;">23.67</span></td>
<td id="S3.T3.11.4.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.11.4.1.3.1" class="ltx_text" style="background-color:#BFBFBF;">21.13</span></td>
<td id="S3.T3.11.4.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.11.4.1.4.1" class="ltx_text" style="background-color:#BFBFBF;">-6.4/5.0</span></td>
</tr>
<tr id="S3.T3.11.5.2" class="ltx_tr" style="background-color:#BFBFBF;">
<td id="S3.T3.11.5.2.1" class="ltx_td ltx_align_center"><span id="S3.T3.11.5.2.1.1" class="ltx_text" style="background-color:#BFBFBF;">3.5 hours</span></td>
<td id="S3.T3.11.5.2.2" class="ltx_td ltx_align_center"><span id="S3.T3.11.5.2.2.1" class="ltx_text" style="background-color:#BFBFBF;">25.91</span></td>
<td id="S3.T3.11.5.2.3" class="ltx_td ltx_align_center"><span id="S3.T3.11.5.2.3.1" class="ltx_text" style="background-color:#BFBFBF;">21.90</span></td>
<td id="S3.T3.11.5.2.4" class="ltx_td ltx_align_center"><span id="S3.T3.11.5.2.4.1" class="ltx_text" style="background-color:#BFBFBF;">-16.5/1.5</span></td>
</tr>
<tr id="S3.T3.11.6.3" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T3.11.6.3.1" class="ltx_td ltx_align_center"><span id="S3.T3.11.6.3.1.1" class="ltx_text" style="background-color:#E6E6E6;">7 hours</span></td>
<td id="S3.T3.11.6.3.2" class="ltx_td ltx_align_center"><span id="S3.T3.11.6.3.2.1" class="ltx_text" style="background-color:#E6E6E6;">28.44</span></td>
<td id="S3.T3.11.6.3.3" class="ltx_td ltx_align_center"><span id="S3.T3.11.6.3.3.1" class="ltx_text" style="background-color:#E6E6E6;">22.5</span></td>
<td id="S3.T3.11.6.3.4" class="ltx_td ltx_align_center"><span id="S3.T3.11.6.3.4.1" class="ltx_text" style="background-color:#E6E6E6;">-27.9/-1.2</span></td>
</tr>
<tr id="S3.T3.11.7.4" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T3.11.7.4.1" class="ltx_td ltx_align_center"><span id="S3.T3.11.7.4.1.1" class="ltx_text" style="background-color:#E6E6E6;">10.5 hours</span></td>
<td id="S3.T3.11.7.4.2" class="ltx_td ltx_align_center"><span id="S3.T3.11.7.4.2.1" class="ltx_text" style="background-color:#E6E6E6;">30.18</span></td>
<td id="S3.T3.11.7.4.3" class="ltx_td ltx_align_center"><span id="S3.T3.11.7.4.3.1" class="ltx_text" style="background-color:#E6E6E6;">23.38</span></td>
<td id="S3.T3.11.7.4.4" class="ltx_td ltx_align_center"><span id="S3.T3.11.7.4.4.1" class="ltx_text" style="background-color:#E6E6E6;">-35.7/-5.1</span></td>
</tr>
<tr id="S3.T3.11.8.5" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T3.11.8.5.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.11.8.5.1.1" class="ltx_text" style="background-color:#E6E6E6;">12.6 hours</span></td>
<td id="S3.T3.11.8.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.11.8.5.2.1" class="ltx_text" style="background-color:#E6E6E6;">31.47</span></td>
<td id="S3.T3.11.8.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.11.8.5.3.1" class="ltx_text" style="background-color:#E6E6E6;">24.20</span></td>
<td id="S3.T3.11.8.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.11.8.5.4.1" class="ltx_text" style="background-color:#E6E6E6;">-41.5/-8.8</span></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.T3.14" class="ltx_p ltx_figure_panel ltx_align_center">model trained on real data only: 22.24% WER</p>
</div>
</div>
</figure>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Multiple accents</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.7" class="ltx_p">In this Section, we considered multiple accents without limiting to the Indian accented English case. In this context, we used the Interspeech 2020 accented English recognition challenge dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> described in SectionÂ 3. For each accented partition, we selected the cleaner recordings according to the metadata annotations provided with the audio recording. However, this initial selection process resulted in imbalanced subset dimensions. To rectify this imbalance, we uniformly reduced the length of all partitions to match the duration of the shortest accented subset, amounting to approximately 11 hours, accomplished through a random sampling procedure. 
<br class="ltx_break">Initially, our baseline results were established using the ASR model (referred to as the <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathit{C}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathit{C}</annotation></semantics></math> model) trained on the complete 960-hour Librispeech dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. First, we decoded each test accented subset with model <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathit{C}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathit{C}</annotation></semantics></math> (results shown in TableÂ 1, first row). Second, we fine-tuned model <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\mathit{C}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\mathit{C}</annotation></semantics></math> on each accented training subset separately (<math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\mathit{FT}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">ğ¹ğ‘‡</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğ¹ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\mathit{FT}</annotation></semantics></math>, TableÂ 1, second row). Finally, we fine-tuned the model <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="\mathit{C}" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">\mathit{C}</annotation></semantics></math> by mixing all the training accented subsets together (<math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="\mathit{FM}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">ğ¹ğ‘€</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">ğ¹ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\mathit{FM}</annotation></semantics></math>, TableÂ 1, third row). Decoding results for each accented test subset are reported in TableÂ 1 (upper section, light grey rows). To train the TTS model to reproduce different accented voices, we used the same train subsets of the Interspeech 2020 accented English recognition challenge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> described earlier. We started the training from the publicly available checkpoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and continued for 300 further epochs. Furthermore, while training, the TTS model was guided to learn a different language embedding for each accent. For doing this, we modified the language embedding layers to fit the new accents (treated as new languages) and we randomly initialized the previously learnt weights for all language (now accent) embedding layers. 
<br class="ltx_break">Following the results obtained for a single accent (TableÂ 2, second row, best WERR), we mixed 75% TTS-generated data with 25% real data for all the multi-accent experiments (TableÂ 1, lower section, dark grey rows). We repeated analogous ASR experiments as for the non-augmented sets. Results are presented in TableÂ 3 (dark grey rows). In this case, it is seen that the TTS trained on multiple accented sets combined with accent embeddings does not improve ASR performance when used for data augmentation. This might be due to the TTS's inability to model all different pronunciation through accent embeddings or to the lower data quality of the Interspeech 2020 corpus. To test the latter hypothesis, we fine tuned <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="\mathrm{TTS_{c}}" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><msub id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2">TTS</ci><ci id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3">c</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">\mathrm{TTS_{c}}</annotation></semantics></math> on three Indian speakers selected from the Interspeech 2020 dataset.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>WER results of the <span id="S3.T4.9.1" class="ltx_text ltx_font_italic">test-IND</span> set. R-<math id="S3.T4.2.m1.1" class="ltx_Math" alttext="\mathrm{TTS_{INI}}" display="inline"><semantics id="S3.T4.2.m1.1b"><msub id="S3.T4.2.m1.1.1" xref="S3.T4.2.m1.1.1.cmml"><mi id="S3.T4.2.m1.1.1.2" xref="S3.T4.2.m1.1.1.2.cmml">TTS</mi><mi id="S3.T4.2.m1.1.1.3" xref="S3.T4.2.m1.1.1.3.cmml">INI</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T4.2.m1.1c"><apply id="S3.T4.2.m1.1.1.cmml" xref="S3.T4.2.m1.1.1"><csymbol cd="ambiguous" id="S3.T4.2.m1.1.1.1.cmml" xref="S3.T4.2.m1.1.1">subscript</csymbol><ci id="S3.T4.2.m1.1.1.2.cmml" xref="S3.T4.2.m1.1.1.2">TTS</ci><ci id="S3.T4.2.m1.1.1.3.cmml" xref="S3.T4.2.m1.1.1.3">INI</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.2.m1.1d">\mathrm{TTS_{INI}}</annotation></semantics></math>: ASR model adapted on a mix of real and synthetic speech obtained from the TTS model fine-tuned on a small subset (3 speakers) of the <span id="S3.T4.10.2" class="ltx_text ltx_font_italic">train-IND</span> subset.</figcaption>
<table id="S3.T4.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.3.1" class="ltx_tr">
<th id="S3.T4.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S3.T4.3.1.2.1" class="ltx_text ltx_font_bold">real data</span></th>
<th id="S3.T4.3.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" colspan="2">
<span id="S3.T4.3.1.1.1" class="ltx_text ltx_font_bold">WER[%]</span> Â Â   <svg id="S3.T4.3.1.1.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>
</th>
</tr>
<tr id="S3.T4.6.4" class="ltx_tr">
<th id="S3.T4.6.4.4" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S3.T4.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S3.T4.4.2.1.m1.1" class="ltx_Math" alttext="\mathrm{R}" display="inline"><semantics id="S3.T4.4.2.1.m1.1a"><mi mathvariant="normal" id="S3.T4.4.2.1.m1.1.1" xref="S3.T4.4.2.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.T4.4.2.1.m1.1b"><ci id="S3.T4.4.2.1.m1.1.1.cmml" xref="S3.T4.4.2.1.m1.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.4.2.1.m1.1c">\mathrm{R}</annotation></semantics></math></th>
<th id="S3.T4.6.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S3.T4.5.3.2.m1.1" class="ltx_Math" alttext="\mathrm{R}" display="inline"><semantics id="S3.T4.5.3.2.m1.1a"><mi mathvariant="normal" id="S3.T4.5.3.2.m1.1.1" xref="S3.T4.5.3.2.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.T4.5.3.2.m1.1b"><ci id="S3.T4.5.3.2.m1.1.1.cmml" xref="S3.T4.5.3.2.m1.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.5.3.2.m1.1c">\mathrm{R}</annotation></semantics></math>-<math id="S3.T4.6.4.3.m2.1" class="ltx_Math" alttext="\mathrm{TTS_{INI}}" display="inline"><semantics id="S3.T4.6.4.3.m2.1a"><msub id="S3.T4.6.4.3.m2.1.1" xref="S3.T4.6.4.3.m2.1.1.cmml"><mi id="S3.T4.6.4.3.m2.1.1.2" xref="S3.T4.6.4.3.m2.1.1.2.cmml">TTS</mi><mi id="S3.T4.6.4.3.m2.1.1.3" xref="S3.T4.6.4.3.m2.1.1.3.cmml">INI</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T4.6.4.3.m2.1b"><apply id="S3.T4.6.4.3.m2.1.1.cmml" xref="S3.T4.6.4.3.m2.1.1"><csymbol cd="ambiguous" id="S3.T4.6.4.3.m2.1.1.1.cmml" xref="S3.T4.6.4.3.m2.1.1">subscript</csymbol><ci id="S3.T4.6.4.3.m2.1.1.2.cmml" xref="S3.T4.6.4.3.m2.1.1.2">TTS</ci><ci id="S3.T4.6.4.3.m2.1.1.3.cmml" xref="S3.T4.6.4.3.m2.1.1.3">INI</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.6.4.3.m2.1c">\mathrm{TTS_{INI}}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.6.5.1" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S3.T4.6.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="S3.T4.6.5.1.1.1" class="ltx_text" style="background-color:#E6E6E6;">10%</span></th>
<td id="S3.T4.6.5.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.6.5.1.2.1" class="ltx_text" style="background-color:#E6E6E6;">13.29</span></td>
<td id="S3.T4.6.5.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T4.6.5.1.3.1" class="ltx_text" style="background-color:#E6E6E6;">11.68</span></td>
</tr>
<tr id="S3.T4.6.6.2" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S3.T4.6.6.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S3.T4.6.6.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">25%</span></th>
<td id="S3.T4.6.6.2.2" class="ltx_td ltx_align_center"><span id="S3.T4.6.6.2.2.1" class="ltx_text" style="background-color:#E6E6E6;">11.80</span></td>
<td id="S3.T4.6.6.2.3" class="ltx_td ltx_align_center"><span id="S3.T4.6.6.2.3.1" class="ltx_text" style="background-color:#E6E6E6;">10.31</span></td>
</tr>
<tr id="S3.T4.6.7.3" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S3.T4.6.7.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S3.T4.6.7.3.1.1" class="ltx_text" style="background-color:#E6E6E6;">50%</span></th>
<td id="S3.T4.6.7.3.2" class="ltx_td ltx_align_center"><span id="S3.T4.6.7.3.2.1" class="ltx_text" style="background-color:#E6E6E6;">10.51</span></td>
<td id="S3.T4.6.7.3.3" class="ltx_td ltx_align_center"><span id="S3.T4.6.7.3.3.1" class="ltx_text" style="background-color:#E6E6E6;">9.55</span></td>
</tr>
<tr id="S3.T4.6.8.4" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S3.T4.6.8.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S3.T4.6.8.4.1.1" class="ltx_text" style="background-color:#E6E6E6;">75%</span></th>
<td id="S3.T4.6.8.4.2" class="ltx_td ltx_align_center"><span id="S3.T4.6.8.4.2.1" class="ltx_text" style="background-color:#E6E6E6;">9.74</span></td>
<td id="S3.T4.6.8.4.3" class="ltx_td ltx_align_center"><span id="S3.T4.6.8.4.3.1" class="ltx_text" style="background-color:#E6E6E6;">8.95</span></td>
</tr>
<tr id="S3.T4.6.9.5" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S3.T4.6.9.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb"><span id="S3.T4.6.9.5.1.1" class="ltx_text" style="background-color:#E6E6E6;">90%</span></th>
<td id="S3.T4.6.9.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T4.6.9.5.2.1" class="ltx_text" style="background-color:#E6E6E6;">9.53</span></td>
<td id="S3.T4.6.9.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T4.6.9.5.3.1" class="ltx_text" style="background-color:#E6E6E6;">8.86</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.2" class="ltx_p">The results for these experiments are given in TableÂ 4 and show that this model produced augmentation results on par or worse than the pre-trained model (TableÂ 2, <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathrm{R}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi mathvariant="normal" id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathrm{R}</annotation></semantics></math>-<math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathrm{TTS_{C}}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">TTS</mi><mi mathvariant="normal" id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">TTS</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">C</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\mathrm{TTS_{C}}</annotation></semantics></math>) from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Because of this reason, we believe that, when compared with the VCTK speakers, the lower data quality of the Interspeech 2020 corpus severely impacts the quality of the synthetic accented speech used for augmentation.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Combine TTS with other audio augmentations</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Finally, we tested the effects of common speech augmentation techniques namely room impulse response (RIR), noise, speed and SpecAugment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> in comparison and in combination with TTS augmentation. During the training process, for each batch, we independently apply augmentations to all utterances. Subsequently, we concatenate the original and augmented samples to form the new batch. For RIR and noise augmentation, we used the OpenRIR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> dataset which contains both real and simulated RIRs and noises.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>WER results of the <span id="S3.T5.12.1" class="ltx_text ltx_font_italic">test-IND</span> set. <math id="S3.T5.3.m1.1" class="ltx_Math" alttext="\mathrm{R_{aug}}" display="inline"><semantics id="S3.T5.3.m1.1b"><msub id="S3.T5.3.m1.1.1" xref="S3.T5.3.m1.1.1.cmml"><mi mathvariant="normal" id="S3.T5.3.m1.1.1.2" xref="S3.T5.3.m1.1.1.2.cmml">R</mi><mi id="S3.T5.3.m1.1.1.3" xref="S3.T5.3.m1.1.1.3.cmml">aug</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T5.3.m1.1c"><apply id="S3.T5.3.m1.1.1.cmml" xref="S3.T5.3.m1.1.1"><csymbol cd="ambiguous" id="S3.T5.3.m1.1.1.1.cmml" xref="S3.T5.3.m1.1.1">subscript</csymbol><ci id="S3.T5.3.m1.1.1.2.cmml" xref="S3.T5.3.m1.1.1.2">R</ci><ci id="S3.T5.3.m1.1.1.3.cmml" xref="S3.T5.3.m1.1.1.3">aug</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.3.m1.1d">\mathrm{R_{aug}}</annotation></semantics></math>: ASR model fine-tuned on real data augmented with the techniques specified in SectionÂ 3.3. <math id="S3.T5.4.m2.1" class="ltx_Math" alttext="\mathrm{R}-\mathrm{TTS_{INI}}" display="inline"><semantics id="S3.T5.4.m2.1b"><mrow id="S3.T5.4.m2.1.1" xref="S3.T5.4.m2.1.1.cmml"><mi mathvariant="normal" id="S3.T5.4.m2.1.1.2" xref="S3.T5.4.m2.1.1.2.cmml">R</mi><mo id="S3.T5.4.m2.1.1.1" xref="S3.T5.4.m2.1.1.1.cmml">âˆ’</mo><msub id="S3.T5.4.m2.1.1.3" xref="S3.T5.4.m2.1.1.3.cmml"><mi id="S3.T5.4.m2.1.1.3.2" xref="S3.T5.4.m2.1.1.3.2.cmml">TTS</mi><mi id="S3.T5.4.m2.1.1.3.3" xref="S3.T5.4.m2.1.1.3.3.cmml">INI</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T5.4.m2.1c"><apply id="S3.T5.4.m2.1.1.cmml" xref="S3.T5.4.m2.1.1"><minus id="S3.T5.4.m2.1.1.1.cmml" xref="S3.T5.4.m2.1.1.1"></minus><ci id="S3.T5.4.m2.1.1.2.cmml" xref="S3.T5.4.m2.1.1.2">R</ci><apply id="S3.T5.4.m2.1.1.3.cmml" xref="S3.T5.4.m2.1.1.3"><csymbol cd="ambiguous" id="S3.T5.4.m2.1.1.3.1.cmml" xref="S3.T5.4.m2.1.1.3">subscript</csymbol><ci id="S3.T5.4.m2.1.1.3.2.cmml" xref="S3.T5.4.m2.1.1.3.2">TTS</ci><ci id="S3.T5.4.m2.1.1.3.3.cmml" xref="S3.T5.4.m2.1.1.3.3">INI</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.4.m2.1d">\mathrm{R}-\mathrm{TTS_{INI}}</annotation></semantics></math>: ASR model fine-tuned on a mix of synthetic TTS speech obtained from the model adapted to a subset (3 speakers) of the <span id="S3.T5.13.2" class="ltx_text ltx_font_italic">train-IND</span> subset.</figcaption>
<table id="S3.T5.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T5.5.1" class="ltx_tr">
<th id="S3.T5.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T5.5.1.2.1" class="ltx_text ltx_font_bold">real</span></th>
<th id="S3.T5.5.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" colspan="3">
<span id="S3.T5.5.1.1.1" class="ltx_text ltx_font_bold">WER[%]</span> Â Â   <svg id="S3.T5.5.1.1.pic1" class="ltx_picture" height="9.22" overflow="visible" version="1.1" width="9.22"><g transform="translate(0,9.22) matrix(1 0 0 -1 0 0)"></g></svg>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T5.9.5" class="ltx_tr">
<td id="S3.T5.9.5.5" class="ltx_td ltx_border_t"></td>
<th id="S3.T5.6.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S3.T5.6.2.1.m1.1" class="ltx_Math" alttext="\mathrm{R}" display="inline"><semantics id="S3.T5.6.2.1.m1.1a"><mi mathvariant="normal" id="S3.T5.6.2.1.m1.1.1" xref="S3.T5.6.2.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S3.T5.6.2.1.m1.1b"><ci id="S3.T5.6.2.1.m1.1.1.cmml" xref="S3.T5.6.2.1.m1.1.1">R</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.6.2.1.m1.1c">\mathrm{R}</annotation></semantics></math></th>
<th id="S3.T5.7.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S3.T5.7.3.2.m1.1" class="ltx_Math" alttext="\mathrm{R}_{aug}" display="inline"><semantics id="S3.T5.7.3.2.m1.1a"><msub id="S3.T5.7.3.2.m1.1.1" xref="S3.T5.7.3.2.m1.1.1.cmml"><mi mathvariant="normal" id="S3.T5.7.3.2.m1.1.1.2" xref="S3.T5.7.3.2.m1.1.1.2.cmml">R</mi><mrow id="S3.T5.7.3.2.m1.1.1.3" xref="S3.T5.7.3.2.m1.1.1.3.cmml"><mi id="S3.T5.7.3.2.m1.1.1.3.2" xref="S3.T5.7.3.2.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T5.7.3.2.m1.1.1.3.1" xref="S3.T5.7.3.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.T5.7.3.2.m1.1.1.3.3" xref="S3.T5.7.3.2.m1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T5.7.3.2.m1.1.1.3.1a" xref="S3.T5.7.3.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.T5.7.3.2.m1.1.1.3.4" xref="S3.T5.7.3.2.m1.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T5.7.3.2.m1.1b"><apply id="S3.T5.7.3.2.m1.1.1.cmml" xref="S3.T5.7.3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.T5.7.3.2.m1.1.1.1.cmml" xref="S3.T5.7.3.2.m1.1.1">subscript</csymbol><ci id="S3.T5.7.3.2.m1.1.1.2.cmml" xref="S3.T5.7.3.2.m1.1.1.2">R</ci><apply id="S3.T5.7.3.2.m1.1.1.3.cmml" xref="S3.T5.7.3.2.m1.1.1.3"><times id="S3.T5.7.3.2.m1.1.1.3.1.cmml" xref="S3.T5.7.3.2.m1.1.1.3.1"></times><ci id="S3.T5.7.3.2.m1.1.1.3.2.cmml" xref="S3.T5.7.3.2.m1.1.1.3.2">ğ‘</ci><ci id="S3.T5.7.3.2.m1.1.1.3.3.cmml" xref="S3.T5.7.3.2.m1.1.1.3.3">ğ‘¢</ci><ci id="S3.T5.7.3.2.m1.1.1.3.4.cmml" xref="S3.T5.7.3.2.m1.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.7.3.2.m1.1c">\mathrm{R}_{aug}</annotation></semantics></math></th>
<th id="S3.T5.9.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S3.T5.8.4.3.m1.1" class="ltx_Math" alttext="\mathrm{R}_{aug}" display="inline"><semantics id="S3.T5.8.4.3.m1.1a"><msub id="S3.T5.8.4.3.m1.1.1" xref="S3.T5.8.4.3.m1.1.1.cmml"><mi mathvariant="normal" id="S3.T5.8.4.3.m1.1.1.2" xref="S3.T5.8.4.3.m1.1.1.2.cmml">R</mi><mrow id="S3.T5.8.4.3.m1.1.1.3" xref="S3.T5.8.4.3.m1.1.1.3.cmml"><mi id="S3.T5.8.4.3.m1.1.1.3.2" xref="S3.T5.8.4.3.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T5.8.4.3.m1.1.1.3.1" xref="S3.T5.8.4.3.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.T5.8.4.3.m1.1.1.3.3" xref="S3.T5.8.4.3.m1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.T5.8.4.3.m1.1.1.3.1a" xref="S3.T5.8.4.3.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.T5.8.4.3.m1.1.1.3.4" xref="S3.T5.8.4.3.m1.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T5.8.4.3.m1.1b"><apply id="S3.T5.8.4.3.m1.1.1.cmml" xref="S3.T5.8.4.3.m1.1.1"><csymbol cd="ambiguous" id="S3.T5.8.4.3.m1.1.1.1.cmml" xref="S3.T5.8.4.3.m1.1.1">subscript</csymbol><ci id="S3.T5.8.4.3.m1.1.1.2.cmml" xref="S3.T5.8.4.3.m1.1.1.2">R</ci><apply id="S3.T5.8.4.3.m1.1.1.3.cmml" xref="S3.T5.8.4.3.m1.1.1.3"><times id="S3.T5.8.4.3.m1.1.1.3.1.cmml" xref="S3.T5.8.4.3.m1.1.1.3.1"></times><ci id="S3.T5.8.4.3.m1.1.1.3.2.cmml" xref="S3.T5.8.4.3.m1.1.1.3.2">ğ‘</ci><ci id="S3.T5.8.4.3.m1.1.1.3.3.cmml" xref="S3.T5.8.4.3.m1.1.1.3.3">ğ‘¢</ci><ci id="S3.T5.8.4.3.m1.1.1.3.4.cmml" xref="S3.T5.8.4.3.m1.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.8.4.3.m1.1c">\mathrm{R}_{aug}</annotation></semantics></math>-<math id="S3.T5.9.5.4.m2.1" class="ltx_Math" alttext="\mathrm{TTS_{INI}}" display="inline"><semantics id="S3.T5.9.5.4.m2.1a"><msub id="S3.T5.9.5.4.m2.1.1" xref="S3.T5.9.5.4.m2.1.1.cmml"><mi id="S3.T5.9.5.4.m2.1.1.2" xref="S3.T5.9.5.4.m2.1.1.2.cmml">TTS</mi><mi id="S3.T5.9.5.4.m2.1.1.3" xref="S3.T5.9.5.4.m2.1.1.3.cmml">INI</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T5.9.5.4.m2.1b"><apply id="S3.T5.9.5.4.m2.1.1.cmml" xref="S3.T5.9.5.4.m2.1.1"><csymbol cd="ambiguous" id="S3.T5.9.5.4.m2.1.1.1.cmml" xref="S3.T5.9.5.4.m2.1.1">subscript</csymbol><ci id="S3.T5.9.5.4.m2.1.1.2.cmml" xref="S3.T5.9.5.4.m2.1.1.2">TTS</ci><ci id="S3.T5.9.5.4.m2.1.1.3.cmml" xref="S3.T5.9.5.4.m2.1.1.3">INI</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.9.5.4.m2.1c">\mathrm{TTS_{INI}}</annotation></semantics></math>
</th>
</tr>
<tr id="S3.T5.9.6.1" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T5.9.6.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T5.9.6.1.1.1" class="ltx_text" style="background-color:#E6E6E6;">10%</span></td>
<td id="S3.T5.9.6.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T5.9.6.1.2.1" class="ltx_text" style="background-color:#E6E6E6;">13.29</span></td>
<td id="S3.T5.9.6.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T5.9.6.1.3.1" class="ltx_text" style="background-color:#E6E6E6;">13.52</span></td>
<td id="S3.T5.9.6.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T5.9.6.1.4.1" class="ltx_text" style="background-color:#E6E6E6;">11.03</span></td>
</tr>
<tr id="S3.T5.9.7.2" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T5.9.7.2.1" class="ltx_td ltx_align_center"><span id="S3.T5.9.7.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">25%</span></td>
<td id="S3.T5.9.7.2.2" class="ltx_td ltx_align_center"><span id="S3.T5.9.7.2.2.1" class="ltx_text" style="background-color:#E6E6E6;">11.80</span></td>
<td id="S3.T5.9.7.2.3" class="ltx_td ltx_align_center"><span id="S3.T5.9.7.2.3.1" class="ltx_text" style="background-color:#E6E6E6;">11.90</span></td>
<td id="S3.T5.9.7.2.4" class="ltx_td ltx_align_center"><span id="S3.T5.9.7.2.4.1" class="ltx_text" style="background-color:#E6E6E6;">10.08</span></td>
</tr>
<tr id="S3.T5.9.8.3" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T5.9.8.3.1" class="ltx_td ltx_align_center"><span id="S3.T5.9.8.3.1.1" class="ltx_text" style="background-color:#E6E6E6;">50%</span></td>
<td id="S3.T5.9.8.3.2" class="ltx_td ltx_align_center"><span id="S3.T5.9.8.3.2.1" class="ltx_text" style="background-color:#E6E6E6;">10.51</span></td>
<td id="S3.T5.9.8.3.3" class="ltx_td ltx_align_center"><span id="S3.T5.9.8.3.3.1" class="ltx_text" style="background-color:#E6E6E6;">10.08</span></td>
<td id="S3.T5.9.8.3.4" class="ltx_td ltx_align_center"><span id="S3.T5.9.8.3.4.1" class="ltx_text" style="background-color:#E6E6E6;">9.66</span></td>
</tr>
<tr id="S3.T5.9.9.4" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T5.9.9.4.1" class="ltx_td ltx_align_center"><span id="S3.T5.9.9.4.1.1" class="ltx_text" style="background-color:#E6E6E6;">75%</span></td>
<td id="S3.T5.9.9.4.2" class="ltx_td ltx_align_center"><span id="S3.T5.9.9.4.2.1" class="ltx_text" style="background-color:#E6E6E6;">9.74</span></td>
<td id="S3.T5.9.9.4.3" class="ltx_td ltx_align_center"><span id="S3.T5.9.9.4.3.1" class="ltx_text" style="background-color:#E6E6E6;">9.33</span></td>
<td id="S3.T5.9.9.4.4" class="ltx_td ltx_align_center"><span id="S3.T5.9.9.4.4.1" class="ltx_text" style="background-color:#E6E6E6;">9.10</span></td>
</tr>
<tr id="S3.T5.9.10.5" class="ltx_tr" style="background-color:#E6E6E6;">
<td id="S3.T5.9.10.5.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T5.9.10.5.1.1" class="ltx_text" style="background-color:#E6E6E6;">90%</span></td>
<td id="S3.T5.9.10.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T5.9.10.5.2.1" class="ltx_text" style="background-color:#E6E6E6;">9.53</span></td>
<td id="S3.T5.9.10.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T5.9.10.5.3.1" class="ltx_text" style="background-color:#E6E6E6;">9.00</span></td>
<td id="S3.T5.9.10.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T5.9.10.5.4.1" class="ltx_text" style="background-color:#E6E6E6;">9.04</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.5" class="ltx_p">When dealing with accented speech, the findings presented in TableÂ 5 indicate that relying solely on conventional speech augmentation techniques does not provide enhancements in ASR performance (<math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\mathrm{R}_{aug}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">R</mi><mrow id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1a" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.1.m1.1.1.3.4" xref="S3.SS3.p2.1.m1.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">R</ci><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><times id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.1"></times><ci id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3">ğ‘¢</ci><ci id="S3.SS3.p2.1.m1.1.1.3.4.cmml" xref="S3.SS3.p2.1.m1.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\mathrm{R}_{aug}</annotation></semantics></math>, TableÂ 5). Moreover, the combination of the conventional speech augmentations with the synthetic TTS data, seems to harm the ASR. More precisely, in the case of <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="\mathrm{R_{aug}}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">R</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">aug</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">R</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">aug</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">\mathrm{R_{aug}}</annotation></semantics></math>, conventional augmentation appears to degrade the ASR on smaller (10% and 25%) partitions but improves the WER for larger sets. However, in the case of <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="\mathrm{R}_{aug}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><msub id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">R</mi><mrow id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.3.2" xref="S3.SS3.p2.3.m3.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.3.1" xref="S3.SS3.p2.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.3.m3.1.1.3.3" xref="S3.SS3.p2.3.m3.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.1.1.3.1a" xref="S3.SS3.p2.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.3.m3.1.1.3.4" xref="S3.SS3.p2.3.m3.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">R</ci><apply id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3"><times id="S3.SS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.3.1"></times><ci id="S3.SS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.p2.3.m3.1.1.3.2">ğ‘</ci><ci id="S3.SS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3.3">ğ‘¢</ci><ci id="S3.SS3.p2.3.m3.1.1.3.4.cmml" xref="S3.SS3.p2.3.m3.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">\mathrm{R}_{aug}</annotation></semantics></math>-<math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\mathrm{TTS_{INI}}" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><msub id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml">TTS</mi><mi id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">INI</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2">TTS</ci><ci id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">INI</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\mathrm{TTS_{INI}}</annotation></semantics></math>, we observe the opposite trend: limited improvements on smaller partitions and degradation on the larger (analogous results for model <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="\mathrm{TTS_{INI}}" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><msub id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">TTS</mi><mi id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml">INI</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">TTS</ci><ci id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">INI</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">\mathrm{TTS_{INI}}</annotation></semantics></math>).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusions</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper we describe a zero-shot TTS system application to the problem of biased ASR systems in low resource and under represented scenarios. We show that the pre-trained open-source model provides some WER improvement when used for data augmentation on a single accent. However, when the model is fine-tuned on a small amount of high-quality accented speech data the augmentation with synthetic data leads to statistically improved results when compared with the pre-trained model. Furthermore, when the ASR models are fine-tuned solely on TTS generated data, corresponding to the condition when no real accented speech is available, only the proposed method can improve the ASR WER. Moreover, we repurposed the language embeddings to encode accent specific pronunciations and fine-tuned the TTS model on the whole Interspeech 2020 dataset. However, this model didn't lead to improved WER when decoding real accented speech. We argue that this might be due to the fact that the Interspeech 2020 recordings are lower quality when compared to VCTK: this was tested by fine tuning the TTS model on a subset of the Indian training partition of the Interspeech dataset and using this model for ASR data augmentation. Finally we tested the effect of common speech augmentation techniques in combination with the TTS augmentation and show that this augmentation strategy harms the ASR when dealing with accented data. Further research will focus on understanding the fundamental difference between real and synthetic TTS speech from the perspective of different ASR models.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Acknowledgements</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This project was funded by the European Unionâ€™s Horizon 2020 program under the Marie SkÅ‚odowska-Curie grant No 956369.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J.Â Li, V.Â Manohar, P.Â Chitkara, A.Â Tjandra, M.Â Picheny, F.Â Zhang, X.Â Zhang, and Y.Â Saraf, ``Accent-robust automatic speech recognition using supervised and unsupervised wav2vec embeddings,'' <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.03520</em>, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
H.-J. Na and J.-S. Park, ``Accented speech recognition based on end-to-end domain adversarial training of neural networks,'' <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol.Â 11, no.Â 18, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
S.Â Liu, D.Â Wang, Y.Â Cao, L.Â Sun, X.Â Wu, S.Â Kang, Z.Â Wu, X.Â Liu, D.Â Su, D.Â Yu, and H.Â Meng, ``End-to-end accent conversion without using native utterances,'' in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2020, pp. 6289â€“6293.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
P.Â Klumpp, P.Â Chitkara, L.Â Sari, P.Â Serai, J.Â Wu, I.-E. Veliche, R.Â Huang, and Q.Â He, ``Synthetic cross-accent data augmentation for automatic speech recognition,'' <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, 2023. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2303.00802" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2303.00802</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
E.Â Casanova, J.Â Weber, C.Â D. Shulby, A.Â C. Junior, E.Â GÃ¶lge, and M.Â A. Ponti, ``Yourtts: Towards zero-shot multi-speaker tts and zero-shot voice conversion for everyone,'' in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Int. Conf. on Machine Learning</em>.Â Â Â PMLR, 2022, pp. 2709â€“2720.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
M.Â Ravanelli, T.Â Parcollet, P.Â Plantinga, A.Â Rouhe, S.Â Cornell, L.Â Lugosch, C.Â Subakan, N.Â Dawalatabad, A.Â Heba, J.Â Zhong, J.-C. Chou, S.-L. Yeh, S.-W. Fu, C.-F. Liao, E.Â Rastorgueva, F.Â Grondin, W.Â Aris, H.Â Na, Y.Â Gao, R.Â D. Mori, and Y.Â Bengio, ``SpeechBrain: A general-purpose speech toolkit,'' 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2106.04624" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2106.04624</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J.Â Kim, J.Â Kong, and J.Â Son, ``Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech,'' in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Int. Conf. on Machine Learning</em>.Â Â Â PMLR, 2021, pp. 5530â€“5540.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J.Â Kong, J.Â Kim, and J.Â Bae, ``Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis,'' <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol.Â 33, pp. 17â€‰022â€“17â€‰033, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
J.Â Kim, S.Â Kim, J.Â Kong, and S.Â Yoon, ``Glow-tts: A generative flow for text-to-speech via monotonic alignment search,'' <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol.Â 33, pp. 8067â€“8077, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
H.Â S. Heo, B.-J. Lee, J.Â Huh, and J.Â S. Chung, ``Clova baseline system for the voxceleb speaker recognition challenge 2020,'' 2020. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2009.14153" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2009.14153</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A.Â Graves, S.Â FernÃ¡ndez, F.Â Gomez, and J.Â Schmidhuber, ``Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,'' in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd Int. Conf. on Machine learning</em>, 2006, pp. 369â€“376.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J.Â Yamagishi, C.Â Veaux, and K.Â MacDonald, ``CSTR VCTK Corpus: English multi-speaker corpus for CSTR voice cloning toolkit,'' 2019. [Online]. Available: <a target="_blank" href="https://datashare.ed.ac.uk/handle/10283/2950" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://datashare.ed.ac.uk/handle/10283/2950</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
X.Â Shi, F.Â Yu, Y.Â Lu, Y.Â Liang, Q.Â Feng, D.Â Wang, Y.Â Qian, and L.Â Xie, ``The accented english speech recognition challenge 2020: Open datasets, tracks, baselines, results and methods,'' <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2102.10233" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2102.10233</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
V.Â Panayotov, G.Â Chen, D.Â Povey, and S.Â Khudanpur, ``Librispeech: An asr corpus based on public domain audio books,'' in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">2015 IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2015, pp. 5206â€“5210.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
K.Â Ito and L.Â Johnson, ``The LJ speech dataset,'' 2017. [Online]. Available: <a target="_blank" href="https://keithito.com/LJ-Speech-Dataset/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://keithito.com/LJ-Speech-Dataset/</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
E.Â Casanova, A.Â C. Junior, C.Â Shulby, F.Â S. deÂ Oliveira, J.Â P. Teixeira, M.Â A. Ponti, and S.Â AluÃ­sio, ``TTS-portuguese corpus: a corpus for speech synthesis in brazilian portuguese,'' <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Language Resources and Evaluation</em>, vol.Â 56, no.Â 3, pp. 1043â€“1055, jan 2022. [Online]. Available: <a target="_blank" href="https://doi.org/10.1007%2Fs10579-021-09570-4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007%2Fs10579-021-09570-4</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
I.Â Solak, ``The m-ailabs speech dataset.'' 2017. [Online]. Available: <a target="_blank" href="https://www.caito.de/2019/01/the-m-ailabs-speechdataset/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.caito.de/2019/01/the-m-ailabs-speechdataset/</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
D.Â S. Park, W.Â Chan, Y.Â Zhang, C.-C. Chiu, B.Â Zoph, E.Â D. Cubuk, and Q.Â V. Le, ``Specaugment: A simple data augmentation method for automatic speech recognition,'' in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Interspeech 2019</em>.Â Â Â ISCA, Sep. 2019.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
T.Â Ko, V.Â Peddinti, D.Â Povey, M.Â L. Seltzer, and S.Â Khudanpur, ``A study on data augmentation of reverberant speech for robust speech recognition,'' <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 5220â€“5224, 2017.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:creator" content="{Author name(s) withheld}"></div>
<div class="ltx_rdf" about="" property="dcterms:title" content="{Submitted to INTERSPEECH}"></div>

<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.11106" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.11107" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.11107">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.11107" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.11108" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 20:35:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
