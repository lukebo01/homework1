<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.17272] A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR</title><meta property="og:description" content="Recent works have shown promising results in connecting speech encoders to large language models (LLMs) for speech recognition. However, several limitations persist, including limited fine-tuning options, a lack of mec…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.17272">

<!--Generated on Fri Jul  5 20:10:08 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.2" class="ltx_ERROR undefined">\name</span>
<p id="p1.3" class="ltx_p">[affiliation=]Van TungPham
<span id="p1.3.1" class="ltx_ERROR undefined">\name</span>[affiliation=]YistLin
<span id="p1.3.2" class="ltx_ERROR undefined">\name</span>[affiliation=]TaoHan
<span id="p1.3.3" class="ltx_ERROR undefined">\name</span>[affiliation=]WeiLi
<span id="p1.3.4" class="ltx_ERROR undefined">\name</span>[affiliation=]JunZhang
<span id="p1.3.5" class="ltx_ERROR undefined">\name</span>[affiliation=]LuLu
<span id="p1.3.6" class="ltx_ERROR undefined">\name</span>[affiliation=]YuxuanWang




</p>
</div>
<h1 class="ltx_title ltx_title_document">A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Recent works have shown promising results in connecting speech encoders to large language models (LLMs) for speech recognition. However, several limitations persist, including limited fine-tuning options, a lack of mechanisms to enforce speech-text alignment, and high insertion errors especially in domain mismatch conditions. This paper presents a comprehensive solution to address these issues. We begin by investigating more thoughtful fine-tuning schemes. Next, we propose a matching loss to enhance alignment between modalities. Finally, we explore training and inference methods to mitigate high insertion errors. Experimental results on the Librispeech corpus demonstrate that partially fine-tuning the encoder and LLM using parameter-efficient methods, such as LoRA, is the most cost-effective approach. Additionally, the matching loss improves modality alignment, enhancing performance. The proposed training and inference methods significantly reduce insertion errors.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>speech recognition, pretrained speech encoder, parameter efficient, hallucination, modalities matching
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recently, large language models (LLM), characterised by their billions of parameters and training on massive datasets, have demonstrated emergent abilities to address various tasks in natural language processing field. Meanwhile, foundation models also advanced state-of-the-art in other research fields such as speech processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and computer vision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Hence, it is natural to develop effective approaches that unify foundation models from different modalities to build strong speech and visual understanding ability. In this work, we aim to connect a speech foundation model to an LLM for speech recognition.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The architecture of LLM-based ASR generally consists of three components: a speech encoder, an adapter, and an LLM. Recent works in LLM-based ASR examined techniques to compress the output of speech encoder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, design different adapters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, fine-tune the LLM partially <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> or keep it unchanged <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Despite these efforts, several issues still persist. Firstly, existing works only fine-tuned certain modules with specific configurations, which might exclude many efficient settings. Secondly, there is no method to explicitly force the representations generated by the adapter to be in a similar space, i.e. aligned, to those of LLM embeddings, although <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> shown that these representations are aligned to some extent after ASR fine-tuning. Finally, we observe very high insertion errors when the model is trained with limited training data or when test sets are mismatched with the training set - a problem that has not been studied before.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this work, we present a comprehensive solution
to address aforementioned issues. We first perform an empirical study about more thoughtful fine-tuning settings, each corresponding to different fine-tune options for each module, to identify efficient settings. We then propose a matching loss on top of a cross attention to explicitly force the two modalities to align with each other, leading to better ASR performance. Finally, we propose several training and inference strategies to address the high insertion problem. Specifically, for inference, we apply n-gram non-repetition and length penalty constraints during beam search decoding. In terms of training, we propose using a non-speech corpus with empty transcript for fine-tuning and data augmentations based on speed and volume perturbations.
</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The paper is organized as follows. Section 2 presents related works. In Section 3, we describe our proposed solution, followed by experimental setup in Section 4. Section 5 presents experimental results and analysis, then we conclude our work in Section 6.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related works</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Recently published works have extended LLMs with the ability to ingest other modalities, such as audio <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and vision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Regarding audio processing, LLM-based models have been studied for diverse tasks such as automatic speech recognition (ASR) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, speech translation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, audio event detection and understanding <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, etc. There are two paradigms for these models. The first one <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> converts continuous audio into discrete tokens and then merges text and audio tokens into a shared vocabulary while the second one <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> directly connects and adapts continuous representation of pretrained audio encoder into LLM. Although the first strategy is able to generate speech outputs from text or speech inputs by using codec-based discrete tokens, it may suffer from the information loss caused by discretization process hence might not be optimal for the speech-to-text task. In this work, we focus on the ASR task and we follow the second paradism.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Due to the immense number of parameters in LLM models, it can be computationally impractical to adapt the whole LLM to a target task. Several approaches have been proposed to address this issue include: inserting adapter layers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> or prefix embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> which are trained on target tasks. While these approaches are parameter-efficient, they increase the inference costs. Low-rank Adaptation (LoRa) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> solves these issues by using low-rank matrices which are memory efficient during training and does not impact inference time.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed solution</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We first investigate more comprehensive fine-tuning schemes in Section 3.1. In Section 3.2, we introduce the proposed matching loss to improve alignment between modalities, followed by training and inference techniques to address the insertion issue in Section 3.3.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Fine-tuning schemes for LLM-based ASR</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Existing works only fine-tuned certain modules of LLM-based ASR models with limited configurations. For example, SLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> only trained an adapter while keeping the other modules unchanged; whereas in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, LoRa was used in the LLM and fine-tuned together with the adapter and entire encoder. It is also worth noting that existing works either fully fine-tuned the encoder or kept it frozen, ignoring the option for partial fine-tuning, which is more practical given the immense number of parameters in many current speech encoders.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In this work, we investigate more thoughtful fine-tuning schemes with more options for each module. Specifically,</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">The LLM module typically has a very large size, thus it is impossible to fully fine-tune it using popular deep learning frameworks. Therefore, we consider freezing the LLM or fine-tuning it using a popular parameter-efficient method, e.g. LoRa <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Foundation encoders such as HuBert <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> or wav2vec2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> can be fully fine-tuned on recent advanced GPUs, such as the A100, which have high memory capacity. Hence, we consider three fine-tuning options for the encoder: frozen, partially fine-tuned with LoRa, and fully fine-tuned.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">For the adapter, we use a fully connected layer adapter, which is similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Specifically, it consists of a 1D convolution layer for subsampling, followed by the GeLu operation then a linear projection to have the same dimension as LLM embedding space. We denote this adapter as Conv1dMLP. Besides Conv1dMLP, we also consider different architectures for the adapter. Each of them requires a different number of parameters and has different expressive capacity. The first variant, denoted as DwsMLP, replaces a standard 1D convolution with a simple depthwise separable CNN, which requires fewer parameters. The second variant, denoted as Conv1dTransformer, uses Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> layers after subsampling (similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>), which generally have high expressive capacity but require substantially more parameters.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Improving modalities alignment by matching loss</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Past work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> has shown that the representation generated by the adapter is aligned, to some extent, with the LLM embeddings of the text. This alignment is implicitly achieved by fine-tuning the model using the ASR task, and there is no mechanism to explicitly force the two modalities to be aligned.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">In this work, we propose a matching loss to explicitly align these modalities, which is not a trivial problem since the two sequences have different lengths. To overcome this challenge, we first apply cross attention, such as dot-product attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, between the text embedding and acoustic embedding sequences. This generates a sequence of acoustic representations that has the same length as the text embedding sequence. After that, we can easily apply standard loss functions such as mean square error (MSE) or Cosine distance between the text embedding and the newly generated acoustic representations.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.5" class="ltx_p">Formally, let us first denote <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mo id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><lt id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">&lt;</annotation></semantics></math><span id="S3.SS2.p3.5.2" class="ltx_text ltx_font_bold">X</span>, <span id="S3.SS2.p3.2.1" class="ltx_text ltx_font_bold">Y<math id="S3.SS2.p3.2.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S3.SS2.p3.2.1.m1.1a"><mo id="S3.SS2.p3.2.1.m1.1.1" xref="S3.SS2.p3.2.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.1.m1.1b"><gt id="S3.SS2.p3.2.1.m1.1.1.cmml" xref="S3.SS2.p3.2.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.1.m1.1c">&gt;</annotation></semantics></math></span> as a training utterance, where <span id="S3.SS2.p3.5.3" class="ltx_text ltx_markedasmath ltx_font_bold">X</span> is a sequence of acoustic features and <math id="S3.SS2.p3.4.m3.5" class="ltx_Math" alttext="\textbf{Y}=\{y_{1},y_{2},...,y_{|\textbf{Y}|}\}" display="inline"><semantics id="S3.SS2.p3.4.m3.5a"><mrow id="S3.SS2.p3.4.m3.5.5" xref="S3.SS2.p3.4.m3.5.5.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.4.m3.5.5.5" xref="S3.SS2.p3.4.m3.5.5.5a.cmml">Y</mtext><mo id="S3.SS2.p3.4.m3.5.5.4" xref="S3.SS2.p3.4.m3.5.5.4.cmml">=</mo><mrow id="S3.SS2.p3.4.m3.5.5.3.3" xref="S3.SS2.p3.4.m3.5.5.3.4.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m3.5.5.3.3.4" xref="S3.SS2.p3.4.m3.5.5.3.4.cmml">{</mo><msub id="S3.SS2.p3.4.m3.3.3.1.1.1" xref="S3.SS2.p3.4.m3.3.3.1.1.1.cmml"><mi id="S3.SS2.p3.4.m3.3.3.1.1.1.2" xref="S3.SS2.p3.4.m3.3.3.1.1.1.2.cmml">y</mi><mn id="S3.SS2.p3.4.m3.3.3.1.1.1.3" xref="S3.SS2.p3.4.m3.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p3.4.m3.5.5.3.3.5" xref="S3.SS2.p3.4.m3.5.5.3.4.cmml">,</mo><msub id="S3.SS2.p3.4.m3.4.4.2.2.2" xref="S3.SS2.p3.4.m3.4.4.2.2.2.cmml"><mi id="S3.SS2.p3.4.m3.4.4.2.2.2.2" xref="S3.SS2.p3.4.m3.4.4.2.2.2.2.cmml">y</mi><mn id="S3.SS2.p3.4.m3.4.4.2.2.2.3" xref="S3.SS2.p3.4.m3.4.4.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p3.4.m3.5.5.3.3.6" xref="S3.SS2.p3.4.m3.5.5.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p3.4.m3.2.2" xref="S3.SS2.p3.4.m3.2.2.cmml">…</mi><mo id="S3.SS2.p3.4.m3.5.5.3.3.7" xref="S3.SS2.p3.4.m3.5.5.3.4.cmml">,</mo><msub id="S3.SS2.p3.4.m3.5.5.3.3.3" xref="S3.SS2.p3.4.m3.5.5.3.3.3.cmml"><mi id="S3.SS2.p3.4.m3.5.5.3.3.3.2" xref="S3.SS2.p3.4.m3.5.5.3.3.3.2.cmml">y</mi><mrow id="S3.SS2.p3.4.m3.1.1.1.3" xref="S3.SS2.p3.4.m3.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m3.1.1.1.3.1" xref="S3.SS2.p3.4.m3.1.1.1.2.1.cmml">|</mo><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.4.m3.1.1.1.1" xref="S3.SS2.p3.4.m3.1.1.1.1a.cmml">Y</mtext><mo stretchy="false" id="S3.SS2.p3.4.m3.1.1.1.3.2" xref="S3.SS2.p3.4.m3.1.1.1.2.1.cmml">|</mo></mrow></msub><mo stretchy="false" id="S3.SS2.p3.4.m3.5.5.3.3.8" xref="S3.SS2.p3.4.m3.5.5.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m3.5b"><apply id="S3.SS2.p3.4.m3.5.5.cmml" xref="S3.SS2.p3.4.m3.5.5"><eq id="S3.SS2.p3.4.m3.5.5.4.cmml" xref="S3.SS2.p3.4.m3.5.5.4"></eq><ci id="S3.SS2.p3.4.m3.5.5.5a.cmml" xref="S3.SS2.p3.4.m3.5.5.5"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p3.4.m3.5.5.5.cmml" xref="S3.SS2.p3.4.m3.5.5.5">Y</mtext></ci><set id="S3.SS2.p3.4.m3.5.5.3.4.cmml" xref="S3.SS2.p3.4.m3.5.5.3.3"><apply id="S3.SS2.p3.4.m3.3.3.1.1.1.cmml" xref="S3.SS2.p3.4.m3.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m3.3.3.1.1.1.1.cmml" xref="S3.SS2.p3.4.m3.3.3.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m3.3.3.1.1.1.2.cmml" xref="S3.SS2.p3.4.m3.3.3.1.1.1.2">𝑦</ci><cn type="integer" id="S3.SS2.p3.4.m3.3.3.1.1.1.3.cmml" xref="S3.SS2.p3.4.m3.3.3.1.1.1.3">1</cn></apply><apply id="S3.SS2.p3.4.m3.4.4.2.2.2.cmml" xref="S3.SS2.p3.4.m3.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m3.4.4.2.2.2.1.cmml" xref="S3.SS2.p3.4.m3.4.4.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.4.m3.4.4.2.2.2.2.cmml" xref="S3.SS2.p3.4.m3.4.4.2.2.2.2">𝑦</ci><cn type="integer" id="S3.SS2.p3.4.m3.4.4.2.2.2.3.cmml" xref="S3.SS2.p3.4.m3.4.4.2.2.2.3">2</cn></apply><ci id="S3.SS2.p3.4.m3.2.2.cmml" xref="S3.SS2.p3.4.m3.2.2">…</ci><apply id="S3.SS2.p3.4.m3.5.5.3.3.3.cmml" xref="S3.SS2.p3.4.m3.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m3.5.5.3.3.3.1.cmml" xref="S3.SS2.p3.4.m3.5.5.3.3.3">subscript</csymbol><ci id="S3.SS2.p3.4.m3.5.5.3.3.3.2.cmml" xref="S3.SS2.p3.4.m3.5.5.3.3.3.2">𝑦</ci><apply id="S3.SS2.p3.4.m3.1.1.1.2.cmml" xref="S3.SS2.p3.4.m3.1.1.1.3"><abs id="S3.SS2.p3.4.m3.1.1.1.2.1.cmml" xref="S3.SS2.p3.4.m3.1.1.1.3.1"></abs><ci id="S3.SS2.p3.4.m3.1.1.1.1a.cmml" xref="S3.SS2.p3.4.m3.1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.SS2.p3.4.m3.1.1.1.1.cmml" xref="S3.SS2.p3.4.m3.1.1.1.1">Y</mtext></ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m3.5c">\textbf{Y}=\{y_{1},y_{2},...,y_{|\textbf{Y}|}\}</annotation></semantics></math> is a sequence of output text. Then, the matching loss, denoted as <math id="S3.SS2.p3.5.m4.1" class="ltx_Math" alttext="L_{m}" display="inline"><semantics id="S3.SS2.p3.5.m4.1a"><msub id="S3.SS2.p3.5.m4.1.1" xref="S3.SS2.p3.5.m4.1.1.cmml"><mi id="S3.SS2.p3.5.m4.1.1.2" xref="S3.SS2.p3.5.m4.1.1.2.cmml">L</mi><mi id="S3.SS2.p3.5.m4.1.1.3" xref="S3.SS2.p3.5.m4.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m4.1b"><apply id="S3.SS2.p3.5.m4.1.1.cmml" xref="S3.SS2.p3.5.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m4.1.1.1.cmml" xref="S3.SS2.p3.5.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.5.m4.1.1.2.cmml" xref="S3.SS2.p3.5.m4.1.1.2">𝐿</ci><ci id="S3.SS2.p3.5.m4.1.1.3.cmml" xref="S3.SS2.p3.5.m4.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m4.1c">L_{m}</annotation></semantics></math>, can be described as follows</p>
<table id="S6.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\displaystyle\textbf{E}_{\textbf{Y}}" display="inline"><semantics id="S3.E1.m1.1a"><msub id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2a.cmml">E</mtext><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3a.cmml">Y</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.2a.cmml" xref="S3.E1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2">E</mtext></ci><ci id="S3.E1.m1.1.1.3a.cmml" xref="S3.E1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3">Y</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle\textbf{E}_{\textbf{Y}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1.m2.4" class="ltx_Math" alttext="\displaystyle=Emb(y_{1})\ Emb(y_{2})...Emb(y_{|\textbf{Y}|})" display="inline"><semantics id="S3.E1.m2.4a"><mrow id="S3.E1.m2.4.4" xref="S3.E1.m2.4.4.cmml"><mi id="S3.E1.m2.4.4.5" xref="S3.E1.m2.4.4.5.cmml"></mi><mo id="S3.E1.m2.4.4.4" xref="S3.E1.m2.4.4.4.cmml">=</mo><mrow id="S3.E1.m2.4.4.3" xref="S3.E1.m2.4.4.3.cmml"><mi id="S3.E1.m2.4.4.3.5" xref="S3.E1.m2.4.4.3.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi id="S3.E1.m2.4.4.3.6" xref="S3.E1.m2.4.4.3.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4a" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi id="S3.E1.m2.4.4.3.7" xref="S3.E1.m2.4.4.3.7.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4b" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mrow id="S3.E1.m2.2.2.1.1.1" xref="S3.E1.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m2.2.2.1.1.1.2" xref="S3.E1.m2.2.2.1.1.1.1.cmml">(</mo><msub id="S3.E1.m2.2.2.1.1.1.1" xref="S3.E1.m2.2.2.1.1.1.1.cmml"><mi id="S3.E1.m2.2.2.1.1.1.1.2" xref="S3.E1.m2.2.2.1.1.1.1.2.cmml">y</mi><mn id="S3.E1.m2.2.2.1.1.1.1.3" xref="S3.E1.m2.2.2.1.1.1.1.3.cmml">1</mn></msub><mo stretchy="false" id="S3.E1.m2.2.2.1.1.1.3" xref="S3.E1.m2.2.2.1.1.1.1.cmml">)</mo></mrow><mo lspace="0.500em" rspace="0em" id="S3.E1.m2.4.4.3.4c" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi id="S3.E1.m2.4.4.3.8" xref="S3.E1.m2.4.4.3.8.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4d" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi id="S3.E1.m2.4.4.3.9" xref="S3.E1.m2.4.4.3.9.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4e" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi id="S3.E1.m2.4.4.3.10" xref="S3.E1.m2.4.4.3.10.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4f" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mrow id="S3.E1.m2.3.3.2.2.1" xref="S3.E1.m2.3.3.2.2.1.1.cmml"><mo stretchy="false" id="S3.E1.m2.3.3.2.2.1.2" xref="S3.E1.m2.3.3.2.2.1.1.cmml">(</mo><msub id="S3.E1.m2.3.3.2.2.1.1" xref="S3.E1.m2.3.3.2.2.1.1.cmml"><mi id="S3.E1.m2.3.3.2.2.1.1.2" xref="S3.E1.m2.3.3.2.2.1.1.2.cmml">y</mi><mn id="S3.E1.m2.3.3.2.2.1.1.3" xref="S3.E1.m2.3.3.2.2.1.1.3.cmml">2</mn></msub><mo stretchy="false" id="S3.E1.m2.3.3.2.2.1.3" xref="S3.E1.m2.3.3.2.2.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4g" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi mathvariant="normal" id="S3.E1.m2.4.4.3.11" xref="S3.E1.m2.4.4.3.11.cmml">…</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4h" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi id="S3.E1.m2.4.4.3.12" xref="S3.E1.m2.4.4.3.12.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4i" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi id="S3.E1.m2.4.4.3.13" xref="S3.E1.m2.4.4.3.13.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4j" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mi id="S3.E1.m2.4.4.3.14" xref="S3.E1.m2.4.4.3.14.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E1.m2.4.4.3.4k" xref="S3.E1.m2.4.4.3.4.cmml">​</mo><mrow id="S3.E1.m2.4.4.3.3.1" xref="S3.E1.m2.4.4.3.3.1.1.cmml"><mo stretchy="false" id="S3.E1.m2.4.4.3.3.1.2" xref="S3.E1.m2.4.4.3.3.1.1.cmml">(</mo><msub id="S3.E1.m2.4.4.3.3.1.1" xref="S3.E1.m2.4.4.3.3.1.1.cmml"><mi id="S3.E1.m2.4.4.3.3.1.1.2" xref="S3.E1.m2.4.4.3.3.1.1.2.cmml">y</mi><mrow id="S3.E1.m2.1.1.1.3" xref="S3.E1.m2.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m2.1.1.1.3.1" xref="S3.E1.m2.1.1.1.2.1.cmml">|</mo><mtext class="ltx_mathvariant_bold" id="S3.E1.m2.1.1.1.1" xref="S3.E1.m2.1.1.1.1a.cmml">Y</mtext><mo stretchy="false" id="S3.E1.m2.1.1.1.3.2" xref="S3.E1.m2.1.1.1.2.1.cmml">|</mo></mrow></msub><mo stretchy="false" id="S3.E1.m2.4.4.3.3.1.3" xref="S3.E1.m2.4.4.3.3.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m2.4b"><apply id="S3.E1.m2.4.4.cmml" xref="S3.E1.m2.4.4"><eq id="S3.E1.m2.4.4.4.cmml" xref="S3.E1.m2.4.4.4"></eq><csymbol cd="latexml" id="S3.E1.m2.4.4.5.cmml" xref="S3.E1.m2.4.4.5">absent</csymbol><apply id="S3.E1.m2.4.4.3.cmml" xref="S3.E1.m2.4.4.3"><times id="S3.E1.m2.4.4.3.4.cmml" xref="S3.E1.m2.4.4.3.4"></times><ci id="S3.E1.m2.4.4.3.5.cmml" xref="S3.E1.m2.4.4.3.5">𝐸</ci><ci id="S3.E1.m2.4.4.3.6.cmml" xref="S3.E1.m2.4.4.3.6">𝑚</ci><ci id="S3.E1.m2.4.4.3.7.cmml" xref="S3.E1.m2.4.4.3.7">𝑏</ci><apply id="S3.E1.m2.2.2.1.1.1.1.cmml" xref="S3.E1.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m2.2.2.1.1.1.1.1.cmml" xref="S3.E1.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m2.2.2.1.1.1.1.2.cmml" xref="S3.E1.m2.2.2.1.1.1.1.2">𝑦</ci><cn type="integer" id="S3.E1.m2.2.2.1.1.1.1.3.cmml" xref="S3.E1.m2.2.2.1.1.1.1.3">1</cn></apply><ci id="S3.E1.m2.4.4.3.8.cmml" xref="S3.E1.m2.4.4.3.8">𝐸</ci><ci id="S3.E1.m2.4.4.3.9.cmml" xref="S3.E1.m2.4.4.3.9">𝑚</ci><ci id="S3.E1.m2.4.4.3.10.cmml" xref="S3.E1.m2.4.4.3.10">𝑏</ci><apply id="S3.E1.m2.3.3.2.2.1.1.cmml" xref="S3.E1.m2.3.3.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m2.3.3.2.2.1.1.1.cmml" xref="S3.E1.m2.3.3.2.2.1">subscript</csymbol><ci id="S3.E1.m2.3.3.2.2.1.1.2.cmml" xref="S3.E1.m2.3.3.2.2.1.1.2">𝑦</ci><cn type="integer" id="S3.E1.m2.3.3.2.2.1.1.3.cmml" xref="S3.E1.m2.3.3.2.2.1.1.3">2</cn></apply><ci id="S3.E1.m2.4.4.3.11.cmml" xref="S3.E1.m2.4.4.3.11">…</ci><ci id="S3.E1.m2.4.4.3.12.cmml" xref="S3.E1.m2.4.4.3.12">𝐸</ci><ci id="S3.E1.m2.4.4.3.13.cmml" xref="S3.E1.m2.4.4.3.13">𝑚</ci><ci id="S3.E1.m2.4.4.3.14.cmml" xref="S3.E1.m2.4.4.3.14">𝑏</ci><apply id="S3.E1.m2.4.4.3.3.1.1.cmml" xref="S3.E1.m2.4.4.3.3.1"><csymbol cd="ambiguous" id="S3.E1.m2.4.4.3.3.1.1.1.cmml" xref="S3.E1.m2.4.4.3.3.1">subscript</csymbol><ci id="S3.E1.m2.4.4.3.3.1.1.2.cmml" xref="S3.E1.m2.4.4.3.3.1.1.2">𝑦</ci><apply id="S3.E1.m2.1.1.1.2.cmml" xref="S3.E1.m2.1.1.1.3"><abs id="S3.E1.m2.1.1.1.2.1.cmml" xref="S3.E1.m2.1.1.1.3.1"></abs><ci id="S3.E1.m2.1.1.1.1a.cmml" xref="S3.E1.m2.1.1.1.1"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E1.m2.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1">Y</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m2.4c">\displaystyle=Emb(y_{1})\ Emb(y_{2})...Emb(y_{|\textbf{Y}|})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\displaystyle\textbf{X}_{1}" display="inline"><semantics id="S3.E2.m1.1a"><msub id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2a.cmml">X</mtext><mn id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.2a.cmml" xref="S3.E2.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2">X</mtext></ci><cn type="integer" id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle\textbf{X}_{1}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2.m2.2" class="ltx_Math" alttext="\displaystyle=Adapt(Enc(\textbf{X}))" display="inline"><semantics id="S3.E2.m2.2a"><mrow id="S3.E2.m2.2.2" xref="S3.E2.m2.2.2.cmml"><mi id="S3.E2.m2.2.2.3" xref="S3.E2.m2.2.2.3.cmml"></mi><mo id="S3.E2.m2.2.2.2" xref="S3.E2.m2.2.2.2.cmml">=</mo><mrow id="S3.E2.m2.2.2.1" xref="S3.E2.m2.2.2.1.cmml"><mi id="S3.E2.m2.2.2.1.3" xref="S3.E2.m2.2.2.1.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.2" xref="S3.E2.m2.2.2.1.2.cmml">​</mo><mi id="S3.E2.m2.2.2.1.4" xref="S3.E2.m2.2.2.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.2a" xref="S3.E2.m2.2.2.1.2.cmml">​</mo><mi id="S3.E2.m2.2.2.1.5" xref="S3.E2.m2.2.2.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.2b" xref="S3.E2.m2.2.2.1.2.cmml">​</mo><mi id="S3.E2.m2.2.2.1.6" xref="S3.E2.m2.2.2.1.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.2c" xref="S3.E2.m2.2.2.1.2.cmml">​</mo><mi id="S3.E2.m2.2.2.1.7" xref="S3.E2.m2.2.2.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.2d" xref="S3.E2.m2.2.2.1.2.cmml">​</mo><mrow id="S3.E2.m2.2.2.1.1.1" xref="S3.E2.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m2.2.2.1.1.1.2" xref="S3.E2.m2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m2.2.2.1.1.1.1" xref="S3.E2.m2.2.2.1.1.1.1.cmml"><mi id="S3.E2.m2.2.2.1.1.1.1.2" xref="S3.E2.m2.2.2.1.1.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.1.1.1.1" xref="S3.E2.m2.2.2.1.1.1.1.1.cmml">​</mo><mi id="S3.E2.m2.2.2.1.1.1.1.3" xref="S3.E2.m2.2.2.1.1.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.1.1.1.1a" xref="S3.E2.m2.2.2.1.1.1.1.1.cmml">​</mo><mi id="S3.E2.m2.2.2.1.1.1.1.4" xref="S3.E2.m2.2.2.1.1.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.1.1.1.1b" xref="S3.E2.m2.2.2.1.1.1.1.1.cmml">​</mo><mrow id="S3.E2.m2.2.2.1.1.1.1.5.2" xref="S3.E2.m2.1.1a.cmml"><mo stretchy="false" id="S3.E2.m2.2.2.1.1.1.1.5.2.1" xref="S3.E2.m2.1.1a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S3.E2.m2.1.1" xref="S3.E2.m2.1.1.cmml">X</mtext><mo stretchy="false" id="S3.E2.m2.2.2.1.1.1.1.5.2.2" xref="S3.E2.m2.1.1a.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m2.2.2.1.1.1.3" xref="S3.E2.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m2.2b"><apply id="S3.E2.m2.2.2.cmml" xref="S3.E2.m2.2.2"><eq id="S3.E2.m2.2.2.2.cmml" xref="S3.E2.m2.2.2.2"></eq><csymbol cd="latexml" id="S3.E2.m2.2.2.3.cmml" xref="S3.E2.m2.2.2.3">absent</csymbol><apply id="S3.E2.m2.2.2.1.cmml" xref="S3.E2.m2.2.2.1"><times id="S3.E2.m2.2.2.1.2.cmml" xref="S3.E2.m2.2.2.1.2"></times><ci id="S3.E2.m2.2.2.1.3.cmml" xref="S3.E2.m2.2.2.1.3">𝐴</ci><ci id="S3.E2.m2.2.2.1.4.cmml" xref="S3.E2.m2.2.2.1.4">𝑑</ci><ci id="S3.E2.m2.2.2.1.5.cmml" xref="S3.E2.m2.2.2.1.5">𝑎</ci><ci id="S3.E2.m2.2.2.1.6.cmml" xref="S3.E2.m2.2.2.1.6">𝑝</ci><ci id="S3.E2.m2.2.2.1.7.cmml" xref="S3.E2.m2.2.2.1.7">𝑡</ci><apply id="S3.E2.m2.2.2.1.1.1.1.cmml" xref="S3.E2.m2.2.2.1.1.1"><times id="S3.E2.m2.2.2.1.1.1.1.1.cmml" xref="S3.E2.m2.2.2.1.1.1.1.1"></times><ci id="S3.E2.m2.2.2.1.1.1.1.2.cmml" xref="S3.E2.m2.2.2.1.1.1.1.2">𝐸</ci><ci id="S3.E2.m2.2.2.1.1.1.1.3.cmml" xref="S3.E2.m2.2.2.1.1.1.1.3">𝑛</ci><ci id="S3.E2.m2.2.2.1.1.1.1.4.cmml" xref="S3.E2.m2.2.2.1.1.1.1.4">𝑐</ci><ci id="S3.E2.m2.1.1a.cmml" xref="S3.E2.m2.2.2.1.1.1.1.5.2"><mtext class="ltx_mathvariant_bold" id="S3.E2.m2.1.1.cmml" xref="S3.E2.m2.1.1">X</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m2.2c">\displaystyle=Adapt(Enc(\textbf{X}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span id="S3.E3.2.1.1.1" class="ltx_text ltx_markedasmath ltx_font_bold">H</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E3.m2.3" class="ltx_Math" alttext="\displaystyle=CrossAtt(\textbf{E}_{\textbf{Y}},\textbf{X}_{1})=softmax(\frac{\textbf{E}_{\textbf{Y}}\textbf{X}_{1}^{T}}{\sqrt{d_{llm}}})\textbf{X}_{1}" display="inline"><semantics id="S3.E3.m2.3a"><mrow id="S3.E3.m2.3.3" xref="S3.E3.m2.3.3.cmml"><mi id="S3.E3.m2.3.3.4" xref="S3.E3.m2.3.3.4.cmml"></mi><mo id="S3.E3.m2.3.3.5" xref="S3.E3.m2.3.3.5.cmml">=</mo><mrow id="S3.E3.m2.3.3.2" xref="S3.E3.m2.3.3.2.cmml"><mi id="S3.E3.m2.3.3.2.4" xref="S3.E3.m2.3.3.2.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.2.3" xref="S3.E3.m2.3.3.2.3.cmml">​</mo><mi id="S3.E3.m2.3.3.2.5" xref="S3.E3.m2.3.3.2.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.2.3a" xref="S3.E3.m2.3.3.2.3.cmml">​</mo><mi id="S3.E3.m2.3.3.2.6" xref="S3.E3.m2.3.3.2.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.2.3b" xref="S3.E3.m2.3.3.2.3.cmml">​</mo><mi id="S3.E3.m2.3.3.2.7" xref="S3.E3.m2.3.3.2.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.2.3c" xref="S3.E3.m2.3.3.2.3.cmml">​</mo><mi id="S3.E3.m2.3.3.2.8" xref="S3.E3.m2.3.3.2.8.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.2.3d" xref="S3.E3.m2.3.3.2.3.cmml">​</mo><mi id="S3.E3.m2.3.3.2.9" xref="S3.E3.m2.3.3.2.9.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.2.3e" xref="S3.E3.m2.3.3.2.3.cmml">​</mo><mi id="S3.E3.m2.3.3.2.10" xref="S3.E3.m2.3.3.2.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.2.3f" xref="S3.E3.m2.3.3.2.3.cmml">​</mo><mi id="S3.E3.m2.3.3.2.11" xref="S3.E3.m2.3.3.2.11.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.2.3g" xref="S3.E3.m2.3.3.2.3.cmml">​</mo><mrow id="S3.E3.m2.3.3.2.2.2" xref="S3.E3.m2.3.3.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m2.3.3.2.2.2.3" xref="S3.E3.m2.3.3.2.2.3.cmml">(</mo><msub id="S3.E3.m2.2.2.1.1.1.1" xref="S3.E3.m2.2.2.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.2.2.1.1.1.1.2" xref="S3.E3.m2.2.2.1.1.1.1.2a.cmml">E</mtext><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.2.2.1.1.1.1.3" xref="S3.E3.m2.2.2.1.1.1.1.3a.cmml">Y</mtext></msub><mo id="S3.E3.m2.3.3.2.2.2.4" xref="S3.E3.m2.3.3.2.2.3.cmml">,</mo><msub id="S3.E3.m2.3.3.2.2.2.2" xref="S3.E3.m2.3.3.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.3.3.2.2.2.2.2" xref="S3.E3.m2.3.3.2.2.2.2.2a.cmml">X</mtext><mn id="S3.E3.m2.3.3.2.2.2.2.3" xref="S3.E3.m2.3.3.2.2.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S3.E3.m2.3.3.2.2.2.5" xref="S3.E3.m2.3.3.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E3.m2.3.3.6" xref="S3.E3.m2.3.3.6.cmml">=</mo><mrow id="S3.E3.m2.3.3.7" xref="S3.E3.m2.3.3.7.cmml"><mi id="S3.E3.m2.3.3.7.2" xref="S3.E3.m2.3.3.7.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.7.1" xref="S3.E3.m2.3.3.7.1.cmml">​</mo><mi id="S3.E3.m2.3.3.7.3" xref="S3.E3.m2.3.3.7.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.7.1a" xref="S3.E3.m2.3.3.7.1.cmml">​</mo><mi id="S3.E3.m2.3.3.7.4" xref="S3.E3.m2.3.3.7.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.7.1b" xref="S3.E3.m2.3.3.7.1.cmml">​</mo><mi id="S3.E3.m2.3.3.7.5" xref="S3.E3.m2.3.3.7.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.7.1c" xref="S3.E3.m2.3.3.7.1.cmml">​</mo><mi id="S3.E3.m2.3.3.7.6" xref="S3.E3.m2.3.3.7.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.7.1d" xref="S3.E3.m2.3.3.7.1.cmml">​</mo><mi id="S3.E3.m2.3.3.7.7" xref="S3.E3.m2.3.3.7.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.7.1e" xref="S3.E3.m2.3.3.7.1.cmml">​</mo><mi id="S3.E3.m2.3.3.7.8" xref="S3.E3.m2.3.3.7.8.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.7.1f" xref="S3.E3.m2.3.3.7.1.cmml">​</mo><mrow id="S3.E3.m2.3.3.7.9.2" xref="S3.E3.m2.1.1.cmml"><mo stretchy="false" id="S3.E3.m2.3.3.7.9.2.1" xref="S3.E3.m2.1.1.cmml">(</mo><mstyle displaystyle="true" id="S3.E3.m2.1.1" xref="S3.E3.m2.1.1.cmml"><mfrac id="S3.E3.m2.1.1a" xref="S3.E3.m2.1.1.cmml"><mrow id="S3.E3.m2.1.1.2" xref="S3.E3.m2.1.1.2.cmml"><msub id="S3.E3.m2.1.1.2.2" xref="S3.E3.m2.1.1.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.1.1.2.2.2" xref="S3.E3.m2.1.1.2.2.2a.cmml">E</mtext><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.1.1.2.2.3" xref="S3.E3.m2.1.1.2.2.3a.cmml">Y</mtext></msub><mo lspace="0em" rspace="0em" id="S3.E3.m2.1.1.2.1" xref="S3.E3.m2.1.1.2.1.cmml">​</mo><msubsup id="S3.E3.m2.1.1.2.3" xref="S3.E3.m2.1.1.2.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.1.1.2.3.2.2" xref="S3.E3.m2.1.1.2.3.2.2a.cmml">X</mtext><mn id="S3.E3.m2.1.1.2.3.2.3" xref="S3.E3.m2.1.1.2.3.2.3.cmml">1</mn><mi id="S3.E3.m2.1.1.2.3.3" xref="S3.E3.m2.1.1.2.3.3.cmml">T</mi></msubsup></mrow><msqrt id="S3.E3.m2.1.1.3" xref="S3.E3.m2.1.1.3.cmml"><msub id="S3.E3.m2.1.1.3.2" xref="S3.E3.m2.1.1.3.2.cmml"><mi id="S3.E3.m2.1.1.3.2.2" xref="S3.E3.m2.1.1.3.2.2.cmml">d</mi><mrow id="S3.E3.m2.1.1.3.2.3" xref="S3.E3.m2.1.1.3.2.3.cmml"><mi id="S3.E3.m2.1.1.3.2.3.2" xref="S3.E3.m2.1.1.3.2.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.1.1.3.2.3.1" xref="S3.E3.m2.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E3.m2.1.1.3.2.3.3" xref="S3.E3.m2.1.1.3.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E3.m2.1.1.3.2.3.1a" xref="S3.E3.m2.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E3.m2.1.1.3.2.3.4" xref="S3.E3.m2.1.1.3.2.3.4.cmml">m</mi></mrow></msub></msqrt></mfrac></mstyle><mo stretchy="false" id="S3.E3.m2.3.3.7.9.2.2" xref="S3.E3.m2.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m2.3.3.7.1g" xref="S3.E3.m2.3.3.7.1.cmml">​</mo><msub id="S3.E3.m2.3.3.7.10" xref="S3.E3.m2.3.3.7.10.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.3.3.7.10.2" xref="S3.E3.m2.3.3.7.10.2a.cmml">X</mtext><mn id="S3.E3.m2.3.3.7.10.3" xref="S3.E3.m2.3.3.7.10.3.cmml">1</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m2.3b"><apply id="S3.E3.m2.3.3.cmml" xref="S3.E3.m2.3.3"><and id="S3.E3.m2.3.3a.cmml" xref="S3.E3.m2.3.3"></and><apply id="S3.E3.m2.3.3b.cmml" xref="S3.E3.m2.3.3"><eq id="S3.E3.m2.3.3.5.cmml" xref="S3.E3.m2.3.3.5"></eq><csymbol cd="latexml" id="S3.E3.m2.3.3.4.cmml" xref="S3.E3.m2.3.3.4">absent</csymbol><apply id="S3.E3.m2.3.3.2.cmml" xref="S3.E3.m2.3.3.2"><times id="S3.E3.m2.3.3.2.3.cmml" xref="S3.E3.m2.3.3.2.3"></times><ci id="S3.E3.m2.3.3.2.4.cmml" xref="S3.E3.m2.3.3.2.4">𝐶</ci><ci id="S3.E3.m2.3.3.2.5.cmml" xref="S3.E3.m2.3.3.2.5">𝑟</ci><ci id="S3.E3.m2.3.3.2.6.cmml" xref="S3.E3.m2.3.3.2.6">𝑜</ci><ci id="S3.E3.m2.3.3.2.7.cmml" xref="S3.E3.m2.3.3.2.7">𝑠</ci><ci id="S3.E3.m2.3.3.2.8.cmml" xref="S3.E3.m2.3.3.2.8">𝑠</ci><ci id="S3.E3.m2.3.3.2.9.cmml" xref="S3.E3.m2.3.3.2.9">𝐴</ci><ci id="S3.E3.m2.3.3.2.10.cmml" xref="S3.E3.m2.3.3.2.10">𝑡</ci><ci id="S3.E3.m2.3.3.2.11.cmml" xref="S3.E3.m2.3.3.2.11">𝑡</ci><interval closure="open" id="S3.E3.m2.3.3.2.2.3.cmml" xref="S3.E3.m2.3.3.2.2.2"><apply id="S3.E3.m2.2.2.1.1.1.1.cmml" xref="S3.E3.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m2.2.2.1.1.1.1.1.cmml" xref="S3.E3.m2.2.2.1.1.1.1">subscript</csymbol><ci id="S3.E3.m2.2.2.1.1.1.1.2a.cmml" xref="S3.E3.m2.2.2.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.2.2.1.1.1.1.2.cmml" xref="S3.E3.m2.2.2.1.1.1.1.2">E</mtext></ci><ci id="S3.E3.m2.2.2.1.1.1.1.3a.cmml" xref="S3.E3.m2.2.2.1.1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E3.m2.2.2.1.1.1.1.3.cmml" xref="S3.E3.m2.2.2.1.1.1.1.3">Y</mtext></ci></apply><apply id="S3.E3.m2.3.3.2.2.2.2.cmml" xref="S3.E3.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m2.3.3.2.2.2.2.1.cmml" xref="S3.E3.m2.3.3.2.2.2.2">subscript</csymbol><ci id="S3.E3.m2.3.3.2.2.2.2.2a.cmml" xref="S3.E3.m2.3.3.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.3.3.2.2.2.2.2.cmml" xref="S3.E3.m2.3.3.2.2.2.2.2">X</mtext></ci><cn type="integer" id="S3.E3.m2.3.3.2.2.2.2.3.cmml" xref="S3.E3.m2.3.3.2.2.2.2.3">1</cn></apply></interval></apply></apply><apply id="S3.E3.m2.3.3c.cmml" xref="S3.E3.m2.3.3"><eq id="S3.E3.m2.3.3.6.cmml" xref="S3.E3.m2.3.3.6"></eq><share href="#S3.E3.m2.3.3.2.cmml" id="S3.E3.m2.3.3d.cmml" xref="S3.E3.m2.3.3"></share><apply id="S3.E3.m2.3.3.7.cmml" xref="S3.E3.m2.3.3.7"><times id="S3.E3.m2.3.3.7.1.cmml" xref="S3.E3.m2.3.3.7.1"></times><ci id="S3.E3.m2.3.3.7.2.cmml" xref="S3.E3.m2.3.3.7.2">𝑠</ci><ci id="S3.E3.m2.3.3.7.3.cmml" xref="S3.E3.m2.3.3.7.3">𝑜</ci><ci id="S3.E3.m2.3.3.7.4.cmml" xref="S3.E3.m2.3.3.7.4">𝑓</ci><ci id="S3.E3.m2.3.3.7.5.cmml" xref="S3.E3.m2.3.3.7.5">𝑡</ci><ci id="S3.E3.m2.3.3.7.6.cmml" xref="S3.E3.m2.3.3.7.6">𝑚</ci><ci id="S3.E3.m2.3.3.7.7.cmml" xref="S3.E3.m2.3.3.7.7">𝑎</ci><ci id="S3.E3.m2.3.3.7.8.cmml" xref="S3.E3.m2.3.3.7.8">𝑥</ci><apply id="S3.E3.m2.1.1.cmml" xref="S3.E3.m2.3.3.7.9.2"><divide id="S3.E3.m2.1.1.1.cmml" xref="S3.E3.m2.3.3.7.9.2"></divide><apply id="S3.E3.m2.1.1.2.cmml" xref="S3.E3.m2.1.1.2"><times id="S3.E3.m2.1.1.2.1.cmml" xref="S3.E3.m2.1.1.2.1"></times><apply id="S3.E3.m2.1.1.2.2.cmml" xref="S3.E3.m2.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.2.2.1.cmml" xref="S3.E3.m2.1.1.2.2">subscript</csymbol><ci id="S3.E3.m2.1.1.2.2.2a.cmml" xref="S3.E3.m2.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.1.1.2.2.2.cmml" xref="S3.E3.m2.1.1.2.2.2">E</mtext></ci><ci id="S3.E3.m2.1.1.2.2.3a.cmml" xref="S3.E3.m2.1.1.2.2.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E3.m2.1.1.2.2.3.cmml" xref="S3.E3.m2.1.1.2.2.3">Y</mtext></ci></apply><apply id="S3.E3.m2.1.1.2.3.cmml" xref="S3.E3.m2.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.2.3.1.cmml" xref="S3.E3.m2.1.1.2.3">superscript</csymbol><apply id="S3.E3.m2.1.1.2.3.2.cmml" xref="S3.E3.m2.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.2.3.2.1.cmml" xref="S3.E3.m2.1.1.2.3">subscript</csymbol><ci id="S3.E3.m2.1.1.2.3.2.2a.cmml" xref="S3.E3.m2.1.1.2.3.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.1.1.2.3.2.2.cmml" xref="S3.E3.m2.1.1.2.3.2.2">X</mtext></ci><cn type="integer" id="S3.E3.m2.1.1.2.3.2.3.cmml" xref="S3.E3.m2.1.1.2.3.2.3">1</cn></apply><ci id="S3.E3.m2.1.1.2.3.3.cmml" xref="S3.E3.m2.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S3.E3.m2.1.1.3.cmml" xref="S3.E3.m2.1.1.3"><root id="S3.E3.m2.1.1.3a.cmml" xref="S3.E3.m2.1.1.3"></root><apply id="S3.E3.m2.1.1.3.2.cmml" xref="S3.E3.m2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.3.2.1.cmml" xref="S3.E3.m2.1.1.3.2">subscript</csymbol><ci id="S3.E3.m2.1.1.3.2.2.cmml" xref="S3.E3.m2.1.1.3.2.2">𝑑</ci><apply id="S3.E3.m2.1.1.3.2.3.cmml" xref="S3.E3.m2.1.1.3.2.3"><times id="S3.E3.m2.1.1.3.2.3.1.cmml" xref="S3.E3.m2.1.1.3.2.3.1"></times><ci id="S3.E3.m2.1.1.3.2.3.2.cmml" xref="S3.E3.m2.1.1.3.2.3.2">𝑙</ci><ci id="S3.E3.m2.1.1.3.2.3.3.cmml" xref="S3.E3.m2.1.1.3.2.3.3">𝑙</ci><ci id="S3.E3.m2.1.1.3.2.3.4.cmml" xref="S3.E3.m2.1.1.3.2.3.4">𝑚</ci></apply></apply></apply></apply><apply id="S3.E3.m2.3.3.7.10.cmml" xref="S3.E3.m2.3.3.7.10"><csymbol cd="ambiguous" id="S3.E3.m2.3.3.7.10.1.cmml" xref="S3.E3.m2.3.3.7.10">subscript</csymbol><ci id="S3.E3.m2.3.3.7.10.2a.cmml" xref="S3.E3.m2.3.3.7.10.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m2.3.3.7.10.2.cmml" xref="S3.E3.m2.3.3.7.10.2">X</mtext></ci><cn type="integer" id="S3.E3.m2.3.3.7.10.3.cmml" xref="S3.E3.m2.3.3.7.10.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m2.3c">\displaystyle=CrossAtt(\textbf{E}_{\textbf{Y}},\textbf{X}_{1})=softmax(\frac{\textbf{E}_{\textbf{Y}}\textbf{X}_{1}^{T}}{\sqrt{d_{llm}}})\textbf{X}_{1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\displaystyle L_{m}" display="inline"><semantics id="S3.E4.m1.1a"><msub id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mi id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">L</mi><mi id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2">𝐿</ci><ci id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\displaystyle L_{m}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E4.m2.4" class="ltx_Math" alttext="\displaystyle=a\ MSE(\textbf{E}_{\textbf{Y}},\textbf{H})+b\ Cosine(\textbf{E}_{\textbf{Y}},\textbf{H})\vspace{-0.3cm}" display="inline"><semantics id="S3.E4.m2.4a"><mrow id="S3.E4.m2.4.4" xref="S3.E4.m2.4.4.cmml"><mi id="S3.E4.m2.4.4.4" xref="S3.E4.m2.4.4.4.cmml"></mi><mo id="S3.E4.m2.4.4.3" xref="S3.E4.m2.4.4.3.cmml">=</mo><mrow id="S3.E4.m2.4.4.2" xref="S3.E4.m2.4.4.2.cmml"><mrow id="S3.E4.m2.3.3.1.1" xref="S3.E4.m2.3.3.1.1.cmml"><mi id="S3.E4.m2.3.3.1.1.3" xref="S3.E4.m2.3.3.1.1.3.cmml">a</mi><mo lspace="0.500em" rspace="0em" id="S3.E4.m2.3.3.1.1.2" xref="S3.E4.m2.3.3.1.1.2.cmml">​</mo><mi id="S3.E4.m2.3.3.1.1.4" xref="S3.E4.m2.3.3.1.1.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.3.3.1.1.2a" xref="S3.E4.m2.3.3.1.1.2.cmml">​</mo><mi id="S3.E4.m2.3.3.1.1.5" xref="S3.E4.m2.3.3.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.3.3.1.1.2b" xref="S3.E4.m2.3.3.1.1.2.cmml">​</mo><mi id="S3.E4.m2.3.3.1.1.6" xref="S3.E4.m2.3.3.1.1.6.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.3.3.1.1.2c" xref="S3.E4.m2.3.3.1.1.2.cmml">​</mo><mrow id="S3.E4.m2.3.3.1.1.1.1" xref="S3.E4.m2.3.3.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m2.3.3.1.1.1.1.2" xref="S3.E4.m2.3.3.1.1.1.2.cmml">(</mo><msub id="S3.E4.m2.3.3.1.1.1.1.1" xref="S3.E4.m2.3.3.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.3.3.1.1.1.1.1.2" xref="S3.E4.m2.3.3.1.1.1.1.1.2a.cmml">E</mtext><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.3.3.1.1.1.1.1.3" xref="S3.E4.m2.3.3.1.1.1.1.1.3a.cmml">Y</mtext></msub><mo id="S3.E4.m2.3.3.1.1.1.1.3" xref="S3.E4.m2.3.3.1.1.1.2.cmml">,</mo><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.1.1" xref="S3.E4.m2.1.1a.cmml">H</mtext><mo stretchy="false" id="S3.E4.m2.3.3.1.1.1.1.4" xref="S3.E4.m2.3.3.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m2.4.4.2.3" xref="S3.E4.m2.4.4.2.3.cmml">+</mo><mrow id="S3.E4.m2.4.4.2.2" xref="S3.E4.m2.4.4.2.2.cmml"><mi id="S3.E4.m2.4.4.2.2.3" xref="S3.E4.m2.4.4.2.2.3.cmml">b</mi><mo lspace="0.500em" rspace="0em" id="S3.E4.m2.4.4.2.2.2" xref="S3.E4.m2.4.4.2.2.2.cmml">​</mo><mi id="S3.E4.m2.4.4.2.2.4" xref="S3.E4.m2.4.4.2.2.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.4.4.2.2.2a" xref="S3.E4.m2.4.4.2.2.2.cmml">​</mo><mi id="S3.E4.m2.4.4.2.2.5" xref="S3.E4.m2.4.4.2.2.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.4.4.2.2.2b" xref="S3.E4.m2.4.4.2.2.2.cmml">​</mo><mi id="S3.E4.m2.4.4.2.2.6" xref="S3.E4.m2.4.4.2.2.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.4.4.2.2.2c" xref="S3.E4.m2.4.4.2.2.2.cmml">​</mo><mi id="S3.E4.m2.4.4.2.2.7" xref="S3.E4.m2.4.4.2.2.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.4.4.2.2.2d" xref="S3.E4.m2.4.4.2.2.2.cmml">​</mo><mi id="S3.E4.m2.4.4.2.2.8" xref="S3.E4.m2.4.4.2.2.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.4.4.2.2.2e" xref="S3.E4.m2.4.4.2.2.2.cmml">​</mo><mi id="S3.E4.m2.4.4.2.2.9" xref="S3.E4.m2.4.4.2.2.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m2.4.4.2.2.2f" xref="S3.E4.m2.4.4.2.2.2.cmml">​</mo><mrow id="S3.E4.m2.4.4.2.2.1.1" xref="S3.E4.m2.4.4.2.2.1.2.cmml"><mo stretchy="false" id="S3.E4.m2.4.4.2.2.1.1.2" xref="S3.E4.m2.4.4.2.2.1.2.cmml">(</mo><msub id="S3.E4.m2.4.4.2.2.1.1.1" xref="S3.E4.m2.4.4.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.4.4.2.2.1.1.1.2" xref="S3.E4.m2.4.4.2.2.1.1.1.2a.cmml">E</mtext><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.4.4.2.2.1.1.1.3" xref="S3.E4.m2.4.4.2.2.1.1.1.3a.cmml">Y</mtext></msub><mo id="S3.E4.m2.4.4.2.2.1.1.3" xref="S3.E4.m2.4.4.2.2.1.2.cmml">,</mo><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.2.2" xref="S3.E4.m2.2.2a.cmml">H</mtext><mo stretchy="false" id="S3.E4.m2.4.4.2.2.1.1.4" xref="S3.E4.m2.4.4.2.2.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m2.4b"><apply id="S3.E4.m2.4.4.cmml" xref="S3.E4.m2.4.4"><eq id="S3.E4.m2.4.4.3.cmml" xref="S3.E4.m2.4.4.3"></eq><csymbol cd="latexml" id="S3.E4.m2.4.4.4.cmml" xref="S3.E4.m2.4.4.4">absent</csymbol><apply id="S3.E4.m2.4.4.2.cmml" xref="S3.E4.m2.4.4.2"><plus id="S3.E4.m2.4.4.2.3.cmml" xref="S3.E4.m2.4.4.2.3"></plus><apply id="S3.E4.m2.3.3.1.1.cmml" xref="S3.E4.m2.3.3.1.1"><times id="S3.E4.m2.3.3.1.1.2.cmml" xref="S3.E4.m2.3.3.1.1.2"></times><ci id="S3.E4.m2.3.3.1.1.3.cmml" xref="S3.E4.m2.3.3.1.1.3">𝑎</ci><ci id="S3.E4.m2.3.3.1.1.4.cmml" xref="S3.E4.m2.3.3.1.1.4">𝑀</ci><ci id="S3.E4.m2.3.3.1.1.5.cmml" xref="S3.E4.m2.3.3.1.1.5">𝑆</ci><ci id="S3.E4.m2.3.3.1.1.6.cmml" xref="S3.E4.m2.3.3.1.1.6">𝐸</ci><interval closure="open" id="S3.E4.m2.3.3.1.1.1.2.cmml" xref="S3.E4.m2.3.3.1.1.1.1"><apply id="S3.E4.m2.3.3.1.1.1.1.1.cmml" xref="S3.E4.m2.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m2.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m2.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m2.3.3.1.1.1.1.1.2a.cmml" xref="S3.E4.m2.3.3.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.3.3.1.1.1.1.1.2.cmml" xref="S3.E4.m2.3.3.1.1.1.1.1.2">E</mtext></ci><ci id="S3.E4.m2.3.3.1.1.1.1.1.3a.cmml" xref="S3.E4.m2.3.3.1.1.1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E4.m2.3.3.1.1.1.1.1.3.cmml" xref="S3.E4.m2.3.3.1.1.1.1.1.3">Y</mtext></ci></apply><ci id="S3.E4.m2.1.1a.cmml" xref="S3.E4.m2.1.1"><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.1.1.cmml" xref="S3.E4.m2.1.1">H</mtext></ci></interval></apply><apply id="S3.E4.m2.4.4.2.2.cmml" xref="S3.E4.m2.4.4.2.2"><times id="S3.E4.m2.4.4.2.2.2.cmml" xref="S3.E4.m2.4.4.2.2.2"></times><ci id="S3.E4.m2.4.4.2.2.3.cmml" xref="S3.E4.m2.4.4.2.2.3">𝑏</ci><ci id="S3.E4.m2.4.4.2.2.4.cmml" xref="S3.E4.m2.4.4.2.2.4">𝐶</ci><ci id="S3.E4.m2.4.4.2.2.5.cmml" xref="S3.E4.m2.4.4.2.2.5">𝑜</ci><ci id="S3.E4.m2.4.4.2.2.6.cmml" xref="S3.E4.m2.4.4.2.2.6">𝑠</ci><ci id="S3.E4.m2.4.4.2.2.7.cmml" xref="S3.E4.m2.4.4.2.2.7">𝑖</ci><ci id="S3.E4.m2.4.4.2.2.8.cmml" xref="S3.E4.m2.4.4.2.2.8">𝑛</ci><ci id="S3.E4.m2.4.4.2.2.9.cmml" xref="S3.E4.m2.4.4.2.2.9">𝑒</ci><interval closure="open" id="S3.E4.m2.4.4.2.2.1.2.cmml" xref="S3.E4.m2.4.4.2.2.1.1"><apply id="S3.E4.m2.4.4.2.2.1.1.1.cmml" xref="S3.E4.m2.4.4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m2.4.4.2.2.1.1.1.1.cmml" xref="S3.E4.m2.4.4.2.2.1.1.1">subscript</csymbol><ci id="S3.E4.m2.4.4.2.2.1.1.1.2a.cmml" xref="S3.E4.m2.4.4.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.4.4.2.2.1.1.1.2.cmml" xref="S3.E4.m2.4.4.2.2.1.1.1.2">E</mtext></ci><ci id="S3.E4.m2.4.4.2.2.1.1.1.3a.cmml" xref="S3.E4.m2.4.4.2.2.1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S3.E4.m2.4.4.2.2.1.1.1.3.cmml" xref="S3.E4.m2.4.4.2.2.1.1.1.3">Y</mtext></ci></apply><ci id="S3.E4.m2.2.2a.cmml" xref="S3.E4.m2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E4.m2.2.2.cmml" xref="S3.E4.m2.2.2">H</mtext></ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m2.4c">\displaystyle=a\ MSE(\textbf{E}_{\textbf{Y}},\textbf{H})+b\ Cosine(\textbf{E}_{\textbf{Y}},\textbf{H})\vspace{-0.3cm}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.12" class="ltx_p">where <math id="S3.SS2.p3.6.m1.1" class="ltx_Math" alttext="Emb" display="inline"><semantics id="S3.SS2.p3.6.m1.1a"><mrow id="S3.SS2.p3.6.m1.1.1" xref="S3.SS2.p3.6.m1.1.1.cmml"><mi id="S3.SS2.p3.6.m1.1.1.2" xref="S3.SS2.p3.6.m1.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m1.1.1.1" xref="S3.SS2.p3.6.m1.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.6.m1.1.1.3" xref="S3.SS2.p3.6.m1.1.1.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m1.1.1.1a" xref="S3.SS2.p3.6.m1.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.6.m1.1.1.4" xref="S3.SS2.p3.6.m1.1.1.4.cmml">b</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m1.1b"><apply id="S3.SS2.p3.6.m1.1.1.cmml" xref="S3.SS2.p3.6.m1.1.1"><times id="S3.SS2.p3.6.m1.1.1.1.cmml" xref="S3.SS2.p3.6.m1.1.1.1"></times><ci id="S3.SS2.p3.6.m1.1.1.2.cmml" xref="S3.SS2.p3.6.m1.1.1.2">𝐸</ci><ci id="S3.SS2.p3.6.m1.1.1.3.cmml" xref="S3.SS2.p3.6.m1.1.1.3">𝑚</ci><ci id="S3.SS2.p3.6.m1.1.1.4.cmml" xref="S3.SS2.p3.6.m1.1.1.4">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m1.1c">Emb</annotation></semantics></math>, <math id="S3.SS2.p3.7.m2.1" class="ltx_Math" alttext="Enc" display="inline"><semantics id="S3.SS2.p3.7.m2.1a"><mrow id="S3.SS2.p3.7.m2.1.1" xref="S3.SS2.p3.7.m2.1.1.cmml"><mi id="S3.SS2.p3.7.m2.1.1.2" xref="S3.SS2.p3.7.m2.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m2.1.1.1" xref="S3.SS2.p3.7.m2.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.7.m2.1.1.3" xref="S3.SS2.p3.7.m2.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m2.1.1.1a" xref="S3.SS2.p3.7.m2.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.7.m2.1.1.4" xref="S3.SS2.p3.7.m2.1.1.4.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m2.1b"><apply id="S3.SS2.p3.7.m2.1.1.cmml" xref="S3.SS2.p3.7.m2.1.1"><times id="S3.SS2.p3.7.m2.1.1.1.cmml" xref="S3.SS2.p3.7.m2.1.1.1"></times><ci id="S3.SS2.p3.7.m2.1.1.2.cmml" xref="S3.SS2.p3.7.m2.1.1.2">𝐸</ci><ci id="S3.SS2.p3.7.m2.1.1.3.cmml" xref="S3.SS2.p3.7.m2.1.1.3">𝑛</ci><ci id="S3.SS2.p3.7.m2.1.1.4.cmml" xref="S3.SS2.p3.7.m2.1.1.4">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m2.1c">Enc</annotation></semantics></math>, <math id="S3.SS2.p3.8.m3.1" class="ltx_Math" alttext="Adapt" display="inline"><semantics id="S3.SS2.p3.8.m3.1a"><mrow id="S3.SS2.p3.8.m3.1.1" xref="S3.SS2.p3.8.m3.1.1.cmml"><mi id="S3.SS2.p3.8.m3.1.1.2" xref="S3.SS2.p3.8.m3.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.8.m3.1.1.1" xref="S3.SS2.p3.8.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.8.m3.1.1.3" xref="S3.SS2.p3.8.m3.1.1.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.8.m3.1.1.1a" xref="S3.SS2.p3.8.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.8.m3.1.1.4" xref="S3.SS2.p3.8.m3.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.8.m3.1.1.1b" xref="S3.SS2.p3.8.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.8.m3.1.1.5" xref="S3.SS2.p3.8.m3.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.8.m3.1.1.1c" xref="S3.SS2.p3.8.m3.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.8.m3.1.1.6" xref="S3.SS2.p3.8.m3.1.1.6.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m3.1b"><apply id="S3.SS2.p3.8.m3.1.1.cmml" xref="S3.SS2.p3.8.m3.1.1"><times id="S3.SS2.p3.8.m3.1.1.1.cmml" xref="S3.SS2.p3.8.m3.1.1.1"></times><ci id="S3.SS2.p3.8.m3.1.1.2.cmml" xref="S3.SS2.p3.8.m3.1.1.2">𝐴</ci><ci id="S3.SS2.p3.8.m3.1.1.3.cmml" xref="S3.SS2.p3.8.m3.1.1.3">𝑑</ci><ci id="S3.SS2.p3.8.m3.1.1.4.cmml" xref="S3.SS2.p3.8.m3.1.1.4">𝑎</ci><ci id="S3.SS2.p3.8.m3.1.1.5.cmml" xref="S3.SS2.p3.8.m3.1.1.5">𝑝</ci><ci id="S3.SS2.p3.8.m3.1.1.6.cmml" xref="S3.SS2.p3.8.m3.1.1.6">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m3.1c">Adapt</annotation></semantics></math> are LLM embedding, encoder and adapter functions respectively; <math id="S3.SS2.p3.9.m4.1" class="ltx_Math" alttext="d_{llm}" display="inline"><semantics id="S3.SS2.p3.9.m4.1a"><msub id="S3.SS2.p3.9.m4.1.1" xref="S3.SS2.p3.9.m4.1.1.cmml"><mi id="S3.SS2.p3.9.m4.1.1.2" xref="S3.SS2.p3.9.m4.1.1.2.cmml">d</mi><mrow id="S3.SS2.p3.9.m4.1.1.3" xref="S3.SS2.p3.9.m4.1.1.3.cmml"><mi id="S3.SS2.p3.9.m4.1.1.3.2" xref="S3.SS2.p3.9.m4.1.1.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.9.m4.1.1.3.1" xref="S3.SS2.p3.9.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.9.m4.1.1.3.3" xref="S3.SS2.p3.9.m4.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.9.m4.1.1.3.1a" xref="S3.SS2.p3.9.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p3.9.m4.1.1.3.4" xref="S3.SS2.p3.9.m4.1.1.3.4.cmml">m</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m4.1b"><apply id="S3.SS2.p3.9.m4.1.1.cmml" xref="S3.SS2.p3.9.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m4.1.1.1.cmml" xref="S3.SS2.p3.9.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.9.m4.1.1.2.cmml" xref="S3.SS2.p3.9.m4.1.1.2">𝑑</ci><apply id="S3.SS2.p3.9.m4.1.1.3.cmml" xref="S3.SS2.p3.9.m4.1.1.3"><times id="S3.SS2.p3.9.m4.1.1.3.1.cmml" xref="S3.SS2.p3.9.m4.1.1.3.1"></times><ci id="S3.SS2.p3.9.m4.1.1.3.2.cmml" xref="S3.SS2.p3.9.m4.1.1.3.2">𝑙</ci><ci id="S3.SS2.p3.9.m4.1.1.3.3.cmml" xref="S3.SS2.p3.9.m4.1.1.3.3">𝑙</ci><ci id="S3.SS2.p3.9.m4.1.1.3.4.cmml" xref="S3.SS2.p3.9.m4.1.1.3.4">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m4.1c">d_{llm}</annotation></semantics></math> is the LLM hidden dimension; <math id="S3.SS2.p3.10.m5.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.SS2.p3.10.m5.1a"><mi id="S3.SS2.p3.10.m5.1.1" xref="S3.SS2.p3.10.m5.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m5.1b"><ci id="S3.SS2.p3.10.m5.1.1.cmml" xref="S3.SS2.p3.10.m5.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m5.1c">a</annotation></semantics></math> and <math id="S3.SS2.p3.11.m6.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S3.SS2.p3.11.m6.1a"><mi id="S3.SS2.p3.11.m6.1.1" xref="S3.SS2.p3.11.m6.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m6.1b"><ci id="S3.SS2.p3.11.m6.1.1.cmml" xref="S3.SS2.p3.11.m6.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m6.1c">b</annotation></semantics></math> are tunable hyper-parameters. The model is then trained using a combination of cross-entropy and <math id="S3.SS2.p3.12.m7.1" class="ltx_Math" alttext="L_{m}" display="inline"><semantics id="S3.SS2.p3.12.m7.1a"><msub id="S3.SS2.p3.12.m7.1.1" xref="S3.SS2.p3.12.m7.1.1.cmml"><mi id="S3.SS2.p3.12.m7.1.1.2" xref="S3.SS2.p3.12.m7.1.1.2.cmml">L</mi><mi id="S3.SS2.p3.12.m7.1.1.3" xref="S3.SS2.p3.12.m7.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m7.1b"><apply id="S3.SS2.p3.12.m7.1.1.cmml" xref="S3.SS2.p3.12.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.12.m7.1.1.1.cmml" xref="S3.SS2.p3.12.m7.1.1">subscript</csymbol><ci id="S3.SS2.p3.12.m7.1.1.2.cmml" xref="S3.SS2.p3.12.m7.1.1.2">𝐿</ci><ci id="S3.SS2.p3.12.m7.1.1.3.cmml" xref="S3.SS2.p3.12.m7.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m7.1c">L_{m}</annotation></semantics></math> losses.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Inference and training methods to reduce insertion errors</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">When analyzing model inference using the standard beam search algorithm, we found that models trained with a small amount of data, i.e. 10h, produced relatively high insertion errors. More importantly, when testing the robustness of our model on several out-of-domain test sets, we observed more severe insertion problems. Specifically, in these cases, models repeat an n-gram until reaching the output length limit.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">To alleviate insertion errors, one straightforward approach is to apply following constraints during beam search inference:</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p">Apply n-gram non-repetition constraint (denoted as NRNS): This constraint ensures that n-gram tokens of a specified length, e.g., 5, do not repeat during decoding.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p">Apply length penalty (denoted as LP): This method imposes a greater penalty on long decoding transcripts, thereby reducing insertion errors.</p>
</div>
</li>
</ul>
<p id="S3.SS3.p2.2" class="ltx_p">Note that we utilize a publicly available LLM model from Hugging Face, where the above constraints are readily provided as options, namely, 'no_repeat_ngram_size' and 'length_penalty' <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://huggingface.co/docs/transformers/en/main_classes/text_generation</span></span></span>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">We observed that after applying inference constraints, insertion errors still persist substantially on out-of-domain test sets. We also noticed that the repetition problem frequently occurs in audio trunks containing only non-speech signals such as music or noise. We propose to apply the following training methods to address the insertion issue.</p>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p">Data augmentation (referred to as DA): To enhance the system's robustness against variations in acoustic conditions and speaking styles, we perform data augmentation to introduce diverse acoustic conditions during training. Our data augmentation includes volume perturbation and speed perturbation, which are applied with certain probabilities. We refrain from adding random noise or music to training utterances, as we observed that it negatively impacts performance.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p">Fine-tuning a pre-trained model using non-speech segments with empty transcripts (referred to as NSET): Ideally, a model should not generate any output for audio trunks containing non-speech signals. We achieve this by augmenting the ASR training data with a non-speech corpus containing audio segments with empty transcripts. Subsequently, we fine-tune already trained models for a short duration.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental setup</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We conducted experiments using the LibriSpeech corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. In addition to training on the full 960h dataset, we trained models on two subsets: train-clean 100h and 10h. We report Word Error Rate (WER) results on the LibriSpeech dev-clean, dev-other, test-clean, and test-other sets. To assess model robustness, we also report results on two out-of-domain test sets: CoVoST2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and GigaSpeech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. For NSET training, we utilized the noise and music subsets of the Musan <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> corpus to construct the non-speech corpus.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model settings</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We utilized the hubert-large-ll60k model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> (300M parameters) and the Vicuna vicuna-7b-v1.5 model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> (7B parameters) from the Hugging Face website as the speech encoder and LLM, respectively. The encoder and LLM have hidden dimensions of 1024 and 4096, respectively. For the adapter, the 1D convolution has input and output channels of 1024 and 4096, respectively, and performs 8 times subsampling. The linear transformations in Conv1dMLP and DwsMLP have input and output dimensions of 4096. Consequently, Conv1dMLP has 48M parameters, while DwsMLP employs depthwise separable convolution, resulting in only 20M parameters. Conv1dTransformer, however, employs 2 layers of Transformer with a hidden dimension of 4096 and FFN dimension 2.5x larger, i.e., 10240, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Consequently, Conv1dTransformer has 320M parameters, significantly more than the other two adapter types.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.2" class="ltx_p">For LoRa of the encoder, we implement <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\{r=8,\alpha=16\}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p2.1.m1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">{</mo><mrow id="S4.SS2.p2.1.m1.1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.1.1.3.cmml"><mrow id="S4.SS2.p2.1.m1.1.1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1.2.cmml">r</mi><mo id="S4.SS2.p2.1.m1.1.1.1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml">=</mo><mn id="S4.SS2.p2.1.m1.1.1.1.1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1.3.cmml">8</mn></mrow><mo id="S4.SS2.p2.1.m1.1.1.1.1.2.3" xref="S4.SS2.p2.1.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S4.SS2.p2.1.m1.1.1.1.1.2.2" xref="S4.SS2.p2.1.m1.1.1.1.1.2.2.cmml"><mi id="S4.SS2.p2.1.m1.1.1.1.1.2.2.2" xref="S4.SS2.p2.1.m1.1.1.1.1.2.2.2.cmml">α</mi><mo id="S4.SS2.p2.1.m1.1.1.1.1.2.2.1" xref="S4.SS2.p2.1.m1.1.1.1.1.2.2.1.cmml">=</mo><mn id="S4.SS2.p2.1.m1.1.1.1.1.2.2.3" xref="S4.SS2.p2.1.m1.1.1.1.1.2.2.3.cmml">16</mn></mrow></mrow><mo stretchy="false" id="S4.SS2.p2.1.m1.1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><set id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1"><apply id="S4.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.1.3a.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S4.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1"><eq id="S4.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1.1"></eq><ci id="S4.SS2.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1.2">𝑟</ci><cn type="integer" id="S4.SS2.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1.3">8</cn></apply><apply id="S4.SS2.p2.1.m1.1.1.1.1.2.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2.2"><eq id="S4.SS2.p2.1.m1.1.1.1.1.2.2.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2.2.1"></eq><ci id="S4.SS2.p2.1.m1.1.1.1.1.2.2.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2.2.2">𝛼</ci><cn type="integer" id="S4.SS2.p2.1.m1.1.1.1.1.2.2.3.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.2.2.3">16</cn></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\{r=8,\alpha=16\}</annotation></semantics></math> on the query and value matrices of the self-attention module at each layer, resulting in 0.65M parameters. As for the LLM, we employ <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="\{r=16,\alpha=16\}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mrow id="S4.SS2.p2.2.m2.1.1.1" xref="S4.SS2.p2.2.m2.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p2.2.m2.1.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">{</mo><mrow id="S4.SS2.p2.2.m2.1.1.1.1.2" xref="S4.SS2.p2.2.m2.1.1.1.1.3.cmml"><mrow id="S4.SS2.p2.2.m2.1.1.1.1.1.1" xref="S4.SS2.p2.2.m2.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.1.1.1.1.2" xref="S4.SS2.p2.2.m2.1.1.1.1.1.1.2.cmml">r</mi><mo id="S4.SS2.p2.2.m2.1.1.1.1.1.1.1" xref="S4.SS2.p2.2.m2.1.1.1.1.1.1.1.cmml">=</mo><mn id="S4.SS2.p2.2.m2.1.1.1.1.1.1.3" xref="S4.SS2.p2.2.m2.1.1.1.1.1.1.3.cmml">16</mn></mrow><mo id="S4.SS2.p2.2.m2.1.1.1.1.2.3" xref="S4.SS2.p2.2.m2.1.1.1.1.3a.cmml">,</mo><mrow id="S4.SS2.p2.2.m2.1.1.1.1.2.2" xref="S4.SS2.p2.2.m2.1.1.1.1.2.2.cmml"><mi id="S4.SS2.p2.2.m2.1.1.1.1.2.2.2" xref="S4.SS2.p2.2.m2.1.1.1.1.2.2.2.cmml">α</mi><mo id="S4.SS2.p2.2.m2.1.1.1.1.2.2.1" xref="S4.SS2.p2.2.m2.1.1.1.1.2.2.1.cmml">=</mo><mn id="S4.SS2.p2.2.m2.1.1.1.1.2.2.3" xref="S4.SS2.p2.2.m2.1.1.1.1.2.2.3.cmml">16</mn></mrow></mrow><mo stretchy="false" id="S4.SS2.p2.2.m2.1.1.1.3" xref="S4.SS2.p2.2.m2.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><set id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.1"><apply id="S4.SS2.p2.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.1.3a.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S4.SS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.1.1"><eq id="S4.SS2.p2.2.m2.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.1.1.1"></eq><ci id="S4.SS2.p2.2.m2.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.1.1.2">𝑟</ci><cn type="integer" id="S4.SS2.p2.2.m2.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.1.1.3">16</cn></apply><apply id="S4.SS2.p2.2.m2.1.1.1.1.2.2.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.2.2"><eq id="S4.SS2.p2.2.m2.1.1.1.1.2.2.1.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.2.2.1"></eq><ci id="S4.SS2.p2.2.m2.1.1.1.1.2.2.2.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.2.2.2">𝛼</ci><cn type="integer" id="S4.SS2.p2.2.m2.1.1.1.1.2.2.3.cmml" xref="S4.SS2.p2.2.m2.1.1.1.1.2.2.3">16</cn></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">\{r=16,\alpha=16\}</annotation></semantics></math> across all query, key, and value matrices of the self-attention, yielding 16M parameters.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Table <a href="#S4.T1" title="Table 1 ‣ 4.2 Model settings ‣ 4 Experimental setup ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents all fine-tuning schemes, each corresponding to a specific configuration of each module. Due to the large number of configurations, we only explore adapter variants under two conditions: (1) with both encoder and decoder frozen, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>; (2) with both encoder and decoder fine-tuned using the LoRa method.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.3.2" class="ltx_text" style="font-size:90%;">Different fine-tuning configurations</span></figcaption>
<table id="S4.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.4.1.1" class="ltx_tr">
<th id="S4.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">SID</th>
<th id="S4.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">Encoder</th>
<th id="S4.T1.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">Adapter</th>
<th id="S4.T1.4.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">LLM</th>
<th id="S4.T1.4.1.1.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">Params</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.4.2.1" class="ltx_tr">
<td id="S4.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:-0.5pt 6.8pt;">S1</td>
<td id="S4.T1.4.2.1.2" class="ltx_td ltx_align_left ltx_border_t" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.2.1.3" class="ltx_td ltx_align_left ltx_border_t" style="padding:-0.5pt 6.8pt;">Conv1dMLP</td>
<td id="S4.T1.4.2.1.4" class="ltx_td ltx_align_left ltx_border_t" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.2.1.5" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 6.8pt;">48M</td>
</tr>
<tr id="S4.T1.4.3.2" class="ltx_tr">
<td id="S4.T1.4.3.2.1" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">S2</td>
<td id="S4.T1.4.3.2.2" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.3.2.3" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Conv1dMLP</td>
<td id="S4.T1.4.3.2.4" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.3.2.5" class="ltx_td ltx_align_right" style="padding:-0.5pt 6.8pt;">64M</td>
</tr>
<tr id="S4.T1.4.4.3" class="ltx_tr">
<td id="S4.T1.4.4.3.1" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">S3</td>
<td id="S4.T1.4.4.3.2" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.4.3.3" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Conv1dMLP</td>
<td id="S4.T1.4.4.3.4" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.4.3.5" class="ltx_td ltx_align_right" style="padding:-0.5pt 6.8pt;">49M</td>
</tr>
<tr id="S4.T1.4.5.4" class="ltx_tr">
<td id="S4.T1.4.5.4.1" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">S4</td>
<td id="S4.T1.4.5.4.2" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.5.4.3" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Conv1dMLP</td>
<td id="S4.T1.4.5.4.4" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.5.4.5" class="ltx_td ltx_align_right" style="padding:-0.5pt 6.8pt;">65M</td>
</tr>
<tr id="S4.T1.4.6.5" class="ltx_tr">
<td id="S4.T1.4.6.5.1" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">S5</td>
<td id="S4.T1.4.6.5.2" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Full</td>
<td id="S4.T1.4.6.5.3" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Conv1dMLP</td>
<td id="S4.T1.4.6.5.4" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.6.5.5" class="ltx_td ltx_align_right" style="padding:-0.5pt 6.8pt;">345M</td>
</tr>
<tr id="S4.T1.4.7.6" class="ltx_tr">
<td id="S4.T1.4.7.6.1" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">S6</td>
<td id="S4.T1.4.7.6.2" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Full</td>
<td id="S4.T1.4.7.6.3" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Conv1dMLP</td>
<td id="S4.T1.4.7.6.4" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.7.6.5" class="ltx_td ltx_align_right" style="padding:-0.5pt 6.8pt;">361M</td>
</tr>
<tr id="S4.T1.4.8.7" class="ltx_tr">
<td id="S4.T1.4.8.7.1" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">S7</td>
<td id="S4.T1.4.8.7.2" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.8.7.3" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">DwsMLP</td>
<td id="S4.T1.4.8.7.4" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.8.7.5" class="ltx_td ltx_align_right" style="padding:-0.5pt 6.8pt;">20M</td>
</tr>
<tr id="S4.T1.4.9.8" class="ltx_tr">
<td id="S4.T1.4.9.8.1" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">S8</td>
<td id="S4.T1.4.9.8.2" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.9.8.3" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Conv1dTransformer</td>
<td id="S4.T1.4.9.8.4" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">Frozen</td>
<td id="S4.T1.4.9.8.5" class="ltx_td ltx_align_right" style="padding:-0.5pt 6.8pt;">320M</td>
</tr>
<tr id="S4.T1.4.10.9" class="ltx_tr">
<td id="S4.T1.4.10.9.1" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">S9</td>
<td id="S4.T1.4.10.9.2" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.10.9.3" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">DwsMLP</td>
<td id="S4.T1.4.10.9.4" class="ltx_td ltx_align_left" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.10.9.5" class="ltx_td ltx_align_right" style="padding:-0.5pt 6.8pt;">37M</td>
</tr>
<tr id="S4.T1.4.11.10" class="ltx_tr">
<td id="S4.T1.4.11.10.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding:-0.5pt 6.8pt;">S10</td>
<td id="S4.T1.4.11.10.2" class="ltx_td ltx_align_left ltx_border_bb" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.11.10.3" class="ltx_td ltx_align_left ltx_border_bb" style="padding:-0.5pt 6.8pt;">Conv1dTransformer</td>
<td id="S4.T1.4.11.10.4" class="ltx_td ltx_align_left ltx_border_bb" style="padding:-0.5pt 6.8pt;">LoRa</td>
<td id="S4.T1.4.11.10.5" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 6.8pt;">337M</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Training and inference setting</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We trained our models on A100 GPUs for 50k, 20k, and 10k steps for 960h, 100h, and 10h datasets, respectively. Checkpoints were saved at every 1k steps for the 960h and 100h data and every 500 steps for the 10h data. Following training, we selected five consecutive checkpoints with the best averaged validation loss and averaged them for evaluation.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">In our initial experiments on the matching loss, we found that the best results were achieved with {a = 0.01, b = 0.04}, hence we use this setting for all experiments in Section <a href="#S3.SS2" title="3.2 Improving modalities alignment by matching loss ‣ 3 Proposed solution ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. For inference, we employed beam search with default settings from Hugging Face, i.e. {beam_size = 5, max_length = 256, NRNS = 0, LP = 1.0}</p>
</div>
<figure id="S4.T2" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.3.2" class="ltx_text" style="font-size:90%;">WER results of different fine-tuning configurations (a) and matching loss (b)</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S4.T2.4" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.4.1.1" class="ltx_tr">
<th id="S4.T2.4.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding:-0.5pt 3.7pt;"></th>
<th id="S4.T2.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding:-0.5pt 3.7pt;" colspan="4">960h training data</th>
<th id="S4.T2.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding:-0.5pt 3.7pt;" colspan="4">100h training data</th>
<th id="S4.T2.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 3.7pt;" colspan="4">10h training data</th>
</tr>
<tr id="S4.T2.4.2.2" class="ltx_tr">
<th id="S4.T2.4.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;"><span id="S4.T2.4.2.2.1.1" class="ltx_text">SID</span></th>
<th id="S4.T2.4.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-clean</th>
<th id="S4.T2.4.2.2.3" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-other</th>
<th id="S4.T2.4.2.2.4" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">test-clean</th>
<th id="S4.T2.4.2.2.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r" style="padding:-0.5pt 3.7pt;">test-other</th>
<th id="S4.T2.4.2.2.6" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-clean</th>
<th id="S4.T2.4.2.2.7" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-other</th>
<th id="S4.T2.4.2.2.8" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">test-clean</th>
<th id="S4.T2.4.2.2.9" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r" style="padding:-0.5pt 3.7pt;">test-other</th>
<th id="S4.T2.4.2.2.10" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-clean</th>
<th id="S4.T2.4.2.2.11" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-other</th>
<th id="S4.T2.4.2.2.12" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">test-clean</th>
<th id="S4.T2.4.2.2.13" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">test-other</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.4.3.1" class="ltx_tr">
<th id="S4.T2.4.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:-0.5pt 3.7pt;">S1</th>
<td id="S4.T2.4.3.1.2" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">2.38</td>
<td id="S4.T2.4.3.1.3" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">5.99</td>
<td id="S4.T2.4.3.1.4" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">2.29</td>
<td id="S4.T2.4.3.1.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:-0.5pt 3.7pt;">5.67</td>
<td id="S4.T2.4.3.1.6" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">3.55</td>
<td id="S4.T2.4.3.1.7" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">9.35</td>
<td id="S4.T2.4.3.1.8" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">4.23</td>
<td id="S4.T2.4.3.1.9" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:-0.5pt 3.7pt;">8.69</td>
<td id="S4.T2.4.3.1.10" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">11.96</td>
<td id="S4.T2.4.3.1.11" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">22.55</td>
<td id="S4.T2.4.3.1.12" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">14.51</td>
<td id="S4.T2.4.3.1.13" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">20.60</td>
</tr>
<tr id="S4.T2.4.4.2" class="ltx_tr">
<th id="S4.T2.4.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S2</th>
<td id="S4.T2.4.4.2.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.01</td>
<td id="S4.T2.4.4.2.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.71</td>
<td id="S4.T2.4.4.2.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.02</td>
<td id="S4.T2.4.4.2.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">4.31</td>
<td id="S4.T2.4.4.2.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.42</td>
<td id="S4.T2.4.4.2.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">6.34</td>
<td id="S4.T2.4.4.2.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.45</td>
<td id="S4.T2.4.4.2.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">7.19</td>
<td id="S4.T2.4.4.2.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">13.52</td>
<td id="S4.T2.4.4.2.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">21.45</td>
<td id="S4.T2.4.4.2.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">13.30</td>
<td id="S4.T2.4.4.2.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">18.75</td>
</tr>
<tr id="S4.T2.4.5.3" class="ltx_tr">
<th id="S4.T2.4.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S3</th>
<td id="S4.T2.4.5.3.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.87</td>
<td id="S4.T2.4.5.3.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.61</td>
<td id="S4.T2.4.5.3.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.79</td>
<td id="S4.T2.4.5.3.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">3.91</td>
<td id="S4.T2.4.5.3.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.86</td>
<td id="S4.T2.4.5.3.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">5.33</td>
<td id="S4.T2.4.5.3.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.70</td>
<td id="S4.T2.4.5.3.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">5.99</td>
<td id="S4.T2.4.5.3.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.36</td>
<td id="S4.T2.4.5.3.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">12.49</td>
<td id="S4.T2.4.5.3.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">6.74</td>
<td id="S4.T2.4.5.3.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">11.72</td>
</tr>
<tr id="S4.T2.4.6.4" class="ltx_tr">
<th id="S4.T2.4.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S4</th>
<td id="S4.T2.4.6.4.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.70</td>
<td id="S4.T2.4.6.4.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.59</td>
<td id="S4.T2.4.6.4.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.78</td>
<td id="S4.T2.4.6.4.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">3.62</td>
<td id="S4.T2.4.6.4.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.68</td>
<td id="S4.T2.4.6.4.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">5.64</td>
<td id="S4.T2.4.6.4.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.57</td>
<td id="S4.T2.4.6.4.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">5.27</td>
<td id="S4.T2.4.6.4.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.36</td>
<td id="S4.T2.4.6.4.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">11.92</td>
<td id="S4.T2.4.6.4.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.44</td>
<td id="S4.T2.4.6.4.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">11.49</td>
</tr>
<tr id="S4.T2.4.7.5" class="ltx_tr">
<th id="S4.T2.4.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S5</th>
<td id="S4.T2.4.7.5.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.72</td>
<td id="S4.T2.4.7.5.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.96</td>
<td id="S4.T2.4.7.5.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.70</td>
<td id="S4.T2.4.7.5.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">3.58</td>
<td id="S4.T2.4.7.5.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.51</td>
<td id="S4.T2.4.7.5.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.87</td>
<td id="S4.T2.4.7.5.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.86</td>
<td id="S4.T2.4.7.5.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">5.14</td>
<td id="S4.T2.4.7.5.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">6.27</td>
<td id="S4.T2.4.7.5.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">10.25</td>
<td id="S4.T2.4.7.5.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">5.75</td>
<td id="S4.T2.4.7.5.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">10.40</td>
</tr>
<tr id="S4.T2.4.8.6" class="ltx_tr">
<th id="S4.T2.4.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S6</th>
<td id="S4.T2.4.8.6.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.50</td>
<td id="S4.T2.4.8.6.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.21</td>
<td id="S4.T2.4.8.6.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.74</td>
<td id="S4.T2.4.8.6.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">3.16</td>
<td id="S4.T2.4.8.6.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.40</td>
<td id="S4.T2.4.8.6.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.55</td>
<td id="S4.T2.4.8.6.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.28</td>
<td id="S4.T2.4.8.6.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">4.92</td>
<td id="S4.T2.4.8.6.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">6.43</td>
<td id="S4.T2.4.8.6.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">8.08</td>
<td id="S4.T2.4.8.6.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.97</td>
<td id="S4.T2.4.8.6.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">9.11</td>
</tr>
<tr id="S4.T2.4.9.7" class="ltx_tr">
<th id="S4.T2.4.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S7</th>
<td id="S4.T2.4.9.7.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.34</td>
<td id="S4.T2.4.9.7.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.98</td>
<td id="S4.T2.4.9.7.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.26</td>
<td id="S4.T2.4.9.7.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">7.24</td>
<td id="S4.T2.4.9.7.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.65</td>
<td id="S4.T2.4.9.7.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.22</td>
<td id="S4.T2.4.9.7.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.19</td>
<td id="S4.T2.4.9.7.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">9.09</td>
<td id="S4.T2.4.9.7.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">12.12</td>
<td id="S4.T2.4.9.7.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">23.51</td>
<td id="S4.T2.4.9.7.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">12.30</td>
<td id="S4.T2.4.9.7.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">19.96</td>
</tr>
<tr id="S4.T2.4.10.8" class="ltx_tr">
<th id="S4.T2.4.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S8</th>
<td id="S4.T2.4.10.8.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.96</td>
<td id="S4.T2.4.10.8.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.13</td>
<td id="S4.T2.4.10.8.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.02</td>
<td id="S4.T2.4.10.8.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">4.41</td>
<td id="S4.T2.4.10.8.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.91</td>
<td id="S4.T2.4.10.8.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.31</td>
<td id="S4.T2.4.10.8.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.34</td>
<td id="S4.T2.4.10.8.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">8.25</td>
<td id="S4.T2.4.10.8.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">21.63</td>
<td id="S4.T2.4.10.8.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">31.06</td>
<td id="S4.T2.4.10.8.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">25.96</td>
<td id="S4.T2.4.10.8.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">34.72</td>
</tr>
<tr id="S4.T2.4.11.9" class="ltx_tr">
<th id="S4.T2.4.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S9</th>
<td id="S4.T2.4.11.9.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.61</td>
<td id="S4.T2.4.11.9.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.34</td>
<td id="S4.T2.4.11.9.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.59</td>
<td id="S4.T2.4.11.9.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">3.89</td>
<td id="S4.T2.4.11.9.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.72</td>
<td id="S4.T2.4.11.9.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">5.31</td>
<td id="S4.T2.4.11.9.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.66</td>
<td id="S4.T2.4.11.9.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">5.65</td>
<td id="S4.T2.4.11.9.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.23</td>
<td id="S4.T2.4.11.9.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">13.56</td>
<td id="S4.T2.4.11.9.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">8.12</td>
<td id="S4.T2.4.11.9.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">12.22</td>
</tr>
<tr id="S4.T2.4.12.10" class="ltx_tr">
<th id="S4.T2.4.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding:-0.5pt 3.7pt;">S10</th>
<td id="S4.T2.4.12.10.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">1.88</td>
<td id="S4.T2.4.12.10.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">3.83</td>
<td id="S4.T2.4.12.10.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">1.85</td>
<td id="S4.T2.4.12.10.5" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" style="padding:-0.5pt 3.7pt;">3.77</td>
<td id="S4.T2.4.12.10.6" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">3.62</td>
<td id="S4.T2.4.12.10.7" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">5.88</td>
<td id="S4.T2.4.12.10.8" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">3.80</td>
<td id="S4.T2.4.12.10.9" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" style="padding:-0.5pt 3.7pt;">5.90</td>
<td id="S4.T2.4.12.10.10" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">13.30</td>
<td id="S4.T2.4.12.10.11" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">19.22</td>
<td id="S4.T2.4.12.10.12" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">13.61</td>
<td id="S4.T2.4.12.10.13" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">18.55</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.5.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.T2.6.2" class="ltx_text" style="font-size:90%;">(a) Results of different fine-tuning configurations</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S4.T2.7" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.7.1.1" class="ltx_tr">
<th id="S4.T2.7.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding:-0.5pt 3.7pt;"></th>
<th id="S4.T2.7.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding:-0.5pt 3.7pt;" colspan="4">960h training data</th>
<th id="S4.T2.7.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding:-0.5pt 3.7pt;" colspan="4">100h training data</th>
<th id="S4.T2.7.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 3.7pt;" colspan="4">10h training data</th>
</tr>
<tr id="S4.T2.7.2.2" class="ltx_tr">
<th id="S4.T2.7.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;"><span id="S4.T2.7.2.2.1.1" class="ltx_text">SID</span></th>
<th id="S4.T2.7.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-clean</th>
<th id="S4.T2.7.2.2.3" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-other</th>
<th id="S4.T2.7.2.2.4" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">test-clean</th>
<th id="S4.T2.7.2.2.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r" style="padding:-0.5pt 3.7pt;">test-other</th>
<th id="S4.T2.7.2.2.6" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-clean</th>
<th id="S4.T2.7.2.2.7" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-other</th>
<th id="S4.T2.7.2.2.8" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">test-clean</th>
<th id="S4.T2.7.2.2.9" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r" style="padding:-0.5pt 3.7pt;">test-other</th>
<th id="S4.T2.7.2.2.10" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-clean</th>
<th id="S4.T2.7.2.2.11" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">dev-other</th>
<th id="S4.T2.7.2.2.12" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">test-clean</th>
<th id="S4.T2.7.2.2.13" class="ltx_td ltx_align_right ltx_th ltx_th_column" style="padding:-0.5pt 3.7pt;">test-other</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.7.3.1" class="ltx_tr">
<th id="S4.T2.7.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:-0.5pt 3.7pt;">S1</th>
<td id="S4.T2.7.3.1.2" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">2.38</td>
<td id="S4.T2.7.3.1.3" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">5.99</td>
<td id="S4.T2.7.3.1.4" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">2.29</td>
<td id="S4.T2.7.3.1.5" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:-0.5pt 3.7pt;">5.67</td>
<td id="S4.T2.7.3.1.6" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">3.55</td>
<td id="S4.T2.7.3.1.7" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">9.35</td>
<td id="S4.T2.7.3.1.8" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">4.23</td>
<td id="S4.T2.7.3.1.9" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:-0.5pt 3.7pt;">8.69</td>
<td id="S4.T2.7.3.1.10" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">11.96</td>
<td id="S4.T2.7.3.1.11" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">22.55</td>
<td id="S4.T2.7.3.1.12" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">14.51</td>
<td id="S4.T2.7.3.1.13" class="ltx_td ltx_align_right ltx_border_t" style="padding:-0.5pt 3.7pt;">20.60</td>
</tr>
<tr id="S4.T2.7.4.2" class="ltx_tr">
<th id="S4.T2.7.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">T1</th>
<td id="S4.T2.7.4.2.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.38</td>
<td id="S4.T2.7.4.2.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">5.33</td>
<td id="S4.T2.7.4.2.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.36</td>
<td id="S4.T2.7.4.2.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">4.81</td>
<td id="S4.T2.7.4.2.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">4.32</td>
<td id="S4.T2.7.4.2.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.31</td>
<td id="S4.T2.7.4.2.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.93</td>
<td id="S4.T2.7.4.2.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">6.93</td>
<td id="S4.T2.7.4.2.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">9.67</td>
<td id="S4.T2.7.4.2.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">15.93</td>
<td id="S4.T2.7.4.2.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">12.40</td>
<td id="S4.T2.7.4.2.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">15.02</td>
</tr>
<tr id="S4.T2.7.5.3" class="ltx_tr">
<th id="S4.T2.7.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:-0.5pt 3.7pt;">S4</th>
<td id="S4.T2.7.5.3.2" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.70</td>
<td id="S4.T2.7.5.3.3" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">3.59</td>
<td id="S4.T2.7.5.3.4" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">1.78</td>
<td id="S4.T2.7.5.3.5" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">3.62</td>
<td id="S4.T2.7.5.3.6" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.68</td>
<td id="S4.T2.7.5.3.7" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">5.64</td>
<td id="S4.T2.7.5.3.8" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">2.57</td>
<td id="S4.T2.7.5.3.9" class="ltx_td ltx_align_right ltx_border_r" style="padding:-0.5pt 3.7pt;">5.27</td>
<td id="S4.T2.7.5.3.10" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.36</td>
<td id="S4.T2.7.5.3.11" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">11.92</td>
<td id="S4.T2.7.5.3.12" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">7.44</td>
<td id="S4.T2.7.5.3.13" class="ltx_td ltx_align_right" style="padding:-0.5pt 3.7pt;">11.49</td>
</tr>
<tr id="S4.T2.7.6.4" class="ltx_tr">
<th id="S4.T2.7.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding:-0.5pt 3.7pt;">T4</th>
<td id="S4.T2.7.6.4.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">1.63</td>
<td id="S4.T2.7.6.4.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">3.47</td>
<td id="S4.T2.7.6.4.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">1.63</td>
<td id="S4.T2.7.6.4.5" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" style="padding:-0.5pt 3.7pt;">3.48</td>
<td id="S4.T2.7.6.4.6" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">2.58</td>
<td id="S4.T2.7.6.4.7" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">5.62</td>
<td id="S4.T2.7.6.4.8" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">2.59</td>
<td id="S4.T2.7.6.4.9" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" style="padding:-0.5pt 3.7pt;">5.26</td>
<td id="S4.T2.7.6.4.10" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">6.83</td>
<td id="S4.T2.7.6.4.11" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">10.34</td>
<td id="S4.T2.7.6.4.12" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">7.29</td>
<td id="S4.T2.7.6.4.13" class="ltx_td ltx_align_right ltx_border_bb" style="padding:-0.5pt 3.7pt;">10.60</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.8.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.T2.9.2" class="ltx_text" style="font-size:90%;">(b) Results with and without matching loss. S1 and S4 are systems without matching loss while T1 and T4 are systems with matching loss</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental results and analysis</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Results of different fine-tuning scheme</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Table <a href="#S4.T2" title="Table 2 ‣ 4.3 Training and inference setting ‣ 4 Experimental setup ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a) shows the results of different fine-tuning configurations which can be summarized as follows:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">Applying LoRa to LLM significantly enhances performance across most test sets, especially on dev/test-other. For instance, on the 960h condition, S2 surpasses S1 by 21.4%/24.0% relative WER reduction (WER reduced from 5.99%/5.67% to 4.71%/4.31%) on dev/test-other and by 15.6%/11.8% (WER reduced from 2.38%/2.29% to 2.01%/2.02%) on dev/test-clean subsets. We posit that the dev/test-other subsets present challenging cases in terms of both acoustic and linguistic conditions, and fine-tuning the LLM enables better adaptation to the LibriSpeech domain.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">In the encoder module, full fine-tuning yields the best outcomes, followed by partial fine-tuning with LoRa across all conditions. However, partial fine-tuning proves to be the most cost-effective. For instance, on 960h condition, partial fine-tuning S4 setting significantly outperforms the frozen setting S2 (WER reduced from 2.01%/4.71% to 1.70%/3.59% on dev-clean/other) while only adding 0.65M extra parameters.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">Regarding adapter achitectures, the Conv1dTransformer clearly outperforms Conv1dMLP when both encoder and LLM are frozen and trained with 960h data, but does not exhibit benefit in other conditions. The other variant, DwsMLP, is generally worse than Conv1dMLP in most of conditions.</p>
</div>
</li>
</ul>
<p id="S5.SS1.p1.2" class="ltx_p">In summary, fine-tuning both the encoder and LLM with LoRa and using Conv1dMLP as the adapter (S4 setting) achieves the optimal balance between performance and additional parameters. Thus, we employ S4 for subsequent experiments. Additionally, we utilize S1 for further experiments due to its crucial advantage: preserving all functionalities of the foundation encoder and LLM, which may be critical for certain applications.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Results of matching loss</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Table <a href="#S4.T2" title="Table 2 ‣ 4.3 Training and inference setting ‣ 4 Experimental setup ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(b) presents the results of systems with and without matching loss. S1 and S4 are systems without matching loss taken from Table <a href="#S4.T2" title="Table 2 ‣ 4.3 Training and inference setting ‣ 4 Experimental setup ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a), while T1 and T4 are corresponding systems with the matching loss.
The matching loss enhances performance across most conditions, with a more pronounced improvement observed in S1 compared to S4. This discrepancy may stem from the LoRa modules in both encoder and LLM components, which already aid in aligning acoustic and text representations, thereby diminishing the benefit from the matching loss.
Notably, the improvement on dev/test-other subsets exceeds that of dev/test-clean. This discrepancy can be attributed to the presence of challenging cases in dev/test-other, characterized by higher modality mismatch, which the matching loss mitigates, resulting in improved performance. We then take the best model, i.e. T4, for experiments in the next section.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Results of inference and training techniques</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We analyze the impact of NRNS and LP constraints on T4 models trained with 960h (full data) and 10h (low resource) on dev sets. We observe a consistent trend in the results of both dev-clean and dev-other, so we present only the results for dev-other in Table <a href="#S5.T3" title="Table 3 ‣ 5.3 Results of inference and training techniques ‣ 5 Experimental results and analysis ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We also report the insertion error rate (IER) in some cases for analysis. Each constraint helps to reduce IER in the 10h conditions. For instance, NRNS = 10 reduces IER from 1.88% to 0.89% on dev-other, resulting in a WER improvement from 10.35% to 9.35%. However, combining these constraints does not yield additional benefits, suggesting that LP and NRNS may not be complementary. Overall, the optimal setting is NRNS = 10, LP = 0.</p>
</div>
<figure id="S5.T3" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S5.T3.3.2" class="ltx_text" style="font-size:90%;">Effect of NRNS and LP on WER and IER of dev-other. IER are showed in parentheses</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S5.T3.4" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.4.1.1" class="ltx_tr">
<th id="S5.T3.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding:-0.5pt 6.8pt;">Data</th>
<th id="S5.T3.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">0</th>
<th id="S5.T3.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">5</th>
<th id="S5.T3.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">10</th>
<th id="S5.T3.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">15</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.4.2.1" class="ltx_tr">
<th id="S5.T3.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:-0.5pt 6.8pt;">960h</th>
<td id="S5.T3.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">3.47 (0.33)</td>
<td id="S5.T3.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">3.46</td>
<td id="S5.T3.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">3.44 (0.33)</td>
<td id="S5.T3.4.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">3.44</td>
</tr>
<tr id="S5.T3.4.3.2" class="ltx_tr">
<th id="S5.T3.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding:-0.5pt 6.8pt;">10h</th>
<td id="S5.T3.4.3.2.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:-0.5pt 6.8pt;">10.34 (1.88)</td>
<td id="S5.T3.4.3.2.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding:-0.5pt 6.8pt;">9.36</td>
<td id="S5.T3.4.3.2.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding:-0.5pt 6.8pt;">9.35 (0.89)</td>
<td id="S5.T3.4.3.2.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding:-0.5pt 6.8pt;">9.46</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.5.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.T3.6.2" class="ltx_text" style="font-size:90%;">(a) Effect of NRNS constraint on WER and IER</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S5.T3.7" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.7.1.1" class="ltx_tr">
<th id="S5.T3.7.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding:-0.5pt 6.8pt;">Data</th>
<th id="S5.T3.7.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding:-0.5pt 6.8pt;">NRNS</th>
<th id="S5.T3.7.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">1.0</th>
<th id="S5.T3.7.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">0.5</th>
<th id="S5.T3.7.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">0</th>
<th id="S5.T3.7.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 6.8pt;">-0.5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.7.2.1" class="ltx_tr">
<th id="S5.T3.7.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:-0.5pt 6.8pt;" rowspan="2"><span id="S5.T3.7.2.1.1.1" class="ltx_text">960h</span></th>
<th id="S5.T3.7.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding:-0.5pt 6.8pt;">0</th>
<td id="S5.T3.7.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">3.47 (0.33)</td>
<td id="S5.T3.7.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">3.49 (0.32)</td>
<td id="S5.T3.7.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">3.50</td>
<td id="S5.T3.7.2.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">3.50</td>
</tr>
<tr id="S5.T3.7.3.2" class="ltx_tr">
<th id="S5.T3.7.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" style="padding:-0.5pt 6.8pt;">10</th>
<td id="S5.T3.7.3.2.2" class="ltx_td ltx_align_center" style="padding:-0.5pt 6.8pt;">3.44 (0.33)</td>
<td id="S5.T3.7.3.2.3" class="ltx_td ltx_align_center" style="padding:-0.5pt 6.8pt;">3.46 (0.33)</td>
<td id="S5.T3.7.3.2.4" class="ltx_td ltx_align_center" style="padding:-0.5pt 6.8pt;">3.47</td>
<td id="S5.T3.7.3.2.5" class="ltx_td ltx_align_center" style="padding:-0.5pt 6.8pt;">3.49</td>
</tr>
<tr id="S5.T3.7.4.3" class="ltx_tr">
<th id="S5.T3.7.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding:-0.5pt 6.8pt;" rowspan="2"><span id="S5.T3.7.4.3.1.1" class="ltx_text">10h</span></th>
<th id="S5.T3.7.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding:-0.5pt 6.8pt;">0</th>
<td id="S5.T3.7.4.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">10.34 (1.88)</td>
<td id="S5.T3.7.4.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">9.44 (0.94)</td>
<td id="S5.T3.7.4.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">9.61</td>
<td id="S5.T3.7.4.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:-0.5pt 6.8pt;">9.71</td>
</tr>
<tr id="S5.T3.7.5.4" class="ltx_tr">
<th id="S5.T3.7.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" style="padding:-0.5pt 6.8pt;">10</th>
<td id="S5.T3.7.5.4.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding:-0.5pt 6.8pt;">9.35 (0.89)</td>
<td id="S5.T3.7.5.4.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding:-0.5pt 6.8pt;">9.35 (0.89)</td>
<td id="S5.T3.7.5.4.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding:-0.5pt 6.8pt;">9.51</td>
<td id="S5.T3.7.5.4.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding:-0.5pt 6.8pt;">9.61</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.8.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.T3.9.2" class="ltx_text" style="font-size:90%;">(b) Effect of the LP constraint on WER and IER</span></figcaption>
</figure>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">We assess the above constraints on test-clean, test-other, and two out-of-domain test sets. Results are summarized in Table <a href="#S5.T4" title="Table 4 ‣ 5.3 Results of inference and training techniques ‣ 5 Experimental results and analysis ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Applying constraints reduces IER and consequently enhances performance on in-domain test sets under the 10h training condition. Importantly, applying constraints significantly reduces IER on out-of-domain test sets for both 960h and 10h conditions. For instance, for the model trained with 960h, IER decreases from 33.06% to 14.52% in GigaSpeech, leading to a WER reduction from 46.42% to 27.83%.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S5.T4.3.2" class="ltx_text" style="font-size:90%;">WER and IER (showed in parentheses) on different test sets without and with contraints during inference.</span></figcaption>
<table id="S5.T4.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.4.1.1" class="ltx_tr">
<th id="S5.T4.4.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding:-0.5pt 1.4pt;">Data</th>
<th id="S5.T4.4.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.4pt;">Constraint</th>
<th id="S5.T4.4.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.4pt;">test-clean</th>
<th id="S5.T4.4.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.4pt;">test-other</th>
<th id="S5.T4.4.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.4pt;">CoVoST2</th>
<th id="S5.T4.4.1.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.4pt;">GigaSpeech</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.4.2.1" class="ltx_tr">
<th id="S5.T4.4.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:-0.5pt 1.4pt;" rowspan="2"><span id="S5.T4.4.2.1.1.1" class="ltx_text">960h</span></th>
<td id="S5.T4.4.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">No</td>
<td id="S5.T4.4.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">1.63 (0.15)</td>
<td id="S5.T4.4.2.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">3.48 (0.40)</td>
<td id="S5.T4.4.2.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">31.47 (16.94)</td>
<td id="S5.T4.4.2.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">46.42 (33.06)</td>
</tr>
<tr id="S5.T4.4.3.2" class="ltx_tr">
<td id="S5.T4.4.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.4pt;">Yes</td>
<td id="S5.T4.4.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.4pt;">1.63 (0.15)</td>
<td id="S5.T4.4.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.4pt;">3.49 (0.40)</td>
<td id="S5.T4.4.3.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.4pt;">19.73 (5.21)</td>
<td id="S5.T4.4.3.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.4pt;">27.83 (14.52)</td>
</tr>
<tr id="S5.T4.4.4.3" class="ltx_tr">
<th id="S5.T4.4.4.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding:-0.5pt 1.4pt;" rowspan="2"><span id="S5.T4.4.4.3.1.1" class="ltx_text">10h</span></th>
<td id="S5.T4.4.4.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">No</td>
<td id="S5.T4.4.4.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">7.29 (1.51)</td>
<td id="S5.T4.4.4.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">10.60 (1.83)</td>
<td id="S5.T4.4.4.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">47.89 (24.80)</td>
<td id="S5.T4.4.4.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.4pt;">59.67 (39.02)</td>
</tr>
<tr id="S5.T4.4.5.4" class="ltx_tr">
<td id="S5.T4.4.5.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.4pt;">Yes</td>
<td id="S5.T4.4.5.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.4pt;">6.37 (0.61)</td>
<td id="S5.T4.4.5.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.4pt;">9.73 (1.00)</td>
<td id="S5.T4.4.5.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.4pt;">33.09 (10.07)</td>
<td id="S5.T4.4.5.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.4pt;">44.39 (23.86)</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">We examine the effects of training methods: DA and NSET, summarized in Table <a href="#S5.T5" title="Table 5 ‣ 5.3 Results of inference and training techniques ‣ 5 Experimental results and analysis ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. DA significantly improves performance across all conditions, notably in low-resource training and out-of-domain evaluation scenarios. Notably, in scenarios like 960h training and testing on GigaSpeech, the reduction in IER is close to that of WER, indicating that most of the WER benefit stems from reduced insertion errors. Moreover, DA not only reduces insertion errors but also leads to fewer deletion/substitution errors in test-clean and test-other, particularly in the 10h condition. NSET training remarkably reduces insertion errors in out-of-domain test sets. However, this method sometime increases deletion errors resulting in higher WER, particularly in the 10h training condition. Although the combination of DA and NSET does not always yield the lowest insertion errors, it generally results in better WER due to fewer deletion errors. Overall, DA+NSET demonstrates increased robustness while effectively suppressing insertion errors, as demonstrated in an example from CoVoST2 corpus in Table <a href="#S5.T6" title="Table 6 ‣ 5.3 Results of inference and training techniques ‣ 5 Experimental results and analysis ‣ A Comprehensive Solution to Connect Speech Encoder and Large Language Model for ASR" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T5.2.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S5.T5.3.2" class="ltx_text" style="font-size:90%;">WER and IER (showed in parentheses) on different test sets with different training methods</span></figcaption>
<table id="S5.T5.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T5.4.1.1" class="ltx_tr">
<th id="S5.T5.4.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding:-0.5pt 1.1pt;">Data</th>
<th id="S5.T5.4.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.1pt;">Methods</th>
<th id="S5.T5.4.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.1pt;">test-clean</th>
<th id="S5.T5.4.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.1pt;">Test-other</th>
<th id="S5.T5.4.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.1pt;">CoVoST2</th>
<th id="S5.T5.4.1.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding:-0.5pt 1.1pt;">GigaSpeech</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T5.4.2.1" class="ltx_tr">
<th id="S5.T5.4.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding:-0.5pt 1.1pt;" rowspan="4"><span id="S5.T5.4.2.1.1.1" class="ltx_text">960h</span></th>
<td id="S5.T5.4.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">default</td>
<td id="S5.T5.4.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">1.63 (0.15)</td>
<td id="S5.T5.4.2.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">3.49 (0.40)</td>
<td id="S5.T5.4.2.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">19.73 (5.21)</td>
<td id="S5.T5.4.2.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">27.83 (14.52)</td>
</tr>
<tr id="S5.T5.4.3.2" class="ltx_tr">
<td id="S5.T5.4.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">DA</td>
<td id="S5.T5.4.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">1.61 (0.15)</td>
<td id="S5.T5.4.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">3.37 (0.39)</td>
<td id="S5.T5.4.3.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">18.93 (4.67)</td>
<td id="S5.T5.4.3.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">23.90 (10.81)</td>
</tr>
<tr id="S5.T5.4.4.3" class="ltx_tr">
<td id="S5.T5.4.4.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">NSET</td>
<td id="S5.T5.4.4.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">1.70 (0.16)</td>
<td id="S5.T5.4.4.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">3.53 (0.39)</td>
<td id="S5.T5.4.4.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">19.05 (3.77)</td>
<td id="S5.T5.4.4.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">16.78 (3.22)</td>
</tr>
<tr id="S5.T5.4.5.4" class="ltx_tr">
<td id="S5.T5.4.5.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">DA+NSET</td>
<td id="S5.T5.4.5.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">1.67 (0.15)</td>
<td id="S5.T5.4.5.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">3.48 (0.41)</td>
<td id="S5.T5.4.5.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">18.40 (3.79)</td>
<td id="S5.T5.4.5.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">16.58 (3.33)</td>
</tr>
<tr id="S5.T5.4.6.5" class="ltx_tr">
<th id="S5.T5.4.6.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding:-0.5pt 1.1pt;" rowspan="4"><span id="S5.T5.4.6.5.1.1" class="ltx_text">10h</span></th>
<td id="S5.T5.4.6.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">default</td>
<td id="S5.T5.4.6.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">6.37 (0.61)</td>
<td id="S5.T5.4.6.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">9.73 (1.00)</td>
<td id="S5.T5.4.6.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">33.09 (10.07)</td>
<td id="S5.T5.4.6.5.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding:-0.5pt 1.1pt;">44.39 (23.86)</td>
</tr>
<tr id="S5.T5.4.7.6" class="ltx_tr">
<td id="S5.T5.4.7.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">DA</td>
<td id="S5.T5.4.7.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">5.36 (0.46)</td>
<td id="S5.T5.4.7.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">8.65 (0.83)</td>
<td id="S5.T5.4.7.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">31.25 (9.20)</td>
<td id="S5.T5.4.7.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">40.73 (21.51)</td>
</tr>
<tr id="S5.T5.4.8.7" class="ltx_tr">
<td id="S5.T5.4.8.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">NSET</td>
<td id="S5.T5.4.8.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">7.05 (0.60)</td>
<td id="S5.T5.4.8.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">10.57 (1.06)</td>
<td id="S5.T5.4.8.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">32.84 (8.44)</td>
<td id="S5.T5.4.8.7.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:-0.5pt 1.1pt;">26.36 (5.56)</td>
</tr>
<tr id="S5.T5.4.9.8" class="ltx_tr">
<td id="S5.T5.4.9.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.1pt;">DA+NSET</td>
<td id="S5.T5.4.9.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.1pt;">5.80 (0.48)</td>
<td id="S5.T5.4.9.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.1pt;">9.13 (0.94)</td>
<td id="S5.T5.4.9.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.1pt;">31.40 (8.02)</td>
<td id="S5.T5.4.9.8.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:-0.5pt 1.1pt;">26.87 (6.84)</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.2.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S5.T6.3.2" class="ltx_text" style="font-size:90%;">Decoding hypotheses generated by models trained with different methods for the utterance common_voice_en_37177</span></figcaption>
<table id="S5.T6.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T6.4.1.1" class="ltx_tr">
<th id="S5.T6.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">ref / hyps</th>
<th id="S5.T6.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">Text</th>
</tr>
<tr id="S5.T6.4.2.2" class="ltx_tr">
<th id="S5.T6.4.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">reference</th>
<th id="S5.T6.4.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">ican't stand the sight of blood</th>
</tr>
<tr id="S5.T6.4.3.3" class="ltx_tr">
<th id="S5.T6.4.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">hyp - default</th>
<th id="S5.T6.4.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">
<table id="S5.T6.4.3.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T6.4.3.3.2.1.1" class="ltx_tr">
<td id="S5.T6.4.3.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">or ican't stand the sight of blood or ican't</td>
</tr>
<tr id="S5.T6.4.3.3.2.1.2" class="ltx_tr">
<td id="S5.T6.4.3.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">stand the site of blood … or ican't stand</td>
</tr>
<tr id="S5.T6.4.3.3.2.1.3" class="ltx_tr">
<td id="S5.T6.4.3.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">the sight of blood</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T6.4.4.1" class="ltx_tr">
<th id="S5.T6.4.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">hyp - DA</th>
<td id="S5.T6.4.4.1.2" class="ltx_td ltx_align_left" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">ican't stand the sight of blood i</td>
</tr>
<tr id="S5.T6.4.5.2" class="ltx_tr">
<th id="S5.T6.4.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">hyp - NSET</th>
<td id="S5.T6.4.5.2.2" class="ltx_td ltx_align_left" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">&lt;empty&gt;</td>
</tr>
<tr id="S5.T6.4.6.3" class="ltx_tr">
<th id="S5.T6.4.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">hyp - DA+NSET</th>
<td id="S5.T6.4.6.3.2" class="ltx_td ltx_align_left ltx_border_bb" style="padding-top:-0.5pt;padding-bottom:-0.5pt;">ican't stand the sight of blood</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We presented a systematic approach to integrate a speech encoder with an LLM for the ASR task. Our findings indicate that employing the parameter-efficient LoRa method on both the encoder and LLM represents the most cost-effective fine-tuning strategy. Additionally, we introduced a matching loss to enhance alignment between modalities, thereby improving ASR performance. Moreover, we explored various inference methods alongside training techniques to mitigate insertion errors. Results demonstrate a substantial reduction in insertion errors using these methods, resulting in significantly improved ASR performance, especially for out-of-domain test sets.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
W.-N. Hsu, B. Bolte, Y.-H. H. Tsai, K. Lakhotia, R. Salakhutdinov, and A. Mohamed, ``Hubert: Self-supervised speech representation learning by masked prediction of hidden units,'' <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Trans. Audio, Speech and Lang. Proc.</em>, vol. 29, p. 3451–3460, Oct 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Y. Zhang, W. Han, J. Qin, Y. Wang, A. Bapna, Z. Chen, N. Chen, B. Li, V. Axelrod, G. Wang, Z. Meng, K. Hu, A. Rosenberg, R. Prabhavalkar, D. S. Park, P. Haghani, J. Riesa, G. Perng, H. Soltau, T. Strohman, B. Ramabhadran, T. Sainath, P. Moreno, C.-C. Chiu, J. Schalkwyk, F. Beaufays, and Y. Wu, ``Google usm: Scaling automatic speech recognition beyond 100 languages,'' <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.09093</em>, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J. Li, D. Li, S. Savarese, and S. Hoi, ``Blip-2: bootstrapping language-image pre-training with frozen image encoders and large language models,'' in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ICML</em>, ser. ICML'23, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J. Wu, Y. Gaur, Z. Chen, L. Zhou, Y. Zhu, T. Wang, J. Li, S. Liu, B. Ren, L. Liu, and Y. Wu, ``On decoder-only architecture for speech-to-text and large language model integration,'' <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>, pp. 1–8, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Fathullah, C. Wu, E. Lakomkin, J. Jia, Y. Shangguan, K. Li, J. Guo, W. Xiong, J. Mahadeokar, O. Kalinli, C. Fuegen, and M. Seltzer, ``Prompting large language models with speech recognition abilities,'' <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2307.11795, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M. Wang, W. Han, I. Shafran, Z. Wu, C.-C. Chiu, Y. Cao, N. Chen, Y. Zhang, H. Soltau, P. K. Rubenstein <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Slm: Bridge the thin gap between speech and text foundation models,'' in <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)</em>.   IEEE, 2023, pp. 1–8.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
W. Yu, C. Tang, G. Sun, X. Chen, T. Tan, W. Li, L. Lu, Z. Ma, and C. Zhang, ``Connecting speech encoder and large language model for asr,'' <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2309.13963, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Ling, Y. Hu, S. Qian, G. Ye, Y. Qian, Y. Gong, E. Lin, and M. Zeng, ``Adapting large language model with speech for fully formatted end-to-end speech recognition,'' <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2307.08234, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
D. Zhang, S. Li, X. Zhang, J. Zhan, P. Wang, Y. Zhou, and X. Qiu, ``SpeechGPT: Empowering large language models with intrinsic cross-modal conversational abilities,'' in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, H. Bouamor, J. Pino, and K. Bali, Eds., Dec. 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
P. Rubenstein, C. Asawaroengchai, D. Nguyen, A. Bapna, Z. Borsos, F. Quitry, P. Chen, D. Badawy, W. Han, E. Kharitonov, H. Muckenhirn, D. Padfield, J. Qin, D. Rozenberg, T. Sainath, J. Schalkwyk, M. Sharifi <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Audiopalm: A large language model that can speak and listen,'' <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2306.12925, 06 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
C. Lyu, M. Wu, L. Wang, X. Huang, B. Liu, Z. Du, S. Shi, and Z. Tu, ``Macaw-llm: Multi-modal language modeling with image, audio, video, and text integration,'' <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.09093</em>, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y. Li, Y. Wu, J. Li, and S. Liu, ``Prompting large language models for zero-shot domain adaptation in speech recognition,'' in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Automatic Speech Recognition and Understanding Workshop, ASRU 2023, Taipei, Taiwan, December 16-20, 2023</em>.   IEEE, 2023, pp. 1–8.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
L. Barrault <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">et al.</em>, ``Seamless: Multilingual expressive and streaming speech translation,'' <em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2312.05187, 2023.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
T. Wang, L. Zhou, Z. Zhang, Y. Wu, S. Liu, Y. Gaur, Z. Chen, J. Li, and F. Wei, ``Viola: Unified codec language models for speech recognition, synthesis, and translation,'' <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2305.16107, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y. Gong, H. Luo, A. H. Liu, L. Karlinsky, and J. Glass, ``Listen, think, and understand,'' <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.10790</em>, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
S.-A. Rebuffi, H. Bilen, and A. Vedaldi, ``Learning multiple visual domains with residual adapters,'' in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">NIPS</em>, 2017.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
X. L. Li and P. Liang, ``Prefix-tuning: Optimizing continuous prompts for generation,'' in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">ACL-IJCNLP</em>, Aug. 2021, pp. 4582–4597.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, ``Lora: Low-rank adaptation of large language models,'' <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.09685</em>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
A. Baevski, H. Zhou, A. Mohamed, and M. Auli, ``wav2vec 2.0: A framework for self-supervised learning of speech representations,'' in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">34th Conference on Neural Information Processing Systems (NeurIPS)</em>, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, ``Attention is all you need,'' in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 31st International Conference on Neural Information Processing Systems</em>, ser. NIPS'17, 2017, p. 6000–6010.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, ``Librispeech: An asr corpus based on public domain audio books,'' in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 04 2015, pp. 5206–5210.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
C. Wang, A. Wu, and J. Pino, ``Covost 2 and massively multilingual speech-to-text translation,'' <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv:2007.10310</em>, 2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
G. Chen, S. Chai, G.-B. Wang, J. Du, W. Zhang, C. Weng, D. Su, D. Povey, J. Trmal, J. Zhang, M. Jin, S. Khudanpur, S. Watanabe, S. Zhao, W. Zou, X. Li, X. Yao, Y. Wang, Y. Wang, Z. You, and Z. Yan, ``Gigaspeech: An evolving, multi-domain asr corpus with 10, 000 hours of transcribed audio,'' <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2106.06909, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
D. Snyder, G. Chen, and D. Povey, ``Musan: A music, speech, and noise corpus,'' <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/1510.08484, 2015.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng, S. Zhuang, Y. Zhuang, J. E. Gonzalez, I. Stoica, and E. P. Xing, ``Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality,'' March 2023. [Online]. Available: <a target="_blank" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://lmsys.org/blog/2023-03-30-vicuna/</a>

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.17271" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.17272" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.17272">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.17272" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.17273" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 20:10:08 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
