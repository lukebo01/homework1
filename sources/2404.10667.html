<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.10667] VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time</title><meta property="og:description" content="We introduce VASA, a framework for generating lifelike talking faces with appealing visual affective skills (VAS) given a single static image and a speech audio clip. Our premiere model, VASA-1, is capable of not only …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.10667">

<!--Generated on Sun May  5 15:15:25 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">VASA-1: Lifelike Audio-Driven Talking Faces
<br class="ltx_break">Generated in Real Time</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Microsoft Research Asia
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">​​​​​​ Sicheng Xu  
<br class="ltx_break">​​​​Microsoft Research Asia 
<br class="ltx_break"><span id="id6.5.id1" class="ltx_text ltx_font_typewriter">​​​​​​sichengxu@microsoft.com​​</span>
&amp;​​​​Guojun Chen<sup id="id7.6.id2" class="ltx_sup">∗</sup> 
<br class="ltx_break">​​​​Microsoft Research Asia 
<br class="ltx_break"><span id="id8.7.id3" class="ltx_text ltx_font_typewriter">​​​​guoch@microsoft.com</span>
&amp;Yu-Xiao Guo<sup id="id9.8.id4" class="ltx_sup">∗</sup> 
<br class="ltx_break">Microsoft Research Asia 
<br class="ltx_break"><span id="id10.9.id5" class="ltx_text ltx_font_typewriter">yuxgu@microsoft.com</span>
&amp;   Jiaolong Yang<math id="id4.4.m3.1" class="ltx_Math" alttext="{{}^{*\ \!{\dagger}}}" display="inline"><semantics id="id4.4.m3.1a"><msup id="id4.4.m3.1.1" xref="id4.4.m3.1.1.cmml"><mi id="id4.4.m3.1.1a" xref="id4.4.m3.1.1.cmml"></mi><mrow id="id4.4.m3.1.1.1" xref="id4.4.m3.1.1.1.cmml"><mi id="id4.4.m3.1.1.1.2" xref="id4.4.m3.1.1.1.2.cmml"></mi><mo lspace="0.222em" id="id4.4.m3.1.1.1.1" xref="id4.4.m3.1.1.1.1.cmml">∗</mo><mo lspace="0.013em" id="id4.4.m3.1.1.1.3" xref="id4.4.m3.1.1.1.3.cmml">†</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id4.4.m3.1b"><apply id="id4.4.m3.1.1.cmml" xref="id4.4.m3.1.1"><apply id="id4.4.m3.1.1.1.cmml" xref="id4.4.m3.1.1.1"><times id="id4.4.m3.1.1.1.1.cmml" xref="id4.4.m3.1.1.1.1"></times><csymbol cd="latexml" id="id4.4.m3.1.1.1.2.cmml" xref="id4.4.m3.1.1.1.2">absent</csymbol><ci id="id4.4.m3.1.1.1.3.cmml" xref="id4.4.m3.1.1.1.3">†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.m3.1c">{{}^{*\ \!{\dagger}}}</annotation></semantics></math> 
<br class="ltx_break">Microsoft Research Asia 
<br class="ltx_break"><span id="id11.10.id6" class="ltx_text ltx_font_typewriter">jiaoyan@microsoft.com</span>
&amp;Chong Li    
<br class="ltx_break">Microsoft Research Asia 
<br class="ltx_break"><span id="id12.11.id7" class="ltx_text ltx_font_typewriter">chol@microsoft.com</span>
&amp;Zhenyu Zang
<br class="ltx_break">Microsoft Research Asia 
<br class="ltx_break"><span id="id13.12.id8" class="ltx_text ltx_font_typewriter">​​​​zhenyuzang@microsoft.com​​​​</span>
&amp;Yizhong Zhang 
<br class="ltx_break">Microsoft Research Asia 
<br class="ltx_break"><span id="id14.13.id9" class="ltx_text ltx_font_typewriter">yizzhan@microsoft.com​</span>
&amp;Xin Tong 
<br class="ltx_break">Microsoft Research Asia 
<br class="ltx_break"><span id="id15.14.id10" class="ltx_text ltx_font_typewriter">xtong@microsoft.com</span>
&amp;Baining Guo 
<br class="ltx_break">Microsoft Research Asia 
<br class="ltx_break"><span id="id16.15.id11" class="ltx_text ltx_font_typewriter">bainguo@microsoft.com</span>
</span><span class="ltx_author_notes">: Equal contributions. <sup id="id17.16.id1" class="ltx_sup"><span id="id17.16.id1.1" class="ltx_text ltx_font_italic">†</span></sup>: Corresponding author.  See the contribution statement section for contributions.
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id5.1" class="ltx_p">We introduce VASA, a framework for generating lifelike talking faces with appealing visual affective skills (VAS) given a single static image and a speech audio clip. Our premiere model, VASA-1, is capable of not only producing lip movements that are exquisitely synchronized with the audio, but also capturing a large spectrum of facial nuances and natural head motions that contribute to the perception of authenticity and liveliness.
The core innovations include a diffusion-based holistic facial dynamics and head movement generation model that works in a face latent space, and the development of such an expressive and disentangled face latent space using videos.
Through extensive experiments including evaluation on a set of new metrics, we show that our method significantly outperforms previous methods along various dimensions comprehensively. Our method delivers high video quality with realistic facial and head dynamics and also supports the online generation of 512<math id="id5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="id5.1.m1.1a"><mo id="id5.1.m1.1.1" xref="id5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="id5.1.m1.1b"><times id="id5.1.m1.1.1.cmml" xref="id5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id5.1.m1.1c">\times</annotation></semantics></math>512 videos at up to 40 FPS with negligible starting latency.
It paves the way for real-time engagements with lifelike avatars that emulate human conversational behaviors. Project webpage: <a target="_blank" href="https://www.microsoft.com/en-us/research/project/vasa-1/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.microsoft.com/en-us/research/project/vasa-1/</a></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In the realm of multimedia and communication, the human face is not just a visage but a dynamic canvas, where every subtle movement and expression can articulate emotions, convey unspoken messages, and foster empathetic connections.
The emergence of AI-generated talking faces offers a window into a future where technology amplifies the richness of human-human and human-AI interactions. Such technology holds the promise of enriching digital communication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite>, increasing accessibility for those with communicative impairments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite>, transforming education methods with interactive AI tutoring <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>, and providing therapeutic support and social interaction in healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">As one step towards achieving such capabilities, our work introduces VASA-1, a new method that can produce audio-generated talking faces with a high level of realism and liveliness.
Given a static face image of an arbitrary individual, alongside a speech audio clip from any person, our approach is capable of generating a hyper-realistic talking face video efficiently.
This video not only features lip movements that are meticulously synchronized with the audio input but also exhibits a wide range of natural, human-like facial dynamics and head movements.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Creating talking faces from audio has attracted significant attention in recent years with numerous approaches proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">75</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">73</span></a>, <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>, <a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>, <a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>, <a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>, <a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>, <a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite>.
However, existing techniques are still far from achieving the authenticity of natural talking faces. Current research has predominantly focused on the precision of lip synchronization with promising accuracy obtained <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>]</cite>. The creation of expressive facial dynamics and the subtle nuances of lifelike facial behavior remain largely neglected.
This results in generated faces that seem rigid and unconvincing.
Additionally, natural head movements also play a vital role in enhancing the perception of realism.
Although recent studies have attempted to simulate realistic head motions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>, <a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite>, there remains a sizable gap between the generated animations and the genuine human movement patterns.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2404.10667/assets/figures/teaser.jpg" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="580" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Given a single portrait image, a speech audio clip, and optionally a set of other control signals, our approach produces a high-quality lifelike talking face video of 512<math id="S1.F1.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.F1.2.m1.1b"><mo id="S1.F1.2.m1.1.1" xref="S1.F1.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.F1.2.m1.1c"><times id="S1.F1.2.m1.1.1.cmml" xref="S1.F1.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.2.m1.1d">\times</annotation></semantics></math> 512 resolution at up to 40 FPS. The method is generic and robust, and the generated talking faces can faithfully mimic human facial expressions and head movements, reaching a high level of realism and liveliness. (<em id="S1.F1.4.1" class="ltx_emph ltx_font_italic">All the photorealistic portrait images in this paper are virtual, non-existing identities generated by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite>. See our project page for the generated video samples with audios.</em>)</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Another important factor is the efficiency of generation, which plays a pivotal role in real-time applications such as live communication. While image and video diffusion techniques have brought remarkable advancements in talking face generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>, <a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>, <a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> as well as the broader video generation field <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>, the substantial computation demands have limited their practicality for interactive systems. A critical need exists for optimized algorithms that can bridge the gap between high-quality video synthesis and the low-latency requirements of real-time applications.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Given the limitations of existing methods, this work develops an efficient yet powerful audio-conditioned generative model that works in the <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">latent space</em> of head and facial movements. Different from prior works, we train a Diffusion Transformer model on the latent space of <em id="S1.p5.1.2" class="ltx_emph ltx_font_italic">holistic facial dynamics</em> as well as head movements. We consider all possible facial dynamics – including lip motion, (non-lip) expression, eye gaze and blinking, among others – as a single latent variable and model its probabilistic distribution in a unified manner. By contrast, existing methods often apply separate models for different factors, even with interleaved regressive and generative formulations for them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>, <a href="#bib.bib74" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">74</span></a>, <a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite>. Our holistic facial dynamics modeling, together with the jointly learned head motion patterns, leads to the generation of a diverse array of lifelike and emotive talking behaviors.
Furthermore, we incorporate a set of optional conditioning signals such as main gaze direction, head distance, and emotion offset into the learning process. This makes the generative modeling of complex distribution more tractable and increases the generation controllability.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To achieve our goal, another challenge lies in constructing the latent space for the aforementioned holistic facial dynamics and gathering the data for the diffusion model training. Beyond facial and head movements, a human face image contains other factors such as identity and appearance. In this work, we seek to build a proper latent space for human face using a large volume of face videos . Our aim is for the face latent space to possess both a total state of <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">disentanglement</em> between facial dynamics and other factors, as well as a high degree of <em id="S1.p6.1.2" class="ltx_emph ltx_font_italic">expressiveness</em> to model rich facial appearance details and dynamic nuances.
We base our method on the 3D-aided representation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> and equip it with a collection of carefully-designed loss functions. Trained on face videos in an self-supervised or weakly-supervised manner, our encoder can produce well-disentangled factors including 3D appearance, identity, head pose and holistic facial dynamics, and the decoder can generate high quality faces following the given latent codes.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">VASA-1 has collectively advanced the realism of lip-audio synchronization, facial dynamics, and head movement to new heights. Coupled with high image generation quality and efficient running speed, we achieved real-time talking faces that are realistic and lifelike.
Through detailed evaluations, we show that our method significantly outperforms existing methods. We believe VASA-1 brings us closer to a future where digital AI avatars can engage with us in ways that are as natural and intuitive as interactions with real humans, demonstrating appealing visual affective skills for more dynamic and empathetic information exchange.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Disentangled face representation learning.</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">The representation of facial images through disentangled variables has been extensively studied by previous works. Some methods utilize sparse keypoints <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">42</span></a>, <a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">69</span></a>]</cite> or 3D face models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>, <a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">71</span></a>]</cite> to explicitly characterize facial dynamics and other properties, but these can suffer from issues such as inaccurate reconstructions or limited expressive capabilities. There are also many works dedicated to learning disentangled representations within a latent space. A common approach involves separating faces into identity and non-identity components, then recombining them across different frames, either in a 2D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib74" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">74</span></a>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>, <a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>]</cite> or 3D context <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. The main challenge faced by these methods is the effective disentanglement of various factors while still achieving expressive representations of all static and dynamic facial attributes, which is addressed in this work.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Audio-driven talking face generation.</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">Talking face video generation from audio inputs has been a long-standing task in computer vision and graphics.
Early works have focused on synthesizing only the lips, achieved by mapping audio signals directly to lip movements while leaving other facial attributes unchanged <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>]</cite>. More recent efforts have expanded the scope to include a broader array of facial expressions and head movements derived from audio inputs. For instance, the method of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite> separates the generation targets into different categories, including lip-only 3DMM coefficients, eye blinks, and head poses. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>]</cite> proposed to decompose lip and non-lip features on the top of the expression latent from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">74</span></a>]</cite>. Both <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>]</cite> regress lip-related representations directly from audio features and model other attributes in a probabilistic manner. In contrast to these approaches, our method generates comprehensive facial dynamics and head poses from audio along with other control signals. This approach differs from the trend of further disentanglement, seeking instead to create more holistic and integrated outputs.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Video generation.</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">Recent advances in generative models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite> have led to significant progress in video generation. Earlier video generation approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> employed the adversarial learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite> framework, while more recent methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">66</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite> have leveraged diffusion or auto-regressive models to capture diverse video distributions.
Recently, several works concurrent to us <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>, <a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> have adapted video diffusion techniques to audio-driven talking face generation, achieving promising results despite the slow training and inference speeds.
In contrast, our method can deliver both efficiency and high-quality results in the generation of talking face videos.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Task definition.</h4>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.2" class="ltx_p">As illustrated in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
The input to our method consists of a single face image <math id="S3.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{I}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">𝐈</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">𝐈</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.1c">\mathbf{I}</annotation></semantics></math> of an arbitrary identity and a speech audio clip <math id="S3.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{a}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.2.m2.1a"><mi id="S3.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">𝐚</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1">𝐚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.2.m2.1c">\mathbf{a}</annotation></semantics></math> from, again, an arbitrary person. The goal is to generate a synthesized video of the input face image speaking with the given audio in a realistic and coherent manner.
A successfully generated video should exhibit high fidelity in several key aspects: the clarity and authenticity of the image frames, precise synchronization between the audio and lip movements, expressive and emotive facial dynamics, and naturalistic head poses.</p>
</div>
<div id="S3.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p2.3" class="ltx_p">Our generation process can also accept a set of optional control signals to guide the generation, which include the main eye gaze direction <math id="S3.SS0.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{g}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p2.1.m1.1a"><mi id="S3.SS0.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">𝐠</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.1.m1.1b"><ci id="S3.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.1.m1.1.1">𝐠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.1.m1.1c">\mathbf{g}</annotation></semantics></math>, head-to-camera distance <math id="S3.SS0.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS0.SSS0.Px1.p2.2.m2.1a"><mi id="S3.SS0.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p2.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.2.m2.1b"><ci id="S3.SS0.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.2.m2.1c">d</annotation></semantics></math>, and emotion offset <math id="S3.SS0.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{e}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p2.3.m3.1a"><mi id="S3.SS0.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1.cmml">𝐞</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p2.3.m3.1b"><ci id="S3.SS0.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px1.p2.3.m3.1.1">𝐞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p2.3.m3.1c">\mathbf{e}</annotation></semantics></math>. More details will be provided in the later sections.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Overall framework.</h4>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.1" class="ltx_p">Instead of generating video frames directly, we generate holistic facial dynamics and head motion in the latent space conditioned on audio and other signals. Given these motion latent codes, our method then produces video frames by a face decoder, which also takes the appearance and identity features extracted using a face encoder from the input image as input.</p>
</div>
<div id="S3.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p2.1" class="ltx_p">To achieve this, we start by constructing a face latent space and training the face encoder and decoder. An expressive and disentangled face latent learning framework is crafted and trained on real-life face videos. Then we train a simple yet powerful Diffusion Transformer to model the motion distribution and generate the motion latent codes in the test time given audio and other conditions.</p>
</div>
</section>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Expressive and Disentangled Face Latent Space Construction</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Given a corpus of unlabeled talking face videos, we aim to build a latent space for human face with high degrees of <em id="S3.SS1.p1.1.1" class="ltx_emph ltx_font_italic">disentanglement</em> and <em id="S3.SS1.p1.1.2" class="ltx_emph ltx_font_italic">expressiveness</em>.
The disentanglement enables effective generative modeling of the human head and holistic facial behaviors on massive videos, irrespective of the subject identities. It also enables disentangled factor control of the output which is desirable in many applications. Existing methods fall short of either expressiveness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>, <a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>]</cite> or disentanglement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>, <a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">71</span></a>]</cite> or both. The expressiveness of facial appearance and dynamic movements, on the other hand, ensures that the decoder can output high quality videos with rich facial details and the latent generator is able to capture nuanced facial dynamics.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.7" class="ltx_p">To achieve this, we base our model on the 3D-aid face reenactment framework from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. The 3D appearance feature volume can better characterize the appearance details in 3D compared to 2D feature maps. The explicit 3D feature warping is also powerful in modeling 3D head and facial movements.
Specifically, we decompose a facial image into a canonical 3D appearance volume <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{V}^{app}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msup id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">𝐕</mi><mrow id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml"><mi id="S3.SS1.p2.1.m1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.1.1.3.1" xref="S3.SS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.1.m1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.1.1.3.1a" xref="S3.SS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.1.m1.1.1.3.4" xref="S3.SS1.p2.1.m1.1.1.3.4.cmml">p</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝐕</ci><apply id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><times id="S3.SS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.1"></times><ci id="S3.SS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.2">𝑎</ci><ci id="S3.SS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3">𝑝</ci><ci id="S3.SS1.p2.1.m1.1.1.3.4.cmml" xref="S3.SS1.p2.1.m1.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathbf{V}^{app}</annotation></semantics></math>, an identity code <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{z}^{id}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msup id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">𝐳</mi><mrow id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS1.p2.2.m2.1.1.3.2" xref="S3.SS1.p2.2.m2.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.1.1.3.1" xref="S3.SS1.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.2.m2.1.1.3.3" xref="S3.SS1.p2.2.m2.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝐳</ci><apply id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3"><times id="S3.SS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS1.p2.2.m2.1.1.3.1"></times><ci id="S3.SS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS1.p2.2.m2.1.1.3.2">𝑖</ci><ci id="S3.SS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\mathbf{z}^{id}</annotation></semantics></math>, a 3D head pose <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{z}^{pose}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msup id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">𝐳</mi><mrow id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml"><mi id="S3.SS1.p2.3.m3.1.1.3.2" xref="S3.SS1.p2.3.m3.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.3.1" xref="S3.SS1.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.3.m3.1.1.3.3" xref="S3.SS1.p2.3.m3.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.3.1a" xref="S3.SS1.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.3.m3.1.1.3.4" xref="S3.SS1.p2.3.m3.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.3.m3.1.1.3.1b" xref="S3.SS1.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.3.m3.1.1.3.5" xref="S3.SS1.p2.3.m3.1.1.3.5.cmml">e</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝐳</ci><apply id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3"><times id="S3.SS1.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.p2.3.m3.1.1.3.1"></times><ci id="S3.SS1.p2.3.m3.1.1.3.2.cmml" xref="S3.SS1.p2.3.m3.1.1.3.2">𝑝</ci><ci id="S3.SS1.p2.3.m3.1.1.3.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3">𝑜</ci><ci id="S3.SS1.p2.3.m3.1.1.3.4.cmml" xref="S3.SS1.p2.3.m3.1.1.3.4">𝑠</ci><ci id="S3.SS1.p2.3.m3.1.1.3.5.cmml" xref="S3.SS1.p2.3.m3.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathbf{z}^{pose}</annotation></semantics></math>, and a facial dynamics code <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{z}^{dyn}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><msup id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">𝐳</mi><mrow id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml"><mi id="S3.SS1.p2.4.m4.1.1.3.2" xref="S3.SS1.p2.4.m4.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.3.1" xref="S3.SS1.p2.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.1.1.3.1a" xref="S3.SS1.p2.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.4.m4.1.1.3.4" xref="S3.SS1.p2.4.m4.1.1.3.4.cmml">n</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝐳</ci><apply id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><times id="S3.SS1.p2.4.m4.1.1.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3.1"></times><ci id="S3.SS1.p2.4.m4.1.1.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.2">𝑑</ci><ci id="S3.SS1.p2.4.m4.1.1.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3">𝑦</ci><ci id="S3.SS1.p2.4.m4.1.1.3.4.cmml" xref="S3.SS1.p2.4.m4.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\mathbf{z}^{dyn}</annotation></semantics></math>. Each of them is extracted from a face image by an independent encoder, except that <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{V}^{app}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><msup id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">𝐕</mi><mrow id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml"><mi id="S3.SS1.p2.5.m5.1.1.3.2" xref="S3.SS1.p2.5.m5.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.3.1" xref="S3.SS1.p2.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.5.m5.1.1.3.3" xref="S3.SS1.p2.5.m5.1.1.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.5.m5.1.1.3.1a" xref="S3.SS1.p2.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.5.m5.1.1.3.4" xref="S3.SS1.p2.5.m5.1.1.3.4.cmml">p</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝐕</ci><apply id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3"><times id="S3.SS1.p2.5.m5.1.1.3.1.cmml" xref="S3.SS1.p2.5.m5.1.1.3.1"></times><ci id="S3.SS1.p2.5.m5.1.1.3.2.cmml" xref="S3.SS1.p2.5.m5.1.1.3.2">𝑎</ci><ci id="S3.SS1.p2.5.m5.1.1.3.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3.3">𝑝</ci><ci id="S3.SS1.p2.5.m5.1.1.3.4.cmml" xref="S3.SS1.p2.5.m5.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\mathbf{V}^{app}</annotation></semantics></math> is constructed by first extracting a posed 3D volume followed by rigid and non-rigid 3D warping to the canonical volume, as done in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>.
A single decoder <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\mathcal{D}</annotation></semantics></math> takes these latent variables as input and reconstructs the face image, where similar warping fields in the inverse direction are first applied to <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="\mathbf{V}^{app}" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><msup id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">𝐕</mi><mrow id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml"><mi id="S3.SS1.p2.7.m7.1.1.3.2" xref="S3.SS1.p2.7.m7.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.7.m7.1.1.3.1" xref="S3.SS1.p2.7.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.7.m7.1.1.3.3" xref="S3.SS1.p2.7.m7.1.1.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.7.m7.1.1.3.1a" xref="S3.SS1.p2.7.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p2.7.m7.1.1.3.4" xref="S3.SS1.p2.7.m7.1.1.3.4.cmml">p</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">superscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">𝐕</ci><apply id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3"><times id="S3.SS1.p2.7.m7.1.1.3.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3.1"></times><ci id="S3.SS1.p2.7.m7.1.1.3.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.2">𝑎</ci><ci id="S3.SS1.p2.7.m7.1.1.3.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3">𝑝</ci><ci id="S3.SS1.p2.7.m7.1.1.3.4.cmml" xref="S3.SS1.p2.7.m7.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">\mathbf{V}^{app}</annotation></semantics></math> to get the posed appearance volume. Readers are referred to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> for more details of this architecture.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.17" class="ltx_p">To learn the disentangled latent space, the core idea is to construct image reconstruction loss by swapping latent variables between different images in videos. Our basic loss functions are adapted from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. However, we identified the poor disentanglement between facial dynamics and head pose using the original losses. The disentanglement between identity and motions is also imperfect. Therefore, we introduce several additional losses crucial to achieve our goal. For instance, inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite>, we add a pairwise head pose and facial dynamics transfer loss to improve their disentanglement. Let <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{I}_{i}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">𝐈</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathbf{I}_{i}</annotation></semantics></math> and <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="\mathbf{I}_{j}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">𝐈</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\mathbf{I}_{j}</annotation></semantics></math> be two frames randomly sampled from the same video of a subject. We extract their latent variables using the encoders, and transfer <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{I}_{i}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">𝐈</ci><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\mathbf{I}_{i}</annotation></semantics></math>’s head pose onto <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="\mathbf{I}_{j}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><msub id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2">𝐈</ci><ci id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">\mathbf{I}_{j}</annotation></semantics></math> as <math id="S3.SS1.p3.5.m5.6" class="ltx_Math" alttext="\hat{\mathbf{I}}_{j,\mathbf{z}^{pose}_{i}}=\mathcal{D}(\mathbf{V}^{app}_{j},\mathbf{z}^{id}_{j},\mathbf{z}^{pose}_{i},\mathbf{z}^{dyn}_{j})" display="inline"><semantics id="S3.SS1.p3.5.m5.6a"><mrow id="S3.SS1.p3.5.m5.6.6" xref="S3.SS1.p3.5.m5.6.6.cmml"><msub id="S3.SS1.p3.5.m5.6.6.6" xref="S3.SS1.p3.5.m5.6.6.6.cmml"><mover accent="true" id="S3.SS1.p3.5.m5.6.6.6.2" xref="S3.SS1.p3.5.m5.6.6.6.2.cmml"><mi id="S3.SS1.p3.5.m5.6.6.6.2.2" xref="S3.SS1.p3.5.m5.6.6.6.2.2.cmml">𝐈</mi><mo id="S3.SS1.p3.5.m5.6.6.6.2.1" xref="S3.SS1.p3.5.m5.6.6.6.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p3.5.m5.2.2.2.2" xref="S3.SS1.p3.5.m5.2.2.2.3.cmml"><mi id="S3.SS1.p3.5.m5.1.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.1.cmml">j</mi><mo id="S3.SS1.p3.5.m5.2.2.2.2.2" xref="S3.SS1.p3.5.m5.2.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p3.5.m5.2.2.2.2.1" xref="S3.SS1.p3.5.m5.2.2.2.2.1.cmml"><mi id="S3.SS1.p3.5.m5.2.2.2.2.1.2.2" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.5.m5.2.2.2.2.1.3" xref="S3.SS1.p3.5.m5.2.2.2.2.1.3.cmml">i</mi><mrow id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.cmml"><mi id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.2" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.1" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.3" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.1a" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.4" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.1b" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.5" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.5.cmml">e</mi></mrow></msubsup></mrow></msub><mo id="S3.SS1.p3.5.m5.6.6.5" xref="S3.SS1.p3.5.m5.6.6.5.cmml">=</mo><mrow id="S3.SS1.p3.5.m5.6.6.4" xref="S3.SS1.p3.5.m5.6.6.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.5.m5.6.6.4.6" xref="S3.SS1.p3.5.m5.6.6.4.6.cmml">𝒟</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.6.6.4.5" xref="S3.SS1.p3.5.m5.6.6.4.5.cmml">​</mo><mrow id="S3.SS1.p3.5.m5.6.6.4.4.4" xref="S3.SS1.p3.5.m5.6.6.4.4.5.cmml"><mo stretchy="false" id="S3.SS1.p3.5.m5.6.6.4.4.4.5" xref="S3.SS1.p3.5.m5.6.6.4.4.5.cmml">(</mo><msubsup id="S3.SS1.p3.5.m5.3.3.1.1.1.1" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.cmml"><mi id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.2" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.2.cmml">𝐕</mi><mi id="S3.SS1.p3.5.m5.3.3.1.1.1.1.3" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.3.cmml">j</mi><mrow id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.cmml"><mi id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.2" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.1" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.3" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.1a" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.4" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.4.cmml">p</mi></mrow></msubsup><mo id="S3.SS1.p3.5.m5.6.6.4.4.4.6" xref="S3.SS1.p3.5.m5.6.6.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.5.m5.4.4.2.2.2.2" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.cmml"><mi id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.2" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.5.m5.4.4.2.2.2.2.3" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.3.cmml">j</mi><mrow id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.2" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.1" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.3" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.3.cmml">d</mi></mrow></msubsup><mo id="S3.SS1.p3.5.m5.6.6.4.4.4.7" xref="S3.SS1.p3.5.m5.6.6.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.5.m5.5.5.3.3.3.3" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.cmml"><mi id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.2" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.5.m5.5.5.3.3.3.3.3" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.3.cmml">i</mi><mrow id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.cmml"><mi id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.2" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.1" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.3" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.1a" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.4" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.1b" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.5" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.5.cmml">e</mi></mrow></msubsup><mo id="S3.SS1.p3.5.m5.6.6.4.4.4.8" xref="S3.SS1.p3.5.m5.6.6.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.5.m5.6.6.4.4.4.4" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.cmml"><mi id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.2" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.5.m5.6.6.4.4.4.4.3" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.3.cmml">j</mi><mrow id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.cmml"><mi id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.2" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.1" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.3" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.1a" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.4" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.4.cmml">n</mi></mrow></msubsup><mo stretchy="false" id="S3.SS1.p3.5.m5.6.6.4.4.4.9" xref="S3.SS1.p3.5.m5.6.6.4.4.5.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.6b"><apply id="S3.SS1.p3.5.m5.6.6.cmml" xref="S3.SS1.p3.5.m5.6.6"><eq id="S3.SS1.p3.5.m5.6.6.5.cmml" xref="S3.SS1.p3.5.m5.6.6.5"></eq><apply id="S3.SS1.p3.5.m5.6.6.6.cmml" xref="S3.SS1.p3.5.m5.6.6.6"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.6.6.6.1.cmml" xref="S3.SS1.p3.5.m5.6.6.6">subscript</csymbol><apply id="S3.SS1.p3.5.m5.6.6.6.2.cmml" xref="S3.SS1.p3.5.m5.6.6.6.2"><ci id="S3.SS1.p3.5.m5.6.6.6.2.1.cmml" xref="S3.SS1.p3.5.m5.6.6.6.2.1">^</ci><ci id="S3.SS1.p3.5.m5.6.6.6.2.2.cmml" xref="S3.SS1.p3.5.m5.6.6.6.2.2">𝐈</ci></apply><list id="S3.SS1.p3.5.m5.2.2.2.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2"><ci id="S3.SS1.p3.5.m5.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1.1.1">𝑗</ci><apply id="S3.SS1.p3.5.m5.2.2.2.2.1.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.2.2.2.2.1.1.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1">subscript</csymbol><apply id="S3.SS1.p3.5.m5.2.2.2.2.1.2.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.2.2.2.2.1.2.1.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1">superscript</csymbol><ci id="S3.SS1.p3.5.m5.2.2.2.2.1.2.2.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.2">𝐳</ci><apply id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3"><times id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.1.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.1"></times><ci id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.2.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.2">𝑝</ci><ci id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.3">𝑜</ci><ci id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.4.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.4">𝑠</ci><ci id="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.5.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS1.p3.5.m5.2.2.2.2.1.3.cmml" xref="S3.SS1.p3.5.m5.2.2.2.2.1.3">𝑖</ci></apply></list></apply><apply id="S3.SS1.p3.5.m5.6.6.4.cmml" xref="S3.SS1.p3.5.m5.6.6.4"><times id="S3.SS1.p3.5.m5.6.6.4.5.cmml" xref="S3.SS1.p3.5.m5.6.6.4.5"></times><ci id="S3.SS1.p3.5.m5.6.6.4.6.cmml" xref="S3.SS1.p3.5.m5.6.6.4.6">𝒟</ci><vector id="S3.SS1.p3.5.m5.6.6.4.4.5.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4"><apply id="S3.SS1.p3.5.m5.3.3.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.3.3.1.1.1.1.1.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.1.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.2.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.2">𝐕</ci><apply id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3"><times id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.1.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.1"></times><ci id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.2.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.2">𝑎</ci><ci id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.3.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.3">𝑝</ci><ci id="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.4.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.2.3.4">𝑝</ci></apply></apply><ci id="S3.SS1.p3.5.m5.3.3.1.1.1.1.3.cmml" xref="S3.SS1.p3.5.m5.3.3.1.1.1.1.3">𝑗</ci></apply><apply id="S3.SS1.p3.5.m5.4.4.2.2.2.2.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.4.4.2.2.2.2.1.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2">subscript</csymbol><apply id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.1.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2">superscript</csymbol><ci id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.2.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.2">𝐳</ci><apply id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3"><times id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.1"></times><ci id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.2">𝑖</ci><ci id="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.2.3.3">𝑑</ci></apply></apply><ci id="S3.SS1.p3.5.m5.4.4.2.2.2.2.3.cmml" xref="S3.SS1.p3.5.m5.4.4.2.2.2.2.3">𝑗</ci></apply><apply id="S3.SS1.p3.5.m5.5.5.3.3.3.3.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.5.5.3.3.3.3.1.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3">subscript</csymbol><apply id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.1.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3">superscript</csymbol><ci id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.2.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.2">𝐳</ci><apply id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3"><times id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.1.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.1"></times><ci id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.2.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.2">𝑝</ci><ci id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.3.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.3">𝑜</ci><ci id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.4.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.4">𝑠</ci><ci id="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.5.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS1.p3.5.m5.5.5.3.3.3.3.3.cmml" xref="S3.SS1.p3.5.m5.5.5.3.3.3.3.3">𝑖</ci></apply><apply id="S3.SS1.p3.5.m5.6.6.4.4.4.4.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.6.6.4.4.4.4.1.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4">subscript</csymbol><apply id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.1.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4">superscript</csymbol><ci id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.2.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.2">𝐳</ci><apply id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3"><times id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.1.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.1"></times><ci id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.2.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.2">𝑑</ci><ci id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.3.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.3">𝑦</ci><ci id="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.4.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS1.p3.5.m5.6.6.4.4.4.4.3.cmml" xref="S3.SS1.p3.5.m5.6.6.4.4.4.4.3">𝑗</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.6c">\hat{\mathbf{I}}_{j,\mathbf{z}^{pose}_{i}}=\mathcal{D}(\mathbf{V}^{app}_{j},\mathbf{z}^{id}_{j},\mathbf{z}^{pose}_{i},\mathbf{z}^{dyn}_{j})</annotation></semantics></math> and <math id="S3.SS1.p3.6.m6.1" class="ltx_Math" alttext="\mathbf{I}_{j}" display="inline"><semantics id="S3.SS1.p3.6.m6.1a"><msub id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml"><mi id="S3.SS1.p3.6.m6.1.1.2" xref="S3.SS1.p3.6.m6.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.6.m6.1.1.3" xref="S3.SS1.p3.6.m6.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><apply id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.6.m6.1.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p3.6.m6.1.1.2.cmml" xref="S3.SS1.p3.6.m6.1.1.2">𝐈</ci><ci id="S3.SS1.p3.6.m6.1.1.3.cmml" xref="S3.SS1.p3.6.m6.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">\mathbf{I}_{j}</annotation></semantics></math>’s facial motion onto <math id="S3.SS1.p3.7.m7.1" class="ltx_Math" alttext="\mathbf{I}_{i}" display="inline"><semantics id="S3.SS1.p3.7.m7.1a"><msub id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml"><mi id="S3.SS1.p3.7.m7.1.1.2" xref="S3.SS1.p3.7.m7.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.7.m7.1.1.3" xref="S3.SS1.p3.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.1b"><apply id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.7.m7.1.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p3.7.m7.1.1.2.cmml" xref="S3.SS1.p3.7.m7.1.1.2">𝐈</ci><ci id="S3.SS1.p3.7.m7.1.1.3.cmml" xref="S3.SS1.p3.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.1c">\mathbf{I}_{i}</annotation></semantics></math> as <math id="S3.SS1.p3.8.m8.6" class="ltx_Math" alttext="\hat{\mathbf{I}}_{i,\mathbf{z}^{dyn}_{j}}=\mathcal{D}(\mathbf{V}^{app}_{i},\mathbf{z}^{id}_{i},\mathbf{z}^{pose}_{i},\mathbf{z}^{dyn}_{j})" display="inline"><semantics id="S3.SS1.p3.8.m8.6a"><mrow id="S3.SS1.p3.8.m8.6.6" xref="S3.SS1.p3.8.m8.6.6.cmml"><msub id="S3.SS1.p3.8.m8.6.6.6" xref="S3.SS1.p3.8.m8.6.6.6.cmml"><mover accent="true" id="S3.SS1.p3.8.m8.6.6.6.2" xref="S3.SS1.p3.8.m8.6.6.6.2.cmml"><mi id="S3.SS1.p3.8.m8.6.6.6.2.2" xref="S3.SS1.p3.8.m8.6.6.6.2.2.cmml">𝐈</mi><mo id="S3.SS1.p3.8.m8.6.6.6.2.1" xref="S3.SS1.p3.8.m8.6.6.6.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p3.8.m8.2.2.2.2" xref="S3.SS1.p3.8.m8.2.2.2.3.cmml"><mi id="S3.SS1.p3.8.m8.1.1.1.1" xref="S3.SS1.p3.8.m8.1.1.1.1.cmml">i</mi><mo id="S3.SS1.p3.8.m8.2.2.2.2.2" xref="S3.SS1.p3.8.m8.2.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p3.8.m8.2.2.2.2.1" xref="S3.SS1.p3.8.m8.2.2.2.2.1.cmml"><mi id="S3.SS1.p3.8.m8.2.2.2.2.1.2.2" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.8.m8.2.2.2.2.1.3" xref="S3.SS1.p3.8.m8.2.2.2.2.1.3.cmml">j</mi><mrow id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.cmml"><mi id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.2" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.1" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.3" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.1a" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.4" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.4.cmml">n</mi></mrow></msubsup></mrow></msub><mo id="S3.SS1.p3.8.m8.6.6.5" xref="S3.SS1.p3.8.m8.6.6.5.cmml">=</mo><mrow id="S3.SS1.p3.8.m8.6.6.4" xref="S3.SS1.p3.8.m8.6.6.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.8.m8.6.6.4.6" xref="S3.SS1.p3.8.m8.6.6.4.6.cmml">𝒟</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.6.6.4.5" xref="S3.SS1.p3.8.m8.6.6.4.5.cmml">​</mo><mrow id="S3.SS1.p3.8.m8.6.6.4.4.4" xref="S3.SS1.p3.8.m8.6.6.4.4.5.cmml"><mo stretchy="false" id="S3.SS1.p3.8.m8.6.6.4.4.4.5" xref="S3.SS1.p3.8.m8.6.6.4.4.5.cmml">(</mo><msubsup id="S3.SS1.p3.8.m8.3.3.1.1.1.1" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.cmml"><mi id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.2" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.2.cmml">𝐕</mi><mi id="S3.SS1.p3.8.m8.3.3.1.1.1.1.3" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.3.cmml">i</mi><mrow id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.cmml"><mi id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.2" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.1" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.3" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.1a" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.4" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.4.cmml">p</mi></mrow></msubsup><mo id="S3.SS1.p3.8.m8.6.6.4.4.4.6" xref="S3.SS1.p3.8.m8.6.6.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.8.m8.4.4.2.2.2.2" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.cmml"><mi id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.2" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.8.m8.4.4.2.2.2.2.3" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.3.cmml">i</mi><mrow id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.2" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.1" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.3" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.3.cmml">d</mi></mrow></msubsup><mo id="S3.SS1.p3.8.m8.6.6.4.4.4.7" xref="S3.SS1.p3.8.m8.6.6.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.8.m8.5.5.3.3.3.3" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.cmml"><mi id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.2" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.8.m8.5.5.3.3.3.3.3" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.3.cmml">i</mi><mrow id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.cmml"><mi id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.2" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.1" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.3" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.1a" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.4" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.1b" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.5" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.5.cmml">e</mi></mrow></msubsup><mo id="S3.SS1.p3.8.m8.6.6.4.4.4.8" xref="S3.SS1.p3.8.m8.6.6.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.8.m8.6.6.4.4.4.4" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.cmml"><mi id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.2" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.8.m8.6.6.4.4.4.4.3" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.3.cmml">j</mi><mrow id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.cmml"><mi id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.2" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.1" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.3" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.1a" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.4" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.4.cmml">n</mi></mrow></msubsup><mo stretchy="false" id="S3.SS1.p3.8.m8.6.6.4.4.4.9" xref="S3.SS1.p3.8.m8.6.6.4.4.5.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.6b"><apply id="S3.SS1.p3.8.m8.6.6.cmml" xref="S3.SS1.p3.8.m8.6.6"><eq id="S3.SS1.p3.8.m8.6.6.5.cmml" xref="S3.SS1.p3.8.m8.6.6.5"></eq><apply id="S3.SS1.p3.8.m8.6.6.6.cmml" xref="S3.SS1.p3.8.m8.6.6.6"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.6.6.6.1.cmml" xref="S3.SS1.p3.8.m8.6.6.6">subscript</csymbol><apply id="S3.SS1.p3.8.m8.6.6.6.2.cmml" xref="S3.SS1.p3.8.m8.6.6.6.2"><ci id="S3.SS1.p3.8.m8.6.6.6.2.1.cmml" xref="S3.SS1.p3.8.m8.6.6.6.2.1">^</ci><ci id="S3.SS1.p3.8.m8.6.6.6.2.2.cmml" xref="S3.SS1.p3.8.m8.6.6.6.2.2">𝐈</ci></apply><list id="S3.SS1.p3.8.m8.2.2.2.3.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2"><ci id="S3.SS1.p3.8.m8.1.1.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1.1.1">𝑖</ci><apply id="S3.SS1.p3.8.m8.2.2.2.2.1.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.2.2.2.2.1.1.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1">subscript</csymbol><apply id="S3.SS1.p3.8.m8.2.2.2.2.1.2.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.2.2.2.2.1.2.1.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1">superscript</csymbol><ci id="S3.SS1.p3.8.m8.2.2.2.2.1.2.2.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.2">𝐳</ci><apply id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3"><times id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.1.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.1"></times><ci id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.2.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.2">𝑑</ci><ci id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.3.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.3">𝑦</ci><ci id="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.4.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS1.p3.8.m8.2.2.2.2.1.3.cmml" xref="S3.SS1.p3.8.m8.2.2.2.2.1.3">𝑗</ci></apply></list></apply><apply id="S3.SS1.p3.8.m8.6.6.4.cmml" xref="S3.SS1.p3.8.m8.6.6.4"><times id="S3.SS1.p3.8.m8.6.6.4.5.cmml" xref="S3.SS1.p3.8.m8.6.6.4.5"></times><ci id="S3.SS1.p3.8.m8.6.6.4.6.cmml" xref="S3.SS1.p3.8.m8.6.6.4.6">𝒟</ci><vector id="S3.SS1.p3.8.m8.6.6.4.4.5.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4"><apply id="S3.SS1.p3.8.m8.3.3.1.1.1.1.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.3.3.1.1.1.1.1.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.1.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.2.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.2">𝐕</ci><apply id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3"><times id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.1.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.1"></times><ci id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.2.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.2">𝑎</ci><ci id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.3.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.3">𝑝</ci><ci id="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.4.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.2.3.4">𝑝</ci></apply></apply><ci id="S3.SS1.p3.8.m8.3.3.1.1.1.1.3.cmml" xref="S3.SS1.p3.8.m8.3.3.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS1.p3.8.m8.4.4.2.2.2.2.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.4.4.2.2.2.2.1.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2">subscript</csymbol><apply id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.1.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2">superscript</csymbol><ci id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.2.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.2">𝐳</ci><apply id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3"><times id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.1"></times><ci id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.2">𝑖</ci><ci id="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.2.3.3">𝑑</ci></apply></apply><ci id="S3.SS1.p3.8.m8.4.4.2.2.2.2.3.cmml" xref="S3.SS1.p3.8.m8.4.4.2.2.2.2.3">𝑖</ci></apply><apply id="S3.SS1.p3.8.m8.5.5.3.3.3.3.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.5.5.3.3.3.3.1.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3">subscript</csymbol><apply id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.1.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3">superscript</csymbol><ci id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.2.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.2">𝐳</ci><apply id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3"><times id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.1.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.1"></times><ci id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.2.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.2">𝑝</ci><ci id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.3.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.3">𝑜</ci><ci id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.4.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.4">𝑠</ci><ci id="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.5.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS1.p3.8.m8.5.5.3.3.3.3.3.cmml" xref="S3.SS1.p3.8.m8.5.5.3.3.3.3.3">𝑖</ci></apply><apply id="S3.SS1.p3.8.m8.6.6.4.4.4.4.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.6.6.4.4.4.4.1.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4">subscript</csymbol><apply id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.1.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4">superscript</csymbol><ci id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.2.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.2">𝐳</ci><apply id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3"><times id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.1.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.1"></times><ci id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.2.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.2">𝑑</ci><ci id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.3.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.3">𝑦</ci><ci id="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.4.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS1.p3.8.m8.6.6.4.4.4.4.3.cmml" xref="S3.SS1.p3.8.m8.6.6.4.4.4.4.3">𝑗</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.6c">\hat{\mathbf{I}}_{i,\mathbf{z}^{dyn}_{j}}=\mathcal{D}(\mathbf{V}^{app}_{i},\mathbf{z}^{id}_{i},\mathbf{z}^{pose}_{i},\mathbf{z}^{dyn}_{j})</annotation></semantics></math>. The discrepancy loss between <math id="S3.SS1.p3.9.m9.2" class="ltx_Math" alttext="\hat{\mathbf{I}}_{j,\mathbf{z}^{pose}_{i}}" display="inline"><semantics id="S3.SS1.p3.9.m9.2a"><msub id="S3.SS1.p3.9.m9.2.3" xref="S3.SS1.p3.9.m9.2.3.cmml"><mover accent="true" id="S3.SS1.p3.9.m9.2.3.2" xref="S3.SS1.p3.9.m9.2.3.2.cmml"><mi id="S3.SS1.p3.9.m9.2.3.2.2" xref="S3.SS1.p3.9.m9.2.3.2.2.cmml">𝐈</mi><mo id="S3.SS1.p3.9.m9.2.3.2.1" xref="S3.SS1.p3.9.m9.2.3.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p3.9.m9.2.2.2.2" xref="S3.SS1.p3.9.m9.2.2.2.3.cmml"><mi id="S3.SS1.p3.9.m9.1.1.1.1" xref="S3.SS1.p3.9.m9.1.1.1.1.cmml">j</mi><mo id="S3.SS1.p3.9.m9.2.2.2.2.2" xref="S3.SS1.p3.9.m9.2.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p3.9.m9.2.2.2.2.1" xref="S3.SS1.p3.9.m9.2.2.2.2.1.cmml"><mi id="S3.SS1.p3.9.m9.2.2.2.2.1.2.2" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.9.m9.2.2.2.2.1.3" xref="S3.SS1.p3.9.m9.2.2.2.2.1.3.cmml">i</mi><mrow id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.cmml"><mi id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.2" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.1" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.3" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.1a" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.4" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.1b" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.5" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.5.cmml">e</mi></mrow></msubsup></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.9.m9.2b"><apply id="S3.SS1.p3.9.m9.2.3.cmml" xref="S3.SS1.p3.9.m9.2.3"><csymbol cd="ambiguous" id="S3.SS1.p3.9.m9.2.3.1.cmml" xref="S3.SS1.p3.9.m9.2.3">subscript</csymbol><apply id="S3.SS1.p3.9.m9.2.3.2.cmml" xref="S3.SS1.p3.9.m9.2.3.2"><ci id="S3.SS1.p3.9.m9.2.3.2.1.cmml" xref="S3.SS1.p3.9.m9.2.3.2.1">^</ci><ci id="S3.SS1.p3.9.m9.2.3.2.2.cmml" xref="S3.SS1.p3.9.m9.2.3.2.2">𝐈</ci></apply><list id="S3.SS1.p3.9.m9.2.2.2.3.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2"><ci id="S3.SS1.p3.9.m9.1.1.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1.1.1">𝑗</ci><apply id="S3.SS1.p3.9.m9.2.2.2.2.1.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.9.m9.2.2.2.2.1.1.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1">subscript</csymbol><apply id="S3.SS1.p3.9.m9.2.2.2.2.1.2.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.9.m9.2.2.2.2.1.2.1.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1">superscript</csymbol><ci id="S3.SS1.p3.9.m9.2.2.2.2.1.2.2.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.2">𝐳</ci><apply id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3"><times id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.1.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.1"></times><ci id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.2.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.2">𝑝</ci><ci id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.3.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.3">𝑜</ci><ci id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.4.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.4">𝑠</ci><ci id="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.5.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS1.p3.9.m9.2.2.2.2.1.3.cmml" xref="S3.SS1.p3.9.m9.2.2.2.2.1.3">𝑖</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.9.m9.2c">\hat{\mathbf{I}}_{j,\mathbf{z}^{pose}_{i}}</annotation></semantics></math> and <math id="S3.SS1.p3.10.m10.2" class="ltx_Math" alttext="\hat{\mathbf{I}}_{i,\mathbf{z}^{dyn}_{j}}" display="inline"><semantics id="S3.SS1.p3.10.m10.2a"><msub id="S3.SS1.p3.10.m10.2.3" xref="S3.SS1.p3.10.m10.2.3.cmml"><mover accent="true" id="S3.SS1.p3.10.m10.2.3.2" xref="S3.SS1.p3.10.m10.2.3.2.cmml"><mi id="S3.SS1.p3.10.m10.2.3.2.2" xref="S3.SS1.p3.10.m10.2.3.2.2.cmml">𝐈</mi><mo id="S3.SS1.p3.10.m10.2.3.2.1" xref="S3.SS1.p3.10.m10.2.3.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p3.10.m10.2.2.2.2" xref="S3.SS1.p3.10.m10.2.2.2.3.cmml"><mi id="S3.SS1.p3.10.m10.1.1.1.1" xref="S3.SS1.p3.10.m10.1.1.1.1.cmml">i</mi><mo id="S3.SS1.p3.10.m10.2.2.2.2.2" xref="S3.SS1.p3.10.m10.2.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p3.10.m10.2.2.2.2.1" xref="S3.SS1.p3.10.m10.2.2.2.2.1.cmml"><mi id="S3.SS1.p3.10.m10.2.2.2.2.1.2.2" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.10.m10.2.2.2.2.1.3" xref="S3.SS1.p3.10.m10.2.2.2.2.1.3.cmml">j</mi><mrow id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.cmml"><mi id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.2" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.1" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.3" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.1a" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.4" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.4.cmml">n</mi></mrow></msubsup></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.10.m10.2b"><apply id="S3.SS1.p3.10.m10.2.3.cmml" xref="S3.SS1.p3.10.m10.2.3"><csymbol cd="ambiguous" id="S3.SS1.p3.10.m10.2.3.1.cmml" xref="S3.SS1.p3.10.m10.2.3">subscript</csymbol><apply id="S3.SS1.p3.10.m10.2.3.2.cmml" xref="S3.SS1.p3.10.m10.2.3.2"><ci id="S3.SS1.p3.10.m10.2.3.2.1.cmml" xref="S3.SS1.p3.10.m10.2.3.2.1">^</ci><ci id="S3.SS1.p3.10.m10.2.3.2.2.cmml" xref="S3.SS1.p3.10.m10.2.3.2.2">𝐈</ci></apply><list id="S3.SS1.p3.10.m10.2.2.2.3.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2"><ci id="S3.SS1.p3.10.m10.1.1.1.1.cmml" xref="S3.SS1.p3.10.m10.1.1.1.1">𝑖</ci><apply id="S3.SS1.p3.10.m10.2.2.2.2.1.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.10.m10.2.2.2.2.1.1.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1">subscript</csymbol><apply id="S3.SS1.p3.10.m10.2.2.2.2.1.2.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.10.m10.2.2.2.2.1.2.1.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1">superscript</csymbol><ci id="S3.SS1.p3.10.m10.2.2.2.2.1.2.2.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.2">𝐳</ci><apply id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3"><times id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.1.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.1"></times><ci id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.2.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.2">𝑑</ci><ci id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.3.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.3">𝑦</ci><ci id="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.4.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS1.p3.10.m10.2.2.2.2.1.3.cmml" xref="S3.SS1.p3.10.m10.2.2.2.2.1.3">𝑗</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.10.m10.2c">\hat{\mathbf{I}}_{i,\mathbf{z}^{dyn}_{j}}</annotation></semantics></math> is subsequently minimized. To reinforce the disentanglement between identity and motions, we add a face identity similarity loss for the cross-identity pose and facial motion transfer results. Let <math id="S3.SS1.p3.11.m11.1" class="ltx_Math" alttext="\mathbf{I}_{s}" display="inline"><semantics id="S3.SS1.p3.11.m11.1a"><msub id="S3.SS1.p3.11.m11.1.1" xref="S3.SS1.p3.11.m11.1.1.cmml"><mi id="S3.SS1.p3.11.m11.1.1.2" xref="S3.SS1.p3.11.m11.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.11.m11.1.1.3" xref="S3.SS1.p3.11.m11.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.11.m11.1b"><apply id="S3.SS1.p3.11.m11.1.1.cmml" xref="S3.SS1.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.11.m11.1.1.1.cmml" xref="S3.SS1.p3.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p3.11.m11.1.1.2.cmml" xref="S3.SS1.p3.11.m11.1.1.2">𝐈</ci><ci id="S3.SS1.p3.11.m11.1.1.3.cmml" xref="S3.SS1.p3.11.m11.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.11.m11.1c">\mathbf{I}_{s}</annotation></semantics></math> and <math id="S3.SS1.p3.12.m12.1" class="ltx_Math" alttext="\mathbf{I}_{d}" display="inline"><semantics id="S3.SS1.p3.12.m12.1a"><msub id="S3.SS1.p3.12.m12.1.1" xref="S3.SS1.p3.12.m12.1.1.cmml"><mi id="S3.SS1.p3.12.m12.1.1.2" xref="S3.SS1.p3.12.m12.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.12.m12.1.1.3" xref="S3.SS1.p3.12.m12.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.12.m12.1b"><apply id="S3.SS1.p3.12.m12.1.1.cmml" xref="S3.SS1.p3.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.12.m12.1.1.1.cmml" xref="S3.SS1.p3.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p3.12.m12.1.1.2.cmml" xref="S3.SS1.p3.12.m12.1.1.2">𝐈</ci><ci id="S3.SS1.p3.12.m12.1.1.3.cmml" xref="S3.SS1.p3.12.m12.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.12.m12.1c">\mathbf{I}_{d}</annotation></semantics></math> be the video frames of two different subjects, we can transfer the motions of <math id="S3.SS1.p3.13.m13.1" class="ltx_Math" alttext="\mathbf{I}_{d}" display="inline"><semantics id="S3.SS1.p3.13.m13.1a"><msub id="S3.SS1.p3.13.m13.1.1" xref="S3.SS1.p3.13.m13.1.1.cmml"><mi id="S3.SS1.p3.13.m13.1.1.2" xref="S3.SS1.p3.13.m13.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.13.m13.1.1.3" xref="S3.SS1.p3.13.m13.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.13.m13.1b"><apply id="S3.SS1.p3.13.m13.1.1.cmml" xref="S3.SS1.p3.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.13.m13.1.1.1.cmml" xref="S3.SS1.p3.13.m13.1.1">subscript</csymbol><ci id="S3.SS1.p3.13.m13.1.1.2.cmml" xref="S3.SS1.p3.13.m13.1.1.2">𝐈</ci><ci id="S3.SS1.p3.13.m13.1.1.3.cmml" xref="S3.SS1.p3.13.m13.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.13.m13.1c">\mathbf{I}_{d}</annotation></semantics></math> onto <math id="S3.SS1.p3.14.m14.1" class="ltx_Math" alttext="\mathbf{I}_{s}" display="inline"><semantics id="S3.SS1.p3.14.m14.1a"><msub id="S3.SS1.p3.14.m14.1.1" xref="S3.SS1.p3.14.m14.1.1.cmml"><mi id="S3.SS1.p3.14.m14.1.1.2" xref="S3.SS1.p3.14.m14.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.14.m14.1.1.3" xref="S3.SS1.p3.14.m14.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.14.m14.1b"><apply id="S3.SS1.p3.14.m14.1.1.cmml" xref="S3.SS1.p3.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.14.m14.1.1.1.cmml" xref="S3.SS1.p3.14.m14.1.1">subscript</csymbol><ci id="S3.SS1.p3.14.m14.1.1.2.cmml" xref="S3.SS1.p3.14.m14.1.1.2">𝐈</ci><ci id="S3.SS1.p3.14.m14.1.1.3.cmml" xref="S3.SS1.p3.14.m14.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.14.m14.1c">\mathbf{I}_{s}</annotation></semantics></math> and obtain <math id="S3.SS1.p3.15.m15.7" class="ltx_Math" alttext="\hat{\mathbf{I}}_{s,\mathbf{z}^{pose}_{d},\mathbf{z}^{dyn}_{d}}=\mathcal{D}(\mathbf{V}^{app}_{s},\mathbf{z}^{id}_{s},\mathbf{z}^{pose}_{d},\mathbf{z}^{dyn}_{d})" display="inline"><semantics id="S3.SS1.p3.15.m15.7a"><mrow id="S3.SS1.p3.15.m15.7.7" xref="S3.SS1.p3.15.m15.7.7.cmml"><msub id="S3.SS1.p3.15.m15.7.7.6" xref="S3.SS1.p3.15.m15.7.7.6.cmml"><mover accent="true" id="S3.SS1.p3.15.m15.7.7.6.2" xref="S3.SS1.p3.15.m15.7.7.6.2.cmml"><mi id="S3.SS1.p3.15.m15.7.7.6.2.2" xref="S3.SS1.p3.15.m15.7.7.6.2.2.cmml">𝐈</mi><mo id="S3.SS1.p3.15.m15.7.7.6.2.1" xref="S3.SS1.p3.15.m15.7.7.6.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p3.15.m15.3.3.3.3" xref="S3.SS1.p3.15.m15.3.3.3.4.cmml"><mi id="S3.SS1.p3.15.m15.1.1.1.1" xref="S3.SS1.p3.15.m15.1.1.1.1.cmml">s</mi><mo id="S3.SS1.p3.15.m15.3.3.3.3.3" xref="S3.SS1.p3.15.m15.3.3.3.4.cmml">,</mo><msubsup id="S3.SS1.p3.15.m15.2.2.2.2.1" xref="S3.SS1.p3.15.m15.2.2.2.2.1.cmml"><mi id="S3.SS1.p3.15.m15.2.2.2.2.1.2.2" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.15.m15.2.2.2.2.1.3" xref="S3.SS1.p3.15.m15.2.2.2.2.1.3.cmml">d</mi><mrow id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.cmml"><mi id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.2" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.1" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.3" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.1a" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.4" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.1b" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.5" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.5.cmml">e</mi></mrow></msubsup><mo id="S3.SS1.p3.15.m15.3.3.3.3.4" xref="S3.SS1.p3.15.m15.3.3.3.4.cmml">,</mo><msubsup id="S3.SS1.p3.15.m15.3.3.3.3.2" xref="S3.SS1.p3.15.m15.3.3.3.3.2.cmml"><mi id="S3.SS1.p3.15.m15.3.3.3.3.2.2.2" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.15.m15.3.3.3.3.2.3" xref="S3.SS1.p3.15.m15.3.3.3.3.2.3.cmml">d</mi><mrow id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.cmml"><mi id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.2" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.1" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.3" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.1a" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.4" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.4.cmml">n</mi></mrow></msubsup></mrow></msub><mo id="S3.SS1.p3.15.m15.7.7.5" xref="S3.SS1.p3.15.m15.7.7.5.cmml">=</mo><mrow id="S3.SS1.p3.15.m15.7.7.4" xref="S3.SS1.p3.15.m15.7.7.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.15.m15.7.7.4.6" xref="S3.SS1.p3.15.m15.7.7.4.6.cmml">𝒟</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.7.7.4.5" xref="S3.SS1.p3.15.m15.7.7.4.5.cmml">​</mo><mrow id="S3.SS1.p3.15.m15.7.7.4.4.4" xref="S3.SS1.p3.15.m15.7.7.4.4.5.cmml"><mo stretchy="false" id="S3.SS1.p3.15.m15.7.7.4.4.4.5" xref="S3.SS1.p3.15.m15.7.7.4.4.5.cmml">(</mo><msubsup id="S3.SS1.p3.15.m15.4.4.1.1.1.1" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.cmml"><mi id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.2" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.2.cmml">𝐕</mi><mi id="S3.SS1.p3.15.m15.4.4.1.1.1.1.3" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.3.cmml">s</mi><mrow id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.cmml"><mi id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.2" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.1" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.3" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.1a" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.4" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.4.cmml">p</mi></mrow></msubsup><mo id="S3.SS1.p3.15.m15.7.7.4.4.4.6" xref="S3.SS1.p3.15.m15.7.7.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.15.m15.5.5.2.2.2.2" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.cmml"><mi id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.2" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.15.m15.5.5.2.2.2.2.3" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.3.cmml">s</mi><mrow id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.2" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.1" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.3" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.3.cmml">d</mi></mrow></msubsup><mo id="S3.SS1.p3.15.m15.7.7.4.4.4.7" xref="S3.SS1.p3.15.m15.7.7.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.15.m15.6.6.3.3.3.3" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.cmml"><mi id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.2" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.15.m15.6.6.3.3.3.3.3" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.3.cmml">d</mi><mrow id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.cmml"><mi id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.2" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.1" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.3" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.1a" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.4" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.1b" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.5" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.5.cmml">e</mi></mrow></msubsup><mo id="S3.SS1.p3.15.m15.7.7.4.4.4.8" xref="S3.SS1.p3.15.m15.7.7.4.4.5.cmml">,</mo><msubsup id="S3.SS1.p3.15.m15.7.7.4.4.4.4" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.cmml"><mi id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.2" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.15.m15.7.7.4.4.4.4.3" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.3.cmml">d</mi><mrow id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.cmml"><mi id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.2" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.1" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.3" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.1a" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.4" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.4.cmml">n</mi></mrow></msubsup><mo stretchy="false" id="S3.SS1.p3.15.m15.7.7.4.4.4.9" xref="S3.SS1.p3.15.m15.7.7.4.4.5.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.15.m15.7b"><apply id="S3.SS1.p3.15.m15.7.7.cmml" xref="S3.SS1.p3.15.m15.7.7"><eq id="S3.SS1.p3.15.m15.7.7.5.cmml" xref="S3.SS1.p3.15.m15.7.7.5"></eq><apply id="S3.SS1.p3.15.m15.7.7.6.cmml" xref="S3.SS1.p3.15.m15.7.7.6"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.7.7.6.1.cmml" xref="S3.SS1.p3.15.m15.7.7.6">subscript</csymbol><apply id="S3.SS1.p3.15.m15.7.7.6.2.cmml" xref="S3.SS1.p3.15.m15.7.7.6.2"><ci id="S3.SS1.p3.15.m15.7.7.6.2.1.cmml" xref="S3.SS1.p3.15.m15.7.7.6.2.1">^</ci><ci id="S3.SS1.p3.15.m15.7.7.6.2.2.cmml" xref="S3.SS1.p3.15.m15.7.7.6.2.2">𝐈</ci></apply><list id="S3.SS1.p3.15.m15.3.3.3.4.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3"><ci id="S3.SS1.p3.15.m15.1.1.1.1.cmml" xref="S3.SS1.p3.15.m15.1.1.1.1">𝑠</ci><apply id="S3.SS1.p3.15.m15.2.2.2.2.1.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.2.2.2.2.1.1.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1">subscript</csymbol><apply id="S3.SS1.p3.15.m15.2.2.2.2.1.2.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.2.2.2.2.1.2.1.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1">superscript</csymbol><ci id="S3.SS1.p3.15.m15.2.2.2.2.1.2.2.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.2">𝐳</ci><apply id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3"><times id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.1.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.1"></times><ci id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.2.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.2">𝑝</ci><ci id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.3.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.3">𝑜</ci><ci id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.4.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.4">𝑠</ci><ci id="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.5.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS1.p3.15.m15.2.2.2.2.1.3.cmml" xref="S3.SS1.p3.15.m15.2.2.2.2.1.3">𝑑</ci></apply><apply id="S3.SS1.p3.15.m15.3.3.3.3.2.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.3.3.3.3.2.1.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2">subscript</csymbol><apply id="S3.SS1.p3.15.m15.3.3.3.3.2.2.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.3.3.3.3.2.2.1.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2">superscript</csymbol><ci id="S3.SS1.p3.15.m15.3.3.3.3.2.2.2.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.2">𝐳</ci><apply id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3"><times id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.1.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.1"></times><ci id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.2.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.2">𝑑</ci><ci id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.3.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.3">𝑦</ci><ci id="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.4.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS1.p3.15.m15.3.3.3.3.2.3.cmml" xref="S3.SS1.p3.15.m15.3.3.3.3.2.3">𝑑</ci></apply></list></apply><apply id="S3.SS1.p3.15.m15.7.7.4.cmml" xref="S3.SS1.p3.15.m15.7.7.4"><times id="S3.SS1.p3.15.m15.7.7.4.5.cmml" xref="S3.SS1.p3.15.m15.7.7.4.5"></times><ci id="S3.SS1.p3.15.m15.7.7.4.6.cmml" xref="S3.SS1.p3.15.m15.7.7.4.6">𝒟</ci><vector id="S3.SS1.p3.15.m15.7.7.4.4.5.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4"><apply id="S3.SS1.p3.15.m15.4.4.1.1.1.1.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.4.4.1.1.1.1.1.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.1.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.2.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.2">𝐕</ci><apply id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3"><times id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.1.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.1"></times><ci id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.2.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.2">𝑎</ci><ci id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.3.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.3">𝑝</ci><ci id="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.4.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.2.3.4">𝑝</ci></apply></apply><ci id="S3.SS1.p3.15.m15.4.4.1.1.1.1.3.cmml" xref="S3.SS1.p3.15.m15.4.4.1.1.1.1.3">𝑠</ci></apply><apply id="S3.SS1.p3.15.m15.5.5.2.2.2.2.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.5.5.2.2.2.2.1.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2">subscript</csymbol><apply id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.1.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2">superscript</csymbol><ci id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.2.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.2">𝐳</ci><apply id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3"><times id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.1"></times><ci id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.2">𝑖</ci><ci id="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.2.3.3">𝑑</ci></apply></apply><ci id="S3.SS1.p3.15.m15.5.5.2.2.2.2.3.cmml" xref="S3.SS1.p3.15.m15.5.5.2.2.2.2.3">𝑠</ci></apply><apply id="S3.SS1.p3.15.m15.6.6.3.3.3.3.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.6.6.3.3.3.3.1.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3">subscript</csymbol><apply id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.1.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3">superscript</csymbol><ci id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.2.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.2">𝐳</ci><apply id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3"><times id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.1.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.1"></times><ci id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.2.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.2">𝑝</ci><ci id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.3.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.3">𝑜</ci><ci id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.4.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.4">𝑠</ci><ci id="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.5.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS1.p3.15.m15.6.6.3.3.3.3.3.cmml" xref="S3.SS1.p3.15.m15.6.6.3.3.3.3.3">𝑑</ci></apply><apply id="S3.SS1.p3.15.m15.7.7.4.4.4.4.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.7.7.4.4.4.4.1.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4">subscript</csymbol><apply id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.1.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4">superscript</csymbol><ci id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.2.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.2">𝐳</ci><apply id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3"><times id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.1.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.1"></times><ci id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.2.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.2">𝑑</ci><ci id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.3.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.3">𝑦</ci><ci id="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.4.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS1.p3.15.m15.7.7.4.4.4.4.3.cmml" xref="S3.SS1.p3.15.m15.7.7.4.4.4.4.3">𝑑</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.15.m15.7c">\hat{\mathbf{I}}_{s,\mathbf{z}^{pose}_{d},\mathbf{z}^{dyn}_{d}}=\mathcal{D}(\mathbf{V}^{app}_{s},\mathbf{z}^{id}_{s},\mathbf{z}^{pose}_{d},\mathbf{z}^{dyn}_{d})</annotation></semantics></math>. Then, a cosine similarity loss between the deep face identity features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite> extracted from <math id="S3.SS1.p3.16.m16.1" class="ltx_Math" alttext="\mathbf{I}_{s}" display="inline"><semantics id="S3.SS1.p3.16.m16.1a"><msub id="S3.SS1.p3.16.m16.1.1" xref="S3.SS1.p3.16.m16.1.1.cmml"><mi id="S3.SS1.p3.16.m16.1.1.2" xref="S3.SS1.p3.16.m16.1.1.2.cmml">𝐈</mi><mi id="S3.SS1.p3.16.m16.1.1.3" xref="S3.SS1.p3.16.m16.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.16.m16.1b"><apply id="S3.SS1.p3.16.m16.1.1.cmml" xref="S3.SS1.p3.16.m16.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.16.m16.1.1.1.cmml" xref="S3.SS1.p3.16.m16.1.1">subscript</csymbol><ci id="S3.SS1.p3.16.m16.1.1.2.cmml" xref="S3.SS1.p3.16.m16.1.1.2">𝐈</ci><ci id="S3.SS1.p3.16.m16.1.1.3.cmml" xref="S3.SS1.p3.16.m16.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.16.m16.1c">\mathbf{I}_{s}</annotation></semantics></math> and <math id="S3.SS1.p3.17.m17.3" class="ltx_Math" alttext="\hat{\mathbf{I}}_{s,\mathbf{z}^{pose}_{d},\mathbf{z}^{dyn}_{d}}" display="inline"><semantics id="S3.SS1.p3.17.m17.3a"><msub id="S3.SS1.p3.17.m17.3.4" xref="S3.SS1.p3.17.m17.3.4.cmml"><mover accent="true" id="S3.SS1.p3.17.m17.3.4.2" xref="S3.SS1.p3.17.m17.3.4.2.cmml"><mi id="S3.SS1.p3.17.m17.3.4.2.2" xref="S3.SS1.p3.17.m17.3.4.2.2.cmml">𝐈</mi><mo id="S3.SS1.p3.17.m17.3.4.2.1" xref="S3.SS1.p3.17.m17.3.4.2.1.cmml">^</mo></mover><mrow id="S3.SS1.p3.17.m17.3.3.3.3" xref="S3.SS1.p3.17.m17.3.3.3.4.cmml"><mi id="S3.SS1.p3.17.m17.1.1.1.1" xref="S3.SS1.p3.17.m17.1.1.1.1.cmml">s</mi><mo id="S3.SS1.p3.17.m17.3.3.3.3.3" xref="S3.SS1.p3.17.m17.3.3.3.4.cmml">,</mo><msubsup id="S3.SS1.p3.17.m17.2.2.2.2.1" xref="S3.SS1.p3.17.m17.2.2.2.2.1.cmml"><mi id="S3.SS1.p3.17.m17.2.2.2.2.1.2.2" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.17.m17.2.2.2.2.1.3" xref="S3.SS1.p3.17.m17.2.2.2.2.1.3.cmml">d</mi><mrow id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.cmml"><mi id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.2" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.1" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.3" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.1a" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.4" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.1b" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.5" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.5.cmml">e</mi></mrow></msubsup><mo id="S3.SS1.p3.17.m17.3.3.3.3.4" xref="S3.SS1.p3.17.m17.3.3.3.4.cmml">,</mo><msubsup id="S3.SS1.p3.17.m17.3.3.3.3.2" xref="S3.SS1.p3.17.m17.3.3.3.3.2.cmml"><mi id="S3.SS1.p3.17.m17.3.3.3.3.2.2.2" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.2.cmml">𝐳</mi><mi id="S3.SS1.p3.17.m17.3.3.3.3.2.3" xref="S3.SS1.p3.17.m17.3.3.3.3.2.3.cmml">d</mi><mrow id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.cmml"><mi id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.2" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.1" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.3" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.1a" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.1.cmml">​</mo><mi id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.4" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.4.cmml">n</mi></mrow></msubsup></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.17.m17.3b"><apply id="S3.SS1.p3.17.m17.3.4.cmml" xref="S3.SS1.p3.17.m17.3.4"><csymbol cd="ambiguous" id="S3.SS1.p3.17.m17.3.4.1.cmml" xref="S3.SS1.p3.17.m17.3.4">subscript</csymbol><apply id="S3.SS1.p3.17.m17.3.4.2.cmml" xref="S3.SS1.p3.17.m17.3.4.2"><ci id="S3.SS1.p3.17.m17.3.4.2.1.cmml" xref="S3.SS1.p3.17.m17.3.4.2.1">^</ci><ci id="S3.SS1.p3.17.m17.3.4.2.2.cmml" xref="S3.SS1.p3.17.m17.3.4.2.2">𝐈</ci></apply><list id="S3.SS1.p3.17.m17.3.3.3.4.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3"><ci id="S3.SS1.p3.17.m17.1.1.1.1.cmml" xref="S3.SS1.p3.17.m17.1.1.1.1">𝑠</ci><apply id="S3.SS1.p3.17.m17.2.2.2.2.1.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.17.m17.2.2.2.2.1.1.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1">subscript</csymbol><apply id="S3.SS1.p3.17.m17.2.2.2.2.1.2.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.SS1.p3.17.m17.2.2.2.2.1.2.1.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1">superscript</csymbol><ci id="S3.SS1.p3.17.m17.2.2.2.2.1.2.2.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.2">𝐳</ci><apply id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3"><times id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.1.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.1"></times><ci id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.2.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.2">𝑝</ci><ci id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.3.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.3">𝑜</ci><ci id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.4.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.4">𝑠</ci><ci id="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.5.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS1.p3.17.m17.2.2.2.2.1.3.cmml" xref="S3.SS1.p3.17.m17.2.2.2.2.1.3">𝑑</ci></apply><apply id="S3.SS1.p3.17.m17.3.3.3.3.2.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p3.17.m17.3.3.3.3.2.1.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2">subscript</csymbol><apply id="S3.SS1.p3.17.m17.3.3.3.3.2.2.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p3.17.m17.3.3.3.3.2.2.1.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2">superscript</csymbol><ci id="S3.SS1.p3.17.m17.3.3.3.3.2.2.2.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.2">𝐳</ci><apply id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3"><times id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.1.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.1"></times><ci id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.2.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.2">𝑑</ci><ci id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.3.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.3">𝑦</ci><ci id="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.4.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS1.p3.17.m17.3.3.3.3.2.3.cmml" xref="S3.SS1.p3.17.m17.3.3.3.3.2.3">𝑑</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.17.m17.3c">\hat{\mathbf{I}}_{s,\mathbf{z}^{pose}_{d},\mathbf{z}^{dyn}_{d}}</annotation></semantics></math> is applied.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2404.10667/assets/figures/pipeline_.jpg" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="186" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Our holistic facial dynamics and head pose generation framework with diffusion transformer.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Holistic Facial Dynamics Generation with Diffusion Transformer</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Given the constructed face latent space and trained encoders, we can extract the facial dynamics and head movements from real-life talking face videos and train a generative model. Crucially, we consider identity-agnostic holistic facial dynamics generation (HFDG), where our learned latent codes represent all facial movements such as lip motion, (non-lip) expression, and eye gaze and blinking. This is in contrast to existing methods that apply separate models for different factors with interleaved regression and generative formulations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>, <a href="#bib.bib74" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">74</span></a>, <a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite>. Furthermore, previous methods often train on a limited number of identities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>, <a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">65</span></a>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite> and cannot model the wide range of motion patterns of different humans, especially given an expressive motion latent space.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">In this work, we utilize diffusion models for audio-conditioned HFDG and train on massive talking face videos from a large number of identities. In particular, we apply a transformer architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">55</span></a>, <a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> for our sequence generation task. Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Expressive and Disentangled Face Latent Space Construction ‣ 3 Method ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows an overview of our HFDG framework.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.3" class="ltx_p">Formally, a motion sequence extracted from a video clip is defined as <math id="S3.SS2.p3.1.m1.5" class="ltx_Math" alttext="\mathbf{X}=\{[\mathbf{z}^{pose}_{i},\mathbf{z}^{dyn}_{i}]\},i=1,\ldots,W" display="inline"><semantics id="S3.SS2.p3.1.m1.5a"><mrow id="S3.SS2.p3.1.m1.5.5.2" xref="S3.SS2.p3.1.m1.5.5.3.cmml"><mrow id="S3.SS2.p3.1.m1.4.4.1.1" xref="S3.SS2.p3.1.m1.4.4.1.1.cmml"><mi id="S3.SS2.p3.1.m1.4.4.1.1.3" xref="S3.SS2.p3.1.m1.4.4.1.1.3.cmml">𝐗</mi><mo id="S3.SS2.p3.1.m1.4.4.1.1.2" xref="S3.SS2.p3.1.m1.4.4.1.1.2.cmml">=</mo><mrow id="S3.SS2.p3.1.m1.4.4.1.1.1.1" xref="S3.SS2.p3.1.m1.4.4.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.2" xref="S3.SS2.p3.1.m1.4.4.1.1.1.2.cmml">{</mo><mrow id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.3" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.3.cmml">[</mo><msubsup id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.2" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.2.cmml">𝐳</mi><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.3.cmml">i</mi><mrow id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.2" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.1" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.3" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.1a" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.4" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.1b" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.5" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.5.cmml">e</mi></mrow></msubsup><mo id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.4" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.3.cmml">,</mo><msubsup id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.cmml"><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.2" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.2.cmml">𝐳</mi><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.3" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.3.cmml">i</mi><mrow id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.2" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.1" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.3" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.1a" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.4" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.4.cmml">n</mi></mrow></msubsup><mo stretchy="false" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.5" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.3.cmml">]</mo></mrow><mo stretchy="false" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.3" xref="S3.SS2.p3.1.m1.4.4.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S3.SS2.p3.1.m1.5.5.2.3" xref="S3.SS2.p3.1.m1.5.5.3a.cmml">,</mo><mrow id="S3.SS2.p3.1.m1.5.5.2.2" xref="S3.SS2.p3.1.m1.5.5.2.2.cmml"><mi id="S3.SS2.p3.1.m1.5.5.2.2.2" xref="S3.SS2.p3.1.m1.5.5.2.2.2.cmml">i</mi><mo id="S3.SS2.p3.1.m1.5.5.2.2.1" xref="S3.SS2.p3.1.m1.5.5.2.2.1.cmml">=</mo><mrow id="S3.SS2.p3.1.m1.5.5.2.2.3.2" xref="S3.SS2.p3.1.m1.5.5.2.2.3.1.cmml"><mn id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">1</mn><mo id="S3.SS2.p3.1.m1.5.5.2.2.3.2.1" xref="S3.SS2.p3.1.m1.5.5.2.2.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p3.1.m1.2.2" xref="S3.SS2.p3.1.m1.2.2.cmml">…</mi><mo id="S3.SS2.p3.1.m1.5.5.2.2.3.2.2" xref="S3.SS2.p3.1.m1.5.5.2.2.3.1.cmml">,</mo><mi id="S3.SS2.p3.1.m1.3.3" xref="S3.SS2.p3.1.m1.3.3.cmml">W</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.5b"><apply id="S3.SS2.p3.1.m1.5.5.3.cmml" xref="S3.SS2.p3.1.m1.5.5.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.5.5.3a.cmml" xref="S3.SS2.p3.1.m1.5.5.2.3">formulae-sequence</csymbol><apply id="S3.SS2.p3.1.m1.4.4.1.1.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1"><eq id="S3.SS2.p3.1.m1.4.4.1.1.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.2"></eq><ci id="S3.SS2.p3.1.m1.4.4.1.1.3.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.3">𝐗</ci><set id="S3.SS2.p3.1.m1.4.4.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1"><interval closure="closed" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2"><apply id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.2">𝐳</ci><apply id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3"><times id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.2">𝑝</ci><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.3">𝑜</ci><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.4">𝑠</ci><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.5.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.1.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2">subscript</csymbol><apply id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.2">𝐳</ci><apply id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3"><times id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.1"></times><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.2">𝑑</ci><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.3">𝑦</ci><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.4.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.3.cmml" xref="S3.SS2.p3.1.m1.4.4.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval></set></apply><apply id="S3.SS2.p3.1.m1.5.5.2.2.cmml" xref="S3.SS2.p3.1.m1.5.5.2.2"><eq id="S3.SS2.p3.1.m1.5.5.2.2.1.cmml" xref="S3.SS2.p3.1.m1.5.5.2.2.1"></eq><ci id="S3.SS2.p3.1.m1.5.5.2.2.2.cmml" xref="S3.SS2.p3.1.m1.5.5.2.2.2">𝑖</ci><list id="S3.SS2.p3.1.m1.5.5.2.2.3.1.cmml" xref="S3.SS2.p3.1.m1.5.5.2.2.3.2"><cn type="integer" id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">1</cn><ci id="S3.SS2.p3.1.m1.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2">…</ci><ci id="S3.SS2.p3.1.m1.3.3.cmml" xref="S3.SS2.p3.1.m1.3.3">𝑊</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.5c">\mathbf{X}=\{[\mathbf{z}^{pose}_{i},\mathbf{z}^{dyn}_{i}]\},i=1,\ldots,W</annotation></semantics></math>. Given its accompanying audio clip <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\mathbf{a}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">𝐚</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">𝐚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\mathbf{a}</annotation></semantics></math>, we extract the synchronized audio features <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{A}=\{\mathbf{f}^{audio}_{i}\}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mrow id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">𝐀</mi><mo id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">=</mo><mrow id="S3.SS2.p3.3.m3.1.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.3.m3.1.1.1.1.2" xref="S3.SS2.p3.3.m3.1.1.1.2.cmml">{</mo><msubsup id="S3.SS2.p3.3.m3.1.1.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.2.2" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.2.cmml">𝐟</mi><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.3" xref="S3.SS2.p3.3.m3.1.1.1.1.1.3.cmml">i</mi><mrow id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.cmml"><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.2" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.3" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1a" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.4" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1b" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.5" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1c" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.6" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.6.cmml">o</mi></mrow></msubsup><mo stretchy="false" id="S3.SS2.p3.3.m3.1.1.1.1.3" xref="S3.SS2.p3.3.m3.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><eq id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2"></eq><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">𝐀</ci><set id="S3.SS2.p3.3.m3.1.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1"><apply id="S3.SS2.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1">subscript</csymbol><apply id="S3.SS2.p3.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.2">𝐟</ci><apply id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3"><times id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.1"></times><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.2">𝑎</ci><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.3">𝑢</ci><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.4.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.4">𝑑</ci><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.5.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.5">𝑖</ci><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.6.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.2.3.6">𝑜</ci></apply></apply><ci id="S3.SS2.p3.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1.3">𝑖</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathbf{A}=\{\mathbf{f}^{audio}_{i}\}</annotation></semantics></math>, for which we use a pretrained feature extractor Wav2Vec2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite>.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Diffusion formulation.</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.7" class="ltx_p">Diffusion models define two Markov chains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>, <a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite>, the forward chain progressively adds Gaussian noise to the target data, while the reverse chain iteratively restores the raw signal from noise. Following the denoising score matching objective <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite>, we define the simplified loss function as</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.8" class="ltx_Math" alttext="\mathbb{E}_{t\sim\mathcal{U}[1,T],~{}\mathbf{X}^{0},\mathbf{C}\sim q(\mathbf{X}^{0},\mathcal{C})}(\|\mathbf{X}^{0}-\mathcal{H}(\mathbf{X}^{t},t,\mathbf{C})\|^{2})," display="block"><semantics id="S3.E1.m1.8a"><mrow id="S3.E1.m1.8.8.1" xref="S3.E1.m1.8.8.1.1.cmml"><mrow id="S3.E1.m1.8.8.1.1" xref="S3.E1.m1.8.8.1.1.cmml"><msub id="S3.E1.m1.8.8.1.1.3" xref="S3.E1.m1.8.8.1.1.3.cmml"><mi id="S3.E1.m1.8.8.1.1.3.2" xref="S3.E1.m1.8.8.1.1.3.2.cmml">𝔼</mi><mrow id="S3.E1.m1.5.5.5.5" xref="S3.E1.m1.5.5.5.6.cmml"><mrow id="S3.E1.m1.4.4.4.4.1" xref="S3.E1.m1.4.4.4.4.1.cmml"><mi id="S3.E1.m1.4.4.4.4.1.4" xref="S3.E1.m1.4.4.4.4.1.4.cmml">t</mi><mo id="S3.E1.m1.4.4.4.4.1.3" xref="S3.E1.m1.4.4.4.4.1.3.cmml">∼</mo><mrow id="S3.E1.m1.4.4.4.4.1.2.2" xref="S3.E1.m1.4.4.4.4.1.2.3.cmml"><mrow id="S3.E1.m1.4.4.4.4.1.1.1.1" xref="S3.E1.m1.4.4.4.4.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.4.4.4.4.1.1.1.1.2" xref="S3.E1.m1.4.4.4.4.1.1.1.1.2.cmml">𝒰</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.4.1.1.1.1.1" xref="S3.E1.m1.4.4.4.4.1.1.1.1.1.cmml">​</mo><mrow id="S3.E1.m1.4.4.4.4.1.1.1.1.3.2" xref="S3.E1.m1.4.4.4.4.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.4.4.1.1.1.1.3.2.1" xref="S3.E1.m1.4.4.4.4.1.1.1.1.3.1.cmml">[</mo><mn id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">1</mn><mo id="S3.E1.m1.4.4.4.4.1.1.1.1.3.2.2" xref="S3.E1.m1.4.4.4.4.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">T</mi><mo stretchy="false" id="S3.E1.m1.4.4.4.4.1.1.1.1.3.2.3" xref="S3.E1.m1.4.4.4.4.1.1.1.1.3.1.cmml">]</mo></mrow></mrow><mo rspace="0.397em" id="S3.E1.m1.4.4.4.4.1.2.2.3" xref="S3.E1.m1.4.4.4.4.1.2.3.cmml">,</mo><msup id="S3.E1.m1.4.4.4.4.1.2.2.2" xref="S3.E1.m1.4.4.4.4.1.2.2.2.cmml"><mi id="S3.E1.m1.4.4.4.4.1.2.2.2.2" xref="S3.E1.m1.4.4.4.4.1.2.2.2.2.cmml">𝐗</mi><mn id="S3.E1.m1.4.4.4.4.1.2.2.2.3" xref="S3.E1.m1.4.4.4.4.1.2.2.2.3.cmml">0</mn></msup></mrow></mrow><mo id="S3.E1.m1.5.5.5.5.3" xref="S3.E1.m1.5.5.5.6a.cmml">,</mo><mrow id="S3.E1.m1.5.5.5.5.2" xref="S3.E1.m1.5.5.5.5.2.cmml"><mi id="S3.E1.m1.5.5.5.5.2.3" xref="S3.E1.m1.5.5.5.5.2.3.cmml">𝐂</mi><mo id="S3.E1.m1.5.5.5.5.2.2" xref="S3.E1.m1.5.5.5.5.2.2.cmml">∼</mo><mrow id="S3.E1.m1.5.5.5.5.2.1" xref="S3.E1.m1.5.5.5.5.2.1.cmml"><mi id="S3.E1.m1.5.5.5.5.2.1.3" xref="S3.E1.m1.5.5.5.5.2.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.5.5.5.5.2.1.2" xref="S3.E1.m1.5.5.5.5.2.1.2.cmml">​</mo><mrow id="S3.E1.m1.5.5.5.5.2.1.1.1" xref="S3.E1.m1.5.5.5.5.2.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.5.5.5.5.2.1.1.1.2" xref="S3.E1.m1.5.5.5.5.2.1.1.2.cmml">(</mo><msup id="S3.E1.m1.5.5.5.5.2.1.1.1.1" xref="S3.E1.m1.5.5.5.5.2.1.1.1.1.cmml"><mi id="S3.E1.m1.5.5.5.5.2.1.1.1.1.2" xref="S3.E1.m1.5.5.5.5.2.1.1.1.1.2.cmml">𝐗</mi><mn id="S3.E1.m1.5.5.5.5.2.1.1.1.1.3" xref="S3.E1.m1.5.5.5.5.2.1.1.1.1.3.cmml">0</mn></msup><mo id="S3.E1.m1.5.5.5.5.2.1.1.1.3" xref="S3.E1.m1.5.5.5.5.2.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml">𝒞</mi><mo stretchy="false" id="S3.E1.m1.5.5.5.5.2.1.1.1.4" xref="S3.E1.m1.5.5.5.5.2.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.8.8.1.1.2" xref="S3.E1.m1.8.8.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.8.8.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.8.8.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.cmml">(</mo><msup id="S3.E1.m1.8.8.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.8.8.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.cmml"><msup id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.2.cmml">𝐗</mi><mn id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.3.cmml">0</mn></msup><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.cmml">ℋ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msup id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐗</mi><mi id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msup><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.6.6" xref="S3.E1.m1.6.6.cmml">t</mi><mo id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E1.m1.7.7" xref="S3.E1.m1.7.7.cmml">𝐂</mi><mo stretchy="false" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E1.m1.8.8.1.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S3.E1.m1.8.8.1.1.1.1.3" xref="S3.E1.m1.8.8.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.8.8.1.2" xref="S3.E1.m1.8.8.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.8b"><apply id="S3.E1.m1.8.8.1.1.cmml" xref="S3.E1.m1.8.8.1"><times id="S3.E1.m1.8.8.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.2"></times><apply id="S3.E1.m1.8.8.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.3.1.cmml" xref="S3.E1.m1.8.8.1.1.3">subscript</csymbol><ci id="S3.E1.m1.8.8.1.1.3.2.cmml" xref="S3.E1.m1.8.8.1.1.3.2">𝔼</ci><apply id="S3.E1.m1.5.5.5.6.cmml" xref="S3.E1.m1.5.5.5.5"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.6a.cmml" xref="S3.E1.m1.5.5.5.5.3">formulae-sequence</csymbol><apply id="S3.E1.m1.4.4.4.4.1.cmml" xref="S3.E1.m1.4.4.4.4.1"><csymbol cd="latexml" id="S3.E1.m1.4.4.4.4.1.3.cmml" xref="S3.E1.m1.4.4.4.4.1.3">similar-to</csymbol><ci id="S3.E1.m1.4.4.4.4.1.4.cmml" xref="S3.E1.m1.4.4.4.4.1.4">𝑡</ci><list id="S3.E1.m1.4.4.4.4.1.2.3.cmml" xref="S3.E1.m1.4.4.4.4.1.2.2"><apply id="S3.E1.m1.4.4.4.4.1.1.1.1.cmml" xref="S3.E1.m1.4.4.4.4.1.1.1.1"><times id="S3.E1.m1.4.4.4.4.1.1.1.1.1.cmml" xref="S3.E1.m1.4.4.4.4.1.1.1.1.1"></times><ci id="S3.E1.m1.4.4.4.4.1.1.1.1.2.cmml" xref="S3.E1.m1.4.4.4.4.1.1.1.1.2">𝒰</ci><interval closure="closed" id="S3.E1.m1.4.4.4.4.1.1.1.1.3.1.cmml" xref="S3.E1.m1.4.4.4.4.1.1.1.1.3.2"><cn type="integer" id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">1</cn><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">𝑇</ci></interval></apply><apply id="S3.E1.m1.4.4.4.4.1.2.2.2.cmml" xref="S3.E1.m1.4.4.4.4.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.4.1.2.2.2.1.cmml" xref="S3.E1.m1.4.4.4.4.1.2.2.2">superscript</csymbol><ci id="S3.E1.m1.4.4.4.4.1.2.2.2.2.cmml" xref="S3.E1.m1.4.4.4.4.1.2.2.2.2">𝐗</ci><cn type="integer" id="S3.E1.m1.4.4.4.4.1.2.2.2.3.cmml" xref="S3.E1.m1.4.4.4.4.1.2.2.2.3">0</cn></apply></list></apply><apply id="S3.E1.m1.5.5.5.5.2.cmml" xref="S3.E1.m1.5.5.5.5.2"><csymbol cd="latexml" id="S3.E1.m1.5.5.5.5.2.2.cmml" xref="S3.E1.m1.5.5.5.5.2.2">similar-to</csymbol><ci id="S3.E1.m1.5.5.5.5.2.3.cmml" xref="S3.E1.m1.5.5.5.5.2.3">𝐂</ci><apply id="S3.E1.m1.5.5.5.5.2.1.cmml" xref="S3.E1.m1.5.5.5.5.2.1"><times id="S3.E1.m1.5.5.5.5.2.1.2.cmml" xref="S3.E1.m1.5.5.5.5.2.1.2"></times><ci id="S3.E1.m1.5.5.5.5.2.1.3.cmml" xref="S3.E1.m1.5.5.5.5.2.1.3">𝑞</ci><interval closure="open" id="S3.E1.m1.5.5.5.5.2.1.1.2.cmml" xref="S3.E1.m1.5.5.5.5.2.1.1.1"><apply id="S3.E1.m1.5.5.5.5.2.1.1.1.1.cmml" xref="S3.E1.m1.5.5.5.5.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.5.2.1.1.1.1.1.cmml" xref="S3.E1.m1.5.5.5.5.2.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.5.5.5.5.2.1.1.1.1.2.cmml" xref="S3.E1.m1.5.5.5.5.2.1.1.1.1.2">𝐗</ci><cn type="integer" id="S3.E1.m1.5.5.5.5.2.1.1.1.1.3.cmml" xref="S3.E1.m1.5.5.5.5.2.1.1.1.1.3">0</cn></apply><ci id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3">𝒞</ci></interval></apply></apply></apply></apply><apply id="S3.E1.m1.8.8.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.8.8.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.2">𝐗</ci><cn type="integer" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.3.3">0</cn></apply><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1"><times id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.3">ℋ</ci><vector id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.2">𝐗</ci><ci id="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="S3.E1.m1.6.6.cmml" xref="S3.E1.m1.6.6">𝑡</ci><ci id="S3.E1.m1.7.7.cmml" xref="S3.E1.m1.7.7">𝐂</ci></vector></apply></apply></apply><cn type="integer" id="S3.E1.m1.8.8.1.1.1.1.1.3.cmml" xref="S3.E1.m1.8.8.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.8c">\mathbb{E}_{t\sim\mathcal{U}[1,T],~{}\mathbf{X}^{0},\mathbf{C}\sim q(\mathbf{X}^{0},\mathcal{C})}(\|\mathbf{X}^{0}-\mathcal{H}(\mathbf{X}^{t},t,\mathbf{C})\|^{2}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS0.Px1.p1.6" class="ltx_p">where <math id="S3.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">t</annotation></semantics></math> denotes the time step, <math id="S3.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{X}^{0}=\mathbf{X}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><msup id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.2.cmml">𝐗</mi><mn id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.3.cmml">0</mn></msup><mo id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml">=</mo><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml">𝐗</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1"><eq id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1"></eq><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.2">𝐗</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.3">0</cn></apply><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3">𝐗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">\mathbf{X}^{0}=\mathbf{X}</annotation></semantics></math> is the raw motion latent sequence, and <math id="S3.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{X}^{t}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><msup id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml">𝐗</mi><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.2">𝐗</ci><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">\mathbf{X}^{t}</annotation></semantics></math> is the noisy inputs generated by the diffusion forward process <math id="S3.SS2.SSS0.Px1.p1.4.m4.4" class="ltx_Math" alttext="q(\mathbf{X}^{t}|\mathbf{X}^{t-1})=\mathcal{N}(\mathbf{X}^{t};\sqrt{1-\beta_{t}}\mathbf{X}^{t-1},\beta_{t}\mathrm{I})" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.4.m4.4a"><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.4.4" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.cmml"><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.3.cmml">q</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.2.cmml">​</mo><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml"><msup id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.2.cmml">𝐗</mi><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.3.cmml">t</mi></msup><mo fence="false" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.1.cmml">|</mo><msup id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.2.cmml">𝐗</mi><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.cmml">=</mo><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.5" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.5.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.4" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.4.cmml">​</mo><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.4" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml">(</mo><msup id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.2.cmml">𝐗</mi><mi id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.3.cmml">t</mi></msup><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.5" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml">;</mo><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.cmml"><msqrt id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.cmml"><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.cmml"><mn id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.2.cmml">1</mn><mo id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.1.cmml">−</mo><msub id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.2.cmml">β</mi><mi id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.1.cmml">​</mo><msup id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.2.cmml">𝐗</mi><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.2.cmml">t</mi><mo id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.1.cmml">−</mo><mn id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.3.cmml">1</mn></mrow></msup></mrow><mo id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.6" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml">,</mo><mrow id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.cmml"><msub id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.2" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.2.cmml">β</mi><mi id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.1" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.3" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.3.cmml">I</mi></mrow><mo stretchy="false" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.7" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.4.m4.4b"><apply id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4"><eq id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.5"></eq><apply id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1"><times id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.2"></times><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.3">𝑞</ci><apply id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.2">𝐗</ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.2">𝐗</ci><apply id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3"><minus id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.1"></minus><ci id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></apply><apply id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4"><times id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.4.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.4"></times><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.5.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.5">𝒩</ci><list id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3"><apply id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.2">𝐗</ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.3">𝑡</ci></apply><apply id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2"><times id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.1"></times><apply id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2"><root id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2a.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2"></root><apply id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2"><minus id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.1"></minus><cn type="integer" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.2">1</cn><apply id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.2">𝛽</ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.3">𝑡</ci></apply></apply></apply><apply id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.2">𝐗</ci><apply id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3"><minus id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.1"></minus><ci id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.2">𝑡</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.3">1</cn></apply></apply></apply><apply id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3"><times id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.1"></times><apply id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.2">𝛽</ci><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.3">𝑡</ci></apply><ci id="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.3">I</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.4.m4.4c">q(\mathbf{X}^{t}|\mathbf{X}^{t-1})=\mathcal{N}(\mathbf{X}^{t};\sqrt{1-\beta_{t}}\mathbf{X}^{t-1},\beta_{t}\mathrm{I})</annotation></semantics></math>. <math id="S3.SS2.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{H}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1.cmml">ℋ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.5.m5.1b"><ci id="S3.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.5.m5.1.1">ℋ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.5.m5.1c">\mathcal{H}</annotation></semantics></math> is our transformer network which predicts the raw signal itself instead of noise. <math id="S3.SS2.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\mathbf{C}" display="inline"><semantics id="S3.SS2.SSS0.Px1.p1.6.m6.1a"><mi id="S3.SS2.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS2.SSS0.Px1.p1.6.m6.1.1.cmml">𝐂</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.6.m6.1b"><ci id="S3.SS2.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.6.m6.1.1">𝐂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.6.m6.1c">\mathbf{C}</annotation></semantics></math> is the condition signal, to be described next.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Conditioning signals.</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">The primary condition signal for our audio-driven motion generation task is the audio feature sequence <math id="S3.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">𝐀</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">𝐀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">\mathbf{A}</annotation></semantics></math>. We also incorporate several additional signals, which not only make the generative modeling more tractable but also increase the generation controllability.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p2.8" class="ltx_p">Specifically, we consider the main eye gaze direction <math id="S3.SS2.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{g}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1.cmml">𝐠</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.1.m1.1.1">𝐠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.1.m1.1c">\mathbf{g}</annotation></semantics></math>, head-to-camera distance <math id="S3.SS2.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.2.m2.1a"><mi id="S3.SS2.SSS0.Px2.p2.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.2.m2.1b"><ci id="S3.SS2.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.2.m2.1c">d</annotation></semantics></math>, and emotion offset <math id="S3.SS2.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{e}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.3.m3.1a"><mi id="S3.SS2.SSS0.Px2.p2.3.m3.1.1" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1.cmml">𝐞</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.3.m3.1b"><ci id="S3.SS2.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.3.m3.1.1">𝐞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.3.m3.1c">\mathbf{e}</annotation></semantics></math>. The main gaze direction, <math id="S3.SS2.SSS0.Px2.p2.4.m4.2" class="ltx_Math" alttext="\mathbf{g}=(\theta,\phi)" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.4.m4.2a"><mrow id="S3.SS2.SSS0.Px2.p2.4.m4.2.3" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.cmml"><mi id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.2" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.2.cmml">𝐠</mi><mo id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.1" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.1.cmml">=</mo><mrow id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.2" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.2.1" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.1.cmml">(</mo><mi id="S3.SS2.SSS0.Px2.p2.4.m4.1.1" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1.cmml">θ</mi><mo id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.2.2" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.1.cmml">,</mo><mi id="S3.SS2.SSS0.Px2.p2.4.m4.2.2" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.2.cmml">ϕ</mi><mo stretchy="false" id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.2.3" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.4.m4.2b"><apply id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3"><eq id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.1"></eq><ci id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.2.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.2">𝐠</ci><interval closure="open" id="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.3.3.2"><ci id="S3.SS2.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.1.1">𝜃</ci><ci id="S3.SS2.SSS0.Px2.p2.4.m4.2.2.cmml" xref="S3.SS2.SSS0.Px2.p2.4.m4.2.2">italic-ϕ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.4.m4.2c">\mathbf{g}=(\theta,\phi)</annotation></semantics></math>, is defined by a vector in spherical coordinates. It specifies the focused direction of the generated talking face.
We extract <math id="S3.SS2.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{g}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.5.m5.1a"><mi id="S3.SS2.SSS0.Px2.p2.5.m5.1.1" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1.cmml">𝐠</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.5.m5.1b"><ci id="S3.SS2.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.5.m5.1.1">𝐠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.5.m5.1c">\mathbf{g}</annotation></semantics></math> for the training video clips using <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">70</span></a>]</cite> on each frame followed by a simple histogram-based clustering algorithm.
The head distance <math id="S3.SS2.SSS0.Px2.p2.6.m6.1" class="ltx_Math" alttext="{d}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.6.m6.1a"><mi id="S3.SS2.SSS0.Px2.p2.6.m6.1.1" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.6.m6.1b"><ci id="S3.SS2.SSS0.Px2.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.6.m6.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.6.m6.1c">{d}</annotation></semantics></math> is a normalized scalar controlling the distance between the face and the virtual camera, which affects the face scale in the generated face video.
We obtain this scale label for the training videos using <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>.
The emotion offset <math id="S3.SS2.SSS0.Px2.p2.7.m7.1" class="ltx_Math" alttext="\mathbf{e}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.7.m7.1a"><mi id="S3.SS2.SSS0.Px2.p2.7.m7.1.1" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1.cmml">𝐞</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.7.m7.1b"><ci id="S3.SS2.SSS0.Px2.p2.7.m7.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.7.m7.1.1">𝐞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.7.m7.1c">\mathbf{e}</annotation></semantics></math> modulates the depicted emotion on the talking face.
Note that emotion is often intrinsically linked to and can be largely inferred from audio; hence, <math id="S3.SS2.SSS0.Px2.p2.8.m8.1" class="ltx_Math" alttext="\mathbf{e}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p2.8.m8.1a"><mi id="S3.SS2.SSS0.Px2.p2.8.m8.1.1" xref="S3.SS2.SSS0.Px2.p2.8.m8.1.1.cmml">𝐞</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p2.8.m8.1b"><ci id="S3.SS2.SSS0.Px2.p2.8.m8.1.1.cmml" xref="S3.SS2.SSS0.Px2.p2.8.m8.1.1">𝐞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p2.8.m8.1c">\mathbf{e}</annotation></semantics></math> serves only as a <em id="S3.SS2.SSS0.Px2.p2.8.1" class="ltx_emph ltx_font_italic">global offset</em> added to enhance or moderately alter the emotion when required. It is <em id="S3.SS2.SSS0.Px2.p2.8.2" class="ltx_emph ltx_font_italic">not</em> designed to achieve a total emotion shift during inference or produce emotions incongruent with the input audio. In practice, we use the averaged emotion coefficients extracted by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite> as our emotion signal.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p3.2" class="ltx_p">In order to achieve a seamless transition between adjacent windows, we incorporate the last <math id="S3.SS2.SSS0.Px2.p3.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p3.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.1.m1.1c">K</annotation></semantics></math> frames of the audio feature and generated motions from the previous window as the condition of the current one. To summarize, our input condition can be denoted as <math id="S3.SS2.SSS0.Px2.p3.2.m2.6" class="ltx_Math" alttext="\mathbf{C}=[\mathbf{X}^{pre},\mathbf{A}^{pre};\mathbf{A},\mathbf{g},d,\mathbf{e}]" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.2.m2.6a"><mrow id="S3.SS2.SSS0.Px2.p3.2.m2.6.6" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.cmml"><mi id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.4" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.4.cmml">𝐂</mi><mo id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.3" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.3.cmml">=</mo><mrow id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.3" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml">[</mo><msup id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.2" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.2.cmml">𝐗</mi><mrow id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.2" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.1" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.3" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.1a" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.4" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.4.cmml">e</mi></mrow></msup><mo id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.4" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml">,</mo><msup id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.cmml"><mi id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.2" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.2.cmml">𝐀</mi><mrow id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.cmml"><mi id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.2" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.1" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.3" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.1a" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.4" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.4.cmml">e</mi></mrow></msup><mo id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.5" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml">;</mo><mi id="S3.SS2.SSS0.Px2.p3.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p3.2.m2.1.1.cmml">𝐀</mi><mo id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.6" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml">,</mo><mi id="S3.SS2.SSS0.Px2.p3.2.m2.2.2" xref="S3.SS2.SSS0.Px2.p3.2.m2.2.2.cmml">𝐠</mi><mo id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.7" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml">,</mo><mi id="S3.SS2.SSS0.Px2.p3.2.m2.3.3" xref="S3.SS2.SSS0.Px2.p3.2.m2.3.3.cmml">d</mi><mo id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.8" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml">,</mo><mi id="S3.SS2.SSS0.Px2.p3.2.m2.4.4" xref="S3.SS2.SSS0.Px2.p3.2.m2.4.4.cmml">𝐞</mi><mo stretchy="false" id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.9" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.2.m2.6b"><apply id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6"><eq id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.3.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.3"></eq><ci id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.4.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.4">𝐂</ci><list id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.3.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2"><apply id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.2">𝐗</ci><apply id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3"><times id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.1"></times><ci id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.2">𝑝</ci><ci id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.3">𝑟</ci><ci id="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.4.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.5.5.1.1.1.3.4">𝑒</ci></apply></apply><apply id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.2">𝐀</ci><apply id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3"><times id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.1.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.1"></times><ci id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.2.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.2">𝑝</ci><ci id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.3.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.3">𝑟</ci><ci id="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.4.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.6.6.2.2.2.3.4">𝑒</ci></apply></apply><ci id="S3.SS2.SSS0.Px2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.1.1">𝐀</ci><ci id="S3.SS2.SSS0.Px2.p3.2.m2.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.2.2">𝐠</ci><ci id="S3.SS2.SSS0.Px2.p3.2.m2.3.3.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.3.3">𝑑</ci><ci id="S3.SS2.SSS0.Px2.p3.2.m2.4.4.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.4.4">𝐞</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.2.m2.6c">\mathbf{C}=[\mathbf{X}^{pre},\mathbf{A}^{pre};\mathbf{A},\mathbf{g},d,\mathbf{e}]</annotation></semantics></math></p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Classifier-free guidance (CFG) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite>.</h4>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.6" class="ltx_p">In the training stage, we randomly drop each of the input conditions. During inference, we apply</p>
<table id="Sx2.EGx1" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.9" class="ltx_Math" alttext="\displaystyle\hat{\mathbf{X}}^{0}=(1+\sum_{\mathbf{c}\in\mathbf{C}}\lambda_{\mathbf{c}})\cdot\mathcal{H}(\mathbf{X}^{t},t,\mathbf{C})-\sum_{\mathbf{c}\in\mathbf{C}}\lambda_{c}\cdot\mathcal{H}(\mathbf{X}^{t},t,\mathbf{C}|_{\mathbf{c}=\emptyset})" display="inline"><semantics id="S3.E2.m1.9a"><mrow id="S3.E2.m1.9.9" xref="S3.E2.m1.9.9.cmml"><msup id="S3.E2.m1.9.9.6" xref="S3.E2.m1.9.9.6.cmml"><mover accent="true" id="S3.E2.m1.9.9.6.2" xref="S3.E2.m1.9.9.6.2.cmml"><mi id="S3.E2.m1.9.9.6.2.2" xref="S3.E2.m1.9.9.6.2.2.cmml">𝐗</mi><mo id="S3.E2.m1.9.9.6.2.1" xref="S3.E2.m1.9.9.6.2.1.cmml">^</mo></mover><mn id="S3.E2.m1.9.9.6.3" xref="S3.E2.m1.9.9.6.3.cmml">0</mn></msup><mo id="S3.E2.m1.9.9.5" xref="S3.E2.m1.9.9.5.cmml">=</mo><mrow id="S3.E2.m1.9.9.4" xref="S3.E2.m1.9.9.4.cmml"><mrow id="S3.E2.m1.7.7.2.2" xref="S3.E2.m1.7.7.2.2.cmml"><mrow id="S3.E2.m1.6.6.1.1.1" xref="S3.E2.m1.6.6.1.1.1.cmml"><mrow id="S3.E2.m1.6.6.1.1.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.1.1.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.6.6.1.1.1.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.1.1.cmml"><mn id="S3.E2.m1.6.6.1.1.1.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E2.m1.6.6.1.1.1.1.1.1.1" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E2.m1.6.6.1.1.1.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.cmml"><mstyle displaystyle="true" id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.cmml"><munder id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1a" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.2.cmml">∑</mo><mrow id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.cmml"><mi id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.2.cmml">𝐜</mi><mo id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.1" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.1.cmml">∈</mo><mi id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.3" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.3.cmml">𝐂</mi></mrow></munder></mstyle><msub id="S3.E2.m1.6.6.1.1.1.1.1.1.3.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.2.cmml">λ</mi><mi id="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.3.cmml">𝐜</mi></msub></mrow></mrow><mo rspace="0.055em" stretchy="false" id="S3.E2.m1.6.6.1.1.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.E2.m1.6.6.1.1.1.2" xref="S3.E2.m1.6.6.1.1.1.2.cmml">⋅</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.6.6.1.1.1.3" xref="S3.E2.m1.6.6.1.1.1.3.cmml">ℋ</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.7.7.2.2.3" xref="S3.E2.m1.7.7.2.2.3.cmml">​</mo><mrow id="S3.E2.m1.7.7.2.2.2.1" xref="S3.E2.m1.7.7.2.2.2.2.cmml"><mo stretchy="false" id="S3.E2.m1.7.7.2.2.2.1.2" xref="S3.E2.m1.7.7.2.2.2.2.cmml">(</mo><msup id="S3.E2.m1.7.7.2.2.2.1.1" xref="S3.E2.m1.7.7.2.2.2.1.1.cmml"><mi id="S3.E2.m1.7.7.2.2.2.1.1.2" xref="S3.E2.m1.7.7.2.2.2.1.1.2.cmml">𝐗</mi><mi id="S3.E2.m1.7.7.2.2.2.1.1.3" xref="S3.E2.m1.7.7.2.2.2.1.1.3.cmml">t</mi></msup><mo id="S3.E2.m1.7.7.2.2.2.1.3" xref="S3.E2.m1.7.7.2.2.2.2.cmml">,</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">t</mi><mo id="S3.E2.m1.7.7.2.2.2.1.4" xref="S3.E2.m1.7.7.2.2.2.2.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">𝐂</mi><mo stretchy="false" id="S3.E2.m1.7.7.2.2.2.1.5" xref="S3.E2.m1.7.7.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.9.9.4.5" xref="S3.E2.m1.9.9.4.5.cmml">−</mo><mrow id="S3.E2.m1.9.9.4.4" xref="S3.E2.m1.9.9.4.4.cmml"><mstyle displaystyle="true" id="S3.E2.m1.9.9.4.4.3" xref="S3.E2.m1.9.9.4.4.3.cmml"><munder id="S3.E2.m1.9.9.4.4.3a" xref="S3.E2.m1.9.9.4.4.3.cmml"><mo movablelimits="false" id="S3.E2.m1.9.9.4.4.3.2" xref="S3.E2.m1.9.9.4.4.3.2.cmml">∑</mo><mrow id="S3.E2.m1.9.9.4.4.3.3" xref="S3.E2.m1.9.9.4.4.3.3.cmml"><mi id="S3.E2.m1.9.9.4.4.3.3.2" xref="S3.E2.m1.9.9.4.4.3.3.2.cmml">𝐜</mi><mo id="S3.E2.m1.9.9.4.4.3.3.1" xref="S3.E2.m1.9.9.4.4.3.3.1.cmml">∈</mo><mi id="S3.E2.m1.9.9.4.4.3.3.3" xref="S3.E2.m1.9.9.4.4.3.3.3.cmml">𝐂</mi></mrow></munder></mstyle><mrow id="S3.E2.m1.9.9.4.4.2" xref="S3.E2.m1.9.9.4.4.2.cmml"><mrow id="S3.E2.m1.9.9.4.4.2.4" xref="S3.E2.m1.9.9.4.4.2.4.cmml"><msub id="S3.E2.m1.9.9.4.4.2.4.2" xref="S3.E2.m1.9.9.4.4.2.4.2.cmml"><mi id="S3.E2.m1.9.9.4.4.2.4.2.2" xref="S3.E2.m1.9.9.4.4.2.4.2.2.cmml">λ</mi><mi id="S3.E2.m1.9.9.4.4.2.4.2.3" xref="S3.E2.m1.9.9.4.4.2.4.2.3.cmml">c</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.9.9.4.4.2.4.1" xref="S3.E2.m1.9.9.4.4.2.4.1.cmml">⋅</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.9.9.4.4.2.4.3" xref="S3.E2.m1.9.9.4.4.2.4.3.cmml">ℋ</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.9.9.4.4.2.3" xref="S3.E2.m1.9.9.4.4.2.3.cmml">​</mo><mrow id="S3.E2.m1.9.9.4.4.2.2.2" xref="S3.E2.m1.9.9.4.4.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.9.9.4.4.2.2.2.3" xref="S3.E2.m1.9.9.4.4.2.2.3.cmml">(</mo><msup id="S3.E2.m1.8.8.3.3.1.1.1.1" xref="S3.E2.m1.8.8.3.3.1.1.1.1.cmml"><mi id="S3.E2.m1.8.8.3.3.1.1.1.1.2" xref="S3.E2.m1.8.8.3.3.1.1.1.1.2.cmml">𝐗</mi><mi id="S3.E2.m1.8.8.3.3.1.1.1.1.3" xref="S3.E2.m1.8.8.3.3.1.1.1.1.3.cmml">t</mi></msup><mo id="S3.E2.m1.9.9.4.4.2.2.2.4" xref="S3.E2.m1.9.9.4.4.2.2.3.cmml">,</mo><mi id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml">t</mi><mo id="S3.E2.m1.9.9.4.4.2.2.2.5" xref="S3.E2.m1.9.9.4.4.2.2.3.cmml">,</mo><msub id="S3.E2.m1.9.9.4.4.2.2.2.2.2" xref="S3.E2.m1.9.9.4.4.2.2.2.2.1.cmml"><mrow id="S3.E2.m1.9.9.4.4.2.2.2.2.2.2" xref="S3.E2.m1.9.9.4.4.2.2.2.2.1.cmml"><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">𝐂</mi><mo stretchy="false" id="S3.E2.m1.9.9.4.4.2.2.2.2.2.2.1" xref="S3.E2.m1.9.9.4.4.2.2.2.2.1.1.cmml">|</mo></mrow><mrow id="S3.E2.m1.4.4.1" xref="S3.E2.m1.4.4.1.cmml"><mi id="S3.E2.m1.4.4.1.2" xref="S3.E2.m1.4.4.1.2.cmml">𝐜</mi><mo id="S3.E2.m1.4.4.1.1" xref="S3.E2.m1.4.4.1.1.cmml">=</mo><mi mathvariant="normal" id="S3.E2.m1.4.4.1.3" xref="S3.E2.m1.4.4.1.3.cmml">∅</mi></mrow></msub><mo stretchy="false" id="S3.E2.m1.9.9.4.4.2.2.2.6" xref="S3.E2.m1.9.9.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.9b"><apply id="S3.E2.m1.9.9.cmml" xref="S3.E2.m1.9.9"><eq id="S3.E2.m1.9.9.5.cmml" xref="S3.E2.m1.9.9.5"></eq><apply id="S3.E2.m1.9.9.6.cmml" xref="S3.E2.m1.9.9.6"><csymbol cd="ambiguous" id="S3.E2.m1.9.9.6.1.cmml" xref="S3.E2.m1.9.9.6">superscript</csymbol><apply id="S3.E2.m1.9.9.6.2.cmml" xref="S3.E2.m1.9.9.6.2"><ci id="S3.E2.m1.9.9.6.2.1.cmml" xref="S3.E2.m1.9.9.6.2.1">^</ci><ci id="S3.E2.m1.9.9.6.2.2.cmml" xref="S3.E2.m1.9.9.6.2.2">𝐗</ci></apply><cn type="integer" id="S3.E2.m1.9.9.6.3.cmml" xref="S3.E2.m1.9.9.6.3">0</cn></apply><apply id="S3.E2.m1.9.9.4.cmml" xref="S3.E2.m1.9.9.4"><minus id="S3.E2.m1.9.9.4.5.cmml" xref="S3.E2.m1.9.9.4.5"></minus><apply id="S3.E2.m1.7.7.2.2.cmml" xref="S3.E2.m1.7.7.2.2"><times id="S3.E2.m1.7.7.2.2.3.cmml" xref="S3.E2.m1.7.7.2.2.3"></times><apply id="S3.E2.m1.6.6.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1"><ci id="S3.E2.m1.6.6.1.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1.2">⋅</ci><apply id="S3.E2.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1"><plus id="S3.E2.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.1"></plus><cn type="integer" id="S3.E2.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.2">1</cn><apply id="S3.E2.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3"><apply id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1">subscript</csymbol><sum id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.2"></sum><apply id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3"><in id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.1"></in><ci id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.2">𝐜</ci><ci id="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.3.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.1.3.3">𝐂</ci></apply></apply><apply id="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.2">𝜆</ci><ci id="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.6.6.1.1.1.1.1.1.3.2.3">𝐜</ci></apply></apply></apply><ci id="S3.E2.m1.6.6.1.1.1.3.cmml" xref="S3.E2.m1.6.6.1.1.1.3">ℋ</ci></apply><vector id="S3.E2.m1.7.7.2.2.2.2.cmml" xref="S3.E2.m1.7.7.2.2.2.1"><apply id="S3.E2.m1.7.7.2.2.2.1.1.cmml" xref="S3.E2.m1.7.7.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.2.2.2.1.1.1.cmml" xref="S3.E2.m1.7.7.2.2.2.1.1">superscript</csymbol><ci id="S3.E2.m1.7.7.2.2.2.1.1.2.cmml" xref="S3.E2.m1.7.7.2.2.2.1.1.2">𝐗</ci><ci id="S3.E2.m1.7.7.2.2.2.1.1.3.cmml" xref="S3.E2.m1.7.7.2.2.2.1.1.3">𝑡</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑡</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">𝐂</ci></vector></apply><apply id="S3.E2.m1.9.9.4.4.cmml" xref="S3.E2.m1.9.9.4.4"><apply id="S3.E2.m1.9.9.4.4.3.cmml" xref="S3.E2.m1.9.9.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.9.9.4.4.3.1.cmml" xref="S3.E2.m1.9.9.4.4.3">subscript</csymbol><sum id="S3.E2.m1.9.9.4.4.3.2.cmml" xref="S3.E2.m1.9.9.4.4.3.2"></sum><apply id="S3.E2.m1.9.9.4.4.3.3.cmml" xref="S3.E2.m1.9.9.4.4.3.3"><in id="S3.E2.m1.9.9.4.4.3.3.1.cmml" xref="S3.E2.m1.9.9.4.4.3.3.1"></in><ci id="S3.E2.m1.9.9.4.4.3.3.2.cmml" xref="S3.E2.m1.9.9.4.4.3.3.2">𝐜</ci><ci id="S3.E2.m1.9.9.4.4.3.3.3.cmml" xref="S3.E2.m1.9.9.4.4.3.3.3">𝐂</ci></apply></apply><apply id="S3.E2.m1.9.9.4.4.2.cmml" xref="S3.E2.m1.9.9.4.4.2"><times id="S3.E2.m1.9.9.4.4.2.3.cmml" xref="S3.E2.m1.9.9.4.4.2.3"></times><apply id="S3.E2.m1.9.9.4.4.2.4.cmml" xref="S3.E2.m1.9.9.4.4.2.4"><ci id="S3.E2.m1.9.9.4.4.2.4.1.cmml" xref="S3.E2.m1.9.9.4.4.2.4.1">⋅</ci><apply id="S3.E2.m1.9.9.4.4.2.4.2.cmml" xref="S3.E2.m1.9.9.4.4.2.4.2"><csymbol cd="ambiguous" id="S3.E2.m1.9.9.4.4.2.4.2.1.cmml" xref="S3.E2.m1.9.9.4.4.2.4.2">subscript</csymbol><ci id="S3.E2.m1.9.9.4.4.2.4.2.2.cmml" xref="S3.E2.m1.9.9.4.4.2.4.2.2">𝜆</ci><ci id="S3.E2.m1.9.9.4.4.2.4.2.3.cmml" xref="S3.E2.m1.9.9.4.4.2.4.2.3">𝑐</ci></apply><ci id="S3.E2.m1.9.9.4.4.2.4.3.cmml" xref="S3.E2.m1.9.9.4.4.2.4.3">ℋ</ci></apply><vector id="S3.E2.m1.9.9.4.4.2.2.3.cmml" xref="S3.E2.m1.9.9.4.4.2.2.2"><apply id="S3.E2.m1.8.8.3.3.1.1.1.1.cmml" xref="S3.E2.m1.8.8.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.8.8.3.3.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.8.8.3.3.1.1.1.1.2.cmml" xref="S3.E2.m1.8.8.3.3.1.1.1.1.2">𝐗</ci><ci id="S3.E2.m1.8.8.3.3.1.1.1.1.3.cmml" xref="S3.E2.m1.8.8.3.3.1.1.1.1.3">𝑡</ci></apply><ci id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5">𝑡</ci><apply id="S3.E2.m1.9.9.4.4.2.2.2.2.1.cmml" xref="S3.E2.m1.9.9.4.4.2.2.2.2.2"><csymbol cd="latexml" id="S3.E2.m1.9.9.4.4.2.2.2.2.1.1.cmml" xref="S3.E2.m1.9.9.4.4.2.2.2.2.2.2.1">evaluated-at</csymbol><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">𝐂</ci><apply id="S3.E2.m1.4.4.1.cmml" xref="S3.E2.m1.4.4.1"><eq id="S3.E2.m1.4.4.1.1.cmml" xref="S3.E2.m1.4.4.1.1"></eq><ci id="S3.E2.m1.4.4.1.2.cmml" xref="S3.E2.m1.4.4.1.2">𝐜</ci><emptyset id="S3.E2.m1.4.4.1.3.cmml" xref="S3.E2.m1.4.4.1.3"></emptyset></apply></apply></vector></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.9c">\displaystyle\hat{\mathbf{X}}^{0}=(1+\sum_{\mathbf{c}\in\mathbf{C}}\lambda_{\mathbf{c}})\cdot\mathcal{H}(\mathbf{X}^{t},t,\mathbf{C})-\sum_{\mathbf{c}\in\mathbf{C}}\lambda_{c}\cdot\mathcal{H}(\mathbf{X}^{t},t,\mathbf{C}|_{\mathbf{c}=\emptyset})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS0.Px3.p1.5" class="ltx_p">where <math id="S3.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\lambda_{\mathbf{c}}" display="inline"><semantics id="S3.SS2.SSS0.Px3.p1.1.m1.1a"><msub id="S3.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml">λ</mi><mi id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml">𝐜</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.2">𝜆</ci><ci id="S3.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p1.1.m1.1.1.3">𝐜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.1.m1.1c">\lambda_{\mathbf{c}}</annotation></semantics></math> is the CFG scale for condition <math id="S3.SS2.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{c}" display="inline"><semantics id="S3.SS2.SSS0.Px3.p1.2.m2.1a"><mi id="S3.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px3.p1.2.m2.1.1.cmml">𝐜</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.2.m2.1b"><ci id="S3.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.2.m2.1.1">𝐜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.2.m2.1c">\mathbf{c}</annotation></semantics></math>. <math id="S3.SS2.SSS0.Px3.p1.3.m3.2" class="ltx_Math" alttext="\mathbf{C}|_{\mathbf{c}=\emptyset}" display="inline"><semantics id="S3.SS2.SSS0.Px3.p1.3.m3.2a"><msub id="S3.SS2.SSS0.Px3.p1.3.m3.2.3.2" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.3.1.cmml"><mrow id="S3.SS2.SSS0.Px3.p1.3.m3.2.3.2.2" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.3.1.cmml"><mi id="S3.SS2.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px3.p1.3.m3.1.1.cmml">𝐂</mi><mo stretchy="false" id="S3.SS2.SSS0.Px3.p1.3.m3.2.3.2.2.1" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.3.1.1.cmml">|</mo></mrow><mrow id="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.cmml"><mi id="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.2" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.2.cmml">𝐜</mi><mo id="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.1" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.1.cmml">=</mo><mi mathvariant="normal" id="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.3" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.3.cmml">∅</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.3.m3.2b"><apply id="S3.SS2.SSS0.Px3.p1.3.m3.2.3.1.cmml" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.3.2"><csymbol cd="latexml" id="S3.SS2.SSS0.Px3.p1.3.m3.2.3.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.3.2.2.1">evaluated-at</csymbol><ci id="S3.SS2.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.3.m3.1.1">𝐂</ci><apply id="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.cmml" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1"><eq id="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.1"></eq><ci id="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.2.cmml" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.2">𝐜</ci><emptyset id="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.3.cmml" xref="S3.SS2.SSS0.Px3.p1.3.m3.2.2.1.3"></emptyset></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.3.m3.2c">\mathbf{C}|_{\mathbf{c}=\emptyset}</annotation></semantics></math> denotes that the condition <math id="S3.SS2.SSS0.Px3.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{c}" display="inline"><semantics id="S3.SS2.SSS0.Px3.p1.4.m4.1a"><mi id="S3.SS2.SSS0.Px3.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px3.p1.4.m4.1.1.cmml">𝐜</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.4.m4.1b"><ci id="S3.SS2.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.4.m4.1.1">𝐜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.4.m4.1c">\mathbf{c}</annotation></semantics></math> is replaced with <math id="S3.SS2.SSS0.Px3.p1.5.m5.1" class="ltx_Math" alttext="\emptyset" display="inline"><semantics id="S3.SS2.SSS0.Px3.p1.5.m5.1a"><mi mathvariant="normal" id="S3.SS2.SSS0.Px3.p1.5.m5.1.1" xref="S3.SS2.SSS0.Px3.p1.5.m5.1.1.cmml">∅</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p1.5.m5.1b"><emptyset id="S3.SS2.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px3.p1.5.m5.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p1.5.m5.1c">\emptyset</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p2.6" class="ltx_p">During training, we use a drop probability of <math id="S3.SS2.SSS0.Px3.p2.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.1.m1.1a"><mn id="S3.SS2.SSS0.Px3.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.1.m1.1b"><cn type="float" id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.1.m1.1c">0.1</annotation></semantics></math> for each condition except for <math id="S3.SS2.SSS0.Px3.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{X}^{pre}" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.2.m2.1a"><msup id="S3.SS2.SSS0.Px3.p2.2.m2.1.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.2.cmml">𝐗</mi><mrow id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.3" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.1a" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.4" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.4.cmml">e</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.2.m2.1b"><apply id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.2">𝐗</ci><apply id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3"><times id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.1"></times><ci id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.2">𝑝</ci><ci id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.3">𝑟</ci><ci id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.4.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.3.4">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.2.m2.1c">\mathbf{X}^{pre}</annotation></semantics></math> and <math id="S3.SS2.SSS0.Px3.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{A}^{pre}" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.3.m3.1a"><msup id="S3.SS2.SSS0.Px3.p2.3.m3.1.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.cmml">𝐀</mi><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.1a" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.4" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.4.cmml">e</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.3.m3.1b"><apply id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2">𝐀</ci><apply id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3"><times id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.1"></times><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.2">𝑝</ci><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3">𝑟</ci><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.4.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.4">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.3.m3.1c">\mathbf{A}^{pre}</annotation></semantics></math> for which we use <math id="S3.SS2.SSS0.Px3.p2.4.m4.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.4.m4.1a"><mn id="S3.SS2.SSS0.Px3.p2.4.m4.1.1" xref="S3.SS2.SSS0.Px3.p2.4.m4.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.4.m4.1b"><cn type="float" id="S3.SS2.SSS0.Px3.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.4.m4.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.4.m4.1c">0.5</annotation></semantics></math>. This is to ensure the model can well handle the first window with no preceding audio and motions (i.e., set to <math id="S3.SS2.SSS0.Px3.p2.5.m5.1" class="ltx_Math" alttext="\emptyset" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.5.m5.1a"><mi mathvariant="normal" id="S3.SS2.SSS0.Px3.p2.5.m5.1.1" xref="S3.SS2.SSS0.Px3.p2.5.m5.1.1.cmml">∅</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.5.m5.1b"><emptyset id="S3.SS2.SSS0.Px3.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.5.m5.1.1"></emptyset></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.5.m5.1c">\emptyset</annotation></semantics></math>). We also randomly drop the last few frames of <math id="S3.SS2.SSS0.Px3.p2.6.m6.1" class="ltx_Math" alttext="\mathbf{A}" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.6.m6.1a"><mi id="S3.SS2.SSS0.Px3.p2.6.m6.1.1" xref="S3.SS2.SSS0.Px3.p2.6.m6.1.1.cmml">𝐀</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.6.m6.1b"><ci id="S3.SS2.SSS0.Px3.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.6.m6.1.1">𝐀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.6.m6.1c">\mathbf{A}</annotation></semantics></math> to ensure robust motion generation for audio sequences shorter than the window length.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Talking Face Video Generation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.5" class="ltx_p">At inference time, given an arbitrary face image and an audio clip, we first extract the 3D appearance volume <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{V}^{app}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msup id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">𝐕</mi><mrow id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.1.1.3.1" xref="S3.SS3.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.1.1.3.1a" xref="S3.SS3.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.1.m1.1.1.3.4" xref="S3.SS3.p1.1.m1.1.1.3.4.cmml">p</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝐕</ci><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><times id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.1"></times><ci id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">𝑎</ci><ci id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">𝑝</ci><ci id="S3.SS3.p1.1.m1.1.1.3.4.cmml" xref="S3.SS3.p1.1.m1.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathbf{V}^{app}</annotation></semantics></math> and identity code <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{z}^{id}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msup id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">𝐳</mi><mrow id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.2.m2.1.1.3.1" xref="S3.SS3.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝐳</ci><apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><times id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3.1"></times><ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">𝑖</ci><ci id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\mathbf{z}^{id}</annotation></semantics></math> using our trained face encoders. Then, we extract the audio features, split them into segments of length <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">W</annotation></semantics></math>, and generate the head and facial motion sequences <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="\{\mathbf{X}=\{[\mathbf{z}^{pose}_{i},\mathbf{z}^{dyn}_{i}]\}\}" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mrow id="S3.SS3.p1.4.m4.1.1.1" xref="S3.SS3.p1.4.m4.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">{</mo><mrow id="S3.SS3.p1.4.m4.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.1.3.cmml">𝐗</mi><mo id="S3.SS3.p1.4.m4.1.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.1.2.cmml">=</mo><mrow id="S3.SS3.p1.4.m4.1.1.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.3.cmml">[</mo><msubsup id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.2.cmml">𝐳</mi><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.3.cmml">i</mi><mrow id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.1a" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.4" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.1b" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.5" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.5.cmml">e</mi></mrow></msubsup><mo id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.4" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.3.cmml">,</mo><msubsup id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.2.cmml">𝐳</mi><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.3.cmml">i</mi><mrow id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.1.cmml">​</mo><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.1a" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.1.cmml">​</mo><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.4" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.4.cmml">n</mi></mrow></msubsup><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.5" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.3.cmml">]</mo></mrow><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.2.cmml">}</mo></mrow></mrow><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><set id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1"><apply id="S3.SS3.p1.4.m4.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1"><eq id="S3.SS3.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.2"></eq><ci id="S3.SS3.p1.4.m4.1.1.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.3">𝐗</ci><set id="S3.SS3.p1.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1"><interval closure="closed" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2"><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.2">𝐳</ci><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3"><times id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.2">𝑝</ci><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.3">𝑜</ci><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.4">𝑠</ci><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.5.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.2.3.5">𝑒</ci></apply></apply><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.2">𝐳</ci><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3"><times id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.1"></times><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.2">𝑑</ci><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.3">𝑦</ci><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.4.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.2.3.4">𝑛</ci></apply></apply><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval></set></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">\{\mathbf{X}=\{[\mathbf{z}^{pose}_{i},\mathbf{z}^{dyn}_{i}]\}\}</annotation></semantics></math> one by one in a sliding-window manner using our trained diffusion transformer <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{H}" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">ℋ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">ℋ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">\mathcal{H}</annotation></semantics></math>. The final video can be generated subsequently using our trained decoder.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Implementation details.</h4>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.5" class="ltx_p">For face latent space learning, we use the public VoxCeleb2 dataset from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite> which contains talking face videos from about 6K subjects. We reprocess the dataset and discard the clips with multiple individuals and those of low quality using the method of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite>. For motion latent generation, we use an 8-layer transformer encoder with an embedding dim <math id="S4.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="512" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.1.m1.1a"><mn id="S4.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.1.m1.1c">512</annotation></semantics></math> and head number <math id="S4.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.2.m2.1a"><mn id="S4.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.2.m2.1b"><cn type="integer" id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.2.m2.1c">8</annotation></semantics></math> as our diffusion network. The model is trained on VoxCeleb2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite> and another high-resolution talk video dataset collected by us, which contains about 3.5K subjects. In our default setup, the model uses a forward-facing main gaze condition, an average head distance of all training videos, and an empty emotion offset condition. The CFG parameters are set to <math id="S4.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=0.5" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.3.m3.1a"><mrow id="S4.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.cmml"><msub id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml"><mi id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.2.cmml">λ</mi><mi id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1"><eq id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.1"></eq><apply id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.2">𝜆</ci><ci id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.3.m3.1c">\lambda_{\mathbf{A}}=0.5</annotation></semantics></math> and <math id="S4.SS0.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="\lambda_{\mathbf{g}}=1.0" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.4.m4.1a"><mrow id="S4.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.cmml"><msub id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml"><mi id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.2" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.2.cmml">λ</mi><mi id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.3" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.3.cmml">𝐠</mi></msub><mo id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.1" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.3" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.4.m4.1b"><apply id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1"><eq id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.1"></eq><apply id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.2">𝜆</ci><ci id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.3">𝐠</ci></apply><cn type="float" id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.4.m4.1c">\lambda_{\mathbf{g}}=1.0</annotation></semantics></math>, and <math id="S4.SS0.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.5.m5.1a"><mn id="S4.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.5.m5.1b"><cn type="integer" id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.5.m5.1c">50</annotation></semantics></math> sampling steps are used.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Evaluation benchmarks.</h4>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">We evaluate our method using two datasets. The first is a subset of VoxCeleb2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite>. We randomly selected 46 subjects from the test split of VoxCeleb2 and randomly sampled 10 video clips for each subject, resulting in a total of 460 clips. These video clips are about 5<math id="S4.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS0.SSS0.Px2.p1.1.m1.1a"><mo id="S4.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.1.m1.1c">\sim</annotation></semantics></math>15 seconds long (80% are less than 10 seconds), with most of the content being interviews and news reports. To further evaluate our method under long speech generation with a wider range of vocal variations, we further collected 32 one-minute clips of 17 individuals. These videos are predominantly sourced from online coaching sessions and educational lectures and the talking styles are considerably more diverse than VoxCeleb2. We refer to this dataset as OneMin-32.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2404.10667/assets/figures/control_.jpg" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="421" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Generated talking faces under different control signals. <em id="S4.F3.4.1" class="ltx_emph ltx_font_italic">Top row</em>: results under different main gaze direction condition (forward-facing, leftwards, rightwards, and upwards, respectively). <em id="S4.F3.5.2" class="ltx_emph ltx_font_italic">Middle row</em>: results under different head distances (from far to near). <em id="S4.F3.6.3" class="ltx_emph ltx_font_italic">Bottom row</em>: results under different emotion offset (neutral, happy, angry and surprised, respectively).
</figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2404.10667/assets/figures/id_exp.jpg" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="359" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Disentanglement between identity and motion. In these examples, the same generated head and facial motion sequences are applied onto three different face images.</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2404.10667/assets/figures/pose_exp.jpg" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="474" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Disentanglement between head pose and facial dynamics. <em id="S4.F5.2.1" class="ltx_emph ltx_font_italic">From top to bottom</em>: the raw generated sequence, applying generated poses with fixed initial facial dynamics, and applying generated facial dynamics with fixed initial head pose and pre-defined spinning poses, respectively.
</figcaption>
</figure>
</section>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Qualitative Evaluation</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Visual results.</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> presents some representative audio-driven talking face generation results of our method. Visually inspected, our method can generate high-quality video frames with vivid facial emotions. Moreover, it can generate human-like conversational behaviors, including sporadic shifts in eye gaze during speech and contemplation, as well as the natural and variable rhythm of eye blinking, among other nuances. <em id="S4.SS1.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">We highly recommend that readers view our video results online to fully perceive the capabilities and output quality of our method.</em></p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Generation controllability.</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">Figure <a href="#S4.F3" title="Figure 3 ‣ Evaluation benchmarks. ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows our generated results under different control signals including main eye gaze, head distance, and emotion offset. It is evident that our generation model can well interpret these signals and produce talking face results that closely adhere to these specified parameters.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Disentanglement of face latents.</h4>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">Figure <a href="#S4.F4" title="Figure 4 ‣ Evaluation benchmarks. ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows
that when applying the same motion latent sequences onto different subjects, our method effectively maintains both the distinct facial movements and the unique facial identities. This indicates the efficacy of our method in disentangling identity and motion.
Figure <a href="#S4.F5" title="Figure 5 ‣ Evaluation benchmarks. ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> further illustrates the effective disentanglement between head pose and facial dynamics. By holding one aspect constant and changing the other, the resulting images faithfully reflect the intended head and facial motions without interference.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Out-of-distribution generation.</h4>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p1.1" class="ltx_p">Our method exhibits the capability to handle photo and audio inputs that fall outside the training distribution. For instance, as shown in Figure <a href="#S4.F6" title="Figure 6 ‣ Out-of-distribution generation. ‣ 4.1 Qualitative Evaluation ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, it can handle artistic photos, singing audio clips (top two rows), and non-English speech (the last row). Notably, these data variants were not present in the training dataset.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2404.10667/assets/figures/ood.jpg" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="359" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Generation results with out-of-distribution images (non-photorealistic) and audios (singing audios for the first two rows and non-English speech for the last row). Our method can still generate high quality videos well-aligned with the audios, although it was not trained on such data variations.
</figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Quantitative Evaluation</h3>

<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Evaluation metrics.</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">We use the following metrics for quantitative evaluation of our generated lip movement, head pose and overall video quality, including a new data-driven audio-pose synchronization metric trained in a way similar to CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite>:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.4" class="ltx_p"><em id="S4.I1.i1.p1.4.1" class="ltx_emph ltx_font_italic">Audio-lip synchronization.</em> We use a pretrained audio-lip synchronization network, i.e., SyncNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>, to assess the alignment of the input audio with the generated lip movements in videos. Specifically, we compute the confidence score and feature distance as <math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="S_{C}" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><msub id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml"><mi id="S4.I1.i1.p1.1.m1.1.1.2" xref="S4.I1.i1.p1.1.m1.1.1.2.cmml">S</mi><mi id="S4.I1.i1.p1.1.m1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><apply id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.I1.i1.p1.1.m1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.I1.i1.p1.1.m1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.2">𝑆</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">S_{C}</annotation></semantics></math> and <math id="S4.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="S_{D}" display="inline"><semantics id="S4.I1.i1.p1.2.m2.1a"><msub id="S4.I1.i1.p1.2.m2.1.1" xref="S4.I1.i1.p1.2.m2.1.1.cmml"><mi id="S4.I1.i1.p1.2.m2.1.1.2" xref="S4.I1.i1.p1.2.m2.1.1.2.cmml">S</mi><mi id="S4.I1.i1.p1.2.m2.1.1.3" xref="S4.I1.i1.p1.2.m2.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.2.m2.1b"><apply id="S4.I1.i1.p1.2.m2.1.1.cmml" xref="S4.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.I1.i1.p1.2.m2.1.1.1.cmml" xref="S4.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.I1.i1.p1.2.m2.1.1.2.cmml" xref="S4.I1.i1.p1.2.m2.1.1.2">𝑆</ci><ci id="S4.I1.i1.p1.2.m2.1.1.3.cmml" xref="S4.I1.i1.p1.2.m2.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.2.m2.1c">S_{D}</annotation></semantics></math> respectively. Higher <math id="S4.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="S_{C}" display="inline"><semantics id="S4.I1.i1.p1.3.m3.1a"><msub id="S4.I1.i1.p1.3.m3.1.1" xref="S4.I1.i1.p1.3.m3.1.1.cmml"><mi id="S4.I1.i1.p1.3.m3.1.1.2" xref="S4.I1.i1.p1.3.m3.1.1.2.cmml">S</mi><mi id="S4.I1.i1.p1.3.m3.1.1.3" xref="S4.I1.i1.p1.3.m3.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.3.m3.1b"><apply id="S4.I1.i1.p1.3.m3.1.1.cmml" xref="S4.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.I1.i1.p1.3.m3.1.1.1.cmml" xref="S4.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.I1.i1.p1.3.m3.1.1.2.cmml" xref="S4.I1.i1.p1.3.m3.1.1.2">𝑆</ci><ci id="S4.I1.i1.p1.3.m3.1.1.3.cmml" xref="S4.I1.i1.p1.3.m3.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.3.m3.1c">S_{C}</annotation></semantics></math> and lower <math id="S4.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="S_{D}" display="inline"><semantics id="S4.I1.i1.p1.4.m4.1a"><msub id="S4.I1.i1.p1.4.m4.1.1" xref="S4.I1.i1.p1.4.m4.1.1.cmml"><mi id="S4.I1.i1.p1.4.m4.1.1.2" xref="S4.I1.i1.p1.4.m4.1.1.2.cmml">S</mi><mi id="S4.I1.i1.p1.4.m4.1.1.3" xref="S4.I1.i1.p1.4.m4.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.4.m4.1b"><apply id="S4.I1.i1.p1.4.m4.1.1.cmml" xref="S4.I1.i1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.I1.i1.p1.4.m4.1.1.1.cmml" xref="S4.I1.i1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.I1.i1.p1.4.m4.1.1.2.cmml" xref="S4.I1.i1.p1.4.m4.1.1.2">𝑆</ci><ci id="S4.I1.i1.p1.4.m4.1.1.3.cmml" xref="S4.I1.i1.p1.4.m4.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.4.m4.1c">S_{D}</annotation></semantics></math> indicate better audio-lip synchronization quality in general.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><em id="S4.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Audio-pose alignment.</em> Measuring the alignment between the generated head poses and input audio is not trivial and there are no well-established metrics. A few recent studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> employed the Beat Align Score <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite> to evaluate audio-pose alignment. However, this metric is not optimal because the concept of a “beat” in the context of natural speech and human head motion is ambiguous.
In this work, we introduce a new data-driven metric called <em id="S4.I1.i2.p1.1.2" class="ltx_emph ltx_font_italic">Contrastive Audio and Pose Pretraining (CAPP)</em> score. Inspired by CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite>, we jointly train a pose sequence encoder and an audio sequence encoder and predict whether the input pose sequence and audio are paired. The audio encoder is initialized from a pretrained Wav2Vec2 network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> and the pose encoder is a randomly initialized 6-layer transformer network. The input window size is 3 seconds. Our CAPP model is trained on 2K hours of real-life audio and pose sequences, and demonstrates a robust capability to assess the degree of synchronization between audio inputs and generate poses (see Sec. <a href="#S4.SS3" title="4.3 Analysis and Ablation Study ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.2" class="ltx_p"><em id="S4.I1.i3.p1.2.1" class="ltx_emph ltx_font_italic">Pose variation intensity.</em> We further define a pose variation intensity score <math id="S4.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="\Delta P" display="inline"><semantics id="S4.I1.i3.p1.1.m1.1a"><mrow id="S4.I1.i3.p1.1.m1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S4.I1.i3.p1.1.m1.1.1.2" xref="S4.I1.i3.p1.1.m1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.1.m1.1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.1.m1.1.1.3" xref="S4.I1.i3.p1.1.m1.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.1b"><apply id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1"><times id="S4.I1.i3.p1.1.m1.1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1.1"></times><ci id="S4.I1.i3.p1.1.m1.1.1.2.cmml" xref="S4.I1.i3.p1.1.m1.1.1.2">Δ</ci><ci id="S4.I1.i3.p1.1.m1.1.1.3.cmml" xref="S4.I1.i3.p1.1.m1.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.1c">\Delta P</annotation></semantics></math> which is the average of the pose angle differences between adjacent frames. Averaged over all the frames of all generated videos, <math id="S4.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="\Delta P" display="inline"><semantics id="S4.I1.i3.p1.2.m2.1a"><mrow id="S4.I1.i3.p1.2.m2.1.1" xref="S4.I1.i3.p1.2.m2.1.1.cmml"><mi mathvariant="normal" id="S4.I1.i3.p1.2.m2.1.1.2" xref="S4.I1.i3.p1.2.m2.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.I1.i3.p1.2.m2.1.1.1" xref="S4.I1.i3.p1.2.m2.1.1.1.cmml">​</mo><mi id="S4.I1.i3.p1.2.m2.1.1.3" xref="S4.I1.i3.p1.2.m2.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.2.m2.1b"><apply id="S4.I1.i3.p1.2.m2.1.1.cmml" xref="S4.I1.i3.p1.2.m2.1.1"><times id="S4.I1.i3.p1.2.m2.1.1.1.cmml" xref="S4.I1.i3.p1.2.m2.1.1.1"></times><ci id="S4.I1.i3.p1.2.m2.1.1.2.cmml" xref="S4.I1.i3.p1.2.m2.1.1.2">Δ</ci><ci id="S4.I1.i3.p1.2.m2.1.1.3.cmml" xref="S4.I1.i3.p1.2.m2.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.2.m2.1c">\Delta P</annotation></semantics></math> provides an indication of the overall head motion intensity generated by a method.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><em id="S4.I1.i4.p1.1.1" class="ltx_emph ltx_font_italic">Video quality.</em> Following previous video generation works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">66</span></a>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite>, we use the Fréchet Video Distance (FVD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite> to evaluate the generated video quality. We compute the FVD metric using sequences of 25 consecutive frames.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Compared methods.</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">We compare our method with there existing audio-driven talking face generation methods: MakeItTalk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">75</span></a>]</cite>, Audio2Head <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite>, and SadTalker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite>.
MakeItTalk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">75</span></a>]</cite> employs an LSTM to convert audio into dynamic facial landmarks, then use the landmarks to animate a source image into a video sequence through either image warping or neural network based image translation. Audio2Head <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite> uses a motion-aware recurrent network to translate audio into head poses, which, along with the original audio, are used to generate dense motion fields. The motion fields are further applied to the image features and the final output is then generated by a neural network.
SadTalker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite> employs a VAE network to generate pose offsets from audio and a regression network to predict lip-only coefficients from audio features. A random variable is used for eye blink generation. This method can generate varied poses and eye blinks from identical audio inputs but only regress a deterministic pattern for other motions such as eyebrow, gaze and facial expressions.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Main results.</h4>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p1.1" class="ltx_p">For each audio input, we generate a single video for deterministic approaches, i.e., MakeItTalk and Audio2Head. For SadTalker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite> and our method, we sample three videos for each audio and average the computed metrics.
Since different pose representations are used by these methods, we re-extract the head poses from the generated frames to compute the pose-related metrics (i.e., CAPP and <math id="S4.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\Delta P" display="inline"><semantics id="S4.SS2.SSS0.Px3.p1.1.m1.1a"><mrow id="S4.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1"><times id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1"></times><ci id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2">Δ</ci><ci id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p1.1.m1.1c">\Delta P</annotation></semantics></math>).
For the FVD metric, we use 2K 25-frame video clips of both the real videos and generated ones.
For reference purpose, we also report the evaluated metrics of real videos.</p>
</div>
<div id="S4.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p2.3" class="ltx_p">Table <a href="#S4.T1" title="Table 1 ‣ Main results. ‣ 4.2 Quantitative Evaluation ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Table <a href="#S4.T2" title="Table 2 ‣ Main results. ‣ 4.2 Quantitative Evaluation ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> present the results on the VoxCeleb2 and OneMin-32 benchmarks. Note that we did not evaluate the FVD on VoxCeleb2 as its video quality is varied and often low. On both benchmarks, our method achieves the best results among all methods on all evaluated metrics. In terms of audio-lip synchronization scores (<math id="S4.SS2.SSS0.Px3.p2.1.m1.1" class="ltx_Math" alttext="S_{C}" display="inline"><semantics id="S4.SS2.SSS0.Px3.p2.1.m1.1a"><msub id="S4.SS2.SSS0.Px3.p2.1.m1.1.1" xref="S4.SS2.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="S4.SS2.SSS0.Px3.p2.1.m1.1.1.2" xref="S4.SS2.SSS0.Px3.p2.1.m1.1.1.2.cmml">S</mi><mi id="S4.SS2.SSS0.Px3.p2.1.m1.1.1.3" xref="S4.SS2.SSS0.Px3.p2.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.1.m1.1b"><apply id="S4.SS2.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px3.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p2.1.m1.1.1.2">𝑆</ci><ci id="S4.SS2.SSS0.Px3.p2.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p2.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p2.1.m1.1c">S_{C}</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px3.p2.2.m2.1" class="ltx_Math" alttext="S_{D}" display="inline"><semantics id="S4.SS2.SSS0.Px3.p2.2.m2.1a"><msub id="S4.SS2.SSS0.Px3.p2.2.m2.1.1" xref="S4.SS2.SSS0.Px3.p2.2.m2.1.1.cmml"><mi id="S4.SS2.SSS0.Px3.p2.2.m2.1.1.2" xref="S4.SS2.SSS0.Px3.p2.2.m2.1.1.2.cmml">S</mi><mi id="S4.SS2.SSS0.Px3.p2.2.m2.1.1.3" xref="S4.SS2.SSS0.Px3.p2.2.m2.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.2.m2.1b"><apply id="S4.SS2.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px3.p2.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px3.p2.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p2.2.m2.1.1.2">𝑆</ci><ci id="S4.SS2.SSS0.Px3.p2.2.m2.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p2.2.m2.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p2.2.m2.1c">S_{D}</annotation></semantics></math>), our method outperforms all others by a wide margin. Note that our method yields better scores than real videos, which is due to effect of the audio CFG (see Sec. <a href="#S4.SS3" title="4.3 Analysis and Ablation Study ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>). Our generated poses are better aligned with the audios especially on the OneMin-32 benchmark, as reflected by the CAPP scores. The head movements also exhibit the highest intensity according to <math id="S4.SS2.SSS0.Px3.p2.3.m3.1" class="ltx_Math" alttext="\Delta P" display="inline"><semantics id="S4.SS2.SSS0.Px3.p2.3.m3.1a"><mrow id="S4.SS2.SSS0.Px3.p2.3.m3.1.1" xref="S4.SS2.SSS0.Px3.p2.3.m3.1.1.cmml"><mi mathvariant="normal" id="S4.SS2.SSS0.Px3.p2.3.m3.1.1.2" xref="S4.SS2.SSS0.Px3.p2.3.m3.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px3.p2.3.m3.1.1.1" xref="S4.SS2.SSS0.Px3.p2.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS2.SSS0.Px3.p2.3.m3.1.1.3" xref="S4.SS2.SSS0.Px3.p2.3.m3.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.3.m3.1b"><apply id="S4.SS2.SSS0.Px3.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.3.m3.1.1"><times id="S4.SS2.SSS0.Px3.p2.3.m3.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.3.m3.1.1.1"></times><ci id="S4.SS2.SSS0.Px3.p2.3.m3.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p2.3.m3.1.1.2">Δ</ci><ci id="S4.SS2.SSS0.Px3.p2.3.m3.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p2.3.m3.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p2.3.m3.1c">\Delta P</annotation></semantics></math>, although there’s still a gap to the intensity of real videos. Our FVD score is significantly lower than others, demonstrating the much higher video quality and realism of our results.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison with previous methods on the VoxCeleb2 benchmark. </figcaption>
<table id="S4.T1.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.6.6" class="ltx_tr">
<th id="S4.T1.6.6.7" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="S_{C}" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><msub id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.1.1.1.m1.1.1.2" xref="S4.T1.1.1.1.m1.1.1.2.cmml">S</mi><mi mathsize="90%" id="S4.T1.1.1.1.m1.1.1.3" xref="S4.T1.1.1.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.1.1.1.m1.1.1.2.cmml" xref="S4.T1.1.1.1.m1.1.1.2">𝑆</ci><ci id="S4.T1.1.1.1.m1.1.1.3.cmml" xref="S4.T1.1.1.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">S_{C}</annotation></semantics></math><span id="S4.T1.2.2.2.1" class="ltx_text" style="font-size:90%;"> </span><math id="S4.T1.2.2.2.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.2.2.2.m2.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.2.2.2.m2.1.1" xref="S4.T1.2.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m2.1b"><ci id="S4.T1.2.2.2.m2.1.1.cmml" xref="S4.T1.2.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m2.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T1.3.3.3.m1.1" class="ltx_Math" alttext="S_{D}" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><msub id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml"><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.2" xref="S4.T1.3.3.3.m1.1.1.2.cmml">S</mi><mi mathsize="90%" id="S4.T1.3.3.3.m1.1.1.3" xref="S4.T1.3.3.3.m1.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><apply id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.3.3.3.m1.1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T1.3.3.3.m1.1.1.2.cmml" xref="S4.T1.3.3.3.m1.1.1.2">𝑆</ci><ci id="S4.T1.3.3.3.m1.1.1.3.cmml" xref="S4.T1.3.3.3.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">S_{D}</annotation></semantics></math><span id="S4.T1.4.4.4.1" class="ltx_text" style="font-size:90%;"> </span><math id="S4.T1.4.4.4.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.4.4.4.m2.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.4.4.4.m2.1.1" xref="S4.T1.4.4.4.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m2.1b"><ci id="S4.T1.4.4.4.m2.1.1.cmml" xref="S4.T1.4.4.4.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.m2.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T1.5.5.5.1" class="ltx_text" style="font-size:90%;">CAPP</span><math id="S4.T1.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.5.5.5.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T1.5.5.5.m1.1.1" xref="S4.T1.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.m1.1b"><ci id="S4.T1.5.5.5.m1.1.1.cmml" xref="S4.T1.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T1.6.6.6" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T1.6.6.6.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T1.6.6.6.m1.1a"><mi mathsize="90%" mathvariant="normal" id="S4.T1.6.6.6.m1.1.1" xref="S4.T1.6.6.6.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.m1.1b"><ci id="S4.T1.6.6.6.m1.1.1.cmml" xref="S4.T1.6.6.6.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.m1.1c">\Delta</annotation></semantics></math><span id="S4.T1.6.6.6.1" class="ltx_text" style="font-size:90%;">P</span>
</td>
</tr>
<tr id="S4.T1.10.11.1" class="ltx_tr">
<th id="S4.T1.10.11.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">
<span id="S4.T1.10.11.1.1.1" class="ltx_text" style="font-size:90%;">MakeItTalk </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.10.11.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib75" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">75</span></a><span id="S4.T1.10.11.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T1.10.11.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.10.11.1.2.1" class="ltx_text" style="font-size:90%;">4.176</span></td>
<td id="S4.T1.10.11.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.10.11.1.3.1" class="ltx_text" style="font-size:90%;">15.513</span></td>
<td id="S4.T1.10.11.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.10.11.1.4.1" class="ltx_text" style="font-size:90%;">-0.051</span></td>
<td id="S4.T1.10.11.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.10.11.1.5.1" class="ltx_text" style="font-size:90%;">0.210</span></td>
</tr>
<tr id="S4.T1.10.12.2" class="ltx_tr">
<th id="S4.T1.10.12.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="S4.T1.10.12.2.1.1" class="ltx_text" style="font-size:90%;">Audio2Head </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.10.12.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a><span id="S4.T1.10.12.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T1.10.12.2.2" class="ltx_td ltx_align_center"><span id="S4.T1.10.12.2.2.1" class="ltx_text" style="font-size:90%;">6.172</span></td>
<td id="S4.T1.10.12.2.3" class="ltx_td ltx_align_center"><span id="S4.T1.10.12.2.3.1" class="ltx_text" style="font-size:90%;">8.470</span></td>
<td id="S4.T1.10.12.2.4" class="ltx_td ltx_align_center"><span id="S4.T1.10.12.2.4.1" class="ltx_text" style="font-size:90%;">0.246</span></td>
<td id="S4.T1.10.12.2.5" class="ltx_td ltx_align_center"><span id="S4.T1.10.12.2.5.1" class="ltx_text" style="font-size:90%;">0.260</span></td>
</tr>
<tr id="S4.T1.10.13.3" class="ltx_tr">
<th id="S4.T1.10.13.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="S4.T1.10.13.3.1.1" class="ltx_text" style="font-size:90%;">SadTalker </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.10.13.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a><span id="S4.T1.10.13.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T1.10.13.3.2" class="ltx_td ltx_align_center"><span id="S4.T1.10.13.3.2.1" class="ltx_text" style="font-size:90%;">5.843</span></td>
<td id="S4.T1.10.13.3.3" class="ltx_td ltx_align_center"><span id="S4.T1.10.13.3.3.1" class="ltx_text" style="font-size:90%;">8.813</span></td>
<td id="S4.T1.10.13.3.4" class="ltx_td ltx_align_center"><span id="S4.T1.10.13.3.4.1" class="ltx_text" style="font-size:90%;">0.441</span></td>
<td id="S4.T1.10.13.3.5" class="ltx_td ltx_align_center"><span id="S4.T1.10.13.3.5.1" class="ltx_text" style="font-size:90%;">0.275</span></td>
</tr>
<tr id="S4.T1.10.10" class="ltx_tr">
<th id="S4.T1.10.10.5" class="ltx_td ltx_align_center ltx_th ltx_th_row"><em id="S4.T1.10.10.5.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Ours</em></th>
<td id="S4.T1.7.7.1" class="ltx_td ltx_align_center"><math id="S4.T1.7.7.1.m1.1" class="ltx_Math" alttext="\mathbb{8.841}" display="inline"><semantics id="S4.T1.7.7.1.m1.1a"><mn class="ltx_mathvariant_double-struck" mathsize="90%" mathvariant="double-struck" id="S4.T1.7.7.1.m1.1.1" xref="S4.T1.7.7.1.m1.1.1.cmml">8.841</mn><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.1.m1.1b"><cn type="float" id="S4.T1.7.7.1.m1.1.1.cmml" xref="S4.T1.7.7.1.m1.1.1">8.841</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.1.m1.1c">\mathbb{8.841}</annotation></semantics></math></td>
<td id="S4.T1.8.8.2" class="ltx_td ltx_align_center"><math id="S4.T1.8.8.2.m1.1" class="ltx_Math" alttext="\mathbb{6.312}" display="inline"><semantics id="S4.T1.8.8.2.m1.1a"><mn class="ltx_mathvariant_double-struck" mathsize="90%" mathvariant="double-struck" id="S4.T1.8.8.2.m1.1.1" xref="S4.T1.8.8.2.m1.1.1.cmml">6.312</mn><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.2.m1.1b"><cn type="float" id="S4.T1.8.8.2.m1.1.1.cmml" xref="S4.T1.8.8.2.m1.1.1">6.312</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.2.m1.1c">\mathbb{6.312}</annotation></semantics></math></td>
<td id="S4.T1.9.9.3" class="ltx_td ltx_align_center"><math id="S4.T1.9.9.3.m1.1" class="ltx_Math" alttext="\mathbb{0.468}" display="inline"><semantics id="S4.T1.9.9.3.m1.1a"><mn class="ltx_mathvariant_double-struck" mathsize="90%" mathvariant="double-struck" id="S4.T1.9.9.3.m1.1.1" xref="S4.T1.9.9.3.m1.1.1.cmml">0.468</mn><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.3.m1.1b"><cn type="float" id="S4.T1.9.9.3.m1.1.1.cmml" xref="S4.T1.9.9.3.m1.1.1">0.468</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.3.m1.1c">\mathbb{0.468}</annotation></semantics></math></td>
<td id="S4.T1.10.10.4" class="ltx_td ltx_align_center"><math id="S4.T1.10.10.4.m1.1" class="ltx_Math" alttext="\mathbb{0.304}" display="inline"><semantics id="S4.T1.10.10.4.m1.1a"><mn class="ltx_mathvariant_double-struck" mathsize="90%" mathvariant="double-struck" id="S4.T1.10.10.4.m1.1.1" xref="S4.T1.10.10.4.m1.1.1.cmml">0.304</mn><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.4.m1.1b"><cn type="float" id="S4.T1.10.10.4.m1.1.1.cmml" xref="S4.T1.10.10.4.m1.1.1">0.304</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.4.m1.1c">\mathbb{0.304}</annotation></semantics></math></td>
</tr>
<tr id="S4.T1.10.14.4" class="ltx_tr">
<th id="S4.T1.10.14.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_t"><span id="S4.T1.10.14.4.1.1" class="ltx_text" style="font-size:90%;color:#808080;">Real video</span></th>
<td id="S4.T1.10.14.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.10.14.4.2.1" class="ltx_text" style="font-size:90%;color:#808080;">7.640</span></td>
<td id="S4.T1.10.14.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.10.14.4.3.1" class="ltx_text" style="font-size:90%;color:#808080;">7.189</span></td>
<td id="S4.T1.10.14.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.10.14.4.4.1" class="ltx_text" style="font-size:90%;color:#808080;">0.588</span></td>
<td id="S4.T1.10.14.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.10.14.4.5.1" class="ltx_text" style="font-size:90%;color:#808080;">0.505</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison with previous methods on the OneMin-32 benchmark.</figcaption>
<table id="S4.T2.12" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.7.7" class="ltx_tr">
<td id="S4.T2.7.7.8" class="ltx_td ltx_border_t"></td>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="S_{C}" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><msub id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml"><mi id="S4.T2.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.m1.1.1.2.cmml">S</mi><mi id="S4.T2.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T2.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.m1.1.1.2">𝑆</ci><ci id="S4.T2.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">S_{C}</annotation></semantics></math> <math id="S4.T2.2.2.2.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.2.2.2.m2.1a"><mo stretchy="false" id="S4.T2.2.2.2.m2.1.1" xref="S4.T2.2.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m2.1b"><ci id="S4.T2.2.2.2.m2.1.1.cmml" xref="S4.T2.2.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m2.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T2.4.4.4" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T2.3.3.3.m1.1" class="ltx_Math" alttext="S_{D}" display="inline"><semantics id="S4.T2.3.3.3.m1.1a"><msub id="S4.T2.3.3.3.m1.1.1" xref="S4.T2.3.3.3.m1.1.1.cmml"><mi id="S4.T2.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.m1.1.1.2.cmml">S</mi><mi id="S4.T2.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.m1.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T2.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.m1.1.1.2">𝑆</ci><ci id="S4.T2.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">S_{D}</annotation></semantics></math> <math id="S4.T2.4.4.4.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.4.4.4.m2.1a"><mo stretchy="false" id="S4.T2.4.4.4.m2.1.1" xref="S4.T2.4.4.4.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m2.1b"><ci id="S4.T2.4.4.4.m2.1.1.cmml" xref="S4.T2.4.4.4.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m2.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T2.5.5.5" class="ltx_td ltx_align_center ltx_border_t">CAPP<math id="S4.T2.5.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.5.5.5.m1.1a"><mo stretchy="false" id="S4.T2.5.5.5.m1.1.1" xref="S4.T2.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.m1.1b"><ci id="S4.T2.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.m1.1c">\uparrow</annotation></semantics></math>
</td>
<td id="S4.T2.6.6.6" class="ltx_td ltx_align_center ltx_border_t">
<math id="S4.T2.6.6.6.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T2.6.6.6.m1.1a"><mi mathvariant="normal" id="S4.T2.6.6.6.m1.1.1" xref="S4.T2.6.6.6.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.m1.1b"><ci id="S4.T2.6.6.6.m1.1.1.cmml" xref="S4.T2.6.6.6.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.m1.1c">\Delta</annotation></semantics></math>P</td>
<td id="S4.T2.7.7.7" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T2.7.7.7.m1.1" class="ltx_Math" alttext="\text{FVD}_{25}\downarrow" display="inline"><semantics id="S4.T2.7.7.7.m1.1a"><mrow id="S4.T2.7.7.7.m1.1.1" xref="S4.T2.7.7.7.m1.1.1.cmml"><msub id="S4.T2.7.7.7.m1.1.1.2" xref="S4.T2.7.7.7.m1.1.1.2.cmml"><mtext id="S4.T2.7.7.7.m1.1.1.2.2" xref="S4.T2.7.7.7.m1.1.1.2.2a.cmml">FVD</mtext><mn id="S4.T2.7.7.7.m1.1.1.2.3" xref="S4.T2.7.7.7.m1.1.1.2.3.cmml">25</mn></msub><mo stretchy="false" id="S4.T2.7.7.7.m1.1.1.1" xref="S4.T2.7.7.7.m1.1.1.1.cmml">↓</mo><mi id="S4.T2.7.7.7.m1.1.1.3" xref="S4.T2.7.7.7.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.m1.1b"><apply id="S4.T2.7.7.7.m1.1.1.cmml" xref="S4.T2.7.7.7.m1.1.1"><ci id="S4.T2.7.7.7.m1.1.1.1.cmml" xref="S4.T2.7.7.7.m1.1.1.1">↓</ci><apply id="S4.T2.7.7.7.m1.1.1.2.cmml" xref="S4.T2.7.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.7.7.7.m1.1.1.2.1.cmml" xref="S4.T2.7.7.7.m1.1.1.2">subscript</csymbol><ci id="S4.T2.7.7.7.m1.1.1.2.2a.cmml" xref="S4.T2.7.7.7.m1.1.1.2.2"><mtext id="S4.T2.7.7.7.m1.1.1.2.2.cmml" xref="S4.T2.7.7.7.m1.1.1.2.2">FVD</mtext></ci><cn type="integer" id="S4.T2.7.7.7.m1.1.1.2.3.cmml" xref="S4.T2.7.7.7.m1.1.1.2.3">25</cn></apply><csymbol cd="latexml" id="S4.T2.7.7.7.m1.1.1.3.cmml" xref="S4.T2.7.7.7.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.m1.1c">\text{FVD}_{25}\downarrow</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.12.13.1" class="ltx_tr">
<td id="S4.T2.12.13.1.1" class="ltx_td ltx_align_center ltx_border_t">MakeItTalk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">75</span></a>]</cite>
</td>
<td id="S4.T2.12.13.1.2" class="ltx_td ltx_align_center ltx_border_t">-0.123</td>
<td id="S4.T2.12.13.1.3" class="ltx_td ltx_align_center ltx_border_t">14.340</td>
<td id="S4.T2.12.13.1.4" class="ltx_td ltx_align_center ltx_border_t">0.002</td>
<td id="S4.T2.12.13.1.5" class="ltx_td ltx_align_center ltx_border_t">0.190</td>
<td id="S4.T2.12.13.1.6" class="ltx_td ltx_align_center ltx_border_t">304.833</td>
</tr>
<tr id="S4.T2.12.14.2" class="ltx_tr">
<td id="S4.T2.12.14.2.1" class="ltx_td ltx_align_center">Audio2Head <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>]</cite>
</td>
<td id="S4.T2.12.14.2.2" class="ltx_td ltx_align_center">5.992</td>
<td id="S4.T2.12.14.2.3" class="ltx_td ltx_align_center">8.211</td>
<td id="S4.T2.12.14.2.4" class="ltx_td ltx_align_center">0.205</td>
<td id="S4.T2.12.14.2.5" class="ltx_td ltx_align_center">0.239</td>
<td id="S4.T2.12.14.2.6" class="ltx_td ltx_align_center">209.772</td>
</tr>
<tr id="S4.T2.12.15.3" class="ltx_tr">
<td id="S4.T2.12.15.3.1" class="ltx_td ltx_align_center">SadTalker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite>
</td>
<td id="S4.T2.12.15.3.2" class="ltx_td ltx_align_center">5.501</td>
<td id="S4.T2.12.15.3.3" class="ltx_td ltx_align_center">8.850</td>
<td id="S4.T2.12.15.3.4" class="ltx_td ltx_align_center">0.383</td>
<td id="S4.T2.12.15.3.5" class="ltx_td ltx_align_center">0.252</td>
<td id="S4.T2.12.15.3.6" class="ltx_td ltx_align_center">214.507</td>
</tr>
<tr id="S4.T2.12.12" class="ltx_tr">
<td id="S4.T2.12.12.6" class="ltx_td ltx_align_center"><em id="S4.T2.12.12.6.1" class="ltx_emph ltx_font_italic">Ours</em></td>
<td id="S4.T2.8.8.1" class="ltx_td ltx_align_center"><math id="S4.T2.8.8.1.m1.1" class="ltx_Math" alttext="\mathbb{7.957}" display="inline"><semantics id="S4.T2.8.8.1.m1.1a"><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T2.8.8.1.m1.1.1" xref="S4.T2.8.8.1.m1.1.1.cmml">7.957</mn><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.1.m1.1b"><cn type="float" id="S4.T2.8.8.1.m1.1.1.cmml" xref="S4.T2.8.8.1.m1.1.1">7.957</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.1.m1.1c">\mathbb{7.957}</annotation></semantics></math></td>
<td id="S4.T2.9.9.2" class="ltx_td ltx_align_center"><math id="S4.T2.9.9.2.m1.1" class="ltx_Math" alttext="\mathbb{6.635}" display="inline"><semantics id="S4.T2.9.9.2.m1.1a"><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T2.9.9.2.m1.1.1" xref="S4.T2.9.9.2.m1.1.1.cmml">6.635</mn><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.2.m1.1b"><cn type="float" id="S4.T2.9.9.2.m1.1.1.cmml" xref="S4.T2.9.9.2.m1.1.1">6.635</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.2.m1.1c">\mathbb{6.635}</annotation></semantics></math></td>
<td id="S4.T2.10.10.3" class="ltx_td ltx_align_center"><math id="S4.T2.10.10.3.m1.1" class="ltx_Math" alttext="\mathbb{0.465}" display="inline"><semantics id="S4.T2.10.10.3.m1.1a"><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T2.10.10.3.m1.1.1" xref="S4.T2.10.10.3.m1.1.1.cmml">0.465</mn><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.3.m1.1b"><cn type="float" id="S4.T2.10.10.3.m1.1.1.cmml" xref="S4.T2.10.10.3.m1.1.1">0.465</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.3.m1.1c">\mathbb{0.465}</annotation></semantics></math></td>
<td id="S4.T2.11.11.4" class="ltx_td ltx_align_center"><math id="S4.T2.11.11.4.m1.1" class="ltx_Math" alttext="\mathbb{0.316}" display="inline"><semantics id="S4.T2.11.11.4.m1.1a"><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T2.11.11.4.m1.1.1" xref="S4.T2.11.11.4.m1.1.1.cmml">0.316</mn><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.4.m1.1b"><cn type="float" id="S4.T2.11.11.4.m1.1.1.cmml" xref="S4.T2.11.11.4.m1.1.1">0.316</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.4.m1.1c">\mathbb{0.316}</annotation></semantics></math></td>
<td id="S4.T2.12.12.5" class="ltx_td ltx_align_center"><math id="S4.T2.12.12.5.m1.1" class="ltx_Math" alttext="\mathbb{105.884}" display="inline"><semantics id="S4.T2.12.12.5.m1.1a"><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T2.12.12.5.m1.1.1" xref="S4.T2.12.12.5.m1.1.1.cmml">105.884</mn><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.5.m1.1b"><cn type="float" id="S4.T2.12.12.5.m1.1.1.cmml" xref="S4.T2.12.12.5.m1.1.1">105.884</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.5.m1.1c">\mathbb{105.884}</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.12.16.4" class="ltx_tr">
<td id="S4.T2.12.16.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.12.16.4.1.1" class="ltx_text" style="color:#808080;">Real video</span></td>
<td id="S4.T2.12.16.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.12.16.4.2.1" class="ltx_text" style="color:#808080;">7.192</span></td>
<td id="S4.T2.12.16.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.12.16.4.3.1" class="ltx_text" style="color:#808080;">7.254</span></td>
<td id="S4.T2.12.16.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.12.16.4.4.1" class="ltx_text" style="color:#808080;">0.559</span></td>
<td id="S4.T2.12.16.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.12.16.4.5.1" class="ltx_text" style="color:#808080;">0.405</span></td>
<td id="S4.T2.12.16.4.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.12.16.4.6.1" class="ltx_text" style="color:#808080;">29.245</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Analysis and Ablation Study</h3>

<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">CAPP metric.</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">We analyze the effectiveness of our proposed CAPP metric in measuring the alignment between audio and head pose.</p>
</div>
<figure id="S4.T3" class="ltx_table ltx_align_floatright">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>CAPP under frame shifting</figcaption>
<table id="S4.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.4.4" class="ltx_tr">
<th id="S4.T3.4.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">0</th>
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\pm</annotation></semantics></math>1</th>
<th id="S4.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T3.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.2.2.2.m1.1a"><mo id="S4.T3.2.2.2.m1.1.1" xref="S4.T3.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><csymbol cd="latexml" id="S4.T3.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">\pm</annotation></semantics></math>2</th>
<th id="S4.T3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T3.3.3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.3.3.3.m1.1a"><mo id="S4.T3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><csymbol cd="latexml" id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">\pm</annotation></semantics></math>3</th>
<th id="S4.T3.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T3.4.4.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T3.4.4.4.m1.1a"><mo id="S4.T3.4.4.4.m1.1.1" xref="S4.T3.4.4.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><csymbol cd="latexml" id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">\pm</annotation></semantics></math>4</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.4.5.1" class="ltx_tr">
<th id="S4.T3.4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_t">​<span id="S4.T3.4.5.1.1.1" class="ltx_text ltx_font_bold">0.608</span>​</th>
<td id="S4.T3.4.5.1.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​0.462​</td>
<td id="S4.T3.4.5.1.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​0.206​</td>
<td id="S4.T3.4.5.1.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​0.069​</td>
<td id="S4.T3.4.5.1.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​0.082​</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p2.1" class="ltx_p">First, we study its sensitivity to temporal shifting by manually introducing frame offsets to ground-truth audio-pose pairs. We extract 3-second clip segments from the VoxCeleb2 test split, yielding approximately 2.1K audio-pose pairs. The average CAPP score for these pairs is <math id="S4.SS3.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="0.608" display="inline"><semantics id="S4.SS3.SSS0.Px1.p2.1.m1.1a"><mn id="S4.SS3.SSS0.Px1.p2.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1.cmml">0.608</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p2.1.m1.1b"><cn type="float" id="S4.SS3.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p2.1.m1.1.1">0.608</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p2.1.m1.1c">0.608</annotation></semantics></math>, as shown in Table <a href="#S4.T3" title="Table 3 ‣ CAPP metric. ‣ 4.3 Analysis and Ablation Study ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
Manual frame shifts lead to a rapid decline in CAPP scores, approaching zero for shifts larger than two frames. This indicates a robust correlation between CAPP scores and audio-head pose alignment.</p>
</div>
<figure id="S4.T4" class="ltx_table ltx_align_floatright">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>CAPP under pose variation scaling</figcaption>
<table id="S4.T4.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.5.5" class="ltx_tr">
<th id="S4.T4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T4.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.1.1.1.m1.1a"><mo id="S4.T4.1.1.1.m1.1.1" xref="S4.T4.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><times id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">\times</annotation></semantics></math>0.2</th>
<th id="S4.T4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T4.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.2.2.2.m1.1a"><mo id="S4.T4.2.2.2.m1.1.1" xref="S4.T4.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.m1.1b"><times id="S4.T4.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.m1.1c">\times</annotation></semantics></math>0.5</th>
<th id="S4.T4.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T4.3.3.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.3.3.3.m1.1a"><mo id="S4.T4.3.3.3.m1.1.1" xref="S4.T4.3.3.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.m1.1b"><times id="S4.T4.3.3.3.m1.1.1.cmml" xref="S4.T4.3.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.m1.1c">\times</annotation></semantics></math>1.0</th>
<th id="S4.T4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T4.4.4.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.4.4.4.m1.1a"><mo id="S4.T4.4.4.4.m1.1.1" xref="S4.T4.4.4.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.m1.1b"><times id="S4.T4.4.4.4.m1.1.1.cmml" xref="S4.T4.4.4.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.m1.1c">\times</annotation></semantics></math>1.5</th>
<th id="S4.T4.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T4.5.5.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T4.5.5.5.m1.1a"><mo id="S4.T4.5.5.5.m1.1.1" xref="S4.T4.5.5.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.m1.1b"><times id="S4.T4.5.5.5.m1.1.1.cmml" xref="S4.T4.5.5.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.m1.1c">\times</annotation></semantics></math>3.0</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.5.6.1" class="ltx_tr">
<td id="S4.T4.5.6.1.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​0.368​</td>
<td id="S4.T4.5.6.1.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​0.584​</td>
<td id="S4.T4.5.6.1.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​<span id="S4.T4.5.6.1.3.1" class="ltx_text ltx_font_bold">0.608</span>​</td>
<td id="S4.T4.5.6.1.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​0.587​</td>
<td id="S4.T4.5.6.1.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">​0.505​</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS3.SSS0.Px1.p3" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p3.1" class="ltx_p">We further investigate the effect of head movement intensity on CAPP by manually scaling the pose differences between consecutive frames using various factors. Table <a href="#S4.T4" title="Table 4 ‣ CAPP metric. ‣ 4.3 Analysis and Ablation Study ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that altering movement intensity negatively impacts the CAPP scores, demonstrating CAPP can assess the alignment of audio and pose in terms of their intensity. However, this sensitivity to intensity appears less pronounced than that to temporal misalignment.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">CFG scales.</h4>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.2" class="ltx_p">The CFG strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite> for diffusion models can attain a trade-off between sample quality and diversity. Here we evaluate the choice of the CFG scales for the audio and main gaze conditions (i.e., <math id="S4.SS3.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\lambda_{\mathbf{A}}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml">𝐀</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3">𝐀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.1.m1.1c">\lambda_{\mathbf{A}}</annotation></semantics></math> and <math id="S4.SS3.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\lambda_{\mathbf{g}}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.2.m2.1a"><msub id="S4.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml">𝐠</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3">𝐠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.2.m2.1c">\lambda_{\mathbf{g}}</annotation></semantics></math> in Eq. <a href="#S3.E2" title="In Classifier-free guidance (CFG) [26]. ‣ 3.2 Holistic Facial Dynamics Generation with Diffusion Transformer ‣ 3 Method ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) in our model.</p>
</div>
<div id="S4.SS3.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p2.6" class="ltx_p">As shown in Table <a href="#S4.T5" title="Table 5 ‣ CFG scales. ‣ 4.3 Analysis and Ablation Study ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, as we increase the value of <math id="S4.SS3.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="\lambda_{\mathbf{g}}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.1.m1.1a"><msub id="S4.SS3.SSS0.Px2.p2.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3.cmml">𝐠</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.1.m1.1.1.3">𝐠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.1.m1.1c">\lambda_{\mathbf{g}}</annotation></semantics></math>, the accuracy of gaze control improves. Increasing the audio CFG scale to <math id="S4.SS3.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=0.5" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.2.m2.1a"><mrow id="S4.SS3.SSS0.Px2.p2.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.cmml"><msub id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.2" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.3" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1"><eq id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.1"></eq><apply id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.2.m2.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.2.m2.1c">\lambda_{\mathbf{A}}=0.5</annotation></semantics></math> significantly enhances the performance of lip-audio alignment (<math id="S4.SS3.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="S_{C}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.3.m3.1a"><msub id="S4.SS3.SSS0.Px2.p2.3.m3.1.1" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.2" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.2.cmml">S</mi><mi id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.3" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.3.m3.1b"><apply id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.2">𝑆</ci><ci id="S4.SS3.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.3.m3.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.3.m3.1c">S_{C}</annotation></semantics></math> and <math id="S4.SS3.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="S_{D}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.4.m4.1a"><msub id="S4.SS3.SSS0.Px2.p2.4.m4.1.1" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p2.4.m4.1.1.2" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1.2.cmml">S</mi><mi id="S4.SS3.SSS0.Px2.p2.4.m4.1.1.3" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.4.m4.1b"><apply id="S4.SS3.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1.2">𝑆</ci><ci id="S4.SS3.SSS0.Px2.p2.4.m4.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.4.m4.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.4.m4.1c">S_{D}</annotation></semantics></math>), pose-audio alignment (CAPP), and pose variation intensity (<math id="S4.SS3.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="\Delta P" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.5.m5.1a"><mrow id="S4.SS3.SSS0.Px2.p2.5.m5.1.1" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.cmml"><mi mathvariant="normal" id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.2" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.1" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.3" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.3.cmml">P</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.5.m5.1b"><apply id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1"><times id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.1"></times><ci id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.2">Δ</ci><ci id="S4.SS3.SSS0.Px2.p2.5.m5.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.5.m5.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.5.m5.1c">\Delta P</annotation></semantics></math>). With positive audio CFG, the lip-audio alignment scores even surpass those evaluated on real videos (the results without audio CFG, i.e., <math id="S4.SS3.SSS0.Px2.p2.6.m6.1" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=0" display="inline"><semantics id="S4.SS3.SSS0.Px2.p2.6.m6.1a"><mrow id="S4.SS3.SSS0.Px2.p2.6.m6.1.1" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.cmml"><msub id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.2" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.3" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.1" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.3" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p2.6.m6.1b"><apply id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1"><eq id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.1"></eq><apply id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.2.3">𝐀</ci></apply><cn type="integer" id="S4.SS3.SSS0.Px2.p2.6.m6.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p2.6.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p2.6.m6.1c">\lambda_{\mathbf{A}}=0</annotation></semantics></math>, were slightly worse than or comparable to them). Moreover, the FVD score shows a slight drop which indicates slightly better video quality.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Ablation study of the audio and main gaze CFG scales as well as the sampling steps. <math id="S4.T5.3.m1.1" class="ltx_Math" alttext="\mathcal{E}_{g}" display="inline"><semantics id="S4.T5.3.m1.1b"><msub id="S4.T5.3.m1.1.1" xref="S4.T5.3.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T5.3.m1.1.1.2" xref="S4.T5.3.m1.1.1.2.cmml">ℰ</mi><mi id="S4.T5.3.m1.1.1.3" xref="S4.T5.3.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.3.m1.1c"><apply id="S4.T5.3.m1.1.1.cmml" xref="S4.T5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.3.m1.1.1.1.cmml" xref="S4.T5.3.m1.1.1">subscript</csymbol><ci id="S4.T5.3.m1.1.1.2.cmml" xref="S4.T5.3.m1.1.1.2">ℰ</ci><ci id="S4.T5.3.m1.1.1.3.cmml" xref="S4.T5.3.m1.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.m1.1d">\mathcal{E}_{g}</annotation></semantics></math> denotes the average angular error of main gaze directions and <math id="S4.T5.4.m2.1" class="ltx_Math" alttext="\mathcal{E}_{s}" display="inline"><semantics id="S4.T5.4.m2.1b"><msub id="S4.T5.4.m2.1.1" xref="S4.T5.4.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T5.4.m2.1.1.2" xref="S4.T5.4.m2.1.1.2.cmml">ℰ</mi><mi id="S4.T5.4.m2.1.1.3" xref="S4.T5.4.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.4.m2.1c"><apply id="S4.T5.4.m2.1.1.cmml" xref="S4.T5.4.m2.1.1"><csymbol cd="ambiguous" id="S4.T5.4.m2.1.1.1.cmml" xref="S4.T5.4.m2.1.1">subscript</csymbol><ci id="S4.T5.4.m2.1.1.2.cmml" xref="S4.T5.4.m2.1.1.2">ℰ</ci><ci id="S4.T5.4.m2.1.1.3.cmml" xref="S4.T5.4.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.m2.1d">\mathcal{E}_{s}</annotation></semantics></math> is the average head distance error.</figcaption>
<table id="S4.T5.21" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.13.9" class="ltx_tr">
<th id="S4.T5.13.9.10" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S4.T5.6.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T5.5.1.1.m1.1" class="ltx_Math" alttext="S_{C}" display="inline"><semantics id="S4.T5.5.1.1.m1.1a"><msub id="S4.T5.5.1.1.m1.1.1" xref="S4.T5.5.1.1.m1.1.1.cmml"><mi id="S4.T5.5.1.1.m1.1.1.2" xref="S4.T5.5.1.1.m1.1.1.2.cmml">S</mi><mi id="S4.T5.5.1.1.m1.1.1.3" xref="S4.T5.5.1.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.5.1.1.m1.1b"><apply id="S4.T5.5.1.1.m1.1.1.cmml" xref="S4.T5.5.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.5.1.1.m1.1.1.1.cmml" xref="S4.T5.5.1.1.m1.1.1">subscript</csymbol><ci id="S4.T5.5.1.1.m1.1.1.2.cmml" xref="S4.T5.5.1.1.m1.1.1.2">𝑆</ci><ci id="S4.T5.5.1.1.m1.1.1.3.cmml" xref="S4.T5.5.1.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.1.1.m1.1c">S_{C}</annotation></semantics></math> <math id="S4.T5.6.2.2.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.6.2.2.m2.1a"><mo stretchy="false" id="S4.T5.6.2.2.m2.1.1" xref="S4.T5.6.2.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.2.2.m2.1b"><ci id="S4.T5.6.2.2.m2.1.1.cmml" xref="S4.T5.6.2.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.2.2.m2.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S4.T5.8.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T5.7.3.3.m1.1" class="ltx_Math" alttext="S_{D}" display="inline"><semantics id="S4.T5.7.3.3.m1.1a"><msub id="S4.T5.7.3.3.m1.1.1" xref="S4.T5.7.3.3.m1.1.1.cmml"><mi id="S4.T5.7.3.3.m1.1.1.2" xref="S4.T5.7.3.3.m1.1.1.2.cmml">S</mi><mi id="S4.T5.7.3.3.m1.1.1.3" xref="S4.T5.7.3.3.m1.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T5.7.3.3.m1.1b"><apply id="S4.T5.7.3.3.m1.1.1.cmml" xref="S4.T5.7.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T5.7.3.3.m1.1.1.1.cmml" xref="S4.T5.7.3.3.m1.1.1">subscript</csymbol><ci id="S4.T5.7.3.3.m1.1.1.2.cmml" xref="S4.T5.7.3.3.m1.1.1.2">𝑆</ci><ci id="S4.T5.7.3.3.m1.1.1.3.cmml" xref="S4.T5.7.3.3.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.3.3.m1.1c">S_{D}</annotation></semantics></math> <math id="S4.T5.8.4.4.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T5.8.4.4.m2.1a"><mo stretchy="false" id="S4.T5.8.4.4.m2.1.1" xref="S4.T5.8.4.4.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.8.4.4.m2.1b"><ci id="S4.T5.8.4.4.m2.1.1.cmml" xref="S4.T5.8.4.4.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.4.4.m2.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T5.9.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">CAPP<math id="S4.T5.9.5.5.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T5.9.5.5.m1.1a"><mo stretchy="false" id="S4.T5.9.5.5.m1.1.1" xref="S4.T5.9.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.9.5.5.m1.1b"><ci id="S4.T5.9.5.5.m1.1.1.cmml" xref="S4.T5.9.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.5.5.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="S4.T5.10.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<math id="S4.T5.10.6.6.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S4.T5.10.6.6.m1.1a"><mi mathvariant="normal" id="S4.T5.10.6.6.m1.1.1" xref="S4.T5.10.6.6.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T5.10.6.6.m1.1b"><ci id="S4.T5.10.6.6.m1.1.1.cmml" xref="S4.T5.10.6.6.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.6.6.m1.1c">\Delta</annotation></semantics></math>P</th>
<th id="S4.T5.11.7.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S4.T5.11.7.7.m1.1" class="ltx_Math" alttext="\text{FVD}_{25}\downarrow" display="inline"><semantics id="S4.T5.11.7.7.m1.1a"><mrow id="S4.T5.11.7.7.m1.1.1" xref="S4.T5.11.7.7.m1.1.1.cmml"><msub id="S4.T5.11.7.7.m1.1.1.2" xref="S4.T5.11.7.7.m1.1.1.2.cmml"><mtext id="S4.T5.11.7.7.m1.1.1.2.2" xref="S4.T5.11.7.7.m1.1.1.2.2a.cmml">FVD</mtext><mn id="S4.T5.11.7.7.m1.1.1.2.3" xref="S4.T5.11.7.7.m1.1.1.2.3.cmml">25</mn></msub><mo stretchy="false" id="S4.T5.11.7.7.m1.1.1.1" xref="S4.T5.11.7.7.m1.1.1.1.cmml">↓</mo><mi id="S4.T5.11.7.7.m1.1.1.3" xref="S4.T5.11.7.7.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.11.7.7.m1.1b"><apply id="S4.T5.11.7.7.m1.1.1.cmml" xref="S4.T5.11.7.7.m1.1.1"><ci id="S4.T5.11.7.7.m1.1.1.1.cmml" xref="S4.T5.11.7.7.m1.1.1.1">↓</ci><apply id="S4.T5.11.7.7.m1.1.1.2.cmml" xref="S4.T5.11.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.11.7.7.m1.1.1.2.1.cmml" xref="S4.T5.11.7.7.m1.1.1.2">subscript</csymbol><ci id="S4.T5.11.7.7.m1.1.1.2.2a.cmml" xref="S4.T5.11.7.7.m1.1.1.2.2"><mtext id="S4.T5.11.7.7.m1.1.1.2.2.cmml" xref="S4.T5.11.7.7.m1.1.1.2.2">FVD</mtext></ci><cn type="integer" id="S4.T5.11.7.7.m1.1.1.2.3.cmml" xref="S4.T5.11.7.7.m1.1.1.2.3">25</cn></apply><csymbol cd="latexml" id="S4.T5.11.7.7.m1.1.1.3.cmml" xref="S4.T5.11.7.7.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.11.7.7.m1.1c">\text{FVD}_{25}\downarrow</annotation></semantics></math></th>
<th id="S4.T5.12.8.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S4.T5.12.8.8.m1.1" class="ltx_Math" alttext="\mathcal{E}_{\theta_{g}}\downarrow" display="inline"><semantics id="S4.T5.12.8.8.m1.1a"><mrow id="S4.T5.12.8.8.m1.1.1" xref="S4.T5.12.8.8.m1.1.1.cmml"><msub id="S4.T5.12.8.8.m1.1.1.2" xref="S4.T5.12.8.8.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T5.12.8.8.m1.1.1.2.2" xref="S4.T5.12.8.8.m1.1.1.2.2.cmml">ℰ</mi><msub id="S4.T5.12.8.8.m1.1.1.2.3" xref="S4.T5.12.8.8.m1.1.1.2.3.cmml"><mi id="S4.T5.12.8.8.m1.1.1.2.3.2" xref="S4.T5.12.8.8.m1.1.1.2.3.2.cmml">θ</mi><mi id="S4.T5.12.8.8.m1.1.1.2.3.3" xref="S4.T5.12.8.8.m1.1.1.2.3.3.cmml">g</mi></msub></msub><mo stretchy="false" id="S4.T5.12.8.8.m1.1.1.1" xref="S4.T5.12.8.8.m1.1.1.1.cmml">↓</mo><mi id="S4.T5.12.8.8.m1.1.1.3" xref="S4.T5.12.8.8.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.12.8.8.m1.1b"><apply id="S4.T5.12.8.8.m1.1.1.cmml" xref="S4.T5.12.8.8.m1.1.1"><ci id="S4.T5.12.8.8.m1.1.1.1.cmml" xref="S4.T5.12.8.8.m1.1.1.1">↓</ci><apply id="S4.T5.12.8.8.m1.1.1.2.cmml" xref="S4.T5.12.8.8.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.12.8.8.m1.1.1.2.1.cmml" xref="S4.T5.12.8.8.m1.1.1.2">subscript</csymbol><ci id="S4.T5.12.8.8.m1.1.1.2.2.cmml" xref="S4.T5.12.8.8.m1.1.1.2.2">ℰ</ci><apply id="S4.T5.12.8.8.m1.1.1.2.3.cmml" xref="S4.T5.12.8.8.m1.1.1.2.3"><csymbol cd="ambiguous" id="S4.T5.12.8.8.m1.1.1.2.3.1.cmml" xref="S4.T5.12.8.8.m1.1.1.2.3">subscript</csymbol><ci id="S4.T5.12.8.8.m1.1.1.2.3.2.cmml" xref="S4.T5.12.8.8.m1.1.1.2.3.2">𝜃</ci><ci id="S4.T5.12.8.8.m1.1.1.2.3.3.cmml" xref="S4.T5.12.8.8.m1.1.1.2.3.3">𝑔</ci></apply></apply><csymbol cd="latexml" id="S4.T5.12.8.8.m1.1.1.3.cmml" xref="S4.T5.12.8.8.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.12.8.8.m1.1c">\mathcal{E}_{\theta_{g}}\downarrow</annotation></semantics></math></th>
<th id="S4.T5.13.9.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S4.T5.13.9.9.m1.1" class="ltx_Math" alttext="\mathcal{E}_{s}\downarrow" display="inline"><semantics id="S4.T5.13.9.9.m1.1a"><mrow id="S4.T5.13.9.9.m1.1.1" xref="S4.T5.13.9.9.m1.1.1.cmml"><msub id="S4.T5.13.9.9.m1.1.1.2" xref="S4.T5.13.9.9.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T5.13.9.9.m1.1.1.2.2" xref="S4.T5.13.9.9.m1.1.1.2.2.cmml">ℰ</mi><mi id="S4.T5.13.9.9.m1.1.1.2.3" xref="S4.T5.13.9.9.m1.1.1.2.3.cmml">s</mi></msub><mo stretchy="false" id="S4.T5.13.9.9.m1.1.1.1" xref="S4.T5.13.9.9.m1.1.1.1.cmml">↓</mo><mi id="S4.T5.13.9.9.m1.1.1.3" xref="S4.T5.13.9.9.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.13.9.9.m1.1b"><apply id="S4.T5.13.9.9.m1.1.1.cmml" xref="S4.T5.13.9.9.m1.1.1"><ci id="S4.T5.13.9.9.m1.1.1.1.cmml" xref="S4.T5.13.9.9.m1.1.1.1">↓</ci><apply id="S4.T5.13.9.9.m1.1.1.2.cmml" xref="S4.T5.13.9.9.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.13.9.9.m1.1.1.2.1.cmml" xref="S4.T5.13.9.9.m1.1.1.2">subscript</csymbol><ci id="S4.T5.13.9.9.m1.1.1.2.2.cmml" xref="S4.T5.13.9.9.m1.1.1.2.2">ℰ</ci><ci id="S4.T5.13.9.9.m1.1.1.2.3.cmml" xref="S4.T5.13.9.9.m1.1.1.2.3">𝑠</ci></apply><csymbol cd="latexml" id="S4.T5.13.9.9.m1.1.1.3.cmml" xref="S4.T5.13.9.9.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.13.9.9.m1.1c">\mathcal{E}_{s}\downarrow</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.14.10" class="ltx_tr">
<th id="S4.T5.14.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="S4.T5.14.10.1.m1.2" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=0.0,\ \!\lambda_{\mathbf{g}}=0.0" display="inline"><semantics id="S4.T5.14.10.1.m1.2a"><mrow id="S4.T5.14.10.1.m1.2.2.2" xref="S4.T5.14.10.1.m1.2.2.3.cmml"><mrow id="S4.T5.14.10.1.m1.1.1.1.1" xref="S4.T5.14.10.1.m1.1.1.1.1.cmml"><msub id="S4.T5.14.10.1.m1.1.1.1.1.2" xref="S4.T5.14.10.1.m1.1.1.1.1.2.cmml"><mi id="S4.T5.14.10.1.m1.1.1.1.1.2.2" xref="S4.T5.14.10.1.m1.1.1.1.1.2.2.cmml">λ</mi><mi id="S4.T5.14.10.1.m1.1.1.1.1.2.3" xref="S4.T5.14.10.1.m1.1.1.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.T5.14.10.1.m1.1.1.1.1.1" xref="S4.T5.14.10.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.T5.14.10.1.m1.1.1.1.1.3" xref="S4.T5.14.10.1.m1.1.1.1.1.3.cmml">0.0</mn></mrow><mo rspace="0.497em" id="S4.T5.14.10.1.m1.2.2.2.3" xref="S4.T5.14.10.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.T5.14.10.1.m1.2.2.2.2" xref="S4.T5.14.10.1.m1.2.2.2.2.cmml"><msub id="S4.T5.14.10.1.m1.2.2.2.2.2" xref="S4.T5.14.10.1.m1.2.2.2.2.2.cmml"><mi id="S4.T5.14.10.1.m1.2.2.2.2.2.2" xref="S4.T5.14.10.1.m1.2.2.2.2.2.2.cmml">λ</mi><mi id="S4.T5.14.10.1.m1.2.2.2.2.2.3" xref="S4.T5.14.10.1.m1.2.2.2.2.2.3.cmml">𝐠</mi></msub><mo id="S4.T5.14.10.1.m1.2.2.2.2.1" xref="S4.T5.14.10.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.T5.14.10.1.m1.2.2.2.2.3" xref="S4.T5.14.10.1.m1.2.2.2.2.3.cmml">0.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.14.10.1.m1.2b"><apply id="S4.T5.14.10.1.m1.2.2.3.cmml" xref="S4.T5.14.10.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.T5.14.10.1.m1.2.2.3a.cmml" xref="S4.T5.14.10.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.T5.14.10.1.m1.1.1.1.1.cmml" xref="S4.T5.14.10.1.m1.1.1.1.1"><eq id="S4.T5.14.10.1.m1.1.1.1.1.1.cmml" xref="S4.T5.14.10.1.m1.1.1.1.1.1"></eq><apply id="S4.T5.14.10.1.m1.1.1.1.1.2.cmml" xref="S4.T5.14.10.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.14.10.1.m1.1.1.1.1.2.1.cmml" xref="S4.T5.14.10.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.T5.14.10.1.m1.1.1.1.1.2.2.cmml" xref="S4.T5.14.10.1.m1.1.1.1.1.2.2">𝜆</ci><ci id="S4.T5.14.10.1.m1.1.1.1.1.2.3.cmml" xref="S4.T5.14.10.1.m1.1.1.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.T5.14.10.1.m1.1.1.1.1.3.cmml" xref="S4.T5.14.10.1.m1.1.1.1.1.3">0.0</cn></apply><apply id="S4.T5.14.10.1.m1.2.2.2.2.cmml" xref="S4.T5.14.10.1.m1.2.2.2.2"><eq id="S4.T5.14.10.1.m1.2.2.2.2.1.cmml" xref="S4.T5.14.10.1.m1.2.2.2.2.1"></eq><apply id="S4.T5.14.10.1.m1.2.2.2.2.2.cmml" xref="S4.T5.14.10.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T5.14.10.1.m1.2.2.2.2.2.1.cmml" xref="S4.T5.14.10.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.T5.14.10.1.m1.2.2.2.2.2.2.cmml" xref="S4.T5.14.10.1.m1.2.2.2.2.2.2">𝜆</ci><ci id="S4.T5.14.10.1.m1.2.2.2.2.2.3.cmml" xref="S4.T5.14.10.1.m1.2.2.2.2.2.3">𝐠</ci></apply><cn type="float" id="S4.T5.14.10.1.m1.2.2.2.2.3.cmml" xref="S4.T5.14.10.1.m1.2.2.2.2.3">0.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.14.10.1.m1.2c">\lambda_{\mathbf{A}}=0.0,\ \!\lambda_{\mathbf{g}}=0.0</annotation></semantics></math></th>
<td id="S4.T5.14.10.2" class="ltx_td ltx_align_center ltx_border_t">7.087</td>
<td id="S4.T5.14.10.3" class="ltx_td ltx_align_center ltx_border_t">7.391</td>
<td id="S4.T5.14.10.4" class="ltx_td ltx_align_center ltx_border_t">0.414</td>
<td id="S4.T5.14.10.5" class="ltx_td ltx_align_center ltx_border_t">0.291</td>
<td id="S4.T5.14.10.6" class="ltx_td ltx_align_center ltx_border_t">117.425</td>
<td id="S4.T5.14.10.7" class="ltx_td ltx_align_center ltx_border_t">5.730</td>
<td id="S4.T5.14.10.8" class="ltx_td ltx_align_center ltx_border_t">0.004</td>
</tr>
<tr id="S4.T5.15.11" class="ltx_tr">
<th id="S4.T5.15.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T5.15.11.1.m1.2" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=0.0,\ \!\lambda_{\mathbf{g}}=1.0" display="inline"><semantics id="S4.T5.15.11.1.m1.2a"><mrow id="S4.T5.15.11.1.m1.2.2.2" xref="S4.T5.15.11.1.m1.2.2.3.cmml"><mrow id="S4.T5.15.11.1.m1.1.1.1.1" xref="S4.T5.15.11.1.m1.1.1.1.1.cmml"><msub id="S4.T5.15.11.1.m1.1.1.1.1.2" xref="S4.T5.15.11.1.m1.1.1.1.1.2.cmml"><mi id="S4.T5.15.11.1.m1.1.1.1.1.2.2" xref="S4.T5.15.11.1.m1.1.1.1.1.2.2.cmml">λ</mi><mi id="S4.T5.15.11.1.m1.1.1.1.1.2.3" xref="S4.T5.15.11.1.m1.1.1.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.T5.15.11.1.m1.1.1.1.1.1" xref="S4.T5.15.11.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.T5.15.11.1.m1.1.1.1.1.3" xref="S4.T5.15.11.1.m1.1.1.1.1.3.cmml">0.0</mn></mrow><mo rspace="0.497em" id="S4.T5.15.11.1.m1.2.2.2.3" xref="S4.T5.15.11.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.T5.15.11.1.m1.2.2.2.2" xref="S4.T5.15.11.1.m1.2.2.2.2.cmml"><msub id="S4.T5.15.11.1.m1.2.2.2.2.2" xref="S4.T5.15.11.1.m1.2.2.2.2.2.cmml"><mi id="S4.T5.15.11.1.m1.2.2.2.2.2.2" xref="S4.T5.15.11.1.m1.2.2.2.2.2.2.cmml">λ</mi><mi id="S4.T5.15.11.1.m1.2.2.2.2.2.3" xref="S4.T5.15.11.1.m1.2.2.2.2.2.3.cmml">𝐠</mi></msub><mo id="S4.T5.15.11.1.m1.2.2.2.2.1" xref="S4.T5.15.11.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.T5.15.11.1.m1.2.2.2.2.3" xref="S4.T5.15.11.1.m1.2.2.2.2.3.cmml">1.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.15.11.1.m1.2b"><apply id="S4.T5.15.11.1.m1.2.2.3.cmml" xref="S4.T5.15.11.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.T5.15.11.1.m1.2.2.3a.cmml" xref="S4.T5.15.11.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.T5.15.11.1.m1.1.1.1.1.cmml" xref="S4.T5.15.11.1.m1.1.1.1.1"><eq id="S4.T5.15.11.1.m1.1.1.1.1.1.cmml" xref="S4.T5.15.11.1.m1.1.1.1.1.1"></eq><apply id="S4.T5.15.11.1.m1.1.1.1.1.2.cmml" xref="S4.T5.15.11.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.15.11.1.m1.1.1.1.1.2.1.cmml" xref="S4.T5.15.11.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.T5.15.11.1.m1.1.1.1.1.2.2.cmml" xref="S4.T5.15.11.1.m1.1.1.1.1.2.2">𝜆</ci><ci id="S4.T5.15.11.1.m1.1.1.1.1.2.3.cmml" xref="S4.T5.15.11.1.m1.1.1.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.T5.15.11.1.m1.1.1.1.1.3.cmml" xref="S4.T5.15.11.1.m1.1.1.1.1.3">0.0</cn></apply><apply id="S4.T5.15.11.1.m1.2.2.2.2.cmml" xref="S4.T5.15.11.1.m1.2.2.2.2"><eq id="S4.T5.15.11.1.m1.2.2.2.2.1.cmml" xref="S4.T5.15.11.1.m1.2.2.2.2.1"></eq><apply id="S4.T5.15.11.1.m1.2.2.2.2.2.cmml" xref="S4.T5.15.11.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T5.15.11.1.m1.2.2.2.2.2.1.cmml" xref="S4.T5.15.11.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.T5.15.11.1.m1.2.2.2.2.2.2.cmml" xref="S4.T5.15.11.1.m1.2.2.2.2.2.2">𝜆</ci><ci id="S4.T5.15.11.1.m1.2.2.2.2.2.3.cmml" xref="S4.T5.15.11.1.m1.2.2.2.2.2.3">𝐠</ci></apply><cn type="float" id="S4.T5.15.11.1.m1.2.2.2.2.3.cmml" xref="S4.T5.15.11.1.m1.2.2.2.2.3">1.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.15.11.1.m1.2c">\lambda_{\mathbf{A}}=0.0,\ \!\lambda_{\mathbf{g}}=1.0</annotation></semantics></math></th>
<td id="S4.T5.15.11.2" class="ltx_td ltx_align_center">7.134</td>
<td id="S4.T5.15.11.3" class="ltx_td ltx_align_center">7.345</td>
<td id="S4.T5.15.11.4" class="ltx_td ltx_align_center">0.421</td>
<td id="S4.T5.15.11.5" class="ltx_td ltx_align_center">0.290</td>
<td id="S4.T5.15.11.6" class="ltx_td ltx_align_center">116.547</td>
<td id="S4.T5.15.11.7" class="ltx_td ltx_align_center">5.329</td>
<td id="S4.T5.15.11.8" class="ltx_td ltx_align_center">0.004</td>
</tr>
<tr id="S4.T5.16.12" class="ltx_tr">
<th id="S4.T5.16.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T5.16.12.1.m1.2" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=0.0,\ \!\lambda_{\mathbf{g}}=2.0" display="inline"><semantics id="S4.T5.16.12.1.m1.2a"><mrow id="S4.T5.16.12.1.m1.2.2.2" xref="S4.T5.16.12.1.m1.2.2.3.cmml"><mrow id="S4.T5.16.12.1.m1.1.1.1.1" xref="S4.T5.16.12.1.m1.1.1.1.1.cmml"><msub id="S4.T5.16.12.1.m1.1.1.1.1.2" xref="S4.T5.16.12.1.m1.1.1.1.1.2.cmml"><mi id="S4.T5.16.12.1.m1.1.1.1.1.2.2" xref="S4.T5.16.12.1.m1.1.1.1.1.2.2.cmml">λ</mi><mi id="S4.T5.16.12.1.m1.1.1.1.1.2.3" xref="S4.T5.16.12.1.m1.1.1.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.T5.16.12.1.m1.1.1.1.1.1" xref="S4.T5.16.12.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.T5.16.12.1.m1.1.1.1.1.3" xref="S4.T5.16.12.1.m1.1.1.1.1.3.cmml">0.0</mn></mrow><mo rspace="0.497em" id="S4.T5.16.12.1.m1.2.2.2.3" xref="S4.T5.16.12.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.T5.16.12.1.m1.2.2.2.2" xref="S4.T5.16.12.1.m1.2.2.2.2.cmml"><msub id="S4.T5.16.12.1.m1.2.2.2.2.2" xref="S4.T5.16.12.1.m1.2.2.2.2.2.cmml"><mi id="S4.T5.16.12.1.m1.2.2.2.2.2.2" xref="S4.T5.16.12.1.m1.2.2.2.2.2.2.cmml">λ</mi><mi id="S4.T5.16.12.1.m1.2.2.2.2.2.3" xref="S4.T5.16.12.1.m1.2.2.2.2.2.3.cmml">𝐠</mi></msub><mo id="S4.T5.16.12.1.m1.2.2.2.2.1" xref="S4.T5.16.12.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.T5.16.12.1.m1.2.2.2.2.3" xref="S4.T5.16.12.1.m1.2.2.2.2.3.cmml">2.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.16.12.1.m1.2b"><apply id="S4.T5.16.12.1.m1.2.2.3.cmml" xref="S4.T5.16.12.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.T5.16.12.1.m1.2.2.3a.cmml" xref="S4.T5.16.12.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.T5.16.12.1.m1.1.1.1.1.cmml" xref="S4.T5.16.12.1.m1.1.1.1.1"><eq id="S4.T5.16.12.1.m1.1.1.1.1.1.cmml" xref="S4.T5.16.12.1.m1.1.1.1.1.1"></eq><apply id="S4.T5.16.12.1.m1.1.1.1.1.2.cmml" xref="S4.T5.16.12.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.16.12.1.m1.1.1.1.1.2.1.cmml" xref="S4.T5.16.12.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.T5.16.12.1.m1.1.1.1.1.2.2.cmml" xref="S4.T5.16.12.1.m1.1.1.1.1.2.2">𝜆</ci><ci id="S4.T5.16.12.1.m1.1.1.1.1.2.3.cmml" xref="S4.T5.16.12.1.m1.1.1.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.T5.16.12.1.m1.1.1.1.1.3.cmml" xref="S4.T5.16.12.1.m1.1.1.1.1.3">0.0</cn></apply><apply id="S4.T5.16.12.1.m1.2.2.2.2.cmml" xref="S4.T5.16.12.1.m1.2.2.2.2"><eq id="S4.T5.16.12.1.m1.2.2.2.2.1.cmml" xref="S4.T5.16.12.1.m1.2.2.2.2.1"></eq><apply id="S4.T5.16.12.1.m1.2.2.2.2.2.cmml" xref="S4.T5.16.12.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T5.16.12.1.m1.2.2.2.2.2.1.cmml" xref="S4.T5.16.12.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.T5.16.12.1.m1.2.2.2.2.2.2.cmml" xref="S4.T5.16.12.1.m1.2.2.2.2.2.2">𝜆</ci><ci id="S4.T5.16.12.1.m1.2.2.2.2.2.3.cmml" xref="S4.T5.16.12.1.m1.2.2.2.2.2.3">𝐠</ci></apply><cn type="float" id="S4.T5.16.12.1.m1.2.2.2.2.3.cmml" xref="S4.T5.16.12.1.m1.2.2.2.2.3">2.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.16.12.1.m1.2c">\lambda_{\mathbf{A}}=0.0,\ \!\lambda_{\mathbf{g}}=2.0</annotation></semantics></math></th>
<td id="S4.T5.16.12.2" class="ltx_td ltx_align_center">7.108</td>
<td id="S4.T5.16.12.3" class="ltx_td ltx_align_center">7.386</td>
<td id="S4.T5.16.12.4" class="ltx_td ltx_align_center">0.414</td>
<td id="S4.T5.16.12.5" class="ltx_td ltx_align_center">0.298</td>
<td id="S4.T5.16.12.6" class="ltx_td ltx_align_center">117.784</td>
<td id="S4.T5.16.12.7" class="ltx_td ltx_align_center">5.064</td>
<td id="S4.T5.16.12.8" class="ltx_td ltx_align_center">0.005</td>
</tr>
<tr id="S4.T5.17.13" class="ltx_tr">
<th id="S4.T5.17.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T5.17.13.1.m1.2" class="ltx_Math" alttext="\mathbb{\lambda_{A}=0.5,\lambda_{\mathbf{g}}=1.0}" display="inline"><semantics id="S4.T5.17.13.1.m1.2a"><mrow id="S4.T5.17.13.1.m1.2.2.2" xref="S4.T5.17.13.1.m1.2.2.3.cmml"><mrow id="S4.T5.17.13.1.m1.1.1.1.1" xref="S4.T5.17.13.1.m1.1.1.1.1.cmml"><msub id="S4.T5.17.13.1.m1.1.1.1.1.2" xref="S4.T5.17.13.1.m1.1.1.1.1.2.cmml"><mi id="S4.T5.17.13.1.m1.1.1.1.1.2.2" xref="S4.T5.17.13.1.m1.1.1.1.1.2.2.cmml">λ</mi><mi id="S4.T5.17.13.1.m1.1.1.1.1.2.3" xref="S4.T5.17.13.1.m1.1.1.1.1.2.3.cmml">𝔸</mi></msub><mo id="S4.T5.17.13.1.m1.1.1.1.1.1" xref="S4.T5.17.13.1.m1.1.1.1.1.1.cmml">=</mo><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T5.17.13.1.m1.1.1.1.1.3" xref="S4.T5.17.13.1.m1.1.1.1.1.3.cmml">0.5</mn></mrow><mo id="S4.T5.17.13.1.m1.2.2.2.3" xref="S4.T5.17.13.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.T5.17.13.1.m1.2.2.2.2" xref="S4.T5.17.13.1.m1.2.2.2.2.cmml"><msub id="S4.T5.17.13.1.m1.2.2.2.2.2" xref="S4.T5.17.13.1.m1.2.2.2.2.2.cmml"><mi id="S4.T5.17.13.1.m1.2.2.2.2.2.2" xref="S4.T5.17.13.1.m1.2.2.2.2.2.2.cmml">λ</mi><mi id="S4.T5.17.13.1.m1.2.2.2.2.2.3" xref="S4.T5.17.13.1.m1.2.2.2.2.2.3.cmml">𝐠</mi></msub><mo id="S4.T5.17.13.1.m1.2.2.2.2.1" xref="S4.T5.17.13.1.m1.2.2.2.2.1.cmml">=</mo><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T5.17.13.1.m1.2.2.2.2.3" xref="S4.T5.17.13.1.m1.2.2.2.2.3.cmml">1.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.17.13.1.m1.2b"><apply id="S4.T5.17.13.1.m1.2.2.3.cmml" xref="S4.T5.17.13.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.T5.17.13.1.m1.2.2.3a.cmml" xref="S4.T5.17.13.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.T5.17.13.1.m1.1.1.1.1.cmml" xref="S4.T5.17.13.1.m1.1.1.1.1"><eq id="S4.T5.17.13.1.m1.1.1.1.1.1.cmml" xref="S4.T5.17.13.1.m1.1.1.1.1.1"></eq><apply id="S4.T5.17.13.1.m1.1.1.1.1.2.cmml" xref="S4.T5.17.13.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.17.13.1.m1.1.1.1.1.2.1.cmml" xref="S4.T5.17.13.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.T5.17.13.1.m1.1.1.1.1.2.2.cmml" xref="S4.T5.17.13.1.m1.1.1.1.1.2.2">𝜆</ci><ci id="S4.T5.17.13.1.m1.1.1.1.1.2.3.cmml" xref="S4.T5.17.13.1.m1.1.1.1.1.2.3">𝔸</ci></apply><cn type="float" id="S4.T5.17.13.1.m1.1.1.1.1.3.cmml" xref="S4.T5.17.13.1.m1.1.1.1.1.3">0.5</cn></apply><apply id="S4.T5.17.13.1.m1.2.2.2.2.cmml" xref="S4.T5.17.13.1.m1.2.2.2.2"><eq id="S4.T5.17.13.1.m1.2.2.2.2.1.cmml" xref="S4.T5.17.13.1.m1.2.2.2.2.1"></eq><apply id="S4.T5.17.13.1.m1.2.2.2.2.2.cmml" xref="S4.T5.17.13.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T5.17.13.1.m1.2.2.2.2.2.1.cmml" xref="S4.T5.17.13.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.T5.17.13.1.m1.2.2.2.2.2.2.cmml" xref="S4.T5.17.13.1.m1.2.2.2.2.2.2">𝜆</ci><ci id="S4.T5.17.13.1.m1.2.2.2.2.2.3.cmml" xref="S4.T5.17.13.1.m1.2.2.2.2.2.3">𝐠</ci></apply><cn type="float" id="S4.T5.17.13.1.m1.2.2.2.2.3.cmml" xref="S4.T5.17.13.1.m1.2.2.2.2.3">1.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.17.13.1.m1.2c">\mathbb{\lambda_{A}=0.5,\lambda_{\mathbf{g}}=1.0}</annotation></semantics></math></th>
<td id="S4.T5.17.13.2" class="ltx_td ltx_align_center">7.957</td>
<td id="S4.T5.17.13.3" class="ltx_td ltx_align_center">6.635</td>
<td id="S4.T5.17.13.4" class="ltx_td ltx_align_center">0.465</td>
<td id="S4.T5.17.13.5" class="ltx_td ltx_align_center">0.316</td>
<td id="S4.T5.17.13.6" class="ltx_td ltx_align_center">105.884</td>
<td id="S4.T5.17.13.7" class="ltx_td ltx_align_center">5.253</td>
<td id="S4.T5.17.13.8" class="ltx_td ltx_align_center">0.005</td>
</tr>
<tr id="S4.T5.18.14" class="ltx_tr">
<th id="S4.T5.18.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T5.18.14.1.m1.2" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=1.0,\ \!\lambda_{\mathbf{g}}=1.0" display="inline"><semantics id="S4.T5.18.14.1.m1.2a"><mrow id="S4.T5.18.14.1.m1.2.2.2" xref="S4.T5.18.14.1.m1.2.2.3.cmml"><mrow id="S4.T5.18.14.1.m1.1.1.1.1" xref="S4.T5.18.14.1.m1.1.1.1.1.cmml"><msub id="S4.T5.18.14.1.m1.1.1.1.1.2" xref="S4.T5.18.14.1.m1.1.1.1.1.2.cmml"><mi id="S4.T5.18.14.1.m1.1.1.1.1.2.2" xref="S4.T5.18.14.1.m1.1.1.1.1.2.2.cmml">λ</mi><mi id="S4.T5.18.14.1.m1.1.1.1.1.2.3" xref="S4.T5.18.14.1.m1.1.1.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.T5.18.14.1.m1.1.1.1.1.1" xref="S4.T5.18.14.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.T5.18.14.1.m1.1.1.1.1.3" xref="S4.T5.18.14.1.m1.1.1.1.1.3.cmml">1.0</mn></mrow><mo rspace="0.497em" id="S4.T5.18.14.1.m1.2.2.2.3" xref="S4.T5.18.14.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.T5.18.14.1.m1.2.2.2.2" xref="S4.T5.18.14.1.m1.2.2.2.2.cmml"><msub id="S4.T5.18.14.1.m1.2.2.2.2.2" xref="S4.T5.18.14.1.m1.2.2.2.2.2.cmml"><mi id="S4.T5.18.14.1.m1.2.2.2.2.2.2" xref="S4.T5.18.14.1.m1.2.2.2.2.2.2.cmml">λ</mi><mi id="S4.T5.18.14.1.m1.2.2.2.2.2.3" xref="S4.T5.18.14.1.m1.2.2.2.2.2.3.cmml">𝐠</mi></msub><mo id="S4.T5.18.14.1.m1.2.2.2.2.1" xref="S4.T5.18.14.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.T5.18.14.1.m1.2.2.2.2.3" xref="S4.T5.18.14.1.m1.2.2.2.2.3.cmml">1.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.18.14.1.m1.2b"><apply id="S4.T5.18.14.1.m1.2.2.3.cmml" xref="S4.T5.18.14.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.T5.18.14.1.m1.2.2.3a.cmml" xref="S4.T5.18.14.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.T5.18.14.1.m1.1.1.1.1.cmml" xref="S4.T5.18.14.1.m1.1.1.1.1"><eq id="S4.T5.18.14.1.m1.1.1.1.1.1.cmml" xref="S4.T5.18.14.1.m1.1.1.1.1.1"></eq><apply id="S4.T5.18.14.1.m1.1.1.1.1.2.cmml" xref="S4.T5.18.14.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.18.14.1.m1.1.1.1.1.2.1.cmml" xref="S4.T5.18.14.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.T5.18.14.1.m1.1.1.1.1.2.2.cmml" xref="S4.T5.18.14.1.m1.1.1.1.1.2.2">𝜆</ci><ci id="S4.T5.18.14.1.m1.1.1.1.1.2.3.cmml" xref="S4.T5.18.14.1.m1.1.1.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.T5.18.14.1.m1.1.1.1.1.3.cmml" xref="S4.T5.18.14.1.m1.1.1.1.1.3">1.0</cn></apply><apply id="S4.T5.18.14.1.m1.2.2.2.2.cmml" xref="S4.T5.18.14.1.m1.2.2.2.2"><eq id="S4.T5.18.14.1.m1.2.2.2.2.1.cmml" xref="S4.T5.18.14.1.m1.2.2.2.2.1"></eq><apply id="S4.T5.18.14.1.m1.2.2.2.2.2.cmml" xref="S4.T5.18.14.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T5.18.14.1.m1.2.2.2.2.2.1.cmml" xref="S4.T5.18.14.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.T5.18.14.1.m1.2.2.2.2.2.2.cmml" xref="S4.T5.18.14.1.m1.2.2.2.2.2.2">𝜆</ci><ci id="S4.T5.18.14.1.m1.2.2.2.2.2.3.cmml" xref="S4.T5.18.14.1.m1.2.2.2.2.2.3">𝐠</ci></apply><cn type="float" id="S4.T5.18.14.1.m1.2.2.2.2.3.cmml" xref="S4.T5.18.14.1.m1.2.2.2.2.3">1.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.18.14.1.m1.2c">\lambda_{\mathbf{A}}=1.0,\ \!\lambda_{\mathbf{g}}=1.0</annotation></semantics></math></th>
<td id="S4.T5.18.14.2" class="ltx_td ltx_align_center">8.218</td>
<td id="S4.T5.18.14.3" class="ltx_td ltx_align_center">6.437</td>
<td id="S4.T5.18.14.4" class="ltx_td ltx_align_center">0.474</td>
<td id="S4.T5.18.14.5" class="ltx_td ltx_align_center">0.342</td>
<td id="S4.T5.18.14.6" class="ltx_td ltx_align_center">104.886</td>
<td id="S4.T5.18.14.7" class="ltx_td ltx_align_center">5.333</td>
<td id="S4.T5.18.14.8" class="ltx_td ltx_align_center">0.005</td>
</tr>
<tr id="S4.T5.19.15" class="ltx_tr">
<th id="S4.T5.19.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T5.19.15.1.m1.2" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=2.0,\ \!\lambda_{\mathbf{g}}=1.0" display="inline"><semantics id="S4.T5.19.15.1.m1.2a"><mrow id="S4.T5.19.15.1.m1.2.2.2" xref="S4.T5.19.15.1.m1.2.2.3.cmml"><mrow id="S4.T5.19.15.1.m1.1.1.1.1" xref="S4.T5.19.15.1.m1.1.1.1.1.cmml"><msub id="S4.T5.19.15.1.m1.1.1.1.1.2" xref="S4.T5.19.15.1.m1.1.1.1.1.2.cmml"><mi id="S4.T5.19.15.1.m1.1.1.1.1.2.2" xref="S4.T5.19.15.1.m1.1.1.1.1.2.2.cmml">λ</mi><mi id="S4.T5.19.15.1.m1.1.1.1.1.2.3" xref="S4.T5.19.15.1.m1.1.1.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.T5.19.15.1.m1.1.1.1.1.1" xref="S4.T5.19.15.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.T5.19.15.1.m1.1.1.1.1.3" xref="S4.T5.19.15.1.m1.1.1.1.1.3.cmml">2.0</mn></mrow><mo rspace="0.497em" id="S4.T5.19.15.1.m1.2.2.2.3" xref="S4.T5.19.15.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.T5.19.15.1.m1.2.2.2.2" xref="S4.T5.19.15.1.m1.2.2.2.2.cmml"><msub id="S4.T5.19.15.1.m1.2.2.2.2.2" xref="S4.T5.19.15.1.m1.2.2.2.2.2.cmml"><mi id="S4.T5.19.15.1.m1.2.2.2.2.2.2" xref="S4.T5.19.15.1.m1.2.2.2.2.2.2.cmml">λ</mi><mi id="S4.T5.19.15.1.m1.2.2.2.2.2.3" xref="S4.T5.19.15.1.m1.2.2.2.2.2.3.cmml">𝐠</mi></msub><mo id="S4.T5.19.15.1.m1.2.2.2.2.1" xref="S4.T5.19.15.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.T5.19.15.1.m1.2.2.2.2.3" xref="S4.T5.19.15.1.m1.2.2.2.2.3.cmml">1.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.19.15.1.m1.2b"><apply id="S4.T5.19.15.1.m1.2.2.3.cmml" xref="S4.T5.19.15.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.T5.19.15.1.m1.2.2.3a.cmml" xref="S4.T5.19.15.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.T5.19.15.1.m1.1.1.1.1.cmml" xref="S4.T5.19.15.1.m1.1.1.1.1"><eq id="S4.T5.19.15.1.m1.1.1.1.1.1.cmml" xref="S4.T5.19.15.1.m1.1.1.1.1.1"></eq><apply id="S4.T5.19.15.1.m1.1.1.1.1.2.cmml" xref="S4.T5.19.15.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.19.15.1.m1.1.1.1.1.2.1.cmml" xref="S4.T5.19.15.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.T5.19.15.1.m1.1.1.1.1.2.2.cmml" xref="S4.T5.19.15.1.m1.1.1.1.1.2.2">𝜆</ci><ci id="S4.T5.19.15.1.m1.1.1.1.1.2.3.cmml" xref="S4.T5.19.15.1.m1.1.1.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.T5.19.15.1.m1.1.1.1.1.3.cmml" xref="S4.T5.19.15.1.m1.1.1.1.1.3">2.0</cn></apply><apply id="S4.T5.19.15.1.m1.2.2.2.2.cmml" xref="S4.T5.19.15.1.m1.2.2.2.2"><eq id="S4.T5.19.15.1.m1.2.2.2.2.1.cmml" xref="S4.T5.19.15.1.m1.2.2.2.2.1"></eq><apply id="S4.T5.19.15.1.m1.2.2.2.2.2.cmml" xref="S4.T5.19.15.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T5.19.15.1.m1.2.2.2.2.2.1.cmml" xref="S4.T5.19.15.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.T5.19.15.1.m1.2.2.2.2.2.2.cmml" xref="S4.T5.19.15.1.m1.2.2.2.2.2.2">𝜆</ci><ci id="S4.T5.19.15.1.m1.2.2.2.2.2.3.cmml" xref="S4.T5.19.15.1.m1.2.2.2.2.2.3">𝐠</ci></apply><cn type="float" id="S4.T5.19.15.1.m1.2.2.2.2.3.cmml" xref="S4.T5.19.15.1.m1.2.2.2.2.3">1.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.19.15.1.m1.2c">\lambda_{\mathbf{A}}=2.0,\ \!\lambda_{\mathbf{g}}=1.0</annotation></semantics></math></th>
<td id="S4.T5.19.15.2" class="ltx_td ltx_align_center">8.295</td>
<td id="S4.T5.19.15.3" class="ltx_td ltx_align_center">6.397</td>
<td id="S4.T5.19.15.4" class="ltx_td ltx_align_center">0.455</td>
<td id="S4.T5.19.15.5" class="ltx_td ltx_align_center">0.395</td>
<td id="S4.T5.19.15.6" class="ltx_td ltx_align_center">104.293</td>
<td id="S4.T5.19.15.7" class="ltx_td ltx_align_center">5.531</td>
<td id="S4.T5.19.15.8" class="ltx_td ltx_align_center">0.005</td>
</tr>
<tr id="S4.T5.21.17" class="ltx_tr">
<th id="S4.T5.21.17.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<math id="S4.T5.20.16.1.m1.2" class="ltx_Math" alttext="\mathbb{\lambda_{\mathbf{A}}=0.5,\lambda_{\mathbf{g}}=1.0}" display="inline"><semantics id="S4.T5.20.16.1.m1.2a"><mrow id="S4.T5.20.16.1.m1.2.2.2" xref="S4.T5.20.16.1.m1.2.2.3.cmml"><mrow id="S4.T5.20.16.1.m1.1.1.1.1" xref="S4.T5.20.16.1.m1.1.1.1.1.cmml"><msub id="S4.T5.20.16.1.m1.1.1.1.1.2" xref="S4.T5.20.16.1.m1.1.1.1.1.2.cmml"><mi id="S4.T5.20.16.1.m1.1.1.1.1.2.2" xref="S4.T5.20.16.1.m1.1.1.1.1.2.2.cmml">λ</mi><mi id="S4.T5.20.16.1.m1.1.1.1.1.2.3" xref="S4.T5.20.16.1.m1.1.1.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.T5.20.16.1.m1.1.1.1.1.1" xref="S4.T5.20.16.1.m1.1.1.1.1.1.cmml">=</mo><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T5.20.16.1.m1.1.1.1.1.3" xref="S4.T5.20.16.1.m1.1.1.1.1.3.cmml">0.5</mn></mrow><mo id="S4.T5.20.16.1.m1.2.2.2.3" xref="S4.T5.20.16.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.T5.20.16.1.m1.2.2.2.2" xref="S4.T5.20.16.1.m1.2.2.2.2.cmml"><msub id="S4.T5.20.16.1.m1.2.2.2.2.2" xref="S4.T5.20.16.1.m1.2.2.2.2.2.cmml"><mi id="S4.T5.20.16.1.m1.2.2.2.2.2.2" xref="S4.T5.20.16.1.m1.2.2.2.2.2.2.cmml">λ</mi><mi id="S4.T5.20.16.1.m1.2.2.2.2.2.3" xref="S4.T5.20.16.1.m1.2.2.2.2.2.3.cmml">𝐠</mi></msub><mo id="S4.T5.20.16.1.m1.2.2.2.2.1" xref="S4.T5.20.16.1.m1.2.2.2.2.1.cmml">=</mo><mn class="ltx_mathvariant_double-struck" mathvariant="double-struck" id="S4.T5.20.16.1.m1.2.2.2.2.3" xref="S4.T5.20.16.1.m1.2.2.2.2.3.cmml">1.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.20.16.1.m1.2b"><apply id="S4.T5.20.16.1.m1.2.2.3.cmml" xref="S4.T5.20.16.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.T5.20.16.1.m1.2.2.3a.cmml" xref="S4.T5.20.16.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.T5.20.16.1.m1.1.1.1.1.cmml" xref="S4.T5.20.16.1.m1.1.1.1.1"><eq id="S4.T5.20.16.1.m1.1.1.1.1.1.cmml" xref="S4.T5.20.16.1.m1.1.1.1.1.1"></eq><apply id="S4.T5.20.16.1.m1.1.1.1.1.2.cmml" xref="S4.T5.20.16.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.T5.20.16.1.m1.1.1.1.1.2.1.cmml" xref="S4.T5.20.16.1.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.T5.20.16.1.m1.1.1.1.1.2.2.cmml" xref="S4.T5.20.16.1.m1.1.1.1.1.2.2">𝜆</ci><ci id="S4.T5.20.16.1.m1.1.1.1.1.2.3.cmml" xref="S4.T5.20.16.1.m1.1.1.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.T5.20.16.1.m1.1.1.1.1.3.cmml" xref="S4.T5.20.16.1.m1.1.1.1.1.3">0.5</cn></apply><apply id="S4.T5.20.16.1.m1.2.2.2.2.cmml" xref="S4.T5.20.16.1.m1.2.2.2.2"><eq id="S4.T5.20.16.1.m1.2.2.2.2.1.cmml" xref="S4.T5.20.16.1.m1.2.2.2.2.1"></eq><apply id="S4.T5.20.16.1.m1.2.2.2.2.2.cmml" xref="S4.T5.20.16.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.T5.20.16.1.m1.2.2.2.2.2.1.cmml" xref="S4.T5.20.16.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S4.T5.20.16.1.m1.2.2.2.2.2.2.cmml" xref="S4.T5.20.16.1.m1.2.2.2.2.2.2">𝜆</ci><ci id="S4.T5.20.16.1.m1.2.2.2.2.2.3.cmml" xref="S4.T5.20.16.1.m1.2.2.2.2.2.3">𝐠</ci></apply><cn type="float" id="S4.T5.20.16.1.m1.2.2.2.2.3.cmml" xref="S4.T5.20.16.1.m1.2.2.2.2.3">1.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.20.16.1.m1.2c">\mathbb{\lambda_{\mathbf{A}}=0.5,\lambda_{\mathbf{g}}=1.0}</annotation></semantics></math> <span id="S4.T5.21.17.2.1" class="ltx_text" style="font-size:80%;">(steps<math id="S4.T5.21.17.2.1.m1.1" class="ltx_Math" alttext="=10" display="inline"><semantics id="S4.T5.21.17.2.1.m1.1a"><mrow id="S4.T5.21.17.2.1.m1.1.1" xref="S4.T5.21.17.2.1.m1.1.1.cmml"><mi id="S4.T5.21.17.2.1.m1.1.1.2" xref="S4.T5.21.17.2.1.m1.1.1.2.cmml"></mi><mo id="S4.T5.21.17.2.1.m1.1.1.1" xref="S4.T5.21.17.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.T5.21.17.2.1.m1.1.1.3" xref="S4.T5.21.17.2.1.m1.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.21.17.2.1.m1.1b"><apply id="S4.T5.21.17.2.1.m1.1.1.cmml" xref="S4.T5.21.17.2.1.m1.1.1"><eq id="S4.T5.21.17.2.1.m1.1.1.1.cmml" xref="S4.T5.21.17.2.1.m1.1.1.1"></eq><csymbol cd="latexml" id="S4.T5.21.17.2.1.m1.1.1.2.cmml" xref="S4.T5.21.17.2.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T5.21.17.2.1.m1.1.1.3.cmml" xref="S4.T5.21.17.2.1.m1.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.21.17.2.1.m1.1c">=10</annotation></semantics></math>)</span>
</th>
<td id="S4.T5.21.17.3" class="ltx_td ltx_align_center ltx_border_t">8.293</td>
<td id="S4.T5.21.17.4" class="ltx_td ltx_align_center ltx_border_t">6.363</td>
<td id="S4.T5.21.17.5" class="ltx_td ltx_align_center ltx_border_t">0.523</td>
<td id="S4.T5.21.17.6" class="ltx_td ltx_align_center ltx_border_t">0.243</td>
<td id="S4.T5.21.17.7" class="ltx_td ltx_align_center ltx_border_t">117.060</td>
<td id="S4.T5.21.17.8" class="ltx_td ltx_align_center ltx_border_t">5.469</td>
<td id="S4.T5.21.17.9" class="ltx_td ltx_align_center ltx_border_t">0.006</td>
</tr>
<tr id="S4.T5.21.18.1" class="ltx_tr">
<th id="S4.T5.21.18.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t"><span id="S4.T5.21.18.1.1.1" class="ltx_text" style="color:#808080;">Real video</span></th>
<td id="S4.T5.21.18.1.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T5.21.18.1.2.1" class="ltx_text" style="color:#808080;">7.192</span></td>
<td id="S4.T5.21.18.1.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T5.21.18.1.3.1" class="ltx_text" style="color:#808080;">7.254</span></td>
<td id="S4.T5.21.18.1.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T5.21.18.1.4.1" class="ltx_text" style="color:#808080;">0.559</span></td>
<td id="S4.T5.21.18.1.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T5.21.18.1.5.1" class="ltx_text" style="color:#808080;">0.405</span></td>
<td id="S4.T5.21.18.1.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T5.21.18.1.6.1" class="ltx_text" style="color:#808080;">29.244</span></td>
<td id="S4.T5.21.18.1.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">–</td>
<td id="S4.T5.21.18.1.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">–</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS3.SSS0.Px2.p3" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p3.5" class="ltx_p">Further increasing <math id="S4.SS3.SSS0.Px2.p3.1.m1.1" class="ltx_Math" alttext="\lambda_{\mathbf{A}}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p3.1.m1.1a"><msub id="S4.SS3.SSS0.Px2.p3.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.3.cmml">𝐀</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p3.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p3.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p3.1.m1.1.1.3">𝐀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p3.1.m1.1c">\lambda_{\mathbf{A}}</annotation></semantics></math> marginally improves lip-audio synchronization and reduces <math id="S4.SS3.SSS0.Px2.p3.2.m2.1" class="ltx_Math" alttext="\text{FVD}_{25}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p3.2.m2.1a"><msub id="S4.SS3.SSS0.Px2.p3.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1.cmml"><mtext id="S4.SS3.SSS0.Px2.p3.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1.2a.cmml">FVD</mtext><mn id="S4.SS3.SSS0.Px2.p3.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1.3.cmml">25</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p3.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p3.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p3.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p3.2.m2.1.1.2a.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1.2"><mtext id="S4.SS3.SSS0.Px2.p3.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1.2">FVD</mtext></ci><cn type="integer" id="S4.SS3.SSS0.Px2.p3.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p3.2.m2.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p3.2.m2.1c">\text{FVD}_{25}</annotation></semantics></math>, but at the cost of slightly degrading audio-pose synchronization and gaze controllability.
In addition, observations from the generated videos indicate that a higher <math id="S4.SS3.SSS0.Px2.p3.3.m3.1" class="ltx_Math" alttext="\lambda_{\mathbf{A}}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p3.3.m3.1a"><msub id="S4.SS3.SSS0.Px2.p3.3.m3.1.1" xref="S4.SS3.SSS0.Px2.p3.3.m3.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p3.3.m3.1.1.2" xref="S4.SS3.SSS0.Px2.p3.3.m3.1.1.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p3.3.m3.1.1.3" xref="S4.SS3.SSS0.Px2.p3.3.m3.1.1.3.cmml">𝐀</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p3.3.m3.1b"><apply id="S4.SS3.SSS0.Px2.p3.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p3.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p3.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p3.3.m3.1.1.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p3.3.m3.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p3.3.m3.1.1.3">𝐀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p3.3.m3.1c">\lambda_{\mathbf{A}}</annotation></semantics></math> significantly amplifies mouth movements for strong vocals and causes head pose jitter during rapid speech. For balanced performance and overall generation quality, we set <math id="S4.SS3.SSS0.Px2.p3.4.m4.1" class="ltx_Math" alttext="\lambda_{\mathbf{A}}=0.5" display="inline"><semantics id="S4.SS3.SSS0.Px2.p3.4.m4.1a"><mrow id="S4.SS3.SSS0.Px2.p3.4.m4.1.1" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.cmml"><msub id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.2" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.3" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.3.cmml">𝐀</mi></msub><mo id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.1" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.3" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p3.4.m4.1b"><apply id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1"><eq id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.1"></eq><apply id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.2.3">𝐀</ci></apply><cn type="float" id="S4.SS3.SSS0.Px2.p3.4.m4.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p3.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p3.4.m4.1c">\lambda_{\mathbf{A}}=0.5</annotation></semantics></math> and <math id="S4.SS3.SSS0.Px2.p3.5.m5.1" class="ltx_Math" alttext="\lambda_{\mathbf{g}}=1.0" display="inline"><semantics id="S4.SS3.SSS0.Px2.p3.5.m5.1a"><mrow id="S4.SS3.SSS0.Px2.p3.5.m5.1.1" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.cmml"><msub id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.2" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.2.cmml">λ</mi><mi id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.3" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.3.cmml">𝐠</mi></msub><mo id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.1" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.3" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p3.5.m5.1b"><apply id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1"><eq id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.1"></eq><apply id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.2">𝜆</ci><ci id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.2.3">𝐠</ci></apply><cn type="float" id="S4.SS3.SSS0.Px2.p3.5.m5.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p3.5.m5.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p3.5.m5.1c">\lambda_{\mathbf{g}}=1.0</annotation></semantics></math> as our standard configuration.</p>
</div>
<div id="S4.SS3.SSS0.Px2.p4" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p4.2" class="ltx_p">We also evaluated the influence of sampling steps on performance. Table <a href="#S4.T5" title="Table 5 ‣ CFG scales. ‣ 4.3 Analysis and Ablation Study ‣ 4 Experiments ‣ VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates that decreasing the steps from <math id="S4.SS3.SSS0.Px2.p4.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS3.SSS0.Px2.p4.1.m1.1a"><mn id="S4.SS3.SSS0.Px2.p4.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p4.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p4.1.m1.1b"><cn type="integer" id="S4.SS3.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p4.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p4.1.m1.1c">50</annotation></semantics></math> to <math id="S4.SS3.SSS0.Px2.p4.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.SSS0.Px2.p4.2.m2.1a"><mn id="S4.SS3.SSS0.Px2.p4.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p4.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p4.2.m2.1b"><cn type="integer" id="S4.SS3.SSS0.Px2.p4.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p4.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p4.2.m2.1c">10</annotation></semantics></math> improves audio-lip and audio-pose alignment while compromising pose variation intensity and overall video quality. This step reduction could accelerate the inference process by a factor of 5 for this latent motion generation module.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In summary, our work presents VASA-1, an audio-driven talking face generation model that stands out for its efficient generation of realistic lip synchronization, vivid facial expressions, and naturalistic head movements from a single image and audio input. It significantly outperforms existing methods in delivering video quality and performance efficiency, demonstrating promising visual affective skills in the generated face videos. The technical cornerstone is an innovative holistic facial dynamics and head movement generation model that works in an expressive and disentangled face latent space.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">The advancements made by VASA-1 have the potential to reshape human-human and human-AI interactions across various domains, including communication, education, and healthcare. The integration of controllable conditioning signals further enhances the model’s adaptability for personalized user experiences.</p>
</div>
<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Limitations and future work.</h4>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.1" class="ltx_p">There are still several limitations with our method. Currently, it processes human regions only up to the torso. Extending to the full upper body could offer additional capabilities. While utilizing 3D latent representations, the absence of a more explicit 3D face model such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">63</span></a>, <a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">64</span></a>]</cite> may result in artifacts like texture sticking due to the neural rendering. Additionally, our approach does not account for non-rigid elements like hair and clothing, which could be addressed with a stronger video prior. In the future, we also plan to incorporate more diverse talking styles and emotions to improve expressiveness and control.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Social Impact and Responsible AI Considerations </h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Our research focuses on generating audio-driven visual affective skills for virtual AI avatars, aiming for positive applications.
It is not intended to create content that is used to mislead or deceive. However, like other related content generation techniques, it could still potentially be misused for impersonating humans. We are opposed to any behavior to create misleading or harmful contents of real persons, and are interested in applying our technique for advancing forgery detection. Currently, the videos generated by this method still contain identifiable artifacts, and the numerical study shows that there’s still a gap to achieve the authenticity of real videos.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">While acknowledging the possibility of misuse, it’s imperative to recognize the substantial positive potential of our technique. The benefits – ranging from enhancing educational equity, improving accessibility for individuals with communication challenges, and offering companionship or therapeutic support to those in need – underscore the importance of our research and other related explorations. We are dedicated to developing AI responsibly, with the goal of advancing human well-being.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Contribution statement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Sicheng Xu, Guojun Chen, Yu-Xiao Guo were the core contributors to the implementation, training, and experimentation of various algorithm modules, as well as the data processing and management. Jiaolong Yang initiated the project idea, led the project, designed the overall framework, and provided detailed technical advice to each component. Chong Li, Zhengyu Zang and Yizhong Zhang contributed to enhancing the system quality, conducting evaluations, and demonstrating results. Xin Tong provided technical advice throughout the project and helped with project coordination. Baining Guo offered strategic research direction guidance, scientific advising, and other project supports. Paper written by Jiaolong Yang and Sicheng Xu.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We would like to thank our colleagues Zheng Zhang, Zhirong Wu, Shujie Liu, Dong Chen, Xu Tan and others for the valuable discussions and insightful suggestions for our project.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.4.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://www.prnewswire.com/news-releases/deepbrain-ai-delivers-ai-avatar-to-empower-people-with-disabilities-302026965.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.prnewswire.com/news-releases/deepbrain-ai-delivers-ai-avatar-to-empower-people-with-disabilities-302026965.html</a><span id="bib.bib1.5.2" class="ltx_text" style="font-size:90%;">,
2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.6.1" class="ltx_text" style="font-size:90%;">[Online; accessed 8-Apr-2024].
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.2.2.1" class="ltx_text" style="font-size:90%;">[2]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.4.1" class="ltx_text" style="font-size:90%;">
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.5.1" class="ltx_text" style="font-size:90%;">wav2vec 2.0: A framework for self-supervised learning of speech
representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib2.7.2" class="ltx_text" style="font-size:90%;">,
33:12449–12460, 2020.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.2.2.1" class="ltx_text" style="font-size:90%;">[3]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.4.1" class="ltx_text" style="font-size:90%;">
Omer Bar-Tal, Hila Chefer, Omer Tov, Charles Herrmann, Roni Paiss, Shiran Zada,
Ariel Ephrat, Junhwa Hur, Yuanzhen Li, Tomer Michaeli, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.5.1" class="ltx_text" style="font-size:90%;">Lumiere: A space-time diffusion model for video generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2401.12945</span><span id="bib.bib3.7.2" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.2.2.1" class="ltx_text" style="font-size:90%;">[4]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text" style="font-size:90%;">
James Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long
Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.5.1" class="ltx_text" style="font-size:90%;">Improving image generation with better captions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">https://cdn. openai. com/papers/dall-e-3.pdf</span><span id="bib.bib4.7.2" class="ltx_text" style="font-size:90%;">, 2(3):8, 2023.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.2.2.1" class="ltx_text" style="font-size:90%;">[5]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.4.1" class="ltx_text" style="font-size:90%;">
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej
Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts,
et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.5.1" class="ltx_text" style="font-size:90%;">Stable video diffusion: Scaling latent video diffusion models to
large datasets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2311.15127</span><span id="bib.bib5.7.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.2.2.1" class="ltx_text" style="font-size:90%;">[6]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.4.1" class="ltx_text" style="font-size:90%;">
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim,
Sanja Fidler, and Karsten Kreis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.5.1" class="ltx_text" style="font-size:90%;">Align your latents: High-resolution video synthesis with latent
diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib6.8.3" class="ltx_text" style="font-size:90%;">, pages 22563–22575, 2023.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.2.2.1" class="ltx_text" style="font-size:90%;">[7]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text" style="font-size:90%;">
Aras Bozkurt, Xiao Junhong, Sarah Lambert, Angelica Pazurek, Helen Crompton,
Suzan Koseoglu, Robert Farrow, Melissa Bond, Chrissi Nerantzi, Sarah
Honeychurch, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.5.1" class="ltx_text" style="font-size:90%;">Speculative futures on chatgpt and generative artificial intelligence
(ai): A collective reflection from the educational landscape.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Asian Journal of Distance Education</span><span id="bib.bib7.7.2" class="ltx_text" style="font-size:90%;">, 18(1):53–130, 2023.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.2.2.1" class="ltx_text" style="font-size:90%;">[8]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.4.1" class="ltx_text" style="font-size:90%;">
Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David
Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, Clarence Ng, Ricky Wang, and
Aditya Ramesh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.5.1" class="ltx_text" style="font-size:90%;">Video generation models as world simulators.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.6.1" class="ltx_text" style="font-size:90%;">2024.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.2.2.1" class="ltx_text" style="font-size:90%;">[9]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text" style="font-size:90%;">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.5.1" class="ltx_text" style="font-size:90%;">Language models are few-shot learners.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib9.7.2" class="ltx_text" style="font-size:90%;">,
33:1877–1901, 2020.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.2.2.1" class="ltx_text" style="font-size:90%;">[10]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.4.1" class="ltx_text" style="font-size:90%;">
Egor Burkov, Igor Pasechnik, Artur Grigorev, and Victor Lempitsky.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.5.1" class="ltx_text" style="font-size:90%;">Neural head reenactment with latent pose descriptors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib10.8.3" class="ltx_text" style="font-size:90%;">, pages 13786–13795, 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.2.2.1" class="ltx_text" style="font-size:90%;">[11]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.4.1" class="ltx_text" style="font-size:90%;">
Lele Chen, Zhiheng Li, Ross K Maddox, Zhiyao Duan, and Chenliang Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.5.1" class="ltx_text" style="font-size:90%;">Lip movements generation at a glance.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib11.8.3" class="ltx_text" style="font-size:90%;">, pages 520–535,
2018.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.2.2.1" class="ltx_text" style="font-size:90%;">[12]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.4.1" class="ltx_text" style="font-size:90%;">
Kun Cheng, Xiaodong Cun, Yong Zhang, Menghan Xia, Fei Yin, Mingrui Zhu, Xuan
Wang, Jue Wang, and Nannan Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.5.1" class="ltx_text" style="font-size:90%;">Videoretalking: Audio-based lip synchronization for talking head
video editing in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">SIGGRAPH Asia 2022</span><span id="bib.bib12.8.3" class="ltx_text" style="font-size:90%;">, pages 1–9, 2022.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.2.2.1" class="ltx_text" style="font-size:90%;">[13]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.4.1" class="ltx_text" style="font-size:90%;">
Joon Son Chung, Arsha Nagrani, and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.5.1" class="ltx_text" style="font-size:90%;">Voxceleb2: Deep speaker recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1806.05622</span><span id="bib.bib13.7.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.2.2.1" class="ltx_text" style="font-size:90%;">[14]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text" style="font-size:90%;">
Joon Son Chung and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.5.1" class="ltx_text" style="font-size:90%;">Out of time: automated lip sync in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Asian Conference on Computer Vision Workshops</span><span id="bib.bib14.8.3" class="ltx_text" style="font-size:90%;">, pages
251–263. Springer, 2017.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.2.2.1" class="ltx_text" style="font-size:90%;">[15]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.4.1" class="ltx_text" style="font-size:90%;">
Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.5.1" class="ltx_text" style="font-size:90%;">Arcface: Additive angular margin loss for deep face recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib15.8.3" class="ltx_text" style="font-size:90%;">, pages 4690–4699, 2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.2.2.1" class="ltx_text" style="font-size:90%;">[16]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.4.1" class="ltx_text" style="font-size:90%;">
Yu Deng, Jiaolong Yang, Sicheng Xu, Dong Chen, Yunde Jia, and Xin Tong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.5.1" class="ltx_text" style="font-size:90%;">Accurate 3d face reconstruction with weakly-supervised learning: From
single image to image set.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition Workshops</span><span id="bib.bib16.8.3" class="ltx_text" style="font-size:90%;">, pages 0–0, 2019.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.2.2.1" class="ltx_text" style="font-size:90%;">[17]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.4.1" class="ltx_text" style="font-size:90%;">
Nikita Drobyshev, Jenya Chelishev, Taras Khakhulin, Aleksei Ivakhnenko, Victor
Lempitsky, and Egor Zakharov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.5.1" class="ltx_text" style="font-size:90%;">Megaportraits: One-shot megapixel neural head avatars.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 30th ACM International Conference on
Multimedia</span><span id="bib.bib17.8.3" class="ltx_text" style="font-size:90%;">, pages 2663–2671, 2022.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.2.2.1" class="ltx_text" style="font-size:90%;">[18]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.4.1" class="ltx_text" style="font-size:90%;">
Chenpeng Du, Qi Chen, Tianyu He, Xu Tan, Xie Chen, Kai Yu, Sheng Zhao, and
Jiang Bian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.5.1" class="ltx_text" style="font-size:90%;">Dae-talker: High fidelity speech-driven talking face generation with
diffusion autoencoder.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the ACM International Conference on
Multimedia</span><span id="bib.bib18.8.3" class="ltx_text" style="font-size:90%;">, pages 4281–4289, 2023.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.2.2.1" class="ltx_text" style="font-size:90%;">[19]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.4.1" class="ltx_text" style="font-size:90%;">
Yingruo Fan, Zhaojiang Lin, Jun Saito, Wenping Wang, and Taku Komura.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.5.1" class="ltx_text" style="font-size:90%;">Faceformer: Speech-driven 3d facial animation with transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib19.8.3" class="ltx_text" style="font-size:90%;">, pages 18770–18780, 2022.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.2.2.1" class="ltx_text" style="font-size:90%;">[20]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.4.1" class="ltx_text" style="font-size:90%;">
Yue Gao, Yuan Zhou, Jinglu Wang, Xiao Li, Xiang Ming, and Yan Lu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.5.1" class="ltx_text" style="font-size:90%;">High-fidelity and freely controllable talking head video generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib20.8.3" class="ltx_text" style="font-size:90%;">, pages 5609–5619, 2023.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.2.2.1" class="ltx_text" style="font-size:90%;">[21]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.4.1" class="ltx_text" style="font-size:90%;">
Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, Samaneh Azadi,
Sai Saketh Rambhatla, Akbar Shah, Xi Yin, Devi Parikh, and Ishan Misra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.5.1" class="ltx_text" style="font-size:90%;">Emu video: Factorizing text-to-video generation by explicit image
conditioning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2311.10709</span><span id="bib.bib21.7.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.2.2.1" class="ltx_text" style="font-size:90%;">[22]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.4.1" class="ltx_text" style="font-size:90%;">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.5.1" class="ltx_text" style="font-size:90%;">Generative adversarial nets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib22.7.2" class="ltx_text" style="font-size:90%;">, 27, 2014.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.2.2.1" class="ltx_text" style="font-size:90%;">[23]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.4.1" class="ltx_text" style="font-size:90%;">
Yudong Guo, Keyu Chen, Sen Liang, Yong-Jin Liu, Hujun Bao, and Juyong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.5.1" class="ltx_text" style="font-size:90%;">Ad-nerf: Audio driven neural radiance fields for talking head
synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF International Conference on Computer Vision</span><span id="bib.bib23.8.3" class="ltx_text" style="font-size:90%;">, pages
5784–5794, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.2.2.1" class="ltx_text" style="font-size:90%;">[24]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.4.1" class="ltx_text" style="font-size:90%;">
Tianyu He, Junliang Guo, Runyi Yu, Yuchi Wang, Jialiang Zhu, Kaikai An, Leyi
Li, Xu Tan, Chunyu Wang, Han Hu, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.5.1" class="ltx_text" style="font-size:90%;">Gaia: Zero-shot talking avatar generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</span><span id="bib.bib24.8.3" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.2.2.1" class="ltx_text" style="font-size:90%;">[25]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.4.1" class="ltx_text" style="font-size:90%;">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.5.1" class="ltx_text" style="font-size:90%;">Denoising diffusion probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib25.7.2" class="ltx_text" style="font-size:90%;">,
33:6840–6851, 2020.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.2.2.1" class="ltx_text" style="font-size:90%;">[26]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.4.1" class="ltx_text" style="font-size:90%;">
Jonathan Ho and Tim Salimans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.5.1" class="ltx_text" style="font-size:90%;">Classifier-free diffusion guidance.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2207.12598</span><span id="bib.bib26.7.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.2.2.1" class="ltx_text" style="font-size:90%;">[27]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.4.1" class="ltx_text" style="font-size:90%;">
Esperanza Johnson, Ramón Hervás, Carlos Gutiérrez López de la
Franca, Tania Mondéjar, Sergio F Ochoa, and Jesús Favela.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.5.1" class="ltx_text" style="font-size:90%;">Assessing empathy and managing emotions through interactions with an
affective avatar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Health informatics journal</span><span id="bib.bib27.7.2" class="ltx_text" style="font-size:90%;">, 24(2):182–193, 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.2.2.1" class="ltx_text" style="font-size:90%;">[28]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.4.1" class="ltx_text" style="font-size:90%;">
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
Timo Aila.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.5.1" class="ltx_text" style="font-size:90%;">Analyzing and improving the image quality of stylegan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib28.8.3" class="ltx_text" style="font-size:90%;">, pages 8110–8119, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.2.2.1" class="ltx_text" style="font-size:90%;">[29]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.4.1" class="ltx_text" style="font-size:90%;">
Greg Kessler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.5.1" class="ltx_text" style="font-size:90%;">Technology and the future of language teaching.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Foreign Language Annals</span><span id="bib.bib29.7.2" class="ltx_text" style="font-size:90%;">, 51(1):205–218, 2018.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.2.2.1" class="ltx_text" style="font-size:90%;">[30]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.4.1" class="ltx_text" style="font-size:90%;">
Dan Kondratyuk, Lijun Yu, Xiuye Gu, José Lezama, Jonathan Huang, Rachel
Hornung, Hartwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birodkar, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.5.1" class="ltx_text" style="font-size:90%;">Videopoet: A large language model for zero-shot video generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2312.14125</span><span id="bib.bib30.7.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.2.2.1" class="ltx_text" style="font-size:90%;">[31]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.4.1" class="ltx_text" style="font-size:90%;">
Julian Leff, Geoffrey Williams, Mark Huckvale, Maurice Arbuthnot, and Alex P
Leff.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.5.1" class="ltx_text" style="font-size:90%;">Avatar therapy for persecutory auditory hallucinations: What is it
and how does it work?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Psychosis</span><span id="bib.bib31.7.2" class="ltx_text" style="font-size:90%;">, 6(2):166–176, 2014.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.2.2.1" class="ltx_text" style="font-size:90%;">[32]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.4.1" class="ltx_text" style="font-size:90%;">
Borong Liang, Yan Pan, Zhizhi Guo, Hang Zhou, Zhibin Hong, Xiaoguang Han, Junyu
Han, Jingtuo Liu, Errui Ding, and Jingdong Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.5.1" class="ltx_text" style="font-size:90%;">Expressive talking head generation with granular audio-visual
control.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib32.8.3" class="ltx_text" style="font-size:90%;">, pages 3387–3396, 2022.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.2.2.1" class="ltx_text" style="font-size:90%;">[33]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.4.1" class="ltx_text" style="font-size:90%;">
Shugao Ma, Tomas Simon, Jason Saragih, Dawei Wang, Yuecheng Li, Fernando
De La Torre, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.5.1" class="ltx_text" style="font-size:90%;">Pixel codec avatars.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib33.8.3" class="ltx_text" style="font-size:90%;">, pages 64–73, 2021.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.2.2.1" class="ltx_text" style="font-size:90%;">[34]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.4.1" class="ltx_text" style="font-size:90%;">
Yifeng Ma, Suzhen Wang, Zhipeng Hu, Changjie Fan, Tangjie Lv, Yu Ding, Zhidong
Deng, and Xin Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.5.1" class="ltx_text" style="font-size:90%;">Styletalk: One-shot talking head generation with controllable
speaking styles.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI Conference on Artificial Intelligence</span><span id="bib.bib34.8.3" class="ltx_text" style="font-size:90%;">, pages
arXiv–2301, 2023.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.2.2.1" class="ltx_text" style="font-size:90%;">[35]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.4.1" class="ltx_text" style="font-size:90%;">
Youxin Pang, Yong Zhang, Weize Quan, Yanbo Fan, Xiaodong Cun, Ying Shan, and
Dong-ming Yan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.5.1" class="ltx_text" style="font-size:90%;">Dpe: Disentanglement of pose and expression for general video
portrait editing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib35.8.3" class="ltx_text" style="font-size:90%;">, pages 427–436, 2023.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.2.2.1" class="ltx_text" style="font-size:90%;">[36]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.4.1" class="ltx_text" style="font-size:90%;">
William Peebles and Saining Xie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.5.1" class="ltx_text" style="font-size:90%;">Scalable diffusion models with transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib36.8.3" class="ltx_text" style="font-size:90%;">, pages 4195–4205, 2023.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.2.2.1" class="ltx_text" style="font-size:90%;">[37]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.4.1" class="ltx_text" style="font-size:90%;">
KR Prajwal, Rudrabha Mukhopadhyay, Vinay P Namboodiri, and CV Jawahar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.5.1" class="ltx_text" style="font-size:90%;">A lip sync expert is all you need for speech to lip generation in the
wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM International Conference on Multimedia</span><span id="bib.bib37.8.3" class="ltx_text" style="font-size:90%;">, pages 484–492,
2020.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.2.2.1" class="ltx_text" style="font-size:90%;">[38]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.4.1" class="ltx_text" style="font-size:90%;">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.5.1" class="ltx_text" style="font-size:90%;">Learning transferable visual models from natural language
supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib38.8.3" class="ltx_text" style="font-size:90%;">, pages
8748–8763. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.2.2.1" class="ltx_text" style="font-size:90%;">[39]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.4.1" class="ltx_text" style="font-size:90%;">
Imogen C Rehm, Emily Foenander, Klaire Wallace, Jo-Anne M Abbott, Michael
Kyrios, and Neil Thomas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.5.1" class="ltx_text" style="font-size:90%;">What role can avatars play in e-mental health interventions?
exploring new models of client–therapist interaction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Frontiers in Psychiatry</span><span id="bib.bib39.7.2" class="ltx_text" style="font-size:90%;">, 7:186, 2016.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.2.2.1" class="ltx_text" style="font-size:90%;">[40]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.4.1" class="ltx_text" style="font-size:90%;">
Yurui Ren, Ge Li, Yuanqi Chen, Thomas H Li, and Shan Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.5.1" class="ltx_text" style="font-size:90%;">PIRenderer: Controllable portrait image generation via semantic
neural rendering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib40.8.3" class="ltx_text" style="font-size:90%;">, pages 13759–13768, 2021.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.2.2.1" class="ltx_text" style="font-size:90%;">[41]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.4.1" class="ltx_text" style="font-size:90%;">
Andrey V Savchenko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.5.1" class="ltx_text" style="font-size:90%;">Hsemotion: High-speed emotion recognition library.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Software Impacts</span><span id="bib.bib41.7.2" class="ltx_text" style="font-size:90%;">, 14:100433, 2022.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.2.2.1" class="ltx_text" style="font-size:90%;">[42]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.4.1" class="ltx_text" style="font-size:90%;">
Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa
Ricci, and Nicu Sebe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.5.1" class="ltx_text" style="font-size:90%;">First order motion model for image animation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib42.8.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.2.2.1" class="ltx_text" style="font-size:90%;">[43]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.4.1" class="ltx_text" style="font-size:90%;">
Li Siyao, Weijiang Yu, Tianpei Gu, Chunze Lin, Quan Wang, Chen Qian,
Chen Change Loy, and Ziwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.5.1" class="ltx_text" style="font-size:90%;">Bailando: 3d dance generation by actor-critic gpt with choreographic
memory.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib43.8.3" class="ltx_text" style="font-size:90%;">, pages 11050–11059, 2022.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.2.2.1" class="ltx_text" style="font-size:90%;">[44]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.4.1" class="ltx_text" style="font-size:90%;">
Ivan Skorokhodov, Sergey Tulyakov, and Mohamed Elhoseiny.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.5.1" class="ltx_text" style="font-size:90%;">Stylegan-v: A continuous video generator with the price, image
quality and perks of stylegan2.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib44.8.3" class="ltx_text" style="font-size:90%;">, pages 3626–3636, 2022.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.2.2.1" class="ltx_text" style="font-size:90%;">[45]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.4.1" class="ltx_text" style="font-size:90%;">
Jiaming Song, Chenlin Meng, and Stefano Ermon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.5.1" class="ltx_text" style="font-size:90%;">Denoising diffusion implicit models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2010.02502</span><span id="bib.bib45.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.2.2.1" class="ltx_text" style="font-size:90%;">[46]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.4.1" class="ltx_text" style="font-size:90%;">
Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano
Ermon, and Ben Poole.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.5.1" class="ltx_text" style="font-size:90%;">Score-based generative modeling through stochastic differential
equations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.13456</span><span id="bib.bib46.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.2.2.1" class="ltx_text" style="font-size:90%;">[47]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.4.1" class="ltx_text" style="font-size:90%;">
Michał Stypułkowski, Konstantinos Vougioukas, Sen He, Maciej Zięba,
Stavros Petridis, and Maja Pantic.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.5.1" class="ltx_text" style="font-size:90%;">Diffused heads: Diffusion models beat gans on talking-face
generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications
of Computer Vision</span><span id="bib.bib47.8.3" class="ltx_text" style="font-size:90%;">, pages 5091–5100, 2024.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.2.2.1" class="ltx_text" style="font-size:90%;">[48]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.4.1" class="ltx_text" style="font-size:90%;">
Shaolin Su, Qingsen Yan, Yu Zhu, Cheng Zhang, Xin Ge, Jinqiu Sun, and Yanning
Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.5.1" class="ltx_text" style="font-size:90%;">Blindly assess image quality in the wild guided by a self-adaptive
hyper network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib48.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib48.8.3" class="ltx_text" style="font-size:90%;">, pages 3667–3676, 2020.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.2.2.1" class="ltx_text" style="font-size:90%;">[49]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.4.1" class="ltx_text" style="font-size:90%;">
Yasheng Sun, Hang Zhou, Ziwei Liu, and Hideki Koike.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.5.1" class="ltx_text" style="font-size:90%;">Speech2talking-face: Inferring and driving a face with synchronized
audio-visual representation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Joint Conference on Artificial Intelligence</span><span id="bib.bib49.8.3" class="ltx_text" style="font-size:90%;">,
volume 2, page 4, 2021.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.2.2.1" class="ltx_text" style="font-size:90%;">[50]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.4.1" class="ltx_text" style="font-size:90%;">
Zhiyao Sun, Tian Lv, Sheng Ye, Matthieu Gaetan Lin, Jenny Sheng, Yu-Hui Wen,
Minjing Yu, and Yong-jin Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.5.1" class="ltx_text" style="font-size:90%;">Diffposetalk: Speech-driven stylistic 3d facial animation and head
pose generation via diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2310.00434</span><span id="bib.bib50.7.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.2.2.1" class="ltx_text" style="font-size:90%;">[51]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.4.1" class="ltx_text" style="font-size:90%;">
Supasorn Suwajanakorn, Steven M Seitz, and Ira Kemelmacher-Shlizerman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.5.1" class="ltx_text" style="font-size:90%;">Synthesizing obama: learning lip sync from audio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics</span><span id="bib.bib51.7.2" class="ltx_text" style="font-size:90%;">, 36(4):1–13, 2017.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.2.2.1" class="ltx_text" style="font-size:90%;">[52]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.4.1" class="ltx_text" style="font-size:90%;">
Linrui Tian, Qi Wang, Bang Zhang, and Liefeng Bo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.5.1" class="ltx_text" style="font-size:90%;">Emo: Emote portrait alive-generating expressive portrait videos with
audio2video diffusion model under weak conditions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2402.17485</span><span id="bib.bib52.7.2" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.2.2.1" class="ltx_text" style="font-size:90%;">[53]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.4.1" class="ltx_text" style="font-size:90%;">
Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.5.1" class="ltx_text" style="font-size:90%;">Mocogan: Decomposing motion and content for video generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib53.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib53.8.3" class="ltx_text" style="font-size:90%;">, pages 1526–1535, 2018.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.2.2.1" class="ltx_text" style="font-size:90%;">[54]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.4.1" class="ltx_text" style="font-size:90%;">
Thomas Unterthiner, Sjoerd van Steenkiste, Karol Kurach, Raphaël Marinier,
Marcin Michalski, and Sylvain Gelly.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.5.1" class="ltx_text" style="font-size:90%;">Fvd: A new metric for video generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.6.1" class="ltx_text" style="font-size:90%;">2019.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.2.2.1" class="ltx_text" style="font-size:90%;">[55]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.4.1" class="ltx_text" style="font-size:90%;">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.5.1" class="ltx_text" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib55.7.2" class="ltx_text" style="font-size:90%;">, 30, 2017.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.2.2.1" class="ltx_text" style="font-size:90%;">[56]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.4.1" class="ltx_text" style="font-size:90%;">
Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.5.1" class="ltx_text" style="font-size:90%;">Generating videos with scene dynamics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib56.7.2" class="ltx_text" style="font-size:90%;">, 29, 2016.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.2.2.1" class="ltx_text" style="font-size:90%;">[57]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.4.1" class="ltx_text" style="font-size:90%;">
Duomin Wang, Yu Deng, Zixin Yin, Heung-Yeung Shum, and Baoyuan Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.5.1" class="ltx_text" style="font-size:90%;">Progressive disentangled representation learning for fine-grained
controllable talking head synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib57.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib57.8.3" class="ltx_text" style="font-size:90%;">, pages 17979–17989, 2023.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.2.2.1" class="ltx_text" style="font-size:90%;">[58]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.4.1" class="ltx_text" style="font-size:90%;">
Jiayu Wang, Kang Zhao, Shiwei Zhang, Yingya Zhang, Yujun Shen, Deli Zhao, and
Jingren Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.5.1" class="ltx_text" style="font-size:90%;">Lipformer: High-fidelity and generalizable talking face generation
with a pre-learned facial codebook.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib58.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib58.8.3" class="ltx_text" style="font-size:90%;">, pages 13844–13853, 2023.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.2.2.1" class="ltx_text" style="font-size:90%;">[59]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.4.1" class="ltx_text" style="font-size:90%;">
Suzhen Wang, Lincheng Li, Yu Ding, Changjie Fan, and Xin Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.5.1" class="ltx_text" style="font-size:90%;">Audio2head: Audio-driven one-shot talking-head generation with
natural head motion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib59.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Joint Conference on Artificial Intelligence</span><span id="bib.bib59.8.3" class="ltx_text" style="font-size:90%;">,
2021.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.2.2.1" class="ltx_text" style="font-size:90%;">[60]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.4.1" class="ltx_text" style="font-size:90%;">
Suzhen Wang, Lincheng Li, Yu Ding, and Xin Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.5.1" class="ltx_text" style="font-size:90%;">One-shot talking face generation from single-speaker audio-visual
correlation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib60.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI Conference on Artificial Intelligence</span><span id="bib.bib60.8.3" class="ltx_text" style="font-size:90%;">, volume 36, pages
2531–2539, 2022.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.2.2.1" class="ltx_text" style="font-size:90%;">[61]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.4.1" class="ltx_text" style="font-size:90%;">
Ting-Chun Wang, Arun Mallya, and Ming-Yu Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.5.1" class="ltx_text" style="font-size:90%;">One-shot free-view neural talking-head synthesis for video
conferencing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib61.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib61.8.3" class="ltx_text" style="font-size:90%;">, pages 10039–10049, 2021.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.2.2.1" class="ltx_text" style="font-size:90%;">[62]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.4.1" class="ltx_text" style="font-size:90%;">
Huawei Wei, Zejun Yang, and Zhisheng Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.5.1" class="ltx_text" style="font-size:90%;">Aniportrait: Audio-driven synthesis of photorealistic portrait
animation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2403.17694</span><span id="bib.bib62.7.2" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.2.2.1" class="ltx_text" style="font-size:90%;">[63]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.4.1" class="ltx_text" style="font-size:90%;">
Yue Wu, Yu Deng, Jiaolong Yang, Fangyun Wei, Qifeng Chen, and Xin Tong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.5.1" class="ltx_text" style="font-size:90%;">Anifacegan: Animatable 3d-aware face image generation for video
avatars.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib63.7.2" class="ltx_text" style="font-size:90%;">,
35:36188–36201, 2022.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.2.2.1" class="ltx_text" style="font-size:90%;">[64]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.4.1" class="ltx_text" style="font-size:90%;">
Yue Wu, Sicheng Xu, Jianfeng Xiang, Fangyun Wei, Qifeng Chen, Jiaolong Yang,
and Xin Tong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.5.1" class="ltx_text" style="font-size:90%;">Aniportraitgan: Animatable 3d portrait generation from 2d image
collections.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib64.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">SIGGRAPH Asia 2023</span><span id="bib.bib64.8.3" class="ltx_text" style="font-size:90%;">, pages 1–9, 2023.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib65.2.2.1" class="ltx_text" style="font-size:90%;">[65]</span></span>
<span class="ltx_bibblock"><span id="bib.bib65.4.1" class="ltx_text" style="font-size:90%;">
Jinbo Xing, Menghan Xia, Yuechen Zhang, Xiaodong Cun, Jue Wang, and Tien-Tsin
Wong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.5.1" class="ltx_text" style="font-size:90%;">Codetalker: Speech-driven 3d facial animation with discrete motion
prior.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib65.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib65.8.3" class="ltx_text" style="font-size:90%;">, pages 12780–12790, 2023.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib66.2.2.1" class="ltx_text" style="font-size:90%;">[66]</span></span>
<span class="ltx_bibblock"><span id="bib.bib66.4.1" class="ltx_text" style="font-size:90%;">
Wilson Yan, Yunzhi Zhang, Pieter Abbeel, and Aravind Srinivas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.5.1" class="ltx_text" style="font-size:90%;">Videogpt: Video generation using vq-vae and transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.10157</span><span id="bib.bib66.7.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib67.2.2.1" class="ltx_text" style="font-size:90%;">[67]</span></span>
<span class="ltx_bibblock"><span id="bib.bib67.4.1" class="ltx_text" style="font-size:90%;">
Fei Yin, Yong Zhang, Xiaodong Cun, Mingdeng Cao, Yanbo Fan, Xuan Wang, Qingyan
Bai, Baoyuan Wu, Jue Wang, and Yujiu Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.5.1" class="ltx_text" style="font-size:90%;">Styleheat: One-shot high-resolution editable talking face generation
via pre-trained stylegan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib67.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib67.8.3" class="ltx_text" style="font-size:90%;">, pages 85–101, 2022.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib68.2.2.1" class="ltx_text" style="font-size:90%;">[68]</span></span>
<span class="ltx_bibblock"><span id="bib.bib68.4.1" class="ltx_text" style="font-size:90%;">
Zhentao Yu, Zixin Yin, Deyu Zhou, Duomin Wang, Finn Wong, and Baoyuan Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.5.1" class="ltx_text" style="font-size:90%;">Talking head generation with probabilistic audio-to-visual diffusion
priors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib68.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib68.8.3" class="ltx_text" style="font-size:90%;">, pages 7645–7655, 2023.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib69.2.2.1" class="ltx_text" style="font-size:90%;">[69]</span></span>
<span class="ltx_bibblock"><span id="bib.bib69.4.1" class="ltx_text" style="font-size:90%;">
Egor Zakharov, Aleksei Ivakhnenko, Aliaksandra Shysheya, and Victor Lempitsky.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.5.1" class="ltx_text" style="font-size:90%;">Fast bi-layer neural synthesis of one-shot realistic head avatars.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib69.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib69.8.3" class="ltx_text" style="font-size:90%;">, pages 524–540,
2020.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib70.2.2.1" class="ltx_text" style="font-size:90%;">[70]</span></span>
<span class="ltx_bibblock"><span id="bib.bib70.4.1" class="ltx_text" style="font-size:90%;">
Raimondas Zemblys, Diederick C Niehorster, and Kenneth Holmqvist.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.5.1" class="ltx_text" style="font-size:90%;">gazenet: End-to-end eye-movement event detection with deep neural
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Behavior research methods</span><span id="bib.bib70.7.2" class="ltx_text" style="font-size:90%;">, 51:840–864, 2019.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib71.2.2.1" class="ltx_text" style="font-size:90%;">[71]</span></span>
<span class="ltx_bibblock"><span id="bib.bib71.4.1" class="ltx_text" style="font-size:90%;">
Bowen Zhang, Chenyang Qi, Pan Zhang, Bo Zhang, HsiangTao Wu, Dong Chen, Qifeng
Chen, Yong Wang, and Fang Wen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.5.1" class="ltx_text" style="font-size:90%;">Metaportrait: Identity-preserving talking head generation with fast
personalized adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib71.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib71.8.3" class="ltx_text" style="font-size:90%;">, pages 22096–22105, 2023.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib72.2.2.1" class="ltx_text" style="font-size:90%;">[72]</span></span>
<span class="ltx_bibblock"><span id="bib.bib72.4.1" class="ltx_text" style="font-size:90%;">
Wenxuan Zhang, Xiaodong Cun, Xuan Wang, Yong Zhang, Xi Shen, Yu Guo, Ying Shan,
and Fei Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.5.1" class="ltx_text" style="font-size:90%;">Sadtalker: Learning realistic 3d motion coefficients for stylized
audio-driven single image talking face animation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib72.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib72.8.3" class="ltx_text" style="font-size:90%;">, pages 8652–8661, 2023.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib73.2.2.1" class="ltx_text" style="font-size:90%;">[73]</span></span>
<span class="ltx_bibblock"><span id="bib.bib73.4.1" class="ltx_text" style="font-size:90%;">
Zhimeng Zhang, Lincheng Li, Yu Ding, and Changjie Fan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.5.1" class="ltx_text" style="font-size:90%;">Flow-guided one-shot talking face generation with a high-resolution
audio-visual dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib73.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib73.8.3" class="ltx_text" style="font-size:90%;">, pages 3661–3670, 2021.
</span>
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib74.2.2.1" class="ltx_text" style="font-size:90%;">[74]</span></span>
<span class="ltx_bibblock"><span id="bib.bib74.4.1" class="ltx_text" style="font-size:90%;">
Hang Zhou, Yasheng Sun, Wayne Wu, Chen Change Loy, Xiaogang Wang, and Ziwei
Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib74.5.1" class="ltx_text" style="font-size:90%;">Pose-controllable talking face generation by implicitly modularized
audio-visual representation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib74.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib74.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on computer Vision and
Pattern Recognition</span><span id="bib.bib74.8.3" class="ltx_text" style="font-size:90%;">, pages 4176–4186, 2021.
</span>
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib75.2.2.1" class="ltx_text" style="font-size:90%;">[75]</span></span>
<span class="ltx_bibblock"><span id="bib.bib75.4.1" class="ltx_text" style="font-size:90%;">
Yang Zhou, Xintong Han, Eli Shechtman, Jose Echevarria, Evangelos Kalogerakis,
and Dingzeyu Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib75.5.1" class="ltx_text" style="font-size:90%;">Makelttalk: speaker-aware talking-head animation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib75.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions On Graphics (TOG)</span><span id="bib.bib75.7.2" class="ltx_text" style="font-size:90%;">, 39(6):1–15, 2020.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.10666" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.10667" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.10667">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.10667" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.10668" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 15:15:25 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
