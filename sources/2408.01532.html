<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.01532] Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization</title><meta property="og:description" content="In the digital age, the emergence of deepfakes and synthetic media presents a significant threat to societal and political integrity.
Deepfakes based on multi-modal manipulation, such as audio-visual, are more realisti…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.01532">

<!--Generated on Thu Sep  5 15:07:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vinaya Sree Katamneni and Ajita Rattani
<br class="ltx_break">University of North Texas at Denton
<br class="ltx_break">Denton, Texas, USA
<br class="ltx_break"><span id="id3.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">vinayasreekatamneni@my.unt.edu; ajita.rattani@unt.edu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.2" class="ltx_p">In the digital age, the emergence of deepfakes and synthetic media presents a significant threat to societal and political integrity.
Deepfakes based on multi-modal manipulation, such as audio-visual, are more realistic and pose a greater threat.
Current multi-modal deepfake detectors are often based on the attention-based fusion of heterogeneous data streams from multiple modalities. However, the heterogeneous nature of the data (such as audio and visual signals) creates a distributional modality gap and poses a significant challenge in effective fusion and hence multi-modal deepfake detection.
In this paper, we propose a novel multi-modal attention framework based on recurrent neural networks (RNNs) that leverages contextual
information for audio-visual deepfake detection. The proposed approach applies
attention to multi-modal multi-sequence representations and learns the contributing features among them for deepfake detection and localization.
Thorough experimental validations on audio-visual deepfake datasets, namely FakeAVCeleb, AV-Deepfake1M, TVIL, and LAV-DF datasets, demonstrate the efficacy of our approach. Cross-comparison with the published studies demonstrates superior performance of our approach with an improved accuracy and precision by <math id="id1.1.m1.1" class="ltx_Math" alttext="3.47\%" display="inline"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mn id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">3.47</mn><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="latexml" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">percent</csymbol><cn type="float" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">3.47</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">3.47\%</annotation></semantics></math> and <math id="id2.2.m2.1" class="ltx_Math" alttext="2.05\%" display="inline"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mn id="id2.2.m2.1.1.2" xref="id2.2.m2.1.1.2.cmml">2.05</mn><mo id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><csymbol cd="latexml" id="id2.2.m2.1.1.1.cmml" xref="id2.2.m2.1.1.1">percent</csymbol><cn type="float" id="id2.2.m2.1.1.2.cmml" xref="id2.2.m2.1.1.2">2.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">2.05\%</annotation></semantics></math> in deepfake detection and localization, respectively. Thus, obtaining state-of-the-art performance. To facilitate reproducibility, the code and the datasets information is available at <a target="_blank" href="https://github.com/vcbsl/audio-visual-deepfake/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/vcbsl/audio-visual-deepfake/</a>.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:90%;">Keywords—</span><span id="p1.1.2" class="ltx_text" style="font-size:90%;"> Audio-visual Deepfake Detection, Contextual Cross-Attention, Deepfake Localization, Multi-modal Manipulation</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text" style="font-size:90%;">With advances in deep-generative models </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib41" title="" class="ltx_ref">41</a><span id="S1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.4" class="ltx_text" style="font-size:90%;">, synthetic audio and visual media have become so realistic that they are often indistinguishable from authentic content for human eyes. However, synthetic media generation techniques used by malicious users to deceive pose a serious social and political threat </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a><span id="S1.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.7" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text" style="font-size:90%;">In this context, visual (facial) deepfakes are generated using facial forgery techniques that depict human subjects with altered identities (i.e., face swapping), malicious actions (such as expression swapping), and facial attribute manipulation (such as skin color, gender, and age) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a><span id="S1.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.4" class="ltx_text" style="font-size:90%;">. Voice deepfakes, like facial deepfake technology, rely on advanced generative neural networks to synthesize audio that mimics the voice of a target speaker. Among them, Text-to-speech (TTS) voice deepfakes involve generating synthetic speech from text input that mimics a specific target speaker’s voice </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib51" title="" class="ltx_ref">51</a><span id="S1.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.7" class="ltx_text" style="font-size:90%;">. Voice conversion-based deepfakes involve altering a person’s voice to sound like another person while retaining the original content and linguistic style </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib54" title="" class="ltx_ref">54</a><span id="S1.p2.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.10" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text" style="font-size:90%;">Audio and visual deepfakes have been employed to attack authentication systems, impersonate celebrities and politicians, and defraud finance. As a countermeasure, several unimodal audio and visual deepfake detectors have been proposed </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a><span id="S1.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.4" class="ltx_text" style="font-size:90%;">. Lately, multi-modal deepfakes that manipulate multiple modalities, such as audio-visual, to create highly convincing and immersive fake content have shown staggering growth with advanced multimedia processing and generative AI capabilities </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib65" title="" class="ltx_ref">65</a><span id="S1.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.7" class="ltx_text" style="font-size:90%;">. These advanced multi-modal deepfake techniques leverage the strengths of different modalities to generate more realistic and impactful results.</span></p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2408.01532/assets/teaser.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of our proposed audio-visual deepfake detection and localization framework. The audio-visual sequences extracted from the input video are processed using our proposed MMMS-BA approach for deepfake detection and localization.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text" style="font-size:90%;">Existing unimodal deepfake detectors are primarily designed to detect a single type of manipulation, such as visual, acoustic, and text.
Consequently, multi-modal deepfake detectors are being investigated to detect and localize multi-modal manipulations, collectively. Within the scope of this work, several audio-visual deepfake detection and localization techniques have been proposed </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S1.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.4" class="ltx_text" style="font-size:90%;">.
Deepfake detection aims at binary classification into pristine or deepfake. Localization aims to locate the start and end timestamps of manipulated audio-visual segments, thus facilitating a better understanding of deepfake detection results. Existing audio-visual deepfake detectors are often based on the fusion of heterogeneous streams using feature concatenation and employing attention mechanism </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a><span id="S1.p4.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.7" class="ltx_text" style="font-size:90%;">.
Deepfake localization approaches are either anchor-based </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S1.p4.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.10" class="ltx_text" style="font-size:90%;"> that utilize a sliding window approach to detect deepfake segments or boundary prediction based </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p4.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S1.p4.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p4.1.13" class="ltx_text" style="font-size:90%;"> that
focuses on predicting the boundary of fake segments in a video using boundary matching loss.</span></p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text" style="font-size:90%;">The major </span><span id="S1.p5.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">limitations</span><span id="S1.p5.1.3" class="ltx_text" style="font-size:90%;"> of the current attention-based fusion approaches for audio-visual deepfake detection stem from the heterogeneous nature of audio and visual signals. Consequently, the unique capabilities of each modality (modality-specific features) are not utilized effectively in the fusion process. Furthermore, noise in one modality adversely affects the overall performance of the multi-modal framework. These methods also fail to explicitly model the interactions between different modalities, such as the relationship between audio, full face, and lip movement sequences. As a result, correlation and dependencies between modalities are not fully captured, leading to suboptimal performance in deepfake detection.
Moreover, current approaches do not incorporate contextual information which refers to consistent and meaningful patterns across sequences, both within and across modalities.
Lastly, most current fusion-based approaches focus solely on audio-visual detection without integrated mechanisms for localization. Given that deepfakes have become more content-driven generating partially fake media </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p5.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S1.p5.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p5.1.6" class="ltx_text" style="font-size:90%;">, integrated deepfake detection as well as localization is crucial.</span></p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text" style="font-size:90%;">This work </span><span id="S1.p6.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">proposes</span><span id="S1.p6.1.3" class="ltx_text" style="font-size:90%;"> a recurrent neural network-based multi-modal multi-sequence attention framework for audio-visual deepfake detection, called Multi-Modal Multi-Sequence Bi-Modal Attention (MMMS-BA). Our framework focuses on relevant features across modality pairs, leveraging attention from neighboring sequences and multi-modal representations for enhanced representation learning. Our proposed MMMS-BA performs deepfake detection as well as localization using classification and regression heads. Figure </span><a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S1.p6.1.4" class="ltx_text" style="font-size:90%;"> illustrates our proposed MMMS-BA framework for audio-visual deepfake detection and localization.</span></p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p"><span id="S1.p7.1.1" class="ltx_text" style="font-size:90%;">In summary, the </span><span id="S1.p7.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">contributions</span><span id="S1.p7.1.3" class="ltx_text" style="font-size:90%;"> of this work are as follows:</span></p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text" style="font-size:90%;">A novel approach for audio-visual deepfake detection and localization (MMMS-BA) based on contextual cross-attention mechanism utilizing multi-modal multi-sequence information.</span></p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text" style="font-size:90%;">Extensive evaluation on the publicly available audio-visual deepfake detection and localization datasets namely, AV-DeepFake1M </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.I1.i2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S1.I1.i2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.I1.i2.p1.1.4" class="ltx_text" style="font-size:90%;">, FakeAVCeleb </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.I1.i2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S1.I1.i2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.I1.i2.p1.1.7" class="ltx_text" style="font-size:90%;">, LAV-DF </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.I1.i2.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S1.I1.i2.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.I1.i2.p1.1.10" class="ltx_text" style="font-size:90%;">, and TVIL </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.I1.i2.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S1.I1.i2.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.I1.i2.p1.1.13" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text" style="font-size:90%;">Cross-comparison of MMMS-BA with the published work on audio-visual multi-modal deepfake detection and localization.</span></p>
</div>
</li>
</ol>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p"><span id="S1.p8.1.1" class="ltx_text" style="font-size:90%;">This paper is summarized as follows: Section </span><a href="#S2" title="2 Related Work ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S1.p8.1.2" class="ltx_text" style="font-size:90%;"> discusses related work on audio-visual deepfake detection and localization. The proposed approach is detailed in Section </span><a href="#S3" title="3 Methodology ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S1.p8.1.3" class="ltx_text" style="font-size:90%;">. Section </span><a href="#S4" title="4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S1.p8.1.4" class="ltx_text" style="font-size:90%;"> covers the datasets, evaluation metrics, and results. An ablation study analyzing varied modalities and attention mechanisms is presented in Section </span><a href="#S5" title="5 Ablation Study ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S1.p8.1.5" class="ltx_text" style="font-size:90%;">. Conclusion and future research directions are discussed in Section </span><a href="#S6" title="6 Conclusion and Future Work ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S1.p8.1.6" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text" style="font-size:90%;">In this section, we discuss the work related to audio-visual multi-modal deepfake detection and localization.</span></p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Audio-Visual Deepfake Detection</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Audio-visual deepfake detection techniques employ audio and visual signals to detect multi-modal manipulation. A foundational work in this area, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S2.SS1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p1.1.4" class="ltx_text" style="font-size:90%;"> assembled the FakeAVCeleb dataset consisting of audio and visual deepfakes and benchmarked various audio-visual deepfake detectors based on ensemble-based voting scheme and multi-modal convolutional neural network (CNN) based on feature concatenation.</span></p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text" style="font-size:90%;">In particular, most of the existing audio-visual deepfake detectors are based on attention mechanism-based feature concatenation </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a><span id="S2.SS1.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p2.1.4" class="ltx_text" style="font-size:90%;"> to learn informative multi-modal features for deepfake detection. Studies in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a><span id="S2.SS1.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p2.1.7" class="ltx_text" style="font-size:90%;"> used a siamese network architecture for emotion recognition from audio and visual cues incorporating contrastive loss. Deepfake videos are detected by analyzing discrepancies in emotional cues between audio and visual modalities.
Studies in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p2.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a><span id="S2.SS1.p2.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p2.1.10" class="ltx_text" style="font-size:90%;"> explicitly model the disagreement between the embeddings of the multiple modalities using contrastive loss for deepfake detection.</span></p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text" style="font-size:90%;">The work in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S2.SS1.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p3.1.4" class="ltx_text" style="font-size:90%;"> and </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S2.SS1.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p3.1.7" class="ltx_text" style="font-size:90%;"> explores the mismatch between phonemes (distinct units of sound in speech) and visemes (the visual representation of phonemes) for deepfake detection. These studies specifically focus on inconsistencies in the lip region concerning the audio which deepfake generation approaches often struggle to replicate incorrectly, thus offering a potential for deepfake detection </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p3.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a><span id="S2.SS1.p3.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS1.p3.1.10" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2408.01532/assets/CCMA.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="143" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustration of the proposed Multi-Modal Multi-Sequence Bi-modal Attention (MMMS-BA) model for audio-visual deepfake detection and localization.</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Localization of Deepfakes</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p"><span id="S2.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">Localization aims to ground the time intervals in an input where manipulation has occurred. Audio-visual deepfake localization-based approaches can be categorized into two: anchor-based </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S2.SS2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.4" class="ltx_text" style="font-size:90%;"> and those based on the prediction of boundaries of fake segments in a video </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S2.SS2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.7" class="ltx_text" style="font-size:90%;">. Anchor-based approaches make use of a sliding window over the input to ground the manipulated segments. In contrast, prediction-based approaches process the entire video and determine the fake segments using the proposed boundary-sensitive network </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S2.SS2.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p1.1.10" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">The foundational study in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S2.SS2.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p2.1.4" class="ltx_text" style="font-size:90%;"> introduced a novel method focused on detecting and localizing discrepancies between audio and visual modalities based on temporal mismatches and unnatural movements within videos.
Building on their initial work </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p2.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S2.SS2.p2.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p2.1.7" class="ltx_text" style="font-size:90%;">, the authors introduced a new dataset, Localized Audio-Visual Deepfake (LAV-DF), along with the multi-modal deepfake detection that incorporates contrastive loss function to differentiate between real and fake segments by pushing apart the feature representations of genuine and forged segments in the feature space. In addition, the loss of boundary matching precisely predicts the boundaries (start and end points) of the forged segments.</span></p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text" style="font-size:90%;">Work in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S2.SS2.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p3.1.4" class="ltx_text" style="font-size:90%;"> advances the method in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S2.SS2.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p3.1.7" class="ltx_text" style="font-size:90%;"> further by introducing a framework (named BA-TFD+) that integrates a multi-scale vision transformer with a 3D CNN architecture and trained with contrastive, frame classification, boundary matching and multi-modal boundary matching loss functions for improved precision and reliability of deepfake detection and localization.</span></p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p"><span id="S2.SS2.p4.1.1" class="ltx_text" style="font-size:90%;">Another work </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S2.SS2.p4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.SS2.p4.1.4" class="ltx_text" style="font-size:90%;"> in this direction introduces a framework named UMMAFormer, a universal, transformer-based framework adapted to audio and visual multi-modalities to detect temporal forgeries using anomaly detection based on self-attention mechanism.</span></p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Formulation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Our proposed framework aims to detect and localize deepfakes by focusing on the relationship between audio, visual and lip movement sequences by harnessing the information embedded within each modality and across their intersection.</span></p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.4" class="ltx_p"><span id="S3.SS1.p2.4.1" class="ltx_text" style="font-size:90%;">For a given video </span><math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi mathsize="90%" id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">D</annotation></semantics></math><span id="S3.SS1.p2.4.2" class="ltx_text" style="font-size:90%;"> that contains </span><math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi mathsize="90%" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">N</annotation></semantics></math><span id="S3.SS1.p2.4.3" class="ltx_text" style="font-size:90%;"> sequences, where each sequence </span><math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="d_{i}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">d</mi><mi mathsize="90%" id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝑑</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">d_{i}</annotation></semantics></math><span id="S3.SS1.p2.4.4" class="ltx_text" style="font-size:90%;"> is composed of </span><math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mn mathsize="90%" id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><cn type="integer" id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">3</annotation></semantics></math><span id="S3.SS1.p2.4.5" class="ltx_text" style="font-size:90%;"> different modalities (full visual face, lip region, and audio), the formulation can be represented as follows:</span></p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="D=\{d_{i}\}_{i=1}^{N}\quad;\quad d_{i}=\{x_{i}^{v},x_{i}^{l},x_{i}^{a}\}" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.3.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">D</mi><mo mathsize="90%" id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">=</mo><msubsup id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">{</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml">d</mi><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml">i</mi><mo mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.1.1.3.1.cmml">=</mo><mn mathsize="90%" id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">N</mi></msubsup></mrow><mo mathsize="90%" rspace="1.067em" id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.3a.cmml">;</mo><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml"><msub id="S3.E1.m1.2.2.2.2.5" xref="S3.E1.m1.2.2.2.2.5.cmml"><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.5.2" xref="S3.E1.m1.2.2.2.2.5.2.cmml">d</mi><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.5.3" xref="S3.E1.m1.2.2.2.2.5.3.cmml">i</mi></msub><mo mathsize="90%" id="S3.E1.m1.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.4.cmml">=</mo><mrow id="S3.E1.m1.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.3.4.cmml"><mo maxsize="90%" minsize="90%" id="S3.E1.m1.2.2.2.2.3.3.4" xref="S3.E1.m1.2.2.2.2.3.4.cmml">{</mo><msubsup id="S3.E1.m1.2.2.2.2.1.1.1" xref="S3.E1.m1.2.2.2.2.1.1.1.cmml"><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.1.1.1.2.2" xref="S3.E1.m1.2.2.2.2.1.1.1.2.2.cmml">x</mi><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.1.1.1.2.3" xref="S3.E1.m1.2.2.2.2.1.1.1.2.3.cmml">i</mi><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.1.1.1.3" xref="S3.E1.m1.2.2.2.2.1.1.1.3.cmml">v</mi></msubsup><mo mathsize="90%" id="S3.E1.m1.2.2.2.2.3.3.5" xref="S3.E1.m1.2.2.2.2.3.4.cmml">,</mo><msubsup id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.cmml"><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.2.cmml">x</mi><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.2.3.cmml">l</mi></msubsup><mo mathsize="90%" id="S3.E1.m1.2.2.2.2.3.3.6" xref="S3.E1.m1.2.2.2.2.3.4.cmml">,</mo><msubsup id="S3.E1.m1.2.2.2.2.3.3.3" xref="S3.E1.m1.2.2.2.2.3.3.3.cmml"><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.3.3.3.2.2" xref="S3.E1.m1.2.2.2.2.3.3.3.2.2.cmml">x</mi><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.3.3.3.2.3" xref="S3.E1.m1.2.2.2.2.3.3.3.2.3.cmml">i</mi><mi mathsize="90%" id="S3.E1.m1.2.2.2.2.3.3.3.3" xref="S3.E1.m1.2.2.2.2.3.3.3.3.cmml">a</mi></msubsup><mo maxsize="90%" minsize="90%" id="S3.E1.m1.2.2.2.2.3.3.7" xref="S3.E1.m1.2.2.2.2.3.4.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></eq><ci id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3">𝐷</ci><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1">subscript</csymbol><set id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.2">𝑑</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><eq id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.1"></eq><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3">𝑁</ci></apply></apply><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><eq id="S3.E1.m1.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.2.4"></eq><apply id="S3.E1.m1.2.2.2.2.5.cmml" xref="S3.E1.m1.2.2.2.2.5"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.5.1.cmml" xref="S3.E1.m1.2.2.2.2.5">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.5.2.cmml" xref="S3.E1.m1.2.2.2.2.5.2">𝑑</ci><ci id="S3.E1.m1.2.2.2.2.5.3.cmml" xref="S3.E1.m1.2.2.2.2.5.3">𝑖</ci></apply><set id="S3.E1.m1.2.2.2.2.3.4.cmml" xref="S3.E1.m1.2.2.2.2.3.3"><apply id="S3.E1.m1.2.2.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1">superscript</csymbol><apply id="S3.E1.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.2.2">𝑥</ci><ci id="S3.E1.m1.2.2.2.2.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.2.3">𝑖</ci></apply><ci id="S3.E1.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.2.2.1.1.1.3">𝑣</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2.2">𝑥</ci><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply><ci id="S3.E1.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3">𝑙</ci></apply><apply id="S3.E1.m1.2.2.2.2.3.3.3.cmml" xref="S3.E1.m1.2.2.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.3.3.3.1.cmml" xref="S3.E1.m1.2.2.2.2.3.3.3">superscript</csymbol><apply id="S3.E1.m1.2.2.2.2.3.3.3.2.cmml" xref="S3.E1.m1.2.2.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.3.3.3.2.1.cmml" xref="S3.E1.m1.2.2.2.2.3.3.3">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.3.3.3.2.2.cmml" xref="S3.E1.m1.2.2.2.2.3.3.3.2.2">𝑥</ci><ci id="S3.E1.m1.2.2.2.2.3.3.3.2.3.cmml" xref="S3.E1.m1.2.2.2.2.3.3.3.2.3">𝑖</ci></apply><ci id="S3.E1.m1.2.2.2.2.3.3.3.3.cmml" xref="S3.E1.m1.2.2.2.2.3.3.3.3">𝑎</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">D=\{d_{i}\}_{i=1}^{N}\quad;\quad d_{i}=\{x_{i}^{v},x_{i}^{l},x_{i}^{a}\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.3" class="ltx_p"><span id="S3.SS1.p3.3.1" class="ltx_text" style="font-size:90%;">Here, each sequence </span><math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="d_{i}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">d</mi><mi mathsize="90%" id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">𝑑</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">d_{i}</annotation></semantics></math><span id="S3.SS1.p3.3.2" class="ltx_text" style="font-size:90%;"> consists of three modalities represented by </span><math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="x_{i}^{m}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msubsup id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p3.2.m2.1.1.2.2" xref="S3.SS1.p3.2.m2.1.1.2.2.cmml">x</mi><mi mathsize="90%" id="S3.SS1.p3.2.m2.1.1.2.3" xref="S3.SS1.p3.2.m2.1.1.2.3.cmml">i</mi><mi mathsize="90%" id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">m</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2.2">𝑥</ci><ci id="S3.SS1.p3.2.m2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">x_{i}^{m}</annotation></semantics></math><span id="S3.SS1.p3.3.3" class="ltx_text" style="font-size:90%;"> for </span><math id="S3.SS1.p3.3.m3.3" class="ltx_Math" alttext="m\in\{v,l,a\}" display="inline"><semantics id="S3.SS1.p3.3.m3.3a"><mrow id="S3.SS1.p3.3.m3.3.4" xref="S3.SS1.p3.3.m3.3.4.cmml"><mi mathsize="90%" id="S3.SS1.p3.3.m3.3.4.2" xref="S3.SS1.p3.3.m3.3.4.2.cmml">m</mi><mo mathsize="90%" id="S3.SS1.p3.3.m3.3.4.1" xref="S3.SS1.p3.3.m3.3.4.1.cmml">∈</mo><mrow id="S3.SS1.p3.3.m3.3.4.3.2" xref="S3.SS1.p3.3.m3.3.4.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS1.p3.3.m3.3.4.3.2.1" xref="S3.SS1.p3.3.m3.3.4.3.1.cmml">{</mo><mi mathsize="90%" id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">v</mi><mo mathsize="90%" id="S3.SS1.p3.3.m3.3.4.3.2.2" xref="S3.SS1.p3.3.m3.3.4.3.1.cmml">,</mo><mi mathsize="90%" id="S3.SS1.p3.3.m3.2.2" xref="S3.SS1.p3.3.m3.2.2.cmml">l</mi><mo mathsize="90%" id="S3.SS1.p3.3.m3.3.4.3.2.3" xref="S3.SS1.p3.3.m3.3.4.3.1.cmml">,</mo><mi mathsize="90%" id="S3.SS1.p3.3.m3.3.3" xref="S3.SS1.p3.3.m3.3.3.cmml">a</mi><mo maxsize="90%" minsize="90%" id="S3.SS1.p3.3.m3.3.4.3.2.4" xref="S3.SS1.p3.3.m3.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.3b"><apply id="S3.SS1.p3.3.m3.3.4.cmml" xref="S3.SS1.p3.3.m3.3.4"><in id="S3.SS1.p3.3.m3.3.4.1.cmml" xref="S3.SS1.p3.3.m3.3.4.1"></in><ci id="S3.SS1.p3.3.m3.3.4.2.cmml" xref="S3.SS1.p3.3.m3.3.4.2">𝑚</ci><set id="S3.SS1.p3.3.m3.3.4.3.1.cmml" xref="S3.SS1.p3.3.m3.3.4.3.2"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">𝑣</ci><ci id="S3.SS1.p3.3.m3.2.2.cmml" xref="S3.SS1.p3.3.m3.2.2">𝑙</ci><ci id="S3.SS1.p3.3.m3.3.3.cmml" xref="S3.SS1.p3.3.m3.3.3">𝑎</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.3c">m\in\{v,l,a\}</annotation></semantics></math><span id="S3.SS1.p3.3.4" class="ltx_text" style="font-size:90%;"> for the full visual face, lip region, and audio modality.</span></p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.3" class="ltx_p"><span id="S3.SS1.p4.3.1" class="ltx_text" style="font-size:90%;">The classification head detects the modified sequences and the regression head is employed to localize fake segments. For the video </span><math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mi mathsize="90%" id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">D</annotation></semantics></math><span id="S3.SS1.p4.3.2" class="ltx_text" style="font-size:90%;"> with </span><math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mi mathsize="90%" id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">N</annotation></semantics></math><span id="S3.SS1.p4.3.3" class="ltx_text" style="font-size:90%;"> sequences, the entire video </span><math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mi mathsize="90%" id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">D</annotation></semantics></math><span id="S3.SS1.p4.3.4" class="ltx_text" style="font-size:90%;"> is classified as fake if at least one sequence is classified as fake.</span></p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.8" class="ltx_p"><span id="S3.SS1.p5.8.1" class="ltx_text" style="font-size:90%;">The localization of the segments is represented as </span><math id="S3.SS1.p5.1.m1.4" class="ltx_Math" alttext="Y=\{y_{1},y_{2},...,y_{N_{f}}\}" display="inline"><semantics id="S3.SS1.p5.1.m1.4a"><mrow id="S3.SS1.p5.1.m1.4.4" xref="S3.SS1.p5.1.m1.4.4.cmml"><mi mathsize="90%" id="S3.SS1.p5.1.m1.4.4.5" xref="S3.SS1.p5.1.m1.4.4.5.cmml">Y</mi><mo mathsize="90%" id="S3.SS1.p5.1.m1.4.4.4" xref="S3.SS1.p5.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS1.p5.1.m1.4.4.3.3" xref="S3.SS1.p5.1.m1.4.4.3.4.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS1.p5.1.m1.4.4.3.3.4" xref="S3.SS1.p5.1.m1.4.4.3.4.cmml">{</mo><msub id="S3.SS1.p5.1.m1.2.2.1.1.1" xref="S3.SS1.p5.1.m1.2.2.1.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p5.1.m1.2.2.1.1.1.2" xref="S3.SS1.p5.1.m1.2.2.1.1.1.2.cmml">y</mi><mn mathsize="90%" id="S3.SS1.p5.1.m1.2.2.1.1.1.3" xref="S3.SS1.p5.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.SS1.p5.1.m1.4.4.3.3.5" xref="S3.SS1.p5.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS1.p5.1.m1.3.3.2.2.2" xref="S3.SS1.p5.1.m1.3.3.2.2.2.cmml"><mi mathsize="90%" id="S3.SS1.p5.1.m1.3.3.2.2.2.2" xref="S3.SS1.p5.1.m1.3.3.2.2.2.2.cmml">y</mi><mn mathsize="90%" id="S3.SS1.p5.1.m1.3.3.2.2.2.3" xref="S3.SS1.p5.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo mathsize="90%" id="S3.SS1.p5.1.m1.4.4.3.3.6" xref="S3.SS1.p5.1.m1.4.4.3.4.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">…</mi><mo mathsize="90%" id="S3.SS1.p5.1.m1.4.4.3.3.7" xref="S3.SS1.p5.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS1.p5.1.m1.4.4.3.3.3" xref="S3.SS1.p5.1.m1.4.4.3.3.3.cmml"><mi mathsize="90%" id="S3.SS1.p5.1.m1.4.4.3.3.3.2" xref="S3.SS1.p5.1.m1.4.4.3.3.3.2.cmml">y</mi><msub id="S3.SS1.p5.1.m1.4.4.3.3.3.3" xref="S3.SS1.p5.1.m1.4.4.3.3.3.3.cmml"><mi mathsize="90%" id="S3.SS1.p5.1.m1.4.4.3.3.3.3.2" xref="S3.SS1.p5.1.m1.4.4.3.3.3.3.2.cmml">N</mi><mi mathsize="90%" id="S3.SS1.p5.1.m1.4.4.3.3.3.3.3" xref="S3.SS1.p5.1.m1.4.4.3.3.3.3.3.cmml">f</mi></msub></msub><mo maxsize="90%" minsize="90%" id="S3.SS1.p5.1.m1.4.4.3.3.8" xref="S3.SS1.p5.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.4b"><apply id="S3.SS1.p5.1.m1.4.4.cmml" xref="S3.SS1.p5.1.m1.4.4"><eq id="S3.SS1.p5.1.m1.4.4.4.cmml" xref="S3.SS1.p5.1.m1.4.4.4"></eq><ci id="S3.SS1.p5.1.m1.4.4.5.cmml" xref="S3.SS1.p5.1.m1.4.4.5">𝑌</ci><set id="S3.SS1.p5.1.m1.4.4.3.4.cmml" xref="S3.SS1.p5.1.m1.4.4.3.3"><apply id="S3.SS1.p5.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p5.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p5.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.2.2.1.1.1.2">𝑦</ci><cn type="integer" id="S3.SS1.p5.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.p5.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p5.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p5.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p5.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p5.1.m1.3.3.2.2.2.2">𝑦</ci><cn type="integer" id="S3.SS1.p5.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS1.p5.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">…</ci><apply id="S3.SS1.p5.1.m1.4.4.3.3.3.cmml" xref="S3.SS1.p5.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS1.p5.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS1.p5.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS1.p5.1.m1.4.4.3.3.3.2">𝑦</ci><apply id="S3.SS1.p5.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS1.p5.1.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.4.4.3.3.3.3.1.cmml" xref="S3.SS1.p5.1.m1.4.4.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p5.1.m1.4.4.3.3.3.3.2.cmml" xref="S3.SS1.p5.1.m1.4.4.3.3.3.3.2">𝑁</ci><ci id="S3.SS1.p5.1.m1.4.4.3.3.3.3.3.cmml" xref="S3.SS1.p5.1.m1.4.4.3.3.3.3.3">𝑓</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.4c">Y=\{y_{1},y_{2},...,y_{N_{f}}\}</annotation></semantics></math><span id="S3.SS1.p5.8.2" class="ltx_text" style="font-size:90%;"> where </span><math id="S3.SS1.p5.2.m2.1" class="ltx_Math" alttext="N_{f}" display="inline"><semantics id="S3.SS1.p5.2.m2.1a"><msub id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p5.2.m2.1.1.2" xref="S3.SS1.p5.2.m2.1.1.2.cmml">N</mi><mi mathsize="90%" id="S3.SS1.p5.2.m2.1.1.3" xref="S3.SS1.p5.2.m2.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><apply id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p5.2.m2.1.1.2.cmml" xref="S3.SS1.p5.2.m2.1.1.2">𝑁</ci><ci id="S3.SS1.p5.2.m2.1.1.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">N_{f}</annotation></semantics></math><span id="S3.SS1.p5.8.3" class="ltx_text" style="font-size:90%;"> are the number of fake segments. For a fake sequence </span><math id="S3.SS1.p5.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p5.3.m3.1a"><mi mathsize="90%" id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><ci id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">i</annotation></semantics></math><span id="S3.SS1.p5.8.4" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS1.p5.4.m4.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S3.SS1.p5.4.m4.1a"><msub id="S3.SS1.p5.4.m4.1.1" xref="S3.SS1.p5.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p5.4.m4.1.1.2" xref="S3.SS1.p5.4.m4.1.1.2.cmml">y</mi><mi mathsize="90%" id="S3.SS1.p5.4.m4.1.1.3" xref="S3.SS1.p5.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m4.1b"><apply id="S3.SS1.p5.4.m4.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.4.m4.1.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p5.4.m4.1.1.2.cmml" xref="S3.SS1.p5.4.m4.1.1.2">𝑦</ci><ci id="S3.SS1.p5.4.m4.1.1.3.cmml" xref="S3.SS1.p5.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m4.1c">y_{i}</annotation></semantics></math><span id="S3.SS1.p5.8.5" class="ltx_text" style="font-size:90%;"> represents the </span><math id="S3.SS1.p5.5.m5.1" class="ltx_Math" alttext="i^{th}" display="inline"><semantics id="S3.SS1.p5.5.m5.1a"><msup id="S3.SS1.p5.5.m5.1.1" xref="S3.SS1.p5.5.m5.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p5.5.m5.1.1.2" xref="S3.SS1.p5.5.m5.1.1.2.cmml">i</mi><mrow id="S3.SS1.p5.5.m5.1.1.3" xref="S3.SS1.p5.5.m5.1.1.3.cmml"><mi mathsize="90%" id="S3.SS1.p5.5.m5.1.1.3.2" xref="S3.SS1.p5.5.m5.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.5.m5.1.1.3.1" xref="S3.SS1.p5.5.m5.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS1.p5.5.m5.1.1.3.3" xref="S3.SS1.p5.5.m5.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.5.m5.1b"><apply id="S3.SS1.p5.5.m5.1.1.cmml" xref="S3.SS1.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.5.m5.1.1.1.cmml" xref="S3.SS1.p5.5.m5.1.1">superscript</csymbol><ci id="S3.SS1.p5.5.m5.1.1.2.cmml" xref="S3.SS1.p5.5.m5.1.1.2">𝑖</ci><apply id="S3.SS1.p5.5.m5.1.1.3.cmml" xref="S3.SS1.p5.5.m5.1.1.3"><times id="S3.SS1.p5.5.m5.1.1.3.1.cmml" xref="S3.SS1.p5.5.m5.1.1.3.1"></times><ci id="S3.SS1.p5.5.m5.1.1.3.2.cmml" xref="S3.SS1.p5.5.m5.1.1.3.2">𝑡</ci><ci id="S3.SS1.p5.5.m5.1.1.3.3.cmml" xref="S3.SS1.p5.5.m5.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.5.m5.1c">i^{th}</annotation></semantics></math><span id="S3.SS1.p5.8.6" class="ltx_text" style="font-size:90%;"> sequence output. Each instance </span><math id="S3.SS1.p5.6.m6.2" class="ltx_Math" alttext="y_{i}=(s_{i},e_{i})" display="inline"><semantics id="S3.SS1.p5.6.m6.2a"><mrow id="S3.SS1.p5.6.m6.2.2" xref="S3.SS1.p5.6.m6.2.2.cmml"><msub id="S3.SS1.p5.6.m6.2.2.4" xref="S3.SS1.p5.6.m6.2.2.4.cmml"><mi mathsize="90%" id="S3.SS1.p5.6.m6.2.2.4.2" xref="S3.SS1.p5.6.m6.2.2.4.2.cmml">y</mi><mi mathsize="90%" id="S3.SS1.p5.6.m6.2.2.4.3" xref="S3.SS1.p5.6.m6.2.2.4.3.cmml">i</mi></msub><mo mathsize="90%" id="S3.SS1.p5.6.m6.2.2.3" xref="S3.SS1.p5.6.m6.2.2.3.cmml">=</mo><mrow id="S3.SS1.p5.6.m6.2.2.2.2" xref="S3.SS1.p5.6.m6.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS1.p5.6.m6.2.2.2.2.3" xref="S3.SS1.p5.6.m6.2.2.2.3.cmml">(</mo><msub id="S3.SS1.p5.6.m6.1.1.1.1.1" xref="S3.SS1.p5.6.m6.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p5.6.m6.1.1.1.1.1.2" xref="S3.SS1.p5.6.m6.1.1.1.1.1.2.cmml">s</mi><mi mathsize="90%" id="S3.SS1.p5.6.m6.1.1.1.1.1.3" xref="S3.SS1.p5.6.m6.1.1.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="S3.SS1.p5.6.m6.2.2.2.2.4" xref="S3.SS1.p5.6.m6.2.2.2.3.cmml">,</mo><msub id="S3.SS1.p5.6.m6.2.2.2.2.2" xref="S3.SS1.p5.6.m6.2.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS1.p5.6.m6.2.2.2.2.2.2" xref="S3.SS1.p5.6.m6.2.2.2.2.2.2.cmml">e</mi><mi mathsize="90%" id="S3.SS1.p5.6.m6.2.2.2.2.2.3" xref="S3.SS1.p5.6.m6.2.2.2.2.2.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="S3.SS1.p5.6.m6.2.2.2.2.5" xref="S3.SS1.p5.6.m6.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.6.m6.2b"><apply id="S3.SS1.p5.6.m6.2.2.cmml" xref="S3.SS1.p5.6.m6.2.2"><eq id="S3.SS1.p5.6.m6.2.2.3.cmml" xref="S3.SS1.p5.6.m6.2.2.3"></eq><apply id="S3.SS1.p5.6.m6.2.2.4.cmml" xref="S3.SS1.p5.6.m6.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p5.6.m6.2.2.4.1.cmml" xref="S3.SS1.p5.6.m6.2.2.4">subscript</csymbol><ci id="S3.SS1.p5.6.m6.2.2.4.2.cmml" xref="S3.SS1.p5.6.m6.2.2.4.2">𝑦</ci><ci id="S3.SS1.p5.6.m6.2.2.4.3.cmml" xref="S3.SS1.p5.6.m6.2.2.4.3">𝑖</ci></apply><interval closure="open" id="S3.SS1.p5.6.m6.2.2.2.3.cmml" xref="S3.SS1.p5.6.m6.2.2.2.2"><apply id="S3.SS1.p5.6.m6.1.1.1.1.1.cmml" xref="S3.SS1.p5.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p5.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS1.p5.6.m6.1.1.1.1.1.2">𝑠</ci><ci id="S3.SS1.p5.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS1.p5.6.m6.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS1.p5.6.m6.2.2.2.2.2.cmml" xref="S3.SS1.p5.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p5.6.m6.2.2.2.2.2.1.cmml" xref="S3.SS1.p5.6.m6.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p5.6.m6.2.2.2.2.2.2.cmml" xref="S3.SS1.p5.6.m6.2.2.2.2.2.2">𝑒</ci><ci id="S3.SS1.p5.6.m6.2.2.2.2.2.3.cmml" xref="S3.SS1.p5.6.m6.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.6.m6.2c">y_{i}=(s_{i},e_{i})</annotation></semantics></math><span id="S3.SS1.p5.8.7" class="ltx_text" style="font-size:90%;"> is defined by its starting time </span><math id="S3.SS1.p5.7.m7.1" class="ltx_Math" alttext="s_{i}" display="inline"><semantics id="S3.SS1.p5.7.m7.1a"><msub id="S3.SS1.p5.7.m7.1.1" xref="S3.SS1.p5.7.m7.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p5.7.m7.1.1.2" xref="S3.SS1.p5.7.m7.1.1.2.cmml">s</mi><mi mathsize="90%" id="S3.SS1.p5.7.m7.1.1.3" xref="S3.SS1.p5.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.7.m7.1b"><apply id="S3.SS1.p5.7.m7.1.1.cmml" xref="S3.SS1.p5.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.7.m7.1.1.1.cmml" xref="S3.SS1.p5.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p5.7.m7.1.1.2.cmml" xref="S3.SS1.p5.7.m7.1.1.2">𝑠</ci><ci id="S3.SS1.p5.7.m7.1.1.3.cmml" xref="S3.SS1.p5.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.7.m7.1c">s_{i}</annotation></semantics></math><span id="S3.SS1.p5.8.8" class="ltx_text" style="font-size:90%;"> and ending time </span><math id="S3.SS1.p5.8.m8.1" class="ltx_Math" alttext="e_{i}" display="inline"><semantics id="S3.SS1.p5.8.m8.1a"><msub id="S3.SS1.p5.8.m8.1.1" xref="S3.SS1.p5.8.m8.1.1.cmml"><mi mathsize="90%" id="S3.SS1.p5.8.m8.1.1.2" xref="S3.SS1.p5.8.m8.1.1.2.cmml">e</mi><mi mathsize="90%" id="S3.SS1.p5.8.m8.1.1.3" xref="S3.SS1.p5.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.8.m8.1b"><apply id="S3.SS1.p5.8.m8.1.1.cmml" xref="S3.SS1.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.8.m8.1.1.1.cmml" xref="S3.SS1.p5.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p5.8.m8.1.1.2.cmml" xref="S3.SS1.p5.8.m8.1.1.2">𝑒</ci><ci id="S3.SS1.p5.8.m8.1.1.3.cmml" xref="S3.SS1.p5.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.8.m8.1c">e_{i}</annotation></semantics></math><span id="S3.SS1.p5.8.9" class="ltx_text" style="font-size:90%;"> of the sequence. Figure </span><a href="#S2.F2" title="Figure 2 ‣ 2.1 Audio-Visual Deepfake Detection ‣ 2 Related Work ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S3.SS1.p5.8.10" class="ltx_text" style="font-size:90%;"> illustrates the step-by-step process involved in our MMMS-BA which includes feature extraction and processing (as described below), and classification and regression heads for deepfake detection and localization. The following sub-sections provide details on each of these steps.</span></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Multi-modal Multi-sequence - Bi-modal Attention (MMMS-BA) Framework</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">Sequences in a video represent the time series information and the classification of a sequence would have a relation with the other sequences. To model the relationship with the neighboring sequences and multiple modalities, we propose a recurrent neural network-based multi-modal attention framework named Multi-Modal Multi-Sequence Bi-modal Attention (MMMS-BA). Figure </span><a href="#S2.F2" title="Figure 2 ‣ 2.1 Audio-Visual Deepfake Detection ‣ 2 Related Work ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S3.SS2.p1.1.2" class="ltx_text" style="font-size:90%;"> shows the steps involved in applying the attention mechanism to the input sequences.</span></p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.13" class="ltx_p"><span id="S3.SS2.p2.13.1" class="ltx_text" style="font-size:90%;">The MMMS-BA framework processes and analyzes multi-modal data across sequences in an input video. Assuming a particular video has </span><math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi mathsize="90%" id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">N</annotation></semantics></math><span id="S3.SS2.p2.13.2" class="ltx_text" style="font-size:90%;"> sequences, the raw sequence levels are represented as </span><math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="x_{i}^{v}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><msubsup id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.2.m2.1.1.2.2" xref="S3.SS2.p2.2.m2.1.1.2.2.cmml">x</mi><mi mathsize="90%" id="S3.SS2.p2.2.m2.1.1.2.3" xref="S3.SS2.p2.2.m2.1.1.2.3.cmml">i</mi><mi mathsize="90%" id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">v</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.2.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2.2">𝑥</ci><ci id="S3.SS2.p2.2.m2.1.1.2.3.cmml" xref="S3.SS2.p2.2.m2.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">x_{i}^{v}</annotation></semantics></math><span id="S3.SS2.p2.13.3" class="ltx_text" style="font-size:90%;"> for the full visual face, </span><math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="x_{i}^{a}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><msubsup id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.3.m3.1.1.2.2" xref="S3.SS2.p2.3.m3.1.1.2.2.cmml">x</mi><mi mathsize="90%" id="S3.SS2.p2.3.m3.1.1.2.3" xref="S3.SS2.p2.3.m3.1.1.2.3.cmml">i</mi><mi mathsize="90%" id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">superscript</csymbol><apply id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.2.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2.2">𝑥</ci><ci id="S3.SS2.p2.3.m3.1.1.2.3.cmml" xref="S3.SS2.p2.3.m3.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">x_{i}^{a}</annotation></semantics></math><span id="S3.SS2.p2.13.4" class="ltx_text" style="font-size:90%;"> for the audio and </span><math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="x_{i}^{l}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><msubsup id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.4.m4.1.1.2.2" xref="S3.SS2.p2.4.m4.1.1.2.2.cmml">x</mi><mi mathsize="90%" id="S3.SS2.p2.4.m4.1.1.2.3" xref="S3.SS2.p2.4.m4.1.1.2.3.cmml">i</mi><mi mathsize="90%" id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">superscript</csymbol><apply id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.2.1.cmml" xref="S3.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2.2">𝑥</ci><ci id="S3.SS2.p2.4.m4.1.1.2.3.cmml" xref="S3.SS2.p2.4.m4.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">x_{i}^{l}</annotation></semantics></math><span id="S3.SS2.p2.13.5" class="ltx_text" style="font-size:90%;"> for the lip sequence from equation  </span><a href="#S3.E1" title="In 3.1 Problem Formulation ‣ 3 Methodology ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S3.SS2.p2.13.6" class="ltx_text" style="font-size:90%;">.
Three separate Bi-GRU layers with forward and backward state concatenation are first applied to the full visual face </span><math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="x_{i}^{v}" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><msubsup id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.5.m5.1.1.2.2" xref="S3.SS2.p2.5.m5.1.1.2.2.cmml">x</mi><mi mathsize="90%" id="S3.SS2.p2.5.m5.1.1.2.3" xref="S3.SS2.p2.5.m5.1.1.2.3.cmml">i</mi><mi mathsize="90%" id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml">v</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">superscript</csymbol><apply id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.2.1.cmml" xref="S3.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2.2">𝑥</ci><ci id="S3.SS2.p2.5.m5.1.1.2.3.cmml" xref="S3.SS2.p2.5.m5.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">x_{i}^{v}</annotation></semantics></math><span id="S3.SS2.p2.13.7" class="ltx_text" style="font-size:90%;">, audio </span><math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="x_{i}^{a}" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><msubsup id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.6.m6.1.1.2.2" xref="S3.SS2.p2.6.m6.1.1.2.2.cmml">x</mi><mi mathsize="90%" id="S3.SS2.p2.6.m6.1.1.2.3" xref="S3.SS2.p2.6.m6.1.1.2.3.cmml">i</mi><mi mathsize="90%" id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml">a</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">superscript</csymbol><apply id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.2.1.cmml" xref="S3.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.2.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2.2">𝑥</ci><ci id="S3.SS2.p2.6.m6.1.1.2.3.cmml" xref="S3.SS2.p2.6.m6.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">x_{i}^{a}</annotation></semantics></math><span id="S3.SS2.p2.13.8" class="ltx_text" style="font-size:90%;">, and lip sequence </span><math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="x_{i}^{l}" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><msubsup id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><mi mathsize="90%" id="S3.SS2.p2.7.m7.1.1.2.2" xref="S3.SS2.p2.7.m7.1.1.2.2.cmml">x</mi><mi mathsize="90%" id="S3.SS2.p2.7.m7.1.1.2.3" xref="S3.SS2.p2.7.m7.1.1.2.3.cmml">i</mi><mi mathsize="90%" id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">superscript</csymbol><apply id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.2.1.cmml" xref="S3.SS2.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.2.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2.2">𝑥</ci><ci id="S3.SS2.p2.7.m7.1.1.2.3.cmml" xref="S3.SS2.p2.7.m7.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">x_{i}^{l}</annotation></semantics></math><span id="S3.SS2.p2.13.9" class="ltx_text" style="font-size:90%;"> representations followed by the fully connected dense layers, resulting in </span><math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><mi mathsize="90%" id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><ci id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">L</annotation></semantics></math><span id="S3.SS2.p2.13.10" class="ltx_text" style="font-size:90%;"> (lip region), </span><math id="S3.SS2.p2.9.m9.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.p2.9.m9.1a"><mi mathsize="90%" id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><ci id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">V</annotation></semantics></math><span id="S3.SS2.p2.13.11" class="ltx_text" style="font-size:90%;"> (full visual face), and </span><math id="S3.SS2.p2.10.m10.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.p2.10.m10.1a"><mi mathsize="90%" id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><ci id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">A</annotation></semantics></math><span id="S3.SS2.p2.13.12" class="ltx_text" style="font-size:90%;"> (audio) embeddings. Finally, pairwise attentions are computed on various bi-modal combinations of three modalities - </span><math id="S3.SS2.p2.11.m11.2" class="ltx_Math" alttext="(V,L)" display="inline"><semantics id="S3.SS2.p2.11.m11.2a"><mrow id="S3.SS2.p2.11.m11.2.3.2" xref="S3.SS2.p2.11.m11.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.11.m11.2.3.2.1" xref="S3.SS2.p2.11.m11.2.3.1.cmml">(</mo><mi mathsize="90%" id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml">V</mi><mo mathsize="90%" id="S3.SS2.p2.11.m11.2.3.2.2" xref="S3.SS2.p2.11.m11.2.3.1.cmml">,</mo><mi mathsize="90%" id="S3.SS2.p2.11.m11.2.2" xref="S3.SS2.p2.11.m11.2.2.cmml">L</mi><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.11.m11.2.3.2.3" xref="S3.SS2.p2.11.m11.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.2b"><interval closure="open" id="S3.SS2.p2.11.m11.2.3.1.cmml" xref="S3.SS2.p2.11.m11.2.3.2"><ci id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1">𝑉</ci><ci id="S3.SS2.p2.11.m11.2.2.cmml" xref="S3.SS2.p2.11.m11.2.2">𝐿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.2c">(V,L)</annotation></semantics></math><span id="S3.SS2.p2.13.13" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS2.p2.12.m12.2" class="ltx_Math" alttext="(L,A)" display="inline"><semantics id="S3.SS2.p2.12.m12.2a"><mrow id="S3.SS2.p2.12.m12.2.3.2" xref="S3.SS2.p2.12.m12.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.12.m12.2.3.2.1" xref="S3.SS2.p2.12.m12.2.3.1.cmml">(</mo><mi mathsize="90%" id="S3.SS2.p2.12.m12.1.1" xref="S3.SS2.p2.12.m12.1.1.cmml">L</mi><mo mathsize="90%" id="S3.SS2.p2.12.m12.2.3.2.2" xref="S3.SS2.p2.12.m12.2.3.1.cmml">,</mo><mi mathsize="90%" id="S3.SS2.p2.12.m12.2.2" xref="S3.SS2.p2.12.m12.2.2.cmml">A</mi><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.12.m12.2.3.2.3" xref="S3.SS2.p2.12.m12.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.12.m12.2b"><interval closure="open" id="S3.SS2.p2.12.m12.2.3.1.cmml" xref="S3.SS2.p2.12.m12.2.3.2"><ci id="S3.SS2.p2.12.m12.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1">𝐿</ci><ci id="S3.SS2.p2.12.m12.2.2.cmml" xref="S3.SS2.p2.12.m12.2.2">𝐴</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.12.m12.2c">(L,A)</annotation></semantics></math><span id="S3.SS2.p2.13.14" class="ltx_text" style="font-size:90%;"> &amp; </span><math id="S3.SS2.p2.13.m13.2" class="ltx_Math" alttext="(A,V)" display="inline"><semantics id="S3.SS2.p2.13.m13.2a"><mrow id="S3.SS2.p2.13.m13.2.3.2" xref="S3.SS2.p2.13.m13.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.13.m13.2.3.2.1" xref="S3.SS2.p2.13.m13.2.3.1.cmml">(</mo><mi mathsize="90%" id="S3.SS2.p2.13.m13.1.1" xref="S3.SS2.p2.13.m13.1.1.cmml">A</mi><mo mathsize="90%" id="S3.SS2.p2.13.m13.2.3.2.2" xref="S3.SS2.p2.13.m13.2.3.1.cmml">,</mo><mi mathsize="90%" id="S3.SS2.p2.13.m13.2.2" xref="S3.SS2.p2.13.m13.2.2.cmml">V</mi><mo maxsize="90%" minsize="90%" id="S3.SS2.p2.13.m13.2.3.2.3" xref="S3.SS2.p2.13.m13.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.13.m13.2b"><interval closure="open" id="S3.SS2.p2.13.m13.2.3.1.cmml" xref="S3.SS2.p2.13.m13.2.3.2"><ci id="S3.SS2.p2.13.m13.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1">𝐴</ci><ci id="S3.SS2.p2.13.m13.2.2.cmml" xref="S3.SS2.p2.13.m13.2.2">𝑉</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.13.m13.2c">(A,V)</annotation></semantics></math><span id="S3.SS2.p2.13.15" class="ltx_text" style="font-size:90%;"> as explained in the section </span><a href="#S3.SS2.SSS1" title="3.2.1 Bi-modal Attention ‣ 3.2 Multi-modal Multi-sequence - Bi-modal Attention (MMMS-BA) Framework ‣ 3 Methodology ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3.2.1</span></a><span id="S3.SS2.p2.13.16" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Bi-modal Attention</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.5" class="ltx_p"><span id="S3.SS2.SSS1.p1.5.1" class="ltx_text" style="font-size:90%;">Modality representations of </span><math id="S3.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><mi mathsize="90%" id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><ci id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">V</annotation></semantics></math><span id="S3.SS2.SSS1.p1.5.2" class="ltx_text" style="font-size:90%;"> &amp; </span><math id="S3.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><mi mathsize="90%" id="S3.SS2.SSS1.p1.2.m2.1.1" xref="S3.SS2.SSS1.p1.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.2.m2.1b"><ci id="S3.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.1c">L</annotation></semantics></math><span id="S3.SS2.SSS1.p1.5.3" class="ltx_text" style="font-size:90%;"> are obtained from the Bi-GRU network and hence contain the contextual information of the sequences for each modality. Figure </span><math id="S3.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS2.SSS1.p1.3.m3.1a"><mn mathsize="90%" id="S3.SS2.SSS1.p1.3.m3.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.3.m3.1b"><cn type="integer" id="S3.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.3.m3.1c">1</annotation></semantics></math><span id="S3.SS2.SSS1.p1.5.4" class="ltx_text" style="font-size:90%;"> in the Appendix provides additional details on the computation of bi-modal attention for each modality pair. At first, we compute a pair of matching matrices </span><math id="S3.SS2.SSS1.p1.4.m4.1" class="ltx_Math" alttext="M1" display="inline"><semantics id="S3.SS2.SSS1.p1.4.m4.1a"><mrow id="S3.SS2.SSS1.p1.4.m4.1.1" xref="S3.SS2.SSS1.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS1.p1.4.m4.1.1.2" xref="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p1.4.m4.1.1.1" xref="S3.SS2.SSS1.p1.4.m4.1.1.1.cmml">​</mo><mn mathsize="90%" id="S3.SS2.SSS1.p1.4.m4.1.1.3" xref="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.4.m4.1b"><apply id="S3.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1"><times id="S3.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.1"></times><ci id="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.2">𝑀</ci><cn type="integer" id="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.4.m4.1c">M1</annotation></semantics></math><span id="S3.SS2.SSS1.p1.5.5" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS2.SSS1.p1.5.m5.1" class="ltx_Math" alttext="M2" display="inline"><semantics id="S3.SS2.SSS1.p1.5.m5.1a"><mrow id="S3.SS2.SSS1.p1.5.m5.1.1" xref="S3.SS2.SSS1.p1.5.m5.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS1.p1.5.m5.1.1.2" xref="S3.SS2.SSS1.p1.5.m5.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p1.5.m5.1.1.1" xref="S3.SS2.SSS1.p1.5.m5.1.1.1.cmml">​</mo><mn mathsize="90%" id="S3.SS2.SSS1.p1.5.m5.1.1.3" xref="S3.SS2.SSS1.p1.5.m5.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.5.m5.1b"><apply id="S3.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1"><times id="S3.SS2.SSS1.p1.5.m5.1.1.1.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1.1"></times><ci id="S3.SS2.SSS1.p1.5.m5.1.1.2.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1.2">𝑀</ci><cn type="integer" id="S3.SS2.SSS1.p1.5.m5.1.1.3.cmml" xref="S3.SS2.SSS1.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.5.m5.1c">M2</annotation></semantics></math><span id="S3.SS2.SSS1.p1.5.6" class="ltx_text" style="font-size:90%;"> over two representations that account for the cross-modality information.</span></p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="M_{1}=V\cdot L^{T}\quad\text{and}\quad M_{2}=L\cdot V^{T}" display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><msub id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.2.2" xref="S3.E2.m1.1.1.2.2.cmml">M</mi><mn mathsize="90%" id="S3.E2.m1.1.1.2.3" xref="S3.E2.m1.1.1.2.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.1.1.4" xref="S3.E2.m1.1.1.4.cmml"><mrow id="S3.E2.m1.1.1.4.2" xref="S3.E2.m1.1.1.4.2.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.4.2.2" xref="S3.E2.m1.1.1.4.2.2.cmml">V</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.E2.m1.1.1.4.2.1" xref="S3.E2.m1.1.1.4.2.1.cmml">⋅</mo><msup id="S3.E2.m1.1.1.4.2.3" xref="S3.E2.m1.1.1.4.2.3.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.4.2.3.2" xref="S3.E2.m1.1.1.4.2.3.2.cmml">L</mi><mi mathsize="90%" id="S3.E2.m1.1.1.4.2.3.3" xref="S3.E2.m1.1.1.4.2.3.3.cmml">T</mi></msup></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.4.1" xref="S3.E2.m1.1.1.4.1.cmml">​</mo><mtext mathsize="90%" id="S3.E2.m1.1.1.4.3" xref="S3.E2.m1.1.1.4.3a.cmml">and</mtext><mo lspace="0.900em" rspace="0em" id="S3.E2.m1.1.1.4.1a" xref="S3.E2.m1.1.1.4.1.cmml">​</mo><msub id="S3.E2.m1.1.1.4.4" xref="S3.E2.m1.1.1.4.4.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.4.4.2" xref="S3.E2.m1.1.1.4.4.2.cmml">M</mi><mn mathsize="90%" id="S3.E2.m1.1.1.4.4.3" xref="S3.E2.m1.1.1.4.4.3.cmml">2</mn></msub></mrow><mo mathsize="90%" id="S3.E2.m1.1.1.5" xref="S3.E2.m1.1.1.5.cmml">=</mo><mrow id="S3.E2.m1.1.1.6" xref="S3.E2.m1.1.1.6.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.6.2" xref="S3.E2.m1.1.1.6.2.cmml">L</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.E2.m1.1.1.6.1" xref="S3.E2.m1.1.1.6.1.cmml">⋅</mo><msup id="S3.E2.m1.1.1.6.3" xref="S3.E2.m1.1.1.6.3.cmml"><mi mathsize="90%" id="S3.E2.m1.1.1.6.3.2" xref="S3.E2.m1.1.1.6.3.2.cmml">V</mi><mi mathsize="90%" id="S3.E2.m1.1.1.6.3.3" xref="S3.E2.m1.1.1.6.3.3.cmml">T</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><and id="S3.E2.m1.1.1a.cmml" xref="S3.E2.m1.1.1"></and><apply id="S3.E2.m1.1.1b.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"></eq><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.2.2">𝑀</ci><cn type="integer" id="S3.E2.m1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.2.3">1</cn></apply><apply id="S3.E2.m1.1.1.4.cmml" xref="S3.E2.m1.1.1.4"><times id="S3.E2.m1.1.1.4.1.cmml" xref="S3.E2.m1.1.1.4.1"></times><apply id="S3.E2.m1.1.1.4.2.cmml" xref="S3.E2.m1.1.1.4.2"><ci id="S3.E2.m1.1.1.4.2.1.cmml" xref="S3.E2.m1.1.1.4.2.1">⋅</ci><ci id="S3.E2.m1.1.1.4.2.2.cmml" xref="S3.E2.m1.1.1.4.2.2">𝑉</ci><apply id="S3.E2.m1.1.1.4.2.3.cmml" xref="S3.E2.m1.1.1.4.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.4.2.3.1.cmml" xref="S3.E2.m1.1.1.4.2.3">superscript</csymbol><ci id="S3.E2.m1.1.1.4.2.3.2.cmml" xref="S3.E2.m1.1.1.4.2.3.2">𝐿</ci><ci id="S3.E2.m1.1.1.4.2.3.3.cmml" xref="S3.E2.m1.1.1.4.2.3.3">𝑇</ci></apply></apply><ci id="S3.E2.m1.1.1.4.3a.cmml" xref="S3.E2.m1.1.1.4.3"><mtext mathsize="90%" id="S3.E2.m1.1.1.4.3.cmml" xref="S3.E2.m1.1.1.4.3">and</mtext></ci><apply id="S3.E2.m1.1.1.4.4.cmml" xref="S3.E2.m1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.4.4.1.cmml" xref="S3.E2.m1.1.1.4.4">subscript</csymbol><ci id="S3.E2.m1.1.1.4.4.2.cmml" xref="S3.E2.m1.1.1.4.4.2">𝑀</ci><cn type="integer" id="S3.E2.m1.1.1.4.4.3.cmml" xref="S3.E2.m1.1.1.4.4.3">2</cn></apply></apply></apply><apply id="S3.E2.m1.1.1c.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.5.cmml" xref="S3.E2.m1.1.1.5"></eq><share href="#S3.E2.m1.1.1.4.cmml" id="S3.E2.m1.1.1d.cmml" xref="S3.E2.m1.1.1"></share><apply id="S3.E2.m1.1.1.6.cmml" xref="S3.E2.m1.1.1.6"><ci id="S3.E2.m1.1.1.6.1.cmml" xref="S3.E2.m1.1.1.6.1">⋅</ci><ci id="S3.E2.m1.1.1.6.2.cmml" xref="S3.E2.m1.1.1.6.2">𝐿</ci><apply id="S3.E2.m1.1.1.6.3.cmml" xref="S3.E2.m1.1.1.6.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.6.3.1.cmml" xref="S3.E2.m1.1.1.6.3">superscript</csymbol><ci id="S3.E2.m1.1.1.6.3.2.cmml" xref="S3.E2.m1.1.1.6.3.2">𝑉</ci><ci id="S3.E2.m1.1.1.6.3.3.cmml" xref="S3.E2.m1.1.1.6.3.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">M_{1}=V\cdot L^{T}\quad\text{and}\quad M_{2}=L\cdot V^{T}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Multi-sequence Attention</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.6" class="ltx_p"><span id="S3.SS2.SSS2.p1.6.1" class="ltx_text" style="font-size:90%;">As mentioned earlier, we aim to leverage the contextual information of each sequence for the prediction. The probability distribution scores (</span><math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="K_{1}" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><msub id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS2.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml">K</mi><mn mathsize="90%" id="S3.SS2.SSS2.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><apply id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2">𝐾</ci><cn type="integer" id="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">K_{1}</annotation></semantics></math><span id="S3.SS2.SSS2.p1.6.2" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="K_{2}" display="inline"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><msub id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS2.p1.2.m2.1.1.2" xref="S3.SS2.SSS2.p1.2.m2.1.1.2.cmml">K</mi><mn mathsize="90%" id="S3.SS2.SSS2.p1.2.m2.1.1.3" xref="S3.SS2.SSS2.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><apply id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.2">𝐾</ci><cn type="integer" id="S3.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">K_{2}</annotation></semantics></math><span id="S3.SS2.SSS2.p1.6.3" class="ltx_text" style="font-size:90%;">) are computed over each sequence of bi-modal attention matrices </span><math id="S3.SS2.SSS2.p1.3.m3.1" class="ltx_Math" alttext="M_{1}" display="inline"><semantics id="S3.SS2.SSS2.p1.3.m3.1a"><msub id="S3.SS2.SSS2.p1.3.m3.1.1" xref="S3.SS2.SSS2.p1.3.m3.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS2.p1.3.m3.1.1.2" xref="S3.SS2.SSS2.p1.3.m3.1.1.2.cmml">M</mi><mn mathsize="90%" id="S3.SS2.SSS2.p1.3.m3.1.1.3" xref="S3.SS2.SSS2.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.3.m3.1b"><apply id="S3.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1.2">𝑀</ci><cn type="integer" id="S3.SS2.SSS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.3.m3.1c">M_{1}</annotation></semantics></math><span id="S3.SS2.SSS2.p1.6.4" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS2.SSS2.p1.4.m4.1" class="ltx_Math" alttext="M_{2}" display="inline"><semantics id="S3.SS2.SSS2.p1.4.m4.1a"><msub id="S3.SS2.SSS2.p1.4.m4.1.1" xref="S3.SS2.SSS2.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS2.p1.4.m4.1.1.2" xref="S3.SS2.SSS2.p1.4.m4.1.1.2.cmml">M</mi><mn mathsize="90%" id="S3.SS2.SSS2.p1.4.m4.1.1.3" xref="S3.SS2.SSS2.p1.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.4.m4.1b"><apply id="S3.SS2.SSS2.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.2">𝑀</ci><cn type="integer" id="S3.SS2.SSS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.4.m4.1c">M_{2}</annotation></semantics></math><span id="S3.SS2.SSS2.p1.6.5" class="ltx_text" style="font-size:90%;"> (refer to equation  </span><a href="#S3.E2" title="In 3.2.1 Bi-modal Attention ‣ 3.2 Multi-modal Multi-sequence - Bi-modal Attention (MMMS-BA) Framework ‣ 3 Methodology ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S3.SS2.SSS2.p1.6.6" class="ltx_text" style="font-size:90%;">) using a softmax function. This essentially computes the attention weights for the contextual sequences. Finally, soft attention is applied over the multi-modal multi-sequence attention matrices to compute the modality-wise attentive representations, i.e., </span><math id="S3.SS2.SSS2.p1.5.m5.1" class="ltx_Math" alttext="O_{1}" display="inline"><semantics id="S3.SS2.SSS2.p1.5.m5.1a"><msub id="S3.SS2.SSS2.p1.5.m5.1.1" xref="S3.SS2.SSS2.p1.5.m5.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS2.p1.5.m5.1.1.2" xref="S3.SS2.SSS2.p1.5.m5.1.1.2.cmml">O</mi><mn mathsize="90%" id="S3.SS2.SSS2.p1.5.m5.1.1.3" xref="S3.SS2.SSS2.p1.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.5.m5.1b"><apply id="S3.SS2.SSS2.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.2">𝑂</ci><cn type="integer" id="S3.SS2.SSS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.SSS2.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.5.m5.1c">O_{1}</annotation></semantics></math><span id="S3.SS2.SSS2.p1.6.7" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS2.SSS2.p1.6.m6.1" class="ltx_Math" alttext="O_{2}" display="inline"><semantics id="S3.SS2.SSS2.p1.6.m6.1a"><msub id="S3.SS2.SSS2.p1.6.m6.1.1" xref="S3.SS2.SSS2.p1.6.m6.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS2.p1.6.m6.1.1.2" xref="S3.SS2.SSS2.p1.6.m6.1.1.2.cmml">O</mi><mn mathsize="90%" id="S3.SS2.SSS2.p1.6.m6.1.1.3" xref="S3.SS2.SSS2.p1.6.m6.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.6.m6.1b"><apply id="S3.SS2.SSS2.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.2">𝑂</ci><cn type="integer" id="S3.SS2.SSS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.SSS2.p1.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.6.m6.1c">O_{2}</annotation></semantics></math><span id="S3.SS2.SSS2.p1.6.8" class="ltx_text" style="font-size:90%;"> explained below.</span></p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.8" class="ltx_math_unparsed" alttext="K_{1}(i,j)=\frac{e^{M1(i,j)}}{\sum_{k=1}^{N}e^{M1(i,k)}}\quad\text{for}\ i,j=1,2,..,N" display="block"><semantics id="S3.E3.m1.8a"><mrow id="S3.E3.m1.8b"><msub id="S3.E3.m1.8.9"><mi mathsize="90%" id="S3.E3.m1.8.9.2">K</mi><mn mathsize="90%" id="S3.E3.m1.8.9.3">1</mn></msub><mrow id="S3.E3.m1.8.10"><mo maxsize="90%" minsize="90%" id="S3.E3.m1.8.10.1">(</mo><mi mathsize="90%" id="S3.E3.m1.5.5">i</mi><mo mathsize="90%" id="S3.E3.m1.8.10.2">,</mo><mi mathsize="90%" id="S3.E3.m1.6.6">j</mi><mo maxsize="90%" minsize="90%" id="S3.E3.m1.8.10.3">)</mo></mrow><mo mathsize="90%" id="S3.E3.m1.8.11">=</mo><mfrac id="S3.E3.m1.4.4"><msup id="S3.E3.m1.2.2.2"><mi mathsize="90%" id="S3.E3.m1.2.2.2.4">e</mi><mrow id="S3.E3.m1.2.2.2.2.2"><mi mathsize="90%" id="S3.E3.m1.2.2.2.2.2.4">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.3">​</mo><mn mathsize="90%" id="S3.E3.m1.2.2.2.2.2.5">1</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.3a">​</mo><mrow id="S3.E3.m1.2.2.2.2.2.6.2"><mo maxsize="90%" minsize="90%" id="S3.E3.m1.2.2.2.2.2.6.2.1">(</mo><mi mathsize="90%" id="S3.E3.m1.1.1.1.1.1.1">i</mi><mo mathsize="90%" id="S3.E3.m1.2.2.2.2.2.6.2.2">,</mo><mi mathsize="90%" id="S3.E3.m1.2.2.2.2.2.2">j</mi><mo maxsize="90%" minsize="90%" id="S3.E3.m1.2.2.2.2.2.6.2.3">)</mo></mrow></mrow></msup><mrow id="S3.E3.m1.4.4.4"><msubsup id="S3.E3.m1.4.4.4.3"><mo maxsize="90%" minsize="90%" stretchy="true" id="S3.E3.m1.4.4.4.3.2.2">∑</mo><mrow id="S3.E3.m1.4.4.4.3.2.3"><mi mathsize="90%" id="S3.E3.m1.4.4.4.3.2.3.2">k</mi><mo mathsize="90%" id="S3.E3.m1.4.4.4.3.2.3.1">=</mo><mn mathsize="90%" id="S3.E3.m1.4.4.4.3.2.3.3">1</mn></mrow><mi mathsize="90%" id="S3.E3.m1.4.4.4.3.3">N</mi></msubsup><msup id="S3.E3.m1.4.4.4.4"><mi mathsize="90%" id="S3.E3.m1.4.4.4.4.2">e</mi><mrow id="S3.E3.m1.4.4.4.2.2"><mi mathsize="90%" id="S3.E3.m1.4.4.4.2.2.4">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.4.2.2.3">​</mo><mn mathsize="90%" id="S3.E3.m1.4.4.4.2.2.5">1</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.4.2.2.3a">​</mo><mrow id="S3.E3.m1.4.4.4.2.2.6.2"><mo maxsize="90%" minsize="90%" id="S3.E3.m1.4.4.4.2.2.6.2.1">(</mo><mi mathsize="90%" id="S3.E3.m1.3.3.3.1.1.1">i</mi><mo mathsize="90%" id="S3.E3.m1.4.4.4.2.2.6.2.2">,</mo><mi mathsize="90%" id="S3.E3.m1.4.4.4.2.2.2">k</mi><mo maxsize="90%" minsize="90%" id="S3.E3.m1.4.4.4.2.2.6.2.3">)</mo></mrow></mrow></msup></mrow></mfrac><mtext mathsize="90%" id="S3.E3.m1.8.12">for</mtext><mi mathsize="90%" id="S3.E3.m1.8.13">i</mi><mo mathsize="90%" id="S3.E3.m1.8.14">,</mo><mi mathsize="90%" id="S3.E3.m1.8.15">j</mi><mo mathsize="90%" id="S3.E3.m1.8.16">=</mo><mn mathsize="90%" id="S3.E3.m1.7.7">1</mn><mo mathsize="90%" id="S3.E3.m1.8.17">,</mo><mn mathsize="90%" id="S3.E3.m1.8.8">2</mn><mo mathsize="90%" id="S3.E3.m1.8.18">,</mo><mo lspace="0em" mathsize="90%" rspace="0.0835em" id="S3.E3.m1.8.19">.</mo><mo lspace="0.0835em" mathsize="90%" rspace="0.167em" id="S3.E3.m1.8.20">.</mo><mo mathsize="90%" id="S3.E3.m1.8.21">,</mo><mi mathsize="90%" id="S3.E3.m1.8.22">N</mi></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.8c">K_{1}(i,j)=\frac{e^{M1(i,j)}}{\sum_{k=1}^{N}e^{M1(i,k)}}\quad\text{for}\ i,j=1,2,..,N</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.8" class="ltx_math_unparsed" alttext="K_{2}(i,j)=\frac{e^{M2(i,j)}}{\sum_{k=1}^{N}e^{M2(i,k)}}\quad\text{for}\ i,j=1,2,..,N" display="block"><semantics id="S3.E4.m1.8a"><mrow id="S3.E4.m1.8b"><msub id="S3.E4.m1.8.9"><mi mathsize="90%" id="S3.E4.m1.8.9.2">K</mi><mn mathsize="90%" id="S3.E4.m1.8.9.3">2</mn></msub><mrow id="S3.E4.m1.8.10"><mo maxsize="90%" minsize="90%" id="S3.E4.m1.8.10.1">(</mo><mi mathsize="90%" id="S3.E4.m1.5.5">i</mi><mo mathsize="90%" id="S3.E4.m1.8.10.2">,</mo><mi mathsize="90%" id="S3.E4.m1.6.6">j</mi><mo maxsize="90%" minsize="90%" id="S3.E4.m1.8.10.3">)</mo></mrow><mo mathsize="90%" id="S3.E4.m1.8.11">=</mo><mfrac id="S3.E4.m1.4.4"><msup id="S3.E4.m1.2.2.2"><mi mathsize="90%" id="S3.E4.m1.2.2.2.4">e</mi><mrow id="S3.E4.m1.2.2.2.2.2"><mi mathsize="90%" id="S3.E4.m1.2.2.2.2.2.4">M</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.2.2.3">​</mo><mn mathsize="90%" id="S3.E4.m1.2.2.2.2.2.5">2</mn><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.2.2.3a">​</mo><mrow id="S3.E4.m1.2.2.2.2.2.6.2"><mo maxsize="90%" minsize="90%" id="S3.E4.m1.2.2.2.2.2.6.2.1">(</mo><mi mathsize="90%" id="S3.E4.m1.1.1.1.1.1.1">i</mi><mo mathsize="90%" id="S3.E4.m1.2.2.2.2.2.6.2.2">,</mo><mi mathsize="90%" id="S3.E4.m1.2.2.2.2.2.2">j</mi><mo maxsize="90%" minsize="90%" id="S3.E4.m1.2.2.2.2.2.6.2.3">)</mo></mrow></mrow></msup><mrow id="S3.E4.m1.4.4.4"><msubsup id="S3.E4.m1.4.4.4.3"><mo maxsize="90%" minsize="90%" stretchy="true" id="S3.E4.m1.4.4.4.3.2.2">∑</mo><mrow id="S3.E4.m1.4.4.4.3.2.3"><mi mathsize="90%" id="S3.E4.m1.4.4.4.3.2.3.2">k</mi><mo mathsize="90%" id="S3.E4.m1.4.4.4.3.2.3.1">=</mo><mn mathsize="90%" id="S3.E4.m1.4.4.4.3.2.3.3">1</mn></mrow><mi mathsize="90%" id="S3.E4.m1.4.4.4.3.3">N</mi></msubsup><msup id="S3.E4.m1.4.4.4.4"><mi mathsize="90%" id="S3.E4.m1.4.4.4.4.2">e</mi><mrow id="S3.E4.m1.4.4.4.2.2"><mi mathsize="90%" id="S3.E4.m1.4.4.4.2.2.4">M</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.4.2.2.3">​</mo><mn mathsize="90%" id="S3.E4.m1.4.4.4.2.2.5">2</mn><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.4.2.2.3a">​</mo><mrow id="S3.E4.m1.4.4.4.2.2.6.2"><mo maxsize="90%" minsize="90%" id="S3.E4.m1.4.4.4.2.2.6.2.1">(</mo><mi mathsize="90%" id="S3.E4.m1.3.3.3.1.1.1">i</mi><mo mathsize="90%" id="S3.E4.m1.4.4.4.2.2.6.2.2">,</mo><mi mathsize="90%" id="S3.E4.m1.4.4.4.2.2.2">k</mi><mo maxsize="90%" minsize="90%" id="S3.E4.m1.4.4.4.2.2.6.2.3">)</mo></mrow></mrow></msup></mrow></mfrac><mtext mathsize="90%" id="S3.E4.m1.8.12">for</mtext><mi mathsize="90%" id="S3.E4.m1.8.13">i</mi><mo mathsize="90%" id="S3.E4.m1.8.14">,</mo><mi mathsize="90%" id="S3.E4.m1.8.15">j</mi><mo mathsize="90%" id="S3.E4.m1.8.16">=</mo><mn mathsize="90%" id="S3.E4.m1.7.7">1</mn><mo mathsize="90%" id="S3.E4.m1.8.17">,</mo><mn mathsize="90%" id="S3.E4.m1.8.8">2</mn><mo mathsize="90%" id="S3.E4.m1.8.18">,</mo><mo lspace="0em" mathsize="90%" rspace="0.0835em" id="S3.E4.m1.8.19">.</mo><mo lspace="0.0835em" mathsize="90%" rspace="0.167em" id="S3.E4.m1.8.20">.</mo><mo mathsize="90%" id="S3.E4.m1.8.21">,</mo><mi mathsize="90%" id="S3.E4.m1.8.22">N</mi></mrow><annotation encoding="application/x-tex" id="S3.E4.m1.8c">K_{2}(i,j)=\frac{e^{M2(i,j)}}{\sum_{k=1}^{N}e^{M2(i,k)}}\quad\text{for}\ i,j=1,2,..,N</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="O_{1}=K_{1}\cdot L\quad\text{and}\quad O_{2}=K_{2}\cdot V" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><msub id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml"><mi mathsize="90%" id="S3.E5.m1.1.1.2.2" xref="S3.E5.m1.1.1.2.2.cmml">O</mi><mn mathsize="90%" id="S3.E5.m1.1.1.2.3" xref="S3.E5.m1.1.1.2.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.1.1.4" xref="S3.E5.m1.1.1.4.cmml"><mrow id="S3.E5.m1.1.1.4.2" xref="S3.E5.m1.1.1.4.2.cmml"><msub id="S3.E5.m1.1.1.4.2.2" xref="S3.E5.m1.1.1.4.2.2.cmml"><mi mathsize="90%" id="S3.E5.m1.1.1.4.2.2.2" xref="S3.E5.m1.1.1.4.2.2.2.cmml">K</mi><mn mathsize="90%" id="S3.E5.m1.1.1.4.2.2.3" xref="S3.E5.m1.1.1.4.2.2.3.cmml">1</mn></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.E5.m1.1.1.4.2.1" xref="S3.E5.m1.1.1.4.2.1.cmml">⋅</mo><mi mathsize="90%" id="S3.E5.m1.1.1.4.2.3" xref="S3.E5.m1.1.1.4.2.3.cmml">L</mi></mrow><mo lspace="0.900em" rspace="0em" id="S3.E5.m1.1.1.4.1" xref="S3.E5.m1.1.1.4.1.cmml">​</mo><mtext mathsize="90%" id="S3.E5.m1.1.1.4.3" xref="S3.E5.m1.1.1.4.3a.cmml">and</mtext><mo lspace="0.900em" rspace="0em" id="S3.E5.m1.1.1.4.1a" xref="S3.E5.m1.1.1.4.1.cmml">​</mo><msub id="S3.E5.m1.1.1.4.4" xref="S3.E5.m1.1.1.4.4.cmml"><mi mathsize="90%" id="S3.E5.m1.1.1.4.4.2" xref="S3.E5.m1.1.1.4.4.2.cmml">O</mi><mn mathsize="90%" id="S3.E5.m1.1.1.4.4.3" xref="S3.E5.m1.1.1.4.4.3.cmml">2</mn></msub></mrow><mo mathsize="90%" id="S3.E5.m1.1.1.5" xref="S3.E5.m1.1.1.5.cmml">=</mo><mrow id="S3.E5.m1.1.1.6" xref="S3.E5.m1.1.1.6.cmml"><msub id="S3.E5.m1.1.1.6.2" xref="S3.E5.m1.1.1.6.2.cmml"><mi mathsize="90%" id="S3.E5.m1.1.1.6.2.2" xref="S3.E5.m1.1.1.6.2.2.cmml">K</mi><mn mathsize="90%" id="S3.E5.m1.1.1.6.2.3" xref="S3.E5.m1.1.1.6.2.3.cmml">2</mn></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.E5.m1.1.1.6.1" xref="S3.E5.m1.1.1.6.1.cmml">⋅</mo><mi mathsize="90%" id="S3.E5.m1.1.1.6.3" xref="S3.E5.m1.1.1.6.3.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><and id="S3.E5.m1.1.1a.cmml" xref="S3.E5.m1.1.1"></and><apply id="S3.E5.m1.1.1b.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"></eq><apply id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.2.2">𝑂</ci><cn type="integer" id="S3.E5.m1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.2.3">1</cn></apply><apply id="S3.E5.m1.1.1.4.cmml" xref="S3.E5.m1.1.1.4"><times id="S3.E5.m1.1.1.4.1.cmml" xref="S3.E5.m1.1.1.4.1"></times><apply id="S3.E5.m1.1.1.4.2.cmml" xref="S3.E5.m1.1.1.4.2"><ci id="S3.E5.m1.1.1.4.2.1.cmml" xref="S3.E5.m1.1.1.4.2.1">⋅</ci><apply id="S3.E5.m1.1.1.4.2.2.cmml" xref="S3.E5.m1.1.1.4.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.4.2.2.1.cmml" xref="S3.E5.m1.1.1.4.2.2">subscript</csymbol><ci id="S3.E5.m1.1.1.4.2.2.2.cmml" xref="S3.E5.m1.1.1.4.2.2.2">𝐾</ci><cn type="integer" id="S3.E5.m1.1.1.4.2.2.3.cmml" xref="S3.E5.m1.1.1.4.2.2.3">1</cn></apply><ci id="S3.E5.m1.1.1.4.2.3.cmml" xref="S3.E5.m1.1.1.4.2.3">𝐿</ci></apply><ci id="S3.E5.m1.1.1.4.3a.cmml" xref="S3.E5.m1.1.1.4.3"><mtext mathsize="90%" id="S3.E5.m1.1.1.4.3.cmml" xref="S3.E5.m1.1.1.4.3">and</mtext></ci><apply id="S3.E5.m1.1.1.4.4.cmml" xref="S3.E5.m1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.4.4.1.cmml" xref="S3.E5.m1.1.1.4.4">subscript</csymbol><ci id="S3.E5.m1.1.1.4.4.2.cmml" xref="S3.E5.m1.1.1.4.4.2">𝑂</ci><cn type="integer" id="S3.E5.m1.1.1.4.4.3.cmml" xref="S3.E5.m1.1.1.4.4.3">2</cn></apply></apply></apply><apply id="S3.E5.m1.1.1c.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.5.cmml" xref="S3.E5.m1.1.1.5"></eq><share href="#S3.E5.m1.1.1.4.cmml" id="S3.E5.m1.1.1d.cmml" xref="S3.E5.m1.1.1"></share><apply id="S3.E5.m1.1.1.6.cmml" xref="S3.E5.m1.1.1.6"><ci id="S3.E5.m1.1.1.6.1.cmml" xref="S3.E5.m1.1.1.6.1">⋅</ci><apply id="S3.E5.m1.1.1.6.2.cmml" xref="S3.E5.m1.1.1.6.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.6.2.1.cmml" xref="S3.E5.m1.1.1.6.2">subscript</csymbol><ci id="S3.E5.m1.1.1.6.2.2.cmml" xref="S3.E5.m1.1.1.6.2.2">𝐾</ci><cn type="integer" id="S3.E5.m1.1.1.6.2.3.cmml" xref="S3.E5.m1.1.1.6.2.3">2</cn></apply><ci id="S3.E5.m1.1.1.6.3.cmml" xref="S3.E5.m1.1.1.6.3">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">O_{1}=K_{1}\cdot L\quad\text{and}\quad O_{2}=K_{2}\cdot V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p3.6" class="ltx_p"><span id="S3.SS2.SSS2.p3.6.1" class="ltx_text" style="font-size:90%;">where </span><math id="S3.SS2.SSS2.p3.1.m1.1" class="ltx_Math" alttext="M_{1}" display="inline"><semantics id="S3.SS2.SSS2.p3.1.m1.1a"><msub id="S3.SS2.SSS2.p3.1.m1.1.1" xref="S3.SS2.SSS2.p3.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS2.p3.1.m1.1.1.2" xref="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml">M</mi><mn mathsize="90%" id="S3.SS2.SSS2.p3.1.m1.1.1.3" xref="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.1.m1.1b"><apply id="S3.SS2.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.2">𝑀</ci><cn type="integer" id="S3.SS2.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.1.m1.1c">M_{1}</annotation></semantics></math><span id="S3.SS2.SSS2.p3.6.2" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS2.SSS2.p3.2.m2.1" class="ltx_Math" alttext="M_{2}" display="inline"><semantics id="S3.SS2.SSS2.p3.2.m2.1a"><msub id="S3.SS2.SSS2.p3.2.m2.1.1" xref="S3.SS2.SSS2.p3.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS2.p3.2.m2.1.1.2" xref="S3.SS2.SSS2.p3.2.m2.1.1.2.cmml">M</mi><mn mathsize="90%" id="S3.SS2.SSS2.p3.2.m2.1.1.3" xref="S3.SS2.SSS2.p3.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.2.m2.1b"><apply id="S3.SS2.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.2">𝑀</ci><cn type="integer" id="S3.SS2.SSS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p3.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.2.m2.1c">M_{2}</annotation></semantics></math><span id="S3.SS2.SSS2.p3.6.3" class="ltx_text" style="font-size:90%;"> are the bi-modal attention matrices between </span><math id="S3.SS2.SSS2.p3.3.m3.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.SSS2.p3.3.m3.1a"><mi mathsize="90%" id="S3.SS2.SSS2.p3.3.m3.1.1" xref="S3.SS2.SSS2.p3.3.m3.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.3.m3.1b"><ci id="S3.SS2.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p3.3.m3.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.3.m3.1c">V</annotation></semantics></math><span id="S3.SS2.SSS2.p3.6.4" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS2.SSS2.p3.4.m4.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.SSS2.p3.4.m4.1a"><mi mathsize="90%" id="S3.SS2.SSS2.p3.4.m4.1.1" xref="S3.SS2.SSS2.p3.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.4.m4.1b"><ci id="S3.SS2.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p3.4.m4.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.4.m4.1c">L</annotation></semantics></math><span id="S3.SS2.SSS2.p3.6.5" class="ltx_text" style="font-size:90%;">. </span><math id="S3.SS2.SSS2.p3.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS2.p3.5.m5.1a"><mi mathsize="90%" id="S3.SS2.SSS2.p3.5.m5.1.1" xref="S3.SS2.SSS2.p3.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.5.m5.1b"><ci id="S3.SS2.SSS2.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS2.p3.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.5.m5.1c">i</annotation></semantics></math><span id="S3.SS2.SSS2.p3.6.6" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS2.SSS2.p3.6.m6.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.SSS2.p3.6.m6.1a"><mi mathsize="90%" id="S3.SS2.SSS2.p3.6.m6.1.1" xref="S3.SS2.SSS2.p3.6.m6.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p3.6.m6.1b"><ci id="S3.SS2.SSS2.p3.6.m6.1.1.cmml" xref="S3.SS2.SSS2.p3.6.m6.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p3.6.m6.1c">j</annotation></semantics></math><span id="S3.SS2.SSS2.p3.6.7" class="ltx_text" style="font-size:90%;"> represent sequences in the input.</span></p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Multiplicative Gating and Concatenation</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.6" class="ltx_p"><span id="S3.SS2.SSS3.p1.6.1" class="ltx_text" style="font-size:90%;">A multiplicative gating function is computed between the multi-modal sequence-specific representations of each modality </span><math id="S3.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="O_{1}" display="inline"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><msub id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p1.1.m1.1.1.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml">O</mi><mn mathsize="90%" id="S3.SS2.SSS3.p1.1.m1.1.1.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.1b"><apply id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.2">𝑂</ci><cn type="integer" id="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.1c">O_{1}</annotation></semantics></math><span id="S3.SS2.SSS3.p1.6.2" class="ltx_text" style="font-size:90%;"> &amp; </span><math id="S3.SS2.SSS3.p1.2.m2.1" class="ltx_Math" alttext="O_{2}" display="inline"><semantics id="S3.SS2.SSS3.p1.2.m2.1a"><msub id="S3.SS2.SSS3.p1.2.m2.1.1" xref="S3.SS2.SSS3.p1.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p1.2.m2.1.1.2" xref="S3.SS2.SSS3.p1.2.m2.1.1.2.cmml">O</mi><mn mathsize="90%" id="S3.SS2.SSS3.p1.2.m2.1.1.3" xref="S3.SS2.SSS3.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.2.m2.1b"><apply id="S3.SS2.SSS3.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1.2">𝑂</ci><cn type="integer" id="S3.SS2.SSS3.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.2.m2.1c">O_{2}</annotation></semantics></math><span id="S3.SS2.SSS3.p1.6.3" class="ltx_text" style="font-size:90%;"> (refer equation </span><a href="#S3.E5" title="In 3.2.2 Multi-sequence Attention ‣ 3.2 Multi-modal Multi-sequence - Bi-modal Attention (MMMS-BA) Framework ‣ 3 Methodology ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S3.SS2.SSS3.p1.6.4" class="ltx_text" style="font-size:90%;">) and the corresponding bi-modal pair. This element-wise matrix multiplication assists in attending to the important components of multiple modalities and sequences. Attention matrices </span><math id="S3.SS2.SSS3.p1.3.m3.1" class="ltx_Math" alttext="A_{1}" display="inline"><semantics id="S3.SS2.SSS3.p1.3.m3.1a"><msub id="S3.SS2.SSS3.p1.3.m3.1.1" xref="S3.SS2.SSS3.p1.3.m3.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p1.3.m3.1.1.2" xref="S3.SS2.SSS3.p1.3.m3.1.1.2.cmml">A</mi><mn mathsize="90%" id="S3.SS2.SSS3.p1.3.m3.1.1.3" xref="S3.SS2.SSS3.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.3.m3.1b"><apply id="S3.SS2.SSS3.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1.2">𝐴</ci><cn type="integer" id="S3.SS2.SSS3.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.3.m3.1c">A_{1}</annotation></semantics></math><span id="S3.SS2.SSS3.p1.6.5" class="ltx_text" style="font-size:90%;"> &amp; </span><math id="S3.SS2.SSS3.p1.4.m4.1" class="ltx_Math" alttext="A_{2}" display="inline"><semantics id="S3.SS2.SSS3.p1.4.m4.1a"><msub id="S3.SS2.SSS3.p1.4.m4.1.1" xref="S3.SS2.SSS3.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p1.4.m4.1.1.2" xref="S3.SS2.SSS3.p1.4.m4.1.1.2.cmml">A</mi><mn mathsize="90%" id="S3.SS2.SSS3.p1.4.m4.1.1.3" xref="S3.SS2.SSS3.p1.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.4.m4.1b"><apply id="S3.SS2.SSS3.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1.2">𝐴</ci><cn type="integer" id="S3.SS2.SSS3.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.4.m4.1c">A_{2}</annotation></semantics></math><span id="S3.SS2.SSS3.p1.6.6" class="ltx_text" style="font-size:90%;"> are then concatenated to obtain the pair-wise attention between </span><math id="S3.SS2.SSS3.p1.5.m5.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.SSS3.p1.5.m5.1a"><mi mathsize="90%" id="S3.SS2.SSS3.p1.5.m5.1.1" xref="S3.SS2.SSS3.p1.5.m5.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.5.m5.1b"><ci id="S3.SS2.SSS3.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS3.p1.5.m5.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.5.m5.1c">V</annotation></semantics></math><span id="S3.SS2.SSS3.p1.6.7" class="ltx_text" style="font-size:90%;"> and </span><math id="S3.SS2.SSS3.p1.6.m6.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.SSS3.p1.6.m6.1a"><mi mathsize="90%" id="S3.SS2.SSS3.p1.6.m6.1.1" xref="S3.SS2.SSS3.p1.6.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.6.m6.1b"><ci id="S3.SS2.SSS3.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS3.p1.6.m6.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.6.m6.1c">L</annotation></semantics></math><span id="S3.SS2.SSS3.p1.6.8" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="A_{1}=O_{1}\odot V\quad\text{and}\quad A_{2}=O_{2}\odot L" display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><msub id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2.cmml"><mi mathsize="90%" id="S3.E6.m1.1.1.2.2" xref="S3.E6.m1.1.1.2.2.cmml">A</mi><mn mathsize="90%" id="S3.E6.m1.1.1.2.3" xref="S3.E6.m1.1.1.2.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml">=</mo><mrow id="S3.E6.m1.1.1.4" xref="S3.E6.m1.1.1.4.cmml"><mrow id="S3.E6.m1.1.1.4.2" xref="S3.E6.m1.1.1.4.2.cmml"><msub id="S3.E6.m1.1.1.4.2.2" xref="S3.E6.m1.1.1.4.2.2.cmml"><mi mathsize="90%" id="S3.E6.m1.1.1.4.2.2.2" xref="S3.E6.m1.1.1.4.2.2.2.cmml">O</mi><mn mathsize="90%" id="S3.E6.m1.1.1.4.2.2.3" xref="S3.E6.m1.1.1.4.2.2.3.cmml">1</mn></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.E6.m1.1.1.4.2.1" xref="S3.E6.m1.1.1.4.2.1.cmml">⊙</mo><mi mathsize="90%" id="S3.E6.m1.1.1.4.2.3" xref="S3.E6.m1.1.1.4.2.3.cmml">V</mi></mrow><mo lspace="0.900em" rspace="0em" id="S3.E6.m1.1.1.4.1" xref="S3.E6.m1.1.1.4.1.cmml">​</mo><mtext mathsize="90%" id="S3.E6.m1.1.1.4.3" xref="S3.E6.m1.1.1.4.3a.cmml">and</mtext><mo lspace="0.900em" rspace="0em" id="S3.E6.m1.1.1.4.1a" xref="S3.E6.m1.1.1.4.1.cmml">​</mo><msub id="S3.E6.m1.1.1.4.4" xref="S3.E6.m1.1.1.4.4.cmml"><mi mathsize="90%" id="S3.E6.m1.1.1.4.4.2" xref="S3.E6.m1.1.1.4.4.2.cmml">A</mi><mn mathsize="90%" id="S3.E6.m1.1.1.4.4.3" xref="S3.E6.m1.1.1.4.4.3.cmml">2</mn></msub></mrow><mo mathsize="90%" id="S3.E6.m1.1.1.5" xref="S3.E6.m1.1.1.5.cmml">=</mo><mrow id="S3.E6.m1.1.1.6" xref="S3.E6.m1.1.1.6.cmml"><msub id="S3.E6.m1.1.1.6.2" xref="S3.E6.m1.1.1.6.2.cmml"><mi mathsize="90%" id="S3.E6.m1.1.1.6.2.2" xref="S3.E6.m1.1.1.6.2.2.cmml">O</mi><mn mathsize="90%" id="S3.E6.m1.1.1.6.2.3" xref="S3.E6.m1.1.1.6.2.3.cmml">2</mn></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S3.E6.m1.1.1.6.1" xref="S3.E6.m1.1.1.6.1.cmml">⊙</mo><mi mathsize="90%" id="S3.E6.m1.1.1.6.3" xref="S3.E6.m1.1.1.6.3.cmml">L</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><and id="S3.E6.m1.1.1a.cmml" xref="S3.E6.m1.1.1"></and><apply id="S3.E6.m1.1.1b.cmml" xref="S3.E6.m1.1.1"><eq id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"></eq><apply id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.2.2">𝐴</ci><cn type="integer" id="S3.E6.m1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.2.3">1</cn></apply><apply id="S3.E6.m1.1.1.4.cmml" xref="S3.E6.m1.1.1.4"><times id="S3.E6.m1.1.1.4.1.cmml" xref="S3.E6.m1.1.1.4.1"></times><apply id="S3.E6.m1.1.1.4.2.cmml" xref="S3.E6.m1.1.1.4.2"><csymbol cd="latexml" id="S3.E6.m1.1.1.4.2.1.cmml" xref="S3.E6.m1.1.1.4.2.1">direct-product</csymbol><apply id="S3.E6.m1.1.1.4.2.2.cmml" xref="S3.E6.m1.1.1.4.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.4.2.2.1.cmml" xref="S3.E6.m1.1.1.4.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.4.2.2.2.cmml" xref="S3.E6.m1.1.1.4.2.2.2">𝑂</ci><cn type="integer" id="S3.E6.m1.1.1.4.2.2.3.cmml" xref="S3.E6.m1.1.1.4.2.2.3">1</cn></apply><ci id="S3.E6.m1.1.1.4.2.3.cmml" xref="S3.E6.m1.1.1.4.2.3">𝑉</ci></apply><ci id="S3.E6.m1.1.1.4.3a.cmml" xref="S3.E6.m1.1.1.4.3"><mtext mathsize="90%" id="S3.E6.m1.1.1.4.3.cmml" xref="S3.E6.m1.1.1.4.3">and</mtext></ci><apply id="S3.E6.m1.1.1.4.4.cmml" xref="S3.E6.m1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.4.4.1.cmml" xref="S3.E6.m1.1.1.4.4">subscript</csymbol><ci id="S3.E6.m1.1.1.4.4.2.cmml" xref="S3.E6.m1.1.1.4.4.2">𝐴</ci><cn type="integer" id="S3.E6.m1.1.1.4.4.3.cmml" xref="S3.E6.m1.1.1.4.4.3">2</cn></apply></apply></apply><apply id="S3.E6.m1.1.1c.cmml" xref="S3.E6.m1.1.1"><eq id="S3.E6.m1.1.1.5.cmml" xref="S3.E6.m1.1.1.5"></eq><share href="#S3.E6.m1.1.1.4.cmml" id="S3.E6.m1.1.1d.cmml" xref="S3.E6.m1.1.1"></share><apply id="S3.E6.m1.1.1.6.cmml" xref="S3.E6.m1.1.1.6"><csymbol cd="latexml" id="S3.E6.m1.1.1.6.1.cmml" xref="S3.E6.m1.1.1.6.1">direct-product</csymbol><apply id="S3.E6.m1.1.1.6.2.cmml" xref="S3.E6.m1.1.1.6.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.6.2.1.cmml" xref="S3.E6.m1.1.1.6.2">subscript</csymbol><ci id="S3.E6.m1.1.1.6.2.2.cmml" xref="S3.E6.m1.1.1.6.2.2">𝑂</ci><cn type="integer" id="S3.E6.m1.1.1.6.2.3.cmml" xref="S3.E6.m1.1.1.6.2.3">2</cn></apply><ci id="S3.E6.m1.1.1.6.3.cmml" xref="S3.E6.m1.1.1.6.3">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">A_{1}=O_{1}\odot V\quad\text{and}\quad A_{2}=O_{2}\odot L</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para">
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.2" class="ltx_Math" alttext="MMMS\text{-}BA_{VL}=\text{concat}[A_{1},A_{2}]" display="block"><semantics id="S3.E7.m1.2a"><mrow id="S3.E7.m1.2.2" xref="S3.E7.m1.2.2.cmml"><mrow id="S3.E7.m1.2.2.4" xref="S3.E7.m1.2.2.4.cmml"><mi mathsize="90%" id="S3.E7.m1.2.2.4.2" xref="S3.E7.m1.2.2.4.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.4.1" xref="S3.E7.m1.2.2.4.1.cmml">​</mo><mi mathsize="90%" id="S3.E7.m1.2.2.4.3" xref="S3.E7.m1.2.2.4.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.4.1a" xref="S3.E7.m1.2.2.4.1.cmml">​</mo><mi mathsize="90%" id="S3.E7.m1.2.2.4.4" xref="S3.E7.m1.2.2.4.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.4.1b" xref="S3.E7.m1.2.2.4.1.cmml">​</mo><mi mathsize="90%" id="S3.E7.m1.2.2.4.5" xref="S3.E7.m1.2.2.4.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.4.1c" xref="S3.E7.m1.2.2.4.1.cmml">​</mo><mtext mathsize="90%" id="S3.E7.m1.2.2.4.6" xref="S3.E7.m1.2.2.4.6a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.4.1d" xref="S3.E7.m1.2.2.4.1.cmml">​</mo><mi mathsize="90%" id="S3.E7.m1.2.2.4.7" xref="S3.E7.m1.2.2.4.7.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.4.1e" xref="S3.E7.m1.2.2.4.1.cmml">​</mo><msub id="S3.E7.m1.2.2.4.8" xref="S3.E7.m1.2.2.4.8.cmml"><mi mathsize="90%" id="S3.E7.m1.2.2.4.8.2" xref="S3.E7.m1.2.2.4.8.2.cmml">A</mi><mrow id="S3.E7.m1.2.2.4.8.3" xref="S3.E7.m1.2.2.4.8.3.cmml"><mi mathsize="90%" id="S3.E7.m1.2.2.4.8.3.2" xref="S3.E7.m1.2.2.4.8.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.4.8.3.1" xref="S3.E7.m1.2.2.4.8.3.1.cmml">​</mo><mi mathsize="90%" id="S3.E7.m1.2.2.4.8.3.3" xref="S3.E7.m1.2.2.4.8.3.3.cmml">L</mi></mrow></msub></mrow><mo mathsize="90%" id="S3.E7.m1.2.2.3" xref="S3.E7.m1.2.2.3.cmml">=</mo><mrow id="S3.E7.m1.2.2.2" xref="S3.E7.m1.2.2.2.cmml"><mtext mathsize="90%" id="S3.E7.m1.2.2.2.4" xref="S3.E7.m1.2.2.2.4a.cmml">concat</mtext><mo lspace="0em" rspace="0em" id="S3.E7.m1.2.2.2.3" xref="S3.E7.m1.2.2.2.3.cmml">​</mo><mrow id="S3.E7.m1.2.2.2.2.2" xref="S3.E7.m1.2.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.E7.m1.2.2.2.2.2.3" xref="S3.E7.m1.2.2.2.2.3.cmml">[</mo><msub id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.E7.m1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml">A</mi><mn mathsize="90%" id="S3.E7.m1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.E7.m1.2.2.2.2.2.4" xref="S3.E7.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E7.m1.2.2.2.2.2.2" xref="S3.E7.m1.2.2.2.2.2.2.cmml"><mi mathsize="90%" id="S3.E7.m1.2.2.2.2.2.2.2" xref="S3.E7.m1.2.2.2.2.2.2.2.cmml">A</mi><mn mathsize="90%" id="S3.E7.m1.2.2.2.2.2.2.3" xref="S3.E7.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo maxsize="90%" minsize="90%" id="S3.E7.m1.2.2.2.2.2.5" xref="S3.E7.m1.2.2.2.2.3.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.2b"><apply id="S3.E7.m1.2.2.cmml" xref="S3.E7.m1.2.2"><eq id="S3.E7.m1.2.2.3.cmml" xref="S3.E7.m1.2.2.3"></eq><apply id="S3.E7.m1.2.2.4.cmml" xref="S3.E7.m1.2.2.4"><times id="S3.E7.m1.2.2.4.1.cmml" xref="S3.E7.m1.2.2.4.1"></times><ci id="S3.E7.m1.2.2.4.2.cmml" xref="S3.E7.m1.2.2.4.2">𝑀</ci><ci id="S3.E7.m1.2.2.4.3.cmml" xref="S3.E7.m1.2.2.4.3">𝑀</ci><ci id="S3.E7.m1.2.2.4.4.cmml" xref="S3.E7.m1.2.2.4.4">𝑀</ci><ci id="S3.E7.m1.2.2.4.5.cmml" xref="S3.E7.m1.2.2.4.5">𝑆</ci><ci id="S3.E7.m1.2.2.4.6a.cmml" xref="S3.E7.m1.2.2.4.6"><mtext mathsize="90%" id="S3.E7.m1.2.2.4.6.cmml" xref="S3.E7.m1.2.2.4.6">-</mtext></ci><ci id="S3.E7.m1.2.2.4.7.cmml" xref="S3.E7.m1.2.2.4.7">𝐵</ci><apply id="S3.E7.m1.2.2.4.8.cmml" xref="S3.E7.m1.2.2.4.8"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.4.8.1.cmml" xref="S3.E7.m1.2.2.4.8">subscript</csymbol><ci id="S3.E7.m1.2.2.4.8.2.cmml" xref="S3.E7.m1.2.2.4.8.2">𝐴</ci><apply id="S3.E7.m1.2.2.4.8.3.cmml" xref="S3.E7.m1.2.2.4.8.3"><times id="S3.E7.m1.2.2.4.8.3.1.cmml" xref="S3.E7.m1.2.2.4.8.3.1"></times><ci id="S3.E7.m1.2.2.4.8.3.2.cmml" xref="S3.E7.m1.2.2.4.8.3.2">𝑉</ci><ci id="S3.E7.m1.2.2.4.8.3.3.cmml" xref="S3.E7.m1.2.2.4.8.3.3">𝐿</ci></apply></apply></apply><apply id="S3.E7.m1.2.2.2.cmml" xref="S3.E7.m1.2.2.2"><times id="S3.E7.m1.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.3"></times><ci id="S3.E7.m1.2.2.2.4a.cmml" xref="S3.E7.m1.2.2.2.4"><mtext mathsize="90%" id="S3.E7.m1.2.2.2.4.cmml" xref="S3.E7.m1.2.2.2.4">concat</mtext></ci><interval closure="closed" id="S3.E7.m1.2.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.2.2"><apply id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2">𝐴</ci><cn type="integer" id="S3.E7.m1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.E7.m1.2.2.2.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.2.2.2.2.1.cmml" xref="S3.E7.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E7.m1.2.2.2.2.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2.2.2.2">𝐴</ci><cn type="integer" id="S3.E7.m1.2.2.2.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.2.2.2.3">2</cn></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.2c">MMMS\text{-}BA_{VL}=\text{concat}[A_{1},A_{2}]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS3.p4.10" class="ltx_p"><span id="S3.SS2.SSS3.p4.10.1" class="ltx_text" style="font-size:90%;">Similar to </span><math id="S3.SS2.SSS3.p4.1.m1.1" class="ltx_Math" alttext="MMMS\text{-}BA_{VL}" display="inline"><semantics id="S3.SS2.SSS3.p4.1.m1.1a"><mrow id="S3.SS2.SSS3.p4.1.m1.1.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.1.m1.1.1.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.1.m1.1.1.1a" xref="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.4" xref="S3.SS2.SSS3.p4.1.m1.1.1.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.1.m1.1.1.1b" xref="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.5" xref="S3.SS2.SSS3.p4.1.m1.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.1.m1.1.1.1c" xref="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml">​</mo><mtext mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.6" xref="S3.SS2.SSS3.p4.1.m1.1.1.6a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.1.m1.1.1.1d" xref="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.7" xref="S3.SS2.SSS3.p4.1.m1.1.1.7.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.1.m1.1.1.1e" xref="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS3.p4.1.m1.1.1.8" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.8.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.2.cmml">A</mi><mrow id="S3.SS2.SSS3.p4.1.m1.1.1.8.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.3.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.8.3.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.1.m1.1.1.8.3.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.8.3.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.3.3.cmml">L</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.1.m1.1b"><apply id="S3.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1"><times id="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.1"></times><ci id="S3.SS2.SSS3.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2">𝑀</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3">𝑀</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.4.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.4">𝑀</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.5.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.5">𝑆</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.6a.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.6"><mtext mathsize="90%" id="S3.SS2.SSS3.p4.1.m1.1.1.6.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.6">-</mtext></ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.7.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.7">𝐵</ci><apply id="S3.SS2.SSS3.p4.1.m1.1.1.8.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.8"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.1.m1.1.1.8.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.8">subscript</csymbol><ci id="S3.SS2.SSS3.p4.1.m1.1.1.8.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.2">𝐴</ci><apply id="S3.SS2.SSS3.p4.1.m1.1.1.8.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.3"><times id="S3.SS2.SSS3.p4.1.m1.1.1.8.3.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.3.1"></times><ci id="S3.SS2.SSS3.p4.1.m1.1.1.8.3.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.3.2">𝑉</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.8.3.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.8.3.3">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.1.m1.1c">MMMS\text{-}BA_{VL}</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.2" class="ltx_text" style="font-size:90%;"> in equation </span><a href="#S3.E7" title="In 3.2.3 Multiplicative Gating and Concatenation ‣ 3.2 Multi-modal Multi-sequence - Bi-modal Attention (MMMS-BA) Framework ‣ 3 Methodology ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">7</span></a><span id="S3.SS2.SSS3.p4.10.3" class="ltx_text" style="font-size:90%;">, we follow the same procedure to compute </span><math id="S3.SS2.SSS3.p4.2.m2.1" class="ltx_Math" alttext="MMMS\text{-}BA_{AV}" display="inline"><semantics id="S3.SS2.SSS3.p4.2.m2.1a"><mrow id="S3.SS2.SSS3.p4.2.m2.1.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.2.m2.1.1.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.2.m2.1.1.1a" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.4" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.2.m2.1.1.1b" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.5" xref="S3.SS2.SSS3.p4.2.m2.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.2.m2.1.1.1c" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.cmml">​</mo><mtext mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.6" xref="S3.SS2.SSS3.p4.2.m2.1.1.6a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.2.m2.1.1.1d" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.7" xref="S3.SS2.SSS3.p4.2.m2.1.1.7.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.2.m2.1.1.1e" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS3.p4.2.m2.1.1.8" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.8.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.2.cmml">A</mi><mrow id="S3.SS2.SSS3.p4.2.m2.1.1.8.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.3.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.8.3.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.2.m2.1.1.8.3.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.8.3.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.3.3.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.2.m2.1b"><apply id="S3.SS2.SSS3.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1"><times id="S3.SS2.SSS3.p4.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.1"></times><ci id="S3.SS2.SSS3.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.2">𝑀</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3">𝑀</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.4.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4">𝑀</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.5.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.5">𝑆</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.6a.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.6"><mtext mathsize="90%" id="S3.SS2.SSS3.p4.2.m2.1.1.6.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.6">-</mtext></ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.7.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.7">𝐵</ci><apply id="S3.SS2.SSS3.p4.2.m2.1.1.8.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.8"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.2.m2.1.1.8.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.8">subscript</csymbol><ci id="S3.SS2.SSS3.p4.2.m2.1.1.8.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.2">𝐴</ci><apply id="S3.SS2.SSS3.p4.2.m2.1.1.8.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.3"><times id="S3.SS2.SSS3.p4.2.m2.1.1.8.3.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.3.1"></times><ci id="S3.SS2.SSS3.p4.2.m2.1.1.8.3.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.3.2">𝐴</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.8.3.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.8.3.3">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.2.m2.1c">MMMS\text{-}BA_{AV}</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.4" class="ltx_text" style="font-size:90%;">, and </span><math id="S3.SS2.SSS3.p4.3.m3.1" class="ltx_Math" alttext="MMMS\text{-}BA_{AL}" display="inline"><semantics id="S3.SS2.SSS3.p4.3.m3.1a"><mrow id="S3.SS2.SSS3.p4.3.m3.1.1" xref="S3.SS2.SSS3.p4.3.m3.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.2" xref="S3.SS2.SSS3.p4.3.m3.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.3.m3.1.1.1" xref="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.3" xref="S3.SS2.SSS3.p4.3.m3.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.3.m3.1.1.1a" xref="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.4" xref="S3.SS2.SSS3.p4.3.m3.1.1.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.3.m3.1.1.1b" xref="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.5" xref="S3.SS2.SSS3.p4.3.m3.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.3.m3.1.1.1c" xref="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml">​</mo><mtext mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.6" xref="S3.SS2.SSS3.p4.3.m3.1.1.6a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.3.m3.1.1.1d" xref="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.7" xref="S3.SS2.SSS3.p4.3.m3.1.1.7.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.3.m3.1.1.1e" xref="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS3.p4.3.m3.1.1.8" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.8.2" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.2.cmml">A</mi><mrow id="S3.SS2.SSS3.p4.3.m3.1.1.8.3" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.3.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.8.3.2" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.3.m3.1.1.8.3.1" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.8.3.3" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.3.3.cmml">L</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.3.m3.1b"><apply id="S3.SS2.SSS3.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1"><times id="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.1"></times><ci id="S3.SS2.SSS3.p4.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.2">𝑀</ci><ci id="S3.SS2.SSS3.p4.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.3">𝑀</ci><ci id="S3.SS2.SSS3.p4.3.m3.1.1.4.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.4">𝑀</ci><ci id="S3.SS2.SSS3.p4.3.m3.1.1.5.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.5">𝑆</ci><ci id="S3.SS2.SSS3.p4.3.m3.1.1.6a.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.6"><mtext mathsize="90%" id="S3.SS2.SSS3.p4.3.m3.1.1.6.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.6">-</mtext></ci><ci id="S3.SS2.SSS3.p4.3.m3.1.1.7.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.7">𝐵</ci><apply id="S3.SS2.SSS3.p4.3.m3.1.1.8.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.8"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.3.m3.1.1.8.1.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.8">subscript</csymbol><ci id="S3.SS2.SSS3.p4.3.m3.1.1.8.2.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.2">𝐴</ci><apply id="S3.SS2.SSS3.p4.3.m3.1.1.8.3.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.3"><times id="S3.SS2.SSS3.p4.3.m3.1.1.8.3.1.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.3.1"></times><ci id="S3.SS2.SSS3.p4.3.m3.1.1.8.3.2.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.3.2">𝐴</ci><ci id="S3.SS2.SSS3.p4.3.m3.1.1.8.3.3.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.8.3.3">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.3.m3.1c">MMMS\text{-}BA_{AL}</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.5" class="ltx_text" style="font-size:90%;">.
Finally, motivated by the residual skip connection network, the pairwise attention representations </span><math id="S3.SS2.SSS3.p4.4.m4.1" class="ltx_Math" alttext="MMMS\text{-}BA_{VL}" display="inline"><semantics id="S3.SS2.SSS3.p4.4.m4.1a"><mrow id="S3.SS2.SSS3.p4.4.m4.1.1" xref="S3.SS2.SSS3.p4.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.2" xref="S3.SS2.SSS3.p4.4.m4.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.4.m4.1.1.1" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.3" xref="S3.SS2.SSS3.p4.4.m4.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.4.m4.1.1.1a" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.4" xref="S3.SS2.SSS3.p4.4.m4.1.1.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.4.m4.1.1.1b" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.5" xref="S3.SS2.SSS3.p4.4.m4.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.4.m4.1.1.1c" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.cmml">​</mo><mtext mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.6" xref="S3.SS2.SSS3.p4.4.m4.1.1.6a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.4.m4.1.1.1d" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.7" xref="S3.SS2.SSS3.p4.4.m4.1.1.7.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.4.m4.1.1.1e" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS3.p4.4.m4.1.1.8" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.8.2" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.2.cmml">A</mi><mrow id="S3.SS2.SSS3.p4.4.m4.1.1.8.3" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.3.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.8.3.2" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.4.m4.1.1.8.3.1" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.8.3.3" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.3.3.cmml">L</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.4.m4.1b"><apply id="S3.SS2.SSS3.p4.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1"><times id="S3.SS2.SSS3.p4.4.m4.1.1.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.1"></times><ci id="S3.SS2.SSS3.p4.4.m4.1.1.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.2">𝑀</ci><ci id="S3.SS2.SSS3.p4.4.m4.1.1.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.3">𝑀</ci><ci id="S3.SS2.SSS3.p4.4.m4.1.1.4.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.4">𝑀</ci><ci id="S3.SS2.SSS3.p4.4.m4.1.1.5.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.5">𝑆</ci><ci id="S3.SS2.SSS3.p4.4.m4.1.1.6a.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.6"><mtext mathsize="90%" id="S3.SS2.SSS3.p4.4.m4.1.1.6.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.6">-</mtext></ci><ci id="S3.SS2.SSS3.p4.4.m4.1.1.7.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.7">𝐵</ci><apply id="S3.SS2.SSS3.p4.4.m4.1.1.8.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.8"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.4.m4.1.1.8.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.8">subscript</csymbol><ci id="S3.SS2.SSS3.p4.4.m4.1.1.8.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.2">𝐴</ci><apply id="S3.SS2.SSS3.p4.4.m4.1.1.8.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.3"><times id="S3.SS2.SSS3.p4.4.m4.1.1.8.3.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.3.1"></times><ci id="S3.SS2.SSS3.p4.4.m4.1.1.8.3.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.3.2">𝑉</ci><ci id="S3.SS2.SSS3.p4.4.m4.1.1.8.3.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.8.3.3">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.4.m4.1c">MMMS\text{-}BA_{VL}</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.6" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS2.SSS3.p4.5.m5.1" class="ltx_Math" alttext="MMMS\text{-}BA_{AV}" display="inline"><semantics id="S3.SS2.SSS3.p4.5.m5.1a"><mrow id="S3.SS2.SSS3.p4.5.m5.1.1" xref="S3.SS2.SSS3.p4.5.m5.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.2" xref="S3.SS2.SSS3.p4.5.m5.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.5.m5.1.1.1" xref="S3.SS2.SSS3.p4.5.m5.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.3" xref="S3.SS2.SSS3.p4.5.m5.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.5.m5.1.1.1a" xref="S3.SS2.SSS3.p4.5.m5.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.4" xref="S3.SS2.SSS3.p4.5.m5.1.1.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.5.m5.1.1.1b" xref="S3.SS2.SSS3.p4.5.m5.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.5" xref="S3.SS2.SSS3.p4.5.m5.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.5.m5.1.1.1c" xref="S3.SS2.SSS3.p4.5.m5.1.1.1.cmml">​</mo><mtext mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.6" xref="S3.SS2.SSS3.p4.5.m5.1.1.6a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.5.m5.1.1.1d" xref="S3.SS2.SSS3.p4.5.m5.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.7" xref="S3.SS2.SSS3.p4.5.m5.1.1.7.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.5.m5.1.1.1e" xref="S3.SS2.SSS3.p4.5.m5.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS3.p4.5.m5.1.1.8" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.8.2" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.2.cmml">A</mi><mrow id="S3.SS2.SSS3.p4.5.m5.1.1.8.3" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.3.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.8.3.2" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.5.m5.1.1.8.3.1" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.8.3.3" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.3.3.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.5.m5.1b"><apply id="S3.SS2.SSS3.p4.5.m5.1.1.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1"><times id="S3.SS2.SSS3.p4.5.m5.1.1.1.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.1"></times><ci id="S3.SS2.SSS3.p4.5.m5.1.1.2.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.2">𝑀</ci><ci id="S3.SS2.SSS3.p4.5.m5.1.1.3.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.3">𝑀</ci><ci id="S3.SS2.SSS3.p4.5.m5.1.1.4.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.4">𝑀</ci><ci id="S3.SS2.SSS3.p4.5.m5.1.1.5.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.5">𝑆</ci><ci id="S3.SS2.SSS3.p4.5.m5.1.1.6a.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.6"><mtext mathsize="90%" id="S3.SS2.SSS3.p4.5.m5.1.1.6.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.6">-</mtext></ci><ci id="S3.SS2.SSS3.p4.5.m5.1.1.7.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.7">𝐵</ci><apply id="S3.SS2.SSS3.p4.5.m5.1.1.8.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.8"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.5.m5.1.1.8.1.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.8">subscript</csymbol><ci id="S3.SS2.SSS3.p4.5.m5.1.1.8.2.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.2">𝐴</ci><apply id="S3.SS2.SSS3.p4.5.m5.1.1.8.3.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.3"><times id="S3.SS2.SSS3.p4.5.m5.1.1.8.3.1.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.3.1"></times><ci id="S3.SS2.SSS3.p4.5.m5.1.1.8.3.2.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.3.2">𝐴</ci><ci id="S3.SS2.SSS3.p4.5.m5.1.1.8.3.3.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.8.3.3">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.5.m5.1c">MMMS\text{-}BA_{AV}</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.7" class="ltx_text" style="font-size:90%;">, and </span><math id="S3.SS2.SSS3.p4.6.m6.1" class="ltx_Math" alttext="MMMS\text{-}BA_{AL}" display="inline"><semantics id="S3.SS2.SSS3.p4.6.m6.1a"><mrow id="S3.SS2.SSS3.p4.6.m6.1.1" xref="S3.SS2.SSS3.p4.6.m6.1.1.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.2" xref="S3.SS2.SSS3.p4.6.m6.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.6.m6.1.1.1" xref="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.3" xref="S3.SS2.SSS3.p4.6.m6.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.6.m6.1.1.1a" xref="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.4" xref="S3.SS2.SSS3.p4.6.m6.1.1.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.6.m6.1.1.1b" xref="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.5" xref="S3.SS2.SSS3.p4.6.m6.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.6.m6.1.1.1c" xref="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml">​</mo><mtext mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.6" xref="S3.SS2.SSS3.p4.6.m6.1.1.6a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.6.m6.1.1.1d" xref="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.7" xref="S3.SS2.SSS3.p4.6.m6.1.1.7.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.6.m6.1.1.1e" xref="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS3.p4.6.m6.1.1.8" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.8.2" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.2.cmml">A</mi><mrow id="S3.SS2.SSS3.p4.6.m6.1.1.8.3" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.3.cmml"><mi mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.8.3.2" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.6.m6.1.1.8.3.1" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.8.3.3" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.3.3.cmml">L</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.6.m6.1b"><apply id="S3.SS2.SSS3.p4.6.m6.1.1.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1"><times id="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.1"></times><ci id="S3.SS2.SSS3.p4.6.m6.1.1.2.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.2">𝑀</ci><ci id="S3.SS2.SSS3.p4.6.m6.1.1.3.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.3">𝑀</ci><ci id="S3.SS2.SSS3.p4.6.m6.1.1.4.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.4">𝑀</ci><ci id="S3.SS2.SSS3.p4.6.m6.1.1.5.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.5">𝑆</ci><ci id="S3.SS2.SSS3.p4.6.m6.1.1.6a.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.6"><mtext mathsize="90%" id="S3.SS2.SSS3.p4.6.m6.1.1.6.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.6">-</mtext></ci><ci id="S3.SS2.SSS3.p4.6.m6.1.1.7.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.7">𝐵</ci><apply id="S3.SS2.SSS3.p4.6.m6.1.1.8.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.8"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.6.m6.1.1.8.1.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.8">subscript</csymbol><ci id="S3.SS2.SSS3.p4.6.m6.1.1.8.2.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.2">𝐴</ci><apply id="S3.SS2.SSS3.p4.6.m6.1.1.8.3.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.3"><times id="S3.SS2.SSS3.p4.6.m6.1.1.8.3.1.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.3.1"></times><ci id="S3.SS2.SSS3.p4.6.m6.1.1.8.3.2.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.3.2">𝐴</ci><ci id="S3.SS2.SSS3.p4.6.m6.1.1.8.3.3.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.8.3.3">𝐿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.6.m6.1c">MMMS\text{-}BA_{AL}</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.8" class="ltx_text" style="font-size:90%;"> are concatenated with the individual modalities (</span><math id="S3.SS2.SSS3.p4.7.m7.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.SSS3.p4.7.m7.1a"><mi mathsize="90%" id="S3.SS2.SSS3.p4.7.m7.1.1" xref="S3.SS2.SSS3.p4.7.m7.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.7.m7.1b"><ci id="S3.SS2.SSS3.p4.7.m7.1.1.cmml" xref="S3.SS2.SSS3.p4.7.m7.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.7.m7.1c">V</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.9" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS2.SSS3.p4.8.m8.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.SSS3.p4.8.m8.1a"><mi mathsize="90%" id="S3.SS2.SSS3.p4.8.m8.1.1" xref="S3.SS2.SSS3.p4.8.m8.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.8.m8.1b"><ci id="S3.SS2.SSS3.p4.8.m8.1.1.cmml" xref="S3.SS2.SSS3.p4.8.m8.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.8.m8.1c">A</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.10" class="ltx_text" style="font-size:90%;">, and </span><math id="S3.SS2.SSS3.p4.9.m9.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS2.SSS3.p4.9.m9.1a"><mi mathsize="90%" id="S3.SS2.SSS3.p4.9.m9.1.1" xref="S3.SS2.SSS3.p4.9.m9.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.9.m9.1b"><ci id="S3.SS2.SSS3.p4.9.m9.1.1.cmml" xref="S3.SS2.SSS3.p4.9.m9.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.9.m9.1c">L</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.11" class="ltx_text" style="font-size:90%;">) to increase gradient flow to the lower layers. This concatenated feature vector </span><math id="S3.SS2.SSS3.p4.10.m10.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.SSS3.p4.10.m10.1a"><mi mathsize="90%" id="S3.SS2.SSS3.p4.10.m10.1.1" xref="S3.SS2.SSS3.p4.10.m10.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.10.m10.1b"><ci id="S3.SS2.SSS3.p4.10.m10.1.1.cmml" xref="S3.SS2.SSS3.p4.10.m10.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.10.m10.1c">W</annotation></semantics></math><span id="S3.SS2.SSS3.p4.10.12" class="ltx_text" style="font-size:90%;"> (see Figure </span><a href="#S2.F2" title="Figure 2 ‣ 2.1 Audio-Visual Deepfake Detection ‣ 2 Related Work ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S3.SS2.SSS3.p4.10.13" class="ltx_text" style="font-size:90%;">) is then used for deepfake detection.</span></p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Localization</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.8" class="ltx_p"><span id="S3.SS3.p1.8.1" class="ltx_text" style="font-size:90%;">For the sequences classified as fake, their corresponding timestamp in the input video are localized as the fake segments. The localization of the segments is represented as </span><math id="S3.SS3.p1.1.m1.4" class="ltx_Math" alttext="Y=\{y_{1},y_{2},...,y_{N_{f}}\}" display="inline"><semantics id="S3.SS3.p1.1.m1.4a"><mrow id="S3.SS3.p1.1.m1.4.4" xref="S3.SS3.p1.1.m1.4.4.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.4.4.5" xref="S3.SS3.p1.1.m1.4.4.5.cmml">Y</mi><mo mathsize="90%" id="S3.SS3.p1.1.m1.4.4.4" xref="S3.SS3.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS3.p1.1.m1.4.4.3.3" xref="S3.SS3.p1.1.m1.4.4.3.4.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.1.m1.4.4.3.3.4" xref="S3.SS3.p1.1.m1.4.4.3.4.cmml">{</mo><msub id="S3.SS3.p1.1.m1.2.2.1.1.1" xref="S3.SS3.p1.1.m1.2.2.1.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.2.2.1.1.1.2" xref="S3.SS3.p1.1.m1.2.2.1.1.1.2.cmml">y</mi><mn mathsize="90%" id="S3.SS3.p1.1.m1.2.2.1.1.1.3" xref="S3.SS3.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo mathsize="90%" id="S3.SS3.p1.1.m1.4.4.3.3.5" xref="S3.SS3.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS3.p1.1.m1.3.3.2.2.2" xref="S3.SS3.p1.1.m1.3.3.2.2.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.3.3.2.2.2.2" xref="S3.SS3.p1.1.m1.3.3.2.2.2.2.cmml">y</mi><mn mathsize="90%" id="S3.SS3.p1.1.m1.3.3.2.2.2.3" xref="S3.SS3.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo mathsize="90%" id="S3.SS3.p1.1.m1.4.4.3.3.6" xref="S3.SS3.p1.1.m1.4.4.3.4.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">…</mi><mo mathsize="90%" id="S3.SS3.p1.1.m1.4.4.3.3.7" xref="S3.SS3.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS3.p1.1.m1.4.4.3.3.3" xref="S3.SS3.p1.1.m1.4.4.3.3.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.4.4.3.3.3.2" xref="S3.SS3.p1.1.m1.4.4.3.3.3.2.cmml">y</mi><msub id="S3.SS3.p1.1.m1.4.4.3.3.3.3" xref="S3.SS3.p1.1.m1.4.4.3.3.3.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.1.m1.4.4.3.3.3.3.2" xref="S3.SS3.p1.1.m1.4.4.3.3.3.3.2.cmml">N</mi><mi mathsize="90%" id="S3.SS3.p1.1.m1.4.4.3.3.3.3.3" xref="S3.SS3.p1.1.m1.4.4.3.3.3.3.3.cmml">f</mi></msub></msub><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.1.m1.4.4.3.3.8" xref="S3.SS3.p1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.4b"><apply id="S3.SS3.p1.1.m1.4.4.cmml" xref="S3.SS3.p1.1.m1.4.4"><eq id="S3.SS3.p1.1.m1.4.4.4.cmml" xref="S3.SS3.p1.1.m1.4.4.4"></eq><ci id="S3.SS3.p1.1.m1.4.4.5.cmml" xref="S3.SS3.p1.1.m1.4.4.5">𝑌</ci><set id="S3.SS3.p1.1.m1.4.4.3.4.cmml" xref="S3.SS3.p1.1.m1.4.4.3.3"><apply id="S3.SS3.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS3.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.2.2.1.1.1.2">𝑦</ci><cn type="integer" id="S3.SS3.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS3.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS3.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS3.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS3.p1.1.m1.3.3.2.2.2.2">𝑦</ci><cn type="integer" id="S3.SS3.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS3.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">…</ci><apply id="S3.SS3.p1.1.m1.4.4.3.3.3.cmml" xref="S3.SS3.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS3.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS3.p1.1.m1.4.4.3.3.3.2">𝑦</ci><apply id="S3.SS3.p1.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS3.p1.1.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.4.4.3.3.3.3.1.cmml" xref="S3.SS3.p1.1.m1.4.4.3.3.3.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.4.4.3.3.3.3.2.cmml" xref="S3.SS3.p1.1.m1.4.4.3.3.3.3.2">𝑁</ci><ci id="S3.SS3.p1.1.m1.4.4.3.3.3.3.3.cmml" xref="S3.SS3.p1.1.m1.4.4.3.3.3.3.3">𝑓</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.4c">Y=\{y_{1},y_{2},...,y_{N_{f}}\}</annotation></semantics></math><span id="S3.SS3.p1.8.2" class="ltx_text" style="font-size:90%;"> where </span><math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="N_{f}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">N</mi><mi mathsize="90%" id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝑁</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">N_{f}</annotation></semantics></math><span id="S3.SS3.p1.8.3" class="ltx_text" style="font-size:90%;"> are the number of fake segments. For a fake sequence </span><math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi mathsize="90%" id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">i</annotation></semantics></math><span id="S3.SS3.p1.8.4" class="ltx_text" style="font-size:90%;">, </span><math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><msub id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">y</mi><mi mathsize="90%" id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">𝑦</ci><ci id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">y_{i}</annotation></semantics></math><span id="S3.SS3.p1.8.5" class="ltx_text" style="font-size:90%;"> represents the </span><math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="i^{th}" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><msup id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.5.m5.1.1.2" xref="S3.SS3.p1.5.m5.1.1.2.cmml">i</mi><mrow id="S3.SS3.p1.5.m5.1.1.3" xref="S3.SS3.p1.5.m5.1.1.3.cmml"><mi mathsize="90%" id="S3.SS3.p1.5.m5.1.1.3.2" xref="S3.SS3.p1.5.m5.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.5.m5.1.1.3.1" xref="S3.SS3.p1.5.m5.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS3.p1.5.m5.1.1.3.3" xref="S3.SS3.p1.5.m5.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><apply id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">superscript</csymbol><ci id="S3.SS3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.2">𝑖</ci><apply id="S3.SS3.p1.5.m5.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.3"><times id="S3.SS3.p1.5.m5.1.1.3.1.cmml" xref="S3.SS3.p1.5.m5.1.1.3.1"></times><ci id="S3.SS3.p1.5.m5.1.1.3.2.cmml" xref="S3.SS3.p1.5.m5.1.1.3.2">𝑡</ci><ci id="S3.SS3.p1.5.m5.1.1.3.3.cmml" xref="S3.SS3.p1.5.m5.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">i^{th}</annotation></semantics></math><span id="S3.SS3.p1.8.6" class="ltx_text" style="font-size:90%;"> sequence output. Each instance </span><math id="S3.SS3.p1.6.m6.2" class="ltx_Math" alttext="y_{i}=(s_{i},e_{i})" display="inline"><semantics id="S3.SS3.p1.6.m6.2a"><mrow id="S3.SS3.p1.6.m6.2.2" xref="S3.SS3.p1.6.m6.2.2.cmml"><msub id="S3.SS3.p1.6.m6.2.2.4" xref="S3.SS3.p1.6.m6.2.2.4.cmml"><mi mathsize="90%" id="S3.SS3.p1.6.m6.2.2.4.2" xref="S3.SS3.p1.6.m6.2.2.4.2.cmml">y</mi><mi mathsize="90%" id="S3.SS3.p1.6.m6.2.2.4.3" xref="S3.SS3.p1.6.m6.2.2.4.3.cmml">i</mi></msub><mo mathsize="90%" id="S3.SS3.p1.6.m6.2.2.3" xref="S3.SS3.p1.6.m6.2.2.3.cmml">=</mo><mrow id="S3.SS3.p1.6.m6.2.2.2.2" xref="S3.SS3.p1.6.m6.2.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.6.m6.2.2.2.2.3" xref="S3.SS3.p1.6.m6.2.2.2.3.cmml">(</mo><msub id="S3.SS3.p1.6.m6.1.1.1.1.1" xref="S3.SS3.p1.6.m6.1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.6.m6.1.1.1.1.1.2" xref="S3.SS3.p1.6.m6.1.1.1.1.1.2.cmml">s</mi><mi mathsize="90%" id="S3.SS3.p1.6.m6.1.1.1.1.1.3" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3.cmml">i</mi></msub><mo mathsize="90%" id="S3.SS3.p1.6.m6.2.2.2.2.4" xref="S3.SS3.p1.6.m6.2.2.2.3.cmml">,</mo><msub id="S3.SS3.p1.6.m6.2.2.2.2.2" xref="S3.SS3.p1.6.m6.2.2.2.2.2.cmml"><mi mathsize="90%" id="S3.SS3.p1.6.m6.2.2.2.2.2.2" xref="S3.SS3.p1.6.m6.2.2.2.2.2.2.cmml">e</mi><mi mathsize="90%" id="S3.SS3.p1.6.m6.2.2.2.2.2.3" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3.cmml">i</mi></msub><mo maxsize="90%" minsize="90%" id="S3.SS3.p1.6.m6.2.2.2.2.5" xref="S3.SS3.p1.6.m6.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.2b"><apply id="S3.SS3.p1.6.m6.2.2.cmml" xref="S3.SS3.p1.6.m6.2.2"><eq id="S3.SS3.p1.6.m6.2.2.3.cmml" xref="S3.SS3.p1.6.m6.2.2.3"></eq><apply id="S3.SS3.p1.6.m6.2.2.4.cmml" xref="S3.SS3.p1.6.m6.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.2.2.4.1.cmml" xref="S3.SS3.p1.6.m6.2.2.4">subscript</csymbol><ci id="S3.SS3.p1.6.m6.2.2.4.2.cmml" xref="S3.SS3.p1.6.m6.2.2.4.2">𝑦</ci><ci id="S3.SS3.p1.6.m6.2.2.4.3.cmml" xref="S3.SS3.p1.6.m6.2.2.4.3">𝑖</ci></apply><interval closure="open" id="S3.SS3.p1.6.m6.2.2.2.3.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2"><apply id="S3.SS3.p1.6.m6.1.1.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m6.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.2">𝑠</ci><ci id="S3.SS3.p1.6.m6.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS3.p1.6.m6.2.2.2.2.2.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.6.m6.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2.2">𝑒</ci><ci id="S3.SS3.p1.6.m6.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.6.m6.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.2c">y_{i}=(s_{i},e_{i})</annotation></semantics></math><span id="S3.SS3.p1.8.7" class="ltx_text" style="font-size:90%;"> is defined by its starting time </span><math id="S3.SS3.p1.7.m7.1" class="ltx_Math" alttext="s_{i}" display="inline"><semantics id="S3.SS3.p1.7.m7.1a"><msub id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.7.m7.1.1.2" xref="S3.SS3.p1.7.m7.1.1.2.cmml">s</mi><mi mathsize="90%" id="S3.SS3.p1.7.m7.1.1.3" xref="S3.SS3.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><apply id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2">𝑠</ci><ci id="S3.SS3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">s_{i}</annotation></semantics></math><span id="S3.SS3.p1.8.8" class="ltx_text" style="font-size:90%;"> and ending time </span><math id="S3.SS3.p1.8.m8.1" class="ltx_Math" alttext="e_{i}" display="inline"><semantics id="S3.SS3.p1.8.m8.1a"><msub id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml"><mi mathsize="90%" id="S3.SS3.p1.8.m8.1.1.2" xref="S3.SS3.p1.8.m8.1.1.2.cmml">e</mi><mi mathsize="90%" id="S3.SS3.p1.8.m8.1.1.3" xref="S3.SS3.p1.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><apply id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.8.m8.1.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p1.8.m8.1.1.2.cmml" xref="S3.SS3.p1.8.m8.1.1.2">𝑒</ci><ci id="S3.SS3.p1.8.m8.1.1.3.cmml" xref="S3.SS3.p1.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">e_{i}</annotation></semantics></math><span id="S3.SS3.p1.8.9" class="ltx_text" style="font-size:90%;"> of the sequence. These segments are further processed using Non-Maximum Suppression (NMS)  </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS3.p1.8.10.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S3.SS3.p1.8.11.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS3.p1.8.12" class="ltx_text" style="font-size:90%;"> to remove highly overlapping instances, leading to the final localization timestamps.</span></p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Loss Function</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p"><span id="S3.SS4.p1.1.1" class="ltx_text" style="font-size:90%;">The model’s overall learning process involves minimizing the combined loss as follows:</span></p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.1" class="ltx_Math" alttext="\mathcal{L}=\sum_{N}\left(\mathcal{L}_{cls}+\lambda_{reg}\mathds{1}_{c_{i}}\mathcal{L}_{reg}\right)/N_{f}," display="block"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E8.m1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.3.cmml">ℒ</mi><mo mathsize="90%" rspace="0.111em" id="S3.E8.m1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E8.m1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.cmml"><munder id="S3.E8.m1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" rspace="0em" stretchy="true" id="S3.E8.m1.1.1.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.1.2.2.cmml">∑</mo><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.1.2.3.cmml">N</mi></munder><mrow id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">ℒ</mi><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1a" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.4" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.4.cmml">s</mi></mrow></msub><mo mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.cmml"><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">λ</mi><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml">​</mo><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.1a" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml">​</mo><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.4" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">​</mo><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mn mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">𝟙</mn><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml">c</mi><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml">i</mi></msub></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.1a" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">​</mo><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.2.cmml">ℒ</mi><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.cmml"><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.1.cmml">​</mo><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.1a" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.1.cmml">​</mo><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.4" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.4.cmml">g</mi></mrow></msub></mrow></mrow><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo maxsize="90%" minsize="90%" stretchy="true" symmetric="true" id="S3.E8.m1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.2.cmml">/</mo><msub id="S3.E8.m1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.3.cmml"><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.1.1.3.2.cmml">N</mi><mi mathsize="90%" id="S3.E8.m1.1.1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.1.1.3.3.cmml">f</mi></msub></mrow></mrow></mrow><mo mathsize="90%" id="S3.E8.m1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"><eq id="S3.E8.m1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.2"></eq><ci id="S3.E8.m1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.3">ℒ</ci><apply id="S3.E8.m1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1"><apply id="S3.E8.m1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E8.m1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.2.2"></sum><ci id="S3.E8.m1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.2.3">𝑁</ci></apply><apply id="S3.E8.m1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1"><divide id="S3.E8.m1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2"></divide><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1"><plus id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.2">ℒ</ci><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3"><times id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.2">𝑐</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.3">𝑙</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.4">𝑠</ci></apply></apply><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.1"></times><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.2">𝜆</ci><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3"><times id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.1"></times><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.2">𝑟</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.3">𝑒</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.4.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.3.4">𝑔</ci></apply></apply><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3">subscript</csymbol><cn type="integer" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.2">1</cn><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.2">𝑐</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.3">𝑖</ci></apply></apply><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.2">ℒ</ci><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3"><times id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.1"></times><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.2">𝑟</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.3">𝑒</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.4.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.4.3.4">𝑔</ci></apply></apply></apply></apply><apply id="S3.E8.m1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3.2">𝑁</ci><ci id="S3.E8.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3.3">𝑓</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">\mathcal{L}=\sum_{N}\left(\mathcal{L}_{cls}+\lambda_{reg}\mathds{1}_{c_{i}}\mathcal{L}_{reg}\right)/N_{f},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.8" class="ltx_p"><span id="S3.SS4.p2.8.1" class="ltx_text" style="font-size:90%;">where </span><math id="S3.SS4.p2.1.m1.1" class="ltx_Math" alttext="N_{f}" display="inline"><semantics id="S3.SS4.p2.1.m1.1a"><msub id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">N</mi><mi mathsize="90%" id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">𝑁</ci><ci id="S3.SS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">N_{f}</annotation></semantics></math><span id="S3.SS4.p2.8.2" class="ltx_text" style="font-size:90%;"> is the total number of fake sequences. </span><math id="S3.SS4.p2.2.m2.1" class="ltx_Math" alttext="\mathds{1}_{c_{i}}" display="inline"><semantics id="S3.SS4.p2.2.m2.1a"><msub id="S3.SS4.p2.2.m2.1.1" xref="S3.SS4.p2.2.m2.1.1.cmml"><mn mathsize="90%" id="S3.SS4.p2.2.m2.1.1.2" xref="S3.SS4.p2.2.m2.1.1.2.cmml">𝟙</mn><msub id="S3.SS4.p2.2.m2.1.1.3" xref="S3.SS4.p2.2.m2.1.1.3.cmml"><mi mathsize="90%" id="S3.SS4.p2.2.m2.1.1.3.2" xref="S3.SS4.p2.2.m2.1.1.3.2.cmml">c</mi><mi mathsize="90%" id="S3.SS4.p2.2.m2.1.1.3.3" xref="S3.SS4.p2.2.m2.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.2.m2.1b"><apply id="S3.SS4.p2.2.m2.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.1.1.1.cmml" xref="S3.SS4.p2.2.m2.1.1">subscript</csymbol><cn type="integer" id="S3.SS4.p2.2.m2.1.1.2.cmml" xref="S3.SS4.p2.2.m2.1.1.2">1</cn><apply id="S3.SS4.p2.2.m2.1.1.3.cmml" xref="S3.SS4.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.p2.2.m2.1.1.3.1.cmml" xref="S3.SS4.p2.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS4.p2.2.m2.1.1.3.2.cmml" xref="S3.SS4.p2.2.m2.1.1.3.2">𝑐</ci><ci id="S3.SS4.p2.2.m2.1.1.3.3.cmml" xref="S3.SS4.p2.2.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.2.m2.1c">\mathds{1}_{c_{i}}</annotation></semantics></math><span id="S3.SS4.p2.8.3" class="ltx_text" style="font-size:90%;"> is an indicator function that denotes if a sequence </span><math id="S3.SS4.p2.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS4.p2.3.m3.1a"><mi mathsize="90%" id="S3.SS4.p2.3.m3.1.1" xref="S3.SS4.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.3.m3.1b"><ci id="S3.SS4.p2.3.m3.1.1.cmml" xref="S3.SS4.p2.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.3.m3.1c">i</annotation></semantics></math><span id="S3.SS4.p2.8.4" class="ltx_text" style="font-size:90%;"> is fake with value equal to </span><math id="S3.SS4.p2.4.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS4.p2.4.m4.1a"><mn mathsize="90%" id="S3.SS4.p2.4.m4.1.1" xref="S3.SS4.p2.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.4.m4.1b"><cn type="integer" id="S3.SS4.p2.4.m4.1.1.cmml" xref="S3.SS4.p2.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.4.m4.1c">1</annotation></semantics></math><span id="S3.SS4.p2.8.5" class="ltx_text" style="font-size:90%;"> otherwise </span><math id="S3.SS4.p2.5.m5.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.SS4.p2.5.m5.1a"><mn mathsize="90%" id="S3.SS4.p2.5.m5.1.1" xref="S3.SS4.p2.5.m5.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.5.m5.1b"><cn type="integer" id="S3.SS4.p2.5.m5.1.1.cmml" xref="S3.SS4.p2.5.m5.1.1">0</cn></annotation-xml></semantics></math><span id="S3.SS4.p2.8.6" class="ltx_text" style="font-size:90%;">. </span><math id="S3.SS4.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS4.p2.6.m6.1a"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.SS4.p2.6.m6.1.1" xref="S3.SS4.p2.6.m6.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.6.m6.1b"><ci id="S3.SS4.p2.6.m6.1.1.cmml" xref="S3.SS4.p2.6.m6.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.6.m6.1c">\mathcal{L}</annotation></semantics></math><span id="S3.SS4.p2.8.7" class="ltx_text" style="font-size:90%;"> is applied and averaged in all sequences during training. </span><math id="S3.SS4.p2.7.m7.1" class="ltx_Math" alttext="\lambda_{reg}" display="inline"><semantics id="S3.SS4.p2.7.m7.1a"><msub id="S3.SS4.p2.7.m7.1.1" xref="S3.SS4.p2.7.m7.1.1.cmml"><mi mathsize="90%" id="S3.SS4.p2.7.m7.1.1.2" xref="S3.SS4.p2.7.m7.1.1.2.cmml">λ</mi><mrow id="S3.SS4.p2.7.m7.1.1.3" xref="S3.SS4.p2.7.m7.1.1.3.cmml"><mi mathsize="90%" id="S3.SS4.p2.7.m7.1.1.3.2" xref="S3.SS4.p2.7.m7.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.7.m7.1.1.3.1" xref="S3.SS4.p2.7.m7.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p2.7.m7.1.1.3.3" xref="S3.SS4.p2.7.m7.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.7.m7.1.1.3.1a" xref="S3.SS4.p2.7.m7.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p2.7.m7.1.1.3.4" xref="S3.SS4.p2.7.m7.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.7.m7.1b"><apply id="S3.SS4.p2.7.m7.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.7.m7.1.1.1.cmml" xref="S3.SS4.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS4.p2.7.m7.1.1.2.cmml" xref="S3.SS4.p2.7.m7.1.1.2">𝜆</ci><apply id="S3.SS4.p2.7.m7.1.1.3.cmml" xref="S3.SS4.p2.7.m7.1.1.3"><times id="S3.SS4.p2.7.m7.1.1.3.1.cmml" xref="S3.SS4.p2.7.m7.1.1.3.1"></times><ci id="S3.SS4.p2.7.m7.1.1.3.2.cmml" xref="S3.SS4.p2.7.m7.1.1.3.2">𝑟</ci><ci id="S3.SS4.p2.7.m7.1.1.3.3.cmml" xref="S3.SS4.p2.7.m7.1.1.3.3">𝑒</ci><ci id="S3.SS4.p2.7.m7.1.1.3.4.cmml" xref="S3.SS4.p2.7.m7.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.7.m7.1c">\lambda_{reg}</annotation></semantics></math><span id="S3.SS4.p2.8.8" class="ltx_text" style="font-size:90%;"> is a coefficient that balances classification and regression loss. We set </span><math id="S3.SS4.p2.8.m8.1" class="ltx_Math" alttext="\lambda_{reg}=1" display="inline"><semantics id="S3.SS4.p2.8.m8.1a"><mrow id="S3.SS4.p2.8.m8.1.1" xref="S3.SS4.p2.8.m8.1.1.cmml"><msub id="S3.SS4.p2.8.m8.1.1.2" xref="S3.SS4.p2.8.m8.1.1.2.cmml"><mi mathsize="90%" id="S3.SS4.p2.8.m8.1.1.2.2" xref="S3.SS4.p2.8.m8.1.1.2.2.cmml">λ</mi><mrow id="S3.SS4.p2.8.m8.1.1.2.3" xref="S3.SS4.p2.8.m8.1.1.2.3.cmml"><mi mathsize="90%" id="S3.SS4.p2.8.m8.1.1.2.3.2" xref="S3.SS4.p2.8.m8.1.1.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.8.m8.1.1.2.3.1" xref="S3.SS4.p2.8.m8.1.1.2.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p2.8.m8.1.1.2.3.3" xref="S3.SS4.p2.8.m8.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p2.8.m8.1.1.2.3.1a" xref="S3.SS4.p2.8.m8.1.1.2.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p2.8.m8.1.1.2.3.4" xref="S3.SS4.p2.8.m8.1.1.2.3.4.cmml">g</mi></mrow></msub><mo mathsize="90%" id="S3.SS4.p2.8.m8.1.1.1" xref="S3.SS4.p2.8.m8.1.1.1.cmml">=</mo><mn mathsize="90%" id="S3.SS4.p2.8.m8.1.1.3" xref="S3.SS4.p2.8.m8.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.8.m8.1b"><apply id="S3.SS4.p2.8.m8.1.1.cmml" xref="S3.SS4.p2.8.m8.1.1"><eq id="S3.SS4.p2.8.m8.1.1.1.cmml" xref="S3.SS4.p2.8.m8.1.1.1"></eq><apply id="S3.SS4.p2.8.m8.1.1.2.cmml" xref="S3.SS4.p2.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS4.p2.8.m8.1.1.2.1.cmml" xref="S3.SS4.p2.8.m8.1.1.2">subscript</csymbol><ci id="S3.SS4.p2.8.m8.1.1.2.2.cmml" xref="S3.SS4.p2.8.m8.1.1.2.2">𝜆</ci><apply id="S3.SS4.p2.8.m8.1.1.2.3.cmml" xref="S3.SS4.p2.8.m8.1.1.2.3"><times id="S3.SS4.p2.8.m8.1.1.2.3.1.cmml" xref="S3.SS4.p2.8.m8.1.1.2.3.1"></times><ci id="S3.SS4.p2.8.m8.1.1.2.3.2.cmml" xref="S3.SS4.p2.8.m8.1.1.2.3.2">𝑟</ci><ci id="S3.SS4.p2.8.m8.1.1.2.3.3.cmml" xref="S3.SS4.p2.8.m8.1.1.2.3.3">𝑒</ci><ci id="S3.SS4.p2.8.m8.1.1.2.3.4.cmml" xref="S3.SS4.p2.8.m8.1.1.2.3.4">𝑔</ci></apply></apply><cn type="integer" id="S3.SS4.p2.8.m8.1.1.3.cmml" xref="S3.SS4.p2.8.m8.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.8.m8.1c">\lambda_{reg}=1</annotation></semantics></math><span id="S3.SS4.p2.8.9" class="ltx_text" style="font-size:90%;"> by default.</span></p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.3" class="ltx_p"><span id="S3.SS4.p3.3.1" class="ltx_text" style="font-size:90%;">Notably </span><math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{cls}" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><msub id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.SS4.p3.1.m1.1.1.2" xref="S3.SS4.p3.1.m1.1.1.2.cmml">ℒ</mi><mrow id="S3.SS4.p3.1.m1.1.1.3" xref="S3.SS4.p3.1.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.SS4.p3.1.m1.1.1.3.2" xref="S3.SS4.p3.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.3.1" xref="S3.SS4.p3.1.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p3.1.m1.1.1.3.3" xref="S3.SS4.p3.1.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.1.m1.1.1.3.1a" xref="S3.SS4.p3.1.m1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p3.1.m1.1.1.3.4" xref="S3.SS4.p3.1.m1.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><apply id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.1.m1.1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p3.1.m1.1.1.2.cmml" xref="S3.SS4.p3.1.m1.1.1.2">ℒ</ci><apply id="S3.SS4.p3.1.m1.1.1.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3"><times id="S3.SS4.p3.1.m1.1.1.3.1.cmml" xref="S3.SS4.p3.1.m1.1.1.3.1"></times><ci id="S3.SS4.p3.1.m1.1.1.3.2.cmml" xref="S3.SS4.p3.1.m1.1.1.3.2">𝑐</ci><ci id="S3.SS4.p3.1.m1.1.1.3.3.cmml" xref="S3.SS4.p3.1.m1.1.1.3.3">𝑙</ci><ci id="S3.SS4.p3.1.m1.1.1.3.4.cmml" xref="S3.SS4.p3.1.m1.1.1.3.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">\mathcal{L}_{cls}</annotation></semantics></math><span id="S3.SS4.p3.3.2" class="ltx_text" style="font-size:90%;"> uses focal loss </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS4.p3.3.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib34" title="" class="ltx_ref">34</a><span id="S3.SS4.p3.3.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS4.p3.3.5" class="ltx_text" style="font-size:90%;"> to classify sequences as real or fake. </span><math id="S3.SS4.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{reg}" display="inline"><semantics id="S3.SS4.p3.2.m2.1a"><msub id="S3.SS4.p3.2.m2.1.1" xref="S3.SS4.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.SS4.p3.2.m2.1.1.2" xref="S3.SS4.p3.2.m2.1.1.2.cmml">ℒ</mi><mrow id="S3.SS4.p3.2.m2.1.1.3" xref="S3.SS4.p3.2.m2.1.1.3.cmml"><mi mathsize="90%" id="S3.SS4.p3.2.m2.1.1.3.2" xref="S3.SS4.p3.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.2.m2.1.1.3.1" xref="S3.SS4.p3.2.m2.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p3.2.m2.1.1.3.3" xref="S3.SS4.p3.2.m2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.2.m2.1.1.3.1a" xref="S3.SS4.p3.2.m2.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p3.2.m2.1.1.3.4" xref="S3.SS4.p3.2.m2.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.2.m2.1b"><apply id="S3.SS4.p3.2.m2.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.2.m2.1.1.1.cmml" xref="S3.SS4.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p3.2.m2.1.1.2.cmml" xref="S3.SS4.p3.2.m2.1.1.2">ℒ</ci><apply id="S3.SS4.p3.2.m2.1.1.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3"><times id="S3.SS4.p3.2.m2.1.1.3.1.cmml" xref="S3.SS4.p3.2.m2.1.1.3.1"></times><ci id="S3.SS4.p3.2.m2.1.1.3.2.cmml" xref="S3.SS4.p3.2.m2.1.1.3.2">𝑟</ci><ci id="S3.SS4.p3.2.m2.1.1.3.3.cmml" xref="S3.SS4.p3.2.m2.1.1.3.3">𝑒</ci><ci id="S3.SS4.p3.2.m2.1.1.3.4.cmml" xref="S3.SS4.p3.2.m2.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.2.m2.1c">\mathcal{L}_{reg}</annotation></semantics></math><span id="S3.SS4.p3.3.6" class="ltx_text" style="font-size:90%;"> adopts a differentiable IoU loss from  </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS4.p3.3.7.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib49" title="" class="ltx_ref">49</a><span id="S3.SS4.p3.3.8.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.SS4.p3.3.9" class="ltx_text" style="font-size:90%;">. </span><math id="S3.SS4.p3.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{reg}" display="inline"><semantics id="S3.SS4.p3.3.m3.1a"><msub id="S3.SS4.p3.3.m3.1.1" xref="S3.SS4.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.SS4.p3.3.m3.1.1.2" xref="S3.SS4.p3.3.m3.1.1.2.cmml">ℒ</mi><mrow id="S3.SS4.p3.3.m3.1.1.3" xref="S3.SS4.p3.3.m3.1.1.3.cmml"><mi mathsize="90%" id="S3.SS4.p3.3.m3.1.1.3.2" xref="S3.SS4.p3.3.m3.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.3.m3.1.1.3.1" xref="S3.SS4.p3.3.m3.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p3.3.m3.1.1.3.3" xref="S3.SS4.p3.3.m3.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p3.3.m3.1.1.3.1a" xref="S3.SS4.p3.3.m3.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S3.SS4.p3.3.m3.1.1.3.4" xref="S3.SS4.p3.3.m3.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.3.m3.1b"><apply id="S3.SS4.p3.3.m3.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p3.3.m3.1.1.1.cmml" xref="S3.SS4.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p3.3.m3.1.1.2.cmml" xref="S3.SS4.p3.3.m3.1.1.2">ℒ</ci><apply id="S3.SS4.p3.3.m3.1.1.3.cmml" xref="S3.SS4.p3.3.m3.1.1.3"><times id="S3.SS4.p3.3.m3.1.1.3.1.cmml" xref="S3.SS4.p3.3.m3.1.1.3.1"></times><ci id="S3.SS4.p3.3.m3.1.1.3.2.cmml" xref="S3.SS4.p3.3.m3.1.1.3.2">𝑟</ci><ci id="S3.SS4.p3.3.m3.1.1.3.3.cmml" xref="S3.SS4.p3.3.m3.1.1.3.3">𝑒</ci><ci id="S3.SS4.p3.3.m3.1.1.3.4.cmml" xref="S3.SS4.p3.3.m3.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.3.m3.1c">\mathcal{L}_{reg}</annotation></semantics></math><span id="S3.SS4.p3.3.10" class="ltx_text" style="font-size:90%;"> is only enabled when the current sequence is fake.</span></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Validations</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Evaluation of the proposed method is conducted on publicly available audio-visual AV-DeepFake1M </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S4.SS1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.4" class="ltx_text" style="font-size:90%;">, FakeAVCeleb </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S4.SS1.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.7" class="ltx_text" style="font-size:90%;">, LAV-DF </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S4.SS1.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.10" class="ltx_text" style="font-size:90%;">, and TVIL </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS1.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S4.SS1.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS1.p1.1.13" class="ltx_text" style="font-size:90%;"> deepfake datasets. Table  </span><a href="#S4.T1" title="Table 1 ‣ 4.1 Datasets ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S4.SS1.p1.1.14" class="ltx_text" style="font-size:90%;"> provides details on the datasets used in this study. More details about the datasets are available in the Appendix, section </span><math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn mathsize="90%" id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">1</annotation></semantics></math><span id="S4.SS1.p1.1.15" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Details on the datasets used in this study.</figcaption>
<div id="S4.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:500.4pt;height:78.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-37.4pt,5.9pt) scale(0.87,0.87) ;">
<table id="S4.T1.4.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.4.1.1.1" class="ltx_tr">
<td id="S4.T1.4.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Dataset</span></td>
<td id="S4.T1.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Year</span></td>
<td id="S4.T1.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Tasks</span></td>
<td id="S4.T1.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Manipulated Modality</span></td>
<td id="S4.T1.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Manipulation Method</span></td>
<td id="S4.T1.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">#Subjects</span></td>
</tr>
<tr id="S4.T1.4.1.2.2" class="ltx_tr">
<td id="S4.T1.4.1.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T1.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">FakeAVCeleb </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.4.1.2.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib29" title="" class="ltx_ref">29</a><span id="S4.T1.4.1.2.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.2.2.2.1" class="ltx_text" style="font-size:90%;">2021</span></td>
<td id="S4.T1.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.2.2.3.1" class="ltx_text" style="font-size:90%;">Detection</span></td>
<td id="S4.T1.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.2.2.4.1" class="ltx_text" style="font-size:90%;">Audio and Visual</span></td>
<td id="S4.T1.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.2.2.5.1" class="ltx_text" style="font-size:90%;">Re-enactment</span></td>
<td id="S4.T1.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.2.2.6.1" class="ltx_text" style="font-size:90%;">500</span></td>
</tr>
<tr id="S4.T1.4.1.3.3" class="ltx_tr">
<td id="S4.T1.4.1.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T1.4.1.3.3.1.1" class="ltx_text" style="font-size:90%;">LAV-DF </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.4.1.3.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S4.T1.4.1.3.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.3.3.2.1" class="ltx_text" style="font-size:90%;">2022</span></td>
<td id="S4.T1.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.3.3.3.1" class="ltx_text" style="font-size:90%;">Detection and Localization</span></td>
<td id="S4.T1.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.3.3.4.1" class="ltx_text" style="font-size:90%;">Audio and Visual</span></td>
<td id="S4.T1.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.3.3.5.1" class="ltx_text" style="font-size:90%;">Content-driven</span></td>
<td id="S4.T1.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.3.3.6.1" class="ltx_text" style="font-size:90%;">153</span></td>
</tr>
<tr id="S4.T1.4.1.4.4" class="ltx_tr">
<td id="S4.T1.4.1.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T1.4.1.4.4.1.1" class="ltx_text" style="font-size:90%;">TVIL </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.4.1.4.4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S4.T1.4.1.4.4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.4.4.2.1" class="ltx_text" style="font-size:90%;">2023</span></td>
<td id="S4.T1.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.4.4.3.1" class="ltx_text" style="font-size:90%;">Detection and Localization</span></td>
<td id="S4.T1.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.4.4.4.1" class="ltx_text" style="font-size:90%;">Audio and Visual</span></td>
<td id="S4.T1.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.4.4.5.1" class="ltx_text" style="font-size:90%;">Inpainting forgery</span></td>
<td id="S4.T1.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.4.1.4.4.6.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
</tr>
<tr id="S4.T1.4.1.5.5" class="ltx_tr">
<td id="S4.T1.4.1.5.5.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T1.4.1.5.5.1.1" class="ltx_text" style="font-size:90%;">AV-Deepfake1M </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.4.1.5.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S4.T1.4.1.5.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T1.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.4.1.5.5.2.1" class="ltx_text" style="font-size:90%;">2023</span></td>
<td id="S4.T1.4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.4.1.5.5.3.1" class="ltx_text" style="font-size:90%;">Detection and Localization</span></td>
<td id="S4.T1.4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.4.1.5.5.4.1" class="ltx_text" style="font-size:90%;">Audio and Visual</span></td>
<td id="S4.T1.4.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.4.1.5.5.5.1" class="ltx_text" style="font-size:90%;">Content-driven</span></td>
<td id="S4.T1.4.1.5.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.4.1.5.5.6.1" class="ltx_text" style="font-size:90%;">2068</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p"><span id="S4.SS2.p1.3.1" class="ltx_text" style="font-size:90%;">For the deepfake detection task using MMMS-BA, our model architecture includes bidirectional GRUs with </span><math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn mathsize="90%" id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="integer" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">300</annotation></semantics></math><span id="S4.SS2.p1.3.2" class="ltx_text" style="font-size:90%;"> neurons each, followed by a dense layer comprising </span><math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mn mathsize="90%" id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn type="integer" id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">100</annotation></semantics></math><span id="S4.SS2.p1.3.3" class="ltx_text" style="font-size:90%;"> neurons. This dense layer ensures that the input features from all three modalities, i.e., full visual face, lip sequences, and audios are projected to the same dimensions, facilitating cohesive integration of information. Dropout regularization is applied with a rate of </span><math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="0.3" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mn mathsize="90%" id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">0.3</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><cn type="float" id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">0.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">0.3</annotation></semantics></math><span id="S4.SS2.p1.3.4" class="ltx_text" style="font-size:90%;"> across all layers, including the Bi-GRU layers. ReLU activation functions are utilized in the dense layers, while softmax activation is employed in the final classification layer, and ReLU (to ensure nonnegative values for start and end timestamps) is employed with Differential Intersection over Union (DIoU) loss, which measures the accuracy of the predicted timestamps against the ground truth.</span></p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">The hyperparameters, including activation functions and dropout probabilities, were selected through a grid-search process using the validation set. The Adam optimizer with an exponential decay learning rate scheduler is used for optimization, and an early stopping strategy is implemented to determine the optimal training for each model. During training, we use a batch size of </span><math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mn mathsize="90%" id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><cn type="integer" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">32</annotation></semantics></math><span id="S4.SS2.p2.1.2" class="ltx_text" style="font-size:90%;">. We conducted experiments using different combinations of bi-modal inputs, encompassing full visual face, lip sequences, and audio modalities.</span></p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Evaluation Metrics</span><span id="S4.SS2.p3.1.2" class="ltx_text" style="font-size:90%;">: For performance evaluation, we used standard evaluation metrics commonly used for deepfake detection, such as area under the ROC Curve (AUC), partial AUC (pAUC) (at </span><math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mn mathsize="90%" id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><cn type="integer" id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">10</annotation></semantics></math><span id="S4.SS2.p3.1.3" class="ltx_text" style="font-size:90%;">% False Positive Rate (FPR)), and Equal Error Rate (EER) similar to the studies on deepfake detection </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p3.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a><span id="S4.SS2.p3.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p3.1.6" class="ltx_text" style="font-size:90%;">.
For localization, we used average precision (AP) and average recall (AR) similar to the published work in </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2.p3.1.7.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S4.SS2.p3.1.8.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS2.p3.1.9" class="ltx_text" style="font-size:90%;"> at different thresholds to evaluate the model.</span></p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Performance of Deepfake Detection</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.2" class="ltx_p"><span id="S4.SS3.p1.2.1" class="ltx_text" style="font-size:90%;">Tables </span><a href="#S4.T2" title="Table 2 ‣ 4.3 Performance of Deepfake Detection ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S4.SS3.p1.2.2" class="ltx_text" style="font-size:90%;"> and </span><a href="#S4.T3" title="Table 3 ‣ 4.3 Performance of Deepfake Detection ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S4.SS3.p1.2.3" class="ltx_text" style="font-size:90%;"> summarize the performance of our MMMS-BA model on intra- and cross-dataset evaluation when trained on FakeAVCeleb and AV-Deepfake1M datasets.
For the AV-Deepfake1M dataset, training and validation sets are available, and the testing set has not yet been released. In this regard, we have used the training set for both training (</span><math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="85" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mn mathsize="90%" id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">85</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><cn type="integer" id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">85</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">85</annotation></semantics></math><span id="S4.SS3.p1.2.4" class="ltx_text" style="font-size:90%;"> %) and validation (</span><math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="15\%" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mn mathsize="90%" id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">15</mn><mo mathsize="90%" id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">15\%</annotation></semantics></math><span id="S4.SS3.p1.2.5" class="ltx_text" style="font-size:90%;">). While the actual validation set is used for testing the trained models.</span></p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Intra- and cross-dataset evaluation of MMMS-BA when trained on FakeAVCeleb dataset.</figcaption>
<div id="S4.T2.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:242.0pt;height:78.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.1pt,5.9pt) scale(0.87,0.87) ;">
<table id="S4.T2.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.4.1.1.1" class="ltx_tr">
<th id="S4.T2.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Testing Dataset</span></th>
<td id="S4.T2.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AUC</span></td>
<td id="S4.T2.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">pAUC</span></td>
<td id="S4.T2.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">EER</span></td>
<td id="S4.T2.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">ACC</span></td>
<td id="S4.T2.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">TPR</span></td>
<td id="S4.T2.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.4.1.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">FPR</span></td>
</tr>
<tr id="S4.T2.4.1.2.2" class="ltx_tr">
<th id="S4.T2.4.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">FakeAVCeleb</span></th>
<td id="S4.T2.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.2.2.2.1" class="ltx_text" style="font-size:90%;">0.989</span></td>
<td id="S4.T2.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.2.2.3.1" class="ltx_text" style="font-size:90%;">0.977</span></td>
<td id="S4.T2.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.2.2.4.1" class="ltx_text" style="font-size:90%;">0.029</span></td>
<td id="S4.T2.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.2.2.5.1" class="ltx_text" style="font-size:90%;">0.979</span></td>
<td id="S4.T2.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.2.2.6.1" class="ltx_text" style="font-size:90%;">0.965</span></td>
<td id="S4.T2.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.4.1.2.2.7.1" class="ltx_text" style="font-size:90%;">0.039</span></td>
</tr>
<tr id="S4.T2.4.1.3.3" class="ltx_tr">
<th id="S4.T2.4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.4.1.3.3.1.1" class="ltx_text" style="font-size:90%;">AV-Deepfake1M</span></th>
<td id="S4.T2.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.3.3.2.1" class="ltx_text" style="font-size:90%;">0.909</span></td>
<td id="S4.T2.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.3.3.3.1" class="ltx_text" style="font-size:90%;">0.884</span></td>
<td id="S4.T2.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.3.3.4.1" class="ltx_text" style="font-size:90%;">0.178</span></td>
<td id="S4.T2.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.3.3.5.1" class="ltx_text" style="font-size:90%;">0.821</span></td>
<td id="S4.T2.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.3.3.6.1" class="ltx_text" style="font-size:90%;">0.893</span></td>
<td id="S4.T2.4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.4.1.3.3.7.1" class="ltx_text" style="font-size:90%;">0.249</span></td>
</tr>
<tr id="S4.T2.4.1.4.4" class="ltx_tr">
<th id="S4.T2.4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.4.1.4.4.1.1" class="ltx_text" style="font-size:90%;">LAV-DF</span></th>
<td id="S4.T2.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.4.4.2.1" class="ltx_text" style="font-size:90%;">0.958</span></td>
<td id="S4.T2.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.4.4.3.1" class="ltx_text" style="font-size:90%;">0.938</span></td>
<td id="S4.T2.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.4.4.4.1" class="ltx_text" style="font-size:90%;">0.078</span></td>
<td id="S4.T2.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.4.4.5.1" class="ltx_text" style="font-size:90%;">0.932</span></td>
<td id="S4.T2.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.4.1.4.4.6.1" class="ltx_text" style="font-size:90%;">0.912</span></td>
<td id="S4.T2.4.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.4.1.4.4.7.1" class="ltx_text" style="font-size:90%;">0.081</span></td>
</tr>
<tr id="S4.T2.4.1.5.5" class="ltx_tr">
<th id="S4.T2.4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.4.1.5.5.1.1" class="ltx_text" style="font-size:90%;">TVIL</span></th>
<td id="S4.T2.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.4.1.5.5.2.1" class="ltx_text" style="font-size:90%;">0.942</span></td>
<td id="S4.T2.4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.4.1.5.5.3.1" class="ltx_text" style="font-size:90%;">0.920</span></td>
<td id="S4.T2.4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.4.1.5.5.4.1" class="ltx_text" style="font-size:90%;">0.126</span></td>
<td id="S4.T2.4.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.4.1.5.5.5.1" class="ltx_text" style="font-size:90%;">0.947</span></td>
<td id="S4.T2.4.1.5.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.4.1.5.5.6.1" class="ltx_text" style="font-size:90%;">0.927</span></td>
<td id="S4.T2.4.1.5.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.4.1.5.5.7.1" class="ltx_text" style="font-size:90%;">0.093</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Intra- and cross-dataset evaluation of MMMS-BA when trained on AV-Deepfake1M dataset.</figcaption>
<div id="S4.T3.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:242.0pt;height:78.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.1pt,5.9pt) scale(0.87,0.87) ;">
<table id="S4.T3.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.4.1.1.1" class="ltx_tr">
<th id="S4.T3.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.4.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Testing Dataset</span></th>
<td id="S4.T3.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AUC</span></td>
<td id="S4.T3.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">pAUC</span></td>
<td id="S4.T3.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">EER</span></td>
<td id="S4.T3.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">ACC</span></td>
<td id="S4.T3.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">TPR</span></td>
<td id="S4.T3.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.1.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">FPR</span></td>
</tr>
<tr id="S4.T3.4.1.2.2" class="ltx_tr">
<th id="S4.T3.4.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">AV-Deepfake1M</span></th>
<td id="S4.T3.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.2.2.2.1" class="ltx_text" style="font-size:90%;">0.979</span></td>
<td id="S4.T3.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.2.2.3.1" class="ltx_text" style="font-size:90%;">0.962</span></td>
<td id="S4.T3.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.2.2.4.1" class="ltx_text" style="font-size:90%;">0.051</span></td>
<td id="S4.T3.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.2.2.5.1" class="ltx_text" style="font-size:90%;">0.968</span></td>
<td id="S4.T3.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.2.2.6.1" class="ltx_text" style="font-size:90%;">0.954</span></td>
<td id="S4.T3.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.1.2.2.7.1" class="ltx_text" style="font-size:90%;">0.062</span></td>
</tr>
<tr id="S4.T3.4.1.3.3" class="ltx_tr">
<th id="S4.T3.4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.4.1.3.3.1.1" class="ltx_text" style="font-size:90%;">FakeAVCeleb</span></th>
<td id="S4.T3.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.3.3.2.1" class="ltx_text" style="font-size:90%;">0.955</span></td>
<td id="S4.T3.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.3.3.3.1" class="ltx_text" style="font-size:90%;">0.935</span></td>
<td id="S4.T3.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.3.3.4.1" class="ltx_text" style="font-size:90%;">0.088</span></td>
<td id="S4.T3.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.3.3.5.1" class="ltx_text" style="font-size:90%;">0.947</span></td>
<td id="S4.T3.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.3.3.6.1" class="ltx_text" style="font-size:90%;">0.938</span></td>
<td id="S4.T3.4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.1.3.3.7.1" class="ltx_text" style="font-size:90%;">0.108</span></td>
</tr>
<tr id="S4.T3.4.1.4.4" class="ltx_tr">
<th id="S4.T3.4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.4.1.4.4.1.1" class="ltx_text" style="font-size:90%;">LAV-DF</span></th>
<td id="S4.T3.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.4.4.2.1" class="ltx_text" style="font-size:90%;">0.968</span></td>
<td id="S4.T3.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.4.4.3.1" class="ltx_text" style="font-size:90%;">0.952</span></td>
<td id="S4.T3.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.4.4.4.1" class="ltx_text" style="font-size:90%;">0.068</span></td>
<td id="S4.T3.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.4.4.5.1" class="ltx_text" style="font-size:90%;">0.956</span></td>
<td id="S4.T3.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.1.4.4.6.1" class="ltx_text" style="font-size:90%;">0.941</span></td>
<td id="S4.T3.4.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.1.4.4.7.1" class="ltx_text" style="font-size:90%;">0.074</span></td>
</tr>
<tr id="S4.T3.4.1.5.5" class="ltx_tr">
<th id="S4.T3.4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.4.1.5.5.1.1" class="ltx_text" style="font-size:90%;">TVIL</span></th>
<td id="S4.T3.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.4.1.5.5.2.1" class="ltx_text" style="font-size:90%;">0.932</span></td>
<td id="S4.T3.4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.4.1.5.5.3.1" class="ltx_text" style="font-size:90%;">0.912</span></td>
<td id="S4.T3.4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.4.1.5.5.4.1" class="ltx_text" style="font-size:90%;">0.118</span></td>
<td id="S4.T3.4.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.4.1.5.5.5.1" class="ltx_text" style="font-size:90%;">0.913</span></td>
<td id="S4.T3.4.1.5.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.4.1.5.5.6.1" class="ltx_text" style="font-size:90%;">0.890</span></td>
<td id="S4.T3.4.1.5.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T3.4.1.5.5.7.1" class="ltx_text" style="font-size:90%;">0.145</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.4" class="ltx_p"><span id="S4.SS3.p2.4.1" class="ltx_text" style="font-size:90%;">The results presented in Table </span><a href="#S4.T2" title="Table 2 ‣ 4.3 Performance of Deepfake Detection ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S4.SS3.p2.4.2" class="ltx_text" style="font-size:90%;"> and Table </span><a href="#S4.T3" title="Table 3 ‣ 4.3 Performance of Deepfake Detection ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S4.SS3.p2.4.3" class="ltx_text" style="font-size:90%;"> demonstrate the performance of our MMMS-BA model on intra- and cross datasets when trained on the FakeAVCeleb and AV-Deepfake1M datasets. The model trained and tested on the FakeAVCeleb obtained an AUC and ACC of </span><math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="0.989" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mn mathsize="90%" id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">0.989</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><cn type="float" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">0.989</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">0.989</annotation></semantics></math><span id="S4.SS3.p2.4.4" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="0.979" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mn mathsize="90%" id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">0.979</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><cn type="float" id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">0.979</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">0.979</annotation></semantics></math><span id="S4.SS3.p2.4.5" class="ltx_text" style="font-size:90%;"> respectively. When trained and tested on the AV-Deepfake1M dataset, the model has an AUC and ACC of </span><math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="0.979" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mn mathsize="90%" id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">0.979</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><cn type="float" id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">0.979</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">0.979</annotation></semantics></math><span id="S4.SS3.p2.4.6" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="0.968" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mn mathsize="90%" id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">0.968</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><cn type="float" id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">0.968</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">0.968</annotation></semantics></math><span id="S4.SS3.p2.4.7" class="ltx_text" style="font-size:90%;">, respectively. This indicates the model’s ability to effectively learn the characteristics of audio-visual manipulations present in the FakeAVCeleb and AV-Deepfake1M datasets.</span></p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.4" class="ltx_p"><span id="S4.SS3.p3.4.1" class="ltx_text" style="font-size:90%;">Table </span><a href="#S4.T2" title="Table 2 ‣ 4.3 Performance of Deepfake Detection ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">2</span></a><span id="S4.SS3.p3.4.2" class="ltx_text" style="font-size:90%;"> shows that the cross-dataset evaluations have a performance landscape. When trained on FakeAVCeleb and tested on AV-Deepfake1M, LAV-DF, and TVIL. On average, there is a decrease of only </span><math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="0.053" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mn mathsize="90%" id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml">0.053</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><cn type="float" id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">0.053</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">0.053</annotation></semantics></math><span id="S4.SS3.p3.4.3" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="0.076" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mn mathsize="90%" id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml">0.076</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><cn type="float" id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1">0.076</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">0.076</annotation></semantics></math><span id="S4.SS3.p3.4.4" class="ltx_text" style="font-size:90%;"> AUC and ACC, respectively, over intra-dataset evaluation.
For the AV-Deepfake1M dataset, the model obtained the lowest performance with an AUC and ACC of </span><math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="0.909" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mn mathsize="90%" id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">0.909</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><cn type="float" id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">0.909</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">0.909</annotation></semantics></math><span id="S4.SS3.p3.4.5" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="0.893" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mn mathsize="90%" id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml">0.893</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><cn type="float" id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1">0.893</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">0.893</annotation></semantics></math><span id="S4.SS3.p3.4.6" class="ltx_text" style="font-size:90%;">, respectively. This is expected due to the differences in manipulation techniques across datasets. The model maintains relatively high performance when tested on LAV-DF and TVIL. This could be because of the similar manipulation technique in the LAV-DF dataset. While the TVIL dataset has inpainting-based manipulation providing visual cues for detection.</span></p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.6" class="ltx_p"><span id="S4.SS3.p4.6.1" class="ltx_text" style="font-size:90%;">When trained on AV-Deepfake1M and tested on FakeAVCeleb, LAV-DF, and TVIL datasets, a decrease of only </span><math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="0.027" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mn mathsize="90%" id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml">0.027</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><cn type="float" id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">0.027</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">0.027</annotation></semantics></math><span id="S4.SS3.p4.6.2" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS3.p4.2.m2.1" class="ltx_Math" alttext="0.029" display="inline"><semantics id="S4.SS3.p4.2.m2.1a"><mn mathsize="90%" id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml">0.029</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.1b"><cn type="float" id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1">0.029</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.1c">0.029</annotation></semantics></math><span id="S4.SS3.p4.6.3" class="ltx_text" style="font-size:90%;"> AUC and ACC, respectively, is recorded over the intra-dataset evaluation.
The model obtained the lowest performance with an AUC of </span><math id="S4.SS3.p4.3.m3.1" class="ltx_Math" alttext="0.932" display="inline"><semantics id="S4.SS3.p4.3.m3.1a"><mn mathsize="90%" id="S4.SS3.p4.3.m3.1.1" xref="S4.SS3.p4.3.m3.1.1.cmml">0.932</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.3.m3.1b"><cn type="float" id="S4.SS3.p4.3.m3.1.1.cmml" xref="S4.SS3.p4.3.m3.1.1">0.932</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.3.m3.1c">0.932</annotation></semantics></math><span id="S4.SS3.p4.6.4" class="ltx_text" style="font-size:90%;"> and ACC of </span><math id="S4.SS3.p4.4.m4.1" class="ltx_Math" alttext="0.913" display="inline"><semantics id="S4.SS3.p4.4.m4.1a"><mn mathsize="90%" id="S4.SS3.p4.4.m4.1.1" xref="S4.SS3.p4.4.m4.1.1.cmml">0.913</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.m4.1b"><cn type="float" id="S4.SS3.p4.4.m4.1.1.cmml" xref="S4.SS3.p4.4.m4.1.1">0.913</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.m4.1c">0.913</annotation></semantics></math><span id="S4.SS3.p4.6.5" class="ltx_text" style="font-size:90%;"> on the TVIL dataset. This is expected due to the differences in manipulation techniques across datasets.
The model obtained the best performance on the LAV-DF dataset with AUC and ACC of </span><math id="S4.SS3.p4.5.m5.1" class="ltx_Math" alttext="0.968" display="inline"><semantics id="S4.SS3.p4.5.m5.1a"><mn mathsize="90%" id="S4.SS3.p4.5.m5.1.1" xref="S4.SS3.p4.5.m5.1.1.cmml">0.968</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.5.m5.1b"><cn type="float" id="S4.SS3.p4.5.m5.1.1.cmml" xref="S4.SS3.p4.5.m5.1.1">0.968</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.5.m5.1c">0.968</annotation></semantics></math><span id="S4.SS3.p4.6.6" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS3.p4.6.m6.1" class="ltx_Math" alttext="0.956" display="inline"><semantics id="S4.SS3.p4.6.m6.1a"><mn mathsize="90%" id="S4.SS3.p4.6.m6.1.1" xref="S4.SS3.p4.6.m6.1.1.cmml">0.956</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.6.m6.1b"><cn type="float" id="S4.SS3.p4.6.m6.1.1.cmml" xref="S4.SS3.p4.6.m6.1.1">0.956</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.6.m6.1c">0.956</annotation></semantics></math><span id="S4.SS3.p4.6.7" class="ltx_text" style="font-size:90%;">, respectively. This is because both AV-Deepfake1M and LAV-DF use content-driven manipulation techniques (see Table </span><a href="#S4.T1" title="Table 1 ‣ 4.1 Datasets ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S4.SS3.p4.6.8" class="ltx_text" style="font-size:90%;">).</span></p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Comparison of MMMS-BA with published audio-visual deepfake detection approaches trained and tested on the FakeAVCeleb dataset.</figcaption>
<div id="S4.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:264.7pt;height:228.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-19.8pt,17.1pt) scale(0.87,0.87) ;">
<table id="S4.T4.4.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.4.1.1.1" class="ltx_tr">
<td id="S4.T4.4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Model</span></td>
<td id="S4.T4.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AUC</span></td>
<td id="S4.T4.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">ACC</span></td>
</tr>
<tr id="S4.T4.4.1.2.2" class="ltx_tr">
<td id="S4.T4.4.1.2.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">MIS-AVoiDD </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.2.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib53" title="" class="ltx_ref">53</a><span id="S4.T4.4.1.2.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.2.2.1" class="ltx_text" style="font-size:90%;">0.973</span></td>
<td id="S4.T4.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.2.2.3.1" class="ltx_text" style="font-size:90%;">0.962</span></td>
</tr>
<tr id="S4.T4.4.1.3.3" class="ltx_tr">
<td id="S4.T4.4.1.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S4.T4.4.1.3.3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.4.1.3.3.1.1.1" class="ltx_tr">
<td id="S4.T4.4.1.3.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T4.4.1.3.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Unsupervised Multi-modal</span></td>
</tr>
<tr id="S4.T4.4.1.3.3.1.1.2" class="ltx_tr">
<td id="S4.T4.4.1.3.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S4.T4.4.1.3.3.1.1.2.1.1" class="ltx_text" style="font-size:90%;">Deepfake Detection </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.3.3.1.1.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib57" title="" class="ltx_ref">57</a><span id="S4.T4.4.1.3.3.1.1.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
</tr>
</table>
</td>
<td id="S4.T4.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.3.3.2.1" class="ltx_text" style="font-size:90%;">0.968</span></td>
<td id="S4.T4.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.3.3.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T4.4.1.4.4" class="ltx_tr">
<td id="S4.T4.4.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.4.4.1.1" class="ltx_text" style="font-size:90%;">Audio-visual person-of-interest </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.4.4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S4.T4.4.1.4.4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.4.4.2.1" class="ltx_text" style="font-size:90%;">0.946</span></td>
<td id="S4.T4.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.4.4.3.1" class="ltx_text" style="font-size:90%;">0.850</span></td>
</tr>
<tr id="S4.T4.4.1.5.5" class="ltx_tr">
<td id="S4.T4.4.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.5.5.1.1" class="ltx_text" style="font-size:90%;">Audio-visual anomaly detection </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.5.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S4.T4.4.1.5.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.5.5.2.1" class="ltx_text" style="font-size:90%;">0.942</span></td>
<td id="S4.T4.4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.5.5.3.1" class="ltx_text" style="font-size:90%;">0.945</span></td>
</tr>
<tr id="S4.T4.4.1.6.6" class="ltx_tr">
<td id="S4.T4.4.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.6.6.1.1" class="ltx_text" style="font-size:90%;">Multi-modal contrastive learning </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.6.6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib36" title="" class="ltx_ref">36</a><span id="S4.T4.4.1.6.6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.6.6.2.1" class="ltx_text" style="font-size:90%;">0.978</span></td>
<td id="S4.T4.4.1.6.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.6.6.3.1" class="ltx_text" style="font-size:90%;">0.965</span></td>
</tr>
<tr id="S4.T4.4.1.7.7" class="ltx_tr">
<td id="S4.T4.4.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.7.7.1.1" class="ltx_text" style="font-size:90%;">PVAS-MDD </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.7.7.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib62" title="" class="ltx_ref">62</a><span id="S4.T4.4.1.7.7.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.7.7.2.1" class="ltx_text" style="font-size:90%;">0.965</span></td>
<td id="S4.T4.4.1.7.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.7.7.3.1" class="ltx_text" style="font-size:90%;">0.948</span></td>
</tr>
<tr id="S4.T4.4.1.8.8" class="ltx_tr">
<td id="S4.T4.4.1.8.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.8.8.1.1" class="ltx_text" style="font-size:90%;">Novel Smart Deepfake Detection </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.8.8.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S4.T4.4.1.8.8.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.8.8.2.1" class="ltx_text" style="font-size:90%;">0.954</span></td>
<td id="S4.T4.4.1.8.8.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.8.8.3.1" class="ltx_text" style="font-size:90%;">0.960</span></td>
</tr>
<tr id="S4.T4.4.1.9.9" class="ltx_tr">
<td id="S4.T4.4.1.9.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.9.9.1.1" class="ltx_text" style="font-size:90%;">Multimodaltrace </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.9.9.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib48" title="" class="ltx_ref">48</a><span id="S4.T4.4.1.9.9.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.9.9.2.1" class="ltx_text" style="font-size:90%;">0.929</span></td>
<td id="S4.T4.4.1.9.9.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.9.9.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T4.4.1.10.10" class="ltx_tr">
<td id="S4.T4.4.1.10.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.10.10.1.1" class="ltx_text" style="font-size:90%;">Hearing and seeing abnormality </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.10.10.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib56" title="" class="ltx_ref">56</a><span id="S4.T4.4.1.10.10.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.10.10.2.1" class="ltx_text" style="font-size:90%;">0.944</span></td>
<td id="S4.T4.4.1.10.10.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.10.10.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T4.4.1.11.11" class="ltx_tr">
<td id="S4.T4.4.1.11.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S4.T4.4.1.11.11.1.1" class="ltx_text" style="font-size:90%;">NPVforensics </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.4.1.11.11.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S4.T4.4.1.11.11.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="S4.T4.4.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.11.11.2.1" class="ltx_text" style="font-size:90%;">0.925</span></td>
<td id="S4.T4.4.1.11.11.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.1.11.11.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T4.4.1.12.12" class="ltx_tr">
<td id="S4.T4.4.1.12.12.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<table id="S4.T4.4.1.12.12.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.4.1.12.12.1.1.1" class="ltx_tr">
<td id="S4.T4.4.1.12.12.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S4.T4.4.1.12.12.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Our-MMMS-BA</span><span id="S4.T4.4.1.12.12.1.1.1.1.2" class="ltx_text" style="font-size:90%;"> (Visual, Audio,</span>
</td>
</tr>
<tr id="S4.T4.4.1.12.12.1.1.2" class="ltx_tr">
<td id="S4.T4.4.1.12.12.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T4.4.1.12.12.1.1.2.1.1" class="ltx_text" style="font-size:90%;">and Lip Sequence)</span></td>
</tr>
</table>
</td>
<td id="S4.T4.4.1.12.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T4.4.1.12.12.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.989</span></td>
<td id="S4.T4.4.1.12.12.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T4.4.1.12.12.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.979</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.4" class="ltx_p"><span id="S4.SS3.p5.4.1" class="ltx_text" style="font-size:90%;">In </span><span id="S4.SS3.p5.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">summary</span><span id="S4.SS3.p5.4.3" class="ltx_text" style="font-size:90%;">, the experimental results for deepfake detection suggest a high generalization and efficacy of the MMMS-BA model. On the intra-dataset evaluation of the model on FakeAVCeleb and AV-Deepfake1M datasets, an average AUC and ACC of </span><math id="S4.SS3.p5.1.m1.1" class="ltx_Math" alttext="0.984" display="inline"><semantics id="S4.SS3.p5.1.m1.1a"><mn mathsize="90%" id="S4.SS3.p5.1.m1.1.1" xref="S4.SS3.p5.1.m1.1.1.cmml">0.984</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.1.m1.1b"><cn type="float" id="S4.SS3.p5.1.m1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1">0.984</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.1.m1.1c">0.984</annotation></semantics></math><span id="S4.SS3.p5.4.4" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS3.p5.2.m2.1" class="ltx_Math" alttext="0.973" display="inline"><semantics id="S4.SS3.p5.2.m2.1a"><mn mathsize="90%" id="S4.SS3.p5.2.m2.1.1" xref="S4.SS3.p5.2.m2.1.1.cmml">0.973</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.2.m2.1b"><cn type="float" id="S4.SS3.p5.2.m2.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1">0.973</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.2.m2.1c">0.973</annotation></semantics></math><span id="S4.SS3.p5.4.5" class="ltx_text" style="font-size:90%;">, respectively, is obtained. The high performance of the model on the FakeAVCeleb dataset also confirms that our model obtains efficient detection performance even when one of the modalities (audio or visual) is manipulated, as available in the FakeAVCeleb dataset.
On cross-dataset evaluation of the model, an average AUC and ACC of </span><math id="S4.SS3.p5.3.m3.1" class="ltx_Math" alttext="0.944" display="inline"><semantics id="S4.SS3.p5.3.m3.1a"><mn mathsize="90%" id="S4.SS3.p5.3.m3.1.1" xref="S4.SS3.p5.3.m3.1.1.cmml">0.944</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.3.m3.1b"><cn type="float" id="S4.SS3.p5.3.m3.1.1.cmml" xref="S4.SS3.p5.3.m3.1.1">0.944</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.3.m3.1c">0.944</annotation></semantics></math><span id="S4.SS3.p5.4.6" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS3.p5.4.m4.1" class="ltx_Math" alttext="0.919" display="inline"><semantics id="S4.SS3.p5.4.m4.1a"><mn mathsize="90%" id="S4.SS3.p5.4.m4.1.1" xref="S4.SS3.p5.4.m4.1.1.cmml">0.919</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.4.m4.1b"><cn type="float" id="S4.SS3.p5.4.m4.1.1.cmml" xref="S4.SS3.p5.4.m4.1.1">0.919</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.4.m4.1c">0.919</annotation></semantics></math><span id="S4.SS3.p5.4.7" class="ltx_text" style="font-size:90%;">, respectively, are obtained, suggesting the high performance and generalizability of our proposed MMMS-BA model.</span></p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Comparison with the Published Audio-Visual Deepfake Detectors</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.3" class="ltx_p"><span id="S4.SS4.p1.3.1" class="ltx_text" style="font-size:90%;">The comparison shown in Table </span><a href="#S4.T4" title="Table 4 ‣ 4.3 Performance of Deepfake Detection ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S4.SS4.p1.3.2" class="ltx_text" style="font-size:90%;"> highlights the competitive landscape of deepfake detection models trained and evaluated on the FakeAVCeleb dataset. As can be seen in Table </span><a href="#S4.T4" title="Table 4 ‣ 4.3 Performance of Deepfake Detection ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">4</span></a><span id="S4.SS4.p1.3.3" class="ltx_text" style="font-size:90%;">, the MMMS-BA model, which uses the full facial image, audio, and lip modality, outperforms all existing audio-visual deepfake detectors by obtaining an AUC of </span><math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="0.989" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mn mathsize="90%" id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">0.989</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><cn type="float" id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">0.989</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">0.989</annotation></semantics></math><span id="S4.SS4.p1.3.4" class="ltx_text" style="font-size:90%;"> and an ACC of </span><math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="0.979" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mn mathsize="90%" id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">0.979</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><cn type="float" id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">0.979</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">0.979</annotation></semantics></math><span id="S4.SS4.p1.3.5" class="ltx_text" style="font-size:90%;">. In particular, our MMMS-BA model outperforms NPVForensics </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p1.3.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S4.SS4.p1.3.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS4.p1.3.8" class="ltx_text" style="font-size:90%;"> which also utilizes face, audio, and lip movement data. NPVForensics is based on mining the correlation between non-critical phonemes and visemes using a Swin Transformer and cross-modal fusion, but it achieves lower performance over MMMS-BA due to its limited ability to capture temporal dependencies and interactions across multiple sequences.
The Unsupervised Cross-Modal Inconsistencies </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS4.p1.3.9.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib57" title="" class="ltx_ref">57</a><span id="S4.SS4.p1.3.10.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS4.p1.3.11" class="ltx_text" style="font-size:90%;"> model obtained the second-best performance, with an AUC of </span><math id="S4.SS4.p1.3.m3.1" class="ltx_Math" alttext="0.968" display="inline"><semantics id="S4.SS4.p1.3.m3.1a"><mn mathsize="90%" id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">0.968</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><cn type="float" id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">0.968</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">0.968</annotation></semantics></math><span id="S4.SS4.p1.3.12" class="ltx_text" style="font-size:90%;">. This also suggests the potential of leveraging motion inconsistencies between modalities for deepfake detection.</span></p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.2" class="ltx_p"><span id="S4.SS4.p2.2.1" class="ltx_text" style="font-size:90%;">In </span><span id="S4.SS4.p2.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">summary</span><span id="S4.SS4.p2.2.3" class="ltx_text" style="font-size:90%;">, MMMS-BA outperforms all recently published work based on integrating audio, visual, and lip-movement data with an average performance increment of </span><math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="0.0341" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mn mathsize="90%" id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml">0.0341</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><cn type="float" id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1">0.0341</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">0.0341</annotation></semantics></math><span id="S4.SS4.p2.2.4" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="3.47" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mn mathsize="90%" id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml">3.47</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><cn type="float" id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1">3.47</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">3.47</annotation></semantics></math><span id="S4.SS4.p2.2.5" class="ltx_text" style="font-size:90%;">% in AUC and ACC, respectively. Thus, obtaining state-of-the-art performance.</span></p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Comparison between MMMS-BA and other methods on LAV-DF, TVIL, and AV-Deepfake1M datasets. Bold faces represent the best performance. (AP- Average Precision and AR- Average Recall).</figcaption>
<div id="S4.T5.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:492.0pt;height:234.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.8pt,17.6pt) scale(0.87,0.87) ;">
<table id="S4.T5.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.4.1.1.1" class="ltx_tr">
<th id="S4.T5.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S4.T5.4.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Testing Dataset</span></th>
<th id="S4.T5.4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S4.T5.4.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Method</span></th>
<th id="S4.T5.4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.4.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AP@0.5</span></th>
<th id="S4.T5.4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.4.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AP@0.75</span></th>
<th id="S4.T5.4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.4.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AP@0.95</span></th>
<th id="S4.T5.4.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.4.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AR@10</span></th>
<th id="S4.T5.4.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.4.1.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AR@20</span></th>
<th id="S4.T5.4.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.4.1.1.1.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AR@50</span></th>
<th id="S4.T5.4.1.1.1.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.4.1.1.1.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AR@100</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.4.1.2.1" class="ltx_tr">
<th id="S4.T5.4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T5.4.1.2.1.1.1" class="ltx_text" style="font-size:90%;">AV-Deepfake1M</span></th>
<th id="S4.T5.4.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T5.4.1.2.1.2.1" class="ltx_text" style="font-size:90%;">Enc-Dec</span></th>
<td id="S4.T5.4.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.2.1.3.1" class="ltx_text" style="font-size:90%;">06.23</span></td>
<td id="S4.T5.4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.2.1.4.1" class="ltx_text" style="font-size:90%;">0.08</span></td>
<td id="S4.T5.4.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.2.1.5.1" class="ltx_text" style="font-size:90%;">0.00</span></td>
<td id="S4.T5.4.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.2.1.6.1" class="ltx_text" style="font-size:90%;">11.45</span></td>
<td id="S4.T5.4.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.2.1.7.1" class="ltx_text" style="font-size:90%;">15.79</span></td>
<td id="S4.T5.4.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.2.1.8.1" class="ltx_text" style="font-size:90%;">23.75</span></td>
<td id="S4.T5.4.1.2.1.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T5.4.1.2.1.9.1" class="ltx_text" style="font-size:90%;">31.71</span></td>
</tr>
<tr id="S4.T5.4.1.3.2" class="ltx_tr">
<th id="S4.T5.4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S4.T5.4.1.3.2.1.1" class="ltx_text" style="font-size:90%;">ActionFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.4.1.3.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib63" title="" class="ltx_ref">63</a><span id="S4.T5.4.1.3.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T5.4.1.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.3.2.2.1" class="ltx_text" style="font-size:90%;">36.08</span></td>
<td id="S4.T5.4.1.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.3.2.3.1" class="ltx_text" style="font-size:90%;">12.01</span></td>
<td id="S4.T5.4.1.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.3.2.4.1" class="ltx_text" style="font-size:90%;">00.16</span></td>
<td id="S4.T5.4.1.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.3.2.5.1" class="ltx_text" style="font-size:90%;">26.60</span></td>
<td id="S4.T5.4.1.3.2.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.3.2.6.1" class="ltx_text" style="font-size:90%;">27.00</span></td>
<td id="S4.T5.4.1.3.2.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.3.2.7.1" class="ltx_text" style="font-size:90%;">27.11</span></td>
<td id="S4.T5.4.1.3.2.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.3.2.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T5.4.1.4.3" class="ltx_tr">
<th id="S4.T5.4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S4.T5.4.1.4.3.1.1" class="ltx_text" style="font-size:90%;">BA-TFD+ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.4.1.4.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S4.T5.4.1.4.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T5.4.1.4.3.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.4.3.2.1" class="ltx_text" style="font-size:90%;">44.42</span></td>
<td id="S4.T5.4.1.4.3.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.4.3.3.1" class="ltx_text" style="font-size:90%;">13.64</span></td>
<td id="S4.T5.4.1.4.3.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.4.3.4.1" class="ltx_text" style="font-size:90%;">00.03</span></td>
<td id="S4.T5.4.1.4.3.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.4.3.5.1" class="ltx_text" style="font-size:90%;">34.67</span></td>
<td id="S4.T5.4.1.4.3.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.4.3.6.1" class="ltx_text" style="font-size:90%;">40.37</span></td>
<td id="S4.T5.4.1.4.3.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.4.3.7.1" class="ltx_text" style="font-size:90%;">48.86</span></td>
<td id="S4.T5.4.1.4.3.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.4.3.8.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T5.4.1.5.4" class="ltx_tr">
<th id="S4.T5.4.1.5.4.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T5.4.1.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S4.T5.4.1.5.4.2.1" class="ltx_text" style="font-size:90%;">UMMAFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.4.1.5.4.2.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S4.T5.4.1.5.4.2.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T5.4.1.5.4.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.5.4.3.1" class="ltx_text" style="font-size:90%;">51.64</span></td>
<td id="S4.T5.4.1.5.4.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.5.4.4.1" class="ltx_text" style="font-size:90%;">28.07</span></td>
<td id="S4.T5.4.1.5.4.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.5.4.5.1" class="ltx_text" style="font-size:90%;">01.58</span></td>
<td id="S4.T5.4.1.5.4.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.5.4.6.1" class="ltx_text" style="font-size:90%;">42.09</span></td>
<td id="S4.T5.4.1.5.4.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.5.4.7.1" class="ltx_text" style="font-size:90%;">43.45</span></td>
<td id="S4.T5.4.1.5.4.8" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.5.4.8.1" class="ltx_text" style="font-size:90%;">48.86</span></td>
<td id="S4.T5.4.1.5.4.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.5.4.9.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T5.4.1.6.5" class="ltx_tr">
<th id="S4.T5.4.1.6.5.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T5.4.1.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T5.4.1.6.5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Our-MMMS-BA</span></th>
<td id="S4.T5.4.1.6.5.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.6.5.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">62.75</span></td>
<td id="S4.T5.4.1.6.5.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.6.5.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">35.87</span></td>
<td id="S4.T5.4.1.6.5.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.6.5.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">18.37</span></td>
<td id="S4.T5.4.1.6.5.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.6.5.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">54.28</span></td>
<td id="S4.T5.4.1.6.5.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.6.5.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">55.94</span></td>
<td id="S4.T5.4.1.6.5.8" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.6.5.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">57.49</span></td>
<td id="S4.T5.4.1.6.5.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.6.5.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">59.66</span></td>
</tr>
<tr id="S4.T5.4.1.7.6" class="ltx_tr">
<th id="S4.T5.4.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T5.4.1.7.6.1.1" class="ltx_text" style="font-size:90%;">LAV-DF</span></th>
<th id="S4.T5.4.1.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T5.4.1.7.6.2.1" class="ltx_text" style="font-size:90%;">Enc-Dec</span></th>
<td id="S4.T5.4.1.7.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.7.6.3.1" class="ltx_text" style="font-size:90%;">12.96</span></td>
<td id="S4.T5.4.1.7.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.7.6.4.1" class="ltx_text" style="font-size:90%;">0.97</span></td>
<td id="S4.T5.4.1.7.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.7.6.5.1" class="ltx_text" style="font-size:90%;">0.00</span></td>
<td id="S4.T5.4.1.7.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.7.6.6.1" class="ltx_text" style="font-size:90%;">18.79</span></td>
<td id="S4.T5.4.1.7.6.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.7.6.7.1" class="ltx_text" style="font-size:90%;">21.67</span></td>
<td id="S4.T5.4.1.7.6.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.7.6.8.1" class="ltx_text" style="font-size:90%;">30.54</span></td>
<td id="S4.T5.4.1.7.6.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T5.4.1.7.6.9.1" class="ltx_text" style="font-size:90%;">38.12</span></td>
</tr>
<tr id="S4.T5.4.1.8.7" class="ltx_tr">
<th id="S4.T5.4.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S4.T5.4.1.8.7.1.1" class="ltx_text" style="font-size:90%;">ActionFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.4.1.8.7.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib63" title="" class="ltx_ref">63</a><span id="S4.T5.4.1.8.7.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T5.4.1.8.7.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.8.7.2.1" class="ltx_text" style="font-size:90%;">85.23</span></td>
<td id="S4.T5.4.1.8.7.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.8.7.3.1" class="ltx_text" style="font-size:90%;">59.05</span></td>
<td id="S4.T5.4.1.8.7.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.8.7.4.1" class="ltx_text" style="font-size:90%;">00.93</span></td>
<td id="S4.T5.4.1.8.7.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.8.7.5.1" class="ltx_text" style="font-size:90%;">76.93</span></td>
<td id="S4.T5.4.1.8.7.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.8.7.6.1" class="ltx_text" style="font-size:90%;">77.19</span></td>
<td id="S4.T5.4.1.8.7.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.8.7.7.1" class="ltx_text" style="font-size:90%;">77.23</span></td>
<td id="S4.T5.4.1.8.7.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.8.7.8.1" class="ltx_text" style="font-size:90%;">77.23</span></td>
</tr>
<tr id="S4.T5.4.1.9.8" class="ltx_tr">
<th id="S4.T5.4.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S4.T5.4.1.9.8.1.1" class="ltx_text" style="font-size:90%;">BA-TFD+ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.4.1.9.8.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S4.T5.4.1.9.8.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T5.4.1.9.8.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.9.8.2.1" class="ltx_text" style="font-size:90%;">96.30</span></td>
<td id="S4.T5.4.1.9.8.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.9.8.3.1" class="ltx_text" style="font-size:90%;">84.96</span></td>
<td id="S4.T5.4.1.9.8.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.9.8.4.1" class="ltx_text" style="font-size:90%;">04.44</span></td>
<td id="S4.T5.4.1.9.8.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.9.8.5.1" class="ltx_text" style="font-size:90%;">78.75</span></td>
<td id="S4.T5.4.1.9.8.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.9.8.6.1" class="ltx_text" style="font-size:90%;">79.40</span></td>
<td id="S4.T5.4.1.9.8.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.9.8.7.1" class="ltx_text" style="font-size:90%;">80.48</span></td>
<td id="S4.T5.4.1.9.8.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.9.8.8.1" class="ltx_text" style="font-size:90%;">81.62</span></td>
</tr>
<tr id="S4.T5.4.1.10.9" class="ltx_tr">
<th id="S4.T5.4.1.10.9.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T5.4.1.10.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T5.4.1.10.9.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Our-MMMS-BA</span></th>
<td id="S4.T5.4.1.10.9.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.10.9.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">97.56</span></td>
<td id="S4.T5.4.1.10.9.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.10.9.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">95.25</span></td>
<td id="S4.T5.4.1.10.9.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.10.9.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">39.02</span></td>
<td id="S4.T5.4.1.10.9.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.10.9.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">89.42</span></td>
<td id="S4.T5.4.1.10.9.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.10.9.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">95.93</span></td>
<td id="S4.T5.4.1.10.9.8" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.10.9.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">93.45</span></td>
<td id="S4.T5.4.1.10.9.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.10.9.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">94.05</span></td>
</tr>
<tr id="S4.T5.4.1.11.10" class="ltx_tr">
<th id="S4.T5.4.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T5.4.1.11.10.1.1" class="ltx_text" style="font-size:90%;">TVIL</span></th>
<th id="S4.T5.4.1.11.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T5.4.1.11.10.2.1" class="ltx_text" style="font-size:90%;">Enc-Dec</span></th>
<td id="S4.T5.4.1.11.10.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.11.10.3.1" class="ltx_text" style="font-size:90%;">23.08</span></td>
<td id="S4.T5.4.1.11.10.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.11.10.4.1" class="ltx_text" style="font-size:90%;">08.45</span></td>
<td id="S4.T5.4.1.11.10.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.11.10.5.1" class="ltx_text" style="font-size:90%;">05.32</span></td>
<td id="S4.T5.4.1.11.10.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.11.10.6.1" class="ltx_text" style="font-size:90%;">17.16</span></td>
<td id="S4.T5.4.1.11.10.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.11.10.7.1" class="ltx_text" style="font-size:90%;">23.47</span></td>
<td id="S4.T5.4.1.11.10.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.11.10.8.1" class="ltx_text" style="font-size:90%;">43.98</span></td>
<td id="S4.T5.4.1.11.10.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T5.4.1.11.10.9.1" class="ltx_text" style="font-size:90%;">45.18</span></td>
</tr>
<tr id="S4.T5.4.1.12.11" class="ltx_tr">
<th id="S4.T5.4.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S4.T5.4.1.12.11.1.1" class="ltx_text" style="font-size:90%;">ActionFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.4.1.12.11.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib63" title="" class="ltx_ref">63</a><span id="S4.T5.4.1.12.11.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T5.4.1.12.11.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.12.11.2.1" class="ltx_text" style="font-size:90%;">86.27</span></td>
<td id="S4.T5.4.1.12.11.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.12.11.3.1" class="ltx_text" style="font-size:90%;">83.03</span></td>
<td id="S4.T5.4.1.12.11.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.12.11.4.1" class="ltx_text" style="font-size:90%;">28.17</span></td>
<td id="S4.T5.4.1.12.11.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.12.11.5.1" class="ltx_text" style="font-size:90%;">84.82</span></td>
<td id="S4.T5.4.1.12.11.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.12.11.6.1" class="ltx_text" style="font-size:90%;">85.77</span></td>
<td id="S4.T5.4.1.12.11.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.12.11.7.1" class="ltx_text" style="font-size:90%;">88.10</span></td>
<td id="S4.T5.4.1.12.11.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.12.11.8.1" class="ltx_text" style="font-size:90%;">88.49</span></td>
</tr>
<tr id="S4.T5.4.1.13.12" class="ltx_tr">
<th id="S4.T5.4.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S4.T5.4.1.13.12.1.1" class="ltx_text" style="font-size:90%;">BA-TFD+ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.4.1.13.12.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S4.T5.4.1.13.12.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T5.4.1.13.12.2" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.13.12.2.1" class="ltx_text" style="font-size:90%;">76.90</span></td>
<td id="S4.T5.4.1.13.12.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.13.12.3.1" class="ltx_text" style="font-size:90%;">38.50</span></td>
<td id="S4.T5.4.1.13.12.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.13.12.4.1" class="ltx_text" style="font-size:90%;">0.25</span></td>
<td id="S4.T5.4.1.13.12.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.13.12.5.1" class="ltx_text" style="font-size:90%;">66.90</span></td>
<td id="S4.T5.4.1.13.12.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.13.12.6.1" class="ltx_text" style="font-size:90%;">64.08</span></td>
<td id="S4.T5.4.1.13.12.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.13.12.7.1" class="ltx_text" style="font-size:90%;">60.77</span></td>
<td id="S4.T5.4.1.13.12.8" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.13.12.8.1" class="ltx_text" style="font-size:90%;">58.42</span></td>
</tr>
<tr id="S4.T5.4.1.14.13" class="ltx_tr">
<th id="S4.T5.4.1.14.13.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T5.4.1.14.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S4.T5.4.1.14.13.2.1" class="ltx_text" style="font-size:90%;">UMMAFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T5.4.1.14.13.2.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S4.T5.4.1.14.13.2.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<td id="S4.T5.4.1.14.13.3" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.14.13.3.1" class="ltx_text" style="font-size:90%;">88.68</span></td>
<td id="S4.T5.4.1.14.13.4" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.14.13.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">84.70</span></td>
<td id="S4.T5.4.1.14.13.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.14.13.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">62.43</span></td>
<td id="S4.T5.4.1.14.13.6" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.14.13.6.1" class="ltx_text" style="font-size:90%;">87.09</span></td>
<td id="S4.T5.4.1.14.13.7" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.14.13.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">88.21</span></td>
<td id="S4.T5.4.1.14.13.8" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.14.13.8.1" class="ltx_text" style="font-size:90%;">90.43</span></td>
<td id="S4.T5.4.1.14.13.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.4.1.14.13.9.1" class="ltx_text" style="font-size:90%;">91.16</span></td>
</tr>
<tr id="S4.T5.4.1.15.14" class="ltx_tr">
<th id="S4.T5.4.1.15.14.1" class="ltx_td ltx_th ltx_th_row ltx_border_b"></th>
<th id="S4.T5.4.1.15.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b"><span id="S4.T5.4.1.15.14.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Our-MMMS-BA</span></th>
<td id="S4.T5.4.1.15.14.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.4.1.15.14.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">96.87</span></td>
<td id="S4.T5.4.1.15.14.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.4.1.15.14.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">81.33</span></td>
<td id="S4.T5.4.1.15.14.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.4.1.15.14.5.1" class="ltx_text" style="font-size:90%;">28.43</span></td>
<td id="S4.T5.4.1.15.14.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.4.1.15.14.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">88.61</span></td>
<td id="S4.T5.4.1.15.14.7" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.4.1.15.14.7.1" class="ltx_text" style="font-size:90%;">87.83</span></td>
<td id="S4.T5.4.1.15.14.8" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.4.1.15.14.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">90.47</span></td>
<td id="S4.T5.4.1.15.14.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_b"><span id="S4.T5.4.1.15.14.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">92.91</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Deepfake Localization Performance</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p"><span id="S4.SS5.p1.1.1" class="ltx_text" style="font-size:90%;">Table </span><a href="#S4.T5" title="Table 5 ‣ 4.4 Comparison with the Published Audio-Visual Deepfake Detectors ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S4.SS5.p1.1.2" class="ltx_text" style="font-size:90%;"> shows the performance evaluation of the encoder-decoder (Enc-Dec), ActionFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib63" title="" class="ltx_ref">63</a><span id="S4.SS5.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS5.p1.1.5" class="ltx_text" style="font-size:90%;">, BA-TFD+ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p1.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S4.SS5.p1.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS5.p1.1.8" class="ltx_text" style="font-size:90%;">, UMMAFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p1.1.9.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S4.SS5.p1.1.10.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS5.p1.1.11" class="ltx_text" style="font-size:90%;"> and MMMS-BA based deepfake localization approaches when trained on AV-Deepfake1M and tested on LAV-DF, TVIL, and AV-Deepfake1M datasets. The Enc-Dec approach represents a sequence-to-sequence encoder-decoder-based architecture employed considering audio and visual modalities. For Enc-Dec, audio and visual encoders are used, and the hidden representations from these encoders are concatenated together, followed by two dense layers, and the output classification layer provides sequences.
The start and end timestamps of the fake sequences are the fake segments in a video. The results for methods ActionFormer, BA-TFD+, and UMMAFormer reported in Table </span><a href="#S4.T5" title="Table 5 ‣ 4.4 Comparison with the Published Audio-Visual Deepfake Detectors ‣ 4 Experimental Validations ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">5</span></a><span id="S4.SS5.p1.1.12" class="ltx_text" style="font-size:90%;"> are taken from the original papers </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p1.1.13.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S4.SS5.p1.1.14.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS5.p1.1.15" class="ltx_text" style="font-size:90%;">. Since the evaluation is done on the same datasets used in our study, it is a fair comparison.</span></p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.4" class="ltx_p"><span id="S4.SS5.p2.4.1" class="ltx_text" style="font-size:90%;">The Enc-Dec model obtained the lowest performance across all datasets and metrics. This is expected as it is based on simple feature concatenation from audio-visual streams and does not include any advanced processing techniques like attention mechanism.
On AV-Deepfake1M, the MMMS-BA model has obtained the best performance with AP@0.5 and AR@50 of </span><math id="S4.SS5.p2.1.m1.1" class="ltx_Math" alttext="62.75" display="inline"><semantics id="S4.SS5.p2.1.m1.1a"><mn mathsize="90%" id="S4.SS5.p2.1.m1.1.1" xref="S4.SS5.p2.1.m1.1.1.cmml">62.75</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b"><cn type="float" id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1">62.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">62.75</annotation></semantics></math><span id="S4.SS5.p2.4.2" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS5.p2.2.m2.1" class="ltx_Math" alttext="57.49" display="inline"><semantics id="S4.SS5.p2.2.m2.1a"><mn mathsize="90%" id="S4.SS5.p2.2.m2.1.1" xref="S4.SS5.p2.2.m2.1.1.cmml">57.49</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.2.m2.1b"><cn type="float" id="S4.SS5.p2.2.m2.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1">57.49</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.2.m2.1c">57.49</annotation></semantics></math><span id="S4.SS5.p2.4.3" class="ltx_text" style="font-size:90%;">, respectively. UMMAFormer is the second best model obtaining AP@0.5 and AR@0.5 of </span><math id="S4.SS5.p2.3.m3.1" class="ltx_Math" alttext="51.64" display="inline"><semantics id="S4.SS5.p2.3.m3.1a"><mn mathsize="90%" id="S4.SS5.p2.3.m3.1.1" xref="S4.SS5.p2.3.m3.1.1.cmml">51.64</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.3.m3.1b"><cn type="float" id="S4.SS5.p2.3.m3.1.1.cmml" xref="S4.SS5.p2.3.m3.1.1">51.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.3.m3.1c">51.64</annotation></semantics></math><span id="S4.SS5.p2.4.4" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS5.p2.4.m4.1" class="ltx_Math" alttext="48.86" display="inline"><semantics id="S4.SS5.p2.4.m4.1a"><mn mathsize="90%" id="S4.SS5.p2.4.m4.1.1" xref="S4.SS5.p2.4.m4.1.1.cmml">48.86</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.4.m4.1b"><cn type="float" id="S4.SS5.p2.4.m4.1.1.cmml" xref="S4.SS5.p2.4.m4.1.1">48.86</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.4.m4.1c">48.86</annotation></semantics></math><span id="S4.SS5.p2.4.5" class="ltx_text" style="font-size:90%;">, respectively. MMMS-BA has obtained better performance on the AV-Deepfake1M dataset when compared to the best model in  </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS5.p2.4.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S4.SS5.p2.4.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S4.SS5.p2.4.8" class="ltx_text" style="font-size:90%;">. However, the lower performance observed on the AV-Deepfake1M dataset, although it was used as a training set, underscores the highly realistic fake content generated in a content-driven manner, altering the real transcripts with replace, delete, and insert operations and the corresponding audio-visual modalities accordingly.</span></p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.4" class="ltx_p"><span id="S4.SS5.p3.4.1" class="ltx_text" style="font-size:90%;">When evaluated on the LAV-DF dataset, MMMS-BA obtained the best performance with an AP@0.5 and AR@50 of </span><math id="S4.SS5.p3.1.m1.1" class="ltx_Math" alttext="97.56" display="inline"><semantics id="S4.SS5.p3.1.m1.1a"><mn mathsize="90%" id="S4.SS5.p3.1.m1.1.1" xref="S4.SS5.p3.1.m1.1.1.cmml">97.56</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.1.m1.1b"><cn type="float" id="S4.SS5.p3.1.m1.1.1.cmml" xref="S4.SS5.p3.1.m1.1.1">97.56</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.1.m1.1c">97.56</annotation></semantics></math><span id="S4.SS5.p3.4.2" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS5.p3.2.m2.1" class="ltx_Math" alttext="93.45" display="inline"><semantics id="S4.SS5.p3.2.m2.1a"><mn mathsize="90%" id="S4.SS5.p3.2.m2.1.1" xref="S4.SS5.p3.2.m2.1.1.cmml">93.45</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.2.m2.1b"><cn type="float" id="S4.SS5.p3.2.m2.1.1.cmml" xref="S4.SS5.p3.2.m2.1.1">93.45</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.2.m2.1c">93.45</annotation></semantics></math><span id="S4.SS5.p3.4.3" class="ltx_text" style="font-size:90%;">, respectively. BA-TFD+ has obtained the second-best performance with an AP@0.5 and AR@50 of </span><math id="S4.SS5.p3.3.m3.1" class="ltx_Math" alttext="96.30" display="inline"><semantics id="S4.SS5.p3.3.m3.1a"><mn mathsize="90%" id="S4.SS5.p3.3.m3.1.1" xref="S4.SS5.p3.3.m3.1.1.cmml">96.30</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.3.m3.1b"><cn type="float" id="S4.SS5.p3.3.m3.1.1.cmml" xref="S4.SS5.p3.3.m3.1.1">96.30</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.3.m3.1c">96.30</annotation></semantics></math><span id="S4.SS5.p3.4.4" class="ltx_text" style="font-size:90%;"> and </span><math id="S4.SS5.p3.4.m4.1" class="ltx_Math" alttext="80.48" display="inline"><semantics id="S4.SS5.p3.4.m4.1a"><mn mathsize="90%" id="S4.SS5.p3.4.m4.1.1" xref="S4.SS5.p3.4.m4.1.1.cmml">80.48</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.4.m4.1b"><cn type="float" id="S4.SS5.p3.4.m4.1.1.cmml" xref="S4.SS5.p3.4.m4.1.1">80.48</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.4.m4.1c">80.48</annotation></semantics></math><span id="S4.SS5.p3.4.5" class="ltx_text" style="font-size:90%;">, respectively.
Although BA-TFD+ showed a smaller performance difference compared to MMMS-BA at lower threshold levels, it exhibited a larger performance difference at higher thresholds, indicating a less precise localization.</span></p>
</div>
<div id="S4.SS5.p4" class="ltx_para">
<p id="S4.SS5.p4.8" class="ltx_p"><span id="S4.SS5.p4.8.1" class="ltx_text" style="font-size:90%;">On the TVIL dataset, the MMMS-BA model demonstrated the best performance with an AP@0.5 of </span><math id="S4.SS5.p4.1.m1.1" class="ltx_Math" alttext="96.87" display="inline"><semantics id="S4.SS5.p4.1.m1.1a"><mn mathsize="90%" id="S4.SS5.p4.1.m1.1.1" xref="S4.SS5.p4.1.m1.1.1.cmml">96.87</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.1.m1.1b"><cn type="float" id="S4.SS5.p4.1.m1.1.1.cmml" xref="S4.SS5.p4.1.m1.1.1">96.87</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.1.m1.1c">96.87</annotation></semantics></math><span id="S4.SS5.p4.8.2" class="ltx_text" style="font-size:90%;"> and an AR@50 of </span><math id="S4.SS5.p4.2.m2.1" class="ltx_Math" alttext="90.47" display="inline"><semantics id="S4.SS5.p4.2.m2.1a"><mn mathsize="90%" id="S4.SS5.p4.2.m2.1.1" xref="S4.SS5.p4.2.m2.1.1.cmml">90.47</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.2.m2.1b"><cn type="float" id="S4.SS5.p4.2.m2.1.1.cmml" xref="S4.SS5.p4.2.m2.1.1">90.47</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.2.m2.1c">90.47</annotation></semantics></math><span id="S4.SS5.p4.8.3" class="ltx_text" style="font-size:90%;">. The UMMAFormer model followed closely with an AP@0.5 of </span><math id="S4.SS5.p4.3.m3.1" class="ltx_Math" alttext="88.68" display="inline"><semantics id="S4.SS5.p4.3.m3.1a"><mn mathsize="90%" id="S4.SS5.p4.3.m3.1.1" xref="S4.SS5.p4.3.m3.1.1.cmml">88.68</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.3.m3.1b"><cn type="float" id="S4.SS5.p4.3.m3.1.1.cmml" xref="S4.SS5.p4.3.m3.1.1">88.68</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.3.m3.1c">88.68</annotation></semantics></math><span id="S4.SS5.p4.8.4" class="ltx_text" style="font-size:90%;"> and an AR@50 of </span><math id="S4.SS5.p4.4.m4.1" class="ltx_Math" alttext="90.43" display="inline"><semantics id="S4.SS5.p4.4.m4.1a"><mn mathsize="90%" id="S4.SS5.p4.4.m4.1.1" xref="S4.SS5.p4.4.m4.1.1.cmml">90.43</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.4.m4.1b"><cn type="float" id="S4.SS5.p4.4.m4.1.1.cmml" xref="S4.SS5.p4.4.m4.1.1">90.43</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.4.m4.1c">90.43</annotation></semantics></math><span id="S4.SS5.p4.8.5" class="ltx_text" style="font-size:90%;">, and it achieved the highest scores for AP@0.75 (</span><math id="S4.SS5.p4.5.m5.1" class="ltx_Math" alttext="84.70" display="inline"><semantics id="S4.SS5.p4.5.m5.1a"><mn mathsize="90%" id="S4.SS5.p4.5.m5.1.1" xref="S4.SS5.p4.5.m5.1.1.cmml">84.70</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.5.m5.1b"><cn type="float" id="S4.SS5.p4.5.m5.1.1.cmml" xref="S4.SS5.p4.5.m5.1.1">84.70</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.5.m5.1c">84.70</annotation></semantics></math><span id="S4.SS5.p4.8.6" class="ltx_text" style="font-size:90%;">) and AP@0.95 (</span><math id="S4.SS5.p4.6.m6.1" class="ltx_Math" alttext="62.43" display="inline"><semantics id="S4.SS5.p4.6.m6.1a"><mn mathsize="90%" id="S4.SS5.p4.6.m6.1.1" xref="S4.SS5.p4.6.m6.1.1.cmml">62.43</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.6.m6.1b"><cn type="float" id="S4.SS5.p4.6.m6.1.1.cmml" xref="S4.SS5.p4.6.m6.1.1">62.43</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.6.m6.1c">62.43</annotation></semantics></math><span id="S4.SS5.p4.8.7" class="ltx_text" style="font-size:90%;">). The Enc-Dec model had the lowest performance with an AP@0.5 of </span><math id="S4.SS5.p4.7.m7.1" class="ltx_Math" alttext="23.08" display="inline"><semantics id="S4.SS5.p4.7.m7.1a"><mn mathsize="90%" id="S4.SS5.p4.7.m7.1.1" xref="S4.SS5.p4.7.m7.1.1.cmml">23.08</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.7.m7.1b"><cn type="float" id="S4.SS5.p4.7.m7.1.1.cmml" xref="S4.SS5.p4.7.m7.1.1">23.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.7.m7.1c">23.08</annotation></semantics></math><span id="S4.SS5.p4.8.8" class="ltx_text" style="font-size:90%;"> and an AR@50 of </span><math id="S4.SS5.p4.8.m8.1" class="ltx_Math" alttext="43.98" display="inline"><semantics id="S4.SS5.p4.8.m8.1a"><mn mathsize="90%" id="S4.SS5.p4.8.m8.1.1" xref="S4.SS5.p4.8.m8.1.1.cmml">43.98</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p4.8.m8.1b"><cn type="float" id="S4.SS5.p4.8.m8.1.1.cmml" xref="S4.SS5.p4.8.m8.1.1">43.98</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p4.8.m8.1c">43.98</annotation></semantics></math><span id="S4.SS5.p4.8.9" class="ltx_text" style="font-size:90%;"> due to its ineffective use of the available modality information.</span></p>
</div>
<div id="S4.SS5.p5" class="ltx_para">
<p id="S4.SS5.p5.1" class="ltx_p"><span id="S4.SS5.p5.1.1" class="ltx_text" style="font-size:90%;">In </span><span id="S4.SS5.p5.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">summary</span><span id="S4.SS5.p5.1.3" class="ltx_text" style="font-size:90%;">, the MMMS-BA model consistently demonstrated the best localization capability across all datasets. This is due to the utilization of contextual information across the sequences over existing methods, resulting in better robustness in deepfake localization.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">5 </span>Ablation Study</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text" style="font-size:90%;">An ablation study is conducted by varying the attention mechanism in the contextual cross-modal attention block in Figure </span><a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">1</span></a><span id="S5.p1.1.2" class="ltx_text" style="font-size:90%;"> resulting in two other variations, i.e., Multi-Modal Uni-Sequences - Self-Attention (MMUS-SA) and Multi-Sequence - Self-Attention (MS-SA). We also ablated between the bi-modal combination of the modalities considered, that is, the full face, voice, and lip region. The details given below.</span></p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Varying the Attention at Sequence and Modality Level</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p"><span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Multi-Modal Uni-Sequences - Self Attention (MMUS-SA) Framework</span><span id="S5.SS1.p1.1.2" class="ltx_text" style="font-size:90%;">: MMUS-SA framework does not account for information from other sequences at the attention level but utilizes multi-modal information of a single sequence for prediction. For more details on the calculation of attention in the MMUS-SA framework refer to the Appendix, section </span><math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mn mathsize="90%" id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn type="integer" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">2</annotation></semantics></math><span id="S5.SS1.p1.1.3" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Multi-Sequence - Self Attention (MS-SA) Framework</span><span id="S5.SS1.p2.1.2" class="ltx_text" style="font-size:90%;">: In the MS-SA framework, we apply self-attention to the sequences of each modality separately and use these for classification. For more details on the calculation of attention in the MMUS-SA framework refer to the Appendix, section </span><math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mn mathsize="90%" id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><cn type="integer" id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">2</annotation></semantics></math><span id="S5.SS1.p2.1.3" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p"><span id="S5.SS1.p3.1.1" class="ltx_text" style="font-size:90%;">Table </span><a href="#S5.T6" title="Table 6 ‣ 5.1 Varying the Attention at Sequence and Modality Level ‣ 5 Ablation Study ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">6</span></a><span id="S5.SS1.p3.1.2" class="ltx_text" style="font-size:90%;"> shows the performance of the MMUS-SA and MS-SA models over MMMS-BA when trained and tested on FakeAVCeleb. From the results obtained, it is evident that MMMS-BA has obtained the best performance with the lowest EER of </span><math id="S5.SS1.p3.1.m1.1" class="ltx_Math" alttext="0.029" display="inline"><semantics id="S5.SS1.p3.1.m1.1a"><mn mathsize="90%" id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml">0.029</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><cn type="float" id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">0.029</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">0.029</annotation></semantics></math><span id="S5.SS1.p3.1.3" class="ltx_text" style="font-size:90%;">. The MMUS-SA model has a closer performance with the MMMS-BA variation but has a higher EER. This suggests that incorporating self-attention into a single sequence in multiple modalities achieved a closer AUC, but was unable to obtain a low EER. However, MS-SA has obtained the lowest performance when compared to the other two variations. The reason is that MS-SA does not incorporate the interaction between the modalities for multi-modal manipulation detection.</span></p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p"><span id="S5.SS1.p4.1.1" class="ltx_text" style="font-size:90%;">In </span><span id="S5.SS1.p4.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">summary</span><span id="S5.SS1.p4.1.3" class="ltx_text" style="font-size:90%;">, MS-SA and MMUS-SA attention methods typically identify important features within a modality over multiple sequences and a single sequence across different modalities, respectively. However, the proposed MMMS-BA model is specifically designed to understand the intricate relationship between different modalities over multiple sequences, leading to a more robust representation of the data and enhanced performance. Consequently, obtaining better performance over MMUS-SA and MS-SA. This confirms the importance of using interactions between both multi-sequences and multi-modalities for deepfake detection.</span></p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance comparison of MMMS-BA with MMUS-BA and MS-SA models with varied attention mechanism, trained and tested on FakeAVCeleb dataset.</figcaption>
<div id="S5.T6.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:215.9pt;height:59.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-22.1pt,6.1pt) scale(0.83,0.83) ;">
<table id="S5.T6.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T6.4.1.1.1" class="ltx_tr">
<th id="S5.T6.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T6.4.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Model</span></th>
<td id="S5.T6.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AUC</span></td>
<td id="S5.T6.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">pAUC</span></td>
<td id="S5.T6.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">EER</span></td>
<td id="S5.T6.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">ACC</span></td>
<td id="S5.T6.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">TPR</span></td>
<td id="S5.T6.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.4.1.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">FPR</span></td>
</tr>
<tr id="S5.T6.4.1.2.2" class="ltx_tr">
<th id="S5.T6.4.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T6.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">MMUS-SA</span></th>
<td id="S5.T6.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.2.2.2.1" class="ltx_text" style="font-size:90%;">0.989</span></td>
<td id="S5.T6.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.2.2.3.1" class="ltx_text" style="font-size:90%;">0.978</span></td>
<td id="S5.T6.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.2.2.4.1" class="ltx_text" style="font-size:90%;">0.033</span></td>
<td id="S5.T6.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.2.2.5.1" class="ltx_text" style="font-size:90%;">0.979</span></td>
<td id="S5.T6.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.2.2.6.1" class="ltx_text" style="font-size:90%;">0.963</span></td>
<td id="S5.T6.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.4.1.2.2.7.1" class="ltx_text" style="font-size:90%;">0.039</span></td>
</tr>
<tr id="S5.T6.4.1.3.3" class="ltx_tr">
<th id="S5.T6.4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T6.4.1.3.3.1.1" class="ltx_text" style="font-size:90%;">MS-SA</span></th>
<td id="S5.T6.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.3.3.2.1" class="ltx_text" style="font-size:90%;">0.977</span></td>
<td id="S5.T6.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.3.3.3.1" class="ltx_text" style="font-size:90%;">0.956</span></td>
<td id="S5.T6.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.3.3.4.1" class="ltx_text" style="font-size:90%;">0.045</span></td>
<td id="S5.T6.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.3.3.5.1" class="ltx_text" style="font-size:90%;">0.965</span></td>
<td id="S5.T6.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.4.1.3.3.6.1" class="ltx_text" style="font-size:90%;">0.943</span></td>
<td id="S5.T6.4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.4.1.3.3.7.1" class="ltx_text" style="font-size:90%;">0.051</span></td>
</tr>
<tr id="S5.T6.4.1.4.4" class="ltx_tr">
<th id="S5.T6.4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T6.4.1.4.4.1.1" class="ltx_text" style="font-size:90%;">MMMS-BA</span></th>
<td id="S5.T6.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T6.4.1.4.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.989</span></td>
<td id="S5.T6.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T6.4.1.4.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.977</span></td>
<td id="S5.T6.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T6.4.1.4.4.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.029</span></td>
<td id="S5.T6.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T6.4.1.4.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.979</span></td>
<td id="S5.T6.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T6.4.1.4.4.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.965</span></td>
<td id="S5.T6.4.1.4.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S5.T6.4.1.4.4.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.039</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Performance of MMMS-BA on Different Combination of Modalities</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.4" class="ltx_p"><span id="S5.SS2.p1.4.1" class="ltx_text" style="font-size:90%;">In this study, we ablated between the combination of modalities (V-full visual face, L-lip sequence, and A-audio) and evaluated the performance of MMMS-BA when trained and tested on FakeAVCeleb.
Table </span><a href="#S5.T7" title="Table 7 ‣ 5.2 Performance of MMMS-BA on Different Combination of Modalities ‣ 5 Ablation Study ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">7</span></a><span id="S5.SS2.p1.4.2" class="ltx_text" style="font-size:90%;"> illustrates the role of different modalities in enhancing detection accuracy.
As can be seen, the combination of visual and lip (V + L) obtained the lowest performance with an AUC of </span><math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="0.814" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mn mathsize="90%" id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">0.814</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><cn type="float" id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">0.814</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">0.814</annotation></semantics></math><span id="S5.SS2.p1.4.3" class="ltx_text" style="font-size:90%;">. This result can be attributed to the absence of audio data, which limits the model to visual information alone.
The combination of lip and audio (L + A) obtained a performance improvement over (V + L) with an increase in AUC of </span><math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="0.11" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mn mathsize="90%" id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">0.11</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><cn type="float" id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">0.11</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">0.11</annotation></semantics></math><span id="S5.SS2.p1.4.4" class="ltx_text" style="font-size:90%;">. This enhancement suggests that incorporating audio data alongside lip sequences provides complementary information, enhancing the model’s performance.
The combination of visual and audio (V+A) obtained further improvement over (V+L and L+A) with an AUC of </span><math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="0.955" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><mn mathsize="90%" id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">0.955</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><cn type="float" id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">0.955</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">0.955</annotation></semantics></math><span id="S5.SS2.p1.4.5" class="ltx_text" style="font-size:90%;">. This integration demonstrates that including audio features with full-face visual data offers additional insights, thereby boosting detection accuracy beyond the (V + L) and (L + A) combinations. The best performance is obtained by combining (V+L+A) with an average increment in AUC of </span><math id="S5.SS2.p1.4.m4.1" class="ltx_Math" alttext="0.091" display="inline"><semantics id="S5.SS2.p1.4.m4.1a"><mn mathsize="90%" id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">0.091</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><cn type="float" id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">0.091</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">0.091</annotation></semantics></math><span id="S5.SS2.p1.4.6" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p"><span id="S5.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">In </span><span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">summary</span><span id="S5.SS2.p2.1.3" class="ltx_text" style="font-size:90%;">, this analysis suggests that incorporating lip sequence data along with (V+A) contributes significantly to the effectiveness of the model. Full-face images encompass a complex mix of facial features, making it challenging for the model to isolate and differentiate inconsistencies in the lip region effectively.
Thus, the additional lip modality enriched the information available to the model, ultimately improving its discriminatory power and performance, also supported by the NPVForensics model </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS2.p2.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S5.SS2.p2.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S5.SS2.p2.1.6" class="ltx_text" style="font-size:90%;"> for audio-visual deepfake detection.</span></p>
</div>
<figure id="S5.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 7: </span>Performance comparison of MMMS-BA with different bi-modal combinations (V-full visual face, L-lip sequence, and A-audio) when trained and tested on the FakeAVCeleb dataset.</figcaption>
<div id="S5.T7.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:215.3pt;height:63.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-44.0pt,13.1pt) scale(0.71,0.71) ;">
<table id="S5.T7.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T7.4.1.1.1" class="ltx_tr">
<th id="S5.T7.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.4.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Model and Modalities</span></th>
<td id="S5.T7.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AUC</span></td>
<td id="S5.T7.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">pAUC</span></td>
<td id="S5.T7.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">EER</span></td>
<td id="S5.T7.4.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">ACC</span></td>
<td id="S5.T7.4.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.1.1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">TPR</span></td>
<td id="S5.T7.4.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.4.1.1.1.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">FPR</span></td>
</tr>
<tr id="S5.T7.4.1.2.2" class="ltx_tr">
<th id="S5.T7.4.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.4.1.2.2.1.1" class="ltx_text" style="font-size:90%;">MMMS-BA (V+A)</span></th>
<td id="S5.T7.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.2.2.2.1" class="ltx_text" style="font-size:90%;">0.955</span></td>
<td id="S5.T7.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.2.2.3.1" class="ltx_text" style="font-size:90%;">0.941</span></td>
<td id="S5.T7.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.2.2.4.1" class="ltx_text" style="font-size:90%;">0.074</span></td>
<td id="S5.T7.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.2.2.5.1" class="ltx_text" style="font-size:90%;">0.939</span></td>
<td id="S5.T7.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.2.2.6.1" class="ltx_text" style="font-size:90%;">0.922</span></td>
<td id="S5.T7.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.4.1.2.2.7.1" class="ltx_text" style="font-size:90%;">0.095</span></td>
</tr>
<tr id="S5.T7.4.1.3.3" class="ltx_tr">
<th id="S5.T7.4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.4.1.3.3.1.1" class="ltx_text" style="font-size:90%;">MMMS-BA (V+L)</span></th>
<td id="S5.T7.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.3.3.2.1" class="ltx_text" style="font-size:90%;">0.814</span></td>
<td id="S5.T7.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.3.3.3.1" class="ltx_text" style="font-size:90%;">0.798</span></td>
<td id="S5.T7.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.3.3.4.1" class="ltx_text" style="font-size:90%;">0.263</span></td>
<td id="S5.T7.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.3.3.5.1" class="ltx_text" style="font-size:90%;">0.736</span></td>
<td id="S5.T7.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.3.3.6.1" class="ltx_text" style="font-size:90%;">0.818</span></td>
<td id="S5.T7.4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.4.1.3.3.7.1" class="ltx_text" style="font-size:90%;">0.345</span></td>
</tr>
<tr id="S5.T7.4.1.4.4" class="ltx_tr">
<th id="S5.T7.4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.4.1.4.4.1.1" class="ltx_text" style="font-size:90%;">MMMS-BA (L+A)</span></th>
<td id="S5.T7.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.4.4.2.1" class="ltx_text" style="font-size:90%;">0.924</span></td>
<td id="S5.T7.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.4.4.3.1" class="ltx_text" style="font-size:90%;">0.907</span></td>
<td id="S5.T7.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.4.4.4.1" class="ltx_text" style="font-size:90%;">0.175</span></td>
<td id="S5.T7.4.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.4.4.5.1" class="ltx_text" style="font-size:90%;">0.823</span></td>
<td id="S5.T7.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.4.1.4.4.6.1" class="ltx_text" style="font-size:90%;">0.931</span></td>
<td id="S5.T7.4.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.4.1.4.4.7.1" class="ltx_text" style="font-size:90%;">0.282</span></td>
</tr>
<tr id="S5.T7.4.1.5.5" class="ltx_tr">
<th id="S5.T7.4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T7.4.1.5.5.1.1" class="ltx_text" style="font-size:90%;">MMMS-BA (V+L+A)</span></th>
<td id="S5.T7.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T7.4.1.5.5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.989</span></td>
<td id="S5.T7.4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T7.4.1.5.5.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.978</span></td>
<td id="S5.T7.4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T7.4.1.5.5.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.033</span></td>
<td id="S5.T7.4.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T7.4.1.5.5.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.979</span></td>
<td id="S5.T7.4.1.5.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T7.4.1.5.5.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.963</span></td>
<td id="S5.T7.4.1.5.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S5.T7.4.1.5.5.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.039</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text" style="font-size:90%;">With the rapid evolution of deepfake techniques combining synthesized audio with forged videos, there is an urgent need for robust audio-visual deepfake detection and localization techniques. Current audio-visual deepfake detection approaches relying on fusing audio and visual streams employing basic attention mechanisms, overlook intricate inter-modal relationships crucial for accurate detection. To address this challenge, we introduced the MMMS-BA framework. This framework effectively captures intra- and inter-modal correlations by applying attention to multi-modal multi-sequence representations and learns the contributing features among
them for effective deepfake detection and localization
Our experimental findings demonstrate that MMMS-BA outperforms existing audio-visual deepfake detectors, achieving SOTA performance in detecting and localizing deepfake segments within videos.</span></p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text" style="font-size:90%;">Given the proliferation of AI-generated content using sophisticated generative models, tackling emerging forms of content manipulation remains a critical challenge. Therefore, as part of future research directions, we will extend our framework to incorporate text analysis along with audio and visual modalities to ensure robust protection against misleading multimedia content. In addition, our model will be adapted to account for missing modalities during the training and inference stage.
</span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
D. Afchar, V. Nozick, J. Yamagishi, and I. Echizen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Mesonet: a compact facial video forgery detection network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE International Workshop on Information Forensics and Security (WIFS)</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 1–7, 2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
S. Agarwal, H. Farid, T. El-Gaaly, and S.-N. Lim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Detecting deep-fake videos from appearance and behavior.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE International Workshop on Information Forensics and Security (WIFS)</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 1–6, 2020.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
S. Agarwal, H. Farid, O. Fried, and M. Agrawala.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Detecting deep-fake videos from phoneme-viseme mismatches.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 660–661, 2020.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
S. Agarwal, L. Hu, E. Ng, T. Darrell, H. Li, and A. Rohrbach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Watch those words: Video falsification detection using word-conditioned facial motion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 4710–4719, 2023.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
S. Asha, P. Vinod, and V. G. Menon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">A defensive attention mechanism to detect deepfake content across multiple modalities.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Multimedia Systems</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 30(1):56, 2024.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
A. Bagchi, J. Mahmood, D. Fernandes, and R. K. Sarvadevabhatla.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Hear me out: Fusional approaches for audio augmented temporal action localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.14118</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
N. Bodla, B. Singh, R. Chellappa, and L. S. Davis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Soft-nms–improving object detection with one line of code.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer vision</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 5561–5569, 2017.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Z. Cai, S. Ghosh, A. P. Adatia, M. Hayat, A. Dhall, and K. Stefanov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Av-deepfake1m: A large-scale llm-driven audio-visual deepfake dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2311.15308</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Z. Cai, S. Ghosh, T. Gedeon, A. Dhall, K. Stefanov, and M. Hayat.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">” glitch in the matrix!”: A large scale benchmark for content driven audio-visual forgery detection and localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2305.01979</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Z. Cai, K. Stefanov, A. Dhall, and M. Hayat.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Do you really mean that? content driven audio-visual deepfake dataset and multimodal method for temporal forgery localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 International Conference on Digital Image Computing: Techniques and Applications (DICTA)</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, pages 1–10. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Y. Chen, Y. Yu, R. Ni, Y. Zhao, and H. Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Npvforensics: Jointing non-critical phonemes and visemes for deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2306.06885</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
H. Cheng, Y. Guo, T. Wang, Q. Li, X. Chang, and L. Nie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Voice-face homogeneity tells deepfake.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Multimedia Computing, Communications and Applications</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 20(3):1–22, 2023.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
A. Chintha, B. Thai, S. J. Sohrawardi, K. Bhatt, A. Hickerson, M. Wright, and R. Ptucha.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Recurrent convolutional structures for audio spoof and video deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Journal of Selected Topics in Signal Processing</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">, 14(5):1024–1037, 2020.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Y. Choi, M. Choi, M. Kim, J.-W. Ha, S. Kim, and J. Choo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, June 2018.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
K. Chugh, P. Gupta, A. Dhall, and R. Subramanian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Not made for each other- audio-visual dissonance-based deepfake detection and localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 28th ACM International Conference on Multimedia</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, MM ’20, page 439–447, New York, NY, USA, 2020. Association for Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
J. S. Chung, A. Nagrani, and A. Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">VoxCeleb2: Deep Speaker Recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Interspeech 2018</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 1086–1090, 2018.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
D. Citron.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">How deepfakes undermine truth and threaten democracy.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
D. Cozzolino, A. Pianese, M. Nießner, and L. Verdoliva.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Audio-visual person-of-interest deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 943–952, 2023.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
M. Elpeltagy, A. Ismail, M. S. Zaki, and K. Eldahshan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">A novel smart deepfake video detection system.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Journal of Advanced Computer Science and Applications</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, 14(1), 2023.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
C. Feng, Z. Chen, and A. Owens.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Self-supervised video forensics by audio-visual anomaly detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 10491–10503, 2023.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
J. Gao, K. Chen, and R. Nevatia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Ctap: Complementary temporal action proposal generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European conference on computer vision (ECCV)</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 68–83, 2018.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
J. Gao, Z. Yang, K. Chen, C. Sun, and R. Nevatia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Turn tap: Temporal unit regression network for temporal action proposals.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer vision</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 3628–3636, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
A. Haliassos, K. Vougioukas, S. Petridis, and M. Pantic.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Lips don’t lie: A generalisable and robust approach to face forgery detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 5037–5047, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
A. Hamza, A. R. R. Javed, F. Iqbal, N. Kryvinska, A. S. Almadhor, Z. Jalil, and R. Borghol.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Deepfake audio detection via mfcc features using machine learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 10:134018–134028, 2022.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
T. Hwang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Deepfakes: A grounded threat assessment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">Technical report, Georgetown University, July 2020.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
H. Ilyas, A. Javed, and K. M. Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Avfakenet: A unified end-to-end dense swin transformer deep learning model for audio–visual deepfakes detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Applied Soft Computing</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:90%;">, 136:110124, 2023.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
V. S. Katamneni, A. V. Nadimpalli, and A. Rattani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Demographic fairness and accountability of audio and video-based unimodal and bi-modal deepfake detectors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In T. Bourlai, editor, </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Face Recognition Across the Imaging Spectrum (FRAIS)</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">. Springer, 2023.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
H. Khalid, M. Kim, S. Tariq, and S. S. Woo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Evaluation of an audio-video multimodal deepfake dataset using unimodal and multimodal detectors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 1st Workshop on Synthetic Multimedia - Audiovisual Deepfake Generation and Detection</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, ADGD ’21, page 7–15, New York, NY, USA, 2021. Association for Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
H. Khalid, S. Tariq, M. Kim, and S. S. Woo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Fakeavceleb: A novel audio-video multimodal deepfake dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2108.05080</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
H. Khalid, S. Tariq, and S. S. Woo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Fakeavceleb: A novel audio-video multimodal deepfake dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, abs/2108.05080, 2021.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
J. K. Lewis, I. E. Toubal, H. Chen, V. Sandesera, M. Lomnitz, Z. Hampel-Arias, C. Prasad, and K. Palaniappan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Deepfake video detection based on spatial, spectral, and temporal inconsistencies using multimodal deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages 1–9. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
L. Li, J. Bao, T. Zhang, H. Yang, D. Chen, F. Wen, and B. Guo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Face x-ray for more general face forgery detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, pages 5000–5009, 2020.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Y. Li and S. Lyu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Exposing deepfake videos by detecting face warping artifacts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Focal loss for dense object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer vision</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 2980–2988, 2017.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
X. Liu, Y. Yu, X. Li, and Y. Zhao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Magnifying multimodal forgery clues for deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Signal Processing: Image Communication</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, 118:117010, 2023.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
X. Liu, Y. Yu, X. Li, and Y. Zhao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Mcl: multimodal contrastive learning for deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Circuits and Systems for Video Technology</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
M. Masood, A. Javed, and A. Irtaza.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Attention-based multimodal learning framework for generalized audio-visual deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PREPRINT Research Square : rs.3.rs-3415144/v1</span><span id="bib.bib37.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
T. Mittal, U. Bhattacharya, R. Chandra, A. Bera, and D. Manocha.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Emotions don’t lie: An audio-visual deepfake detection method using affective cues.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 28th ACM International Conference on Multimedia</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, MM ’20, page 2823–2832, New York, NY, USA, 2020. Association for Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
L. Muda, M. Begam, and I. Elamvazuthi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Voice recognition algorithms using mel frequency cepstral coefficient (mfcc) and dynamic time warping (dtw) techniques.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib39.4.2" class="ltx_text" style="font-size:90%;">, abs/1003.4083, 2010.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
A. V. Nadimpalli and A. Rattani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Gbdf: Gender balanced deepfake dataset towards fair deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ArXiv</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, abs/2207.10246, 2022.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
A. V. Nadimpalli and A. Rattani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Proactive deepfake detection using gan-based visible watermarking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Trans. Multimedia Comput. Commun. Appl.</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:90%;">, Sep 2023.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
R. Nekadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Siamese Network-based Multi-modal Deepfake Detection</span><span id="bib.bib42.3.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.4.1" class="ltx_text" style="font-size:90%;">University of Missouri-Kansas City, 2020.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
T. T. Nguyen, C. M. Nguyen, D. Nguyen, D. T. Nguyen, and S. Nahavandi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Deep learning for deepfakes creation and detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ArXiv</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:90%;">, abs/1909.11573, 2019.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Y. Nirkin, Y. Keller, and T. Hassner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Fsgan: Subject agnostic face swapping and reenactment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">, October 2019.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
T. Oorloff, S. Koppisetti, N. Bonettini, D. Solanki, B. Colman, Y. Yacoob, A. Shahriyari, and G. Bharaj.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Avff: Audio-visual feature fusion for video deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv e-prints</span><span id="bib.bib45.4.2" class="ltx_text" style="font-size:90%;">, pages arXiv–2406, 2024.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
A. Pianese, D. Cozzolino, G. Poggi, and L. Verdoliva.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Deepfake audio detection by speaker verification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE International Workshop on Information Forensics and Security (WIFS)</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">, pages 1–6. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Y. Qian, Z. Chen, and S. Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">Audio-visual deep neural network for robust person verification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/ACM Transactions on Audio, Speech, and Language Processing</span><span id="bib.bib47.4.2" class="ltx_text" style="font-size:90%;">, 29:1079–1092, 2021.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
M. A. Raza and K. M. Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Multimodaltrace: Deepfake detection using audiovisual representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib48.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib48.5.3" class="ltx_text" style="font-size:90%;">, pages 993–1000, 2023.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
H. Rezatofighi, N. Tsoi, J. Gwak, A. Sadeghian, I. Reid, and S. Savarese.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Generalized intersection over union: A metric and a loss for bounding box regression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span id="bib.bib49.5.3" class="ltx_text" style="font-size:90%;">, pages 658–666, 2019.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
A. Rössler, D. Cozzolino, L. Verdoliva, C. Riess, J. Thies, and M. Niessner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Faceforensics++: Learning to detect manipulated facial images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, pages 1–11, 2019.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
D. Salvi, B. Hosler, P. Bestagini, M. C. Stamm, and S. Tubaro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Timit-tts: A text-to-speech dataset for multimodal synthetic media detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib51.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
R. Shao, T. Wu, J. Wu, L. Nie, and Z. Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Detecting and grounding multi-modal media manipulation and beyond.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib52.4.2" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
V. Sree Katamneni and A. Rattani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Mis-avoidd: Modality invariant and specific representation for audio-visual deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv e-prints</span><span id="bib.bib53.4.2" class="ltx_text" style="font-size:90%;">, pages arXiv–2310, 2023.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
C. Sun, S. Jia, S. Hou, and S. Lyu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Ai-synthesized voice detection using neural vocoder artifacts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2304.13085</span><span id="bib.bib54.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
C.-S. Sung, J.-C. Chen, and C.-S. Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">Hearing and seeing abnormality: Self-supervised audio-visual mutual learning for deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib55.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib55.5.3" class="ltx_text" style="font-size:90%;">, pages 1–5, 2023.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
C.-S. Sung, J.-C. Chen, and C.-S. Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">Hearing and seeing abnormality: Self-supervised audio-visual mutual learning for deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib56.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib56.5.3" class="ltx_text" style="font-size:90%;">, pages 1–5. IEEE, 2023.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
M. Tian, M. Khayatkhoei, J. Mathai, and W. AbdAlmageed.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Unsupervised multimodal deepfake detection using intra-and cross-modal inconsistencies.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2311.17088</span><span id="bib.bib57.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
R. Tolosana, R. Vera-Rodríguez, J. Fierrez, A. Morales, and J. Ortega-Garcia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.2.1" class="ltx_text" style="font-size:90%;">Deepfakes and beyond: A survey of face manipulation and fake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Inf. Fusion</span><span id="bib.bib58.4.2" class="ltx_text" style="font-size:90%;">, 64:131–148, 2020.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text" style="font-size:90%;">
G. Wang, P. Zhang, L. Xie, W. Huang, Y. Zha, and Y. Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.2.1" class="ltx_text" style="font-size:90%;">An audio-visual attention based multimodal network for fake talking face videos detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2203.05178</span><span id="bib.bib59.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text" style="font-size:90%;">
N. Xu, L. Yang, Y. Fan, J. Yang, D. Yue, Y. Liang, B. Price, S. Cohen, and T. Huang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.2.1" class="ltx_text" style="font-size:90%;">Youtube-vos: Sequence-to-sequence video object segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib60.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European conference on computer vision (ECCV)</span><span id="bib.bib60.5.3" class="ltx_text" style="font-size:90%;">, pages 585–601, 2018.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text" style="font-size:90%;">
T. Xu, P. Zhang, Q. Huang, H. Zhang, Z. Gan, X. Huang, and X. He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.2.1" class="ltx_text" style="font-size:90%;">Attngan: Fine-grained text to image generation with attentional generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib61.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib61.5.3" class="ltx_text" style="font-size:90%;">, June 2018.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text" style="font-size:90%;">
Y. Yu, X. Liu, R. Ni, S. Yang, Y. Zhao, and A. C. Kot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.2.1" class="ltx_text" style="font-size:90%;">Pvass-mdd: predictive visual-audio alignment self-supervision for multimodal deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Circuits and Systems for Video Technology</span><span id="bib.bib62.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text" style="font-size:90%;">
C.-L. Zhang, J. Wu, and Y. Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.2.1" class="ltx_text" style="font-size:90%;">Actionformer: Localizing moments of actions with transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib63.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib63.5.3" class="ltx_text" style="font-size:90%;">, pages 492–510. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text" style="font-size:90%;">
R. Zhang, H. Wang, M. Du, H. Liu, Y. Zhou, and Q. Zeng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.2.1" class="ltx_text" style="font-size:90%;">Ummaformer: A universal multimodal-adaptive transformer framework for temporal forgery localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib64.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 31st ACM International Conference on Multimedia</span><span id="bib.bib64.5.3" class="ltx_text" style="font-size:90%;">, pages 8749–8759, 2023.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text" style="font-size:90%;">
T. Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.2.1" class="ltx_text" style="font-size:90%;">Deepfake generation and detection, a survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Multimedia Tools and Applications</span><span id="bib.bib65.4.2" class="ltx_text" style="font-size:90%;">, 81(5):6259–6276, 2022.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text" style="font-size:90%;">
Y. Zhang, J. Zhan, W. Jiang, and Z. Fan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.2.1" class="ltx_text" style="font-size:90%;">Deepfake detection based on incompatibility between multiple modes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib66.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 International Conference on Intelligent Technology and Embedded Systems (ICITES)</span><span id="bib.bib66.5.3" class="ltx_text" style="font-size:90%;">, pages 1–7. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text" style="font-size:90%;">
L. Zhao, M. Zhang, H. Ding, and X. Cui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.2.1" class="ltx_text" style="font-size:90%;">Fine-grained deepfake detection based on cross-modality attention.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Neural Computing and Applications</span><span id="bib.bib67.4.2" class="ltx_text" style="font-size:90%;">, pages 1–14, 2023.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text" style="font-size:90%;">
Y. Zhou and S.-N. Lim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.2.1" class="ltx_text" style="font-size:90%;">Joint audio-visual deepfake detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib68.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</span><span id="bib.bib68.5.3" class="ltx_text" style="font-size:90%;">, pages 14800–14809, 2021.
</span>
</span>
</li>
</ul>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">7 </span>Supplementary Material</h2>

<figure id="S7.F3" class="ltx_figure"><img src="/html/2408.01532/assets/Attention_computation.png" id="S7.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="389" height="183" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Multi-Modal Multi-Sequence Attention computation of Audio and Full Visual Face Modalities (<math id="S7.F3.2.m1.1" class="ltx_Math" alttext="MMMS\text{-}BA_{AV}" display="inline"><semantics id="S7.F3.2.m1.1b"><mrow id="S7.F3.2.m1.1.1" xref="S7.F3.2.m1.1.1.cmml"><mi id="S7.F3.2.m1.1.1.2" xref="S7.F3.2.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S7.F3.2.m1.1.1.1" xref="S7.F3.2.m1.1.1.1.cmml">​</mo><mi id="S7.F3.2.m1.1.1.3" xref="S7.F3.2.m1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S7.F3.2.m1.1.1.1b" xref="S7.F3.2.m1.1.1.1.cmml">​</mo><mi id="S7.F3.2.m1.1.1.4" xref="S7.F3.2.m1.1.1.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S7.F3.2.m1.1.1.1c" xref="S7.F3.2.m1.1.1.1.cmml">​</mo><mi id="S7.F3.2.m1.1.1.5" xref="S7.F3.2.m1.1.1.5.cmml">S</mi><mo lspace="0em" rspace="0em" id="S7.F3.2.m1.1.1.1d" xref="S7.F3.2.m1.1.1.1.cmml">​</mo><mtext id="S7.F3.2.m1.1.1.6" xref="S7.F3.2.m1.1.1.6a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S7.F3.2.m1.1.1.1e" xref="S7.F3.2.m1.1.1.1.cmml">​</mo><mi id="S7.F3.2.m1.1.1.7" xref="S7.F3.2.m1.1.1.7.cmml">B</mi><mo lspace="0em" rspace="0em" id="S7.F3.2.m1.1.1.1f" xref="S7.F3.2.m1.1.1.1.cmml">​</mo><msub id="S7.F3.2.m1.1.1.8" xref="S7.F3.2.m1.1.1.8.cmml"><mi id="S7.F3.2.m1.1.1.8.2" xref="S7.F3.2.m1.1.1.8.2.cmml">A</mi><mrow id="S7.F3.2.m1.1.1.8.3" xref="S7.F3.2.m1.1.1.8.3.cmml"><mi id="S7.F3.2.m1.1.1.8.3.2" xref="S7.F3.2.m1.1.1.8.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S7.F3.2.m1.1.1.8.3.1" xref="S7.F3.2.m1.1.1.8.3.1.cmml">​</mo><mi id="S7.F3.2.m1.1.1.8.3.3" xref="S7.F3.2.m1.1.1.8.3.3.cmml">V</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.F3.2.m1.1c"><apply id="S7.F3.2.m1.1.1.cmml" xref="S7.F3.2.m1.1.1"><times id="S7.F3.2.m1.1.1.1.cmml" xref="S7.F3.2.m1.1.1.1"></times><ci id="S7.F3.2.m1.1.1.2.cmml" xref="S7.F3.2.m1.1.1.2">𝑀</ci><ci id="S7.F3.2.m1.1.1.3.cmml" xref="S7.F3.2.m1.1.1.3">𝑀</ci><ci id="S7.F3.2.m1.1.1.4.cmml" xref="S7.F3.2.m1.1.1.4">𝑀</ci><ci id="S7.F3.2.m1.1.1.5.cmml" xref="S7.F3.2.m1.1.1.5">𝑆</ci><ci id="S7.F3.2.m1.1.1.6a.cmml" xref="S7.F3.2.m1.1.1.6"><mtext id="S7.F3.2.m1.1.1.6.cmml" xref="S7.F3.2.m1.1.1.6">-</mtext></ci><ci id="S7.F3.2.m1.1.1.7.cmml" xref="S7.F3.2.m1.1.1.7">𝐵</ci><apply id="S7.F3.2.m1.1.1.8.cmml" xref="S7.F3.2.m1.1.1.8"><csymbol cd="ambiguous" id="S7.F3.2.m1.1.1.8.1.cmml" xref="S7.F3.2.m1.1.1.8">subscript</csymbol><ci id="S7.F3.2.m1.1.1.8.2.cmml" xref="S7.F3.2.m1.1.1.8.2">𝐴</ci><apply id="S7.F3.2.m1.1.1.8.3.cmml" xref="S7.F3.2.m1.1.1.8.3"><times id="S7.F3.2.m1.1.1.8.3.1.cmml" xref="S7.F3.2.m1.1.1.8.3.1"></times><ci id="S7.F3.2.m1.1.1.8.3.2.cmml" xref="S7.F3.2.m1.1.1.8.3.2">𝐴</ci><ci id="S7.F3.2.m1.1.1.8.3.3.cmml" xref="S7.F3.2.m1.1.1.8.3.3">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.F3.2.m1.1d">MMMS\text{-}BA_{AV}</annotation></semantics></math>)</figcaption>
</figure>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Dataset Details</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p"><span id="S7.SS1.p1.1.1" class="ltx_text" style="font-size:90%;">Evaluation of the proposed method is conducted on publicly available audio-visual AV-Deepfake1M </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.SS1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S7.SS1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.SS1.p1.1.4" class="ltx_text" style="font-size:90%;">, FakeAVCeleb </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.SS1.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S7.SS1.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.SS1.p1.1.7" class="ltx_text" style="font-size:90%;">, LAV-DF </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.SS1.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S7.SS1.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.SS1.p1.1.10" class="ltx_text" style="font-size:90%;">, and TVIL </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.SS1.p1.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S7.SS1.p1.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.SS1.p1.1.13" class="ltx_text" style="font-size:90%;"> deepfake datasets mentioned in Section </span><math id="S7.SS1.p1.1.m1.1" class="ltx_Math" alttext="4.1" display="inline"><semantics id="S7.SS1.p1.1.m1.1a"><mn mathsize="90%" id="S7.SS1.p1.1.m1.1.1" xref="S7.SS1.p1.1.m1.1.1.cmml">4.1</mn><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.1.m1.1b"><cn type="float" id="S7.SS1.p1.1.m1.1.1.cmml" xref="S7.SS1.p1.1.m1.1.1">4.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.1.m1.1c">4.1</annotation></semantics></math><span id="S7.SS1.p1.1.14" class="ltx_text" style="font-size:90%;"> of the main paper. Further, details on these datasets are given below.</span></p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<ul id="S7.I1" class="ltx_itemize">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i1.p1" class="ltx_para ltx_noindent">
<p id="S7.I1.i1.p1.1" class="ltx_p"><span id="S7.I1.i1.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">FakeAVCeleb:</span><span id="S7.I1.i1.p1.1.2" class="ltx_text" style="font-size:90%;"> The FakeAVCeleb dataset </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.I1.i1.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S7.I1.i1.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.I1.i1.p1.1.5" class="ltx_text" style="font-size:90%;"> is a collection of videos with audio and visual manipulations of celebrities that have been generated using various deepfake techniques. The dataset is created by selecting videos from the VoxCeleb2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.I1.i1.p1.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S7.I1.i1.p1.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.I1.i1.p1.1.8" class="ltx_text" style="font-size:90%;"> dataset, featuring </span><math id="S7.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="500" display="inline"><semantics id="S7.I1.i1.p1.1.m1.1a"><mn mathsize="90%" id="S7.I1.i1.p1.1.m1.1.1" xref="S7.I1.i1.p1.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S7.I1.i1.p1.1.m1.1b"><cn type="integer" id="S7.I1.i1.p1.1.m1.1.1.cmml" xref="S7.I1.i1.p1.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.I1.i1.p1.1.m1.1c">500</annotation></semantics></math><span id="S7.I1.i1.p1.1.9" class="ltx_text" style="font-size:90%;"> celebrities.
The videos in this dataset are clean, featuring only one person’s frontal face without any occlusion.
The dataset is well-balanced and annotated in terms of gender, race, geography, and visual and audio manipulations, making it useful for training deep learning models that can generalize well on unseen test sets.
We chose this dataset for our multimodal detection experiments because it contains both audio and visual manipulations, as well as a variety of deep-fake generation techniques.</span></p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S7.I1.i2.p1.1" class="ltx_p"><span id="S7.I1.i2.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">LAV-DF Dataset</span><span id="S7.I1.i2.p1.1.2" class="ltx_text" style="font-size:90%;">

The Localized Audio Visual DeepFake (LAV-DF) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.I1.i2.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S7.I1.i2.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.I1.i2.p1.1.5" class="ltx_text" style="font-size:90%;"> dataset emerges as a critical asset in deepfake detection, particularly for benchmarking methods to detect and localize manipulated segments within videos.
Comprising 136,304 videos across 153 unique identities, the dataset offers a diverse collection that includes 36,431 real videos alongside 99,873 videos embedded with fake segments. For a complete evaluation, LAV-DF is divided into three identity-independent subsets: training (78,703 videos), validation (31,501 videos), and testing (26,100 videos), each offering a distinct set of identities to ensure an unbiased assessment.</span></p>
</div>
</li>
<li id="S7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i3.p1" class="ltx_para ltx_noindent">
<p id="S7.I1.i3.p1.1" class="ltx_p"><span id="S7.I1.i3.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">TVIL Dataset</span><span id="S7.I1.i3.p1.1.2" class="ltx_text" style="font-size:90%;">

In response to the increasing challenges posed by advanced AI-generated content (AIGC) technologies, the TVIL dataset </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.I1.i3.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S7.I1.i3.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.I1.i3.p1.1.5" class="ltx_text" style="font-size:90%;"> has been synthesized as a new benchmark aimed at locating video inpainting segments.
Constructed upon the foundation of YouTubeVOS 2018  </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.I1.i3.p1.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib60" title="" class="ltx_ref">60</a><span id="S7.I1.i3.p1.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.I1.i3.p1.1.8" class="ltx_text" style="font-size:90%;">, which aggregates over 4,000 videos from YouTube, the TVIL dataset leverages one of the most prolific platforms for video content as its base. This choice is strategic, considering YouTube’s prominence in content generation and the spread of misinformation. By synthesizing a dataset rooted in YouTube videos, TVIL is poised to offer a robust evaluation framework that defends against misinformation and catalyzes new research directions in the fight against digital content forgery.</span></p>
</div>
</li>
<li id="S7.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i4.p1" class="ltx_para ltx_noindent">
<p id="S7.I1.i4.p1.1" class="ltx_p"><span id="S7.I1.i4.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">AV-Deepfake1M Dataset</span><span id="S7.I1.i4.p1.1.2" class="ltx_text" style="font-size:90%;">

The AV-Deepfake1M </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S7.I1.i4.p1.1.3.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S7.I1.i4.p1.1.4.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S7.I1.i4.p1.1.5" class="ltx_text" style="font-size:90%;"> dataset stands as a pioneering contribution to the field of audio-visual deepfake detection, encompassing an extensive compilation of 1,886 hours of audio-visual data curated using content-driven manipulation techniques.
from 2,068 unique subjects set against diverse background environments.
This dataset is distinguished in facilitating the development of detection algorithms capable of navigating the landscape of content-driven audio-visual manipulations.</span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>On Varying Attention Mechanism</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p"><span id="S7.SS2.p1.1.1" class="ltx_text" style="font-size:90%;">This section provides more details on the calculation of attention in MMUS-SA and MS-SA variations discussed in Section 5.1 of the main paper.</span></p>
<ul id="S7.I2" class="ltx_itemize">
<li id="S7.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I2.i1.p1" class="ltx_para">
<p id="S7.I2.i1.p1.13" class="ltx_p"><span id="S7.I2.i1.p1.13.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Multi-Modal Uni-Sequences - Self Attention (MMUS-SA) Framework</span><span id="S7.I2.i1.p1.13.2" class="ltx_text" style="font-size:90%;">: MMUS-SA framework does not account for information from other sequences at the attention level, rather it utilizes multi-modal information of a single sequence for prediction.
For a video </span><math id="S7.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S7.I2.i1.p1.1.m1.1a"><mi mathsize="90%" id="S7.I2.i1.p1.1.m1.1.1" xref="S7.I2.i1.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.1.m1.1b"><ci id="S7.I2.i1.p1.1.m1.1.1.cmml" xref="S7.I2.i1.p1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.1.m1.1c">D</annotation></semantics></math><span id="S7.I2.i1.p1.13.3" class="ltx_text" style="font-size:90%;"> having ‘</span><math id="S7.I2.i1.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S7.I2.i1.p1.2.m2.1a"><mi mathsize="90%" id="S7.I2.i1.p1.2.m2.1.1" xref="S7.I2.i1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.2.m2.1b"><ci id="S7.I2.i1.p1.2.m2.1.1.cmml" xref="S7.I2.i1.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.2.m2.1c">N</annotation></semantics></math><span id="S7.I2.i1.p1.13.4" class="ltx_text" style="font-size:90%;">’ sequences, ‘</span><math id="S7.I2.i1.p1.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S7.I2.i1.p1.3.m3.1a"><mi mathsize="90%" id="S7.I2.i1.p1.3.m3.1.1" xref="S7.I2.i1.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.3.m3.1b"><ci id="S7.I2.i1.p1.3.m3.1.1.cmml" xref="S7.I2.i1.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.3.m3.1c">N</annotation></semantics></math><span id="S7.I2.i1.p1.13.5" class="ltx_text" style="font-size:90%;">’ separate attention blocks are needed, where each block computes the self-attention over multi-modal information of a single sequence. Let </span><math id="S7.I2.i1.p1.4.m4.1" class="ltx_Math" alttext="X_{p}" display="inline"><semantics id="S7.I2.i1.p1.4.m4.1a"><msub id="S7.I2.i1.p1.4.m4.1.1" xref="S7.I2.i1.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.4.m4.1.1.2" xref="S7.I2.i1.p1.4.m4.1.1.2.cmml">X</mi><mi mathsize="90%" id="S7.I2.i1.p1.4.m4.1.1.3" xref="S7.I2.i1.p1.4.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.4.m4.1b"><apply id="S7.I2.i1.p1.4.m4.1.1.cmml" xref="S7.I2.i1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p1.4.m4.1.1.1.cmml" xref="S7.I2.i1.p1.4.m4.1.1">subscript</csymbol><ci id="S7.I2.i1.p1.4.m4.1.1.2.cmml" xref="S7.I2.i1.p1.4.m4.1.1.2">𝑋</ci><ci id="S7.I2.i1.p1.4.m4.1.1.3.cmml" xref="S7.I2.i1.p1.4.m4.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.4.m4.1c">X_{p}</annotation></semantics></math><span id="S7.I2.i1.p1.13.6" class="ltx_text" style="font-size:90%;"> be the information matrix of the </span><math id="S7.I2.i1.p1.5.m5.1" class="ltx_Math" alttext="p^{th}" display="inline"><semantics id="S7.I2.i1.p1.5.m5.1a"><msup id="S7.I2.i1.p1.5.m5.1.1" xref="S7.I2.i1.p1.5.m5.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.5.m5.1.1.2" xref="S7.I2.i1.p1.5.m5.1.1.2.cmml">p</mi><mrow id="S7.I2.i1.p1.5.m5.1.1.3" xref="S7.I2.i1.p1.5.m5.1.1.3.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.5.m5.1.1.3.2" xref="S7.I2.i1.p1.5.m5.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S7.I2.i1.p1.5.m5.1.1.3.1" xref="S7.I2.i1.p1.5.m5.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S7.I2.i1.p1.5.m5.1.1.3.3" xref="S7.I2.i1.p1.5.m5.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.5.m5.1b"><apply id="S7.I2.i1.p1.5.m5.1.1.cmml" xref="S7.I2.i1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p1.5.m5.1.1.1.cmml" xref="S7.I2.i1.p1.5.m5.1.1">superscript</csymbol><ci id="S7.I2.i1.p1.5.m5.1.1.2.cmml" xref="S7.I2.i1.p1.5.m5.1.1.2">𝑝</ci><apply id="S7.I2.i1.p1.5.m5.1.1.3.cmml" xref="S7.I2.i1.p1.5.m5.1.1.3"><times id="S7.I2.i1.p1.5.m5.1.1.3.1.cmml" xref="S7.I2.i1.p1.5.m5.1.1.3.1"></times><ci id="S7.I2.i1.p1.5.m5.1.1.3.2.cmml" xref="S7.I2.i1.p1.5.m5.1.1.3.2">𝑡</ci><ci id="S7.I2.i1.p1.5.m5.1.1.3.3.cmml" xref="S7.I2.i1.p1.5.m5.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.5.m5.1c">p^{th}</annotation></semantics></math><span id="S7.I2.i1.p1.13.7" class="ltx_text" style="font-size:90%;"> sequence where the three ‘</span><math id="S7.I2.i1.p1.6.m6.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S7.I2.i1.p1.6.m6.1a"><mi mathsize="90%" id="S7.I2.i1.p1.6.m6.1.1" xref="S7.I2.i1.p1.6.m6.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.6.m6.1b"><ci id="S7.I2.i1.p1.6.m6.1.1.cmml" xref="S7.I2.i1.p1.6.m6.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.6.m6.1c">r</annotation></semantics></math><span id="S7.I2.i1.p1.13.8" class="ltx_text" style="font-size:90%;">’ dimensional rows are the outputs of the dense layers for the three modalities. The attention matrix </span><math id="S7.I2.i1.p1.7.m7.1" class="ltx_Math" alttext="A_{p}" display="inline"><semantics id="S7.I2.i1.p1.7.m7.1a"><msub id="S7.I2.i1.p1.7.m7.1.1" xref="S7.I2.i1.p1.7.m7.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.7.m7.1.1.2" xref="S7.I2.i1.p1.7.m7.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i1.p1.7.m7.1.1.3" xref="S7.I2.i1.p1.7.m7.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.7.m7.1b"><apply id="S7.I2.i1.p1.7.m7.1.1.cmml" xref="S7.I2.i1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p1.7.m7.1.1.1.cmml" xref="S7.I2.i1.p1.7.m7.1.1">subscript</csymbol><ci id="S7.I2.i1.p1.7.m7.1.1.2.cmml" xref="S7.I2.i1.p1.7.m7.1.1.2">𝐴</ci><ci id="S7.I2.i1.p1.7.m7.1.1.3.cmml" xref="S7.I2.i1.p1.7.m7.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.7.m7.1c">A_{p}</annotation></semantics></math><span id="S7.I2.i1.p1.13.9" class="ltx_text" style="font-size:90%;"> is computed separately for </span><math id="S7.I2.i1.p1.8.m8.1" class="ltx_Math" alttext="p=1^{st}" display="inline"><semantics id="S7.I2.i1.p1.8.m8.1a"><mrow id="S7.I2.i1.p1.8.m8.1.1" xref="S7.I2.i1.p1.8.m8.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.8.m8.1.1.2" xref="S7.I2.i1.p1.8.m8.1.1.2.cmml">p</mi><mo mathsize="90%" id="S7.I2.i1.p1.8.m8.1.1.1" xref="S7.I2.i1.p1.8.m8.1.1.1.cmml">=</mo><msup id="S7.I2.i1.p1.8.m8.1.1.3" xref="S7.I2.i1.p1.8.m8.1.1.3.cmml"><mn mathsize="90%" id="S7.I2.i1.p1.8.m8.1.1.3.2" xref="S7.I2.i1.p1.8.m8.1.1.3.2.cmml">1</mn><mrow id="S7.I2.i1.p1.8.m8.1.1.3.3" xref="S7.I2.i1.p1.8.m8.1.1.3.3.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.8.m8.1.1.3.3.2" xref="S7.I2.i1.p1.8.m8.1.1.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S7.I2.i1.p1.8.m8.1.1.3.3.1" xref="S7.I2.i1.p1.8.m8.1.1.3.3.1.cmml">​</mo><mi mathsize="90%" id="S7.I2.i1.p1.8.m8.1.1.3.3.3" xref="S7.I2.i1.p1.8.m8.1.1.3.3.3.cmml">t</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.8.m8.1b"><apply id="S7.I2.i1.p1.8.m8.1.1.cmml" xref="S7.I2.i1.p1.8.m8.1.1"><eq id="S7.I2.i1.p1.8.m8.1.1.1.cmml" xref="S7.I2.i1.p1.8.m8.1.1.1"></eq><ci id="S7.I2.i1.p1.8.m8.1.1.2.cmml" xref="S7.I2.i1.p1.8.m8.1.1.2">𝑝</ci><apply id="S7.I2.i1.p1.8.m8.1.1.3.cmml" xref="S7.I2.i1.p1.8.m8.1.1.3"><csymbol cd="ambiguous" id="S7.I2.i1.p1.8.m8.1.1.3.1.cmml" xref="S7.I2.i1.p1.8.m8.1.1.3">superscript</csymbol><cn type="integer" id="S7.I2.i1.p1.8.m8.1.1.3.2.cmml" xref="S7.I2.i1.p1.8.m8.1.1.3.2">1</cn><apply id="S7.I2.i1.p1.8.m8.1.1.3.3.cmml" xref="S7.I2.i1.p1.8.m8.1.1.3.3"><times id="S7.I2.i1.p1.8.m8.1.1.3.3.1.cmml" xref="S7.I2.i1.p1.8.m8.1.1.3.3.1"></times><ci id="S7.I2.i1.p1.8.m8.1.1.3.3.2.cmml" xref="S7.I2.i1.p1.8.m8.1.1.3.3.2">𝑠</ci><ci id="S7.I2.i1.p1.8.m8.1.1.3.3.3.cmml" xref="S7.I2.i1.p1.8.m8.1.1.3.3.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.8.m8.1c">p=1^{st}</annotation></semantics></math><span id="S7.I2.i1.p1.13.10" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i1.p1.9.m9.1" class="ltx_Math" alttext="2^{nd}" display="inline"><semantics id="S7.I2.i1.p1.9.m9.1a"><msup id="S7.I2.i1.p1.9.m9.1.1" xref="S7.I2.i1.p1.9.m9.1.1.cmml"><mn mathsize="90%" id="S7.I2.i1.p1.9.m9.1.1.2" xref="S7.I2.i1.p1.9.m9.1.1.2.cmml">2</mn><mrow id="S7.I2.i1.p1.9.m9.1.1.3" xref="S7.I2.i1.p1.9.m9.1.1.3.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.9.m9.1.1.3.2" xref="S7.I2.i1.p1.9.m9.1.1.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S7.I2.i1.p1.9.m9.1.1.3.1" xref="S7.I2.i1.p1.9.m9.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S7.I2.i1.p1.9.m9.1.1.3.3" xref="S7.I2.i1.p1.9.m9.1.1.3.3.cmml">d</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.9.m9.1b"><apply id="S7.I2.i1.p1.9.m9.1.1.cmml" xref="S7.I2.i1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p1.9.m9.1.1.1.cmml" xref="S7.I2.i1.p1.9.m9.1.1">superscript</csymbol><cn type="integer" id="S7.I2.i1.p1.9.m9.1.1.2.cmml" xref="S7.I2.i1.p1.9.m9.1.1.2">2</cn><apply id="S7.I2.i1.p1.9.m9.1.1.3.cmml" xref="S7.I2.i1.p1.9.m9.1.1.3"><times id="S7.I2.i1.p1.9.m9.1.1.3.1.cmml" xref="S7.I2.i1.p1.9.m9.1.1.3.1"></times><ci id="S7.I2.i1.p1.9.m9.1.1.3.2.cmml" xref="S7.I2.i1.p1.9.m9.1.1.3.2">𝑛</ci><ci id="S7.I2.i1.p1.9.m9.1.1.3.3.cmml" xref="S7.I2.i1.p1.9.m9.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.9.m9.1c">2^{nd}</annotation></semantics></math><span id="S7.I2.i1.p1.13.11" class="ltx_text" style="font-size:90%;">, … </span><math id="S7.I2.i1.p1.10.m10.1" class="ltx_Math" alttext="N^{th}" display="inline"><semantics id="S7.I2.i1.p1.10.m10.1a"><msup id="S7.I2.i1.p1.10.m10.1.1" xref="S7.I2.i1.p1.10.m10.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.10.m10.1.1.2" xref="S7.I2.i1.p1.10.m10.1.1.2.cmml">N</mi><mrow id="S7.I2.i1.p1.10.m10.1.1.3" xref="S7.I2.i1.p1.10.m10.1.1.3.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.10.m10.1.1.3.2" xref="S7.I2.i1.p1.10.m10.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S7.I2.i1.p1.10.m10.1.1.3.1" xref="S7.I2.i1.p1.10.m10.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S7.I2.i1.p1.10.m10.1.1.3.3" xref="S7.I2.i1.p1.10.m10.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.10.m10.1b"><apply id="S7.I2.i1.p1.10.m10.1.1.cmml" xref="S7.I2.i1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p1.10.m10.1.1.1.cmml" xref="S7.I2.i1.p1.10.m10.1.1">superscript</csymbol><ci id="S7.I2.i1.p1.10.m10.1.1.2.cmml" xref="S7.I2.i1.p1.10.m10.1.1.2">𝑁</ci><apply id="S7.I2.i1.p1.10.m10.1.1.3.cmml" xref="S7.I2.i1.p1.10.m10.1.1.3"><times id="S7.I2.i1.p1.10.m10.1.1.3.1.cmml" xref="S7.I2.i1.p1.10.m10.1.1.3.1"></times><ci id="S7.I2.i1.p1.10.m10.1.1.3.2.cmml" xref="S7.I2.i1.p1.10.m10.1.1.3.2">𝑡</ci><ci id="S7.I2.i1.p1.10.m10.1.1.3.3.cmml" xref="S7.I2.i1.p1.10.m10.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.10.m10.1c">N^{th}</annotation></semantics></math><span id="S7.I2.i1.p1.13.12" class="ltx_text" style="font-size:90%;"> sequences. Finally, for each sequence </span><math id="S7.I2.i1.p1.11.m11.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S7.I2.i1.p1.11.m11.1a"><mi mathsize="90%" id="S7.I2.i1.p1.11.m11.1.1" xref="S7.I2.i1.p1.11.m11.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.11.m11.1b"><ci id="S7.I2.i1.p1.11.m11.1.1.cmml" xref="S7.I2.i1.p1.11.m11.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.11.m11.1c">p</annotation></semantics></math><span id="S7.I2.i1.p1.13.13" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i1.p1.12.m12.1" class="ltx_Math" alttext="A_{p}" display="inline"><semantics id="S7.I2.i1.p1.12.m12.1a"><msub id="S7.I2.i1.p1.12.m12.1.1" xref="S7.I2.i1.p1.12.m12.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.12.m12.1.1.2" xref="S7.I2.i1.p1.12.m12.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i1.p1.12.m12.1.1.3" xref="S7.I2.i1.p1.12.m12.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.12.m12.1b"><apply id="S7.I2.i1.p1.12.m12.1.1.cmml" xref="S7.I2.i1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p1.12.m12.1.1.1.cmml" xref="S7.I2.i1.p1.12.m12.1.1">subscript</csymbol><ci id="S7.I2.i1.p1.12.m12.1.1.2.cmml" xref="S7.I2.i1.p1.12.m12.1.1.2">𝐴</ci><ci id="S7.I2.i1.p1.12.m12.1.1.3.cmml" xref="S7.I2.i1.p1.12.m12.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.12.m12.1c">A_{p}</annotation></semantics></math><span id="S7.I2.i1.p1.13.14" class="ltx_text" style="font-size:90%;"> and </span><math id="S7.I2.i1.p1.13.m13.1" class="ltx_Math" alttext="X_{p}" display="inline"><semantics id="S7.I2.i1.p1.13.m13.1a"><msub id="S7.I2.i1.p1.13.m13.1.1" xref="S7.I2.i1.p1.13.m13.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p1.13.m13.1.1.2" xref="S7.I2.i1.p1.13.m13.1.1.2.cmml">X</mi><mi mathsize="90%" id="S7.I2.i1.p1.13.m13.1.1.3" xref="S7.I2.i1.p1.13.m13.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p1.13.m13.1b"><apply id="S7.I2.i1.p1.13.m13.1.1.cmml" xref="S7.I2.i1.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p1.13.m13.1.1.1.cmml" xref="S7.I2.i1.p1.13.m13.1.1">subscript</csymbol><ci id="S7.I2.i1.p1.13.m13.1.1.2.cmml" xref="S7.I2.i1.p1.13.m13.1.1.2">𝑋</ci><ci id="S7.I2.i1.p1.13.m13.1.1.3.cmml" xref="S7.I2.i1.p1.13.m13.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p1.13.m13.1c">X_{p}</annotation></semantics></math><span id="S7.I2.i1.p1.13.15" class="ltx_text" style="font-size:90%;"> are concatenated and passed to the output layer for classification.</span></p>
</div>
<div id="S7.I2.i1.p2" class="ltx_para">
<table id="S7.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E9.m1.1" class="ltx_Math" alttext="M_{\text{p}}=X_{\text{p}}\cdot X^{T}_{\text{p}}" display="block"><semantics id="S7.E9.m1.1a"><mrow id="S7.E9.m1.1.1" xref="S7.E9.m1.1.1.cmml"><msub id="S7.E9.m1.1.1.2" xref="S7.E9.m1.1.1.2.cmml"><mi mathsize="90%" id="S7.E9.m1.1.1.2.2" xref="S7.E9.m1.1.1.2.2.cmml">M</mi><mtext mathsize="90%" id="S7.E9.m1.1.1.2.3" xref="S7.E9.m1.1.1.2.3a.cmml">p</mtext></msub><mo mathsize="90%" id="S7.E9.m1.1.1.1" xref="S7.E9.m1.1.1.1.cmml">=</mo><mrow id="S7.E9.m1.1.1.3" xref="S7.E9.m1.1.1.3.cmml"><msub id="S7.E9.m1.1.1.3.2" xref="S7.E9.m1.1.1.3.2.cmml"><mi mathsize="90%" id="S7.E9.m1.1.1.3.2.2" xref="S7.E9.m1.1.1.3.2.2.cmml">X</mi><mtext mathsize="90%" id="S7.E9.m1.1.1.3.2.3" xref="S7.E9.m1.1.1.3.2.3a.cmml">p</mtext></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S7.E9.m1.1.1.3.1" xref="S7.E9.m1.1.1.3.1.cmml">⋅</mo><msubsup id="S7.E9.m1.1.1.3.3" xref="S7.E9.m1.1.1.3.3.cmml"><mi mathsize="90%" id="S7.E9.m1.1.1.3.3.2.2" xref="S7.E9.m1.1.1.3.3.2.2.cmml">X</mi><mtext mathsize="90%" id="S7.E9.m1.1.1.3.3.3" xref="S7.E9.m1.1.1.3.3.3a.cmml">p</mtext><mi mathsize="90%" id="S7.E9.m1.1.1.3.3.2.3" xref="S7.E9.m1.1.1.3.3.2.3.cmml">T</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E9.m1.1b"><apply id="S7.E9.m1.1.1.cmml" xref="S7.E9.m1.1.1"><eq id="S7.E9.m1.1.1.1.cmml" xref="S7.E9.m1.1.1.1"></eq><apply id="S7.E9.m1.1.1.2.cmml" xref="S7.E9.m1.1.1.2"><csymbol cd="ambiguous" id="S7.E9.m1.1.1.2.1.cmml" xref="S7.E9.m1.1.1.2">subscript</csymbol><ci id="S7.E9.m1.1.1.2.2.cmml" xref="S7.E9.m1.1.1.2.2">𝑀</ci><ci id="S7.E9.m1.1.1.2.3a.cmml" xref="S7.E9.m1.1.1.2.3"><mtext mathsize="63%" id="S7.E9.m1.1.1.2.3.cmml" xref="S7.E9.m1.1.1.2.3">p</mtext></ci></apply><apply id="S7.E9.m1.1.1.3.cmml" xref="S7.E9.m1.1.1.3"><ci id="S7.E9.m1.1.1.3.1.cmml" xref="S7.E9.m1.1.1.3.1">⋅</ci><apply id="S7.E9.m1.1.1.3.2.cmml" xref="S7.E9.m1.1.1.3.2"><csymbol cd="ambiguous" id="S7.E9.m1.1.1.3.2.1.cmml" xref="S7.E9.m1.1.1.3.2">subscript</csymbol><ci id="S7.E9.m1.1.1.3.2.2.cmml" xref="S7.E9.m1.1.1.3.2.2">𝑋</ci><ci id="S7.E9.m1.1.1.3.2.3a.cmml" xref="S7.E9.m1.1.1.3.2.3"><mtext mathsize="63%" id="S7.E9.m1.1.1.3.2.3.cmml" xref="S7.E9.m1.1.1.3.2.3">p</mtext></ci></apply><apply id="S7.E9.m1.1.1.3.3.cmml" xref="S7.E9.m1.1.1.3.3"><csymbol cd="ambiguous" id="S7.E9.m1.1.1.3.3.1.cmml" xref="S7.E9.m1.1.1.3.3">subscript</csymbol><apply id="S7.E9.m1.1.1.3.3.2.cmml" xref="S7.E9.m1.1.1.3.3"><csymbol cd="ambiguous" id="S7.E9.m1.1.1.3.3.2.1.cmml" xref="S7.E9.m1.1.1.3.3">superscript</csymbol><ci id="S7.E9.m1.1.1.3.3.2.2.cmml" xref="S7.E9.m1.1.1.3.3.2.2">𝑋</ci><ci id="S7.E9.m1.1.1.3.3.2.3.cmml" xref="S7.E9.m1.1.1.3.3.2.3">𝑇</ci></apply><ci id="S7.E9.m1.1.1.3.3.3a.cmml" xref="S7.E9.m1.1.1.3.3.3"><mtext mathsize="63%" id="S7.E9.m1.1.1.3.3.3.cmml" xref="S7.E9.m1.1.1.3.3.3">p</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E9.m1.1c">M_{\text{p}}=X_{\text{p}}\cdot X^{T}_{\text{p}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.I2.i1.p3" class="ltx_para">
<table id="S7.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E10.m1.10" class="ltx_Math" alttext="N_{\text{p}}(i,j)=\frac{e^{M_{\text{p}}(i,j)}}{\sum_{k=1}^{3}e^{M_{\text{p}}(i,k)}}\text{ for }i,j=1,2,3;" display="block"><semantics id="S7.E10.m1.10a"><mrow id="S7.E10.m1.10.10.1"><mrow id="S7.E10.m1.10.10.1.1.2" xref="S7.E10.m1.10.10.1.1.3.cmml"><mrow id="S7.E10.m1.10.10.1.1.1.1" xref="S7.E10.m1.10.10.1.1.1.1.cmml"><mrow id="S7.E10.m1.10.10.1.1.1.1.2" xref="S7.E10.m1.10.10.1.1.1.1.2.cmml"><msub id="S7.E10.m1.10.10.1.1.1.1.2.2" xref="S7.E10.m1.10.10.1.1.1.1.2.2.cmml"><mi mathsize="90%" id="S7.E10.m1.10.10.1.1.1.1.2.2.2" xref="S7.E10.m1.10.10.1.1.1.1.2.2.2.cmml">N</mi><mtext mathsize="90%" id="S7.E10.m1.10.10.1.1.1.1.2.2.3" xref="S7.E10.m1.10.10.1.1.1.1.2.2.3a.cmml">p</mtext></msub><mo lspace="0em" rspace="0em" id="S7.E10.m1.10.10.1.1.1.1.2.1" xref="S7.E10.m1.10.10.1.1.1.1.2.1.cmml">​</mo><mrow id="S7.E10.m1.10.10.1.1.1.1.2.3.2" xref="S7.E10.m1.10.10.1.1.1.1.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S7.E10.m1.10.10.1.1.1.1.2.3.2.1" xref="S7.E10.m1.10.10.1.1.1.1.2.3.1.cmml">(</mo><mi mathsize="90%" id="S7.E10.m1.5.5" xref="S7.E10.m1.5.5.cmml">i</mi><mo mathsize="90%" id="S7.E10.m1.10.10.1.1.1.1.2.3.2.2" xref="S7.E10.m1.10.10.1.1.1.1.2.3.1.cmml">,</mo><mi mathsize="90%" id="S7.E10.m1.6.6" xref="S7.E10.m1.6.6.cmml">j</mi><mo maxsize="90%" minsize="90%" id="S7.E10.m1.10.10.1.1.1.1.2.3.2.3" xref="S7.E10.m1.10.10.1.1.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S7.E10.m1.10.10.1.1.1.1.1" xref="S7.E10.m1.10.10.1.1.1.1.1.cmml">=</mo><mrow id="S7.E10.m1.10.10.1.1.1.1.3" xref="S7.E10.m1.10.10.1.1.1.1.3.cmml"><mfrac id="S7.E10.m1.4.4" xref="S7.E10.m1.4.4.cmml"><msup id="S7.E10.m1.2.2.2" xref="S7.E10.m1.2.2.2.cmml"><mi mathsize="90%" id="S7.E10.m1.2.2.2.4" xref="S7.E10.m1.2.2.2.4.cmml">e</mi><mrow id="S7.E10.m1.2.2.2.2.2" xref="S7.E10.m1.2.2.2.2.2.cmml"><msub id="S7.E10.m1.2.2.2.2.2.4" xref="S7.E10.m1.2.2.2.2.2.4.cmml"><mi mathsize="90%" id="S7.E10.m1.2.2.2.2.2.4.2" xref="S7.E10.m1.2.2.2.2.2.4.2.cmml">M</mi><mtext mathsize="90%" id="S7.E10.m1.2.2.2.2.2.4.3" xref="S7.E10.m1.2.2.2.2.2.4.3a.cmml">p</mtext></msub><mo lspace="0em" rspace="0em" id="S7.E10.m1.2.2.2.2.2.3" xref="S7.E10.m1.2.2.2.2.2.3.cmml">​</mo><mrow id="S7.E10.m1.2.2.2.2.2.5.2" xref="S7.E10.m1.2.2.2.2.2.5.1.cmml"><mo maxsize="90%" minsize="90%" id="S7.E10.m1.2.2.2.2.2.5.2.1" xref="S7.E10.m1.2.2.2.2.2.5.1.cmml">(</mo><mi mathsize="90%" id="S7.E10.m1.1.1.1.1.1.1" xref="S7.E10.m1.1.1.1.1.1.1.cmml">i</mi><mo mathsize="90%" id="S7.E10.m1.2.2.2.2.2.5.2.2" xref="S7.E10.m1.2.2.2.2.2.5.1.cmml">,</mo><mi mathsize="90%" id="S7.E10.m1.2.2.2.2.2.2" xref="S7.E10.m1.2.2.2.2.2.2.cmml">j</mi><mo maxsize="90%" minsize="90%" id="S7.E10.m1.2.2.2.2.2.5.2.3" xref="S7.E10.m1.2.2.2.2.2.5.1.cmml">)</mo></mrow></mrow></msup><mrow id="S7.E10.m1.4.4.4" xref="S7.E10.m1.4.4.4.cmml"><msubsup id="S7.E10.m1.4.4.4.3" xref="S7.E10.m1.4.4.4.3.cmml"><mo maxsize="90%" minsize="90%" stretchy="true" id="S7.E10.m1.4.4.4.3.2.2" xref="S7.E10.m1.4.4.4.3.2.2.cmml">∑</mo><mrow id="S7.E10.m1.4.4.4.3.2.3" xref="S7.E10.m1.4.4.4.3.2.3.cmml"><mi mathsize="90%" id="S7.E10.m1.4.4.4.3.2.3.2" xref="S7.E10.m1.4.4.4.3.2.3.2.cmml">k</mi><mo mathsize="90%" id="S7.E10.m1.4.4.4.3.2.3.1" xref="S7.E10.m1.4.4.4.3.2.3.1.cmml">=</mo><mn mathsize="90%" id="S7.E10.m1.4.4.4.3.2.3.3" xref="S7.E10.m1.4.4.4.3.2.3.3.cmml">1</mn></mrow><mn mathsize="90%" id="S7.E10.m1.4.4.4.3.3" xref="S7.E10.m1.4.4.4.3.3.cmml">3</mn></msubsup><msup id="S7.E10.m1.4.4.4.4" xref="S7.E10.m1.4.4.4.4.cmml"><mi mathsize="90%" id="S7.E10.m1.4.4.4.4.2" xref="S7.E10.m1.4.4.4.4.2.cmml">e</mi><mrow id="S7.E10.m1.4.4.4.2.2" xref="S7.E10.m1.4.4.4.2.2.cmml"><msub id="S7.E10.m1.4.4.4.2.2.4" xref="S7.E10.m1.4.4.4.2.2.4.cmml"><mi mathsize="90%" id="S7.E10.m1.4.4.4.2.2.4.2" xref="S7.E10.m1.4.4.4.2.2.4.2.cmml">M</mi><mtext mathsize="90%" id="S7.E10.m1.4.4.4.2.2.4.3" xref="S7.E10.m1.4.4.4.2.2.4.3a.cmml">p</mtext></msub><mo lspace="0em" rspace="0em" id="S7.E10.m1.4.4.4.2.2.3" xref="S7.E10.m1.4.4.4.2.2.3.cmml">​</mo><mrow id="S7.E10.m1.4.4.4.2.2.5.2" xref="S7.E10.m1.4.4.4.2.2.5.1.cmml"><mo maxsize="90%" minsize="90%" id="S7.E10.m1.4.4.4.2.2.5.2.1" xref="S7.E10.m1.4.4.4.2.2.5.1.cmml">(</mo><mi mathsize="90%" id="S7.E10.m1.3.3.3.1.1.1" xref="S7.E10.m1.3.3.3.1.1.1.cmml">i</mi><mo mathsize="90%" id="S7.E10.m1.4.4.4.2.2.5.2.2" xref="S7.E10.m1.4.4.4.2.2.5.1.cmml">,</mo><mi mathsize="90%" id="S7.E10.m1.4.4.4.2.2.2" xref="S7.E10.m1.4.4.4.2.2.2.cmml">k</mi><mo maxsize="90%" minsize="90%" id="S7.E10.m1.4.4.4.2.2.5.2.3" xref="S7.E10.m1.4.4.4.2.2.5.1.cmml">)</mo></mrow></mrow></msup></mrow></mfrac><mo lspace="0em" rspace="0em" id="S7.E10.m1.10.10.1.1.1.1.3.1" xref="S7.E10.m1.10.10.1.1.1.1.3.1.cmml">​</mo><mtext mathsize="90%" id="S7.E10.m1.10.10.1.1.1.1.3.2" xref="S7.E10.m1.10.10.1.1.1.1.3.2a.cmml"> for </mtext><mo lspace="0em" rspace="0em" id="S7.E10.m1.10.10.1.1.1.1.3.1a" xref="S7.E10.m1.10.10.1.1.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S7.E10.m1.10.10.1.1.1.1.3.3" xref="S7.E10.m1.10.10.1.1.1.1.3.3.cmml">i</mi></mrow></mrow><mo mathsize="90%" id="S7.E10.m1.10.10.1.1.2.3" xref="S7.E10.m1.10.10.1.1.3a.cmml">,</mo><mrow id="S7.E10.m1.10.10.1.1.2.2" xref="S7.E10.m1.10.10.1.1.2.2.cmml"><mi mathsize="90%" id="S7.E10.m1.10.10.1.1.2.2.2" xref="S7.E10.m1.10.10.1.1.2.2.2.cmml">j</mi><mo mathsize="90%" id="S7.E10.m1.10.10.1.1.2.2.1" xref="S7.E10.m1.10.10.1.1.2.2.1.cmml">=</mo><mrow id="S7.E10.m1.10.10.1.1.2.2.3.2" xref="S7.E10.m1.10.10.1.1.2.2.3.1.cmml"><mn mathsize="90%" id="S7.E10.m1.7.7" xref="S7.E10.m1.7.7.cmml">1</mn><mo mathsize="90%" id="S7.E10.m1.10.10.1.1.2.2.3.2.1" xref="S7.E10.m1.10.10.1.1.2.2.3.1.cmml">,</mo><mn mathsize="90%" id="S7.E10.m1.8.8" xref="S7.E10.m1.8.8.cmml">2</mn><mo mathsize="90%" id="S7.E10.m1.10.10.1.1.2.2.3.2.2" xref="S7.E10.m1.10.10.1.1.2.2.3.1.cmml">,</mo><mn mathsize="90%" id="S7.E10.m1.9.9" xref="S7.E10.m1.9.9.cmml">3</mn></mrow></mrow></mrow><mo mathsize="90%" id="S7.E10.m1.10.10.1.2">;</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.E10.m1.10b"><apply id="S7.E10.m1.10.10.1.1.3.cmml" xref="S7.E10.m1.10.10.1.1.2"><csymbol cd="ambiguous" id="S7.E10.m1.10.10.1.1.3a.cmml" xref="S7.E10.m1.10.10.1.1.2.3">formulae-sequence</csymbol><apply id="S7.E10.m1.10.10.1.1.1.1.cmml" xref="S7.E10.m1.10.10.1.1.1.1"><eq id="S7.E10.m1.10.10.1.1.1.1.1.cmml" xref="S7.E10.m1.10.10.1.1.1.1.1"></eq><apply id="S7.E10.m1.10.10.1.1.1.1.2.cmml" xref="S7.E10.m1.10.10.1.1.1.1.2"><times id="S7.E10.m1.10.10.1.1.1.1.2.1.cmml" xref="S7.E10.m1.10.10.1.1.1.1.2.1"></times><apply id="S7.E10.m1.10.10.1.1.1.1.2.2.cmml" xref="S7.E10.m1.10.10.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S7.E10.m1.10.10.1.1.1.1.2.2.1.cmml" xref="S7.E10.m1.10.10.1.1.1.1.2.2">subscript</csymbol><ci id="S7.E10.m1.10.10.1.1.1.1.2.2.2.cmml" xref="S7.E10.m1.10.10.1.1.1.1.2.2.2">𝑁</ci><ci id="S7.E10.m1.10.10.1.1.1.1.2.2.3a.cmml" xref="S7.E10.m1.10.10.1.1.1.1.2.2.3"><mtext mathsize="63%" id="S7.E10.m1.10.10.1.1.1.1.2.2.3.cmml" xref="S7.E10.m1.10.10.1.1.1.1.2.2.3">p</mtext></ci></apply><interval closure="open" id="S7.E10.m1.10.10.1.1.1.1.2.3.1.cmml" xref="S7.E10.m1.10.10.1.1.1.1.2.3.2"><ci id="S7.E10.m1.5.5.cmml" xref="S7.E10.m1.5.5">𝑖</ci><ci id="S7.E10.m1.6.6.cmml" xref="S7.E10.m1.6.6">𝑗</ci></interval></apply><apply id="S7.E10.m1.10.10.1.1.1.1.3.cmml" xref="S7.E10.m1.10.10.1.1.1.1.3"><times id="S7.E10.m1.10.10.1.1.1.1.3.1.cmml" xref="S7.E10.m1.10.10.1.1.1.1.3.1"></times><apply id="S7.E10.m1.4.4.cmml" xref="S7.E10.m1.4.4"><divide id="S7.E10.m1.4.4.5.cmml" xref="S7.E10.m1.4.4"></divide><apply id="S7.E10.m1.2.2.2.cmml" xref="S7.E10.m1.2.2.2"><csymbol cd="ambiguous" id="S7.E10.m1.2.2.2.3.cmml" xref="S7.E10.m1.2.2.2">superscript</csymbol><ci id="S7.E10.m1.2.2.2.4.cmml" xref="S7.E10.m1.2.2.2.4">𝑒</ci><apply id="S7.E10.m1.2.2.2.2.2.cmml" xref="S7.E10.m1.2.2.2.2.2"><times id="S7.E10.m1.2.2.2.2.2.3.cmml" xref="S7.E10.m1.2.2.2.2.2.3"></times><apply id="S7.E10.m1.2.2.2.2.2.4.cmml" xref="S7.E10.m1.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S7.E10.m1.2.2.2.2.2.4.1.cmml" xref="S7.E10.m1.2.2.2.2.2.4">subscript</csymbol><ci id="S7.E10.m1.2.2.2.2.2.4.2.cmml" xref="S7.E10.m1.2.2.2.2.2.4.2">𝑀</ci><ci id="S7.E10.m1.2.2.2.2.2.4.3a.cmml" xref="S7.E10.m1.2.2.2.2.2.4.3"><mtext mathsize="45%" id="S7.E10.m1.2.2.2.2.2.4.3.cmml" xref="S7.E10.m1.2.2.2.2.2.4.3">p</mtext></ci></apply><interval closure="open" id="S7.E10.m1.2.2.2.2.2.5.1.cmml" xref="S7.E10.m1.2.2.2.2.2.5.2"><ci id="S7.E10.m1.1.1.1.1.1.1.cmml" xref="S7.E10.m1.1.1.1.1.1.1">𝑖</ci><ci id="S7.E10.m1.2.2.2.2.2.2.cmml" xref="S7.E10.m1.2.2.2.2.2.2">𝑗</ci></interval></apply></apply><apply id="S7.E10.m1.4.4.4.cmml" xref="S7.E10.m1.4.4.4"><apply id="S7.E10.m1.4.4.4.3.cmml" xref="S7.E10.m1.4.4.4.3"><csymbol cd="ambiguous" id="S7.E10.m1.4.4.4.3.1.cmml" xref="S7.E10.m1.4.4.4.3">superscript</csymbol><apply id="S7.E10.m1.4.4.4.3.2.cmml" xref="S7.E10.m1.4.4.4.3"><csymbol cd="ambiguous" id="S7.E10.m1.4.4.4.3.2.1.cmml" xref="S7.E10.m1.4.4.4.3">subscript</csymbol><sum id="S7.E10.m1.4.4.4.3.2.2.cmml" xref="S7.E10.m1.4.4.4.3.2.2"></sum><apply id="S7.E10.m1.4.4.4.3.2.3.cmml" xref="S7.E10.m1.4.4.4.3.2.3"><eq id="S7.E10.m1.4.4.4.3.2.3.1.cmml" xref="S7.E10.m1.4.4.4.3.2.3.1"></eq><ci id="S7.E10.m1.4.4.4.3.2.3.2.cmml" xref="S7.E10.m1.4.4.4.3.2.3.2">𝑘</ci><cn type="integer" id="S7.E10.m1.4.4.4.3.2.3.3.cmml" xref="S7.E10.m1.4.4.4.3.2.3.3">1</cn></apply></apply><cn type="integer" id="S7.E10.m1.4.4.4.3.3.cmml" xref="S7.E10.m1.4.4.4.3.3">3</cn></apply><apply id="S7.E10.m1.4.4.4.4.cmml" xref="S7.E10.m1.4.4.4.4"><csymbol cd="ambiguous" id="S7.E10.m1.4.4.4.4.1.cmml" xref="S7.E10.m1.4.4.4.4">superscript</csymbol><ci id="S7.E10.m1.4.4.4.4.2.cmml" xref="S7.E10.m1.4.4.4.4.2">𝑒</ci><apply id="S7.E10.m1.4.4.4.2.2.cmml" xref="S7.E10.m1.4.4.4.2.2"><times id="S7.E10.m1.4.4.4.2.2.3.cmml" xref="S7.E10.m1.4.4.4.2.2.3"></times><apply id="S7.E10.m1.4.4.4.2.2.4.cmml" xref="S7.E10.m1.4.4.4.2.2.4"><csymbol cd="ambiguous" id="S7.E10.m1.4.4.4.2.2.4.1.cmml" xref="S7.E10.m1.4.4.4.2.2.4">subscript</csymbol><ci id="S7.E10.m1.4.4.4.2.2.4.2.cmml" xref="S7.E10.m1.4.4.4.2.2.4.2">𝑀</ci><ci id="S7.E10.m1.4.4.4.2.2.4.3a.cmml" xref="S7.E10.m1.4.4.4.2.2.4.3"><mtext mathsize="45%" id="S7.E10.m1.4.4.4.2.2.4.3.cmml" xref="S7.E10.m1.4.4.4.2.2.4.3">p</mtext></ci></apply><interval closure="open" id="S7.E10.m1.4.4.4.2.2.5.1.cmml" xref="S7.E10.m1.4.4.4.2.2.5.2"><ci id="S7.E10.m1.3.3.3.1.1.1.cmml" xref="S7.E10.m1.3.3.3.1.1.1">𝑖</ci><ci id="S7.E10.m1.4.4.4.2.2.2.cmml" xref="S7.E10.m1.4.4.4.2.2.2">𝑘</ci></interval></apply></apply></apply></apply><ci id="S7.E10.m1.10.10.1.1.1.1.3.2a.cmml" xref="S7.E10.m1.10.10.1.1.1.1.3.2"><mtext mathsize="90%" id="S7.E10.m1.10.10.1.1.1.1.3.2.cmml" xref="S7.E10.m1.10.10.1.1.1.1.3.2"> for </mtext></ci><ci id="S7.E10.m1.10.10.1.1.1.1.3.3.cmml" xref="S7.E10.m1.10.10.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S7.E10.m1.10.10.1.1.2.2.cmml" xref="S7.E10.m1.10.10.1.1.2.2"><eq id="S7.E10.m1.10.10.1.1.2.2.1.cmml" xref="S7.E10.m1.10.10.1.1.2.2.1"></eq><ci id="S7.E10.m1.10.10.1.1.2.2.2.cmml" xref="S7.E10.m1.10.10.1.1.2.2.2">𝑗</ci><list id="S7.E10.m1.10.10.1.1.2.2.3.1.cmml" xref="S7.E10.m1.10.10.1.1.2.2.3.2"><cn type="integer" id="S7.E10.m1.7.7.cmml" xref="S7.E10.m1.7.7">1</cn><cn type="integer" id="S7.E10.m1.8.8.cmml" xref="S7.E10.m1.8.8">2</cn><cn type="integer" id="S7.E10.m1.9.9.cmml" xref="S7.E10.m1.9.9">3</cn></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E10.m1.10c">N_{\text{p}}(i,j)=\frac{e^{M_{\text{p}}(i,j)}}{\sum_{k=1}^{3}e^{M_{\text{p}}(i,k)}}\text{ for }i,j=1,2,3;</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.I2.i1.p4" class="ltx_para">
<table id="S7.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E11.m1.1" class="ltx_Math" alttext="O_{\text{p}}=N_{\text{p}}\cdot X_{\text{p}}" display="block"><semantics id="S7.E11.m1.1a"><mrow id="S7.E11.m1.1.1" xref="S7.E11.m1.1.1.cmml"><msub id="S7.E11.m1.1.1.2" xref="S7.E11.m1.1.1.2.cmml"><mi mathsize="90%" id="S7.E11.m1.1.1.2.2" xref="S7.E11.m1.1.1.2.2.cmml">O</mi><mtext mathsize="90%" id="S7.E11.m1.1.1.2.3" xref="S7.E11.m1.1.1.2.3a.cmml">p</mtext></msub><mo mathsize="90%" id="S7.E11.m1.1.1.1" xref="S7.E11.m1.1.1.1.cmml">=</mo><mrow id="S7.E11.m1.1.1.3" xref="S7.E11.m1.1.1.3.cmml"><msub id="S7.E11.m1.1.1.3.2" xref="S7.E11.m1.1.1.3.2.cmml"><mi mathsize="90%" id="S7.E11.m1.1.1.3.2.2" xref="S7.E11.m1.1.1.3.2.2.cmml">N</mi><mtext mathsize="90%" id="S7.E11.m1.1.1.3.2.3" xref="S7.E11.m1.1.1.3.2.3a.cmml">p</mtext></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S7.E11.m1.1.1.3.1" xref="S7.E11.m1.1.1.3.1.cmml">⋅</mo><msub id="S7.E11.m1.1.1.3.3" xref="S7.E11.m1.1.1.3.3.cmml"><mi mathsize="90%" id="S7.E11.m1.1.1.3.3.2" xref="S7.E11.m1.1.1.3.3.2.cmml">X</mi><mtext mathsize="90%" id="S7.E11.m1.1.1.3.3.3" xref="S7.E11.m1.1.1.3.3.3a.cmml">p</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E11.m1.1b"><apply id="S7.E11.m1.1.1.cmml" xref="S7.E11.m1.1.1"><eq id="S7.E11.m1.1.1.1.cmml" xref="S7.E11.m1.1.1.1"></eq><apply id="S7.E11.m1.1.1.2.cmml" xref="S7.E11.m1.1.1.2"><csymbol cd="ambiguous" id="S7.E11.m1.1.1.2.1.cmml" xref="S7.E11.m1.1.1.2">subscript</csymbol><ci id="S7.E11.m1.1.1.2.2.cmml" xref="S7.E11.m1.1.1.2.2">𝑂</ci><ci id="S7.E11.m1.1.1.2.3a.cmml" xref="S7.E11.m1.1.1.2.3"><mtext mathsize="63%" id="S7.E11.m1.1.1.2.3.cmml" xref="S7.E11.m1.1.1.2.3">p</mtext></ci></apply><apply id="S7.E11.m1.1.1.3.cmml" xref="S7.E11.m1.1.1.3"><ci id="S7.E11.m1.1.1.3.1.cmml" xref="S7.E11.m1.1.1.3.1">⋅</ci><apply id="S7.E11.m1.1.1.3.2.cmml" xref="S7.E11.m1.1.1.3.2"><csymbol cd="ambiguous" id="S7.E11.m1.1.1.3.2.1.cmml" xref="S7.E11.m1.1.1.3.2">subscript</csymbol><ci id="S7.E11.m1.1.1.3.2.2.cmml" xref="S7.E11.m1.1.1.3.2.2">𝑁</ci><ci id="S7.E11.m1.1.1.3.2.3a.cmml" xref="S7.E11.m1.1.1.3.2.3"><mtext mathsize="63%" id="S7.E11.m1.1.1.3.2.3.cmml" xref="S7.E11.m1.1.1.3.2.3">p</mtext></ci></apply><apply id="S7.E11.m1.1.1.3.3.cmml" xref="S7.E11.m1.1.1.3.3"><csymbol cd="ambiguous" id="S7.E11.m1.1.1.3.3.1.cmml" xref="S7.E11.m1.1.1.3.3">subscript</csymbol><ci id="S7.E11.m1.1.1.3.3.2.cmml" xref="S7.E11.m1.1.1.3.3.2">𝑋</ci><ci id="S7.E11.m1.1.1.3.3.3a.cmml" xref="S7.E11.m1.1.1.3.3.3"><mtext mathsize="63%" id="S7.E11.m1.1.1.3.3.3.cmml" xref="S7.E11.m1.1.1.3.3.3">p</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E11.m1.1c">O_{\text{p}}=N_{\text{p}}\cdot X_{\text{p}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.I2.i1.p5" class="ltx_para">
<table id="S7.E12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E12.m1.1" class="ltx_Math" alttext="A_{\text{p}}=O_{\text{p}}\odot X_{\text{p}}" display="block"><semantics id="S7.E12.m1.1a"><mrow id="S7.E12.m1.1.1" xref="S7.E12.m1.1.1.cmml"><msub id="S7.E12.m1.1.1.2" xref="S7.E12.m1.1.1.2.cmml"><mi mathsize="90%" id="S7.E12.m1.1.1.2.2" xref="S7.E12.m1.1.1.2.2.cmml">A</mi><mtext mathsize="90%" id="S7.E12.m1.1.1.2.3" xref="S7.E12.m1.1.1.2.3a.cmml">p</mtext></msub><mo mathsize="90%" id="S7.E12.m1.1.1.1" xref="S7.E12.m1.1.1.1.cmml">=</mo><mrow id="S7.E12.m1.1.1.3" xref="S7.E12.m1.1.1.3.cmml"><msub id="S7.E12.m1.1.1.3.2" xref="S7.E12.m1.1.1.3.2.cmml"><mi mathsize="90%" id="S7.E12.m1.1.1.3.2.2" xref="S7.E12.m1.1.1.3.2.2.cmml">O</mi><mtext mathsize="90%" id="S7.E12.m1.1.1.3.2.3" xref="S7.E12.m1.1.1.3.2.3a.cmml">p</mtext></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S7.E12.m1.1.1.3.1" xref="S7.E12.m1.1.1.3.1.cmml">⊙</mo><msub id="S7.E12.m1.1.1.3.3" xref="S7.E12.m1.1.1.3.3.cmml"><mi mathsize="90%" id="S7.E12.m1.1.1.3.3.2" xref="S7.E12.m1.1.1.3.3.2.cmml">X</mi><mtext mathsize="90%" id="S7.E12.m1.1.1.3.3.3" xref="S7.E12.m1.1.1.3.3.3a.cmml">p</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E12.m1.1b"><apply id="S7.E12.m1.1.1.cmml" xref="S7.E12.m1.1.1"><eq id="S7.E12.m1.1.1.1.cmml" xref="S7.E12.m1.1.1.1"></eq><apply id="S7.E12.m1.1.1.2.cmml" xref="S7.E12.m1.1.1.2"><csymbol cd="ambiguous" id="S7.E12.m1.1.1.2.1.cmml" xref="S7.E12.m1.1.1.2">subscript</csymbol><ci id="S7.E12.m1.1.1.2.2.cmml" xref="S7.E12.m1.1.1.2.2">𝐴</ci><ci id="S7.E12.m1.1.1.2.3a.cmml" xref="S7.E12.m1.1.1.2.3"><mtext mathsize="63%" id="S7.E12.m1.1.1.2.3.cmml" xref="S7.E12.m1.1.1.2.3">p</mtext></ci></apply><apply id="S7.E12.m1.1.1.3.cmml" xref="S7.E12.m1.1.1.3"><csymbol cd="latexml" id="S7.E12.m1.1.1.3.1.cmml" xref="S7.E12.m1.1.1.3.1">direct-product</csymbol><apply id="S7.E12.m1.1.1.3.2.cmml" xref="S7.E12.m1.1.1.3.2"><csymbol cd="ambiguous" id="S7.E12.m1.1.1.3.2.1.cmml" xref="S7.E12.m1.1.1.3.2">subscript</csymbol><ci id="S7.E12.m1.1.1.3.2.2.cmml" xref="S7.E12.m1.1.1.3.2.2">𝑂</ci><ci id="S7.E12.m1.1.1.3.2.3a.cmml" xref="S7.E12.m1.1.1.3.2.3"><mtext mathsize="63%" id="S7.E12.m1.1.1.3.2.3.cmml" xref="S7.E12.m1.1.1.3.2.3">p</mtext></ci></apply><apply id="S7.E12.m1.1.1.3.3.cmml" xref="S7.E12.m1.1.1.3.3"><csymbol cd="ambiguous" id="S7.E12.m1.1.1.3.3.1.cmml" xref="S7.E12.m1.1.1.3.3">subscript</csymbol><ci id="S7.E12.m1.1.1.3.3.2.cmml" xref="S7.E12.m1.1.1.3.3.2">𝑋</ci><ci id="S7.E12.m1.1.1.3.3.3a.cmml" xref="S7.E12.m1.1.1.3.3.3"><mtext mathsize="63%" id="S7.E12.m1.1.1.3.3.3.cmml" xref="S7.E12.m1.1.1.3.3.3">p</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E12.m1.1c">A_{\text{p}}=O_{\text{p}}\odot X_{\text{p}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(12)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.I2.i1.p6" class="ltx_para">
<p id="S7.I2.i1.p6.5" class="ltx_p"><span id="S7.I2.i1.p6.5.1" class="ltx_text" style="font-size:90%;">The attention matrix </span><math id="S7.I2.i1.p6.1.m1.1" class="ltx_Math" alttext="A_{\text{u}}" display="inline"><semantics id="S7.I2.i1.p6.1.m1.1a"><msub id="S7.I2.i1.p6.1.m1.1.1" xref="S7.I2.i1.p6.1.m1.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p6.1.m1.1.1.2" xref="S7.I2.i1.p6.1.m1.1.1.2.cmml">A</mi><mtext mathsize="90%" id="S7.I2.i1.p6.1.m1.1.1.3" xref="S7.I2.i1.p6.1.m1.1.1.3a.cmml">u</mtext></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p6.1.m1.1b"><apply id="S7.I2.i1.p6.1.m1.1.1.cmml" xref="S7.I2.i1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p6.1.m1.1.1.1.cmml" xref="S7.I2.i1.p6.1.m1.1.1">subscript</csymbol><ci id="S7.I2.i1.p6.1.m1.1.1.2.cmml" xref="S7.I2.i1.p6.1.m1.1.1.2">𝐴</ci><ci id="S7.I2.i1.p6.1.m1.1.1.3a.cmml" xref="S7.I2.i1.p6.1.m1.1.1.3"><mtext mathsize="63%" id="S7.I2.i1.p6.1.m1.1.1.3.cmml" xref="S7.I2.i1.p6.1.m1.1.1.3">u</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p6.1.m1.1c">A_{\text{u}}</annotation></semantics></math><span id="S7.I2.i1.p6.5.2" class="ltx_text" style="font-size:90%;"> is computed separately for </span><math id="S7.I2.i1.p6.2.m2.4" class="ltx_Math" alttext="p=1^{\text{st}},2^{\text{nd}},\ldots,N^{\text{th}}" display="inline"><semantics id="S7.I2.i1.p6.2.m2.4a"><mrow id="S7.I2.i1.p6.2.m2.4.4" xref="S7.I2.i1.p6.2.m2.4.4.cmml"><mi mathsize="90%" id="S7.I2.i1.p6.2.m2.4.4.5" xref="S7.I2.i1.p6.2.m2.4.4.5.cmml">p</mi><mo mathsize="90%" id="S7.I2.i1.p6.2.m2.4.4.4" xref="S7.I2.i1.p6.2.m2.4.4.4.cmml">=</mo><mrow id="S7.I2.i1.p6.2.m2.4.4.3.3" xref="S7.I2.i1.p6.2.m2.4.4.3.4.cmml"><msup id="S7.I2.i1.p6.2.m2.2.2.1.1.1" xref="S7.I2.i1.p6.2.m2.2.2.1.1.1.cmml"><mn mathsize="90%" id="S7.I2.i1.p6.2.m2.2.2.1.1.1.2" xref="S7.I2.i1.p6.2.m2.2.2.1.1.1.2.cmml">1</mn><mtext mathsize="90%" id="S7.I2.i1.p6.2.m2.2.2.1.1.1.3" xref="S7.I2.i1.p6.2.m2.2.2.1.1.1.3a.cmml">st</mtext></msup><mo mathsize="90%" id="S7.I2.i1.p6.2.m2.4.4.3.3.4" xref="S7.I2.i1.p6.2.m2.4.4.3.4.cmml">,</mo><msup id="S7.I2.i1.p6.2.m2.3.3.2.2.2" xref="S7.I2.i1.p6.2.m2.3.3.2.2.2.cmml"><mn mathsize="90%" id="S7.I2.i1.p6.2.m2.3.3.2.2.2.2" xref="S7.I2.i1.p6.2.m2.3.3.2.2.2.2.cmml">2</mn><mtext mathsize="90%" id="S7.I2.i1.p6.2.m2.3.3.2.2.2.3" xref="S7.I2.i1.p6.2.m2.3.3.2.2.2.3a.cmml">nd</mtext></msup><mo mathsize="90%" id="S7.I2.i1.p6.2.m2.4.4.3.3.5" xref="S7.I2.i1.p6.2.m2.4.4.3.4.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S7.I2.i1.p6.2.m2.1.1" xref="S7.I2.i1.p6.2.m2.1.1.cmml">…</mi><mo mathsize="90%" id="S7.I2.i1.p6.2.m2.4.4.3.3.6" xref="S7.I2.i1.p6.2.m2.4.4.3.4.cmml">,</mo><msup id="S7.I2.i1.p6.2.m2.4.4.3.3.3" xref="S7.I2.i1.p6.2.m2.4.4.3.3.3.cmml"><mi mathsize="90%" id="S7.I2.i1.p6.2.m2.4.4.3.3.3.2" xref="S7.I2.i1.p6.2.m2.4.4.3.3.3.2.cmml">N</mi><mtext mathsize="90%" id="S7.I2.i1.p6.2.m2.4.4.3.3.3.3" xref="S7.I2.i1.p6.2.m2.4.4.3.3.3.3a.cmml">th</mtext></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p6.2.m2.4b"><apply id="S7.I2.i1.p6.2.m2.4.4.cmml" xref="S7.I2.i1.p6.2.m2.4.4"><eq id="S7.I2.i1.p6.2.m2.4.4.4.cmml" xref="S7.I2.i1.p6.2.m2.4.4.4"></eq><ci id="S7.I2.i1.p6.2.m2.4.4.5.cmml" xref="S7.I2.i1.p6.2.m2.4.4.5">𝑝</ci><list id="S7.I2.i1.p6.2.m2.4.4.3.4.cmml" xref="S7.I2.i1.p6.2.m2.4.4.3.3"><apply id="S7.I2.i1.p6.2.m2.2.2.1.1.1.cmml" xref="S7.I2.i1.p6.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p6.2.m2.2.2.1.1.1.1.cmml" xref="S7.I2.i1.p6.2.m2.2.2.1.1.1">superscript</csymbol><cn type="integer" id="S7.I2.i1.p6.2.m2.2.2.1.1.1.2.cmml" xref="S7.I2.i1.p6.2.m2.2.2.1.1.1.2">1</cn><ci id="S7.I2.i1.p6.2.m2.2.2.1.1.1.3a.cmml" xref="S7.I2.i1.p6.2.m2.2.2.1.1.1.3"><mtext mathsize="63%" id="S7.I2.i1.p6.2.m2.2.2.1.1.1.3.cmml" xref="S7.I2.i1.p6.2.m2.2.2.1.1.1.3">st</mtext></ci></apply><apply id="S7.I2.i1.p6.2.m2.3.3.2.2.2.cmml" xref="S7.I2.i1.p6.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S7.I2.i1.p6.2.m2.3.3.2.2.2.1.cmml" xref="S7.I2.i1.p6.2.m2.3.3.2.2.2">superscript</csymbol><cn type="integer" id="S7.I2.i1.p6.2.m2.3.3.2.2.2.2.cmml" xref="S7.I2.i1.p6.2.m2.3.3.2.2.2.2">2</cn><ci id="S7.I2.i1.p6.2.m2.3.3.2.2.2.3a.cmml" xref="S7.I2.i1.p6.2.m2.3.3.2.2.2.3"><mtext mathsize="63%" id="S7.I2.i1.p6.2.m2.3.3.2.2.2.3.cmml" xref="S7.I2.i1.p6.2.m2.3.3.2.2.2.3">nd</mtext></ci></apply><ci id="S7.I2.i1.p6.2.m2.1.1.cmml" xref="S7.I2.i1.p6.2.m2.1.1">…</ci><apply id="S7.I2.i1.p6.2.m2.4.4.3.3.3.cmml" xref="S7.I2.i1.p6.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S7.I2.i1.p6.2.m2.4.4.3.3.3.1.cmml" xref="S7.I2.i1.p6.2.m2.4.4.3.3.3">superscript</csymbol><ci id="S7.I2.i1.p6.2.m2.4.4.3.3.3.2.cmml" xref="S7.I2.i1.p6.2.m2.4.4.3.3.3.2">𝑁</ci><ci id="S7.I2.i1.p6.2.m2.4.4.3.3.3.3a.cmml" xref="S7.I2.i1.p6.2.m2.4.4.3.3.3.3"><mtext mathsize="63%" id="S7.I2.i1.p6.2.m2.4.4.3.3.3.3.cmml" xref="S7.I2.i1.p6.2.m2.4.4.3.3.3.3">th</mtext></ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p6.2.m2.4c">p=1^{\text{st}},2^{\text{nd}},\ldots,N^{\text{th}}</annotation></semantics></math><span id="S7.I2.i1.p6.5.3" class="ltx_text" style="font-size:90%;"> sequences. Finally, for each sequence </span><math id="S7.I2.i1.p6.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S7.I2.i1.p6.3.m3.1a"><mi mathsize="90%" id="S7.I2.i1.p6.3.m3.1.1" xref="S7.I2.i1.p6.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p6.3.m3.1b"><ci id="S7.I2.i1.p6.3.m3.1.1.cmml" xref="S7.I2.i1.p6.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p6.3.m3.1c">p</annotation></semantics></math><span id="S7.I2.i1.p6.5.4" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i1.p6.4.m4.1" class="ltx_Math" alttext="A_{\text{p}}" display="inline"><semantics id="S7.I2.i1.p6.4.m4.1a"><msub id="S7.I2.i1.p6.4.m4.1.1" xref="S7.I2.i1.p6.4.m4.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p6.4.m4.1.1.2" xref="S7.I2.i1.p6.4.m4.1.1.2.cmml">A</mi><mtext mathsize="90%" id="S7.I2.i1.p6.4.m4.1.1.3" xref="S7.I2.i1.p6.4.m4.1.1.3a.cmml">p</mtext></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p6.4.m4.1b"><apply id="S7.I2.i1.p6.4.m4.1.1.cmml" xref="S7.I2.i1.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p6.4.m4.1.1.1.cmml" xref="S7.I2.i1.p6.4.m4.1.1">subscript</csymbol><ci id="S7.I2.i1.p6.4.m4.1.1.2.cmml" xref="S7.I2.i1.p6.4.m4.1.1.2">𝐴</ci><ci id="S7.I2.i1.p6.4.m4.1.1.3a.cmml" xref="S7.I2.i1.p6.4.m4.1.1.3"><mtext mathsize="63%" id="S7.I2.i1.p6.4.m4.1.1.3.cmml" xref="S7.I2.i1.p6.4.m4.1.1.3">p</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p6.4.m4.1c">A_{\text{p}}</annotation></semantics></math><span id="S7.I2.i1.p6.5.5" class="ltx_text" style="font-size:90%;"> and </span><math id="S7.I2.i1.p6.5.m5.1" class="ltx_Math" alttext="X_{\text{p}}" display="inline"><semantics id="S7.I2.i1.p6.5.m5.1a"><msub id="S7.I2.i1.p6.5.m5.1.1" xref="S7.I2.i1.p6.5.m5.1.1.cmml"><mi mathsize="90%" id="S7.I2.i1.p6.5.m5.1.1.2" xref="S7.I2.i1.p6.5.m5.1.1.2.cmml">X</mi><mtext mathsize="90%" id="S7.I2.i1.p6.5.m5.1.1.3" xref="S7.I2.i1.p6.5.m5.1.1.3a.cmml">p</mtext></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i1.p6.5.m5.1b"><apply id="S7.I2.i1.p6.5.m5.1.1.cmml" xref="S7.I2.i1.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S7.I2.i1.p6.5.m5.1.1.1.cmml" xref="S7.I2.i1.p6.5.m5.1.1">subscript</csymbol><ci id="S7.I2.i1.p6.5.m5.1.1.2.cmml" xref="S7.I2.i1.p6.5.m5.1.1.2">𝑋</ci><ci id="S7.I2.i1.p6.5.m5.1.1.3a.cmml" xref="S7.I2.i1.p6.5.m5.1.1.3"><mtext mathsize="63%" id="S7.I2.i1.p6.5.m5.1.1.3.cmml" xref="S7.I2.i1.p6.5.m5.1.1.3">p</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i1.p6.5.m5.1c">X_{\text{p}}</annotation></semantics></math><span id="S7.I2.i1.p6.5.6" class="ltx_text" style="font-size:90%;"> are concatenated and passed to the output layer for classification.</span></p>
</div>
</li>
<li id="S7.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I2.i2.p1" class="ltx_para">
<p id="S7.I2.i2.p1.12" class="ltx_p"><span id="S7.I2.i2.p1.12.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Multi-Sequence - Self Attention (MS-SA) Framework</span><span id="S7.I2.i2.p1.12.2" class="ltx_text" style="font-size:90%;">: In the MS-SA framework, we apply self-attention to the sequences of each modality separately and use these for classification. In contrast to the MMSS-SA framework, MS-SA utilizes the contextual information of the sequences at the attention level. Let </span><math id="S7.I2.i2.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S7.I2.i2.p1.1.m1.1a"><mi mathsize="90%" id="S7.I2.i2.p1.1.m1.1.1" xref="S7.I2.i2.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.1.m1.1b"><ci id="S7.I2.i2.p1.1.m1.1.1.cmml" xref="S7.I2.i2.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.1.m1.1c">L</annotation></semantics></math><span id="S7.I2.i2.p1.12.3" class="ltx_text" style="font-size:90%;"> (text), </span><math id="S7.I2.i2.p1.2.m2.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S7.I2.i2.p1.2.m2.1a"><mi mathsize="90%" id="S7.I2.i2.p1.2.m2.1.1" xref="S7.I2.i2.p1.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.2.m2.1b"><ci id="S7.I2.i2.p1.2.m2.1.1.cmml" xref="S7.I2.i2.p1.2.m2.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.2.m2.1c">V</annotation></semantics></math><span id="S7.I2.i2.p1.12.4" class="ltx_text" style="font-size:90%;"> (visual), and </span><math id="S7.I2.i2.p1.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S7.I2.i2.p1.3.m3.1a"><mi mathsize="90%" id="S7.I2.i2.p1.3.m3.1.1" xref="S7.I2.i2.p1.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.3.m3.1b"><ci id="S7.I2.i2.p1.3.m3.1.1.cmml" xref="S7.I2.i2.p1.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.3.m3.1c">L</annotation></semantics></math><span id="S7.I2.i2.p1.12.5" class="ltx_text" style="font-size:90%;"> (lip region) be the outputs of the dense layers. Three separate attention blocks are required for the three modalities, where each block takes multi-sequence information of a single modality and computes the self-attention matrix. Attention matrices </span><math id="S7.I2.i2.p1.4.m4.1" class="ltx_Math" alttext="A_{l}" display="inline"><semantics id="S7.I2.i2.p1.4.m4.1a"><msub id="S7.I2.i2.p1.4.m4.1.1" xref="S7.I2.i2.p1.4.m4.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p1.4.m4.1.1.2" xref="S7.I2.i2.p1.4.m4.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i2.p1.4.m4.1.1.3" xref="S7.I2.i2.p1.4.m4.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.4.m4.1b"><apply id="S7.I2.i2.p1.4.m4.1.1.cmml" xref="S7.I2.i2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p1.4.m4.1.1.1.cmml" xref="S7.I2.i2.p1.4.m4.1.1">subscript</csymbol><ci id="S7.I2.i2.p1.4.m4.1.1.2.cmml" xref="S7.I2.i2.p1.4.m4.1.1.2">𝐴</ci><ci id="S7.I2.i2.p1.4.m4.1.1.3.cmml" xref="S7.I2.i2.p1.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.4.m4.1c">A_{l}</annotation></semantics></math><span id="S7.I2.i2.p1.12.6" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i2.p1.5.m5.1" class="ltx_Math" alttext="A_{v}" display="inline"><semantics id="S7.I2.i2.p1.5.m5.1a"><msub id="S7.I2.i2.p1.5.m5.1.1" xref="S7.I2.i2.p1.5.m5.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p1.5.m5.1.1.2" xref="S7.I2.i2.p1.5.m5.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i2.p1.5.m5.1.1.3" xref="S7.I2.i2.p1.5.m5.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.5.m5.1b"><apply id="S7.I2.i2.p1.5.m5.1.1.cmml" xref="S7.I2.i2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p1.5.m5.1.1.1.cmml" xref="S7.I2.i2.p1.5.m5.1.1">subscript</csymbol><ci id="S7.I2.i2.p1.5.m5.1.1.2.cmml" xref="S7.I2.i2.p1.5.m5.1.1.2">𝐴</ci><ci id="S7.I2.i2.p1.5.m5.1.1.3.cmml" xref="S7.I2.i2.p1.5.m5.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.5.m5.1c">A_{v}</annotation></semantics></math><span id="S7.I2.i2.p1.12.7" class="ltx_text" style="font-size:90%;">, and </span><math id="S7.I2.i2.p1.6.m6.1" class="ltx_Math" alttext="A_{a}" display="inline"><semantics id="S7.I2.i2.p1.6.m6.1a"><msub id="S7.I2.i2.p1.6.m6.1.1" xref="S7.I2.i2.p1.6.m6.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p1.6.m6.1.1.2" xref="S7.I2.i2.p1.6.m6.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i2.p1.6.m6.1.1.3" xref="S7.I2.i2.p1.6.m6.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.6.m6.1b"><apply id="S7.I2.i2.p1.6.m6.1.1.cmml" xref="S7.I2.i2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p1.6.m6.1.1.1.cmml" xref="S7.I2.i2.p1.6.m6.1.1">subscript</csymbol><ci id="S7.I2.i2.p1.6.m6.1.1.2.cmml" xref="S7.I2.i2.p1.6.m6.1.1.2">𝐴</ci><ci id="S7.I2.i2.p1.6.m6.1.1.3.cmml" xref="S7.I2.i2.p1.6.m6.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.6.m6.1c">A_{a}</annotation></semantics></math><span id="S7.I2.i2.p1.12.8" class="ltx_text" style="font-size:90%;"> are computed for lip, visual, and acoustic, respectively. Finally, </span><math id="S7.I2.i2.p1.7.m7.1" class="ltx_Math" alttext="A_{v}" display="inline"><semantics id="S7.I2.i2.p1.7.m7.1a"><msub id="S7.I2.i2.p1.7.m7.1.1" xref="S7.I2.i2.p1.7.m7.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p1.7.m7.1.1.2" xref="S7.I2.i2.p1.7.m7.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i2.p1.7.m7.1.1.3" xref="S7.I2.i2.p1.7.m7.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.7.m7.1b"><apply id="S7.I2.i2.p1.7.m7.1.1.cmml" xref="S7.I2.i2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p1.7.m7.1.1.1.cmml" xref="S7.I2.i2.p1.7.m7.1.1">subscript</csymbol><ci id="S7.I2.i2.p1.7.m7.1.1.2.cmml" xref="S7.I2.i2.p1.7.m7.1.1.2">𝐴</ci><ci id="S7.I2.i2.p1.7.m7.1.1.3.cmml" xref="S7.I2.i2.p1.7.m7.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.7.m7.1c">A_{v}</annotation></semantics></math><span id="S7.I2.i2.p1.12.9" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i2.p1.8.m8.1" class="ltx_Math" alttext="A_{l}" display="inline"><semantics id="S7.I2.i2.p1.8.m8.1a"><msub id="S7.I2.i2.p1.8.m8.1.1" xref="S7.I2.i2.p1.8.m8.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p1.8.m8.1.1.2" xref="S7.I2.i2.p1.8.m8.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i2.p1.8.m8.1.1.3" xref="S7.I2.i2.p1.8.m8.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.8.m8.1b"><apply id="S7.I2.i2.p1.8.m8.1.1.cmml" xref="S7.I2.i2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p1.8.m8.1.1.1.cmml" xref="S7.I2.i2.p1.8.m8.1.1">subscript</csymbol><ci id="S7.I2.i2.p1.8.m8.1.1.2.cmml" xref="S7.I2.i2.p1.8.m8.1.1.2">𝐴</ci><ci id="S7.I2.i2.p1.8.m8.1.1.3.cmml" xref="S7.I2.i2.p1.8.m8.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.8.m8.1c">A_{l}</annotation></semantics></math><span id="S7.I2.i2.p1.12.10" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i2.p1.9.m9.1" class="ltx_Math" alttext="A_{a}" display="inline"><semantics id="S7.I2.i2.p1.9.m9.1a"><msub id="S7.I2.i2.p1.9.m9.1.1" xref="S7.I2.i2.p1.9.m9.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p1.9.m9.1.1.2" xref="S7.I2.i2.p1.9.m9.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i2.p1.9.m9.1.1.3" xref="S7.I2.i2.p1.9.m9.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.9.m9.1b"><apply id="S7.I2.i2.p1.9.m9.1.1.cmml" xref="S7.I2.i2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p1.9.m9.1.1.1.cmml" xref="S7.I2.i2.p1.9.m9.1.1">subscript</csymbol><ci id="S7.I2.i2.p1.9.m9.1.1.2.cmml" xref="S7.I2.i2.p1.9.m9.1.1.2">𝐴</ci><ci id="S7.I2.i2.p1.9.m9.1.1.3.cmml" xref="S7.I2.i2.p1.9.m9.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.9.m9.1c">A_{a}</annotation></semantics></math><span id="S7.I2.i2.p1.12.11" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i2.p1.10.m10.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S7.I2.i2.p1.10.m10.1a"><mi mathsize="90%" id="S7.I2.i2.p1.10.m10.1.1" xref="S7.I2.i2.p1.10.m10.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.10.m10.1b"><ci id="S7.I2.i2.p1.10.m10.1.1.cmml" xref="S7.I2.i2.p1.10.m10.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.10.m10.1c">V</annotation></semantics></math><span id="S7.I2.i2.p1.12.12" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i2.p1.11.m11.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S7.I2.i2.p1.11.m11.1a"><mi mathsize="90%" id="S7.I2.i2.p1.11.m11.1.1" xref="S7.I2.i2.p1.11.m11.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.11.m11.1b"><ci id="S7.I2.i2.p1.11.m11.1.1.cmml" xref="S7.I2.i2.p1.11.m11.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.11.m11.1c">L</annotation></semantics></math><span id="S7.I2.i2.p1.12.13" class="ltx_text" style="font-size:90%;">, and </span><math id="S7.I2.i2.p1.12.m12.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S7.I2.i2.p1.12.m12.1a"><mi mathsize="90%" id="S7.I2.i2.p1.12.m12.1.1" xref="S7.I2.i2.p1.12.m12.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p1.12.m12.1b"><ci id="S7.I2.i2.p1.12.m12.1.1.cmml" xref="S7.I2.i2.p1.12.m12.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p1.12.m12.1c">A</annotation></semantics></math><span id="S7.I2.i2.p1.12.14" class="ltx_text" style="font-size:90%;"> are concatenated and passed to the output layer for classification.</span></p>
</div>
<div id="S7.I2.i2.p2" class="ltx_para">
<table id="S7.E13" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E13.m1.1" class="ltx_Math" alttext="M_{v}=V\cdot V^{T}" display="block"><semantics id="S7.E13.m1.1a"><mrow id="S7.E13.m1.1.1" xref="S7.E13.m1.1.1.cmml"><msub id="S7.E13.m1.1.1.2" xref="S7.E13.m1.1.1.2.cmml"><mi mathsize="90%" id="S7.E13.m1.1.1.2.2" xref="S7.E13.m1.1.1.2.2.cmml">M</mi><mi mathsize="90%" id="S7.E13.m1.1.1.2.3" xref="S7.E13.m1.1.1.2.3.cmml">v</mi></msub><mo mathsize="90%" id="S7.E13.m1.1.1.1" xref="S7.E13.m1.1.1.1.cmml">=</mo><mrow id="S7.E13.m1.1.1.3" xref="S7.E13.m1.1.1.3.cmml"><mi mathsize="90%" id="S7.E13.m1.1.1.3.2" xref="S7.E13.m1.1.1.3.2.cmml">V</mi><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S7.E13.m1.1.1.3.1" xref="S7.E13.m1.1.1.3.1.cmml">⋅</mo><msup id="S7.E13.m1.1.1.3.3" xref="S7.E13.m1.1.1.3.3.cmml"><mi mathsize="90%" id="S7.E13.m1.1.1.3.3.2" xref="S7.E13.m1.1.1.3.3.2.cmml">V</mi><mi mathsize="90%" id="S7.E13.m1.1.1.3.3.3" xref="S7.E13.m1.1.1.3.3.3.cmml">T</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E13.m1.1b"><apply id="S7.E13.m1.1.1.cmml" xref="S7.E13.m1.1.1"><eq id="S7.E13.m1.1.1.1.cmml" xref="S7.E13.m1.1.1.1"></eq><apply id="S7.E13.m1.1.1.2.cmml" xref="S7.E13.m1.1.1.2"><csymbol cd="ambiguous" id="S7.E13.m1.1.1.2.1.cmml" xref="S7.E13.m1.1.1.2">subscript</csymbol><ci id="S7.E13.m1.1.1.2.2.cmml" xref="S7.E13.m1.1.1.2.2">𝑀</ci><ci id="S7.E13.m1.1.1.2.3.cmml" xref="S7.E13.m1.1.1.2.3">𝑣</ci></apply><apply id="S7.E13.m1.1.1.3.cmml" xref="S7.E13.m1.1.1.3"><ci id="S7.E13.m1.1.1.3.1.cmml" xref="S7.E13.m1.1.1.3.1">⋅</ci><ci id="S7.E13.m1.1.1.3.2.cmml" xref="S7.E13.m1.1.1.3.2">𝑉</ci><apply id="S7.E13.m1.1.1.3.3.cmml" xref="S7.E13.m1.1.1.3.3"><csymbol cd="ambiguous" id="S7.E13.m1.1.1.3.3.1.cmml" xref="S7.E13.m1.1.1.3.3">superscript</csymbol><ci id="S7.E13.m1.1.1.3.3.2.cmml" xref="S7.E13.m1.1.1.3.3.2">𝑉</ci><ci id="S7.E13.m1.1.1.3.3.3.cmml" xref="S7.E13.m1.1.1.3.3.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E13.m1.1c">M_{v}=V\cdot V^{T}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(13)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.I2.i2.p3" class="ltx_para">
<table id="S7.E14" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E14.m1.11" class="ltx_Math" alttext="N_{v}(i,j)=\frac{e^{M_{v}(i,j)}}{\sum_{k=1}^{u}e^{M_{v}(i,k)}}\text{ for }i,j=1,\ldots,u" display="block"><semantics id="S7.E14.m1.11a"><mrow id="S7.E14.m1.11.11.2" xref="S7.E14.m1.11.11.3.cmml"><mrow id="S7.E14.m1.10.10.1.1" xref="S7.E14.m1.10.10.1.1.cmml"><mrow id="S7.E14.m1.10.10.1.1.2" xref="S7.E14.m1.10.10.1.1.2.cmml"><msub id="S7.E14.m1.10.10.1.1.2.2" xref="S7.E14.m1.10.10.1.1.2.2.cmml"><mi mathsize="90%" id="S7.E14.m1.10.10.1.1.2.2.2" xref="S7.E14.m1.10.10.1.1.2.2.2.cmml">N</mi><mi mathsize="90%" id="S7.E14.m1.10.10.1.1.2.2.3" xref="S7.E14.m1.10.10.1.1.2.2.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S7.E14.m1.10.10.1.1.2.1" xref="S7.E14.m1.10.10.1.1.2.1.cmml">​</mo><mrow id="S7.E14.m1.10.10.1.1.2.3.2" xref="S7.E14.m1.10.10.1.1.2.3.1.cmml"><mo maxsize="90%" minsize="90%" id="S7.E14.m1.10.10.1.1.2.3.2.1" xref="S7.E14.m1.10.10.1.1.2.3.1.cmml">(</mo><mi mathsize="90%" id="S7.E14.m1.5.5" xref="S7.E14.m1.5.5.cmml">i</mi><mo mathsize="90%" id="S7.E14.m1.10.10.1.1.2.3.2.2" xref="S7.E14.m1.10.10.1.1.2.3.1.cmml">,</mo><mi mathsize="90%" id="S7.E14.m1.6.6" xref="S7.E14.m1.6.6.cmml">j</mi><mo maxsize="90%" minsize="90%" id="S7.E14.m1.10.10.1.1.2.3.2.3" xref="S7.E14.m1.10.10.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S7.E14.m1.10.10.1.1.1" xref="S7.E14.m1.10.10.1.1.1.cmml">=</mo><mrow id="S7.E14.m1.10.10.1.1.3" xref="S7.E14.m1.10.10.1.1.3.cmml"><mfrac id="S7.E14.m1.4.4" xref="S7.E14.m1.4.4.cmml"><msup id="S7.E14.m1.2.2.2" xref="S7.E14.m1.2.2.2.cmml"><mi mathsize="90%" id="S7.E14.m1.2.2.2.4" xref="S7.E14.m1.2.2.2.4.cmml">e</mi><mrow id="S7.E14.m1.2.2.2.2.2" xref="S7.E14.m1.2.2.2.2.2.cmml"><msub id="S7.E14.m1.2.2.2.2.2.4" xref="S7.E14.m1.2.2.2.2.2.4.cmml"><mi mathsize="90%" id="S7.E14.m1.2.2.2.2.2.4.2" xref="S7.E14.m1.2.2.2.2.2.4.2.cmml">M</mi><mi mathsize="90%" id="S7.E14.m1.2.2.2.2.2.4.3" xref="S7.E14.m1.2.2.2.2.2.4.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S7.E14.m1.2.2.2.2.2.3" xref="S7.E14.m1.2.2.2.2.2.3.cmml">​</mo><mrow id="S7.E14.m1.2.2.2.2.2.5.2" xref="S7.E14.m1.2.2.2.2.2.5.1.cmml"><mo maxsize="90%" minsize="90%" id="S7.E14.m1.2.2.2.2.2.5.2.1" xref="S7.E14.m1.2.2.2.2.2.5.1.cmml">(</mo><mi mathsize="90%" id="S7.E14.m1.1.1.1.1.1.1" xref="S7.E14.m1.1.1.1.1.1.1.cmml">i</mi><mo mathsize="90%" id="S7.E14.m1.2.2.2.2.2.5.2.2" xref="S7.E14.m1.2.2.2.2.2.5.1.cmml">,</mo><mi mathsize="90%" id="S7.E14.m1.2.2.2.2.2.2" xref="S7.E14.m1.2.2.2.2.2.2.cmml">j</mi><mo maxsize="90%" minsize="90%" id="S7.E14.m1.2.2.2.2.2.5.2.3" xref="S7.E14.m1.2.2.2.2.2.5.1.cmml">)</mo></mrow></mrow></msup><mrow id="S7.E14.m1.4.4.4" xref="S7.E14.m1.4.4.4.cmml"><msubsup id="S7.E14.m1.4.4.4.3" xref="S7.E14.m1.4.4.4.3.cmml"><mo maxsize="90%" minsize="90%" stretchy="true" id="S7.E14.m1.4.4.4.3.2.2" xref="S7.E14.m1.4.4.4.3.2.2.cmml">∑</mo><mrow id="S7.E14.m1.4.4.4.3.2.3" xref="S7.E14.m1.4.4.4.3.2.3.cmml"><mi mathsize="90%" id="S7.E14.m1.4.4.4.3.2.3.2" xref="S7.E14.m1.4.4.4.3.2.3.2.cmml">k</mi><mo mathsize="90%" id="S7.E14.m1.4.4.4.3.2.3.1" xref="S7.E14.m1.4.4.4.3.2.3.1.cmml">=</mo><mn mathsize="90%" id="S7.E14.m1.4.4.4.3.2.3.3" xref="S7.E14.m1.4.4.4.3.2.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="S7.E14.m1.4.4.4.3.3" xref="S7.E14.m1.4.4.4.3.3.cmml">u</mi></msubsup><msup id="S7.E14.m1.4.4.4.4" xref="S7.E14.m1.4.4.4.4.cmml"><mi mathsize="90%" id="S7.E14.m1.4.4.4.4.2" xref="S7.E14.m1.4.4.4.4.2.cmml">e</mi><mrow id="S7.E14.m1.4.4.4.2.2" xref="S7.E14.m1.4.4.4.2.2.cmml"><msub id="S7.E14.m1.4.4.4.2.2.4" xref="S7.E14.m1.4.4.4.2.2.4.cmml"><mi mathsize="90%" id="S7.E14.m1.4.4.4.2.2.4.2" xref="S7.E14.m1.4.4.4.2.2.4.2.cmml">M</mi><mi mathsize="90%" id="S7.E14.m1.4.4.4.2.2.4.3" xref="S7.E14.m1.4.4.4.2.2.4.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S7.E14.m1.4.4.4.2.2.3" xref="S7.E14.m1.4.4.4.2.2.3.cmml">​</mo><mrow id="S7.E14.m1.4.4.4.2.2.5.2" xref="S7.E14.m1.4.4.4.2.2.5.1.cmml"><mo maxsize="90%" minsize="90%" id="S7.E14.m1.4.4.4.2.2.5.2.1" xref="S7.E14.m1.4.4.4.2.2.5.1.cmml">(</mo><mi mathsize="90%" id="S7.E14.m1.3.3.3.1.1.1" xref="S7.E14.m1.3.3.3.1.1.1.cmml">i</mi><mo mathsize="90%" id="S7.E14.m1.4.4.4.2.2.5.2.2" xref="S7.E14.m1.4.4.4.2.2.5.1.cmml">,</mo><mi mathsize="90%" id="S7.E14.m1.4.4.4.2.2.2" xref="S7.E14.m1.4.4.4.2.2.2.cmml">k</mi><mo maxsize="90%" minsize="90%" id="S7.E14.m1.4.4.4.2.2.5.2.3" xref="S7.E14.m1.4.4.4.2.2.5.1.cmml">)</mo></mrow></mrow></msup></mrow></mfrac><mo lspace="0em" rspace="0em" id="S7.E14.m1.10.10.1.1.3.1" xref="S7.E14.m1.10.10.1.1.3.1.cmml">​</mo><mtext mathsize="90%" id="S7.E14.m1.10.10.1.1.3.2" xref="S7.E14.m1.10.10.1.1.3.2a.cmml"> for </mtext><mo lspace="0em" rspace="0em" id="S7.E14.m1.10.10.1.1.3.1a" xref="S7.E14.m1.10.10.1.1.3.1.cmml">​</mo><mi mathsize="90%" id="S7.E14.m1.10.10.1.1.3.3" xref="S7.E14.m1.10.10.1.1.3.3.cmml">i</mi></mrow></mrow><mo mathsize="90%" id="S7.E14.m1.11.11.2.3" xref="S7.E14.m1.11.11.3a.cmml">,</mo><mrow id="S7.E14.m1.11.11.2.2" xref="S7.E14.m1.11.11.2.2.cmml"><mi mathsize="90%" id="S7.E14.m1.11.11.2.2.2" xref="S7.E14.m1.11.11.2.2.2.cmml">j</mi><mo mathsize="90%" id="S7.E14.m1.11.11.2.2.1" xref="S7.E14.m1.11.11.2.2.1.cmml">=</mo><mrow id="S7.E14.m1.11.11.2.2.3.2" xref="S7.E14.m1.11.11.2.2.3.1.cmml"><mn mathsize="90%" id="S7.E14.m1.7.7" xref="S7.E14.m1.7.7.cmml">1</mn><mo mathsize="90%" id="S7.E14.m1.11.11.2.2.3.2.1" xref="S7.E14.m1.11.11.2.2.3.1.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S7.E14.m1.8.8" xref="S7.E14.m1.8.8.cmml">…</mi><mo mathsize="90%" id="S7.E14.m1.11.11.2.2.3.2.2" xref="S7.E14.m1.11.11.2.2.3.1.cmml">,</mo><mi mathsize="90%" id="S7.E14.m1.9.9" xref="S7.E14.m1.9.9.cmml">u</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E14.m1.11b"><apply id="S7.E14.m1.11.11.3.cmml" xref="S7.E14.m1.11.11.2"><csymbol cd="ambiguous" id="S7.E14.m1.11.11.3a.cmml" xref="S7.E14.m1.11.11.2.3">formulae-sequence</csymbol><apply id="S7.E14.m1.10.10.1.1.cmml" xref="S7.E14.m1.10.10.1.1"><eq id="S7.E14.m1.10.10.1.1.1.cmml" xref="S7.E14.m1.10.10.1.1.1"></eq><apply id="S7.E14.m1.10.10.1.1.2.cmml" xref="S7.E14.m1.10.10.1.1.2"><times id="S7.E14.m1.10.10.1.1.2.1.cmml" xref="S7.E14.m1.10.10.1.1.2.1"></times><apply id="S7.E14.m1.10.10.1.1.2.2.cmml" xref="S7.E14.m1.10.10.1.1.2.2"><csymbol cd="ambiguous" id="S7.E14.m1.10.10.1.1.2.2.1.cmml" xref="S7.E14.m1.10.10.1.1.2.2">subscript</csymbol><ci id="S7.E14.m1.10.10.1.1.2.2.2.cmml" xref="S7.E14.m1.10.10.1.1.2.2.2">𝑁</ci><ci id="S7.E14.m1.10.10.1.1.2.2.3.cmml" xref="S7.E14.m1.10.10.1.1.2.2.3">𝑣</ci></apply><interval closure="open" id="S7.E14.m1.10.10.1.1.2.3.1.cmml" xref="S7.E14.m1.10.10.1.1.2.3.2"><ci id="S7.E14.m1.5.5.cmml" xref="S7.E14.m1.5.5">𝑖</ci><ci id="S7.E14.m1.6.6.cmml" xref="S7.E14.m1.6.6">𝑗</ci></interval></apply><apply id="S7.E14.m1.10.10.1.1.3.cmml" xref="S7.E14.m1.10.10.1.1.3"><times id="S7.E14.m1.10.10.1.1.3.1.cmml" xref="S7.E14.m1.10.10.1.1.3.1"></times><apply id="S7.E14.m1.4.4.cmml" xref="S7.E14.m1.4.4"><divide id="S7.E14.m1.4.4.5.cmml" xref="S7.E14.m1.4.4"></divide><apply id="S7.E14.m1.2.2.2.cmml" xref="S7.E14.m1.2.2.2"><csymbol cd="ambiguous" id="S7.E14.m1.2.2.2.3.cmml" xref="S7.E14.m1.2.2.2">superscript</csymbol><ci id="S7.E14.m1.2.2.2.4.cmml" xref="S7.E14.m1.2.2.2.4">𝑒</ci><apply id="S7.E14.m1.2.2.2.2.2.cmml" xref="S7.E14.m1.2.2.2.2.2"><times id="S7.E14.m1.2.2.2.2.2.3.cmml" xref="S7.E14.m1.2.2.2.2.2.3"></times><apply id="S7.E14.m1.2.2.2.2.2.4.cmml" xref="S7.E14.m1.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S7.E14.m1.2.2.2.2.2.4.1.cmml" xref="S7.E14.m1.2.2.2.2.2.4">subscript</csymbol><ci id="S7.E14.m1.2.2.2.2.2.4.2.cmml" xref="S7.E14.m1.2.2.2.2.2.4.2">𝑀</ci><ci id="S7.E14.m1.2.2.2.2.2.4.3.cmml" xref="S7.E14.m1.2.2.2.2.2.4.3">𝑣</ci></apply><interval closure="open" id="S7.E14.m1.2.2.2.2.2.5.1.cmml" xref="S7.E14.m1.2.2.2.2.2.5.2"><ci id="S7.E14.m1.1.1.1.1.1.1.cmml" xref="S7.E14.m1.1.1.1.1.1.1">𝑖</ci><ci id="S7.E14.m1.2.2.2.2.2.2.cmml" xref="S7.E14.m1.2.2.2.2.2.2">𝑗</ci></interval></apply></apply><apply id="S7.E14.m1.4.4.4.cmml" xref="S7.E14.m1.4.4.4"><apply id="S7.E14.m1.4.4.4.3.cmml" xref="S7.E14.m1.4.4.4.3"><csymbol cd="ambiguous" id="S7.E14.m1.4.4.4.3.1.cmml" xref="S7.E14.m1.4.4.4.3">superscript</csymbol><apply id="S7.E14.m1.4.4.4.3.2.cmml" xref="S7.E14.m1.4.4.4.3"><csymbol cd="ambiguous" id="S7.E14.m1.4.4.4.3.2.1.cmml" xref="S7.E14.m1.4.4.4.3">subscript</csymbol><sum id="S7.E14.m1.4.4.4.3.2.2.cmml" xref="S7.E14.m1.4.4.4.3.2.2"></sum><apply id="S7.E14.m1.4.4.4.3.2.3.cmml" xref="S7.E14.m1.4.4.4.3.2.3"><eq id="S7.E14.m1.4.4.4.3.2.3.1.cmml" xref="S7.E14.m1.4.4.4.3.2.3.1"></eq><ci id="S7.E14.m1.4.4.4.3.2.3.2.cmml" xref="S7.E14.m1.4.4.4.3.2.3.2">𝑘</ci><cn type="integer" id="S7.E14.m1.4.4.4.3.2.3.3.cmml" xref="S7.E14.m1.4.4.4.3.2.3.3">1</cn></apply></apply><ci id="S7.E14.m1.4.4.4.3.3.cmml" xref="S7.E14.m1.4.4.4.3.3">𝑢</ci></apply><apply id="S7.E14.m1.4.4.4.4.cmml" xref="S7.E14.m1.4.4.4.4"><csymbol cd="ambiguous" id="S7.E14.m1.4.4.4.4.1.cmml" xref="S7.E14.m1.4.4.4.4">superscript</csymbol><ci id="S7.E14.m1.4.4.4.4.2.cmml" xref="S7.E14.m1.4.4.4.4.2">𝑒</ci><apply id="S7.E14.m1.4.4.4.2.2.cmml" xref="S7.E14.m1.4.4.4.2.2"><times id="S7.E14.m1.4.4.4.2.2.3.cmml" xref="S7.E14.m1.4.4.4.2.2.3"></times><apply id="S7.E14.m1.4.4.4.2.2.4.cmml" xref="S7.E14.m1.4.4.4.2.2.4"><csymbol cd="ambiguous" id="S7.E14.m1.4.4.4.2.2.4.1.cmml" xref="S7.E14.m1.4.4.4.2.2.4">subscript</csymbol><ci id="S7.E14.m1.4.4.4.2.2.4.2.cmml" xref="S7.E14.m1.4.4.4.2.2.4.2">𝑀</ci><ci id="S7.E14.m1.4.4.4.2.2.4.3.cmml" xref="S7.E14.m1.4.4.4.2.2.4.3">𝑣</ci></apply><interval closure="open" id="S7.E14.m1.4.4.4.2.2.5.1.cmml" xref="S7.E14.m1.4.4.4.2.2.5.2"><ci id="S7.E14.m1.3.3.3.1.1.1.cmml" xref="S7.E14.m1.3.3.3.1.1.1">𝑖</ci><ci id="S7.E14.m1.4.4.4.2.2.2.cmml" xref="S7.E14.m1.4.4.4.2.2.2">𝑘</ci></interval></apply></apply></apply></apply><ci id="S7.E14.m1.10.10.1.1.3.2a.cmml" xref="S7.E14.m1.10.10.1.1.3.2"><mtext mathsize="90%" id="S7.E14.m1.10.10.1.1.3.2.cmml" xref="S7.E14.m1.10.10.1.1.3.2"> for </mtext></ci><ci id="S7.E14.m1.10.10.1.1.3.3.cmml" xref="S7.E14.m1.10.10.1.1.3.3">𝑖</ci></apply></apply><apply id="S7.E14.m1.11.11.2.2.cmml" xref="S7.E14.m1.11.11.2.2"><eq id="S7.E14.m1.11.11.2.2.1.cmml" xref="S7.E14.m1.11.11.2.2.1"></eq><ci id="S7.E14.m1.11.11.2.2.2.cmml" xref="S7.E14.m1.11.11.2.2.2">𝑗</ci><list id="S7.E14.m1.11.11.2.2.3.1.cmml" xref="S7.E14.m1.11.11.2.2.3.2"><cn type="integer" id="S7.E14.m1.7.7.cmml" xref="S7.E14.m1.7.7">1</cn><ci id="S7.E14.m1.8.8.cmml" xref="S7.E14.m1.8.8">…</ci><ci id="S7.E14.m1.9.9.cmml" xref="S7.E14.m1.9.9">𝑢</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E14.m1.11c">N_{v}(i,j)=\frac{e^{M_{v}(i,j)}}{\sum_{k=1}^{u}e^{M_{v}(i,k)}}\text{ for }i,j=1,\ldots,u</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(14)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.I2.i2.p4" class="ltx_para">
<table id="S7.E15" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E15.m1.1" class="ltx_Math" alttext="O_{v}=N_{v}\cdot V" display="block"><semantics id="S7.E15.m1.1a"><mrow id="S7.E15.m1.1.1" xref="S7.E15.m1.1.1.cmml"><msub id="S7.E15.m1.1.1.2" xref="S7.E15.m1.1.1.2.cmml"><mi mathsize="90%" id="S7.E15.m1.1.1.2.2" xref="S7.E15.m1.1.1.2.2.cmml">O</mi><mi mathsize="90%" id="S7.E15.m1.1.1.2.3" xref="S7.E15.m1.1.1.2.3.cmml">v</mi></msub><mo mathsize="90%" id="S7.E15.m1.1.1.1" xref="S7.E15.m1.1.1.1.cmml">=</mo><mrow id="S7.E15.m1.1.1.3" xref="S7.E15.m1.1.1.3.cmml"><msub id="S7.E15.m1.1.1.3.2" xref="S7.E15.m1.1.1.3.2.cmml"><mi mathsize="90%" id="S7.E15.m1.1.1.3.2.2" xref="S7.E15.m1.1.1.3.2.2.cmml">N</mi><mi mathsize="90%" id="S7.E15.m1.1.1.3.2.3" xref="S7.E15.m1.1.1.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S7.E15.m1.1.1.3.1" xref="S7.E15.m1.1.1.3.1.cmml">⋅</mo><mi mathsize="90%" id="S7.E15.m1.1.1.3.3" xref="S7.E15.m1.1.1.3.3.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E15.m1.1b"><apply id="S7.E15.m1.1.1.cmml" xref="S7.E15.m1.1.1"><eq id="S7.E15.m1.1.1.1.cmml" xref="S7.E15.m1.1.1.1"></eq><apply id="S7.E15.m1.1.1.2.cmml" xref="S7.E15.m1.1.1.2"><csymbol cd="ambiguous" id="S7.E15.m1.1.1.2.1.cmml" xref="S7.E15.m1.1.1.2">subscript</csymbol><ci id="S7.E15.m1.1.1.2.2.cmml" xref="S7.E15.m1.1.1.2.2">𝑂</ci><ci id="S7.E15.m1.1.1.2.3.cmml" xref="S7.E15.m1.1.1.2.3">𝑣</ci></apply><apply id="S7.E15.m1.1.1.3.cmml" xref="S7.E15.m1.1.1.3"><ci id="S7.E15.m1.1.1.3.1.cmml" xref="S7.E15.m1.1.1.3.1">⋅</ci><apply id="S7.E15.m1.1.1.3.2.cmml" xref="S7.E15.m1.1.1.3.2"><csymbol cd="ambiguous" id="S7.E15.m1.1.1.3.2.1.cmml" xref="S7.E15.m1.1.1.3.2">subscript</csymbol><ci id="S7.E15.m1.1.1.3.2.2.cmml" xref="S7.E15.m1.1.1.3.2.2">𝑁</ci><ci id="S7.E15.m1.1.1.3.2.3.cmml" xref="S7.E15.m1.1.1.3.2.3">𝑣</ci></apply><ci id="S7.E15.m1.1.1.3.3.cmml" xref="S7.E15.m1.1.1.3.3">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E15.m1.1c">O_{v}=N_{v}\cdot V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(15)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.I2.i2.p5" class="ltx_para">
<table id="S7.E16" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E16.m1.1" class="ltx_Math" alttext="A_{v}=O_{v}\odot V" display="block"><semantics id="S7.E16.m1.1a"><mrow id="S7.E16.m1.1.1" xref="S7.E16.m1.1.1.cmml"><msub id="S7.E16.m1.1.1.2" xref="S7.E16.m1.1.1.2.cmml"><mi mathsize="90%" id="S7.E16.m1.1.1.2.2" xref="S7.E16.m1.1.1.2.2.cmml">A</mi><mi mathsize="90%" id="S7.E16.m1.1.1.2.3" xref="S7.E16.m1.1.1.2.3.cmml">v</mi></msub><mo mathsize="90%" id="S7.E16.m1.1.1.1" xref="S7.E16.m1.1.1.1.cmml">=</mo><mrow id="S7.E16.m1.1.1.3" xref="S7.E16.m1.1.1.3.cmml"><msub id="S7.E16.m1.1.1.3.2" xref="S7.E16.m1.1.1.3.2.cmml"><mi mathsize="90%" id="S7.E16.m1.1.1.3.2.2" xref="S7.E16.m1.1.1.3.2.2.cmml">O</mi><mi mathsize="90%" id="S7.E16.m1.1.1.3.2.3" xref="S7.E16.m1.1.1.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" mathsize="90%" rspace="0.222em" id="S7.E16.m1.1.1.3.1" xref="S7.E16.m1.1.1.3.1.cmml">⊙</mo><mi mathsize="90%" id="S7.E16.m1.1.1.3.3" xref="S7.E16.m1.1.1.3.3.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E16.m1.1b"><apply id="S7.E16.m1.1.1.cmml" xref="S7.E16.m1.1.1"><eq id="S7.E16.m1.1.1.1.cmml" xref="S7.E16.m1.1.1.1"></eq><apply id="S7.E16.m1.1.1.2.cmml" xref="S7.E16.m1.1.1.2"><csymbol cd="ambiguous" id="S7.E16.m1.1.1.2.1.cmml" xref="S7.E16.m1.1.1.2">subscript</csymbol><ci id="S7.E16.m1.1.1.2.2.cmml" xref="S7.E16.m1.1.1.2.2">𝐴</ci><ci id="S7.E16.m1.1.1.2.3.cmml" xref="S7.E16.m1.1.1.2.3">𝑣</ci></apply><apply id="S7.E16.m1.1.1.3.cmml" xref="S7.E16.m1.1.1.3"><csymbol cd="latexml" id="S7.E16.m1.1.1.3.1.cmml" xref="S7.E16.m1.1.1.3.1">direct-product</csymbol><apply id="S7.E16.m1.1.1.3.2.cmml" xref="S7.E16.m1.1.1.3.2"><csymbol cd="ambiguous" id="S7.E16.m1.1.1.3.2.1.cmml" xref="S7.E16.m1.1.1.3.2">subscript</csymbol><ci id="S7.E16.m1.1.1.3.2.2.cmml" xref="S7.E16.m1.1.1.3.2.2">𝑂</ci><ci id="S7.E16.m1.1.1.3.2.3.cmml" xref="S7.E16.m1.1.1.3.2.3">𝑣</ci></apply><ci id="S7.E16.m1.1.1.3.3.cmml" xref="S7.E16.m1.1.1.3.3">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E16.m1.1c">A_{v}=O_{v}\odot V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(16)</span></td>
</tr></tbody>
</table>
<p id="S7.I2.i2.p5.5" class="ltx_p"><span id="S7.I2.i2.p5.5.1" class="ltx_text" style="font-size:90%;">The attention matrix </span><math id="S7.I2.i2.p5.1.m1.1" class="ltx_Math" alttext="A_{p}" display="inline"><semantics id="S7.I2.i2.p5.1.m1.1a"><msub id="S7.I2.i2.p5.1.m1.1.1" xref="S7.I2.i2.p5.1.m1.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p5.1.m1.1.1.2" xref="S7.I2.i2.p5.1.m1.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i2.p5.1.m1.1.1.3" xref="S7.I2.i2.p5.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p5.1.m1.1b"><apply id="S7.I2.i2.p5.1.m1.1.1.cmml" xref="S7.I2.i2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p5.1.m1.1.1.1.cmml" xref="S7.I2.i2.p5.1.m1.1.1">subscript</csymbol><ci id="S7.I2.i2.p5.1.m1.1.1.2.cmml" xref="S7.I2.i2.p5.1.m1.1.1.2">𝐴</ci><ci id="S7.I2.i2.p5.1.m1.1.1.3.cmml" xref="S7.I2.i2.p5.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p5.1.m1.1c">A_{p}</annotation></semantics></math><span id="S7.I2.i2.p5.5.2" class="ltx_text" style="font-size:90%;"> is computed for </span><math id="S7.I2.i2.p5.2.m2.4" class="ltx_Math" alttext="p=1^{\text{st}},2^{\text{nd}},\ldots,u^{\text{th}}" display="inline"><semantics id="S7.I2.i2.p5.2.m2.4a"><mrow id="S7.I2.i2.p5.2.m2.4.4" xref="S7.I2.i2.p5.2.m2.4.4.cmml"><mi mathsize="90%" id="S7.I2.i2.p5.2.m2.4.4.5" xref="S7.I2.i2.p5.2.m2.4.4.5.cmml">p</mi><mo mathsize="90%" id="S7.I2.i2.p5.2.m2.4.4.4" xref="S7.I2.i2.p5.2.m2.4.4.4.cmml">=</mo><mrow id="S7.I2.i2.p5.2.m2.4.4.3.3" xref="S7.I2.i2.p5.2.m2.4.4.3.4.cmml"><msup id="S7.I2.i2.p5.2.m2.2.2.1.1.1" xref="S7.I2.i2.p5.2.m2.2.2.1.1.1.cmml"><mn mathsize="90%" id="S7.I2.i2.p5.2.m2.2.2.1.1.1.2" xref="S7.I2.i2.p5.2.m2.2.2.1.1.1.2.cmml">1</mn><mtext mathsize="90%" id="S7.I2.i2.p5.2.m2.2.2.1.1.1.3" xref="S7.I2.i2.p5.2.m2.2.2.1.1.1.3a.cmml">st</mtext></msup><mo mathsize="90%" id="S7.I2.i2.p5.2.m2.4.4.3.3.4" xref="S7.I2.i2.p5.2.m2.4.4.3.4.cmml">,</mo><msup id="S7.I2.i2.p5.2.m2.3.3.2.2.2" xref="S7.I2.i2.p5.2.m2.3.3.2.2.2.cmml"><mn mathsize="90%" id="S7.I2.i2.p5.2.m2.3.3.2.2.2.2" xref="S7.I2.i2.p5.2.m2.3.3.2.2.2.2.cmml">2</mn><mtext mathsize="90%" id="S7.I2.i2.p5.2.m2.3.3.2.2.2.3" xref="S7.I2.i2.p5.2.m2.3.3.2.2.2.3a.cmml">nd</mtext></msup><mo mathsize="90%" id="S7.I2.i2.p5.2.m2.4.4.3.3.5" xref="S7.I2.i2.p5.2.m2.4.4.3.4.cmml">,</mo><mi mathsize="90%" mathvariant="normal" id="S7.I2.i2.p5.2.m2.1.1" xref="S7.I2.i2.p5.2.m2.1.1.cmml">…</mi><mo mathsize="90%" id="S7.I2.i2.p5.2.m2.4.4.3.3.6" xref="S7.I2.i2.p5.2.m2.4.4.3.4.cmml">,</mo><msup id="S7.I2.i2.p5.2.m2.4.4.3.3.3" xref="S7.I2.i2.p5.2.m2.4.4.3.3.3.cmml"><mi mathsize="90%" id="S7.I2.i2.p5.2.m2.4.4.3.3.3.2" xref="S7.I2.i2.p5.2.m2.4.4.3.3.3.2.cmml">u</mi><mtext mathsize="90%" id="S7.I2.i2.p5.2.m2.4.4.3.3.3.3" xref="S7.I2.i2.p5.2.m2.4.4.3.3.3.3a.cmml">th</mtext></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p5.2.m2.4b"><apply id="S7.I2.i2.p5.2.m2.4.4.cmml" xref="S7.I2.i2.p5.2.m2.4.4"><eq id="S7.I2.i2.p5.2.m2.4.4.4.cmml" xref="S7.I2.i2.p5.2.m2.4.4.4"></eq><ci id="S7.I2.i2.p5.2.m2.4.4.5.cmml" xref="S7.I2.i2.p5.2.m2.4.4.5">𝑝</ci><list id="S7.I2.i2.p5.2.m2.4.4.3.4.cmml" xref="S7.I2.i2.p5.2.m2.4.4.3.3"><apply id="S7.I2.i2.p5.2.m2.2.2.1.1.1.cmml" xref="S7.I2.i2.p5.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p5.2.m2.2.2.1.1.1.1.cmml" xref="S7.I2.i2.p5.2.m2.2.2.1.1.1">superscript</csymbol><cn type="integer" id="S7.I2.i2.p5.2.m2.2.2.1.1.1.2.cmml" xref="S7.I2.i2.p5.2.m2.2.2.1.1.1.2">1</cn><ci id="S7.I2.i2.p5.2.m2.2.2.1.1.1.3a.cmml" xref="S7.I2.i2.p5.2.m2.2.2.1.1.1.3"><mtext mathsize="63%" id="S7.I2.i2.p5.2.m2.2.2.1.1.1.3.cmml" xref="S7.I2.i2.p5.2.m2.2.2.1.1.1.3">st</mtext></ci></apply><apply id="S7.I2.i2.p5.2.m2.3.3.2.2.2.cmml" xref="S7.I2.i2.p5.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S7.I2.i2.p5.2.m2.3.3.2.2.2.1.cmml" xref="S7.I2.i2.p5.2.m2.3.3.2.2.2">superscript</csymbol><cn type="integer" id="S7.I2.i2.p5.2.m2.3.3.2.2.2.2.cmml" xref="S7.I2.i2.p5.2.m2.3.3.2.2.2.2">2</cn><ci id="S7.I2.i2.p5.2.m2.3.3.2.2.2.3a.cmml" xref="S7.I2.i2.p5.2.m2.3.3.2.2.2.3"><mtext mathsize="63%" id="S7.I2.i2.p5.2.m2.3.3.2.2.2.3.cmml" xref="S7.I2.i2.p5.2.m2.3.3.2.2.2.3">nd</mtext></ci></apply><ci id="S7.I2.i2.p5.2.m2.1.1.cmml" xref="S7.I2.i2.p5.2.m2.1.1">…</ci><apply id="S7.I2.i2.p5.2.m2.4.4.3.3.3.cmml" xref="S7.I2.i2.p5.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S7.I2.i2.p5.2.m2.4.4.3.3.3.1.cmml" xref="S7.I2.i2.p5.2.m2.4.4.3.3.3">superscript</csymbol><ci id="S7.I2.i2.p5.2.m2.4.4.3.3.3.2.cmml" xref="S7.I2.i2.p5.2.m2.4.4.3.3.3.2">𝑢</ci><ci id="S7.I2.i2.p5.2.m2.4.4.3.3.3.3a.cmml" xref="S7.I2.i2.p5.2.m2.4.4.3.3.3.3"><mtext mathsize="63%" id="S7.I2.i2.p5.2.m2.4.4.3.3.3.3.cmml" xref="S7.I2.i2.p5.2.m2.4.4.3.3.3.3">th</mtext></ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p5.2.m2.4c">p=1^{\text{st}},2^{\text{nd}},\ldots,u^{\text{th}}</annotation></semantics></math><span id="S7.I2.i2.p5.5.3" class="ltx_text" style="font-size:90%;"> sequences. Finally, for each sequence </span><math id="S7.I2.i2.p5.3.m3.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S7.I2.i2.p5.3.m3.1a"><mi mathsize="90%" id="S7.I2.i2.p5.3.m3.1.1" xref="S7.I2.i2.p5.3.m3.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p5.3.m3.1b"><ci id="S7.I2.i2.p5.3.m3.1.1.cmml" xref="S7.I2.i2.p5.3.m3.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p5.3.m3.1c">u</annotation></semantics></math><span id="S7.I2.i2.p5.5.4" class="ltx_text" style="font-size:90%;">, </span><math id="S7.I2.i2.p5.4.m4.1" class="ltx_Math" alttext="A_{p}" display="inline"><semantics id="S7.I2.i2.p5.4.m4.1a"><msub id="S7.I2.i2.p5.4.m4.1.1" xref="S7.I2.i2.p5.4.m4.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p5.4.m4.1.1.2" xref="S7.I2.i2.p5.4.m4.1.1.2.cmml">A</mi><mi mathsize="90%" id="S7.I2.i2.p5.4.m4.1.1.3" xref="S7.I2.i2.p5.4.m4.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p5.4.m4.1b"><apply id="S7.I2.i2.p5.4.m4.1.1.cmml" xref="S7.I2.i2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p5.4.m4.1.1.1.cmml" xref="S7.I2.i2.p5.4.m4.1.1">subscript</csymbol><ci id="S7.I2.i2.p5.4.m4.1.1.2.cmml" xref="S7.I2.i2.p5.4.m4.1.1.2">𝐴</ci><ci id="S7.I2.i2.p5.4.m4.1.1.3.cmml" xref="S7.I2.i2.p5.4.m4.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p5.4.m4.1c">A_{p}</annotation></semantics></math><span id="S7.I2.i2.p5.5.5" class="ltx_text" style="font-size:90%;">, and </span><math id="S7.I2.i2.p5.5.m5.1" class="ltx_Math" alttext="X_{p}" display="inline"><semantics id="S7.I2.i2.p5.5.m5.1a"><msub id="S7.I2.i2.p5.5.m5.1.1" xref="S7.I2.i2.p5.5.m5.1.1.cmml"><mi mathsize="90%" id="S7.I2.i2.p5.5.m5.1.1.2" xref="S7.I2.i2.p5.5.m5.1.1.2.cmml">X</mi><mi mathsize="90%" id="S7.I2.i2.p5.5.m5.1.1.3" xref="S7.I2.i2.p5.5.m5.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S7.I2.i2.p5.5.m5.1b"><apply id="S7.I2.i2.p5.5.m5.1.1.cmml" xref="S7.I2.i2.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S7.I2.i2.p5.5.m5.1.1.1.cmml" xref="S7.I2.i2.p5.5.m5.1.1">subscript</csymbol><ci id="S7.I2.i2.p5.5.m5.1.1.2.cmml" xref="S7.I2.i2.p5.5.m5.1.1.2">𝑋</ci><ci id="S7.I2.i2.p5.5.m5.1.1.3.cmml" xref="S7.I2.i2.p5.5.m5.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.I2.i2.p5.5.m5.1c">X_{p}</annotation></semantics></math><span id="S7.I2.i2.p5.5.6" class="ltx_text" style="font-size:90%;"> are concatenated and passed to the output layer with softmax activation for classification.</span></p>
</div>
</li>
</ul>
</div>
<div id="S7.SS2.p2" class="ltx_para ltx_noindent">
<p id="S7.SS2.p2.1" class="ltx_p"><span id="S7.SS2.p2.1.1" class="ltx_text" style="font-size:90%;">Further, Figure </span><a href="#S7.F3" title="Figure 3 ‣ 7 Supplementary Material ‣ Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">3</span></a><span id="S7.SS2.p2.1.2" class="ltx_text" style="font-size:90%;"> provides further details on the attention computation for our model MMMS-BA discussed in Section </span><math id="S7.SS2.p2.1.m1.1" class="ltx_Math" alttext="3.2" display="inline"><semantics id="S7.SS2.p2.1.m1.1a"><mn mathsize="90%" id="S7.SS2.p2.1.m1.1.1" xref="S7.SS2.p2.1.m1.1.1.cmml">3.2</mn><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.1.m1.1b"><cn type="float" id="S7.SS2.p2.1.m1.1.1.cmml" xref="S7.SS2.p2.1.m1.1.1">3.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.1.m1.1c">3.2</annotation></semantics></math><span id="S7.SS2.p2.1.3" class="ltx_text" style="font-size:90%;"> of the main paper.</span></p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.01531" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.01532" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.01532">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.01532" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.01533" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 15:07:10 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
