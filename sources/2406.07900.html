<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.07900] Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations</title><meta property="og:description" content="Recent advancements in Deep and Self-Supervised Learning (SSL) have led to substantial improvements in Speech Emotion Recognition (SER) performance, reaching unprecedented levels. However, obtaining sufficient amounts â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.07900">

<!--Generated on Fri Jul  5 17:51:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.3" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.4" class="ltx_ERROR undefined">\name</span>
<p id="p1.2" class="ltx_p">[]BulatKhaertdinov<sup id="p1.2.1" class="ltx_sup">âˆ—</sup>
<span id="p1.2.2" class="ltx_ERROR undefined">\name</span>[]PedroJeuris<sup id="p1.2.3" class="ltx_sup">âˆ—</sup>
<span id="p1.2.4" class="ltx_ERROR undefined">\name</span>[]AnnandaSousa
<span id="p1.2.5" class="ltx_ERROR undefined">\name</span>[]EnriqueHortal




</p>
</div>
<h1 class="ltx_title ltx_title_document">Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Recent advancements in Deep and Self-Supervised Learning (SSL) have led to substantial improvements in Speech Emotion Recognition (SER) performance, reaching unprecedented levels. However, obtaining sufficient amounts of accurately labeled data for training or fine-tuning the models remains a costly and challenging task. In this paper, we propose a multi-view SSL pre-training technique that can be applied to various representations of speech, including the ones generated by large speech models, to improve SER performance in scenarios where annotations are limited. Our experiments, based on wav2vec 2.0, spectral and paralinguistic features, demonstrate that the proposed framework boosts the SER performance, by up to 10% in Unweighted Average Recall, in settings with extremely sparse data annotations.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>speech emotion recognition, self-supervised learning, contrastive learning, sparse annotations
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>Authors contributed equally to this work</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Emotion recognition is a crucial task of Affective Computing that gained a significant amount of research attention in the last decades. Speech serves as a key marker for effective emotion recognition, encompassing diverse acoustic, prosodic, and other voice-related information and accounting for inter-speaker differences <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. During the last ten years, Speech Emotion Recognition (SER) algorithms have been significantly improved due to the rapid development of Deep Learning architectures. The earlier methods of the decade were based on the end-to-end supervised Deep Learning models exploiting prosodic or spectral features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, or raw audio waveforms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. In the last couple of years, the research focus has been shifting towards exploiting Transformer-based large speech models, such as wav2vec 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, WavLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, and HuBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, pre-trained via Self-Supervised Learning frameworks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">One of the key challenges always associated with emotion recognition is collecting data with trustworthy annotations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Furthermore, emotion recognition systems could be deployed in various scenarios requiring data collection in natural settings and utilizing specific emotional models that are not covered in open access data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. In this case, acquiring a dataset even with hundreds of samples containing effectively elicited emotions and accurate annotations is an extremely challenging and time-consuming process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Deep learning models trained from scratch typically require large amounts of accurately annotated data to achieve satisfactory performance, whereas large pre-trained models can be fine-tuned with less, but still significant, amounts of annotated data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, motivated by these challenges, we introduce multi-view contrastive SSL pre-training that can be applied on top of various audio features (views), including paralinguistic cues, spectral representations, and features extracted by large speech models pre-trained on ASR datasets. The contributions of this work can be summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">The introduced framework, denoted as Pairwise-CL, aims to pre-train encoders on multiple speech views for further fine-tuning with sparsely annotated data. Pre-training is based on contrastive SSL loss computed between representations of speech views in a pairwise fashion. Specifically, the encoders from the selected views aim to align representations of each utterance in the projected latent space.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">The proposed framework can be adapted to any combination and number of views. The experiments in this paper were conducted on three types of views, namely wav2vec 2.0 features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, mel spectrograms and eGeMAPS-88 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We analyze the representations learnt from each view and quantify their alignment using projection-weighted Canonical Correlation Analysis (PWCCA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Pairwise-CL: Multi-view Contrastive Learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In the last years, contrastive Self-Supervised Learning has shown promising results in multi-modal and multi-view pre-training in different domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. The main idea lies in maximizing similarities between different representations of the same instance in a projected latent space while contrasting them to other instances. The pre-training strategy introduced in this paper is inspired by Contrastive Multiview Coding (CMC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> suggested for multi-view image representation learning. Namely, we propose using normalized temperature-scaled cross-entropy loss (NT-Xent) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> in between pairs of view-level representations corresponding to different audio features. We denote the proposed framework as Pairwise-CL.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.11" class="ltx_p">Formally, assume there is a mini-batch of size <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">N</annotation></semantics></math> with features from <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">K</annotation></semantics></math> views <math id="S2.SS1.p2.3.m3.4" class="ltx_Math" alttext="\{f_{1}(\bm{x}_{l}^{1}),f_{2}(\bm{x}_{l}^{2}),\dots,f_{K}(\bm{x}_{l}^{K})\}_{l=1}^{N}" display="inline"><semantics id="S2.SS1.p2.3.m3.4a"><msubsup id="S2.SS1.p2.3.m3.4.4" xref="S2.SS1.p2.3.m3.4.4.cmml"><mrow id="S2.SS1.p2.3.m3.4.4.3.3.3" xref="S2.SS1.p2.3.m3.4.4.3.3.4.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.4.4.3.3.3.4" xref="S2.SS1.p2.3.m3.4.4.3.3.4.cmml">{</mo><mrow id="S2.SS1.p2.3.m3.2.2.1.1.1.1" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.cmml"><msub id="S2.SS1.p2.3.m3.2.2.1.1.1.1.3" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.cmml"><mi id="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.2" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.2.cmml">f</mi><mn id="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.3" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p2.3.m3.2.2.1.1.1.1.2" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.2" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.2" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.2.cmml">ğ’™</mi><mi id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.3" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.3.cmml">l</mi><mn id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.3" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.3.cmml">1</mn></msubsup><mo stretchy="false" id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.3" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p2.3.m3.4.4.3.3.3.5" xref="S2.SS1.p2.3.m3.4.4.3.3.4.cmml">,</mo><mrow id="S2.SS1.p2.3.m3.3.3.2.2.2.2" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.cmml"><msub id="S2.SS1.p2.3.m3.3.3.2.2.2.2.3" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.cmml"><mi id="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.2" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.2.cmml">f</mi><mn id="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.3" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p2.3.m3.3.3.2.2.2.2.2" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.2.cmml">â€‹</mo><mrow id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.2" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.cmml">(</mo><msubsup id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.cmml"><mi id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.2" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.2.cmml">ğ’™</mi><mi id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.3" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.3.cmml">l</mi><mn id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.3" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.3.cmml">2</mn></msubsup><mo stretchy="false" id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.3" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p2.3.m3.4.4.3.3.3.6" xref="S2.SS1.p2.3.m3.4.4.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">â€¦</mi><mo id="S2.SS1.p2.3.m3.4.4.3.3.3.7" xref="S2.SS1.p2.3.m3.4.4.3.3.4.cmml">,</mo><mrow id="S2.SS1.p2.3.m3.4.4.3.3.3.3" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.cmml"><msub id="S2.SS1.p2.3.m3.4.4.3.3.3.3.3" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.cmml"><mi id="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.2" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.2.cmml">f</mi><mi id="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.3" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.3.cmml">K</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p2.3.m3.4.4.3.3.3.3.2" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.2.cmml">â€‹</mo><mrow id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.2" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.cmml">(</mo><msubsup id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.cmml"><mi id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.2" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.2.cmml">ğ’™</mi><mi id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.3" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.3.cmml">l</mi><mi id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.3" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.3.cmml">K</mi></msubsup><mo stretchy="false" id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.3" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.SS1.p2.3.m3.4.4.3.3.3.8" xref="S2.SS1.p2.3.m3.4.4.3.3.4.cmml">}</mo></mrow><mrow id="S2.SS1.p2.3.m3.4.4.3.5" xref="S2.SS1.p2.3.m3.4.4.3.5.cmml"><mi id="S2.SS1.p2.3.m3.4.4.3.5.2" xref="S2.SS1.p2.3.m3.4.4.3.5.2.cmml">l</mi><mo id="S2.SS1.p2.3.m3.4.4.3.5.1" xref="S2.SS1.p2.3.m3.4.4.3.5.1.cmml">=</mo><mn id="S2.SS1.p2.3.m3.4.4.3.5.3" xref="S2.SS1.p2.3.m3.4.4.3.5.3.cmml">1</mn></mrow><mi id="S2.SS1.p2.3.m3.4.4.5" xref="S2.SS1.p2.3.m3.4.4.5.cmml">N</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.4b"><apply id="S2.SS1.p2.3.m3.4.4.cmml" xref="S2.SS1.p2.3.m3.4.4"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.4.4.4.cmml" xref="S2.SS1.p2.3.m3.4.4">superscript</csymbol><apply id="S2.SS1.p2.3.m3.4.4.3.cmml" xref="S2.SS1.p2.3.m3.4.4"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.4.4.3.4.cmml" xref="S2.SS1.p2.3.m3.4.4">subscript</csymbol><set id="S2.SS1.p2.3.m3.4.4.3.3.4.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3"><apply id="S2.SS1.p2.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1"><times id="S2.SS1.p2.3.m3.2.2.1.1.1.1.2.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.2"></times><apply id="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.1.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.2.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.2">ğ‘“</ci><cn type="integer" id="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.3.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.3.3">1</cn></apply><apply id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1">superscript</csymbol><apply id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.2">ğ’™</ci><ci id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.2.3">ğ‘™</ci></apply><cn type="integer" id="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.3.m3.2.2.1.1.1.1.1.1.1.3">1</cn></apply></apply><apply id="S2.SS1.p2.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2"><times id="S2.SS1.p2.3.m3.3.3.2.2.2.2.2.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.2"></times><apply id="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.1.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.3">subscript</csymbol><ci id="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.2.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.2">ğ‘“</ci><cn type="integer" id="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.3.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.3.3">2</cn></apply><apply id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1">superscript</csymbol><apply id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.1.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1">subscript</csymbol><ci id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.2.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.2">ğ’™</ci><ci id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.3.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.2.3">ğ‘™</ci></apply><cn type="integer" id="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.3.cmml" xref="S2.SS1.p2.3.m3.3.3.2.2.2.2.1.1.1.3">2</cn></apply></apply><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">â€¦</ci><apply id="S2.SS1.p2.3.m3.4.4.3.3.3.3.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3"><times id="S2.SS1.p2.3.m3.4.4.3.3.3.3.2.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.2"></times><apply id="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.1.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.3">subscript</csymbol><ci id="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.2.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.2">ğ‘“</ci><ci id="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.3.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.3.3">ğ¾</ci></apply><apply id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.1.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1">superscript</csymbol><apply id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.1.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1">subscript</csymbol><ci id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.2.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.2">ğ’™</ci><ci id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.3.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.3.cmml" xref="S2.SS1.p2.3.m3.4.4.3.3.3.3.1.1.1.3">ğ¾</ci></apply></apply></set><apply id="S2.SS1.p2.3.m3.4.4.3.5.cmml" xref="S2.SS1.p2.3.m3.4.4.3.5"><eq id="S2.SS1.p2.3.m3.4.4.3.5.1.cmml" xref="S2.SS1.p2.3.m3.4.4.3.5.1"></eq><ci id="S2.SS1.p2.3.m3.4.4.3.5.2.cmml" xref="S2.SS1.p2.3.m3.4.4.3.5.2">ğ‘™</ci><cn type="integer" id="S2.SS1.p2.3.m3.4.4.3.5.3.cmml" xref="S2.SS1.p2.3.m3.4.4.3.5.3">1</cn></apply></apply><ci id="S2.SS1.p2.3.m3.4.4.5.cmml" xref="S2.SS1.p2.3.m3.4.4.5">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.4c">\{f_{1}(\bm{x}_{l}^{1}),f_{2}(\bm{x}_{l}^{2}),\dots,f_{K}(\bm{x}_{l}^{K})\}_{l=1}^{N}</annotation></semantics></math> where <math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="f_{i}(\cdot):\mathcal{X}_{i}\rightarrow\Phi_{i}\subset\mathbb{R}^{d_{i}}" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mrow id="S2.SS1.p2.4.m4.1.2" xref="S2.SS1.p2.4.m4.1.2.cmml"><mrow id="S2.SS1.p2.4.m4.1.2.2" xref="S2.SS1.p2.4.m4.1.2.2.cmml"><msub id="S2.SS1.p2.4.m4.1.2.2.2" xref="S2.SS1.p2.4.m4.1.2.2.2.cmml"><mi id="S2.SS1.p2.4.m4.1.2.2.2.2" xref="S2.SS1.p2.4.m4.1.2.2.2.2.cmml">f</mi><mi id="S2.SS1.p2.4.m4.1.2.2.2.3" xref="S2.SS1.p2.4.m4.1.2.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p2.4.m4.1.2.2.1" xref="S2.SS1.p2.4.m4.1.2.2.1.cmml">â€‹</mo><mrow id="S2.SS1.p2.4.m4.1.2.2.3.2" xref="S2.SS1.p2.4.m4.1.2.2.cmml"><mo stretchy="false" id="S2.SS1.p2.4.m4.1.2.2.3.2.1" xref="S2.SS1.p2.4.m4.1.2.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml">â‹…</mo><mo rspace="0.278em" stretchy="false" id="S2.SS1.p2.4.m4.1.2.2.3.2.2" xref="S2.SS1.p2.4.m4.1.2.2.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S2.SS1.p2.4.m4.1.2.1" xref="S2.SS1.p2.4.m4.1.2.1.cmml">:</mo><mrow id="S2.SS1.p2.4.m4.1.2.3" xref="S2.SS1.p2.4.m4.1.2.3.cmml"><msub id="S2.SS1.p2.4.m4.1.2.3.2" xref="S2.SS1.p2.4.m4.1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.4.m4.1.2.3.2.2" xref="S2.SS1.p2.4.m4.1.2.3.2.2.cmml">ğ’³</mi><mi id="S2.SS1.p2.4.m4.1.2.3.2.3" xref="S2.SS1.p2.4.m4.1.2.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S2.SS1.p2.4.m4.1.2.3.3" xref="S2.SS1.p2.4.m4.1.2.3.3.cmml">â†’</mo><msub id="S2.SS1.p2.4.m4.1.2.3.4" xref="S2.SS1.p2.4.m4.1.2.3.4.cmml"><mi mathvariant="normal" id="S2.SS1.p2.4.m4.1.2.3.4.2" xref="S2.SS1.p2.4.m4.1.2.3.4.2.cmml">Î¦</mi><mi id="S2.SS1.p2.4.m4.1.2.3.4.3" xref="S2.SS1.p2.4.m4.1.2.3.4.3.cmml">i</mi></msub><mo id="S2.SS1.p2.4.m4.1.2.3.5" xref="S2.SS1.p2.4.m4.1.2.3.5.cmml">âŠ‚</mo><msup id="S2.SS1.p2.4.m4.1.2.3.6" xref="S2.SS1.p2.4.m4.1.2.3.6.cmml"><mi id="S2.SS1.p2.4.m4.1.2.3.6.2" xref="S2.SS1.p2.4.m4.1.2.3.6.2.cmml">â„</mi><msub id="S2.SS1.p2.4.m4.1.2.3.6.3" xref="S2.SS1.p2.4.m4.1.2.3.6.3.cmml"><mi id="S2.SS1.p2.4.m4.1.2.3.6.3.2" xref="S2.SS1.p2.4.m4.1.2.3.6.3.2.cmml">d</mi><mi id="S2.SS1.p2.4.m4.1.2.3.6.3.3" xref="S2.SS1.p2.4.m4.1.2.3.6.3.3.cmml">i</mi></msub></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><apply id="S2.SS1.p2.4.m4.1.2.cmml" xref="S2.SS1.p2.4.m4.1.2"><ci id="S2.SS1.p2.4.m4.1.2.1.cmml" xref="S2.SS1.p2.4.m4.1.2.1">:</ci><apply id="S2.SS1.p2.4.m4.1.2.2.cmml" xref="S2.SS1.p2.4.m4.1.2.2"><times id="S2.SS1.p2.4.m4.1.2.2.1.cmml" xref="S2.SS1.p2.4.m4.1.2.2.1"></times><apply id="S2.SS1.p2.4.m4.1.2.2.2.cmml" xref="S2.SS1.p2.4.m4.1.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.2.2.2.1.cmml" xref="S2.SS1.p2.4.m4.1.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.2.2.2.2.cmml" xref="S2.SS1.p2.4.m4.1.2.2.2.2">ğ‘“</ci><ci id="S2.SS1.p2.4.m4.1.2.2.2.3.cmml" xref="S2.SS1.p2.4.m4.1.2.2.2.3">ğ‘–</ci></apply><ci id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1">â‹…</ci></apply><apply id="S2.SS1.p2.4.m4.1.2.3.cmml" xref="S2.SS1.p2.4.m4.1.2.3"><and id="S2.SS1.p2.4.m4.1.2.3a.cmml" xref="S2.SS1.p2.4.m4.1.2.3"></and><apply id="S2.SS1.p2.4.m4.1.2.3b.cmml" xref="S2.SS1.p2.4.m4.1.2.3"><ci id="S2.SS1.p2.4.m4.1.2.3.3.cmml" xref="S2.SS1.p2.4.m4.1.2.3.3">â†’</ci><apply id="S2.SS1.p2.4.m4.1.2.3.2.cmml" xref="S2.SS1.p2.4.m4.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.2.3.2.1.cmml" xref="S2.SS1.p2.4.m4.1.2.3.2">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.2.3.2.2.cmml" xref="S2.SS1.p2.4.m4.1.2.3.2.2">ğ’³</ci><ci id="S2.SS1.p2.4.m4.1.2.3.2.3.cmml" xref="S2.SS1.p2.4.m4.1.2.3.2.3">ğ‘–</ci></apply><apply id="S2.SS1.p2.4.m4.1.2.3.4.cmml" xref="S2.SS1.p2.4.m4.1.2.3.4"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.2.3.4.1.cmml" xref="S2.SS1.p2.4.m4.1.2.3.4">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.2.3.4.2.cmml" xref="S2.SS1.p2.4.m4.1.2.3.4.2">Î¦</ci><ci id="S2.SS1.p2.4.m4.1.2.3.4.3.cmml" xref="S2.SS1.p2.4.m4.1.2.3.4.3">ğ‘–</ci></apply></apply><apply id="S2.SS1.p2.4.m4.1.2.3c.cmml" xref="S2.SS1.p2.4.m4.1.2.3"><subset id="S2.SS1.p2.4.m4.1.2.3.5.cmml" xref="S2.SS1.p2.4.m4.1.2.3.5"></subset><share href="#S2.SS1.p2.4.m4.1.2.3.4.cmml" id="S2.SS1.p2.4.m4.1.2.3d.cmml" xref="S2.SS1.p2.4.m4.1.2.3"></share><apply id="S2.SS1.p2.4.m4.1.2.3.6.cmml" xref="S2.SS1.p2.4.m4.1.2.3.6"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.2.3.6.1.cmml" xref="S2.SS1.p2.4.m4.1.2.3.6">superscript</csymbol><ci id="S2.SS1.p2.4.m4.1.2.3.6.2.cmml" xref="S2.SS1.p2.4.m4.1.2.3.6.2">â„</ci><apply id="S2.SS1.p2.4.m4.1.2.3.6.3.cmml" xref="S2.SS1.p2.4.m4.1.2.3.6.3"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.2.3.6.3.1.cmml" xref="S2.SS1.p2.4.m4.1.2.3.6.3">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.2.3.6.3.2.cmml" xref="S2.SS1.p2.4.m4.1.2.3.6.3.2">ğ‘‘</ci><ci id="S2.SS1.p2.4.m4.1.2.3.6.3.3.cmml" xref="S2.SS1.p2.4.m4.1.2.3.6.3.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">f_{i}(\cdot):\mathcal{X}_{i}\rightarrow\Phi_{i}\subset\mathbb{R}^{d_{i}}</annotation></semantics></math> is a view-level encoder mapping inputs <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="\bm{x}_{l}^{i}\in\mathcal{X}_{i}" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><mrow id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml"><msubsup id="S2.SS1.p2.5.m5.1.1.2" xref="S2.SS1.p2.5.m5.1.1.2.cmml"><mi id="S2.SS1.p2.5.m5.1.1.2.2.2" xref="S2.SS1.p2.5.m5.1.1.2.2.2.cmml">ğ’™</mi><mi id="S2.SS1.p2.5.m5.1.1.2.2.3" xref="S2.SS1.p2.5.m5.1.1.2.2.3.cmml">l</mi><mi id="S2.SS1.p2.5.m5.1.1.2.3" xref="S2.SS1.p2.5.m5.1.1.2.3.cmml">i</mi></msubsup><mo id="S2.SS1.p2.5.m5.1.1.1" xref="S2.SS1.p2.5.m5.1.1.1.cmml">âˆˆ</mo><msub id="S2.SS1.p2.5.m5.1.1.3" xref="S2.SS1.p2.5.m5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p2.5.m5.1.1.3.2" xref="S2.SS1.p2.5.m5.1.1.3.2.cmml">ğ’³</mi><mi id="S2.SS1.p2.5.m5.1.1.3.3" xref="S2.SS1.p2.5.m5.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1"><in id="S2.SS1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1.1"></in><apply id="S2.SS1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.2.1.cmml" xref="S2.SS1.p2.5.m5.1.1.2">superscript</csymbol><apply id="S2.SS1.p2.5.m5.1.1.2.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.2.2.1.cmml" xref="S2.SS1.p2.5.m5.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.5.m5.1.1.2.2.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2.2.2">ğ’™</ci><ci id="S2.SS1.p2.5.m5.1.1.2.2.3.cmml" xref="S2.SS1.p2.5.m5.1.1.2.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p2.5.m5.1.1.2.3.cmml" xref="S2.SS1.p2.5.m5.1.1.2.3">ğ‘–</ci></apply><apply id="S2.SS1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.3.1.cmml" xref="S2.SS1.p2.5.m5.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.5.m5.1.1.3.2.cmml" xref="S2.SS1.p2.5.m5.1.1.3.2">ğ’³</ci><ci id="S2.SS1.p2.5.m5.1.1.3.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">\bm{x}_{l}^{i}\in\mathcal{X}_{i}</annotation></semantics></math> from <math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><mi id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><ci id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">i</annotation></semantics></math>-th view to a vector of size <math id="S2.SS1.p2.7.m7.1" class="ltx_Math" alttext="d_{i}" display="inline"><semantics id="S2.SS1.p2.7.m7.1a"><msub id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml"><mi id="S2.SS1.p2.7.m7.1.1.2" xref="S2.SS1.p2.7.m7.1.1.2.cmml">d</mi><mi id="S2.SS1.p2.7.m7.1.1.3" xref="S2.SS1.p2.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><apply id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m7.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2">ğ‘‘</ci><ci id="S2.SS1.p2.7.m7.1.1.3.cmml" xref="S2.SS1.p2.7.m7.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">d_{i}</annotation></semantics></math>. The view-level representation dimensionality <math id="S2.SS1.p2.8.m8.1" class="ltx_Math" alttext="d_{i}" display="inline"><semantics id="S2.SS1.p2.8.m8.1a"><msub id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml"><mi id="S2.SS1.p2.8.m8.1.1.2" xref="S2.SS1.p2.8.m8.1.1.2.cmml">d</mi><mi id="S2.SS1.p2.8.m8.1.1.3" xref="S2.SS1.p2.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><apply id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.8.m8.1.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.p2.8.m8.1.1.2.cmml" xref="S2.SS1.p2.8.m8.1.1.2">ğ‘‘</ci><ci id="S2.SS1.p2.8.m8.1.1.3.cmml" xref="S2.SS1.p2.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">d_{i}</annotation></semantics></math> is based on the encoder architecture processing the view. Then, the features from each view are mapped to the space where contrastive loss is computed using separate projection networks <math id="S2.SS1.p2.9.m9.1" class="ltx_Math" alttext="g_{i}:\Phi_{i}\rightarrow\Lambda\subset\mathbb{R}^{D}" display="inline"><semantics id="S2.SS1.p2.9.m9.1a"><mrow id="S2.SS1.p2.9.m9.1.1" xref="S2.SS1.p2.9.m9.1.1.cmml"><msub id="S2.SS1.p2.9.m9.1.1.2" xref="S2.SS1.p2.9.m9.1.1.2.cmml"><mi id="S2.SS1.p2.9.m9.1.1.2.2" xref="S2.SS1.p2.9.m9.1.1.2.2.cmml">g</mi><mi id="S2.SS1.p2.9.m9.1.1.2.3" xref="S2.SS1.p2.9.m9.1.1.2.3.cmml">i</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S2.SS1.p2.9.m9.1.1.1" xref="S2.SS1.p2.9.m9.1.1.1.cmml">:</mo><mrow id="S2.SS1.p2.9.m9.1.1.3" xref="S2.SS1.p2.9.m9.1.1.3.cmml"><msub id="S2.SS1.p2.9.m9.1.1.3.2" xref="S2.SS1.p2.9.m9.1.1.3.2.cmml"><mi mathvariant="normal" id="S2.SS1.p2.9.m9.1.1.3.2.2" xref="S2.SS1.p2.9.m9.1.1.3.2.2.cmml">Î¦</mi><mi id="S2.SS1.p2.9.m9.1.1.3.2.3" xref="S2.SS1.p2.9.m9.1.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S2.SS1.p2.9.m9.1.1.3.3" xref="S2.SS1.p2.9.m9.1.1.3.3.cmml">â†’</mo><mi mathvariant="normal" id="S2.SS1.p2.9.m9.1.1.3.4" xref="S2.SS1.p2.9.m9.1.1.3.4.cmml">Î›</mi><mo id="S2.SS1.p2.9.m9.1.1.3.5" xref="S2.SS1.p2.9.m9.1.1.3.5.cmml">âŠ‚</mo><msup id="S2.SS1.p2.9.m9.1.1.3.6" xref="S2.SS1.p2.9.m9.1.1.3.6.cmml"><mi id="S2.SS1.p2.9.m9.1.1.3.6.2" xref="S2.SS1.p2.9.m9.1.1.3.6.2.cmml">â„</mi><mi id="S2.SS1.p2.9.m9.1.1.3.6.3" xref="S2.SS1.p2.9.m9.1.1.3.6.3.cmml">D</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m9.1b"><apply id="S2.SS1.p2.9.m9.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1"><ci id="S2.SS1.p2.9.m9.1.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1.1">:</ci><apply id="S2.SS1.p2.9.m9.1.1.2.cmml" xref="S2.SS1.p2.9.m9.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.1.2.1.cmml" xref="S2.SS1.p2.9.m9.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.9.m9.1.1.2.2.cmml" xref="S2.SS1.p2.9.m9.1.1.2.2">ğ‘”</ci><ci id="S2.SS1.p2.9.m9.1.1.2.3.cmml" xref="S2.SS1.p2.9.m9.1.1.2.3">ğ‘–</ci></apply><apply id="S2.SS1.p2.9.m9.1.1.3.cmml" xref="S2.SS1.p2.9.m9.1.1.3"><and id="S2.SS1.p2.9.m9.1.1.3a.cmml" xref="S2.SS1.p2.9.m9.1.1.3"></and><apply id="S2.SS1.p2.9.m9.1.1.3b.cmml" xref="S2.SS1.p2.9.m9.1.1.3"><ci id="S2.SS1.p2.9.m9.1.1.3.3.cmml" xref="S2.SS1.p2.9.m9.1.1.3.3">â†’</ci><apply id="S2.SS1.p2.9.m9.1.1.3.2.cmml" xref="S2.SS1.p2.9.m9.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.1.3.2.1.cmml" xref="S2.SS1.p2.9.m9.1.1.3.2">subscript</csymbol><ci id="S2.SS1.p2.9.m9.1.1.3.2.2.cmml" xref="S2.SS1.p2.9.m9.1.1.3.2.2">Î¦</ci><ci id="S2.SS1.p2.9.m9.1.1.3.2.3.cmml" xref="S2.SS1.p2.9.m9.1.1.3.2.3">ğ‘–</ci></apply><ci id="S2.SS1.p2.9.m9.1.1.3.4.cmml" xref="S2.SS1.p2.9.m9.1.1.3.4">Î›</ci></apply><apply id="S2.SS1.p2.9.m9.1.1.3c.cmml" xref="S2.SS1.p2.9.m9.1.1.3"><subset id="S2.SS1.p2.9.m9.1.1.3.5.cmml" xref="S2.SS1.p2.9.m9.1.1.3.5"></subset><share href="#S2.SS1.p2.9.m9.1.1.3.4.cmml" id="S2.SS1.p2.9.m9.1.1.3d.cmml" xref="S2.SS1.p2.9.m9.1.1.3"></share><apply id="S2.SS1.p2.9.m9.1.1.3.6.cmml" xref="S2.SS1.p2.9.m9.1.1.3.6"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.1.3.6.1.cmml" xref="S2.SS1.p2.9.m9.1.1.3.6">superscript</csymbol><ci id="S2.SS1.p2.9.m9.1.1.3.6.2.cmml" xref="S2.SS1.p2.9.m9.1.1.3.6.2">â„</ci><ci id="S2.SS1.p2.9.m9.1.1.3.6.3.cmml" xref="S2.SS1.p2.9.m9.1.1.3.6.3">ğ·</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m9.1c">g_{i}:\Phi_{i}\rightarrow\Lambda\subset\mathbb{R}^{D}</annotation></semantics></math>, i.e. <math id="S2.SS1.p2.10.m10.1" class="ltx_Math" alttext="\bm{z}_{l}^{i}=g_{i}(f_{i}(\bm{x}_{l}^{i}))" display="inline"><semantics id="S2.SS1.p2.10.m10.1a"><mrow id="S2.SS1.p2.10.m10.1.1" xref="S2.SS1.p2.10.m10.1.1.cmml"><msubsup id="S2.SS1.p2.10.m10.1.1.3" xref="S2.SS1.p2.10.m10.1.1.3.cmml"><mi id="S2.SS1.p2.10.m10.1.1.3.2.2" xref="S2.SS1.p2.10.m10.1.1.3.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p2.10.m10.1.1.3.2.3" xref="S2.SS1.p2.10.m10.1.1.3.2.3.cmml">l</mi><mi id="S2.SS1.p2.10.m10.1.1.3.3" xref="S2.SS1.p2.10.m10.1.1.3.3.cmml">i</mi></msubsup><mo id="S2.SS1.p2.10.m10.1.1.2" xref="S2.SS1.p2.10.m10.1.1.2.cmml">=</mo><mrow id="S2.SS1.p2.10.m10.1.1.1" xref="S2.SS1.p2.10.m10.1.1.1.cmml"><msub id="S2.SS1.p2.10.m10.1.1.1.3" xref="S2.SS1.p2.10.m10.1.1.1.3.cmml"><mi id="S2.SS1.p2.10.m10.1.1.1.3.2" xref="S2.SS1.p2.10.m10.1.1.1.3.2.cmml">g</mi><mi id="S2.SS1.p2.10.m10.1.1.1.3.3" xref="S2.SS1.p2.10.m10.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p2.10.m10.1.1.1.2" xref="S2.SS1.p2.10.m10.1.1.1.2.cmml">â€‹</mo><mrow id="S2.SS1.p2.10.m10.1.1.1.1.1" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.10.m10.1.1.1.1.1.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p2.10.m10.1.1.1.1.1.1" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.cmml"><msub id="S2.SS1.p2.10.m10.1.1.1.1.1.1.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.cmml"><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.2.cmml">f</mi><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p2.10.m10.1.1.1.1.1.1.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.2.cmml">ğ’™</mi><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.3.cmml">l</mi><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.SS1.p2.10.m10.1.1.1.1.1.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m10.1b"><apply id="S2.SS1.p2.10.m10.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1"><eq id="S2.SS1.p2.10.m10.1.1.2.cmml" xref="S2.SS1.p2.10.m10.1.1.2"></eq><apply id="S2.SS1.p2.10.m10.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.3.1.cmml" xref="S2.SS1.p2.10.m10.1.1.3">superscript</csymbol><apply id="S2.SS1.p2.10.m10.1.1.3.2.cmml" xref="S2.SS1.p2.10.m10.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.3.2.1.cmml" xref="S2.SS1.p2.10.m10.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.10.m10.1.1.3.2.2.cmml" xref="S2.SS1.p2.10.m10.1.1.3.2.2">ğ’›</ci><ci id="S2.SS1.p2.10.m10.1.1.3.2.3.cmml" xref="S2.SS1.p2.10.m10.1.1.3.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p2.10.m10.1.1.3.3.cmml" xref="S2.SS1.p2.10.m10.1.1.3.3">ğ‘–</ci></apply><apply id="S2.SS1.p2.10.m10.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1"><times id="S2.SS1.p2.10.m10.1.1.1.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.2"></times><apply id="S2.SS1.p2.10.m10.1.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.1.3.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.10.m10.1.1.1.3.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.3.2">ğ‘”</ci><ci id="S2.SS1.p2.10.m10.1.1.1.3.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.3.3">ğ‘–</ci></apply><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1"><times id="S2.SS1.p2.10.m10.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.2"></times><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.2">ğ‘“</ci><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.3.3">ğ‘–</ci></apply><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.2">ğ’™</ci><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m10.1c">\bm{z}_{l}^{i}=g_{i}(f_{i}(\bm{x}_{l}^{i}))</annotation></semantics></math>. Thus, the set of projected representations can be written as <math id="S2.SS1.p2.11.m11.4" class="ltx_Math" alttext="\{\bm{z}_{l}^{1},\bm{z}_{l}^{2},\dots,\bm{z}_{l}^{K}\}_{l=1}^{N}" display="inline"><semantics id="S2.SS1.p2.11.m11.4a"><msubsup id="S2.SS1.p2.11.m11.4.4" xref="S2.SS1.p2.11.m11.4.4.cmml"><mrow id="S2.SS1.p2.11.m11.4.4.3.3.3" xref="S2.SS1.p2.11.m11.4.4.3.3.4.cmml"><mo stretchy="false" id="S2.SS1.p2.11.m11.4.4.3.3.3.4" xref="S2.SS1.p2.11.m11.4.4.3.3.4.cmml">{</mo><msubsup id="S2.SS1.p2.11.m11.2.2.1.1.1.1" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1.cmml"><mi id="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.2" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.3" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.3.cmml">l</mi><mn id="S2.SS1.p2.11.m11.2.2.1.1.1.1.3" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1.3.cmml">1</mn></msubsup><mo id="S2.SS1.p2.11.m11.4.4.3.3.3.5" xref="S2.SS1.p2.11.m11.4.4.3.3.4.cmml">,</mo><msubsup id="S2.SS1.p2.11.m11.3.3.2.2.2.2" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2.cmml"><mi id="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.2" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.3" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.3.cmml">l</mi><mn id="S2.SS1.p2.11.m11.3.3.2.2.2.2.3" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2.3.cmml">2</mn></msubsup><mo id="S2.SS1.p2.11.m11.4.4.3.3.3.6" xref="S2.SS1.p2.11.m11.4.4.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p2.11.m11.1.1" xref="S2.SS1.p2.11.m11.1.1.cmml">â€¦</mi><mo id="S2.SS1.p2.11.m11.4.4.3.3.3.7" xref="S2.SS1.p2.11.m11.4.4.3.3.4.cmml">,</mo><msubsup id="S2.SS1.p2.11.m11.4.4.3.3.3.3" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3.cmml"><mi id="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.2" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.3" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.3.cmml">l</mi><mi id="S2.SS1.p2.11.m11.4.4.3.3.3.3.3" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3.3.cmml">K</mi></msubsup><mo stretchy="false" id="S2.SS1.p2.11.m11.4.4.3.3.3.8" xref="S2.SS1.p2.11.m11.4.4.3.3.4.cmml">}</mo></mrow><mrow id="S2.SS1.p2.11.m11.4.4.3.5" xref="S2.SS1.p2.11.m11.4.4.3.5.cmml"><mi id="S2.SS1.p2.11.m11.4.4.3.5.2" xref="S2.SS1.p2.11.m11.4.4.3.5.2.cmml">l</mi><mo id="S2.SS1.p2.11.m11.4.4.3.5.1" xref="S2.SS1.p2.11.m11.4.4.3.5.1.cmml">=</mo><mn id="S2.SS1.p2.11.m11.4.4.3.5.3" xref="S2.SS1.p2.11.m11.4.4.3.5.3.cmml">1</mn></mrow><mi id="S2.SS1.p2.11.m11.4.4.5" xref="S2.SS1.p2.11.m11.4.4.5.cmml">N</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.11.m11.4b"><apply id="S2.SS1.p2.11.m11.4.4.cmml" xref="S2.SS1.p2.11.m11.4.4"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.4.4.4.cmml" xref="S2.SS1.p2.11.m11.4.4">superscript</csymbol><apply id="S2.SS1.p2.11.m11.4.4.3.cmml" xref="S2.SS1.p2.11.m11.4.4"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.4.4.3.4.cmml" xref="S2.SS1.p2.11.m11.4.4">subscript</csymbol><set id="S2.SS1.p2.11.m11.4.4.3.3.4.cmml" xref="S2.SS1.p2.11.m11.4.4.3.3.3"><apply id="S2.SS1.p2.11.m11.2.2.1.1.1.1.cmml" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.2.2.1.1.1.1.1.cmml" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1">superscript</csymbol><apply id="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.cmml" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.1.cmml" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.2.cmml" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.2">ğ’›</ci><ci id="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.3.cmml" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1.2.3">ğ‘™</ci></apply><cn type="integer" id="S2.SS1.p2.11.m11.2.2.1.1.1.1.3.cmml" xref="S2.SS1.p2.11.m11.2.2.1.1.1.1.3">1</cn></apply><apply id="S2.SS1.p2.11.m11.3.3.2.2.2.2.cmml" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.3.3.2.2.2.2.1.cmml" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2">superscript</csymbol><apply id="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.cmml" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.1.cmml" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.2.cmml" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.2">ğ’›</ci><ci id="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.3.cmml" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2.2.3">ğ‘™</ci></apply><cn type="integer" id="S2.SS1.p2.11.m11.3.3.2.2.2.2.3.cmml" xref="S2.SS1.p2.11.m11.3.3.2.2.2.2.3">2</cn></apply><ci id="S2.SS1.p2.11.m11.1.1.cmml" xref="S2.SS1.p2.11.m11.1.1">â€¦</ci><apply id="S2.SS1.p2.11.m11.4.4.3.3.3.3.cmml" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.4.4.3.3.3.3.1.cmml" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3">superscript</csymbol><apply id="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.cmml" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.1.cmml" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3">subscript</csymbol><ci id="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.2.cmml" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.2">ğ’›</ci><ci id="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.3.cmml" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p2.11.m11.4.4.3.3.3.3.3.cmml" xref="S2.SS1.p2.11.m11.4.4.3.3.3.3.3">ğ¾</ci></apply></set><apply id="S2.SS1.p2.11.m11.4.4.3.5.cmml" xref="S2.SS1.p2.11.m11.4.4.3.5"><eq id="S2.SS1.p2.11.m11.4.4.3.5.1.cmml" xref="S2.SS1.p2.11.m11.4.4.3.5.1"></eq><ci id="S2.SS1.p2.11.m11.4.4.3.5.2.cmml" xref="S2.SS1.p2.11.m11.4.4.3.5.2">ğ‘™</ci><cn type="integer" id="S2.SS1.p2.11.m11.4.4.3.5.3.cmml" xref="S2.SS1.p2.11.m11.4.4.3.5.3">1</cn></apply></apply><ci id="S2.SS1.p2.11.m11.4.4.5.cmml" xref="S2.SS1.p2.11.m11.4.4.5">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.11.m11.4c">\{\bm{z}_{l}^{1},\bm{z}_{l}^{2},\dots,\bm{z}_{l}^{K}\}_{l=1}^{N}</annotation></semantics></math>.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/x1.png" id="S2.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="462" height="267" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S2.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Multi-view pre-training with Pairwise-CL with the selected views: wav2vec 2.0, eGeMAPS-88, and mel spectrograms.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/x2.png" id="S2.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="460" height="185" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S2.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Fine-tuning or supervised training for one of the views. The view-level encoders can be either frozen or fine-tuned with a classifier.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">The proposed multi-view SSL framework for speech emotion recognition.</span></figcaption>
</figure>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.6" class="ltx_p">A pair of projected representations <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="\bm{z}_{l}^{i}" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><msubsup id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml"><mi id="S2.SS1.p3.1.m1.1.1.2.2" xref="S2.SS1.p3.1.m1.1.1.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p3.1.m1.1.1.2.3" xref="S2.SS1.p3.1.m1.1.1.2.3.cmml">l</mi><mi id="S2.SS1.p3.1.m1.1.1.3" xref="S2.SS1.p3.1.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><apply id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">superscript</csymbol><apply id="S2.SS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.1.1.2.1.cmml" xref="S2.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p3.1.m1.1.1.2.2.cmml" xref="S2.SS1.p3.1.m1.1.1.2.2">ğ’›</ci><ci id="S2.SS1.p3.1.m1.1.1.2.3.cmml" xref="S2.SS1.p3.1.m1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">\bm{z}_{l}^{i}</annotation></semantics></math> and <math id="S2.SS1.p3.2.m2.1" class="ltx_Math" alttext="\bm{z}_{l}^{j}" display="inline"><semantics id="S2.SS1.p3.2.m2.1a"><msubsup id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml"><mi id="S2.SS1.p3.2.m2.1.1.2.2" xref="S2.SS1.p3.2.m2.1.1.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p3.2.m2.1.1.2.3" xref="S2.SS1.p3.2.m2.1.1.2.3.cmml">l</mi><mi id="S2.SS1.p3.2.m2.1.1.3" xref="S2.SS1.p3.2.m2.1.1.3.cmml">j</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><apply id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.1.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">superscript</csymbol><apply id="S2.SS1.p3.2.m2.1.1.2.cmml" xref="S2.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.1.1.2.1.cmml" xref="S2.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p3.2.m2.1.1.2.2.cmml" xref="S2.SS1.p3.2.m2.1.1.2.2">ğ’›</ci><ci id="S2.SS1.p3.2.m2.1.1.2.3.cmml" xref="S2.SS1.p3.2.m2.1.1.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p3.2.m2.1.1.3.cmml" xref="S2.SS1.p3.2.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">\bm{z}_{l}^{j}</annotation></semantics></math> is considered positive as they correspond to views of the same <math id="S2.SS1.p3.3.m3.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.SS1.p3.3.m3.1a"><mi id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><ci id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">l</annotation></semantics></math>-th instance in a mini-batch. The NT-Xent loss <math id="S2.SS1.p3.4.m4.1" class="ltx_Math" alttext="l_{l}^{i\rightarrow j}" display="inline"><semantics id="S2.SS1.p3.4.m4.1a"><msubsup id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml"><mi id="S2.SS1.p3.4.m4.1.1.2.2" xref="S2.SS1.p3.4.m4.1.1.2.2.cmml">l</mi><mi id="S2.SS1.p3.4.m4.1.1.2.3" xref="S2.SS1.p3.4.m4.1.1.2.3.cmml">l</mi><mrow id="S2.SS1.p3.4.m4.1.1.3" xref="S2.SS1.p3.4.m4.1.1.3.cmml"><mi id="S2.SS1.p3.4.m4.1.1.3.2" xref="S2.SS1.p3.4.m4.1.1.3.2.cmml">i</mi><mo stretchy="false" id="S2.SS1.p3.4.m4.1.1.3.1" xref="S2.SS1.p3.4.m4.1.1.3.1.cmml">â†’</mo><mi id="S2.SS1.p3.4.m4.1.1.3.3" xref="S2.SS1.p3.4.m4.1.1.3.3.cmml">j</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.1b"><apply id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.4.m4.1.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">superscript</csymbol><apply id="S2.SS1.p3.4.m4.1.1.2.cmml" xref="S2.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.4.m4.1.1.2.1.cmml" xref="S2.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S2.SS1.p3.4.m4.1.1.2.2.cmml" xref="S2.SS1.p3.4.m4.1.1.2.2">ğ‘™</ci><ci id="S2.SS1.p3.4.m4.1.1.2.3.cmml" xref="S2.SS1.p3.4.m4.1.1.2.3">ğ‘™</ci></apply><apply id="S2.SS1.p3.4.m4.1.1.3.cmml" xref="S2.SS1.p3.4.m4.1.1.3"><ci id="S2.SS1.p3.4.m4.1.1.3.1.cmml" xref="S2.SS1.p3.4.m4.1.1.3.1">â†’</ci><ci id="S2.SS1.p3.4.m4.1.1.3.2.cmml" xref="S2.SS1.p3.4.m4.1.1.3.2">ğ‘–</ci><ci id="S2.SS1.p3.4.m4.1.1.3.3.cmml" xref="S2.SS1.p3.4.m4.1.1.3.3">ğ‘—</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.1c">l_{l}^{i\rightarrow j}</annotation></semantics></math> treating <math id="S2.SS1.p3.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p3.5.m5.1a"><mi id="S2.SS1.p3.5.m5.1.1" xref="S2.SS1.p3.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m5.1b"><ci id="S2.SS1.p3.5.m5.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m5.1c">i</annotation></semantics></math>-th view from <math id="S2.SS1.p3.6.m6.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.SS1.p3.6.m6.1a"><mi id="S2.SS1.p3.6.m6.1.1" xref="S2.SS1.p3.6.m6.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.6.m6.1b"><ci id="S2.SS1.p3.6.m6.1.1.cmml" xref="S2.SS1.p3.6.m6.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.6.m6.1c">l</annotation></semantics></math>-th example as an anchor can be computed as follows:</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.5" class="ltx_Math" alttext="l_{l}^{i\rightarrow j}=-log\frac{\delta({\bm{z}}_{l}^{i},{\bm{z}}_{l}^{j})}{\sum_{k=1}^{N}\delta({\bm{z}}_{l}^{i},{\bm{z}}_{k}^{j})}," display="block"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1" xref="S2.E1.m1.5.5.1.1.cmml"><msubsup id="S2.E1.m1.5.5.1.1.2" xref="S2.E1.m1.5.5.1.1.2.cmml"><mi id="S2.E1.m1.5.5.1.1.2.2.2" xref="S2.E1.m1.5.5.1.1.2.2.2.cmml">l</mi><mi id="S2.E1.m1.5.5.1.1.2.2.3" xref="S2.E1.m1.5.5.1.1.2.2.3.cmml">l</mi><mrow id="S2.E1.m1.5.5.1.1.2.3" xref="S2.E1.m1.5.5.1.1.2.3.cmml"><mi id="S2.E1.m1.5.5.1.1.2.3.2" xref="S2.E1.m1.5.5.1.1.2.3.2.cmml">i</mi><mo stretchy="false" id="S2.E1.m1.5.5.1.1.2.3.1" xref="S2.E1.m1.5.5.1.1.2.3.1.cmml">â†’</mo><mi id="S2.E1.m1.5.5.1.1.2.3.3" xref="S2.E1.m1.5.5.1.1.2.3.3.cmml">j</mi></mrow></msubsup><mo id="S2.E1.m1.5.5.1.1.1" xref="S2.E1.m1.5.5.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.5.5.1.1.3" xref="S2.E1.m1.5.5.1.1.3.cmml"><mo id="S2.E1.m1.5.5.1.1.3a" xref="S2.E1.m1.5.5.1.1.3.cmml">âˆ’</mo><mrow id="S2.E1.m1.5.5.1.1.3.2" xref="S2.E1.m1.5.5.1.1.3.2.cmml"><mi id="S2.E1.m1.5.5.1.1.3.2.2" xref="S2.E1.m1.5.5.1.1.3.2.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.1.1.3.2.1" xref="S2.E1.m1.5.5.1.1.3.2.1.cmml">â€‹</mo><mi id="S2.E1.m1.5.5.1.1.3.2.3" xref="S2.E1.m1.5.5.1.1.3.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.1.1.3.2.1a" xref="S2.E1.m1.5.5.1.1.3.2.1.cmml">â€‹</mo><mi id="S2.E1.m1.5.5.1.1.3.2.4" xref="S2.E1.m1.5.5.1.1.3.2.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.1.1.3.2.1b" xref="S2.E1.m1.5.5.1.1.3.2.1.cmml">â€‹</mo><mfrac id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml"><mi id="S2.E1.m1.2.2.2.4" xref="S2.E1.m1.2.2.2.4.cmml">Î´</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.E1.m1.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.3.cmml">(</mo><msubsup id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.2.2.cmml">ğ’›</mi><mi id="S2.E1.m1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.2.3.cmml">l</mi><mi id="S2.E1.m1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S2.E1.m1.2.2.2.2.2.4" xref="S2.E1.m1.2.2.2.2.3.cmml">,</mo><msubsup id="S2.E1.m1.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.2.2.cmml">ğ’›</mi><mi id="S2.E1.m1.2.2.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.2.2.2.3.cmml">l</mi><mi id="S2.E1.m1.2.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.2.2.3.cmml">j</mi></msubsup><mo stretchy="false" id="S2.E1.m1.2.2.2.2.2.5" xref="S2.E1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mrow id="S2.E1.m1.4.4.4" xref="S2.E1.m1.4.4.4.cmml"><msubsup id="S2.E1.m1.4.4.4.3" xref="S2.E1.m1.4.4.4.3.cmml"><mo id="S2.E1.m1.4.4.4.3.2.2" xref="S2.E1.m1.4.4.4.3.2.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.4.4.4.3.2.3" xref="S2.E1.m1.4.4.4.3.2.3.cmml"><mi id="S2.E1.m1.4.4.4.3.2.3.2" xref="S2.E1.m1.4.4.4.3.2.3.2.cmml">k</mi><mo id="S2.E1.m1.4.4.4.3.2.3.1" xref="S2.E1.m1.4.4.4.3.2.3.1.cmml">=</mo><mn id="S2.E1.m1.4.4.4.3.2.3.3" xref="S2.E1.m1.4.4.4.3.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.4.4.4.3.3" xref="S2.E1.m1.4.4.4.3.3.cmml">N</mi></msubsup><mrow id="S2.E1.m1.4.4.4.2" xref="S2.E1.m1.4.4.4.2.cmml"><mi id="S2.E1.m1.4.4.4.2.4" xref="S2.E1.m1.4.4.4.2.4.cmml">Î´</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.4.2.3" xref="S2.E1.m1.4.4.4.2.3.cmml">â€‹</mo><mrow id="S2.E1.m1.4.4.4.2.2.2" xref="S2.E1.m1.4.4.4.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.4.2.2.2.3" xref="S2.E1.m1.4.4.4.2.2.3.cmml">(</mo><msubsup id="S2.E1.m1.3.3.3.1.1.1.1" xref="S2.E1.m1.3.3.3.1.1.1.1.cmml"><mi id="S2.E1.m1.3.3.3.1.1.1.1.2.2" xref="S2.E1.m1.3.3.3.1.1.1.1.2.2.cmml">ğ’›</mi><mi id="S2.E1.m1.3.3.3.1.1.1.1.2.3" xref="S2.E1.m1.3.3.3.1.1.1.1.2.3.cmml">l</mi><mi id="S2.E1.m1.3.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.3.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S2.E1.m1.4.4.4.2.2.2.4" xref="S2.E1.m1.4.4.4.2.2.3.cmml">,</mo><msubsup id="S2.E1.m1.4.4.4.2.2.2.2" xref="S2.E1.m1.4.4.4.2.2.2.2.cmml"><mi id="S2.E1.m1.4.4.4.2.2.2.2.2.2" xref="S2.E1.m1.4.4.4.2.2.2.2.2.2.cmml">ğ’›</mi><mi id="S2.E1.m1.4.4.4.2.2.2.2.2.3" xref="S2.E1.m1.4.4.4.2.2.2.2.2.3.cmml">k</mi><mi id="S2.E1.m1.4.4.4.2.2.2.2.3" xref="S2.E1.m1.4.4.4.2.2.2.2.3.cmml">j</mi></msubsup><mo stretchy="false" id="S2.E1.m1.4.4.4.2.2.2.5" xref="S2.E1.m1.4.4.4.2.2.3.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow></mrow></mrow><mo id="S2.E1.m1.5.5.1.2" xref="S2.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.1.1.cmml" xref="S2.E1.m1.5.5.1"><eq id="S2.E1.m1.5.5.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1"></eq><apply id="S2.E1.m1.5.5.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2">superscript</csymbol><apply id="S2.E1.m1.5.5.1.1.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.2.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.2.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2.2">ğ‘™</ci><ci id="S2.E1.m1.5.5.1.1.2.2.3.cmml" xref="S2.E1.m1.5.5.1.1.2.2.3">ğ‘™</ci></apply><apply id="S2.E1.m1.5.5.1.1.2.3.cmml" xref="S2.E1.m1.5.5.1.1.2.3"><ci id="S2.E1.m1.5.5.1.1.2.3.1.cmml" xref="S2.E1.m1.5.5.1.1.2.3.1">â†’</ci><ci id="S2.E1.m1.5.5.1.1.2.3.2.cmml" xref="S2.E1.m1.5.5.1.1.2.3.2">ğ‘–</ci><ci id="S2.E1.m1.5.5.1.1.2.3.3.cmml" xref="S2.E1.m1.5.5.1.1.2.3.3">ğ‘—</ci></apply></apply><apply id="S2.E1.m1.5.5.1.1.3.cmml" xref="S2.E1.m1.5.5.1.1.3"><minus id="S2.E1.m1.5.5.1.1.3.1.cmml" xref="S2.E1.m1.5.5.1.1.3"></minus><apply id="S2.E1.m1.5.5.1.1.3.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2"><times id="S2.E1.m1.5.5.1.1.3.2.1.cmml" xref="S2.E1.m1.5.5.1.1.3.2.1"></times><ci id="S2.E1.m1.5.5.1.1.3.2.2.cmml" xref="S2.E1.m1.5.5.1.1.3.2.2">ğ‘™</ci><ci id="S2.E1.m1.5.5.1.1.3.2.3.cmml" xref="S2.E1.m1.5.5.1.1.3.2.3">ğ‘œ</ci><ci id="S2.E1.m1.5.5.1.1.3.2.4.cmml" xref="S2.E1.m1.5.5.1.1.3.2.4">ğ‘”</ci><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><divide id="S2.E1.m1.4.4.5.cmml" xref="S2.E1.m1.4.4"></divide><apply id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"><times id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.3"></times><ci id="S2.E1.m1.2.2.2.4.cmml" xref="S2.E1.m1.2.2.2.4">ğ›¿</ci><interval closure="open" id="S2.E1.m1.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2"><apply id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.2">ğ’›</ci><ci id="S2.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.E1.m1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.E1.m1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2">superscript</csymbol><apply id="S2.E1.m1.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S2.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2.2">ğ’›</ci><ci id="S2.E1.m1.2.2.2.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2.3">ğ‘™</ci></apply><ci id="S2.E1.m1.2.2.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3">ğ‘—</ci></apply></interval></apply><apply id="S2.E1.m1.4.4.4.cmml" xref="S2.E1.m1.4.4.4"><apply id="S2.E1.m1.4.4.4.3.cmml" xref="S2.E1.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.4.3.1.cmml" xref="S2.E1.m1.4.4.4.3">superscript</csymbol><apply id="S2.E1.m1.4.4.4.3.2.cmml" xref="S2.E1.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.4.3.2.1.cmml" xref="S2.E1.m1.4.4.4.3">subscript</csymbol><sum id="S2.E1.m1.4.4.4.3.2.2.cmml" xref="S2.E1.m1.4.4.4.3.2.2"></sum><apply id="S2.E1.m1.4.4.4.3.2.3.cmml" xref="S2.E1.m1.4.4.4.3.2.3"><eq id="S2.E1.m1.4.4.4.3.2.3.1.cmml" xref="S2.E1.m1.4.4.4.3.2.3.1"></eq><ci id="S2.E1.m1.4.4.4.3.2.3.2.cmml" xref="S2.E1.m1.4.4.4.3.2.3.2">ğ‘˜</ci><cn type="integer" id="S2.E1.m1.4.4.4.3.2.3.3.cmml" xref="S2.E1.m1.4.4.4.3.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.4.4.4.3.3.cmml" xref="S2.E1.m1.4.4.4.3.3">ğ‘</ci></apply><apply id="S2.E1.m1.4.4.4.2.cmml" xref="S2.E1.m1.4.4.4.2"><times id="S2.E1.m1.4.4.4.2.3.cmml" xref="S2.E1.m1.4.4.4.2.3"></times><ci id="S2.E1.m1.4.4.4.2.4.cmml" xref="S2.E1.m1.4.4.4.2.4">ğ›¿</ci><interval closure="open" id="S2.E1.m1.4.4.4.2.2.3.cmml" xref="S2.E1.m1.4.4.4.2.2.2"><apply id="S2.E1.m1.3.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.3.1.1.1.1">superscript</csymbol><apply id="S2.E1.m1.3.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.3.1.1.1.1.2.1.cmml" xref="S2.E1.m1.3.3.3.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.3.1.1.1.1.2.2.cmml" xref="S2.E1.m1.3.3.3.1.1.1.1.2.2">ğ’›</ci><ci id="S2.E1.m1.3.3.3.1.1.1.1.2.3.cmml" xref="S2.E1.m1.3.3.3.1.1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.E1.m1.3.3.3.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.3.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.E1.m1.4.4.4.2.2.2.2.cmml" xref="S2.E1.m1.4.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.4.2.2.2.2.1.cmml" xref="S2.E1.m1.4.4.4.2.2.2.2">superscript</csymbol><apply id="S2.E1.m1.4.4.4.2.2.2.2.2.cmml" xref="S2.E1.m1.4.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.4.2.2.2.2.2.1.cmml" xref="S2.E1.m1.4.4.4.2.2.2.2">subscript</csymbol><ci id="S2.E1.m1.4.4.4.2.2.2.2.2.2.cmml" xref="S2.E1.m1.4.4.4.2.2.2.2.2.2">ğ’›</ci><ci id="S2.E1.m1.4.4.4.2.2.2.2.2.3.cmml" xref="S2.E1.m1.4.4.4.2.2.2.2.2.3">ğ‘˜</ci></apply><ci id="S2.E1.m1.4.4.4.2.2.2.2.3.cmml" xref="S2.E1.m1.4.4.4.2.2.2.2.3">ğ‘—</ci></apply></interval></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">l_{l}^{i\rightarrow j}=-log\frac{\delta({\bm{z}}_{l}^{i},{\bm{z}}_{l}^{j})}{\sum_{k=1}^{N}\delta({\bm{z}}_{l}^{i},{\bm{z}}_{k}^{j})},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p4.4" class="ltx_p">where <math id="S2.SS1.p4.1.m1.4" class="ltx_Math" alttext="\delta({\bm{z}}_{l}^{i},{\bm{z}}_{l}^{j})=exp(\frac{s({\bm{z}}_{l}^{i},{\bm{z}}_{l}^{j})}{\tau})" display="inline"><semantics id="S2.SS1.p4.1.m1.4a"><mrow id="S2.SS1.p4.1.m1.4.4" xref="S2.SS1.p4.1.m1.4.4.cmml"><mrow id="S2.SS1.p4.1.m1.4.4.2" xref="S2.SS1.p4.1.m1.4.4.2.cmml"><mi id="S2.SS1.p4.1.m1.4.4.2.4" xref="S2.SS1.p4.1.m1.4.4.2.4.cmml">Î´</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.1.m1.4.4.2.3" xref="S2.SS1.p4.1.m1.4.4.2.3.cmml">â€‹</mo><mrow id="S2.SS1.p4.1.m1.4.4.2.2.2" xref="S2.SS1.p4.1.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p4.1.m1.4.4.2.2.2.3" xref="S2.SS1.p4.1.m1.4.4.2.2.3.cmml">(</mo><msubsup id="S2.SS1.p4.1.m1.3.3.1.1.1.1" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1.cmml"><mi id="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.2" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.3" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.3.cmml">l</mi><mi id="S2.SS1.p4.1.m1.3.3.1.1.1.1.3" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S2.SS1.p4.1.m1.4.4.2.2.2.4" xref="S2.SS1.p4.1.m1.4.4.2.2.3.cmml">,</mo><msubsup id="S2.SS1.p4.1.m1.4.4.2.2.2.2" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2.cmml"><mi id="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.2" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.3" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.3.cmml">l</mi><mi id="S2.SS1.p4.1.m1.4.4.2.2.2.2.3" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2.3.cmml">j</mi></msubsup><mo stretchy="false" id="S2.SS1.p4.1.m1.4.4.2.2.2.5" xref="S2.SS1.p4.1.m1.4.4.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p4.1.m1.4.4.3" xref="S2.SS1.p4.1.m1.4.4.3.cmml">=</mo><mrow id="S2.SS1.p4.1.m1.4.4.4" xref="S2.SS1.p4.1.m1.4.4.4.cmml"><mi id="S2.SS1.p4.1.m1.4.4.4.2" xref="S2.SS1.p4.1.m1.4.4.4.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.1.m1.4.4.4.1" xref="S2.SS1.p4.1.m1.4.4.4.1.cmml">â€‹</mo><mi id="S2.SS1.p4.1.m1.4.4.4.3" xref="S2.SS1.p4.1.m1.4.4.4.3.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.1.m1.4.4.4.1a" xref="S2.SS1.p4.1.m1.4.4.4.1.cmml">â€‹</mo><mi id="S2.SS1.p4.1.m1.4.4.4.4" xref="S2.SS1.p4.1.m1.4.4.4.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.1.m1.4.4.4.1b" xref="S2.SS1.p4.1.m1.4.4.4.1.cmml">â€‹</mo><mrow id="S2.SS1.p4.1.m1.4.4.4.5.2" xref="S2.SS1.p4.1.m1.2.2.cmml"><mo stretchy="false" id="S2.SS1.p4.1.m1.4.4.4.5.2.1" xref="S2.SS1.p4.1.m1.2.2.cmml">(</mo><mfrac id="S2.SS1.p4.1.m1.2.2" xref="S2.SS1.p4.1.m1.2.2.cmml"><mrow id="S2.SS1.p4.1.m1.2.2.2" xref="S2.SS1.p4.1.m1.2.2.2.cmml"><mi id="S2.SS1.p4.1.m1.2.2.2.4" xref="S2.SS1.p4.1.m1.2.2.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.1.m1.2.2.2.3" xref="S2.SS1.p4.1.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.SS1.p4.1.m1.2.2.2.2.2" xref="S2.SS1.p4.1.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p4.1.m1.2.2.2.2.2.3" xref="S2.SS1.p4.1.m1.2.2.2.2.3.cmml">(</mo><msubsup id="S2.SS1.p4.1.m1.1.1.1.1.1.1" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.2" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.3" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.3.cmml">l</mi><mi id="S2.SS1.p4.1.m1.1.1.1.1.1.1.3" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S2.SS1.p4.1.m1.2.2.2.2.2.4" xref="S2.SS1.p4.1.m1.2.2.2.2.3.cmml">,</mo><msubsup id="S2.SS1.p4.1.m1.2.2.2.2.2.2" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2.cmml"><mi id="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.2" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.3" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.3.cmml">l</mi><mi id="S2.SS1.p4.1.m1.2.2.2.2.2.2.3" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2.3.cmml">j</mi></msubsup><mo stretchy="false" id="S2.SS1.p4.1.m1.2.2.2.2.2.5" xref="S2.SS1.p4.1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mi id="S2.SS1.p4.1.m1.2.2.4" xref="S2.SS1.p4.1.m1.2.2.4.cmml">Ï„</mi></mfrac><mo stretchy="false" id="S2.SS1.p4.1.m1.4.4.4.5.2.2" xref="S2.SS1.p4.1.m1.2.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.4b"><apply id="S2.SS1.p4.1.m1.4.4.cmml" xref="S2.SS1.p4.1.m1.4.4"><eq id="S2.SS1.p4.1.m1.4.4.3.cmml" xref="S2.SS1.p4.1.m1.4.4.3"></eq><apply id="S2.SS1.p4.1.m1.4.4.2.cmml" xref="S2.SS1.p4.1.m1.4.4.2"><times id="S2.SS1.p4.1.m1.4.4.2.3.cmml" xref="S2.SS1.p4.1.m1.4.4.2.3"></times><ci id="S2.SS1.p4.1.m1.4.4.2.4.cmml" xref="S2.SS1.p4.1.m1.4.4.2.4">ğ›¿</ci><interval closure="open" id="S2.SS1.p4.1.m1.4.4.2.2.3.cmml" xref="S2.SS1.p4.1.m1.4.4.2.2.2"><apply id="S2.SS1.p4.1.m1.3.3.1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1">superscript</csymbol><apply id="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.1.cmml" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.2.cmml" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.2">ğ’›</ci><ci id="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.3.cmml" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p4.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.SS1.p4.1.m1.3.3.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.SS1.p4.1.m1.4.4.2.2.2.2.cmml" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.4.4.2.2.2.2.1.cmml" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2">superscript</csymbol><apply id="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.cmml" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.1.cmml" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.2.cmml" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.2">ğ’›</ci><ci id="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.3.cmml" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p4.1.m1.4.4.2.2.2.2.3.cmml" xref="S2.SS1.p4.1.m1.4.4.2.2.2.2.3">ğ‘—</ci></apply></interval></apply><apply id="S2.SS1.p4.1.m1.4.4.4.cmml" xref="S2.SS1.p4.1.m1.4.4.4"><times id="S2.SS1.p4.1.m1.4.4.4.1.cmml" xref="S2.SS1.p4.1.m1.4.4.4.1"></times><ci id="S2.SS1.p4.1.m1.4.4.4.2.cmml" xref="S2.SS1.p4.1.m1.4.4.4.2">ğ‘’</ci><ci id="S2.SS1.p4.1.m1.4.4.4.3.cmml" xref="S2.SS1.p4.1.m1.4.4.4.3">ğ‘¥</ci><ci id="S2.SS1.p4.1.m1.4.4.4.4.cmml" xref="S2.SS1.p4.1.m1.4.4.4.4">ğ‘</ci><apply id="S2.SS1.p4.1.m1.2.2.cmml" xref="S2.SS1.p4.1.m1.4.4.4.5.2"><divide id="S2.SS1.p4.1.m1.2.2.3.cmml" xref="S2.SS1.p4.1.m1.4.4.4.5.2"></divide><apply id="S2.SS1.p4.1.m1.2.2.2.cmml" xref="S2.SS1.p4.1.m1.2.2.2"><times id="S2.SS1.p4.1.m1.2.2.2.3.cmml" xref="S2.SS1.p4.1.m1.2.2.2.3"></times><ci id="S2.SS1.p4.1.m1.2.2.2.4.cmml" xref="S2.SS1.p4.1.m1.2.2.2.4">ğ‘ </ci><interval closure="open" id="S2.SS1.p4.1.m1.2.2.2.2.3.cmml" xref="S2.SS1.p4.1.m1.2.2.2.2.2"><apply id="S2.SS1.p4.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.2">ğ’›</ci><ci id="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p4.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p4.1.m1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S2.SS1.p4.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.2.2.2.2.2.2.1.cmml" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2">superscript</csymbol><apply id="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.cmml" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.1.cmml" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.2">ğ’›</ci><ci id="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.3.cmml" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p4.1.m1.2.2.2.2.2.2.3.cmml" xref="S2.SS1.p4.1.m1.2.2.2.2.2.2.3">ğ‘—</ci></apply></interval></apply><ci id="S2.SS1.p4.1.m1.2.2.4.cmml" xref="S2.SS1.p4.1.m1.2.2.4">ğœ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.4c">\delta({\bm{z}}_{l}^{i},{\bm{z}}_{l}^{j})=exp(\frac{s({\bm{z}}_{l}^{i},{\bm{z}}_{l}^{j})}{\tau})</annotation></semantics></math> and <math id="S2.SS1.p4.2.m2.1" class="ltx_Math" alttext="s(\cdot)" display="inline"><semantics id="S2.SS1.p4.2.m2.1a"><mrow id="S2.SS1.p4.2.m2.1.2" xref="S2.SS1.p4.2.m2.1.2.cmml"><mi id="S2.SS1.p4.2.m2.1.2.2" xref="S2.SS1.p4.2.m2.1.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p4.2.m2.1.2.1" xref="S2.SS1.p4.2.m2.1.2.1.cmml">â€‹</mo><mrow id="S2.SS1.p4.2.m2.1.2.3.2" xref="S2.SS1.p4.2.m2.1.2.cmml"><mo stretchy="false" id="S2.SS1.p4.2.m2.1.2.3.2.1" xref="S2.SS1.p4.2.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS1.p4.2.m2.1.1" xref="S2.SS1.p4.2.m2.1.1.cmml">â‹…</mo><mo stretchy="false" id="S2.SS1.p4.2.m2.1.2.3.2.2" xref="S2.SS1.p4.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.2.m2.1b"><apply id="S2.SS1.p4.2.m2.1.2.cmml" xref="S2.SS1.p4.2.m2.1.2"><times id="S2.SS1.p4.2.m2.1.2.1.cmml" xref="S2.SS1.p4.2.m2.1.2.1"></times><ci id="S2.SS1.p4.2.m2.1.2.2.cmml" xref="S2.SS1.p4.2.m2.1.2.2">ğ‘ </ci><ci id="S2.SS1.p4.2.m2.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.2.m2.1c">s(\cdot)</annotation></semantics></math> is the cosine similarity function <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Therefore, the total loss aggregated for the whole mini-batch of views <math id="S2.SS1.p4.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p4.3.m3.1a"><mi id="S2.SS1.p4.3.m3.1.1" xref="S2.SS1.p4.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.3.m3.1b"><ci id="S2.SS1.p4.3.m3.1.1.cmml" xref="S2.SS1.p4.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.3.m3.1c">i</annotation></semantics></math> and <math id="S2.SS1.p4.4.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.SS1.p4.4.m4.1a"><mi id="S2.SS1.p4.4.m4.1.1" xref="S2.SS1.p4.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.4.m4.1b"><ci id="S2.SS1.p4.4.m4.1.1.cmml" xref="S2.SS1.p4.4.m4.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.4.m4.1c">j</annotation></semantics></math> can be averaged as:</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.3" class="ltx_Math" alttext="L^{i,j}=\frac{1}{N}\sum_{l=1}^{N}(l_{l}^{i\rightarrow j}+l_{l}^{j\rightarrow i})" display="block"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml"><msup id="S2.E2.m1.3.3.3" xref="S2.E2.m1.3.3.3.cmml"><mi id="S2.E2.m1.3.3.3.2" xref="S2.E2.m1.3.3.3.2.cmml">L</mi><mrow id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">i</mi><mo id="S2.E2.m1.2.2.2.4.1" xref="S2.E2.m1.2.2.2.3.cmml">,</mo><mi id="S2.E2.m1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.cmml">j</mi></mrow></msup><mo id="S2.E2.m1.3.3.2" xref="S2.E2.m1.3.3.2.cmml">=</mo><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.cmml"><mfrac id="S2.E2.m1.3.3.1.3" xref="S2.E2.m1.3.3.1.3.cmml"><mn id="S2.E2.m1.3.3.1.3.2" xref="S2.E2.m1.3.3.1.3.2.cmml">1</mn><mi id="S2.E2.m1.3.3.1.3.3" xref="S2.E2.m1.3.3.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.3.3.1.2" xref="S2.E2.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><munderover id="S2.E2.m1.3.3.1.1.2" xref="S2.E2.m1.3.3.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S2.E2.m1.3.3.1.1.2.2.2" xref="S2.E2.m1.3.3.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S2.E2.m1.3.3.1.1.2.2.3" xref="S2.E2.m1.3.3.1.1.2.2.3.cmml"><mi id="S2.E2.m1.3.3.1.1.2.2.3.2" xref="S2.E2.m1.3.3.1.1.2.2.3.2.cmml">l</mi><mo id="S2.E2.m1.3.3.1.1.2.2.3.1" xref="S2.E2.m1.3.3.1.1.2.2.3.1.cmml">=</mo><mn id="S2.E2.m1.3.3.1.1.2.2.3.3" xref="S2.E2.m1.3.3.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.3.3.1.1.2.3" xref="S2.E2.m1.3.3.1.1.2.3.cmml">N</mi></munderover><mrow id="S2.E2.m1.3.3.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml"><msubsup id="S2.E2.m1.3.3.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.2.2.2" xref="S2.E2.m1.3.3.1.1.1.1.1.2.2.2.cmml">l</mi><mi id="S2.E2.m1.3.3.1.1.1.1.1.2.2.3" xref="S2.E2.m1.3.3.1.1.1.1.1.2.2.3.cmml">l</mi><mrow id="S2.E2.m1.3.3.1.1.1.1.1.2.3" xref="S2.E2.m1.3.3.1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.2.3.2" xref="S2.E2.m1.3.3.1.1.1.1.1.2.3.2.cmml">i</mi><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.1.1.2.3.1" xref="S2.E2.m1.3.3.1.1.1.1.1.2.3.1.cmml">â†’</mo><mi id="S2.E2.m1.3.3.1.1.1.1.1.2.3.3" xref="S2.E2.m1.3.3.1.1.1.1.1.2.3.3.cmml">j</mi></mrow></msubsup><mo id="S2.E2.m1.3.3.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml">+</mo><msubsup id="S2.E2.m1.3.3.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.3.2.2" xref="S2.E2.m1.3.3.1.1.1.1.1.3.2.2.cmml">l</mi><mi id="S2.E2.m1.3.3.1.1.1.1.1.3.2.3" xref="S2.E2.m1.3.3.1.1.1.1.1.3.2.3.cmml">l</mi><mrow id="S2.E2.m1.3.3.1.1.1.1.1.3.3" xref="S2.E2.m1.3.3.1.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.3.3.2" xref="S2.E2.m1.3.3.1.1.1.1.1.3.3.2.cmml">j</mi><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.1.1.3.3.1" xref="S2.E2.m1.3.3.1.1.1.1.1.3.3.1.cmml">â†’</mo><mi id="S2.E2.m1.3.3.1.1.1.1.1.3.3.3" xref="S2.E2.m1.3.3.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msubsup></mrow><mo stretchy="false" id="S2.E2.m1.3.3.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3"><eq id="S2.E2.m1.3.3.2.cmml" xref="S2.E2.m1.3.3.2"></eq><apply id="S2.E2.m1.3.3.3.cmml" xref="S2.E2.m1.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.3.1.cmml" xref="S2.E2.m1.3.3.3">superscript</csymbol><ci id="S2.E2.m1.3.3.3.2.cmml" xref="S2.E2.m1.3.3.3.2">ğ¿</ci><list id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.4"><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">ğ‘–</ci><ci id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2">ğ‘—</ci></list></apply><apply id="S2.E2.m1.3.3.1.cmml" xref="S2.E2.m1.3.3.1"><times id="S2.E2.m1.3.3.1.2.cmml" xref="S2.E2.m1.3.3.1.2"></times><apply id="S2.E2.m1.3.3.1.3.cmml" xref="S2.E2.m1.3.3.1.3"><divide id="S2.E2.m1.3.3.1.3.1.cmml" xref="S2.E2.m1.3.3.1.3"></divide><cn type="integer" id="S2.E2.m1.3.3.1.3.2.cmml" xref="S2.E2.m1.3.3.1.3.2">1</cn><ci id="S2.E2.m1.3.3.1.3.3.cmml" xref="S2.E2.m1.3.3.1.3.3">ğ‘</ci></apply><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1.1"><apply id="S2.E2.m1.3.3.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2">superscript</csymbol><apply id="S2.E2.m1.3.3.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.2.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2">subscript</csymbol><sum id="S2.E2.m1.3.3.1.1.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2.2"></sum><apply id="S2.E2.m1.3.3.1.1.2.2.3.cmml" xref="S2.E2.m1.3.3.1.1.2.2.3"><eq id="S2.E2.m1.3.3.1.1.2.2.3.1.cmml" xref="S2.E2.m1.3.3.1.1.2.2.3.1"></eq><ci id="S2.E2.m1.3.3.1.1.2.2.3.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2.3.2">ğ‘™</ci><cn type="integer" id="S2.E2.m1.3.3.1.1.2.2.3.3.cmml" xref="S2.E2.m1.3.3.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.3.3.1.1.2.3.cmml" xref="S2.E2.m1.3.3.1.1.2.3">ğ‘</ci></apply><apply id="S2.E2.m1.3.3.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1"><plus id="S2.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1"></plus><apply id="S2.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2">superscript</csymbol><apply id="S2.E2.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.2.2.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2.2.2">ğ‘™</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.2.2.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2.2.3">ğ‘™</ci></apply><apply id="S2.E2.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2.3"><ci id="S2.E2.m1.3.3.1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2.3.1">â†’</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2.3.2">ğ‘–</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.2.3.3">ğ‘—</ci></apply></apply><apply id="S2.E2.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3">superscript</csymbol><apply id="S2.E2.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3.2.2">ğ‘™</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3.2.3">ğ‘™</ci></apply><apply id="S2.E2.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3.3"><ci id="S2.E2.m1.3.3.1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3.3.1">â†’</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3.3.2">ğ‘—</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.3.3.3">ğ‘–</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">L^{i,j}=\frac{1}{N}\sum_{l=1}^{N}(l_{l}^{i\rightarrow j}+l_{l}^{j\rightarrow i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p id="S2.SS1.p6.2" class="ltx_p">Furthermore, each instance <math id="S2.SS1.p6.1.m1.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.SS1.p6.1.m1.1a"><mi id="S2.SS1.p6.1.m1.1.1" xref="S2.SS1.p6.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.1.m1.1b"><ci id="S2.SS1.p6.1.m1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.1.m1.1c">l</annotation></semantics></math> in a mini-batch is represented by <math id="S2.SS1.p6.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS1.p6.2.m2.1a"><mi id="S2.SS1.p6.2.m2.1.1" xref="S2.SS1.p6.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.2.m2.1b"><ci id="S2.SS1.p6.2.m2.1.1.cmml" xref="S2.SS1.p6.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.2.m2.1c">K</annotation></semantics></math> different views. In the proposed Pairwise-CL, we compute losses between all pairs of views, and average them:</p>
</div>
<div id="S2.SS1.p7" class="ltx_para">
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.5" class="ltx_Math" alttext="\mathcal{L}=\frac{1}{C(K,2)}\sum_{k=1}^{K}\sum_{k^{\prime}=1}^{K}\mathbb{I}_{k\neq k^{\prime}}L^{k,k^{\prime}}," display="block"><semantics id="S2.E3.m1.5a"><mrow id="S2.E3.m1.5.5.1" xref="S2.E3.m1.5.5.1.1.cmml"><mrow id="S2.E3.m1.5.5.1.1" xref="S2.E3.m1.5.5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.5.5.1.1.2" xref="S2.E3.m1.5.5.1.1.2.cmml">â„’</mi><mo id="S2.E3.m1.5.5.1.1.1" xref="S2.E3.m1.5.5.1.1.1.cmml">=</mo><mrow id="S2.E3.m1.5.5.1.1.3" xref="S2.E3.m1.5.5.1.1.3.cmml"><mfrac id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml"><mn id="S2.E3.m1.2.2.4" xref="S2.E3.m1.2.2.4.cmml">1</mn><mrow id="S2.E3.m1.2.2.2" xref="S2.E3.m1.2.2.2.cmml"><mi id="S2.E3.m1.2.2.2.4" xref="S2.E3.m1.2.2.2.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.3" xref="S2.E3.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S2.E3.m1.2.2.2.5.2" xref="S2.E3.m1.2.2.2.5.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.2.5.2.1" xref="S2.E3.m1.2.2.2.5.1.cmml">(</mo><mi id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">K</mi><mo id="S2.E3.m1.2.2.2.5.2.2" xref="S2.E3.m1.2.2.2.5.1.cmml">,</mo><mn id="S2.E3.m1.2.2.2.2" xref="S2.E3.m1.2.2.2.2.cmml">2</mn><mo stretchy="false" id="S2.E3.m1.2.2.2.5.2.3" xref="S2.E3.m1.2.2.2.5.1.cmml">)</mo></mrow></mrow></mfrac><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.3.1" xref="S2.E3.m1.5.5.1.1.3.1.cmml">â€‹</mo><mrow id="S2.E3.m1.5.5.1.1.3.2" xref="S2.E3.m1.5.5.1.1.3.2.cmml"><munderover id="S2.E3.m1.5.5.1.1.3.2.1" xref="S2.E3.m1.5.5.1.1.3.2.1.cmml"><mo movablelimits="false" rspace="0em" id="S2.E3.m1.5.5.1.1.3.2.1.2.2" xref="S2.E3.m1.5.5.1.1.3.2.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E3.m1.5.5.1.1.3.2.1.2.3" xref="S2.E3.m1.5.5.1.1.3.2.1.2.3.cmml"><mi id="S2.E3.m1.5.5.1.1.3.2.1.2.3.2" xref="S2.E3.m1.5.5.1.1.3.2.1.2.3.2.cmml">k</mi><mo id="S2.E3.m1.5.5.1.1.3.2.1.2.3.1" xref="S2.E3.m1.5.5.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S2.E3.m1.5.5.1.1.3.2.1.2.3.3" xref="S2.E3.m1.5.5.1.1.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E3.m1.5.5.1.1.3.2.1.3" xref="S2.E3.m1.5.5.1.1.3.2.1.3.cmml">K</mi></munderover><mrow id="S2.E3.m1.5.5.1.1.3.2.2" xref="S2.E3.m1.5.5.1.1.3.2.2.cmml"><munderover id="S2.E3.m1.5.5.1.1.3.2.2.1" xref="S2.E3.m1.5.5.1.1.3.2.2.1.cmml"><mo movablelimits="false" id="S2.E3.m1.5.5.1.1.3.2.2.1.2.2" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.cmml"><msup id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.cmml"><mi id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.2" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.2.cmml">k</mi><mo id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.3" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.3.cmml">â€²</mo></msup><mo id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.1" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.1.cmml">=</mo><mn id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.3" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E3.m1.5.5.1.1.3.2.2.1.3" xref="S2.E3.m1.5.5.1.1.3.2.2.1.3.cmml">K</mi></munderover><mrow id="S2.E3.m1.5.5.1.1.3.2.2.2" xref="S2.E3.m1.5.5.1.1.3.2.2.2.cmml"><msub id="S2.E3.m1.5.5.1.1.3.2.2.2.2" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.cmml"><mi id="S2.E3.m1.5.5.1.1.3.2.2.2.2.2" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.2.cmml">ğ•€</mi><mrow id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.cmml"><mi id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.2" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.2.cmml">k</mi><mo id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.1" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.1.cmml">â‰ </mo><msup id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.cmml"><mi id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.2" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.2.cmml">k</mi><mo id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.3" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.3.cmml">â€²</mo></msup></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.5.5.1.1.3.2.2.2.1" xref="S2.E3.m1.5.5.1.1.3.2.2.2.1.cmml">â€‹</mo><msup id="S2.E3.m1.5.5.1.1.3.2.2.2.3" xref="S2.E3.m1.5.5.1.1.3.2.2.2.3.cmml"><mi id="S2.E3.m1.5.5.1.1.3.2.2.2.3.2" xref="S2.E3.m1.5.5.1.1.3.2.2.2.3.2.cmml">L</mi><mrow id="S2.E3.m1.4.4.2.2" xref="S2.E3.m1.4.4.2.3.cmml"><mi id="S2.E3.m1.3.3.1.1" xref="S2.E3.m1.3.3.1.1.cmml">k</mi><mo id="S2.E3.m1.4.4.2.2.2" xref="S2.E3.m1.4.4.2.3.cmml">,</mo><msup id="S2.E3.m1.4.4.2.2.1" xref="S2.E3.m1.4.4.2.2.1.cmml"><mi id="S2.E3.m1.4.4.2.2.1.2" xref="S2.E3.m1.4.4.2.2.1.2.cmml">k</mi><mo id="S2.E3.m1.4.4.2.2.1.3" xref="S2.E3.m1.4.4.2.2.1.3.cmml">â€²</mo></msup></mrow></msup></mrow></mrow></mrow></mrow></mrow><mo id="S2.E3.m1.5.5.1.2" xref="S2.E3.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.5b"><apply id="S2.E3.m1.5.5.1.1.cmml" xref="S2.E3.m1.5.5.1"><eq id="S2.E3.m1.5.5.1.1.1.cmml" xref="S2.E3.m1.5.5.1.1.1"></eq><ci id="S2.E3.m1.5.5.1.1.2.cmml" xref="S2.E3.m1.5.5.1.1.2">â„’</ci><apply id="S2.E3.m1.5.5.1.1.3.cmml" xref="S2.E3.m1.5.5.1.1.3"><times id="S2.E3.m1.5.5.1.1.3.1.cmml" xref="S2.E3.m1.5.5.1.1.3.1"></times><apply id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2"><divide id="S2.E3.m1.2.2.3.cmml" xref="S2.E3.m1.2.2"></divide><cn type="integer" id="S2.E3.m1.2.2.4.cmml" xref="S2.E3.m1.2.2.4">1</cn><apply id="S2.E3.m1.2.2.2.cmml" xref="S2.E3.m1.2.2.2"><times id="S2.E3.m1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.3"></times><ci id="S2.E3.m1.2.2.2.4.cmml" xref="S2.E3.m1.2.2.2.4">ğ¶</ci><interval closure="open" id="S2.E3.m1.2.2.2.5.1.cmml" xref="S2.E3.m1.2.2.2.5.2"><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">ğ¾</ci><cn type="integer" id="S2.E3.m1.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2">2</cn></interval></apply></apply><apply id="S2.E3.m1.5.5.1.1.3.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2"><apply id="S2.E3.m1.5.5.1.1.3.2.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3.2.1.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1">superscript</csymbol><apply id="S2.E3.m1.5.5.1.1.3.2.1.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3.2.1.2.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1">subscript</csymbol><sum id="S2.E3.m1.5.5.1.1.3.2.1.2.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1.2.2"></sum><apply id="S2.E3.m1.5.5.1.1.3.2.1.2.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1.2.3"><eq id="S2.E3.m1.5.5.1.1.3.2.1.2.3.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1.2.3.1"></eq><ci id="S2.E3.m1.5.5.1.1.3.2.1.2.3.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1.2.3.2">ğ‘˜</ci><cn type="integer" id="S2.E3.m1.5.5.1.1.3.2.1.2.3.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1.2.3.3">1</cn></apply></apply><ci id="S2.E3.m1.5.5.1.1.3.2.1.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.1.3">ğ¾</ci></apply><apply id="S2.E3.m1.5.5.1.1.3.2.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2"><apply id="S2.E3.m1.5.5.1.1.3.2.2.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3.2.2.1.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1">superscript</csymbol><apply id="S2.E3.m1.5.5.1.1.3.2.2.1.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3.2.2.1.2.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1">subscript</csymbol><sum id="S2.E3.m1.5.5.1.1.3.2.2.1.2.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.2"></sum><apply id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3"><eq id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.1"></eq><apply id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2">superscript</csymbol><ci id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.2">ğ‘˜</ci><ci id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.2.3">â€²</ci></apply><cn type="integer" id="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.2.3.3">1</cn></apply></apply><ci id="S2.E3.m1.5.5.1.1.3.2.2.1.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.1.3">ğ¾</ci></apply><apply id="S2.E3.m1.5.5.1.1.3.2.2.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2"><times id="S2.E3.m1.5.5.1.1.3.2.2.2.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.1"></times><apply id="S2.E3.m1.5.5.1.1.3.2.2.2.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3.2.2.2.2.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2">subscript</csymbol><ci id="S2.E3.m1.5.5.1.1.3.2.2.2.2.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.2">ğ•€</ci><apply id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3"><neq id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.1"></neq><ci id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.2">ğ‘˜</ci><apply id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3">superscript</csymbol><ci id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.2">ğ‘˜</ci><ci id="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.2.3.3.3">â€²</ci></apply></apply></apply><apply id="S2.E3.m1.5.5.1.1.3.2.2.2.3.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.1.1.3.2.2.2.3.1.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.3">superscript</csymbol><ci id="S2.E3.m1.5.5.1.1.3.2.2.2.3.2.cmml" xref="S2.E3.m1.5.5.1.1.3.2.2.2.3.2">ğ¿</ci><list id="S2.E3.m1.4.4.2.3.cmml" xref="S2.E3.m1.4.4.2.2"><ci id="S2.E3.m1.3.3.1.1.cmml" xref="S2.E3.m1.3.3.1.1">ğ‘˜</ci><apply id="S2.E3.m1.4.4.2.2.1.cmml" xref="S2.E3.m1.4.4.2.2.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.2.2.1.1.cmml" xref="S2.E3.m1.4.4.2.2.1">superscript</csymbol><ci id="S2.E3.m1.4.4.2.2.1.2.cmml" xref="S2.E3.m1.4.4.2.2.1.2">ğ‘˜</ci><ci id="S2.E3.m1.4.4.2.2.1.3.cmml" xref="S2.E3.m1.4.4.2.2.1.3">â€²</ci></apply></list></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.5c">\mathcal{L}=\frac{1}{C(K,2)}\sum_{k=1}^{K}\sum_{k^{\prime}=1}^{K}\mathbb{I}_{k\neq k^{\prime}}L^{k,k^{\prime}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p7.4" class="ltx_p">where <math id="S2.SS1.p7.1.m1.2" class="ltx_Math" alttext="C(K,2)" display="inline"><semantics id="S2.SS1.p7.1.m1.2a"><mrow id="S2.SS1.p7.1.m1.2.3" xref="S2.SS1.p7.1.m1.2.3.cmml"><mi id="S2.SS1.p7.1.m1.2.3.2" xref="S2.SS1.p7.1.m1.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p7.1.m1.2.3.1" xref="S2.SS1.p7.1.m1.2.3.1.cmml">â€‹</mo><mrow id="S2.SS1.p7.1.m1.2.3.3.2" xref="S2.SS1.p7.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS1.p7.1.m1.2.3.3.2.1" xref="S2.SS1.p7.1.m1.2.3.3.1.cmml">(</mo><mi id="S2.SS1.p7.1.m1.1.1" xref="S2.SS1.p7.1.m1.1.1.cmml">K</mi><mo id="S2.SS1.p7.1.m1.2.3.3.2.2" xref="S2.SS1.p7.1.m1.2.3.3.1.cmml">,</mo><mn id="S2.SS1.p7.1.m1.2.2" xref="S2.SS1.p7.1.m1.2.2.cmml">2</mn><mo stretchy="false" id="S2.SS1.p7.1.m1.2.3.3.2.3" xref="S2.SS1.p7.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.1.m1.2b"><apply id="S2.SS1.p7.1.m1.2.3.cmml" xref="S2.SS1.p7.1.m1.2.3"><times id="S2.SS1.p7.1.m1.2.3.1.cmml" xref="S2.SS1.p7.1.m1.2.3.1"></times><ci id="S2.SS1.p7.1.m1.2.3.2.cmml" xref="S2.SS1.p7.1.m1.2.3.2">ğ¶</ci><interval closure="open" id="S2.SS1.p7.1.m1.2.3.3.1.cmml" xref="S2.SS1.p7.1.m1.2.3.3.2"><ci id="S2.SS1.p7.1.m1.1.1.cmml" xref="S2.SS1.p7.1.m1.1.1">ğ¾</ci><cn type="integer" id="S2.SS1.p7.1.m1.2.2.cmml" xref="S2.SS1.p7.1.m1.2.2">2</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.1.m1.2c">C(K,2)</annotation></semantics></math> is a number of possible pairs from <math id="S2.SS1.p7.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS1.p7.2.m2.1a"><mi id="S2.SS1.p7.2.m2.1.1" xref="S2.SS1.p7.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.2.m2.1b"><ci id="S2.SS1.p7.2.m2.1.1.cmml" xref="S2.SS1.p7.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.2.m2.1c">K</annotation></semantics></math> views. Therefore, the proposed loss function aims to maximize the similarities for multi-view representations <math id="S2.SS1.p7.3.m3.4" class="ltx_Math" alttext="\{\bm{z}_{l}^{1},\bm{z}_{l}^{2},\dots,\bm{z}_{l}^{K}\}" display="inline"><semantics id="S2.SS1.p7.3.m3.4a"><mrow id="S2.SS1.p7.3.m3.4.4.3" xref="S2.SS1.p7.3.m3.4.4.4.cmml"><mo stretchy="false" id="S2.SS1.p7.3.m3.4.4.3.4" xref="S2.SS1.p7.3.m3.4.4.4.cmml">{</mo><msubsup id="S2.SS1.p7.3.m3.2.2.1.1" xref="S2.SS1.p7.3.m3.2.2.1.1.cmml"><mi id="S2.SS1.p7.3.m3.2.2.1.1.2.2" xref="S2.SS1.p7.3.m3.2.2.1.1.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p7.3.m3.2.2.1.1.2.3" xref="S2.SS1.p7.3.m3.2.2.1.1.2.3.cmml">l</mi><mn id="S2.SS1.p7.3.m3.2.2.1.1.3" xref="S2.SS1.p7.3.m3.2.2.1.1.3.cmml">1</mn></msubsup><mo id="S2.SS1.p7.3.m3.4.4.3.5" xref="S2.SS1.p7.3.m3.4.4.4.cmml">,</mo><msubsup id="S2.SS1.p7.3.m3.3.3.2.2" xref="S2.SS1.p7.3.m3.3.3.2.2.cmml"><mi id="S2.SS1.p7.3.m3.3.3.2.2.2.2" xref="S2.SS1.p7.3.m3.3.3.2.2.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p7.3.m3.3.3.2.2.2.3" xref="S2.SS1.p7.3.m3.3.3.2.2.2.3.cmml">l</mi><mn id="S2.SS1.p7.3.m3.3.3.2.2.3" xref="S2.SS1.p7.3.m3.3.3.2.2.3.cmml">2</mn></msubsup><mo id="S2.SS1.p7.3.m3.4.4.3.6" xref="S2.SS1.p7.3.m3.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p7.3.m3.1.1" xref="S2.SS1.p7.3.m3.1.1.cmml">â€¦</mi><mo id="S2.SS1.p7.3.m3.4.4.3.7" xref="S2.SS1.p7.3.m3.4.4.4.cmml">,</mo><msubsup id="S2.SS1.p7.3.m3.4.4.3.3" xref="S2.SS1.p7.3.m3.4.4.3.3.cmml"><mi id="S2.SS1.p7.3.m3.4.4.3.3.2.2" xref="S2.SS1.p7.3.m3.4.4.3.3.2.2.cmml">ğ’›</mi><mi id="S2.SS1.p7.3.m3.4.4.3.3.2.3" xref="S2.SS1.p7.3.m3.4.4.3.3.2.3.cmml">l</mi><mi id="S2.SS1.p7.3.m3.4.4.3.3.3" xref="S2.SS1.p7.3.m3.4.4.3.3.3.cmml">K</mi></msubsup><mo stretchy="false" id="S2.SS1.p7.3.m3.4.4.3.8" xref="S2.SS1.p7.3.m3.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.3.m3.4b"><set id="S2.SS1.p7.3.m3.4.4.4.cmml" xref="S2.SS1.p7.3.m3.4.4.3"><apply id="S2.SS1.p7.3.m3.2.2.1.1.cmml" xref="S2.SS1.p7.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p7.3.m3.2.2.1.1.1.cmml" xref="S2.SS1.p7.3.m3.2.2.1.1">superscript</csymbol><apply id="S2.SS1.p7.3.m3.2.2.1.1.2.cmml" xref="S2.SS1.p7.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p7.3.m3.2.2.1.1.2.1.cmml" xref="S2.SS1.p7.3.m3.2.2.1.1">subscript</csymbol><ci id="S2.SS1.p7.3.m3.2.2.1.1.2.2.cmml" xref="S2.SS1.p7.3.m3.2.2.1.1.2.2">ğ’›</ci><ci id="S2.SS1.p7.3.m3.2.2.1.1.2.3.cmml" xref="S2.SS1.p7.3.m3.2.2.1.1.2.3">ğ‘™</ci></apply><cn type="integer" id="S2.SS1.p7.3.m3.2.2.1.1.3.cmml" xref="S2.SS1.p7.3.m3.2.2.1.1.3">1</cn></apply><apply id="S2.SS1.p7.3.m3.3.3.2.2.cmml" xref="S2.SS1.p7.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p7.3.m3.3.3.2.2.1.cmml" xref="S2.SS1.p7.3.m3.3.3.2.2">superscript</csymbol><apply id="S2.SS1.p7.3.m3.3.3.2.2.2.cmml" xref="S2.SS1.p7.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p7.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS1.p7.3.m3.3.3.2.2">subscript</csymbol><ci id="S2.SS1.p7.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS1.p7.3.m3.3.3.2.2.2.2">ğ’›</ci><ci id="S2.SS1.p7.3.m3.3.3.2.2.2.3.cmml" xref="S2.SS1.p7.3.m3.3.3.2.2.2.3">ğ‘™</ci></apply><cn type="integer" id="S2.SS1.p7.3.m3.3.3.2.2.3.cmml" xref="S2.SS1.p7.3.m3.3.3.2.2.3">2</cn></apply><ci id="S2.SS1.p7.3.m3.1.1.cmml" xref="S2.SS1.p7.3.m3.1.1">â€¦</ci><apply id="S2.SS1.p7.3.m3.4.4.3.3.cmml" xref="S2.SS1.p7.3.m3.4.4.3.3"><csymbol cd="ambiguous" id="S2.SS1.p7.3.m3.4.4.3.3.1.cmml" xref="S2.SS1.p7.3.m3.4.4.3.3">superscript</csymbol><apply id="S2.SS1.p7.3.m3.4.4.3.3.2.cmml" xref="S2.SS1.p7.3.m3.4.4.3.3"><csymbol cd="ambiguous" id="S2.SS1.p7.3.m3.4.4.3.3.2.1.cmml" xref="S2.SS1.p7.3.m3.4.4.3.3">subscript</csymbol><ci id="S2.SS1.p7.3.m3.4.4.3.3.2.2.cmml" xref="S2.SS1.p7.3.m3.4.4.3.3.2.2">ğ’›</ci><ci id="S2.SS1.p7.3.m3.4.4.3.3.2.3.cmml" xref="S2.SS1.p7.3.m3.4.4.3.3.2.3">ğ‘™</ci></apply><ci id="S2.SS1.p7.3.m3.4.4.3.3.3.cmml" xref="S2.SS1.p7.3.m3.4.4.3.3.3">ğ¾</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.3.m3.4c">\{\bm{z}_{l}^{1},\bm{z}_{l}^{2},\dots,\bm{z}_{l}^{K}\}</annotation></semantics></math> corresponding to the same <math id="S2.SS1.p7.4.m4.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S2.SS1.p7.4.m4.1a"><mi id="S2.SS1.p7.4.m4.1.1" xref="S2.SS1.p7.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.4.m4.1b"><ci id="S2.SS1.p7.4.m4.1.1.cmml" xref="S2.SS1.p7.4.m4.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.4.m4.1c">l</annotation></semantics></math>-th instance.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Utilizing the Proposed Framework</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The proposed pre-training framework can be applied to any number of speech views. In this study, we evaluate the framework using a combination of three views, namely wav2vec 2.0 features, eGeMAPS-88 low-level descriptors, and mel-scale spectrograms, as shown in Figure <a href="#S2.F1" title="Figure 1 â€£ 2.1 Pairwise-CL: Multi-view Contrastive Learning â€£ 2 Methodology â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. This choice is based on their ability to capture different characteristics of speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Pre-training.</span> Representations from each view are processed by a view-specific projection network before computing a pairwise contrastive loss as shown in Figure <a href="#S2.F2" title="Figure 2 â€£ 2.2 Utilizing the Proposed Framework â€£ 2 Methodology â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Thus, the encoders are trained on unlabeled audio signals to align representations of views from corresponding instances by maximizing cosine similarities among them. We highlight that our approach is only focused on pre-training the view-level encoders, also referred to as downstream architectures for large speech models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Thus, during pre-training, the wav2vec 2.0 model is frozen and used as a feature extraction method, unlike in relevant studies exploring tuning wav2vec 2.0 parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Fine-tuning.</span> Each of the view-level encoders can be fine-tuned by adding a classifier on top of the learnt representations (Figure <a href="#S2.F1.sf2" title="In Figure 1 â€£ 2.1 Pairwise-CL: Multi-view Contrastive Learning â€£ 2 Methodology â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>). During fine-tuning, the view-level encoders can be either frozen or further tuned via backpropagation using a supervision signal from labeled speech instances.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div id="S2.F2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:118.3pt;height:64pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-48.4pt,26.2pt) scale(0.55,0.55) ;"><img src="/html/2406.07900/assets/x3.png" id="S2.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="226" height="124" alt="Refer to caption">
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.4.2" class="ltx_text" style="font-size:90%;">Pairwise contrastive loss calculation. Representations from each view are first passed through a separate projection head. Later, the contrastive loss is computed in a pairwise fashion, according to Equations <a href="#S2.E1" title="In 2.1 Pairwise-CL: Multi-view Contrastive Learning â€£ 2 Methodology â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> - <a href="#S2.E3" title="In 2.1 Pairwise-CL: Multi-view Contrastive Learning â€£ 2 Methodology â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Implementation Details</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The experiments in this study are based on the IEMOCAP dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> frequently exploited in the SER literature. The data is collected with 10 subjects in 5 sessions (2 subjects per session). In particular, we use two versions of the dataset in this paper. First, the full version of the dataset, which we refer to as IEMOCAP-10, contains about 10,000 audio samples with 10 distinct emotion annotations. In recent research studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> a subset of this dataset with 5,531 samples<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>In our experiments, we excluded scripted dialogue <span id="footnote1.1" class="ltx_text ltx_font_typewriter">Ses05M-script01-1</span> from session 5 containing another trial of the same script as <span id="footnote1.2" class="ltx_text ltx_font_typewriter">Ses05F-script01-1</span> and <span id="footnote1.3" class="ltx_text ltx_font_typewriter">Ses05M-script01-1b</span>. All baselines and proposed approaches are evaluated on this subset of data.</span></span></span> and 4 emotions (<span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">neutral</span>, <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">angry</span>, <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">sad</span>, and <span id="S3.SS1.p1.1.4" class="ltx_text ltx_font_italic">happy</span> merged with <span id="S3.SS1.p1.1.5" class="ltx_text ltx_font_italic">excited</span>), which we denote as IEMOCAP-4, is commonly used. We use IEMOCAP-10 without labels for pre-training purposes, whereas IEMOCAP-4 is mainly used for fine-tuning. We exploit a leave-one-session-out cross-validation (5-fold) protocol consistent between pre-training and fine-tuning data in order to prevent data leakage. In each cross-validation iteration, one session is used for testing purposes, another session is used for validation and early stopping, and three remaining sessions are used for training. We use Unweighted Average Recall (UAR) and Weighted Accuracy (WA) as metrics for SER.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.T2.3" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:238.5pt;">
<div id="S3.T2.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:261.1pt;height:107.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-23.0pt,9.4pt) scale(0.85,0.85) ;">
<table id="S3.T2.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1.2.1" class="ltx_tr">
<th id="S3.T2.1.1.1.2.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row"></th>
<th id="S3.T2.1.1.1.2.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S3.T2.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" colspan="2">wav2vec 2.0</th>
<th id="S3.T2.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" colspan="2">Spectral</th>
<th id="S3.T2.1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" colspan="2">eGeMAPS-88</th>
</tr>
<tr id="S3.T2.1.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Method</th>
<th id="S3.T2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><math id="S3.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.T2.1.1.1.1.1.m1.1a"><mi id="S3.T2.1.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.1.m1.1c">\tau</annotation></semantics></math></th>
<th id="S3.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">UAR</th>
<th id="S3.T2.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">WA</th>
<th id="S3.T2.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">UAR</th>
<th id="S3.T2.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">WA</th>
<th id="S3.T2.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">UAR</th>
<th id="S3.T2.1.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">WA</th>
</tr>
<tr id="S3.T2.1.1.1.3.2" class="ltx_tr">
<th id="S3.T2.1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">Supervised</th>
<th id="S3.T2.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">-</th>
<th id="S3.T2.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">62.11</th>
<th id="S3.T2.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">59.43</th>
<th id="S3.T2.1.1.1.3.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S3.T2.1.1.1.3.2.5.1" class="ltx_text ltx_font_bold">53.39</span></th>
<th id="S3.T2.1.1.1.3.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.3.2.6.1" class="ltx_text ltx_font_bold">52.09</span></th>
<th id="S3.T2.1.1.1.3.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t">49.97</th>
<th id="S3.T2.1.1.1.3.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">48.1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1.4.1" class="ltx_tr">
<th id="S3.T2.1.1.1.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="4"><span id="S3.T2.1.1.1.4.1.1.1" class="ltx_text">Pairwise-CL</span></th>
<td id="S3.T2.1.1.1.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.1</td>
<th id="S3.T2.1.1.1.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">62.24</th>
<td id="S3.T2.1.1.1.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.4.1.4.1" class="ltx_text ltx_framed ltx_framed_underline">61.51</span></td>
<th id="S3.T2.1.1.1.4.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">51.2</th>
<td id="S3.T2.1.1.1.4.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.94</td>
<th id="S3.T2.1.1.1.4.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="S3.T2.1.1.1.4.1.7.1" class="ltx_text ltx_framed ltx_framed_underline">51.38</span></th>
<td id="S3.T2.1.1.1.4.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.1.1.1.4.1.8.1" class="ltx_text ltx_font_bold">49.69</span></td>
</tr>
<tr id="S3.T2.1.1.1.5.2" class="ltx_tr">
<td id="S3.T2.1.1.1.5.2.1" class="ltx_td ltx_align_center ltx_border_r">0.25</td>
<th id="S3.T2.1.1.1.5.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">62.38</th>
<td id="S3.T2.1.1.1.5.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.1.1.1.5.2.3.1" class="ltx_text ltx_font_bold">61.59</span></td>
<th id="S3.T2.1.1.1.5.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">50.69</th>
<td id="S3.T2.1.1.1.5.2.5" class="ltx_td ltx_align_center ltx_border_r">50.17</td>
<th id="S3.T2.1.1.1.5.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_row">50.77</th>
<td id="S3.T2.1.1.1.5.2.7" class="ltx_td ltx_align_center">47.99</td>
</tr>
<tr id="S3.T2.1.1.1.6.3" class="ltx_tr">
<td id="S3.T2.1.1.1.6.3.1" class="ltx_td ltx_align_center ltx_border_r">0.5</td>
<th id="S3.T2.1.1.1.6.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S3.T2.1.1.1.6.3.2.1" class="ltx_text ltx_font_bold">63.11</span></th>
<td id="S3.T2.1.1.1.6.3.3" class="ltx_td ltx_align_center ltx_border_r">61.36</td>
<th id="S3.T2.1.1.1.6.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S3.T2.1.1.1.6.3.4.1" class="ltx_text ltx_framed ltx_framed_underline">53.37</span></th>
<td id="S3.T2.1.1.1.6.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.1.1.1.6.3.5.1" class="ltx_text ltx_framed ltx_framed_underline">51.97</span></td>
<th id="S3.T2.1.1.1.6.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S3.T2.1.1.1.6.3.6.1" class="ltx_text ltx_font_bold">52.96</span></th>
<td id="S3.T2.1.1.1.6.3.7" class="ltx_td ltx_align_center"><span id="S3.T2.1.1.1.6.3.7.1" class="ltx_text ltx_framed ltx_framed_underline">49.16</span></td>
</tr>
<tr id="S3.T2.1.1.1.7.4" class="ltx_tr">
<td id="S3.T2.1.1.1.7.4.1" class="ltx_td ltx_align_center ltx_border_r">1.0</td>
<th id="S3.T2.1.1.1.7.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">62.35</th>
<td id="S3.T2.1.1.1.7.4.3" class="ltx_td ltx_align_center ltx_border_r">60.88</td>
<th id="S3.T2.1.1.1.7.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">51.97</th>
<td id="S3.T2.1.1.1.7.4.5" class="ltx_td ltx_align_center ltx_border_r">49.61</td>
<th id="S3.T2.1.1.1.7.4.6" class="ltx_td ltx_align_center ltx_th ltx_th_row">50.34</th>
<td id="S3.T2.1.1.1.7.4.7" class="ltx_td ltx_align_center">48.43</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.T2.3.4.2.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T2.3.3.1" class="ltx_text" style="font-size:90%;">Performance metrics for models pre-trained with different values of temperature <math id="S3.T2.3.3.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.T2.3.3.1.m1.1b"><mi id="S3.T2.3.3.1.m1.1.1" xref="S3.T2.3.3.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.1.m1.1c"><ci id="S3.T2.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.1.m1.1d">\tau</annotation></semantics></math> and fine-tuned on IEMOCAP-4.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.T2.fig1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_bottom" style="width:173.4pt;">
<div id="S3.T2.fig1.1" class="ltx_inline-block ltx_transformed_outer" style="width:160.1pt;height:107.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.1pt,9.4pt) scale(0.85,0.85) ;">
<table id="S3.T2.fig1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.fig1.1.1.1.1" class="ltx_tr">
<th id="S3.T2.fig1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">View</th>
<th id="S3.T2.fig1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Frozen</th>
<th id="S3.T2.fig1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">UAR</th>
<th id="S3.T2.fig1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">WA</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.fig1.1.1.2.1" class="ltx_tr">
<td id="S3.T2.fig1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T2.fig1.1.1.2.1.1.1" class="ltx_text">wav2vec 2.0</span></td>
<td id="S3.T2.fig1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S3.T2.fig1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">63.11</td>
<td id="S3.T2.fig1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">61.36</td>
</tr>
<tr id="S3.T2.fig1.1.1.3.2" class="ltx_tr">
<td id="S3.T2.fig1.1.1.3.2.1" class="ltx_td ltx_align_center">âœ“</td>
<td id="S3.T2.fig1.1.1.3.2.2" class="ltx_td ltx_align_center">55.43</td>
<td id="S3.T2.fig1.1.1.3.2.3" class="ltx_td ltx_align_center">53.97</td>
</tr>
<tr id="S3.T2.fig1.1.1.4.3" class="ltx_tr">
<td id="S3.T2.fig1.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T2.fig1.1.1.4.3.1.1" class="ltx_text">Spectral</span></td>
<td id="S3.T2.fig1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S3.T2.fig1.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">53.37</td>
<td id="S3.T2.fig1.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">51.97</td>
</tr>
<tr id="S3.T2.fig1.1.1.5.4" class="ltx_tr">
<td id="S3.T2.fig1.1.1.5.4.1" class="ltx_td ltx_align_center">âœ“</td>
<td id="S3.T2.fig1.1.1.5.4.2" class="ltx_td ltx_align_center">50.34</td>
<td id="S3.T2.fig1.1.1.5.4.3" class="ltx_td ltx_align_center">48.43</td>
</tr>
<tr id="S3.T2.fig1.1.1.6.5" class="ltx_tr">
<td id="S3.T2.fig1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T2.fig1.1.1.6.5.1.1" class="ltx_text">eGeMAPS-88</span></td>
<td id="S3.T2.fig1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t">âœ—</td>
<td id="S3.T2.fig1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_t">52.96</td>
<td id="S3.T2.fig1.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t">49.16</td>
</tr>
<tr id="S3.T2.fig1.1.1.7.6" class="ltx_tr">
<td id="S3.T2.fig1.1.1.7.6.1" class="ltx_td ltx_align_center">âœ“</td>
<td id="S3.T2.fig1.1.1.7.6.2" class="ltx_td ltx_align_center">49.65</td>
<td id="S3.T2.fig1.1.1.7.6.3" class="ltx_td ltx_align_center">48.97</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.T2.fig1.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.fig1.3.2" class="ltx_text" style="font-size:90%;">Results for pre-trained models with frozen and tuned view-level encoders.</span></figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Views and Feature Encoders</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We applied our multi-view pre-training strategy to three views of audio signals downsampled to 16,000 Hz. Each of these views is processed with a view-specific backbone architecture.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">wav2vec 2.0.</span> We use a base version of the wav2vec 2.0 model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> pre-trained on the LibriSpeech dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> available in torchaudio<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><span id="footnote2.1" class="ltx_text ltx_font_typewriter">https://pytorch.org/audio/stable/pipelines.html</span></span></span></span>. We trim or pad all audio inputs to a 15-second length <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> before feeding them to the model. The generated features are passed through the view-level encoder as proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. In particular, the outputs of the CNN and transformer blocks are averaged with learnable weights and passed through a two-layer pointwise 1D-CNN, that outputs vectors of size 128.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">Mel-scale spectrograms.</span> The mel spectrograms are extracted with a 25-millisecond window length and a 10-millisecond hop <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. We employed 64 mel filterbanks covering frequencies from 60 Hz to 7800 Hz. We trim or pad all audio inputs to a 15-second length before generating spectrograms. The obtained spectrograms are then fed to a CNN backbone with three layers.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">eGeMAPS-88.</span> The extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS-88) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> contains 88 derived parameters related to frequency (pitch, jitter), energy, and spectrum aggregated for the whole utterance. We generated these features using the opensmile<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><span id="footnote3.1" class="ltx_text ltx_font_typewriter">https://audeering.github.io/opensmile-python/</span></span></span></span> package. A two-layered MLP with 256 and 128 neurons is used as a view-level encoder.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Pre-training and Fine-tuning</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">During pre-training, we used an MLP with 2 layers of size 256 and 128 as a projection head. The models are pre-trained for 100 epochs with a per-view batch size of 128 and early stopping after 30 epochs with no improvement in validation loss. In the fine-tuning stage, the projection head is dropped and the features are directly passed to a linear classification head with softmax activation. For both pre-training and fine-tuning, we use the Adam optimization algorithm with an initial learning rate of 0.001. During fine-tuning, we decrease the learning rate by a factor of 0.9 after every 5 epochs with no improvement in validation UAR. Pre-training and fine-tuning have been conducted using Nvidia Quadro RTX 5000 GPU (16GB VRAM) with features extracted in advance. With this setup, Pairwise-CL pre-training takes approximately 13 minutes per epoch, whereas fine-tuning time varies based on the used view: 2 seconds for eGEMAPS, 10 seconds for spectrograms, and about 3 minutes for wav2vec 2.0 representations.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluations</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Fully Annotated Dataset and Temperature</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.4" class="ltx_p"><span id="S4.SS1.p1.4.1" class="ltx_text ltx_font_bold">Grid search for temperature.</span> First, we conduct experiments to identify the optimal value of temperature <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\tau</annotation></semantics></math> in the contrastive loss function (Equation <a href="#S2.E1" title="In 2.1 Pairwise-CL: Multi-view Contrastive Learning â€£ 2 Methodology â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). We pre-trained view-level encoders on IEMOCAP-10 with <math id="S4.SS1.p1.2.m2.4" class="ltx_Math" alttext="\tau\in\{0.1,0.25,0.5,1.0\}" display="inline"><semantics id="S4.SS1.p1.2.m2.4a"><mrow id="S4.SS1.p1.2.m2.4.5" xref="S4.SS1.p1.2.m2.4.5.cmml"><mi id="S4.SS1.p1.2.m2.4.5.2" xref="S4.SS1.p1.2.m2.4.5.2.cmml">Ï„</mi><mo id="S4.SS1.p1.2.m2.4.5.1" xref="S4.SS1.p1.2.m2.4.5.1.cmml">âˆˆ</mo><mrow id="S4.SS1.p1.2.m2.4.5.3.2" xref="S4.SS1.p1.2.m2.4.5.3.1.cmml"><mo stretchy="false" id="S4.SS1.p1.2.m2.4.5.3.2.1" xref="S4.SS1.p1.2.m2.4.5.3.1.cmml">{</mo><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">0.1</mn><mo id="S4.SS1.p1.2.m2.4.5.3.2.2" xref="S4.SS1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="S4.SS1.p1.2.m2.2.2" xref="S4.SS1.p1.2.m2.2.2.cmml">0.25</mn><mo id="S4.SS1.p1.2.m2.4.5.3.2.3" xref="S4.SS1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="S4.SS1.p1.2.m2.3.3" xref="S4.SS1.p1.2.m2.3.3.cmml">0.5</mn><mo id="S4.SS1.p1.2.m2.4.5.3.2.4" xref="S4.SS1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="S4.SS1.p1.2.m2.4.4" xref="S4.SS1.p1.2.m2.4.4.cmml">1.0</mn><mo stretchy="false" id="S4.SS1.p1.2.m2.4.5.3.2.5" xref="S4.SS1.p1.2.m2.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.4b"><apply id="S4.SS1.p1.2.m2.4.5.cmml" xref="S4.SS1.p1.2.m2.4.5"><in id="S4.SS1.p1.2.m2.4.5.1.cmml" xref="S4.SS1.p1.2.m2.4.5.1"></in><ci id="S4.SS1.p1.2.m2.4.5.2.cmml" xref="S4.SS1.p1.2.m2.4.5.2">ğœ</ci><set id="S4.SS1.p1.2.m2.4.5.3.1.cmml" xref="S4.SS1.p1.2.m2.4.5.3.2"><cn type="float" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">0.1</cn><cn type="float" id="S4.SS1.p1.2.m2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2">0.25</cn><cn type="float" id="S4.SS1.p1.2.m2.3.3.cmml" xref="S4.SS1.p1.2.m2.3.3">0.5</cn><cn type="float" id="S4.SS1.p1.2.m2.4.4.cmml" xref="S4.SS1.p1.2.m2.4.4">1.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.4c">\tau\in\{0.1,0.25,0.5,1.0\}</annotation></semantics></math> and fine-tuned them on IEMOCAP-4 with all available annotations. The measured metric values are outlined in Table <a href="#S3.T2" title="Table 2 â€£ 3.1 Data â€£ 3 Implementation Details â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. In this experiment, the parameters of view-level encoders were not frozen. The first row in the table corresponds to the supervised models trained on each view with the same view-level encoder and classifier architectures. As can be seen from the table, the pre-trained models obtain higher performance in terms of UAR and Weighted Accuracy on wav2vec 2.0 and eGeMAPS-88 features. Besides, pre-trained model performance (with temperature <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="\tau=0.5" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">Ï„</mi><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><eq id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></eq><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">ğœ</ci><cn type="float" id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">\tau=0.5</annotation></semantics></math>) is comparable when using mel spectrograms. These results demonstrate that the proposed pre-training strategy, in some cases, can further improve performance when large annotated datasets are available for both pre-training and fine-tuning. Besides, the models pre-trained with temperature <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="\tau=0.5" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">Ï„</mi><mo id="S4.SS1.p1.4.m4.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><eq id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1"></eq><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">ğœ</ci><cn type="float" id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">\tau=0.5</annotation></semantics></math> achieve the highest or the second-highest results for almost all views and metrics. Thus, these pre-training settings will be further explored in the subsequent experiments.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Fine-tune or freeze?</span> To evaluate the feature representations learnt by encoders on the SSL task only, we compare tuned and frozen encoders during fine-tuning in Table <a href="#S3.T2" title="Table 2 â€£ 3.1 Data â€£ 3 Implementation Details â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. As can be seen, the framework with frozen encoders is less effective. In particular, fine-tuning the view-level encoder on top of the wav2vec features leads to the largest improvement (almost 8% UAR), compared to the frozen view-level encoder. However, it is worth mentioning that the proposed pre-training allows us to obtain about 50-55% UAR for all views without tuning the encoders with labels. The gap between the models is less notable (about 3% UAR) for eGeMAPS-88 and mel spectrograms.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/x4.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="362" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">wav2vec 2.0</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/x5.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="362" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">Mel spectrograms</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/x6.png" id="S4.F3.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="362" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F3.sf3.3.2" class="ltx_text" style="font-size:90%;">eGeMAPS-88</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.4.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.5.2" class="ltx_text" style="font-size:90%;">UAR for fine-tuning with limited amounts of labeled data: <span id="S4.F3.5.2.1" class="ltx_text ltx_font_italic">*</span> - statistically significant differences, <span id="S4.F3.5.2.2" class="ltx_text ltx_font_italic">ns</span> - not significant.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Limited Annotated Data</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.4" class="ltx_p"><span id="S4.SS2.p1.4.1" class="ltx_text ltx_font_bold">Pairwise-CL vs Supervised.</span> The main motivation of our study is to suggest a pre-training strategy for settings with small amounts of labeled data. Thus, we simulate the scenario with limited annotated data available for fine-tuning by using <math id="S4.SS2.p1.1.m1.4" class="ltx_Math" alttext="p\in\{2\%,5\%,10\%,25\%\}" display="inline"><semantics id="S4.SS2.p1.1.m1.4a"><mrow id="S4.SS2.p1.1.m1.4.4" xref="S4.SS2.p1.1.m1.4.4.cmml"><mi id="S4.SS2.p1.1.m1.4.4.6" xref="S4.SS2.p1.1.m1.4.4.6.cmml">p</mi><mo id="S4.SS2.p1.1.m1.4.4.5" xref="S4.SS2.p1.1.m1.4.4.5.cmml">âˆˆ</mo><mrow id="S4.SS2.p1.1.m1.4.4.4.4" xref="S4.SS2.p1.1.m1.4.4.4.5.cmml"><mo stretchy="false" id="S4.SS2.p1.1.m1.4.4.4.4.5" xref="S4.SS2.p1.1.m1.4.4.4.5.cmml">{</mo><mrow id="S4.SS2.p1.1.m1.1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.1.1.1.2.cmml">2</mn><mo id="S4.SS2.p1.1.m1.1.1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1.cmml">%</mo></mrow><mo id="S4.SS2.p1.1.m1.4.4.4.4.6" xref="S4.SS2.p1.1.m1.4.4.4.5.cmml">,</mo><mrow id="S4.SS2.p1.1.m1.2.2.2.2.2" xref="S4.SS2.p1.1.m1.2.2.2.2.2.cmml"><mn id="S4.SS2.p1.1.m1.2.2.2.2.2.2" xref="S4.SS2.p1.1.m1.2.2.2.2.2.2.cmml">5</mn><mo id="S4.SS2.p1.1.m1.2.2.2.2.2.1" xref="S4.SS2.p1.1.m1.2.2.2.2.2.1.cmml">%</mo></mrow><mo id="S4.SS2.p1.1.m1.4.4.4.4.7" xref="S4.SS2.p1.1.m1.4.4.4.5.cmml">,</mo><mrow id="S4.SS2.p1.1.m1.3.3.3.3.3" xref="S4.SS2.p1.1.m1.3.3.3.3.3.cmml"><mn id="S4.SS2.p1.1.m1.3.3.3.3.3.2" xref="S4.SS2.p1.1.m1.3.3.3.3.3.2.cmml">10</mn><mo id="S4.SS2.p1.1.m1.3.3.3.3.3.1" xref="S4.SS2.p1.1.m1.3.3.3.3.3.1.cmml">%</mo></mrow><mo id="S4.SS2.p1.1.m1.4.4.4.4.8" xref="S4.SS2.p1.1.m1.4.4.4.5.cmml">,</mo><mrow id="S4.SS2.p1.1.m1.4.4.4.4.4" xref="S4.SS2.p1.1.m1.4.4.4.4.4.cmml"><mn id="S4.SS2.p1.1.m1.4.4.4.4.4.2" xref="S4.SS2.p1.1.m1.4.4.4.4.4.2.cmml">25</mn><mo id="S4.SS2.p1.1.m1.4.4.4.4.4.1" xref="S4.SS2.p1.1.m1.4.4.4.4.4.1.cmml">%</mo></mrow><mo stretchy="false" id="S4.SS2.p1.1.m1.4.4.4.4.9" xref="S4.SS2.p1.1.m1.4.4.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.4b"><apply id="S4.SS2.p1.1.m1.4.4.cmml" xref="S4.SS2.p1.1.m1.4.4"><in id="S4.SS2.p1.1.m1.4.4.5.cmml" xref="S4.SS2.p1.1.m1.4.4.5"></in><ci id="S4.SS2.p1.1.m1.4.4.6.cmml" xref="S4.SS2.p1.1.m1.4.4.6">ğ‘</ci><set id="S4.SS2.p1.1.m1.4.4.4.5.cmml" xref="S4.SS2.p1.1.m1.4.4.4.4"><apply id="S4.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1.2">2</cn></apply><apply id="S4.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.2.2.2.2.2.1.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2.1">percent</csymbol><cn type="integer" id="S4.SS2.p1.1.m1.2.2.2.2.2.2.cmml" xref="S4.SS2.p1.1.m1.2.2.2.2.2.2">5</cn></apply><apply id="S4.SS2.p1.1.m1.3.3.3.3.3.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.3.3.3.3.3.1.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3.1">percent</csymbol><cn type="integer" id="S4.SS2.p1.1.m1.3.3.3.3.3.2.cmml" xref="S4.SS2.p1.1.m1.3.3.3.3.3.2">10</cn></apply><apply id="S4.SS2.p1.1.m1.4.4.4.4.4.cmml" xref="S4.SS2.p1.1.m1.4.4.4.4.4"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.4.4.4.4.4.1.cmml" xref="S4.SS2.p1.1.m1.4.4.4.4.4.1">percent</csymbol><cn type="integer" id="S4.SS2.p1.1.m1.4.4.4.4.4.2.cmml" xref="S4.SS2.p1.1.m1.4.4.4.4.4.2">25</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.4c">p\in\{2\%,5\%,10\%,25\%\}</annotation></semantics></math> of training data from each class in IEMOCAP-4. We fine-tune the pre-trained encoder and train the supervised encoder from scratch models 10 times for each proportion of annotations <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">p</annotation></semantics></math>. In Figure <a href="#S4.F3" title="Figure 3 â€£ 4.1 Fully Annotated Dataset and Temperature â€£ 4 Evaluations â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we report the average UAR values obtained for each <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mi id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><ci id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">p</annotation></semantics></math> along with 95% confidence intervals. Besides, we conduct the Mann-Whitney U-test (<math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="\alpha=0.05" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">Î±</mi><mo id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><eq id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1"></eq><ci id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">ğ›¼</ci><cn type="float" id="S4.SS2.p1.4.m4.1.1.3.cmml" xref="S4.SS2.p1.4.m4.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">\alpha=0.05</annotation></semantics></math>) to check for statistically significant differences between the supervised and pre-trained models.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.2" class="ltx_p">According to the obtained metrics, the proposed pre-training strategy significantly improves UAR for all three views in cases with extremely limited annotations (<math id="S4.SS2.p2.1.m1.2" class="ltx_Math" alttext="p\in\{2\%,5\%\}" display="inline"><semantics id="S4.SS2.p2.1.m1.2a"><mrow id="S4.SS2.p2.1.m1.2.2" xref="S4.SS2.p2.1.m1.2.2.cmml"><mi id="S4.SS2.p2.1.m1.2.2.4" xref="S4.SS2.p2.1.m1.2.2.4.cmml">p</mi><mo id="S4.SS2.p2.1.m1.2.2.3" xref="S4.SS2.p2.1.m1.2.2.3.cmml">âˆˆ</mo><mrow id="S4.SS2.p2.1.m1.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S4.SS2.p2.1.m1.2.2.2.2.3" xref="S4.SS2.p2.1.m1.2.2.2.3.cmml">{</mo><mrow id="S4.SS2.p2.1.m1.1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.1.cmml"><mn id="S4.SS2.p2.1.m1.1.1.1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.1.1.1.2.cmml">2</mn><mo id="S4.SS2.p2.1.m1.1.1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1.cmml">%</mo></mrow><mo id="S4.SS2.p2.1.m1.2.2.2.2.4" xref="S4.SS2.p2.1.m1.2.2.2.3.cmml">,</mo><mrow id="S4.SS2.p2.1.m1.2.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.2.cmml"><mn id="S4.SS2.p2.1.m1.2.2.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.2.2.cmml">5</mn><mo id="S4.SS2.p2.1.m1.2.2.2.2.2.1" xref="S4.SS2.p2.1.m1.2.2.2.2.2.1.cmml">%</mo></mrow><mo stretchy="false" id="S4.SS2.p2.1.m1.2.2.2.2.5" xref="S4.SS2.p2.1.m1.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.2b"><apply id="S4.SS2.p2.1.m1.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2"><in id="S4.SS2.p2.1.m1.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.3"></in><ci id="S4.SS2.p2.1.m1.2.2.4.cmml" xref="S4.SS2.p2.1.m1.2.2.4">ğ‘</ci><set id="S4.SS2.p2.1.m1.2.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2"><apply id="S4.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S4.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.1.1.1.2">2</cn></apply><apply id="S4.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2"><csymbol cd="latexml" id="S4.SS2.p2.1.m1.2.2.2.2.2.1.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.1.m1.2.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2.2.2">5</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.2c">p\in\{2\%,5\%\}</annotation></semantics></math>). In these cases, the fine-tuning data amounts to approximately 100 and 250 labeled examples per training set (3 session folds). The performance gaps are particularly high for handcrafted features, where improvements reach up to 10-15% in UAR. For spectral features, supervised models outperform pre-trained ones starting from 10% of annotations available, whereas, for eGeMAPS, the pre-training strategy is beneficial for all values of <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">p</annotation></semantics></math>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Pre-training data distribution.</span> In the previous experiment, the models were pre-trained on IEMOCAP-10 which contains 10 emotions, from which 5 (<span id="S4.SS2.p3.1.2" class="ltx_text ltx_font_italic">happy</span> and <span id="S4.SS2.p3.1.3" class="ltx_text ltx_font_italic">excited</span> are merged) are presented in the fine-tuning IEMOCAP-4 dataset. Thus, the remaining emotions are not relevant for fine-tuning. Even though such a scenario represents a realistic case when only some parts of the dataset are annotated, it is interesting to explore how the distribution of pre-training data affects the performance on downstream emotions. In particular, we conduct pre-training on IEMOCAP-4 containing target emotions only. Furthermore, we pre-train another set of encoders on the remaining part of IEMOCAP with out-of-distribution emotions only. We compare both sets of models after fine-tuning them with sparse annotations on IEMOCAP-4 (Figure <a href="#S4.F4" title="Figure 4 â€£ 4.2 Limited Annotated Data â€£ 4 Evaluations â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). On average, models pre-trained on target distribution data show comparable or better performance, with statistically significant differences observed for wav2vec 2.0 at 2% of annotations, spectrograms at 5% and 10%, and eGeMAPS at 10% and 25%. Nevertheless, the gaps in performance for the most sparse annotations are generally smaller compared to the ones reported in Figure <a href="#S4.F3" title="Figure 3 â€£ 4.1 Fully Annotated Dataset and Temperature â€£ 4 Evaluations â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Thus, model pre-training with target emotions is beneficial but does not lead to large improvements when annotations are limited.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/x7.png" id="S4.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="362" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">wav2vec 2.0</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/x8.png" id="S4.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="362" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">Mel spectrograms</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/x9.png" id="S4.F4.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="362" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F4.sf3.3.2" class="ltx_text" style="font-size:90%;">eGeMAPS-88</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">Comparison of model pre-trained on datasets with target (green) and out-of-distribution (red) annotations.</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>View-level Representations and Alignment</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Figure <a href="#S4.F5" title="Figure 5 â€£ 4.3 View-level Representations and Alignment â€£ 4 Evaluations â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> demonstrates the representations learnt by pre-trained and supervised view-level encoders in a two-dimensional space using t-SNE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. The supervised models were trained on fully annotated IEMOCAP-4. The illustrated data points correspond to the unseen test subjects from the last cross-validation fold.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2406.07900/assets/figures/pt_w2v2_tsne.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="584" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F5.sf1.3.2" class="ltx_text" style="font-size:90%;">wav2vec 2.0</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2406.07900/assets/figures/pt_spec_tsne.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="645" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F5.sf2.3.2" class="ltx_text" style="font-size:90%;">Spectral</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2406.07900/assets/figures/pt_egemaps_tsne.png" id="S4.F5.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="585" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F5.sf3.3.2" class="ltx_text" style="font-size:90%;">eGeMAPS-88</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/figures/sup_w2v2_tsne.png" id="S4.F5.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="585" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F5.sf4.3.2" class="ltx_text" style="font-size:90%;">wav2vec 2.0</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/figures/sup_spec_tsne.png" id="S4.F5.sf5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="586" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S4.F5.sf5.3.2" class="ltx_text" style="font-size:90%;">Spectral</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/figures/sup_egemaps_tsne.png" id="S4.F5.sf6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="585" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S4.F5.sf6.3.2" class="ltx_text" style="font-size:90%;">eGeMAPS-88</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Representations from the test set projected onto the two-dimensional space using t-SNE: (a)-(c) â€“ Pairwise-CL (before fine-tuning); (d)-(f) â€“ supervised training from scratch.</span></figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">The proposed pre-training strategy aims to align representations of different audio signal views. We utilize a projection-weighted Canonical Correlation Analysis (PWCCA) to quantify their alignment. PWCCA has been introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> as a technique for identifying common structures in features and exploring the similarities between deep representations. Table <a href="#S4.T3" title="Table 3 â€£ 4.3 View-level Representations and Alignment â€£ 4 Evaluations â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> compares the PWCCA scores obtained for representations of view-level encoders after pre-training to those of supervised models trained independently. The highest level of alignment is obtained for the combination of wav2vec 2.0 and spectral views. Interestingly, even though the PWCCA scores are comparable for pairs with eGeMAPS, there are significant gains in performance for this view after pre-training according to Figure <a href="#S4.F3.sf3" title="In Figure 3 â€£ 4.1 Fully Annotated Dataset and Temperature â€£ 4 Evaluations â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:229.9pt;height:61.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.3pt,5.4pt) scale(0.85,0.85) ;">
<table id="S4.T3.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.2.1.1.1" class="ltx_tr">
<td id="S4.T3.2.1.1.1.1" class="ltx_td"></td>
<th id="S4.T3.2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">w2v2-egemaps</th>
<th id="S4.T3.2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">w2v2-spec</th>
<th id="S4.T3.2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">spec-egemaps</th>
</tr>
<tr id="S4.T3.2.1.2.2" class="ltx_tr">
<td id="S4.T3.2.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Pairwise-CL</td>
<td id="S4.T3.2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.652</td>
<td id="S4.T3.2.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">0.782</td>
<td id="S4.T3.2.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">0.640</td>
</tr>
<tr id="S4.T3.2.1.3.3" class="ltx_tr">
<td id="S4.T3.2.1.3.3.1" class="ltx_td ltx_align_center">Supervised</td>
<td id="S4.T3.2.1.3.3.2" class="ltx_td ltx_align_center">0.686</td>
<td id="S4.T3.2.1.3.3.3" class="ltx_td ltx_align_center">0.657</td>
<td id="S4.T3.2.1.3.3.4" class="ltx_td ltx_align_center">0.644</td>
</tr>
<tr id="S4.T3.2.1.4.4" class="ltx_tr">
<td id="S4.T3.2.1.4.4.1" class="ltx_td ltx_align_center">Random</td>
<td id="S4.T3.2.1.4.4.2" class="ltx_td ltx_align_center">0.299</td>
<td id="S4.T3.2.1.4.4.3" class="ltx_td ltx_align_center">0.389</td>
<td id="S4.T3.2.1.4.4.4" class="ltx_td ltx_align_center">0.390</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.3.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.4.2" class="ltx_text" style="font-size:90%;">PWCCA scores computed for pairs of view-level representations on test instances. The scores are averaged across folds. As a baseline, random scores were computed for pairs of randomly generated vectors of matching shapes.</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we introduced a lightweight contrastive SSL strategy to refine representations of speech in SER settings with sparsely annotated data. Specifically, we evaluated the strategy for three types of views, namely eGeMAPS-88, mel spectrograms, and wav2vec 2.0 features, capturing diverse characteristics of speech. Our experiments demonstrate that the proposed Pairwise-CL technique significantly improves the SER performance when low amounts of annotated data are available. For future work, we suggest experimenting with more views of speech and consider including more modalities during pre-training.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This work has been conducted within the XR2Learn project funded by the European Unionâ€™s Horizon Innovation Actions program, under Grant Agreement N.101092851.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
E.Â Ghaleb, ``Bimodal emotion recognition through audio-visual cues,'' Ph.D. dissertation, Maastricht University, Netherlands, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
F.Â Eyben, K.Â R. Scherer, B.Â W. Schuller, J.Â Sundberg, E.Â AndrÃ©, C.Â Busso, L.Â Y. Devillers, J.Â Epps, P.Â Laukka, S.Â S. Narayanan <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">etÂ al.</em>, ``The geneva minimalistic acoustic parameter set (gemaps) for voice research and affective computing,'' <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">IEEE transactions on affective computing</em>, vol.Â 7, no.Â 2, pp. 190â€“202, 2015.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
J.Â Deng, Z.Â Zhang, F.Â Eyben, and B.Â Schuller, ``Autoencoder-based unsupervised domain adaptation for speech emotion recognition,'' <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Letters</em>, vol.Â 21, no.Â 9, pp. 1068â€“1072, 2014.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
W.Â Zheng, J.Â Yu, and Y.Â Zou, ``An experimental study of speech emotion recognition based on deep convolutional neural networks,'' in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">2015 international conference on affective computing and intelligent interaction (ACII)</em>.Â Â Â IEEE, 2015, pp. 827â€“831.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
G.Â Trigeorgis, F.Â Ringeval, R.Â Brueckner, E.Â Marchi, M.Â A. Nicolaou, B.Â Schuller, and S.Â Zafeiriou, ``Adieu features? end-to-end speech emotion recognition using a deep convolutional recurrent network,'' in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2016 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>.Â Â Â IEEE, 2016, pp. 5200â€“5204.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A.Â Baevski, Y.Â Zhou, A.Â Mohamed, and M.Â Auli, ``wav2vec 2.0: A framework for self-supervised learning of speech representations,'' <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.Â 33, pp. 12â€‰449â€“12â€‰460, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
S.Â Chen, C.Â Wang, Z.Â Chen, Y.Â Wu, S.Â Liu, Z.Â Chen, J.Â Li, N.Â Kanda, T.Â Yoshioka, X.Â Xiao <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">etÂ al.</em>, ``Wavlm: Large-scale self-supervised pre-training for full stack speech processing,'' <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">IEEE Journal of Selected Topics in Signal Processing</em>, vol.Â 16, no.Â 6, pp. 1505â€“1518, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
W.-N. Hsu, B.Â Bolte, Y.-H.Â H. Tsai, K.Â Lakhotia, R.Â Salakhutdinov, and A.Â Mohamed, ``Hubert: Self-supervised speech representation learning by masked prediction of hidden units,'' <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, vol.Â 29, pp. 3451â€“3460, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L.Â Pepino, P.Â Riera, and L.Â Ferrer, ``Emotion Recognition from Speech Using wav2vec 2.0 Embeddings,'' in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2021</em>, 2021, pp. 3400â€“3404.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y.Â Wang, A.Â Boumadane, and A.Â Heba, ``A fine-tuned wav2vec 2.0/hubert benchmark for speech emotion recognition, speaker verification and spoken language understanding,'' <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.02735</em>, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
E.Â Morais, R.Â Hoory, W.Â Zhu, I.Â Gat, M.Â Damasceno, and H.Â Aronowitz, ``Speech emotion recognition using self-supervised features,'' in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.Â Â Â IEEE, 2022, pp. 6922â€“6926.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S.Â Zaiem, Y.Â Kemiche, T.Â Parcollet, S.Â Essid, and M.Â Ravanelli, ``Speech self-supervised representations benchmarking: a case for larger probing heads,'' <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.14456</em>, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
D.Â M. Schuller and B.Â W. Schuller, ``A review on five recent and near-future developments in computational processing of emotion in the human voice,'' <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Emotion Review</em>, vol.Â 13, no.Â 1, pp. 44â€“50, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
O.Â Rudovic, H.Â W. Park, J.Â Busche, B.Â Schuller, C.Â Breazeal, and R.Â W. Picard, ``Personalized estimation of engagement from videos using active learning with deep reinforcement learning,'' in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>.Â Â Â IEEE, 2019, pp. 217â€“226.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
P.Â Singh, R.Â Srivastava, K.Â Rana, and V.Â Kumar, ``A multimodal hierarchical approach to speech emotion recognition from audio and text,'' <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 229, p. 107316, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
S.Â M.Â H. Mousavi, B.Â Khaertdinov, P.Â Jeuris, E.Â Hortal, D.Â Andreoletti, and S.Â Giordano, ``Emotion recognition in adaptive virtual reality settings: Challenges and opportunities,'' in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">CEUR Workshop Proceedings</em>, vol. 3517.Â Â Â Rheinisch-Westfaelische Technische Hochschule Aachen* Lehrstuhl Informatik V, 2023, pp. 1â€“20.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M.Â B. AkÃ§ay and K.Â OÄŸuz, ``Speech emotion recognition: Emotional models, databases, features, preprocessing methods, supporting modalities, and classifiers,'' <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Speech Communication</em>, vol. 116, pp. 56â€“76, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
A.Â Morcos, M.Â Raghu, and S.Â Bengio, ``Insights on representational similarity in neural networks with canonical correlation,'' <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.Â 31, 2018.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Y.Â Tian, D.Â Krishnan, and P.Â Isola, ``Contrastive multiview coding,'' in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part XI 16</em>.Â Â Â Springer, 2020, pp. 776â€“794.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
R.Â Brinzea, B.Â Khaertdinov, and S.Â Asteriadis, ``Contrastive learning with cross-modal knowledge mining for multimodal human activity recognition,'' in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">2022 International Joint Conference on Neural Networks (IJCNN)</em>.Â Â Â IEEE, 2022, pp. 01â€“08.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J.Â Xu, H.Â Tang, Y.Â Ren, L.Â Peng, X.Â Zhu, and L.Â He, ``Multi-level feature learning for contrastive multi-view clustering,'' in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2022, pp. 16â€‰051â€“16â€‰060.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
G.Â Tu, B.Â Liang, R.Â Mao, M.Â Yang, and R.Â Xu, ``Context or knowledge is not always necessary: A contrastive learning framework for emotion recognition in conversations,'' in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023</em>, 2023, pp. 14â€‰054â€“14â€‰067.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
R.Â Girdhar, A.Â El-Nouby, Z.Â Liu, M.Â Singh, K.Â V. Alwala, A.Â Joulin, and I.Â Misra, ``Imagebind: One embedding space to bind them all,'' in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2023, pp. 15â€‰180â€“15â€‰190.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
T.Â Chen, S.Â Kornblith, M.Â Norouzi, and G.Â Hinton, ``A simple framework for contrastive learning of visual representations,'' in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.Â Â Â PMLR, 2020, pp. 1597â€“1607.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Y.Â Li, Y.Â Mohamied, P.Â Bell, and C.Â Lai, ``Exploration of a self-supervised speech model: A study on emotional corpora,'' in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">2022 IEEE Spoken Language Technology Workshop (SLT)</em>.Â Â Â IEEE, 2023, pp. 868â€“875.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
L.-W. Chen and A.Â Rudnicky, ``Exploring wav2vec 2.0 fine tuning for improved speech emotion recognition,'' in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.Â Â Â IEEE, 2023, pp. 1â€“5.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
C.Â Busso, M.Â Bulut, C.-C. Lee, A.Â Kazemzadeh, E.Â Mower, S.Â Kim, J.Â N. Chang, S.Â Lee, and S.Â S. Narayanan, ``Iemocap: Interactive emotional dyadic motion capture database,'' <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Language resources and evaluation</em>, vol.Â 42, pp. 335â€“359, 2008.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
V.Â Panayotov, G.Â Chen, D.Â Povey, and S.Â Khudanpur, ``Librispeech: An asr corpus based on public domain audio books,'' in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2015, pp. 5206â€“5210.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
A.Â Saeed, D.Â Grangier, and N.Â Zeghidour, ``Contrastive learning of general-purpose audio representations,'' in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.Â Â Â IEEE, 2021, pp. 3875â€“3879.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
H.Â M. Fayek, M.Â Lech, and L.Â Cavedon, ``Evaluating deep learning architectures for speech emotion recognition,'' <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Neural networks: the official journal of the International Neural Network Society</em>, vol.Â 92, pp. 60â€“68, 2017.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
L.Â VanÂ der Maaten and G.Â Hinton, ``Visualizing data using t-sne.'' <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Journal of machine learning research</em>, vol.Â 9, no.Â 11, 2008.

</span>
</li>
</ul>
</section>
<figure id="S6.T4" class="ltx_table">
<div id="S6.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:524.2pt;height:181.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-49.9pt,17.3pt) scale(0.84,0.84) ;">
<table id="S6.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T4.1.1.2.1" class="ltx_tr">
<th id="S6.T4.1.1.2.1.1" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T4.1.1.2.1.2" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T4.1.1.2.1.3" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T4.1.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="4">wav2vec 2.0</th>
<th id="S6.T4.1.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="4">Spectral</th>
<th id="S6.T4.1.1.2.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="4">eGeMAPS-88</th>
<th id="S6.T4.1.1.2.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Average Ranks</th>
</tr>
<tr id="S6.T4.1.1.3.2" class="ltx_tr">
<th id="S6.T4.1.1.3.2.1" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T4.1.1.3.2.2" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T4.1.1.3.2.3" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S6.T4.1.1.3.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Val</th>
<th id="S6.T4.1.1.3.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Test</th>
<th id="S6.T4.1.1.3.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Val</th>
<th id="S6.T4.1.1.3.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Test</th>
<th id="S6.T4.1.1.3.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Val</th>
<th id="S6.T4.1.1.3.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="2">Test</th>
<th id="S6.T4.1.1.3.2.10" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T4.1.1.3.2.11" class="ltx_td ltx_th ltx_th_column"></th>
</tr>
<tr id="S6.T4.1.1.1" class="ltx_tr">
<th id="S6.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column">Method</th>
<th id="S6.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column"><math id="S6.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S6.T4.1.1.1.1.m1.1a"><mi id="S6.T4.1.1.1.1.m1.1.1" xref="S6.T4.1.1.1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S6.T4.1.1.1.1.m1.1b"><ci id="S6.T4.1.1.1.1.m1.1.1.cmml" xref="S6.T4.1.1.1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.1.1.1.1.m1.1c">\tau</annotation></semantics></math></th>
<th id="S6.T4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r">Frozen</th>
<th id="S6.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">UAR</th>
<th id="S6.T4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">WA</th>
<th id="S6.T4.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">UAR</th>
<th id="S6.T4.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">WA</th>
<th id="S6.T4.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">UAR</th>
<th id="S6.T4.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">WA</th>
<th id="S6.T4.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column">UAR</th>
<th id="S6.T4.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column">WA</th>
<th id="S6.T4.1.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column">UAR</th>
<th id="S6.T4.1.1.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column">WA</th>
<th id="S6.T4.1.1.1.14" class="ltx_td ltx_align_center ltx_th ltx_th_column">UAR</th>
<th id="S6.T4.1.1.1.15" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">WA</th>
<th id="S6.T4.1.1.1.16" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S6.T4.1.1.1.16.1" class="ltx_text">Val</span></th>
<th id="S6.T4.1.1.1.17" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S6.T4.1.1.1.17.1" class="ltx_text">Test</span></th>
</tr>
<tr id="S6.T4.1.1.4.3" class="ltx_tr">
<th id="S6.T4.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Supervised</th>
<th id="S6.T4.1.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">-</th>
<th id="S6.T4.1.1.4.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">-</th>
<th id="S6.T4.1.1.4.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">61.35</th>
<th id="S6.T4.1.1.4.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">60.72</th>
<th id="S6.T4.1.1.4.3.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">62.11</th>
<th id="S6.T4.1.1.4.3.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">59.43</th>
<th id="S6.T4.1.1.4.3.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">55.11</th>
<th id="S6.T4.1.1.4.3.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">54.59</th>
<th id="S6.T4.1.1.4.3.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">53.39</th>
<th id="S6.T4.1.1.4.3.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">52.09</th>
<th id="S6.T4.1.1.4.3.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">48.62</th>
<th id="S6.T4.1.1.4.3.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">48.1</th>
<th id="S6.T4.1.1.4.3.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">49.97</th>
<th id="S6.T4.1.1.4.3.15" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">48.1</th>
<th id="S6.T4.1.1.4.3.16" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">4.67</th>
<th id="S6.T4.1.1.4.3.17" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">4.17</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T4.1.1.5.1" class="ltx_tr">
<td id="S6.T4.1.1.5.1.1" class="ltx_td ltx_border_t"></td>
<td id="S6.T4.1.1.5.1.2" class="ltx_td ltx_align_left ltx_border_t">0.1</td>
<td id="S6.T4.1.1.5.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">âœ—</td>
<td id="S6.T4.1.1.5.1.4" class="ltx_td ltx_align_center ltx_border_t">62.49</td>
<td id="S6.T4.1.1.5.1.5" class="ltx_td ltx_align_center ltx_border_t">62.06</td>
<td id="S6.T4.1.1.5.1.6" class="ltx_td ltx_align_center ltx_border_t">62.24</td>
<td id="S6.T4.1.1.5.1.7" class="ltx_td ltx_align_center ltx_border_t">61.51</td>
<td id="S6.T4.1.1.5.1.8" class="ltx_td ltx_align_center ltx_border_t">53.36</td>
<td id="S6.T4.1.1.5.1.9" class="ltx_td ltx_align_center ltx_border_t">52.69</td>
<td id="S6.T4.1.1.5.1.10" class="ltx_td ltx_align_center ltx_border_t">51.2</td>
<td id="S6.T4.1.1.5.1.11" class="ltx_td ltx_align_center ltx_border_t">49.94</td>
<td id="S6.T4.1.1.5.1.12" class="ltx_td ltx_align_center ltx_border_t">51.32</td>
<td id="S6.T4.1.1.5.1.13" class="ltx_td ltx_align_center ltx_border_t">51.09</td>
<td id="S6.T4.1.1.5.1.14" class="ltx_td ltx_align_center ltx_border_t">51.38</td>
<td id="S6.T4.1.1.5.1.15" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.69</td>
<td id="S6.T4.1.1.5.1.16" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.1.1.5.1.16.1" class="ltx_text ltx_framed ltx_framed_underline">2.5</span></td>
<td id="S6.T4.1.1.5.1.17" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.1.1.5.1.17.1" class="ltx_text ltx_framed ltx_framed_underline">2.83</span></td>
</tr>
<tr id="S6.T4.1.1.6.2" class="ltx_tr">
<td id="S6.T4.1.1.6.2.1" class="ltx_td"></td>
<td id="S6.T4.1.1.6.2.2" class="ltx_td"></td>
<td id="S6.T4.1.1.6.2.3" class="ltx_td ltx_align_left ltx_border_r">âœ“</td>
<td id="S6.T4.1.1.6.2.4" class="ltx_td ltx_align_center">55.67</td>
<td id="S6.T4.1.1.6.2.5" class="ltx_td ltx_align_center">54.93</td>
<td id="S6.T4.1.1.6.2.6" class="ltx_td ltx_align_center">57.18</td>
<td id="S6.T4.1.1.6.2.7" class="ltx_td ltx_align_center">55.13</td>
<td id="S6.T4.1.1.6.2.8" class="ltx_td ltx_align_center">47.78</td>
<td id="S6.T4.1.1.6.2.9" class="ltx_td ltx_align_center">47.79</td>
<td id="S6.T4.1.1.6.2.10" class="ltx_td ltx_align_center">47.45</td>
<td id="S6.T4.1.1.6.2.11" class="ltx_td ltx_align_center">47.27</td>
<td id="S6.T4.1.1.6.2.12" class="ltx_td ltx_align_center">49.08</td>
<td id="S6.T4.1.1.6.2.13" class="ltx_td ltx_align_center">48.63</td>
<td id="S6.T4.1.1.6.2.14" class="ltx_td ltx_align_center">50.05</td>
<td id="S6.T4.1.1.6.2.15" class="ltx_td ltx_align_center ltx_border_r">48.76</td>
<td id="S6.T4.1.1.6.2.16" class="ltx_td ltx_align_center">6.67</td>
<td id="S6.T4.1.1.6.2.17" class="ltx_td ltx_align_center">6</td>
</tr>
<tr id="S6.T4.1.1.7.3" class="ltx_tr">
<td id="S6.T4.1.1.7.3.1" class="ltx_td"></td>
<td id="S6.T4.1.1.7.3.2" class="ltx_td ltx_align_left">0.25</td>
<td id="S6.T4.1.1.7.3.3" class="ltx_td ltx_align_left ltx_border_r">âœ—</td>
<td id="S6.T4.1.1.7.3.4" class="ltx_td ltx_align_center">62.88</td>
<td id="S6.T4.1.1.7.3.5" class="ltx_td ltx_align_center">62.46</td>
<td id="S6.T4.1.1.7.3.6" class="ltx_td ltx_align_center">62.38</td>
<td id="S6.T4.1.1.7.3.7" class="ltx_td ltx_align_center">61.59</td>
<td id="S6.T4.1.1.7.3.8" class="ltx_td ltx_align_center">53.17</td>
<td id="S6.T4.1.1.7.3.9" class="ltx_td ltx_align_center">52.64</td>
<td id="S6.T4.1.1.7.3.10" class="ltx_td ltx_align_center">50.69</td>
<td id="S6.T4.1.1.7.3.11" class="ltx_td ltx_align_center">50.17</td>
<td id="S6.T4.1.1.7.3.12" class="ltx_td ltx_align_center">50.85</td>
<td id="S6.T4.1.1.7.3.13" class="ltx_td ltx_align_center">49.72</td>
<td id="S6.T4.1.1.7.3.14" class="ltx_td ltx_align_center">50.77</td>
<td id="S6.T4.1.1.7.3.15" class="ltx_td ltx_align_center ltx_border_r">47.99</td>
<td id="S6.T4.1.1.7.3.16" class="ltx_td ltx_align_center">3</td>
<td id="S6.T4.1.1.7.3.17" class="ltx_td ltx_align_center">3.67</td>
</tr>
<tr id="S6.T4.1.1.8.4" class="ltx_tr">
<td id="S6.T4.1.1.8.4.1" class="ltx_td"></td>
<td id="S6.T4.1.1.8.4.2" class="ltx_td"></td>
<td id="S6.T4.1.1.8.4.3" class="ltx_td ltx_align_left ltx_border_r">âœ“</td>
<td id="S6.T4.1.1.8.4.4" class="ltx_td ltx_align_center">57.11</td>
<td id="S6.T4.1.1.8.4.5" class="ltx_td ltx_align_center">56.41</td>
<td id="S6.T4.1.1.8.4.6" class="ltx_td ltx_align_center">56.77</td>
<td id="S6.T4.1.1.8.4.7" class="ltx_td ltx_align_center">54.59</td>
<td id="S6.T4.1.1.8.4.8" class="ltx_td ltx_align_center">47.2</td>
<td id="S6.T4.1.1.8.4.9" class="ltx_td ltx_align_center">47.81</td>
<td id="S6.T4.1.1.8.4.10" class="ltx_td ltx_align_center">47.07</td>
<td id="S6.T4.1.1.8.4.11" class="ltx_td ltx_align_center">46.99</td>
<td id="S6.T4.1.1.8.4.12" class="ltx_td ltx_align_center">49.54</td>
<td id="S6.T4.1.1.8.4.13" class="ltx_td ltx_align_center">49.58</td>
<td id="S6.T4.1.1.8.4.14" class="ltx_td ltx_align_center">48.99</td>
<td id="S6.T4.1.1.8.4.15" class="ltx_td ltx_align_center ltx_border_r">49.02</td>
<td id="S6.T4.1.1.8.4.16" class="ltx_td ltx_align_center">6</td>
<td id="S6.T4.1.1.8.4.17" class="ltx_td ltx_align_center">6.83</td>
</tr>
<tr id="S6.T4.1.1.9.5" class="ltx_tr">
<td id="S6.T4.1.1.9.5.1" class="ltx_td"></td>
<td id="S6.T4.1.1.9.5.2" class="ltx_td ltx_align_left">0.5</td>
<td id="S6.T4.1.1.9.5.3" class="ltx_td ltx_align_left ltx_border_r">âœ—</td>
<td id="S6.T4.1.1.9.5.4" class="ltx_td ltx_align_center">62.73</td>
<td id="S6.T4.1.1.9.5.5" class="ltx_td ltx_align_center">61.8</td>
<td id="S6.T4.1.1.9.5.6" class="ltx_td ltx_align_center">63.11</td>
<td id="S6.T4.1.1.9.5.7" class="ltx_td ltx_align_center">61.36</td>
<td id="S6.T4.1.1.9.5.8" class="ltx_td ltx_align_center">54.89</td>
<td id="S6.T4.1.1.9.5.9" class="ltx_td ltx_align_center">54.06</td>
<td id="S6.T4.1.1.9.5.10" class="ltx_td ltx_align_center">53.37</td>
<td id="S6.T4.1.1.9.5.11" class="ltx_td ltx_align_center">51.97</td>
<td id="S6.T4.1.1.9.5.12" class="ltx_td ltx_align_center">50.66</td>
<td id="S6.T4.1.1.9.5.13" class="ltx_td ltx_align_center">50.13</td>
<td id="S6.T4.1.1.9.5.14" class="ltx_td ltx_align_center">52.96</td>
<td id="S6.T4.1.1.9.5.15" class="ltx_td ltx_align_center ltx_border_r">49.16</td>
<td id="S6.T4.1.1.9.5.16" class="ltx_td ltx_align_center"><span id="S6.T4.1.1.9.5.16.1" class="ltx_text ltx_font_bold">2.33</span></td>
<td id="S6.T4.1.1.9.5.17" class="ltx_td ltx_align_center"><span id="S6.T4.1.1.9.5.17.1" class="ltx_text ltx_font_bold">1.83</span></td>
</tr>
<tr id="S6.T4.1.1.10.6" class="ltx_tr">
<td id="S6.T4.1.1.10.6.1" class="ltx_td"></td>
<td id="S6.T4.1.1.10.6.2" class="ltx_td"></td>
<td id="S6.T4.1.1.10.6.3" class="ltx_td ltx_align_left ltx_border_r">âœ“</td>
<td id="S6.T4.1.1.10.6.4" class="ltx_td ltx_align_center">55.6</td>
<td id="S6.T4.1.1.10.6.5" class="ltx_td ltx_align_center">55.05</td>
<td id="S6.T4.1.1.10.6.6" class="ltx_td ltx_align_center">55.43</td>
<td id="S6.T4.1.1.10.6.7" class="ltx_td ltx_align_center">53.97</td>
<td id="S6.T4.1.1.10.6.8" class="ltx_td ltx_align_center">47.15</td>
<td id="S6.T4.1.1.10.6.9" class="ltx_td ltx_align_center">47.37</td>
<td id="S6.T4.1.1.10.6.10" class="ltx_td ltx_align_center">50.34</td>
<td id="S6.T4.1.1.10.6.11" class="ltx_td ltx_align_center">48.43</td>
<td id="S6.T4.1.1.10.6.12" class="ltx_td ltx_align_center">48.81</td>
<td id="S6.T4.1.1.10.6.13" class="ltx_td ltx_align_center">48.47</td>
<td id="S6.T4.1.1.10.6.14" class="ltx_td ltx_align_center">49.65</td>
<td id="S6.T4.1.1.10.6.15" class="ltx_td ltx_align_center ltx_border_r">48.97</td>
<td id="S6.T4.1.1.10.6.16" class="ltx_td ltx_align_center">7.67</td>
<td id="S6.T4.1.1.10.6.17" class="ltx_td ltx_align_center">6.5</td>
</tr>
<tr id="S6.T4.1.1.11.7" class="ltx_tr">
<td id="S6.T4.1.1.11.7.1" class="ltx_td"></td>
<td id="S6.T4.1.1.11.7.2" class="ltx_td ltx_align_left">1</td>
<td id="S6.T4.1.1.11.7.3" class="ltx_td ltx_align_left ltx_border_r">âœ—</td>
<td id="S6.T4.1.1.11.7.4" class="ltx_td ltx_align_center">62.22</td>
<td id="S6.T4.1.1.11.7.5" class="ltx_td ltx_align_center">60.9</td>
<td id="S6.T4.1.1.11.7.6" class="ltx_td ltx_align_center">62.35</td>
<td id="S6.T4.1.1.11.7.7" class="ltx_td ltx_align_center">60.88</td>
<td id="S6.T4.1.1.11.7.8" class="ltx_td ltx_align_center">53.99</td>
<td id="S6.T4.1.1.11.7.9" class="ltx_td ltx_align_center">53.07</td>
<td id="S6.T4.1.1.11.7.10" class="ltx_td ltx_align_center">51.97</td>
<td id="S6.T4.1.1.11.7.11" class="ltx_td ltx_align_center">49.61</td>
<td id="S6.T4.1.1.11.7.12" class="ltx_td ltx_align_center">50.6</td>
<td id="S6.T4.1.1.11.7.13" class="ltx_td ltx_align_center">49.97</td>
<td id="S6.T4.1.1.11.7.14" class="ltx_td ltx_align_center">50.34</td>
<td id="S6.T4.1.1.11.7.15" class="ltx_td ltx_align_center ltx_border_r">48.43</td>
<td id="S6.T4.1.1.11.7.16" class="ltx_td ltx_align_center">3.5</td>
<td id="S6.T4.1.1.11.7.17" class="ltx_td ltx_align_center">4.17</td>
</tr>
<tr id="S6.T4.1.1.12.8" class="ltx_tr">
<td id="S6.T4.1.1.12.8.1" class="ltx_td ltx_align_center"><span id="S6.T4.1.1.12.8.1.1" class="ltx_text">Pairwise CL</span></td>
<td id="S6.T4.1.1.12.8.2" class="ltx_td"></td>
<td id="S6.T4.1.1.12.8.3" class="ltx_td ltx_align_left ltx_border_r">âœ“</td>
<td id="S6.T4.1.1.12.8.4" class="ltx_td ltx_align_center">55.4</td>
<td id="S6.T4.1.1.12.8.5" class="ltx_td ltx_align_center">54.83</td>
<td id="S6.T4.1.1.12.8.6" class="ltx_td ltx_align_center">54.33</td>
<td id="S6.T4.1.1.12.8.7" class="ltx_td ltx_align_center">53.21</td>
<td id="S6.T4.1.1.12.8.8" class="ltx_td ltx_align_center">47.39</td>
<td id="S6.T4.1.1.12.8.9" class="ltx_td ltx_align_center">47.33</td>
<td id="S6.T4.1.1.12.8.10" class="ltx_td ltx_align_center">47</td>
<td id="S6.T4.1.1.12.8.11" class="ltx_td ltx_align_center">46</td>
<td id="S6.T4.1.1.12.8.12" class="ltx_td ltx_align_center">47.57</td>
<td id="S6.T4.1.1.12.8.13" class="ltx_td ltx_align_center">46.72</td>
<td id="S6.T4.1.1.12.8.14" class="ltx_td ltx_align_center">48.74</td>
<td id="S6.T4.1.1.12.8.15" class="ltx_td ltx_align_center ltx_border_r">45.91</td>
<td id="S6.T4.1.1.12.8.16" class="ltx_td ltx_align_center">8.67</td>
<td id="S6.T4.1.1.12.8.17" class="ltx_td ltx_align_center">9</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S6.T4.4.2" class="ltx_text" style="font-size:90%;">Fine-tuning results for frozen and tuned view-level encoders pre-trained with different temperature values. For each column with UAR and WA, ranks were calculated by sorting the reported scores. In the last two columns, average ranks obtained for validation and test metrics are presented.</span></figcaption>
</figure>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Supplementary Materials</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Number of parameters</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">In Table <a href="#S7.T5" title="Table 5 â€£ 7.1 Number of parameters â€£ 7 Supplementary Materials â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we present the number of frozen and trainable parameters in the utilized models during pre-training and fine-tuning. As highlighted in Section 2.2, we did not tune the parameters of wav2vec 2.0 and used it as a feature encoder. Thus, the number of frozen parameters in all models exploiting this architecture is no less than the number of wav2vec 2.0 parameters (94.5 million). It can be seen, that the proposed pre-training method outperforms plain fine-tuning on limited data (Figure 3a from the paper) by tuning a small number of parameters corresponding to the view-level encoder applied on top of wav2vec 2.0 features.</p>
</div>
<figure id="S7.T5" class="ltx_table">
<div id="S7.T5.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:268.0pt;height:138.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.0pt,20.7pt) scale(0.77,0.77) ;">
<table id="S7.T5.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T5.2.1.1.1" class="ltx_tr">
<th id="S7.T5.2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">View</th>
<th id="S7.T5.2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Encoder</th>
<th id="S7.T5.2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Frozen</th>
<th id="S7.T5.2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"># frozen (M)</th>
<th id="S7.T5.2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"># trainable (M)</th>
</tr>
<tr id="S7.T5.2.1.2.2" class="ltx_tr">
<th id="S7.T5.2.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="5">Supervised Training / Fine-tuning</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T5.2.1.3.1" class="ltx_tr">
<td id="S7.T5.2.1.3.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T5.2.1.3.1.1.1" class="ltx_text">wav2vec 2.0</span></td>
<td id="S7.T5.2.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S7.T5.2.1.3.1.2.1" class="ltx_text">Pointwise CNN</span></td>
<td id="S7.T5.2.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">âœ—</td>
<td id="S7.T5.2.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">94.4</td>
<td id="S7.T5.2.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.132</td>
</tr>
<tr id="S7.T5.2.1.4.2" class="ltx_tr">
<td id="S7.T5.2.1.4.2.1" class="ltx_td ltx_align_center ltx_border_r">âœ“</td>
<td id="S7.T5.2.1.4.2.2" class="ltx_td ltx_align_center">94.515</td>
<td id="S7.T5.2.1.4.2.3" class="ltx_td ltx_align_center">0.017</td>
</tr>
<tr id="S7.T5.2.1.5.3" class="ltx_tr">
<td id="S7.T5.2.1.5.3.1" class="ltx_td ltx_align_center" rowspan="2"><span id="S7.T5.2.1.5.3.1.1" class="ltx_text">Spectrograms</span></td>
<td id="S7.T5.2.1.5.3.2" class="ltx_td ltx_align_center" rowspan="2"><span id="S7.T5.2.1.5.3.2.1" class="ltx_text">CNN</span></td>
<td id="S7.T5.2.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r">âœ—</td>
<td id="S7.T5.2.1.5.3.4" class="ltx_td ltx_align_center">0</td>
<td id="S7.T5.2.1.5.3.5" class="ltx_td ltx_align_center">0.061</td>
</tr>
<tr id="S7.T5.2.1.6.4" class="ltx_tr">
<td id="S7.T5.2.1.6.4.1" class="ltx_td ltx_align_center ltx_border_r">âœ“</td>
<td id="S7.T5.2.1.6.4.2" class="ltx_td ltx_align_center">0.035</td>
<td id="S7.T5.2.1.6.4.3" class="ltx_td ltx_align_center">0.026</td>
</tr>
<tr id="S7.T5.2.1.7.5" class="ltx_tr">
<td id="S7.T5.2.1.7.5.1" class="ltx_td ltx_align_center" rowspan="2"><span id="S7.T5.2.1.7.5.1.1" class="ltx_text">eGeMAPS-88</span></td>
<td id="S7.T5.2.1.7.5.2" class="ltx_td ltx_align_center" rowspan="2"><span id="S7.T5.2.1.7.5.2.1" class="ltx_text">MLP</span></td>
<td id="S7.T5.2.1.7.5.3" class="ltx_td ltx_align_center ltx_border_r">âœ—</td>
<td id="S7.T5.2.1.7.5.4" class="ltx_td ltx_align_center">0</td>
<td id="S7.T5.2.1.7.5.5" class="ltx_td ltx_align_center">0.029</td>
</tr>
<tr id="S7.T5.2.1.8.6" class="ltx_tr">
<td id="S7.T5.2.1.8.6.1" class="ltx_td ltx_align_center ltx_border_r">âœ“</td>
<td id="S7.T5.2.1.8.6.2" class="ltx_td ltx_align_center">0.011</td>
<td id="S7.T5.2.1.8.6.3" class="ltx_td ltx_align_center">0.018</td>
</tr>
<tr id="S7.T5.2.1.9.7" class="ltx_tr">
<td id="S7.T5.2.1.9.7.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5">Pre-training</td>
</tr>
<tr id="S7.T5.2.1.10.8" class="ltx_tr">
<td id="S7.T5.2.1.10.8.1" class="ltx_td ltx_align_center ltx_border_t">Multi-view</td>
<td id="S7.T5.2.1.10.8.2" class="ltx_td ltx_align_center ltx_border_t">All encoders</td>
<td id="S7.T5.2.1.10.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S7.T5.2.1.10.8.4" class="ltx_td ltx_align_center ltx_border_t">94.5</td>
<td id="S7.T5.2.1.10.8.5" class="ltx_td ltx_align_center ltx_border_t">0.202</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S7.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S7.T5.4.2" class="ltx_text" style="font-size:90%;">Model sizes during supervised training, fine-tuning and pre-training with Pairwise CL. The number (#) of frozen and trainable parameters is presented in millions (M).</span></figcaption>
</figure>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Fully-annotated Fine-tuning: Extended Results</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">In Tables 1 and 2 from the paper, we demonstrated the summary of the fine-tuning results averaged over unseen test folds in leave-one-session-out cross-validation settings of IEMOCAP-4. Specifically, we tried out different temperature values and freezing or tuning the view-level encoders during fine-tuning. In Table <a href="#S6.T4" title="Table 4 â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (next page), we present a more thorough summary of the results given all possible combinations between these hyperparameters along with the average metrics obtained on validation and test sessions. Furthermore, we computed the performance ranks (1 â€“ highest metric score, 9 â€“ lowest) of models for each metric and data split, and averaged them for validation and test. The average ranks are presented in the last two columns of the table. As can be seen, the highest ranks on both validation (2.33) and test (1.83) data correspond to the model pre-trained with temperature <math id="S7.SS2.p1.1.m1.1" class="ltx_Math" alttext="\tau=0.5" display="inline"><semantics id="S7.SS2.p1.1.m1.1a"><mrow id="S7.SS2.p1.1.m1.1.1" xref="S7.SS2.p1.1.m1.1.1.cmml"><mi id="S7.SS2.p1.1.m1.1.1.2" xref="S7.SS2.p1.1.m1.1.1.2.cmml">Ï„</mi><mo id="S7.SS2.p1.1.m1.1.1.1" xref="S7.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S7.SS2.p1.1.m1.1.1.3" xref="S7.SS2.p1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.1.m1.1b"><apply id="S7.SS2.p1.1.m1.1.1.cmml" xref="S7.SS2.p1.1.m1.1.1"><eq id="S7.SS2.p1.1.m1.1.1.1.cmml" xref="S7.SS2.p1.1.m1.1.1.1"></eq><ci id="S7.SS2.p1.1.m1.1.1.2.cmml" xref="S7.SS2.p1.1.m1.1.1.2">ğœ</ci><cn type="float" id="S7.SS2.p1.1.m1.1.1.3.cmml" xref="S7.SS2.p1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.1.m1.1c">\tau=0.5</annotation></semantics></math>, which have been further used in the experiments with sparse annotations (Section 4.2 from the paper).</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Randomly Initialized Representations</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">In Figure 5 from the paper, we visualize the feature representations produced by the view-level encoder after pre-training and supervised learning from scratch. As a baseline, in Figure <a href="#S7.F6" title="Figure 6 â€£ 7.3 Randomly Initialized Representations â€£ 7 Supplementary Materials â€£ Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we also demonstrate the t-SNE scatter plot right after random initialization of vier-level encoders, i.e. before any type of training has been applied to them. According to the figure, eGeMAPS-88 and wav2vec 2.0 representations have some initial structure. For wav2vec 2.0, this can be explained by the fact that this method has already been pre-trained on raw speech, whereas eGeMAPS-88 is a set of features that extract handcrafted features meaningful for recognizing emotions. In the case of the spectrograms, the initial representations do not reflect any patterns. Nevertheless, the proposed SSL pre-training strategy contributes to better grouping of representations bringing them closer to what can be achieved with fine-tuning or supervised training on the fully annotated dataset.</p>
</div>
<figure id="S7.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/figures/rand_w2v2_tsne.png" id="S7.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="645" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S7.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">wav2vec 2.0</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/figures/rand_spec_tsne.png" id="S7.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="645" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S7.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">Spectral</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S7.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.07900/assets/figures/rand_egemaps_tsne.png" id="S7.F6.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="645" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F6.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S7.F6.sf3.3.2" class="ltx_text" style="font-size:90%;">eGeMAPS-88</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S7.F6.3.2" class="ltx_text" style="font-size:90%;">Representations of randomly initialized view-level encoders from the test set projected onto 2D-space using t-SNE.</span></figcaption>
</figure>
</section>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.07899" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.07900" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.07900">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.07900" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.07901" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 17:51:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
