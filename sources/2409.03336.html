<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.03336] Estimating Indoor Scene Depth Maps from Ultrasonic Echoes</title><meta property="og:description" content="Measuring 3D geometric structures of indoor scenes requires dedicated depth sensors, which are not always available.
Echo-based depth estimation has recently been studied as a promising alternative solution.
All previo…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Estimating Indoor Scene Depth Maps from Ultrasonic Echoes">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Estimating Indoor Scene Depth Maps from Ultrasonic Echoes">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.03336">

<!--Generated on Sat Oct  5 19:51:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Estimating Indoor Scene Depth Maps from Ultrasonic Echoes</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Measuring 3D geometric structures of indoor scenes requires dedicated depth sensors, which are not always available.
Echo-based depth estimation has recently been studied as a promising alternative solution.
All previous studies have assumed the use of echoes in the audible range. However, one major problem is that audible echoes cannot be used in quiet spaces or other situations where producing audible sounds is prohibited.
In this paper, we consider echo-based depth estimation using inaudible ultrasonic echoes.
While ultrasonic waves provide high measurement accuracy in theory, the actual depth estimation accuracy when ultrasonic echoes are used has remained unclear, due to its disadvantage of being sensitive to noise and susceptible to attenuation.
We first investigate the depth estimation accuracy when the frequency of the sound source is restricted to the high-frequency band, and found that the accuracy decreased when the frequency was limited to ultrasonic ranges.
Based on this observation, we propose a novel deep learning method to improve the accuracy of ultrasonic echo-based depth estimation by using audible echoes as auxiliary data only during training.
Experimental results with a public dataset demonstrate that our method improves the estimation accuracy.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— </span></span>
Deep learning, echo-based depth estimation, ultrasonic echoes</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The geometric structure of a scene is essential for a variety of applications, including navigation, path planning for autonomous mobile robots, and spatial layout design for indoor scenes.
Measuring geometric structures requires specialized optical sensors to acquire the depth of a scene, such as infrared light, LiDARs, or specially configured camera devices such as stereo cameras.
However, such measurement devices are not always available as these are often costly and require strict setup conditions for accurate measurements.
While deep monocular depth estimation, which uses deep learning to estimate depth maps of scenes from monocular RGB images captured by ordinary cameras, has also been explored for a decade <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, there are many spaces where cameras cannot be used, such as dark rooms or spaces with privacy protection or legal restrictions.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.03336/assets/13-4.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="288" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span><span id="S1.F1.4.2" class="ltx_text ltx_font_bold">Overview of Our Idea.</span>
Top: All existing echo-based depth estimation methods use audible echo spectrograms during training and testing, which are not always used depending on the surrounding conditions of the target scene.
Bottom: In this paper, we aim to mitigate this problem by using inaudible ultrasonic echo spectrograms during testing.
Based on the observation that a straightforward approach that restricts the frequency band to the ultrasonic range leads to poor depth estimation accuracy, we propose an approach that uses audible echoes as auxiliary data only during training. We confirm that our method improves the depth estimation accuracy in terms of root mean squared error (RMSE) between the estimated and the ground truth depth maps.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this study, we consider echo-based depth estimation.
Suppose we have a microphone array consisting of multiple microphones at different spatial locations in the scene.
A known sound emitted from a sound source (i.e, loudspeaker) is reflected by surfaces such as walls, windows, furniture, etc., and arrives at each microphone.
The time of arrival to each microphone depends on geometric properties of the surfaces in the scene. That is, the time difference of arrival of the echoes contains information about the geometric structure of the scene.
The problem of recovering the depth map from the echoes is an inverse problem and is difficult to solve analytically, hence is usually solved using deep learning.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Several efforts on echo-based depth estimation have been reported in the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
These primarily focus on exploring effective network architectures for this task.
For example, the use of U-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, spatial pyramid pooling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, and bilinear attentions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> have been investigated.
Besides these, multi-modal approaches combined with RGB images have also been discussed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
However, one major drawback of the existing methods is that they all assume the use of audible echoes observed using audible sound sources.
Obtaining effective echoes that can stably acquire the 3D structure of an indoor scene requires generating sound loud enough to reverberate throughout the room.
Therefore, the existing methods cannot be used in rooms where generating audible sound is prohibited or where harmful effects on the surrounding environment or human body are concerned.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.2" class="ltx_p">In this paper, we examine echo-based depth estimation using inaudible ultrasonic sound sources. To the best of our knowledge, this is the first work to explore ultrasonic echo-based depth estimation.
On one hand, an ultrasonic wave has a short wavelength, which has a theoretical potential to provide high measurement accuracy.
On the other hand, however, a critical drawback is that it is sensitive to noise or interference and tends to attenuate quickly.
Due to this nature of ultrasonic echoes, practical applications of ultrasonic measurements in air have been mainly limited to point measurements within a short distance range (typically <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S1.p4.1.m1.1a"><mo id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><lt id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">&lt;</annotation></semantics></math> 1m), and the actual accuracy in depth estimation, which requires measurements of two-dimensional surfaces in a longer range (typically <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S1.p4.2.m2.1a"><mo id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><lt id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">&lt;</annotation></semantics></math> 10m <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>), has remained unknown.
Therefore, we first conduct preliminary experiments to investigate how the depth estimation accuracy changes when the frequency of the sound source is gradually limited from the audible range to the ultrasonic range.
From the results we found that the estimation accuracy decreased when the frequency range was limited to the ultrasonic band only (discussed later in Sec. <a href="#S2" title="2 PRELIMINARY EXPERIMENTS ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In light of the finding, we propose a novel deep learning method that uses audible echoes as auxiliary data only during training.
Our method generates synthetic echoes for training by linearly mixing the spectral information of ultrasonic and audible echoes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, and uses the synthetic echoes as auxiliary data (Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). This enables learning of a depth estimation network that is robust to missing audible frequency bands.
Experimental results with Replica <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, which is one of the most popular public datasets for echo-based depth estimation, demonstrate that our method improves the depth estimation accuracy using ultrasonic echoes.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>PRELIMINARY EXPERIMENTS</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We first conduct preliminary experiments to assess the viability of ultrasonic sound sources in the context of depth estimation for indoor scenes.
Specifically, we evaluate the depth estimation accuracy when the frequency band of the sound source is gradually limited toward the ultrasonic band.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2409.03336/assets/32.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="203" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.3.1.1" class="ltx_text ltx_font_bold">Fig. 2</span>: </span><span id="S2.F2.4.2" class="ltx_text ltx_font_bold">Echo-based Depth Estimation Framework.</span>
A known chirp signal is emitted to the indoor scene and spectrograms of the multi-channel echoes from the microphone array are extracted.
The features are fed into a convolutional neural network (CNN) to estimate the depth map of the scene.
The CNN is trained to minimize the RMSE between the estimated and ground truth depth maps.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Dataset</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.5" class="ltx_p">We consistently use Replica <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, one of the two standard public benchmark datasets for evaluating the accuracy of echo-based depth estimation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The other dataset, Matterport3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, does not provide room impulse responses that can reproduce ultrasonic bands so cannot be used for this paper.</span></span></span>.
Replica has data of a total of <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="18" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mn id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">18</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><cn type="integer" id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">18</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">18</annotation></semantics></math> indoor scenes covering hotels, apartments, office rooms, etc, and this has been used in research using machine learning for egocentric computer vision, semantic segmentation in 2D and 3D, and performing navigation development. For training and testing, we follow the official training-test split provided by the dataset publisher. The original Replica dataset publishes ground truth depth maps and binaural echoes for various spatial locations and orientations within each scene. However, the echoes provided are limited to audible range up to <math id="S2.SS1.p1.2.m2.2" class="ltx_Math" alttext="16,000" display="inline"><semantics id="S2.SS1.p1.2.m2.2a"><mrow id="S2.SS1.p1.2.m2.2.3.2" xref="S2.SS1.p1.2.m2.2.3.1.cmml"><mn id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">16</mn><mo id="S2.SS1.p1.2.m2.2.3.2.1" xref="S2.SS1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S2.SS1.p1.2.m2.2.2" xref="S2.SS1.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.2b"><list id="S2.SS1.p1.2.m2.2.3.1.cmml" xref="S2.SS1.p1.2.m2.2.3.2"><cn type="integer" id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">16</cn><cn type="integer" id="S2.SS1.p1.2.m2.2.2.cmml" xref="S2.SS1.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.2c">16,000</annotation></semantics></math> Hz, so experiments with ultrasonic echoes cannot be conducted.
We therefore synthesize ultrasonic echoes by using the room impulse responses (RIRs) associated with the Replica dataset.
The RIR is the echo observed at a certain location when an impulse signal is emitted at (another) location.
Hence, by convolving the RIR with the input sound emitted at the location of the sound source, the echo observed at a given location can be simulated.
More specifically, let <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="h(t)" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mrow id="S2.SS1.p1.3.m3.1.2" xref="S2.SS1.p1.3.m3.1.2.cmml"><mi id="S2.SS1.p1.3.m3.1.2.2" xref="S2.SS1.p1.3.m3.1.2.2.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p1.3.m3.1.2.1" xref="S2.SS1.p1.3.m3.1.2.1.cmml">​</mo><mrow id="S2.SS1.p1.3.m3.1.2.3.2" xref="S2.SS1.p1.3.m3.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.3.m3.1.2.3.2.1" xref="S2.SS1.p1.3.m3.1.2.cmml">(</mo><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p1.3.m3.1.2.3.2.2" xref="S2.SS1.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.2.cmml" xref="S2.SS1.p1.3.m3.1.2"><times id="S2.SS1.p1.3.m3.1.2.1.cmml" xref="S2.SS1.p1.3.m3.1.2.1"></times><ci id="S2.SS1.p1.3.m3.1.2.2.cmml" xref="S2.SS1.p1.3.m3.1.2.2">ℎ</ci><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">h(t)</annotation></semantics></math> and <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="x(t)" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.2" xref="S2.SS1.p1.4.m4.1.2.cmml"><mi id="S2.SS1.p1.4.m4.1.2.2" xref="S2.SS1.p1.4.m4.1.2.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p1.4.m4.1.2.1" xref="S2.SS1.p1.4.m4.1.2.1.cmml">​</mo><mrow id="S2.SS1.p1.4.m4.1.2.3.2" xref="S2.SS1.p1.4.m4.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.4.m4.1.2.3.2.1" xref="S2.SS1.p1.4.m4.1.2.cmml">(</mo><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p1.4.m4.1.2.3.2.2" xref="S2.SS1.p1.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.2.cmml" xref="S2.SS1.p1.4.m4.1.2"><times id="S2.SS1.p1.4.m4.1.2.1.cmml" xref="S2.SS1.p1.4.m4.1.2.1"></times><ci id="S2.SS1.p1.4.m4.1.2.2.cmml" xref="S2.SS1.p1.4.m4.1.2.2">𝑥</ci><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">x(t)</annotation></semantics></math> denote the RIR and the sound emitted at the location of the sound source, respectively. The echo <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="y(t)" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><mrow id="S2.SS1.p1.5.m5.1.2" xref="S2.SS1.p1.5.m5.1.2.cmml"><mi id="S2.SS1.p1.5.m5.1.2.2" xref="S2.SS1.p1.5.m5.1.2.2.cmml">y</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p1.5.m5.1.2.1" xref="S2.SS1.p1.5.m5.1.2.1.cmml">​</mo><mrow id="S2.SS1.p1.5.m5.1.2.3.2" xref="S2.SS1.p1.5.m5.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.5.m5.1.2.3.2.1" xref="S2.SS1.p1.5.m5.1.2.cmml">(</mo><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">t</mi><mo stretchy="false" id="S2.SS1.p1.5.m5.1.2.3.2.2" xref="S2.SS1.p1.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.2.cmml" xref="S2.SS1.p1.5.m5.1.2"><times id="S2.SS1.p1.5.m5.1.2.1.cmml" xref="S2.SS1.p1.5.m5.1.2.1"></times><ci id="S2.SS1.p1.5.m5.1.2.2.cmml" xref="S2.SS1.p1.5.m5.1.2.2">𝑦</ci><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">y(t)</annotation></semantics></math> is simulated by the following equation.</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.3" class="ltx_Math" alttext="y(t)=\sum^{t}_{k=0}h(t-k)x(k)" display="block"><semantics id="S2.E1.m1.3a"><mrow id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml"><mrow id="S2.E1.m1.3.3.3" xref="S2.E1.m1.3.3.3.cmml"><mi id="S2.E1.m1.3.3.3.2" xref="S2.E1.m1.3.3.3.2.cmml">y</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.3.1" xref="S2.E1.m1.3.3.3.1.cmml">​</mo><mrow id="S2.E1.m1.3.3.3.3.2" xref="S2.E1.m1.3.3.3.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.3.3.2.1" xref="S2.E1.m1.3.3.3.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">t</mi><mo stretchy="false" id="S2.E1.m1.3.3.3.3.2.2" xref="S2.E1.m1.3.3.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S2.E1.m1.3.3.2" xref="S2.E1.m1.3.3.2.cmml">=</mo><mrow id="S2.E1.m1.3.3.1" xref="S2.E1.m1.3.3.1.cmml"><munderover id="S2.E1.m1.3.3.1.2" xref="S2.E1.m1.3.3.1.2.cmml"><mo movablelimits="false" id="S2.E1.m1.3.3.1.2.2.2" xref="S2.E1.m1.3.3.1.2.2.2.cmml">∑</mo><mrow id="S2.E1.m1.3.3.1.2.3" xref="S2.E1.m1.3.3.1.2.3.cmml"><mi id="S2.E1.m1.3.3.1.2.3.2" xref="S2.E1.m1.3.3.1.2.3.2.cmml">k</mi><mo id="S2.E1.m1.3.3.1.2.3.1" xref="S2.E1.m1.3.3.1.2.3.1.cmml">=</mo><mn id="S2.E1.m1.3.3.1.2.3.3" xref="S2.E1.m1.3.3.1.2.3.3.cmml">0</mn></mrow><mi id="S2.E1.m1.3.3.1.2.2.3" xref="S2.E1.m1.3.3.1.2.2.3.cmml">t</mi></munderover><mrow id="S2.E1.m1.3.3.1.1" xref="S2.E1.m1.3.3.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.3" xref="S2.E1.m1.3.3.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2" xref="S2.E1.m1.3.3.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.3.3.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.1.2.cmml">t</mi><mo id="S2.E1.m1.3.3.1.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.1.cmml">−</mo><mi id="S2.E1.m1.3.3.1.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.1.3.cmml">k</mi></mrow><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2a" xref="S2.E1.m1.3.3.1.1.2.cmml">​</mo><mi id="S2.E1.m1.3.3.1.1.4" xref="S2.E1.m1.3.3.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2b" xref="S2.E1.m1.3.3.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.3.3.1.1.5.2" xref="S2.E1.m1.3.3.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.5.2.1" xref="S2.E1.m1.3.3.1.1.cmml">(</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">k</mi><mo stretchy="false" id="S2.E1.m1.3.3.1.1.5.2.2" xref="S2.E1.m1.3.3.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.3b"><apply id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3"><eq id="S2.E1.m1.3.3.2.cmml" xref="S2.E1.m1.3.3.2"></eq><apply id="S2.E1.m1.3.3.3.cmml" xref="S2.E1.m1.3.3.3"><times id="S2.E1.m1.3.3.3.1.cmml" xref="S2.E1.m1.3.3.3.1"></times><ci id="S2.E1.m1.3.3.3.2.cmml" xref="S2.E1.m1.3.3.3.2">𝑦</ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝑡</ci></apply><apply id="S2.E1.m1.3.3.1.cmml" xref="S2.E1.m1.3.3.1"><apply id="S2.E1.m1.3.3.1.2.cmml" xref="S2.E1.m1.3.3.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.2.1.cmml" xref="S2.E1.m1.3.3.1.2">subscript</csymbol><apply id="S2.E1.m1.3.3.1.2.2.cmml" xref="S2.E1.m1.3.3.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.2.2.1.cmml" xref="S2.E1.m1.3.3.1.2">superscript</csymbol><sum id="S2.E1.m1.3.3.1.2.2.2.cmml" xref="S2.E1.m1.3.3.1.2.2.2"></sum><ci id="S2.E1.m1.3.3.1.2.2.3.cmml" xref="S2.E1.m1.3.3.1.2.2.3">𝑡</ci></apply><apply id="S2.E1.m1.3.3.1.2.3.cmml" xref="S2.E1.m1.3.3.1.2.3"><eq id="S2.E1.m1.3.3.1.2.3.1.cmml" xref="S2.E1.m1.3.3.1.2.3.1"></eq><ci id="S2.E1.m1.3.3.1.2.3.2.cmml" xref="S2.E1.m1.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.E1.m1.3.3.1.2.3.3.cmml" xref="S2.E1.m1.3.3.1.2.3.3">0</cn></apply></apply><apply id="S2.E1.m1.3.3.1.1.cmml" xref="S2.E1.m1.3.3.1.1"><times id="S2.E1.m1.3.3.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.2"></times><ci id="S2.E1.m1.3.3.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.3">ℎ</ci><apply id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><minus id="S2.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.1"></minus><ci id="S2.E1.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.2">𝑡</ci><ci id="S2.E1.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.3">𝑘</ci></apply><ci id="S2.E1.m1.3.3.1.1.4.cmml" xref="S2.E1.m1.3.3.1.1.4">𝑥</ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.3c">y(t)=\sum^{t}_{k=0}h(t-k)x(k)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.9" class="ltx_p">We use a chirp that varied from <math id="S2.SS1.p1.6.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.SS1.p1.6.m1.1a"><mn id="S2.SS1.p1.6.m1.1.1" xref="S2.SS1.p1.6.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m1.1b"><cn type="integer" id="S2.SS1.p1.6.m1.1.1.cmml" xref="S2.SS1.p1.6.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m1.1c">1</annotation></semantics></math> Hz to <math id="S2.SS1.p1.7.m2.2" class="ltx_Math" alttext="22,050" display="inline"><semantics id="S2.SS1.p1.7.m2.2a"><mrow id="S2.SS1.p1.7.m2.2.3.2" xref="S2.SS1.p1.7.m2.2.3.1.cmml"><mn id="S2.SS1.p1.7.m2.1.1" xref="S2.SS1.p1.7.m2.1.1.cmml">22</mn><mo id="S2.SS1.p1.7.m2.2.3.2.1" xref="S2.SS1.p1.7.m2.2.3.1.cmml">,</mo><mn id="S2.SS1.p1.7.m2.2.2" xref="S2.SS1.p1.7.m2.2.2.cmml">050</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m2.2b"><list id="S2.SS1.p1.7.m2.2.3.1.cmml" xref="S2.SS1.p1.7.m2.2.3.2"><cn type="integer" id="S2.SS1.p1.7.m2.1.1.cmml" xref="S2.SS1.p1.7.m2.1.1">22</cn><cn type="integer" id="S2.SS1.p1.7.m2.2.2.cmml" xref="S2.SS1.p1.7.m2.2.2">050</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m2.2c">22,050</annotation></semantics></math> Hz in <math id="S2.SS1.p1.8.m3.1" class="ltx_Math" alttext="0.05" display="inline"><semantics id="S2.SS1.p1.8.m3.1a"><mn id="S2.SS1.p1.8.m3.1.1" xref="S2.SS1.p1.8.m3.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m3.1b"><cn type="float" id="S2.SS1.p1.8.m3.1.1.cmml" xref="S2.SS1.p1.8.m3.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m3.1c">0.05</annotation></semantics></math> seconds as the sound source and apply a high-pass filter to it to limit the frequency range. In order to account for higher-order reverberation components, we use a sampling frequency of 44,100 Hz and a sufficiently long period of recording time (<math id="S2.SS1.p1.9.m4.1" class="ltx_Math" alttext="0.12" display="inline"><semantics id="S2.SS1.p1.9.m4.1a"><mn id="S2.SS1.p1.9.m4.1.1" xref="S2.SS1.p1.9.m4.1.1.cmml">0.12</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m4.1b"><cn type="float" id="S2.SS1.p1.9.m4.1.1.cmml" xref="S2.SS1.p1.9.m4.1.1">0.12</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m4.1c">0.12</annotation></semantics></math> seconds).
The synthesized echoes are used as input for estimation, and the depth map provided by the original Replica dataset is used as the ground truth output.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Depth Estimation Method</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.3" class="ltx_p">We design our depth estimation framework shown in Fig <a href="#S2.F2" title="Figure 2 ‣ 2 PRELIMINARY EXPERIMENTS ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> by following the state-of-the-art echo-based depth estimation method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Note that several more recent echo-based depth estimation methods have been proposed  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> but these methods are not applicable to our problem because they assume that special images other than echoes are available as input (stereo images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, RGB-D images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, and spherical images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>).
First, the short-time Fourier transform (STFT) is applied to the binaural echoes generated by the procedure described in Sec. <a href="#S2.SS1" title="2.1 Dataset ‣ 2 PRELIMINARY EXPERIMENTS ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a> to get the spectrograms of the observed echoes.
The upper limit of the effective frequency is limited to <math id="S2.SS2.p1.1.m1.2" class="ltx_Math" alttext="22,050" display="inline"><semantics id="S2.SS2.p1.1.m1.2a"><mrow id="S2.SS2.p1.1.m1.2.3.2" xref="S2.SS2.p1.1.m1.2.3.1.cmml"><mn id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">22</mn><mo id="S2.SS2.p1.1.m1.2.3.2.1" xref="S2.SS2.p1.1.m1.2.3.1.cmml">,</mo><mn id="S2.SS2.p1.1.m1.2.2" xref="S2.SS2.p1.1.m1.2.2.cmml">050</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.2b"><list id="S2.SS2.p1.1.m1.2.3.1.cmml" xref="S2.SS2.p1.1.m1.2.3.2"><cn type="integer" id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">22</cn><cn type="integer" id="S2.SS2.p1.1.m1.2.2.cmml" xref="S2.SS2.p1.1.m1.2.2">050</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.2c">22,050</annotation></semantics></math> Hz based on the sampling theorem. The depth map is estimated by using a depth estimation network from the obtained spectrograms. For the depth estimation network architecture, we use exactly the same architecture as EchoNet used in a recent echo-based depth estimation method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, which is an encoder-decoder type CNN consisting of three convolution layers and seven deconvolution layers. We train it by Adam for <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><mn id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><cn type="integer" id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">300</annotation></semantics></math> epochs with the batch size of 8 and the learning rate of <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="0.0001" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><mn id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml">0.0001</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><cn type="float" id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">0.0001</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">0.0001</annotation></semantics></math>.
The CNN is trained to recover the ground truth depth map from the spectrograms by minimizing the RMSE between the estimated and the ground truth depth maps.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2409.03336/assets/30.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="352" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.3.1.1" class="ltx_text ltx_font_bold">Fig. 3</span>: </span><span id="S2.F3.4.2" class="ltx_text ltx_font_bold">Results of Preliminary Experiments.</span> RMSE values of all the frequency setups (lower is better). The blue and orange bars indicate the results using audible and ultrasonic sound sources, respectively.</figcaption>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Results</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.9" class="ltx_p">We evaluate the depth estimation accuracy in terms of RMSE between the estimated and ground truth depth maps. We basically follow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> on the training protocols.
We report the average of five runs with different random seeds.
To evaluate the estimation accuracy with echoes in different frequency bands, we use the following eight cutoff settings of the high-pass filter: <math id="S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S2.SS3.p1.1.m1.1a"><mn id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><cn type="integer" id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">1</annotation></semantics></math> Hz, <math id="S2.SS3.p1.2.m2.2" class="ltx_Math" alttext="15,000" display="inline"><semantics id="S2.SS3.p1.2.m2.2a"><mrow id="S2.SS3.p1.2.m2.2.3.2" xref="S2.SS3.p1.2.m2.2.3.1.cmml"><mn id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">15</mn><mo id="S2.SS3.p1.2.m2.2.3.2.1" xref="S2.SS3.p1.2.m2.2.3.1.cmml">,</mo><mn id="S2.SS3.p1.2.m2.2.2" xref="S2.SS3.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.2b"><list id="S2.SS3.p1.2.m2.2.3.1.cmml" xref="S2.SS3.p1.2.m2.2.3.2"><cn type="integer" id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">15</cn><cn type="integer" id="S2.SS3.p1.2.m2.2.2.cmml" xref="S2.SS3.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.2c">15,000</annotation></semantics></math> Hz, <math id="S2.SS3.p1.3.m3.2" class="ltx_Math" alttext="17,500" display="inline"><semantics id="S2.SS3.p1.3.m3.2a"><mrow id="S2.SS3.p1.3.m3.2.3.2" xref="S2.SS3.p1.3.m3.2.3.1.cmml"><mn id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml">17</mn><mo id="S2.SS3.p1.3.m3.2.3.2.1" xref="S2.SS3.p1.3.m3.2.3.1.cmml">,</mo><mn id="S2.SS3.p1.3.m3.2.2" xref="S2.SS3.p1.3.m3.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.2b"><list id="S2.SS3.p1.3.m3.2.3.1.cmml" xref="S2.SS3.p1.3.m3.2.3.2"><cn type="integer" id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">17</cn><cn type="integer" id="S2.SS3.p1.3.m3.2.2.cmml" xref="S2.SS3.p1.3.m3.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.2c">17,500</annotation></semantics></math> Hz, <math id="S2.SS3.p1.4.m4.2" class="ltx_Math" alttext="19,000" display="inline"><semantics id="S2.SS3.p1.4.m4.2a"><mrow id="S2.SS3.p1.4.m4.2.3.2" xref="S2.SS3.p1.4.m4.2.3.1.cmml"><mn id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml">19</mn><mo id="S2.SS3.p1.4.m4.2.3.2.1" xref="S2.SS3.p1.4.m4.2.3.1.cmml">,</mo><mn id="S2.SS3.p1.4.m4.2.2" xref="S2.SS3.p1.4.m4.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.2b"><list id="S2.SS3.p1.4.m4.2.3.1.cmml" xref="S2.SS3.p1.4.m4.2.3.2"><cn type="integer" id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1">19</cn><cn type="integer" id="S2.SS3.p1.4.m4.2.2.cmml" xref="S2.SS3.p1.4.m4.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.2c">19,000</annotation></semantics></math> Hz, <math id="S2.SS3.p1.5.m5.2" class="ltx_Math" alttext="19,500" display="inline"><semantics id="S2.SS3.p1.5.m5.2a"><mrow id="S2.SS3.p1.5.m5.2.3.2" xref="S2.SS3.p1.5.m5.2.3.1.cmml"><mn id="S2.SS3.p1.5.m5.1.1" xref="S2.SS3.p1.5.m5.1.1.cmml">19</mn><mo id="S2.SS3.p1.5.m5.2.3.2.1" xref="S2.SS3.p1.5.m5.2.3.1.cmml">,</mo><mn id="S2.SS3.p1.5.m5.2.2" xref="S2.SS3.p1.5.m5.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.5.m5.2b"><list id="S2.SS3.p1.5.m5.2.3.1.cmml" xref="S2.SS3.p1.5.m5.2.3.2"><cn type="integer" id="S2.SS3.p1.5.m5.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1">19</cn><cn type="integer" id="S2.SS3.p1.5.m5.2.2.cmml" xref="S2.SS3.p1.5.m5.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.5.m5.2c">19,500</annotation></semantics></math> Hz, <math id="S2.SS3.p1.6.m6.2" class="ltx_Math" alttext="20,000" display="inline"><semantics id="S2.SS3.p1.6.m6.2a"><mrow id="S2.SS3.p1.6.m6.2.3.2" xref="S2.SS3.p1.6.m6.2.3.1.cmml"><mn id="S2.SS3.p1.6.m6.1.1" xref="S2.SS3.p1.6.m6.1.1.cmml">20</mn><mo id="S2.SS3.p1.6.m6.2.3.2.1" xref="S2.SS3.p1.6.m6.2.3.1.cmml">,</mo><mn id="S2.SS3.p1.6.m6.2.2" xref="S2.SS3.p1.6.m6.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.6.m6.2b"><list id="S2.SS3.p1.6.m6.2.3.1.cmml" xref="S2.SS3.p1.6.m6.2.3.2"><cn type="integer" id="S2.SS3.p1.6.m6.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1">20</cn><cn type="integer" id="S2.SS3.p1.6.m6.2.2.cmml" xref="S2.SS3.p1.6.m6.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.6.m6.2c">20,000</annotation></semantics></math> Hz, <math id="S2.SS3.p1.7.m7.2" class="ltx_Math" alttext="21,000" display="inline"><semantics id="S2.SS3.p1.7.m7.2a"><mrow id="S2.SS3.p1.7.m7.2.3.2" xref="S2.SS3.p1.7.m7.2.3.1.cmml"><mn id="S2.SS3.p1.7.m7.1.1" xref="S2.SS3.p1.7.m7.1.1.cmml">21</mn><mo id="S2.SS3.p1.7.m7.2.3.2.1" xref="S2.SS3.p1.7.m7.2.3.1.cmml">,</mo><mn id="S2.SS3.p1.7.m7.2.2" xref="S2.SS3.p1.7.m7.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.7.m7.2b"><list id="S2.SS3.p1.7.m7.2.3.1.cmml" xref="S2.SS3.p1.7.m7.2.3.2"><cn type="integer" id="S2.SS3.p1.7.m7.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1">21</cn><cn type="integer" id="S2.SS3.p1.7.m7.2.2.cmml" xref="S2.SS3.p1.7.m7.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.7.m7.2c">21,000</annotation></semantics></math> Hz, <math id="S2.SS3.p1.8.m8.2" class="ltx_Math" alttext="22,000" display="inline"><semantics id="S2.SS3.p1.8.m8.2a"><mrow id="S2.SS3.p1.8.m8.2.3.2" xref="S2.SS3.p1.8.m8.2.3.1.cmml"><mn id="S2.SS3.p1.8.m8.1.1" xref="S2.SS3.p1.8.m8.1.1.cmml">22</mn><mo id="S2.SS3.p1.8.m8.2.3.2.1" xref="S2.SS3.p1.8.m8.2.3.1.cmml">,</mo><mn id="S2.SS3.p1.8.m8.2.2" xref="S2.SS3.p1.8.m8.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.8.m8.2b"><list id="S2.SS3.p1.8.m8.2.3.1.cmml" xref="S2.SS3.p1.8.m8.2.3.2"><cn type="integer" id="S2.SS3.p1.8.m8.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1">22</cn><cn type="integer" id="S2.SS3.p1.8.m8.2.2.cmml" xref="S2.SS3.p1.8.m8.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.8.m8.2c">22,000</annotation></semantics></math> Hz. <math id="S2.SS3.p1.9.m9.2" class="ltx_Math" alttext="20,000" display="inline"><semantics id="S2.SS3.p1.9.m9.2a"><mrow id="S2.SS3.p1.9.m9.2.3.2" xref="S2.SS3.p1.9.m9.2.3.1.cmml"><mn id="S2.SS3.p1.9.m9.1.1" xref="S2.SS3.p1.9.m9.1.1.cmml">20</mn><mo id="S2.SS3.p1.9.m9.2.3.2.1" xref="S2.SS3.p1.9.m9.2.3.1.cmml">,</mo><mn id="S2.SS3.p1.9.m9.2.2" xref="S2.SS3.p1.9.m9.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.9.m9.2b"><list id="S2.SS3.p1.9.m9.2.3.1.cmml" xref="S2.SS3.p1.9.m9.2.3.2"><cn type="integer" id="S2.SS3.p1.9.m9.1.1.cmml" xref="S2.SS3.p1.9.m9.1.1">20</cn><cn type="integer" id="S2.SS3.p1.9.m9.2.2.cmml" xref="S2.SS3.p1.9.m9.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.9.m9.2c">20,000</annotation></semantics></math> Hz and above are considered ultrasonic, so three out of the eight settings of the bands correspond to the ultrasonic cases.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.2" class="ltx_p">The results are shown in Fig. <a href="#S2.F3" title="Figure 3 ‣ 2.2 Depth Estimation Method ‣ 2 PRELIMINARY EXPERIMENTS ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Up to <math id="S2.SS3.p2.1.m1.2" class="ltx_Math" alttext="19,500" display="inline"><semantics id="S2.SS3.p2.1.m1.2a"><mrow id="S2.SS3.p2.1.m1.2.3.2" xref="S2.SS3.p2.1.m1.2.3.1.cmml"><mn id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">19</mn><mo id="S2.SS3.p2.1.m1.2.3.2.1" xref="S2.SS3.p2.1.m1.2.3.1.cmml">,</mo><mn id="S2.SS3.p2.1.m1.2.2" xref="S2.SS3.p2.1.m1.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.2b"><list id="S2.SS3.p2.1.m1.2.3.1.cmml" xref="S2.SS3.p2.1.m1.2.3.2"><cn type="integer" id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">19</cn><cn type="integer" id="S2.SS3.p2.1.m1.2.2.cmml" xref="S2.SS3.p2.1.m1.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.2c">19,500</annotation></semantics></math> Hz, the accuracy tends to be improved (i.e., RMSE decreases) as the frequency band is limited.
This may be due to the dominance of the high-frequency band, which has high measurement accuracy in theory.
However, as the frequency band is further restricted above <math id="S2.SS3.p2.2.m2.2" class="ltx_Math" alttext="20,000" display="inline"><semantics id="S2.SS3.p2.2.m2.2a"><mrow id="S2.SS3.p2.2.m2.2.3.2" xref="S2.SS3.p2.2.m2.2.3.1.cmml"><mn id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml">20</mn><mo id="S2.SS3.p2.2.m2.2.3.2.1" xref="S2.SS3.p2.2.m2.2.3.1.cmml">,</mo><mn id="S2.SS3.p2.2.m2.2.2" xref="S2.SS3.p2.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.2b"><list id="S2.SS3.p2.2.m2.2.3.1.cmml" xref="S2.SS3.p2.2.m2.2.3.2"><cn type="integer" id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">20</cn><cn type="integer" id="S2.SS3.p2.2.m2.2.2.cmml" xref="S2.SS3.p2.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.2c">20,000</annotation></semantics></math> Hz, the accuracy is observed to decrease.
The reason may be due to a decrease in power in the ultrasonic band due to the effect of attenuation and a decrease in the amount of information due to the limitation of the frequency band.
To conclude, we observed that the depth estimation accuracy decreased with the ultrasonic band only, and improved with a slightly lower frequency band included.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2409.03336/assets/33.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="290" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F4.5.1.1" class="ltx_text ltx_font_bold">Fig. 4</span>: </span><span id="S2.F4.6.2" class="ltx_text ltx_font_bold">Our Method.</span> Generate an augmented echo by fusing an ultrasonic echo and an audible echo with a lower frequency band.
Learning is performed to minimize the weighted sum of the two losses evaluated for the two depth maps estimated using ultrasonic and augmented echoes, respectively.
The weight <math id="S2.F4.2.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S2.F4.2.m1.1b"><mi id="S2.F4.2.m1.1.1" xref="S2.F4.2.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S2.F4.2.m1.1c"><ci id="S2.F4.2.m1.1.1.cmml" xref="S2.F4.2.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F4.2.m1.1d">\lambda</annotation></semantics></math> is scheduled as the learning proceeds.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Based on the results of the preliminary experiments reported above, we propose a novel deep learning method to improve ultrasonic echo-based depth estimation.
The overview of the proposed method is illustrated in Fig. <a href="#S2.F4" title="Figure 4 ‣ 2.3 Results ‣ 2 PRELIMINARY EXPERIMENTS ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
The key idea is to use audible echoes obtained from lower-frequency audible sounds only during training, with the aim of obtaining a depth estimation network robust to missing lower-frequency bands.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Auxiliary Echo Generation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.11" class="ltx_p">The core of the proposed method is to generate an “augmented echo” synthesized by combining the spectrograms of the ultrasonic echo obtained from an ultrasonic source and of an auxiliary lower-frequency echo obtained from an audible source.
The combination is performed in the Mixup data augmentation manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> as follows.</p>
<table id="S5.EGx1" class="ltx_equationgroup ltx_eqn_eqnarray ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\displaystyle X_{a}" display="inline"><semantics id="S3.E2.m1.1a"><msub id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mi id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">X</mi><mi id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2">𝑋</ci><ci id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle X_{a}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S3.E2.m2.1" class="ltx_Math" alttext="\displaystyle=" display="inline"><semantics id="S3.E2.m2.1a"><mo id="S3.E2.m2.1.1" xref="S3.E2.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.E2.m2.1b"><eq id="S3.E2.m2.1.1.cmml" xref="S3.E2.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m2.1c">\displaystyle=</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2.m3.1" class="ltx_Math" alttext="\displaystyle\alpha X_{u}+(1-\alpha)X_{l}," display="inline"><semantics id="S3.E2.m3.1a"><mrow id="S3.E2.m3.1.1.1" xref="S3.E2.m3.1.1.1.1.cmml"><mrow id="S3.E2.m3.1.1.1.1" xref="S3.E2.m3.1.1.1.1.cmml"><mrow id="S3.E2.m3.1.1.1.1.3" xref="S3.E2.m3.1.1.1.1.3.cmml"><mi id="S3.E2.m3.1.1.1.1.3.2" xref="S3.E2.m3.1.1.1.1.3.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S3.E2.m3.1.1.1.1.3.1" xref="S3.E2.m3.1.1.1.1.3.1.cmml">​</mo><msub id="S3.E2.m3.1.1.1.1.3.3" xref="S3.E2.m3.1.1.1.1.3.3.cmml"><mi id="S3.E2.m3.1.1.1.1.3.3.2" xref="S3.E2.m3.1.1.1.1.3.3.2.cmml">X</mi><mi id="S3.E2.m3.1.1.1.1.3.3.3" xref="S3.E2.m3.1.1.1.1.3.3.3.cmml">u</mi></msub></mrow><mo id="S3.E2.m3.1.1.1.1.2" xref="S3.E2.m3.1.1.1.1.2.cmml">+</mo><mrow id="S3.E2.m3.1.1.1.1.1" xref="S3.E2.m3.1.1.1.1.1.cmml"><mrow id="S3.E2.m3.1.1.1.1.1.1.1" xref="S3.E2.m3.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m3.1.1.1.1.1.1.1.2" xref="S3.E2.m3.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m3.1.1.1.1.1.1.1.1" xref="S3.E2.m3.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E2.m3.1.1.1.1.1.1.1.1.2" xref="S3.E2.m3.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E2.m3.1.1.1.1.1.1.1.1.1" xref="S3.E2.m3.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E2.m3.1.1.1.1.1.1.1.1.3" xref="S3.E2.m3.1.1.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo stretchy="false" id="S3.E2.m3.1.1.1.1.1.1.1.3" xref="S3.E2.m3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m3.1.1.1.1.1.2" xref="S3.E2.m3.1.1.1.1.1.2.cmml">​</mo><msub id="S3.E2.m3.1.1.1.1.1.3" xref="S3.E2.m3.1.1.1.1.1.3.cmml"><mi id="S3.E2.m3.1.1.1.1.1.3.2" xref="S3.E2.m3.1.1.1.1.1.3.2.cmml">X</mi><mi id="S3.E2.m3.1.1.1.1.1.3.3" xref="S3.E2.m3.1.1.1.1.1.3.3.cmml">l</mi></msub></mrow></mrow><mo id="S3.E2.m3.1.1.1.2" xref="S3.E2.m3.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m3.1b"><apply id="S3.E2.m3.1.1.1.1.cmml" xref="S3.E2.m3.1.1.1"><plus id="S3.E2.m3.1.1.1.1.2.cmml" xref="S3.E2.m3.1.1.1.1.2"></plus><apply id="S3.E2.m3.1.1.1.1.3.cmml" xref="S3.E2.m3.1.1.1.1.3"><times id="S3.E2.m3.1.1.1.1.3.1.cmml" xref="S3.E2.m3.1.1.1.1.3.1"></times><ci id="S3.E2.m3.1.1.1.1.3.2.cmml" xref="S3.E2.m3.1.1.1.1.3.2">𝛼</ci><apply id="S3.E2.m3.1.1.1.1.3.3.cmml" xref="S3.E2.m3.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m3.1.1.1.1.3.3.1.cmml" xref="S3.E2.m3.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E2.m3.1.1.1.1.3.3.2.cmml" xref="S3.E2.m3.1.1.1.1.3.3.2">𝑋</ci><ci id="S3.E2.m3.1.1.1.1.3.3.3.cmml" xref="S3.E2.m3.1.1.1.1.3.3.3">𝑢</ci></apply></apply><apply id="S3.E2.m3.1.1.1.1.1.cmml" xref="S3.E2.m3.1.1.1.1.1"><times id="S3.E2.m3.1.1.1.1.1.2.cmml" xref="S3.E2.m3.1.1.1.1.1.2"></times><apply id="S3.E2.m3.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m3.1.1.1.1.1.1.1"><minus id="S3.E2.m3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m3.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E2.m3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m3.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E2.m3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m3.1.1.1.1.1.1.1.1.3">𝛼</ci></apply><apply id="S3.E2.m3.1.1.1.1.1.3.cmml" xref="S3.E2.m3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m3.1.1.1.1.1.3.1.cmml" xref="S3.E2.m3.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m3.1.1.1.1.1.3.2.cmml" xref="S3.E2.m3.1.1.1.1.1.3.2">𝑋</ci><ci id="S3.E2.m3.1.1.1.1.1.3.3.cmml" xref="S3.E2.m3.1.1.1.1.1.3.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m3.1c">\displaystyle\alpha X_{u}+(1-\alpha)X_{l},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\displaystyle Y_{a}" display="inline"><semantics id="S3.E3.m1.1a"><msub id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mi id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">Y</mi><mi id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2">𝑌</ci><ci id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\displaystyle Y_{a}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_eqn_cell"><math id="S3.E3.m2.1" class="ltx_Math" alttext="\displaystyle=" display="inline"><semantics id="S3.E3.m2.1a"><mo id="S3.E3.m2.1.1" xref="S3.E3.m2.1.1.cmml">=</mo><annotation-xml encoding="MathML-Content" id="S3.E3.m2.1b"><eq id="S3.E3.m2.1.1.cmml" xref="S3.E3.m2.1.1"></eq></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m2.1c">\displaystyle=</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E3.m3.1" class="ltx_Math" alttext="\displaystyle\alpha Y_{u}+(1-\alpha)Y_{l}." display="inline"><semantics id="S3.E3.m3.1a"><mrow id="S3.E3.m3.1.1.1" xref="S3.E3.m3.1.1.1.1.cmml"><mrow id="S3.E3.m3.1.1.1.1" xref="S3.E3.m3.1.1.1.1.cmml"><mrow id="S3.E3.m3.1.1.1.1.3" xref="S3.E3.m3.1.1.1.1.3.cmml"><mi id="S3.E3.m3.1.1.1.1.3.2" xref="S3.E3.m3.1.1.1.1.3.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S3.E3.m3.1.1.1.1.3.1" xref="S3.E3.m3.1.1.1.1.3.1.cmml">​</mo><msub id="S3.E3.m3.1.1.1.1.3.3" xref="S3.E3.m3.1.1.1.1.3.3.cmml"><mi id="S3.E3.m3.1.1.1.1.3.3.2" xref="S3.E3.m3.1.1.1.1.3.3.2.cmml">Y</mi><mi id="S3.E3.m3.1.1.1.1.3.3.3" xref="S3.E3.m3.1.1.1.1.3.3.3.cmml">u</mi></msub></mrow><mo id="S3.E3.m3.1.1.1.1.2" xref="S3.E3.m3.1.1.1.1.2.cmml">+</mo><mrow id="S3.E3.m3.1.1.1.1.1" xref="S3.E3.m3.1.1.1.1.1.cmml"><mrow id="S3.E3.m3.1.1.1.1.1.1.1" xref="S3.E3.m3.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m3.1.1.1.1.1.1.1.2" xref="S3.E3.m3.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m3.1.1.1.1.1.1.1.1" xref="S3.E3.m3.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E3.m3.1.1.1.1.1.1.1.1.2" xref="S3.E3.m3.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E3.m3.1.1.1.1.1.1.1.1.1" xref="S3.E3.m3.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E3.m3.1.1.1.1.1.1.1.1.3" xref="S3.E3.m3.1.1.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo stretchy="false" id="S3.E3.m3.1.1.1.1.1.1.1.3" xref="S3.E3.m3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m3.1.1.1.1.1.2" xref="S3.E3.m3.1.1.1.1.1.2.cmml">​</mo><msub id="S3.E3.m3.1.1.1.1.1.3" xref="S3.E3.m3.1.1.1.1.1.3.cmml"><mi id="S3.E3.m3.1.1.1.1.1.3.2" xref="S3.E3.m3.1.1.1.1.1.3.2.cmml">Y</mi><mi id="S3.E3.m3.1.1.1.1.1.3.3" xref="S3.E3.m3.1.1.1.1.1.3.3.cmml">l</mi></msub></mrow></mrow><mo lspace="0em" id="S3.E3.m3.1.1.1.2" xref="S3.E3.m3.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m3.1b"><apply id="S3.E3.m3.1.1.1.1.cmml" xref="S3.E3.m3.1.1.1"><plus id="S3.E3.m3.1.1.1.1.2.cmml" xref="S3.E3.m3.1.1.1.1.2"></plus><apply id="S3.E3.m3.1.1.1.1.3.cmml" xref="S3.E3.m3.1.1.1.1.3"><times id="S3.E3.m3.1.1.1.1.3.1.cmml" xref="S3.E3.m3.1.1.1.1.3.1"></times><ci id="S3.E3.m3.1.1.1.1.3.2.cmml" xref="S3.E3.m3.1.1.1.1.3.2">𝛼</ci><apply id="S3.E3.m3.1.1.1.1.3.3.cmml" xref="S3.E3.m3.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E3.m3.1.1.1.1.3.3.1.cmml" xref="S3.E3.m3.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E3.m3.1.1.1.1.3.3.2.cmml" xref="S3.E3.m3.1.1.1.1.3.3.2">𝑌</ci><ci id="S3.E3.m3.1.1.1.1.3.3.3.cmml" xref="S3.E3.m3.1.1.1.1.3.3.3">𝑢</ci></apply></apply><apply id="S3.E3.m3.1.1.1.1.1.cmml" xref="S3.E3.m3.1.1.1.1.1"><times id="S3.E3.m3.1.1.1.1.1.2.cmml" xref="S3.E3.m3.1.1.1.1.1.2"></times><apply id="S3.E3.m3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m3.1.1.1.1.1.1.1"><minus id="S3.E3.m3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m3.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E3.m3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m3.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E3.m3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m3.1.1.1.1.1.1.1.1.3">𝛼</ci></apply><apply id="S3.E3.m3.1.1.1.1.1.3.cmml" xref="S3.E3.m3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m3.1.1.1.1.1.3.1.cmml" xref="S3.E3.m3.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m3.1.1.1.1.1.3.2.cmml" xref="S3.E3.m3.1.1.1.1.1.3.2">𝑌</ci><ci id="S3.E3.m3.1.1.1.1.1.3.3.cmml" xref="S3.E3.m3.1.1.1.1.1.3.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m3.1c">\displaystyle\alpha Y_{u}+(1-\alpha)Y_{l}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.10" class="ltx_p"><math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="X_{u},X_{l}" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.2.2" xref="S3.SS1.p1.1.m1.2.2.3.cmml"><msub id="S3.SS1.p1.1.m1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.1.m1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.3.cmml">u</mi></msub><mo id="S3.SS1.p1.1.m1.2.2.2.3" xref="S3.SS1.p1.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.1.m1.2.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS1.p1.1.m1.2.2.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.2.2.cmml">X</mi><mi id="S3.SS1.p1.1.m1.2.2.2.2.3" xref="S3.SS1.p1.1.m1.2.2.2.2.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><list id="S3.SS1.p1.1.m1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.2"><apply id="S3.SS1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.2">𝑋</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.3">𝑢</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.2">𝑋</ci><ci id="S3.SS1.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.2.2.3">𝑙</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">X_{u},X_{l}</annotation></semantics></math> are the two spectrograms to be mixed; in our method, <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="X_{u}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝑋</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">X_{u}</annotation></semantics></math> and <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="X_{l}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑋</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">X_{l}</annotation></semantics></math> are the spectrograms of the ultrasonic echo and auxiliary lower-frequency echo, respectively.
<math id="S3.SS1.p1.4.m4.2" class="ltx_Math" alttext="Y_{u},Y_{l}" display="inline"><semantics id="S3.SS1.p1.4.m4.2a"><mrow id="S3.SS1.p1.4.m4.2.2.2" xref="S3.SS1.p1.4.m4.2.2.3.cmml"><msub id="S3.SS1.p1.4.m4.1.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.1.1.2" xref="S3.SS1.p1.4.m4.1.1.1.1.2.cmml">Y</mi><mi id="S3.SS1.p1.4.m4.1.1.1.1.3" xref="S3.SS1.p1.4.m4.1.1.1.1.3.cmml">u</mi></msub><mo id="S3.SS1.p1.4.m4.2.2.2.3" xref="S3.SS1.p1.4.m4.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.4.m4.2.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.2.cmml"><mi id="S3.SS1.p1.4.m4.2.2.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.2.2.cmml">Y</mi><mi id="S3.SS1.p1.4.m4.2.2.2.2.3" xref="S3.SS1.p1.4.m4.2.2.2.2.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.2b"><list id="S3.SS1.p1.4.m4.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2"><apply id="S3.SS1.p1.4.m4.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.2">𝑌</ci><ci id="S3.SS1.p1.4.m4.1.1.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.3">𝑢</ci></apply><apply id="S3.SS1.p1.4.m4.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.2.2.1.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.2.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2">𝑌</ci><ci id="S3.SS1.p1.4.m4.2.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.3">𝑙</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.2c">Y_{u},Y_{l}</annotation></semantics></math> are the corresponding ground truth depth maps.
<math id="S3.SS1.p1.5.m5.2" class="ltx_Math" alttext="X_{a},Y_{a}" display="inline"><semantics id="S3.SS1.p1.5.m5.2a"><mrow id="S3.SS1.p1.5.m5.2.2.2" xref="S3.SS1.p1.5.m5.2.2.3.cmml"><msub id="S3.SS1.p1.5.m5.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.1.1.2" xref="S3.SS1.p1.5.m5.1.1.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.5.m5.1.1.1.1.3" xref="S3.SS1.p1.5.m5.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.SS1.p1.5.m5.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.5.m5.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.cmml"><mi id="S3.SS1.p1.5.m5.2.2.2.2.2" xref="S3.SS1.p1.5.m5.2.2.2.2.2.cmml">Y</mi><mi id="S3.SS1.p1.5.m5.2.2.2.2.3" xref="S3.SS1.p1.5.m5.2.2.2.2.3.cmml">a</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.2b"><list id="S3.SS1.p1.5.m5.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2"><apply id="S3.SS1.p1.5.m5.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.2">𝑋</ci><ci id="S3.SS1.p1.5.m5.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.3">𝑎</ci></apply><apply id="S3.SS1.p1.5.m5.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.2.2.1.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.2">𝑌</ci><ci id="S3.SS1.p1.5.m5.2.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.2.2.2.2.3">𝑎</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.2c">X_{a},Y_{a}</annotation></semantics></math> are the synthesized spectrogram of the augmented echo and the ground truth depth map, respectively.
<math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\alpha</annotation></semantics></math> is the mixing ratio drawn from the uniform distribution on <math id="S3.SS1.p1.7.m7.2" class="ltx_Math" alttext="[0,1]" display="inline"><semantics id="S3.SS1.p1.7.m7.2a"><mrow id="S3.SS1.p1.7.m7.2.3.2" xref="S3.SS1.p1.7.m7.2.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.7.m7.2.3.2.1" xref="S3.SS1.p1.7.m7.2.3.1.cmml">[</mo><mn id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">0</mn><mo id="S3.SS1.p1.7.m7.2.3.2.2" xref="S3.SS1.p1.7.m7.2.3.1.cmml">,</mo><mn id="S3.SS1.p1.7.m7.2.2" xref="S3.SS1.p1.7.m7.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p1.7.m7.2.3.2.3" xref="S3.SS1.p1.7.m7.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.2b"><interval closure="closed" id="S3.SS1.p1.7.m7.2.3.1.cmml" xref="S3.SS1.p1.7.m7.2.3.2"><cn type="integer" id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">0</cn><cn type="integer" id="S3.SS1.p1.7.m7.2.2.cmml" xref="S3.SS1.p1.7.m7.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.2c">[0,1]</annotation></semantics></math>.
Note that our method always synthesizes two echoes observed at the same location and orientation, so the ground truth depth maps to be mixed are exactly the same, i.e.., <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="Y_{a}=Y_{u}=Y_{l}" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mrow id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><msub id="S3.SS1.p1.8.m8.1.1.2" xref="S3.SS1.p1.8.m8.1.1.2.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2.2" xref="S3.SS1.p1.8.m8.1.1.2.2.cmml">Y</mi><mi id="S3.SS1.p1.8.m8.1.1.2.3" xref="S3.SS1.p1.8.m8.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml">=</mo><msub id="S3.SS1.p1.8.m8.1.1.4" xref="S3.SS1.p1.8.m8.1.1.4.cmml"><mi id="S3.SS1.p1.8.m8.1.1.4.2" xref="S3.SS1.p1.8.m8.1.1.4.2.cmml">Y</mi><mi id="S3.SS1.p1.8.m8.1.1.4.3" xref="S3.SS1.p1.8.m8.1.1.4.3.cmml">u</mi></msub><mo id="S3.SS1.p1.8.m8.1.1.5" xref="S3.SS1.p1.8.m8.1.1.5.cmml">=</mo><msub id="S3.SS1.p1.8.m8.1.1.6" xref="S3.SS1.p1.8.m8.1.1.6.cmml"><mi id="S3.SS1.p1.8.m8.1.1.6.2" xref="S3.SS1.p1.8.m8.1.1.6.2.cmml">Y</mi><mi id="S3.SS1.p1.8.m8.1.1.6.3" xref="S3.SS1.p1.8.m8.1.1.6.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><and id="S3.SS1.p1.8.m8.1.1a.cmml" xref="S3.SS1.p1.8.m8.1.1"></and><apply id="S3.SS1.p1.8.m8.1.1b.cmml" xref="S3.SS1.p1.8.m8.1.1"><eq id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3"></eq><apply id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.2.1.cmml" xref="S3.SS1.p1.8.m8.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.2.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2.2">𝑌</ci><ci id="S3.SS1.p1.8.m8.1.1.2.3.cmml" xref="S3.SS1.p1.8.m8.1.1.2.3">𝑎</ci></apply><apply id="S3.SS1.p1.8.m8.1.1.4.cmml" xref="S3.SS1.p1.8.m8.1.1.4"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.4.1.cmml" xref="S3.SS1.p1.8.m8.1.1.4">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.4.2.cmml" xref="S3.SS1.p1.8.m8.1.1.4.2">𝑌</ci><ci id="S3.SS1.p1.8.m8.1.1.4.3.cmml" xref="S3.SS1.p1.8.m8.1.1.4.3">𝑢</ci></apply></apply><apply id="S3.SS1.p1.8.m8.1.1c.cmml" xref="S3.SS1.p1.8.m8.1.1"><eq id="S3.SS1.p1.8.m8.1.1.5.cmml" xref="S3.SS1.p1.8.m8.1.1.5"></eq><share href="#S3.SS1.p1.8.m8.1.1.4.cmml" id="S3.SS1.p1.8.m8.1.1d.cmml" xref="S3.SS1.p1.8.m8.1.1"></share><apply id="S3.SS1.p1.8.m8.1.1.6.cmml" xref="S3.SS1.p1.8.m8.1.1.6"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.6.1.cmml" xref="S3.SS1.p1.8.m8.1.1.6">subscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.6.2.cmml" xref="S3.SS1.p1.8.m8.1.1.6.2">𝑌</ci><ci id="S3.SS1.p1.8.m8.1.1.6.3.cmml" xref="S3.SS1.p1.8.m8.1.1.6.3">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">Y_{a}=Y_{u}=Y_{l}</annotation></semantics></math>. Hence, it is not necessary to explicitly mix the depth maps.
Since there is a concern that mixing two spectrograms with significantly different frequency bands may not provide effective augmented echoes for training, the proposed method limits the bandwidth difference between <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="X_{u}" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><msub id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">𝑋</ci><ci id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">X_{u}</annotation></semantics></math> and <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="X_{l}" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><msub id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><mi id="S3.SS1.p1.10.m10.1.1.2" xref="S3.SS1.p1.10.m10.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.10.m10.1.1.3" xref="S3.SS1.p1.10.m10.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2">𝑋</ci><ci id="S3.SS1.p1.10.m10.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">X_{l}</annotation></semantics></math> to 1,000 Hz or less.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2409.03336/assets/31_2.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.3.1.1" class="ltx_text ltx_font_bold">Fig. 5</span>: </span><span id="S3.F5.4.2" class="ltx_text ltx_font_bold">Quantitative Results.</span> RMSE values of the ultrasonic echo only, augmented echo only, and the proposed method (lower is better).</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Loss Configuration</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Our depth estimation network is trained with the RMSE loss. However, training the network with only the augmented echoes is not desirable.
The final goal is to improve the depth estimation accuracy when only the ultrasound echo is fed into the network.
Meanwhile, the synthesized augmented echoes always contain audible band spectra (except for the rare case where <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">α</mi><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><eq id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></eq><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝛼</ci><cn type="integer" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\alpha=1</annotation></semantics></math>), which are useful in the early stages of training but not suitable for its later stages.
Based on this idea, the proposed method uses a total loss function defined as a weighted combination of two (sub-)loss functions, one for ultrasonic echoes and the other for augmented echoes, and schedules the weight as the learning proceeds.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.3" class="ltx_p">Let <math id="S3.SS2.p2.1.m1.2" class="ltx_Math" alttext="\mathcal{L}_{u}(X_{u},Y_{u})" display="inline"><semantics id="S3.SS2.p2.1.m1.2a"><mrow id="S3.SS2.p2.1.m1.2.2" xref="S3.SS2.p2.1.m1.2.2.cmml"><msub id="S3.SS2.p2.1.m1.2.2.4" xref="S3.SS2.p2.1.m1.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.2.2.4.2" xref="S3.SS2.p2.1.m1.2.2.4.2.cmml">ℒ</mi><mi id="S3.SS2.p2.1.m1.2.2.4.3" xref="S3.SS2.p2.1.m1.2.2.4.3.cmml">u</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.2.2.3" xref="S3.SS2.p2.1.m1.2.2.3.cmml">​</mo><mrow id="S3.SS2.p2.1.m1.2.2.2.2" xref="S3.SS2.p2.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p2.1.m1.2.2.2.2.3" xref="S3.SS2.p2.1.m1.2.2.2.3.cmml">(</mo><msub id="S3.SS2.p2.1.m1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.3.cmml">u</mi></msub><mo id="S3.SS2.p2.1.m1.2.2.2.2.4" xref="S3.SS2.p2.1.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.1.m1.2.2.2.2.2" xref="S3.SS2.p2.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.1.m1.2.2.2.2.2.2" xref="S3.SS2.p2.1.m1.2.2.2.2.2.2.cmml">Y</mi><mi id="S3.SS2.p2.1.m1.2.2.2.2.2.3" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3.cmml">u</mi></msub><mo stretchy="false" id="S3.SS2.p2.1.m1.2.2.2.2.5" xref="S3.SS2.p2.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.2b"><apply id="S3.SS2.p2.1.m1.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2"><times id="S3.SS2.p2.1.m1.2.2.3.cmml" xref="S3.SS2.p2.1.m1.2.2.3"></times><apply id="S3.SS2.p2.1.m1.2.2.4.cmml" xref="S3.SS2.p2.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.2.2.4.1.cmml" xref="S3.SS2.p2.1.m1.2.2.4">subscript</csymbol><ci id="S3.SS2.p2.1.m1.2.2.4.2.cmml" xref="S3.SS2.p2.1.m1.2.2.4.2">ℒ</ci><ci id="S3.SS2.p2.1.m1.2.2.4.3.cmml" xref="S3.SS2.p2.1.m1.2.2.4.3">𝑢</ci></apply><interval closure="open" id="S3.SS2.p2.1.m1.2.2.2.3.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2"><apply id="S3.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.2">𝑋</ci><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.3">𝑢</ci></apply><apply id="S3.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2.2">𝑌</ci><ci id="S3.SS2.p2.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3">𝑢</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.2c">\mathcal{L}_{u}(X_{u},Y_{u})</annotation></semantics></math> be the loss function for ultrasonic echoes and <math id="S3.SS2.p2.2.m2.2" class="ltx_Math" alttext="\mathcal{L}_{a}(X_{a},Y_{a})" display="inline"><semantics id="S3.SS2.p2.2.m2.2a"><mrow id="S3.SS2.p2.2.m2.2.2" xref="S3.SS2.p2.2.m2.2.2.cmml"><msub id="S3.SS2.p2.2.m2.2.2.4" xref="S3.SS2.p2.2.m2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.2.m2.2.2.4.2" xref="S3.SS2.p2.2.m2.2.2.4.2.cmml">ℒ</mi><mi id="S3.SS2.p2.2.m2.2.2.4.3" xref="S3.SS2.p2.2.m2.2.2.4.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p2.2.m2.2.2.3" xref="S3.SS2.p2.2.m2.2.2.3.cmml">​</mo><mrow id="S3.SS2.p2.2.m2.2.2.2.2" xref="S3.SS2.p2.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p2.2.m2.2.2.2.2.3" xref="S3.SS2.p2.2.m2.2.2.2.3.cmml">(</mo><msub id="S3.SS2.p2.2.m2.1.1.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.1.1.1.2" xref="S3.SS2.p2.2.m2.1.1.1.1.1.2.cmml">X</mi><mi id="S3.SS2.p2.2.m2.1.1.1.1.1.3" xref="S3.SS2.p2.2.m2.1.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.SS2.p2.2.m2.2.2.2.2.4" xref="S3.SS2.p2.2.m2.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.2.m2.2.2.2.2.2" xref="S3.SS2.p2.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.2.m2.2.2.2.2.2.2" xref="S3.SS2.p2.2.m2.2.2.2.2.2.2.cmml">Y</mi><mi id="S3.SS2.p2.2.m2.2.2.2.2.2.3" xref="S3.SS2.p2.2.m2.2.2.2.2.2.3.cmml">a</mi></msub><mo stretchy="false" id="S3.SS2.p2.2.m2.2.2.2.2.5" xref="S3.SS2.p2.2.m2.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.2b"><apply id="S3.SS2.p2.2.m2.2.2.cmml" xref="S3.SS2.p2.2.m2.2.2"><times id="S3.SS2.p2.2.m2.2.2.3.cmml" xref="S3.SS2.p2.2.m2.2.2.3"></times><apply id="S3.SS2.p2.2.m2.2.2.4.cmml" xref="S3.SS2.p2.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.2.2.4.1.cmml" xref="S3.SS2.p2.2.m2.2.2.4">subscript</csymbol><ci id="S3.SS2.p2.2.m2.2.2.4.2.cmml" xref="S3.SS2.p2.2.m2.2.2.4.2">ℒ</ci><ci id="S3.SS2.p2.2.m2.2.2.4.3.cmml" xref="S3.SS2.p2.2.m2.2.2.4.3">𝑎</ci></apply><interval closure="open" id="S3.SS2.p2.2.m2.2.2.2.3.cmml" xref="S3.SS2.p2.2.m2.2.2.2.2"><apply id="S3.SS2.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.2">𝑋</ci><ci id="S3.SS2.p2.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.3">𝑎</ci></apply><apply id="S3.SS2.p2.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.p2.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.2.m2.2.2.2.2.2.2">𝑌</ci><ci id="S3.SS2.p2.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.2.m2.2.2.2.2.2.3">𝑎</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.2c">\mathcal{L}_{a}(X_{a},Y_{a})</annotation></semantics></math> be that for augmented echoes. Our total loss function <math id="S3.SS2.p2.3.m3.3" class="ltx_Math" alttext="\mathcal{L}(X_{u},X_{a},Y_{a})" display="inline"><semantics id="S3.SS2.p2.3.m3.3a"><mrow id="S3.SS2.p2.3.m3.3.3" xref="S3.SS2.p2.3.m3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.3.m3.3.3.5" xref="S3.SS2.p2.3.m3.3.3.5.cmml">ℒ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.3.3.4" xref="S3.SS2.p2.3.m3.3.3.4.cmml">​</mo><mrow id="S3.SS2.p2.3.m3.3.3.3.3" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml"><mo stretchy="false" id="S3.SS2.p2.3.m3.3.3.3.3.4" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml">(</mo><msub id="S3.SS2.p2.3.m3.1.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.2.cmml">X</mi><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.1.3.cmml">u</mi></msub><mo id="S3.SS2.p2.3.m3.3.3.3.3.5" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p2.3.m3.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.cmml"><mi id="S3.SS2.p2.3.m3.2.2.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2.cmml">X</mi><mi id="S3.SS2.p2.3.m3.2.2.2.2.2.3" xref="S3.SS2.p2.3.m3.2.2.2.2.2.3.cmml">a</mi></msub><mo id="S3.SS2.p2.3.m3.3.3.3.3.6" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml">,</mo><msub id="S3.SS2.p2.3.m3.3.3.3.3.3" xref="S3.SS2.p2.3.m3.3.3.3.3.3.cmml"><mi id="S3.SS2.p2.3.m3.3.3.3.3.3.2" xref="S3.SS2.p2.3.m3.3.3.3.3.3.2.cmml">Y</mi><mi id="S3.SS2.p2.3.m3.3.3.3.3.3.3" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3.cmml">a</mi></msub><mo stretchy="false" id="S3.SS2.p2.3.m3.3.3.3.3.7" xref="S3.SS2.p2.3.m3.3.3.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.3b"><apply id="S3.SS2.p2.3.m3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3"><times id="S3.SS2.p2.3.m3.3.3.4.cmml" xref="S3.SS2.p2.3.m3.3.3.4"></times><ci id="S3.SS2.p2.3.m3.3.3.5.cmml" xref="S3.SS2.p2.3.m3.3.3.5">ℒ</ci><vector id="S3.SS2.p2.3.m3.3.3.3.4.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3"><apply id="S3.SS2.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.2">𝑋</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.3">𝑢</ci></apply><apply id="S3.SS2.p2.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.2">𝑋</ci><ci id="S3.SS2.p2.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2.2.3">𝑎</ci></apply><apply id="S3.SS2.p2.3.m3.3.3.3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.3.3.3.3.3.1.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.3.m3.3.3.3.3.3.2.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3.2">𝑌</ci><ci id="S3.SS2.p2.3.m3.3.3.3.3.3.3.cmml" xref="S3.SS2.p2.3.m3.3.3.3.3.3.3">𝑎</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.3c">\mathcal{L}(X_{u},X_{a},Y_{a})</annotation></semantics></math> is defined as:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="\mathcal{L}(X_{u},X_{a},Y_{a})=\lambda\mathcal{L}_{a}(X_{a},Y_{a})+(1-\lambda)\mathcal{L}_{u}(X_{u},Y_{a})," display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.3.5" xref="S3.E4.m1.1.1.1.1.3.5.cmml">ℒ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.4" xref="S3.E4.m1.1.1.1.1.3.4.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.4.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.3.3.3.4" xref="S3.E4.m1.1.1.1.1.3.3.4.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml">u</mi></msub><mo id="S3.E4.m1.1.1.1.1.3.3.3.5" xref="S3.E4.m1.1.1.1.1.3.3.4.cmml">,</mo><msub id="S3.E4.m1.1.1.1.1.2.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.2.2.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.cmml">X</mi><mi id="S3.E4.m1.1.1.1.1.2.2.2.2.3" xref="S3.E4.m1.1.1.1.1.2.2.2.2.3.cmml">a</mi></msub><mo id="S3.E4.m1.1.1.1.1.3.3.3.6" xref="S3.E4.m1.1.1.1.1.3.3.4.cmml">,</mo><msub id="S3.E4.m1.1.1.1.1.3.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.3.3.2" xref="S3.E4.m1.1.1.1.1.3.3.3.3.2.cmml">Y</mi><mi id="S3.E4.m1.1.1.1.1.3.3.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.3.3.3.cmml">a</mi></msub><mo stretchy="false" id="S3.E4.m1.1.1.1.1.3.3.3.7" xref="S3.E4.m1.1.1.1.1.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.9" xref="S3.E4.m1.1.1.1.1.9.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.8" xref="S3.E4.m1.1.1.1.1.8.cmml"><mrow id="S3.E4.m1.1.1.1.1.5.2" xref="S3.E4.m1.1.1.1.1.5.2.cmml"><mi id="S3.E4.m1.1.1.1.1.5.2.4" xref="S3.E4.m1.1.1.1.1.5.2.4.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.5.2.3" xref="S3.E4.m1.1.1.1.1.5.2.3.cmml">​</mo><msub id="S3.E4.m1.1.1.1.1.5.2.5" xref="S3.E4.m1.1.1.1.1.5.2.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.5.2.5.2" xref="S3.E4.m1.1.1.1.1.5.2.5.2.cmml">ℒ</mi><mi id="S3.E4.m1.1.1.1.1.5.2.5.3" xref="S3.E4.m1.1.1.1.1.5.2.5.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.5.2.3a" xref="S3.E4.m1.1.1.1.1.5.2.3.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.5.2.2.2" xref="S3.E4.m1.1.1.1.1.5.2.2.3.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.5.2.2.2.3" xref="S3.E4.m1.1.1.1.1.5.2.2.3.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.4.1.1.1.1" xref="S3.E4.m1.1.1.1.1.4.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.4.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.4.1.1.1.1.2.cmml">X</mi><mi id="S3.E4.m1.1.1.1.1.4.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.4.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.E4.m1.1.1.1.1.5.2.2.2.4" xref="S3.E4.m1.1.1.1.1.5.2.2.3.cmml">,</mo><msub id="S3.E4.m1.1.1.1.1.5.2.2.2.2" xref="S3.E4.m1.1.1.1.1.5.2.2.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.5.2.2.2.2.2" xref="S3.E4.m1.1.1.1.1.5.2.2.2.2.2.cmml">Y</mi><mi id="S3.E4.m1.1.1.1.1.5.2.2.2.2.3" xref="S3.E4.m1.1.1.1.1.5.2.2.2.2.3.cmml">a</mi></msub><mo stretchy="false" id="S3.E4.m1.1.1.1.1.5.2.2.2.5" xref="S3.E4.m1.1.1.1.1.5.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.8.6" xref="S3.E4.m1.1.1.1.1.8.6.cmml">+</mo><mrow id="S3.E4.m1.1.1.1.1.8.5" xref="S3.E4.m1.1.1.1.1.8.5.cmml"><mrow id="S3.E4.m1.1.1.1.1.6.3.1.1" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.6.3.1.1.2" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.6.3.1.1.1" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.cmml"><mn id="S3.E4.m1.1.1.1.1.6.3.1.1.1.2" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.2.cmml">1</mn><mo id="S3.E4.m1.1.1.1.1.6.3.1.1.1.1" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.1.cmml">−</mo><mi id="S3.E4.m1.1.1.1.1.6.3.1.1.1.3" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.3.cmml">λ</mi></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.6.3.1.1.3" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.8.5.4" xref="S3.E4.m1.1.1.1.1.8.5.4.cmml">​</mo><msub id="S3.E4.m1.1.1.1.1.8.5.5" xref="S3.E4.m1.1.1.1.1.8.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.8.5.5.2" xref="S3.E4.m1.1.1.1.1.8.5.5.2.cmml">ℒ</mi><mi id="S3.E4.m1.1.1.1.1.8.5.5.3" xref="S3.E4.m1.1.1.1.1.8.5.5.3.cmml">u</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.8.5.4a" xref="S3.E4.m1.1.1.1.1.8.5.4.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.8.5.3.2" xref="S3.E4.m1.1.1.1.1.8.5.3.3.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.8.5.3.2.3" xref="S3.E4.m1.1.1.1.1.8.5.3.3.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.7.4.2.1.1" xref="S3.E4.m1.1.1.1.1.7.4.2.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.7.4.2.1.1.2" xref="S3.E4.m1.1.1.1.1.7.4.2.1.1.2.cmml">X</mi><mi id="S3.E4.m1.1.1.1.1.7.4.2.1.1.3" xref="S3.E4.m1.1.1.1.1.7.4.2.1.1.3.cmml">u</mi></msub><mo id="S3.E4.m1.1.1.1.1.8.5.3.2.4" xref="S3.E4.m1.1.1.1.1.8.5.3.3.cmml">,</mo><msub id="S3.E4.m1.1.1.1.1.8.5.3.2.2" xref="S3.E4.m1.1.1.1.1.8.5.3.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.8.5.3.2.2.2" xref="S3.E4.m1.1.1.1.1.8.5.3.2.2.2.cmml">Y</mi><mi id="S3.E4.m1.1.1.1.1.8.5.3.2.2.3" xref="S3.E4.m1.1.1.1.1.8.5.3.2.2.3.cmml">a</mi></msub><mo stretchy="false" id="S3.E4.m1.1.1.1.1.8.5.3.2.5" xref="S3.E4.m1.1.1.1.1.8.5.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.9.cmml" xref="S3.E4.m1.1.1.1.1.9"></eq><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><times id="S3.E4.m1.1.1.1.1.3.4.cmml" xref="S3.E4.m1.1.1.1.1.3.4"></times><ci id="S3.E4.m1.1.1.1.1.3.5.cmml" xref="S3.E4.m1.1.1.1.1.3.5">ℒ</ci><vector id="S3.E4.m1.1.1.1.1.3.3.4.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3"><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2">𝑋</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">𝑢</ci></apply><apply id="S3.E4.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2">𝑋</ci><ci id="S3.E4.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.3">𝑎</ci></apply><apply id="S3.E4.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.3.2">𝑌</ci><ci id="S3.E4.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.3.3.3">𝑎</ci></apply></vector></apply><apply id="S3.E4.m1.1.1.1.1.8.cmml" xref="S3.E4.m1.1.1.1.1.8"><plus id="S3.E4.m1.1.1.1.1.8.6.cmml" xref="S3.E4.m1.1.1.1.1.8.6"></plus><apply id="S3.E4.m1.1.1.1.1.5.2.cmml" xref="S3.E4.m1.1.1.1.1.5.2"><times id="S3.E4.m1.1.1.1.1.5.2.3.cmml" xref="S3.E4.m1.1.1.1.1.5.2.3"></times><ci id="S3.E4.m1.1.1.1.1.5.2.4.cmml" xref="S3.E4.m1.1.1.1.1.5.2.4">𝜆</ci><apply id="S3.E4.m1.1.1.1.1.5.2.5.cmml" xref="S3.E4.m1.1.1.1.1.5.2.5"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.5.2.5.1.cmml" xref="S3.E4.m1.1.1.1.1.5.2.5">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.5.2.5.2.cmml" xref="S3.E4.m1.1.1.1.1.5.2.5.2">ℒ</ci><ci id="S3.E4.m1.1.1.1.1.5.2.5.3.cmml" xref="S3.E4.m1.1.1.1.1.5.2.5.3">𝑎</ci></apply><interval closure="open" id="S3.E4.m1.1.1.1.1.5.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.5.2.2.2"><apply id="S3.E4.m1.1.1.1.1.4.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.4.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.4.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.4.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.4.1.1.1.1.2">𝑋</ci><ci id="S3.E4.m1.1.1.1.1.4.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.4.1.1.1.1.3">𝑎</ci></apply><apply id="S3.E4.m1.1.1.1.1.5.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.5.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.5.2.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.5.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.5.2.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.5.2.2.2.2.2">𝑌</ci><ci id="S3.E4.m1.1.1.1.1.5.2.2.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.5.2.2.2.2.3">𝑎</ci></apply></interval></apply><apply id="S3.E4.m1.1.1.1.1.8.5.cmml" xref="S3.E4.m1.1.1.1.1.8.5"><times id="S3.E4.m1.1.1.1.1.8.5.4.cmml" xref="S3.E4.m1.1.1.1.1.8.5.4"></times><apply id="S3.E4.m1.1.1.1.1.6.3.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.6.3.1.1"><minus id="S3.E4.m1.1.1.1.1.6.3.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.1"></minus><cn type="integer" id="S3.E4.m1.1.1.1.1.6.3.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.2">1</cn><ci id="S3.E4.m1.1.1.1.1.6.3.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.6.3.1.1.1.3">𝜆</ci></apply><apply id="S3.E4.m1.1.1.1.1.8.5.5.cmml" xref="S3.E4.m1.1.1.1.1.8.5.5"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.8.5.5.1.cmml" xref="S3.E4.m1.1.1.1.1.8.5.5">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.8.5.5.2.cmml" xref="S3.E4.m1.1.1.1.1.8.5.5.2">ℒ</ci><ci id="S3.E4.m1.1.1.1.1.8.5.5.3.cmml" xref="S3.E4.m1.1.1.1.1.8.5.5.3">𝑢</ci></apply><interval closure="open" id="S3.E4.m1.1.1.1.1.8.5.3.3.cmml" xref="S3.E4.m1.1.1.1.1.8.5.3.2"><apply id="S3.E4.m1.1.1.1.1.7.4.2.1.1.cmml" xref="S3.E4.m1.1.1.1.1.7.4.2.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.7.4.2.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.7.4.2.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.7.4.2.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.7.4.2.1.1.2">𝑋</ci><ci id="S3.E4.m1.1.1.1.1.7.4.2.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.7.4.2.1.1.3">𝑢</ci></apply><apply id="S3.E4.m1.1.1.1.1.8.5.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.8.5.3.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.8.5.3.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.8.5.3.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.8.5.3.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.8.5.3.2.2.2">𝑌</ci><ci id="S3.E4.m1.1.1.1.1.8.5.3.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.8.5.3.2.2.3">𝑎</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\mathcal{L}(X_{u},X_{a},Y_{a})=\lambda\mathcal{L}_{a}(X_{a},Y_{a})+(1-\lambda)\mathcal{L}_{u}(X_{u},Y_{a}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.7" class="ltx_p">where <math id="S3.SS2.p2.4.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS2.p2.4.m1.1a"><mi id="S3.SS2.p2.4.m1.1.1" xref="S3.SS2.p2.4.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m1.1b"><ci id="S3.SS2.p2.4.m1.1.1.cmml" xref="S3.SS2.p2.4.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m1.1c">\lambda</annotation></semantics></math> is a hyperparameter to control the balance between the two loss functions.
This configuration allows us to always evaluate the loss when only ultrasonic echoes are used. <math id="S3.SS2.p2.5.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS2.p2.5.m2.1a"><mi id="S3.SS2.p2.5.m2.1.1" xref="S3.SS2.p2.5.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m2.1b"><ci id="S3.SS2.p2.5.m2.1.1.cmml" xref="S3.SS2.p2.5.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m2.1c">\lambda</annotation></semantics></math> is scheduled as the learning progresses by changing from <math id="S3.SS2.p2.6.m3.1" class="ltx_Math" alttext="\lambda=1" display="inline"><semantics id="S3.SS2.p2.6.m3.1a"><mrow id="S3.SS2.p2.6.m3.1.1" xref="S3.SS2.p2.6.m3.1.1.cmml"><mi id="S3.SS2.p2.6.m3.1.1.2" xref="S3.SS2.p2.6.m3.1.1.2.cmml">λ</mi><mo id="S3.SS2.p2.6.m3.1.1.1" xref="S3.SS2.p2.6.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.6.m3.1.1.3" xref="S3.SS2.p2.6.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m3.1b"><apply id="S3.SS2.p2.6.m3.1.1.cmml" xref="S3.SS2.p2.6.m3.1.1"><eq id="S3.SS2.p2.6.m3.1.1.1.cmml" xref="S3.SS2.p2.6.m3.1.1.1"></eq><ci id="S3.SS2.p2.6.m3.1.1.2.cmml" xref="S3.SS2.p2.6.m3.1.1.2">𝜆</ci><cn type="integer" id="S3.SS2.p2.6.m3.1.1.3.cmml" xref="S3.SS2.p2.6.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m3.1c">\lambda=1</annotation></semantics></math> to <math id="S3.SS2.p2.7.m4.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.SS2.p2.7.m4.1a"><mn id="S3.SS2.p2.7.m4.1.1" xref="S3.SS2.p2.7.m4.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m4.1b"><cn type="integer" id="S3.SS2.p2.7.m4.1.1.cmml" xref="S3.SS2.p2.7.m4.1.1">0</cn></annotation-xml></semantics></math> in a linear scheduling manner.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>EXPERIMENTS</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.6" class="ltx_p">We evaluate the depth estimation accuracy of our method for three frequency settings of the ultrasound band, i.e., when the cutoff frequency of the high-pass filter is set to <math id="S4.p1.1.m1.2" class="ltx_Math" alttext="20,000" display="inline"><semantics id="S4.p1.1.m1.2a"><mrow id="S4.p1.1.m1.2.3.2" xref="S4.p1.1.m1.2.3.1.cmml"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">20</mn><mo id="S4.p1.1.m1.2.3.2.1" xref="S4.p1.1.m1.2.3.1.cmml">,</mo><mn id="S4.p1.1.m1.2.2" xref="S4.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.2b"><list id="S4.p1.1.m1.2.3.1.cmml" xref="S4.p1.1.m1.2.3.2"><cn type="integer" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">20</cn><cn type="integer" id="S4.p1.1.m1.2.2.cmml" xref="S4.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.2c">20,000</annotation></semantics></math> Hz, <math id="S4.p1.2.m2.2" class="ltx_Math" alttext="21,000" display="inline"><semantics id="S4.p1.2.m2.2a"><mrow id="S4.p1.2.m2.2.3.2" xref="S4.p1.2.m2.2.3.1.cmml"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">21</mn><mo id="S4.p1.2.m2.2.3.2.1" xref="S4.p1.2.m2.2.3.1.cmml">,</mo><mn id="S4.p1.2.m2.2.2" xref="S4.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.2b"><list id="S4.p1.2.m2.2.3.1.cmml" xref="S4.p1.2.m2.2.3.2"><cn type="integer" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">21</cn><cn type="integer" id="S4.p1.2.m2.2.2.cmml" xref="S4.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.2c">21,000</annotation></semantics></math> Hz, and <math id="S4.p1.3.m3.2" class="ltx_Math" alttext="22,000" display="inline"><semantics id="S4.p1.3.m3.2a"><mrow id="S4.p1.3.m3.2.3.2" xref="S4.p1.3.m3.2.3.1.cmml"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">22</mn><mo id="S4.p1.3.m3.2.3.2.1" xref="S4.p1.3.m3.2.3.1.cmml">,</mo><mn id="S4.p1.3.m3.2.2" xref="S4.p1.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.2b"><list id="S4.p1.3.m3.2.3.1.cmml" xref="S4.p1.3.m3.2.3.2"><cn type="integer" id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">22</cn><cn type="integer" id="S4.p1.3.m3.2.2.cmml" xref="S4.p1.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.2c">22,000</annotation></semantics></math> Hz. The cutoff frequencies of the corresponding auxiliary lower-frequency echoes are set to <math id="S4.p1.4.m4.2" class="ltx_Math" alttext="19,500" display="inline"><semantics id="S4.p1.4.m4.2a"><mrow id="S4.p1.4.m4.2.3.2" xref="S4.p1.4.m4.2.3.1.cmml"><mn id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">19</mn><mo id="S4.p1.4.m4.2.3.2.1" xref="S4.p1.4.m4.2.3.1.cmml">,</mo><mn id="S4.p1.4.m4.2.2" xref="S4.p1.4.m4.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.2b"><list id="S4.p1.4.m4.2.3.1.cmml" xref="S4.p1.4.m4.2.3.2"><cn type="integer" id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">19</cn><cn type="integer" id="S4.p1.4.m4.2.2.cmml" xref="S4.p1.4.m4.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.2c">19,500</annotation></semantics></math> Hz, <math id="S4.p1.5.m5.2" class="ltx_Math" alttext="20,000" display="inline"><semantics id="S4.p1.5.m5.2a"><mrow id="S4.p1.5.m5.2.3.2" xref="S4.p1.5.m5.2.3.1.cmml"><mn id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">20</mn><mo id="S4.p1.5.m5.2.3.2.1" xref="S4.p1.5.m5.2.3.1.cmml">,</mo><mn id="S4.p1.5.m5.2.2" xref="S4.p1.5.m5.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.2b"><list id="S4.p1.5.m5.2.3.1.cmml" xref="S4.p1.5.m5.2.3.2"><cn type="integer" id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1">20</cn><cn type="integer" id="S4.p1.5.m5.2.2.cmml" xref="S4.p1.5.m5.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.5.m5.2c">20,000</annotation></semantics></math> Hz, and <math id="S4.p1.6.m6.2" class="ltx_Math" alttext="21,000" display="inline"><semantics id="S4.p1.6.m6.2a"><mrow id="S4.p1.6.m6.2.3.2" xref="S4.p1.6.m6.2.3.1.cmml"><mn id="S4.p1.6.m6.1.1" xref="S4.p1.6.m6.1.1.cmml">21</mn><mo id="S4.p1.6.m6.2.3.2.1" xref="S4.p1.6.m6.2.3.1.cmml">,</mo><mn id="S4.p1.6.m6.2.2" xref="S4.p1.6.m6.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.6.m6.2b"><list id="S4.p1.6.m6.2.3.1.cmml" xref="S4.p1.6.m6.2.3.2"><cn type="integer" id="S4.p1.6.m6.1.1.cmml" xref="S4.p1.6.m6.1.1">21</cn><cn type="integer" id="S4.p1.6.m6.2.2.cmml" xref="S4.p1.6.m6.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.6.m6.2c">21,000</annotation></semantics></math> Hz.
For comparison, we evaluate two baselines: the method in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> applied to ultrasonic and augmented echoes, respectively.
Other experimental conditions are the same as those used in our preliminary experiments (see Sec. <a href="#S2" title="2 PRELIMINARY EXPERIMENTS ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2409.03336/assets/34_3.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="419" height="467" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.3.1.1" class="ltx_text ltx_font_bold">Fig. 6</span>: </span><span id="S4.F6.4.2" class="ltx_text ltx_font_bold">Qualitative Results.</span> From left to right, the ground truth depth maps, the results obtained by applying <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> to ultrasonic echoes, and the results by our method.</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Quantitative Results</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The quantitative results are shown in Fig. <a href="#S3.F5" title="Figure 5 ‣ 3.1 Auxiliary Echo Generation ‣ 3 Method ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
Our method achieves the best accuracy for all the settings.
First, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> with augmented echoes surpasses that with ultrasonic echo, which demonstrates the effectiveness of using augmented echoes during learning.
Second, Ours is better than <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> with augmented echoes. This is because low-frequency components are always mixed into the training data in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> with augmented echoes, resulting in overfitting to low-frequency bands that are not actually used for estimation.
These results verify the effectiveness of the proposed method.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Qualitative Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">A few examples of depth maps estimated by the proposed method are shown in Fig. <a href="#S4.F6" title="Figure 6 ‣ 4 EXPERIMENTS ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. The estimated depth maps by ours are closer to the ground truth depth maps than those estimated by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> with ultrasonic echoes. This result further emphasizes the superiority of the proposed method.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>CONCLUSION</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We explored ultrasonic echo-based depth estimation. We proposed a novel method of transferring knowledge of audible sound to ultrasound, based on the solid support of our analysis (Fig. <a href="#S2.F3" title="Figure 3 ‣ 2.2 Depth Estimation Method ‣ 2 PRELIMINARY EXPERIMENTS ‣ Estimating Indoor Scene Depth Maps from Ultrasonic Echoes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). As the first paper addressing ultrasound-based depth estimation, we believe that this paper can provide a new direction to the community. Performance evaluation on real datasets based on our proposed method is a future work.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Acknowledgment.</span> This work was partially supported by JSPS KAKENHI Grant Number 23K11154.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
David Eigen, Christian Puhrsch, and Rob Fergus,

</span>
<span class="ltx_bibblock">“Depth map prediction from a single image using a multi-scale deep network,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Proc. NeurIPS</span>, 2014.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
David Eigeg and Rob Fergus,

</span>
<span class="ltx_bibblock">“Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Proc. ICCV</span>, 2015.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Iro Laina, Christian Rupprecht, and Vasileios Belagiannis,

</span>
<span class="ltx_bibblock">“Deeper depth prediction with fully convolutional residual networks,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Proc. 3DV</span>, 2016.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Fangchang Ma and Sertac Karaman,

</span>
<span class="ltx_bibblock">“Sparse-to-dense: Depth prediction from sparse depth samples and a single image,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Proc. ICRA</span>, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Jesper Haahr Christensen, Sascha Hornauer, and Stella Yu,

</span>
<span class="ltx_bibblock">“BatVision: Learning to see 3d spatial layout with two ears,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Proc. ICRA</span>, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Arun Balajee Vasudevan, Dengxin Dai, and Luc Van Gool,

</span>
<span class="ltx_bibblock">“Semantic object prediction and spatial sound super-resolution with binaural sounds,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Proc. ECCV</span>, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Ruohan Gao, Changan Chen, Ziad Al-Halah, Carl Schissler, and Kristen Grauman,

</span>
<span class="ltx_bibblock">“VisualEchoes: Spatial image representation learning through echolocation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Proc. ECCV</span>, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Alex Turpin, Valentin Kapitany, Jack Radford, Davide Rovelli, Kevin Mitchell, Ashley Lyons, Ilya Starshynov, and Daniele Faccio,

</span>
<span class="ltx_bibblock">“3d imaging from multipath temporal echoes,”

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Physical Review Letters</span>, vol. 126, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Kranti Kumar Parida, Siddharth Srivastava, and Gaurav Sharma,

</span>
<span class="ltx_bibblock">“Beyond image to depth: Improving depth prediction using echoes,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proc. CVPR</span>, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Go Irie, Takashi Shibata, and Akisato Kimura,

</span>
<span class="ltx_bibblock">“Co-attention-guided bilinear model for echo-based depth estimation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proc. ICASSP</span>, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Chenghao Zhang, Kun Tian, Bolin Ni, Gaofeng Meng, Bin Fan, Zhaoxiang Zhang, and Chunhong Pan,

</span>
<span class="ltx_bibblock">“Stereo depth estimation with echoes,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Proc. ECCV</span>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Xiaoyan Jiang Yongbin Gao Gaofeng Cao Siwei Ma Anjie Wang, Zhijun Fang,

</span>
<span class="ltx_bibblock">“Depth estimation of multi-modal scene based on multi-scare modulation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proc. ICIP</span>, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Hang Zhao Lingyu Zhu, Esa Rahtu,

</span>
<span class="ltx_bibblock">“Beyond visual field of view: Perceiving 3d environment with echoes and vision,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Proc. CVPR</span>, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Xiang Li Zhenyu Zhang Baobei Xu Jun Li Jian Yang Zhiqiang Yan, Kun Wang,

</span>
<span class="ltx_bibblock">“Rignet: Repetitive image guided network for depth completion,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proc. ECCV</span>, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Gunhee Kim Heeseung Yun, Joonil Na,

</span>
<span class="ltx_bibblock">“Dense 2d-3d indoor prediction with sound via aligned cross-modal distillation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Proc. ICCV</span>, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz,

</span>
<span class="ltx_bibblock">“mixup: Beyond empirical risk minimization,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Proc. ICLR</span>, 2018.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Julian Straub et al.,

</span>
<span class="ltx_bibblock">“The Replica Dataset: A digital replica of indoor spaces,”

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">arXiv preprint, arXiv:1906.05797</span>, 2019.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Angela Dai Angel Chang et al.,

</span>
<span class="ltx_bibblock">“Matterport3d: Learning from RGB-D data in indoor environments,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Proc. 3DV</span>, 2017.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.03335" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.03336" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.03336">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.03336" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.03337" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 19:51:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
