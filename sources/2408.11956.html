<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.11956] The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability</title><meta property="og:description" content="Emotion expression and perception are nuanced, complex, and highly subjective processes. When multiple annotators label emotional data, the resulting labels contain high variability. Most speech emotion recognition tas…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.11956">

<!--Generated on Thu Sep  5 18:04:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\interspeechcameraready</span><span id="p1.2" class="ltx_ERROR undefined">\name</span>
<p id="p1.3" class="ltx_p">[affiliation=1]JamesTavernor
<span id="p1.3.1" class="ltx_ERROR undefined">\name</span>[affiliation=1]YaraEl-Tawil
<span id="p1.3.2" class="ltx_ERROR undefined">\name</span>[affiliation=1]EmilyMower Provost




 



</p>
</div>
<h1 class="ltx_title ltx_title_document">The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.id1" class="ltx_p">Emotion expression and perception are nuanced, complex, and highly subjective processes. When multiple annotators label emotional data, the resulting labels contain high variability. Most speech emotion recognition tasks address this by averaging annotator labels as ground truth. However, this process omits the nuance of emotion and inter-annotator variability, which are important signals to capture. Previous work has attempted to learn distributions to capture emotion variability, but these methods also lose information about the individual annotators. We address these limitations by learning to predict individual annotators and by introducing a novel method to create distributions from continuous model outputs that permit the learning of emotion distributions during model training. We show that this combined approach can result in emotion distributions that are more accurate than those seen in prior work, in both within- and cross-corpus settings.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>speech recognition, emotion recognition, human-computer interaction, inter-annotator agreement
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Expressions of emotion are nuanced and complex, and people perceive these expressions differently, adding to the complexity. Most emotion recognition models overlook this nuance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. This is because most Speech Emotion Recognition (SER) datasets and tasks present the ground truth as a single label, which is the average of multiple annotations. In this work, we present novel approaches to both accurately learn the perceptions of individual annotators and aggregate these estimates to create distributions of annotator perception. In this way, the model retains information about individual annotator predictions while still being able to summarize the information accurately as a two-dimensional (2D) distribution.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Prior work has investigated methods to retain information about variability and uncertainty. Research has included the prediction of measures such as unbiased annotator standard deviation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, the embedding of individual annotators to improve performance on the aggregated ground truth, with some investigation into how well the model annotator uncertainty correlates with real uncertainty <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, and the prediction of the distribution of annotations over a given utterance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Yet, gaps remain. Methods that summarize model information or predict uncertainty lose fine-grained information about individual annotators. On the other hand, methods that seek to learn annotators primarily do so to improve performance on the aggregated ground truth or investigate much smaller numbers of annotators than are generally used in these datasets.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We present a novel approach that predicts the annotations of individuals and includes a new differentiable method to automatically learn distributions similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, enabling the modeling of individual variation and the retention of the ability to summarize annotators. The model training involves an interleaved approach, alternating between different tasks: learning individual annotators and learning a distribution. We learn individual annotators by training a multi-task (MT) model to predict each annotator in the training set across the dimensions of valence and activation. We learn a distribution by upsampling the observations from the MT model and using Kernel Density Estimation (KDE) to produce a summarization of the model output as a distribution. We introduce differentiable KDE into the model training process to enable the use of gradient descent.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We present both within- and cross-corpus investigations. Within-corpus, we find that a model trained with the interleaved tasks of individual annotator perception and distribution learning can outperform a method that learns to predict the distribution alone <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, in terms of both the performance on consensus labels and the accuracy of the distribution itself, while providing individual annotations as well. We further show that the output of the annotator-specific models (trained only on annotator prediction) can be post-processed to create a distribution, rather than learning a distribution during model training, that outperforms the prior work of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. In this case, an extra step is involved in which the output of the annotator-specific models is transformed into a distribution using either KDE as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> or using the differentiable KDE method presented in this work. We find that using differentiable KDE leads to significantly improved performance, even when only used in post-processing, pointing to the efficacy of this approach for either model learning or post-hoc output summarization. Cross-corpus, we demonstrate that annotator-specific models can be used zero-shot without knowledge about the annotators that labeled the new datasets. We find that the presented approach outperforms a distribution-only method across metrics that capture individual annotators and the accuracy of a given distribution in most cases. Future work will focus on investigating individual characteristics of annotators (e.g., personality) and how this information can also be considered when learning annotator-specific perception.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Previous work has developed soft-label methods that use multiple annotators per label. Dang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> use multi-rater Gaussian Mixture Regression to make temporal emotion predictions for a fixed set of consistent evaluators in their target dataset. Other approaches have captured both the uncertainty in annotator labels and model uncertainty <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. However, a gap remains at the intersection of predicting individual annotations for a variable number of annotators.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.7" class="ltx_p">Instead, we build on the label processing method developed in previous work by Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, which incorporated inter-annotator variance into machine learning models by creating new ground truth labels that incorporate this knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. They upsampled existing annotations by selecting random subsets of annotators for each utterance and took the mean across those annotations. They added random noise to the resulting means, such that <math id="S2.p2.1.m1.3" class="ltx_Math" alttext="x\ noise\sim U(-\frac{std(x)}{2},\frac{std(x)}{2})" display="inline"><semantics id="S2.p2.1.m1.3a"><mrow id="S2.p2.1.m1.3.3" xref="S2.p2.1.m1.3.3.cmml"><mrow id="S2.p2.1.m1.3.3.3" xref="S2.p2.1.m1.3.3.3.cmml"><mi id="S2.p2.1.m1.3.3.3.2" xref="S2.p2.1.m1.3.3.3.2.cmml">x</mi><mo lspace="0.500em" rspace="0em" id="S2.p2.1.m1.3.3.3.1" xref="S2.p2.1.m1.3.3.3.1.cmml">​</mo><mi id="S2.p2.1.m1.3.3.3.3" xref="S2.p2.1.m1.3.3.3.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.3.3.3.1a" xref="S2.p2.1.m1.3.3.3.1.cmml">​</mo><mi id="S2.p2.1.m1.3.3.3.4" xref="S2.p2.1.m1.3.3.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.3.3.3.1b" xref="S2.p2.1.m1.3.3.3.1.cmml">​</mo><mi id="S2.p2.1.m1.3.3.3.5" xref="S2.p2.1.m1.3.3.3.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.3.3.3.1c" xref="S2.p2.1.m1.3.3.3.1.cmml">​</mo><mi id="S2.p2.1.m1.3.3.3.6" xref="S2.p2.1.m1.3.3.3.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.3.3.3.1d" xref="S2.p2.1.m1.3.3.3.1.cmml">​</mo><mi id="S2.p2.1.m1.3.3.3.7" xref="S2.p2.1.m1.3.3.3.7.cmml">e</mi></mrow><mo id="S2.p2.1.m1.3.3.2" xref="S2.p2.1.m1.3.3.2.cmml">∼</mo><mrow id="S2.p2.1.m1.3.3.1" xref="S2.p2.1.m1.3.3.1.cmml"><mi id="S2.p2.1.m1.3.3.1.3" xref="S2.p2.1.m1.3.3.1.3.cmml">U</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.3.3.1.2" xref="S2.p2.1.m1.3.3.1.2.cmml">​</mo><mrow id="S2.p2.1.m1.3.3.1.1.1" xref="S2.p2.1.m1.3.3.1.1.2.cmml"><mo stretchy="false" id="S2.p2.1.m1.3.3.1.1.1.2" xref="S2.p2.1.m1.3.3.1.1.2.cmml">(</mo><mrow id="S2.p2.1.m1.3.3.1.1.1.1" xref="S2.p2.1.m1.3.3.1.1.1.1.cmml"><mo id="S2.p2.1.m1.3.3.1.1.1.1a" xref="S2.p2.1.m1.3.3.1.1.1.1.cmml">−</mo><mfrac id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mrow id="S2.p2.1.m1.1.1.1" xref="S2.p2.1.m1.1.1.1.cmml"><mi id="S2.p2.1.m1.1.1.1.3" xref="S2.p2.1.m1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.1.1.1.2" xref="S2.p2.1.m1.1.1.1.2.cmml">​</mo><mi id="S2.p2.1.m1.1.1.1.4" xref="S2.p2.1.m1.1.1.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.1.1.1.2a" xref="S2.p2.1.m1.1.1.1.2.cmml">​</mo><mi id="S2.p2.1.m1.1.1.1.5" xref="S2.p2.1.m1.1.1.1.5.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.1.1.1.2b" xref="S2.p2.1.m1.1.1.1.2.cmml">​</mo><mrow id="S2.p2.1.m1.1.1.1.6.2" xref="S2.p2.1.m1.1.1.1.cmml"><mo stretchy="false" id="S2.p2.1.m1.1.1.1.6.2.1" xref="S2.p2.1.m1.1.1.1.cmml">(</mo><mi id="S2.p2.1.m1.1.1.1.1" xref="S2.p2.1.m1.1.1.1.1.cmml">x</mi><mo stretchy="false" id="S2.p2.1.m1.1.1.1.6.2.2" xref="S2.p2.1.m1.1.1.1.cmml">)</mo></mrow></mrow><mn id="S2.p2.1.m1.1.1.3" xref="S2.p2.1.m1.1.1.3.cmml">2</mn></mfrac></mrow><mo id="S2.p2.1.m1.3.3.1.1.1.3" xref="S2.p2.1.m1.3.3.1.1.2.cmml">,</mo><mfrac id="S2.p2.1.m1.2.2" xref="S2.p2.1.m1.2.2.cmml"><mrow id="S2.p2.1.m1.2.2.1" xref="S2.p2.1.m1.2.2.1.cmml"><mi id="S2.p2.1.m1.2.2.1.3" xref="S2.p2.1.m1.2.2.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.2.2.1.2" xref="S2.p2.1.m1.2.2.1.2.cmml">​</mo><mi id="S2.p2.1.m1.2.2.1.4" xref="S2.p2.1.m1.2.2.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.2.2.1.2a" xref="S2.p2.1.m1.2.2.1.2.cmml">​</mo><mi id="S2.p2.1.m1.2.2.1.5" xref="S2.p2.1.m1.2.2.1.5.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.2.2.1.2b" xref="S2.p2.1.m1.2.2.1.2.cmml">​</mo><mrow id="S2.p2.1.m1.2.2.1.6.2" xref="S2.p2.1.m1.2.2.1.cmml"><mo stretchy="false" id="S2.p2.1.m1.2.2.1.6.2.1" xref="S2.p2.1.m1.2.2.1.cmml">(</mo><mi id="S2.p2.1.m1.2.2.1.1" xref="S2.p2.1.m1.2.2.1.1.cmml">x</mi><mo stretchy="false" id="S2.p2.1.m1.2.2.1.6.2.2" xref="S2.p2.1.m1.2.2.1.cmml">)</mo></mrow></mrow><mn id="S2.p2.1.m1.2.2.3" xref="S2.p2.1.m1.2.2.3.cmml">2</mn></mfrac><mo stretchy="false" id="S2.p2.1.m1.3.3.1.1.1.4" xref="S2.p2.1.m1.3.3.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.3b"><apply id="S2.p2.1.m1.3.3.cmml" xref="S2.p2.1.m1.3.3"><csymbol cd="latexml" id="S2.p2.1.m1.3.3.2.cmml" xref="S2.p2.1.m1.3.3.2">similar-to</csymbol><apply id="S2.p2.1.m1.3.3.3.cmml" xref="S2.p2.1.m1.3.3.3"><times id="S2.p2.1.m1.3.3.3.1.cmml" xref="S2.p2.1.m1.3.3.3.1"></times><ci id="S2.p2.1.m1.3.3.3.2.cmml" xref="S2.p2.1.m1.3.3.3.2">𝑥</ci><ci id="S2.p2.1.m1.3.3.3.3.cmml" xref="S2.p2.1.m1.3.3.3.3">𝑛</ci><ci id="S2.p2.1.m1.3.3.3.4.cmml" xref="S2.p2.1.m1.3.3.3.4">𝑜</ci><ci id="S2.p2.1.m1.3.3.3.5.cmml" xref="S2.p2.1.m1.3.3.3.5">𝑖</ci><ci id="S2.p2.1.m1.3.3.3.6.cmml" xref="S2.p2.1.m1.3.3.3.6">𝑠</ci><ci id="S2.p2.1.m1.3.3.3.7.cmml" xref="S2.p2.1.m1.3.3.3.7">𝑒</ci></apply><apply id="S2.p2.1.m1.3.3.1.cmml" xref="S2.p2.1.m1.3.3.1"><times id="S2.p2.1.m1.3.3.1.2.cmml" xref="S2.p2.1.m1.3.3.1.2"></times><ci id="S2.p2.1.m1.3.3.1.3.cmml" xref="S2.p2.1.m1.3.3.1.3">𝑈</ci><interval closure="open" id="S2.p2.1.m1.3.3.1.1.2.cmml" xref="S2.p2.1.m1.3.3.1.1.1"><apply id="S2.p2.1.m1.3.3.1.1.1.1.cmml" xref="S2.p2.1.m1.3.3.1.1.1.1"><minus id="S2.p2.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.p2.1.m1.3.3.1.1.1.1"></minus><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><divide id="S2.p2.1.m1.1.1.2.cmml" xref="S2.p2.1.m1.1.1"></divide><apply id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1.1"><times id="S2.p2.1.m1.1.1.1.2.cmml" xref="S2.p2.1.m1.1.1.1.2"></times><ci id="S2.p2.1.m1.1.1.1.3.cmml" xref="S2.p2.1.m1.1.1.1.3">𝑠</ci><ci id="S2.p2.1.m1.1.1.1.4.cmml" xref="S2.p2.1.m1.1.1.1.4">𝑡</ci><ci id="S2.p2.1.m1.1.1.1.5.cmml" xref="S2.p2.1.m1.1.1.1.5">𝑑</ci><ci id="S2.p2.1.m1.1.1.1.1.cmml" xref="S2.p2.1.m1.1.1.1.1">𝑥</ci></apply><cn type="integer" id="S2.p2.1.m1.1.1.3.cmml" xref="S2.p2.1.m1.1.1.3">2</cn></apply></apply><apply id="S2.p2.1.m1.2.2.cmml" xref="S2.p2.1.m1.2.2"><divide id="S2.p2.1.m1.2.2.2.cmml" xref="S2.p2.1.m1.2.2"></divide><apply id="S2.p2.1.m1.2.2.1.cmml" xref="S2.p2.1.m1.2.2.1"><times id="S2.p2.1.m1.2.2.1.2.cmml" xref="S2.p2.1.m1.2.2.1.2"></times><ci id="S2.p2.1.m1.2.2.1.3.cmml" xref="S2.p2.1.m1.2.2.1.3">𝑠</ci><ci id="S2.p2.1.m1.2.2.1.4.cmml" xref="S2.p2.1.m1.2.2.1.4">𝑡</ci><ci id="S2.p2.1.m1.2.2.1.5.cmml" xref="S2.p2.1.m1.2.2.1.5">𝑑</ci><ci id="S2.p2.1.m1.2.2.1.1.cmml" xref="S2.p2.1.m1.2.2.1.1">𝑥</ci></apply><cn type="integer" id="S2.p2.1.m1.2.2.3.cmml" xref="S2.p2.1.m1.2.2.3">2</cn></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.3c">x\ noise\sim U(-\frac{std(x)}{2},\frac{std(x)}{2})</annotation></semantics></math><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We also add <math id="footnote1.m1.1" class="ltx_Math" alttext="\epsilon=1E^{-12}" display="inline"><semantics id="footnote1.m1.1b"><mrow id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml"><mi id="footnote1.m1.1.1.2" xref="footnote1.m1.1.1.2.cmml">ϵ</mi><mo id="footnote1.m1.1.1.1" xref="footnote1.m1.1.1.1.cmml">=</mo><mrow id="footnote1.m1.1.1.3" xref="footnote1.m1.1.1.3.cmml"><mn id="footnote1.m1.1.1.3.2" xref="footnote1.m1.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="footnote1.m1.1.1.3.1" xref="footnote1.m1.1.1.3.1.cmml">​</mo><msup id="footnote1.m1.1.1.3.3" xref="footnote1.m1.1.1.3.3.cmml"><mi id="footnote1.m1.1.1.3.3.2" xref="footnote1.m1.1.1.3.3.2.cmml">E</mi><mrow id="footnote1.m1.1.1.3.3.3" xref="footnote1.m1.1.1.3.3.3.cmml"><mo id="footnote1.m1.1.1.3.3.3b" xref="footnote1.m1.1.1.3.3.3.cmml">−</mo><mn id="footnote1.m1.1.1.3.3.3.2" xref="footnote1.m1.1.1.3.3.3.2.cmml">12</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m1.1c"><apply id="footnote1.m1.1.1.cmml" xref="footnote1.m1.1.1"><eq id="footnote1.m1.1.1.1.cmml" xref="footnote1.m1.1.1.1"></eq><ci id="footnote1.m1.1.1.2.cmml" xref="footnote1.m1.1.1.2">italic-ϵ</ci><apply id="footnote1.m1.1.1.3.cmml" xref="footnote1.m1.1.1.3"><times id="footnote1.m1.1.1.3.1.cmml" xref="footnote1.m1.1.1.3.1"></times><cn type="integer" id="footnote1.m1.1.1.3.2.cmml" xref="footnote1.m1.1.1.3.2">1</cn><apply id="footnote1.m1.1.1.3.3.cmml" xref="footnote1.m1.1.1.3.3"><csymbol cd="ambiguous" id="footnote1.m1.1.1.3.3.1.cmml" xref="footnote1.m1.1.1.3.3">superscript</csymbol><ci id="footnote1.m1.1.1.3.3.2.cmml" xref="footnote1.m1.1.1.3.3.2">𝐸</ci><apply id="footnote1.m1.1.1.3.3.3.cmml" xref="footnote1.m1.1.1.3.3.3"><minus id="footnote1.m1.1.1.3.3.3.1.cmml" xref="footnote1.m1.1.1.3.3.3"></minus><cn type="integer" id="footnote1.m1.1.1.3.3.3.2.cmml" xref="footnote1.m1.1.1.3.3.3.2">12</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m1.1d">\epsilon=1E^{-12}</annotation></semantics></math> to this value to account for cases where standard deviation is 0.</span></span></span>, where <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.p2.2.m2.1a"><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">x</annotation></semantics></math> is activation or valence, <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="std" display="inline"><semantics id="S2.p2.3.m3.1a"><mrow id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml"><mi id="S2.p2.3.m3.1.1.2" xref="S2.p2.3.m3.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.m3.1.1.1" xref="S2.p2.3.m3.1.1.1.cmml">​</mo><mi id="S2.p2.3.m3.1.1.3" xref="S2.p2.3.m3.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.m3.1.1.1a" xref="S2.p2.3.m3.1.1.1.cmml">​</mo><mi id="S2.p2.3.m3.1.1.4" xref="S2.p2.3.m3.1.1.4.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><apply id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1"><times id="S2.p2.3.m3.1.1.1.cmml" xref="S2.p2.3.m3.1.1.1"></times><ci id="S2.p2.3.m3.1.1.2.cmml" xref="S2.p2.3.m3.1.1.2">𝑠</ci><ci id="S2.p2.3.m3.1.1.3.cmml" xref="S2.p2.3.m3.1.1.3">𝑡</ci><ci id="S2.p2.3.m3.1.1.4.cmml" xref="S2.p2.3.m3.1.1.4">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">std</annotation></semantics></math> indicates the standard deviation of the annotator ratings for that utterance, and <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="U" display="inline"><semantics id="S2.p2.4.m4.1a"><mi id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">U</mi><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">𝑈</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">U</annotation></semantics></math> is the uniform distribution. Kernel Density Estimation (KDE) via Diffusion was then calculated over the upsampled observations. They divided the KDE output grid into <math id="S2.p2.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p2.5.m5.1a"><mi id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><ci id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">N</annotation></semantics></math> bins for each dimension and took the mean over the KDE samples inside each bin. They converted this grid to a probability distribution by normalizing over the means. The authors investigated <math id="S2.p2.6.m6.1" class="ltx_Math" alttext="N=2" display="inline"><semantics id="S2.p2.6.m6.1a"><mrow id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml"><mi id="S2.p2.6.m6.1.1.2" xref="S2.p2.6.m6.1.1.2.cmml">N</mi><mo id="S2.p2.6.m6.1.1.1" xref="S2.p2.6.m6.1.1.1.cmml">=</mo><mn id="S2.p2.6.m6.1.1.3" xref="S2.p2.6.m6.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><apply id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1"><eq id="S2.p2.6.m6.1.1.1.cmml" xref="S2.p2.6.m6.1.1.1"></eq><ci id="S2.p2.6.m6.1.1.2.cmml" xref="S2.p2.6.m6.1.1.2">𝑁</ci><cn type="integer" id="S2.p2.6.m6.1.1.3.cmml" xref="S2.p2.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">N=2</annotation></semantics></math> and <math id="S2.p2.7.m7.1" class="ltx_Math" alttext="N=4" display="inline"><semantics id="S2.p2.7.m7.1a"><mrow id="S2.p2.7.m7.1.1" xref="S2.p2.7.m7.1.1.cmml"><mi id="S2.p2.7.m7.1.1.2" xref="S2.p2.7.m7.1.1.2.cmml">N</mi><mo id="S2.p2.7.m7.1.1.1" xref="S2.p2.7.m7.1.1.1.cmml">=</mo><mn id="S2.p2.7.m7.1.1.3" xref="S2.p2.7.m7.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.7.m7.1b"><apply id="S2.p2.7.m7.1.1.cmml" xref="S2.p2.7.m7.1.1"><eq id="S2.p2.7.m7.1.1.1.cmml" xref="S2.p2.7.m7.1.1.1"></eq><ci id="S2.p2.7.m7.1.1.2.cmml" xref="S2.p2.7.m7.1.1.2">𝑁</ci><cn type="integer" id="S2.p2.7.m7.1.1.3.cmml" xref="S2.p2.7.m7.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.7.m7.1c">N=4</annotation></semantics></math>. The KDE step was essential to remove sensitivity to where boundaries were drawn. The authors then trained a model to predict these binned distributions. However, in this approach, the model loses information about individual annotators. Additionally, because the approach is not differentiable, it cannot be included in model training. We present an approach with a differentiable component that permits learning a binned distribution, implemented using sigmoid-based soft operations.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Previous work has investigated the prediction of individual annotators on subjective tasks such as emotion recognition and hate speech <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. Davani et al. introduced an encoder-based model with separate classification heads for each annotator. They trained this model for a binary categorical text emotion recognition task using a dataset that contained 82 annotators. At test time, they aggregated the individual annotator predictions and found that their model outperformed a baseline trained on majority ground truth labels. However, the performance of individual annotators was not discussed. Further, a limitation of this work is that many SER datasets include over 82 annotators, and the authors acknowledge that it would be too computationally expensive to train a model with separate heads for large numbers of annotators. Previous work has shown that clustering similar annotators can mitigate problems with large numbers of annotators <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. However, clustering annotators loses information about individual ratings. In our work, we enable only the relevant heads per batch, making training with a large number of annotators more computationally feasible.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">An alternative approach to learning individual annotators is through annotator embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Prior work from Kocoń et al. demonstrates that annotator-specific embeddings can be used to personalize model predictions and capture the bias of individual annotators. They introduced four methods for encoding annotator information into the model, including a one-hot annotator embedding. This embedding was a one-hot encoded vector of annotator ID that was concatenated to the model input. They found that this led to improved text-based emotion predictions but were focused on a consensus model rather than an individual-specific model. We use the one-hot model and investigate if the model can learn individual annotators.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data setup</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We use the MSP-Improv dataset for training and testing. It was labeled using crowdsourcing and has a relatively large number of evaluations per utterance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Additionally, we use the IEMOCAP, MSP-Podcast, and MuSE datasets to evaluate the cross-corpus results of each method.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">MSP-Improv</span> is an SER dataset consisting of acted improvised dialogue designed to evoke certain emotions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. The dataset has 12 speakers evenly split between male and female actors across six sessions. We select a speaker-independent data split such that all annotators in the validation and test set have evaluated at least one utterance in the training set. Annotators will be present in the training set that do not appear in the validation or test set (for example, when the annotator annotated less than three samples). The resulting train, validation, and test split size is 5,851, 1,287, and 1,300 utterances, respectively<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The code to create the data splits can be found at https://github.com/chailab-umich/ModelingIndividualEvaluators.</span></span></span>. The training set was evaluated by 1,434 individual crowdsourced annotators, with each sample receiving between 5 and 50 annotations (mean of 7.2). A subset of these annotators evaluated the validation and test set (1,305 and 1,197, respectively). Both validation and test set samples have between 5 and 37 evaluations per sample, with a mean of 7.3 and 7.6 annotators.
In few samples (28) the same annotator has annotated more than once. In these cases we have averaged their annotations into one evaluation, and adjusted the mean ground truth for these samples.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">The <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">IEMOCAP</span> dataset contains five dialogue sessions containing scripted and improvised interactions between two actors. There is one female and one male actor in each conversation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. We remove utterances where individual annotations were partially missing or any annotator evaluations were not within the labeling range described in the data collection. After processing, the dataset consists of 9,999 samples. Six annotators labeled the dataset with an average of 2.13 annotators per sample. We test on the full dataset.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">MSP-Podcast</span> is a dataset of speech taken from podcasts and then labeled <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. We use the predefined splits and evaluate on test_set_1, which is comprised of 13,911 utterances and contains 9570 individual annotators. Each utterance was evaluated by 6.9 crowdsourced annotators on average. We use <span id="S3.SS1.p4.1.2" class="ltx_text ltx_font_typewriter">release 1.8</span>, which does not contain transcripts, so we use Microsoft Azure automatic speech recognition to generate them.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">MuSE</span> is a dataset of 28 college students recorded in two 45-minute sessions each, responding to emotional stimuli. One session was when the students were affected by an external stressor, and the other was without the stressor <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Students were recorded using a lapel microphone. Crowdsourced annotators evaluated each utterance. There are 2,584 utterances comprised of 1,385 stressed and 1,199 non-stressed samples. The dataset provides labels annotated with or without context; we use the labels from the 160 individual annotators who labeled without context. Each sample was evaluated between 7 and 9 annotators, with 8 on average.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p"><span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_bold">Dataset Preprocessing</span>
We process all datasets in the same way. We use min-max scaling on the annotator and consensus labels for activation and valence to restrict labels to the <math id="S3.SS1.p6.1.m1.2" class="ltx_Math" alttext="[-1,1]" display="inline"><semantics id="S3.SS1.p6.1.m1.2a"><mrow id="S3.SS1.p6.1.m1.2.2.1" xref="S3.SS1.p6.1.m1.2.2.2.cmml"><mo stretchy="false" id="S3.SS1.p6.1.m1.2.2.1.2" xref="S3.SS1.p6.1.m1.2.2.2.cmml">[</mo><mrow id="S3.SS1.p6.1.m1.2.2.1.1" xref="S3.SS1.p6.1.m1.2.2.1.1.cmml"><mo id="S3.SS1.p6.1.m1.2.2.1.1a" xref="S3.SS1.p6.1.m1.2.2.1.1.cmml">−</mo><mn id="S3.SS1.p6.1.m1.2.2.1.1.2" xref="S3.SS1.p6.1.m1.2.2.1.1.2.cmml">1</mn></mrow><mo id="S3.SS1.p6.1.m1.2.2.1.3" xref="S3.SS1.p6.1.m1.2.2.2.cmml">,</mo><mn id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml">1</mn><mo stretchy="false" id="S3.SS1.p6.1.m1.2.2.1.4" xref="S3.SS1.p6.1.m1.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.2b"><interval closure="closed" id="S3.SS1.p6.1.m1.2.2.2.cmml" xref="S3.SS1.p6.1.m1.2.2.1"><apply id="S3.SS1.p6.1.m1.2.2.1.1.cmml" xref="S3.SS1.p6.1.m1.2.2.1.1"><minus id="S3.SS1.p6.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p6.1.m1.2.2.1.1"></minus><cn type="integer" id="S3.SS1.p6.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p6.1.m1.2.2.1.1.2">1</cn></apply><cn type="integer" id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.2c">[-1,1]</annotation></semantics></math> range. We then use KDE to generate a 2D ground truth probability distributions as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. We use a KDE grid size of 512 as we assume this will be sufficiently large to ensure the probability is insensitive to the grid boundaries.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Architecture</h3>

<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2408.11956/assets/x1.png" id="S3.F1.sf1.g1" class="ltx_graphics ltx_img_landscape" width="460" height="309" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Baseline model</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2408.11956/assets/x2.png" id="S3.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="460" height="428" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">MT Model</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2408.11956/assets/x3.png" id="S3.F1.sf3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="355" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">One-hot Model</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Model Architectures. Layers in gray are the common architecture between models. In (b) and (c) the last two common layers are duplicated as they split the model to two predictions.</span></figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.3" class="ltx_p">We present three models: a baseline, a MT model, and a one-hot model, all of which share the same base architecture but have different output head architectures (Figure <a href="#S3.F1" title="Figure 1 ‣ 3.2 Model Architecture ‣ 3 Experiments ‣ The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). The model input includes the frozen mean-pooled final layers of Wav2Vec2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> CLS embeddings as these have shown effectiveness in SER applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. We apply dropout with probability <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><cn type="float" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">0.2</annotation></semantics></math> and concatenate the embeddings. The concatenated embedding is passed through a single linear layer of size <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><cn type="integer" id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">256</annotation></semantics></math> with ReLU activation. For each prediction (distribution, activation, or valence), the input will pass through two linear layers of size <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mn id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><cn type="integer" id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">256</annotation></semantics></math> with ReLU activations.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">The <span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">baseline</span> model directly learns the generated KDE distribution (as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>), having a final linear layer output of 16 logits for the 4x4 discretized KDE distribution prediction case. The <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_bold">MT</span> model has separate prediction layers for each annotator as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Each annotator's continuous prediction of activation and valence is made via a linear layer with an output size of 1. We use the <span id="S3.SS2.p2.1.3" class="ltx_text ltx_font_bold">one-hot</span> method, previously used for text emotion recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. We use the same architecture as in the MT case but with only one annotator prediction head. The annotator ID is one-hot encoded and concatenated to the Wav2Vec2 and BERT embeddings on the model input. When training within corpus, we reduce computation cost by making predictions only for annotators in the batch input to the model.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Training Tasks</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.2" class="ltx_p">In this section, we define three different training tasks. The Baseline model is trained with the Baseline task. MT and one-hot models are trained by interleaving Tasks 1 and 2 (Task 1+2), defined below. We use stochastic gradient descent with a learning rate of <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mn id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><cn type="float" id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">0.001</annotation></semantics></math>, with a learning rate scheduler that adjusts the learning rate by a factor of <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mn id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><cn type="float" id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">0.1</annotation></semantics></math> after five epochs of no reduction in validation metrics. We train models until early stopping triggers with a patience of 10 with a minimum of 30 epochs. Each model trains with a batch size of 32. For all methods we use the relevant task's validation losses.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Baseline</span>: We predict the flattened 2D distribution and use cross-entropy loss of the 16 logits output against the flattened 2D generated ground truth probability distributions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.5" class="ltx_p"><span id="S3.SS3.p3.5.1" class="ltx_text ltx_font_bold">Task 1 - Annotator Training</span>:
We train annotator-specific predictions using the individual annotator ground truth. We use Lin's Concordance Correlation Coefficient (CCC) loss as our loss function since it better models dimensional attributes than other regression losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
The sets <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="act" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.1.m1.1.1.1a" xref="S3.SS3.p3.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.1.m1.1.1.4" xref="S3.SS3.p3.1.m1.1.1.4.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><times id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1"></times><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝑎</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑐</ci><ci id="S3.SS3.p3.1.m1.1.1.4.cmml" xref="S3.SS3.p3.1.m1.1.1.4">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">act</annotation></semantics></math>, and <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="val" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mrow id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.1" xref="S3.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.1a" xref="S3.SS3.p3.2.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p3.2.m2.1.1.4" xref="S3.SS3.p3.2.m2.1.1.4.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><times id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1.1"></times><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">𝑣</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">𝑎</ci><ci id="S3.SS3.p3.2.m2.1.1.4.cmml" xref="S3.SS3.p3.2.m2.1.1.4">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">val</annotation></semantics></math> contain the ground truth labels from all annotators in a training batch. The sets <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="m_{act}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><msub id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">m</mi><mrow id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml"><mi id="S3.SS3.p3.3.m3.1.1.3.2" xref="S3.SS3.p3.3.m3.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.3.m3.1.1.3.1" xref="S3.SS3.p3.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.3.m3.1.1.3.3" xref="S3.SS3.p3.3.m3.1.1.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.3.m3.1.1.3.1a" xref="S3.SS3.p3.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.3.m3.1.1.3.4" xref="S3.SS3.p3.3.m3.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝑚</ci><apply id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"><times id="S3.SS3.p3.3.m3.1.1.3.1.cmml" xref="S3.SS3.p3.3.m3.1.1.3.1"></times><ci id="S3.SS3.p3.3.m3.1.1.3.2.cmml" xref="S3.SS3.p3.3.m3.1.1.3.2">𝑎</ci><ci id="S3.SS3.p3.3.m3.1.1.3.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3.3">𝑐</ci><ci id="S3.SS3.p3.3.m3.1.1.3.4.cmml" xref="S3.SS3.p3.3.m3.1.1.3.4">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">m_{act}</annotation></semantics></math> and <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="m_{val}" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><msub id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">m</mi><mrow id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml"><mi id="S3.SS3.p3.4.m4.1.1.3.2" xref="S3.SS3.p3.4.m4.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.4.m4.1.1.3.1" xref="S3.SS3.p3.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.4.m4.1.1.3.3" xref="S3.SS3.p3.4.m4.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.4.m4.1.1.3.1a" xref="S3.SS3.p3.4.m4.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.4.m4.1.1.3.4" xref="S3.SS3.p3.4.m4.1.1.3.4.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">𝑚</ci><apply id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3"><times id="S3.SS3.p3.4.m4.1.1.3.1.cmml" xref="S3.SS3.p3.4.m4.1.1.3.1"></times><ci id="S3.SS3.p3.4.m4.1.1.3.2.cmml" xref="S3.SS3.p3.4.m4.1.1.3.2">𝑣</ci><ci id="S3.SS3.p3.4.m4.1.1.3.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3.3">𝑎</ci><ci id="S3.SS3.p3.4.m4.1.1.3.4.cmml" xref="S3.SS3.p3.4.m4.1.1.3.4">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">m_{val}</annotation></semantics></math> contain the model's estimates of these labels. The loss is <math id="S3.SS3.p3.5.m5.4" class="ltx_Math" alttext="2-CCC(m_{act},act)-CCC(m_{val},val)" display="inline"><semantics id="S3.SS3.p3.5.m5.4a"><mrow id="S3.SS3.p3.5.m5.4.4" xref="S3.SS3.p3.5.m5.4.4.cmml"><mn id="S3.SS3.p3.5.m5.4.4.6" xref="S3.SS3.p3.5.m5.4.4.6.cmml">2</mn><mo id="S3.SS3.p3.5.m5.4.4.5" xref="S3.SS3.p3.5.m5.4.4.5.cmml">−</mo><mrow id="S3.SS3.p3.5.m5.2.2.2" xref="S3.SS3.p3.5.m5.2.2.2.cmml"><mi id="S3.SS3.p3.5.m5.2.2.2.4" xref="S3.SS3.p3.5.m5.2.2.2.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.2.2.2.3" xref="S3.SS3.p3.5.m5.2.2.2.3.cmml">​</mo><mi id="S3.SS3.p3.5.m5.2.2.2.5" xref="S3.SS3.p3.5.m5.2.2.2.5.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.2.2.2.3a" xref="S3.SS3.p3.5.m5.2.2.2.3.cmml">​</mo><mi id="S3.SS3.p3.5.m5.2.2.2.6" xref="S3.SS3.p3.5.m5.2.2.2.6.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.2.2.2.3b" xref="S3.SS3.p3.5.m5.2.2.2.3.cmml">​</mo><mrow id="S3.SS3.p3.5.m5.2.2.2.2.2" xref="S3.SS3.p3.5.m5.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p3.5.m5.2.2.2.2.2.3" xref="S3.SS3.p3.5.m5.2.2.2.2.3.cmml">(</mo><msub id="S3.SS3.p3.5.m5.1.1.1.1.1.1" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.5.m5.1.1.1.1.1.1.2" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.2.cmml">m</mi><mrow id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.2" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.1" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.3" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.1a" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.4" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.4.cmml">t</mi></mrow></msub><mo id="S3.SS3.p3.5.m5.2.2.2.2.2.4" xref="S3.SS3.p3.5.m5.2.2.2.2.3.cmml">,</mo><mrow id="S3.SS3.p3.5.m5.2.2.2.2.2.2" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.cmml"><mi id="S3.SS3.p3.5.m5.2.2.2.2.2.2.2" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.2.2.2.2.2.2.1" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.2.2.2.2.2.2.3" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.2.2.2.2.2.2.1a" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.2.2.2.2.2.2.4" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.4.cmml">t</mi></mrow><mo stretchy="false" id="S3.SS3.p3.5.m5.2.2.2.2.2.5" xref="S3.SS3.p3.5.m5.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p3.5.m5.4.4.5a" xref="S3.SS3.p3.5.m5.4.4.5.cmml">−</mo><mrow id="S3.SS3.p3.5.m5.4.4.4" xref="S3.SS3.p3.5.m5.4.4.4.cmml"><mi id="S3.SS3.p3.5.m5.4.4.4.4" xref="S3.SS3.p3.5.m5.4.4.4.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.4.4.4.3" xref="S3.SS3.p3.5.m5.4.4.4.3.cmml">​</mo><mi id="S3.SS3.p3.5.m5.4.4.4.5" xref="S3.SS3.p3.5.m5.4.4.4.5.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.4.4.4.3a" xref="S3.SS3.p3.5.m5.4.4.4.3.cmml">​</mo><mi id="S3.SS3.p3.5.m5.4.4.4.6" xref="S3.SS3.p3.5.m5.4.4.4.6.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.4.4.4.3b" xref="S3.SS3.p3.5.m5.4.4.4.3.cmml">​</mo><mrow id="S3.SS3.p3.5.m5.4.4.4.2.2" xref="S3.SS3.p3.5.m5.4.4.4.2.3.cmml"><mo stretchy="false" id="S3.SS3.p3.5.m5.4.4.4.2.2.3" xref="S3.SS3.p3.5.m5.4.4.4.2.3.cmml">(</mo><msub id="S3.SS3.p3.5.m5.3.3.3.1.1.1" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.cmml"><mi id="S3.SS3.p3.5.m5.3.3.3.1.1.1.2" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.2.cmml">m</mi><mrow id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.cmml"><mi id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.2" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.1" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.3" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.1a" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.4" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.4.cmml">l</mi></mrow></msub><mo id="S3.SS3.p3.5.m5.4.4.4.2.2.4" xref="S3.SS3.p3.5.m5.4.4.4.2.3.cmml">,</mo><mrow id="S3.SS3.p3.5.m5.4.4.4.2.2.2" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.cmml"><mi id="S3.SS3.p3.5.m5.4.4.4.2.2.2.2" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.4.4.4.2.2.2.1" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.4.4.4.2.2.2.3" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.4.4.4.2.2.2.1a" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p3.5.m5.4.4.4.2.2.2.4" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.4.cmml">l</mi></mrow><mo stretchy="false" id="S3.SS3.p3.5.m5.4.4.4.2.2.5" xref="S3.SS3.p3.5.m5.4.4.4.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.4b"><apply id="S3.SS3.p3.5.m5.4.4.cmml" xref="S3.SS3.p3.5.m5.4.4"><minus id="S3.SS3.p3.5.m5.4.4.5.cmml" xref="S3.SS3.p3.5.m5.4.4.5"></minus><cn type="integer" id="S3.SS3.p3.5.m5.4.4.6.cmml" xref="S3.SS3.p3.5.m5.4.4.6">2</cn><apply id="S3.SS3.p3.5.m5.2.2.2.cmml" xref="S3.SS3.p3.5.m5.2.2.2"><times id="S3.SS3.p3.5.m5.2.2.2.3.cmml" xref="S3.SS3.p3.5.m5.2.2.2.3"></times><ci id="S3.SS3.p3.5.m5.2.2.2.4.cmml" xref="S3.SS3.p3.5.m5.2.2.2.4">𝐶</ci><ci id="S3.SS3.p3.5.m5.2.2.2.5.cmml" xref="S3.SS3.p3.5.m5.2.2.2.5">𝐶</ci><ci id="S3.SS3.p3.5.m5.2.2.2.6.cmml" xref="S3.SS3.p3.5.m5.2.2.2.6">𝐶</ci><interval closure="open" id="S3.SS3.p3.5.m5.2.2.2.2.3.cmml" xref="S3.SS3.p3.5.m5.2.2.2.2.2"><apply id="S3.SS3.p3.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.2">𝑚</ci><apply id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3"><times id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.1"></times><ci id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.2">𝑎</ci><ci id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.3">𝑐</ci><ci id="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.4.cmml" xref="S3.SS3.p3.5.m5.1.1.1.1.1.1.3.4">𝑡</ci></apply></apply><apply id="S3.SS3.p3.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2"><times id="S3.SS3.p3.5.m5.2.2.2.2.2.2.1.cmml" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.1"></times><ci id="S3.SS3.p3.5.m5.2.2.2.2.2.2.2.cmml" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.2">𝑎</ci><ci id="S3.SS3.p3.5.m5.2.2.2.2.2.2.3.cmml" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.3">𝑐</ci><ci id="S3.SS3.p3.5.m5.2.2.2.2.2.2.4.cmml" xref="S3.SS3.p3.5.m5.2.2.2.2.2.2.4">𝑡</ci></apply></interval></apply><apply id="S3.SS3.p3.5.m5.4.4.4.cmml" xref="S3.SS3.p3.5.m5.4.4.4"><times id="S3.SS3.p3.5.m5.4.4.4.3.cmml" xref="S3.SS3.p3.5.m5.4.4.4.3"></times><ci id="S3.SS3.p3.5.m5.4.4.4.4.cmml" xref="S3.SS3.p3.5.m5.4.4.4.4">𝐶</ci><ci id="S3.SS3.p3.5.m5.4.4.4.5.cmml" xref="S3.SS3.p3.5.m5.4.4.4.5">𝐶</ci><ci id="S3.SS3.p3.5.m5.4.4.4.6.cmml" xref="S3.SS3.p3.5.m5.4.4.4.6">𝐶</ci><interval closure="open" id="S3.SS3.p3.5.m5.4.4.4.2.3.cmml" xref="S3.SS3.p3.5.m5.4.4.4.2.2"><apply id="S3.SS3.p3.5.m5.3.3.3.1.1.1.cmml" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.3.3.3.1.1.1.1.cmml" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.5.m5.3.3.3.1.1.1.2.cmml" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.2">𝑚</ci><apply id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.cmml" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3"><times id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.1.cmml" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.1"></times><ci id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.2.cmml" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.2">𝑣</ci><ci id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.3.cmml" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.3">𝑎</ci><ci id="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.4.cmml" xref="S3.SS3.p3.5.m5.3.3.3.1.1.1.3.4">𝑙</ci></apply></apply><apply id="S3.SS3.p3.5.m5.4.4.4.2.2.2.cmml" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2"><times id="S3.SS3.p3.5.m5.4.4.4.2.2.2.1.cmml" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.1"></times><ci id="S3.SS3.p3.5.m5.4.4.4.2.2.2.2.cmml" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.2">𝑣</ci><ci id="S3.SS3.p3.5.m5.4.4.4.2.2.2.3.cmml" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.3">𝑎</ci><ci id="S3.SS3.p3.5.m5.4.4.4.2.2.2.4.cmml" xref="S3.SS3.p3.5.m5.4.4.4.2.2.2.4">𝑙</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.4c">2-CCC(m_{act},act)-CCC(m_{val},val)</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold">Task 2 - <span id="S3.SS3.p4.1.1.1" class="ltx_text ltx_font_italic">DiffKDE</span></span>:
We learn the probability distribution using the KDE-generated ground truth labels. The model must produce a probability distribution from the model's activation and valence predictions. However, the KDE method outlined by Zhang et al. in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> is not immediately usable. KDE via diffusion starts with a histogram <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. For each annotation we must know if it is in a particular bin to increment the bin's histogram count. This operation is a binary operation and not differentiable. We introduce a differentiable approximation to this problem by instead calculating a confidence value that a given annotation is within a given bin. We modify an existing one-dimensional (1D) soft-histogram<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://discuss.pytorch.org/t/differentiable-torch-histc/25865/4</span></span></span>, as below, for the 2D data.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.13" class="ltx_p">We use 64 bins for <span id="S3.SS3.p5.13.1" class="ltx_text ltx_font_italic">DiffKDE<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_upright">4</span></span><span id="footnote4.5" class="ltx_text ltx_font_upright">Note: smaller than 512 (used to generate target labels) for speed</span></span></span></span></span>. We first calculate the 1D center of each bin in the range <math id="S3.SS3.p5.1.m1.1" class="ltx_Math" alttext="-1" display="inline"><semantics id="S3.SS3.p5.1.m1.1a"><mrow id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mo id="S3.SS3.p5.1.m1.1.1a" xref="S3.SS3.p5.1.m1.1.1.cmml">−</mo><mn id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><minus id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"></minus><cn type="integer" id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">-1</annotation></semantics></math> to <math id="S3.SS3.p5.2.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS3.p5.2.m2.1a"><mn id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><cn type="integer" id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">1</annotation></semantics></math>. For each of the <math id="S3.SS3.p5.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p5.3.m3.1a"><mi id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><ci id="S3.SS3.p5.3.m3.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">n</annotation></semantics></math> annotations of activation, we subtract the center of each bin from the annotation, resulting in a <math id="S3.SS3.p5.4.m4.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S3.SS3.p5.4.m4.1a"><mn id="S3.SS3.p5.4.m4.1.1" xref="S3.SS3.p5.4.m4.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.4.m4.1b"><cn type="integer" id="S3.SS3.p5.4.m4.1.1.cmml" xref="S3.SS3.p5.4.m4.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.4.m4.1c">64</annotation></semantics></math> size vector, which we call <math id="S3.SS3.p5.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p5.5.m5.1a"><mi id="S3.SS3.p5.5.m5.1.1" xref="S3.SS3.p5.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.5.m5.1b"><ci id="S3.SS3.p5.5.m5.1.1.cmml" xref="S3.SS3.p5.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.5.m5.1c">x</annotation></semantics></math>. The contribution to the <math id="S3.SS3.p5.6.m6.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S3.SS3.p5.6.m6.1a"><mn id="S3.SS3.p5.6.m6.1.1" xref="S3.SS3.p5.6.m6.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.6.m6.1b"><cn type="integer" id="S3.SS3.p5.6.m6.1.1.cmml" xref="S3.SS3.p5.6.m6.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.6.m6.1c">64</annotation></semantics></math> bins will then be calculated using an element-wise <math id="S3.SS3.p5.7.m7.1" class="ltx_Math" alttext="sigmoid" display="inline"><semantics id="S3.SS3.p5.7.m7.1a"><mrow id="S3.SS3.p5.7.m7.1.1" xref="S3.SS3.p5.7.m7.1.1.cmml"><mi id="S3.SS3.p5.7.m7.1.1.2" xref="S3.SS3.p5.7.m7.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.7.m7.1.1.1" xref="S3.SS3.p5.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.7.m7.1.1.3" xref="S3.SS3.p5.7.m7.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.7.m7.1.1.1a" xref="S3.SS3.p5.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.7.m7.1.1.4" xref="S3.SS3.p5.7.m7.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.7.m7.1.1.1b" xref="S3.SS3.p5.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.7.m7.1.1.5" xref="S3.SS3.p5.7.m7.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.7.m7.1.1.1c" xref="S3.SS3.p5.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.7.m7.1.1.6" xref="S3.SS3.p5.7.m7.1.1.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.7.m7.1.1.1d" xref="S3.SS3.p5.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.7.m7.1.1.7" xref="S3.SS3.p5.7.m7.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.7.m7.1.1.1e" xref="S3.SS3.p5.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.7.m7.1.1.8" xref="S3.SS3.p5.7.m7.1.1.8.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.7.m7.1b"><apply id="S3.SS3.p5.7.m7.1.1.cmml" xref="S3.SS3.p5.7.m7.1.1"><times id="S3.SS3.p5.7.m7.1.1.1.cmml" xref="S3.SS3.p5.7.m7.1.1.1"></times><ci id="S3.SS3.p5.7.m7.1.1.2.cmml" xref="S3.SS3.p5.7.m7.1.1.2">𝑠</ci><ci id="S3.SS3.p5.7.m7.1.1.3.cmml" xref="S3.SS3.p5.7.m7.1.1.3">𝑖</ci><ci id="S3.SS3.p5.7.m7.1.1.4.cmml" xref="S3.SS3.p5.7.m7.1.1.4">𝑔</ci><ci id="S3.SS3.p5.7.m7.1.1.5.cmml" xref="S3.SS3.p5.7.m7.1.1.5">𝑚</ci><ci id="S3.SS3.p5.7.m7.1.1.6.cmml" xref="S3.SS3.p5.7.m7.1.1.6">𝑜</ci><ci id="S3.SS3.p5.7.m7.1.1.7.cmml" xref="S3.SS3.p5.7.m7.1.1.7">𝑖</ci><ci id="S3.SS3.p5.7.m7.1.1.8.cmml" xref="S3.SS3.p5.7.m7.1.1.8">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.7.m7.1c">sigmoid</annotation></semantics></math> on this vector, <math id="S3.SS3.p5.8.m8.2" class="ltx_Math" alttext="sigmoid(\sigma*(x+\frac{\delta}{2}))-sigmoid(\sigma*(x-\frac{\delta}{2}))" display="inline"><semantics id="S3.SS3.p5.8.m8.2a"><mrow id="S3.SS3.p5.8.m8.2.2" xref="S3.SS3.p5.8.m8.2.2.cmml"><mrow id="S3.SS3.p5.8.m8.1.1.1" xref="S3.SS3.p5.8.m8.1.1.1.cmml"><mi id="S3.SS3.p5.8.m8.1.1.1.3" xref="S3.SS3.p5.8.m8.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.1.1.1.2" xref="S3.SS3.p5.8.m8.1.1.1.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.1.1.1.4" xref="S3.SS3.p5.8.m8.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.1.1.1.2a" xref="S3.SS3.p5.8.m8.1.1.1.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.1.1.1.5" xref="S3.SS3.p5.8.m8.1.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.1.1.1.2b" xref="S3.SS3.p5.8.m8.1.1.1.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.1.1.1.6" xref="S3.SS3.p5.8.m8.1.1.1.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.1.1.1.2c" xref="S3.SS3.p5.8.m8.1.1.1.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.1.1.1.7" xref="S3.SS3.p5.8.m8.1.1.1.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.1.1.1.2d" xref="S3.SS3.p5.8.m8.1.1.1.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.1.1.1.8" xref="S3.SS3.p5.8.m8.1.1.1.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.1.1.1.2e" xref="S3.SS3.p5.8.m8.1.1.1.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.1.1.1.9" xref="S3.SS3.p5.8.m8.1.1.1.9.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.1.1.1.2f" xref="S3.SS3.p5.8.m8.1.1.1.2.cmml">​</mo><mrow id="S3.SS3.p5.8.m8.1.1.1.1.1" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p5.8.m8.1.1.1.1.1.2" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p5.8.m8.1.1.1.1.1.1" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.8.m8.1.1.1.1.1.1.3" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.3.cmml">σ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p5.8.m8.1.1.1.1.1.1.2" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.2.cmml">∗</mo><mrow id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.2" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.2" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.1" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mfrac id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.2" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.2.cmml">δ</mi><mn id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.3" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.3.cmml">2</mn></mfrac></mrow><mo stretchy="false" id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.3" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS3.p5.8.m8.1.1.1.1.1.3" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p5.8.m8.2.2.3" xref="S3.SS3.p5.8.m8.2.2.3.cmml">−</mo><mrow id="S3.SS3.p5.8.m8.2.2.2" xref="S3.SS3.p5.8.m8.2.2.2.cmml"><mi id="S3.SS3.p5.8.m8.2.2.2.3" xref="S3.SS3.p5.8.m8.2.2.2.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.2.2.2.2" xref="S3.SS3.p5.8.m8.2.2.2.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.2.2.2.4" xref="S3.SS3.p5.8.m8.2.2.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.2.2.2.2a" xref="S3.SS3.p5.8.m8.2.2.2.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.2.2.2.5" xref="S3.SS3.p5.8.m8.2.2.2.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.2.2.2.2b" xref="S3.SS3.p5.8.m8.2.2.2.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.2.2.2.6" xref="S3.SS3.p5.8.m8.2.2.2.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.2.2.2.2c" xref="S3.SS3.p5.8.m8.2.2.2.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.2.2.2.7" xref="S3.SS3.p5.8.m8.2.2.2.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.2.2.2.2d" xref="S3.SS3.p5.8.m8.2.2.2.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.2.2.2.8" xref="S3.SS3.p5.8.m8.2.2.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.2.2.2.2e" xref="S3.SS3.p5.8.m8.2.2.2.2.cmml">​</mo><mi id="S3.SS3.p5.8.m8.2.2.2.9" xref="S3.SS3.p5.8.m8.2.2.2.9.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.8.m8.2.2.2.2f" xref="S3.SS3.p5.8.m8.2.2.2.2.cmml">​</mo><mrow id="S3.SS3.p5.8.m8.2.2.2.1.1" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p5.8.m8.2.2.2.1.1.2" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.SS3.p5.8.m8.2.2.2.1.1.1" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.cmml"><mi id="S3.SS3.p5.8.m8.2.2.2.1.1.1.3" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.3.cmml">σ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p5.8.m8.2.2.2.1.1.1.2" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.2.cmml">∗</mo><mrow id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.2" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.2" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.2.cmml">x</mi><mo id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.1" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.1.cmml">−</mo><mfrac id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.2" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.2.cmml">δ</mi><mn id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.3" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.3.cmml">2</mn></mfrac></mrow><mo stretchy="false" id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.3" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS3.p5.8.m8.2.2.2.1.1.3" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.8.m8.2b"><apply id="S3.SS3.p5.8.m8.2.2.cmml" xref="S3.SS3.p5.8.m8.2.2"><minus id="S3.SS3.p5.8.m8.2.2.3.cmml" xref="S3.SS3.p5.8.m8.2.2.3"></minus><apply id="S3.SS3.p5.8.m8.1.1.1.cmml" xref="S3.SS3.p5.8.m8.1.1.1"><times id="S3.SS3.p5.8.m8.1.1.1.2.cmml" xref="S3.SS3.p5.8.m8.1.1.1.2"></times><ci id="S3.SS3.p5.8.m8.1.1.1.3.cmml" xref="S3.SS3.p5.8.m8.1.1.1.3">𝑠</ci><ci id="S3.SS3.p5.8.m8.1.1.1.4.cmml" xref="S3.SS3.p5.8.m8.1.1.1.4">𝑖</ci><ci id="S3.SS3.p5.8.m8.1.1.1.5.cmml" xref="S3.SS3.p5.8.m8.1.1.1.5">𝑔</ci><ci id="S3.SS3.p5.8.m8.1.1.1.6.cmml" xref="S3.SS3.p5.8.m8.1.1.1.6">𝑚</ci><ci id="S3.SS3.p5.8.m8.1.1.1.7.cmml" xref="S3.SS3.p5.8.m8.1.1.1.7">𝑜</ci><ci id="S3.SS3.p5.8.m8.1.1.1.8.cmml" xref="S3.SS3.p5.8.m8.1.1.1.8">𝑖</ci><ci id="S3.SS3.p5.8.m8.1.1.1.9.cmml" xref="S3.SS3.p5.8.m8.1.1.1.9">𝑑</ci><apply id="S3.SS3.p5.8.m8.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1"><times id="S3.SS3.p5.8.m8.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.2"></times><ci id="S3.SS3.p5.8.m8.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.3">𝜎</ci><apply id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1"><plus id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.1"></plus><ci id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.2">𝑥</ci><apply id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3"><divide id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3"></divide><ci id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.2">𝛿</ci><cn type="integer" id="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p5.8.m8.1.1.1.1.1.1.1.1.1.3.3">2</cn></apply></apply></apply></apply><apply id="S3.SS3.p5.8.m8.2.2.2.cmml" xref="S3.SS3.p5.8.m8.2.2.2"><times id="S3.SS3.p5.8.m8.2.2.2.2.cmml" xref="S3.SS3.p5.8.m8.2.2.2.2"></times><ci id="S3.SS3.p5.8.m8.2.2.2.3.cmml" xref="S3.SS3.p5.8.m8.2.2.2.3">𝑠</ci><ci id="S3.SS3.p5.8.m8.2.2.2.4.cmml" xref="S3.SS3.p5.8.m8.2.2.2.4">𝑖</ci><ci id="S3.SS3.p5.8.m8.2.2.2.5.cmml" xref="S3.SS3.p5.8.m8.2.2.2.5">𝑔</ci><ci id="S3.SS3.p5.8.m8.2.2.2.6.cmml" xref="S3.SS3.p5.8.m8.2.2.2.6">𝑚</ci><ci id="S3.SS3.p5.8.m8.2.2.2.7.cmml" xref="S3.SS3.p5.8.m8.2.2.2.7">𝑜</ci><ci id="S3.SS3.p5.8.m8.2.2.2.8.cmml" xref="S3.SS3.p5.8.m8.2.2.2.8">𝑖</ci><ci id="S3.SS3.p5.8.m8.2.2.2.9.cmml" xref="S3.SS3.p5.8.m8.2.2.2.9">𝑑</ci><apply id="S3.SS3.p5.8.m8.2.2.2.1.1.1.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1"><times id="S3.SS3.p5.8.m8.2.2.2.1.1.1.2.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.2"></times><ci id="S3.SS3.p5.8.m8.2.2.2.1.1.1.3.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.3">𝜎</ci><apply id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1"><minus id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.1"></minus><ci id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.2">𝑥</ci><apply id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3"><divide id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3"></divide><ci id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.2">𝛿</ci><cn type="integer" id="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p5.8.m8.2.2.2.1.1.1.1.1.1.3.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.8.m8.2c">sigmoid(\sigma*(x+\frac{\delta}{2}))-sigmoid(\sigma*(x-\frac{\delta}{2}))</annotation></semantics></math>. The gradient of <math id="S3.SS3.p5.9.m9.1" class="ltx_Math" alttext="sigmoid" display="inline"><semantics id="S3.SS3.p5.9.m9.1a"><mrow id="S3.SS3.p5.9.m9.1.1" xref="S3.SS3.p5.9.m9.1.1.cmml"><mi id="S3.SS3.p5.9.m9.1.1.2" xref="S3.SS3.p5.9.m9.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.9.m9.1.1.1" xref="S3.SS3.p5.9.m9.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.9.m9.1.1.3" xref="S3.SS3.p5.9.m9.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.9.m9.1.1.1a" xref="S3.SS3.p5.9.m9.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.9.m9.1.1.4" xref="S3.SS3.p5.9.m9.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.9.m9.1.1.1b" xref="S3.SS3.p5.9.m9.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.9.m9.1.1.5" xref="S3.SS3.p5.9.m9.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.9.m9.1.1.1c" xref="S3.SS3.p5.9.m9.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.9.m9.1.1.6" xref="S3.SS3.p5.9.m9.1.1.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.9.m9.1.1.1d" xref="S3.SS3.p5.9.m9.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.9.m9.1.1.7" xref="S3.SS3.p5.9.m9.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.9.m9.1.1.1e" xref="S3.SS3.p5.9.m9.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.9.m9.1.1.8" xref="S3.SS3.p5.9.m9.1.1.8.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.9.m9.1b"><apply id="S3.SS3.p5.9.m9.1.1.cmml" xref="S3.SS3.p5.9.m9.1.1"><times id="S3.SS3.p5.9.m9.1.1.1.cmml" xref="S3.SS3.p5.9.m9.1.1.1"></times><ci id="S3.SS3.p5.9.m9.1.1.2.cmml" xref="S3.SS3.p5.9.m9.1.1.2">𝑠</ci><ci id="S3.SS3.p5.9.m9.1.1.3.cmml" xref="S3.SS3.p5.9.m9.1.1.3">𝑖</ci><ci id="S3.SS3.p5.9.m9.1.1.4.cmml" xref="S3.SS3.p5.9.m9.1.1.4">𝑔</ci><ci id="S3.SS3.p5.9.m9.1.1.5.cmml" xref="S3.SS3.p5.9.m9.1.1.5">𝑚</ci><ci id="S3.SS3.p5.9.m9.1.1.6.cmml" xref="S3.SS3.p5.9.m9.1.1.6">𝑜</ci><ci id="S3.SS3.p5.9.m9.1.1.7.cmml" xref="S3.SS3.p5.9.m9.1.1.7">𝑖</ci><ci id="S3.SS3.p5.9.m9.1.1.8.cmml" xref="S3.SS3.p5.9.m9.1.1.8">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.9.m9.1c">sigmoid</annotation></semantics></math> is largest at zero, for values of <math id="S3.SS3.p5.10.m10.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p5.10.m10.1a"><mi id="S3.SS3.p5.10.m10.1.1" xref="S3.SS3.p5.10.m10.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.10.m10.1b"><ci id="S3.SS3.p5.10.m10.1.1.cmml" xref="S3.SS3.p5.10.m10.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.10.m10.1c">x</annotation></semantics></math> far from 0, the <math id="S3.SS3.p5.11.m11.1" class="ltx_Math" alttext="\frac{\delta}{2}" display="inline"><semantics id="S3.SS3.p5.11.m11.1a"><mfrac id="S3.SS3.p5.11.m11.1.1" xref="S3.SS3.p5.11.m11.1.1.cmml"><mi id="S3.SS3.p5.11.m11.1.1.2" xref="S3.SS3.p5.11.m11.1.1.2.cmml">δ</mi><mn id="S3.SS3.p5.11.m11.1.1.3" xref="S3.SS3.p5.11.m11.1.1.3.cmml">2</mn></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.11.m11.1b"><apply id="S3.SS3.p5.11.m11.1.1.cmml" xref="S3.SS3.p5.11.m11.1.1"><divide id="S3.SS3.p5.11.m11.1.1.1.cmml" xref="S3.SS3.p5.11.m11.1.1"></divide><ci id="S3.SS3.p5.11.m11.1.1.2.cmml" xref="S3.SS3.p5.11.m11.1.1.2">𝛿</ci><cn type="integer" id="S3.SS3.p5.11.m11.1.1.3.cmml" xref="S3.SS3.p5.11.m11.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.11.m11.1c">\frac{\delta}{2}</annotation></semantics></math> term has less effect, and the bin value is close to 0. This function is maximized for values of <math id="S3.SS3.p5.12.m12.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p5.12.m12.1a"><mi id="S3.SS3.p5.12.m12.1.1" xref="S3.SS3.p5.12.m12.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.12.m12.1b"><ci id="S3.SS3.p5.12.m12.1.1.cmml" xref="S3.SS3.p5.12.m12.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.12.m12.1c">x</annotation></semantics></math> close to 0. We repeat this for valence to get two <math id="S3.SS3.p5.13.m13.1" class="ltx_Math" alttext="n\times 64" display="inline"><semantics id="S3.SS3.p5.13.m13.1a"><mrow id="S3.SS3.p5.13.m13.1.1" xref="S3.SS3.p5.13.m13.1.1.cmml"><mi id="S3.SS3.p5.13.m13.1.1.2" xref="S3.SS3.p5.13.m13.1.1.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p5.13.m13.1.1.1" xref="S3.SS3.p5.13.m13.1.1.1.cmml">×</mo><mn id="S3.SS3.p5.13.m13.1.1.3" xref="S3.SS3.p5.13.m13.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.13.m13.1b"><apply id="S3.SS3.p5.13.m13.1.1.cmml" xref="S3.SS3.p5.13.m13.1.1"><times id="S3.SS3.p5.13.m13.1.1.1.cmml" xref="S3.SS3.p5.13.m13.1.1.1"></times><ci id="S3.SS3.p5.13.m13.1.1.2.cmml" xref="S3.SS3.p5.13.m13.1.1.2">𝑛</ci><cn type="integer" id="S3.SS3.p5.13.m13.1.1.3.cmml" xref="S3.SS3.p5.13.m13.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.13.m13.1c">n\times 64</annotation></semantics></math> matrices for activation and valence.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.12" class="ltx_p">In the equation, <math id="S3.SS3.p6.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS3.p6.1.m1.1a"><mi id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><ci id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">\sigma</annotation></semantics></math> is a scaling parameter; the larger the value, the more sharp the histogram is, and <math id="S3.SS3.p6.2.m2.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="S3.SS3.p6.2.m2.1a"><mi id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><ci id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">\delta</annotation></semantics></math> is the bin size. Since our data is in the range <math id="S3.SS3.p6.3.m3.1" class="ltx_Math" alttext="-1" display="inline"><semantics id="S3.SS3.p6.3.m3.1a"><mrow id="S3.SS3.p6.3.m3.1.1" xref="S3.SS3.p6.3.m3.1.1.cmml"><mo id="S3.SS3.p6.3.m3.1.1a" xref="S3.SS3.p6.3.m3.1.1.cmml">−</mo><mn id="S3.SS3.p6.3.m3.1.1.2" xref="S3.SS3.p6.3.m3.1.1.2.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m3.1b"><apply id="S3.SS3.p6.3.m3.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1"><minus id="S3.SS3.p6.3.m3.1.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1"></minus><cn type="integer" id="S3.SS3.p6.3.m3.1.1.2.cmml" xref="S3.SS3.p6.3.m3.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m3.1c">-1</annotation></semantics></math> to <math id="S3.SS3.p6.4.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS3.p6.4.m4.1a"><mn id="S3.SS3.p6.4.m4.1.1" xref="S3.SS3.p6.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.4.m4.1b"><cn type="integer" id="S3.SS3.p6.4.m4.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.4.m4.1c">1</annotation></semantics></math>, and we use 64 bins, <math id="S3.SS3.p6.5.m5.1" class="ltx_Math" alttext="\delta=\frac{2}{64}" display="inline"><semantics id="S3.SS3.p6.5.m5.1a"><mrow id="S3.SS3.p6.5.m5.1.1" xref="S3.SS3.p6.5.m5.1.1.cmml"><mi id="S3.SS3.p6.5.m5.1.1.2" xref="S3.SS3.p6.5.m5.1.1.2.cmml">δ</mi><mo id="S3.SS3.p6.5.m5.1.1.1" xref="S3.SS3.p6.5.m5.1.1.1.cmml">=</mo><mfrac id="S3.SS3.p6.5.m5.1.1.3" xref="S3.SS3.p6.5.m5.1.1.3.cmml"><mn id="S3.SS3.p6.5.m5.1.1.3.2" xref="S3.SS3.p6.5.m5.1.1.3.2.cmml">2</mn><mn id="S3.SS3.p6.5.m5.1.1.3.3" xref="S3.SS3.p6.5.m5.1.1.3.3.cmml">64</mn></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.5.m5.1b"><apply id="S3.SS3.p6.5.m5.1.1.cmml" xref="S3.SS3.p6.5.m5.1.1"><eq id="S3.SS3.p6.5.m5.1.1.1.cmml" xref="S3.SS3.p6.5.m5.1.1.1"></eq><ci id="S3.SS3.p6.5.m5.1.1.2.cmml" xref="S3.SS3.p6.5.m5.1.1.2">𝛿</ci><apply id="S3.SS3.p6.5.m5.1.1.3.cmml" xref="S3.SS3.p6.5.m5.1.1.3"><divide id="S3.SS3.p6.5.m5.1.1.3.1.cmml" xref="S3.SS3.p6.5.m5.1.1.3"></divide><cn type="integer" id="S3.SS3.p6.5.m5.1.1.3.2.cmml" xref="S3.SS3.p6.5.m5.1.1.3.2">2</cn><cn type="integer" id="S3.SS3.p6.5.m5.1.1.3.3.cmml" xref="S3.SS3.p6.5.m5.1.1.3.3">64</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.5.m5.1c">\delta=\frac{2}{64}</annotation></semantics></math>. We then matrix multiply these two <math id="S3.SS3.p6.6.m6.1" class="ltx_Math" alttext="n\times 64" display="inline"><semantics id="S3.SS3.p6.6.m6.1a"><mrow id="S3.SS3.p6.6.m6.1.1" xref="S3.SS3.p6.6.m6.1.1.cmml"><mi id="S3.SS3.p6.6.m6.1.1.2" xref="S3.SS3.p6.6.m6.1.1.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p6.6.m6.1.1.1" xref="S3.SS3.p6.6.m6.1.1.1.cmml">×</mo><mn id="S3.SS3.p6.6.m6.1.1.3" xref="S3.SS3.p6.6.m6.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.6.m6.1b"><apply id="S3.SS3.p6.6.m6.1.1.cmml" xref="S3.SS3.p6.6.m6.1.1"><times id="S3.SS3.p6.6.m6.1.1.1.cmml" xref="S3.SS3.p6.6.m6.1.1.1"></times><ci id="S3.SS3.p6.6.m6.1.1.2.cmml" xref="S3.SS3.p6.6.m6.1.1.2">𝑛</ci><cn type="integer" id="S3.SS3.p6.6.m6.1.1.3.cmml" xref="S3.SS3.p6.6.m6.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.6.m6.1c">n\times 64</annotation></semantics></math> matrices by transposing one to get a 2D (<math id="S3.SS3.p6.7.m7.1" class="ltx_Math" alttext="64\times 64" display="inline"><semantics id="S3.SS3.p6.7.m7.1a"><mrow id="S3.SS3.p6.7.m7.1.1" xref="S3.SS3.p6.7.m7.1.1.cmml"><mn id="S3.SS3.p6.7.m7.1.1.2" xref="S3.SS3.p6.7.m7.1.1.2.cmml">64</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p6.7.m7.1.1.1" xref="S3.SS3.p6.7.m7.1.1.1.cmml">×</mo><mn id="S3.SS3.p6.7.m7.1.1.3" xref="S3.SS3.p6.7.m7.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.7.m7.1b"><apply id="S3.SS3.p6.7.m7.1.1.cmml" xref="S3.SS3.p6.7.m7.1.1"><times id="S3.SS3.p6.7.m7.1.1.1.cmml" xref="S3.SS3.p6.7.m7.1.1.1"></times><cn type="integer" id="S3.SS3.p6.7.m7.1.1.2.cmml" xref="S3.SS3.p6.7.m7.1.1.2">64</cn><cn type="integer" id="S3.SS3.p6.7.m7.1.1.3.cmml" xref="S3.SS3.p6.7.m7.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.7.m7.1c">64\times 64</annotation></semantics></math>) matrix. We then normalize to get a final <math id="S3.SS3.p6.8.m8.1" class="ltx_Math" alttext="4\times 4" display="inline"><semantics id="S3.SS3.p6.8.m8.1a"><mrow id="S3.SS3.p6.8.m8.1.1" xref="S3.SS3.p6.8.m8.1.1.cmml"><mn id="S3.SS3.p6.8.m8.1.1.2" xref="S3.SS3.p6.8.m8.1.1.2.cmml">4</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p6.8.m8.1.1.1" xref="S3.SS3.p6.8.m8.1.1.1.cmml">×</mo><mn id="S3.SS3.p6.8.m8.1.1.3" xref="S3.SS3.p6.8.m8.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.8.m8.1b"><apply id="S3.SS3.p6.8.m8.1.1.cmml" xref="S3.SS3.p6.8.m8.1.1"><times id="S3.SS3.p6.8.m8.1.1.1.cmml" xref="S3.SS3.p6.8.m8.1.1.1"></times><cn type="integer" id="S3.SS3.p6.8.m8.1.1.2.cmml" xref="S3.SS3.p6.8.m8.1.1.2">4</cn><cn type="integer" id="S3.SS3.p6.8.m8.1.1.3.cmml" xref="S3.SS3.p6.8.m8.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.8.m8.1c">4\times 4</annotation></semantics></math> probability distribution as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. There is a tradeoff where too large of a <math id="S3.SS3.p6.9.m9.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS3.p6.9.m9.1a"><mi id="S3.SS3.p6.9.m9.1.1" xref="S3.SS3.p6.9.m9.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.9.m9.1b"><ci id="S3.SS3.p6.9.m9.1.1.cmml" xref="S3.SS3.p6.9.m9.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.9.m9.1c">\sigma</annotation></semantics></math> may lead to vanishing gradients, but too low may result in undersaturation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. As such, we set <math id="S3.SS3.p6.10.m10.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS3.p6.10.m10.1a"><mi id="S3.SS3.p6.10.m10.1.1" xref="S3.SS3.p6.10.m10.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.10.m10.1b"><ci id="S3.SS3.p6.10.m10.1.1.cmml" xref="S3.SS3.p6.10.m10.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.10.m10.1c">\sigma</annotation></semantics></math> relatively small at <math id="S3.SS3.p6.11.m11.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S3.SS3.p6.11.m11.1a"><mn id="S3.SS3.p6.11.m11.1.1" xref="S3.SS3.p6.11.m11.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.11.m11.1b"><cn type="integer" id="S3.SS3.p6.11.m11.1.1.cmml" xref="S3.SS3.p6.11.m11.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.11.m11.1c">8</annotation></semantics></math>; lower values did not reduce loss. Future work could investigate the impact of modifying the <math id="S3.SS3.p6.12.m12.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS3.p6.12.m12.1a"><mi id="S3.SS3.p6.12.m12.1.1" xref="S3.SS3.p6.12.m12.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.12.m12.1b"><ci id="S3.SS3.p6.12.m12.1.1.cmml" xref="S3.SS3.p6.12.m12.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.12.m12.1c">\sigma</annotation></semantics></math> parameter. The generation of probabilities in <span id="S3.SS3.p6.12.1" class="ltx_text ltx_font_italic">DiffKDE</span> is done in <span id="S3.SS3.p6.12.2" class="ltx_text ltx_font_typewriter">float16<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span id="footnote5.1.1.1" class="ltx_text ltx_font_serif">5</span></span><span id="footnote5.5" class="ltx_text ltx_font_serif">We use </span><span id="footnote5.6" class="ltx_text">float64</span><span id="footnote5.7" class="ltx_text ltx_font_serif"> during validation and testing for KDE accuracy.</span></span></span></span></span> as it significantly speeds up calculations.</p>
</div>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p">We base our work off an existing KDE via Diffusion library<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://pypi.org/project/KDE-diffusion/</span></span></span>, which we modify to use PyTorch and the soft histogram method from the previous paragraph. All code is available on our GitHub page<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://github.com/chailab-umich/ModelingIndividualEvaluators</span></span></span>. This enables <span id="S3.SS3.p7.1.1" class="ltx_text ltx_font_italic">DiffKDE</span> to be run on GPUs and parallelized into batches. <span id="S3.SS3.p7.1.2" class="ltx_text ltx_font_italic">DiffKDE</span> Loss is the Cross-Entropy loss<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>After normalization, we add <math id="footnote8.m1.1" class="ltx_Math" alttext="\epsilon=1E^{-8}" display="inline"><semantics id="footnote8.m1.1b"><mrow id="footnote8.m1.1.1" xref="footnote8.m1.1.1.cmml"><mi id="footnote8.m1.1.1.2" xref="footnote8.m1.1.1.2.cmml">ϵ</mi><mo id="footnote8.m1.1.1.1" xref="footnote8.m1.1.1.1.cmml">=</mo><mrow id="footnote8.m1.1.1.3" xref="footnote8.m1.1.1.3.cmml"><mn id="footnote8.m1.1.1.3.2" xref="footnote8.m1.1.1.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="footnote8.m1.1.1.3.1" xref="footnote8.m1.1.1.3.1.cmml">​</mo><msup id="footnote8.m1.1.1.3.3" xref="footnote8.m1.1.1.3.3.cmml"><mi id="footnote8.m1.1.1.3.3.2" xref="footnote8.m1.1.1.3.3.2.cmml">E</mi><mrow id="footnote8.m1.1.1.3.3.3" xref="footnote8.m1.1.1.3.3.3.cmml"><mo id="footnote8.m1.1.1.3.3.3b" xref="footnote8.m1.1.1.3.3.3.cmml">−</mo><mn id="footnote8.m1.1.1.3.3.3.2" xref="footnote8.m1.1.1.3.3.3.2.cmml">8</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote8.m1.1c"><apply id="footnote8.m1.1.1.cmml" xref="footnote8.m1.1.1"><eq id="footnote8.m1.1.1.1.cmml" xref="footnote8.m1.1.1.1"></eq><ci id="footnote8.m1.1.1.2.cmml" xref="footnote8.m1.1.1.2">italic-ϵ</ci><apply id="footnote8.m1.1.1.3.cmml" xref="footnote8.m1.1.1.3"><times id="footnote8.m1.1.1.3.1.cmml" xref="footnote8.m1.1.1.3.1"></times><cn type="integer" id="footnote8.m1.1.1.3.2.cmml" xref="footnote8.m1.1.1.3.2">1</cn><apply id="footnote8.m1.1.1.3.3.cmml" xref="footnote8.m1.1.1.3.3"><csymbol cd="ambiguous" id="footnote8.m1.1.1.3.3.1.cmml" xref="footnote8.m1.1.1.3.3">superscript</csymbol><ci id="footnote8.m1.1.1.3.3.2.cmml" xref="footnote8.m1.1.1.3.3.2">𝐸</ci><apply id="footnote8.m1.1.1.3.3.3.cmml" xref="footnote8.m1.1.1.3.3.3"><minus id="footnote8.m1.1.1.3.3.3.1.cmml" xref="footnote8.m1.1.1.3.3.3"></minus><cn type="integer" id="footnote8.m1.1.1.3.3.3.2.cmml" xref="footnote8.m1.1.1.3.3.3.2">8</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote8.m1.1d">\epsilon=1E^{-8}</annotation></semantics></math> to avoid taking <math id="footnote8.m2.1" class="ltx_Math" alttext="\log" display="inline"><semantics id="footnote8.m2.1b"><mi id="footnote8.m2.1.1" xref="footnote8.m2.1.1.cmml">log</mi><annotation-xml encoding="MathML-Content" id="footnote8.m2.1c"><log id="footnote8.m2.1.1.cmml" xref="footnote8.m2.1.1"></log></annotation-xml><annotation encoding="application/x-tex" id="footnote8.m2.1d">\log</annotation></semantics></math> of 0.</span></span></span> of the <span id="S3.SS3.p7.1.3" class="ltx_text ltx_font_italic">DiffKDE</span> output, compared with the generated ground-truth 2D labels.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Evaluation Metrics</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">We first evaluate the ability of the proposed approaches to learn continuous predictions and then the ability of the system to learn distributions. The baseline cannot directly produce continuous ratings, while the proposed approaches can. In order to provide a fair comparison, we generate consensus predictions across all methods in the same manner: we sum along the activation/valence dimensions and then multiply this sum with <math id="S3.SS4.p1.1.m1.4" class="ltx_Math" alttext="[-1,-0.5,0.5,1]" display="inline"><semantics id="S3.SS4.p1.1.m1.4a"><mrow id="S3.SS4.p1.1.m1.4.4.2" xref="S3.SS4.p1.1.m1.4.4.3.cmml"><mo stretchy="false" id="S3.SS4.p1.1.m1.4.4.2.3" xref="S3.SS4.p1.1.m1.4.4.3.cmml">[</mo><mrow id="S3.SS4.p1.1.m1.3.3.1.1" xref="S3.SS4.p1.1.m1.3.3.1.1.cmml"><mo id="S3.SS4.p1.1.m1.3.3.1.1a" xref="S3.SS4.p1.1.m1.3.3.1.1.cmml">−</mo><mn id="S3.SS4.p1.1.m1.3.3.1.1.2" xref="S3.SS4.p1.1.m1.3.3.1.1.2.cmml">1</mn></mrow><mo id="S3.SS4.p1.1.m1.4.4.2.4" xref="S3.SS4.p1.1.m1.4.4.3.cmml">,</mo><mrow id="S3.SS4.p1.1.m1.4.4.2.2" xref="S3.SS4.p1.1.m1.4.4.2.2.cmml"><mo id="S3.SS4.p1.1.m1.4.4.2.2a" xref="S3.SS4.p1.1.m1.4.4.2.2.cmml">−</mo><mn id="S3.SS4.p1.1.m1.4.4.2.2.2" xref="S3.SS4.p1.1.m1.4.4.2.2.2.cmml">0.5</mn></mrow><mo id="S3.SS4.p1.1.m1.4.4.2.5" xref="S3.SS4.p1.1.m1.4.4.3.cmml">,</mo><mn id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">0.5</mn><mo id="S3.SS4.p1.1.m1.4.4.2.6" xref="S3.SS4.p1.1.m1.4.4.3.cmml">,</mo><mn id="S3.SS4.p1.1.m1.2.2" xref="S3.SS4.p1.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS4.p1.1.m1.4.4.2.7" xref="S3.SS4.p1.1.m1.4.4.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.4b"><list id="S3.SS4.p1.1.m1.4.4.3.cmml" xref="S3.SS4.p1.1.m1.4.4.2"><apply id="S3.SS4.p1.1.m1.3.3.1.1.cmml" xref="S3.SS4.p1.1.m1.3.3.1.1"><minus id="S3.SS4.p1.1.m1.3.3.1.1.1.cmml" xref="S3.SS4.p1.1.m1.3.3.1.1"></minus><cn type="integer" id="S3.SS4.p1.1.m1.3.3.1.1.2.cmml" xref="S3.SS4.p1.1.m1.3.3.1.1.2">1</cn></apply><apply id="S3.SS4.p1.1.m1.4.4.2.2.cmml" xref="S3.SS4.p1.1.m1.4.4.2.2"><minus id="S3.SS4.p1.1.m1.4.4.2.2.1.cmml" xref="S3.SS4.p1.1.m1.4.4.2.2"></minus><cn type="float" id="S3.SS4.p1.1.m1.4.4.2.2.2.cmml" xref="S3.SS4.p1.1.m1.4.4.2.2.2">0.5</cn></apply><cn type="float" id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">0.5</cn><cn type="integer" id="S3.SS4.p1.1.m1.2.2.cmml" xref="S3.SS4.p1.1.m1.2.2">1</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.4c">[-1,-0.5,0.5,1]</annotation></semantics></math>. We use CCC to measure the systems' ability to predict individual annotators' labels (note: we cannot evaluate the baseline for this task). Next, we evaluate the consensus predictions by comparing them to the averaged ground truth using CCC. Finally, we measure the differences between the learned and ground truth probability distributions using Total Variation Distance (TVD), and Jensen-Shannon Divergence (JSD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite><span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>We use natural logarithm for JSD instead of <math id="footnote9.m1.1" class="ltx_Math" alttext="\log_{2}" display="inline"><semantics id="footnote9.m1.1b"><msub id="footnote9.m1.1.1" xref="footnote9.m1.1.1.cmml"><mi id="footnote9.m1.1.1.2" xref="footnote9.m1.1.1.2.cmml">log</mi><mn id="footnote9.m1.1.1.3" xref="footnote9.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="footnote9.m1.1c"><apply id="footnote9.m1.1.1.cmml" xref="footnote9.m1.1.1"><csymbol cd="ambiguous" id="footnote9.m1.1.1.1.cmml" xref="footnote9.m1.1.1">subscript</csymbol><log id="footnote9.m1.1.1.2.cmml" xref="footnote9.m1.1.1.2"></log><cn type="integer" id="footnote9.m1.1.1.3.cmml" xref="footnote9.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote9.m1.1d">\log_{2}</annotation></semantics></math></span></span></span>. Test results are reported over five seeds. Significance asserted at a 5% confidence on a paired two-sided t-test.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.13.4.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.6.3" class="ltx_text" style="font-size:90%;">MSP-Improv probability distribution results (*=statistical significant improvement compared to baseline, <math id="S4.T1.4.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T1.4.1.m1.1b"><mo id="S4.T1.4.1.m1.1.1" xref="S4.T1.4.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.1.m1.1c"><ci id="S4.T1.4.1.m1.1.1.cmml" xref="S4.T1.4.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.1.m1.1d">\dagger</annotation></semantics></math>=statistical significant decline). <math id="S4.T1.5.2.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.5.2.m2.1b"><mo stretchy="false" id="S4.T1.5.2.m2.1.1" xref="S4.T1.5.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.2.m2.1c"><ci id="S4.T1.5.2.m2.1.1.cmml" xref="S4.T1.5.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.2.m2.1d">\uparrow</annotation></semantics></math> indicates higher is better, <math id="S4.T1.6.3.m3.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.6.3.m3.1b"><mo stretchy="false" id="S4.T1.6.3.m3.1.1" xref="S4.T1.6.3.m3.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.3.m3.1c"><ci id="S4.T1.6.3.m3.1.1.cmml" xref="S4.T1.6.3.m3.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.3.m3.1d">\downarrow</annotation></semantics></math> indicates lower is better. Each metric's best result is bolded.</span></figcaption>
<table id="S4.T1.11" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.10.4" class="ltx_tr">
<th id="S4.T1.10.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T1.10.4.5.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T1.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S4.T1.7.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.7.1.1.1.1" class="ltx_tr">
<td id="S4.T1.7.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S4.T1.7.1.1.1.1.1.1" class="ltx_text ltx_font_bold">TVD</span><math id="S4.T1.7.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.7.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.7.1.1.1.1.1.m1.1.1" xref="S4.T1.7.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.1.1.1.1.1.m1.1b"><ci id="S4.T1.7.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.7.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
</table>
</th>
<th id="S4.T1.8.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S4.T1.8.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.8.2.2.1.1" class="ltx_tr">
<td id="S4.T1.8.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S4.T1.8.2.2.1.1.1.1" class="ltx_text ltx_font_bold">JSD</span><math id="S4.T1.8.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.8.2.2.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.8.2.2.1.1.1.m1.1.1" xref="S4.T1.8.2.2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.2.2.1.1.1.m1.1b"><ci id="S4.T1.8.2.2.1.1.1.m1.1.1.cmml" xref="S4.T1.8.2.2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.2.2.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
</table>
</th>
<th id="S4.T1.9.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S4.T1.9.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.9.3.3.1.2" class="ltx_tr">
<td id="S4.T1.9.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T1.9.3.3.1.2.1.1" class="ltx_text ltx_font_bold">Activation</span></td>
</tr>
<tr id="S4.T1.9.3.3.1.1" class="ltx_tr">
<td id="S4.T1.9.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S4.T1.9.3.3.1.1.1.1" class="ltx_text ltx_font_bold">CCC</span><math id="S4.T1.9.3.3.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.9.3.3.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.9.3.3.1.1.1.m1.1.1" xref="S4.T1.9.3.3.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.3.3.1.1.1.m1.1b"><ci id="S4.T1.9.3.3.1.1.1.m1.1.1.cmml" xref="S4.T1.9.3.3.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.3.3.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
</table>
</th>
<th id="S4.T1.10.4.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">
<table id="S4.T1.10.4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.10.4.4.1.2" class="ltx_tr">
<td id="S4.T1.10.4.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T1.10.4.4.1.2.1.1" class="ltx_text ltx_font_bold">Valence</span></td>
</tr>
<tr id="S4.T1.10.4.4.1.1" class="ltx_tr">
<td id="S4.T1.10.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S4.T1.10.4.4.1.1.1.1" class="ltx_text ltx_font_bold">CCC</span><math id="S4.T1.10.4.4.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.10.4.4.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.10.4.4.1.1.1.m1.1.1" xref="S4.T1.10.4.4.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.4.4.1.1.1.m1.1b"><ci id="S4.T1.10.4.4.1.1.1.m1.1.1.cmml" xref="S4.T1.10.4.4.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.4.4.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.11.6.1" class="ltx_tr">
<th id="S4.T1.11.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Baseline</th>
<td id="S4.T1.11.6.1.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">.515±.004</td>
<td id="S4.T1.11.6.1.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">.213±.003</td>
<td id="S4.T1.11.6.1.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">.673±.008</td>
<td id="S4.T1.11.6.1.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">.573±.020</td>
</tr>
<tr id="S4.T1.11.7.2" class="ltx_tr">
<th id="S4.T1.11.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.0pt;padding-right:2.0pt;">MT</th>
<td id="S4.T1.11.7.2.2" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T1.11.7.2.2.1" class="ltx_text ltx_font_bold">.503±.001*</span></td>
<td id="S4.T1.11.7.2.3" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T1.11.7.2.3.1" class="ltx_text ltx_font_bold">.211±.001</span></td>
<td id="S4.T1.11.7.2.4" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T1.11.7.2.4.1" class="ltx_text ltx_font_bold">.741±.005*</span></td>
<td id="S4.T1.11.7.2.5" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">.571±.005</td>
</tr>
<tr id="S4.T1.11.5" class="ltx_tr">
<th id="S4.T1.11.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">One-hot</th>
<td id="S4.T1.11.5.3" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">.518±.006</td>
<td id="S4.T1.11.5.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">.228±.004<math id="S4.T1.11.5.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T1.11.5.1.m1.1a"><mo id="S4.T1.11.5.1.m1.1.1" xref="S4.T1.11.5.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.5.1.m1.1b"><ci id="S4.T1.11.5.1.m1.1.1.cmml" xref="S4.T1.11.5.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.5.1.m1.1c">\dagger</annotation></semantics></math>
</td>
<td id="S4.T1.11.5.4" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">.689±.014*</td>
<td id="S4.T1.11.5.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T1.11.5.5.1" class="ltx_text ltx_font_bold">.607±.017*</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>MSP-Improv Results</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.4" class="ltx_p">The MT approach predicts annotator-specific activation more accurately than the one-hot model (<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="0.629\pm 0.002" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">0.629</mn><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">±</mo><mn id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">0.002</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">0.629</cn><cn type="float" id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">0.002</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">0.629\pm 0.002</annotation></semantics></math> vs. <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="0.349\pm 0.015" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mn id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">0.349</mn><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">±</mo><mn id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">0.015</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">0.349</cn><cn type="float" id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">0.015</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">0.349\pm 0.015</annotation></semantics></math>, respectively) while the one-hot model has stronger performance for valence (<math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="0.393\pm 0.006" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mn id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">0.393</mn><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">±</mo><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">0.006</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">0.393</cn><cn type="float" id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">0.006</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">0.393\pm 0.006</annotation></semantics></math> vs. <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="0.429\pm 0.007" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mn id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">0.429</mn><mo id="S4.SS1.p1.4.m4.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml">±</mo><mn id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">0.007</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="latexml" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">0.429</cn><cn type="float" id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">0.007</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">0.429\pm 0.007</annotation></semantics></math>, respectively). The consensus output for both the MT and one-hot approaches show significant improvements in activation CCC compared to the baseline.
In contrast, only the one-hot method significantly improves valence. Overall, we find that the MT model learns more accurate distributions compared to the baseline when using the soft-histogram across both metrics, showing signficant improvement over the baseline for TVD.
The one-hot method has comparable TVD and statistically significantly worse JSD than the baseline.
See Table <a href="#S4.T1" title="Table 1 ‣ 4 Results ‣ The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for more details.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Ablation Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We investigate the importance of the interleaved training tasks for learning the distributions. In the previous experiments, we used <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">DiffKDE</span> during training and testing (Task 1+2). When using Task 1 alone, no distribution is used during training, so the best method to build the distribution is uncertain. We generated results for Task 1 alone using both <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">KDE</span> and <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_italic">DiffKDE</span> to generate distributions. We find that when using <span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_italic">DiffKDE</span> there is a significant performance increase for TVD (0.553±0.003 to 0.500±0.003) and JSD (0.265±0.002 to 0.211±0.002). This is very similar to the performance of Task 1+2 (Table <a href="#S4.T1" title="Table 1 ‣ 4 Results ‣ The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Cross-Corpus Results</h3>

<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.20.4.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.6.3" class="ltx_text" style="font-size:90%;">Cross-corpus zero-shot <span id="S4.T2.6.3.1" class="ltx_text ltx_font_bold">Act</span>ivation, <span id="S4.T2.6.3.2" class="ltx_text ltx_font_bold">Val</span>ence results, *,<math id="S4.T2.4.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.4.1.m1.1b"><mo id="S4.T2.4.1.m1.1.1" xref="S4.T2.4.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.1.m1.1c"><ci id="S4.T2.4.1.m1.1.1.cmml" xref="S4.T2.4.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.1.m1.1d">\dagger</annotation></semantics></math>,<math id="S4.T2.5.2.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.5.2.m2.1b"><mo stretchy="false" id="S4.T2.5.2.m2.1.1" xref="S4.T2.5.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.2.m2.1c"><ci id="S4.T2.5.2.m2.1.1.cmml" xref="S4.T2.5.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.2.m2.1d">\uparrow</annotation></semantics></math>,<math id="S4.T2.6.3.m3.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.6.3.m3.1b"><mo stretchy="false" id="S4.T2.6.3.m3.1.1" xref="S4.T2.6.3.m3.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.3.m3.1c"><ci id="S4.T2.6.3.m3.1.1.cmml" xref="S4.T2.6.3.m3.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.3.m3.1d">\downarrow</annotation></semantics></math> as in Table <a href="#S4.T1" title="Table 1 ‣ 4 Results ‣ The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. P: MSP-Podcast, I: IEMOCAP, M: MuSE</span></figcaption>
<table id="S4.T2.16" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.16.11.1" class="ltx_tr">
<th id="S4.T2.16.11.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"></th>
<th id="S4.T2.16.11.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.11.1.2.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S4.T2.16.11.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.11.1.3.1" class="ltx_text ltx_font_bold">Baseline</span></th>
<th id="S4.T2.16.11.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.11.1.4.1" class="ltx_text ltx_font_bold">MT-1</span></th>
<th id="S4.T2.16.11.1.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.11.1.5.1" class="ltx_text ltx_font_bold">MT-12</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.7.1" class="ltx_tr">
<th id="S4.T2.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="3"><span id="S4.T2.7.1.1.1" class="ltx_text ltx_font_bold">TVD<math id="S4.T2.7.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.7.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.7.1.1.1.1.m1.1.1" xref="S4.T2.7.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.1.1.1.1.m1.1b"><ci id="S4.T2.7.1.1.1.1.m1.1.1.cmml" xref="S4.T2.7.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S4.T2.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.7.1.2.1" class="ltx_text ltx_font_bold">P</span></th>
<td id="S4.T2.7.1.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.601±0.003</td>
<td id="S4.T2.7.1.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.7.1.4.1" class="ltx_text ltx_font_bold">0.507±0.002*</span></td>
<td id="S4.T2.7.1.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.518±0.005*</td>
</tr>
<tr id="S4.T2.16.12.1" class="ltx_tr">
<th id="S4.T2.16.12.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.12.1.1.1" class="ltx_text ltx_font_bold">I</span></th>
<td id="S4.T2.16.12.1.2" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.633±0.002</td>
<td id="S4.T2.16.12.1.3" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.614±0.002*</td>
<td id="S4.T2.16.12.1.4" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.12.1.4.1" class="ltx_text ltx_font_bold">0.613±0.002*</span></td>
</tr>
<tr id="S4.T2.16.13.2" class="ltx_tr">
<th id="S4.T2.16.13.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.13.2.1.1" class="ltx_text ltx_font_bold">M</span></th>
<td id="S4.T2.16.13.2.2" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.530±0.004</td>
<td id="S4.T2.16.13.2.3" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.484±0.007*</td>
<td id="S4.T2.16.13.2.4" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.13.2.4.1" class="ltx_text ltx_font_bold">0.470±0.002*</span></td>
</tr>
<tr id="S4.T2.8.2" class="ltx_tr">
<th id="S4.T2.8.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="3"><span id="S4.T2.8.2.1.1" class="ltx_text ltx_font_bold">JSD<math id="S4.T2.8.2.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.8.2.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.8.2.1.1.1.m1.1.1" xref="S4.T2.8.2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.8.2.1.1.1.m1.1b"><ci id="S4.T2.8.2.1.1.1.m1.1.1.cmml" xref="S4.T2.8.2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.2.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S4.T2.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.8.2.2.1" class="ltx_text ltx_font_bold">P</span></th>
<td id="S4.T2.8.2.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.274±0.002</td>
<td id="S4.T2.8.2.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.8.2.4.1" class="ltx_text ltx_font_bold">0.213±0.001*</span></td>
<td id="S4.T2.8.2.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.220±0.003*</td>
</tr>
<tr id="S4.T2.16.14.3" class="ltx_tr">
<th id="S4.T2.16.14.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.14.3.1.1" class="ltx_text ltx_font_bold">I</span></th>
<td id="S4.T2.16.14.3.2" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.310±0.002</td>
<td id="S4.T2.16.14.3.3" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.14.3.3.1" class="ltx_text ltx_font_bold">0.302±0.002*</span></td>
<td id="S4.T2.16.14.3.4" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.14.3.4.1" class="ltx_text ltx_font_bold">0.302±0.002*</span></td>
</tr>
<tr id="S4.T2.16.15.4" class="ltx_tr">
<th id="S4.T2.16.15.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.15.4.1.1" class="ltx_text ltx_font_bold">M</span></th>
<td id="S4.T2.16.15.4.2" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.218±0.003</td>
<td id="S4.T2.16.15.4.3" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.192±0.005*</td>
<td id="S4.T2.16.15.4.4" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.15.4.4.1" class="ltx_text ltx_font_bold">0.182±0.002*</span></td>
</tr>
<tr id="S4.T2.10.4" class="ltx_tr">
<th id="S4.T2.9.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="3"><span id="S4.T2.9.3.1.1" class="ltx_text">
<span id="S4.T2.9.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T2.9.3.1.1.1.2" class="ltx_tr">
<span id="S4.T2.9.3.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.9.3.1.1.1.2.1.1" class="ltx_text ltx_font_bold">Act.</span></span></span>
<span id="S4.T2.9.3.1.1.1.1" class="ltx_tr">
<span id="S4.T2.9.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.9.3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">CCC</span><math id="S4.T2.9.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.9.3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.9.3.1.1.1.1.1.m1.1.1" xref="S4.T2.9.3.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.3.1.1.1.1.1.m1.1b"><ci id="S4.T2.9.3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.9.3.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.3.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></span>
</span></span></th>
<th id="S4.T2.10.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.10.4.3.1" class="ltx_text ltx_font_bold">P</span></th>
<td id="S4.T2.10.4.4" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.10.4.4.1" class="ltx_text ltx_font_bold">0.261±0.014</span></td>
<td id="S4.T2.10.4.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.10.4.5.1" class="ltx_text ltx_font_bold">0.261±0.008</span></td>
<td id="S4.T2.10.4.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.235±0.012<math id="S4.T2.10.4.2.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.10.4.2.m1.1a"><mo id="S4.T2.10.4.2.m1.1.1" xref="S4.T2.10.4.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.10.4.2.m1.1b"><ci id="S4.T2.10.4.2.m1.1.1.cmml" xref="S4.T2.10.4.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.4.2.m1.1c">\dagger</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T2.16.16.5" class="ltx_tr">
<th id="S4.T2.16.16.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.16.5.1.1" class="ltx_text ltx_font_bold">I</span></th>
<td id="S4.T2.16.16.5.2" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.374±0.010</td>
<td id="S4.T2.16.16.5.3" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.16.5.3.1" class="ltx_text ltx_font_bold">0.429±0.010*</span></td>
<td id="S4.T2.16.16.5.4" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.381±0.015</td>
</tr>
<tr id="S4.T2.16.17.6" class="ltx_tr">
<th id="S4.T2.16.17.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.17.6.1.1" class="ltx_text ltx_font_bold">M</span></th>
<td id="S4.T2.16.17.6.2" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.173±0.022</td>
<td id="S4.T2.16.17.6.3" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.202±0.014</td>
<td id="S4.T2.16.17.6.4" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.17.6.4.1" class="ltx_text ltx_font_bold">0.209±0.012*</span></td>
</tr>
<tr id="S4.T2.13.7" class="ltx_tr">
<th id="S4.T2.11.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="3"><span id="S4.T2.11.5.1.1" class="ltx_text">
<span id="S4.T2.11.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T2.11.5.1.1.1.2" class="ltx_tr">
<span id="S4.T2.11.5.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.11.5.1.1.1.2.1.1" class="ltx_text ltx_font_bold">Val.</span></span></span>
<span id="S4.T2.11.5.1.1.1.1" class="ltx_tr">
<span id="S4.T2.11.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.11.5.1.1.1.1.1.1" class="ltx_text ltx_font_bold">CCC</span><math id="S4.T2.11.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.11.5.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.11.5.1.1.1.1.1.m1.1.1" xref="S4.T2.11.5.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.11.5.1.1.1.1.1.m1.1b"><ci id="S4.T2.11.5.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.11.5.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.5.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></span>
</span></span></th>
<th id="S4.T2.13.7.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.13.7.4.1" class="ltx_text ltx_font_bold">P</span></th>
<td id="S4.T2.13.7.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.13.7.5.1" class="ltx_text ltx_font_bold">0.368±0.003</span></td>
<td id="S4.T2.12.6.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.332±0.009<math id="S4.T2.12.6.2.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.12.6.2.m1.1a"><mo id="S4.T2.12.6.2.m1.1.1" xref="S4.T2.12.6.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.12.6.2.m1.1b"><ci id="S4.T2.12.6.2.m1.1.1.cmml" xref="S4.T2.12.6.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.6.2.m1.1c">\dagger</annotation></semantics></math>
</td>
<td id="S4.T2.13.7.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.302±0.011<math id="S4.T2.13.7.3.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.13.7.3.m1.1a"><mo id="S4.T2.13.7.3.m1.1.1" xref="S4.T2.13.7.3.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.13.7.3.m1.1b"><ci id="S4.T2.13.7.3.m1.1.1.cmml" xref="S4.T2.13.7.3.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.7.3.m1.1c">\dagger</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T2.15.9" class="ltx_tr">
<th id="S4.T2.15.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.15.9.3.1" class="ltx_text ltx_font_bold">I</span></th>
<td id="S4.T2.15.9.4" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.15.9.4.1" class="ltx_text ltx_font_bold">0.321±0.011</span></td>
<td id="S4.T2.14.8.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.255±0.007<math id="S4.T2.14.8.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.14.8.1.m1.1a"><mo id="S4.T2.14.8.1.m1.1.1" xref="S4.T2.14.8.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.14.8.1.m1.1b"><ci id="S4.T2.14.8.1.m1.1.1.cmml" xref="S4.T2.14.8.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.8.1.m1.1c">\dagger</annotation></semantics></math>
</td>
<td id="S4.T2.15.9.2" class="ltx_td ltx_nopad_r ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">0.219±0.011<math id="S4.T2.15.9.2.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.15.9.2.m1.1a"><mo id="S4.T2.15.9.2.m1.1.1" xref="S4.T2.15.9.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.15.9.2.m1.1b"><ci id="S4.T2.15.9.2.m1.1.1.cmml" xref="S4.T2.15.9.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.9.2.m1.1c">\dagger</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T2.16.10" class="ltx_tr">
<th id="S4.T2.16.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.10.2.1" class="ltx_text ltx_font_bold">M</span></th>
<td id="S4.T2.16.10.3" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">0.198±0.017</td>
<td id="S4.T2.16.10.4" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T2.16.10.4.1" class="ltx_text ltx_font_bold">0.202±0.013</span></td>
<td id="S4.T2.16.10.1" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">0.162±0.007<math id="S4.T2.16.10.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.16.10.1.m1.1a"><mo id="S4.T2.16.10.1.m1.1.1" xref="S4.T2.16.10.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.16.10.1.m1.1b"><ci id="S4.T2.16.10.1.m1.1.1.cmml" xref="S4.T2.16.10.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.10.1.m1.1c">\dagger</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In a cross-corpus (zero-shot) context, the model does not have information about all annotators in advance. Therefore, we use all annotator predictions from the model. We use the MT approach as it has generally outperformed one-hot models. The MT models excel in cross-corpus performance and significantly outperform the baseline in all probability distribution measures (TVD and JSD) on all datasets. Additionally, we find statistically significant increases in Activation CCC performance on the IEMOCAP and MuSE datasets for both the annotator-only trained model (Task 1) and the interleaved tasks trained model (Task 1+2). The outlier is Valence CCC, which generally decreases compared to the baseline. See Table <a href="#S4.T2" title="Table 2 ‣ 4.3 Cross-Corpus Results ‣ 4 Results ‣ The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">The MT models generally struggled with the valence dimension, showing significant decreases compared to the baseline. Given that we are using all annotators for zero-shot test time, it is likely many annotator predictions that did not learn valence well have influenced the valence dimension negatively. Ultimately, we believe that using all annotators as we have done in a zero-shot setting is not an upper bound for performance of these models. Instead, selecting a subset of trained annotators may significantly increase performance in the zero-shot setting.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Learning individual annotators is challenging. The model must learn a very large number of annotators across both the dimensions of activation and valence. We have presented an approach that accurately predicts individual annotators and a differentiable KDE operation that can be applied to a multi-task annotator models to produce distributions more accurately than using KDE to generate the distributions.
We find that a multi-task model sufficiently learns the individual annotators to produce a probability distribution that outperforms methods that only learn distributions while retaining information about individual annotators.
Furthermore, we have found significant improvement in multiple zero-shot settings when using the multi-task model over the baseline.
We believe these methods can potentially increase utility to the end-user by providing more information about model predictions retained in the model. Future work also includes improving the capability of the model to capture valence, which will likely improve the distribution performance as well. Additionally, we believe the method provides avenues into studying how emotion models can predict specific to groups of annotators or leverage the knowledge of annotators to improve zero-shot cross-corpus performance.
</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This material is based in part upon work supported by the National Science Foundation (NSF IIS-RI 2230172 and IIS-RI 2230172) and National Institutes of Health (NIH R01MH130411).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
S. Labat, N. Ackaert, T. Demeester, and V. Hoste, ``Variation in the expression and annotation of emotions: a wizard of oz pilot study,'' in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">LREC 2022 Workshop: 1st Workshop on Perspectivist Approaches to NLP (NLPerspectives)</em>.   European Language Resources Association (ELRA), 2022, pp. 66–72.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J. Han, Z. Zhang, M. Schmitt, M. Pantic, and B. Schuller, ``From hard to soft: Towards more human-like emotion recognition by modelling the perception uncertainty,'' in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th ACM international conference on Multimedia</em>, 2017, pp. 890–897.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
N. R. Prabhu, G. Carbajal, N. Lehmann-Willenbrock, and T. Gerkmann, ``End-to-end label uncertainty modeling for speech-based arousal recognition using bayesian neural networks,'' <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.03299</em>, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. M. Davani, M. Díaz, and V. Prabhakaran, ``Dealing with disagreements: Looking beyond the majority vote in subjective annotations,'' <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, vol. 10, pp. 92–110, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J. Kocoń, M. Gruza, J. Bielaniewicz, D. Grimling, K. Kanclerz, P. Miłkowski, and P. Kazienko, ``Learning personal human biases and representations for subjective tasks in natural language processing,'' in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on Data Mining (ICDM)</em>, 2021, pp. 1168–1173.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
H.-C. Chou and C.-C. Lee, ``Learning to recognize per-rater's emotion perception using co-rater training strategy with soft and hard labels.'' in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">INTERSPEECH</em>, 2020, pp. 4108–4112.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
B. Zhang, G. Essl, and E. Mower Provost, ``Predicting the distribution of emotion perception: capturing inter-rater variability,'' in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th ACM International Conference on Multimodal Interaction</em>, 2017, pp. 51–59.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
T. Dang, V. Sethu, and E. Ambikairajah, ``Dynamic multi-rater gaussian mixture regression incorporating temporal dependencies of emotion uncertainty using kalman filters,'' in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2018, pp. 4929–4933.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
W. Wu, C. Zhang, and P. Woodland, ``Estimating the uncertainty in emotion attributes using deep evidential regression,'' in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 2023, pp. 15 681–15 695.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
L. Stappen, L. Schumann, A. Batliner, and B. W. Schuller, ``Embracing and exploiting annotator emotional subjectivity: An affective rater ensemble model,'' in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">2021 9th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)</em>, 2021, pp. 01–08.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. G. Upadhyay, W.-S. Chien, B.-H. Su, and C.-C. Lee, ``Learning with rater-expanded label space to improve speech emotion recognition,'' <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Affective Computing</em>, pp. 1–15, 2024.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
C. Busso, S. Parthasarathy, A. Burmania, M. AbdelWahab, N. Sadoughi, and E. M. Provost, ``Msp-improv: An acted corpus of dyadic interactions to study emotion perception,'' <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Affective Computing</em>, vol. 8, no. 1, pp. 67–80, 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
C. Busso, M. Bulut, C.-C. Lee, A. Kazemzadeh, E. Mower Provost, S. Kim, J. Chang, S. Lee, and S. Narayanan, ``IEMOCAP: Interactive emotional dyadic motion capture database,'' <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Language Resources and Evaluation</em>, vol. 42, pp. 335–359, 12 2008.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
R. Lotfian and C. Busso, ``Building naturalistic emotionally balanced speech corpus by retrieving emotional speech from existing podcast recordings,'' <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Affective Computing</em>, vol. 10, no. 4, pp. 471–483, October-December 2019.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M. Jaiswal, C.-P. Bara, Y. Luo, M. Burzo, R. Mihalcea, and E. M. Provost, ``MuSE: a multimodal dataset of stressed emotion,'' in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, N. Calzolari, F. Béchet, P. Blache, K. Choukri, C. Cieri, T. Declerck, S. Goggi, H. Isahara, B. Maegaard, J. Mariani, H. Mazo, A. Moreno, J. Odijk, and S. Piperidis, Eds.   Marseille, France: European Language Resources Association, May 2020, pp. 1499–1510. [Online]. Available: <a target="_blank" href="https://aclanthology.org/2020.lrec-1.187" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2020.lrec-1.187</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. Baevski, Y. Zhou, A. Mohamed, and M. Auli, ``wav2vec 2.0: A framework for self-supervised learning of speech representations,'' <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol. 33, pp. 12 449–12 460, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ``Bert: Pre-training of deep bidirectional transformers for language understanding,'' in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">North American Chapter of the Association for Computational Linguistics</em>, 2019. [Online]. Available: <a target="_blank" href="https://api.semanticscholar.org/CorpusID:52967399" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:52967399</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J. Tavernor, M. Perez, and E. Mower Provost, ``Episodic Memory For Domain-Adaptable, Robust Speech Emotion Recognition,'' in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proc. INTERSPEECH 2023</em>, 2023, pp. 656–660.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
J. Wagner, A. Triantafyllopoulos, H. Wierstorf, M. Schmitt, F. Burkhardt, F. Eyben, and B. W. Schuller, ``Dawn of the transformer era in speech emotion recognition: closing the valence gap,'' <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2023.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
J. Kocoń, M. Gruza, J. Bielaniewicz, D. Grimling, K. Kanclerz, P. Miłkowski, and P. Kazienko, ``Learning personal human biases and representations for subjective tasks in natural language processing,'' in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on Data Mining (ICDM)</em>.   IEEE, 2021, pp. 1168–1173.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
B. T. Atmaja and M. Akagi, ``Evaluation of error-and correlation-based loss functions for multitask learning dimensional speech emotion recognition,'' in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Journal of Physics: Conference Series</em>, vol. 1896, no. 1.   IOP Publishing, 2021, p. 012004.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Z. I. Botev, J. F. Grotowski, and D. P. Kroese, ``Kernel density estimation via diffusion,'' <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">The Annals of Statistics</em>, vol. 38, no. 5, pp. 2916 – 2957, 2010. [Online]. Available: <a target="_blank" href="https://doi.org/10.1214/10-AOS799" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1214/10-AOS799</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
H. H. Tan and K. H. Lim, ``Vanishing gradient mitigation with deep learning neural network optimization,'' in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2019 7th International Conference on Smart Computing &amp; Communications (ICSCC)</em>, 2019, pp. 1–4.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="{Under review}"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.11955" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.11956" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.11956">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.11956" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.11957" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 18:04:03 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
