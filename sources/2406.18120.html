<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.18120] ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs</title><meta property="og:description" content="Motivated by the widespread increase in the phenomenon of code-switching between Egyptian Arabic and English in recent times, this paper explores the intricacies of machine translation (MT) and automatic speech recogni…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.18120">

<!--Generated on Fri Jul  5 20:16:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_fleqn">
<h1 class="ltx_title ltx_title_document">ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ahmed Heakl
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Youssef Zaghloul
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mennatullah Ali
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rania Hossam
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Walid Gomaa
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">Egypt-Japan University of Science and Technology, New Borg El-Arab City, 21934, Alexandria, Egypt
</span>
<span class="ltx_contact ltx_role_address">Mansoura University, Mansoura, 35511, Egypt
</span>
<span class="ltx_contact ltx_role_address">Alexandria University, El-Shatby, 21526, Alexandria, Egypt
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.2" class="ltx_p">Motivated by the widespread increase in the phenomenon of code-switching between Egyptian Arabic and English in recent times, this paper explores the intricacies of machine translation (MT) and automatic speech recognition (ASR) systems, focusing on translating code-switched Egyptian Arabic-English to either English or Egyptian Arabic. Our goal is to present the methodologies employed in developing these systems, utilizing large language models such as LLama and Gemma. In the field of ASR, we explore the utilization of the Whisper model for code-switched Egyptian Arabic recognition, detailing our experimental procedures including data preprocessing and training techniques.
Through the implementation of a consecutive speech-to-text translation system that integrates ASR with MT, we aim to overcome challenges posed by limited resources and the unique characteristics of the Egyptian Arabic dialect. Evaluation against established metrics showcases promising results, with our methodologies yielding a significant improvement of <math id="id1.1.m1.1" class="ltx_Math" alttext="56\%" display="inline"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mn id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">56</mn><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="latexml" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">56</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">56\%</annotation></semantics></math> in English translation over the state-of-the-art and <math id="id2.2.m2.1" class="ltx_Math" alttext="9.3\%" display="inline"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml"><mn id="id2.2.m2.1.1.2" xref="id2.2.m2.1.1.2.cmml">9.3</mn><mo id="id2.2.m2.1.1.1" xref="id2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><apply id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"><csymbol cd="latexml" id="id2.2.m2.1.1.1.cmml" xref="id2.2.m2.1.1.1">percent</csymbol><cn type="float" id="id2.2.m2.1.1.2.cmml" xref="id2.2.m2.1.1.2">9.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">9.3\%</annotation></semantics></math> in Arabic translation. Since code-switching is deeply inherent in spoken languages, it is crucial that ASR systems can effectively handle this phenomenon. This capability is crucial for enabling seamless interaction in various domains, including business negotiations, cultural exchanges, and academic discourse. Our models and code are available as open-source resources.
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code: <a target="_blank" href="http://github.com/ahmedheakl/arazn-llm" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://github.com/ahmedheakl/arazn-llm</a></span></span></span>, <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Models: <a target="_blank" href="http://huggingface.co/collections/ahmedheakl/arazn-llm-662ceaf12777656607b9524e" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://huggingface.co/collections/ahmedheakl/arazn-llm-662ceaf12777656607b9524e</a></span></span></span>.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6> Dialectal Egyptian Arabic , Code-Switching , Machine Translation , Automatic Speech Recognition , Large Language Models

</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\setcode</span>
<p id="p1.2" class="ltx_p">utf8






</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The term “code-switching” describes the phenomenon of a bilingual or multilingual speaker switching between two or more languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. It has grown to be a prominent phenomenon in
multilingual societies around the globe, particularly in the Arab world <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. In Egypt, code-switching is a significant and common linguistic phenomenon. People’s code choices have been impacted by recent political and social changes in Egypt. As shown in Table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, code-switching is evident in everyday conversations.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Addressing the complexities of code-switching presents a significant challenge due to the vast range of potential data combinations. Compounding this challenge is the scarcity of resources dedicated to training models on code-switched data. Additionally, the extent to which existing language models have encountered code-switched content during pre-training remains uncertain. Consequently, the ability of these models to effectively transfer knowledge to downstream code-switched tasks remains largely unexplored <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Machine translation approaches include direct-based, which uses dictionaries but lacks analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>; rule-based, which leverages linguistic rules but requires manual effort <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>; corpus-based, which relies on data but struggles with low-resource languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>; knowledge-based, which incorporates explicit knowledge but struggles with ambiguity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>; and hybrid, which
combines approaches for better quality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Arabic and English have different cultural backgrounds, affecting translation. ‘The news warms my heart’ becomes <span id="S1.p3.1.1" class="ltx_ERROR undefined">\&lt;</span>الخبر يثلج صدري¿ in Arabic, where ‘warms’ is translated to <span id="S1.p3.1.2" class="ltx_ERROR undefined">\&lt;</span>ثلج¿ (ices), due to the languages’ origins in different climates. This is because English was born in a cold climate, where warmth is a pleasant weather, whereas Arabic was born in a hot climate, where cold is a pleasant weather. Human translators can understand these cultural differences, but machine translators may struggle to capture them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. ArzEn corpus serves as a valuable resource for linguistic research and the development of NLP systems capable of handling code-switched Egyptian Arabic-English while preserving cultural aspects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.2.1.1" class="ltx_tr">
<th id="S1.T1.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Code-switched</th>
<th id="S1.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">English</th>
<th id="S1.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Egyptian Arabic</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.2.2.1" class="ltx_tr">
<td id="S1.T1.2.2.1.1" class="ltx_td ltx_align_right ltx_border_l ltx_border_t">
<span id="S1.T1.2.2.1.1.1" class="ltx_ERROR undefined">\RL</span><span id="S1.T1.2.2.1.1.2" class="ltx_ERROR undefined">\LR</span>meeting فى الشركة</td>
<td id="S1.T1.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">meeting at the company</td>
<td id="S1.T1.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S1.T1.2.2.1.3.1" class="ltx_ERROR undefined">\RL</span>اجتماع فى الشركة</td>
</tr>
<tr id="S1.T1.2.3.2" class="ltx_tr">
<td id="S1.T1.2.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">
<span id="S1.T1.2.3.2.1.1" class="ltx_ERROR undefined">\RL</span>نجرب اكل <span id="S1.T1.2.3.2.1.2" class="ltx_ERROR undefined">\LR</span>italian</td>
<td id="S1.T1.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r">try Italian food</td>
<td id="S1.T1.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="S1.T1.2.3.2.3.1" class="ltx_ERROR undefined">\RL</span>نجرب اكل ايطالى</td>
</tr>
<tr id="S1.T1.2.4.3" class="ltx_tr">
<td id="S1.T1.2.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r">
<span id="S1.T1.2.4.3.1.1" class="ltx_ERROR undefined">\RL</span>اعمل <span id="S1.T1.2.4.3.1.2" class="ltx_ERROR undefined">\LR</span>check لل<span id="S1.T1.2.4.3.1.3" class="ltx_ERROR undefined">\LR</span>email</td>
<td id="S1.T1.2.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">I check the email</td>
<td id="S1.T1.2.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span id="S1.T1.2.4.3.3.1" class="ltx_ERROR undefined">\&lt;</span> ببص على رسايلي¿</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S1.T1.4.2" class="ltx_text" style="font-size:90%;">Examples of English and Egyptian Arabic human translations.</span></figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Our primary contributions are the following:</p>
</div>
<div id="S1.p5" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Translation: Developing translation models using open-source models (Llma2, Llama3, and Gemma) for code-switched Egyptian Arabic-English, aiming to achieve translations that closely mimic human-generated outputs, from code-switched Egyptian Arabic to either English or Egyptian Arabic.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">ASR: Developing an Automatic Speech Recognition (ASR) system using Whisper as a crucial component of a complete pipeline, where spoken code-switched Egyptian Arabic-English utterances are transcribed into written text, which is then translated using machine translation.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Quantization: Quantizing our models to be more accessible to human users through their CPUs/GPUs, ensuring efficient deployment and utilization of our models</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Evaluation framework: Extending available metrics to enhance the reliability of our models, prioritizing evaluation accuracy and performance.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">Open-Sourcing: Making our models and code publicly available to encourage community engagement and further research.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The rest of this paper is organized as follows. Section <a href="#S2" title="2 Related Works ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> reviews related literature. Section <a href="#S3" title="3 Methodology ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> gives our methodology and experimental work. Section <a href="#S4" title="4 Results and Discussion ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents our results and discussion, featuring evaluations across multiple metrics. Concluding remarks are provided in Section <a href="#S5" title="5 Conclusion ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Enhancements in Code-Switching Resources for Egyptian Arabic</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> discussed the phenomenon of code-switching (CSW) in Egyptian movies where code-switching is prevalent due to the complex linguistic landscape and social variables <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, where speakers seamlessly blend dialectal Egyptian Arabic with other languages like English and French.
The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> introduced ArzEn-ST which is a three-way speech translation corpus for code-switched Egyptian Arabic-English, which extends the ArzEn corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
They also presented benchmark baseline results for ASR, MT, and speech translation (ST) tasks.
In addition, the authors in  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> expanded the existing Egyptian Arabic datasets by introducing a new dataset focused on daily life conversations from movies and songs. This dataset is designed for benchmarking new machine translation models, fine-tuning large language models in few-shot settings, and facilitating research in cross-linguistic analysis and lexical semantics. This also helps in capturing more cultural nuances related to Egyptian Arabic.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Code-switched corpora</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> presented the ArzEn corpus, an Egyptian Arabic-English code-switching spontaneous speech corpus. The corpus comprises 12 hours of recorded interviews with 38 Egyptian bilingual university students and employees. The corpus is designed for Automatic Speech Recognition (ASR) systems and offers insights into linguistic, sociological, and psychological aspects of code-switching. The work done in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> extends the ArzEn corpus with translation in both primary (Egyptian-Arabic) and secondary (English) languages.
The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> presented ArzEn-MultiGenre corpus comprising 25,557 segment pairs of Egyptian Arabic song lyrics, novels, and TV show subtitles, all manually translated and aligned with their English counterparts.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>The era of Large Language Models (LLMs)</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The process of translation requires a complete understanding of linguistic conversion, syntactic, grammatical, and cultural dimensions. It is more than mapping words between languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Accurate translation requires a deep understanding of the cultural nuances inherent in both languages, ensuring the preservation of cultural sensitivity and local values <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.
This versatility of LLMs enabled them to excel in numerous NLP applications, such as text generation (Llama2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>), machine translation (NLLB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, SemalessM4T <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, ArzEn-ST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>).
Recent advancements in Large Language Models (LLMs) have led to the development of powerful models like LLaMa2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, Gemma (2B, 7B) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, and LLaMa3 8B, which have demonstrated impressive capabilities in NLP tasks.
Notably, these models have been designed to be more computationally efficient, allowing them to be deployed on consumer-grade GPUs. This shift enables researchers and developers to harness the power of LLMs on local machines, facilitating faster experimentation, prototyping, and deployment of AI applications.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Code-switching Automatic Speech Recognition (CSW-ASR)</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Researchers have explored acoustic, linguistic, and pronunciation modeling approaches, including language identification systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, parallel recognizers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, and single-pass
methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> presented Whisper, a speech recognition system trained on 680,000 hours of multilingual and multitask audio data, achieving zero-shot transfer
capabilities and approaching human accuracy and robustness. The system’s architecture is based on an encoder-decoder transformer, leveraging a minimalist data processing approach and multitask training.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we present the machine translation and automatic speech recognition systems we used.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Machine Translation (MT)</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.10" class="ltx_p">The task of machine translation is represented by a mapping <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{T}:X^{S}\rightarrow Y^{T}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">𝒯</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">:</mo><mrow id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><msup id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2.2" xref="S3.SS1.p1.1.m1.1.1.3.2.2.cmml">X</mi><mi id="S3.SS1.p1.1.m1.1.1.3.2.3" xref="S3.SS1.p1.1.m1.1.1.3.2.3.cmml">S</mi></msup><mo stretchy="false" id="S3.SS1.p1.1.m1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.3.1.cmml">→</mo><msup id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.3.2" xref="S3.SS1.p1.1.m1.1.1.3.3.2.cmml">Y</mi><mi id="S3.SS1.p1.1.m1.1.1.3.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.3.cmml">T</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><ci id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1">:</ci><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝒯</ci><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><ci id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.1">→</ci><apply id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.3.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">superscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.3.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2.2">𝑋</ci><ci id="S3.SS1.p1.1.m1.1.1.3.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2.3">𝑆</ci></apply><apply id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3">superscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.2">𝑌</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\mathcal{T}:X^{S}\rightarrow Y^{T}</annotation></semantics></math> where <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">𝒯</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝒯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathcal{T}</annotation></semantics></math> is the machine translation function, <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="X^{S}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msup id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">X</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑋</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">X^{S}</annotation></semantics></math> is the set of source sentences in the
source language <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">S</annotation></semantics></math>, represented as a sequence of tokens <math id="S3.SS1.p1.5.m5.4" class="ltx_Math" alttext="x=(x_{1},x_{2},...,x_{n})" display="inline"><semantics id="S3.SS1.p1.5.m5.4a"><mrow id="S3.SS1.p1.5.m5.4.4" xref="S3.SS1.p1.5.m5.4.4.cmml"><mi id="S3.SS1.p1.5.m5.4.4.5" xref="S3.SS1.p1.5.m5.4.4.5.cmml">x</mi><mo id="S3.SS1.p1.5.m5.4.4.4" xref="S3.SS1.p1.5.m5.4.4.4.cmml">=</mo><mrow id="S3.SS1.p1.5.m5.4.4.3.3" xref="S3.SS1.p1.5.m5.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m5.4.4.3.3.4" xref="S3.SS1.p1.5.m5.4.4.3.4.cmml">(</mo><msub id="S3.SS1.p1.5.m5.2.2.1.1.1" xref="S3.SS1.p1.5.m5.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.5.m5.2.2.1.1.1.2" xref="S3.SS1.p1.5.m5.2.2.1.1.1.2.cmml">x</mi><mn id="S3.SS1.p1.5.m5.2.2.1.1.1.3" xref="S3.SS1.p1.5.m5.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.5.m5.4.4.3.3.5" xref="S3.SS1.p1.5.m5.4.4.3.4.cmml">,</mo><msub id="S3.SS1.p1.5.m5.3.3.2.2.2" xref="S3.SS1.p1.5.m5.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.5.m5.3.3.2.2.2.2" xref="S3.SS1.p1.5.m5.3.3.2.2.2.2.cmml">x</mi><mn id="S3.SS1.p1.5.m5.3.3.2.2.2.3" xref="S3.SS1.p1.5.m5.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p1.5.m5.4.4.3.3.6" xref="S3.SS1.p1.5.m5.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">…</mi><mo id="S3.SS1.p1.5.m5.4.4.3.3.7" xref="S3.SS1.p1.5.m5.4.4.3.4.cmml">,</mo><msub id="S3.SS1.p1.5.m5.4.4.3.3.3" xref="S3.SS1.p1.5.m5.4.4.3.3.3.cmml"><mi id="S3.SS1.p1.5.m5.4.4.3.3.3.2" xref="S3.SS1.p1.5.m5.4.4.3.3.3.2.cmml">x</mi><mi id="S3.SS1.p1.5.m5.4.4.3.3.3.3" xref="S3.SS1.p1.5.m5.4.4.3.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S3.SS1.p1.5.m5.4.4.3.3.8" xref="S3.SS1.p1.5.m5.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.4b"><apply id="S3.SS1.p1.5.m5.4.4.cmml" xref="S3.SS1.p1.5.m5.4.4"><eq id="S3.SS1.p1.5.m5.4.4.4.cmml" xref="S3.SS1.p1.5.m5.4.4.4"></eq><ci id="S3.SS1.p1.5.m5.4.4.5.cmml" xref="S3.SS1.p1.5.m5.4.4.5">𝑥</ci><vector id="S3.SS1.p1.5.m5.4.4.3.4.cmml" xref="S3.SS1.p1.5.m5.4.4.3.3"><apply id="S3.SS1.p1.5.m5.2.2.1.1.1.cmml" xref="S3.SS1.p1.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S3.SS1.p1.5.m5.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.5.m5.3.3.2.2.2.cmml" xref="S3.SS1.p1.5.m5.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.5.m5.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.5.m5.3.3.2.2.2.2">𝑥</ci><cn type="integer" id="S3.SS1.p1.5.m5.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.5.m5.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">…</ci><apply id="S3.SS1.p1.5.m5.4.4.3.3.3.cmml" xref="S3.SS1.p1.5.m5.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.4.4.3.3.3.1.cmml" xref="S3.SS1.p1.5.m5.4.4.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.4.4.3.3.3.2.cmml" xref="S3.SS1.p1.5.m5.4.4.3.3.3.2">𝑥</ci><ci id="S3.SS1.p1.5.m5.4.4.3.3.3.3.cmml" xref="S3.SS1.p1.5.m5.4.4.3.3.3.3">𝑛</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.4c">x=(x_{1},x_{2},...,x_{n})</annotation></semantics></math>,
and <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="Y^{T}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msup id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">Y</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝑌</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">Y^{T}</annotation></semantics></math> is the set of translated sentences in the target language <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">T</annotation></semantics></math>.
The goal of machine translation is to find the optimal translation <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mover accent="true" id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2" xref="S3.SS1.p1.8.m8.1.1.2.cmml">y</mi><mo id="S3.SS1.p1.8.m8.1.1.1" xref="S3.SS1.p1.8.m8.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><ci id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1.1">^</ci><ci id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">\hat{y}</annotation></semantics></math> that maximizes the likelihood of the target sentence given the source sentence <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="\hat{y}=\arg\max_{y\in Y^{T}}P(y|x)" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mrow id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mover accent="true" id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.3.2" xref="S3.SS1.p1.9.m9.1.1.3.2.cmml">y</mi><mo id="S3.SS1.p1.9.m9.1.1.3.1" xref="S3.SS1.p1.9.m9.1.1.3.1.cmml">^</mo></mover><mo id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">=</mo><mrow id="S3.SS1.p1.9.m9.1.1.1" xref="S3.SS1.p1.9.m9.1.1.1.cmml"><mrow id="S3.SS1.p1.9.m9.1.1.1.3" xref="S3.SS1.p1.9.m9.1.1.1.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.1.3.1" xref="S3.SS1.p1.9.m9.1.1.1.3.1.cmml">arg</mi><mo lspace="0.167em" id="S3.SS1.p1.9.m9.1.1.1.3a" xref="S3.SS1.p1.9.m9.1.1.1.3.cmml">⁡</mo><mrow id="S3.SS1.p1.9.m9.1.1.1.3.2" xref="S3.SS1.p1.9.m9.1.1.1.3.2.cmml"><msub id="S3.SS1.p1.9.m9.1.1.1.3.2.1" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.1.3.2.1.2" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.2.cmml">max</mi><mrow id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.2" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.2.cmml">y</mi><mo id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.1" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.1.cmml">∈</mo><msup id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.2" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.2.cmml">Y</mi><mi id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.3" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.3.cmml">T</mi></msup></mrow></msub><mo lspace="0.167em" id="S3.SS1.p1.9.m9.1.1.1.3.2a" xref="S3.SS1.p1.9.m9.1.1.1.3.2.cmml">⁡</mo><mi id="S3.SS1.p1.9.m9.1.1.1.3.2.2" xref="S3.SS1.p1.9.m9.1.1.1.3.2.2.cmml">P</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p1.9.m9.1.1.1.2" xref="S3.SS1.p1.9.m9.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.9.m9.1.1.1.1.1" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.9.m9.1.1.1.1.1.2" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.9.m9.1.1.1.1.1.1" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.1.1.1.1.2" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S3.SS1.p1.9.m9.1.1.1.1.1.1.1" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS1.p1.9.m9.1.1.1.1.1.1.3" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S3.SS1.p1.9.m9.1.1.1.1.1.3" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><eq id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2"></eq><apply id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3"><ci id="S3.SS1.p1.9.m9.1.1.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.3.1">^</ci><ci id="S3.SS1.p1.9.m9.1.1.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.3.2">𝑦</ci></apply><apply id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1"><times id="S3.SS1.p1.9.m9.1.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.1.2"></times><apply id="S3.SS1.p1.9.m9.1.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3"><arg id="S3.SS1.p1.9.m9.1.1.1.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.1"></arg><apply id="S3.SS1.p1.9.m9.1.1.1.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2"><apply id="S3.SS1.p1.9.m9.1.1.1.3.2.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.3.2.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1">subscript</csymbol><max id="S3.SS1.p1.9.m9.1.1.1.3.2.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.2"></max><apply id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3"><in id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.1"></in><ci id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.2">𝑦</ci><apply id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3">superscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.2">𝑌</ci><ci id="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.3.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.1.3.3.3">𝑇</ci></apply></apply></apply><ci id="S3.SS1.p1.9.m9.1.1.1.3.2.2.cmml" xref="S3.SS1.p1.9.m9.1.1.1.3.2.2">𝑃</ci></apply></apply><apply id="S3.SS1.p1.9.m9.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.9.m9.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS1.p1.9.m9.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.2">𝑦</ci><ci id="S3.SS1.p1.9.m9.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">\hat{y}=\arg\max_{y\in Y^{T}}P(y|x)</annotation></semantics></math> where <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="P(y|x)" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mrow id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><mi id="S3.SS1.p1.10.m10.1.1.3" xref="S3.SS1.p1.10.m10.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.10.m10.1.1.2" xref="S3.SS1.p1.10.m10.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.10.m10.1.1.1.1" xref="S3.SS1.p1.10.m10.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.10.m10.1.1.1.1.2" xref="S3.SS1.p1.10.m10.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.10.m10.1.1.1.1.1" xref="S3.SS1.p1.10.m10.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.10.m10.1.1.1.1.1.2" xref="S3.SS1.p1.10.m10.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S3.SS1.p1.10.m10.1.1.1.1.1.1" xref="S3.SS1.p1.10.m10.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS1.p1.10.m10.1.1.1.1.1.3" xref="S3.SS1.p1.10.m10.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S3.SS1.p1.10.m10.1.1.1.1.3" xref="S3.SS1.p1.10.m10.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><times id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2"></times><ci id="S3.SS1.p1.10.m10.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3">𝑃</ci><apply id="S3.SS1.p1.10.m10.1.1.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.10.m10.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS1.p1.10.m10.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.1.1.1.2">𝑦</ci><ci id="S3.SS1.p1.10.m10.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">P(y|x)</annotation></semantics></math> is the conditional probability of the target sentence given the source sentence. Formally, we can define the machine translation problem as:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_left_padleft"></td>
<td class="ltx_eqn_cell ltx_align_left"><math id="S3.E1.m1.2" class="ltx_Math" alttext="\centering\mathcal{T}^{*}=\arg\min_{\mathcal{T}}\mathbb{E}_{x\sim\mathcal{X}^{\mathcal{S}}}[d(\mathcal{T}(x),y^{*})]\@add@centering" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><msup id="S3.E1.m1.2.2.3" xref="S3.E1.m1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.3.2" xref="S3.E1.m1.2.2.3.2.cmml">𝒯</mi><mo id="S3.E1.m1.2.2.3.3" xref="S3.E1.m1.2.2.3.3.cmml">∗</mo></msup><mo id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.2.cmml">=</mo><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.cmml"><mrow id="S3.E1.m1.2.2.1.3" xref="S3.E1.m1.2.2.1.3.cmml"><mi id="S3.E1.m1.2.2.1.3.1" xref="S3.E1.m1.2.2.1.3.1.cmml">arg</mi><mo lspace="0.167em" id="S3.E1.m1.2.2.1.3a" xref="S3.E1.m1.2.2.1.3.cmml">⁡</mo><mrow id="S3.E1.m1.2.2.1.3.2" xref="S3.E1.m1.2.2.1.3.2.cmml"><munder id="S3.E1.m1.2.2.1.3.2.1" xref="S3.E1.m1.2.2.1.3.2.1.cmml"><mi id="S3.E1.m1.2.2.1.3.2.1.2" xref="S3.E1.m1.2.2.1.3.2.1.2.cmml">min</mi><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.3.2.1.3" xref="S3.E1.m1.2.2.1.3.2.1.3.cmml">𝒯</mi></munder><mo lspace="0.167em" id="S3.E1.m1.2.2.1.3.2a" xref="S3.E1.m1.2.2.1.3.2.cmml">⁡</mo><msub id="S3.E1.m1.2.2.1.3.2.2" xref="S3.E1.m1.2.2.1.3.2.2.cmml"><mi id="S3.E1.m1.2.2.1.3.2.2.2" xref="S3.E1.m1.2.2.1.3.2.2.2.cmml">𝔼</mi><mrow id="S3.E1.m1.2.2.1.3.2.2.3" xref="S3.E1.m1.2.2.1.3.2.2.3.cmml"><mi id="S3.E1.m1.2.2.1.3.2.2.3.2" xref="S3.E1.m1.2.2.1.3.2.2.3.2.cmml">x</mi><mo id="S3.E1.m1.2.2.1.3.2.2.3.1" xref="S3.E1.m1.2.2.1.3.2.2.3.1.cmml">∼</mo><msup id="S3.E1.m1.2.2.1.3.2.2.3.3" xref="S3.E1.m1.2.2.1.3.2.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.3.2.2.3.3.2" xref="S3.E1.m1.2.2.1.3.2.2.3.3.2.cmml">𝒳</mi><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.3.2.2.3.3.3" xref="S3.E1.m1.2.2.1.3.2.2.3.3.3.cmml">𝒮</mi></msup></mrow></msub></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.2.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.cmml">[</mo><mrow id="S3.E1.m1.2.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.4" xref="S3.E1.m1.2.2.1.1.1.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.1.1.2.3.cmml">(</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.2.cmml">𝒯</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.3.2.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.2.2.4" xref="S3.E1.m1.2.2.1.1.1.1.2.3.cmml">,</mo><msup id="S3.E1.m1.2.2.1.1.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.2.2.2.2" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2.2.cmml">y</mi><mo id="S3.E1.m1.2.2.1.1.1.1.2.2.2.3" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2.3.cmml">∗</mo></msup><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.1.2.2.5" xref="S3.E1.m1.2.2.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><eq id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.2"></eq><apply id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.3.1.cmml" xref="S3.E1.m1.2.2.3">superscript</csymbol><ci id="S3.E1.m1.2.2.3.2.cmml" xref="S3.E1.m1.2.2.3.2">𝒯</ci><times id="S3.E1.m1.2.2.3.3.cmml" xref="S3.E1.m1.2.2.3.3"></times></apply><apply id="S3.E1.m1.2.2.1.cmml" xref="S3.E1.m1.2.2.1"><times id="S3.E1.m1.2.2.1.2.cmml" xref="S3.E1.m1.2.2.1.2"></times><apply id="S3.E1.m1.2.2.1.3.cmml" xref="S3.E1.m1.2.2.1.3"><arg id="S3.E1.m1.2.2.1.3.1.cmml" xref="S3.E1.m1.2.2.1.3.1"></arg><apply id="S3.E1.m1.2.2.1.3.2.cmml" xref="S3.E1.m1.2.2.1.3.2"><apply id="S3.E1.m1.2.2.1.3.2.1.cmml" xref="S3.E1.m1.2.2.1.3.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.3.2.1.1.cmml" xref="S3.E1.m1.2.2.1.3.2.1">subscript</csymbol><min id="S3.E1.m1.2.2.1.3.2.1.2.cmml" xref="S3.E1.m1.2.2.1.3.2.1.2"></min><ci id="S3.E1.m1.2.2.1.3.2.1.3.cmml" xref="S3.E1.m1.2.2.1.3.2.1.3">𝒯</ci></apply><apply id="S3.E1.m1.2.2.1.3.2.2.cmml" xref="S3.E1.m1.2.2.1.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.3.2.2.1.cmml" xref="S3.E1.m1.2.2.1.3.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.3.2.2.2.cmml" xref="S3.E1.m1.2.2.1.3.2.2.2">𝔼</ci><apply id="S3.E1.m1.2.2.1.3.2.2.3.cmml" xref="S3.E1.m1.2.2.1.3.2.2.3"><csymbol cd="latexml" id="S3.E1.m1.2.2.1.3.2.2.3.1.cmml" xref="S3.E1.m1.2.2.1.3.2.2.3.1">similar-to</csymbol><ci id="S3.E1.m1.2.2.1.3.2.2.3.2.cmml" xref="S3.E1.m1.2.2.1.3.2.2.3.2">𝑥</ci><apply id="S3.E1.m1.2.2.1.3.2.2.3.3.cmml" xref="S3.E1.m1.2.2.1.3.2.2.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.3.2.2.3.3.1.cmml" xref="S3.E1.m1.2.2.1.3.2.2.3.3">superscript</csymbol><ci id="S3.E1.m1.2.2.1.3.2.2.3.3.2.cmml" xref="S3.E1.m1.2.2.1.3.2.2.3.3.2">𝒳</ci><ci id="S3.E1.m1.2.2.1.3.2.2.3.3.3.cmml" xref="S3.E1.m1.2.2.1.3.2.2.3.3.3">𝒮</ci></apply></apply></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.2.2.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3"></times><ci id="S3.E1.m1.2.2.1.1.1.1.4.cmml" xref="S3.E1.m1.2.2.1.1.1.1.4">𝑑</ci><interval closure="open" id="S3.E1.m1.2.2.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2"><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1"></times><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.2">𝒯</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝑥</ci></apply><apply id="S3.E1.m1.2.2.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2">superscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2.2">𝑦</ci><times id="S3.E1.m1.2.2.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2.2.2.3"></times></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\centering\mathcal{T}^{*}=\arg\min_{\mathcal{T}}\mathbb{E}_{x\sim\mathcal{X}^{\mathcal{S}}}[d(\mathcal{T}(x),y^{*})]\@add@centering</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_left_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.4" class="ltx_p">where <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{T}^{*}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msup id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">𝒯</mi><mo id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝒯</ci><times id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{T}^{*}</annotation></semantics></math> is the optimal machine translation function. <math id="S3.SS1.p2.2.m2.2" class="ltx_Math" alttext="d(\cdot,\cdot)" display="inline"><semantics id="S3.SS1.p2.2.m2.2a"><mrow id="S3.SS1.p2.2.m2.2.3" xref="S3.SS1.p2.2.m2.2.3.cmml"><mi id="S3.SS1.p2.2.m2.2.3.2" xref="S3.SS1.p2.2.m2.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.2.3.1" xref="S3.SS1.p2.2.m2.2.3.1.cmml">​</mo><mrow id="S3.SS1.p2.2.m2.2.3.3.2" xref="S3.SS1.p2.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.2.m2.2.3.3.2.1" xref="S3.SS1.p2.2.m2.2.3.3.1.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">⋅</mo><mo rspace="0em" id="S3.SS1.p2.2.m2.2.3.3.2.2" xref="S3.SS1.p2.2.m2.2.3.3.1.cmml">,</mo><mo lspace="0em" rspace="0em" id="S3.SS1.p2.2.m2.2.2" xref="S3.SS1.p2.2.m2.2.2.cmml">⋅</mo><mo stretchy="false" id="S3.SS1.p2.2.m2.2.3.3.2.3" xref="S3.SS1.p2.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.2b"><apply id="S3.SS1.p2.2.m2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.3"><times id="S3.SS1.p2.2.m2.2.3.1.cmml" xref="S3.SS1.p2.2.m2.2.3.1"></times><ci id="S3.SS1.p2.2.m2.2.3.2.cmml" xref="S3.SS1.p2.2.m2.2.3.2">𝑑</ci><interval closure="open" id="S3.SS1.p2.2.m2.2.3.3.1.cmml" xref="S3.SS1.p2.2.m2.2.3.3.2"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">⋅</ci><ci id="S3.SS1.p2.2.m2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2">⋅</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.2c">d(\cdot,\cdot)</annotation></semantics></math> is a distance metric (e.g. BLEU score, METEOR score) that measures the similarity between the translated sentence and the reference translation <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="y^{*}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msup id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">y</mi><mo id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝑦</ci><times id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">y^{*}</annotation></semantics></math>. The goal is to find the optimal machine translation function <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{T}^{*}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><msup id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">𝒯</mi><mo id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝒯</ci><times id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\mathcal{T}^{*}</annotation></semantics></math> that minimizes the expected distance between the translated sentence and the reference translation. This mathematical definition provides a formal framework for understanding the task of machine translation and its optimization problem.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">We used the infamous translation ArzEn-ST dataset to train all of our models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. We adhere to the same train and test splits as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
Specifically, we utilize the ArzEn-ST test set, comprising 1,402 sentences, and the train set, consisting of 3,344 sentences. To provide our models with a richer context, we also pre-train them on larger datasets, including the entire parallel corpora presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. This approach enables our models to leverage a broader range of linguistic patterns and cultural nuances.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">Data pre-processing involves removing corpus-specific annotations, URLs, and emoticons, as well as converting
all text to lowercase. This step is crucial in ensuring that our models focus on the underlying linguistic structures and cultural nuances of the Egyptian-Arabic language.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">Given the sequential nature of the translation task and the need for culturally enriched translations, we opt for large language models (LLMs) as our primary approach. Specifically, we employ the latest LLMs that can be accommodated by consumer-grade RAM or GPU, including LLaMA3 8B, Gemma1.1 2B, and Gemma1.1 7B <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Notably, we utilize the chat version of each model, which has been trained to follow human instructions, thereby facilitating the training process.
All models are trained using 2 T4 GPUs with 16GB VRAM. It is worth noting that these models are decode-based architectures, which are particularly well-suited for sequential tasks like machine translation. By leveraging the strengths of these models, we aim to produce culturally fitting translations that capture the nuances of Egyptian-Arabic language and culture.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">We employed the paged-Adam optimizer with weight decay <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> in 32-bit precision for all models, except for LLaMa3, which required 8-bit precision due to its substantial size (8 billion parameters). To accommodate the computational demands of the Adam optimizer, which utilizes multiple gradient copies, we trained our models using adapters for LLMs. Specifically, we explored the use of Quantized low-Rank Adapters (QLoRA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and weight-Decomposed low-Rank Adaptation (DoRA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, with the latter yielding the most promising results and exhibiting similar behavior to the original fine-tuning process. We opted for int4 quantization with normal floats (nf4) for each adapter.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.1" class="ltx_p">To mitigate memory constraints during training, we leveraged gradient checkpointing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, which incurs only an additional forward pass per mini-batch, while reducing memory consumption to <math id="S3.SS1.p7.1.m1.1" class="ltx_Math" alttext="O(\sqrt{n})" display="inline"><semantics id="S3.SS1.p7.1.m1.1a"><mrow id="S3.SS1.p7.1.m1.1.2" xref="S3.SS1.p7.1.m1.1.2.cmml"><mi id="S3.SS1.p7.1.m1.1.2.2" xref="S3.SS1.p7.1.m1.1.2.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p7.1.m1.1.2.1" xref="S3.SS1.p7.1.m1.1.2.1.cmml">​</mo><mrow id="S3.SS1.p7.1.m1.1.2.3.2" xref="S3.SS1.p7.1.m1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p7.1.m1.1.2.3.2.1" xref="S3.SS1.p7.1.m1.1.1.cmml">(</mo><msqrt id="S3.SS1.p7.1.m1.1.1" xref="S3.SS1.p7.1.m1.1.1.cmml"><mi id="S3.SS1.p7.1.m1.1.1.2" xref="S3.SS1.p7.1.m1.1.1.2.cmml">n</mi></msqrt><mo stretchy="false" id="S3.SS1.p7.1.m1.1.2.3.2.2" xref="S3.SS1.p7.1.m1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.1.m1.1b"><apply id="S3.SS1.p7.1.m1.1.2.cmml" xref="S3.SS1.p7.1.m1.1.2"><times id="S3.SS1.p7.1.m1.1.2.1.cmml" xref="S3.SS1.p7.1.m1.1.2.1"></times><ci id="S3.SS1.p7.1.m1.1.2.2.cmml" xref="S3.SS1.p7.1.m1.1.2.2">𝑂</ci><apply id="S3.SS1.p7.1.m1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.2.3.2"><root id="S3.SS1.p7.1.m1.1.1a.cmml" xref="S3.SS1.p7.1.m1.1.2.3.2"></root><ci id="S3.SS1.p7.1.m1.1.1.2.cmml" xref="S3.SS1.p7.1.m1.1.1.2">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.1.m1.1c">O(\sqrt{n})</annotation></semantics></math>. Furthermore, to enable training with effectively large batch sizes while minimizing memory constraints, we implemented a gradient accumulation step of 4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. This approach allows us to accumulate gradients from 4 batches, perform backward propagation, and achieve comparable accuracy to updating a batch of 4 at once, while reducing memory requirements by a factor of 4.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<p id="S3.SS1.p8.1" class="ltx_p">Our experiments revealed that the optimal strategy involves training models for a single epoch with a constant learning rate schedule. Additionally, we ensured that input attention masks were configured to mask out the output translation, thereby computing gradients and loss only for the output translation. Lastly, to make our models available on a consumer CPU, we provide the quanitized GGUF version of our best model. The quantization was done through the implementation of GGUF llama.cpp.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Automatic Speech Recognition (ASR)</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.13" class="ltx_p">In the context of Automatic Speech Recognition (ASR), we aim to convert a speech signal into a sequence of words. Let’s assume a speech signal <math id="S3.SS2.p1.1.m1.4" class="ltx_Math" alttext="x=(x_{1},x_{2},...,x_{T})" display="inline"><semantics id="S3.SS2.p1.1.m1.4a"><mrow id="S3.SS2.p1.1.m1.4.4" xref="S3.SS2.p1.1.m1.4.4.cmml"><mi id="S3.SS2.p1.1.m1.4.4.5" xref="S3.SS2.p1.1.m1.4.4.5.cmml">x</mi><mo id="S3.SS2.p1.1.m1.4.4.4" xref="S3.SS2.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS2.p1.1.m1.4.4.3.3" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS2.p1.1.m1.4.4.3.3.4" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">(</mo><msub id="S3.SS2.p1.1.m1.2.2.1.1.1" xref="S3.SS2.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.2.2.1.1.1.2" xref="S3.SS2.p1.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S3.SS2.p1.1.m1.2.2.1.1.1.3" xref="S3.SS2.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p1.1.m1.4.4.3.3.5" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.1.m1.3.3.2.2.2" xref="S3.SS2.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS2.p1.1.m1.3.3.2.2.2.2" xref="S3.SS2.p1.1.m1.3.3.2.2.2.2.cmml">x</mi><mn id="S3.SS2.p1.1.m1.3.3.2.2.2.3" xref="S3.SS2.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p1.1.m1.4.4.3.3.6" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS2.p1.1.m1.4.4.3.3.7" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.1.m1.4.4.3.3.3" xref="S3.SS2.p1.1.m1.4.4.3.3.3.cmml"><mi id="S3.SS2.p1.1.m1.4.4.3.3.3.2" xref="S3.SS2.p1.1.m1.4.4.3.3.3.2.cmml">x</mi><mi id="S3.SS2.p1.1.m1.4.4.3.3.3.3" xref="S3.SS2.p1.1.m1.4.4.3.3.3.3.cmml">T</mi></msub><mo stretchy="false" id="S3.SS2.p1.1.m1.4.4.3.3.8" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.4b"><apply id="S3.SS2.p1.1.m1.4.4.cmml" xref="S3.SS2.p1.1.m1.4.4"><eq id="S3.SS2.p1.1.m1.4.4.4.cmml" xref="S3.SS2.p1.1.m1.4.4.4"></eq><ci id="S3.SS2.p1.1.m1.4.4.5.cmml" xref="S3.SS2.p1.1.m1.4.4.5">𝑥</ci><vector id="S3.SS2.p1.1.m1.4.4.3.4.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3"><apply id="S3.SS2.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S3.SS2.p1.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.2.2">𝑥</ci><cn type="integer" id="S3.SS2.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">…</ci><apply id="S3.SS2.p1.1.m1.4.4.3.3.3.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p1.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3.3.2">𝑥</ci><ci id="S3.SS2.p1.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3.3.3">𝑇</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.4c">x=(x_{1},x_{2},...,x_{T})</annotation></semantics></math> where <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="x_{t}\in\mathbb{R}^{D}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><msub id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">x</mi><mi id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.3.2" xref="S3.SS2.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S3.SS2.p1.2.m2.1.1.3.3" xref="S3.SS2.p1.2.m2.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><in id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></in><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">𝑥</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3">𝑡</ci></apply><apply id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.3.2">ℝ</ci><ci id="S3.SS2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">x_{t}\in\mathbb{R}^{D}</annotation></semantics></math> is the acoustic feature vector at time <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">t</annotation></semantics></math> and <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">T</annotation></semantics></math> is the length of the speech signal. The goal of ASR is to find the most likely sequence of words <math id="S3.SS2.p1.5.m5.4" class="ltx_Math" alttext="w=(w_{1},w_{2},...,w_{N})" display="inline"><semantics id="S3.SS2.p1.5.m5.4a"><mrow id="S3.SS2.p1.5.m5.4.4" xref="S3.SS2.p1.5.m5.4.4.cmml"><mi id="S3.SS2.p1.5.m5.4.4.5" xref="S3.SS2.p1.5.m5.4.4.5.cmml">w</mi><mo id="S3.SS2.p1.5.m5.4.4.4" xref="S3.SS2.p1.5.m5.4.4.4.cmml">=</mo><mrow id="S3.SS2.p1.5.m5.4.4.3.3" xref="S3.SS2.p1.5.m5.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS2.p1.5.m5.4.4.3.3.4" xref="S3.SS2.p1.5.m5.4.4.3.4.cmml">(</mo><msub id="S3.SS2.p1.5.m5.2.2.1.1.1" xref="S3.SS2.p1.5.m5.2.2.1.1.1.cmml"><mi id="S3.SS2.p1.5.m5.2.2.1.1.1.2" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2.cmml">w</mi><mn id="S3.SS2.p1.5.m5.2.2.1.1.1.3" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p1.5.m5.4.4.3.3.5" xref="S3.SS2.p1.5.m5.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.5.m5.3.3.2.2.2" xref="S3.SS2.p1.5.m5.3.3.2.2.2.cmml"><mi id="S3.SS2.p1.5.m5.3.3.2.2.2.2" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2.cmml">w</mi><mn id="S3.SS2.p1.5.m5.3.3.2.2.2.3" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p1.5.m5.4.4.3.3.6" xref="S3.SS2.p1.5.m5.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">…</mi><mo id="S3.SS2.p1.5.m5.4.4.3.3.7" xref="S3.SS2.p1.5.m5.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.5.m5.4.4.3.3.3" xref="S3.SS2.p1.5.m5.4.4.3.3.3.cmml"><mi id="S3.SS2.p1.5.m5.4.4.3.3.3.2" xref="S3.SS2.p1.5.m5.4.4.3.3.3.2.cmml">w</mi><mi id="S3.SS2.p1.5.m5.4.4.3.3.3.3" xref="S3.SS2.p1.5.m5.4.4.3.3.3.3.cmml">N</mi></msub><mo stretchy="false" id="S3.SS2.p1.5.m5.4.4.3.3.8" xref="S3.SS2.p1.5.m5.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.4b"><apply id="S3.SS2.p1.5.m5.4.4.cmml" xref="S3.SS2.p1.5.m5.4.4"><eq id="S3.SS2.p1.5.m5.4.4.4.cmml" xref="S3.SS2.p1.5.m5.4.4.4"></eq><ci id="S3.SS2.p1.5.m5.4.4.5.cmml" xref="S3.SS2.p1.5.m5.4.4.5">𝑤</ci><vector id="S3.SS2.p1.5.m5.4.4.3.4.cmml" xref="S3.SS2.p1.5.m5.4.4.3.3"><apply id="S3.SS2.p1.5.m5.2.2.1.1.1.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2">𝑤</ci><cn type="integer" id="S3.SS2.p1.5.m5.2.2.1.1.1.3.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.p1.5.m5.3.3.2.2.2.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.5.m5.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2">𝑤</ci><cn type="integer" id="S3.SS2.p1.5.m5.3.3.2.2.2.3.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">…</ci><apply id="S3.SS2.p1.5.m5.4.4.3.3.3.cmml" xref="S3.SS2.p1.5.m5.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.4.4.3.3.3.1.cmml" xref="S3.SS2.p1.5.m5.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p1.5.m5.4.4.3.3.3.2.cmml" xref="S3.SS2.p1.5.m5.4.4.3.3.3.2">𝑤</ci><ci id="S3.SS2.p1.5.m5.4.4.3.3.3.3.cmml" xref="S3.SS2.p1.5.m5.4.4.3.3.3.3">𝑁</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.4c">w=(w_{1},w_{2},...,w_{N})</annotation></semantics></math> where <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="w_{n}\in\mathcal{V}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mrow id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><msub id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2.2" xref="S3.SS2.p1.6.m6.1.1.2.2.cmml">w</mi><mi id="S3.SS2.p1.6.m6.1.1.2.3" xref="S3.SS2.p1.6.m6.1.1.2.3.cmml">n</mi></msub><mo id="S3.SS2.p1.6.m6.1.1.1" xref="S3.SS2.p1.6.m6.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml">𝒱</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><in id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1.1"></in><apply id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.2.1.cmml" xref="S3.SS2.p1.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2.2">𝑤</ci><ci id="S3.SS2.p1.6.m6.1.1.2.3.cmml" xref="S3.SS2.p1.6.m6.1.1.2.3">𝑛</ci></apply><ci id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">𝒱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">w_{n}\in\mathcal{V}</annotation></semantics></math> is the <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="n^{th}" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><msup id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml">n</mi><mrow id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml"><mi id="S3.SS2.p1.7.m7.1.1.3.2" xref="S3.SS2.p1.7.m7.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.7.m7.1.1.3.1" xref="S3.SS2.p1.7.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p1.7.m7.1.1.3.3" xref="S3.SS2.p1.7.m7.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2">𝑛</ci><apply id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3"><times id="S3.SS2.p1.7.m7.1.1.3.1.cmml" xref="S3.SS2.p1.7.m7.1.1.3.1"></times><ci id="S3.SS2.p1.7.m7.1.1.3.2.cmml" xref="S3.SS2.p1.7.m7.1.1.3.2">𝑡</ci><ci id="S3.SS2.p1.7.m7.1.1.3.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">n^{th}</annotation></semantics></math> word in the vocabulary <math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">\mathcal{V}</annotation></semantics></math> and <math id="S3.SS2.p1.9.m9.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p1.9.m9.1a"><mi id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.1b"><ci id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">N</annotation></semantics></math> is the length of the transcription. The ASR problem can be formulated as <math id="S3.SS2.p1.10.m10.1" class="ltx_Math" alttext="\hat{w}=\arg\max_{w\in\mathcal{V}^{*}}P(w|x)" display="inline"><semantics id="S3.SS2.p1.10.m10.1a"><mrow id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml"><mover accent="true" id="S3.SS2.p1.10.m10.1.1.3" xref="S3.SS2.p1.10.m10.1.1.3.cmml"><mi id="S3.SS2.p1.10.m10.1.1.3.2" xref="S3.SS2.p1.10.m10.1.1.3.2.cmml">w</mi><mo id="S3.SS2.p1.10.m10.1.1.3.1" xref="S3.SS2.p1.10.m10.1.1.3.1.cmml">^</mo></mover><mo id="S3.SS2.p1.10.m10.1.1.2" xref="S3.SS2.p1.10.m10.1.1.2.cmml">=</mo><mrow id="S3.SS2.p1.10.m10.1.1.1" xref="S3.SS2.p1.10.m10.1.1.1.cmml"><mrow id="S3.SS2.p1.10.m10.1.1.1.3" xref="S3.SS2.p1.10.m10.1.1.1.3.cmml"><mi id="S3.SS2.p1.10.m10.1.1.1.3.1" xref="S3.SS2.p1.10.m10.1.1.1.3.1.cmml">arg</mi><mo lspace="0.167em" id="S3.SS2.p1.10.m10.1.1.1.3a" xref="S3.SS2.p1.10.m10.1.1.1.3.cmml">⁡</mo><mrow id="S3.SS2.p1.10.m10.1.1.1.3.2" xref="S3.SS2.p1.10.m10.1.1.1.3.2.cmml"><msub id="S3.SS2.p1.10.m10.1.1.1.3.2.1" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.cmml"><mi id="S3.SS2.p1.10.m10.1.1.1.3.2.1.2" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.2.cmml">max</mi><mrow id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.cmml"><mi id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.2" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.2.cmml">w</mi><mo id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.1" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.1.cmml">∈</mo><msup id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.2" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.2.cmml">𝒱</mi><mo id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.3" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.3.cmml">∗</mo></msup></mrow></msub><mo lspace="0.167em" id="S3.SS2.p1.10.m10.1.1.1.3.2a" xref="S3.SS2.p1.10.m10.1.1.1.3.2.cmml">⁡</mo><mi id="S3.SS2.p1.10.m10.1.1.1.3.2.2" xref="S3.SS2.p1.10.m10.1.1.1.3.2.2.cmml">P</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p1.10.m10.1.1.1.2" xref="S3.SS2.p1.10.m10.1.1.1.2.cmml">​</mo><mrow id="S3.SS2.p1.10.m10.1.1.1.1.1" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.10.m10.1.1.1.1.1.2" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.10.m10.1.1.1.1.1.1" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.10.m10.1.1.1.1.1.1.2" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.2.cmml">w</mi><mo fence="false" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p1.10.m10.1.1.1.1.1.1.3" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S3.SS2.p1.10.m10.1.1.1.1.1.3" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><apply id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1"><eq id="S3.SS2.p1.10.m10.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.2"></eq><apply id="S3.SS2.p1.10.m10.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.3"><ci id="S3.SS2.p1.10.m10.1.1.3.1.cmml" xref="S3.SS2.p1.10.m10.1.1.3.1">^</ci><ci id="S3.SS2.p1.10.m10.1.1.3.2.cmml" xref="S3.SS2.p1.10.m10.1.1.3.2">𝑤</ci></apply><apply id="S3.SS2.p1.10.m10.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1"><times id="S3.SS2.p1.10.m10.1.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.2"></times><apply id="S3.SS2.p1.10.m10.1.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3"><arg id="S3.SS2.p1.10.m10.1.1.1.3.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.1"></arg><apply id="S3.SS2.p1.10.m10.1.1.1.3.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2"><apply id="S3.SS2.p1.10.m10.1.1.1.3.2.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.1.3.2.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1">subscript</csymbol><max id="S3.SS2.p1.10.m10.1.1.1.3.2.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.2"></max><apply id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3"><in id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.1"></in><ci id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.2">𝑤</ci><apply id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3">superscript</csymbol><ci id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.2">𝒱</ci><times id="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.1.3.3.3"></times></apply></apply></apply><ci id="S3.SS2.p1.10.m10.1.1.1.3.2.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3.2.2">𝑃</ci></apply></apply><apply id="S3.SS2.p1.10.m10.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p1.10.m10.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.2">𝑤</ci><ci id="S3.SS2.p1.10.m10.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">\hat{w}=\arg\max_{w\in\mathcal{V}^{*}}P(w|x)</annotation></semantics></math>, where <math id="S3.SS2.p1.11.m11.1" class="ltx_Math" alttext="P(w|x)" display="inline"><semantics id="S3.SS2.p1.11.m11.1a"><mrow id="S3.SS2.p1.11.m11.1.1" xref="S3.SS2.p1.11.m11.1.1.cmml"><mi id="S3.SS2.p1.11.m11.1.1.3" xref="S3.SS2.p1.11.m11.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.11.m11.1.1.2" xref="S3.SS2.p1.11.m11.1.1.2.cmml">​</mo><mrow id="S3.SS2.p1.11.m11.1.1.1.1" xref="S3.SS2.p1.11.m11.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.11.m11.1.1.1.1.2" xref="S3.SS2.p1.11.m11.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.11.m11.1.1.1.1.1" xref="S3.SS2.p1.11.m11.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.11.m11.1.1.1.1.1.2" xref="S3.SS2.p1.11.m11.1.1.1.1.1.2.cmml">w</mi><mo fence="false" id="S3.SS2.p1.11.m11.1.1.1.1.1.1" xref="S3.SS2.p1.11.m11.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.p1.11.m11.1.1.1.1.1.3" xref="S3.SS2.p1.11.m11.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S3.SS2.p1.11.m11.1.1.1.1.3" xref="S3.SS2.p1.11.m11.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m11.1b"><apply id="S3.SS2.p1.11.m11.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1"><times id="S3.SS2.p1.11.m11.1.1.2.cmml" xref="S3.SS2.p1.11.m11.1.1.2"></times><ci id="S3.SS2.p1.11.m11.1.1.3.cmml" xref="S3.SS2.p1.11.m11.1.1.3">𝑃</ci><apply id="S3.SS2.p1.11.m11.1.1.1.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p1.11.m11.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.p1.11.m11.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.11.m11.1.1.1.1.1.2">𝑤</ci><ci id="S3.SS2.p1.11.m11.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.11.m11.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m11.1c">P(w|x)</annotation></semantics></math> is the
posterior probability of the word sequence <math id="S3.SS2.p1.12.m12.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.SS2.p1.12.m12.1a"><mi id="S3.SS2.p1.12.m12.1.1" xref="S3.SS2.p1.12.m12.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m12.1b"><ci id="S3.SS2.p1.12.m12.1.1.cmml" xref="S3.SS2.p1.12.m12.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m12.1c">w</annotation></semantics></math> given the speech signal <math id="S3.SS2.p1.13.m13.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.p1.13.m13.1a"><mi id="S3.SS2.p1.13.m13.1.1" xref="S3.SS2.p1.13.m13.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.13.m13.1b"><ci id="S3.SS2.p1.13.m13.1.1.cmml" xref="S3.SS2.p1.13.m13.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m13.1c">x</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We propose a cascaded speech-to-text translation system, wherein an ASR system is trained to generate transcriptions, which are subsequently fed into a machine translation model. We opted for a cascaded architecture over an end-to-end approach due to the constraints imposed by limited resources, which rendered the development of an end-to-end system infeasible. Furthermore, previous research has demonstrated that cascaded systems can outperform end-to-end systems in low-resource settings, thereby motivating our design choice <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite></p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">We employed the Whisper model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> to tackle the task of ASR for Egyptian Arabic. The Whisper model, trained on a large-scale dataset of 680,000 hours of multilingual and multitask supervision, demonstrated excellent generalizability to our specific use case. This is particularly valuable for our application, as we are dealing with a unique dialect of Arabic, namely the Egyptian Arabic. The Whisper model, an encoder-decoder architecture, takes the input signal in spectrogram format and utilizes cross-attention mechanisms. For our experiments, we leveraged the ArzEn-ST dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, but restricted the output to transcription only, focusing on code-switched Egyptian Arabic.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Data preprocessing involved resampling all audio to 16 kHz, removing URLs and emoticons from the text, segmenting the speech into 30-second clips, and converting each clip into mel-spectrogram images. Training was conducted on 2 T4 GPUs, each equipped with 16 GB of VRAM. The training process was completed in approximately 5 hours.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.5.5" class="ltx_tr">
<th id="S3.T2.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.5.5.6.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S3.T2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.1.1.1.1" class="ltx_text ltx_font_bold">BLEU <math id="S3.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T2.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S3.T2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.2.2.2.1" class="ltx_text ltx_font_bold">BERT-F1 <math id="S3.T2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.2.2.2.1.m1.1a"><mo stretchy="false" id="S3.T2.2.2.2.1.m1.1.1" xref="S3.T2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.1.m1.1b"><ci id="S3.T2.2.2.2.1.m1.1.1.cmml" xref="S3.T2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S3.T2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.3.3.3.1" class="ltx_text ltx_font_bold">EED <math id="S3.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T2.3.3.3.1.m1.1a"><mo stretchy="false" id="S3.T2.3.3.3.1.m1.1.1" xref="S3.T2.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.1.m1.1b"><ci id="S3.T2.3.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S3.T2.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.4.4.4.1" class="ltx_text ltx_font_bold">METEOR <math id="S3.T2.4.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.4.4.4.1.m1.1a"><mo stretchy="false" id="S3.T2.4.4.4.1.m1.1.1" xref="S3.T2.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.1.m1.1b"><ci id="S3.T2.4.4.4.1.m1.1.1.cmml" xref="S3.T2.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S3.T2.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.5.5.5.1" class="ltx_text ltx_font_bold">LLMG <math id="S3.T2.5.5.5.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T2.5.5.5.1.m1.1a"><mo stretchy="false" id="S3.T2.5.5.5.1.m1.1.1" xref="S3.T2.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.1.m1.1b"><ci id="S3.T2.5.5.5.1.m1.1.1.cmml" xref="S3.T2.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.5.6.1" class="ltx_tr">
<th id="S3.T2.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Hamed et al., 2022 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</th>
<td id="S3.T2.5.6.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8.6</td>
<td id="S3.T2.5.6.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T2.5.6.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T2.5.6.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T2.5.6.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S3.T2.5.7.2" class="ltx_tr">
<th id="S3.T2.5.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Hamed et al., 2022 + Extra</th>
<td id="S3.T2.5.7.2.2" class="ltx_td ltx_align_center ltx_border_r">34.3</td>
<td id="S3.T2.5.7.2.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T2.5.7.2.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T2.5.7.2.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T2.5.7.2.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
</tr>
<tr id="S3.T2.5.8.3" class="ltx_tr">
<th id="S3.T2.5.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">LLaMa2 7B</th>
<td id="S3.T2.5.8.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.2</td>
<td id="S3.T2.5.8.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">42.9%</td>
<td id="S3.T2.5.8.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.68</td>
<td id="S3.T2.5.8.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.12</td>
<td id="S3.T2.5.8.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48%</td>
</tr>
<tr id="S3.T2.5.9.4" class="ltx_tr">
<th id="S3.T2.5.9.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Gemma1.1 2B</th>
<td id="S3.T2.5.9.4.2" class="ltx_td ltx_align_center ltx_border_r">34.3</td>
<td id="S3.T2.5.9.4.3" class="ltx_td ltx_align_center ltx_border_r">72.1%</td>
<td id="S3.T2.5.9.4.4" class="ltx_td ltx_align_center ltx_border_r">0.41</td>
<td id="S3.T2.5.9.4.5" class="ltx_td ltx_align_center ltx_border_r">0.39</td>
<td id="S3.T2.5.9.4.6" class="ltx_td ltx_align_center ltx_border_r">75.8%</td>
</tr>
<tr id="S3.T2.5.10.5" class="ltx_tr">
<th id="S3.T2.5.10.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Gemma1.1 2B + Extra</th>
<td id="S3.T2.5.10.5.2" class="ltx_td ltx_align_center ltx_border_r">37.5</td>
<td id="S3.T2.5.10.5.3" class="ltx_td ltx_align_center ltx_border_r">75.8%</td>
<td id="S3.T2.5.10.5.4" class="ltx_td ltx_align_center ltx_border_r">0.37</td>
<td id="S3.T2.5.10.5.5" class="ltx_td ltx_align_center ltx_border_r">0.56</td>
<td id="S3.T2.5.10.5.6" class="ltx_td ltx_align_center ltx_border_r">79.6%</td>
</tr>
<tr id="S3.T2.5.11.6" class="ltx_tr">
<th id="S3.T2.5.11.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Gemma1.1 7B</th>
<td id="S3.T2.5.11.6.2" class="ltx_td ltx_align_center ltx_border_r">38</td>
<td id="S3.T2.5.11.6.3" class="ltx_td ltx_align_center ltx_border_r">77.0%</td>
<td id="S3.T2.5.11.6.4" class="ltx_td ltx_align_center ltx_border_r">0.37</td>
<td id="S3.T2.5.11.6.5" class="ltx_td ltx_align_center ltx_border_r">0.53</td>
<td id="S3.T2.5.11.6.6" class="ltx_td ltx_align_center ltx_border_r">84.6%</td>
</tr>
<tr id="S3.T2.5.12.7" class="ltx_tr">
<th id="S3.T2.5.12.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Gemma1.1 7B + Extra</th>
<td id="S3.T2.5.12.7.2" class="ltx_td ltx_align_center ltx_border_r">38.2</td>
<td id="S3.T2.5.12.7.3" class="ltx_td ltx_align_center ltx_border_r">77.6%</td>
<td id="S3.T2.5.12.7.4" class="ltx_td ltx_align_center ltx_border_r">0.37</td>
<td id="S3.T2.5.12.7.5" class="ltx_td ltx_align_center ltx_border_r">0.56</td>
<td id="S3.T2.5.12.7.6" class="ltx_td ltx_align_center ltx_border_r">84.3%</td>
</tr>
<tr id="S3.T2.5.13.8" class="ltx_tr">
<th id="S3.T2.5.13.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">LLaMa3 8B GGUF Q5</th>
<td id="S3.T2.5.13.8.2" class="ltx_td ltx_align_center ltx_border_r">53.01</td>
<td id="S3.T2.5.13.8.3" class="ltx_td ltx_align_center ltx_border_r">80.8%</td>
<td id="S3.T2.5.13.8.4" class="ltx_td ltx_align_center ltx_border_r">0.31</td>
<td id="S3.T2.5.13.8.5" class="ltx_td ltx_align_center ltx_border_r">0.58</td>
<td id="S3.T2.5.13.8.6" class="ltx_td ltx_align_center ltx_border_r">86.2%</td>
</tr>
<tr id="S3.T2.5.14.9" class="ltx_tr">
<th id="S3.T2.5.14.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">LLaMa3 8B</th>
<td id="S3.T2.5.14.9.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.5.14.9.2.1" class="ltx_text ltx_font_bold">53.64</span></td>
<td id="S3.T2.5.14.9.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.5.14.9.3.1" class="ltx_text ltx_font_bold">81.1%</span></td>
<td id="S3.T2.5.14.9.4" class="ltx_td ltx_align_center ltx_border_r">0.31</td>
<td id="S3.T2.5.14.9.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.5.14.9.5.1" class="ltx_text ltx_font_bold">0.62</span></td>
<td id="S3.T2.5.14.9.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.5.14.9.6.1" class="ltx_text ltx_font_bold">86.4%</span></td>
</tr>
<tr id="S3.T2.5.15.10" class="ltx_tr">
<th id="S3.T2.5.15.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">LLaMa3 8B + Extra</th>
<td id="S3.T2.5.15.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">52.27</td>
<td id="S3.T2.5.15.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">80.1%</td>
<td id="S3.T2.5.15.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T2.5.15.10.4.1" class="ltx_text ltx_font_bold">0.30</span></td>
<td id="S3.T2.5.15.10.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.59</td>
<td id="S3.T2.5.15.10.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">85.8%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.7.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.8.2" class="ltx_text" style="font-size:90%;">Summary results for the models trained on ArzEn-ST to generate English translations. We report BLEU score using SacreBLEU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>,
BERT F1, Edit Distance (EED), METEOR, and LLaMa3 70B as an LLM Grader (LLMG). The lower section of the table represents our work.</span></figcaption>
</figure>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.5.5" class="ltx_tr">
<th id="S3.T3.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T3.5.5.6.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S3.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.1.1.1.1" class="ltx_text ltx_font_bold">BLEU <math id="S3.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T3.1.1.1.1.m1.1a"><mo stretchy="false" id="S3.T3.1.1.1.1.m1.1.1" xref="S3.T3.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.m1.1b"><ci id="S3.T3.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S3.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.2.2.2.1" class="ltx_text ltx_font_bold">BERT-F1 <math id="S3.T3.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T3.2.2.2.1.m1.1a"><mo stretchy="false" id="S3.T3.2.2.2.1.m1.1.1" xref="S3.T3.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.1.m1.1b"><ci id="S3.T3.2.2.2.1.m1.1.1.cmml" xref="S3.T3.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S3.T3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.3.3.3.1" class="ltx_text ltx_font_bold">EED <math id="S3.T3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T3.3.3.3.1.m1.1a"><mo stretchy="false" id="S3.T3.3.3.3.1.m1.1.1" xref="S3.T3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.1.m1.1b"><ci id="S3.T3.3.3.3.1.m1.1.1.cmml" xref="S3.T3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S3.T3.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.4.4.4.1" class="ltx_text ltx_font_bold">METEOR <math id="S3.T3.4.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T3.4.4.4.1.m1.1a"><mo stretchy="false" id="S3.T3.4.4.4.1.m1.1.1" xref="S3.T3.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.4.1.m1.1b"><ci id="S3.T3.4.4.4.1.m1.1.1.cmml" xref="S3.T3.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S3.T3.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.5.5.5.1" class="ltx_text ltx_font_bold">LLMG <math id="S3.T3.5.5.5.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S3.T3.5.5.5.1.m1.1a"><mo stretchy="false" id="S3.T3.5.5.5.1.m1.1.1" xref="S3.T3.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.5.1.m1.1b"><ci id="S3.T3.5.5.5.1.m1.1.1.cmml" xref="S3.T3.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.5.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.5.6.1" class="ltx_tr">
<th id="S3.T3.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Hamed et al., 2022 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</th>
<td id="S3.T3.5.6.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.0</td>
<td id="S3.T3.5.6.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T3.5.6.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T3.5.6.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S3.T3.5.6.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S3.T3.5.7.2" class="ltx_tr">
<th id="S3.T3.5.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Hamed et al., 2022 + Extra</th>
<td id="S3.T3.5.7.2.2" class="ltx_td ltx_align_center ltx_border_r">79.8</td>
<td id="S3.T3.5.7.2.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T3.5.7.2.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T3.5.7.2.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T3.5.7.2.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
</tr>
<tr id="S3.T3.5.8.3" class="ltx_tr">
<th id="S3.T3.5.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Gemma1.1 2B</th>
<td id="S3.T3.5.8.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.9</td>
<td id="S3.T3.5.8.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.1%</td>
<td id="S3.T3.5.8.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.09</td>
<td id="S3.T3.5.8.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.87</td>
<td id="S3.T3.5.8.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">94%</td>
</tr>
<tr id="S3.T3.5.9.4" class="ltx_tr">
<th id="S3.T3.5.9.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Gemma1.1 7B</th>
<td id="S3.T3.5.9.4.2" class="ltx_td ltx_align_center ltx_border_r">83.7</td>
<td id="S3.T3.5.9.4.3" class="ltx_td ltx_align_center ltx_border_r">95.9%</td>
<td id="S3.T3.5.9.4.4" class="ltx_td ltx_align_center ltx_border_r">0.12</td>
<td id="S3.T3.5.9.4.5" class="ltx_td ltx_align_center ltx_border_r">0.84</td>
<td id="S3.T3.5.9.4.6" class="ltx_td ltx_align_center ltx_border_r">92.6%</td>
</tr>
<tr id="S3.T3.5.10.5" class="ltx_tr">
<th id="S3.T3.5.10.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">LLaMa3 8B GGUF Q5</th>
<td id="S3.T3.5.10.5.2" class="ltx_td ltx_align_center ltx_border_r">86.3</td>
<td id="S3.T3.5.10.5.3" class="ltx_td ltx_align_center ltx_border_r">96.2%</td>
<td id="S3.T3.5.10.5.4" class="ltx_td ltx_align_center ltx_border_r">0.09</td>
<td id="S3.T3.5.10.5.5" class="ltx_td ltx_align_center ltx_border_r">0.76</td>
<td id="S3.T3.5.10.5.6" class="ltx_td ltx_align_center ltx_border_r">94%</td>
</tr>
<tr id="S3.T3.5.11.6" class="ltx_tr">
<th id="S3.T3.5.11.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">LLaMa3 8B</th>
<td id="S3.T3.5.11.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T3.5.11.6.2.1" class="ltx_text ltx_font_bold">87.2</span></td>
<td id="S3.T3.5.11.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T3.5.11.6.3.1" class="ltx_text ltx_font_bold">98.8%</span></td>
<td id="S3.T3.5.11.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T3.5.11.6.4.1" class="ltx_text ltx_font_bold">0.07</span></td>
<td id="S3.T3.5.11.6.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T3.5.11.6.5.1" class="ltx_text ltx_font_bold">0.88</span></td>
<td id="S3.T3.5.11.6.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T3.5.11.6.6.1" class="ltx_text ltx_font_bold">96%</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.7.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S3.T3.8.2" class="ltx_text" style="font-size:90%;">Summary results for the models trained on ArzEn-ST to generate Egyptian Arabic translations. We report BLEU score using SacreBLEU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, BERT F1, Edit Distance (EED), METEOR, and LLaMa3 70B as an LLM Grader (LLMG). The lower section of the table represents our work.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results and Discussion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We evaluated the machine translation models using five criteria: BLEU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, BERT Score <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, edit distance (EED), METEOR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, and LLaMa3-based grading, inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, as traditional metrics are limited in capturing semantic nuances. For ASR, we employed Word-Error Rate (WER) and Character-Error Rate (CER) as evaluation metrics. Our models are compared to the state-of-the-art results in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, with a focus on BLEU for MT and WER and CER for ASR, as these are the only reported metrics.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.4" class="ltx_p">Figure <a href="#S4.F1.sf1" title="In Fig. 1 ‣ 4 Results and Discussion ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a> shows that LLaMa3 outperforms all other models on the ArzEn to English translation task. As in table <a href="#S3.T2" title="Table 2 ‣ 3.2 Automatic Speech Recognition (ASR) ‣ 3 Methodology ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, LLaMa3 achieves a BLEU score of <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="53.64" display="inline"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">53.64</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn type="float" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">53.64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">53.64</annotation></semantics></math>, which is significantly higher than the SoTA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> by <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="56\%" display="inline"><semantics id="S4.p2.2.m2.1a"><mrow id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mn id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">56</mn><mo id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">56</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">56\%</annotation></semantics></math>. Also, smaller models such as Gemma 2B and Gemma 7B achieved comparable results to LLaMa3 8B with <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="9\%" display="inline"><semantics id="S4.p2.3.m3.1a"><mrow id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mn id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">9</mn><mo id="S4.p2.3.m3.1.1.1" xref="S4.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">9\%</annotation></semantics></math> and <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="4.1\%" display="inline"><semantics id="S4.p2.4.m4.1a"><mrow id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><mn id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml">4.1</mn><mo id="S4.p2.4.m4.1.1.1" xref="S4.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2">4.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">4.1\%</annotation></semantics></math> lower in BERT-f1 score, respectively.
On the other hand, LLaMa2 performance is the lowest which can be easily interpreted due to the fact that its tokenizer does not support Arabic tokenization. In contrast to new models such as Gemma and LLaMa3 which uses Byte-Pair Encoding (BPE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> implemented with tiktoken, LLaMa2 just breaks down the Arabic sentence into characters as shown in table <a href="#S4.T5" title="Table 5 ‣ 4 Results and Discussion ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">Notably, models pre-trained on additional data (Hamed et al., 2022 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> + Extra and Gemmal.1 2B + Extra) generally outperform their counterparts trained only on the ArzEn dataset, suggesting that extra pre-training data can effectively enhance machine translation model performance. Although, this gain is marginal for larger models, such as Gemma1.1 7B, it can even be detrimental, as observed in LLaMa3 8B, with a <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="-1\%" display="inline"><semantics id="S4.p3.1.m1.1a"><mrow id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mo id="S4.p3.1.m1.1.1a" xref="S4.p3.1.m1.1.1.cmml">−</mo><mrow id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml"><mn id="S4.p3.1.m1.1.1.2.2" xref="S4.p3.1.m1.1.1.2.2.cmml">1</mn><mo id="S4.p3.1.m1.1.1.2.1" xref="S4.p3.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><minus id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1"></minus><apply id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2"><csymbol cd="latexml" id="S4.p3.1.m1.1.1.2.1.cmml" xref="S4.p3.1.m1.1.1.2.1">percent</csymbol><cn type="integer" id="S4.p3.1.m1.1.1.2.2.cmml" xref="S4.p3.1.m1.1.1.2.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">-1\%</annotation></semantics></math> decrease in BERT-f1 score.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.5.5" class="ltx_tr">
<th id="S4.T4.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T4.5.5.6.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T4.1.1.1.1" class="ltx_text ltx_font_bold">WER <math id="S4.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T4.1.1.1.1.m1.1.1" xref="S4.T4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S4.T4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T4.2.2.2.1" class="ltx_text ltx_font_bold">CER <math id="S4.T4.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T4.2.2.2.1.m1.1.1" xref="S4.T4.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.1.m1.1b"><ci id="S4.T4.2.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S4.T4.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T4.3.3.3.1" class="ltx_text ltx_font_bold">BLEU <math id="S4.T4.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T4.3.3.3.1.m1.1.1" xref="S4.T4.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.1.m1.1b"><ci id="S4.T4.3.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S4.T4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T4.4.4.4.1" class="ltx_text ltx_font_bold">LLMG <math id="S4.T4.4.4.4.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T4.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T4.4.4.4.1.m1.1.1" xref="S4.T4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.1.m1.1b"><ci id="S4.T4.4.4.4.1.m1.1.1.cmml" xref="S4.T4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math></span></th>
<th id="S4.T4.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T4.5.5.5.1" class="ltx_text ltx_font_bold">EED <math id="S4.T4.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T4.5.5.5.1.m1.1.1" xref="S4.T4.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.5.1.m1.1b"><ci id="S4.T4.5.5.5.1.m1.1.1.cmml" xref="S4.T4.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.5.6.1" class="ltx_tr">
<th id="S4.T4.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Hamed et al., 2022 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</th>
<td id="S4.T4.5.6.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.9</td>
<td id="S4.T4.5.6.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.2</td>
<td id="S4.T4.5.6.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T4.5.6.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S4.T4.5.6.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S4.T4.5.7.2" class="ltx_tr">
<th id="S4.T4.5.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Hamed et al., 2022 + Extra</th>
<td id="S4.T4.5.7.2.2" class="ltx_td ltx_align_center ltx_border_r">34.7</td>
<td id="S4.T4.5.7.2.3" class="ltx_td ltx_align_center ltx_border_r">20.0</td>
<td id="S4.T4.5.7.2.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T4.5.7.2.5" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T4.5.7.2.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
</tr>
<tr id="S4.T4.5.8.3" class="ltx_tr">
<th id="S4.T4.5.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Whisper Small</th>
<td id="S4.T4.5.8.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">32.6</td>
<td id="S4.T4.5.8.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">12.8</td>
<td id="S4.T4.5.8.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">51.77</td>
<td id="S4.T4.5.8.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.1%</td>
<td id="S4.T4.5.8.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.14</td>
</tr>
<tr id="S4.T4.5.9.4" class="ltx_tr">
<th id="S4.T4.5.9.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">Whisper Medium</th>
<td id="S4.T4.5.9.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T4.5.9.4.2.1" class="ltx_text ltx_font_bold">31.1</span></td>
<td id="S4.T4.5.9.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T4.5.9.4.3.1" class="ltx_text ltx_font_bold">12.0</span></td>
<td id="S4.T4.5.9.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T4.5.9.4.4.1" class="ltx_text ltx_font_bold">55.41</span></td>
<td id="S4.T4.5.9.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T4.5.9.4.5.1" class="ltx_text ltx_font_bold">92.5%</span></td>
<td id="S4.T4.5.9.4.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T4.5.9.4.6.1" class="ltx_text ltx_font_bold">0.09</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.7.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.8.2" class="ltx_text" style="font-size:90%;">Performance of automatic speech recognition from speech to code-switched Arabic-English task. Lower Word-Error Rate (WER), Character-Error Rate (CER), and Edit Distance (EED) scores indicate better quality. The lower section of the table represents our work.</span></figcaption>
</figure>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">As shown in table <a href="#S3.T3" title="Table 3 ‣ 3.2 Automatic Speech Recognition (ASR) ‣ 3 Methodology ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, translating into Arabic yields significantly higher BLEU scores compared to translating into English, with our optimal Arabic model achieving a BLEU score of 87.2, whereas the best English model attains a BLEU score of 53.64, representing a notable difference of approximately 62%. This phenomenon is consistent with the linguistic characteristics of the source text, where a significant proportion (approximately <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="85\%" display="inline"><semantics id="S4.p4.1.m1.1a"><mrow id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml"><mn id="S4.p4.1.m1.1.1.2" xref="S4.p4.1.m1.1.1.2.cmml">85</mn><mo id="S4.p4.1.m1.1.1.1" xref="S4.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><apply id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1"><csymbol cd="latexml" id="S4.p4.1.m1.1.1.1.cmml" xref="S4.p4.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.p4.1.m1.1.1.2.cmml" xref="S4.p4.1.m1.1.1.2">85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">85\%</annotation></semantics></math>) of Arabic words remain largely unchanged, with only minor modifications required to accommodate the target language.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.2.1.1" class="ltx_tr">
<th id="S4.T5.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T5.2.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T5.2.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T5.2.1.1.2.1" class="ltx_text ltx_font_bold">Tokens</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.2.2.1" class="ltx_tr">
<th id="S4.T5.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">LLaMa2</th>
<td id="S4.T5.2.2.1.2" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">[<span id="S4.T5.2.2.1.2.1" class="ltx_ERROR undefined">\&lt;</span>أ، ن، ا، أ، ح، ب، ا، ل، ت، ف، ا، ح¿]</td>
</tr>
<tr id="S4.T5.2.3.2" class="ltx_tr">
<th id="S4.T5.2.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r">Gemma</th>
<td id="S4.T5.2.3.2.2" class="ltx_td ltx_align_right ltx_border_r">[<span id="S4.T5.2.3.2.2.1" class="ltx_ERROR undefined">\&lt;</span>أنا، أح، ب، التف، اح¿]</td>
</tr>
<tr id="S4.T5.2.4.3" class="ltx_tr">
<th id="S4.T5.2.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">LLaMa3</th>
<td id="S4.T5.2.4.3.2" class="ltx_td ltx_align_right ltx_border_b ltx_border_r">[<span id="S4.T5.2.4.3.2.1" class="ltx_ERROR undefined">\&lt;</span>أنا، أح، ب، التف، اح¿]</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.4.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.5.2" class="ltx_text" style="font-size:90%;">Tokenization results for the Arabic sentence <span id="S4.T5.5.2.1" class="ltx_ERROR undefined">\RL</span>أنا أحب التفاح (I love apples) using different tokenizers. </span></figcaption>
</figure>
<figure id="S4.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.18120/assets/assets/train-eng.png" id="S4.F1.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="315" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Training curves for English translation training.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.18120/assets/assets/train-ranks.png" id="S4.F1.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="315" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Training curves for different QLoRA ranks on Gemma1.1 2B.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.18120/assets/assets/train-ar.png" id="S4.F1.sf3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="315" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">Training curves for Arabic translation training.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F1.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2406.18120/assets/assets/whisper-train.png" id="S4.F1.sf4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="315" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F1.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F1.sf4.3.2" class="ltx_text" style="font-size:90%;">Training curves for Whisper.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F1.2.1.1" class="ltx_text" style="font-size:90%;">Fig. 1</span>: </span><span id="S4.F1.3.2" class="ltx_text" style="font-size:90%;">Training curves for various machine translation models. The x-axis represents the number of training steps, and the y-axis represents the loss. </span></figcaption>
</figure>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">As illustrated in figure <a href="#S4.F1.sf2" title="In Fig. 1 ‣ 4 Results and Discussion ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>, increasing the LoRA rank consistently yields better results. Our experiments reveal that the optimal parameters are a rank of 256 and an alpha value of 128. Furthermore, we observe that higher ranks require increased LoRA dropout to mitigate overfitting, with a dropout of 0.1 employed for ranks exceeding 32.</p>
</div>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.3" class="ltx_p">As shown in table <a href="#S4.T4" title="Table 4 ‣ 4 Results and Discussion ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, our trained Whisper models surpass the state-of-the-art results in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> (+ Extra) by <math id="S4.p6.1.m1.1" class="ltx_Math" alttext="11.6\%" display="inline"><semantics id="S4.p6.1.m1.1a"><mrow id="S4.p6.1.m1.1.1" xref="S4.p6.1.m1.1.1.cmml"><mn id="S4.p6.1.m1.1.1.2" xref="S4.p6.1.m1.1.1.2.cmml">11.6</mn><mo id="S4.p6.1.m1.1.1.1" xref="S4.p6.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p6.1.m1.1b"><apply id="S4.p6.1.m1.1.1.cmml" xref="S4.p6.1.m1.1.1"><csymbol cd="latexml" id="S4.p6.1.m1.1.1.1.cmml" xref="S4.p6.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.p6.1.m1.1.1.2.cmml" xref="S4.p6.1.m1.1.1.2">11.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.1.m1.1c">11.6\%</annotation></semantics></math> in WER, despite being trained solely on the original data without additional pre-training. Furthermore, figure <a href="#S4.F1.sf4" title="In Fig. 1 ‣ 4 Results and Discussion ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(d)</span></a> illustrates that the medium Whisper model marginally outperforms the small version, resulting in a <math id="S4.p6.2.m2.1" class="ltx_Math" alttext="7.1\%" display="inline"><semantics id="S4.p6.2.m2.1a"><mrow id="S4.p6.2.m2.1.1" xref="S4.p6.2.m2.1.1.cmml"><mn id="S4.p6.2.m2.1.1.2" xref="S4.p6.2.m2.1.1.2.cmml">7.1</mn><mo id="S4.p6.2.m2.1.1.1" xref="S4.p6.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p6.2.m2.1b"><apply id="S4.p6.2.m2.1.1.cmml" xref="S4.p6.2.m2.1.1"><csymbol cd="latexml" id="S4.p6.2.m2.1.1.1.cmml" xref="S4.p6.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.p6.2.m2.1.1.2.cmml" xref="S4.p6.2.m2.1.1.2">7.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.2.m2.1c">7.1\%</annotation></semantics></math> increase in BLEU score, as reflected in table <a href="#S4.T4" title="Table 4 ‣ 4 Results and Discussion ‣ ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Whisper can achieve real-time output, with a latency of <math id="S4.p6.3.m3.1" class="ltx_Math" alttext="1.3" display="inline"><semantics id="S4.p6.3.m3.1a"><mn id="S4.p6.3.m3.1.1" xref="S4.p6.3.m3.1.1.cmml">1.3</mn><annotation-xml encoding="MathML-Content" id="S4.p6.3.m3.1b"><cn type="float" id="S4.p6.3.m3.1.1.cmml" xref="S4.p6.3.m3.1.1">1.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.3.m3.1c">1.3</annotation></semantics></math> seconds for a single 30-second clip inference on a consumer-grade GPU with fp16 precision, and 18 seconds on a CPU.</p>
</div>
<div id="S4.p7" class="ltx_para">
<p id="S4.p7.1" class="ltx_p">Notably, for English models, we found that human evaluation is particularly well-suited. Therefore, we conducted a human evaluation study, where 65 university students were asked to assess the quality of 10 randomly selected generated sentences on a scale of 1-10, with 1 indicating an irrelevant translation and 10 representing a perfect translation that captures both meaning and cultural nuances. This approach was necessary, as traditional evaluation metrics such as BERTScore, METEOR, edit distance, and BLEU fail to adequately capture the nuances of meaning and cultural context. Our results show that, on average, the generated translations received a rating of 9.2 out of 10, which supports our claim of capturing both perfect meaning and cultural nuances. For instance, when presented with the sentence “<span id="S4.p7.1.1" class="ltx_ERROR undefined">\RL</span>انا دخلت <span id="S4.p7.1.2" class="ltx_ERROR undefined">\LR</span>IG,” our model produced the translation ”I entered IG school,” notwithstanding that “IG” signifies “Instagram”
in contexts outside of Egyptian culture.</p>
</div>
<div id="S4.p8" class="ltx_para">
<p id="S4.p8.1" class="ltx_p">Finally, our top-performing model, LLaMa3, was quantized from bfloat16 to 5-bit Q5, achieving a 68.75% reduction in bits while maintaining performance, with only 1.2% and 1% degradation in English and Arabic versions, respectively. The quantized model can be deployed on a consumer-grade RAM with a modest 5.6 GB footprint, supporting a throughput of 7.2 tokens/sec, thereby enabling real-time speech translation and video dubbing applications.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This paper has provided insights into the methodologies employed in developing machine translation and automatic speech recognition systems for code-switched Egyptian Arabic. Through careful experimentation and rigorous evaluation, we have demonstrated the effectiveness of our approaches in achieving culturally fitting translations and accurate speech recognition.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Our findings emphasize the importance of using large language models and pre-training with additional data to enhance the performance of MT systems. Moreover, the success of our ASR models, particularly the Whisper architecture, highlights the potential of deep learning techniques in tackling speech recognition tasks, even in low-resource settings.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">Looking ahead, further research could explore advanced optimization techniques and novel model architectures to push the boundaries of MT and ASR performance. Additionally, efforts to expand training data and refine models for specific dialects could result in even more precise translations and transcriptions, fostering greater linguistic accessibility in our globalized world.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Team, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S., Sifre, L., Rivière, M., Kale, M. S., Love, J., Tafti, P., Hussenot, L., Sessa, P. G., Chowdhery, A., Roberts, A., Barua, A., Botev, A., Castro-Ros, A., Slone, A., … Kenealy, K. (2024) “Gemma: Open Models Based on Gemini Research and Technology”, arXiv.org, https://arxiv.org/abs/2403.08295.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Huang, H., Yu, F., Zhu, J., Sun, X., Cheng, H., Song, D., Chen, Z., Alharthi, A., An, B., He, J., Liu, Z., Zhang, Z., Chen, J., Li, J., Wang, B., Zhang, L., Sun, R., Wan, X., Li, H., Xu, J. (2023) “AceGPT, Localizing Large Language Models in Arabic”, arXiv.org, https://arxiv.org/abs/2309.12053.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Hamed, I., Vu, N. T., Abdennadher, S. (2020) “Arzen: A speech corpus for code-switched Egyptian Arabic-English”, in Proceedings of the International Conference on Language Resources and Evaluation, pages 4237-4246.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Al-Sabbagh, R. (2024) “ArzEn-MultiGenre: An aligned parallel dataset of Egyptian Arabic song lyrics, novels, and subtitles, with English translations”, Data in Brief, 54, 110271.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Radford, Alec, Kim, Jong Wook, Xu, Tao, Brockman, Greg, McLeavey, Christine, Sutskever, Ilya (2023) “Robust speech recognition via large-scale weak supervision”, in Proceedings of the 40th International Conference on Machine Learning, Honolulu, Hawaii, USA.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Hamed, I., Habash, N., Abdennadher, S., Vu, N. T. (2022) “ArzEn-ST: A Three-way Speech Translation Corpus for Code-Switched Egyptian Arabic-English”, in Bouamor, H., Al-Khalifa, H., Darwish, K., Rambow, O., Bougares, F., Abdelali, A., Tomeh, N., Khalifa, S., Zaghouani, W. (eds) Proceedings of the Seventh Arabic Natural Language Processing Workshop (WANLP), Abu Dhabi, United Arab Emirates (Hybrid).

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu (2002) “Bleu: a method for automatic evaluation of machine translation”, in Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311-318.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Zhang, T., Kishore, V., Wu, F., Weinberger, K.Q. and Artzi, Y., 2019. Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Banerjee, S. and Lavie, A., 2005, June. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization (pp. 65-72).

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Dettmers, T., Pagnoni, A., Holtzman, A. and Zettlemoyer, L., 2024. Qlora: Efficient finetuning of quantized llms. Advances in Neural Information Processing Systems, 36.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Liu, S.Y., Wang, C.Y., Yin, H., Molchanov, P., Wang, Y.C.F., Cheng, K.T. and Chen, M.H., 2024. DoRA: Weight-Decomposed Low-Rank Adaptation. arXiv preprint arXiv:2402.09353.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Loshchilov, I. and Hutter, F., 2017. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Chen, T., Xu, B., Zhang, C. and Guestrin, C., 2016. Training deep nets with sublinear memory cost. arXiv preprint arXiv:1604.06174.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Lamy-Poirier, J., 2021. Layered gradient accumulation and modular pipeline parallelism: fast and efficient training of large language models. arXiv preprint arXiv:2106.02679.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Denisov, P., Mager, M. and Vu, N. T. (2021) ’IMS’s systems for the IWSLT 2021 low-resource speech translation task’, Proceedings of the International Conference on Spoken Language Translation.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Sitaram, S., Chandu, K.R., Rallabandi, S.K. and Black, A.W., 2019. A survey of code-switched speech and language processing. arXiv preprint arXiv:1904.00784.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Hafez, R. (2015) Factors affecting code switching between Arabic and English. Master’s thesis, The American University in Cairo. Available at: https://fount.aucegypt.edu/etds/148

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Shibata, Y., Kida, T., Fukamachi, S., Takeda, M., Shinohara, A., Shinohara, T. and Arikawa, S., 1999. Byte pair encoding: A text compression scheme that accelerates pattern matching.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Li, L., 2004. Corpus-based machine translation. Shanghai Journal of Translators for Science and Technology, 19(2), pp.59-62.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Al-Taani, A.T. and Hailat, Z.M., 2005. A direct English-Arabic machine translation system. Information Technology Journal, 4(3), pp.256-261.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Farhat, A. and Al-Taani, A., 2015. A rule-based English to Arabic machine translation approach. In international Arab conference on information technology (ACIT’2015).

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Carbonell, J.G., Cullingford, R.E. and Gershman, A.V., 1981. Steps toward knowledge-based machine translation. IEEE Transactions on Pattern Analysis and Machine Intelligence, (4), pp.376-392.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Oladosu, J., Esan, A., Adeyanju, I., Adegoke, B., Olaniyan, O. and Omodunbi, B., 2016. Approaches to machine translation: a review. FUOYE Journal of Engineering and Technology, 1(1).

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Abiola, O.B., Adetunmbi, A.O. and Oguntimilehin, A., 2015. Using hybrid approach for English-to-Yoruba text to text machine translation system (proposed)”. International Journal of Computer Science and Mobile Computing, 4(8), pp.308-313.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S. and Bikel, D., 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
OpenAI, 2022. ChatGPT. Available at: https://openai.com/blog/chatgpt.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Jacobson, R. ed., 2001.Codeswitching worldwide II. Mouton de Gruyter.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Chan, J.Y., Ching, P.C., Lee, T. and Meng, H.M., 2004, December. Detection of language boundary in code-switching utterances by bi-phone probabilities. In 2004 International Symposium on Chinese Spoken Language Processing (pp. 293-296). IEEE.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Weiner, J., Vu, N.T., Telaar, D., Metze, F., Schultz, T., Lyu, D.C., Chng, E.S. and Li, H., 2012. Integration of language identification into a recognition system for spoken conversations containing code-switches. In Spoken Language Technologies for Under-Resourced Languages.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Lyu, D.C., Lyu, R.Y., Chiang, Y.C. and Hsu, C.N., 2006, May. Speech recognition on code-switching among the Chinese dialects. In 2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings (Vol. 1, pp. I-I). IEEE.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Costa-jussà, M.R., Cross, J., Çelebi, O., Elbayad, M., Heafield, K., Heffernan, K., Kalbassi, E., Lam, J., Licht, D., Maillard, J. and Sun, A., 2022. No language left behind: Scaling human-centered machine translation. arXiv preprint arXiv:2207.04672.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Barrault, L., Chung, Y.A., Meglioli, M.C., Dale, D., Dong, N., Duppenthaler, M., Duquenne, P.A., Ellis, B., Elsahar, H., Haaheim, J. and Hoffman, J., 2023. Seamless: Multilingual Expressive and Streaming Speech Translation. arXiv preprint arXiv:2312.05187.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Xiao, C., Ma, W., Xu, S.X., Zhang, K., Wang, Y. and Fu, Q., 2024. From Automation to Augmentation: Large Language Models Elevating Essay Scoring Landscape. arXiv preprint arXiv:2401.06431.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.18119" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.18120" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.18120">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.18120" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.18121" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 20:16:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
