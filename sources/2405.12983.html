<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2405.12983] Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer</title><meta property="og:description" content="Humans are adept at leveraging visual cues from lip movements for recognizing speech in adverse listening conditions. Audio-Visual Speech Recognition (AVSR) models follow similar approach to achieve robust speech recog…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2405.12983">

<!--Generated on Wed Jun  5 14:17:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Humans are adept at leveraging visual cues from lip movements for recognizing speech in adverse listening conditions. Audio-Visual Speech Recognition (AVSR) models follow similar approach to achieve robust speech recognition in noisy conditions. In this work, we present a multilingual AVSR model incorporating several enhancements to improve performance and audio noise robustness. Notably, we adapt the recently proposed Fast Conformer model to process both audio and visual modalities using a novel hybrid CTC/RNN-T architecture. We increase the amount of audio-visual training data for six distinct languages, generating automatic transcriptions of unlabelled multilingual datasets (VoxCeleb2 and AVSpeech). Our proposed model achieves new state-of-the-art performance on the LRS3 dataset, reaching WER of 0.8%. On the recently introduced MuAViC benchmark, our model yields an absolute average-WER reduction of 11.9% in comparison to the original baseline. Finally, we demonstrate the ability of the proposed model to perform audio-only, visual-only, and audio-visual speech recognition at test time.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— </span></span>
audio-visual speech recognition, multilingual, noise robustness, generated transcriptions</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Audio-Visual Speech Recognition (AVSR) has attracted a lot of research attention in recent years due to its ability to use image processing techniques to aid speech recognition systems. Preceding works have shown that including the visual modality of lip movements could improve the robustness of ASR systems with respect to audio noise while achieving better recognition performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Son <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> proposed to use the sequence-to-sequence encoder-decoder with attention architecture to recognise phrases and sentences being spoken by talking faces, with or without the audio. Petridis <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> applied the hybrid CTC/attention architecture to AVSR, achieving better performance and robustness using an early fusion strategy. Ma <span id="S1.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> proposed to encode audio and visual modalities with Conformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> networks to model both local and global temporal relationships using convolution and attention. More recently, AVEC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> added intermediate CTC losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> in encoder networks to improve lip reading performance and AVSR robustness.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Supervised AVSR approaches have shown promising results with stronger audio noise robustness but still rely on a limited amount of human-annotated speech data compared to classical ASR systems. This is especially the case for non-English languages, for which the amount of available data is not as important. Serdyuk <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and Chang <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> showed that performance could greatly be improved using large scale datasets of up to 100k hours composed of YouTube videos. However, these datasets remain private and unusable for comparison. LRS3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, which is the largest publicly available AVSR dataset, contains less than 450 training hours of audio-visual speech while LRW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and LRS2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> datasets are only available to academic institutions. The MuAViC corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, which was recently released as benchmark for multilingual AVSR, contains only 10 hours of German speech.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To remedy this problem, other works started to focus on using self-supervised pre-training techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> to improve performance by learning hidden representations with large scale unlabeled datasets. AV-HuBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> was the first self-supervised system to jointly learn speech representations from audio and video. It iteratively learns to minimize a masked prediction loss by first clustering acoustic features (MFCC) and then audio-visual hidden features using k-means. RAVen <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> proposed to pre-train unimodal encoders by predicting cross-modal representations of slow-moving teacher networks. VATLM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> proposed a visual-audio-text model optimized to predict the hidden units of different modalities with a unified masked prediction task. AV-data2vec <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> learns to predict the unmasked audio-visual output representations of a slow-moving teacher network. All these methods successfully improve generalization and performance by pre-training on the VoxCeleb2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> dataset with various pretext tasks. However, they can be complex to pre-train and still require to be fine-tuned.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">More recently, Ma <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> showed that state-of-the-art performance could simply be achieved by training on generated transcriptions. They first generate English transcriptions of VoxCeleb2 and AVSpeech datasets using Whisper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and use them to increase the amount of training data available. Inspired by this work, we study the impact of generated transcriptions on six languages using large scale multilingual datasets. This paper brings four main contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">A novel hybrid architecture for AVSR using both Connectionist Temporal Classification (CTC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and Recurrent Neural Network Transducer (RNN-T) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> losses.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:-2.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">The use of generated transcriptions from large scale multilingual datasets (VoxCeleb2 and AVSpeech) to improve non-English AVSR performance and robustness.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:-2.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">New state-of-the-art results on the LRS3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> dataset and the recently introduced MuAViC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> benchmark.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;padding-top:-2.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">The ability to use a single model for audio-only, visual-only and audio-visual speech recognition at test time using modality masking before audio-visual fusion.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2405.12983/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="438" height="407" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span><span id="S1.F1.4.2" class="ltx_text ltx_font_bold">Audio-Visual Fast Conformer architecture.</span> The model is trained end-to-end using CTC and RNN-T losses and takes both audio waveforms and lip movements as inputs.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Model Architecture</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Our model design is based on the recently proposed Fast Conformer ASR architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. The Fast Conformer brings compute-memory savings compared to Conformer by further downsampling the input audio mel-spectrogram by a factor of 2. It increases the sampling period from 10ms to 80ms using 3 depth-wise convolutional sub-sampling layers. We adapt this architecture to AVSR by processing both audio and visual inputs, adding a ResNet-based front-end network for visual pre-processing and adopting an early fusion strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. We train our models using both CTC and RNN-Transducer losses, disposing of the need to train both models separately while improving RNN-T performance. The model has 18 Conformer encoder blocks with 512 hidden dimensions and a single layer LSTM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> decoder with 640 hidden dimensions. For audio-visual models, each modality is first processed separately by 10 Conformer blocks using unimodal encoders while 8 blocks are dedicated to the audio-visual encoder. This results in a total of 119M, 130M and 197M parameters for the audio-only, visual-only and audio-visual models, respectively. The complete audio-visual model architecture is shown in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Visual Front-End</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Similar to preceding works, we process input videos using a modified ResNet-18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> where the first layer is a spatio-temporal convolutional layer with kernel size <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="5\times 7\times 7" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml"><mn id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p1.1.m1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p1.1.m1.1.1.1a" xref="S2.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S2.SS1.p1.1.m1.1.1.4" xref="S2.SS1.p1.1.m1.1.1.4.cmml">7</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"><times id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">5</cn><cn type="integer" id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3">7</cn><cn type="integer" id="S2.SS1.p1.1.m1.1.1.4.cmml" xref="S2.SS1.p1.1.m1.1.1.4">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">5\times 7\times 7</annotation></semantics></math>. The resulting feature maps are average-pooled along spatial dimensions and downsampled using a strided temporal convolution layer. The resulting signal has a 80ms sampling period.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Modality Fusion</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">We use an early fusion strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> to learn audio-visual features and reduce model complexity. The acoustic and visual features are concatenated and fed into a joint feed-forward network. We also apply a modality dropout <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> scheme during training to counter a common failure case where audio-visual models tend to ignore the visual modality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Modality dropout is performed by masking one of the two modalities 30% of the time before fusion. This requires the network to learn from both modalities while allowing unimodal inference at test time by masking one of the two modality signals.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Hybrid CTC/RNN-T loss</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.2" class="ltx_p">The network is trained end-to-end using the RNN-Transducer objective with an additional CTC loss, as follows:</p>
<table id="S4.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\displaystyle Loss=(1-\alpha)L_{RNNT}+\alpha L_{CTC}" display="inline"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mrow id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.1" xref="S2.E1.m1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.3.3" xref="S2.E1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.1a" xref="S2.E1.m1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.3.4" xref="S2.E1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.3.1b" xref="S2.E1.m1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.3.5" xref="S2.E1.m1.1.1.3.5.cmml">s</mi></mrow><mo id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml"><mn id="S2.E1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">​</mo><msub id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.3.2.cmml">L</mi><mrow id="S2.E1.m1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.3.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.3.3.1" xref="S2.E1.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.3.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.3.3.1a" xref="S2.E1.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.3.3.4" xref="S2.E1.m1.1.1.1.1.3.3.4.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.3.3.1b" xref="S2.E1.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.3.3.5" xref="S2.E1.m1.1.1.1.1.3.3.5.cmml">T</mi></mrow></msub></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.2.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.3" xref="S2.E1.m1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.3.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.3.1.cmml">​</mo><msub id="S2.E1.m1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.3.3.2.cmml">L</mi><mrow id="S2.E1.m1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.3.3.3.cmml"><mi id="S2.E1.m1.1.1.1.3.3.3.2" xref="S2.E1.m1.1.1.1.3.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.3.3.1" xref="S2.E1.m1.1.1.1.3.3.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.3.3.3.3" xref="S2.E1.m1.1.1.1.3.3.3.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.3.3.1a" xref="S2.E1.m1.1.1.1.3.3.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.3.3.3.4" xref="S2.E1.m1.1.1.1.3.3.3.4.cmml">C</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"></eq><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><times id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3.1"></times><ci id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2">𝐿</ci><ci id="S2.E1.m1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.3.3">𝑜</ci><ci id="S2.E1.m1.1.1.3.4.cmml" xref="S2.E1.m1.1.1.3.4">𝑠</ci><ci id="S2.E1.m1.1.1.3.5.cmml" xref="S2.E1.m1.1.1.3.5">𝑠</ci></apply><apply id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><plus id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.2"></plus><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S2.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.2">1</cn><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3">𝛼</ci></apply><apply id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2">𝐿</ci><apply id="S2.E1.m1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3"><times id="S2.E1.m1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.3.1"></times><ci id="S2.E1.m1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.3.2">𝑅</ci><ci id="S2.E1.m1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3.3">𝑁</ci><ci id="S2.E1.m1.1.1.1.1.3.3.4.cmml" xref="S2.E1.m1.1.1.1.1.3.3.4">𝑁</ci><ci id="S2.E1.m1.1.1.1.1.3.3.5.cmml" xref="S2.E1.m1.1.1.1.1.3.3.5">𝑇</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.3"><times id="S2.E1.m1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.3.1"></times><ci id="S2.E1.m1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.3.2">𝛼</ci><apply id="S2.E1.m1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.3.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.3.3.2">𝐿</ci><apply id="S2.E1.m1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.3.3.3"><times id="S2.E1.m1.1.1.1.3.3.3.1.cmml" xref="S2.E1.m1.1.1.1.3.3.3.1"></times><ci id="S2.E1.m1.1.1.1.3.3.3.2.cmml" xref="S2.E1.m1.1.1.1.3.3.3.2">𝐶</ci><ci id="S2.E1.m1.1.1.1.3.3.3.3.cmml" xref="S2.E1.m1.1.1.1.3.3.3.3">𝑇</ci><ci id="S2.E1.m1.1.1.1.3.3.3.4.cmml" xref="S2.E1.m1.1.1.1.3.3.3.4">𝐶</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\displaystyle Loss=(1-\alpha)L_{RNNT}+\alpha L_{CTC}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS3.p1.1" class="ltx_p">Where <math id="S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS3.p1.1.m1.1a"><mi id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">\alpha</annotation></semantics></math> is a loss scaling constant that we fix to 0.3 in every experiment. Table <a href="#S3.T5" title="Table 5 ‣ 3.5 Learning Objective ‣ 3 Experiments ‣ Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> compares the final performance of CTC, RNN-Transducer and hybrid networks on the LRS3 test set.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Datasets</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We conduct experiments on two publicly available audio-visual datasets, both extracted from TED and TEDx talks: LRS3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, which is an English only AVSR dataset, and MuAViC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, which is multilingual. LRS3 is the largest publicly available English AVSR dataset, including 438.9 hours of audio-visual speech. It is composed of a pre-training set (408 hours), a training-validation set (30 hours) and a test set (0.9 hours) for evaluation. The MuAViC dataset was recently introduced as a multilingual audio-visual corpus. The corpus includes 1200 hours of transcribed audio-visual speech from over 8k speakers in 9 languages: English (en), Arabic (ar), German (de), Greek (el), Spanish (es), French (fr), Italian (it), Portuguese (pt) and Russian (ru). Where the English subset is the addition of LRS3 pre-training and training-validation sets, which we refer to as LRS3 throughout the paper. In this work, we concentrate on Romance and Germanic language subsets for English, Spanish, French, Portuguese Italian and German. We extract additional audio-visual speech data from the large scale VoxCeleb2 (VC2) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and AVSpeech (AVS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> datasets to increase the amount of training data per language. VC2 contains approximately 2400 hours of videos extracted from YouTube with a million utterances by 6000+ celebrities, while AVSpeech has 4700 hours from 150k speakers. Both datasets include a wide variety of people, languages, and face poses.
We detect language ids and generate transcriptions for each audio segment using Whisper Large <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, a 1.55B parameters multilingual model trained on 680k hours of speech data. For English segments, we use a 1.1B parameter Fast Conformer XXL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> model pre-trained on LibriLight and fine-tuned on 24.5k hours of English speech. Table <a href="#S3.T1" title="Table 1 ‣ 3.1 Datasets ‣ 3 Experiments ‣ Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the total amount of training hours per dataset and language.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.4.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>Number of audio-visual speech hours.</figcaption>
<table id="S3.T1.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T1.5.1" class="ltx_tr">
<td id="S3.T1.5.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T1.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Dataset</span></td>
<td id="S3.T1.5.1.2" class="ltx_td ltx_align_center ltx_border_t" colspan="7"><span id="S3.T1.5.1.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Number of training hours per language</span></td>
</tr>
<tr id="S3.T1.5.2" class="ltx_tr">
<td id="S3.T1.5.2.1" class="ltx_td ltx_align_center"><span id="S3.T1.5.2.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">en</span></td>
<td id="S3.T1.5.2.2" class="ltx_td ltx_align_center"><span id="S3.T1.5.2.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">es</span></td>
<td id="S3.T1.5.2.3" class="ltx_td ltx_align_center"><span id="S3.T1.5.2.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">fr</span></td>
<td id="S3.T1.5.2.4" class="ltx_td ltx_align_center"><span id="S3.T1.5.2.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">pt</span></td>
<td id="S3.T1.5.2.5" class="ltx_td ltx_align_center"><span id="S3.T1.5.2.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">it</span></td>
<td id="S3.T1.5.2.6" class="ltx_td ltx_align_center"><span id="S3.T1.5.2.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">de</span></td>
<td id="S3.T1.5.2.7" class="ltx_td ltx_align_center"><span id="S3.T1.5.2.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">all</span></td>
</tr>
<tr id="S3.T1.5.3" class="ltx_tr">
<td id="S3.T1.5.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S3.T1.5.3.1.1" class="ltx_text" style="font-size:70%;">LRS3 / MuAViC</span></td>
<td id="S3.T1.5.3.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.5.3.2.1" class="ltx_text" style="font-size:70%;">435</span></td>
<td id="S3.T1.5.3.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.5.3.3.1" class="ltx_text" style="font-size:70%;">176</span></td>
<td id="S3.T1.5.3.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.5.3.4.1" class="ltx_text" style="font-size:70%;">173</span></td>
<td id="S3.T1.5.3.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.5.3.5.1" class="ltx_text" style="font-size:70%;">152</span></td>
<td id="S3.T1.5.3.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.5.3.6.1" class="ltx_text" style="font-size:70%;">99</span></td>
<td id="S3.T1.5.3.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.5.3.7.1" class="ltx_text" style="font-size:70%;">10</span></td>
<td id="S3.T1.5.3.8" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.5.3.8.1" class="ltx_text" style="font-size:70%;">1046</span></td>
</tr>
<tr id="S3.T1.5.4" class="ltx_tr">
<td id="S3.T1.5.4.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T1.5.4.1.1" class="ltx_text" style="font-size:70%;">VoxCeleb2 (generated)</span></td>
<td id="S3.T1.5.4.2" class="ltx_td ltx_align_center"><span id="S3.T1.5.4.2.1" class="ltx_text" style="font-size:70%;">1252</span></td>
<td id="S3.T1.5.4.3" class="ltx_td ltx_align_center"><span id="S3.T1.5.4.3.1" class="ltx_text" style="font-size:70%;">37</span></td>
<td id="S3.T1.5.4.4" class="ltx_td ltx_align_center"><span id="S3.T1.5.4.4.1" class="ltx_text" style="font-size:70%;">109</span></td>
<td id="S3.T1.5.4.5" class="ltx_td ltx_align_center"><span id="S3.T1.5.4.5.1" class="ltx_text" style="font-size:70%;">8</span></td>
<td id="S3.T1.5.4.6" class="ltx_td ltx_align_center"><span id="S3.T1.5.4.6.1" class="ltx_text" style="font-size:70%;">36</span></td>
<td id="S3.T1.5.4.7" class="ltx_td ltx_align_center"><span id="S3.T1.5.4.7.1" class="ltx_text" style="font-size:70%;">153</span></td>
<td id="S3.T1.5.4.8" class="ltx_td ltx_align_center"><span id="S3.T1.5.4.8.1" class="ltx_text" style="font-size:70%;">1595</span></td>
</tr>
<tr id="S3.T1.5.5" class="ltx_tr">
<td id="S3.T1.5.5.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T1.5.5.1.1" class="ltx_text" style="font-size:70%;">AVSpeech (generated)</span></td>
<td id="S3.T1.5.5.2" class="ltx_td ltx_align_center"><span id="S3.T1.5.5.2.1" class="ltx_text" style="font-size:70%;">1429</span></td>
<td id="S3.T1.5.5.3" class="ltx_td ltx_align_center"><span id="S3.T1.5.5.3.1" class="ltx_text" style="font-size:70%;">257</span></td>
<td id="S3.T1.5.5.4" class="ltx_td ltx_align_center"><span id="S3.T1.5.5.4.1" class="ltx_text" style="font-size:70%;">115</span></td>
<td id="S3.T1.5.5.5" class="ltx_td ltx_align_center"><span id="S3.T1.5.5.5.1" class="ltx_text" style="font-size:70%;">312</span></td>
<td id="S3.T1.5.5.6" class="ltx_td ltx_align_center"><span id="S3.T1.5.5.6.1" class="ltx_text" style="font-size:70%;">66</span></td>
<td id="S3.T1.5.5.7" class="ltx_td ltx_align_center"><span id="S3.T1.5.5.7.1" class="ltx_text" style="font-size:70%;">136</span></td>
<td id="S3.T1.5.5.8" class="ltx_td ltx_align_center"><span id="S3.T1.5.5.8.1" class="ltx_text" style="font-size:70%;">2316</span></td>
</tr>
<tr id="S3.T1.5.6" class="ltx_tr">
<td id="S3.T1.5.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.5.6.1.1" class="ltx_text" style="font-size:70%;">Total generated</span></td>
<td id="S3.T1.5.6.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.5.6.2.1" class="ltx_text" style="font-size:70%;">2681</span></td>
<td id="S3.T1.5.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.5.6.3.1" class="ltx_text" style="font-size:70%;">294</span></td>
<td id="S3.T1.5.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.5.6.4.1" class="ltx_text" style="font-size:70%;">224</span></td>
<td id="S3.T1.5.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.5.6.5.1" class="ltx_text" style="font-size:70%;">319</span></td>
<td id="S3.T1.5.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.5.6.6.1" class="ltx_text" style="font-size:70%;">102</span></td>
<td id="S3.T1.5.6.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.5.6.7.1" class="ltx_text" style="font-size:70%;">289</span></td>
<td id="S3.T1.5.6.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.5.6.8.1" class="ltx_text" style="font-size:70%;">3910</span></td>
</tr>
<tr id="S3.T1.5.7" class="ltx_tr">
<td id="S3.T1.5.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span id="S3.T1.5.7.1.1" class="ltx_text" style="font-size:70%;">Total</span></td>
<td id="S3.T1.5.7.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T1.5.7.2.1" class="ltx_text" style="font-size:70%;">3116</span></td>
<td id="S3.T1.5.7.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T1.5.7.3.1" class="ltx_text" style="font-size:70%;">470</span></td>
<td id="S3.T1.5.7.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T1.5.7.4.1" class="ltx_text" style="font-size:70%;">398</span></td>
<td id="S3.T1.5.7.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T1.5.7.5.1" class="ltx_text" style="font-size:70%;">472</span></td>
<td id="S3.T1.5.7.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T1.5.7.6.1" class="ltx_text" style="font-size:70%;">201</span></td>
<td id="S3.T1.5.7.7" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T1.5.7.7.1" class="ltx_text" style="font-size:70%;">299</span></td>
<td id="S3.T1.5.7.8" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T1.5.7.8.1" class="ltx_text" style="font-size:70%;">4957</span></td>
</tr>
</table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Implementation details</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">For visual pre-processing, we follow previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> to prepare all the datasets. The RetinaFace <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> face detector is used to detect speaker faces. We then remove differences related to rotation and scale by cropping speaker lip regions using bounding boxes of <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="96\times 96" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">96</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">96</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><times id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">96</cn><cn type="integer" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">96\times 96</annotation></semantics></math> pixels to facilitate recognition. We localize 68 face landmarks using a Face Alignment Network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> to align the speaker face and crop lip regions. The cropped images are then converted to grayscale.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.3" class="ltx_p">For data augmentation, we apply Spec-Augment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> to audio mel-spectrograms with mask size parameter <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="F=27" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">F</mi><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">27</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><eq id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></eq><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">27</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">F=27</annotation></semantics></math> and ten time masks with adaptive size <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="pS=0.05" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mrow id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mrow id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2.2" xref="S3.SS2.p2.2.m2.1.1.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.2.m2.1.1.2.1" xref="S3.SS2.p2.2.m2.1.1.2.1.cmml">​</mo><mi id="S3.SS2.p2.2.m2.1.1.2.3" xref="S3.SS2.p2.2.m2.1.1.2.3.cmml">S</mi></mrow><mo id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><eq id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1"></eq><apply id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2"><times id="S3.SS2.p2.2.m2.1.1.2.1.cmml" xref="S3.SS2.p2.2.m2.1.1.2.1"></times><ci id="S3.SS2.p2.2.m2.1.1.2.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2.2">𝑝</ci><ci id="S3.SS2.p2.2.m2.1.1.2.3.cmml" xref="S3.SS2.p2.2.m2.1.1.2.3">𝑆</ci></apply><cn type="float" id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">pS=0.05</annotation></semantics></math>. We also add babble noise from the NoiseX corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> during training, as done in previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. On the visual side, we apply random cropping with crop size <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="88\times 88" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mn id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">88</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.3.m3.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">88</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><times id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1"></times><cn type="integer" id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">88</cn><cn type="integer" id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">88</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">88\times 88</annotation></semantics></math>, horizontal flipping and time masking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. We apply center crop at test time.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.2" class="ltx_p">We first train audio-visual, audio-only and visual-only models on the LRS3 dataset augmented with Voxceleb2 and AVSpeech English transcriptions. Ma <span id="S3.SS2.p3.2.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> pre-train the visual-only models on the LRW dataset using a word classification task to facilitate early convergence and improve final performance. However, since we do not have access to this dataset, we first train the audio-visual model and use the ResNet-18 weights as initialization for the visual-only model. We also add intermediate CTC losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> every 3 Conformer blocks to the visual-only model encoder to speed up convergence. Training is done using the AdamW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> optimizer with <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\beta_{1}=0.9" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><msub id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2.2" xref="S3.SS2.p3.1.m1.1.1.2.2.cmml">β</mi><mn id="S3.SS2.p3.1.m1.1.1.2.3" xref="S3.SS2.p3.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><eq id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></eq><apply id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.2.1.cmml" xref="S3.SS2.p3.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2.2">𝛽</ci><cn type="integer" id="S3.SS2.p3.1.m1.1.1.2.3.cmml" xref="S3.SS2.p3.1.m1.1.1.2.3">1</cn></apply><cn type="float" id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\beta_{1}=0.9</annotation></semantics></math>, <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\beta_{2}=0.98" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mrow id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><msub id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2.2" xref="S3.SS2.p3.2.m2.1.1.2.2.cmml">β</mi><mn id="S3.SS2.p3.2.m2.1.1.2.3" xref="S3.SS2.p3.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S3.SS2.p3.2.m2.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">0.98</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><eq id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1"></eq><apply id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2.2">𝛽</ci><cn type="integer" id="S3.SS2.p3.2.m2.1.1.2.3.cmml" xref="S3.SS2.p3.2.m2.1.1.2.3">2</cn></apply><cn type="float" id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">0.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\beta_{2}=0.98</annotation></semantics></math> and a 1e-3 weight decay. The models are trained for 100k gradient steps with a global batch size of 2048 samples. The learning rate is ramped up linearly to 0.001 during the first 5k steps, held constant until 15k steps and decayed following an inverse square root schedule. An Exponential Moving Average (EMA) model with 0.9999 momentum is updated along training for evaluation.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">For MuAViC, we train monolingual and multilingual models with encoder weights initialized from English pre-trained networks. We use a SentencePiece <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> byte-pair-encoding tokenizer with 256 tokens per language. Multilingual tokenization is done using an aggregated tokenizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, where each language is given a range of tokens and the corresponding range is used during decoding. Multilingual models are trained for 100k steps while monolingual models are trained until convergence, for no more than 1000 epochs.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Results on LRS3</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Table <a href="#S3.T2" title="Table 2 ‣ 3.3 Results on LRS3 ‣ 3 Experiments ‣ Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> compares the Word Error Rates (WER) of our English models with recently published methods on the LRS3 test set. Our audio-only and audio-visual models achieve new state-of-the-art results with WER of 0.7% and 0.8%, respectively. Our lip reading network competes with self-supervised approaches with 25.5% WER. However, it still lags behind Auto-AVSR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> whose visual-only model has 250.4M parameters, trains on additional LRS2 human-labeled transcriptions and uses an external language model during decoding.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.27.1.1" class="ltx_text ltx_font_bold">Table 2</span>: </span>Comparison of WER (%) on the LRS3 test set with recently published methods for Audio-Visual (AV), Audio-Only (A) and Visual-Only (V) speech recognition models. <sup id="S3.T2.28.2" class="ltx_sup"><span id="S3.T2.28.2.1" class="ltx_text ltx_font_italic">∗</span></sup> Shows number of encoder params instead of total params. <sup id="S3.T2.29.3" class="ltx_sup"><span id="S3.T2.29.3.1" class="ltx_text ltx_font_italic">‡</span></sup> Use of additional audio, audio-text and text data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</figcaption>
<table id="S3.T2.16" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.16.13" class="ltx_tr">
<td id="S3.T2.16.13.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;" rowspan="2"><span id="S3.T2.16.13.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Method</span></td>
<td id="S3.T2.16.13.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;" rowspan="2"><span id="S3.T2.16.13.2.1" class="ltx_text" style="font-size:70%;">
<span id="S3.T2.16.13.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.16.13.2.1.1.1" class="ltx_tr">
<span id="S3.T2.16.13.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.13.2.1.1.1.1.1" class="ltx_text ltx_font_bold">AV model</span></span></span>
<span id="S3.T2.16.13.2.1.1.2" class="ltx_tr">
<span id="S3.T2.16.13.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.13.2.1.1.2.1.1" class="ltx_text ltx_font_bold">Params</span></span></span>
</span></span></td>
<td id="S3.T2.16.13.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;" rowspan="2"><span id="S3.T2.16.13.3.1" class="ltx_text" style="font-size:70%;">
<span id="S3.T2.16.13.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.16.13.3.1.1.1" class="ltx_tr">
<span id="S3.T2.16.13.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.13.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Training</span></span></span>
<span id="S3.T2.16.13.3.1.1.2" class="ltx_tr">
<span id="S3.T2.16.13.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.13.3.1.1.2.1.1" class="ltx_text ltx_font_bold">Datasets</span></span></span>
</span></span></td>
<td id="S3.T2.16.13.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;" rowspan="2"><span id="S3.T2.16.13.4.1" class="ltx_text" style="font-size:70%;">
<span id="S3.T2.16.13.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.16.13.4.1.1.1" class="ltx_tr">
<span id="S3.T2.16.13.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.13.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Total</span></span></span>
<span id="S3.T2.16.13.4.1.1.2" class="ltx_tr">
<span id="S3.T2.16.13.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.13.4.1.1.2.1.1" class="ltx_text ltx_font_bold">Hours</span></span></span>
</span></span></td>
<td id="S3.T2.16.13.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;" colspan="3"><span id="S3.T2.16.13.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">LRS3 test WER</span></td>
</tr>
<tr id="S3.T2.16.14" class="ltx_tr">
<td id="S3.T2.16.14.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.14.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">AV</span></td>
<td id="S3.T2.16.14.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.14.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">A</span></td>
<td id="S3.T2.16.14.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.14.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">V</span></td>
</tr>
<tr id="S3.T2.16.15" class="ltx_tr">
<td id="S3.T2.16.15.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.16.15.1.1" class="ltx_text" style="font-size:70%;">CM-seq2seq </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.16.15.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S3.T2.16.15.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.16.15.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.15.2.1" class="ltx_text" style="font-size:70%;">92M</span></td>
<td id="S3.T2.16.15.3" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.15.3.1" class="ltx_text" style="font-size:70%;">LRW,LRS3</span></td>
<td id="S3.T2.16.15.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.15.4.1" class="ltx_text" style="font-size:70%;">595</span></td>
<td id="S3.T2.16.15.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.15.5.1" class="ltx_text" style="font-size:70%;">2.3</span></td>
<td id="S3.T2.16.15.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.15.6.1" class="ltx_text" style="font-size:70%;">2.3</span></td>
<td id="S3.T2.16.15.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.15.7.1" class="ltx_text" style="font-size:70%;">43.3</span></td>
</tr>
<tr id="S3.T2.16.16" class="ltx_tr">
<td id="S3.T2.16.16.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.16.16.1.1" class="ltx_text" style="font-size:70%;">AVEC </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.16.16.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S3.T2.16.16.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.16.16.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.16.2.1" class="ltx_text" style="font-size:70%;">61M</span></td>
<td id="S3.T2.16.16.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.16.3.1" class="ltx_text" style="font-size:70%;">LRW,LRS2&amp;3</span></td>
<td id="S3.T2.16.16.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.16.4.1" class="ltx_text" style="font-size:70%;">818</span></td>
<td id="S3.T2.16.16.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.16.5.1" class="ltx_text" style="font-size:70%;">1.8</span></td>
<td id="S3.T2.16.16.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.16.6.1" class="ltx_text" style="font-size:70%;">2.0</span></td>
<td id="S3.T2.16.16.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.16.7.1" class="ltx_text" style="font-size:70%;">37.5</span></td>
</tr>
<tr id="S3.T2.5.1" class="ltx_tr">
<td id="S3.T2.5.1.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.5.1.2.1" class="ltx_text" style="font-size:70%;">AV-HuBERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.5.1.2.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S3.T2.5.1.2.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.5.1.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.5.1.1.1" class="ltx_text" style="font-size:70%;">103M</span><sup id="S3.T2.5.1.1.2" class="ltx_sup"><span id="S3.T2.5.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.5.1.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.5.1.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.5.1.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.5.1.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.5.1.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.5.1.5.1" class="ltx_text" style="font-size:70%;">1.8</span></td>
<td id="S3.T2.5.1.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.5.1.6.1" class="ltx_text" style="font-size:70%;">2.0</span></td>
<td id="S3.T2.5.1.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.5.1.7.1" class="ltx_text" style="font-size:70%;">34.8</span></td>
</tr>
<tr id="S3.T2.6.2" class="ltx_tr">
<td id="S3.T2.6.2.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.6.2.2.1" class="ltx_text" style="font-size:70%;">RAVen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.6.2.2.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S3.T2.6.2.2.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.6.2.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.6.2.1.1" class="ltx_text" style="font-size:70%;">41M</span><sup id="S3.T2.6.2.1.2" class="ltx_sup"><span id="S3.T2.6.2.1.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.6.2.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.6.2.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.6.2.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.6.2.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.6.2.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.6.2.5.1" class="ltx_text" style="font-size:70%;">-</span></td>
<td id="S3.T2.6.2.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.6.2.6.1" class="ltx_text" style="font-size:70%;">1.9</span></td>
<td id="S3.T2.6.2.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.6.2.7.1" class="ltx_text" style="font-size:70%;">33.1</span></td>
</tr>
<tr id="S3.T2.8.4" class="ltx_tr">
<td id="S3.T2.7.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.7.3.1.1" class="ltx_text" style="font-size:70%;">VATLM </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.7.3.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S3.T2.7.3.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite><sup id="S3.T2.7.3.1.4" class="ltx_sup"><span id="S3.T2.7.3.1.4.1" class="ltx_text ltx_font_italic" style="font-size:70%;">‡</span></sup>
</td>
<td id="S3.T2.8.4.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.8.4.2.1" class="ltx_text" style="font-size:70%;">103M</span><sup id="S3.T2.8.4.2.2" class="ltx_sup"><span id="S3.T2.8.4.2.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.8.4.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.8.4.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.8.4.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.8.4.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.8.4.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.8.4.5.1" class="ltx_text" style="font-size:70%;">1.7</span></td>
<td id="S3.T2.8.4.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.8.4.6.1" class="ltx_text" style="font-size:70%;">-</span></td>
<td id="S3.T2.8.4.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.8.4.7.1" class="ltx_text" style="font-size:70%;">34.2</span></td>
</tr>
<tr id="S3.T2.9.5" class="ltx_tr">
<td id="S3.T2.9.5.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.9.5.2.1" class="ltx_text" style="font-size:70%;">AV-data2vec </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.9.5.2.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S3.T2.9.5.2.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.9.5.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.9.5.1.1" class="ltx_text" style="font-size:70%;">103M</span><sup id="S3.T2.9.5.1.2" class="ltx_sup"><span id="S3.T2.9.5.1.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.9.5.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.9.5.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.9.5.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.9.5.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.9.5.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.9.5.5.1" class="ltx_text" style="font-size:70%;">1.4</span></td>
<td id="S3.T2.9.5.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.9.5.6.1" class="ltx_text" style="font-size:70%;">1.7</span></td>
<td id="S3.T2.9.5.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.9.5.7.1" class="ltx_text" style="font-size:70%;">32.9</span></td>
</tr>
<tr id="S3.T2.10.6" class="ltx_tr">
<td id="S3.T2.10.6.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.10.6.2.1" class="ltx_text" style="font-size:70%;">AV-HuBERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.10.6.2.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a><span id="S3.T2.10.6.2.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.10.6.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.10.6.1.1" class="ltx_text" style="font-size:70%;">325M</span><sup id="S3.T2.10.6.1.2" class="ltx_sup"><span id="S3.T2.10.6.1.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.10.6.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.10.6.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.10.6.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.10.6.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.10.6.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.10.6.5.1" class="ltx_text" style="font-size:70%;">1.4</span></td>
<td id="S3.T2.10.6.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.10.6.6.1" class="ltx_text" style="font-size:70%;">1.3</span></td>
<td id="S3.T2.10.6.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.10.6.7.1" class="ltx_text" style="font-size:70%;">28.6</span></td>
</tr>
<tr id="S3.T2.11.7" class="ltx_tr">
<td id="S3.T2.11.7.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.11.7.2.1" class="ltx_text" style="font-size:70%;">RAVen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.11.7.2.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S3.T2.11.7.2.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.11.7.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.11.7.1.1" class="ltx_text" style="font-size:70%;">328M</span><sup id="S3.T2.11.7.1.2" class="ltx_sup"><span id="S3.T2.11.7.1.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.11.7.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.11.7.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.11.7.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.11.7.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.11.7.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.11.7.5.1" class="ltx_text" style="font-size:70%;">-</span></td>
<td id="S3.T2.11.7.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.11.7.6.1" class="ltx_text" style="font-size:70%;">1.4</span></td>
<td id="S3.T2.11.7.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.11.7.7.1" class="ltx_text" style="font-size:70%;">28.2</span></td>
</tr>
<tr id="S3.T2.13.9" class="ltx_tr">
<td id="S3.T2.12.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.12.8.1.1" class="ltx_text" style="font-size:70%;">VATLM </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.12.8.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S3.T2.12.8.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite><sup id="S3.T2.12.8.1.4" class="ltx_sup"><span id="S3.T2.12.8.1.4.1" class="ltx_text ltx_font_italic" style="font-size:70%;">‡</span></sup>
</td>
<td id="S3.T2.13.9.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.13.9.2.1" class="ltx_text" style="font-size:70%;">325M</span><sup id="S3.T2.13.9.2.2" class="ltx_sup"><span id="S3.T2.13.9.2.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.13.9.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.9.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.13.9.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.9.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.13.9.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.9.5.1" class="ltx_text" style="font-size:70%;">1.2</span></td>
<td id="S3.T2.13.9.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.9.6.1" class="ltx_text" style="font-size:70%;">-</span></td>
<td id="S3.T2.13.9.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.13.9.7.1" class="ltx_text" style="font-size:70%;">28.4</span></td>
</tr>
<tr id="S3.T2.15.11" class="ltx_tr">
<td id="S3.T2.14.10.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.14.10.1.1" class="ltx_text" style="font-size:70%;">u-HuBERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.14.10.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib17" title="" class="ltx_ref">17</a><span id="S3.T2.14.10.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite><sup id="S3.T2.14.10.1.4" class="ltx_sup"><span id="S3.T2.14.10.1.4.1" class="ltx_text ltx_font_italic" style="font-size:70%;">‡</span></sup>
</td>
<td id="S3.T2.15.11.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.15.11.2.1" class="ltx_text" style="font-size:70%;">325M</span><sup id="S3.T2.15.11.2.2" class="ltx_sup"><span id="S3.T2.15.11.2.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.15.11.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.15.11.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.15.11.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.15.11.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.15.11.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.15.11.5.1" class="ltx_text" style="font-size:70%;">1.2</span></td>
<td id="S3.T2.15.11.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.15.11.6.1" class="ltx_text" style="font-size:70%;">1.4</span></td>
<td id="S3.T2.15.11.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.15.11.7.1" class="ltx_text" style="font-size:70%;">27.2</span></td>
</tr>
<tr id="S3.T2.16.12" class="ltx_tr">
<td id="S3.T2.16.12.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.16.12.2.1" class="ltx_text" style="font-size:70%;">AV-data2vec </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.16.12.2.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib18" title="" class="ltx_ref">18</a><span id="S3.T2.16.12.2.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.16.12.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.16.12.1.1" class="ltx_text" style="font-size:70%;">325M</span><sup id="S3.T2.16.12.1.2" class="ltx_sup"><span id="S3.T2.16.12.1.2.1" class="ltx_text ltx_font_italic" style="font-size:70%;">∗</span></sup>
</td>
<td id="S3.T2.16.12.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.12.3.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.16.12.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.12.4.1" class="ltx_text" style="font-size:70%;">1759</span></td>
<td id="S3.T2.16.12.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.12.5.1" class="ltx_text" style="font-size:70%;">1.3</span></td>
<td id="S3.T2.16.12.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.12.6.1" class="ltx_text" style="font-size:70%;">1.4</span></td>
<td id="S3.T2.16.12.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.12.7.1" class="ltx_text" style="font-size:70%;">28.5</span></td>
</tr>
<tr id="S3.T2.16.17" class="ltx_tr">
<td id="S3.T2.16.17.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.16.17.1.1" class="ltx_text" style="font-size:70%;">Auto-AVSR </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.16.17.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S3.T2.16.17.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.16.17.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.17.2.1" class="ltx_text" style="font-size:70%;">425M</span></td>
<td id="S3.T2.16.17.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.17.3.1" class="ltx_text" style="font-size:70%;">+LRW,LRS2,AVS</span></td>
<td id="S3.T2.16.17.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.17.4.1" class="ltx_text" style="font-size:70%;">3448</span></td>
<td id="S3.T2.16.17.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.17.5.1" class="ltx_text" style="font-size:70%;">0.9</span></td>
<td id="S3.T2.16.17.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.17.6.1" class="ltx_text" style="font-size:70%;">1.0</span></td>
<td id="S3.T2.16.17.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.17.7.1" class="ltx_text" style="font-size:70%;">19.1</span></td>
</tr>
<tr id="S3.T2.16.18" class="ltx_tr">
<td id="S3.T2.16.18.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.16.18.1.1" class="ltx_text" style="font-size:70%;">VIT 3D </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.16.18.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S3.T2.16.18.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.16.18.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.18.2.1" class="ltx_text" style="font-size:70%;">310M</span></td>
<td id="S3.T2.16.18.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.18.3.1" class="ltx_text" style="font-size:70%;">YouTube-90k</span></td>
<td id="S3.T2.16.18.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.18.4.1" class="ltx_text" style="font-size:70%;">90k</span></td>
<td id="S3.T2.16.18.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.18.5.1" class="ltx_text" style="font-size:70%;">1.6</span></td>
<td id="S3.T2.16.18.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.18.6.1" class="ltx_text" style="font-size:70%;">-</span></td>
<td id="S3.T2.16.18.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.18.7.1" class="ltx_text" style="font-size:70%;">17.0</span></td>
</tr>
<tr id="S3.T2.16.19" class="ltx_tr">
<td id="S3.T2.16.19.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.16.19.1.1" class="ltx_text" style="font-size:70%;">VGG Conformer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.16.19.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib39" title="" class="ltx_ref">39</a><span id="S3.T2.16.19.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.16.19.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.19.2.1" class="ltx_text" style="font-size:70%;">180M</span></td>
<td id="S3.T2.16.19.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.19.3.1" class="ltx_text" style="font-size:70%;">YouTube-100k</span></td>
<td id="S3.T2.16.19.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.19.4.1" class="ltx_text" style="font-size:70%;">100k</span></td>
<td id="S3.T2.16.19.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.19.5.1" class="ltx_text" style="font-size:70%;">0.9</span></td>
<td id="S3.T2.16.19.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.19.6.1" class="ltx_text" style="font-size:70%;">1.0</span></td>
<td id="S3.T2.16.19.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.19.7.1" class="ltx_text" style="font-size:70%;">-</span></td>
</tr>
<tr id="S3.T2.16.20" class="ltx_tr">
<td id="S3.T2.16.20.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.5pt;padding-right:3.5pt;">
<span id="S3.T2.16.20.1.1" class="ltx_text" style="font-size:70%;">LP Conformer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T2.16.20.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S3.T2.16.20.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T2.16.20.2" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.20.2.1" class="ltx_text" style="font-size:70%;">570M</span></td>
<td id="S3.T2.16.20.3" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.20.3.1" class="ltx_text" style="font-size:70%;">YouTube-100k</span></td>
<td id="S3.T2.16.20.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.20.4.1" class="ltx_text" style="font-size:70%;">100k</span></td>
<td id="S3.T2.16.20.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.20.5.1" class="ltx_text" style="font-size:70%;">0.9</span></td>
<td id="S3.T2.16.20.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.20.6.1" class="ltx_text" style="font-size:70%;">-</span></td>
<td id="S3.T2.16.20.7" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.20.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">12.8</span></td>
</tr>
<tr id="S3.T2.16.21" class="ltx_tr">
<td id="S3.T2.16.21.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;" rowspan="3"><span id="S3.T2.16.21.1.1" class="ltx_text" style="font-size:70%;">Fast Conformer</span></td>
<td id="S3.T2.16.21.2" class="ltx_td ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="S3.T2.16.21.3" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.21.3.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T2.16.21.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.21.4.1" class="ltx_text" style="font-size:70%;">435</span></td>
<td id="S3.T2.16.21.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.21.5.1" class="ltx_text" style="font-size:70%;">1.7</span></td>
<td id="S3.T2.16.21.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.21.6.1" class="ltx_text" style="font-size:70%;">1.6</span></td>
<td id="S3.T2.16.21.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.21.7.1" class="ltx_text" style="font-size:70%;">43.8</span></td>
</tr>
<tr id="S3.T2.16.22" class="ltx_tr">
<td id="S3.T2.16.22.1" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.22.1.1" class="ltx_text" style="font-size:70%;">197M</span></td>
<td id="S3.T2.16.22.2" class="ltx_td ltx_align_left" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.22.2.1" class="ltx_text" style="font-size:70%;">LRS3,VC2</span></td>
<td id="S3.T2.16.22.3" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.22.3.1" class="ltx_text" style="font-size:70%;">1687</span></td>
<td id="S3.T2.16.22.4" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.22.4.1" class="ltx_text" style="font-size:70%;">0.9</span></td>
<td id="S3.T2.16.22.5" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.22.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">0.7</span></td>
<td id="S3.T2.16.22.6" class="ltx_td ltx_align_center" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.22.6.1" class="ltx_text" style="font-size:70%;">31.0</span></td>
</tr>
<tr id="S3.T2.16.23" class="ltx_tr">
<td id="S3.T2.16.23.1" class="ltx_td ltx_border_b" style="padding-left:3.5pt;padding-right:3.5pt;"></td>
<td id="S3.T2.16.23.2" class="ltx_td ltx_align_left ltx_border_b" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.23.2.1" class="ltx_text" style="font-size:70%;">LRS3,VC2,AVS</span></td>
<td id="S3.T2.16.23.3" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.23.3.1" class="ltx_text" style="font-size:70%;">3116</span></td>
<td id="S3.T2.16.23.4" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.23.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">0.8</span></td>
<td id="S3.T2.16.23.5" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.23.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">0.7</span></td>
<td id="S3.T2.16.23.6" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:3.5pt;padding-right:3.5pt;"><span id="S3.T2.16.23.6.1" class="ltx_text" style="font-size:70%;">25.5</span></td>
</tr>
</table>
</figure>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">We evaluate our English models robustness, adding babble noise and white noise with multiple Signal to Noise Ratio (SNR) during test time. Table <a href="#S3.T3" title="Table 3 ‣ 3.3 Results on LRS3 ‣ 3 Experiments ‣ Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> compares the robustness of our model with Auto-AVSR on the LRS3 test set. We observe that our models can recover similar audio robustness by training on generated transcriptions while using half the number of training parameters. It also shows that audio-only models can easily overfit to babble noise, demonstrating the importance of evaluating on noises not encountered during training.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.10.1.1" class="ltx_text ltx_font_bold">Table 3</span>: </span>LRS3 test set WER (%) under noisy conditions. 
<br class="ltx_break"><sup id="S3.T3.11.2" class="ltx_sup"><span id="S3.T3.11.2.1" class="ltx_text ltx_font_italic">†</span></sup> Noise type used during both training and test time.</figcaption>
<table id="S3.T3.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.4.3" class="ltx_tr">
<td id="S3.T3.4.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.3.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Method</span></td>
<td id="S3.T3.4.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.3.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Mode</span></td>
<td id="S3.T3.4.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.3.3.1" class="ltx_text" style="font-size:70%;">
<span id="S3.T3.4.3.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.4.3.3.1.1.1" class="ltx_tr">
<span id="S3.T3.4.3.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.3.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Num</span></span></span>
<span id="S3.T3.4.3.3.1.1.2" class="ltx_tr">
<span id="S3.T3.4.3.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.3.3.1.1.2.1.1" class="ltx_text ltx_font_bold">Params</span></span></span>
</span></span></td>
<td id="S3.T3.4.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.3.4.1" class="ltx_text" style="font-size:70%;">
<span id="S3.T3.4.3.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.4.3.4.1.1.1" class="ltx_tr">
<span id="S3.T3.4.3.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.3.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Audio</span></span></span>
<span id="S3.T3.4.3.4.1.1.2" class="ltx_tr">
<span id="S3.T3.4.3.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.3.4.1.1.2.1.1" class="ltx_text ltx_font_bold">Noise</span></span></span>
</span></span></td>
<td id="S3.T3.4.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" colspan="5"><span id="S3.T3.4.3.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">test time SNR level (dB)</span></td>
</tr>
<tr id="S3.T3.4.4" class="ltx_tr">
<td id="S3.T3.4.4.1" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.4.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">12.5</span></td>
<td id="S3.T3.4.4.2" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.4.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">7.5</span></td>
<td id="S3.T3.4.4.3" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.4.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">2.5</span></td>
<td id="S3.T3.4.4.4" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.4.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">-2.5</span></td>
<td id="S3.T3.4.4.5" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.4.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">-7.5</span></td>
</tr>
<tr id="S3.T3.3.1" class="ltx_tr">
<td id="S3.T3.3.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.3.1.2.1" class="ltx_text" style="font-size:70%;">Auto-AVSR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite></span></td>
<td id="S3.T3.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.3.1.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T3.3.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.3.1.4.1" class="ltx_text" style="font-size:70%;">243M</span></td>
<td id="S3.T3.3.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.3.1.1.1" class="ltx_text" style="font-size:70%;">babble<sup id="S3.T3.3.1.1.1.1" class="ltx_sup"><span id="S3.T3.3.1.1.1.1.1" class="ltx_text ltx_font_italic">†</span></sup></span></td>
<td id="S3.T3.3.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.3.1.5.1" class="ltx_text" style="font-size:70%;">1.1</span></td>
<td id="S3.T3.3.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.3.1.6.1" class="ltx_text" style="font-size:70%;">1.2</span></td>
<td id="S3.T3.3.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.3.1.7.1" class="ltx_text" style="font-size:70%;">1.6</span></td>
<td id="S3.T3.3.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.3.1.8.1" class="ltx_text" style="font-size:70%;">2.7</span></td>
<td id="S3.T3.3.1.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.3.1.9.1" class="ltx_text" style="font-size:70%;">8.3</span></td>
</tr>
<tr id="S3.T3.4.5" class="ltx_tr">
<td id="S3.T3.4.5.1" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.5.1.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T3.4.5.2" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.5.2.1" class="ltx_text" style="font-size:70%;">425M</span></td>
<td id="S3.T3.4.5.3" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.5.3.1" class="ltx_text" style="font-size:70%;">1.0</span></td>
<td id="S3.T3.4.5.4" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.5.4.1" class="ltx_text" style="font-size:70%;">1.0</span></td>
<td id="S3.T3.4.5.5" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.5.5.1" class="ltx_text" style="font-size:70%;">1.5</span></td>
<td id="S3.T3.4.5.6" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.5.6.1" class="ltx_text" style="font-size:70%;">2.2</span></td>
<td id="S3.T3.4.5.7" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.5.7.1" class="ltx_text" style="font-size:70%;">5.6</span></td>
</tr>
<tr id="S3.T3.4.2" class="ltx_tr">
<td id="S3.T3.4.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.2.2.1" class="ltx_text" style="font-size:70%;">Fast Conformer</span></td>
<td id="S3.T3.4.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.2.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T3.4.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.2.4.1" class="ltx_text" style="font-size:70%;">119M</span></td>
<td id="S3.T3.4.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.2.1.1" class="ltx_text" style="font-size:70%;">babble<sup id="S3.T3.4.2.1.1.1" class="ltx_sup"><span id="S3.T3.4.2.1.1.1.1" class="ltx_text ltx_font_italic">†</span></sup></span></td>
<td id="S3.T3.4.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.2.5.1" class="ltx_text" style="font-size:70%;">0.9</span></td>
<td id="S3.T3.4.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.2.6.1" class="ltx_text" style="font-size:70%;">1.2</span></td>
<td id="S3.T3.4.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.2.7.1" class="ltx_text" style="font-size:70%;">1.8</span></td>
<td id="S3.T3.4.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.2.8.1" class="ltx_text" style="font-size:70%;">3.5</span></td>
<td id="S3.T3.4.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.2.9.1" class="ltx_text" style="font-size:70%;">10.9</span></td>
</tr>
<tr id="S3.T3.4.6" class="ltx_tr">
<td id="S3.T3.4.6.1" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.6.1.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T3.4.6.2" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.6.2.1" class="ltx_text" style="font-size:70%;">197M</span></td>
<td id="S3.T3.4.6.3" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.6.3.1" class="ltx_text" style="font-size:70%;">1.2</span></td>
<td id="S3.T3.4.6.4" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.6.4.1" class="ltx_text" style="font-size:70%;">1.5</span></td>
<td id="S3.T3.4.6.5" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.6.5.1" class="ltx_text" style="font-size:70%;">2.0</span></td>
<td id="S3.T3.4.6.6" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.6.6.1" class="ltx_text" style="font-size:70%;">3.2</span></td>
<td id="S3.T3.4.6.7" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.6.7.1" class="ltx_text" style="font-size:70%;">6.7</span></td>
</tr>
<tr id="S3.T3.4.7" class="ltx_tr">
<td id="S3.T3.4.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.7.1.1" class="ltx_text" style="font-size:70%;">Auto-AVSR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite></span></td>
<td id="S3.T3.4.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.7.2.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T3.4.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.7.3.1" class="ltx_text" style="font-size:70%;">243M</span></td>
<td id="S3.T3.4.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.7.4.1" class="ltx_text" style="font-size:70%;">white</span></td>
<td id="S3.T3.4.7.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.7.5.1" class="ltx_text" style="font-size:70%;">2.1</span></td>
<td id="S3.T3.4.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.7.6.1" class="ltx_text" style="font-size:70%;">4.0</span></td>
<td id="S3.T3.4.7.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.7.7.1" class="ltx_text" style="font-size:70%;">10.4</span></td>
<td id="S3.T3.4.7.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.7.8.1" class="ltx_text" style="font-size:70%;">30.2</span></td>
<td id="S3.T3.4.7.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.7.9.1" class="ltx_text" style="font-size:70%;">88.9</span></td>
</tr>
<tr id="S3.T3.4.8" class="ltx_tr">
<td id="S3.T3.4.8.1" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.8.1.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T3.4.8.2" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.8.2.1" class="ltx_text" style="font-size:70%;">425M</span></td>
<td id="S3.T3.4.8.3" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.8.3.1" class="ltx_text" style="font-size:70%;">1.4</span></td>
<td id="S3.T3.4.8.4" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.8.4.1" class="ltx_text" style="font-size:70%;">2.3</span></td>
<td id="S3.T3.4.8.5" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.8.5.1" class="ltx_text" style="font-size:70%;">4.3</span></td>
<td id="S3.T3.4.8.6" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.8.6.1" class="ltx_text" style="font-size:70%;">9.5</span></td>
<td id="S3.T3.4.8.7" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.8.7.1" class="ltx_text" style="font-size:70%;">24.2</span></td>
</tr>
<tr id="S3.T3.4.9" class="ltx_tr">
<td id="S3.T3.4.9.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.9.1.1" class="ltx_text" style="font-size:70%;">Fast Conformer</span></td>
<td id="S3.T3.4.9.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.9.2.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T3.4.9.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.9.3.1" class="ltx_text" style="font-size:70%;">119M</span></td>
<td id="S3.T3.4.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;" rowspan="2"><span id="S3.T3.4.9.4.1" class="ltx_text" style="font-size:70%;">white</span></td>
<td id="S3.T3.4.9.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.9.5.1" class="ltx_text" style="font-size:70%;">1.5</span></td>
<td id="S3.T3.4.9.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.9.6.1" class="ltx_text" style="font-size:70%;">2.8</span></td>
<td id="S3.T3.4.9.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.9.7.1" class="ltx_text" style="font-size:70%;">6.9</span></td>
<td id="S3.T3.4.9.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.9.8.1" class="ltx_text" style="font-size:70%;">17.6</span></td>
<td id="S3.T3.4.9.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.9.9.1" class="ltx_text" style="font-size:70%;">54.8</span></td>
</tr>
<tr id="S3.T3.4.10" class="ltx_tr">
<td id="S3.T3.4.10.1" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.10.1.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T3.4.10.2" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.10.2.1" class="ltx_text" style="font-size:70%;">197M</span></td>
<td id="S3.T3.4.10.3" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.10.3.1" class="ltx_text" style="font-size:70%;">1.3</span></td>
<td id="S3.T3.4.10.4" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.10.4.1" class="ltx_text" style="font-size:70%;">2.1</span></td>
<td id="S3.T3.4.10.5" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.10.5.1" class="ltx_text" style="font-size:70%;">3.2</span></td>
<td id="S3.T3.4.10.6" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.10.6.1" class="ltx_text" style="font-size:70%;">5.7</span></td>
<td id="S3.T3.4.10.7" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S3.T3.4.10.7.1" class="ltx_text" style="font-size:70%;">21.4</span></td>
</tr>
</table>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Results on MuAViC</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Table <a href="#S3.T4" title="Table 4 ‣ 3.4 Results on MuAViC ‣ 3 Experiments ‣ Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> compares our monolingual and multilingual models WER with MuAViC baseline models fine-tuned from AV-HuBERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. We also evaluate Whisper Large <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, which we use to generate transcriptions. We observe that our models trained solely on human-labeled transcriptions achieve better performance than the original work. Including additional generated transcriptions from VoxCeleb2 and AVSpeech datasets further improves performance for every language considered. This is especially the case for the German subset, which contains only 10 hours of human-labeled speech, improving audio-visual WER by almost 20%. Moreover, we find that multilingual models can successfully be trained to recover similar performance by training on all languages, achieving an absolute average WER reduction of 11.94% in comparison to the original baseline. Multilingual training also further improves robustness of audio-visual models, allowing the visual branch to learn from a wide variety of lip movements. Our model improves noisy WER by 28% compared to Whisper, which was trained on 680k hours of multilingual speech data.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T4.6.1.1" class="ltx_text ltx_font_bold">Table 4</span>: </span>Comparison of WER (%) on the MuAViC dataset.</figcaption>
<table id="S3.T4.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T4.2.3" class="ltx_tr">
<td id="S3.T4.2.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.3.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Method</span></td>
<td id="S3.T4.2.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.3.2.1" class="ltx_text" style="font-size:70%;">
<span id="S3.T4.2.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.2.3.2.1.1.1" class="ltx_tr">
<span id="S3.T4.2.3.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.3.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Total</span></span></span>
<span id="S3.T4.2.3.2.1.1.2" class="ltx_tr">
<span id="S3.T4.2.3.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.3.2.1.1.2.1.1" class="ltx_text ltx_font_bold">Hours</span></span></span>
</span></span></td>
<td id="S3.T4.2.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.3.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Mode</span></td>
<td id="S3.T4.2.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" colspan="5"><span id="S3.T4.2.3.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Language test WER</span></td>
<td id="S3.T4.2.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.3.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">avg</span></td>
</tr>
<tr id="S3.T4.2.4" class="ltx_tr">
<td id="S3.T4.2.4.1" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.4.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">es</span></td>
<td id="S3.T4.2.4.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.4.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">fr</span></td>
<td id="S3.T4.2.4.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.4.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">pt</span></td>
<td id="S3.T4.2.4.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.4.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">it</span></td>
<td id="S3.T4.2.4.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.4.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">de</span></td>
</tr>
<tr id="S3.T4.2.5" class="ltx_tr">
<td id="S3.T4.2.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;">
<span id="S3.T4.2.5.1.1" class="ltx_text" style="font-size:70%;">Whisper </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.2.5.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S3.T4.2.5.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite><span id="S3.T4.2.5.1.4" class="ltx_text" style="font-size:70%;"> (ours)</span>
</td>
<td id="S3.T4.2.5.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.5.2.1" class="ltx_text" style="font-size:70%;">680k</span></td>
<td id="S3.T4.2.5.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.5.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.5.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.5.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">7.6</span></td>
<td id="S3.T4.2.5.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.5.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">9.4</span></td>
<td id="S3.T4.2.5.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.5.6.1" class="ltx_text" style="font-size:70%;">11.3</span></td>
<td id="S3.T4.2.5.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.5.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">8.7</span></td>
<td id="S3.T4.2.5.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.5.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">20.4</span></td>
<td id="S3.T4.2.5.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.5.9.1" class="ltx_text ltx_font_bold" style="font-size:70%;">11.5</span></td>
</tr>
<tr id="S3.T4.2.6" class="ltx_tr">
<td id="S3.T4.2.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.6.1.1" class="ltx_text" style="font-size:70%;">Monolingual</span></td>
<td id="S3.T4.2.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.6.2.1" class="ltx_text" style="font-size:70%;">2377</span></td>
<td id="S3.T4.2.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.6.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.6.4.1" class="ltx_text" style="font-size:70%;">16.5</span></td>
<td id="S3.T4.2.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.6.5.1" class="ltx_text" style="font-size:70%;">24.4</span></td>
<td id="S3.T4.2.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.6.6.1" class="ltx_text" style="font-size:70%;">23.0</span></td>
<td id="S3.T4.2.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.6.7.1" class="ltx_text" style="font-size:70%;">19.3</span></td>
<td id="S3.T4.2.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.6.8.1" class="ltx_text" style="font-size:70%;">61.1</span></td>
<td id="S3.T4.2.6.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.6.9.1" class="ltx_text" style="font-size:70%;">28.9</span></td>
</tr>
<tr id="S3.T4.2.7" class="ltx_tr">
<td id="S3.T4.2.7.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;">
<span id="S3.T4.2.7.1.1" class="ltx_text" style="font-size:70%;">AV-HuBERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.2.7.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S3.T4.2.7.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T4.2.7.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.7.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.7.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.7.3.1" class="ltx_text" style="font-size:70%;">15.9</span></td>
<td id="S3.T4.2.7.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.7.4.1" class="ltx_text" style="font-size:70%;">23.7</span></td>
<td id="S3.T4.2.7.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.7.5.1" class="ltx_text" style="font-size:70%;">19.4</span></td>
<td id="S3.T4.2.7.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.7.6.1" class="ltx_text" style="font-size:70%;">18.5</span></td>
<td id="S3.T4.2.7.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.7.7.1" class="ltx_text" style="font-size:70%;">52.4</span></td>
<td id="S3.T4.2.7.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.7.8.1" class="ltx_text" style="font-size:70%;">26.0</span></td>
</tr>
<tr id="S3.T4.2.8" class="ltx_tr">
<td id="S3.T4.2.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.8.1.1" class="ltx_text" style="font-size:70%;">Multilingual</span></td>
<td id="S3.T4.2.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.8.2.1" class="ltx_text" style="font-size:70%;">2467</span></td>
<td id="S3.T4.2.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.8.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.8.4.1" class="ltx_text" style="font-size:70%;">30.6</span></td>
<td id="S3.T4.2.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.8.5.1" class="ltx_text" style="font-size:70%;">27.0</span></td>
<td id="S3.T4.2.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.8.6.1" class="ltx_text" style="font-size:70%;">19.8</span></td>
<td id="S3.T4.2.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.8.7.1" class="ltx_text" style="font-size:70%;">19.3</span></td>
<td id="S3.T4.2.8.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.8.8.1" class="ltx_text" style="font-size:70%;">46.5</span></td>
<td id="S3.T4.2.8.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.8.9.1" class="ltx_text" style="font-size:70%;">28.6</span></td>
</tr>
<tr id="S3.T4.2.9" class="ltx_tr">
<td id="S3.T4.2.9.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;">
<span id="S3.T4.2.9.1.1" class="ltx_text" style="font-size:70%;">AV-HuBERT </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.2.9.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S3.T4.2.9.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite>
</td>
<td id="S3.T4.2.9.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.9.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.9.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.9.3.1" class="ltx_text" style="font-size:70%;">16.2</span></td>
<td id="S3.T4.2.9.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.9.4.1" class="ltx_text" style="font-size:70%;">19.0</span></td>
<td id="S3.T4.2.9.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.9.5.1" class="ltx_text" style="font-size:70%;">19.9</span></td>
<td id="S3.T4.2.9.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.9.6.1" class="ltx_text" style="font-size:70%;">19.8</span></td>
<td id="S3.T4.2.9.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.9.7.1" class="ltx_text" style="font-size:70%;">47.2</span></td>
<td id="S3.T4.2.9.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.9.8.1" class="ltx_text" style="font-size:70%;">24.4</span></td>
</tr>
<tr id="S3.T4.2.10" class="ltx_tr">
<td id="S3.T4.2.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.10.1.1" class="ltx_text" style="font-size:70%;">Monolingual</span></td>
<td id="S3.T4.2.10.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.10.2.1" class="ltx_text" style="font-size:70%;">3735</span></td>
<td id="S3.T4.2.10.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.10.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.10.4.1" class="ltx_text" style="font-size:70%;">8.5</span></td>
<td id="S3.T4.2.10.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.10.5.1" class="ltx_text" style="font-size:70%;">11.1</span></td>
<td id="S3.T4.2.10.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.10.6.1" class="ltx_text" style="font-size:70%;">12.2</span></td>
<td id="S3.T4.2.10.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.10.7.1" class="ltx_text" style="font-size:70%;">11.4</span></td>
<td id="S3.T4.2.10.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.10.8.1" class="ltx_text" style="font-size:70%;">41.3</span></td>
<td id="S3.T4.2.10.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.10.9.1" class="ltx_text" style="font-size:70%;">16.9</span></td>
</tr>
<tr id="S3.T4.2.11" class="ltx_tr">
<td id="S3.T4.2.11.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.11.1.1" class="ltx_text" style="font-size:70%;">Fast Conformer</span></td>
<td id="S3.T4.2.11.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.11.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.11.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.11.3.1" class="ltx_text" style="font-size:70%;">9.4</span></td>
<td id="S3.T4.2.11.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.11.4.1" class="ltx_text" style="font-size:70%;">11.4</span></td>
<td id="S3.T4.2.11.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.11.5.1" class="ltx_text" style="font-size:70%;">12.7</span></td>
<td id="S3.T4.2.11.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.11.6.1" class="ltx_text" style="font-size:70%;">12.4</span></td>
<td id="S3.T4.2.11.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.11.7.1" class="ltx_text" style="font-size:70%;">43.9</span></td>
<td id="S3.T4.2.11.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.11.8.1" class="ltx_text" style="font-size:70%;">18.0</span></td>
</tr>
<tr id="S3.T4.2.12" class="ltx_tr">
<td id="S3.T4.2.12.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.12.1.1" class="ltx_text" style="font-size:70%;">+ generated</span></td>
<td id="S3.T4.2.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.12.2.1" class="ltx_text" style="font-size:70%;">4957</span></td>
<td id="S3.T4.2.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.12.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.12.4.1" class="ltx_text" style="font-size:70%;">7.9</span></td>
<td id="S3.T4.2.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.12.5.1" class="ltx_text" style="font-size:70%;">9.6</span></td>
<td id="S3.T4.2.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.12.6.1" class="ltx_text" style="font-size:70%;">10.2</span></td>
<td id="S3.T4.2.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.12.7.1" class="ltx_text" style="font-size:70%;">10.2</span></td>
<td id="S3.T4.2.12.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.12.8.1" class="ltx_text" style="font-size:70%;">21.7</span></td>
<td id="S3.T4.2.12.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.12.9.1" class="ltx_text" style="font-size:70%;">11.9</span></td>
</tr>
<tr id="S3.T4.2.13" class="ltx_tr">
<td id="S3.T4.2.13.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.13.1.1" class="ltx_text" style="font-size:70%;">transcriptions</span></td>
<td id="S3.T4.2.13.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.13.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.13.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.13.3.1" class="ltx_text" style="font-size:70%;">8.2</span></td>
<td id="S3.T4.2.13.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.13.4.1" class="ltx_text" style="font-size:70%;">9.8</span></td>
<td id="S3.T4.2.13.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.13.5.1" class="ltx_text" style="font-size:70%;">10.2</span></td>
<td id="S3.T4.2.13.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.13.6.1" class="ltx_text" style="font-size:70%;">10.6</span></td>
<td id="S3.T4.2.13.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.13.7.1" class="ltx_text" style="font-size:70%;">22.4</span></td>
<td id="S3.T4.2.13.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.13.8.1" class="ltx_text" style="font-size:70%;">12.2</span></td>
</tr>
<tr id="S3.T4.2.14" class="ltx_tr">
<td id="S3.T4.2.14.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.14.1.1" class="ltx_text" style="font-size:70%;">Multilingual</span></td>
<td id="S3.T4.2.14.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.14.2.1" class="ltx_text" style="font-size:70%;">3735</span></td>
<td id="S3.T4.2.14.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.14.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.14.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.14.4.1" class="ltx_text" style="font-size:70%;">8.8</span></td>
<td id="S3.T4.2.14.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.14.5.1" class="ltx_text" style="font-size:70%;">11.4</span></td>
<td id="S3.T4.2.14.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.14.6.1" class="ltx_text" style="font-size:70%;">11.5</span></td>
<td id="S3.T4.2.14.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.14.7.1" class="ltx_text" style="font-size:70%;">11.0</span></td>
<td id="S3.T4.2.14.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.14.8.1" class="ltx_text" style="font-size:70%;">43.4</span></td>
<td id="S3.T4.2.14.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.14.9.1" class="ltx_text" style="font-size:70%;">17.2</span></td>
</tr>
<tr id="S3.T4.2.15" class="ltx_tr">
<td id="S3.T4.2.15.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.15.1.1" class="ltx_text" style="font-size:70%;">Fast Conformer</span></td>
<td id="S3.T4.2.15.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.15.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.15.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.15.3.1" class="ltx_text" style="font-size:70%;">9.0</span></td>
<td id="S3.T4.2.15.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.15.4.1" class="ltx_text" style="font-size:70%;">11.4</span></td>
<td id="S3.T4.2.15.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.15.5.1" class="ltx_text" style="font-size:70%;">11.8</span></td>
<td id="S3.T4.2.15.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.15.6.1" class="ltx_text" style="font-size:70%;">11.6</span></td>
<td id="S3.T4.2.15.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.15.7.1" class="ltx_text" style="font-size:70%;">46.8</span></td>
<td id="S3.T4.2.15.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.15.8.1" class="ltx_text" style="font-size:70%;">18.1</span></td>
</tr>
<tr id="S3.T4.2.16" class="ltx_tr">
<td id="S3.T4.2.16.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.16.1.1" class="ltx_text" style="font-size:70%;">+ generated</span></td>
<td id="S3.T4.2.16.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.16.2.1" class="ltx_text" style="font-size:70%;">4957</span></td>
<td id="S3.T4.2.16.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.16.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.16.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.16.4.1" class="ltx_text" style="font-size:70%;">8.2</span></td>
<td id="S3.T4.2.16.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.16.5.1" class="ltx_text" style="font-size:70%;">10.6</span></td>
<td id="S3.T4.2.16.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.16.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">9.9</span></td>
<td id="S3.T4.2.16.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.16.7.1" class="ltx_text" style="font-size:70%;">10.2</span></td>
<td id="S3.T4.2.16.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.16.8.1" class="ltx_text" style="font-size:70%;">23.4</span></td>
<td id="S3.T4.2.16.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.16.9.1" class="ltx_text" style="font-size:70%;">12.5</span></td>
</tr>
<tr id="S3.T4.2.17" class="ltx_tr">
<td id="S3.T4.2.17.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.17.1.1" class="ltx_text" style="font-size:70%;">transcriptions</span></td>
<td id="S3.T4.2.17.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.17.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.17.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.17.3.1" class="ltx_text" style="font-size:70%;">8.2</span></td>
<td id="S3.T4.2.17.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.17.4.1" class="ltx_text" style="font-size:70%;">10.3</span></td>
<td id="S3.T4.2.17.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.17.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">9.9</span></td>
<td id="S3.T4.2.17.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.17.6.1" class="ltx_text" style="font-size:70%;">10.4</span></td>
<td id="S3.T4.2.17.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.17.7.1" class="ltx_text" style="font-size:70%;">23.6</span></td>
<td id="S3.T4.2.17.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.17.8.1" class="ltx_text" style="font-size:70%;">12.5</span></td>
</tr>
<tr id="S3.T4.2.2" class="ltx_tr">
<td id="S3.T4.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.3pt;padding-right:4.3pt;" colspan="9">
<span id="S3.T4.2.2.2.1" class="ltx_text" style="font-size:70%;">(</span><math id="S3.T4.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T4.1.1.1.m1.1a"><mo mathsize="70%" stretchy="false" id="S3.T4.1.1.1.m1.1.1" xref="S3.T4.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T4.1.1.1.m1.1b"><ci id="S3.T4.1.1.1.m1.1.1.cmml" xref="S3.T4.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.1.1.1.m1.1c">\downarrow</annotation></semantics></math><span id="S3.T4.2.2.2.2" class="ltx_text" style="font-size:70%;">) </span><span id="S3.T4.2.2.2.3" class="ltx_text ltx_font_italic" style="font-size:70%;">Adding White Noise with -5 SNR at test time</span><span id="S3.T4.2.2.2.4" class="ltx_text" style="font-size:70%;"> (</span><math id="S3.T4.2.2.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S3.T4.2.2.2.m2.1a"><mo mathsize="70%" stretchy="false" id="S3.T4.2.2.2.m2.1.1" xref="S3.T4.2.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T4.2.2.2.m2.1b"><ci id="S3.T4.2.2.2.m2.1.1.cmml" xref="S3.T4.2.2.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T4.2.2.2.m2.1c">\downarrow</annotation></semantics></math><span id="S3.T4.2.2.2.5" class="ltx_text" style="font-size:70%;">)</span>
</td>
</tr>
<tr id="S3.T4.2.18" class="ltx_tr">
<td id="S3.T4.2.18.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;">
<span id="S3.T4.2.18.1.1" class="ltx_text" style="font-size:70%;">Whisper </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T4.2.18.1.2.1" class="ltx_text" style="font-size:70%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S3.T4.2.18.1.3.2" class="ltx_text" style="font-size:70%;">]</span></cite><span id="S3.T4.2.18.1.4" class="ltx_text" style="font-size:70%;"> (ours)</span>
</td>
<td id="S3.T4.2.18.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.18.2.1" class="ltx_text" style="font-size:70%;">680k</span></td>
<td id="S3.T4.2.18.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.18.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.18.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.18.4.1" class="ltx_text" style="font-size:70%;">56.3</span></td>
<td id="S3.T4.2.18.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.18.5.1" class="ltx_text" style="font-size:70%;">61.3</span></td>
<td id="S3.T4.2.18.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.18.6.1" class="ltx_text" style="font-size:70%;">72.4</span></td>
<td id="S3.T4.2.18.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.18.7.1" class="ltx_text" style="font-size:70%;">59.4</span></td>
<td id="S3.T4.2.18.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.18.8.1" class="ltx_text" style="font-size:70%;">69.2</span></td>
<td id="S3.T4.2.18.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.18.9.1" class="ltx_text" style="font-size:70%;">63.7</span></td>
</tr>
<tr id="S3.T4.2.19" class="ltx_tr">
<td id="S3.T4.2.19.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.19.1.1" class="ltx_text" style="font-size:70%;">Monolingual</span></td>
<td id="S3.T4.2.19.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.19.2.1" class="ltx_text" style="font-size:70%;">3735</span></td>
<td id="S3.T4.2.19.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.19.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.19.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.19.4.1" class="ltx_text" style="font-size:70%;">58.7</span></td>
<td id="S3.T4.2.19.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.19.5.1" class="ltx_text" style="font-size:70%;">57.8</span></td>
<td id="S3.T4.2.19.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.19.6.1" class="ltx_text" style="font-size:70%;">63.0</span></td>
<td id="S3.T4.2.19.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.19.7.1" class="ltx_text" style="font-size:70%;">61.5</span></td>
<td id="S3.T4.2.19.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.19.8.1" class="ltx_text" style="font-size:70%;">91.4</span></td>
<td id="S3.T4.2.19.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.19.9.1" class="ltx_text" style="font-size:70%;">66.5</span></td>
</tr>
<tr id="S3.T4.2.20" class="ltx_tr">
<td id="S3.T4.2.20.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.20.1.1" class="ltx_text" style="font-size:70%;">Fast Conformer</span></td>
<td id="S3.T4.2.20.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.20.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.20.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.20.3.1" class="ltx_text" style="font-size:70%;">35.2</span></td>
<td id="S3.T4.2.20.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.20.4.1" class="ltx_text" style="font-size:70%;">49.5</span></td>
<td id="S3.T4.2.20.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.20.5.1" class="ltx_text" style="font-size:70%;">46.9</span></td>
<td id="S3.T4.2.20.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.20.6.1" class="ltx_text" style="font-size:70%;">45.8</span></td>
<td id="S3.T4.2.20.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.20.7.1" class="ltx_text" style="font-size:70%;">75.5</span></td>
<td id="S3.T4.2.20.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.20.8.1" class="ltx_text" style="font-size:70%;">50.6</span></td>
</tr>
<tr id="S3.T4.2.21" class="ltx_tr">
<td id="S3.T4.2.21.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.21.1.1" class="ltx_text" style="font-size:70%;">+ generated</span></td>
<td id="S3.T4.2.21.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.21.2.1" class="ltx_text" style="font-size:70%;">4957</span></td>
<td id="S3.T4.2.21.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.21.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.21.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.21.4.1" class="ltx_text" style="font-size:70%;">40.5</span></td>
<td id="S3.T4.2.21.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.21.5.1" class="ltx_text" style="font-size:70%;">60.6</span></td>
<td id="S3.T4.2.21.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.21.6.1" class="ltx_text" style="font-size:70%;">54.4</span></td>
<td id="S3.T4.2.21.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.21.7.1" class="ltx_text" style="font-size:70%;">49.8</span></td>
<td id="S3.T4.2.21.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.21.8.1" class="ltx_text" style="font-size:70%;">62.5</span></td>
<td id="S3.T4.2.21.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.21.9.1" class="ltx_text" style="font-size:70%;">53.6</span></td>
</tr>
<tr id="S3.T4.2.22" class="ltx_tr">
<td id="S3.T4.2.22.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.22.1.1" class="ltx_text" style="font-size:70%;">transcriptions</span></td>
<td id="S3.T4.2.22.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.22.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.22.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.22.3.1" class="ltx_text" style="font-size:70%;">29.8</span></td>
<td id="S3.T4.2.22.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.22.4.1" class="ltx_text" style="font-size:70%;">41.7</span></td>
<td id="S3.T4.2.22.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.22.5.1" class="ltx_text" style="font-size:70%;">40.1</span></td>
<td id="S3.T4.2.22.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.22.6.1" class="ltx_text" style="font-size:70%;">37.0</span></td>
<td id="S3.T4.2.22.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.22.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">48.1</span></td>
<td id="S3.T4.2.22.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.22.8.1" class="ltx_text" style="font-size:70%;">39.3</span></td>
</tr>
<tr id="S3.T4.2.23" class="ltx_tr">
<td id="S3.T4.2.23.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.23.1.1" class="ltx_text" style="font-size:70%;">Multilingual</span></td>
<td id="S3.T4.2.23.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.23.2.1" class="ltx_text" style="font-size:70%;">3735</span></td>
<td id="S3.T4.2.23.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.23.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.23.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.23.4.1" class="ltx_text" style="font-size:70%;">52.3</span></td>
<td id="S3.T4.2.23.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.23.5.1" class="ltx_text" style="font-size:70%;">63.0</span></td>
<td id="S3.T4.2.23.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.23.6.1" class="ltx_text" style="font-size:70%;">65.4</span></td>
<td id="S3.T4.2.23.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.23.7.1" class="ltx_text" style="font-size:70%;">59.4</span></td>
<td id="S3.T4.2.23.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.23.8.1" class="ltx_text" style="font-size:70%;">94.5</span></td>
<td id="S3.T4.2.23.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.23.9.1" class="ltx_text" style="font-size:70%;">66.9</span></td>
</tr>
<tr id="S3.T4.2.24" class="ltx_tr">
<td id="S3.T4.2.24.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.24.1.1" class="ltx_text" style="font-size:70%;">Fast Conformer</span></td>
<td id="S3.T4.2.24.2" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.24.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.24.3" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.24.3.1" class="ltx_text" style="font-size:70%;">35.1</span></td>
<td id="S3.T4.2.24.4" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.24.4.1" class="ltx_text" style="font-size:70%;">41.9</span></td>
<td id="S3.T4.2.24.5" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.24.5.1" class="ltx_text" style="font-size:70%;">42.4</span></td>
<td id="S3.T4.2.24.6" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.24.6.1" class="ltx_text" style="font-size:70%;">37.5</span></td>
<td id="S3.T4.2.24.7" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.24.7.1" class="ltx_text" style="font-size:70%;">87.0</span></td>
<td id="S3.T4.2.24.8" class="ltx_td ltx_align_center" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.24.8.1" class="ltx_text" style="font-size:70%;">48.8</span></td>
</tr>
<tr id="S3.T4.2.25" class="ltx_tr">
<td id="S3.T4.2.25.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.25.1.1" class="ltx_text" style="font-size:70%;">+ generated</span></td>
<td id="S3.T4.2.25.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;" rowspan="2"><span id="S3.T4.2.25.2.1" class="ltx_text" style="font-size:70%;">4957</span></td>
<td id="S3.T4.2.25.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.25.3.1" class="ltx_text" style="font-size:70%;">A</span></td>
<td id="S3.T4.2.25.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.25.4.1" class="ltx_text" style="font-size:70%;">44.9</span></td>
<td id="S3.T4.2.25.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.25.5.1" class="ltx_text" style="font-size:70%;">52.9</span></td>
<td id="S3.T4.2.25.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.25.6.1" class="ltx_text" style="font-size:70%;">55.9</span></td>
<td id="S3.T4.2.25.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.25.7.1" class="ltx_text" style="font-size:70%;">50.0</span></td>
<td id="S3.T4.2.25.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.25.8.1" class="ltx_text" style="font-size:70%;">69.0</span></td>
<td id="S3.T4.2.25.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.25.9.1" class="ltx_text" style="font-size:70%;">54.5</span></td>
</tr>
<tr id="S3.T4.2.26" class="ltx_tr">
<td id="S3.T4.2.26.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.26.1.1" class="ltx_text" style="font-size:70%;">transcriptions</span></td>
<td id="S3.T4.2.26.2" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.26.2.1" class="ltx_text" style="font-size:70%;">AV</span></td>
<td id="S3.T4.2.26.3" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.26.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">28.2</span></td>
<td id="S3.T4.2.26.4" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.26.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">35.1</span></td>
<td id="S3.T4.2.26.5" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.26.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">34.7</span></td>
<td id="S3.T4.2.26.6" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.26.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">30.3</span></td>
<td id="S3.T4.2.26.7" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.26.7.1" class="ltx_text" style="font-size:70%;">50.3</span></td>
<td id="S3.T4.2.26.8" class="ltx_td ltx_align_center ltx_border_b" style="padding-left:4.3pt;padding-right:4.3pt;"><span id="S3.T4.2.26.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">35.7</span></td>
</tr>
</table>
</figure>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Learning Objective</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">We study the effect of the optimization architecture on final performance. Table <a href="#S3.T5" title="Table 5 ‣ 3.5 Learning Objective ‣ 3 Experiments ‣ Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> compares the WER of CTC, RNN-T and hybrid models on the LRS3 test set. We find that adding a CTC loss slightly helps to improve RNN-T performance. Moreover, the hybrid CTC/RNN-T architecture can be used for CTC and RNN-T decoding without the need to train both networks separately. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we also experiment adding intermediate CTC losses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> every 3 Conformer blocks and find it to further improve lip reading performance.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T5.4.1.1" class="ltx_text ltx_font_bold">Table 5</span>: </span>Effect of loss type on Fast Conformer performance.</figcaption>
<table id="S3.T5.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T5.5.1" class="ltx_tr">
<td id="S3.T5.5.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T5.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Loss Type</span></td>
<td id="S3.T5.5.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T5.5.1.2.1" class="ltx_text" style="font-size:70%;">
<span id="S3.T5.5.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T5.5.1.2.1.1.1" class="ltx_tr">
<span id="S3.T5.5.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T5.5.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Training</span></span></span>
<span id="S3.T5.5.1.2.1.1.2" class="ltx_tr">
<span id="S3.T5.5.1.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T5.5.1.2.1.1.2.1.1" class="ltx_text ltx_font_bold">Datasets</span></span></span>
</span></span></td>
<td id="S3.T5.5.1.3" class="ltx_td ltx_align_center ltx_border_t" colspan="3"><span id="S3.T5.5.1.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">CTC / RNN-T LRS3 test WER (%)</span></td>
</tr>
<tr id="S3.T5.5.2" class="ltx_tr">
<td id="S3.T5.5.2.1" class="ltx_td ltx_align_center"><span id="S3.T5.5.2.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">AV</span></td>
<td id="S3.T5.5.2.2" class="ltx_td ltx_align_center"><span id="S3.T5.5.2.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">A</span></td>
<td id="S3.T5.5.2.3" class="ltx_td ltx_align_center"><span id="S3.T5.5.2.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">V</span></td>
</tr>
<tr id="S3.T5.5.3" class="ltx_tr">
<td id="S3.T5.5.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S3.T5.5.3.1.1" class="ltx_text" style="font-size:70%;">CTC</span></td>
<td id="S3.T5.5.3.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T5.5.3.2.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T5.5.3.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T5.5.3.3.1" class="ltx_text" style="font-size:70%;">2.3</span></td>
<td id="S3.T5.5.3.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T5.5.3.4.1" class="ltx_text" style="font-size:70%;">2.1</span></td>
<td id="S3.T5.5.3.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T5.5.3.5.1" class="ltx_text" style="font-size:70%;">49.7</span></td>
</tr>
<tr id="S3.T5.5.4" class="ltx_tr">
<td id="S3.T5.5.4.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T5.5.4.1.1" class="ltx_text" style="font-size:70%;">RNN-T</span></td>
<td id="S3.T5.5.4.2" class="ltx_td ltx_align_left"><span id="S3.T5.5.4.2.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T5.5.4.3" class="ltx_td ltx_align_center"><span id="S3.T5.5.4.3.1" class="ltx_text" style="font-size:70%;">1.9</span></td>
<td id="S3.T5.5.4.4" class="ltx_td ltx_align_center"><span id="S3.T5.5.4.4.1" class="ltx_text" style="font-size:70%;">1.8</span></td>
<td id="S3.T5.5.4.5" class="ltx_td ltx_align_center"><span id="S3.T5.5.4.5.1" class="ltx_text" style="font-size:70%;">47.7</span></td>
</tr>
<tr id="S3.T5.5.5" class="ltx_tr">
<td id="S3.T5.5.5.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T5.5.5.1.1" class="ltx_text" style="font-size:70%;">CTC / RNN-T</span></td>
<td id="S3.T5.5.5.2" class="ltx_td ltx_align_left"><span id="S3.T5.5.5.2.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T5.5.5.3" class="ltx_td ltx_align_center"><span id="S3.T5.5.5.3.1" class="ltx_text" style="font-size:70%;">2.3 / 1.7</span></td>
<td id="S3.T5.5.5.4" class="ltx_td ltx_align_center"><span id="S3.T5.5.5.4.1" class="ltx_text" style="font-size:70%;">2.0 / 1.6</span></td>
<td id="S3.T5.5.5.5" class="ltx_td ltx_align_center"><span id="S3.T5.5.5.5.1" class="ltx_text" style="font-size:70%;">49.8 / 45.9</span></td>
</tr>
<tr id="S3.T5.5.6" class="ltx_tr">
<td id="S3.T5.5.6.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T5.5.6.1.1" class="ltx_text" style="font-size:70%;">InterCTC / RNN-T</span></td>
<td id="S3.T5.5.6.2" class="ltx_td ltx_align_left"><span id="S3.T5.5.6.2.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T5.5.6.3" class="ltx_td ltx_align_center"><span id="S3.T5.5.6.3.1" class="ltx_text" style="font-size:70%;">2.3 / 1.7</span></td>
<td id="S3.T5.5.6.4" class="ltx_td ltx_align_center"><span id="S3.T5.5.6.4.1" class="ltx_text" style="font-size:70%;">1.9 / 1.6</span></td>
<td id="S3.T5.5.6.5" class="ltx_td ltx_align_center"><span id="S3.T5.5.6.5.1" class="ltx_text" style="font-size:70%;">48.7 / 43.8</span></td>
</tr>
<tr id="S3.T5.5.7" class="ltx_tr">
<td id="S3.T5.5.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span id="S3.T5.5.7.1.1" class="ltx_text" style="font-size:70%;">CTC / RNN-T</span></td>
<td id="S3.T5.5.7.2" class="ltx_td ltx_align_left ltx_border_b"><span id="S3.T5.5.7.2.1" class="ltx_text" style="font-size:70%;">LRS3,VC2,AVS</span></td>
<td id="S3.T5.5.7.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T5.5.7.3.1" class="ltx_text" style="font-size:70%;">1.4 / 0.8</span></td>
<td id="S3.T5.5.7.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T5.5.7.4.1" class="ltx_text" style="font-size:70%;">1.1 / 0.7</span></td>
<td id="S3.T5.5.7.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T5.5.7.5.1" class="ltx_text" style="font-size:70%;">31.1 / 27.0</span></td>
</tr>
</table>
</figure>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Unimodal Inference</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">We study the effect of using InterCTC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> and modality dropout <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> during training on unimodal inference results. Table <a href="#S3.T6" title="Table 6 ‣ 3.6 Unimodal Inference ‣ 3 Experiments ‣ Multilingual Audio-Visual Speech Recognition with Hybrid CTC/RNN-T Fast Conformer" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the LRS3 test WER when masking one of the two modalities in the fusion module at test time. We find that training without InterCTC nor modality dropout leads the model to ignore the visual modality. ASR being a substantially easier task than lip reading, the model does not need to learn visual representations to achieve good performance. Forcing the visual encoder to learn hidden representations using one of these two methods solves the problem. We find that solely using modality dropout during training is sufficient to avoid this issue and allows the model to be used in audio-only mode at test time with a minimum loss of performance.</p>
</div>
<figure id="S3.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T6.4.1.1" class="ltx_text ltx_font_bold">Table 6</span>: </span>Effect of using InterCTC and/or modality dropout during training on unimodal inference performance.</figcaption>
<table id="S3.T6.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T6.5.1" class="ltx_tr">
<td id="S3.T6.5.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2"><span id="S3.T6.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Method</span></td>
<td id="S3.T6.5.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S3.T6.5.1.2.1" class="ltx_text" style="font-size:70%;">
<span id="S3.T6.5.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T6.5.1.2.1.1.1" class="ltx_tr">
<span id="S3.T6.5.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T6.5.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Training</span></span></span>
<span id="S3.T6.5.1.2.1.1.2" class="ltx_tr">
<span id="S3.T6.5.1.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T6.5.1.2.1.1.2.1.1" class="ltx_text ltx_font_bold">Datasets</span></span></span>
</span></span></td>
<td id="S3.T6.5.1.3" class="ltx_td ltx_align_center ltx_border_t" colspan="3"><span id="S3.T6.5.1.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">AV model LRS3 test WER (%)</span></td>
</tr>
<tr id="S3.T6.5.2" class="ltx_tr">
<td id="S3.T6.5.2.1" class="ltx_td ltx_align_center"><span id="S3.T6.5.2.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">no mask</span></td>
<td id="S3.T6.5.2.2" class="ltx_td ltx_align_center"><span id="S3.T6.5.2.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">mask video</span></td>
<td id="S3.T6.5.2.3" class="ltx_td ltx_align_center"><span id="S3.T6.5.2.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">mask audio</span></td>
</tr>
<tr id="S3.T6.5.3" class="ltx_tr">
<td id="S3.T6.5.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S3.T6.5.3.1.1" class="ltx_text" style="font-size:70%;">Fast Conformer</span></td>
<td id="S3.T6.5.3.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T6.5.3.2.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T6.5.3.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.3.3.1" class="ltx_text" style="font-size:70%;">1.9</span></td>
<td id="S3.T6.5.3.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.3.4.1" class="ltx_text" style="font-size:70%;">2.0</span></td>
<td id="S3.T6.5.3.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.3.5.1" class="ltx_text" style="font-size:70%;">100.0</span></td>
</tr>
<tr id="S3.T6.5.4" class="ltx_tr">
<td id="S3.T6.5.4.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T6.5.4.1.1" class="ltx_text" style="font-size:70%;">+ InterCTC</span></td>
<td id="S3.T6.5.4.2" class="ltx_td ltx_align_left"><span id="S3.T6.5.4.2.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T6.5.4.3" class="ltx_td ltx_align_center"><span id="S3.T6.5.4.3.1" class="ltx_text" style="font-size:70%;">1.6</span></td>
<td id="S3.T6.5.4.4" class="ltx_td ltx_align_center"><span id="S3.T6.5.4.4.1" class="ltx_text" style="font-size:70%;">10.2</span></td>
<td id="S3.T6.5.4.5" class="ltx_td ltx_align_center"><span id="S3.T6.5.4.5.1" class="ltx_text" style="font-size:70%;">48.7</span></td>
</tr>
<tr id="S3.T6.5.5" class="ltx_tr">
<td id="S3.T6.5.5.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T6.5.5.1.1" class="ltx_text" style="font-size:70%;">+ mod drop</span></td>
<td id="S3.T6.5.5.2" class="ltx_td ltx_align_left"><span id="S3.T6.5.5.2.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T6.5.5.3" class="ltx_td ltx_align_center"><span id="S3.T6.5.5.3.1" class="ltx_text" style="font-size:70%;">1.7</span></td>
<td id="S3.T6.5.5.4" class="ltx_td ltx_align_center"><span id="S3.T6.5.5.4.1" class="ltx_text" style="font-size:70%;">1.8</span></td>
<td id="S3.T6.5.5.5" class="ltx_td ltx_align_center"><span id="S3.T6.5.5.5.1" class="ltx_text" style="font-size:70%;">44.0</span></td>
</tr>
<tr id="S3.T6.5.6" class="ltx_tr">
<td id="S3.T6.5.6.1" class="ltx_td ltx_align_left ltx_border_r"><span id="S3.T6.5.6.1.1" class="ltx_text" style="font-size:70%;">        + InterCTC</span></td>
<td id="S3.T6.5.6.2" class="ltx_td ltx_align_left"><span id="S3.T6.5.6.2.1" class="ltx_text" style="font-size:70%;">LRS3</span></td>
<td id="S3.T6.5.6.3" class="ltx_td ltx_align_center"><span id="S3.T6.5.6.3.1" class="ltx_text" style="font-size:70%;">1.7</span></td>
<td id="S3.T6.5.6.4" class="ltx_td ltx_align_center"><span id="S3.T6.5.6.4.1" class="ltx_text" style="font-size:70%;">1.9</span></td>
<td id="S3.T6.5.6.5" class="ltx_td ltx_align_center"><span id="S3.T6.5.6.5.1" class="ltx_text" style="font-size:70%;">44.0</span></td>
</tr>
<tr id="S3.T6.5.7" class="ltx_tr">
<td id="S3.T6.5.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span id="S3.T6.5.7.1.1" class="ltx_text" style="font-size:70%;">+ mod drop</span></td>
<td id="S3.T6.5.7.2" class="ltx_td ltx_align_left ltx_border_b"><span id="S3.T6.5.7.2.1" class="ltx_text" style="font-size:70%;">LRS3,VC2,AVS</span></td>
<td id="S3.T6.5.7.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T6.5.7.3.1" class="ltx_text" style="font-size:70%;">0.8</span></td>
<td id="S3.T6.5.7.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T6.5.7.4.1" class="ltx_text" style="font-size:70%;">1.0</span></td>
<td id="S3.T6.5.7.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T6.5.7.5.1" class="ltx_text" style="font-size:70%;">32.2</span></td>
</tr>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this work, we presented a multilingual AVSR model using several enhancements to improve performance and audio noise robustness. We adapted the recently proposed Fast Conformer model to process both audio and visual modalities using a novel hybrid CTC/RNN-T architecture. We increased the amount of audio-visual training data for six distinct languages by generating automatic transcriptions of large scale multilingual datasets. Our hybrid audio-visual Fast Conformer model achieved new state-of-the-art results on the LRS3 dataset, reaching WER of 0.8%. On the recently released MuAViC benchmark, our model yields an absolute average-WER reduction of 11.9% compared to the original baseline. Models and training recipes will be open-sourced through the NVIDIA NeMo toolkit <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
J. Son Chung et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">“Lip reading sentences in the wild,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, 2017, pp. 6447–6456.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
G. Sterpu et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">“Attention-based audio-visual fusion for robust automatic speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICMI</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 111–115.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
T. Afouras et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">“Deep audio-visual speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE TPAMI</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, vol. 44, no. 12, pp. 8717–8727, 2018.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
S. Petridis et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">“Audio-visual speech recognition with a hybrid ctc/attention architecture,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">SLT</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, 2018, pp. 513–520.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
B. Xu et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">“Discriminative multi-modality speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, 2020, pp. 14433–14442.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
P. Ma et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">“End-to-end audio-visual speech recognition with conformers,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, 2021, pp. 7613–7617.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
M. Burchi and R. Timofte,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">“Audio-visual efficient conformer for robust speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">WACV</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 2258–2267.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
A. Gulati et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">“Conformer: Convolution-augmented transformer for speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2005.08100</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
J. Nozaki and T. Komatsu,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">“Relaxing the conditional independence assumption of ctc-based asr by conditioning on intermediate predictions,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.02724</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
D. Serdyuk et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">“Transformer-based video front-ends for audio-visual speech recognition for single and multi-person video,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2201.10439</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
O. Chang et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">“Conformers are all you need for visual speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2302.10915</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
T. Afouras et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">“Lrs3-ted: a large-scale dataset for visual speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1809.00496</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
J. Chung and A. Zisserman,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">“Lip reading in the wild,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ACCV</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">. Springer, 2017, pp. 87–103.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
M. Anwar et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">“Muavic: A multilingual audio-visual corpus for robust speech recognition and robust speech-to-text translation,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2303.00628</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
B. Shi et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">“Learning audio-visual speech representation by masked multimodal cluster prediction,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2201.02184</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
A. Haliassos et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">“Jointly learning visual and auditory speech representations from raw data,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2212.06246</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
W. Hsu and B.Shi,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">“u-hubert: Unified mixed-modal speech pretraining and zero-shot transfer to unlabeled modality,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:90%;">, vol. 35, pp. 21157–21170, 2022.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
J. Lian et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">“Av-data2vec: Self-supervised learning of audio-visual speech representations with contextualized target representations,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2302.06419</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Q. Zhu et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">“Vatlm: Visual-audio-text pre-training with unified masked prediction for speech representation learning,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Multimedia</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
J. Chung et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">“Voxceleb2: Deep speaker recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1806.05622</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
P. Ma et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">“Auto-avsr: Audio-visual speech recognition with automatic labels,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 1–5.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
A. Radford et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">“Robust speech recognition via large-scale weak supervision,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, 2023, pp. 28492–28518.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
A. Graves et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">“Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, 2006, pp. 369–376.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
A. Graves,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">“Sequence transduction with recurrent neural networks,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1211.3711</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 2012.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
D. Rekesh et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">“Fast conformer with linearly scalable attention for efficient speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2305.05084</span><span id="bib.bib25.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
S. Hochreiter and J. Schmidhuber,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">“Long short-term memory,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Neural computation</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:90%;">, vol. 9, no. 8, pp. 1735–1780, 1997.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
K. He et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">“Deep residual learning for image recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, 2016, pp. 770–778.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
A. Ephrat et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">“Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1804.03619</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
J. Deng et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">“Retinaface: Single-shot multi-level face localisation in the wild,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, 2020, pp. 5203–5212.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
A. Bulat and G. Tzimiropoulos,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">“How far are we from solving the 2d &amp; 3d face alignment problem?(and a dataset of 230,000 3d facial landmarks),”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, 2017, pp. 1021–1030.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
D. Park et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">“Specaugment on large scale datasets,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, 2020, pp. 6879–6883.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
A. Varga and HJM. Steeneken,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">“Noisex-92: A database and an experiment to study the effect of additive noise on speech recognition systems,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Speech Commun</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, vol. 12, no. 3, pp. 247–253, 1993.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
M. Pingchuan et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">“Visual speech recognition for multiple languages in the wild,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Nature Machine Intelligence</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">, vol. 4, no. 11, pp. 930–939, 2022.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
J. Lee and S. Watanabe,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">“Intermediate loss regularization for ctc-based speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">in </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">. IEEE, 2021, pp. 6224–6228.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
I. Loshchilov and F. Hutter,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">“Decoupled weight decay regularization,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1711.05101</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
T. Kudo and J. Richardson,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">“Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1808.06226</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
K. Dhawan et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">“Towards training bilingual and code-switched speech recognition models from monolingual data sources,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2306.08753</span><span id="bib.bib37.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
B. Shi et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">“Robust self-supervised audio-visual speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2201.01763</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
C. Oscar et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">“On robustness to missing video for audiovisual speech recognition,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2312.10088</span><span id="bib.bib39.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
O. Kuchaiev et al.,
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">“Nemo: a toolkit for building ai applications using neural modules,”
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1909.09577</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2405.12982" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2405.12983" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2405.12983">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2405.12983" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2405.12984" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Jun  5 14:17:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
