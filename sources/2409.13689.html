<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.13689] Temporally Aligned Audio for Video with Autoregression</title><meta property="og:description" content="We introduce V-AURA, the first autoregressive model to achieve high temporal alignment and relevance in video-to-audio generation.
V-AURA uses a high-framerate visual feature extractor and a cross-modal audio-visual fe…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Temporally Aligned Audio for Video with Autoregression">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Temporally Aligned Audio for Video with Autoregression">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.13689">

<!--Generated on Sat Oct  5 21:18:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
video-to-audio generation,  autoregressive modeling
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Temporally Aligned Audio for Video with Autoregression
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">1<sup id="id1.1.id1" class="ltx_sup">st</sup> Ilpo Viertola
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.2.id1" class="ltx_text ltx_font_italic">Computing Sciences</span>
<br class="ltx_break"><span id="id3.3.id2" class="ltx_text ltx_font_italic">Tampere University
<br class="ltx_break"></span>Tampere, Finland 
<br class="ltx_break">ilpo.viertola@tuni.fi
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">2<sup id="id4.1.id1" class="ltx_sup">nd</sup> Vladimir Iashin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.2.id1" class="ltx_text ltx_font_italic">Computing Sciences, Tampere University</span>
<br class="ltx_break"><span id="id6.3.id2" class="ltx_text ltx_font_italic">Engineering Science, University of Oxford</span>
<br class="ltx_break">Oxford, United Kingdom 
<br class="ltx_break">vi@robots.ox.ac.uk
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">3<sup id="id7.1.id1" class="ltx_sup">rd</sup> Esa Rahtu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id8.2.id1" class="ltx_text ltx_font_italic">Computing Sciences</span>
<br class="ltx_break"><span id="id9.3.id2" class="ltx_text ltx_font_italic">Tampere University
<br class="ltx_break"></span>Tampere, Finland 
<br class="ltx_break">esa.rahtu@tuni.fi
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id10.id1" class="ltx_p">We introduce V-AURA, the first autoregressive model to achieve high temporal alignment and relevance in video-to-audio generation.
V-AURA uses a high-framerate visual feature extractor and a cross-modal audio-visual feature fusion strategy to capture fine-grained visual motion events and ensure precise temporal alignment.
Additionally, we propose VisualSound, a benchmark dataset with high audio-visual relevance.
VisualSound is based on VGGSound, a video dataset consisting of in-the-wild samples extracted from YouTube.
During the curation, we remove samples where auditory events are not aligned with the visual ones.
V-AURA outperforms current state-of-the-art models in temporal alignment and semantic relevance while maintaining comparable audio quality.
Code, samples, VisualSound and models are available at <a href="v-aura.notion.site" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" style="color:#0000FF;">v-aura.notion.site</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
video-to-audio generation, autoregressive modeling

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Video-to-audio generation focuses on synthesizing audio based on a video sequence.
The synthesized audio must be high-quality and closely aligned with the visual events temporally and semantically.
It requires the generative model to deeply understand the timing and meaning of the visual content, supported by well-curated training data where the auditory events are relevant to the visual ones.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The current state-of-the-art models are built on top of diffusion and rectified flow matching (RFM) based methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and have replaced autoregressive methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> built on top of Transformer architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
However, diffusion models often require added complexity compared to autoregressive solutions.
In particular, diffusion models rely on image-based approaches in audio generation, encoding the audio as a mel-spectrogram.
Converting audio into a mel-spectrogram is a lossy conversion as the original signal must be filtered.
Converting the mel-spectrogram back to a waveform requires an additional network since the discarded frequencies must be reconstructed.
During the conversion, some important fine-grained audio information might be lost and generation of detailed audio becomes impossible.
In contrast, we use a pretrained audio codec that encodes waveforms into discrete token sequences and decodes them into waveform representations without transforming the audio to image-space (spectrogram) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
Additionally, the training of diffusion models is more complex and requires more iterations than our autoregressive method.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Most of the video-to-audio models are trained with video datasets consisting of noisy in-the-wild samples scraped from YouTube, such as VGGSound <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> or AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, where the audio-visual relevance is not guaranteed.
For example, the original audio can be replaced with non-related ones, such as background music, narration, or audio effects.
We introduce a novel benchmark, VisualSound, a subset of VGGSound in which samples possess a high audio-visual correspondence.
Removing the harmful samples, and training the model with a smaller but high-quality dataset, increases relevance and temporal alignment between video and audio.
Also, as the amount of noisy samples scales down, the training time decreases significantly.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Compared to the state-of-the-art diffusion and RFM-based models, our autoregressive approach achieves a high temporal alignment and relevance between audio and video.
Our contributions can be summarized as follows: i) the first autoregressive model to achieve strong relevance and temporal alignment in video-to-audio generation, ii) a cross-modal feature alignment strategy emphasizing the natural co-occurrence of audio and video in the autoregressive setting, iii) a new benchmark dataset with strong audio-visual correspondence, and iv) a new synchronization-based objective metric for temporal alignment between video and generated audio.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Early approaches in visual-to-audio generation used Generative Adversarial Networks (GAN) to generate audio within a small set of data classes, given a conditional visual feature sequence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> framed the conditional audio generation as a next token prediction problem using various visual features as the conditional prompt.
Even though these autoregressive methods supported a wider range of audio data classes, they suffered from poor temporal alignment and audio quality.
To improve sample quality, others have explored bridging large pretrained general-purpose generative audio models to multiple modalities via feature mapping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> or by training diffusion latent aligners for semantical and temporal control <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
To emphasize temporal alignment, recent diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and rectified flow matching <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> approaches rely on contrastively trained audio-visual feature extractors.
In addition, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> introduces cross-modal feature fusion in an RFM setting to emphasize temporal alignment.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Even so, existing methods often fail to produce temporally aligned audio due to low visual framerates or weak learned relationships between the modalities.
To address this, we use videos with a 6-times higher framerate than the state-of-the-art and a high-framerate visual feature extractor designed to focus on fine-grain visual and motion features associated with sounds.
We enforce natural audio-video co-occurrence by introducing a channel-wise cross-modal feature fusion in an autoregressive setting.
To enhance sample quality and mitigate hallucinations caused by noisy training data, we introduce VisualSound, a novel dataset with strong audio-visual relevance.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2409.13689/assets/model_v11.2.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="269" height="258" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
<span id="S2.F1.4.1" class="ltx_text ltx_font_bold">Overview of V-AURA</span>.
Given stacks of RGB frames, the visual encoder extracts visual features which are projected into visual feature embeddings.
Then, the temporal dimension of visual embeddings is aligned with the audio embeddings.
The audio tokens from the previous generation step are embedded and added together to represent the full-band audio signal <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
The tokenized audio sequence is padded with learned padding tokens (<math id="S2.F1.2.m1.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S2.F1.2.m1.1b"><mi id="S2.F1.2.m1.1.1" xref="S2.F1.2.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S2.F1.2.m1.1c"><ci id="S2.F1.2.m1.1.1.cmml" xref="S2.F1.2.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.2.m1.1d">P</annotation></semantics></math>).
Embeddings of different modalities are aligned and fused with cross-modal feature fusion before the next generation step in Transformer.
When the audio sequence reaches the desired length, it is decoded back to a waveform using the decoder of the pre-trained codebook-based autoencoder.
</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Method</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The proposed model, V-AURA (<span id="S3.p1.1.1" class="ltx_text ltx_font_bold">V</span>ideo-to-<span id="S3.p1.1.2" class="ltx_text ltx_font_bold">A</span>udio A<span id="S3.p1.1.3" class="ltx_text ltx_font_bold">u</span>to<span id="S3.p1.1.4" class="ltx_text ltx_font_bold">r</span>egressive Fr<span id="S3.p1.1.5" class="ltx_text ltx_font_bold">a</span>mework), generates semantically and temporally aligned audio given a visual stream by predicting audio tokens encoded with a high-fidelity neural audio codec.
First, we extract fine-grained visual and motion features from an input video and temporally upsample them to match the temporal dimension of the audio.
Then, the temporally aligned audio and visual features are fused to emphasize the natural co-occurrence of audio and video.
Given the cross-modal feature embedding, our autoregressive model predicts the next audio token. Once the sequence reaches the desired length, it is decoded into a waveform representation.
We train our model on the VisualSound dataset, which is curated to ensure strong audio-visual relevance.
The dataset is introduced in <a href="#S4" title="IV VisualSound Dataset ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Visual Encoder</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Video-to-audio generation requires not only global but also fine-grained visual and motion information.
It is not enough to detect playing tennis in the scene; the action of the racket hitting the ball must also be caught to generate relevant audio.
To extract subtle high-framerate visual features with strong audio-visual temporal cues, we rely on Segment AVCLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
This enables our model to capture more immediate visual events with a visual framerate of 25 FPS, which is more than 6 times higher than state-of-the-art models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
Following the natural co-occurrence of audio and video, we align the visual features temporally with the auditory ones, enabling our model to generate more temporally aligned audio.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.8" class="ltx_p"><span id="S3.SS1.p2.8.1" class="ltx_text ltx_font_bold">Visual embeddings.</span>
Segment AVCLIP employs TimeSformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> as its visual feature extractor (<math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="M_{v}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">M</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝑀</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">M_{v}</annotation></semantics></math>).
It is pretrained contrastively with audio on a sub-clip level to extract fine-grained motion features from visual events <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
We also experimented with action recognition models, such as S3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, and ImageNet pre-trained models, such as ResNet-50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.
However, these feature extractors did not yield temporally-aligned or high-fidelity results.
Our visual encoder <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="M_{v}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">M</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝑀</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">M_{v}</annotation></semantics></math> transforms a visual stream <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="V\in\mathbb{R}^{T_{v}\times H\times W\times 3}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">V</mi><mo id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml"><mi id="S3.SS1.p2.3.m3.1.1.3.2" xref="S3.SS1.p2.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p2.3.m3.1.1.3.3" xref="S3.SS1.p2.3.m3.1.1.3.3.cmml"><msub id="S3.SS1.p2.3.m3.1.1.3.3.2" xref="S3.SS1.p2.3.m3.1.1.3.3.2.cmml"><mi id="S3.SS1.p2.3.m3.1.1.3.3.2.2" xref="S3.SS1.p2.3.m3.1.1.3.3.2.2.cmml">T</mi><mi id="S3.SS1.p2.3.m3.1.1.3.3.2.3" xref="S3.SS1.p2.3.m3.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.3.m3.1.1.3.3.1" xref="S3.SS1.p2.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p2.3.m3.1.1.3.3.3" xref="S3.SS1.p2.3.m3.1.1.3.3.3.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.3.m3.1.1.3.3.1a" xref="S3.SS1.p2.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p2.3.m3.1.1.3.3.4" xref="S3.SS1.p2.3.m3.1.1.3.3.4.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.3.m3.1.1.3.3.1b" xref="S3.SS1.p2.3.m3.1.1.3.3.1.cmml">×</mo><mn id="S3.SS1.p2.3.m3.1.1.3.3.5" xref="S3.SS1.p2.3.m3.1.1.3.3.5.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><in id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"></in><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝑉</ci><apply id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.3.2.cmml" xref="S3.SS1.p2.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS1.p2.3.m3.1.1.3.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3"><times id="S3.SS1.p2.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3.1"></times><apply id="S3.SS1.p2.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3.2.2">𝑇</ci><ci id="S3.SS1.p2.3.m3.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3.2.3">𝑣</ci></apply><ci id="S3.SS1.p2.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3.3">𝐻</ci><ci id="S3.SS1.p2.3.m3.1.1.3.3.4.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3.4">𝑊</ci><cn type="integer" id="S3.SS1.p2.3.m3.1.1.3.3.5.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3.5">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">V\in\mathbb{R}^{T_{v}\times H\times W\times 3}</annotation></semantics></math>, (<math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="T_{v}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">T</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝑇</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">T_{v}</annotation></semantics></math> is frame count, <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">H</annotation></semantics></math> is height, <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">W</annotation></semantics></math> is width, and 3 is RGB color channels), into a visual feature map which is projected into visual feature embeddings <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="\tilde{x}_{v}\in\mathbb{R}^{t_{v}\times d_{v}}" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mrow id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><msub id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml"><mover accent="true" id="S3.SS1.p2.7.m7.1.1.2.2" xref="S3.SS1.p2.7.m7.1.1.2.2.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2.2.2" xref="S3.SS1.p2.7.m7.1.1.2.2.2.cmml">x</mi><mo id="S3.SS1.p2.7.m7.1.1.2.2.1" xref="S3.SS1.p2.7.m7.1.1.2.2.1.cmml">~</mo></mover><mi id="S3.SS1.p2.7.m7.1.1.2.3" xref="S3.SS1.p2.7.m7.1.1.2.3.cmml">v</mi></msub><mo id="S3.SS1.p2.7.m7.1.1.1" xref="S3.SS1.p2.7.m7.1.1.1.cmml">∈</mo><msup id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml"><mi id="S3.SS1.p2.7.m7.1.1.3.2" xref="S3.SS1.p2.7.m7.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p2.7.m7.1.1.3.3" xref="S3.SS1.p2.7.m7.1.1.3.3.cmml"><msub id="S3.SS1.p2.7.m7.1.1.3.3.2" xref="S3.SS1.p2.7.m7.1.1.3.3.2.cmml"><mi id="S3.SS1.p2.7.m7.1.1.3.3.2.2" xref="S3.SS1.p2.7.m7.1.1.3.3.2.2.cmml">t</mi><mi id="S3.SS1.p2.7.m7.1.1.3.3.2.3" xref="S3.SS1.p2.7.m7.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.7.m7.1.1.3.3.1" xref="S3.SS1.p2.7.m7.1.1.3.3.1.cmml">×</mo><msub id="S3.SS1.p2.7.m7.1.1.3.3.3" xref="S3.SS1.p2.7.m7.1.1.3.3.3.cmml"><mi id="S3.SS1.p2.7.m7.1.1.3.3.3.2" xref="S3.SS1.p2.7.m7.1.1.3.3.3.2.cmml">d</mi><mi id="S3.SS1.p2.7.m7.1.1.3.3.3.3" xref="S3.SS1.p2.7.m7.1.1.3.3.3.3.cmml">v</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><in id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1.1"></in><apply id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.2.1.cmml" xref="S3.SS1.p2.7.m7.1.1.2">subscript</csymbol><apply id="S3.SS1.p2.7.m7.1.1.2.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2.2"><ci id="S3.SS1.p2.7.m7.1.1.2.2.1.cmml" xref="S3.SS1.p2.7.m7.1.1.2.2.1">~</ci><ci id="S3.SS1.p2.7.m7.1.1.2.2.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2.2.2">𝑥</ci></apply><ci id="S3.SS1.p2.7.m7.1.1.2.3.cmml" xref="S3.SS1.p2.7.m7.1.1.2.3">𝑣</ci></apply><apply id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.3.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.3.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.2">ℝ</ci><apply id="S3.SS1.p2.7.m7.1.1.3.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3"><times id="S3.SS1.p2.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.1"></times><apply id="S3.SS1.p2.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.3.3.2.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.3.3.2.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2.2">𝑡</ci><ci id="S3.SS1.p2.7.m7.1.1.3.3.2.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2.3">𝑣</ci></apply><apply id="S3.SS1.p2.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.3.3.3.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.3.3.3.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.3.2">𝑑</ci><ci id="S3.SS1.p2.7.m7.1.1.3.3.3.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.3.3">𝑣</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">\tilde{x}_{v}\in\mathbb{R}^{t_{v}\times d_{v}}</annotation></semantics></math> with a two-layer MLP separated by a GELU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> non-linearity.
Adding the trainable projection improves training efficiency by keeping the weights of the heavy feature extractor <math id="S3.SS1.p2.8.m8.1" class="ltx_Math" alttext="M_{v}" display="inline"><semantics id="S3.SS1.p2.8.m8.1a"><msub id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml"><mi id="S3.SS1.p2.8.m8.1.1.2" xref="S3.SS1.p2.8.m8.1.1.2.cmml">M</mi><mi id="S3.SS1.p2.8.m8.1.1.3" xref="S3.SS1.p2.8.m8.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><apply id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.2">𝑀</ci><ci id="S3.SS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">M_{v}</annotation></semantics></math> fixed.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.4" class="ltx_p"><span id="S3.SS1.p3.4.1" class="ltx_text ltx_font_bold">Temporal alignment of visual embeddings.</span>
Our initial experiments showed that conditioning the autoregressive model by prompting the audio token sequence with visual tokens results in a poor temporal alignment, which is consistent with prior results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Instead, we enforce the natural co-occurrence of audio and visual cues by temporally aligning them on a token level.
The visual embeddings <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\tilde{x}_{v}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mover accent="true" id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2.2" xref="S3.SS1.p3.1.m1.1.1.2.2.cmml">x</mi><mo id="S3.SS1.p3.1.m1.1.1.2.1" xref="S3.SS1.p3.1.m1.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><apply id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2"><ci id="S3.SS1.p3.1.m1.1.1.2.1.cmml" xref="S3.SS1.p3.1.m1.1.1.2.1">~</ci><ci id="S3.SS1.p3.1.m1.1.1.2.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2.2">𝑥</ci></apply><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\tilde{x}_{v}</annotation></semantics></math> are duplicated temporally to match the temporal dimension of audio tokens (<math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="t_{a}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">t</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">𝑡</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">t_{a}</annotation></semantics></math>), yielding a sequence <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="x_{v}\in\mathbb{R}^{t_{a}\times d_{v}}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mrow id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><msub id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2.2" xref="S3.SS1.p3.3.m3.1.1.2.2.cmml">x</mi><mi id="S3.SS1.p3.3.m3.1.1.2.3" xref="S3.SS1.p3.3.m3.1.1.2.3.cmml">v</mi></msub><mo id="S3.SS1.p3.3.m3.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml"><mi id="S3.SS1.p3.3.m3.1.1.3.2" xref="S3.SS1.p3.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p3.3.m3.1.1.3.3" xref="S3.SS1.p3.3.m3.1.1.3.3.cmml"><msub id="S3.SS1.p3.3.m3.1.1.3.3.2" xref="S3.SS1.p3.3.m3.1.1.3.3.2.cmml"><mi id="S3.SS1.p3.3.m3.1.1.3.3.2.2" xref="S3.SS1.p3.3.m3.1.1.3.3.2.2.cmml">t</mi><mi id="S3.SS1.p3.3.m3.1.1.3.3.2.3" xref="S3.SS1.p3.3.m3.1.1.3.3.2.3.cmml">a</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.3.m3.1.1.3.3.1" xref="S3.SS1.p3.3.m3.1.1.3.3.1.cmml">×</mo><msub id="S3.SS1.p3.3.m3.1.1.3.3.3" xref="S3.SS1.p3.3.m3.1.1.3.3.3.cmml"><mi id="S3.SS1.p3.3.m3.1.1.3.3.3.2" xref="S3.SS1.p3.3.m3.1.1.3.3.3.2.cmml">d</mi><mi id="S3.SS1.p3.3.m3.1.1.3.3.3.3" xref="S3.SS1.p3.3.m3.1.1.3.3.3.3.cmml">v</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><in id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1"></in><apply id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.2.1.cmml" xref="S3.SS1.p3.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2.2">𝑥</ci><ci id="S3.SS1.p3.3.m3.1.1.2.3.cmml" xref="S3.SS1.p3.3.m3.1.1.2.3">𝑣</ci></apply><apply id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS1.p3.3.m3.1.1.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3"><times id="S3.SS1.p3.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.1"></times><apply id="S3.SS1.p3.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.3.3.2.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.3.3.2.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.2.2">𝑡</ci><ci id="S3.SS1.p3.3.m3.1.1.3.3.2.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.2.3">𝑎</ci></apply><apply id="S3.SS1.p3.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.3.3.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.3.3.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.3.2">𝑑</ci><ci id="S3.SS1.p3.3.m3.1.1.3.3.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3.3.3.3">𝑣</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">x_{v}\in\mathbb{R}^{t_{a}\times d_{v}}</annotation></semantics></math>.
If <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="t_{a}/t_{v}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><mrow id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><msub id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2.2" xref="S3.SS1.p3.4.m4.1.1.2.2.cmml">t</mi><mi id="S3.SS1.p3.4.m4.1.1.2.3" xref="S3.SS1.p3.4.m4.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS1.p3.4.m4.1.1.1" xref="S3.SS1.p3.4.m4.1.1.1.cmml">/</mo><msub id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml"><mi id="S3.SS1.p3.4.m4.1.1.3.2" xref="S3.SS1.p3.4.m4.1.1.3.2.cmml">t</mi><mi id="S3.SS1.p3.4.m4.1.1.3.3" xref="S3.SS1.p3.4.m4.1.1.3.3.cmml">v</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><divide id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1.1"></divide><apply id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.2.1.cmml" xref="S3.SS1.p3.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2.2">𝑡</ci><ci id="S3.SS1.p3.4.m4.1.1.2.3.cmml" xref="S3.SS1.p3.4.m4.1.1.2.3">𝑎</ci></apply><apply id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.3.1.cmml" xref="S3.SS1.p3.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.3.2.cmml" xref="S3.SS1.p3.4.m4.1.1.3.2">𝑡</ci><ci id="S3.SS1.p3.4.m4.1.1.3.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">t_{a}/t_{v}</annotation></semantics></math> results in a non-integer, the video sequence is padded with learnable tokens to ensure the temporal dimensions match.
During inference, the model is conditioned only on past and present video frames, avoiding unnecessary visual features.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Neural Audio Codec</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We formulate the video-to-audio generation as a next token prediction problem.
To obtain the ground truth audio tokens during training, we rely on the encoder of a state-of-the-art universal audio compression model, Descript Audio Codec (DAC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
During inference, we use the decoder of DAC to transform the generated audio token sequence into the waveform representation.
We use a pretrained version of DAC which was trained on speech, music, and environmental sounds.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.10" class="ltx_p"><span id="S3.SS2.p2.10.1" class="ltx_text ltx_font_bold">Audio tokenization.</span>
The tokenizer (<math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="M_{a}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">M</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝑀</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">M_{a}</annotation></semantics></math>) transforms a waveform <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="A\in\mathbb{R}^{T_{a}}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mrow id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">A</mi><mo id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.p2.2.m2.1.1.3.2" xref="S3.SS2.p2.2.m2.1.1.3.2.cmml">ℝ</mi><msub id="S3.SS2.p2.2.m2.1.1.3.3" xref="S3.SS2.p2.2.m2.1.1.3.3.cmml"><mi id="S3.SS2.p2.2.m2.1.1.3.3.2" xref="S3.SS2.p2.2.m2.1.1.3.3.2.cmml">T</mi><mi id="S3.SS2.p2.2.m2.1.1.3.3.3" xref="S3.SS2.p2.2.m2.1.1.3.3.3.cmml">a</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><in id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1"></in><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝐴</ci><apply id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.3.2">ℝ</ci><apply id="S3.SS2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.3.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.3.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.3.3.2">𝑇</ci><ci id="S3.SS2.p2.2.m2.1.1.3.3.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3.3.3">𝑎</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">A\in\mathbb{R}^{T_{a}}</annotation></semantics></math> into discrete code representations <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\tilde{x}_{a}=M_{a}(A)" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.2" xref="S3.SS2.p2.3.m3.1.2.cmml"><msub id="S3.SS2.p2.3.m3.1.2.2" xref="S3.SS2.p2.3.m3.1.2.2.cmml"><mover accent="true" id="S3.SS2.p2.3.m3.1.2.2.2" xref="S3.SS2.p2.3.m3.1.2.2.2.cmml"><mi id="S3.SS2.p2.3.m3.1.2.2.2.2" xref="S3.SS2.p2.3.m3.1.2.2.2.2.cmml">x</mi><mo id="S3.SS2.p2.3.m3.1.2.2.2.1" xref="S3.SS2.p2.3.m3.1.2.2.2.1.cmml">~</mo></mover><mi id="S3.SS2.p2.3.m3.1.2.2.3" xref="S3.SS2.p2.3.m3.1.2.2.3.cmml">a</mi></msub><mo id="S3.SS2.p2.3.m3.1.2.1" xref="S3.SS2.p2.3.m3.1.2.1.cmml">=</mo><mrow id="S3.SS2.p2.3.m3.1.2.3" xref="S3.SS2.p2.3.m3.1.2.3.cmml"><msub id="S3.SS2.p2.3.m3.1.2.3.2" xref="S3.SS2.p2.3.m3.1.2.3.2.cmml"><mi id="S3.SS2.p2.3.m3.1.2.3.2.2" xref="S3.SS2.p2.3.m3.1.2.3.2.2.cmml">M</mi><mi id="S3.SS2.p2.3.m3.1.2.3.2.3" xref="S3.SS2.p2.3.m3.1.2.3.2.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.2.3.1" xref="S3.SS2.p2.3.m3.1.2.3.1.cmml">​</mo><mrow id="S3.SS2.p2.3.m3.1.2.3.3.2" xref="S3.SS2.p2.3.m3.1.2.3.cmml"><mo stretchy="false" id="S3.SS2.p2.3.m3.1.2.3.3.2.1" xref="S3.SS2.p2.3.m3.1.2.3.cmml">(</mo><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">A</mi><mo stretchy="false" id="S3.SS2.p2.3.m3.1.2.3.3.2.2" xref="S3.SS2.p2.3.m3.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.2.cmml" xref="S3.SS2.p2.3.m3.1.2"><eq id="S3.SS2.p2.3.m3.1.2.1.cmml" xref="S3.SS2.p2.3.m3.1.2.1"></eq><apply id="S3.SS2.p2.3.m3.1.2.2.cmml" xref="S3.SS2.p2.3.m3.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.2.2.1.cmml" xref="S3.SS2.p2.3.m3.1.2.2">subscript</csymbol><apply id="S3.SS2.p2.3.m3.1.2.2.2.cmml" xref="S3.SS2.p2.3.m3.1.2.2.2"><ci id="S3.SS2.p2.3.m3.1.2.2.2.1.cmml" xref="S3.SS2.p2.3.m3.1.2.2.2.1">~</ci><ci id="S3.SS2.p2.3.m3.1.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.1.2.2.2.2">𝑥</ci></apply><ci id="S3.SS2.p2.3.m3.1.2.2.3.cmml" xref="S3.SS2.p2.3.m3.1.2.2.3">𝑎</ci></apply><apply id="S3.SS2.p2.3.m3.1.2.3.cmml" xref="S3.SS2.p2.3.m3.1.2.3"><times id="S3.SS2.p2.3.m3.1.2.3.1.cmml" xref="S3.SS2.p2.3.m3.1.2.3.1"></times><apply id="S3.SS2.p2.3.m3.1.2.3.2.cmml" xref="S3.SS2.p2.3.m3.1.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.2.3.2.1.cmml" xref="S3.SS2.p2.3.m3.1.2.3.2">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.2.3.2.2.cmml" xref="S3.SS2.p2.3.m3.1.2.3.2.2">𝑀</ci><ci id="S3.SS2.p2.3.m3.1.2.3.2.3.cmml" xref="S3.SS2.p2.3.m3.1.2.3.2.3">𝑎</ci></apply><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\tilde{x}_{a}=M_{a}(A)</annotation></semantics></math>, where <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\tilde{x}_{a}\in\mathbb{R}^{t_{a}\times N_{q}}" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mrow id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><msub id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml"><mover accent="true" id="S3.SS2.p2.4.m4.1.1.2.2" xref="S3.SS2.p2.4.m4.1.1.2.2.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2.2.2" xref="S3.SS2.p2.4.m4.1.1.2.2.2.cmml">x</mi><mo id="S3.SS2.p2.4.m4.1.1.2.2.1" xref="S3.SS2.p2.4.m4.1.1.2.2.1.cmml">~</mo></mover><mi id="S3.SS2.p2.4.m4.1.1.2.3" xref="S3.SS2.p2.4.m4.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml"><mi id="S3.SS2.p2.4.m4.1.1.3.2" xref="S3.SS2.p2.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p2.4.m4.1.1.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.cmml"><msub id="S3.SS2.p2.4.m4.1.1.3.3.2" xref="S3.SS2.p2.4.m4.1.1.3.3.2.cmml"><mi id="S3.SS2.p2.4.m4.1.1.3.3.2.2" xref="S3.SS2.p2.4.m4.1.1.3.3.2.2.cmml">t</mi><mi id="S3.SS2.p2.4.m4.1.1.3.3.2.3" xref="S3.SS2.p2.4.m4.1.1.3.3.2.3.cmml">a</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.4.m4.1.1.3.3.1" xref="S3.SS2.p2.4.m4.1.1.3.3.1.cmml">×</mo><msub id="S3.SS2.p2.4.m4.1.1.3.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.3.cmml"><mi id="S3.SS2.p2.4.m4.1.1.3.3.3.2" xref="S3.SS2.p2.4.m4.1.1.3.3.3.2.cmml">N</mi><mi id="S3.SS2.p2.4.m4.1.1.3.3.3.3" xref="S3.SS2.p2.4.m4.1.1.3.3.3.3.cmml">q</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><in id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1"></in><apply id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.2.1.cmml" xref="S3.SS2.p2.4.m4.1.1.2">subscript</csymbol><apply id="S3.SS2.p2.4.m4.1.1.2.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2.2"><ci id="S3.SS2.p2.4.m4.1.1.2.2.1.cmml" xref="S3.SS2.p2.4.m4.1.1.2.2.1">~</ci><ci id="S3.SS2.p2.4.m4.1.1.2.2.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2.2.2">𝑥</ci></apply><ci id="S3.SS2.p2.4.m4.1.1.2.3.cmml" xref="S3.SS2.p2.4.m4.1.1.2.3">𝑎</ci></apply><apply id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2">ℝ</ci><apply id="S3.SS2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3"><times id="S3.SS2.p2.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.1"></times><apply id="S3.SS2.p2.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.3.3.2.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.3.3.2.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.2.2">𝑡</ci><ci id="S3.SS2.p2.4.m4.1.1.3.3.2.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.2.3">𝑎</ci></apply><apply id="S3.SS2.p2.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.3.3.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.3.3.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.3.2">𝑁</ci><ci id="S3.SS2.p2.4.m4.1.1.3.3.3.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3.3.3.3">𝑞</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\tilde{x}_{a}\in\mathbb{R}^{t_{a}\times N_{q}}</annotation></semantics></math> (<math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="N_{q}" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><msub id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">N</mi><mi id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">𝑁</ci><ci id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">N_{q}</annotation></semantics></math> is the number of residual vector quantization (RVQ) levels and <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="t_{a}" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><msub id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml">t</mi><mi id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2">𝑡</ci><ci id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">t_{a}</annotation></semantics></math> (<math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="\ll T_{a}" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><mrow id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><mi id="S3.SS2.p2.7.m7.1.1.2" xref="S3.SS2.p2.7.m7.1.1.2.cmml"></mi><mo id="S3.SS2.p2.7.m7.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.cmml">≪</mo><msub id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml"><mi id="S3.SS2.p2.7.m7.1.1.3.2" xref="S3.SS2.p2.7.m7.1.1.3.2.cmml">T</mi><mi id="S3.SS2.p2.7.m7.1.1.3.3" xref="S3.SS2.p2.7.m7.1.1.3.3.cmml">a</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><csymbol cd="latexml" id="S3.SS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1">much-less-than</csymbol><csymbol cd="latexml" id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2">absent</csymbol><apply id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.3.1.cmml" xref="S3.SS2.p2.7.m7.1.1.3">subscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.3.2.cmml" xref="S3.SS2.p2.7.m7.1.1.3.2">𝑇</ci><ci id="S3.SS2.p2.7.m7.1.1.3.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3.3">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">\ll T_{a}</annotation></semantics></math>) is the downsampled temporal dimension).
We use a pretrained model with <math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="N_{q}=9" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><mrow id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml"><msub id="S3.SS2.p2.8.m8.1.1.2" xref="S3.SS2.p2.8.m8.1.1.2.cmml"><mi id="S3.SS2.p2.8.m8.1.1.2.2" xref="S3.SS2.p2.8.m8.1.1.2.2.cmml">N</mi><mi id="S3.SS2.p2.8.m8.1.1.2.3" xref="S3.SS2.p2.8.m8.1.1.2.3.cmml">q</mi></msub><mo id="S3.SS2.p2.8.m8.1.1.1" xref="S3.SS2.p2.8.m8.1.1.1.cmml">=</mo><mn id="S3.SS2.p2.8.m8.1.1.3" xref="S3.SS2.p2.8.m8.1.1.3.cmml">9</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><apply id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><eq id="S3.SS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1.1"></eq><apply id="S3.SS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.2.1.cmml" xref="S3.SS2.p2.8.m8.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.8.m8.1.1.2.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2.2">𝑁</ci><ci id="S3.SS2.p2.8.m8.1.1.2.3.cmml" xref="S3.SS2.p2.8.m8.1.1.2.3">𝑞</ci></apply><cn type="integer" id="S3.SS2.p2.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3">9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">N_{q}=9</annotation></semantics></math> and do not update the weights during training.
Following advances in music generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, we apply a delay pattern where each residual level is delayed by adding one more special learnable token at the beginning of the sequence compared to the previous level, as shown with the blocks <math id="S3.SS2.p2.9.m9.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.SS2.p2.9.m9.1a"><mi id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><ci id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">P</annotation></semantics></math> in <a href="#S2.F1" title="In II Related Work ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>.
Since we predict codes across all <math id="S3.SS2.p2.10.m10.1" class="ltx_Math" alttext="N_{q}" display="inline"><semantics id="S3.SS2.p2.10.m10.1a"><msub id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml"><mi id="S3.SS2.p2.10.m10.1.1.2" xref="S3.SS2.p2.10.m10.1.1.2.cmml">N</mi><mi id="S3.SS2.p2.10.m10.1.1.3" xref="S3.SS2.p2.10.m10.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><apply id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.1.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS2.p2.10.m10.1.1.2.cmml" xref="S3.SS2.p2.10.m10.1.1.2">𝑁</ci><ci id="S3.SS2.p2.10.m10.1.1.3.cmml" xref="S3.SS2.p2.10.m10.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">N_{q}</annotation></semantics></math> codebooks at each timestep, delaying each residual level provides the model with information about the token in the preceding residual level at that same timestep.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.6" class="ltx_p"><span id="S3.SS2.p3.6.1" class="ltx_text ltx_font_bold">Audio embeddings.</span>
Audio tokens from all <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="N_{q}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">N</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝑁</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">N_{q}</annotation></semantics></math> RVQ-levels (<math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\tilde{x}_{a}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mover accent="true" id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2.2" xref="S3.SS2.p3.2.m2.1.1.2.2.cmml">x</mi><mo id="S3.SS2.p3.2.m2.1.1.2.1" xref="S3.SS2.p3.2.m2.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2"><ci id="S3.SS2.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1.2.1">~</ci><ci id="S3.SS2.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2.2">𝑥</ci></apply><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\tilde{x}_{a}</annotation></semantics></math>) are embedded with level-specific learned embedding tables (<math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="E_{i}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">E</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">𝐸</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">E_{i}</annotation></semantics></math>) and summed to represent the full-band composition of the original signal <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>: <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="x_{a}=\sum_{i=1}^{N_{q}}E_{i}(\tilde{x}_{a}^{i})" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mrow id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><msub id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.3.2" xref="S3.SS2.p3.4.m4.1.1.3.2.cmml">x</mi><mi id="S3.SS2.p3.4.m4.1.1.3.3" xref="S3.SS2.p3.4.m4.1.1.3.3.cmml">a</mi></msub><mo rspace="0.111em" id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">=</mo><mrow id="S3.SS2.p3.4.m4.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.cmml"><msubsup id="S3.SS2.p3.4.m4.1.1.1.2" xref="S3.SS2.p3.4.m4.1.1.1.2.cmml"><mo id="S3.SS2.p3.4.m4.1.1.1.2.2.2" xref="S3.SS2.p3.4.m4.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.SS2.p3.4.m4.1.1.1.2.2.3" xref="S3.SS2.p3.4.m4.1.1.1.2.2.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.1.2.2.3.2" xref="S3.SS2.p3.4.m4.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.SS2.p3.4.m4.1.1.1.2.2.3.1" xref="S3.SS2.p3.4.m4.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.SS2.p3.4.m4.1.1.1.2.2.3.3" xref="S3.SS2.p3.4.m4.1.1.1.2.2.3.3.cmml">1</mn></mrow><msub id="S3.SS2.p3.4.m4.1.1.1.2.3" xref="S3.SS2.p3.4.m4.1.1.1.2.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.1.2.3.2" xref="S3.SS2.p3.4.m4.1.1.1.2.3.2.cmml">N</mi><mi id="S3.SS2.p3.4.m4.1.1.1.2.3.3" xref="S3.SS2.p3.4.m4.1.1.1.2.3.3.cmml">q</mi></msub></msubsup><mrow id="S3.SS2.p3.4.m4.1.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.1.cmml"><msub id="S3.SS2.p3.4.m4.1.1.1.1.3" xref="S3.SS2.p3.4.m4.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.1.1.3.2" xref="S3.SS2.p3.4.m4.1.1.1.1.3.2.cmml">E</mi><mi id="S3.SS2.p3.4.m4.1.1.1.1.3.3" xref="S3.SS2.p3.4.m4.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.1.1.1.1.2" xref="S3.SS2.p3.4.m4.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS2.p3.4.m4.1.1.1.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m4.1.1.1.1.1.1.2" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.2" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.2.cmml">x</mi><mo id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.1" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.1.cmml">~</mo></mover><mi id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.3" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.3.cmml">a</mi><mi id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.3" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S3.SS2.p3.4.m4.1.1.1.1.1.1.3" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><eq id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2"></eq><apply id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.3.2">𝑥</ci><ci id="S3.SS2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3.3">𝑎</ci></apply><apply id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1"><apply id="S3.SS2.p3.4.m4.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.2.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2">superscript</csymbol><apply id="S3.SS2.p3.4.m4.1.1.1.2.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.2.2.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2">subscript</csymbol><sum id="S3.SS2.p3.4.m4.1.1.1.2.2.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.2.2"></sum><apply id="S3.SS2.p3.4.m4.1.1.1.2.2.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.2.3"><eq id="S3.SS2.p3.4.m4.1.1.1.2.2.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.2.3.1"></eq><ci id="S3.SS2.p3.4.m4.1.1.1.2.2.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.SS2.p3.4.m4.1.1.1.2.2.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.2.3.3">1</cn></apply></apply><apply id="S3.SS2.p3.4.m4.1.1.1.2.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.2.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.3">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.1.2.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.3.2">𝑁</ci><ci id="S3.SS2.p3.4.m4.1.1.1.2.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.2.3.3">𝑞</ci></apply></apply><apply id="S3.SS2.p3.4.m4.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1"><times id="S3.SS2.p3.4.m4.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.2"></times><apply id="S3.SS2.p3.4.m4.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.3.2">𝐸</ci><ci id="S3.SS2.p3.4.m4.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.3.3">𝑖</ci></apply><apply id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1">subscript</csymbol><apply id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2"><ci id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.1">~</ci><ci id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.2.2">𝑥</ci></apply><ci id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.2.3">𝑎</ci></apply><ci id="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">x_{a}=\sum_{i=1}^{N_{q}}E_{i}(\tilde{x}_{a}^{i})</annotation></semantics></math>, where <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="x_{a}\in\mathbb{R}^{t_{a}\times d_{a}}" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mrow id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><msub id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2.2" xref="S3.SS2.p3.5.m5.1.1.2.2.cmml">x</mi><mi id="S3.SS2.p3.5.m5.1.1.2.3" xref="S3.SS2.p3.5.m5.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS2.p3.5.m5.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.cmml">∈</mo><msup id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3.2" xref="S3.SS2.p3.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p3.5.m5.1.1.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.cmml"><msub id="S3.SS2.p3.5.m5.1.1.3.3.2" xref="S3.SS2.p3.5.m5.1.1.3.3.2.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3.3.2.2" xref="S3.SS2.p3.5.m5.1.1.3.3.2.2.cmml">t</mi><mi id="S3.SS2.p3.5.m5.1.1.3.3.2.3" xref="S3.SS2.p3.5.m5.1.1.3.3.2.3.cmml">a</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.5.m5.1.1.3.3.1" xref="S3.SS2.p3.5.m5.1.1.3.3.1.cmml">×</mo><msub id="S3.SS2.p3.5.m5.1.1.3.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.3.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3.3.3.2" xref="S3.SS2.p3.5.m5.1.1.3.3.3.2.cmml">d</mi><mi id="S3.SS2.p3.5.m5.1.1.3.3.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.3.3.cmml">a</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><in id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1"></in><apply id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.2.1.cmml" xref="S3.SS2.p3.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2.2">𝑥</ci><ci id="S3.SS2.p3.5.m5.1.1.2.3.cmml" xref="S3.SS2.p3.5.m5.1.1.2.3">𝑎</ci></apply><apply id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.2">ℝ</ci><apply id="S3.SS2.p3.5.m5.1.1.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3"><times id="S3.SS2.p3.5.m5.1.1.3.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.1"></times><apply id="S3.SS2.p3.5.m5.1.1.3.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.3.3.2.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.3.3.2.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.2.2">𝑡</ci><ci id="S3.SS2.p3.5.m5.1.1.3.3.2.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.2.3">𝑎</ci></apply><apply id="S3.SS2.p3.5.m5.1.1.3.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.3.3.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.3.3.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.3.2">𝑑</ci><ci id="S3.SS2.p3.5.m5.1.1.3.3.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3.3.3">𝑎</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">x_{a}\in\mathbb{R}^{t_{a}\times d_{a}}</annotation></semantics></math>, and <math id="S3.SS2.p3.6.m6.2" class="ltx_Math" alttext="t_{a},d_{a}" display="inline"><semantics id="S3.SS2.p3.6.m6.2a"><mrow id="S3.SS2.p3.6.m6.2.2.2" xref="S3.SS2.p3.6.m6.2.2.3.cmml"><msub id="S3.SS2.p3.6.m6.1.1.1.1" xref="S3.SS2.p3.6.m6.1.1.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.1.1.2" xref="S3.SS2.p3.6.m6.1.1.1.1.2.cmml">t</mi><mi id="S3.SS2.p3.6.m6.1.1.1.1.3" xref="S3.SS2.p3.6.m6.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.SS2.p3.6.m6.2.2.2.3" xref="S3.SS2.p3.6.m6.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.6.m6.2.2.2.2" xref="S3.SS2.p3.6.m6.2.2.2.2.cmml"><mi id="S3.SS2.p3.6.m6.2.2.2.2.2" xref="S3.SS2.p3.6.m6.2.2.2.2.2.cmml">d</mi><mi id="S3.SS2.p3.6.m6.2.2.2.2.3" xref="S3.SS2.p3.6.m6.2.2.2.2.3.cmml">a</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.2b"><list id="S3.SS2.p3.6.m6.2.2.3.cmml" xref="S3.SS2.p3.6.m6.2.2.2"><apply id="S3.SS2.p3.6.m6.1.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.1.1.2">𝑡</ci><ci id="S3.SS2.p3.6.m6.1.1.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.1.1.3">𝑎</ci></apply><apply id="S3.SS2.p3.6.m6.2.2.2.2.cmml" xref="S3.SS2.p3.6.m6.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.2.2.2.2.1.cmml" xref="S3.SS2.p3.6.m6.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.6.m6.2.2.2.2.2.cmml" xref="S3.SS2.p3.6.m6.2.2.2.2.2">𝑑</ci><ci id="S3.SS2.p3.6.m6.2.2.2.2.3.cmml" xref="S3.SS2.p3.6.m6.2.2.2.2.3">𝑎</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.2c">t_{a},d_{a}</annotation></semantics></math> are the temporal and latent dimensions.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Autoregressive Generative Model</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The proposed autoregressive generative model takes temporally aligned visual and audio embeddings, fuses them into a cross-modal embedding sequence, and predicts the next audio tokens across all the <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="N_{q}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">N</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑁</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">N_{q}</annotation></semantics></math> codebooks.
After generating all the audio tokens, the token sequence is decoded back to a waveform representation.
During sampling, we employ Classifier-Free Guidance (CFG) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> for enhanced generation quality.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Cross-modal feature fusion.</span>
Drawing on the success of induced alignment between the condition and the generated tokens in non-autoregressive models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, we fuse the audio and visual embeddings into joint audio-visual embeddings via channel-wise concatenation: <math id="S3.SS3.p2.1.m1.3" class="ltx_Math" alttext="x_{av}=\text{concat}_{c}(x_{a},x_{v})\in\mathbb{R}^{t_{a}\times(d_{a}+d_{v})}" display="inline"><semantics id="S3.SS3.p2.1.m1.3a"><mrow id="S3.SS3.p2.1.m1.3.3" xref="S3.SS3.p2.1.m1.3.3.cmml"><msub id="S3.SS3.p2.1.m1.3.3.4" xref="S3.SS3.p2.1.m1.3.3.4.cmml"><mi id="S3.SS3.p2.1.m1.3.3.4.2" xref="S3.SS3.p2.1.m1.3.3.4.2.cmml">x</mi><mrow id="S3.SS3.p2.1.m1.3.3.4.3" xref="S3.SS3.p2.1.m1.3.3.4.3.cmml"><mi id="S3.SS3.p2.1.m1.3.3.4.3.2" xref="S3.SS3.p2.1.m1.3.3.4.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.3.3.4.3.1" xref="S3.SS3.p2.1.m1.3.3.4.3.1.cmml">​</mo><mi id="S3.SS3.p2.1.m1.3.3.4.3.3" xref="S3.SS3.p2.1.m1.3.3.4.3.3.cmml">v</mi></mrow></msub><mo id="S3.SS3.p2.1.m1.3.3.5" xref="S3.SS3.p2.1.m1.3.3.5.cmml">=</mo><mrow id="S3.SS3.p2.1.m1.3.3.2" xref="S3.SS3.p2.1.m1.3.3.2.cmml"><msub id="S3.SS3.p2.1.m1.3.3.2.4" xref="S3.SS3.p2.1.m1.3.3.2.4.cmml"><mtext id="S3.SS3.p2.1.m1.3.3.2.4.2" xref="S3.SS3.p2.1.m1.3.3.2.4.2a.cmml">concat</mtext><mi id="S3.SS3.p2.1.m1.3.3.2.4.3" xref="S3.SS3.p2.1.m1.3.3.2.4.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.3.3.2.3" xref="S3.SS3.p2.1.m1.3.3.2.3.cmml">​</mo><mrow id="S3.SS3.p2.1.m1.3.3.2.2.2" xref="S3.SS3.p2.1.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p2.1.m1.3.3.2.2.2.3" xref="S3.SS3.p2.1.m1.3.3.2.2.3.cmml">(</mo><msub id="S3.SS3.p2.1.m1.2.2.1.1.1.1" xref="S3.SS3.p2.1.m1.2.2.1.1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.2.2.1.1.1.1.2" xref="S3.SS3.p2.1.m1.2.2.1.1.1.1.2.cmml">x</mi><mi id="S3.SS3.p2.1.m1.2.2.1.1.1.1.3" xref="S3.SS3.p2.1.m1.2.2.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.SS3.p2.1.m1.3.3.2.2.2.4" xref="S3.SS3.p2.1.m1.3.3.2.2.3.cmml">,</mo><msub id="S3.SS3.p2.1.m1.3.3.2.2.2.2" xref="S3.SS3.p2.1.m1.3.3.2.2.2.2.cmml"><mi id="S3.SS3.p2.1.m1.3.3.2.2.2.2.2" xref="S3.SS3.p2.1.m1.3.3.2.2.2.2.2.cmml">x</mi><mi id="S3.SS3.p2.1.m1.3.3.2.2.2.2.3" xref="S3.SS3.p2.1.m1.3.3.2.2.2.2.3.cmml">v</mi></msub><mo stretchy="false" id="S3.SS3.p2.1.m1.3.3.2.2.2.5" xref="S3.SS3.p2.1.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p2.1.m1.3.3.6" xref="S3.SS3.p2.1.m1.3.3.6.cmml">∈</mo><msup id="S3.SS3.p2.1.m1.3.3.7" xref="S3.SS3.p2.1.m1.3.3.7.cmml"><mi id="S3.SS3.p2.1.m1.3.3.7.2" xref="S3.SS3.p2.1.m1.3.3.7.2.cmml">ℝ</mi><mrow id="S3.SS3.p2.1.m1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.cmml"><msub id="S3.SS3.p2.1.m1.1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.1.3.2.cmml">t</mi><mi id="S3.SS3.p2.1.m1.1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.1.3.3.cmml">a</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.1.m1.1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.1.2.cmml">×</mo><mrow id="S3.SS3.p2.1.m1.1.1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p2.1.m1.1.1.1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p2.1.m1.1.1.1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.cmml"><msub id="S3.SS3.p2.1.m1.1.1.1.1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.2" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.2.cmml">d</mi><mi id="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.3" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.3.cmml">a</mi></msub><mo id="S3.SS3.p2.1.m1.1.1.1.1.1.1.1" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.1.cmml">+</mo><msub id="S3.SS3.p2.1.m1.1.1.1.1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.2.cmml">d</mi><mi id="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.3.cmml">v</mi></msub></mrow><mo stretchy="false" id="S3.SS3.p2.1.m1.1.1.1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.3b"><apply id="S3.SS3.p2.1.m1.3.3.cmml" xref="S3.SS3.p2.1.m1.3.3"><and id="S3.SS3.p2.1.m1.3.3a.cmml" xref="S3.SS3.p2.1.m1.3.3"></and><apply id="S3.SS3.p2.1.m1.3.3b.cmml" xref="S3.SS3.p2.1.m1.3.3"><eq id="S3.SS3.p2.1.m1.3.3.5.cmml" xref="S3.SS3.p2.1.m1.3.3.5"></eq><apply id="S3.SS3.p2.1.m1.3.3.4.cmml" xref="S3.SS3.p2.1.m1.3.3.4"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.3.3.4.1.cmml" xref="S3.SS3.p2.1.m1.3.3.4">subscript</csymbol><ci id="S3.SS3.p2.1.m1.3.3.4.2.cmml" xref="S3.SS3.p2.1.m1.3.3.4.2">𝑥</ci><apply id="S3.SS3.p2.1.m1.3.3.4.3.cmml" xref="S3.SS3.p2.1.m1.3.3.4.3"><times id="S3.SS3.p2.1.m1.3.3.4.3.1.cmml" xref="S3.SS3.p2.1.m1.3.3.4.3.1"></times><ci id="S3.SS3.p2.1.m1.3.3.4.3.2.cmml" xref="S3.SS3.p2.1.m1.3.3.4.3.2">𝑎</ci><ci id="S3.SS3.p2.1.m1.3.3.4.3.3.cmml" xref="S3.SS3.p2.1.m1.3.3.4.3.3">𝑣</ci></apply></apply><apply id="S3.SS3.p2.1.m1.3.3.2.cmml" xref="S3.SS3.p2.1.m1.3.3.2"><times id="S3.SS3.p2.1.m1.3.3.2.3.cmml" xref="S3.SS3.p2.1.m1.3.3.2.3"></times><apply id="S3.SS3.p2.1.m1.3.3.2.4.cmml" xref="S3.SS3.p2.1.m1.3.3.2.4"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.3.3.2.4.1.cmml" xref="S3.SS3.p2.1.m1.3.3.2.4">subscript</csymbol><ci id="S3.SS3.p2.1.m1.3.3.2.4.2a.cmml" xref="S3.SS3.p2.1.m1.3.3.2.4.2"><mtext id="S3.SS3.p2.1.m1.3.3.2.4.2.cmml" xref="S3.SS3.p2.1.m1.3.3.2.4.2">concat</mtext></ci><ci id="S3.SS3.p2.1.m1.3.3.2.4.3.cmml" xref="S3.SS3.p2.1.m1.3.3.2.4.3">𝑐</ci></apply><interval closure="open" id="S3.SS3.p2.1.m1.3.3.2.2.3.cmml" xref="S3.SS3.p2.1.m1.3.3.2.2.2"><apply id="S3.SS3.p2.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.2.2.1.1.1.1.2">𝑥</ci><ci id="S3.SS3.p2.1.m1.2.2.1.1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.2.2.1.1.1.1.3">𝑎</ci></apply><apply id="S3.SS3.p2.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS3.p2.1.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS3.p2.1.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.1.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS3.p2.1.m1.3.3.2.2.2.2.2">𝑥</ci><ci id="S3.SS3.p2.1.m1.3.3.2.2.2.2.3.cmml" xref="S3.SS3.p2.1.m1.3.3.2.2.2.2.3">𝑣</ci></apply></interval></apply></apply><apply id="S3.SS3.p2.1.m1.3.3c.cmml" xref="S3.SS3.p2.1.m1.3.3"><in id="S3.SS3.p2.1.m1.3.3.6.cmml" xref="S3.SS3.p2.1.m1.3.3.6"></in><share href="#S3.SS3.p2.1.m1.3.3.2.cmml" id="S3.SS3.p2.1.m1.3.3d.cmml" xref="S3.SS3.p2.1.m1.3.3"></share><apply id="S3.SS3.p2.1.m1.3.3.7.cmml" xref="S3.SS3.p2.1.m1.3.3.7"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.3.3.7.1.cmml" xref="S3.SS3.p2.1.m1.3.3.7">superscript</csymbol><ci id="S3.SS3.p2.1.m1.3.3.7.2.cmml" xref="S3.SS3.p2.1.m1.3.3.7.2">ℝ</ci><apply id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1"><times id="S3.SS3.p2.1.m1.1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.1.2"></times><apply id="S3.SS3.p2.1.m1.1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.1.3.2">𝑡</ci><ci id="S3.SS3.p2.1.m1.1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.1.3.3">𝑎</ci></apply><apply id="S3.SS3.p2.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1"><plus id="S3.SS3.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.1"></plus><apply id="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.2">𝑑</ci><ci id="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.2.3">𝑎</ci></apply><apply id="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.2">𝑑</ci><ci id="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.1.1.1.1.3.3">𝑣</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.3c">x_{av}=\text{concat}_{c}(x_{a},x_{v})\in\mathbb{R}^{t_{a}\times(d_{a}+d_{v})}</annotation></semantics></math>.
Also, since the audio sequence is padded while delaying audio tokens (see <a href="#S2.F1" title="In II Related Work ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>) and the visual is not, visual embeddings appear one timestep earlier, enabling the model to recognize the condition before generating audio.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.2" class="ltx_p"><span id="S3.SS3.p3.2.1" class="ltx_text ltx_font_bold">Architecture.</span>
V-AURA is built on top of a GPT-style decoder-only transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> with changes outlined by Llama architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
We train the model to autoregressively predict the <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="N_{q}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">N</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝑁</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">N_{q}</annotation></semantics></math> audio tokens of the next timestep given the sequence of joint audio-visual embeddings (<math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="x_{av}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">x</mi><mrow id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml"><mi id="S3.SS3.p3.2.m2.1.1.3.2" xref="S3.SS3.p3.2.m2.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.3.1" xref="S3.SS3.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p3.2.m2.1.1.3.3" xref="S3.SS3.p3.2.m2.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">𝑥</ci><apply id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3"><times id="S3.SS3.p3.2.m2.1.1.3.1.cmml" xref="S3.SS3.p3.2.m2.1.1.3.1"></times><ci id="S3.SS3.p3.2.m2.1.1.3.2.cmml" xref="S3.SS3.p3.2.m2.1.1.3.2">𝑎</ci><ci id="S3.SS3.p3.2.m2.1.1.3.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3.3">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">x_{av}</annotation></semantics></math>) accumulated by that timestep.
We employ typical cross-entropy loss.
The ground truth is obtained by tokenizing the original waveform with DAC.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.4" class="ltx_p"><span id="S3.SS3.p4.4.1" class="ltx_text ltx_font_bold">Classifier-Free Guidance (CFG).</span>
CFG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> was originally proposed for the score function estimates of the diffusion models but also applies to the autoregressive domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.
During training, the model is conditioned on real video embeddings and empty learnable embeddings 10% of the time.
At inference, sampling is done by combining conditional and unconditional probabilities: <math id="S3.SS3.p4.1.m1.17" class="ltx_Math" alttext="\gamma\log p(x_{a}^{i,j}|x_{av}^{1,1},...,x_{av}^{i,j-1})+(1-\gamma)\log p(x_{a}^{i,j}|x_{av_{0}}^{1,1},...,x_{av_{0}}^{i,j-1})" display="inline"><semantics id="S3.SS3.p4.1.m1.17a"><mrow id="S3.SS3.p4.1.m1.17.17" xref="S3.SS3.p4.1.m1.17.17.cmml"><mrow id="S3.SS3.p4.1.m1.15.15.1" xref="S3.SS3.p4.1.m1.15.15.1.cmml"><mi id="S3.SS3.p4.1.m1.15.15.1.3" xref="S3.SS3.p4.1.m1.15.15.1.3.cmml">γ</mi><mo lspace="0.167em" rspace="0em" id="S3.SS3.p4.1.m1.15.15.1.2" xref="S3.SS3.p4.1.m1.15.15.1.2.cmml">​</mo><mrow id="S3.SS3.p4.1.m1.15.15.1.4" xref="S3.SS3.p4.1.m1.15.15.1.4.cmml"><mi id="S3.SS3.p4.1.m1.15.15.1.4.1" xref="S3.SS3.p4.1.m1.15.15.1.4.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS3.p4.1.m1.15.15.1.4a" xref="S3.SS3.p4.1.m1.15.15.1.4.cmml">⁡</mo><mi id="S3.SS3.p4.1.m1.15.15.1.4.2" xref="S3.SS3.p4.1.m1.15.15.1.4.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.15.15.1.2a" xref="S3.SS3.p4.1.m1.15.15.1.2.cmml">​</mo><mrow id="S3.SS3.p4.1.m1.15.15.1.1.1" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p4.1.m1.15.15.1.1.1.2" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p4.1.m1.15.15.1.1.1.1" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.cmml"><msubsup id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.cmml"><mi id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.2" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.2.cmml">x</mi><mi id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.3" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.3.cmml">a</mi><mrow id="S3.SS3.p4.1.m1.2.2.2.4" xref="S3.SS3.p4.1.m1.2.2.2.3.cmml"><mi id="S3.SS3.p4.1.m1.1.1.1.1" xref="S3.SS3.p4.1.m1.1.1.1.1.cmml">i</mi><mo id="S3.SS3.p4.1.m1.2.2.2.4.1" xref="S3.SS3.p4.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS3.p4.1.m1.2.2.2.2" xref="S3.SS3.p4.1.m1.2.2.2.2.cmml">j</mi></mrow></msubsup><mo fence="false" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.3" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.3.cmml">|</mo><mrow id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.3.cmml"><msubsup id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.2" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.2.cmml">x</mi><mrow id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.2" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.1" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.3" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.3.cmml">v</mi></mrow><mrow id="S3.SS3.p4.1.m1.4.4.2.4" xref="S3.SS3.p4.1.m1.4.4.2.3.cmml"><mn id="S3.SS3.p4.1.m1.3.3.1.1" xref="S3.SS3.p4.1.m1.3.3.1.1.cmml">1</mn><mo id="S3.SS3.p4.1.m1.4.4.2.4.1" xref="S3.SS3.p4.1.m1.4.4.2.3.cmml">,</mo><mn id="S3.SS3.p4.1.m1.4.4.2.2" xref="S3.SS3.p4.1.m1.4.4.2.2.cmml">1</mn></mrow></msubsup><mo id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.3" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p4.1.m1.13.13" xref="S3.SS3.p4.1.m1.13.13.cmml">…</mi><mo id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.4" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.3.cmml">,</mo><msubsup id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.cmml"><mi id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.2" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.2.cmml">x</mi><mrow id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.cmml"><mi id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.2" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.1" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.1.cmml">​</mo><mi id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.3" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.3.cmml">v</mi></mrow><mrow id="S3.SS3.p4.1.m1.6.6.2.2" xref="S3.SS3.p4.1.m1.6.6.2.3.cmml"><mi id="S3.SS3.p4.1.m1.5.5.1.1" xref="S3.SS3.p4.1.m1.5.5.1.1.cmml">i</mi><mo id="S3.SS3.p4.1.m1.6.6.2.2.2" xref="S3.SS3.p4.1.m1.6.6.2.3.cmml">,</mo><mrow id="S3.SS3.p4.1.m1.6.6.2.2.1" xref="S3.SS3.p4.1.m1.6.6.2.2.1.cmml"><mi id="S3.SS3.p4.1.m1.6.6.2.2.1.2" xref="S3.SS3.p4.1.m1.6.6.2.2.1.2.cmml">j</mi><mo id="S3.SS3.p4.1.m1.6.6.2.2.1.1" xref="S3.SS3.p4.1.m1.6.6.2.2.1.1.cmml">−</mo><mn id="S3.SS3.p4.1.m1.6.6.2.2.1.3" xref="S3.SS3.p4.1.m1.6.6.2.2.1.3.cmml">1</mn></mrow></mrow></msubsup></mrow></mrow><mo stretchy="false" id="S3.SS3.p4.1.m1.15.15.1.1.1.3" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p4.1.m1.17.17.4" xref="S3.SS3.p4.1.m1.17.17.4.cmml">+</mo><mrow id="S3.SS3.p4.1.m1.17.17.3" xref="S3.SS3.p4.1.m1.17.17.3.cmml"><mrow id="S3.SS3.p4.1.m1.16.16.2.1.1" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p4.1.m1.16.16.2.1.1.2" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.cmml">(</mo><mrow id="S3.SS3.p4.1.m1.16.16.2.1.1.1" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.cmml"><mn id="S3.SS3.p4.1.m1.16.16.2.1.1.1.2" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.2.cmml">1</mn><mo id="S3.SS3.p4.1.m1.16.16.2.1.1.1.1" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.1.cmml">−</mo><mi id="S3.SS3.p4.1.m1.16.16.2.1.1.1.3" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.3.cmml">γ</mi></mrow><mo stretchy="false" id="S3.SS3.p4.1.m1.16.16.2.1.1.3" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.cmml">)</mo></mrow><mo lspace="0.167em" rspace="0em" id="S3.SS3.p4.1.m1.17.17.3.3" xref="S3.SS3.p4.1.m1.17.17.3.3.cmml">​</mo><mrow id="S3.SS3.p4.1.m1.17.17.3.4" xref="S3.SS3.p4.1.m1.17.17.3.4.cmml"><mi id="S3.SS3.p4.1.m1.17.17.3.4.1" xref="S3.SS3.p4.1.m1.17.17.3.4.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS3.p4.1.m1.17.17.3.4a" xref="S3.SS3.p4.1.m1.17.17.3.4.cmml">⁡</mo><mi id="S3.SS3.p4.1.m1.17.17.3.4.2" xref="S3.SS3.p4.1.m1.17.17.3.4.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.17.17.3.3a" xref="S3.SS3.p4.1.m1.17.17.3.3.cmml">​</mo><mrow id="S3.SS3.p4.1.m1.17.17.3.2.1" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.cmml"><mo stretchy="false" id="S3.SS3.p4.1.m1.17.17.3.2.1.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.cmml">(</mo><mrow id="S3.SS3.p4.1.m1.17.17.3.2.1.1" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.cmml"><msubsup id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.cmml"><mi id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.2.cmml">x</mi><mi id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.3.cmml">a</mi><mrow id="S3.SS3.p4.1.m1.8.8.2.4" xref="S3.SS3.p4.1.m1.8.8.2.3.cmml"><mi id="S3.SS3.p4.1.m1.7.7.1.1" xref="S3.SS3.p4.1.m1.7.7.1.1.cmml">i</mi><mo id="S3.SS3.p4.1.m1.8.8.2.4.1" xref="S3.SS3.p4.1.m1.8.8.2.3.cmml">,</mo><mi id="S3.SS3.p4.1.m1.8.8.2.2" xref="S3.SS3.p4.1.m1.8.8.2.2.cmml">j</mi></mrow></msubsup><mo fence="false" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.3.cmml">|</mo><mrow id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.3.cmml"><msubsup id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.2.cmml">x</mi><mrow id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.cmml"><mi id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.1" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.1.cmml">​</mo><msub id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.cmml"><mi id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.2.cmml">v</mi><mn id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.3.cmml">0</mn></msub></mrow><mrow id="S3.SS3.p4.1.m1.10.10.2.4" xref="S3.SS3.p4.1.m1.10.10.2.3.cmml"><mn id="S3.SS3.p4.1.m1.9.9.1.1" xref="S3.SS3.p4.1.m1.9.9.1.1.cmml">1</mn><mo id="S3.SS3.p4.1.m1.10.10.2.4.1" xref="S3.SS3.p4.1.m1.10.10.2.3.cmml">,</mo><mn id="S3.SS3.p4.1.m1.10.10.2.2" xref="S3.SS3.p4.1.m1.10.10.2.2.cmml">1</mn></mrow></msubsup><mo id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p4.1.m1.14.14" xref="S3.SS3.p4.1.m1.14.14.cmml">…</mi><mo id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.4" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.3.cmml">,</mo><msubsup id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.cmml"><mi id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.2.cmml">x</mi><mrow id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.cmml"><mi id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.1" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.1.cmml">​</mo><msub id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.cmml"><mi id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.2" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.2.cmml">v</mi><mn id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.3.cmml">0</mn></msub></mrow><mrow id="S3.SS3.p4.1.m1.12.12.2.2" xref="S3.SS3.p4.1.m1.12.12.2.3.cmml"><mi id="S3.SS3.p4.1.m1.11.11.1.1" xref="S3.SS3.p4.1.m1.11.11.1.1.cmml">i</mi><mo id="S3.SS3.p4.1.m1.12.12.2.2.2" xref="S3.SS3.p4.1.m1.12.12.2.3.cmml">,</mo><mrow id="S3.SS3.p4.1.m1.12.12.2.2.1" xref="S3.SS3.p4.1.m1.12.12.2.2.1.cmml"><mi id="S3.SS3.p4.1.m1.12.12.2.2.1.2" xref="S3.SS3.p4.1.m1.12.12.2.2.1.2.cmml">j</mi><mo id="S3.SS3.p4.1.m1.12.12.2.2.1.1" xref="S3.SS3.p4.1.m1.12.12.2.2.1.1.cmml">−</mo><mn id="S3.SS3.p4.1.m1.12.12.2.2.1.3" xref="S3.SS3.p4.1.m1.12.12.2.2.1.3.cmml">1</mn></mrow></mrow></msubsup></mrow></mrow><mo stretchy="false" id="S3.SS3.p4.1.m1.17.17.3.2.1.3" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.17b"><apply id="S3.SS3.p4.1.m1.17.17.cmml" xref="S3.SS3.p4.1.m1.17.17"><plus id="S3.SS3.p4.1.m1.17.17.4.cmml" xref="S3.SS3.p4.1.m1.17.17.4"></plus><apply id="S3.SS3.p4.1.m1.15.15.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1"><times id="S3.SS3.p4.1.m1.15.15.1.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.2"></times><ci id="S3.SS3.p4.1.m1.15.15.1.3.cmml" xref="S3.SS3.p4.1.m1.15.15.1.3">𝛾</ci><apply id="S3.SS3.p4.1.m1.15.15.1.4.cmml" xref="S3.SS3.p4.1.m1.15.15.1.4"><log id="S3.SS3.p4.1.m1.15.15.1.4.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.4.1"></log><ci id="S3.SS3.p4.1.m1.15.15.1.4.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.4.2">𝑝</ci></apply><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1"><csymbol cd="latexml" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.3">conditional</csymbol><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4">superscript</csymbol><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4">subscript</csymbol><ci id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.2">𝑥</ci><ci id="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.3.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.4.2.3">𝑎</ci></apply><list id="S3.SS3.p4.1.m1.2.2.2.3.cmml" xref="S3.SS3.p4.1.m1.2.2.2.4"><ci id="S3.SS3.p4.1.m1.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1.1.1">𝑖</ci><ci id="S3.SS3.p4.1.m1.2.2.2.2.cmml" xref="S3.SS3.p4.1.m1.2.2.2.2">𝑗</ci></list></apply><list id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.3.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2"><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.2">𝑥</ci><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3"><times id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.2">𝑎</ci><ci id="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.1.1.1.2.3.3">𝑣</ci></apply></apply><list id="S3.SS3.p4.1.m1.4.4.2.3.cmml" xref="S3.SS3.p4.1.m1.4.4.2.4"><cn type="integer" id="S3.SS3.p4.1.m1.3.3.1.1.cmml" xref="S3.SS3.p4.1.m1.3.3.1.1">1</cn><cn type="integer" id="S3.SS3.p4.1.m1.4.4.2.2.cmml" xref="S3.SS3.p4.1.m1.4.4.2.2">1</cn></list></apply><ci id="S3.SS3.p4.1.m1.13.13.cmml" xref="S3.SS3.p4.1.m1.13.13">…</ci><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2">superscript</csymbol><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.2">𝑥</ci><apply id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3"><times id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.1"></times><ci id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.2">𝑎</ci><ci id="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.SS3.p4.1.m1.15.15.1.1.1.1.2.2.2.2.3.3">𝑣</ci></apply></apply><list id="S3.SS3.p4.1.m1.6.6.2.3.cmml" xref="S3.SS3.p4.1.m1.6.6.2.2"><ci id="S3.SS3.p4.1.m1.5.5.1.1.cmml" xref="S3.SS3.p4.1.m1.5.5.1.1">𝑖</ci><apply id="S3.SS3.p4.1.m1.6.6.2.2.1.cmml" xref="S3.SS3.p4.1.m1.6.6.2.2.1"><minus id="S3.SS3.p4.1.m1.6.6.2.2.1.1.cmml" xref="S3.SS3.p4.1.m1.6.6.2.2.1.1"></minus><ci id="S3.SS3.p4.1.m1.6.6.2.2.1.2.cmml" xref="S3.SS3.p4.1.m1.6.6.2.2.1.2">𝑗</ci><cn type="integer" id="S3.SS3.p4.1.m1.6.6.2.2.1.3.cmml" xref="S3.SS3.p4.1.m1.6.6.2.2.1.3">1</cn></apply></list></apply></list></apply></apply><apply id="S3.SS3.p4.1.m1.17.17.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3"><times id="S3.SS3.p4.1.m1.17.17.3.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.3"></times><apply id="S3.SS3.p4.1.m1.16.16.2.1.1.1.cmml" xref="S3.SS3.p4.1.m1.16.16.2.1.1"><minus id="S3.SS3.p4.1.m1.16.16.2.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.1"></minus><cn type="integer" id="S3.SS3.p4.1.m1.16.16.2.1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.2">1</cn><ci id="S3.SS3.p4.1.m1.16.16.2.1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.16.16.2.1.1.1.3">𝛾</ci></apply><apply id="S3.SS3.p4.1.m1.17.17.3.4.cmml" xref="S3.SS3.p4.1.m1.17.17.3.4"><log id="S3.SS3.p4.1.m1.17.17.3.4.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.4.1"></log><ci id="S3.SS3.p4.1.m1.17.17.3.4.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.4.2">𝑝</ci></apply><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1"><csymbol cd="latexml" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.3">conditional</csymbol><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4">superscript</csymbol><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4">subscript</csymbol><ci id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.2">𝑥</ci><ci id="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.4.2.3">𝑎</ci></apply><list id="S3.SS3.p4.1.m1.8.8.2.3.cmml" xref="S3.SS3.p4.1.m1.8.8.2.4"><ci id="S3.SS3.p4.1.m1.7.7.1.1.cmml" xref="S3.SS3.p4.1.m1.7.7.1.1">𝑖</ci><ci id="S3.SS3.p4.1.m1.8.8.2.2.cmml" xref="S3.SS3.p4.1.m1.8.8.2.2">𝑗</ci></list></apply><list id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2"><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1">superscript</csymbol><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.2">𝑥</ci><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3"><times id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.1"></times><ci id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.2">𝑎</ci><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3">subscript</csymbol><ci id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.2">𝑣</ci><cn type="integer" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.1.1.1.2.3.3.3">0</cn></apply></apply></apply><list id="S3.SS3.p4.1.m1.10.10.2.3.cmml" xref="S3.SS3.p4.1.m1.10.10.2.4"><cn type="integer" id="S3.SS3.p4.1.m1.9.9.1.1.cmml" xref="S3.SS3.p4.1.m1.9.9.1.1">1</cn><cn type="integer" id="S3.SS3.p4.1.m1.10.10.2.2.cmml" xref="S3.SS3.p4.1.m1.10.10.2.2">1</cn></list></apply><ci id="S3.SS3.p4.1.m1.14.14.cmml" xref="S3.SS3.p4.1.m1.14.14">…</ci><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2">superscript</csymbol><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2">subscript</csymbol><ci id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.2">𝑥</ci><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3"><times id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.1"></times><ci id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.2">𝑎</ci><apply id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.1.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3">subscript</csymbol><ci id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.2.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.2">𝑣</ci><cn type="integer" id="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.3.cmml" xref="S3.SS3.p4.1.m1.17.17.3.2.1.1.2.2.2.2.3.3.3">0</cn></apply></apply></apply><list id="S3.SS3.p4.1.m1.12.12.2.3.cmml" xref="S3.SS3.p4.1.m1.12.12.2.2"><ci id="S3.SS3.p4.1.m1.11.11.1.1.cmml" xref="S3.SS3.p4.1.m1.11.11.1.1">𝑖</ci><apply id="S3.SS3.p4.1.m1.12.12.2.2.1.cmml" xref="S3.SS3.p4.1.m1.12.12.2.2.1"><minus id="S3.SS3.p4.1.m1.12.12.2.2.1.1.cmml" xref="S3.SS3.p4.1.m1.12.12.2.2.1.1"></minus><ci id="S3.SS3.p4.1.m1.12.12.2.2.1.2.cmml" xref="S3.SS3.p4.1.m1.12.12.2.2.1.2">𝑗</ci><cn type="integer" id="S3.SS3.p4.1.m1.12.12.2.2.1.3.cmml" xref="S3.SS3.p4.1.m1.12.12.2.2.1.3">1</cn></apply></list></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.17c">\gamma\log p(x_{a}^{i,j}|x_{av}^{1,1},...,x_{av}^{i,j-1})+(1-\gamma)\log p(x_{a}^{i,j}|x_{av_{0}}^{1,1},...,x_{av_{0}}^{i,j-1})</annotation></semantics></math>, where <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="x_{av_{0}}" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><msub id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">x</mi><mrow id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml"><mi id="S3.SS3.p4.2.m2.1.1.3.2" xref="S3.SS3.p4.2.m2.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.2.m2.1.1.3.1" xref="S3.SS3.p4.2.m2.1.1.3.1.cmml">​</mo><msub id="S3.SS3.p4.2.m2.1.1.3.3" xref="S3.SS3.p4.2.m2.1.1.3.3.cmml"><mi id="S3.SS3.p4.2.m2.1.1.3.3.2" xref="S3.SS3.p4.2.m2.1.1.3.3.2.cmml">v</mi><mn id="S3.SS3.p4.2.m2.1.1.3.3.3" xref="S3.SS3.p4.2.m2.1.1.3.3.3.cmml">0</mn></msub></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2">𝑥</ci><apply id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3"><times id="S3.SS3.p4.2.m2.1.1.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.3.1"></times><ci id="S3.SS3.p4.2.m2.1.1.3.2.cmml" xref="S3.SS3.p4.2.m2.1.1.3.2">𝑎</ci><apply id="S3.SS3.p4.2.m2.1.1.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.3.3.2.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3.2">𝑣</ci><cn type="integer" id="S3.SS3.p4.2.m2.1.1.3.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3.3.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">x_{av_{0}}</annotation></semantics></math> is the fused embedding with learned empty conditioning.
The CFG scale (<math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><mi id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><ci id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">\gamma</annotation></semantics></math>) controls diversity and prompt alignment, with lower scales increasing diversity and higher scales yielding more prompt-aligned results.
After experimenting, we selected <math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="\gamma=6" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><mrow id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><mi id="S3.SS3.p4.4.m4.1.1.2" xref="S3.SS3.p4.4.m4.1.1.2.cmml">γ</mi><mo id="S3.SS3.p4.4.m4.1.1.1" xref="S3.SS3.p4.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><eq id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1.1"></eq><ci id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2">𝛾</ci><cn type="integer" id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">\gamma=6</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">VisualSound Dataset</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Yue <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> show that multimodal hallucinations of Large Vision-Language Models can be reduced by filtering the harmful training data, which in turn improves the generation quality as the model does not create irrelevant content.
Motivated by their finding, we aim to strengthen the relevance and temporal alignment between generated audio and conditional video by curating our training data.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We propose VisualSound, a subset of the VGGSound <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> dataset, filtered for samples with high audio-visual correspondence.
The original dataset consists of <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.p2.1.m1.1a"><mo id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><csymbol cd="latexml" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">\sim</annotation></semantics></math>200k 10-second YouTube videos spanning over 300+ classes.
However, since the original dataset is constructed from in-the-wild videos with low audio-visual correspondence filtering, audio events in some samples exhibit low to no relevance to the events in the visual stream.
For example, the original audio can be replaced with non-related audio like background music, narration, audio effects, or polluted with background sounds.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">We rely on the ImageBind model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> to identify videos with poor audio-visual correspondence.
ImageBind is a state-of-the-art joint embedding model that can embed audio and visual streams into the same feature space, allowing computing the similarity between the modalities using cosine distance.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">We experiment with various similarity thresholds and proceed to train the model.
The proposed dataset has a threshold of 0.3, comprising 77 265 training, 8 357 validation, and 5 425 test samples.
We release VisualSound on our project page.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Datasets and Compared Methods</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We train our model on the VisualSound dataset, proposed in <a href="#S4" title="IV VisualSound Dataset ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span> <span class="ltx_text ltx_ref_tag">IV</span></a>.
For evaluation, we use VGGSound-Sparse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, and the test sets of VGGSound, VisualSound, and Visually Aligned Sound (VAS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.
In particular, the VGGSound test set enables us to evaluate the overall generation quality over a wide range of audio classes.
However, the audio-visual correspondence in the VGGSound is not guaranteed.
In contrast, VGGSound-Sparse and VisualSound give a better view of how well the model aligns sounds with actions over time, as these datasets are curated for strong audio-visual relevance.
VGGSound-Sparse has 444 human-verified videos of visible and audible actions in 12 categories like <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_italic">playing tennis</span>, <span id="S5.SS1.p1.1.2" class="ltx_text ltx_font_italic">eating</span>, and <span id="S5.SS1.p1.1.3" class="ltx_text ltx_font_italic">dog barking</span>.
To further evaluate the capabilities of V-AURA, we run experiments on VAS following the train-test split of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
We drop the samples from the <span id="S5.SS1.p1.1.4" class="ltx_text ltx_font_italic">fireworks</span> class since we observed that the temporal alignment with the visual actions is often missing.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The proposed model is compared against three other methods:
SpecVQGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> represents the commonly-used autoregressive baseline, whereas Diff-Foley <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and Frieren <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> serve as state-of-the-art diffusion and RFM-based comparisons respectively.
All the compared methods were trained on VGGSound <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, with SpecVQGAN also on VAS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> and Diff-Foley also on partial AudioSet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
We note that Frieren is published as an ArXiv preprint.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Implementation and Training Details</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.2" class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, we use H.264 and AAC video and audio encodings.
We resample the data to 25 FPS and 44100 Hz.
Video frames are scaled so that the short-side dimensionality is 256 pixels.
Our model is trained with a context length of 2.56 seconds.
During training, we pick a random sub-clip out of the original video while for evaluation and testing, we fix the sub-clip starting times to achieve comparable evaluation results across epochs and experiments.
The batch size is 16 clips per GPU and the models are trained on six NVIDIA V100 32GB GPUs for <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mo id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\sim</annotation></semantics></math>150 epochs until convergence.
The model is optimized using AdamW-optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> with <math id="S5.SS2.p1.2.m2.2" class="ltx_Math" alttext="\beta=[0.9,0.95]" display="inline"><semantics id="S5.SS2.p1.2.m2.2a"><mrow id="S5.SS2.p1.2.m2.2.3" xref="S5.SS2.p1.2.m2.2.3.cmml"><mi id="S5.SS2.p1.2.m2.2.3.2" xref="S5.SS2.p1.2.m2.2.3.2.cmml">β</mi><mo id="S5.SS2.p1.2.m2.2.3.1" xref="S5.SS2.p1.2.m2.2.3.1.cmml">=</mo><mrow id="S5.SS2.p1.2.m2.2.3.3.2" xref="S5.SS2.p1.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S5.SS2.p1.2.m2.2.3.3.2.1" xref="S5.SS2.p1.2.m2.2.3.3.1.cmml">[</mo><mn id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">0.9</mn><mo id="S5.SS2.p1.2.m2.2.3.3.2.2" xref="S5.SS2.p1.2.m2.2.3.3.1.cmml">,</mo><mn id="S5.SS2.p1.2.m2.2.2" xref="S5.SS2.p1.2.m2.2.2.cmml">0.95</mn><mo stretchy="false" id="S5.SS2.p1.2.m2.2.3.3.2.3" xref="S5.SS2.p1.2.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.2b"><apply id="S5.SS2.p1.2.m2.2.3.cmml" xref="S5.SS2.p1.2.m2.2.3"><eq id="S5.SS2.p1.2.m2.2.3.1.cmml" xref="S5.SS2.p1.2.m2.2.3.1"></eq><ci id="S5.SS2.p1.2.m2.2.3.2.cmml" xref="S5.SS2.p1.2.m2.2.3.2">𝛽</ci><interval closure="closed" id="S5.SS2.p1.2.m2.2.3.3.1.cmml" xref="S5.SS2.p1.2.m2.2.3.3.2"><cn type="float" id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">0.9</cn><cn type="float" id="S5.SS2.p1.2.m2.2.2.cmml" xref="S5.SS2.p1.2.m2.2.2">0.95</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.2c">\beta=[0.9,0.95]</annotation></semantics></math>.
Other training parameters are initialized following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.
The training code and models will be publicly released.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Evaluation Metrics</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">To achieve more consistent estimates, we generate 10 samples per test video (if not stated otherwise) and average predictions, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
For a fair comparison, we clip the videos from other methods to match our model’s context size of 2.56 seconds.
Following a common practice, we use the Fréchet Audio Distance (FAD) to judge overall audio quality and Kullback-Leibler Divergence (KLD) to evaluate the relevance of the ground truth audio with the generated audio.
Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we use Image Bind (IB) to define the relevance between the conditional video stream and generated audio.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.3" class="ltx_p">In addition, we propose a synchronization score, <span id="S5.SS3.p2.3.1" class="ltx_text ltx_font_italic">Sync</span>, as a metric of temporal alignment between the generated audio and the visual input.
To this end, we rely on a pre-trained general-purpose audio-visual synchronization model, Synchformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, that classifies a temporal offset between audio and visual traces into 21 classes ranging from <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="-2" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mo id="S5.SS3.p2.1.m1.1.1a" xref="S5.SS3.p2.1.m1.1.1.cmml">−</mo><mn id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><minus id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"></minus><cn type="integer" id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">-2</annotation></semantics></math> to <math id="S5.SS3.p2.2.m2.1" class="ltx_Math" alttext="+2" display="inline"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mo id="S5.SS3.p2.2.m2.1.1a" xref="S5.SS3.p2.2.m2.1.1.cmml">+</mo><mn id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><plus id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"></plus><cn type="integer" id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">+2</annotation></semantics></math> sec. with <math id="S5.SS3.p2.3.m3.1" class="ltx_Math" alttext="0.2" display="inline"><semantics id="S5.SS3.p2.3.m3.1a"><mn id="S5.SS3.p2.3.m3.1.1" xref="S5.SS3.p2.3.m3.1.1.cmml">0.2</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.3.m3.1b"><cn type="float" id="S5.SS3.p2.3.m3.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1">0.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.3.m3.1c">0.2</annotation></semantics></math>-sec. increments.
The final metric is a mean absolute offset among all generated samples in milliseconds.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.5.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.6.2" class="ltx_text ltx_font_italic">Results</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para ltx_noindent">
<p id="S5.SS4.p1.1" class="ltx_p"><span id="S5.SS4.p1.1.1" class="ltx_text ltx_font_bold">Visually guided audio generation.</span>
We report the results in <a href="#S5.T1" title="In V-D Results ‣ V Experiments ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">I</span></a>.
We were not able to evaluate Frieren <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> on VAS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, since the code nor samples are publicly available.
V-AURA exceeds all the compared methods in temporal quality (Sync) and relevance (KLD, IB) across all the datasets while outperforming or maintaining a comparable overall audio quality (FAD).
Especially, the evaluation on VGGSound-Sparse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> highlights the V-AURA’s ability to generate aligned audio (Sync) compared to other methods, whereas results on VisualSound emphasize V-AURA’s strong ability to generate relevant audio (KLD, IB).
Only in terms of FAD, Fieren obtains slightly better performance.
<a href="#S5.F2" title="In V-D Results ‣ V Experiments ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a> highlights the temporal generation quality of V-AURA as all <span id="S5.SS4.p1.1.2" class="ltx_text ltx_font_italic">hits</span> are aligned with the ground truth.
Due to the low video framerate (4 FPS) of Diff-Foley <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and Frieren, detecting a series of rapid hits with precise timings becomes unfeasible.
We provide more samples on our project page for subjective evaluation.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.20" class="ltx_tabular ltx_align_middle">
<tr id="S5.T1.1.1" class="ltx_tr">
<td id="S5.T1.1.1.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;" colspan="6"><span id="S5.T1.1.1.1.1" class="ltx_text ltx_font_bold">VGGSound <math id="S5.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.m1.1b"><ci id="S5.T1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S5.T1.5.5" class="ltx_tr">
<td id="S5.T1.5.5.5" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.5.5.5.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S5.T1.5.5.6" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.5.5.6.1" class="ltx_text ltx_font_bold">Type</span></td>
<td id="S5.T1.2.2.1" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.2.2.1.1" class="ltx_text ltx_font_bold">KLD <math id="S5.T1.2.2.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.2.2.1.1.m1.1a"><mo stretchy="false" id="S5.T1.2.2.1.1.m1.1.1" xref="S5.T1.2.2.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.1.1.m1.1b"><ci id="S5.T1.2.2.1.1.m1.1.1.cmml" xref="S5.T1.2.2.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T1.3.3.2" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.3.3.2.1" class="ltx_text ltx_font_bold">FAD <math id="S5.T1.3.3.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.3.3.2.1.m1.1a"><mo stretchy="false" id="S5.T1.3.3.2.1.m1.1.1" xref="S5.T1.3.3.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.2.1.m1.1b"><ci id="S5.T1.3.3.2.1.m1.1.1.cmml" xref="S5.T1.3.3.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T1.4.4.3" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.4.4.3.1" class="ltx_text ltx_font_bold">IB <math id="S5.T1.4.4.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.4.4.3.1.m1.1a"><mo stretchy="false" id="S5.T1.4.4.3.1.m1.1.1" xref="S5.T1.4.4.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.3.1.m1.1b"><ci id="S5.T1.4.4.3.1.m1.1.1.cmml" xref="S5.T1.4.4.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.3.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S5.T1.5.5.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;">
<span id="S5.T1.5.5.4.2" class="ltx_text"></span> <span id="S5.T1.5.5.4.1" class="ltx_text">
<span id="S5.T1.5.5.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T1.5.5.4.1.1.1" class="ltx_tr">
<span id="S5.T1.5.5.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.5.5.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Sync</span> <math id="S5.T1.5.5.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.5.5.4.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.5.5.4.1.1.1.1.m1.1.1" xref="S5.T1.5.5.4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.4.1.1.1.1.m1.1b"><ci id="S5.T1.5.5.4.1.1.1.1.m1.1.1.cmml" xref="S5.T1.5.5.4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span></span><span id="S5.T1.5.5.4.3" class="ltx_text"></span>
</td>
</tr>
<tr id="S5.T1.20.21" class="ltx_tr">
<td id="S5.T1.20.21.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">SpecVQGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</td>
<td id="S5.T1.20.21.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">AR</td>
<td id="S5.T1.20.21.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">3.16</td>
<td id="S5.T1.20.21.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">6.41</td>
<td id="S5.T1.20.21.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">10.09</td>
<td id="S5.T1.20.21.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">409</td>
</tr>
<tr id="S5.T1.20.22" class="ltx_tr">
<td id="S5.T1.20.22.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">Diff-Foley <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S5.T1.20.22.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">DM</td>
<td id="S5.T1.20.22.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">3.23</td>
<td id="S5.T1.20.22.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">5.62</td>
<td id="S5.T1.20.22.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">16.88</td>
<td id="S5.T1.20.22.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">321</td>
</tr>
<tr id="S5.T1.20.23" class="ltx_tr">
<td id="S5.T1.20.23.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">Frieren <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</td>
<td id="S5.T1.20.23.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">RFM</td>
<td id="S5.T1.20.23.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">2.95</td>
<td id="S5.T1.20.23.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.23.4.1" class="ltx_text ltx_font_bold">1.43</span></td>
<td id="S5.T1.20.23.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">19.56</td>
<td id="S5.T1.20.23.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">277</td>
</tr>
<tr id="S5.T1.20.24" class="ltx_tr">
<td id="S5.T1.20.24.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">V-AURA (Ours)</td>
<td id="S5.T1.20.24.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">AR</td>
<td id="S5.T1.20.24.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.24.3.1" class="ltx_text ltx_font_bold">2.31</span></td>
<td id="S5.T1.20.24.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">1.92</td>
<td id="S5.T1.20.24.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.24.5.1" class="ltx_text ltx_font_bold">25.01</span></td>
<td id="S5.T1.20.24.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.24.6.1" class="ltx_text ltx_font_bold">155</span></td>
</tr>
<tr id="S5.T1.6.6" class="ltx_tr">
<td id="S5.T1.6.6.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;" colspan="6"><span id="S5.T1.6.6.1.1" class="ltx_text ltx_font_bold">VAS <math id="S5.T1.6.6.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.6.6.1.1.m1.1a"><mo stretchy="false" id="S5.T1.6.6.1.1.m1.1.1" xref="S5.T1.6.6.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.1.1.m1.1b"><ci id="S5.T1.6.6.1.1.m1.1.1.cmml" xref="S5.T1.6.6.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S5.T1.10.10" class="ltx_tr">
<td id="S5.T1.10.10.5" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.10.10.5.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S5.T1.10.10.6" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.10.10.6.1" class="ltx_text ltx_font_bold">Type</span></td>
<td id="S5.T1.7.7.1" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.7.7.1.1" class="ltx_text ltx_font_bold">KLD <math id="S5.T1.7.7.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.7.7.1.1.m1.1a"><mo stretchy="false" id="S5.T1.7.7.1.1.m1.1.1" xref="S5.T1.7.7.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.1.1.m1.1b"><ci id="S5.T1.7.7.1.1.m1.1.1.cmml" xref="S5.T1.7.7.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T1.8.8.2" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.8.8.2.1" class="ltx_text ltx_font_bold">FAD <math id="S5.T1.8.8.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.8.8.2.1.m1.1a"><mo stretchy="false" id="S5.T1.8.8.2.1.m1.1.1" xref="S5.T1.8.8.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.8.8.2.1.m1.1b"><ci id="S5.T1.8.8.2.1.m1.1.1.cmml" xref="S5.T1.8.8.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.8.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T1.9.9.3" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.9.9.3.1" class="ltx_text ltx_font_bold">IB <math id="S5.T1.9.9.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.9.9.3.1.m1.1a"><mo stretchy="false" id="S5.T1.9.9.3.1.m1.1.1" xref="S5.T1.9.9.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.9.9.3.1.m1.1b"><ci id="S5.T1.9.9.3.1.m1.1.1.cmml" xref="S5.T1.9.9.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.9.9.3.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S5.T1.10.10.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;">
<span id="S5.T1.10.10.4.2" class="ltx_text"></span> <span id="S5.T1.10.10.4.1" class="ltx_text">
<span id="S5.T1.10.10.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T1.10.10.4.1.1.1" class="ltx_tr">
<span id="S5.T1.10.10.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.10.10.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Sync</span> <math id="S5.T1.10.10.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.10.10.4.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.10.10.4.1.1.1.1.m1.1.1" xref="S5.T1.10.10.4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.10.10.4.1.1.1.1.m1.1b"><ci id="S5.T1.10.10.4.1.1.1.1.m1.1.1.cmml" xref="S5.T1.10.10.4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.10.10.4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span></span><span id="S5.T1.10.10.4.3" class="ltx_text"></span>
</td>
</tr>
<tr id="S5.T1.20.25" class="ltx_tr">
<td id="S5.T1.20.25.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">SpecVQGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</td>
<td id="S5.T1.20.25.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">AR</td>
<td id="S5.T1.20.25.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">3.13</td>
<td id="S5.T1.20.25.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">7.77</td>
<td id="S5.T1.20.25.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">11.18</td>
<td id="S5.T1.20.25.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">536</td>
</tr>
<tr id="S5.T1.20.26" class="ltx_tr">
<td id="S5.T1.20.26.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">Diff-Foley <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S5.T1.20.26.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">DM</td>
<td id="S5.T1.20.26.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">3.27</td>
<td id="S5.T1.20.26.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">8.35</td>
<td id="S5.T1.20.26.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">15.71</td>
<td id="S5.T1.20.26.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">263</td>
</tr>
<tr id="S5.T1.20.27" class="ltx_tr">
<td id="S5.T1.20.27.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">V-AURA (Ours)</td>
<td id="S5.T1.20.27.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">AR</td>
<td id="S5.T1.20.27.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.27.3.1" class="ltx_text ltx_font_bold">1.98</span></td>
<td id="S5.T1.20.27.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.27.4.1" class="ltx_text ltx_font_bold">1.98</span></td>
<td id="S5.T1.20.27.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.27.5.1" class="ltx_text ltx_font_bold">29.00</span></td>
<td id="S5.T1.20.27.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.27.6.1" class="ltx_text ltx_font_bold">120</span></td>
</tr>
<tr id="S5.T1.11.11" class="ltx_tr">
<td id="S5.T1.11.11.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;" colspan="6"><span id="S5.T1.11.11.1.1" class="ltx_text ltx_font_bold">VGGSound-Sparse <math id="S5.T1.11.11.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.11.11.1.1.m1.1a"><mo stretchy="false" id="S5.T1.11.11.1.1.m1.1.1" xref="S5.T1.11.11.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.11.11.1.1.m1.1b"><ci id="S5.T1.11.11.1.1.m1.1.1.cmml" xref="S5.T1.11.11.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.11.11.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S5.T1.15.15" class="ltx_tr">
<td id="S5.T1.15.15.5" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.15.15.5.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S5.T1.15.15.6" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.15.15.6.1" class="ltx_text ltx_font_bold">Type</span></td>
<td id="S5.T1.12.12.1" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.12.12.1.1" class="ltx_text ltx_font_bold">KLD <math id="S5.T1.12.12.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.12.12.1.1.m1.1a"><mo stretchy="false" id="S5.T1.12.12.1.1.m1.1.1" xref="S5.T1.12.12.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.12.12.1.1.m1.1b"><ci id="S5.T1.12.12.1.1.m1.1.1.cmml" xref="S5.T1.12.12.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.12.12.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T1.13.13.2" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.13.13.2.1" class="ltx_text ltx_font_bold">FAD <math id="S5.T1.13.13.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.13.13.2.1.m1.1a"><mo stretchy="false" id="S5.T1.13.13.2.1.m1.1.1" xref="S5.T1.13.13.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.13.13.2.1.m1.1b"><ci id="S5.T1.13.13.2.1.m1.1.1.cmml" xref="S5.T1.13.13.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.13.13.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T1.14.14.3" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.14.14.3.1" class="ltx_text ltx_font_bold">IB <math id="S5.T1.14.14.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.14.14.3.1.m1.1a"><mo stretchy="false" id="S5.T1.14.14.3.1.m1.1.1" xref="S5.T1.14.14.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.14.14.3.1.m1.1b"><ci id="S5.T1.14.14.3.1.m1.1.1.cmml" xref="S5.T1.14.14.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.14.14.3.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S5.T1.15.15.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;">
<span id="S5.T1.15.15.4.2" class="ltx_text"></span> <span id="S5.T1.15.15.4.1" class="ltx_text">
<span id="S5.T1.15.15.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T1.15.15.4.1.1.1" class="ltx_tr">
<span id="S5.T1.15.15.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.15.15.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Sync</span> <math id="S5.T1.15.15.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.15.15.4.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.15.15.4.1.1.1.1.m1.1.1" xref="S5.T1.15.15.4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.15.15.4.1.1.1.1.m1.1b"><ci id="S5.T1.15.15.4.1.1.1.1.m1.1.1.cmml" xref="S5.T1.15.15.4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.15.15.4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span></span><span id="S5.T1.15.15.4.3" class="ltx_text"></span>
</td>
</tr>
<tr id="S5.T1.20.28" class="ltx_tr">
<td id="S5.T1.20.28.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">SpecVQGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</td>
<td id="S5.T1.20.28.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">AR</td>
<td id="S5.T1.20.28.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">3.56</td>
<td id="S5.T1.20.28.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">12.93</td>
<td id="S5.T1.20.28.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">11.01</td>
<td id="S5.T1.20.28.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">411</td>
</tr>
<tr id="S5.T1.20.29" class="ltx_tr">
<td id="S5.T1.20.29.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">Diff-Foley <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S5.T1.20.29.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">DM</td>
<td id="S5.T1.20.29.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">2.87</td>
<td id="S5.T1.20.29.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">8.92</td>
<td id="S5.T1.20.29.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">22.08</td>
<td id="S5.T1.20.29.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">302</td>
</tr>
<tr id="S5.T1.20.30" class="ltx_tr">
<td id="S5.T1.20.30.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">Frieren <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</td>
<td id="S5.T1.20.30.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">RFM</td>
<td id="S5.T1.20.30.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">2.70</td>
<td id="S5.T1.20.30.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.30.4.1" class="ltx_text ltx_font_bold">2.79</span></td>
<td id="S5.T1.20.30.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">22.72</td>
<td id="S5.T1.20.30.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">236</td>
</tr>
<tr id="S5.T1.20.31" class="ltx_tr">
<td id="S5.T1.20.31.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">V-AURA (Ours)</td>
<td id="S5.T1.20.31.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">AR</td>
<td id="S5.T1.20.31.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.31.3.1" class="ltx_text ltx_font_bold">1.93</span></td>
<td id="S5.T1.20.31.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">3.55</td>
<td id="S5.T1.20.31.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.31.5.1" class="ltx_text ltx_font_bold">28.92</span></td>
<td id="S5.T1.20.31.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.31.6.1" class="ltx_text ltx_font_bold">49</span></td>
</tr>
<tr id="S5.T1.16.16" class="ltx_tr">
<td id="S5.T1.16.16.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;" colspan="6"><span id="S5.T1.16.16.1.1" class="ltx_text ltx_font_bold">VisualSound <math id="S5.T1.16.16.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.16.16.1.1.m1.1a"><mo stretchy="false" id="S5.T1.16.16.1.1.m1.1.1" xref="S5.T1.16.16.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.16.16.1.1.m1.1b"><ci id="S5.T1.16.16.1.1.m1.1.1.cmml" xref="S5.T1.16.16.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.16.16.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S5.T1.20.20" class="ltx_tr">
<td id="S5.T1.20.20.5" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.20.5.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S5.T1.20.20.6" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.20.6.1" class="ltx_text ltx_font_bold">Type</span></td>
<td id="S5.T1.17.17.1" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.17.17.1.1" class="ltx_text ltx_font_bold">KLD <math id="S5.T1.17.17.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.17.17.1.1.m1.1a"><mo stretchy="false" id="S5.T1.17.17.1.1.m1.1.1" xref="S5.T1.17.17.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.17.17.1.1.m1.1b"><ci id="S5.T1.17.17.1.1.m1.1.1.cmml" xref="S5.T1.17.17.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.17.17.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T1.18.18.2" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.18.18.2.1" class="ltx_text ltx_font_bold">FAD <math id="S5.T1.18.18.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.18.18.2.1.m1.1a"><mo stretchy="false" id="S5.T1.18.18.2.1.m1.1.1" xref="S5.T1.18.18.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.18.18.2.1.m1.1b"><ci id="S5.T1.18.18.2.1.m1.1.1.cmml" xref="S5.T1.18.18.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.18.18.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T1.19.19.3" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.19.19.3.1" class="ltx_text ltx_font_bold">IB <math id="S5.T1.19.19.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.19.19.3.1.m1.1a"><mo stretchy="false" id="S5.T1.19.19.3.1.m1.1.1" xref="S5.T1.19.19.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.19.19.3.1.m1.1b"><ci id="S5.T1.19.19.3.1.m1.1.1.cmml" xref="S5.T1.19.19.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.19.19.3.1.m1.1c">\uparrow</annotation></semantics></math></span></td>
<td id="S5.T1.20.20.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:7.0pt;padding-right:7.0pt;">
<span id="S5.T1.20.20.4.2" class="ltx_text"></span> <span id="S5.T1.20.20.4.1" class="ltx_text">
<span id="S5.T1.20.20.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T1.20.20.4.1.1.1" class="ltx_tr">
<span id="S5.T1.20.20.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.20.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Sync</span> <math id="S5.T1.20.20.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.20.20.4.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.20.20.4.1.1.1.1.m1.1.1" xref="S5.T1.20.20.4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.20.20.4.1.1.1.1.m1.1b"><ci id="S5.T1.20.20.4.1.1.1.1.m1.1.1.cmml" xref="S5.T1.20.20.4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.20.20.4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span></span><span id="S5.T1.20.20.4.3" class="ltx_text"></span>
</td>
</tr>
<tr id="S5.T1.20.32" class="ltx_tr">
<td id="S5.T1.20.32.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">SpecVQGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</td>
<td id="S5.T1.20.32.2" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">AR</td>
<td id="S5.T1.20.32.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">3.41</td>
<td id="S5.T1.20.32.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">9.02</td>
<td id="S5.T1.20.32.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">10.87</td>
<td id="S5.T1.20.32.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:7.0pt;padding-right:7.0pt;">423</td>
</tr>
<tr id="S5.T1.20.33" class="ltx_tr">
<td id="S5.T1.20.33.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">Diff-Foley <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S5.T1.20.33.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">DM</td>
<td id="S5.T1.20.33.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">2.84</td>
<td id="S5.T1.20.33.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">7.24</td>
<td id="S5.T1.20.33.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">19.79</td>
<td id="S5.T1.20.33.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">338</td>
</tr>
<tr id="S5.T1.20.34" class="ltx_tr">
<td id="S5.T1.20.34.1" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">Frieren <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</td>
<td id="S5.T1.20.34.2" class="ltx_td ltx_align_left" style="padding-left:7.0pt;padding-right:7.0pt;">RFM</td>
<td id="S5.T1.20.34.3" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">2.45</td>
<td id="S5.T1.20.34.4" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.34.4.1" class="ltx_text ltx_font_bold">2.03</span></td>
<td id="S5.T1.20.34.5" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">23.39</td>
<td id="S5.T1.20.34.6" class="ltx_td ltx_align_right" style="padding-left:7.0pt;padding-right:7.0pt;">285</td>
</tr>
<tr id="S5.T1.20.35" class="ltx_tr">
<td id="S5.T1.20.35.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:7.0pt;padding-right:7.0pt;">V-AURA (Ours)</td>
<td id="S5.T1.20.35.2" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:7.0pt;padding-right:7.0pt;">AR</td>
<td id="S5.T1.20.35.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.35.3.1" class="ltx_text ltx_font_bold">1.76</span></td>
<td id="S5.T1.20.35.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:7.0pt;padding-right:7.0pt;">3.27</td>
<td id="S5.T1.20.35.5" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.35.5.1" class="ltx_text ltx_font_bold">29.50</span></td>
<td id="S5.T1.20.35.6" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:7.0pt;padding-right:7.0pt;"><span id="S5.T1.20.35.6.1" class="ltx_text ltx_font_bold">138</span></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>
<span id="S5.T1.22.1" class="ltx_text ltx_font_bold">V-AURA outperforms or achieves comparable results in visually guided audio generation compared to the state-of-the-art.</span> Type denotes the type of the generative model: autoregressive (AR), diffusion (DM), or rectified flow matching (RFM). Results on VAS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> were calculated over 3 samples. We could not evaluate Frieren on VAS as its code or samples are not publicly available. Out of all the models, only SpecVQGAN was trained also on VAS.
</figcaption>
</figure>
<div id="S5.SS4.p2" class="ltx_para ltx_noindent">
<p id="S5.SS4.p2.1" class="ltx_p"><span id="S5.SS4.p2.1.1" class="ltx_text ltx_font_bold">Different VisualSound variants.</span>
<a href="#S4" title="IV VisualSound Dataset ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">IV</span></a> presents the novel video dataset with high audio-visual relevance, where the relevance is defined as the cosine similarity between audio and visual embeddings calculated with ImageBind <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
<a href="#S5.T2" title="In V-D Results ‣ V Experiments ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">II</span></a> compares the performance of our model on VGGSound-Sparse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> after training on the dataset with increasing filtering level on cosine similarity from 0.0 to 0.4 and more.
We make the following observations:
1) The generated samples are more relevant (IB, KLD) and temporally aligned (Sync) to the visual conditioning as the noisy training samples are filtered.
2) As the dataset gets smaller, the overall quality (FAD) slightly deteriorates.
We believe that it is due to the model’s inability to produce audio that would reflect the underlying probability distribution of the original unfiltered dataset.
3) The temporal alignment performance is maximised at 0.3, and filtering the dataset more makes it too small to learn meaningful representations and generalize across hundreds of data classes.
4) As the dataset size drops, the training time reduces, while the generation performance improves or remains comparable.</p>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="/html/2409.13689/assets/spec-illustration-toosmall_v4.png" id="S5.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="269" height="155" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S5.F2.2.1" class="ltx_text ltx_font_bold">V-AURA generates temporally matching audio.</span> Diff-Foley <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> misses some hits, whereas Frieren <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> generates too many. SpecVQGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> does not generate distinguishable hits.</figcaption>
</figure>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.5" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.5.5" class="ltx_tr">
<td id="S5.T2.5.5.6" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.5.6.1" class="ltx_text ltx_font_bold">Thresh.</span></td>
<td id="S5.T2.5.5.7" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.5.7.1" class="ltx_text ltx_font_bold"># Samples</span></td>
<td id="S5.T2.1.1.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="S5.T2.1.1.1.1" class="ltx_text ltx_font_bold">Train</span> <span id="S5.T2.1.1.1.2" class="ltx_ERROR undefined">\faClockO</span><math id="S5.T2.1.1.1.m1.1" class="ltx_Math" alttext="\;\downarrow" display="inline"><semantics id="S5.T2.1.1.1.m1.1a"><mo stretchy="false" id="S5.T2.1.1.1.m1.1.1" xref="S5.T2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.m1.1c">\;\downarrow</annotation></semantics></math>
</td>
<td id="S5.T2.2.2.2" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.2.2.2.1" class="ltx_text ltx_font_bold">KLD <math id="S5.T2.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T2.2.2.2.1.m1.1.1" xref="S5.T2.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.1.m1.1b"><ci id="S5.T2.2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T2.3.3.3" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.3.3.3.1" class="ltx_text ltx_font_bold">FAD <math id="S5.T2.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.3.3.3.1.m1.1a"><mo stretchy="false" id="S5.T2.3.3.3.1.m1.1.1" xref="S5.T2.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.1.m1.1b"><ci id="S5.T2.3.3.3.1.m1.1.1.cmml" xref="S5.T2.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T2.4.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="S5.T2.4.4.4.2" class="ltx_text"></span> <span id="S5.T2.4.4.4.1" class="ltx_text">
<span id="S5.T2.4.4.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.4.4.4.1.1.1" class="ltx_tr">
<span id="S5.T2.4.4.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.4.4.4.1.1.1.1.1" class="ltx_text ltx_font_bold">IB <math id="S5.T2.4.4.4.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.4.4.4.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T2.4.4.4.1.1.1.1.1.m1.1.1" xref="S5.T2.4.4.4.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.1.1.1.1.1.m1.1b"><ci id="S5.T2.4.4.4.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.4.4.4.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></span></span>
</span></span><span id="S5.T2.4.4.4.3" class="ltx_text"></span>
</td>
<td id="S5.T2.5.5.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="S5.T2.5.5.5.2" class="ltx_text"></span> <span id="S5.T2.5.5.5.1" class="ltx_text">
<span id="S5.T2.5.5.5.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.5.5.5.1.1.1" class="ltx_tr">
<span id="S5.T2.5.5.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.5.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Sync</span> <math id="S5.T2.5.5.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.5.5.5.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T2.5.5.5.1.1.1.1.m1.1.1" xref="S5.T2.5.5.5.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.1.1.1.1.m1.1b"><ci id="S5.T2.5.5.5.1.1.1.1.m1.1.1.cmml" xref="S5.T2.5.5.5.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span></span><span id="S5.T2.5.5.5.3" class="ltx_text"></span>
</td>
</tr>
<tr id="S5.T2.5.6" class="ltx_tr">
<td id="S5.T2.5.6.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">0.0</td>
<td id="S5.T2.5.6.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">155 591</td>
<td id="S5.T2.5.6.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">708</td>
<td id="S5.T2.5.6.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">1.94</td>
<td id="S5.T2.5.6.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">3.16</td>
<td id="S5.T2.5.6.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">28.51</td>
<td id="S5.T2.5.6.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">60</td>
</tr>
<tr id="S5.T2.5.7" class="ltx_tr">
<td id="S5.T2.5.7.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;">0.2</td>
<td id="S5.T2.5.7.2" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">119 469</td>
<td id="S5.T2.5.7.3" class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">662</td>
<td id="S5.T2.5.7.4" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">1.94</td>
<td id="S5.T2.5.7.5" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">3.49</td>
<td id="S5.T2.5.7.6" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">28.66</td>
<td id="S5.T2.5.7.7" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;">59</td>
</tr>
<tr id="S5.T2.5.8" class="ltx_tr">
<td id="S5.T2.5.8.1" class="ltx_td ltx_align_left" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.8.1.1" class="ltx_text ltx_font_bold">0.3</span></td>
<td id="S5.T2.5.8.2" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.8.2.1" class="ltx_text ltx_font_bold">77 265</span></td>
<td id="S5.T2.5.8.3" class="ltx_td ltx_align_right ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.8.3.1" class="ltx_text ltx_font_bold">278</span></td>
<td id="S5.T2.5.8.4" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.8.4.1" class="ltx_text ltx_font_bold">1.93</span></td>
<td id="S5.T2.5.8.5" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.8.5.1" class="ltx_text ltx_font_bold">3.55</span></td>
<td id="S5.T2.5.8.6" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.8.6.1" class="ltx_text ltx_font_bold">28.92</span></td>
<td id="S5.T2.5.8.7" class="ltx_td ltx_align_right" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="S5.T2.5.8.7.1" class="ltx_text ltx_font_bold">49</span></td>
</tr>
<tr id="S5.T2.5.9" class="ltx_tr">
<td id="S5.T2.5.9.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">0.4</td>
<td id="S5.T2.5.9.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">33 225</td>
<td id="S5.T2.5.9.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;">168</td>
<td id="S5.T2.5.9.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">1.97</td>
<td id="S5.T2.5.9.5" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">4.11</td>
<td id="S5.T2.5.9.6" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">27.31</td>
<td id="S5.T2.5.9.7" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;">71</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span><span id="S5.T2.7.1" class="ltx_text ltx_font_bold">Removing samples with low audio-visual correspondence allows us to reduce the training time and increase relevance and temporal quality.</span> The bolded row indicates the preferred threshold. A higher threshold indicates greater similarity between the corresponding audio and visual embeddings in the dataset. Reported samples are training samples and the training time is in GPU hours. Models were evaluated on VGGSound-Sparse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</figcaption>
</figure>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.4" class="ltx_tabular ltx_align_middle">
<tr id="S5.T3.4.4" class="ltx_tr">
<td id="S5.T3.4.4.5" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.4.4.5.1" class="ltx_text ltx_font_bold">Cond. methods</span></td>
<td id="S5.T3.1.1.1" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.1.1.1.1" class="ltx_text ltx_font_bold">KLD <math id="S5.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T3.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.m1.1b"><ci id="S5.T3.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.2.2.2" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.2.2.2.1" class="ltx_text ltx_font_bold">FAD <math id="S5.T3.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T3.2.2.2.1.m1.1.1" xref="S5.T3.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.1.m1.1b"><ci id="S5.T3.2.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T3.3.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S5.T3.3.3.3.2" class="ltx_text"></span> <span id="S5.T3.3.3.3.1" class="ltx_text">
<span id="S5.T3.3.3.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.3.3.3.1.1.1" class="ltx_tr">
<span id="S5.T3.3.3.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.3.3.3.1.1.1.1.1" class="ltx_text ltx_font_bold">IB <math id="S5.T3.3.3.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T3.3.3.3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T3.3.3.3.1.1.1.1.1.m1.1.1" xref="S5.T3.3.3.3.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.1.1.1.1.1.m1.1b"><ci id="S5.T3.3.3.3.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.3.3.3.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></span></span>
</span></span><span id="S5.T3.3.3.3.3" class="ltx_text"></span>
</td>
<td id="S5.T3.4.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:10.0pt;padding-right:10.0pt;">
<span id="S5.T3.4.4.4.2" class="ltx_text"></span> <span id="S5.T3.4.4.4.1" class="ltx_text">
<span id="S5.T3.4.4.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.4.4.4.1.1.1" class="ltx_tr">
<span id="S5.T3.4.4.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.4.4.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Sync</span> <math id="S5.T3.4.4.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.4.4.4.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T3.4.4.4.1.1.1.1.m1.1.1" xref="S5.T3.4.4.4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.1.1.1.1.m1.1b"><ci id="S5.T3.4.4.4.1.1.1.1.m1.1.1.cmml" xref="S5.T3.4.4.4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span></span><span id="S5.T3.4.4.4.3" class="ltx_text"></span>
</td>
</tr>
<tr id="S5.T3.4.5" class="ltx_tr">
<td id="S5.T3.4.5.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">Prepend</td>
<td id="S5.T3.4.5.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">1.94</td>
<td id="S5.T3.4.5.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">4.11</td>
<td id="S5.T3.4.5.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">26.44</td>
<td id="S5.T3.4.5.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:10.0pt;padding-right:10.0pt;">105</td>
</tr>
<tr id="S5.T3.4.6" class="ltx_tr">
<td id="S5.T3.4.6.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.4.6.1.1" class="ltx_text ltx_font_bold">Fusion</span></td>
<td id="S5.T3.4.6.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.4.6.2.1" class="ltx_text ltx_font_bold">1.93</span></td>
<td id="S5.T3.4.6.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.4.6.3.1" class="ltx_text ltx_font_bold">3.55</span></td>
<td id="S5.T3.4.6.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.4.6.4.1" class="ltx_text ltx_font_bold">28.92</span></td>
<td id="S5.T3.4.6.5" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:10.0pt;padding-right:10.0pt;"><span id="S5.T3.4.6.5.1" class="ltx_text ltx_font_bold">49</span></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span><span id="S5.T3.6.1" class="ltx_text ltx_font_bold">Cross-modal feature fusion improves synthesized audio.</span> The bolded row indicates the preferred conditioning method. Models were evaluated on VGGSound-Sparse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</figcaption>
</figure>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.4" class="ltx_tabular ltx_align_middle">
<tr id="S5.T4.4.4" class="ltx_tr">
<td id="S5.T4.4.4.5" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.4.4.5.1" class="ltx_text ltx_font_bold">CFG-scale</span></td>
<td id="S5.T4.1.1.1" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.1.1.1.1" class="ltx_text ltx_font_bold">KLD <math id="S5.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T4.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T4.1.1.1.1.m1.1.1" xref="S5.T4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b"><ci id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T4.2.2.2" class="ltx_td ltx_align_right ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.2.2.2.1" class="ltx_text ltx_font_bold">FAD <math id="S5.T4.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T4.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T4.2.2.2.1.m1.1.1" xref="S5.T4.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.1.m1.1b"><ci id="S5.T4.2.2.2.1.m1.1.1.cmml" xref="S5.T4.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S5.T4.3.3.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;">
<span id="S5.T4.3.3.3.2" class="ltx_text"></span> <span id="S5.T4.3.3.3.1" class="ltx_text">
<span id="S5.T4.3.3.3.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T4.3.3.3.1.1.1" class="ltx_tr">
<span id="S5.T4.3.3.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.3.3.3.1.1.1.1.1" class="ltx_text ltx_font_bold">IB <math id="S5.T4.3.3.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T4.3.3.3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T4.3.3.3.1.1.1.1.1.m1.1.1" xref="S5.T4.3.3.3.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.1.1.1.1.1.m1.1b"><ci id="S5.T4.3.3.3.1.1.1.1.1.m1.1.1.cmml" xref="S5.T4.3.3.3.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span></span></span>
</span></span><span id="S5.T4.3.3.3.3" class="ltx_text"></span>
</td>
<td id="S5.T4.4.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:12.0pt;padding-right:12.0pt;">
<span id="S5.T4.4.4.4.2" class="ltx_text"></span> <span id="S5.T4.4.4.4.1" class="ltx_text">
<span id="S5.T4.4.4.4.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T4.4.4.4.1.1.1" class="ltx_tr">
<span id="S5.T4.4.4.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.4.4.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Sync</span> <math id="S5.T4.4.4.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T4.4.4.4.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T4.4.4.4.1.1.1.1.m1.1.1" xref="S5.T4.4.4.4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.1.1.1.1.m1.1b"><ci id="S5.T4.4.4.4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.4.4.4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span>
</span></span><span id="S5.T4.4.4.4.3" class="ltx_text"></span>
</td>
</tr>
<tr id="S5.T4.4.5" class="ltx_tr">
<td id="S5.T4.4.5.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">1</td>
<td id="S5.T4.4.5.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">2.48</td>
<td id="S5.T4.4.5.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">11.44</td>
<td id="S5.T4.4.5.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">16.94</td>
<td id="S5.T4.4.5.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:12.0pt;padding-right:12.0pt;">155</td>
</tr>
<tr id="S5.T4.4.6" class="ltx_tr">
<td id="S5.T4.4.6.1" class="ltx_td ltx_align_left" style="padding-left:12.0pt;padding-right:12.0pt;">3</td>
<td id="S5.T4.4.6.2" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">2.04</td>
<td id="S5.T4.4.6.3" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">5.30</td>
<td id="S5.T4.4.6.4" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">26.71</td>
<td id="S5.T4.4.6.5" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">80</td>
</tr>
<tr id="S5.T4.4.7" class="ltx_tr">
<td id="S5.T4.4.7.1" class="ltx_td ltx_align_left" style="padding-left:12.0pt;padding-right:12.0pt;">5</td>
<td id="S5.T4.4.7.2" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">1.94</td>
<td id="S5.T4.4.7.3" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">3.75</td>
<td id="S5.T4.4.7.4" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">28.52</td>
<td id="S5.T4.4.7.5" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">52</td>
</tr>
<tr id="S5.T4.4.8" class="ltx_tr">
<td id="S5.T4.4.8.1" class="ltx_td ltx_align_left" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.4.8.1.1" class="ltx_text ltx_font_bold">6</span></td>
<td id="S5.T4.4.8.2" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.4.8.2.1" class="ltx_text ltx_font_bold">1.91</span></td>
<td id="S5.T4.4.8.3" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.4.8.3.1" class="ltx_text ltx_font_bold">3.50</span></td>
<td id="S5.T4.4.8.4" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.4.8.4.1" class="ltx_text ltx_font_bold">28.97</span></td>
<td id="S5.T4.4.8.5" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;"><span id="S5.T4.4.8.5.1" class="ltx_text ltx_font_bold">50</span></td>
</tr>
<tr id="S5.T4.4.9" class="ltx_tr">
<td id="S5.T4.4.9.1" class="ltx_td ltx_align_left" style="padding-left:12.0pt;padding-right:12.0pt;">7</td>
<td id="S5.T4.4.9.2" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">1.91</td>
<td id="S5.T4.4.9.3" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">3.74</td>
<td id="S5.T4.4.9.4" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">29.16</td>
<td id="S5.T4.4.9.5" class="ltx_td ltx_align_right" style="padding-left:12.0pt;padding-right:12.0pt;">55</td>
</tr>
<tr id="S5.T4.4.10" class="ltx_tr">
<td id="S5.T4.4.10.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:12.0pt;padding-right:12.0pt;">9</td>
<td id="S5.T4.4.10.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:12.0pt;padding-right:12.0pt;">1.91</td>
<td id="S5.T4.4.10.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:12.0pt;padding-right:12.0pt;">4.08</td>
<td id="S5.T4.4.10.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:12.0pt;padding-right:12.0pt;">29.66</td>
<td id="S5.T4.4.10.5" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:12.0pt;padding-right:12.0pt;">53</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span><span id="S5.T4.6.1" class="ltx_text ltx_font_bold">CFG-scale significantly impacts the generated audio quality.</span> A scale of 6 (bolded) is preferred since it produces a good balance between the metrics. Results were calculated over 3 VGGSound-Sparse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> samples.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS5.5.1.1" class="ltx_text">V-E</span> </span><span id="S5.SS5.6.2" class="ltx_text ltx_font_italic">Ablations</span>
</h3>

<div id="S5.SS5.p1" class="ltx_para ltx_noindent">
<p id="S5.SS5.p1.1" class="ltx_p"><span id="S5.SS5.p1.1.1" class="ltx_text ltx_font_bold">Conditioning methods.</span>
<a href="#S5.T3" title="In V-D Results ‣ V Experiments ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">III</span></a> shows the impact of different conditioning methods on the performance of V-AURA.
Previous autoregressive methods have prepended the conditional embeddings to the audio embedding sequence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
We observe that fusing the modalities allows V-AURA to generate more relevant (IB, KLD), better temporally aligned (Sync), and higher quality (FAD) audio.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para ltx_noindent">
<p id="S5.SS5.p2.1" class="ltx_p"><span id="S5.SS5.p2.1.1" class="ltx_text ltx_font_bold">Classifier-Free Guidance scale.</span>
<a href="#S5.T4" title="In V-D Results ‣ V Experiments ‣ Temporally Aligned Audio for Video with Autoregression" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">IV</span></a> illustrates the effect of CFG-scale to the performance of V-AURA.
We emphasize temporal alignment (Sync) and thus select <math id="S5.SS5.p2.1.m1.1" class="ltx_Math" alttext="\gamma=6" display="inline"><semantics id="S5.SS5.p2.1.m1.1a"><mrow id="S5.SS5.p2.1.m1.1.1" xref="S5.SS5.p2.1.m1.1.1.cmml"><mi id="S5.SS5.p2.1.m1.1.1.2" xref="S5.SS5.p2.1.m1.1.1.2.cmml">γ</mi><mo id="S5.SS5.p2.1.m1.1.1.1" xref="S5.SS5.p2.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS5.p2.1.m1.1.1.3" xref="S5.SS5.p2.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.1.m1.1b"><apply id="S5.SS5.p2.1.m1.1.1.cmml" xref="S5.SS5.p2.1.m1.1.1"><eq id="S5.SS5.p2.1.m1.1.1.1.cmml" xref="S5.SS5.p2.1.m1.1.1.1"></eq><ci id="S5.SS5.p2.1.m1.1.1.2.cmml" xref="S5.SS5.p2.1.m1.1.1.2">𝛾</ci><cn type="integer" id="S5.SS5.p2.1.m1.1.1.3.cmml" xref="S5.SS5.p2.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.1.m1.1c">\gamma=6</annotation></semantics></math>.
Also, the overall generation quality (FAD) reaches the highest with the same scale.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We introduced V-AURA, an autoregressive video-to-audio model that generates audio that is both temporally and semantically aligned with the conditional video stream.
V-AURA consistently outperforms or achieves comparable performance with the current state-of-the-art methods, showing significant improvements in relevance and temporal accuracy.
Improvements are achieved with a high-framerate visual feature extractor combined with a cross-modal feature fusion that emphasises the natural co-occurrence of audio and visual events better than conventional conditioning methods.
Also, training V-AURA using a dataset curated for strong audio-visual correspondence mitigates hallucinations and improves the relevance and temporal quality of synthesised audio.
We proposed the dataset as a novel benchmark for video-to-audio models and refer to it as VisualSound.
Additionally, we proposed an objective temporal alignment metric for the average offset between conditional video and generated audio.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
H. Wang, J. Ma, S. Pascual, R. Cartwright, and W. Cai, “V2a-mapper: A
lightweight solution for vision-to-audio generation by connecting foundation
models,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, 2024.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
S. Luo, C. Yan, C. Hu, and H. Zhao, “Diff-foley: Synchronized video-to-audio
synthesis with latent diffusion models,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2024.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y. Wang, W. Guo, R. Huang, J. Huang, Z. Wang, F. You, R. Li, and Z. Zhao,
“Frieren: Efficient video-to-audio generation with rectified flow
matching,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.00320</em>, 2024.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Y. Zhang, Y. Gu, Y. Zeng, Z. Xing, Y. Wang, Z. Wu, and K. Chen, “Foleycrafter:
Bring silent videos to life with lifelike and synchronized sounds,”
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2407.01494</em>, 2024.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Y. Xing, Y. He, Z. Tian, X. Wang, and Q. Chen, “Seeing and hearing:
Open-domain visual-audio generation with diffusion latent aligners,” in
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2024.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
V. Iashin and E. Rahtu, “Taming visually guided sound generation,” in
<em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">BMVC</em>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
X. Mei, V. Nagaraja, G. L. Lan, Z. Ni, E. Chang, Y. Shi, and V. Chandra,
“Foleygen: Visually-guided audio generation,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2309.10537</em>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
R. Sheffer and Y. Adi, “I hear your true colors: Image guided audio
generation,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Y. Du, Z. Chen, J. Salamon, B. Russell, and A. Owens, “Conditional generation
of audio from video via foley analogies,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
A. Vaswani, “Attention is all you need,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
R. Kumar, P. Seetharaman, A. Luebs, I. Kumar, and K. Kumar, “High-fidelity
audio compression with improved rvqgan,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2024.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
H. Chen, W. Xie, A. Vedaldi, and A. Zisserman, “Vggsound: A large-scale
audio-visual dataset,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
J. F. Gemmeke, D. P. W. Ellis, D. Freedman, A. Jansen, W. Lawrence, R. C.
Moore, M. Plakal, and M. Ritter, “Audio set: An ontology and human-labeled
dataset for audio events,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2017.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
S. Ghose and J. Prevost, “Foleygan: Visually guided generative adversarial
network-based synchronous sound generation in silent videos,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Multimedia</em>, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
P. Chen, Y. Zhang, M. Tan, H. Xiao, D. Huang, and C. Gan, “Generating visually
aligned sound from videos,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE TIP</em>, vol. 29, 2020. [Online].
Available: <a target="_blank" href="http://dx.doi.org/10.1109/TIP.2020.3009820" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1109/TIP.2020.3009820</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
V. Iashin, W. Xie, E. Rahtu, and A. Zisserman, “Synchformer: Efficient
synchronization from sparse cues,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ICASSP</em>, 2024.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
G. Bertasius, H. Wang, and L. Torresani, “Is space-time attention all you need
for video understanding?” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S. Xie, C. Sun, J. Huang, Z. Tu, and K. Murphy, “Rethinking spatiotemporal
feature learning: Speed-accuracy trade-offs in video classification,” in
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">ECCV</em>, 2018.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2016.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
D. Hendrycks and K. Gimpel, “Gaussian error linear units (gelus),”
<em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.08415</em>, 2016.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J. Copet, F. Kreuk, I. Gat, T. Remez, D. Kant, G. Synnaeve, Y. Adi, and
A. Défossez, “Simple and controllable music generation,”
<em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2024.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Ho and T. Salimans, “Classifier-free diffusion guidance,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2207.12598</em>, 2022.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix,
B. Rozière, N. Goyal, E. Hambro, F. Azhar <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Llama: Open
and efficient foundation language models,” <em id="bib.bib23.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2302.13971</em>, 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei,
N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Llama 2:
Open foundation and fine-tuned chat models,” <em id="bib.bib24.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2307.09288</em>, 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
P. Sun, Y. Jiang, S. Chen, S. Zhang, B. Peng, P. Luo, and Z. Yuan,
“Autoregressive model beats diffusion: Llama for scalable image
generation,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2406.06525</em>, 2024.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
F. Kreuk, G. Synnaeve, A. Polyak, U. Singer, A. Défossez, J. Copet, D. Parikh,
Y. Taigman, and Y. Adi, “Audiogen: Textually guided audio generation,”
<em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Z. Yue, L. Zhang, and Q. Jin, “Less is more: Mitigating multimodal
hallucination from an eos decision perspective,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2402.14545</em>, 2024.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
R. Girdhar, A. El-Nouby, Z. Liu, M. Singh, K. V. Alwala, A. Joulin, and
I. Misra, “Imagebind: One embedding space to bind them all,” in
<em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2023.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
V. Iashin, W. Xie, E. Rahtu, and A. Zisserman, “Sparse in space and time:
Audio-visual synchronisation with trainable selectors,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">BMVC</em>,
2022.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
P. Chen, Y. Zhang, M. Tan, H. Xiao, D. Huang, and C. Gan, “Generating visually
aligned sound from videos,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Image Processing</em>,
2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
I. Loshchilov, “Decoupled weight decay regularization,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1711.05101</em>, 2017.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
B. McKinzie, Z. Gan, J.-P. Fauconnier, S. Dodge, B. Zhang, P. Dufter, D. Shah,
X. Du, F. Peng, F. Weers <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Mm1: Methods, analysis &amp; insights
from multimodal llm pre-training,” <em id="bib.bib32.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2403.09611</em>,
2024.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.13688" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.13689" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.13689">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.13689" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.13690" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 21:18:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
